{
    "author": "nhatleSummer22",
    "message": "Merge branch 'tensorflow:master' into nhatle/fix_fused_bn_bug_tf_serving",
    "sha": "682659f1d20f53d82008992cc183a09a70ee2a66",
    "files": [
        {
            "sha": "2e3912041d9cf2ca1b566d6a6f1cbdc5365997cc",
            "filename": ".github/workflows/arm-cd.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-cd.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-cd.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Farm-cd.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -52,12 +52,12 @@ jobs:\n         run: find /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/. -name . -o -prune -exec sudo rm -rf -- {} + || true\n       - name: Checkout repository for nightly (skipped for releases)\n         if: ${{ github.event_name == 'schedule' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n         with:\n           ref: 'nightly'\n       - name: Checkout repository for releases (skipped for nightly)\n         if: ${{ github.event_name == 'push' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       - name: Build and test pip wheel\n         shell: bash\n         run: |"
        },
        {
            "sha": "54903a6998b090dbc56be95aa6cd46bf38e878d4",
            "filename": ".github/workflows/arm-ci-extended-cpp.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci-extended-cpp.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci-extended-cpp.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Farm-ci-extended-cpp.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -50,12 +50,12 @@ jobs:\n         run: find /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/. -name . -o -prune -exec sudo rm -rf -- {} + || true\n       - name: Checkout repository for nightly (skipped for releases)\n         if: ${{ github.event_name == 'schedule' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n         with:\n           ref: 'nightly'\n       - name: Checkout repository\n         if: ${{ github.event_name == 'push' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       - name: Build binary and run C++ tests\n         shell: bash\n         run: |"
        },
        {
            "sha": "2235cfc2d986dad4a14f79a2d71a7dcdf06d9933",
            "filename": ".github/workflows/arm-ci-extended.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci-extended.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci-extended.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Farm-ci-extended.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -51,12 +51,12 @@ jobs:\n         run: find /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/. -name . -o -prune -exec sudo rm -rf -- {} + || true\n       - name: Checkout repository for nightly (skipped for releases)\n         if: ${{ github.event_name == 'schedule' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n         with:\n           ref: 'nightly'\n       - name: Checkout repository\n         if: ${{ github.event_name == 'push' }}\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       - name: Build binary and run python tests on nightly for all python versions\n         shell: bash\n         run: |"
        },
        {
            "sha": "a141bdd4676852f2f019149c805899fd701fdcf5",
            "filename": ".github/workflows/arm-ci.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Farm-ci.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Farm-ci.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -47,7 +47,7 @@ jobs:\n         shell: bash\n         run: find /home/ubuntu/actions-runner/_work/tensorflow/tensorflow/. -name . -o -prune -exec sudo rm -rf -- {} + || true\n       - name: Checkout repository\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       - name: Build binary and run python tests\n         shell: bash\n         run: |"
        },
        {
            "sha": "6421e08ccf0839be632eaa61d47d3f823e327f60",
            "filename": ".github/workflows/cffconvert.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fcffconvert.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fcffconvert.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fcffconvert.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -30,7 +30,7 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n       - name: Check out a copy of the repository\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n \n       - name: Check whether the citation metadata from CITATION.cff is valid\n         uses: citation-file-format/cffconvert-github-action@4cf11baa70a673bfdf9dad0acc7ee33b3f4b6084 # v2.0.0"
        },
        {
            "sha": "28e610437757f16229865e821a2b20119403518b",
            "filename": ".github/workflows/issue-on-pr-rollback.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fissue-on-pr-rollback.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fissue-on-pr-rollback.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fissue-on-pr-rollback.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -33,7 +33,7 @@ jobs:\n       startsWith(github.event.head_commit.message, 'Rollback of PR #')\n     steps:\n       - name: Checkout repo\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       - name: Create a new Github Issue\n         uses: actions/github-script@60a0d83039c74a4aee543508d2ffcb1c3799cdea # v7.0.1\n         with:"
        },
        {
            "sha": "34d28df277c6eb01e00bf3ab43a6d8ff8e470f87",
            "filename": ".github/workflows/osv-scanner-scheduled.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fosv-scanner-scheduled.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fosv-scanner-scheduled.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fosv-scanner-scheduled.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -28,7 +28,7 @@ permissions:\n jobs:\n   scan-scheduled:\n     if: github.repository == 'tensorflow/tensorflow'\n-    uses: \"google/osv-scanner-action/.github/workflows/osv-scanner-reusable.yml@v2.1.0\"\n+    uses: \"google/osv-scanner-action/.github/workflows/osv-scanner-reusable.yml@v2.2.2\"\n     with:\n       scan-args: |-\n         --lockfile=requirements.txt:./requirements_lock_3_9.txt"
        },
        {
            "sha": "26f1ac696996a881e60a5c822514ce088103decf",
            "filename": ".github/workflows/pylint-presubmit.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fpylint-presubmit.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fpylint-presubmit.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fpylint-presubmit.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -28,7 +28,7 @@ jobs:\n     runs-on: ubuntu-latest\n     steps:\n     - name: Checkout code\n-      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n     - name: Get file changes\n       id: get_file_changes\n       uses: trilom/file-changes-action@a6ca26c14274c33b15e6499323aac178af06ad4b # v1.2.4"
        },
        {
            "sha": "69e03a040ae1a29c1b8e1ce8c2ff37036692368d",
            "filename": ".github/workflows/release-branch-cherrypick.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Frelease-branch-cherrypick.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Frelease-branch-cherrypick.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Frelease-branch-cherrypick.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -45,7 +45,7 @@ jobs:\n     if: github.repository == 'tensorflow/tensorflow' # Don't do this in forks\n     steps:\n     - name: Checkout code\n-      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n       with:\n         ref: ${{ github.event.inputs.release_branch }}\n     - name: Get some helpful info for formatting"
        },
        {
            "sha": "87393916383aa25c7e3dc7539a35af6728c8349f",
            "filename": ".github/workflows/scorecards-analysis.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fscorecards-analysis.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fscorecards-analysis.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fscorecards-analysis.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -41,7 +41,7 @@ jobs:\n \n     steps:\n       - name: \"Checkout code\"\n-        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n         with:\n           persist-credentials: false\n \n@@ -64,6 +64,6 @@ jobs:\n       # Upload the results to GitHub's code scanning dashboard (optional).\n       # Commenting out will disable upload of results to your repo's Code Scanning dashboard\n       - name: \"Upload to code-scanning\"\n-        uses: github/codeql-action/upload-sarif@51f77329afa6477de8c49fc9c7046c15b9a4e79d # v3.29.5\n+        uses: github/codeql-action/upload-sarif@3c3833e0f8c1c83d449a7478aa59c036a9165498 # v3.29.5\n         with:\n           sarif_file: results.sarif"
        },
        {
            "sha": "a8dba883f5ff14e04cb770cbb69f2d7b02e8742c",
            "filename": ".github/workflows/update-rbe.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fupdate-rbe.yml",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/.github%2Fworkflows%2Fupdate-rbe.yml",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.github%2Fworkflows%2Fupdate-rbe.yml?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -30,7 +30,7 @@ jobs:\n     if: github.repository == 'tensorflow/tensorflow' # Don't do this in forks\n     steps:\n     - name: Checkout code\n-      uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2\n+      uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0\n     - name: Update the RBE Configs\n       run: |\n         function map() {"
        },
        {
            "sha": "a125bcc15b527f38ae4e00e06efaab7f1fd01648",
            "filename": "WORKSPACE",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/WORKSPACE",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/WORKSPACE",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/WORKSPACE?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -80,9 +80,15 @@ tf_workspace0()\n \n load(\n     \"@local_xla//third_party/py:python_wheel.bzl\",\n+    \"nvidia_wheel_versions_repository\",\n     \"python_wheel_version_suffix_repository\",\n )\n \n+nvidia_wheel_versions_repository(\n+    name = \"nvidia_wheel_versions\",\n+    versions_source = \"//ci/official/requirements_updater:nvidia-requirements.txt\",\n+)\n+\n python_wheel_version_suffix_repository(name = \"tf_wheel_version_suffix\")\n \n load("
        },
        {
            "sha": "0a29465aff05198d2ae722cc092633e87c5d9b22",
            "filename": "ci/official/requirements_updater/BUILD.bazel",
            "status": "modified",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2FBUILD.bazel",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2FBUILD.bazel",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2FBUILD.bazel?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,14 +16,27 @@\n load(\"@python//:defs.bzl\", \"compile_pip_requirements\")\n load(\"@python_version_repo//:py_version.bzl\", \"REQUIREMENTS\")\n \n+# TODO(ybaturina): Remove once TF is migrated to CUDA 12.9.\n+genrule(\n+    name = \"nvidia_constraints\",\n+    srcs = [\"nvidia-requirements.txt\"],\n+    outs = [\"nvidia-constraints.txt\"],\n+    cmd = \"\"\"sed -E \"s/>=/==/\" $(location nvidia-requirements.txt) > $@;\"\"\",\n+)\n+\n compile_pip_requirements(\n     name = \"requirements\",\n+    srcs = [\n+        \"nvidia-requirements.txt\",\n+        \"requirements.in\",\n+        \":nvidia_constraints\",\n+    ],\n     extra_args = [\n         \"--allow-unsafe\",\n         \"--build-isolation\",\n         \"--rebuild\",\n+        \"-c $(location :nvidia_constraints)\",\n     ],\n     generate_hashes = True,\n-    requirements_in = \"requirements.in\",\n     requirements_txt = REQUIREMENTS,\n )"
        },
        {
            "sha": "bad185ceac778deec62fb175817558a8cdf0dec0",
            "filename": "ci/official/requirements_updater/numpy1_requirements/requirements.in",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements.in",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements.in",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements.in?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -34,21 +34,6 @@ packaging==23.2\n setuptools==78.1.1\n jax==0.4.7\n zstandard==0.23.0\n-# NVIDIA CUDA dependencies\n-# Note that the wheels are downloaded only when the targets in bazel command\n-# contain dependencies on these wheels.\n-nvidia-cublas-cu12 == 12.5.3.2\n-nvidia-cuda-cupti-cu12 == 12.5.82\n-nvidia-cuda-nvrtc-cu12 == 12.5.82\n-nvidia-cuda-runtime-cu12 == 12.5.82\n-nvidia-cudnn-cu12 == 9.3.0.75\n-nvidia-cufft-cu12 == 11.2.3.61\n-nvidia-curand-cu12 == 10.3.6.82\n-nvidia-cusolver-cu12 == 11.6.3.83\n-nvidia-cusparse-cu12 == 12.5.1.3\n-nvidia-nccl-cu12 == 2.27.7\n-nvidia-nvjitlink-cu12 == 12.5.82\n-nvidia-nvshmem-cu12>=3.2.5\n # The dependencies below are needed for TF wheel testing.\n tensorflow-io-gcs-filesystem==0.37.1 ; python_version <= \"3.12\"\n libclang >= 13.0.0"
        },
        {
            "sha": "1e4f85c2ab70c7276956fdc9b232f6f27f9f9c3d",
            "filename": "ci/official/requirements_updater/numpy1_requirements/requirements_lock_3_10.txt",
            "status": "modified",
            "additions": 56,
            "deletions": 15,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_10.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_10.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_10.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -407,68 +407,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n-nvidia-nvshmem-cu12==3.3.9 \\\n-    --hash=sha256:2de43cbfe559e16b8e3cb777b95f1fe2ddd5c2cfd79414b09cf9cf099feba2ba \\\n-    --hash=sha256:95ba1e98189c056eb5372bd355ab714b3741a03e6de1e32f167f5240fd967c5f\n-    # via -r ci/official/requirements_updater/requirements.in\n+nvidia-nvshmem-cu12==3.2.5 \\\n+    --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n+    --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "19da7ab86c09706def667adc6e8ea32f14b8dc26",
            "filename": "ci/official/requirements_updater/numpy1_requirements/requirements_lock_3_11.txt",
            "status": "modified",
            "additions": 52,
            "deletions": 12,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_11.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_11.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_11.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -407,69 +407,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n nvidia-nvshmem-cu12==3.2.5 \\\n     --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n     --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "f0b93a1e52b3d5602acd3d9c13863ddb0f112478",
            "filename": "ci/official/requirements_updater/numpy1_requirements/requirements_lock_3_12.txt",
            "status": "modified",
            "additions": 52,
            "deletions": 12,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_12.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_12.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_12.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -407,69 +407,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n nvidia-nvshmem-cu12==3.2.5 \\\n     --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n     --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "9a4144d10d9b315f5c99f8835782d8d1ba82bb74",
            "filename": "ci/official/requirements_updater/numpy1_requirements/requirements_lock_3_9.txt",
            "status": "modified",
            "additions": 56,
            "deletions": 15,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_9.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_9.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnumpy1_requirements%2Frequirements_lock_3_9.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -411,68 +411,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n-nvidia-nvshmem-cu12==3.3.9 \\\n-    --hash=sha256:2de43cbfe559e16b8e3cb777b95f1fe2ddd5c2cfd79414b09cf9cf099feba2ba \\\n-    --hash=sha256:95ba1e98189c056eb5372bd355ab714b3741a03e6de1e32f167f5240fd967c5f\n-    # via -r ci/official/requirements_updater/requirements.in\n+nvidia-nvshmem-cu12==3.2.5 \\\n+    --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n+    --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "e494ea008f858e428f904d4809fe000fb06df48c",
            "filename": "ci/official/requirements_updater/nvidia-requirements.txt",
            "status": "added",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnvidia-requirements.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Fnvidia-requirements.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Fnvidia-requirements.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,16 @@\n+nvidia-cublas-cu12>=12.5.3.2,<13.0\n+nvidia-cuda-cupti-cu12>=12.5.82,<13.0\n+nvidia-cuda-nvcc-cu12>=12.5.82,<13.0\n+nvidia-cuda-nvrtc-cu12>=12.5.82,<13.0\n+nvidia-cuda-runtime-cu12>=12.5.82,<13.0\n+# The upper bound is set for the CUDNN API compatibility.\n+# See\n+# https://docs.nvidia.com/deeplearning/cudnn/backend/latest/developer/forward-compatibility.html#cudnn-api-compatibility\n+nvidia-cudnn-cu12>=9.3.0.75,<10.0\n+nvidia-cufft-cu12>=11.2.3.61,<12.0\n+nvidia-curand-cu12>=10.3.6.82,<11.0\n+nvidia-cusolver-cu12>=11.6.3.83,<12.0\n+nvidia-cusparse-cu12>=12.5.1.3,<13.0\n+nvidia-nccl-cu12>=2.27.7,<3.0\n+nvidia-nvjitlink-cu12>=12.5.82,<13.0\n+nvidia-nvshmem-cu12>=3.2.5\n\\ No newline at end of file"
        },
        {
            "sha": "ce5ecbd998c032ced808325cb7576a24136bf432",
            "filename": "ci/official/requirements_updater/requirements.in",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Frequirements.in",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/ci%2Fofficial%2Frequirements_updater%2Frequirements.in",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/ci%2Fofficial%2Frequirements_updater%2Frequirements.in?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -34,21 +34,6 @@ packaging==23.2\n setuptools==78.1.1\n jax==0.4.7\n zstandard==0.23.0\n-# NVIDIA CUDA dependencies\n-# Note that the wheels are downloaded only when the targets in bazel command\n-# contain dependencies on these wheels.\n-nvidia-cublas-cu12 == 12.5.3.2\n-nvidia-cuda-cupti-cu12 == 12.5.82\n-nvidia-cuda-nvrtc-cu12 == 12.5.82\n-nvidia-cuda-runtime-cu12 == 12.5.82\n-nvidia-cudnn-cu12 == 9.3.0.75\n-nvidia-cufft-cu12 == 11.2.3.61\n-nvidia-curand-cu12 == 10.3.6.82\n-nvidia-cusolver-cu12 == 11.6.3.83\n-nvidia-cusparse-cu12 == 12.5.1.3\n-nvidia-nccl-cu12 == 2.27.7\n-nvidia-nvjitlink-cu12 == 12.5.82\n-nvidia-nvshmem-cu12>=3.2.5\n # The dependencies below are needed for TF wheel testing.\n tensorflow-io-gcs-filesystem==0.37.1 ; python_version <= \"3.12\"\n libclang >= 13.0.0"
        },
        {
            "sha": "34b2ea8a386f1921f14f8897879e791d9c74dbb7",
            "filename": "requirements_lock_3_10.txt",
            "status": "modified",
            "additions": 56,
            "deletions": 15,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_10.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_10.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/requirements_lock_3_10.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -426,68 +426,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n-nvidia-nvshmem-cu12==3.3.9 \\\n-    --hash=sha256:2de43cbfe559e16b8e3cb777b95f1fe2ddd5c2cfd79414b09cf9cf099feba2ba \\\n-    --hash=sha256:95ba1e98189c056eb5372bd355ab714b3741a03e6de1e32f167f5240fd967c5f\n-    # via -r ci/official/requirements_updater/requirements.in\n+nvidia-nvshmem-cu12==3.2.5 \\\n+    --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n+    --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "e7b4bbae6424e55a23a8e586e8da331a6f0c2c4a",
            "filename": "requirements_lock_3_11.txt",
            "status": "modified",
            "additions": 52,
            "deletions": 12,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_11.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_11.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/requirements_lock_3_11.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -426,69 +426,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n nvidia-nvshmem-cu12==3.2.5 \\\n     --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n     --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "6e821e61b1fd412f10a967d1b9e6cbb1fab1372f",
            "filename": "requirements_lock_3_12.txt",
            "status": "modified",
            "additions": 53,
            "deletions": 12,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_12.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_12.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/requirements_lock_3_12.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -426,68 +426,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n nvidia-nvshmem-cu12==3.2.5 \\\n     --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n     --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "4974d7477a6c58363da7c76acb28a1574aa170e6",
            "filename": "requirements_lock_3_13.txt",
            "status": "modified",
            "additions": 52,
            "deletions": 12,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_13.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_13.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/requirements_lock_3_13.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -426,69 +426,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n nvidia-nvshmem-cu12==3.2.5 \\\n     --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n     --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "44318f02618592220d7721d6a30acbb6e93ff7ae",
            "filename": "requirements_lock_3_9.txt",
            "status": "modified",
            "additions": 56,
            "deletions": 15,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_9.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/requirements_lock_3_9.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/requirements_lock_3_9.txt?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -420,68 +420,109 @@ nvidia-cublas-cu12==12.5.3.2 \\\n     --hash=sha256:7d0191251180de606023d396b94d66f66470a0ae96d1dbb906c7656ea0f71eda \\\n     --hash=sha256:ca070ad70e9fa6654084575d01bd001f30cc4665e33d4bb9fc8e0f321caa034b\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cudnn-cu12\n     #   nvidia-cusolver-cu12\n nvidia-cuda-cupti-cu12==12.5.82 \\\n     --hash=sha256:4f835281cf492e2bedd153f5c3de9da8f1d775a419468305e64ce73b3b0c6dc3 \\\n     --hash=sha256:bde77a5feb66752ec61db2adfe47f56b941842825b4c7e2068aff27c9d107953 \\\n     --hash=sha256:d32c06490c6ba35c4323730820c7d0c4c126c04ed58d2f57275adb8d54b138fe\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n+nvidia-cuda-nvcc-cu12==12.5.82 \\\n+    --hash=sha256:6eaa264da57a893ae7606dd80b169d9783444af941697822cb82c8379ffc4957 \\\n+    --hash=sha256:ab02fe922cee01235b7950f045042219fe83e15aceb4cd3c1d36db30b034dec7 \\\n+    --hash=sha256:b03e545b8e8c3ce7ebcd7fc44063180ff52ff01d064ece2127ed90a04ef12cd0\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-nvrtc-cu12==12.5.82 \\\n     --hash=sha256:3dbd97b0104b4bfbc3c4f8c79cd2496307c89c43c29a9f83125f1d76296ff3fd \\\n     --hash=sha256:5bb6a0eb01d4974bb7ca3d48bd3859472debb3c3057a5e7de2b08fbdf35eed7e \\\n     --hash=sha256:e5db37e990056c70953b7772dd778336ef9da0a0b5bb28f9f2a61c2e42b51d78\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cuda-runtime-cu12==12.5.82 \\\n     --hash=sha256:0fd5fbca289bceb9f0690aa9858f06187b554fdeb7e2711dfd5bb3ce58900b46 \\\n     --hash=sha256:3e79a060e126df40fd3a068f3f787eb000fa51b251ec6cd97d09579632687115 \\\n     --hash=sha256:71f015dbf9df05dd71f7480132c6ebf47a6ceb2ab53d7db8e08e4b30ebb87e14\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cudnn-cu12==9.3.0.75 \\\n     --hash=sha256:9ad9c6929ebb5295eb4a1728024666d1c88283373e265a0c5c883e6f9d5cd76d \\\n     --hash=sha256:c5cf7ff3415e446adf195a5b7dd2ba56cd00c3ee78bfdc566e51698931aa4b7f \\\n     --hash=sha256:c819e82eed8cf564b9d37478ea4eab9e87194bb3b7f7f8098bc1f67c9b80f1b6\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cufft-cu12==11.2.3.61 \\\n     --hash=sha256:4a8f6f0ce93c52a50ee83422a80472b5f376054a63f38532d0eab4007e7ef28b \\\n     --hash=sha256:6d45b48a5ee7599e57131129cda2c58544d9b78b95064d3ec3e5c6b96e2b58cc \\\n     --hash=sha256:9a6e8df162585750f61983a638104a48c756aa13f9f48e19ab079b38e3c828b8\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-curand-cu12==10.3.6.82 \\\n     --hash=sha256:0631ba65231260ad832ce233ddda57e7b3b7158eabf000d78e46cbb5bd5b7aae \\\n     --hash=sha256:2823fb27de4e44dbb22394a6adf53aa6e1b013aca0f8c22867d1cfae58405536 \\\n     --hash=sha256:36aabeb5990297bbce3df324ea7c7c13c3aabb140c86d50ab3b23e4ec61672f1\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusolver-cu12==11.6.3.83 \\\n     --hash=sha256:1b8b77d2fe8abe72bb722dafb708cceaeb81f1a03999477f20b33b34f46ab885 \\\n     --hash=sha256:6224732963cba312a84c78114b9a38c4ffabb2e2a6a120923ac99ba6f895c8cf \\\n     --hash=sha256:93cfafacde4428b71778eeb092ec615a02a3d05404da1bcf91c53e3fa1bce42b\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-cusparse-cu12==12.5.1.3 \\\n     --hash=sha256:016df8e993c437e8301e62739f01775cba988fd5253cd4c64173f8e8d2f8e752 \\\n     --hash=sha256:33520db374e2f5ebc976d6faa1852b98c398a57e6f71150fe59705928596ffd1 \\\n     --hash=sha256:7b97fd01f0a61628af99d0efd52132fccc8c18fc5c509f13802dccf0574a19c2\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cusolver-cu12\n nvidia-nccl-cu12==2.27.7 \\\n     --hash=sha256:4617839f3bb730c3845bf9adf92dbe0e009bc53ca5022ed941f2e23fb76e6f17 \\\n     --hash=sha256:de5ba5562f08029a19cb1cd659404b18411ed0d6c90ac5f52f30bf99ad5809aa\n-    # via -r ci/official/requirements_updater/requirements.in\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n nvidia-nvjitlink-cu12==12.5.82 \\\n     --hash=sha256:98103729cc5226e13ca319a10bbf9433bbbd44ef64fe72f45f067cacc14b8d27 \\\n     --hash=sha256:e782564d705ff0bf61ac3e1bf730166da66dd2fe9012f111ede5fc49b64ae697 \\\n     --hash=sha256:f9b37bc5c8cf7509665cb6ada5aaa0ce65618f2332b7d3e78e9790511f111212\n     # via\n-    #   -r ci/official/requirements_updater/requirements.in\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n     #   nvidia-cufft-cu12\n     #   nvidia-cusolver-cu12\n     #   nvidia-cusparse-cu12\n-nvidia-nvshmem-cu12==3.3.9 \\\n-    --hash=sha256:2de43cbfe559e16b8e3cb777b95f1fe2ddd5c2cfd79414b09cf9cf099feba2ba \\\n-    --hash=sha256:95ba1e98189c056eb5372bd355ab714b3741a03e6de1e32f167f5240fd967c5f\n-    # via -r ci/official/requirements_updater/requirements.in\n+nvidia-nvshmem-cu12==3.2.5 \\\n+    --hash=sha256:2f5798d65f1a08f9878aae17cf4d3dcbfe884d1f12cf170556cd40f2be90ca96 \\\n+    --hash=sha256:e076957d5cc72e51061a04f2d46f55df477be53e8a55d0d621be08f7aefe1d00\n+    # via\n+    #   -c ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-constraints.txt\n+    #   -r ci/official/requirements_updater/nvidia-requirements.txt\n opt-einsum==3.3.0 \\\n     --hash=sha256:2455e59e3947d3c275477df7f5205b30635e266fe6dc300e3d9f9646bfcea147 \\\n     --hash=sha256:59f6475f77bbc37dcf7cd748519c0ec60722e91e63ca114e68821c0c54a46549"
        },
        {
            "sha": "6073899502250b36cbb6422b58b435df91647749",
            "filename": "tensorflow/compiler/mlir/lite/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1886,6 +1886,7 @@ tf_cc_binary(\n     srcs = [\n         \":tf_tfl_translate_main\",\n     ],\n+    # visibility = [\"//visibility:public\"], # copybara:uncomment\n     deps = [\n         \":common\",\n         \":converter_flags_proto_cc\","
        },
        {
            "sha": "18289c15a44f229f4a51f1d53a5da52af5549edf",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -251,7 +251,7 @@ bool ShouldFoldOperation(Operation* inst) {\n   int64_t operands_size = get_size(inst->getOperandTypes());\n \n   constexpr int kSizeFactor = 2;\n-  constexpr int64_t kResultsSizeThreshold = (1 << 16);  // 64 Kib =   8 KiB\n+  constexpr int64_t kResultsSizeThreshold = (1 << 19);                // 64 KiB\n   constexpr int64_t kOperandsSizeThreshold = 200L * 1024 * 1024 * 8;  // 200 MiB\n \n   return (operands_size <= kOperandsSizeThreshold) &&"
        },
        {
            "sha": "39cf68d22e743e1f646583a4e91250f9a2220599",
            "filename": "tensorflow/compiler/mlir/lite/stablehlo/transforms/composite_lowering_patterns.td",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fstablehlo%2Ftransforms%2Fcomposite_lowering_patterns.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fstablehlo%2Ftransforms%2Fcomposite_lowering_patterns.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fstablehlo%2Ftransforms%2Fcomposite_lowering_patterns.td?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -244,3 +244,30 @@ def LegalizeCompositePack4Elements1 : Pat<\n         (TFL_PackOp (variadic $i0, $i1, $i2, $i3),\n           (GetCompositeAttributeAs<\"values_count\", \"IntegerAttr\"> $attrs),\n           (GetCompositeAttributeAs<\"axis\", \"IntegerAttr\"> $attrs))>;\n+\n+def LegalizeDynamicSlice : Pat<\n+        (MHLO_CompositeOp:$composite\n+          (variadic $input, $begin, $size),\n+          ConstantStrAttr<StrAttr, \"tfl.slice\">, $attrs, $_, $_),\n+        (TFL_SliceOp $input, $begin, $size)>;\n+\n+def LegalizeDynamicSlice_1 : Pat<\n+        (MHLO_CompositeOp:$composite\n+          (variadic $_, $input, $begin, $size),\n+          ConstantStrAttr<StrAttr, \"tfl.slice\">, $attrs, $_, $_),\n+        (TFL_SliceOp $input, $begin, $size)>;\n+\n+def LegalizeBMM4dAdjY : Pat<\n+        (MHLO_CompositeOp:$composite\n+          (variadic $lhs, $rhs),\n+          ConstantStrAttr<StrAttr, \"tfl.bmm_4d_adj_y\">, $attrs, $_, $_),\n+        (TFL_BatchMatMulOp $lhs, $rhs, ConstBoolAttrFalse, ConstBoolAttrTrue,\n+                     ConstBoolAttrFalse)>;\n+\n+// For dynamic shaped lhs and rhs.\n+def LegalizeBMM4dAdjY_1 : Pat<\n+        (MHLO_CompositeOp:$composite\n+          (variadic $_, $lhs, $rhs),\n+          ConstantStrAttr<StrAttr, \"tfl.bmm_4d_adj_y\">, $attrs, $_, $_),\n+        (TFL_BatchMatMulOp $lhs, $rhs, ConstBoolAttrFalse, ConstBoolAttrTrue,\n+                     ConstBoolAttrFalse)>;"
        },
        {
            "sha": "2b64cc07c7c30bc52ad557d8c0c808185c586bc8",
            "filename": "tensorflow/compiler/mlir/quantization/tensorflow/calibrator/calibration_statistics_saver_op_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Ftensorflow%2Fcalibrator%2Fcalibration_statistics_saver_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Ftensorflow%2Fcalibrator%2Fcalibration_statistics_saver_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Fquantization%2Ftensorflow%2Fcalibrator%2Fcalibration_statistics_saver_op_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -43,7 +43,6 @@ using ::testing::ElementsAre;\n using ::testing::HasSubstr;\n using ::testing::Key;\n using ::testing::SizeIs;\n-using ::tsl::testing::StatusIs;\n \n class CalibrationStatisticsSaverTest : public OpsTestBase {};\n "
        },
        {
            "sha": "379a91c9080edd33098e6a72bd4ea6f4daac573c",
            "filename": "tensorflow/compiler/mlir/tfrt/transforms/mlrt/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -174,6 +174,7 @@ cc_library(\n         \":assign_op_key\",\n         \":passes\",\n         \":while_to_map_fn\",\n+        \"//tensorflow/compiler/mlir/tensorflow:bridge_logger\",\n         \"//tensorflow/compiler/mlir/tensorflow:dump_mlir_util\",\n         \"//tensorflow/compiler/mlir/tensorflow:error_util\",\n         \"//tensorflow/compiler/mlir/tf2xla/api/v2:tf_executor_to_graph\",\n@@ -183,6 +184,7 @@ cc_library(\n         \"//tensorflow/compiler/mlir/tfrt:tfrt_compile_options\",\n         \"//tensorflow/compiler/mlir/tfrt:tfrt_pipeline_options\",\n         \"//tensorflow/compiler/mlir/tfrt/translate/mlrt:mlir_to_bytecode\",\n+        \"//tensorflow/core:framework\",\n         \"//tensorflow/core:protos_all_cc\",\n         \"//tensorflow/core/platform:status\",\n         \"//tensorflow/core/platform:statusor\",\n@@ -194,6 +196,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/strings\",\n+        \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:Pass\","
        },
        {
            "sha": "7b4d35501251be3a0a708421f76f45705776a218",
            "filename": "tensorflow/compiler/mlir/tfrt/transforms/mlrt/import_model.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 2,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2Fimport_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2Fimport_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fmlrt%2Fimport_model.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -14,19 +14,22 @@ limitations under the License.\n ==============================================================================*/\n #include \"tensorflow/compiler/mlir/tfrt/transforms/mlrt/import_model.h\"\n \n+#include <memory>\n #include <string>\n #include <utility>\n #include <vector>\n \n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"llvm/ADT/StringRef.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"  // from @llvm-project\n #include \"mlir/IR/BuiltinOps.h\"  // from @llvm-project\n #include \"mlir/IR/OwningOpRef.h\"  // from @llvm-project\n #include \"mlir/Pass/PassManager.h\"  // from @llvm-project\n #include \"mlir/Support/LogicalResult.h\"  // from @llvm-project\n #include \"mlir/Transforms/Passes.h\"  // from @llvm-project\n+#include \"tensorflow/compiler/mlir/tensorflow/utils/data_dumper_logger_config.h\"\n #include \"tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.h\"\n #include \"tensorflow/compiler/mlir/tensorflow/utils/error_util.h\"\n #include \"tensorflow/compiler/mlir/tfrt/transforms/mlrt/assign_op_key.h\"\n@@ -47,9 +50,30 @@ limitations under the License.\n #include \"tensorflow/core/tfrt/mlrt/attribute/attribute.h\"\n #include \"tensorflow/core/tfrt/mlrt/bytecode/bytecode.h\"\n #include \"tensorflow/core/tfrt/runtime/runtime.h\"\n+#include \"tensorflow/core/util/debug_data_dumper.h\"\n \n namespace tensorflow {\n namespace mlrt_compiler {\n+namespace {\n+// Setup the input pass manager to enable IR dumping after each pass.\n+// Note a side effect of this method is that multi threading will be disabled.\n+void EnablePassIRPrinting(mlir::PassManager& pm,\n+                          const std::string& dump_group_name,\n+                          llvm::StringRef module_name) {\n+  // Print the whole module after each pass, which requires disabling\n+  // multi-threading as well.\n+  pm.getContext()->disableMultithreading();\n+  pm.enableIRPrinting(std::make_unique<::tensorflow::DataDumperLoggerConfig>(\n+      [module_name, dump_group_name](const std::string& pass_tag_name,\n+                                     mlir::Operation* op) {\n+        return DEBUG_DATA_DUMPER()->GetDumpFilename(\n+            module_name.str(), dump_group_name, pass_tag_name);\n+      },\n+      /*pass_prefix=*/\"\",\n+      /*print_module_scope=*/true));\n+  pm.enableTiming();\n+}\n+}  // namespace\n \n absl::StatusOr<mlrt::bc::Buffer> ConvertTfMlirToBytecode(\n     const TfrtCompileOptions& options, tfrt_stub::FallbackState& fallback_state,\n@@ -100,13 +124,18 @@ absl::StatusOr<mlrt::bc::Buffer> ConvertTfMlirToBytecode(\n         // Remove unreachable private functions after map_fn conversion.\n         pm.addPass(mlir::createSymbolDCEPass());\n \n-        tensorflow::CreateTFExecutorToTFInvariantOptimizationPipelineHelper(\n-            pm, options);\n+        tensorflow::CreateTFInvariantOptimizationPipelineHelper(pm, options);\n         // TODO(b/283481729): Add test to cover unused constants that do not\n         // cause op_key discontinuity\n         pm.addNestedPass<mlir::func::FuncOp>(mlir::createCanonicalizerPass());\n         pm.addPass(mlrt_compiler::CreateAssignOpKeyPass());\n+\n         // Run passes until (including) AssignOpKeyPass.\n+        if (VLOG_IS_ON(4)) {\n+          EnablePassIRPrinting(pm, \"mlrt_runtime_lowering_tf\",\n+                               \"mlrt_runtime_lowering_tf\");\n+        }\n+\n         if (mlir::failed(pm.run(module))) {\n           return diag_handler.Combine(absl::InternalError(\n               \"failed to finish passes before (including) assign op keys.\"));"
        },
        {
            "sha": "ddff1b2bde43f981027df0a45ea211961871d742",
            "filename": "tensorflow/compiler/mlir/tfrt/transforms/passes.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -94,6 +94,9 @@ void CreateTFExecutorToTFPreInvariantOptimizationPipelineHelper(\n   // as TFRT-specific optimization may create more opportunities.\n   pm.addNestedPass<mlir::func::FuncOp>(\n       tfrt_compiler::CreateOptimizeTfForTfrtPass());\n+\n+  pm.addNestedPass<mlir::func::FuncOp>(\n+      mlir::CreateExecutorDialectToFunctionalConversionPass());\n   pm.addNestedPass<mlir::func::FuncOp>(mlir::createCanonicalizerPass());\n   // Guarantee all functions have one use, which enables more exact shape\n   // inference.\n@@ -219,8 +222,8 @@ void CreateTFExecutorToTFPreInvariantOptimizationPipelineHelper(\n   AddTfDeviceAssignmentPasses(pm, options);\n }\n \n-void CreateTFExecutorToTFInvariantOptimizationPipelineHelper(\n-    mlir::OpPassManager &pm, const TfrtPipelineOptions &options) {\n+void CreateTFInvariantOptimizationPipelineHelper(\n+    mlir::OpPassManager& pm, const TfrtPipelineOptions& options) {\n   if (options.sink_in_invariant_ops) {\n     pm.addPass(CreateSinkInInvariantOpsPass());\n   }"
        },
        {
            "sha": "1285c8df7147b1f04ca29f77555cd7def80f6627",
            "filename": "tensorflow/compiler/mlir/tfrt/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Fpasses.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -160,7 +160,7 @@ absl::Status CreateTFExecutorToTFPipeline(mlir::PassManager& pm,\n // TODO(deqiangc): refactor below helpers once mlrt is OSSed.\n void CreateTFExecutorToTFPreInvariantOptimizationPipelineHelper(\n     mlir::OpPassManager& pm, const TfrtPipelineOptions& options);\n-void CreateTFExecutorToTFInvariantOptimizationPipelineHelper(\n+void CreateTFInvariantOptimizationPipelineHelper(\n     mlir::OpPassManager& pm, const TfrtPipelineOptions& options);\n \n absl::Status CreateTFExecutorToTFPreInvariantOptimizationPipeline("
        },
        {
            "sha": "de9ed33392544a395fdc3d2a65d5c82c29a51914",
            "filename": "tensorflow/compiler/mlir/tfrt/transforms/tf_to_tfrt.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Ftf_to_tfrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Ftf_to_tfrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftransforms%2Ftf_to_tfrt.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1878,7 +1878,7 @@ void CreateTfToTfrtPipeline(mlir::OpPassManager &pm,\n static void CreateTfExecutorToTfrtPipelineHelper(\n     mlir::OpPassManager &pm, const TfrtPipelineOptions &options) {\n   CreateTFExecutorToTFPreInvariantOptimizationPipelineHelper(pm, options);\n-  CreateTFExecutorToTFInvariantOptimizationPipelineHelper(pm, options);\n+  CreateTFInvariantOptimizationPipelineHelper(pm, options);\n   CreateTfToTfrtPipeline(pm, options);\n }\n \n@@ -1889,7 +1889,7 @@ absl::Status CreateTfExecutorToTfrtPipeline(\n     mlir::PassManager &pm, const TfrtPipelineOptions &options) {\n   TF_RETURN_IF_ERROR(\n       CreateTFExecutorToTFPreInvariantOptimizationPipeline(pm, options));\n-  CreateTFExecutorToTFInvariantOptimizationPipelineHelper(pm, options);\n+  CreateTFInvariantOptimizationPipelineHelper(pm, options);\n   CreateTfToTfrtPipeline(pm, options);\n   return absl::OkStatus();\n }\n@@ -1898,7 +1898,7 @@ absl::Status CreateTFExecutorToTFPipeline(mlir::PassManager &pm,\n                                           const TfrtPipelineOptions &options) {\n   TF_RETURN_IF_ERROR(\n       CreateTFExecutorToTFPreInvariantOptimizationPipeline(pm, options));\n-  CreateTFExecutorToTFInvariantOptimizationPipelineHelper(pm, options);\n+  CreateTFInvariantOptimizationPipelineHelper(pm, options);\n   return absl::OkStatus();\n }\n "
        },
        {
            "sha": "e8004f17a24b474072b1c4e6610cc9f8be7a6a05",
            "filename": "tensorflow/compiler/mlir/tfrt/translate/import_model.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftranslate%2Fimport_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftranslate%2Fimport_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftfrt%2Ftranslate%2Fimport_model.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -280,8 +280,7 @@ absl::Status ConvertTfMlirToBef(\n       [bef_buffer](mlir::PassManager& pm, mlir::ModuleOp module,\n                    const tensorflow::TfrtPipelineOptions& options) {\n         mlir::StatusScopedDiagnosticHandler diag_handler(module.getContext());\n-        tensorflow::CreateTFExecutorToTFInvariantOptimizationPipelineHelper(\n-            pm, options);\n+        tensorflow::CreateTFInvariantOptimizationPipelineHelper(pm, options);\n         tensorflow::CreateTfToTfrtPipeline(pm, options);\n \n         if (mlir::failed(pm.run(module))) {"
        },
        {
            "sha": "4cbe21b73f62c3d4b38ef7b4e26bfa472ac04504",
            "filename": "tensorflow/compiler/mlir/tools/kernel_gen/transforms/tf_framework_legalize_to_llvm.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Ftf_framework_legalize_to_llvm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Ftf_framework_legalize_to_llvm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftools%2Fkernel_gen%2Ftransforms%2Ftf_framework_legalize_to_llvm.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -516,12 +516,10 @@ class NullMemRefOpConverter : public ConvertOpToLLVMPattern<NullMemRefOp> {\n     // Due to the current way of handling unranked memref results escaping, we\n     // have to actually construct a ranked underlying descriptor instead of just\n     // setting its pointer to NULL.\n-    SmallVector<Value, 4> sizes;\n-    UnrankedMemRefDescriptor::computeSizes(rewriter, loc, *getTypeConverter(),\n-                                           desc, addressSpace, sizes);\n+    Value alloca_size = UnrankedMemRefDescriptor::computeSize(\n+        rewriter, loc, *getTypeConverter(), desc, addressSpace);\n     Value underlying_desc_ptr = rewriter.create<LLVM::AllocaOp>(\n-        loc, getVoidPtrType(), IntegerType::get(getContext(), 8),\n-        sizes.front());\n+        loc, getVoidPtrType(), IntegerType::get(getContext(), 8), alloca_size);\n \n     // Populate underlying ranked descriptor.\n     Value null = rewriter.create<LLVM::ZeroOp>(loc, llvm_ptr_type);"
        },
        {
            "sha": "c91df85e3da365100c44dc6e5e6701120289f039",
            "filename": "tensorflow/core/framework/tensor.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fframework%2Ftensor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fframework%2Ftensor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fframework%2Ftensor.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -650,6 +650,12 @@ TensorBuffer* Int4OrInt2FromProtoField(Allocator* a, const TensorProto& in,\n   const int64_t in_n = in.int_val().size();\n   auto begin = in.int_val().begin();\n   if (n <= in_n) {\n+// swapping bits of the data pointer for big endian systems\n+#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\n+    for (int64_t i = 0; i < n; ++i) {\n+      data[i] = ((data[i] & 0xF0) >> 4) | ((data[i] & 0x0F) << 4);\n+    }\n+#endif\n     std::copy_n(begin, n, data);\n   } else if (in_n > 0) {\n     std::copy_n(begin, in_n, data);"
        },
        {
            "sha": "a6cece16d20ddf91536ba82ce8b03af4c2c5b5d6",
            "filename": "tensorflow/core/kernels/concat_lib_gpu_impl.cu.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fconcat_lib_gpu_impl.cu.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -70,7 +70,10 @@ __global__ void concat_variable_kernel(\n   IntType num_inputs = input_ptr_data.size;\n \n   // verbose declaration needed due to template\n-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);\n+  constexpr size_t kAlignTI =\n+      (alignof(T) > alignof(IntType)) ? alignof(T) : alignof(IntType);\n+  constexpr size_t kAlign = (kAlignTI < 16) ? 16 : kAlignTI;\n+  GPU_DYNAMIC_SHARED_MEM_DECL(kAlign, unsigned char, smem);\n   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);\n \n   if (useSmem) {"
        },
        {
            "sha": "b55845bb4e9f6f31a0aa1e81b5524d8ef39ce801",
            "filename": "tensorflow/core/kernels/split_lib_gpu.cu.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsplit_lib_gpu.cu.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -120,7 +120,10 @@ __global__ void split_v_kernel(const T* __restrict__ input_ptr,\n   int num_outputs = output_ptr_data.size;\n \n   // verbose declaration needed due to template\n-  GPU_DYNAMIC_SHARED_MEM_DECL(sizeof(T), unsigned char, smem);\n+  constexpr size_t kAlignTI =\n+      (alignof(T) > alignof(IntType)) ? alignof(T) : alignof(IntType);\n+  constexpr size_t kAlign = (kAlignTI < 16) ? 16 : kAlignTI;\n+  GPU_DYNAMIC_SHARED_MEM_DECL(kAlign, unsigned char, smem);\n   IntType* smem_col_scan = reinterpret_cast<IntType*>(smem);\n \n   if (useSmem) {"
        },
        {
            "sha": "3294ba1185ede8dc7bbbc520310cf8d5c0666eaf",
            "filename": "tensorflow/core/public/version.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fpublic%2Fversion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fcore%2Fpublic%2Fversion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fpublic%2Fversion.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -93,7 +93,7 @@ limitations under the License.\n \n #define TF_GRAPH_DEF_VERSION_MIN_PRODUCER 0\n #define TF_GRAPH_DEF_VERSION_MIN_CONSUMER 0\n-#define TF_GRAPH_DEF_VERSION 2337  // Updated: 2025/9/1\n+#define TF_GRAPH_DEF_VERSION 2340  // Updated: 2025/9/4\n \n // Checkpoint compatibility versions (the versions field in SavedSliceMeta).\n //"
        },
        {
            "sha": "6aa3cfa19ef675e84a9d8a3460e492b835c8d3fe",
            "filename": "tensorflow/lite/core/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -180,9 +180,10 @@ cc_library(\n     ],\n     compatible_with = get_compatible_with_portable(),\n     visibility = [\n-        \"//tensorflow/lite:__subpackages__\",\n         \"//third_party/deepmind/lyria_live/internal/odml:__subpackages__\",\n-        \"//third_party/odml/litert/litert:__subpackages__\",\n+        # copybara:uncomment \"//third_party/odml/litert/litert:__subpackages__\",\n+        # \"//third_party/odml/litert:__subpackages__\",  # copybara:uncomment\n+        \"//tensorflow/lite:__subpackages__\",\n     ] + core_cc_api_stable_visibility_allowlist(),\n     deps = [\n         \":model_builder\","
        },
        {
            "sha": "9f97ec049bc01a1d8aa3eb86b66512db8a9605a2",
            "filename": "tensorflow/lite/core/c/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2Fc%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2Fc%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Fc%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,8 +16,9 @@ load(\n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n     default_visibility = [\n+        # \"//litert:__subpackages__\",  # copybara:uncomment\n+        # copybara:uncomment \"//third_party/odml/litert:__subpackages__\",\n         \"//tensorflow/lite:__subpackages__\",\n-        \"//third_party/odml/litert:__subpackages__\",\n     ],\n     licenses = [\"notice\"],\n )\n@@ -299,9 +300,10 @@ tflite_cc_library_with_c_headers_test(\n     compatible_with = get_compatible_with_portable(),\n     copts = tflite_copts(),\n     visibility = [\n+        # \"//litert/litert:__subpackages__\",  # copybara:uncomment\n+        # copybara:uncomment \"//third_party/odml/litert/litert:__subpackages__\",\n         \"//tensorflow/compiler/mlir/lite/experimental/lrt:__subpackages__\",\n         \"//tensorflow/lite:__subpackages__\",\n-        \"//third_party/odml/litert/litert:__subpackages__\",\n     ] + c_api_visibility_allowlist(),\n     deps = [\n         \"//tensorflow/compiler/mlir/lite/core/c:tflite_common\","
        },
        {
            "sha": "67ba43b54e8ca8efc7d34d8f877375b49a105791",
            "filename": "tensorflow/lite/core/interpreter_builder.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 39,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Finterpreter_builder.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -778,7 +778,9 @@ TfLiteStatus InterpreterBuilder::operator()(\n     std::unique_ptr<Interpreter>* interpreter, int num_threads) {\n   TfLiteStatus status = SetNumThreads(num_threads);\n   if (status != kTfLiteOk) {\n-    interpreter->reset();\n+    if (interpreter) {\n+      interpreter->reset();\n+    }\n     return status;\n   }\n   return (*this)(interpreter);\n@@ -791,30 +793,24 @@ TfLiteStatus InterpreterBuilder::operator()(\n                          \"Null output pointer passed to InterpreterBuilder.\");\n     return kTfLiteError;\n   }\n-\n-  // Safe exit by deleting partially created interpreter, to reduce verbosity\n-  // on error conditions. Use by return cleanup_on_error();\n-  auto cleanup_and_error = [&interpreter]() {\n-    interpreter->reset();\n-    return kTfLiteError;\n-  };\n+  interpreter->reset();\n \n   if (!model_) {\n     TF_LITE_REPORT_ERROR(error_reporter_, \"Null pointer passed in as model.\");\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n   if (model_->version() != TFLITE_SCHEMA_VERSION) {\n     TF_LITE_REPORT_ERROR(error_reporter_,\n                          \"Model provided is schema version %d not equal \"\n                          \"to supported version %d.\\n\",\n                          model_->version(), TFLITE_SCHEMA_VERSION);\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n   if (BuildLocalIndexToRegistrationMapping() != kTfLiteOk) {\n     TF_LITE_REPORT_ERROR(error_reporter_, \"Registration failed.\\n\");\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n   // Flatbuffer model schemas define a list of opcodes independent of the\n@@ -827,32 +823,32 @@ TfLiteStatus InterpreterBuilder::operator()(\n \n   if (subgraphs->size() == 0) {\n     TF_LITE_REPORT_ERROR(error_reporter_, \"No subgraph in the model.\\n\");\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n   if (!buffers) {\n     TF_LITE_REPORT_ERROR(error_reporter_, \"No buffers in the model.\\n\");\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n-  *interpreter = std::make_unique<Interpreter>(error_reporter_);\n+  auto tmp_interpreter = std::make_unique<Interpreter>(error_reporter_);\n   if (subgraphs->size() > 1) {\n-    (*interpreter)->AddSubgraphs(subgraphs->size() - 1);\n+    tmp_interpreter->AddSubgraphs(subgraphs->size() - 1);\n   }\n \n   // Set num threads after all the subgraphs are added.\n-  (*interpreter)->SetNumThreads(num_threads_);\n+  tmp_interpreter->SetNumThreads(num_threads_);\n \n   // Set Interpreter options\n-  (*interpreter)->ApplyOptionsImpl(&options_);\n+  tmp_interpreter->ApplyOptionsImpl(&options_);\n \n-  (*interpreter)\n-      ->SetProfilerImpl(tflite::profiling::MaybeCreatePlatformProfiler());\n+  tmp_interpreter->SetProfilerImpl(\n+      tflite::profiling::MaybeCreatePlatformProfiler());\n \n   bool telemetry_registered = telemetry_profiler_ != nullptr;\n   std::unique_ptr<TfLiteTelemetryInterpreterSettings> telemetry_settings;\n   if (telemetry_registered) {\n-    (*interpreter)->AddProfiler(std::move(telemetry_profiler_));\n+    tmp_interpreter->AddProfiler(std::move(telemetry_profiler_));\n     telemetry_settings = std::make_unique<TfLiteTelemetryInterpreterSettings>();\n     telemetry_settings->subgraph_infos.resize(subgraphs->size());\n   }\n@@ -861,7 +857,7 @@ TfLiteStatus InterpreterBuilder::operator()(\n        ++subgraph_index) {\n     const tflite::SubGraph* subgraph = (*subgraphs)[subgraph_index];\n     tflite::Subgraph* modified_subgraph =\n-        (*interpreter)->subgraph(subgraph_index);\n+        tmp_interpreter->subgraph(subgraph_index);\n     modified_subgraph->allocation_ = allocation_;\n     auto* subgraph_info =\n         telemetry_registered\n@@ -873,10 +869,10 @@ TfLiteStatus InterpreterBuilder::operator()(\n       TF_LITE_REPORT_ERROR(error_reporter_,\n                            \"Did not get tensors in subgraph %d.\\n\",\n                            subgraph_index);\n-      return cleanup_and_error();\n+      return kTfLiteError;\n     }\n     if (modified_subgraph->AddTensors(tensors->size()) != kTfLiteOk) {\n-      return cleanup_and_error();\n+      return kTfLiteError;\n     }\n     // Parse inputs/outputs\n     modified_subgraph->SetInputs(\n@@ -889,9 +885,9 @@ TfLiteStatus InterpreterBuilder::operator()(\n     // nodes.\n     if (ParseTensors(buffers, tensors, modified_subgraph, subgraph_info) !=\n         kTfLiteOk)\n-      return cleanup_and_error();\n+      return kTfLiteError;\n     if (operators && ParseNodes(operators, modified_subgraph) != kTfLiteOk)\n-      return cleanup_and_error();\n+      return kTfLiteError;\n \n     std::vector<int> variables;\n     for (int i = 0; i < modified_subgraph->tensors_size(); ++i) {\n@@ -906,14 +902,14 @@ TfLiteStatus InterpreterBuilder::operator()(\n     }\n   }\n \n-  if (ParseSignatureDefs(model_->signature_defs(), interpreter->get()) !=\n+  if (ParseSignatureDefs(model_->signature_defs(), tmp_interpreter.get()) !=\n       kTfLiteOk) {\n-    return cleanup_and_error();\n+    return kTfLiteError;\n   }\n \n   if (options_.GetUseSignatureTensorNames()) {\n-    for (auto& signature_def : (*interpreter)->signature_defs_) {\n-      auto* subgraph = (*interpreter)->subgraph(signature_def.subgraph_index);\n+    for (auto& signature_def : tmp_interpreter->signature_defs_) {\n+      auto* subgraph = tmp_interpreter->subgraph(signature_def.subgraph_index);\n       for (auto& [name, tensor_index] : signature_def.inputs) {\n         auto tensor = subgraph->tensor(tensor_index);\n         tensor->name = name.c_str();\n@@ -925,33 +921,35 @@ TfLiteStatus InterpreterBuilder::operator()(\n     }\n   }\n \n-  if ((*interpreter)->SetMetadata(metadata_) != kTfLiteOk) {\n-    return cleanup_and_error();\n+  if (tmp_interpreter->SetMetadata(metadata_) != kTfLiteOk) {\n+    return kTfLiteError;\n   }\n \n   if (ShouldCreateLazyDelegateProviders(num_fp32_tensors_)) {\n-    (*interpreter)->lazy_delegate_providers_ =\n+    tmp_interpreter->lazy_delegate_providers_ =\n         op_resolver_.GetDelegateCreators();\n   }\n \n   if (telemetry_registered) {\n     ParseConversionMetadata(telemetry_settings.get());\n-    (*interpreter)->SetTelemetrySettings(std::move(telemetry_settings));\n+    tmp_interpreter->SetTelemetrySettings(std::move(telemetry_settings));\n     // Reports model and interpreter settings if telemetry is applied.\n-    (*interpreter)->ReportTelemetrySettings(kTelemetryBuilderEventName);\n+    tmp_interpreter->ReportTelemetrySettings(kTelemetryBuilderEventName);\n   }\n \n-  TfLiteStatus status = ApplyDelegates(interpreter->get());\n-  if (status != kTfLiteOk) {\n-    interpreter->reset();\n+  if (TfLiteStatus status = ApplyDelegates(tmp_interpreter.get());\n+      status != kTfLiteOk) {\n+    TF_LITE_REPORT_ERROR(error_reporter_, \"Failed to apply delegates.\\n\");\n+    return status;\n   }\n \n   // Apply Interpreter options again for dynamic allocation.\n   if (options_.GetDynamicAllocationForLargeTensors()) {\n-    (*interpreter)->ApplyOptionsImpl(&options_);\n+    tmp_interpreter->ApplyOptionsImpl(&options_);\n   }\n \n-  return status;\n+  *interpreter = std::move(tmp_interpreter);\n+  return kTfLiteOk;\n }\n \n void InterpreterBuilder::AddDelegate(TfLiteDelegate* delegate) {"
        },
        {
            "sha": "274bdb42b0e1c5a60e598b0834618b16e5fd62ad",
            "filename": "tensorflow/lite/delegates/xnnpack/weight_cache.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -155,6 +155,11 @@ bool WeightCacheBuilder::StartBuildStep() {\n     XNNPACK_RETURN_CHECK(buffer_list_data.Map(fd_, header.buffer_list_offset,\n                                               file_path_.c_str()),\n                          \"could not map buffer list mapping\");\n+    flatbuffers::Verifier verifier(\n+        reinterpret_cast<const uint8_t*>(buffer_list_data.data()),\n+        header.buffer_list_size);\n+    XNNPACK_RETURN_CHECK(cache::schema::VerifyBufferListBuffer(verifier),\n+                         \"could not verify buffer list mapping\");\n     cache::schema::GetBufferList(buffer_list_data.data())->UnPackTo(&schema_);\n   }\n "
        },
        {
            "sha": "9e97e5265867d107f82efebe4ed0f711bd079565",
            "filename": "tensorflow/lite/delegates/xnnpack/weight_cache_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -186,6 +186,38 @@ TEST(WeightCacheBuilderTest, AppendWithoutReserveWriteWorks) {\n   EXPECT_THAT(cache_data, ElementsAreArray(payload));\n }\n \n+TEST(WeightCacheBuilderTest, CorruptBufferListFailsGracefully) {\n+  const std::string cache_path = testing::TempDir() + \"/cache\";\n+  const std::string payload = \"This is some data in the file.\";\n+  const PackIdentifier dummy_id{1, 2, 3};\n+\n+  FileDescriptor file_descriptor = FileDescriptor::Open(\n+      cache_path.c_str(), O_CREAT | O_TRUNC | O_RDWR, 0644);\n+  WeightCacheBuilder builder;\n+  ASSERT_TRUE(builder.Start(cache_path.c_str(), file_descriptor));\n+  ASSERT_TRUE(builder.StartBuildStep());\n+\n+  const size_t payload_size = size(payload);\n+  auto loc = builder.Append(dummy_id, payload.c_str(), payload_size);\n+  EXPECT_EQ(loc.size, payload_size);\n+  ASSERT_TRUE(builder.StopBuildStep());\n+\n+  // corrupt the buffer list data.\n+  {\n+    FileDescriptor file_descriptor =\n+        FileDescriptor::Open(cache_path.c_str(), O_RDWR, 0644);\n+    ASSERT_TRUE(file_descriptor.IsValid());\n+    XNNPackCacheHeader header;\n+    file_descriptor.SetPos(0);\n+    ASSERT_TRUE(file_descriptor.Read(&header, sizeof(header)));\n+    file_descriptor.SetPos(header.buffer_list_offset + 1);\n+    std::string data(8, 'a');\n+    ASSERT_TRUE(file_descriptor.Write(data.data(), data.size()));\n+  }\n+\n+  EXPECT_FALSE(builder.StartBuildStep());\n+}\n+\n TEST(WeightCacheBuilderTest, InvalidFileDescriptorFails) {\n   WeightCacheBuilder builder;\n   EXPECT_FALSE(builder.Start(\"\", FileDescriptor()));"
        },
        {
            "sha": "0dea571cb442f4f734ac31b2e6e23097e0d48355",
            "filename": "tensorflow/lite/tools/cmake/modules/eigen.cmake",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Feigen.cmake",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Feigen.cmake",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fcmake%2Fmodules%2Feigen.cmake?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -23,7 +23,7 @@ OverridableFetchContent_Declare(\n   eigen\n   GIT_REPOSITORY https://gitlab.com/libeigen/eigen.git\n   # Sync with tensorflow/third_party/eigen3/workspace.bzl\n-  GIT_TAG 4c38131a16803130b66266a912029504f2cf23cd\n+  GIT_TAG 70d8d99d0df9fd967b135efd8d12ed20fc48d007\n   # It's not currently (cmake 3.17) possible to shallow clone with a GIT TAG\n   # as cmake attempts to git checkout the commit hash after the clone\n   # which doesn't work as it's a shallow clone hence a different commit hash."
        },
        {
            "sha": "f47d73a584555807c128419cc26ea6cbfb8ce85a",
            "filename": "tensorflow/opensource_only.files",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fopensource_only.files",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fopensource_only.files",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fopensource_only.files?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -168,6 +168,7 @@ tf_staging/tensorflow/tools/pip_package/BUILD:\n tf_staging/tensorflow/tools/pip_package/MANIFEST.in:\n tf_staging/tensorflow/tools/pip_package/README:\n tf_staging/tensorflow/tools/pip_package/check_load_py_test:.py\n+tf_staging/tensorflow/tools/pip_package/modify_setup_py:.py\n tf_staging/tensorflow/tools/pip_package/pip_smoke_test:.py\n tf_staging/tensorflow/tools/pip_package/setup:.py.tpl\n tf_staging/tensorflow/tools/pip_package/simple_console:.py"
        },
        {
            "sha": "e4661903a32e39e4f202776c98f12250b650e1fb",
            "filename": "tensorflow/python/_pywrap_tensorflow.def",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2F_pywrap_tensorflow.def",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2F_pywrap_tensorflow.def",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2F_pywrap_tensorflow.def?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -657,10 +657,10 @@ EXPORTS\n   ?StrCat@lts_20250512@absl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@000@Z\n   ?StrCat@lts_20250512@absl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@00@Z\n   ?StrCat@lts_20250512@absl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@0@Z\n-  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@000@Z\n-  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@00@Z\n-  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@0@Z\n-  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@12@@Z\n+  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@lts_20250512@absl@@000@Z\n+  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@lts_20250512@absl@@00@Z\n+  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@lts_20250512@absl@@0@Z\n+  ?StrCat@strings@tsl@@YA?AV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVAlphaNum@lts_20250512@absl@@@Z\n   ?StripDefaultAttributes@tensorflow@@YAXAEBVOpRegistryInterface@1@PEAV?$RepeatedPtrField@VNodeDef@tensorflow@@@protobuf@google@@@Z\n   ?Sub@ops@tensorflow@@YA?AVStatus@lts_20250512@absl@@PEAVAbstractContext@2@QEAVAbstractTensorHandle@2@1PEAPEAV72@PEBD3@Z\n   ?SubRegisterer@gradients@tensorflow@@YAPEAVGradientFunction@12@AEBUForwardOperation@12@@Z"
        },
        {
            "sha": "30f8aaf666c6d3b0a0f3ab40d90315ba91889570",
            "filename": "tensorflow/python/compat/compat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fcompat%2Fcompat.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fcompat%2Fcompat.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fcompat%2Fcompat.py?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,7 +29,7 @@\n # This value changes every day with an automatic CL. It can be modified in code\n # via `forward_compatibility_horizon()` or with the environment variable\n # TF_FORWARD_COMPATIBILITY_DELTA_DAYS, which is added to the compatibility date.\n-_FORWARD_COMPATIBILITY_HORIZON = datetime.date(2025, 9, 1)\n+_FORWARD_COMPATIBILITY_HORIZON = datetime.date(2025, 9, 4)\n _FORWARD_COMPATIBILITY_DELTA_DAYS_VAR_NAME = \"TF_FORWARD_COMPATIBILITY_DELTA_DAYS\"\n _FORWARD_COMPATIBILITY_DATE_NUMBER = None\n "
        },
        {
            "sha": "21a8d478e3a2275fa12d6e1ed41497449c3e8e93",
            "filename": "tensorflow/python/kernel_tests/nn_ops/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fkernel_tests%2Fnn_ops%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fkernel_tests%2Fnn_ops%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fkernel_tests%2Fnn_ops%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -77,6 +77,9 @@ cuda_py_strict_test(\n     name = \"betainc_op_test\",\n     size = \"small\",\n     srcs = [\"betainc_op_test.py\"],\n+    tags = [\n+        \"notap\",  # TODO(delhibabu): Re-enable once the test is fixed.\n+    ],\n     xla_tags = [\n         \"no_cuda_asan\",  # times out\n     ],"
        },
        {
            "sha": "d0211e0b9caeb8d464e04ff20190603695819f72",
            "filename": "tensorflow/python/ops/sparse_ops.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fops%2Fsparse_ops.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fops%2Fsparse_ops.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fops%2Fsparse_ops.py?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -3687,6 +3687,12 @@ def handle(self, args, kwargs):\n     # TODO(b/120307967) Add dispatchers for additional TensorFlow ops.\n     math_ops.abs,\n     math_ops.negative,\n+    math_ops.asinh,\n+    math_ops.sin,\n+    math_ops.tan,\n+    math_ops.atan,\n+    math_ops.asin,\n+    math_ops.atanh,\n     math_ops.sign,\n     math_ops.square,\n     math_ops.sqrt,"
        },
        {
            "sha": "0b3e6d9f974984a3cf9920525c1fe869d6cd7551",
            "filename": "tensorflow/python/ops/sparse_ops_test.py",
            "status": "modified",
            "additions": 31,
            "deletions": 1,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fops%2Fsparse_ops_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Fpython%2Fops%2Fsparse_ops_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fops%2Fsparse_ops_test.py?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -108,6 +108,36 @@ def testSparseExpandDims(self):\n       (math_ops.negative, [1.0, -1.0, 3.0, -4.0], [-1.0, 1.0, -3.0, 4.0]),\n       (math_ops.sign, [3.0, -2.0, 0.0, -4.0], [1.0, -1.0, 0.0, -1.0]),\n       (math_ops.square, [1.0, -1.0, 3.0, -4.0], [1.0, 1.0, 9.0, 16.0]),\n+      (\n+          math_ops.asinh,\n+          [1.0, -1.0, 3.0, -4.0],\n+          [0.8813736, -0.8813736, 1.8184465, -2.0947125],\n+      ),\n+      (\n+          math_ops.sin,\n+          [1.0, -1.0, 3.0, -4.0],\n+          [0.84147096, -0.84147096, 0.14112, 0.7568025],\n+      ),\n+      (\n+          math_ops.asin,\n+          [1.0, -1.0, 0.4, -0.5],\n+          [1.5707964, -1.5707964, 0.41151685, -0.5235988],\n+      ),\n+      (\n+          math_ops.tan,\n+          [1.0, -1.0, 0.4, -0.5],\n+          [1.5574077, -1.5574077, 0.42279324, -0.5463025],\n+      ),\n+      (\n+          math_ops.atan,\n+          [0.4, -0.4, 1.0, 0.5],\n+          [0.3805064, -0.3805064, 0.7853982, 0.4636476],\n+      ),\n+      (\n+          math_ops.atanh,\n+          [0.4, -0.4, -0.5, 0.5],\n+          [0.42364895, -0.42364895, -0.54930615, 0.54930615],\n+      ),\n   ])\n   def testUnarySparseDispatch(self, op, values, expected):\n     st = sparse_tensor.SparseTensor(\n@@ -117,7 +147,7 @@ def testUnarySparseDispatch(self, op, values, expected):\n     result = op(st)\n     result_value = self.evaluate(result)\n     self.assertAllEqual(result_value.indices, st.indices)\n-    self.assertAllEqual(result_value.values, expected)\n+    self.assertAllClose(result_value.values, expected)\n     self.assertAllEqual(result_value.dense_shape, st.dense_shape)\n \n   def testSparseToDenseGradient(self):"
        },
        {
            "sha": "74776d2680eb67c899562e443b32cfee24485007",
            "filename": "tensorflow/tools/pip_package/BUILD",
            "status": "modified",
            "additions": 23,
            "deletions": 2,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fpip_package%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,6 +1,7 @@\n # Description:\n #  Tools for building the TensorFlow pip package.\n \n+load(\"@cuda_cudart//:version.bzl\", _cudart_version = \"VERSION\")\n load(\"@local_config_cuda//cuda:build_defs.bzl\", \"if_cuda\")\n load(\"@local_config_syslibs//:build_defs.bzl\", \"if_not_system_lib\")\n load(\n@@ -13,6 +14,7 @@ load(\n )\n load(\"@local_xla//third_party/py:python_wheel.bzl\", \"collect_data_files\", \"transitive_py_deps\")\n load(\"@local_xla//xla/tsl/mkl:build_defs.bzl\", \"if_enable_mkl\", \"if_mkl\", \"if_mkl_ml\")\n+load(\"@nvidia_wheel_versions//:versions.bzl\", \"NVIDIA_WHEEL_VERSIONS\")\n load(\"//tensorflow:tensorflow.bzl\", \"if_wheel_dependency\", \"if_with_tpu_support\", \"transitive_hdrs\")\n load(\"//tensorflow:tf_version.bzl\", \"TF_SEMANTIC_VERSION_SUFFIX\", \"TF_VERSION\")\n load(\n@@ -268,15 +270,33 @@ transitive_py_deps(\n     deps = COMMON_PIP_DEPS,\n )\n \n+py_binary(\n+    name = \"modify_setup_py_binary\",\n+    srcs = [\n+        \"modify_setup_py.py\",\n+    ],\n+    main = \"modify_setup_py.py\",\n+    deps = [\"@local_xla//third_party/py:setup_py_nvidia_dependencies_util\"],\n+)\n+\n genrule(\n     name = \"setup_py\",\n     srcs = [\"setup.py.tpl\"],\n     outs = [\"setup.py\"],\n-    cmd = \"\"\"sed -E \"s/_VERSION = '0.0.0'/_VERSION = '{wheel_version}{wheel_version_suffix}'/\" \\\n-$(location setup.py.tpl) > $@;\"\"\".format(\n+    cmd = \"\"\"\n+      $(location :modify_setup_py_binary) \\\\\n+          --template_file $(location setup.py.tpl) \\\\\n+          --output_file $(OUTS) \\\\\n+          --nvidia_wheel_versions_data '{nvidia_wheel_versions}' \\\\\n+          --tf_version \"{wheel_version}{wheel_version_suffix}\" \\\\\n+          --cuda_version {cuda_version}\n+    \"\"\".format(\n+        cuda_version = _cudart_version or \"12\",\n+        nvidia_wheel_versions = NVIDIA_WHEEL_VERSIONS,\n         wheel_version = TF_VERSION,\n         wheel_version_suffix = TF_SEMANTIC_VERSION_SUFFIX,\n     ),\n+    tools = [\":modify_setup_py_binary\"],\n )\n \n py_binary(\n@@ -435,6 +455,7 @@ py_import(\n     wheel_deps = if_cuda([\n         \"@pypi_nvidia_cublas_cu12//:pkg\",\n         \"@pypi_nvidia_cuda_cupti_cu12//:pkg\",\n+        \"@pypi_nvidia_cuda_nvcc_cu12//:pkg\",\n         \"@pypi_nvidia_cuda_nvrtc_cu12//:pkg\",\n         \"@pypi_nvidia_cuda_runtime_cu12//:pkg\",\n         \"@pypi_nvidia_cudnn_cu12//:pkg\","
        },
        {
            "sha": "7f78a437060471379c7548128b01d3782e0bdd20",
            "filename": "tensorflow/tools/pip_package/modify_setup_py.py",
            "status": "added",
            "additions": 97,
            "deletions": 0,
            "changes": 97,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2Fmodify_setup_py.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2Fmodify_setup_py.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fpip_package%2Fmodify_setup_py.py?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,97 @@\n+# Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License..\n+# ==============================================================================\n+\"\"\"Modify setup.py with TensorFlow and NVIDIA wheel versions.\"\"\"\n+\n+import argparse\n+import pathlib\n+import third_party.py.setup_py_nvidia_dependencies_util as util\n+\n+\n+def _update_setup_with_tf_and_nvidia_wheel_versions(\n+    template_path: pathlib.Path,\n+    output_path: pathlib.Path,\n+    nvidia_wheel_versions_data: str,\n+    tf_version: str,\n+    cuda_version: str,\n+):\n+  \"\"\"Updates a setup.py template with TensorFlow and NVIDIA wheel versions.\n+\n+  This function reads a setup.py template file, replaces placeholder versions\n+  for TensorFlow and various NVIDIA-related wheels based on the provided\n+  data, and writes the result to an output file.\n+\n+  Args:\n+    template_path: Path to the input setup.py.tpl template file.\n+    output_path: Path where the modified setup.py file will be written.\n+    nvidia_wheel_versions_data: A string containing NVIDIA wheel version data,\n+      with each line in the format \"wheel_name version_spec\".\n+    tf_version: The version string for the TensorFlow package.\n+    cuda_version: The CUDA version string.\n+  \"\"\"\n+\n+  with open(template_path) as f:\n+    content = f.read()\n+\n+  content = content.replace(\"_VERSION = '0.0.0'\", f\"_VERSION = '{tf_version}'\")\n+  content = util.get_setup_py_content_with_nvidia_wheel_versions(\n+      content, cuda_version, nvidia_wheel_versions_data\n+  )\n+\n+  with open(output_path, \"w\") as f:\n+    f.write(content)\n+\n+\n+if __name__ == \"__main__\":\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      \"--template_file\",\n+      type=pathlib.Path,\n+      required=True,\n+      help=\"Path to the setup.py.tpl template file\",\n+  )\n+  parser.add_argument(\n+      \"--output_file\",\n+      type=pathlib.Path,\n+      required=True,\n+      help=\"Path to write the generated setup.py file\",\n+  )\n+  parser.add_argument(\n+      \"--nvidia_wheel_versions_data\",\n+      default=None,\n+      required=True,\n+      help=\"NVIDIA wheel versions data\",\n+  )\n+  parser.add_argument(\n+      \"--cuda_version\",\n+      type=str,\n+      required=True,\n+      help=\"The CUDA version string\",\n+      default=\"12\",\n+  )\n+  parser.add_argument(\n+      \"--tf_version\",\n+      type=str,\n+      required=True,\n+      help=\"The TensorFlow package version string\",\n+  )\n+  args = parser.parse_args()\n+\n+  _update_setup_with_tf_and_nvidia_wheel_versions(\n+      args.template_file,\n+      args.output_file,\n+      args.nvidia_wheel_versions_data,\n+      args.tf_version,\n+      args.cuda_version,\n+  )"
        },
        {
            "sha": "3ee660591813b08c36a33075c39d88212682dbd5",
            "filename": "tensorflow/tools/pip_package/setup.py.tpl",
            "status": "modified",
            "additions": 28,
            "deletions": 12,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fpip_package%2Fsetup.py.tpl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -54,6 +54,22 @@ from setuptools.dist import Distribution\n # result for pip.\n _VERSION = '0.0.0'\n \n+cuda_version = 0  # placeholder\n+cuda_wheel_suffix = ''  # placeholder\n+\n+nvidia_cublas_version = ''  # placeholder\n+nvidia_cuda_cupti_version = ''  # placeholder\n+nvidia_cuda_nvcc_version = ''  # placeholder\n+nvidia_cuda_runtime_version = ''  # placeholder\n+nvidia_cudnn_version = ''  # placeholder\n+nvidia_cufft_version = ''  # placeholder\n+nvidia_cusolver_version = ''  # placeholder\n+nvidia_cusparse_version = ''  # placeholder\n+nvidia_nccl_version = ''  # placeholder\n+nvidia_nvjitlink_version = ''  # placeholder\n+nvidia_cuda_nvrtc_version = ''  # placeholder\n+nvidia_curand_version = ''  # placeholder\n+\n # We use the same setup.py for all tensorflow_* packages and for the nightly\n # equivalents (tf_nightly_*). The package is controlled from the argument line\n # when building the pip package.\n@@ -145,18 +161,18 @@ if collaborator_build:\n EXTRA_PACKAGES = {\n     'and-cuda': [\n         # TODO(nluehr): set nvidia-* versions based on build components.\n-        'nvidia-cublas-cu12 >= 12.5.3.2, < 13.0',\n-        'nvidia-cuda-cupti-cu12 >= 12.5.82, < 13.0',\n-        'nvidia-cuda-nvcc-cu12 >= 12.5.82, < 13.0',\n-        'nvidia-cuda-nvrtc-cu12 >= 12.5.82, < 13.0',\n-        'nvidia-cuda-runtime-cu12 >= 12.5.82, < 13.0',\n-        'nvidia-cudnn-cu12 >= 9.3.0.75, < 10.0',\n-        'nvidia-cufft-cu12 >= 11.2.3.61, < 12.0',\n-        'nvidia-curand-cu12 >= 10.3.6.82, < 11.0',\n-        'nvidia-cusolver-cu12 >= 11.6.3.83, < 12.0',\n-        'nvidia-cusparse-cu12 >= 12.5.1.3, < 13.0',\n-        'nvidia-nccl-cu12 >= 2.27.7, < 3.0',\n-        'nvidia-nvjitlink-cu12 >= 12.5.82, < 13.0',\n+        f'nvidia-cublas{cuda_wheel_suffix}{nvidia_cublas_version}',\n+        f'nvidia-cuda-cupti{cuda_wheel_suffix}{nvidia_cuda_cupti_version}',\n+        f'nvidia-cuda-nvcc{cuda_wheel_suffix}{nvidia_cuda_nvcc_version}',\n+        f'nvidia-cuda-nvrtc{cuda_wheel_suffix}{nvidia_cuda_nvrtc_version}',\n+        f'nvidia-cuda-runtime{cuda_wheel_suffix}{nvidia_cuda_runtime_version}',\n+        f'nvidia-cudnn-cu{cuda_version}{nvidia_cudnn_version}',\n+        f'nvidia-cufft{cuda_wheel_suffix}{nvidia_cufft_version}',\n+        f'nvidia-curand{cuda_wheel_suffix}{nvidia_curand_version}',\n+        f'nvidia-cusolver{cuda_wheel_suffix}{nvidia_cusolver_version}',\n+        f'nvidia-cusparse{cuda_wheel_suffix}{nvidia_cusparse_version}',\n+        f'nvidia-nccl-cu{cuda_version}{nvidia_nccl_version}',\n+        f'nvidia-nvjitlink{cuda_wheel_suffix}{nvidia_nvjitlink_version}',\n     ],\n     'gcs-filesystem': [\n         ('tensorflow-io-gcs-filesystem>=0.23.1; '"
        },
        {
            "sha": "56131cf026c50b898fe99b52ff8b31c7a3acbe75",
            "filename": "tensorflow/tools/toolchains/remote_config/configs.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -50,7 +50,7 @@ def initialize_rbe_configs():\n     # The `ml-build-rbe` image is identical to the `ml-build` image except for the base image.\n     # The `ml-build`'s base image is a standard `ubuntu22.04` image.\n     # The `ml-build-rbe`'s base image is `nvidia/cuda:12.3.2-base-ubuntu22.04` which has nvidia driver installed.\n-    ml_build_rbe_config(\"docker://us-central1-docker.pkg.dev/tensorflow-sigs/tensorflow/ml-build-rbe@sha256:aaeb29799463729092c05f5ac8393113b3bb5d1ecf085f9f1f2016e3a1ece11c\")\n+    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-rbe@sha256:7bae9f7604645cbad40b11a22294f5058db16022315d52a130b832d07e54c9ef\")\n \n     # TF-Version-Specific SIG Build RBE Configs. The crosstool generated from these\n     # configs are python-version-independent because they only care about the"
        },
        {
            "sha": "5afdeffee932391267a2e40bdc4509db5b14179b",
            "filename": "third_party/py/BUILD.bazel",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fpy%2FBUILD.bazel",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fpy%2FBUILD.bazel",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fpy%2FBUILD.bazel?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -65,3 +65,9 @@ py_binary(\n     main = \"unpack_wheel_and_unzip_archive_files.py\",\n     visibility = [\"//visibility:public\"],\n )\n+\n+py_library(\n+    name = \"setup_py_nvidia_dependencies_util\",\n+    srcs = [\"setup_py_nvidia_dependencies_util.py\"],\n+    visibility = [\"//visibility:public\"],\n+)"
        },
        {
            "sha": "6177f2eb1a52255280c41ece27e53dfc852e7625",
            "filename": "third_party/tf_runtime/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Ftf_runtime%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Ftf_runtime%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Ftf_runtime%2Fworkspace.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -6,8 +6,8 @@ def repo():\n     \"\"\"Imports TFRT.\"\"\"\n \n     # Attention: tools parse and update these lines.\n-    TFRT_COMMIT = \"db460e7893e4accc0971876aff9b29b3382ade80\"\n-    TFRT_SHA256 = \"7065c8f508f61e8e2a579829694febe564d93dccf09f22dcc012762d5e20bc88\"\n+    TFRT_COMMIT = \"4ecc3a44a32c832b748328bed3f9a599f795ca8d\"\n+    TFRT_SHA256 = \"5e81d70f9534340f7ef8e63ec43bdd5971135e48183079be50ecb3f74b1fed66\"\n \n     tf_http_archive(\n         name = \"tf_runtime\","
        },
        {
            "sha": "bc871108513d5ab41336e1df6e71afdd630dd65f",
            "filename": "third_party/xla/WORKSPACE",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2FWORKSPACE",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2FWORKSPACE",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2FWORKSPACE?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -9,10 +9,10 @@ load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n # Details: https://github.com/google-ml-infra/rules_ml_toolchain\n http_archive(\n     name = \"rules_ml_toolchain\",\n-    sha256 = \"e7e44c4e349a1c1f31398bd2257c51432e73ea0e7e24cce67090b68b0b50007e\",\n-    strip_prefix = \"rules_ml_toolchain-55dcd0a52c7e0f9eec9927a32512229c09ac3b3e\",\n+    sha256 = \"1a855dd94eebedae69d1804e8837ad70b8018358a0a03eea0bec71d7dc2b096a\",\n+    strip_prefix = \"rules_ml_toolchain-d321763a84c900bc29b4f5459a4f81fad19b2356\",\n     urls = [\n-        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/55dcd0a52c7e0f9eec9927a32512229c09ac3b3e.tar.gz\",\n+        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/d321763a84c900bc29b4f5459a4f81fad19b2356.tar.gz\",\n     ],\n )\n \n@@ -27,6 +27,10 @@ register_toolchains(\"@rules_ml_toolchain//cc:linux_x86_64_linux_x86_64\")\n \n register_toolchains(\"@rules_ml_toolchain//cc:linux_x86_64_linux_x86_64_cuda\")\n \n+register_toolchains(\"@rules_ml_toolchain//cc:linux_aarch64_linux_aarch64\")\n+\n+register_toolchains(\"@rules_ml_toolchain//cc:linux_aarch64_linux_aarch64_cuda\")\n+\n # Initialize the XLA repository and all dependencies.\n #\n # The cascade of load() statements and xla_workspace?() calls works around the"
        },
        {
            "sha": "a6f7c652795c78af2b02c3e7173f457dbfe9cd29",
            "filename": "third_party/xla/build_tools/sycl/ci_test_xla.sh",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -14,7 +14,7 @@\n # limitations under the License.\n # ==============================================================================\n \n-# This script builds and executes tests. It can be run only on a system that \n+# This script builds and executes tests. It can be run only on a system that\n # has an Intel GPU with the appropriate driver and oneAPI tools installed.\n # Hermetic build is not currently fully supported for executing tests.\n ./configure.py --backend=SYCL --host_compiler=CLANG --sycl_compiler=ICPX\n@@ -23,4 +23,5 @@ bazel test \\\n       --build_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n       --test_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n       //xla/stream_executor/sycl:sycl_status_test \\\n+      //xla/stream_executor/sycl:sycl_event_test_intelgpu_any \\\n       //xla/stream_executor/sycl:sycl_kernel_test_intelgpu_any"
        },
        {
            "sha": "41f74de21edbaac64d3a2b97e95f0d54be375d74",
            "filename": "third_party/xla/docs/operation_semantics.md",
            "status": "modified",
            "additions": 334,
            "deletions": 56,
            "changes": 390,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Foperation_semantics.md?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -194,15 +194,15 @@ for a detailed description of the algorithm.\n \n Calculates gradients of batch norm.\n \n-**`BatchNormGrad(operand, scale, mean, variance, grad_output, epsilon,\n-                 feature_index)`**\n+**`BatchNormGrad(operand, scale, batch_mean, batch_var, grad_output, epsilon,\n+feature_index)`**\n \n Arguments       | Type    | Semantics\n --------------- | ------- | ----------------------------------------------------\n `operand`       | `XlaOp` | n dimensional array to be normalized (x)\n `scale`         | `XlaOp` | 1 dimensional array ($\\gamma$)\n-`mean`          | `XlaOp` | 1 dimensional array ($\\mu$)\n-`variance`      | `XlaOp` | 1 dimensional array ($\\sigma^2$)\n+`batch_mean`    | `XlaOp` | 1 dimensional array ($\\mu$)\n+`batch_var`     | `XlaOp` | 1 dimensional array ($\\sigma^2$)\n `grad_output`   | `XlaOp` | Gradients passed to `BatchNormTraining` ($\\nabla y$)\n `epsilon`       | `float` | Epsilon value ($\\epsilon$)\n `feature_index` | `int64` | Index to feature dimension in `operand`\n@@ -235,19 +235,19 @@ d_l&=\n \\end{split}\n $$\n \n-The inputs `mean` and `variance` represent moments values across batch and\n-spatial dimensions.\n+The inputs `batch_mean` and `batch_var` represent moments values across batch\n+and spatial dimensions.\n \n The output type is a tuple of three handles:\n \n | Outputs        | Type    | Semantics                                         |\n | -------------- | ------- | ------------------------------------------------- |\n | `grad_operand` | `XlaOp` | gradient with respect to input `operand` ($\\nabla |\n :                :         : x$)                                               :\n-| `grad_scale`   | `XlaOp` | gradient with respect to input `scale` ($\\nabla   |\n-:                :         : \\gamma$)                                          :\n-| `grad_offset`  | `XlaOp` | gradient with respect to input `offset`($\\nabla   |\n-:                :         : \\beta$)                                           :\n+| `grad_scale`   | `XlaOp` | gradient with respect to input `scale`            |\n+:                :         : ($\\nabla\\gamma$)                                  :\n+| `grad_offset`  | `XlaOp` | gradient with respect to input                    |\n+:                :         : `offset`($\\nabla\\beta$)                           :\n \n ## BatchNormInference\n \n@@ -508,6 +508,13 @@ frontend_attributes = {\n | `decomposition`             | `XlaComputation`       | computation of type `T_0, T_1, ..., T_{N-1} -> S` with N parameters of arbitrary type |\n | `version`                   | `int64`.               | number to version updates to semantics of the composite op                            |\n \n+An ops `decomposition` isnt a field called, but instead appears as a to_apply\n+attribute that points to the function which contains the lower-level\n+implementation, i.e. `to_apply=%funcname`\n+\n+More information on composite and decomposition can be found on\n+[StableHLO Specification](https://openxla.org/stablehlo/spec#composite)\n+\n ## Cholesky\n \n See also\n@@ -657,7 +664,7 @@ Note that there are the following restrictions on the `source_target_pair`:\n -   If a replica id is not a target in any pair, then the output on that replica\n     is a tensor consisting of 0(s) with the same shape as the input.\n \n-## Concatenate\n+## ConcatInDim (Concatenate)\n \n See also\n [`XlaBuilder::ConcatInDim`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n@@ -765,35 +772,46 @@ type of the returned value of each `branch_computations[b]` must be the same.\n Note that only one of the `branch_computations` will be executed depending on\n the value of `branch_index`.\n \n-## Conv (convolution)\n+## Conv (Convolution)\n \n See also\n [`XlaBuilder::Conv`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n \n-As ConvWithGeneralPadding, but the padding is specified in a short-hand way as\n-either SAME or VALID. SAME padding pads the input (`lhs`) with zeroes so that\n-the output has the same shape as the input when not taking striding into\n-account. VALID padding simply means no padding.\n-\n-## ConvWithGeneralPadding (convolution)\n-\n-See also\n-[`XlaBuilder::ConvWithGeneralPadding`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n-\n Computes a convolution of the kind used in neural networks. Here, a convolution\n can be thought of as a n-dimensional window moving across a n-dimensional base\n area and a computation is performed for each possible position of the window.\n \n-| Arguments             | Type                     | Semantics                |\n-| --------------------- | ------------------------ | ------------------------ |\n-| `lhs`                 | `XlaOp`                  | (n+2)-dimensional array of inputs |\n-| `rhs`                 | `XlaOp`                  | (n+2)-dimensional array of kernel weights |\n-| `window_strides`      | `ArraySlice<int64>`      | n-d array of kernel strides |\n-| `padding`             | `ArraySlice< pair<int64,int64>>` | n-d array of (low, high) padding |\n-| `lhs_dilation`        | `ArraySlice<int64>`      | n-d lhs dilation factor array |\n-| `rhs_dilation`        | `ArraySlice<int64>`      | n-d rhs dilation factor array |\n-| `feature_group_count` | int64                    | the number of feature groups |\n-| `batch_group_count`   | int64                    | the number of batch groups |\n+`Conv` Enqueues a convolution instruction onto the computation, which uses the\n+default convolution dimension numbers with no dilation.\n+\n+The padding is specified in a short-hand way as either SAME or VALID. SAME\n+padding pads the input (`lhs`) with zeroes so that the output has the same shape\n+as the input when not taking striding into account. VALID padding simply means\n+no padding.\n+\n+**`Conv(lhs, rhs, window_strides, padding, feature_group_count,\n+batch_group_count, precision_config, preferred_element_type)`**\n+\n+| Arguments                | Type                | Semantics                   |\n+| ------------------------ | ------------------- | --------------------------- |\n+| `lhs`                    | `XlaOp`             | (n+2)-dimensional array of  |\n+:                          :                     : inputs                      :\n+| `rhs`                    | `XlaOp`             | (n+2)-dimensional array of  |\n+:                          :                     : kernel weights              :\n+| `window_strides`         | `ArraySlice<int64>` | n-d array of kernel strides |\n+| `padding`                | `Padding`           | enum of padding             |\n+| `feature_group_count`    | int64               | the number of feature       |\n+:                          :                     : groups                      :\n+| `batch_group_count`      | int64               | the number of batch groups  |\n+| `precision_config`       | optional            | enum for level of precision |\n+:                          : `PrecisionConfig`   :                             :\n+| `preferred_element_type` | optional            | enum of scalar element type |\n+:                          : `PrimitiveType`     :                             :\n+\n+Increasing levels of controls are available for `Conv`: -\n+[ConvWithGeneralPadding](#ConvWithGeneralPadding) -\n+[ConvWithGeneralDimensions](#ConvWithGeneralDimensions) -\n+[ConvGeneral](#ConvGeneral) - [ConvGeneralDilated](#convgeneraldilated)\n \n Let n be the number of spatial dimensions. The `lhs` argument is an\n (n+2)-dimensional array describing the base area. This is called the input,\n@@ -921,6 +939,158 @@ for (b, oz, oy, ox) {  // output coordinates\n }\n ```\n \n+`precision_config` is used to indicate the precision configuration. The level\n+dictates whether hardware should attempt to generate more machine code\n+instructions to provide more accurate dtype emulation when needed (i.e.\n+emulating f32 on a TPU that only supports bf16 matmuls). Values may be\n+`DEFAULT`, `HIGH`, `HIGHEST`. Additional details\n+[in the MXU sections](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus).\n+\n+`preferred_element_type` is a scalar element of higher/lower precision output\n+types used for accumulation. `preferred_element_type` recommends the\n+accumulation type for the given operaiton, however it is not guaranteed. This\n+allows for some hardware backends to instead accumulate in a different type and\n+convert to the preferred output type.\n+\n+### ConvWithGeneralPadding\n+\n+**`ConvWithGeneralPadding(lhs, rhs, window_strides, padding,\n+feature_group_count, batch_group_count, precision_config,\n+preferred_element_type)`**\n+\n+See also\n+[`XlaBuilder::ConvWithGeneralPadding`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n+\n+Same as [`Conv`](#conv-convolution) where padding configuration is explicit.\n+\n+| Arguments                | Type                | Semantics                   |\n+| ------------------------ | ------------------- | --------------------------- |\n+| `lhs`                    | `XlaOp`             | (n+2)-dimensional array of  |\n+:                          :                     : inputs                      :\n+| `rhs`                    | `XlaOp`             | (n+2)-dimensional array of  |\n+:                          :                     : kernel weights              :\n+| `window_strides`         | `ArraySlice<int64>` | n-d array of kernel strides |\n+| `padding`                | `ArraySlice<        | n-d array of (low, high)    |\n+:                          : pair<int64,int64>>` : padding                     :\n+| `feature_group_count`    | int64               | the number of feature       |\n+:                          :                     : groups                      :\n+| `batch_group_count`      | int64               | the number of batch groups  |\n+| `precision_config`       | optional            | enum for level of precision |\n+:                          : `PrecisionConfig`   :                             :\n+| `preferred_element_type` | optional            | enum of scalar element type |\n+:                          : `PrimitiveType`     :                             :\n+\n+### ConvWithGeneralDimensions\n+\n+**`ConvWithGeneralDimensions(lhs, rhs, window_strides, padding,\n+dimension_numbers, feature_group_count, batch_group_count, precision_config,\n+preferred_element_type)`**\n+\n+See also\n+[`XlaBuilder::ConvWithGeneralDimensions`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n+\n+Same as [`Conv`](#conv-convolution) where dimension numbers are explicit.\n+\n+| Arguments                | Type                          | Semantics         |\n+| ------------------------ | ----------------------------- | ----------------- |\n+| `lhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of inputs   :\n+| `rhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of kernel   :\n+:                          :                               : weights           :\n+| `window_strides`         | `ArraySlice<int64>`           | n-d array of      |\n+:                          :                               : kernel strides    :\n+| `padding`                | `Padding`                     | enum of padding   |\n+| `dimension_numbers`      | `ConvolutionDimensionNumbers` | the number of     |\n+:                          :                               : dimensions        :\n+| `feature_group_count`    | int64                         | the number of     |\n+:                          :                               : feature groups    :\n+| `batch_group_count`      | int64                         | the number of     |\n+:                          :                               : batch groups      :\n+| `precision_config`       | optional `PrecisionConfig`    | enum for level of |\n+:                          :                               : precision         :\n+| `preferred_element_type` | optional `PrimitiveType`      | enum of scalar    |\n+:                          :                               : element type      :\n+\n+### ConvGeneral\n+\n+**`ConvGeneral(lhs, rhs, window_strides, padding, dimension_numbers,\n+feature_group_count, batch_group_count, precision_config,\n+preferred_element_type)`**\n+\n+See also\n+[`XlaBuilder::ConvGeneral`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n+\n+Same as [`Conv`](#conv-convolution) where dimension numbers and padding\n+configuration is explicit\n+\n+| Arguments                | Type                          | Semantics         |\n+| ------------------------ | ----------------------------- | ----------------- |\n+| `lhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of inputs   :\n+| `rhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of kernel   :\n+:                          :                               : weights           :\n+| `window_strides`         | `ArraySlice<int64>`           | n-d array of      |\n+:                          :                               : kernel strides    :\n+| `padding`                | `ArraySlice<                  | n-d array of      |\n+:                          : pair<int64,int64>>`           : (low, high)       :\n+:                          :                               : padding           :\n+| `dimension_numbers`      | `ConvolutionDimensionNumbers` | the number of     |\n+:                          :                               : dimensions        :\n+| `feature_group_count`    | int64                         | the number of     |\n+:                          :                               : feature groups    :\n+| `batch_group_count`      | int64                         | the number of     |\n+:                          :                               : batch groups      :\n+| `precision_config`       | optional `PrecisionConfig`    | enum for level of |\n+:                          :                               : precision         :\n+| `preferred_element_type` | optional `PrimitiveType`      | enum of scalar    |\n+:                          :                               : element type      :\n+\n+### ConvGeneralDilated\n+\n+**`ConvGeneralDilated(lhs, rhs, window_strides, padding, lhs_dilation,\n+rhs_dilation, dimension_numbers, feature_group_count, batch_group_count,\n+precision_config, preferred_element_type, window_reversal)`**\n+\n+See also\n+[`XlaBuilder::ConvGeneralDilated`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n+\n+Same as [`Conv`](#conv-convolution) where padding configuration, dilation\n+factors, and dimension numbers are explicit.\n+\n+| Arguments                | Type                          | Semantics         |\n+| ------------------------ | ----------------------------- | ----------------- |\n+| `lhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of inputs   :\n+| `rhs`                    | `XlaOp`                       | (n+2)-dimensional |\n+:                          :                               : array of kernel   :\n+:                          :                               : weights           :\n+| `window_strides`         | `ArraySlice<int64>`           | n-d array of      |\n+:                          :                               : kernel strides    :\n+| `padding`                | `ArraySlice<                  | n-d array of      |\n+:                          : pair<int64,int64>>`           : (low, high)       :\n+:                          :                               : padding           :\n+| `lhs_dilation`           | `ArraySlice<int64>`           | n-d lhs dilation  |\n+:                          :                               : factor array      :\n+| `rhs_dilation`           | `ArraySlice<int64>`           | n-d rhs dilation  |\n+:                          :                               : factor array      :\n+| `dimension_numbers`      | `ConvolutionDimensionNumbers` | the number of     |\n+:                          :                               : dimensions        :\n+| `feature_group_count`    | int64                         | the number of     |\n+:                          :                               : feature groups    :\n+| `batch_group_count`      | int64                         | the number of     |\n+:                          :                               : batch groups      :\n+| `precision_config`       | optional `PrecisionConfig`    | enum for level of |\n+:                          :                               : precision         :\n+| `preferred_element_type` | optional `PrimitiveType`      | enum of scalar    |\n+:                          :                               : element type      :\n+| `window_reversal`        | optional `vector<bool>`       | flag used to      |\n+:                          :                               : logically reverse :\n+:                          :                               : dimension before  :\n+:                          :                               : applying the      :\n+:                          :                               : convolution       :\n+\n ## ConvertElementType\n \n See also\n@@ -1021,39 +1191,64 @@ idempotent.\n See also\n [`XlaBuilder::Dot`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n \n-**`Dot(lhs, rhs)`**\n+**`Dot(lhs, rhs, precision_config, preferred_element_type)`**\n \n-Arguments | Type    | Semantics\n---------- | ------- | ---------------\n-`lhs`     | `XlaOp` | array of type T\n-`rhs`     | `XlaOp` | array of type T\n+| Arguments                | Type              | Semantics                   |\n+| ------------------------ | ----------------- | --------------------------- |\n+| `lhs`                    | `XlaOp`           | array of type T             |\n+| `rhs`                    | `XlaOp`           | array of type T             |\n+| `precision_config`       | optional          | enum for level of precision |\n+:                          : `PrecisionConfig` :                             :\n+| `preferred_element_type` | optional          | enum of scalar element type |\n+:                          : `PrimitiveType`   :                             :\n \n The exact semantics of this operation depend on the ranks of the operands:\n \n-| Input                               | Output          | Semantics               |\n-| ----------------------------------- | --------------- | ----------------------- |\n-| vector [n] `dot` vector [n]         | scalar          | vector dot product      |\n-| matrix [m x k] `dot` vector [k]     | vector [m]      | matrix-vector multiplication |\n-| matrix [m x k] `dot` matrix [k x n] | matrix [m x n]  | matrix-matrix multiplication |\n+| Input                       | Output         | Semantics                    |\n+| --------------------------- | -------------- | ---------------------------- |\n+| vector [n] `dot` vector [n] | scalar         | vector dot product           |\n+| matrix [m x k] `dot` vector | vector [m]     | matrix-vector multiplication |\n+: [k]                         :                :                              :\n+| matrix [m x k] `dot` matrix | matrix [m x n] | matrix-matrix multiplication |\n+: [k x n]                     :                :                              :\n \n The operation performs sum of products over the second dimension of `lhs` (or\n the first if it has 1 dimension) and the first dimension of `rhs`. These are the\n \"contracted\" dimensions. The contracted dimensions of `lhs` and `rhs` must be of\n the same size. In practice, it can be used to perform dot products between\n vectors, vector/matrix multiplications or matrix/matrix multiplications.\n \n+`precision_config` is used to indicate the precision configuration. The level\n+dictates whether hardware should attempt to generate more machine code\n+instructions to provide more accurate dtype emulation when needed (i.e.\n+emulating f32 on a TPU that only supports bf16 matmuls). Values may be\n+`DEFAULT`, `HIGH`, `HIGHEST`. Additional details\n+[in the MXU sections](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus).\n+\n+`preferred_element_type` is a scalar element of higher/lower precision output\n+types used for accumulation. `preferred_element_type` recommends the\n+accumulation type for the given operaiton, however it is not guaranteed. This\n+allows for some hardware backends to instead accumulate in a different type and\n+convert to the preferred output type.\n+\n ## DotGeneral\n \n See also\n [`XlaBuilder::DotGeneral`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n \n-**`DotGeneral(lhs, rhs, dimension_numbers)`**\n+**`DotGeneral(lhs, rhs, dimension_numbers, precision_config,\n+preferred_element_type)`**\n \n-Arguments           | Type                  | Semantics\n-------------------- | --------------------- | ---------------\n-`lhs`               | `XlaOp`               | array of type T\n-`rhs`               | `XlaOp`               | array of type T\n-`dimension_numbers` | `DotDimensionNumbers` | contracting and batch dimension numbers\n+| Arguments                | Type                  | Semantics              |\n+| ------------------------ | --------------------- | ---------------------- |\n+| `lhs`                    | `XlaOp`               | array of type T        |\n+| `rhs`                    | `XlaOp`               | array of type T        |\n+| `dimension_numbers`      | `DotDimensionNumbers` | contracting and batch  |\n+:                          :                       : dimension numbers      :\n+| `precision_config`       | optional              | enum for level of      |\n+:                          : `PrecisionConfig`     : precision              :\n+| `preferred_element_type` | optional              | enum of scalar element |\n+:                          : `PrimitiveType`       : type                   :\n \n Similar to Dot, but allows contracting and batch dimension numbers to be\n specified for both the `lhs` and `rhs`.\n@@ -1129,6 +1324,19 @@ It follows that the resulting dimension number starts with the batch dimension,\n then the `lhs` non-contracting/non-batch dimension, and finally the `rhs`\n non-contracting/non-batch dimension.\n \n+`precision_config` is used to indicate the precision configuration. The level\n+dictates whether hardware should attempt to generate more machine code\n+instructions to provide more accurate dtype emulation when needed (i.e.\n+emulating f32 on a TPU that only supports bf16 matmuls). Values may be\n+`DEFAULT`, `HIGH`, `HIGHEST`. Additional details\n+[can be found in the MXU sections](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus).\n+\n+`preferred_element_type` is a scalar element of higher/lower precision output\n+types used for accumulation. `preferred_element_type` recommends the\n+accumulation type for the given operaiton, however it is not guaranteed. This\n+allows for some hardware backends to instead accumulate in a different type and\n+convert to the preferred output type.\n+\n ## DynamicSlice\n \n See also\n@@ -1426,6 +1634,60 @@ The function is applied to each element in the `operand` array, resulting in an\n array with the same shape. It is allowed for `operand` to be a scalar\n (0-dimensional).\n \n+### Optional Result Accuracy\n+\n+XlaBuilder supports these element-wise unary functions with the optional\n+`result_accuracy` argument:\n+\n+<b>`Cbrt(operand, result_accuracy)`</b> Element-wise cubic root operation `x ->\n+cbrt(x)`.\n+\n+<b>`Cos(operand, result_accuracy)`</b> Element-wise cosine `x -> cos(x)`.\n+\n+<b>`Erf(operand, result_accuracy)`</b> Element-wise error function `x -> erf(x)`\n+where\n+\n+$$\\text{erf}(x) = \\frac{2}{\\sqrt{\\pi}}\\int_0^x e^{-t^2} \\, dt$$.\n+\n+<b>`Exp(operand, result_accuracy)`</b> Element-wise natural exponential `x ->\n+e^x`.\n+\n+<b>`Expm1(operand, result_accuracy)`</b> Element-wise natural exponential minus\n+one `x -> e^x - 1`.\n+\n+<b>`Log(operand, result_accuracy)`</b> Element-wise natural logarithm `x ->\n+ln(x)`.\n+\n+<b>`Log1p(operand, result_accuracy)`</b> Element-wise shifted natural logarithm\n+`x -> ln(1+x)`.\n+\n+<b>`Logistic(operand, result_accuracy)`</b> Element-wise logistic function\n+computation `x -> logistic(x)`.\n+\n+<b>`Rsqrt(operand, result_accuracy)`</b> Element-wise reciprocal of square root\n+operation `x -> 1.0 / sqrt(x)`.\n+\n+<b>`Sin(operand, result_accuracy)`</b> Element-wise sine `x -> sin(x)`.\n+\n+<b>`Sqrt(operand, result_accuracy)`</b> Element-wise square root operation `x ->\n+sqrt(x)`.\n+\n+<b>`Tan(operand, result_accuracy)`</b> Element-wise tangent `x -> tan(x)`.\n+\n+<b>`Tanh(operand, result_accuracy)`</b> Element-wise hyperbolic tangent `x ->\n+tanh(x)`.\n+\n+| Arguments         | Type                      | Semantics                   |\n+| ----------------- | ------------------------- | --------------------------- |\n+| `operand`         | `XlaOp`                   | The operand to the function |\n+| `result_accuracy` | optional `ResultAccuracy` | The types of accuracy the   |\n+:                   :                           : user can request for unary  :\n+:                   :                           : ops with multiple           :\n+:                   :                           : implementations             :\n+\n+For more information on `result_accuracy` see\n+[Result Accuracy](https://github.com/openxla/stablehlo/blob/main/rfcs/20241015-result-accuracy.md)\n+\n ## Fft\n \n The XLA FFT operation implements the forward and inverse Fourier Transforms for\n@@ -1835,6 +2097,9 @@ Blocks any optimization pass from moving computations across the barrier.\n Ensures that all inputs are evaluated before any operators that depend on the\n barrier's outputs.\n \n+See also\n+[StableHLO optimization_barrier](https://openxla.org/stablehlo/spec#optimization_barrier)\n+\n ## Pad\n \n See also\n@@ -1915,14 +2180,20 @@ See also\n \n Applies a reduction function to one or more arrays in parallel.\n \n-**`Reduce(operands..., init_values..., computation, dimensions)`**\n-\n-| Arguments     | Type                  | Semantics                        |\n-| ------------- | --------------------- | -------------------------------- |\n-| `operands`    | Sequence of N `XlaOp` | N arrays of types `T_0, ..., T_{N-1}`. |\n-| `init_values` | Sequence of N `XlaOp` | N scalars of types `T_0, ..., T_{N-1}`. |\n-| `computation` | `XlaComputation`      | computation of type `T_0, ..., T_{N-1}, T_0, ..., T_{N-1} ->` `Collate(T_0, ..., T_{N-1})`. |\n-| `dimensions`  | `int64` array         | unordered array of dimensions to reduce. |\n+**`Reduce(operands..., init_values..., computation, dimensions_to_reduce)`**\n+\n+| Arguments              | Type                  | Semantics                 |\n+| ---------------------- | --------------------- | ------------------------- |\n+| `operands`             | Sequence of N `XlaOp` | N arrays of types `T_0,   |\n+:                        :                       : ..., T_{N-1}`.            :\n+| `init_values`          | Sequence of N `XlaOp` | N scalars of types `T_0,  |\n+:                        :                       : ..., T_{N-1}`.            :\n+| `computation`          | `XlaComputation`      | computation of type `T_0, |\n+:                        :                       : ..., T_{N-1}, T_0, ...,   :\n+:                        :                       : T_{N-1} ->` `Collate(T_0, :\n+:                        :                       : ..., T_{N-1})`.           :\n+| `dimensions_to_reduce` | `int64` array         | unordered array of        |\n+:                        :                       : dimensions to reduce.     :\n \n Where:\n \n@@ -2901,6 +3172,13 @@ let t: (f32[10], s32) = tuple(v, s);\n Tuples can be deconstructed (accessed) via the [`GetTupleElement`]\n (#gettupleelement) operation.\n \n+For more information see\n+[StableHLO Tuple](https://openxla.org/stablehlo/spec#tuple)\n+\n+> **Note:** In HLO, tuples are needed for most ops that return >1 result. While\n+> in StableHLO/MLIR, variadic results can be expressed and tuples are not used,\n+> except in custom_calls/get_tuple_element.\n+\n ## While\n \n See also"
        },
        {
            "sha": "065983e8608cff2c1ad00fb039f0a7d5015aada4",
            "filename": "third_party/xla/opensource_only.files",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fopensource_only.files",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fopensource_only.files",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fopensource_only.files?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -25,6 +25,7 @@ tensorflow/third_party/py/python_repo.bzl:\n tensorflow/third_party/py/python_wheel.bzl:\n tensorflow/third_party/py/rules_pywrap/def_file_filter_tool.py:\n tensorflow/third_party/py/rules_pywrap/wrapped_py_init.cc:\n+tensorflow/third_party/py/setup_py_nvidia_dependencies_util.py:\n tensorflow/third_party/py/unpack_wheel_and_unzip_archive_files.py:\n tensorflow/tools/def_file_filter/BUILD.tpl:\n tensorflow/tools/def_file_filter/BUILD:"
        },
        {
            "sha": "41069982fd80e88b588a6445e5b40e554b56f9a8",
            "filename": "third_party/xla/tensorflow.bazelrc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Ftensorflow.bazelrc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Ftensorflow.bazelrc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Ftensorflow.bazelrc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -229,12 +229,6 @@ build:cuda_nvcc --@local_config_cuda//:cuda_compiler=nvcc\n # Old config for backward compatibility\n build:nvcc_clang --config=cuda_nvcc\n \n-# TODO(yuriit): Remove this once Linux aarch64 hermetic build is supported.\n-# This is a temporary solution to build for Linux aarch64 by using NVCC.\n-build:cuda_nvcc_linux_aarch64 --config=cuda_nvcc\n-build:cuda_nvcc_linux_aarch64 --config=clang_local\n-build:cuda_nvcc_linux_aarch64 --crosstool_top=@local_config_cuda//crosstool:toolchain\n-\n # Debug config. Enables Bazel's 'dbg' compilation mode, build with debugging enabled\n build:dbg -c dbg\n # Compiling all dependencies with debug info can cause linker failures"
        },
        {
            "sha": "ee8f420dd30c2d878172a701f93338b09df2e28c",
            "filename": "third_party/xla/third_party/eigen3/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Feigen3%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Feigen3%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Feigen3%2Fworkspace.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -7,8 +7,8 @@ def repo():\n \n     # Attention: tools parse and update these lines.\n     # LINT.IfChange\n-    EIGEN_COMMIT = \"4c38131a16803130b66266a912029504f2cf23cd\"\n-    EIGEN_SHA256 = \"1a432ccbd597ea7b9faa1557b1752328d6adc1a3db8969f6fe793ff704be3bf0\"\n+    EIGEN_COMMIT = \"70d8d99d0df9fd967b135efd8d12ed20fc48d007\"\n+    EIGEN_SHA256 = \"78d1158871b8d3663cead3fb3c482721155df9a331d94cfcc60bcdf5cdbf18e1\"\n     # LINT.ThenChange(//tensorflow/lite/tools/cmake/modules/eigen.cmake)\n \n     tf_http_archive("
        },
        {
            "sha": "8b4324dcc8c9daff37549a9316b0af612ee68f99",
            "filename": "third_party/xla/third_party/gpus/sycl/build_defs.bzl.tpl",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fgpus%2Fsycl%2Fbuild_defs.bzl.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fgpus%2Fsycl%2Fbuild_defs.bzl.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fgpus%2Fsycl%2Fbuild_defs.bzl.tpl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -13,7 +13,11 @@ def if_sycl(if_true, if_false = []):\n \n def sycl_default_copts():\n     \"\"\"Default options for all SYCL compilations.\"\"\"\n-    return if_sycl([\"-x\", \"sycl\"])\n+    return if_sycl([\"-sycl_compile\"])\n+\n+def sycl_default_linkopts():\n+    \"\"\"Default options for all SYCL compilations.\"\"\"\n+    return if_sycl([\"-link_stage\", \"-lirc\"])\n \n def sycl_build_is_configured():\n     \"\"\"Returns true if SYCL compiler was enabled during the configure process.\"\"\"\n@@ -34,6 +38,13 @@ def if_sycl_build_is_configured(x, y):\n       return x\n     return y\n \n-def sycl_library(copts = [], **kwargs):\n+def sycl_library(copts = [], linkopts = [], tags = [], deps = [], **kwargs):\n     \"\"\"Wrapper over cc_library which adds default SYCL options.\"\"\"\n-    native.cc_library(copts = sycl_default_copts() + copts, **kwargs)\n+    native.cc_library(copts = sycl_default_copts() + copts,\n+                      linkopts = sycl_default_linkopts() + linkopts,\n+                      tags = tags + [\"gpu\"],\n+                      deps = deps + if_sycl_is_configured([\n+                        \"@local_config_sycl//sycl:sycl_headers\",\n+                        \"@local_config_sycl//sycl:level_zero\",\n+                      ]),\n+                      **kwargs)"
        },
        {
            "sha": "217385de4003f17d6151f51efad69947fa57ad57",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 1704,
            "deletions": 247,
            "changes": 1951,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,254 +1,1711 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n-diff -ruN --strip-trailing-cr a/llvm/include/llvm/Analysis/LoopInfo.h b/llvm/include/llvm/Analysis/LoopInfo.h\n---- a/llvm/include/llvm/Analysis/LoopInfo.h\n-+++ b/llvm/include/llvm/Analysis/LoopInfo.h\n-@@ -59,11 +59,12 @@\n-   };\n+diff -ruN --strip-trailing-cr a/clang/include/clang/AST/TemplateName.h b/clang/include/clang/AST/TemplateName.h\n+--- a/clang/include/clang/AST/TemplateName.h\n++++ b/clang/include/clang/AST/TemplateName.h\n+@@ -335,17 +335,17 @@\n+   /// structure, if any.\n+   QualifiedTemplateName *getAsQualifiedTemplateName() const;\n+ \n+-  /// Retrieve the underlying qualified template name,\n+-  /// looking through underlying nodes.\n+-  QualifiedTemplateName *getAsAdjustedQualifiedTemplateName() const;\n+-\n+   /// Retrieve the underlying dependent template name\n+   /// structure, if any.\n+   DependentTemplateName *getAsDependentTemplateName() const;\n+ \n+-  // Retrieve the qualifier stored in either a underlying DependentTemplateName\n+-  // or QualifiedTemplateName.\n+-  NestedNameSpecifier getQualifier() const;\n++  // Retrieve the qualifier and template keyword stored in either a underlying\n++  // DependentTemplateName or QualifiedTemplateName.\n++  std::tuple<NestedNameSpecifier, bool> getQualifierAndTemplateKeyword() const;\n++\n++  NestedNameSpecifier getQualifier() const {\n++    return std::get<0>(getQualifierAndTemplateKeyword());\n++  }\n+ \n+   /// Retrieve the using shadow declaration through which the underlying\n+   /// template declaration is introduced, if any.\n+diff -ruN --strip-trailing-cr a/clang/include/clang/AST/TypeLoc.h b/clang/include/clang/AST/TypeLoc.h\n+--- a/clang/include/clang/AST/TypeLoc.h\n++++ b/clang/include/clang/AST/TypeLoc.h\n+@@ -1862,11 +1862,10 @@\n+     if (!getLocalData()->QualifierData)\n+       return NestedNameSpecifierLoc();\n+ \n+-    auto *QTN =\n+-        getTypePtr()->getTemplateName().getAsAdjustedQualifiedTemplateName();\n+-    assert(QTN && \"missing qualification\");\n+-    return NestedNameSpecifierLoc(QTN->getQualifier(),\n+-                                  getLocalData()->QualifierData);\n++    NestedNameSpecifier Qualifier =\n++        getTypePtr()->getTemplateName().getQualifier();\n++    assert(Qualifier && \"missing qualification\");\n++    return NestedNameSpecifierLoc(Qualifier, getLocalData()->QualifierData);\n+   }\n+ \n+   SourceLocation getTemplateKeywordLoc() const {\n+@@ -2493,10 +2492,9 @@\n+     void *Data = getLocalData()->QualifierData;\n+     if (!Data)\n+       return NestedNameSpecifierLoc();\n+-    NestedNameSpecifier Qualifier = getTypePtr()\n+-                                        ->getTemplateName()\n+-                                        .getAsAdjustedQualifiedTemplateName()\n+-                                        ->getQualifier();\n++    NestedNameSpecifier Qualifier =\n++        getTypePtr()->getTemplateName().getQualifier();\n++    assert(Qualifier && \"missing qualification\");\n+     return NestedNameSpecifierLoc(Qualifier, Data);\n+   }\n+ \n+@@ -2511,10 +2509,7 @@\n+     }\n+ \n+     assert(QualifierLoc.getNestedNameSpecifier() ==\n+-               getTypePtr()\n+-                   ->getTemplateName()\n+-                   .getAsAdjustedQualifiedTemplateName()\n+-                   ->getQualifier() &&\n++               getTypePtr()->getTemplateName().getQualifier() &&\n+            \"Inconsistent nested-name-specifier pointer\");\n+     getLocalData()->QualifierData = QualifierLoc.getOpaqueData();\n+   }\n+diff -ruN --strip-trailing-cr a/clang/include/clang/Serialization/ASTReader.h b/clang/include/clang/Serialization/ASTReader.h\n+--- a/clang/include/clang/Serialization/ASTReader.h\n++++ b/clang/include/clang/Serialization/ASTReader.h\n+@@ -526,6 +526,9 @@\n+   /// A timer used to track the time spent deserializing.\n+   std::unique_ptr<llvm::Timer> ReadTimer;\n+ \n++  // A TimeRegion used to start and stop ReadTimer via RAII.\n++  std::optional<llvm::TimeRegion> ReadTimeRegion;\n++\n+   /// The location where the module file will be considered as\n+   /// imported from. For non-module AST types it should be invalid.\n+   SourceLocation CurrentImportLoc;\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTContext.cpp b/clang/lib/AST/ASTContext.cpp\n+--- a/clang/lib/AST/ASTContext.cpp\n++++ b/clang/lib/AST/ASTContext.cpp\n+@@ -5483,18 +5483,15 @@\n+   return T;\n+ }\n+ \n+-static bool getNonInjectedClassName(const TagDecl *&TD) {\n++static const TagDecl *getNonInjectedClassName(const TagDecl *TD) {\n+   if (const auto *RD = dyn_cast<CXXRecordDecl>(TD);\n+-      RD && RD->isInjectedClassName()) {\n+-    TD = cast<TagDecl>(RD->getDeclContext());\n+-    return true;\n+-  }\n+-  return false;\n++      RD && RD->isInjectedClassName())\n++    return cast<TagDecl>(RD->getDeclContext());\n++  return TD;\n+ }\n+ \n+ CanQualType ASTContext::getCanonicalTagType(const TagDecl *TD) const {\n+-  ::getNonInjectedClassName(TD);\n+-  TD = TD->getCanonicalDecl();\n++  TD = ::getNonInjectedClassName(TD)->getCanonicalDecl();\n+   if (TD->TypeForDecl)\n+     return TD->TypeForDecl->getCanonicalTypeUnqualified();\n+ \n+@@ -5510,40 +5507,42 @@\n+ QualType ASTContext::getTagType(ElaboratedTypeKeyword Keyword,\n+                                 NestedNameSpecifier Qualifier,\n+                                 const TagDecl *TD, bool OwnsTag) const {\n++\n++  const TagDecl *NonInjectedTD = ::getNonInjectedClassName(TD);\n++  bool IsInjected = TD != NonInjectedTD;\n++\n+   ElaboratedTypeKeyword PreferredKeyword =\n+-      getLangOpts().CPlusPlus\n+-          ? ElaboratedTypeKeyword::None\n+-          : KeywordHelpers::getKeywordForTagTypeKind(TD->getTagKind());\n++      getLangOpts().CPlusPlus ? ElaboratedTypeKeyword::None\n++                              : KeywordHelpers::getKeywordForTagTypeKind(\n++                                    NonInjectedTD->getTagKind());\n+ \n+   if (Keyword == PreferredKeyword && !Qualifier && !OwnsTag) {\n+     if (const Type *T = TD->TypeForDecl; T && !T->isCanonicalUnqualified())\n+       return QualType(T, 0);\n+ \n+-    bool IsInjected = ::getNonInjectedClassName(TD);\n+-    const Type *CanonicalType = getCanonicalTagType(TD).getTypePtr();\n++    const Type *CanonicalType = getCanonicalTagType(NonInjectedTD).getTypePtr();\n+     const Type *T =\n+         getTagTypeInternal(Keyword,\n+-                           /*Qualifier=*/std::nullopt, TD,\n++                           /*Qualifier=*/std::nullopt, NonInjectedTD,\n+                            /*OwnsTag=*/false, IsInjected, CanonicalType,\n+                            /*WithFoldingSetNode=*/false);\n+     TD->TypeForDecl = T;\n+     return QualType(T, 0);\n+   }\n+ \n+-  bool IsInjected = ::getNonInjectedClassName(TD);\n+-\n+   llvm::FoldingSetNodeID ID;\n+-  TagTypeFoldingSetPlaceholder::Profile(ID, Keyword, Qualifier, TD, OwnsTag,\n+-                                        IsInjected);\n++  TagTypeFoldingSetPlaceholder::Profile(ID, Keyword, Qualifier, NonInjectedTD,\n++                                        OwnsTag, IsInjected);\n+ \n+   void *InsertPos = nullptr;\n+   if (TagTypeFoldingSetPlaceholder *T =\n+           TagTypes.FindNodeOrInsertPos(ID, InsertPos))\n+     return QualType(T->getTagType(), 0);\n+ \n+-  const Type *CanonicalType = getCanonicalTagType(TD).getTypePtr();\n+-  TagType *T = getTagTypeInternal(Keyword, Qualifier, TD, OwnsTag, IsInjected,\n+-                                  CanonicalType, /*WithFoldingSetNode=*/true);\n++  const Type *CanonicalType = getCanonicalTagType(NonInjectedTD).getTypePtr();\n++  TagType *T =\n++      getTagTypeInternal(Keyword, Qualifier, NonInjectedTD, OwnsTag, IsInjected,\n++                         CanonicalType, /*WithFoldingSetNode=*/true);\n+   TagTypes.InsertNode(TagTypeFoldingSetPlaceholder::fromTagType(T), InsertPos);\n+   return QualType(T, 0);\n+ }\n+@@ -10429,6 +10428,12 @@\n+   assert(Template.getKind() == TemplateName::Template ||\n+          Template.getKind() == TemplateName::UsingTemplate);\n  \n-   /// Return true if the specified value is loop invariant.\n--  bool isLoopInvariant(const Value *V) const;\n-+  bool isLoopInvariant(const Value *V, bool HasCoroSuspendInst = false) const;\n- \n-   /// Return true if all the operands of the specified instruction are loop\n-   /// invariant.\n--  bool hasLoopInvariantOperands(const Instruction *I) const;\n-+  bool hasLoopInvariantOperands(const Instruction *I,\n-+                                bool HasCoroSuspendInst = false) const;\n- \n-   /// If the given value is an instruction inside of the loop and it can be\n-   /// hoisted, do so to make it trivially loop-invariant.\n-diff -ruN --strip-trailing-cr a/llvm/include/llvm/Transforms/Utils/LoopUtils.h b/llvm/include/llvm/Transforms/Utils/LoopUtils.h\n---- a/llvm/include/llvm/Transforms/Utils/LoopUtils.h\n-+++ b/llvm/include/llvm/Transforms/Utils/LoopUtils.h\n-@@ -185,7 +185,8 @@\n-                           TargetLibraryInfo *, Loop *, MemorySSAUpdater &,\n-                           ScalarEvolution *, ICFLoopSafetyInfo *,\n-                           SinkAndHoistLICMFlags &, OptimizationRemarkEmitter *,\n--                          bool, bool AllowSpeculation);\n-+                          bool, bool AllowSpeculation,\n-+                          bool HasCoroSuspendInst = false);\n- \n- /// Return true if the induction variable \\p IV in a Loop whose latch is\n- /// \\p LatchBlock would become dead if the exit test \\p Cond were removed.\n-diff -ruN --strip-trailing-cr a/llvm/lib/Analysis/LoopInfo.cpp b/llvm/lib/Analysis/LoopInfo.cpp\n---- a/llvm/lib/Analysis/LoopInfo.cpp\n-+++ b/llvm/lib/Analysis/LoopInfo.cpp\n-@@ -58,14 +58,26 @@\n- // Loop implementation\n- //\n- \n--bool Loop::isLoopInvariant(const Value *V) const {\n--  if (const Instruction *I = dyn_cast<Instruction>(V))\n--    return !contains(I);\n-+bool Loop::isLoopInvariant(const Value *V, bool HasCoroSuspendInst) const {\n-+  if (const Instruction *I = dyn_cast<Instruction>(V)) {\n-+    // FIXME: this is semantically inconsistent. We're tracking a proper fix in\n-+    // issue #149604.\n-+    // If V is a pointer to stack object and L contains a coro.suspend function\n-+    // call, then V may not be loop invariant because the ramp function and\n-+    // resume function have different stack frames.\n-+    if (HasCoroSuspendInst && isa<AllocaInst>(I))\n-+      return false;\n-+    else\n-+      return !contains(I);\n++  if (Template.getAsTemplateDecl()->getKind() == Decl::TemplateTemplateParm) {\n++    assert(!Qualifier && \"unexpected qualified template template parameter\");\n++    assert(TemplateKeyword == false);\n++    return Template;\n +  }\n-   return true; // All non-instructions are loop invariant\n- }\n- \n--bool Loop::hasLoopInvariantOperands(const Instruction *I) const {\n--  return all_of(I->operands(), [this](Value *V) { return isLoopInvariant(V); });\n-+bool Loop::hasLoopInvariantOperands(const Instruction *I,\n-+                                    bool HasCoroSuspendInst) const {\n-+  return all_of(I->operands(), [&](Value *V) {\n-+    return isLoopInvariant(V, HasCoroSuspendInst);\n-+  });\n- }\n- \n- bool Loop::makeLoopInvariant(Value *V, bool &Changed, Instruction *InsertPt,\n-diff -ruN --strip-trailing-cr a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp\n---- a/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp\n-+++ b/llvm/lib/Target/NVPTX/NVPTXISelLowering.cpp\n-@@ -680,6 +680,8 @@\n-   // No support for these operations with v2f32.\n-   setOperationAction(ISD::INSERT_VECTOR_ELT, MVT::v2f32, Expand);\n-   setOperationAction(ISD::VECTOR_SHUFFLE, MVT::v2f32, Expand);\n-+  // Need custom lowering in case the index is dynamic.\n-+  setOperationAction(ISD::EXTRACT_VECTOR_ELT, MVT::v2f32, Custom);\n- \n-   // Custom conversions to/from v2i8.\n-   setOperationAction(ISD::BITCAST, MVT::v2i8, Custom);\n-diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Scalar/LICM.cpp b/llvm/lib/Transforms/Scalar/LICM.cpp\n---- a/llvm/lib/Transforms/Scalar/LICM.cpp\n-+++ b/llvm/lib/Transforms/Scalar/LICM.cpp\n-@@ -472,7 +472,7 @@\n-   if (Preheader)\n-     Changed |= hoistRegion(DT->getNode(L->getHeader()), AA, LI, DT, AC, TLI, L,\n-                            MSSAU, SE, &SafetyInfo, Flags, ORE, LoopNestMode,\n--                           LicmAllowSpeculation);\n-+                           LicmAllowSpeculation, HasCoroSuspendInst);\n- \n-   // Now that all loop invariants have been removed from the loop, promote any\n-   // memory references to scalars that we can.\n-@@ -881,7 +881,7 @@\n-                        ICFLoopSafetyInfo *SafetyInfo,\n-                        SinkAndHoistLICMFlags &Flags,\n-                        OptimizationRemarkEmitter *ORE, bool LoopNestMode,\n--                       bool AllowSpeculation) {\n-+                       bool AllowSpeculation, bool HasCoroSuspendInst) {\n-   // Verify inputs.\n-   assert(N != nullptr && AA != nullptr && LI != nullptr && DT != nullptr &&\n-          CurLoop != nullptr && SafetyInfo != nullptr &&\n-@@ -914,11 +914,11 @@\n-       // TODO: It may be safe to hoist if we are hoisting to a conditional block\n-       // and we have accurately duplicated the control flow from the loop header\n-       // to that block.\n--      if (CurLoop->hasLoopInvariantOperands(&I) &&\n-+      if (CurLoop->hasLoopInvariantOperands(&I, HasCoroSuspendInst) &&\n-           canSinkOrHoistInst(I, AA, DT, CurLoop, MSSAU, true, Flags, ORE) &&\n--          isSafeToExecuteUnconditionally(\n--              I, DT, TLI, CurLoop, SafetyInfo, ORE,\n--              Preheader->getTerminator(), AC, AllowSpeculation)) {\n-+          isSafeToExecuteUnconditionally(I, DT, TLI, CurLoop, SafetyInfo, ORE,\n-+                                         Preheader->getTerminator(), AC,\n-+                                         AllowSpeculation)) {\n-         hoist(I, DT, CurLoop, CFH.getOrCreateHoistedBlock(BB), SafetyInfo,\n-               MSSAU, SE, ORE);\n-         HoistedInstructions.push_back(&I);\n-@@ -964,7 +964,7 @@\n-                SafetyInfo->doesNotWriteMemoryBefore(I, CurLoop);\n-       };\n-       if ((IsInvariantStart(I) || isGuard(&I)) &&\n--          CurLoop->hasLoopInvariantOperands(&I) &&\n-+          CurLoop->hasLoopInvariantOperands(&I, HasCoroSuspendInst) &&\n-           MustExecuteWithoutWritesBefore(I)) {\n-         hoist(I, DT, CurLoop, CFH.getOrCreateHoistedBlock(BB), SafetyInfo,\n-               MSSAU, SE, ORE);\n-diff -ruN --strip-trailing-cr a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll\n---- a/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll\n-+++ b/llvm/test/CodeGen/NVPTX/f32x2-instructions.ll\n-@@ -79,13 +79,24 @@\n-   ret float %e\n- }\n- \n--; NOTE: disabled as -O3 miscompiles this into pointer arithmetic on\n--; test_extract_i_param_0 where the symbol's address is not taken first (that\n--; is, moved to a temporary)\n--; define float @test_extract_i(<2 x float> %a, i64 %idx) #0 {\n--;   %e = extractelement <2 x float> %a, i64 %idx\n--;   ret float %e\n--; }\n-+define float @test_extract_i(<2 x float> %a, i64 %idx) #0 {\n-+; CHECK-LABEL: test_extract_i(\n-+; CHECK:       {\n-+; CHECK-NEXT:    .reg .pred %p<2>;\n-+; CHECK-NEXT:    .reg .b32 %r<4>;\n-+; CHECK-NEXT:    .reg .b64 %rd<3>;\n-+; CHECK-EMPTY:\n-+; CHECK-NEXT:  // %bb.0:\n-+; CHECK-NEXT:    ld.param.b64 %rd2, [test_extract_i_param_1];\n-+; CHECK-NEXT:    ld.param.b64 %rd1, [test_extract_i_param_0];\n-+; CHECK-NEXT:    setp.eq.b64 %p1, %rd2, 0;\n-+; CHECK-NEXT:    mov.b64 {%r1, %r2}, %rd1;\n-+; CHECK-NEXT:    selp.f32 %r3, %r1, %r2, %p1;\n-+; CHECK-NEXT:    st.param.b32 [func_retval0], %r3;\n-+; CHECK-NEXT:    ret;\n-+  %e = extractelement <2 x float> %a, i64 %idx\n-+  ret float %e\n++\n+   // FIXME: Canonicalization?\n+   llvm::FoldingSetNodeID ID;\n+   QualifiedTemplateName::Profile(ID, Qualifier, TemplateKeyword, Template);\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTImporter.cpp b/clang/lib/AST/ASTImporter.cpp\n+--- a/clang/lib/AST/ASTImporter.cpp\n++++ b/clang/lib/AST/ASTImporter.cpp\n+@@ -1740,10 +1740,21 @@\n+ }\n+ \n+ ExpectedType ASTNodeImporter::VisitTagType(const TagType *T) {\n+-  Expected<TagDecl *> ToDeclOrErr = import(T->getOriginalDecl());\n++  TagDecl *DeclForType = T->getOriginalDecl();\n++  Expected<TagDecl *> ToDeclOrErr = import(DeclForType);\n+   if (!ToDeclOrErr)\n+     return ToDeclOrErr.takeError();\n+ \n++  if (DeclForType->isUsed()) {\n++    // If there is a definition of the 'OriginalDecl', it should be imported to\n++    // have all information for the type in the \"To\" AST. (In some cases no\n++    // other reference may exist to the definition decl and it would not be\n++    // imported otherwise.)\n++    Expected<TagDecl *> ToDefDeclOrErr = import(DeclForType->getDefinition());\n++    if (!ToDefDeclOrErr)\n++      return ToDefDeclOrErr.takeError();\n++  }\n++\n+   if (T->isCanonicalUnqualified())\n+     return Importer.getToContext().getCanonicalTagType(*ToDeclOrErr);\n+ \n+diff -ruN --strip-trailing-cr a/clang/lib/AST/ByteCode/InterpBuiltin.cpp b/clang/lib/AST/ByteCode/InterpBuiltin.cpp\n+--- a/clang/lib/AST/ByteCode/InterpBuiltin.cpp\n++++ b/clang/lib/AST/ByteCode/InterpBuiltin.cpp\n+@@ -1830,6 +1830,7 @@\n+     assert(Call->getArg(1)->getType()->isVectorType() &&\n+            ASTCtx.hasSameUnqualifiedType(Call->getArg(0)->getType(),\n+                                          Call->getArg(1)->getType()));\n++    (void)ASTCtx;\n+     ZeroArg = S.Stk.pop<Pointer>();\n+     assert(ZeroArg.getFieldDesc()->isPrimitiveArray());\n+   }\n+@@ -2728,6 +2729,8 @@\n+   if (!Arg1Type->isVectorType()) {\n+     assert(!Arg2Type->isVectorType());\n+     assert(!Arg3Type->isVectorType());\n++    (void)Arg2Type;\n++    (void)Arg3Type;\n+ \n+     const Floating &Z = S.Stk.pop<Floating>();\n+     const Floating &Y = S.Stk.pop<Floating>();\n+@@ -2753,6 +2756,7 @@\n+   assert(NumElems == Arg2Type->castAs<VectorType>()->getNumElements() &&\n+          NumElems == Arg3Type->castAs<VectorType>()->getNumElements());\n+   assert(ElemT->isRealFloatingType());\n++  (void)ElemT;\n+ \n+   const Pointer &VZ = S.Stk.pop<Pointer>();\n+   const Pointer &VY = S.Stk.pop<Pointer>();\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/DeclarationName.cpp b/clang/lib/AST/DeclarationName.cpp\n+--- a/clang/lib/AST/DeclarationName.cpp\n++++ b/clang/lib/AST/DeclarationName.cpp\n+@@ -113,6 +113,7 @@\n+                                               PrintingPolicy Policy) {\n+   // We know we're printing C++ here. Ensure we print types properly.\n+   Policy.adjustForCPlusPlus();\n++  Policy.SuppressScope = true;\n+ \n+   if (const RecordType *ClassRec = ClassType->getAs<RecordType>()) {\n+     ClassRec->getOriginalDecl()->printName(OS, Policy);\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/MicrosoftMangle.cpp b/clang/lib/AST/MicrosoftMangle.cpp\n+--- a/clang/lib/AST/MicrosoftMangle.cpp\n++++ b/clang/lib/AST/MicrosoftMangle.cpp\n+@@ -3246,13 +3246,17 @@\n+ }\n+ void MicrosoftCXXNameMangler::mangleType(const EnumType *T, Qualifiers,\n+                                          SourceRange) {\n+-  mangleType(cast<TagType>(T)->getOriginalDecl()->getDefinitionOrSelf());\n++  mangleType(cast<TagType>(T)->getOriginalDecl());\n+ }\n+ void MicrosoftCXXNameMangler::mangleType(const RecordType *T, Qualifiers,\n+                                          SourceRange) {\n+-  mangleType(cast<TagType>(T)->getOriginalDecl()->getDefinitionOrSelf());\n++  mangleType(cast<TagType>(T)->getOriginalDecl());\n+ }\n+ void MicrosoftCXXNameMangler::mangleType(const TagDecl *TD) {\n++  // MSVC chooses the tag kind of the definition if it exists, otherwise it\n++  // always picks the first declaration.\n++  const auto *Def = TD->getDefinition();\n++  TD = Def ? Def : TD->getFirstDecl();\n+   mangleTagTypeKind(TD->getTagKind());\n+   mangleName(TD);\n+ }\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/TemplateName.cpp b/clang/lib/AST/TemplateName.cpp\n+--- a/clang/lib/AST/TemplateName.cpp\n++++ b/clang/lib/AST/TemplateName.cpp\n+@@ -289,28 +289,23 @@\n+   return dyn_cast_if_present<QualifiedTemplateName *>(Storage);\n+ }\n+ \n+-QualifiedTemplateName *\n+-TemplateName::getAsAdjustedQualifiedTemplateName() const {\n+-  for (std::optional<TemplateName> Cur = *this; Cur;\n+-       Cur = Cur->desugar(/*IgnoreDeduced=*/true))\n+-    if (QualifiedTemplateName *N = Cur->getAsQualifiedTemplateName())\n+-      return N;\n+-  return nullptr;\n+-}\n+-\n+ DependentTemplateName *TemplateName::getAsDependentTemplateName() const {\n+   return Storage.dyn_cast<DependentTemplateName *>();\n+ }\n+ \n+-NestedNameSpecifier TemplateName::getQualifier() const {\n++std::tuple<NestedNameSpecifier, bool>\n++TemplateName::getQualifierAndTemplateKeyword() const {\n+   for (std::optional<TemplateName> Cur = *this; Cur;\n+        Cur = Cur->desugar(/*IgnoreDeduced=*/true)) {\n+     if (DependentTemplateName *N = Cur->getAsDependentTemplateName())\n+-      return N->getQualifier();\n++      return {N->getQualifier(), N->hasTemplateKeyword()};\n+     if (QualifiedTemplateName *N = Cur->getAsQualifiedTemplateName())\n+-      return N->getQualifier();\n++      return {N->getQualifier(), N->hasTemplateKeyword()};\n++    if (Cur->getAsSubstTemplateTemplateParm() ||\n++        Cur->getAsSubstTemplateTemplateParmPack())\n++      break;\n+   }\n+-  return std::nullopt;\n++  return {std::nullopt, false};\n+ }\n+ \n+ UsingShadowDecl *TemplateName::getAsUsingShadowDecl() const {\n+@@ -448,8 +443,14 @@\n+       Template = cast<TemplateDecl>(Template->getCanonicalDecl());\n+     if (handleAnonymousTTP(Template, OS))\n+       return;\n+-    if (Qual == Qualified::None || Policy.SuppressScope) {\n+-      OS << *Template;\n++    if (Qual == Qualified::None || isa<TemplateTemplateParmDecl>(Template) ||\n++        Policy.SuppressScope) {\n++      if (IdentifierInfo *II = Template->getIdentifier();\n++          Policy.CleanUglifiedParameters && II &&\n++          isa<TemplateTemplateParmDecl>(Template))\n++        OS << II->deuglifiedName();\n++      else\n++        OS << *Template;\n+     } else {\n+       PrintingPolicy NestedNamePolicy = Policy;\n+       NestedNamePolicy.SuppressUnwrittenScope = true;\n+@@ -474,12 +475,7 @@\n+     if (handleAnonymousTTP(UTD, OS))\n+       return;\n+ \n+-    if (IdentifierInfo *II = UTD->getIdentifier();\n+-        Policy.CleanUglifiedParameters && II &&\n+-        isa<TemplateTemplateParmDecl>(UTD))\n+-      OS << II->deuglifiedName();\n+-    else\n+-      OS << *UTD;\n++    OS << *UTD;\n+   } else if (DependentTemplateName *DTN = getAsDependentTemplateName()) {\n+     DTN->print(OS, Policy);\n+   } else if (SubstTemplateTemplateParmStorage *subst =\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/Type.cpp b/clang/lib/AST/Type.cpp\n+--- a/clang/lib/AST/Type.cpp\n++++ b/clang/lib/AST/Type.cpp\n+@@ -1963,12 +1963,10 @@\n+   switch (getTypeClass()) {\n+   case Type::DependentName:\n+     return cast<DependentNameType>(this)->getQualifier();\n+-  case Type::TemplateSpecialization: {\n+-    QualifiedTemplateName *S = cast<TemplateSpecializationType>(this)\n+-                                   ->getTemplateName()\n+-                                   .getAsAdjustedQualifiedTemplateName();\n+-    return S ? S->getQualifier() : std::nullopt;\n+-  }\n++  case Type::TemplateSpecialization:\n++    return cast<TemplateSpecializationType>(this)\n++        ->getTemplateName()\n++        .getQualifier();\n+   case Type::DependentTemplateSpecialization:\n+     return cast<DependentTemplateSpecializationType>(this)\n+         ->getDependentTemplateName()\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/TypeLoc.cpp b/clang/lib/AST/TypeLoc.cpp\n+--- a/clang/lib/AST/TypeLoc.cpp\n++++ b/clang/lib/AST/TypeLoc.cpp\n+@@ -750,8 +750,9 @@\n+ \n+ void TemplateSpecializationTypeLoc::initializeLocal(ASTContext &Context,\n+                                                     SourceLocation Loc) {\n+-  QualifiedTemplateName *Name =\n+-      getTypePtr()->getTemplateName().getAsAdjustedQualifiedTemplateName();\n++\n++  auto [Qualifier, HasTemplateKeyword] =\n++      getTypePtr()->getTemplateName().getQualifierAndTemplateKeyword();\n+ \n+   SourceLocation ElaboratedKeywordLoc =\n+       getTypePtr()->getKeyword() != ElaboratedTypeKeyword::None\n+@@ -759,8 +760,7 @@\n+           : SourceLocation();\n+ \n+   NestedNameSpecifierLoc QualifierLoc;\n+-  if (NestedNameSpecifier Qualifier =\n+-          Name ? Name->getQualifier() : std::nullopt) {\n++  if (Qualifier) {\n+     NestedNameSpecifierLocBuilder Builder;\n+     Builder.MakeTrivial(Context, Qualifier, Loc);\n+     QualifierLoc = Builder.getWithLocInContext(Context);\n+@@ -768,9 +768,7 @@\n+ \n+   TemplateArgumentListInfo TAL(Loc, Loc);\n+   set(ElaboratedKeywordLoc, QualifierLoc,\n+-      /*TemplateKeywordLoc=*/Name && Name->hasTemplateKeyword()\n+-          ? Loc\n+-          : SourceLocation(),\n++      /*TemplateKeywordLoc=*/HasTemplateKeyword ? Loc : SourceLocation(),\n+       /*NameLoc=*/Loc, /*LAngleLoc=*/Loc, /*RAngleLoc=*/Loc);\n+   initializeArgLocs(Context, getTypePtr()->template_arguments(), getArgInfos(),\n+                     Loc);\n+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDecl.cpp b/clang/lib/Sema/SemaDecl.cpp\n+--- a/clang/lib/Sema/SemaDecl.cpp\n++++ b/clang/lib/Sema/SemaDecl.cpp\n+@@ -18032,7 +18032,8 @@\n+           }\n+         }\n+       } else if (auto *RD = dyn_cast<CXXRecordDecl>(PrevDecl);\n+-                 RD && RD->isInjectedClassName()) {\n++                 TUK == TagUseKind::Reference && RD &&\n++                 RD->isInjectedClassName()) {\n+         // If lookup found the injected class name, the previous declaration is\n+         // the class being injected into.\n+         PrevDecl = cast<TagDecl>(RD->getDeclContext());\n+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDeclCXX.cpp b/clang/lib/Sema/SemaDeclCXX.cpp\n+--- a/clang/lib/Sema/SemaDeclCXX.cpp\n++++ b/clang/lib/Sema/SemaDeclCXX.cpp\n+@@ -4568,6 +4568,7 @@\n+       MarkAnyDeclReferenced(TyD->getLocation(), TyD, /*OdrUse=*/false);\n+ \n+       TypeLocBuilder TLB;\n++      // FIXME: This is missing building the UsingType for TyD, if any.\n+       if (const auto *TD = dyn_cast<TagDecl>(TyD)) {\n+         BaseType = Context.getTagType(ElaboratedTypeKeyword::None,\n+                                       SS.getScopeRep(), TD, /*OwnsTag=*/false);\n+@@ -4581,6 +4582,12 @@\n+         TLB.push<TypedefTypeLoc>(BaseType).set(\n+             /*ElaboratedKeywordLoc=*/SourceLocation(),\n+             SS.getWithLocInContext(Context), IdLoc);\n++      } else if (auto *UD = dyn_cast<UnresolvedUsingTypenameDecl>(TyD)) {\n++        BaseType = Context.getUnresolvedUsingType(ElaboratedTypeKeyword::None,\n++                                                  SS.getScopeRep(), UD);\n++        TLB.push<UnresolvedUsingTypeLoc>(BaseType).set(\n++            /*ElaboratedKeywordLoc=*/SourceLocation(),\n++            SS.getWithLocInContext(Context), IdLoc);\n+       } else {\n+         // FIXME: What else can appear here?\n+         assert(SS.isEmpty());\n+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaLookup.cpp b/clang/lib/Sema/SemaLookup.cpp\n+--- a/clang/lib/Sema/SemaLookup.cpp\n++++ b/clang/lib/Sema/SemaLookup.cpp\n+@@ -4581,7 +4581,7 @@\n+         TemplateName Name =\n+             cast<TemplateSpecializationType>(T)->getTemplateName();\n+         if (const QualifiedTemplateName *QTN =\n+-                Name.getAsAdjustedQualifiedTemplateName()) {\n++                Name.getAsQualifiedTemplateName()) {\n+           getNestedNameSpecifierIdentifiers(QTN->getQualifier(), Identifiers);\n+           Name = QTN->getUnderlyingTemplate();\n+         }\n+diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaTemplateInstantiate.cpp b/clang/lib/Sema/SemaTemplateInstantiate.cpp\n+--- a/clang/lib/Sema/SemaTemplateInstantiate.cpp\n++++ b/clang/lib/Sema/SemaTemplateInstantiate.cpp\n+@@ -2083,9 +2083,11 @@\n+     NestedNameSpecifierLoc &QualifierLoc, SourceLocation TemplateKWLoc,\n+     TemplateName Name, SourceLocation NameLoc, QualType ObjectType,\n+     NamedDecl *FirstQualifierInScope, bool AllowInjectedClassName) {\n+-  if (TemplateTemplateParmDecl *TTP\n+-       = dyn_cast_or_null<TemplateTemplateParmDecl>(Name.getAsTemplateDecl())) {\n+-    if (TTP->getDepth() < TemplateArgs.getNumLevels()) {\n++  if (Name.getKind() == TemplateName::Template) {\n++    assert(!QualifierLoc && \"Unexpected qualifier\");\n++    if (auto *TTP =\n++            dyn_cast<TemplateTemplateParmDecl>(Name.getAsTemplateDecl());\n++        TTP && TTP->getDepth() < TemplateArgs.getNumLevels()) {\n+       // If the corresponding template argument is NULL or non-existent, it's\n+       // because we are performing instantiation from explicitly-specified\n+       // template arguments in a function template, but there were some\n+@@ -2128,13 +2130,6 @@\n+ \n+       TemplateName Template = Arg.getAsTemplate();\n+       assert(!Template.isNull() && \"Null template template argument\");\n+-\n+-      if (NestedNameSpecifier Qualifier = Template.getQualifier()) {\n+-        NestedNameSpecifierLocBuilder Builder;\n+-        Builder.MakeTrivial(SemaRef.Context, Qualifier, NameLoc);\n+-        QualifierLoc = Builder.getWithLocInContext(SemaRef.Context);\n+-      }\n+-\n+       return getSema().Context.getSubstTemplateTemplateParm(\n+           Template, AssociatedDecl, TTP->getIndex(), PackIndex, Final);\n+     }\n+diff -ruN --strip-trailing-cr a/clang/lib/Sema/TreeTransform.h b/clang/lib/Sema/TreeTransform.h\n+--- a/clang/lib/Sema/TreeTransform.h\n++++ b/clang/lib/Sema/TreeTransform.h\n+@@ -697,11 +697,6 @@\n+ \n+   StmtResult TransformSEHHandler(Stmt *Handler);\n+ \n+-  QualType TransformTemplateSpecializationType(TypeLocBuilder &TLB,\n+-                                               TemplateSpecializationTypeLoc TL,\n+-                                               TemplateName Template,\n+-                                               CXXScopeSpec &SS);\n+-\n+   QualType TransformDependentTemplateSpecializationType(\n+       TypeLocBuilder &TLB, DependentTemplateSpecializationTypeLoc TL,\n+       QualType ObjectType, NamedDecl *UnqualLookup,\n+@@ -1268,9 +1263,8 @@\n+   ///\n+   /// By default, builds the new template name directly. Subclasses may override\n+   /// this routine to provide different behavior.\n+-  TemplateName RebuildTemplateName(CXXScopeSpec &SS,\n+-                                   bool TemplateKW,\n+-                                   TemplateDecl *Template);\n++  TemplateName RebuildTemplateName(CXXScopeSpec &SS, bool TemplateKW,\n++                                   TemplateName Name);\n+ \n+   /// Build a new template name given a nested name specifier and the\n+   /// name that is referred to as a template.\n+@@ -4776,9 +4770,7 @@\n+     TemplateName Name, SourceLocation NameLoc, QualType ObjectType,\n+     NamedDecl *FirstQualifierInScope, bool AllowInjectedClassName) {\n+   if (QualifiedTemplateName *QTN = Name.getAsQualifiedTemplateName()) {\n+-    // FIXME: Preserve UsingTemplateName.\n+-    TemplateDecl *Template = QTN->getUnderlyingTemplate().getAsTemplateDecl();\n+-    assert(Template && \"qualified template name must refer to a template\");\n++    TemplateName UnderlyingName = QTN->getUnderlyingTemplate();\n+ \n+     if (QualifierLoc) {\n+       QualifierLoc = getDerived().TransformNestedNameSpecifierLoc(\n+@@ -4787,20 +4779,22 @@\n+         return TemplateName();\n+     }\n+ \n+-    TemplateDecl *TransTemplate\n+-      = cast_or_null<TemplateDecl>(getDerived().TransformDecl(NameLoc,\n+-                                                              Template));\n+-    if (!TransTemplate)\n++    NestedNameSpecifierLoc UnderlyingQualifier;\n++    TemplateName NewUnderlyingName = getDerived().TransformTemplateName(\n++        UnderlyingQualifier, TemplateKWLoc, UnderlyingName, NameLoc, ObjectType,\n++        FirstQualifierInScope, AllowInjectedClassName);\n++    if (NewUnderlyingName.isNull())\n+       return TemplateName();\n++    assert(!UnderlyingQualifier && \"unexpected qualifier\");\n+ \n+     if (!getDerived().AlwaysRebuild() &&\n+         QualifierLoc.getNestedNameSpecifier() == QTN->getQualifier() &&\n+-        TransTemplate == Template)\n++        NewUnderlyingName == UnderlyingName)\n+       return Name;\n+     CXXScopeSpec SS;\n+     SS.Adopt(QualifierLoc);\n+     return getDerived().RebuildTemplateName(SS, QTN->hasTemplateKeyword(),\n+-                                            TransTemplate);\n++                                            NewUnderlyingName);\n+   }\n+ \n+   if (DependentTemplateName *DTN = Name.getAsDependentTemplateName()) {\n+@@ -4828,9 +4822,19 @@\n+ \n+   if (SubstTemplateTemplateParmStorage *S =\n+           Name.getAsSubstTemplateTemplateParm()) {\n++    assert(!QualifierLoc && \"Unexpected qualified SubstTemplateTemplateParm\");\n++\n++    NestedNameSpecifierLoc ReplacementQualifierLoc;\n++    TemplateName ReplacementName = S->getReplacement();\n++    if (NestedNameSpecifier Qualifier = ReplacementName.getQualifier()) {\n++      NestedNameSpecifierLocBuilder Builder;\n++      Builder.MakeTrivial(SemaRef.Context, Qualifier, NameLoc);\n++      ReplacementQualifierLoc = Builder.getWithLocInContext(SemaRef.Context);\n++    }\n++\n+     TemplateName NewName = getDerived().TransformTemplateName(\n+-        QualifierLoc, TemplateKWLoc, S->getReplacement(), NameLoc, ObjectType,\n+-        FirstQualifierInScope, AllowInjectedClassName);\n++        ReplacementQualifierLoc, TemplateKWLoc, ReplacementName, NameLoc,\n++        ObjectType, FirstQualifierInScope, AllowInjectedClassName);\n+     if (NewName.isNull())\n+       return TemplateName();\n+     Decl *AssociatedDecl =\n+@@ -4846,21 +4850,17 @@\n+   assert(!Name.getAsDeducedTemplateName() &&\n+          \"DeducedTemplateName should not escape partial ordering\");\n+ \n+-  if (TemplateDecl *Template = Name.getAsTemplateDecl()) {\n+-    assert(!QualifierLoc && \"missed a Qualified Template\");\n+-    TemplateDecl *TransTemplate\n+-      = cast_or_null<TemplateDecl>(getDerived().TransformDecl(NameLoc,\n+-                                                              Template));\n+-    if (!TransTemplate)\n+-      return TemplateName();\n+-\n+-    CXXScopeSpec SS;\n+-    return getDerived().RebuildTemplateName(SS, /*TemplateKeyword=*/false,\n+-                                            TransTemplate);\n++  // FIXME: Preserve UsingTemplateName.\n++  if (auto *Template = Name.getAsTemplateDecl()) {\n++    assert(!QualifierLoc && \"Unexpected qualifier\");\n++    return TemplateName(cast_or_null<TemplateDecl>(\n++        getDerived().TransformDecl(NameLoc, Template)));\n+   }\n+ \n+   if (SubstTemplateTemplateParmPackStorage *SubstPack\n+       = Name.getAsSubstTemplateTemplateParmPack()) {\n++    assert(!QualifierLoc &&\n++           \"Unexpected qualified SubstTemplateTemplateParmPack\");\n+     return getDerived().RebuildTemplateName(\n+         SubstPack->getArgumentPack(), SubstPack->getAssociatedDecl(),\n+         SubstPack->getIndex(), SubstPack->getFinal());\n+@@ -5414,21 +5414,10 @@\n+         TLB, TL.castAs<DependentNameTypeLoc>(), /*DeducedTSTContext=*/false,\n+         ObjectType, UnqualLookup);\n+   }\n+-  case TypeLoc::Typedef:\n+-  case TypeLoc::TemplateSpecialization:\n+-  case TypeLoc::SubstTemplateTypeParm:\n+-  case TypeLoc::SubstTemplateTypeParmPack:\n+-  case TypeLoc::PackIndexing:\n+-  case TypeLoc::Enum:\n+-  case TypeLoc::Record:\n+-  case TypeLoc::InjectedClassName:\n+-  case TypeLoc::TemplateTypeParm:\n+-  case TypeLoc::Decltype:\n+-  case TypeLoc::UnresolvedUsing:\n+-  case TypeLoc::Using:\n+-    return getDerived().TransformType(TLB, TL);\n+   default:\n+-    llvm_unreachable(\"unexpected type class\");\n++    // Any dependent canonical type can appear here, through type alias\n++    // templates.\n++    return getDerived().TransformType(TLB, TL);\n+   }\n+ }\n+ \n+@@ -17386,13 +17375,12 @@\n+   return SemaRef.BuildBitIntType(IsUnsigned, NumBitsExpr, Loc);\n+ }\n+ \n+-template<typename Derived>\n+-TemplateName\n+-TreeTransform<Derived>::RebuildTemplateName(CXXScopeSpec &SS,\n+-                                            bool TemplateKW,\n+-                                            TemplateDecl *Template) {\n++template <typename Derived>\n++TemplateName TreeTransform<Derived>::RebuildTemplateName(CXXScopeSpec &SS,\n++                                                         bool TemplateKW,\n++                                                         TemplateName Name) {\n+   return SemaRef.Context.getQualifiedTemplateName(SS.getScopeRep(), TemplateKW,\n+-                                                  TemplateName(Template));\n++                                                  Name);\n+ }\n+ \n+ template <typename Derived>\n+diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReader.cpp b/clang/lib/Serialization/ASTReader.cpp\n+--- a/clang/lib/Serialization/ASTReader.cpp\n++++ b/clang/lib/Serialization/ASTReader.cpp\n+@@ -11003,8 +11003,9 @@\n+ }\n+ \n+ void ASTReader::StartedDeserializing() {\n+-  if (++NumCurrentElementsDeserializing == 1 && ReadTimer.get())\n+-    ReadTimer->startTimer();\n++  if (llvm::Timer *T = ReadTimer.get();\n++      ++NumCurrentElementsDeserializing == 1 && T)\n++    ReadTimeRegion.emplace(T);\n+ }\n+ \n+ void ASTReader::FinishedDeserializing() {\n+@@ -11062,8 +11063,7 @@\n+           (void)UndeducedFD->getMostRecentDecl();\n+       }\n+ \n+-      if (ReadTimer)\n+-        ReadTimer->stopTimer();\n++      ReadTimeRegion.reset();\n+ \n+       diagnoseOdrViolations();\n+     }\n+diff -ruN --strip-trailing-cr a/clang/test/Analysis/ctu-import-type-decl-definition.c b/clang/test/Analysis/ctu-import-type-decl-definition.c\n+--- a/clang/test/Analysis/ctu-import-type-decl-definition.c\n++++ b/clang/test/Analysis/ctu-import-type-decl-definition.c\n+@@ -0,0 +1,43 @@\n++// RUN: rm -rf %t\n++// RUN: mkdir -p %t\n++// RUN: split-file %s %t\n++\n++// RUN: %clang_cc1 -emit-pch -o %t/import.c.ast %t/import.c\n++\n++// RUN: %clang_extdef_map -- -x c %t/import.c >> %t/externalDefMap.txt\n++// RUN: sed -i 's/$/.ast/' %t/externalDefMap.txt\n++\n++// RUN: %clang_cc1 -analyze \\\n++// RUN:   -analyzer-checker=core \\\n++// RUN:   -analyzer-config experimental-enable-naive-ctu-analysis=true \\\n++// RUN:   -analyzer-config display-ctu-progress=true \\\n++// RUN:   -analyzer-config ctu-dir=%t \\\n++// RUN:   -verify %t/main.c\n++\n++//--- main.c\n++\n++// expected-no-diagnostics\n++\n++typedef struct X_s X_t;\n++unsigned long f_import(struct X_s *xPtr);\n++\n++static void freeWriteFileResources(struct X_s *xPtr) {\n++  f_import(xPtr);\n++}\n++\n++//--- import.c\n++\n++typedef struct Y_s Y_t;\n++\n++struct Y_s {\n++};\n++\n++struct X_s {\n++  Y_t y;\n++};\n++\n++unsigned long f_import(struct X_s *xPtr) {\n++  if (xPtr != 0) {\n++  }\n++  return 0;\n +}\n+diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-decl.cpp b/clang/test/AST/ast-dump-decl.cpp\n+--- a/clang/test/AST/ast-dump-decl.cpp\n++++ b/clang/test/AST/ast-dump-decl.cpp\n+@@ -330,8 +330,8 @@\n+ // CHECK-NEXT:  | | `-Destructor irrelevant non_trivial user_declared{{$}}\n+ // CHECK-NEXT:  | |-CXXRecordDecl 0x{{.+}} <col:24, col:30> col:30 implicit referenced class TestClassTemplate{{$}}\n+ // CHECK-NEXT:  | |-AccessSpecDecl 0x{{.+}} <line:[[@LINE-50]]:3, col:9> col:3 public{{$}}\n+-// CHECK-NEXT:  | |-CXXConstructorDecl 0x[[#%x,TEMPLATE_CONSTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:23> col:5 testClassTemplateDecl::TestClassTemplate<T> 'void ()'{{$}}\n+-// CHECK-NEXT:  | |-CXXDestructorDecl 0x[[#%x,TEMPLATE_DESTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:24> col:5 ~testClassTemplateDecl::TestClassTemplate<T> 'void ()' not_selected{{$}}\n++// CHECK-NEXT:  | |-CXXConstructorDecl 0x[[#%x,TEMPLATE_CONSTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:23> col:5 TestClassTemplate<T> 'void ()'{{$}}\n++// CHECK-NEXT:  | |-CXXDestructorDecl 0x[[#%x,TEMPLATE_DESTRUCTOR_DECL:]] <line:[[@LINE-50]]:5, col:24> col:5 ~TestClassTemplate<T> 'void ()' not_selected{{$}}\n+ // CHECK-NEXT:  | |-CXXMethodDecl 0x[[#%x,TEMPLATE_METHOD_DECL:]] <line:[[@LINE-50]]:5, col:11> col:9 j 'int ()'{{$}}\n+ // CHECK-NEXT:  | `-FieldDecl 0x{{.+}} <line:[[@LINE-50]]:5, col:9> col:9 i 'int'{{$}}\n+ // CHECK-NEXT:  |-ClassTemplateSpecializationDecl 0x{{.+}} <line:[[@LINE-56]]:3, line:[[@LINE-50]]:3> line:[[@LINE-56]]:30 class TestClassTemplate definition implicit_instantiation{{$}}\n+@@ -973,5 +973,35 @@\n+   // CHECK-NEXT: `-VarDecl 0x{{.+}} <col:25, col:48> col:37 call_init 'const T' constexpr callinit{{$}}\n+   // CHECK-NEXT:  `-ParenListExpr 0x{{.+}} <col:46, col:48> 'NULL TYPE'{{$}}\n+   // CHECK-NEXT:   `-IntegerLiteral 0x{{.+}} <col:47> 'int' 0{{$}}\n+-\n+ }\n++\n++namespace TestInjectedClassName {\n++  struct A {\n++    using T1 = A;\n++    using T2 = A;\n++  };\n++  // CHECK-LABEL: Dumping TestInjectedClassName:\n++  // CHECK:       CXXRecordDecl [[TestInjectedClassName_RD:0x[^ ]+]] {{.*}} struct A definition\n++  // CHECK:       CXXRecordDecl {{.*}} implicit referenced struct A\n++  // CHECK-NEXT:  |-TypeAliasDecl {{.*}} T1 'A'\n++  // CHECK-NEXT:  | `-RecordType [[TestInjectedClassName_RT:0x[^ ]+]] 'A' injected\n++  // CHECK-NEXT:  |   `-CXXRecord [[TestInjectedClassName_RD]] 'A'\n++  // CHECK-NEXT:  `-TypeAliasDecl {{.*}} T2 'A'\n++  // CHECK-NEXT:    `-RecordType [[TestInjectedClassName_RT]] 'A' injected\n++  // CHECK-NEXT:      `-CXXRecord [[TestInjectedClassName_RD]] 'A'\n++} // namespace InjectedClassName\n++\n++namespace TestGH155936 {\n++  struct Foo {\n++    struct A {\n++      struct Foo {};\n++    };\n++  };\n++  // CHECK-LABEL: Dumping TestGH155936:\n++  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-6]]:10 struct Foo definition\n++  // CHECK: CXXRecordDecl 0x{{.+}} <col:3, col:10> col:10 implicit struct Foo\n++  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-7]]:12 struct A definition\n++  // CHECK: CXXRecordDecl 0x{{.+}} <col:5, col:12> col:12 implicit struct A\n++  // CHECK: CXXRecordDecl 0x{{.+}} <line:[[@LINE-8]]:7, col:19> col:14 struct Foo definition\n++  // CHECH: CXXRecordDecl 0x{{.+}} <col:9, col:16> col:16 implicit struct Foo\n++} // namspace GH155936\n+diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-templates.cpp b/clang/test/AST/ast-dump-templates.cpp\n+--- a/clang/test/AST/ast-dump-templates.cpp\n++++ b/clang/test/AST/ast-dump-templates.cpp\n+@@ -8170,7 +8170,7 @@\n+ // JSON-NEXT:              \"tokLen\": 1\n+ // JSON-NEXT:             }\n+ // JSON-NEXT:            },\n+-// JSON-NEXT:            \"name\": \"GH153540::N::S<T>\",\n++// JSON-NEXT:            \"name\": \"S<T>\",\n+ // JSON-NEXT:            \"type\": {\n+ // JSON-NEXT:             \"qualType\": \"void (T)\"\n+ // JSON-NEXT:            },\n+diff -ruN --strip-trailing-cr a/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl b/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl\n+--- a/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl\n++++ b/clang/test/AST/HLSL/StructuredBuffers-AST.hlsl\n+@@ -91,7 +91,7 @@\n+ \n+ // Default constructor\n+ \n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void ()' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void ()' inline\n+ // CHECK-NEXT: CompoundStmt\n+ // CHECK-NEXT: BinaryOperator {{.*}} '='\n+ // CHECK-NEXT: MemberExpr {{.*}} lvalue .__handle\n+@@ -105,7 +105,7 @@\n+ \n+ // Constructor from binding\n  \n- define <2 x float> @test_fadd(<2 x float> %a, <2 x float> %b) #0 {\n- ; CHECK-NOF32X2-LABEL: test_fadd(\n-diff -ruN --strip-trailing-cr a/llvm/test/Transforms/LICM/licm-coroutine.ll b/llvm/test/Transforms/LICM/licm-coroutine.ll\n---- a/llvm/test/Transforms/LICM/licm-coroutine.ll\n-+++ b/llvm/test/Transforms/LICM/licm-coroutine.ll\n-@@ -0,0 +1,78 @@\n-+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n-+; RUN: opt < %s -passes=licm -S | FileCheck %s\n-+\n-+; %fca.0 and %fca.1 should not be hoisted out of the loop because the ramp\n-+; function and resume function have different stack frames, so %pointer1 and\n-+; %pointer2 have different values before and after @llvm.coro.suspend.\n-+\n-+define ptr @f(i32 %n) presplitcoroutine {\n-+; CHECK-LABEL: define ptr @f(\n-+; CHECK-SAME: i32 [[N:%.*]]) #[[ATTR0:[0-9]+]] {\n-+; CHECK-NEXT:  [[ENTRY:.*]]:\n-+; CHECK-NEXT:    [[POINTER1:%.*]] = alloca ptr, align 8\n-+; CHECK-NEXT:    [[POINTER2:%.*]] = alloca ptr, align 8\n-+; CHECK-NEXT:    [[ID:%.*]] = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null)\n-+; CHECK-NEXT:    [[SIZE:%.*]] = call i32 @llvm.coro.size.i32()\n-+; CHECK-NEXT:    [[ALLOC:%.*]] = call ptr @malloc(i32 [[SIZE]])\n-+; CHECK-NEXT:    [[HDL:%.*]] = call noalias ptr @llvm.coro.begin(token [[ID]], ptr [[ALLOC]])\n-+; CHECK-NEXT:    br label %[[LOOP:.*]]\n-+; CHECK:       [[LOOP]]:\n-+; CHECK-NEXT:    [[N_VAL:%.*]] = phi i32 [ [[N]], %[[ENTRY]] ], [ [[INC:%.*]], %[[RESUME:.*]] ]\n-+; CHECK-NEXT:    [[INC]] = add nsw i32 [[N_VAL]], 1\n-+; CHECK-NEXT:    call void @print(i32 [[N_VAL]])\n-+; CHECK-NEXT:    [[TMP0:%.*]] = call i8 @llvm.coro.suspend(token none, i1 false)\n-+; CHECK-NEXT:    switch i8 [[TMP0]], label %[[SUSPEND_LOOPEXIT:.*]] [\n-+; CHECK-NEXT:      i8 0, label %[[RESUME]]\n-+; CHECK-NEXT:      i8 1, label %[[CLEANUP:.*]]\n-+; CHECK-NEXT:    ]\n-+; CHECK:       [[RESUME]]:\n-+; CHECK-NEXT:    [[FCA_0:%.*]] = insertvalue [2 x ptr] poison, ptr [[POINTER1]], 0\n-+; CHECK-NEXT:    [[FCA_1:%.*]] = insertvalue [2 x ptr] [[FCA_0]], ptr [[POINTER2]], 1\n-+; CHECK-NEXT:    call void @foo([2 x ptr] [[FCA_1]])\n-+; CHECK-NEXT:    br label %[[LOOP]]\n-+; CHECK:       [[CLEANUP]]:\n-+; CHECK-NEXT:    [[MEM:%.*]] = call ptr @llvm.coro.free(token [[ID]], ptr [[HDL]])\n-+; CHECK-NEXT:    call void @free(ptr [[MEM]])\n-+; CHECK-NEXT:    br label %[[SUSPEND:.*]]\n-+; CHECK:       [[SUSPEND_LOOPEXIT]]:\n-+; CHECK-NEXT:    br label %[[SUSPEND]]\n-+; CHECK:       [[SUSPEND]]:\n-+; CHECK-NEXT:    [[UNUSED:%.*]] = call i1 @llvm.coro.end(ptr [[HDL]], i1 false, token none)\n-+; CHECK-NEXT:    ret ptr [[HDL]]\n-+;\n-+entry:\n-+  %pointer1 = alloca ptr\n-+  %pointer2 = alloca ptr\n-+  %id = call token @llvm.coro.id(i32 0, ptr null, ptr null, ptr null)\n-+  %size = call i32 @llvm.coro.size.i32()\n-+  %alloc = call ptr @malloc(i32 %size)\n-+  %hdl = call noalias ptr @llvm.coro.begin(token %id, ptr %alloc)\n-+  br label %loop\n-+\n-+loop:\n-+  %n.val = phi i32 [ %n, %entry ], [ %inc, %resume ]\n-+  %inc = add nsw i32 %n.val, 1\n-+  call void @print(i32 %n.val)\n-+  %0 = call i8 @llvm.coro.suspend(token none, i1 false)\n-+  switch i8 %0, label %suspend [i8 0, label %resume\n-+  i8 1, label %cleanup]\n-+\n-+resume:\n-+  %fca.0 = insertvalue [2 x ptr] poison, ptr %pointer1, 0\n-+  %fca.1 = insertvalue [2 x ptr] %fca.0, ptr %pointer2, 1\n-+  call void @foo([2 x ptr] %fca.1)\n-+  br label %loop\n-+\n-+cleanup:\n-+  %mem = call ptr @llvm.coro.free(token %id, ptr %hdl)\n-+  call void @free(ptr %mem)\n-+  br label %suspend\n-+suspend:\n-+  %unused = call i1 @llvm.coro.end(ptr %hdl, i1 false, token none)\n-+  ret ptr %hdl\n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline\n+ // CHECK-NEXT: ParmVarDecl {{.*}} registerNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'\n+@@ -129,7 +129,7 @@\n+ \n+ // Constructor from implicit binding\n+ \n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline\n+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} index 'unsigned int'\n+diff -ruN --strip-trailing-cr a/clang/test/AST/HLSL/TypedBuffers-AST.hlsl b/clang/test/AST/HLSL/TypedBuffers-AST.hlsl\n+--- a/clang/test/AST/HLSL/TypedBuffers-AST.hlsl\n++++ b/clang/test/AST/HLSL/TypedBuffers-AST.hlsl\n+@@ -66,7 +66,7 @@\n+ \n+ // Default constructor\n+ \n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void ()' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void ()' inline\n+ // CHECK-NEXT: CompoundStmt\n+ // CHECK-NEXT: BinaryOperator {{.*}} '='\n+ // CHECK-NEXT: MemberExpr {{.*}} lvalue .__handle\n+@@ -80,7 +80,7 @@\n+ \n+ // Constructor from binding\n+ \n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, unsigned int, int, unsigned int, const char *)' inline\n+ // CHECK-NEXT: ParmVarDecl {{.*}} registerNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'\n+@@ -104,7 +104,7 @@\n+ \n+ // Constructor from implicit binding\n+ \n+-// CHECK: CXXConstructorDecl {{.*}} hlsl::[[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline\n++// CHECK: CXXConstructorDecl {{.*}} [[RESOURCE]]<element_type> 'void (unsigned int, int, unsigned int, unsigned int, const char *)' inline\n+ // CHECK-NEXT: ParmVarDecl {{.*}} spaceNo 'unsigned int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} range 'int'\n+ // CHECK-NEXT: ParmVarDecl {{.*}} index 'unsigned int'\n+diff -ruN --strip-trailing-cr a/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp b/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp\n+--- a/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp\n++++ b/clang/test/CodeGenCXX/mangle-ms-cxx11.cpp\n+@@ -358,3 +358,42 @@\n+ // DBG-DAG: DW_TAG_enumeration_type{{.*}}identifier: \".?AW4<unnamed-type-$S3>@s@pr37723@@\"\n+ s x;\n+ }\n++\n++namespace InconsistentTagKinds {\n++  namespace t1 {\n++    class A;\n++    struct A;\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t1@InconsistentTagKinds@@YAXPAVA@12@@Z\"\n++  } // namespace t1\n++  namespace t2 {\n++    struct A;\n++    class A;\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t2@InconsistentTagKinds@@YAXPAUA@12@@Z\"\n++  } // namespace t2\n++  namespace t3 {\n++    class A {};\n++    struct A;\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t3@InconsistentTagKinds@@YAXPAVA@12@@Z\"\n++  } // namespace t3\n++  namespace t4 {\n++    struct A {};\n++    class A;\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t4@InconsistentTagKinds@@YAXPAUA@12@@Z\"\n++  } // namespace t4\n++  namespace t5 {\n++    class A;\n++    struct A {};\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t5@InconsistentTagKinds@@YAXPAUA@12@@Z\"\n++  } // namespace t5\n++  namespace t6 {\n++    struct A;\n++    class A {};\n++    void f(A*) {}\n++    // CHECK-DAG: @\"?f@t6@InconsistentTagKinds@@YAXPAVA@12@@Z\"\n++  } // namespace t6\n++} // namespace InconsistentTagKinds\n+diff -ruN --strip-trailing-cr a/clang/test/CXX/drs/cwg6xx.cpp b/clang/test/CXX/drs/cwg6xx.cpp\n+--- a/clang/test/CXX/drs/cwg6xx.cpp\n++++ b/clang/test/CXX/drs/cwg6xx.cpp\n+@@ -383,7 +383,7 @@\n+   template<typename T> template<typename U> D<T>::D() {}\n+   template<typename T> D<T>::D<T>() {} // #cwg635-D-T\n+   // expected-error@#cwg635-D-T {{out-of-line constructor for 'D' cannot have template arguments}}\n+-  // expected-error@#cwg635-D-T {{redefinition of 'cwg635::D<T>'}}\n++  // expected-error@#cwg635-D-T {{redefinition of 'D<T>'}}\n+   //   expected-note@#cwg635-D {{previous definition is here}}\n+ } // namespace cwg635\n+ \n+diff -ruN --strip-trailing-cr a/clang/test/Index/recursive-cxx-member-calls.cpp b/clang/test/Index/recursive-cxx-member-calls.cpp\n+--- a/clang/test/Index/recursive-cxx-member-calls.cpp\n++++ b/clang/test/Index/recursive-cxx-member-calls.cpp\n+@@ -823,18 +823,18 @@\n+ // CHECK-tokens: Punctuation: \";\" [85:18 - 85:19] ClassTemplate=StringSwitch:83:47 (Definition)\n+ // CHECK-tokens: Keyword: \"public\" [86:1 - 86:7] CXXAccessSpecifier=:86:1 (Definition)\n+ // CHECK-tokens: Punctuation: \":\" [86:7 - 86:8] CXXAccessSpecifier=:86:1 (Definition)\n+-// CHECK-tokens: Keyword: \"explicit\" [87:3 - 87:11] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)\n+-// CHECK-tokens: Identifier: \"StringSwitch\" [87:12 - 87:24] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition) (explicit)\n+-// CHECK-tokens: Punctuation: \"(\" [87:24 - 87:25] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)\n++// CHECK-tokens: Keyword: \"explicit\" [87:3 - 87:11] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)\n++// CHECK-tokens: Identifier: \"StringSwitch\" [87:12 - 87:24] CXXConstructor=StringSwitch<T, R>:87:12 (Definition) (explicit)\n++// CHECK-tokens: Punctuation: \"(\" [87:24 - 87:25] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)\n+ // CHECK-tokens: Identifier: \"StringRef\" [87:25 - 87:34] TypeRef=class llvm::StringRef:38:7\n+ // CHECK-tokens: Identifier: \"Str\" [87:35 - 87:38] ParmDecl=Str:87:35 (Definition)\n+-// CHECK-tokens: Punctuation: \")\" [87:38 - 87:39] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)\n+-// CHECK-tokens: Punctuation: \":\" [87:40 - 87:41] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)\n++// CHECK-tokens: Punctuation: \")\" [87:38 - 87:39] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)\n++// CHECK-tokens: Punctuation: \":\" [87:40 - 87:41] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)\n+ // CHECK-tokens: Identifier: \"Str\" [87:42 - 87:45] MemberRef=Str:84:13\n+ // CHECK-tokens: Punctuation: \"(\" [87:45 - 87:46] CallExpr=StringRef:38:7\n+ // CHECK-tokens: Identifier: \"Str\" [87:46 - 87:49] DeclRefExpr=Str:87:35\n+ // CHECK-tokens: Punctuation: \")\" [87:49 - 87:50] CallExpr=StringRef:38:7\n+-// CHECK-tokens: Punctuation: \",\" [87:50 - 87:51] CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition)\n++// CHECK-tokens: Punctuation: \",\" [87:50 - 87:51] CXXConstructor=StringSwitch<T, R>:87:12 (Definition)\n+ // CHECK-tokens: Identifier: \"Result\" [87:52 - 87:58] MemberRef=Result:85:12\n+ // CHECK-tokens: Punctuation: \"(\" [87:58 - 87:59] UnexposedExpr=\n+ // CHECK-tokens: Literal: \"0\" [87:59 - 87:60] IntegerLiteral=\n+@@ -1839,7 +1839,7 @@\n+ // CHECK: 84:3: TypeRef=class llvm::StringRef:38:7 Extent=[84:3 - 84:12]\n+ // CHECK: 85:12: FieldDecl=Result:85:12 (Definition) Extent=[85:3 - 85:18]\n+ // CHECK: 86:1: CXXAccessSpecifier=:86:1 (Definition) Extent=[86:1 - 86:8]\n+-// CHECK: 87:12: CXXConstructor=llvm::StringSwitch<T, R>:87:12 (Definition) (explicit) Extent=[87:3 - 87:64]\n++// CHECK: 87:12: CXXConstructor=StringSwitch<T, R>:87:12 (Definition) (explicit) Extent=[87:3 - 87:64]\n+ // CHECK: 87:35: ParmDecl=Str:87:35 (Definition) Extent=[87:25 - 87:38]\n+ // CHECK: 87:25: TypeRef=class llvm::StringRef:38:7 Extent=[87:25 - 87:34]\n+ // CHECK: 87:42: MemberRef=Str:84:13 Extent=[87:42 - 87:45]\n+diff -ruN --strip-trailing-cr a/clang/test/PCH/cxx-explicit-specifier.cpp b/clang/test/PCH/cxx-explicit-specifier.cpp\n+--- a/clang/test/PCH/cxx-explicit-specifier.cpp\n++++ b/clang/test/PCH/cxx-explicit-specifier.cpp\n+@@ -85,7 +85,7 @@\n+ //expected-note@-8+ {{explicit conversion function is not a candidate (explicit specifier}}\n+ //expected-note@-11 {{explicit constructor is not a candidate (explicit specifier}}\n+ \n+-//CHECK: explicit(b){{ +}}templ::A<b>(B<b>)\n++//CHECK: explicit(b){{ +}}A\n+ //CHECK: explicit(b{{ +}}^{{ +}}T::value){{ +}}operator\n+ \n+ A a = { b_true }; //expected-error {{class template argument deduction}}\n+diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/cxx20-ctad-type-alias.cpp b/clang/test/SemaCXX/cxx20-ctad-type-alias.cpp\n+--- a/clang/test/SemaCXX/cxx20-ctad-type-alias.cpp\n++++ b/clang/test/SemaCXX/cxx20-ctad-type-alias.cpp\n+@@ -110,10 +110,10 @@\n+ \n+ template <typename X, int Y>\n+ using Bar = Foo<X, sizeof(X)>; // expected-note {{candidate template ignored: couldn't infer template argument 'X'}} \\\n+-                               // expected-note {{implicit deduction guide declared as 'template <typename X> requires __is_deducible(test9::Bar, Foo<X, sizeof(X)>) Bar(Foo<X, sizeof(X)>) -> Foo<X, sizeof(X)>'}} \\\n+-                               // expected-note {{implicit deduction guide declared as 'template <typename X> requires __is_deducible(test9::Bar, Foo<X, sizeof(X)>) Bar(const X (&)[sizeof(X)]) -> Foo<X, sizeof(X)>'}} \\\n++                               // expected-note {{implicit deduction guide declared as 'template <typename X> requires __is_deducible(test9::Bar, test9::Foo<X, sizeof(X)>) Bar(test9::Foo<X, sizeof(X)>) -> test9::Foo<X, sizeof(X)>'}} \\\n++                               // expected-note {{implicit deduction guide declared as 'template <typename X> requires __is_deducible(test9::Bar, test9::Foo<X, sizeof(X)>) Bar(const X (&)[sizeof(X)]) -> test9::Foo<X, sizeof(X)>'}} \\\n+                                // expected-note {{candidate template ignored: constraints not satisfied [with X = int]}} \\\n+-                               // expected-note {{cannot deduce template arguments for 'Bar' from 'Foo<int, 4UL>'}}\n++                               // expected-note {{cannot deduce template arguments for 'test9::Bar' from 'test9::Foo<int, 4UL>'}}\n+ \n+ \n+ Bar s = {{1}}; // expected-error {{no viable constructor or deduction guide }}\n+@@ -138,13 +138,13 @@\n+ struct A {};\n+ template<class T> struct Foo { T c; };\n+ template<class X, class Y=A>\n+-using AFoo = Foo<Y>; // expected-note {{candidate template ignored: could not match 'Foo<Y>' against 'int'}} \\\n+-                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, Foo<Y>) AFoo(Foo<Y>) -> Foo<Y>'}} \\\n++using AFoo = Foo<Y>; // expected-note {{candidate template ignored: could not match 'test11::Foo<Y>' against 'int'}} \\\n++                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, test11::Foo<Y>) AFoo(test11::Foo<Y>) -> test11::Foo<Y>'}} \\\n+                     // expected-note {{candidate template ignored: constraints not satisfied [with Y = int]}} \\\n+-                    // expected-note {{cannot deduce template arguments for 'AFoo' from 'Foo<int>'}} \\\n+-                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, Foo<Y>) AFoo(Y) -> Foo<Y>'}} \\\n++                    // expected-note {{cannot deduce template arguments for 'test11::AFoo' from 'test11::Foo<int>'}} \\\n++                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, test11::Foo<Y>) AFoo(Y) -> test11::Foo<Y>'}} \\\n+                     // expected-note {{candidate function template not viable: requires 0 arguments, but 1 was provided}} \\\n+-                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, Foo<Y>) AFoo() -> Foo<Y>'}}\n++                    // expected-note {{implicit deduction guide declared as 'template <class Y = A> requires __is_deducible(test11::AFoo, test11::Foo<Y>) AFoo() -> test11::Foo<Y>'}}\n+ \n+ AFoo s = {1}; // expected-error {{no viable constructor or deduction guide for deduction of template arguments of 'AFoo'}}\n+ } // namespace test11\n+@@ -197,8 +197,8 @@\n+ template <int K>\n+ using Bar = Foo<double, K>; // expected-note {{constraints not satisfied for class template 'Foo'}}\n+ // expected-note@-1 {{candidate template ignored: could not match}} expected-note@-1 {{candidate template ignored: constraints not satisfied}}\n+-// expected-note@-2 {{implicit deduction guide declared as 'template <int K> requires __is_deducible(test14::Bar, Foo<double, K>) Bar(Foo<double, K>) -> Foo<double, K>'}}\n+-// expected-note@-3 {{implicit deduction guide declared as 'template <int K> requires __is_deducible(test14::Bar, Foo<double, K>) Bar(const double (&)[K]) -> Foo<double, K>'}}\n++// expected-note@-2 {{implicit deduction guide declared as 'template <int K> requires __is_deducible(test14::Bar, test14::Foo<double, K>) Bar(test14::Foo<double, K>) -> test14::Foo<double, K>'}}\n++// expected-note@-3 {{implicit deduction guide declared as 'template <int K> requires __is_deducible(test14::Bar, test14::Foo<double, K>) Bar(const double (&)[K]) -> test14::Foo<double, K>'}}\n+ double abc[3];\n+ Bar s2 = {abc}; // expected-error {{no viable constructor or deduction guide for deduction }}\n+ } // namespace test14\n+@@ -212,9 +212,9 @@\n+ using BFoo = AFoo<W>; // expected-note {{candidate template ignored: constraints not satisfied [with W = int]}} \\\n+                       // expected-note@-1 {{because 'int' does not satisfy 'False'}} \\\n+                       // expected-note@#test15_False {{because 'false' evaluated to false}} \\\n+-                      // expected-note {{implicit deduction guide declared as 'template <False<> W> requires __is_deducible(AFoo, Foo<W *>) && __is_deducible(test15::BFoo, Foo<W *>) BFoo(W *) -> Foo<W *>}} \\\n+-                      // expected-note {{candidate template ignored: could not match 'Foo<W *>' against 'int *'}} \\\n+-                      // expected-note {{template <False<> W> requires __is_deducible(AFoo, Foo<W *>) && __is_deducible(test15::BFoo, Foo<W *>) BFoo(Foo<W *>) -> Foo<W *>}}\n++                      // expected-note {{implicit deduction guide declared as 'template <False<> W> requires __is_deducible(test15::AFoo, test15::Foo<W *>) && __is_deducible(test15::BFoo, test15::Foo<W *>) BFoo(W *) -> test15::Foo<W *>}} \\\n++                      // expected-note {{candidate template ignored: could not match 'test15::Foo<W *>' against 'int *'}} \\\n++                      // expected-note {{template <False<> W> requires __is_deducible(test15::AFoo, test15::Foo<W *>) && __is_deducible(test15::BFoo, test15::Foo<W *>) BFoo(test15::Foo<W *>) -> test15::Foo<W *>}}\n+ int i = 0;\n+ AFoo a1(&i); // OK, deduce Foo<int *>\n+ \n+@@ -276,12 +276,12 @@\n+ Foo(T) -> Foo<int>;\n+ \n+ template <typename U>\n+-using Bar = Foo<U>; // expected-note {{could not match 'Foo<U>' against 'int'}} \\\n+-                    // expected-note {{implicit deduction guide declared as 'template <typename U> requires __is_deducible(test18::Bar, Foo<U>) Bar(Foo<U>) -> Foo<U>'}} \\\n++using Bar = Foo<U>; // expected-note {{could not match 'test18::Foo<U>' against 'int'}} \\\n++                    // expected-note {{implicit deduction guide declared as 'template <typename U> requires __is_deducible(test18::Bar, test18::Foo<U>) Bar(test18::Foo<U>) -> test18::Foo<U>'}} \\\n+                     // expected-note {{candidate template ignored: constraints not satisfied}} \\\n+                     // expected-note {{implicit deduction guide declared as 'template <typename T> requires False<T> && __is_deducible(test18::Bar, Foo<int>) Bar(T) -> Foo<int>'}} \\\n+                     // expected-note {{candidate function template not viable}} \\\n+-                    // expected-note {{implicit deduction guide declared as 'template <typename U> requires __is_deducible(test18::Bar, Foo<U>) Bar() -> Foo<U>'}}\n++                    // expected-note {{implicit deduction guide declared as 'template <typename U> requires __is_deducible(test18::Bar, test18::Foo<U>) Bar() -> test18::Foo<U>'}}\n+ \n+ Bar s = {1}; // expected-error {{no viable constructor or deduction guide for deduction of template arguments}}\n+ } // namespace test18\n+@@ -309,8 +309,8 @@\n+ // Verify that template template type parameter TTP is referenced/used in the\n+ // template arguments of the RHS.\n+ template <template<typename> typename TTP>\n+-using Bar = Foo<K<TTP>>; // expected-note {{candidate template ignored: could not match 'Foo<K<TTP>>' against 'int'}} \\\n+-                        // expected-note {{implicit deduction guide declared as 'template <template <typename> typename TTP> requires __is_deducible(test20::Bar, Foo<K<TTP>>) Bar(Foo<K<TTP>>) -> Foo<K<TTP>>'}}\n++using Bar = Foo<K<TTP>>; // expected-note {{candidate template ignored: could not match 'test20::Foo<K<TTP>>' against 'int'}} \\\n++                        // expected-note {{implicit deduction guide declared as 'template <template <typename> typename TTP> requires __is_deducible(test20::Bar, test20::Foo<K<TTP>>) Bar(test20::Foo<K<TTP>>) -> test20::Foo<K<TTP>>'}}\n+ \n+ template <class T>\n+ class Container {};\n+@@ -463,7 +463,7 @@\n+ BB b{0, 1};\n+ // expected-error@-1 {{no viable}}\n+ // expected-note@#test25_BB 2{{not viable}}\n+-// expected-note@#test25_BB {{template <typename ...US, typename V> requires __is_same(V, int) && __is_deducible(AA, A<int, US...>) && __is_deducible(test25::BB, A<int, US...>) BB(V) -> A<int, US...>}}\n++// expected-note@#test25_BB {{template <typename ...US, typename V> requires __is_same(V, int) && __is_deducible(test25::AA, test25::A<int, US...>) && __is_deducible(test25::BB, test25::A<int, US...>) BB(V) -> test25::A<int, US...>}}\n+ // expected-note@#test25_BB {{implicit deduction guide}}\n+ \n+ }\n+diff -ruN --strip-trailing-cr a/clang/test/SemaCXX/return.cpp b/clang/test/SemaCXX/return.cpp\n+--- a/clang/test/SemaCXX/return.cpp\n++++ b/clang/test/SemaCXX/return.cpp\n+@@ -115,9 +115,9 @@\n+   };\n+ \n+   template <typename T> struct ST {\n+-    ST() { return f(); } // expected-error {{constructor 'ctor_returns_void::ST<T>' must not return void expression}}\n++    ST() { return f(); } // expected-error {{constructor 'ST<T>' must not return void expression}}\n+                          // expected-error@-1 {{constructor 'ST' must not return void expression}}\n+-    ~ST() { return f(); } // expected-error {{destructor '~ctor_returns_void::ST<T>' must not return void expression}}\n++    ~ST() { return f(); } // expected-error {{destructor '~ST<T>' must not return void expression}}\n+                           // expected-error@-1 {{destructor '~ST' must not return void expression}}\n+   };\n+ \n+diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/class-template-ctor-initializer.cpp b/clang/test/SemaTemplate/class-template-ctor-initializer.cpp\n+--- a/clang/test/SemaTemplate/class-template-ctor-initializer.cpp\n++++ b/clang/test/SemaTemplate/class-template-ctor-initializer.cpp\n+@@ -4,8 +4,8 @@\n+ \n+ template<class X> struct A {};\n+ \n+-template<class X> struct B : A<X> { \n+-  B() : A<X>() {} \n++template<class X> struct B : A<X> {\n++  B() : A<X>() {}\n+ };\n+ B<int> x;\n+ \n+@@ -76,3 +76,12 @@\n+   Derived1<void> d1;\n+   Derived2<void> d2;\n+ }\n++\n++namespace UnresolvedUsing {\n++  template <class T> class A {\n++    using typename T::B;\n++    struct C : B {\n++      C() : B() {}\n++    };\n++  };\n++} // namespace UnresolvedUsing\n+diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/deduction-guide.cpp b/clang/test/SemaTemplate/deduction-guide.cpp\n+--- a/clang/test/SemaTemplate/deduction-guide.cpp\n++++ b/clang/test/SemaTemplate/deduction-guide.cpp\n+@@ -331,7 +331,7 @@\n+ // CHECK-NEXT:  |-InjectedClassNameType {{.+}} 'TTP::B<T>' dependent{{$}}\n+ // CHECK-NEXT:  | `-CXXRecord {{.+}} 'B'{{$}}\n+ // CHECK-NEXT:  `-TemplateSpecializationType {{.+}} 'TT<T>' dependent{{$}}\n+-// CHECK-NEXT:    |-name: 'TT':'template-parameter-0-1' qualified\n++// CHECK-NEXT:    |-name: 'TT':'template-parameter-0-1'\n+ // CHECK-NEXT:    | `-TemplateTemplateParmDecl {{.+}} depth 0 index 1\n+ // CHECK-NEXT:    `-TemplateArgument type 'T':'type-parameter-0-0'{{$}}\n+ // CHECK-NEXT:      `-TemplateTypeParmType {{.+}} 'T' dependent depth 0 index 0{{$}}\n+@@ -673,8 +673,8 @@\n+ // CHECK-NEXT: | |-DeducedTemplateSpecializationType {{.*}} 'GH122134::Test' dependent\n+ // CHECK-NEXT: | | `-name: 'GH122134::Test'\n+ // CHECK-NEXT: | |   `-TypeAliasTemplateDecl {{.*}} Test\n+-// CHECK-NEXT: | `-TemplateSpecializationType {{.*}} 'Struct<int, N>' dependent\n+-// CHECK-NEXT: |   |-name: 'Struct':'GH122134::Struct' qualified\n++// CHECK-NEXT: | `-TemplateSpecializationType {{.*}} 'GH122134::Struct<int, N>' dependent\n++// CHECK-NEXT: |   |-name: 'GH122134::Struct'\n+ // CHECK-NEXT: |   | `-ClassTemplateDecl {{.*}} Struct\n+ // CHECK-NEXT: |   |-TemplateArgument type 'int'\n+ // CHECK-NEXT: |   | `-SubstTemplateTypeParmType {{.*}} 'int' sugar class depth 0 index 0 T\n+@@ -684,7 +684,7 @@\n+ // CHECK-NEXT: |     `-SubstNonTypeTemplateParmExpr {{.*}} 'int'\n+ // CHECK-NEXT: |       |-NonTypeTemplateParmDecl {{.*}} 'int' depth 0 index 1\n+ // CHECK-NEXT: |       `-DeclRefExpr {{.*}} 'int' NonTypeTemplateParm {{.*}} 'N' 'int'\n+-// CHECK-NEXT: |-CXXDeductionGuideDecl {{.*}} implicit <deduction guide for Test> 'auto (auto:1) -> Struct<int, N>'\n++// CHECK-NEXT: |-CXXDeductionGuideDecl {{.*}} implicit <deduction guide for Test> 'auto (auto:1) -> GH122134::Struct<int, N>'\n+ // CHECK-NEXT: | `-ParmVarDecl {{.*}} 'auto:1'\n+ \n+ } // namespace GH122134\n+@@ -792,16 +792,16 @@\n+ // CHECK-NEXT:  | |-DeducedTemplateSpecializationType {{.+}} 'GH133132::AA' dependent\n+ // CHECK-NEXT:  | | `-name: 'GH133132::AA'\n+ // CHECK-NEXT:  | |   `-TypeAliasTemplateDecl {{.+}} AA\n+-// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'A<U>' dependent\n+-// CHECK-NEXT:  |   |-name: 'A':'GH133132::A' qualified\n++// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'GH133132::A<U>' dependent\n++// CHECK-NEXT:  |   |-name: 'GH133132::A'\n+ // CHECK-NEXT:  |   | `-ClassTemplateDecl {{.+}} A\n+ // CHECK-NEXT:  |   `-TemplateArgument type 'U':'type-parameter-0-1'\n+ // CHECK-NEXT:  |     `-SubstTemplateTypeParmType {{.+}} 'U' sugar dependent class depth 0 index 0 _Ty\n+ // CHECK-NEXT:  |       |-FunctionTemplate {{.+}} '<deduction guide for A>'\n+ // CHECK-NEXT:  |       `-TemplateTypeParmType {{.+}} 'U' dependent depth 0 index 1\n+ // CHECK-NEXT:  |         `-TemplateTypeParm {{.+}} 'U'\n+-// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for AA> 'auto () -> A<U>'\n+-// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for AA> 'auto () -> A<int>' implicit_instantiation\n++// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for AA> 'auto () -> GH133132::A<U>'\n++// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for AA> 'auto () -> GH133132::A<int>' implicit_instantiation\n+ // CHECK-NEXT:    |-TemplateArgument type 'int'\n+ // CHECK-NEXT:    | `-BuiltinType {{.+}} 'int'\n+ // CHECK-NEXT:    `-TemplateArgument type 'int'\n+@@ -823,22 +823,22 @@\n+ // CHECK-NEXT:  |   `-ClassTemplateDecl {{.+}} A\n+ // CHECK-NEXT:  |-TemplateTemplateParmDecl {{.+}} depth 0 index 1 _Y\n+ // CHECK-NEXT:  | |-TemplateTypeParmDecl {{.+}} class depth 0 index 0\n+-// CHECK-NEXT:  | `-TemplateArgument {{.+}} template '_X':'template-parameter-0-0' qualified\n++// CHECK-NEXT:  | `-TemplateArgument {{.+}} template '_X':'template-parameter-0-0'\n+ // CHECK-NEXT:  |   `-TemplateTemplateParmDecl {{.+}} depth 0 index 0 _X\n+ // CHECK-NEXT:  |-TypeTraitExpr {{.+}} 'bool' __is_deducible\n+ // CHECK-NEXT:  | |-DeducedTemplateSpecializationType {{.+}} 'GH133132::BB' dependent\n+ // CHECK-NEXT:  | | `-name: 'GH133132::BB'\n+ // CHECK-NEXT:  | |   `-TypeAliasTemplateDecl {{.+}} BB\n+-// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'B<_Y>' dependent\n+-// CHECK-NEXT:  |   |-name: 'B':'GH133132::B' qualified\n++// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'GH133132::B<_Y>' dependent\n++// CHECK-NEXT:  |   |-name: 'GH133132::B'\n+ // CHECK-NEXT:  |   | `-ClassTemplateDecl {{.+}} B\n+ // CHECK-NEXT:  |   `-TemplateArgument template '_Y':'template-parameter-0-1' subst index 0\n+ // CHECK-NEXT:  |     |-parameter: TemplateTemplateParmDecl {{.+}} depth 0 index 0 _X\n+ // CHECK-NEXT:  |     |-associated FunctionTemplate {{.+}} '<deduction guide for B>'\n+-// CHECK-NEXT:  |     `-replacement: '_Y':'template-parameter-0-1' qualified\n++// CHECK-NEXT:  |     `-replacement: '_Y':'template-parameter-0-1'\n+ // CHECK-NEXT:  |       `-TemplateTemplateParmDecl {{.+}} depth 0 index 1 _Y\n+-// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for BB> 'auto () -> B<_Y>'\n+-// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for BB> 'auto () -> B<GH133132::A>' implicit_instantiation\n++// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for BB> 'auto () -> GH133132::B<_Y>'\n++// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for BB> 'auto () -> GH133132::B<GH133132::A>' implicit_instantiation\n+ // CHECK-NEXT:    |-TemplateArgument template 'GH133132::A'\n+ // CHECK-NEXT:    | `-ClassTemplateDecl {{.+}} A\n+ // CHECK-NEXT:    `-TemplateArgument template 'GH133132::A'\n+@@ -866,16 +866,16 @@\n+ // CHECK-NEXT:  | |-DeducedTemplateSpecializationType {{.+}} 'GH133132::CC' dependent\n+ // CHECK-NEXT:  | | `-name: 'GH133132::CC'\n+ // CHECK-NEXT:  | |   `-TypeAliasTemplateDecl {{.+}} CC\n+-// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'A<U>' dependent\n+-// CHECK-NEXT:  |   |-name: 'A':'GH133132::A' qualified\n++// CHECK-NEXT:  | `-TemplateSpecializationType {{.+}} 'GH133132::A<U>' dependent\n++// CHECK-NEXT:  |   |-name: 'GH133132::A'\n+ // CHECK-NEXT:  |   | `-ClassTemplateDecl {{.+}} A\n+ // CHECK-NEXT:  |   `-TemplateArgument type 'U':'type-parameter-0-1'\n+ // CHECK-NEXT:  |     `-SubstTemplateTypeParmType {{.+}} 'U' sugar dependent class depth 0 index 0 _Ty\n+ // CHECK-NEXT:  |       |-FunctionTemplate {{.+}} '<deduction guide for A>'\n+ // CHECK-NEXT:  |       `-TemplateTypeParmType {{.+}} 'U' dependent depth 0 index 1\n+ // CHECK-NEXT:  |         `-TemplateTypeParm {{.+}} 'U'\n+-// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for CC> 'auto () -> A<U>'\n+-// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for CC> 'auto () -> A<GH133132::A<int>>' implicit_instantiation\n++// CHECK-NEXT:  |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for CC> 'auto () -> GH133132::A<U>'\n++// CHECK-NEXT:  `-CXXDeductionGuideDecl {{.+}} implicit used <deduction guide for CC> 'auto () -> GH133132::A<GH133132::A<int>>' implicit_instantiation\n+ // CHECK-NEXT:    |-TemplateArgument integral '42'\n+ // CHECK-NEXT:    `-TemplateArgument type 'GH133132::A<int>'\n+ // CHECK-NEXT:      `-RecordType {{.+}} 'GH133132::A<int>'\n+@@ -949,8 +949,8 @@\n+ // CHECK-NEXT:   | |-DeducedTemplateSpecializationType {{.+}} 'GH141425::Alias' dependent\n+ // CHECK-NEXT:   | | `-name: 'GH141425::Alias'\n+ // CHECK-NEXT:   | |   `-TypeAliasTemplateDecl {{.+}} Alias\n+-// CHECK-NEXT:   | `-TemplateSpecializationType {{.+}} 'Container<T...>' dependent\n+-// CHECK-NEXT:   |   |-name: 'Container':'GH141425::Container' qualified\n++// CHECK-NEXT:   | `-TemplateSpecializationType {{.+}} 'GH141425::Container<T...>' dependent\n++// CHECK-NEXT:   |   |-name: 'GH141425::Container'\n+ // CHECK-NEXT:   |   | `-ClassTemplateDecl {{.+}} Container\n+ // CHECK-NEXT:   |   `-TemplateArgument type 'T...':'type-parameter-0-0...'\n+ // CHECK-NEXT:   |     `-PackExpansionType {{.+}} 'T...' dependent\n+@@ -958,7 +958,7 @@\n+ // CHECK-NEXT:   |         |-FunctionTemplate {{.+}} '<deduction guide for Container>'\n+ // CHECK-NEXT:   |         `-TemplateTypeParmType {{.+}} 'T' dependent contains_unexpanded_pack depth 0 index 0 pack\n+ // CHECK-NEXT:   |           `-TemplateTypeParm {{.+}} 'T'\n+-// CHECK-NEXT:   |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for Alias> 'auto (T...) -> Container<T...>'\n++// CHECK-NEXT:   |-CXXDeductionGuideDecl {{.+}} implicit <deduction guide for Alias> 'auto (T...) -> GH141425::Container<T...>'\n+ // CHECK-NEXT:   | `-ParmVarDecl {{.+}} 'T...' pack\n+ \n+ }\n+diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/nested-name-spec-template.cpp b/clang/test/SemaTemplate/nested-name-spec-template.cpp\n+--- a/clang/test/SemaTemplate/nested-name-spec-template.cpp\n++++ b/clang/test/SemaTemplate/nested-name-spec-template.cpp\n+@@ -1,5 +1,5 @@\n+ // RUN: %clang_cc1 -fsyntax-only -verify %s -Wno-c++20-extensions\n+-// RUN: %clang_cc1 -fsyntax-only -verify -std=c++98 %s\n++// RUN: %clang_cc1 -fsyntax-only -verify -Wno-c++11-extensions -std=c++98 %s\n+ // RUN: %clang_cc1 -fsyntax-only -verify -std=c++11 %s\n+ \n+ namespace N {\n+@@ -24,14 +24,7 @@\n+ \n+   M::Promote<int>::type *ret_intptr3(int* ip) { return ip; }\n+   M::template Promote<int>::type *ret_intptr4(int* ip) { return ip; }\n+-#if __cplusplus <= 199711L\n+-  // expected-warning@-2 {{'template' keyword outside of a template}}\n+-#endif\n+-\n+   M::template Promote<int> pi;\n+-#if __cplusplus <= 199711L\n+-  // expected-warning@-2 {{'template' keyword outside of a template}}\n+-#endif\n+ }\n+ \n+ N::M::Promote<int>::type *ret_intptr5(int* ip) { return ip; }\n+@@ -181,3 +174,39 @@\n+   template void f<B>();\n+ } // namespace SubstTemplateTypeParmPackType\n+ #endif\n++\n++namespace DependentUnaryTransform {\n++  template <class T> using decay_t = __decay(T);\n++  template <class, class> struct A;\n++  template <class T> struct A<T, typename decay_t<T>::X>;\n++} // namespace DependentUnaryTransform\n++\n++namespace DependentSizedArray {\n++  template <int V> using Z = int[V];\n++  template <class, class> struct A;\n++  template <class T> struct A<T, typename Z<T(0)>::X>;\n++} // namespace DependentUnaryTransform\n++\n++namespace GH155281 {\n++  template <bool> struct enable_if;\n++  template <class _Tp, _Tp> struct integral_constant;\n++  template <typename> struct conjunction;\n++  template <typename T> using value_type_t = T;\n++  template <class Check> using require_t = typename enable_if<Check::value>::type;\n++  template <template <class> class, template <class> class,\n++            template <class> class, class... Check>\n++  using container_type_check_base =\n++      integral_constant<bool, conjunction<Check...>::value>;\n++  template <typename> struct is_std_vector;\n++  template <template <class> class TypeCheck, class... Check>\n++  using require_std_vector_vt =\n++      require_t<container_type_check_base<is_std_vector, value_type_t, TypeCheck,\n++                                          Check...> >;\n++  template <typename, typename> class vector_seq_view;\n++  namespace internal {\n++  template <typename> using is_matrix_or_std_vector = int;\n++  }\n++  template <typename T>\n++  class vector_seq_view<\n++      T, require_std_vector_vt<internal::is_matrix_or_std_vector, T> >;\n++} // namespace GH155281\n+diff -ruN --strip-trailing-cr a/clang/unittests/AST/DeclTest.cpp b/clang/unittests/AST/DeclTest.cpp\n+--- a/clang/unittests/AST/DeclTest.cpp\n++++ b/clang/unittests/AST/DeclTest.cpp\n+@@ -570,3 +570,19 @@\n+   EXPECT_EQ(GetNameInfoRange(Matches[1]), \"<input.cc:6:14, col:15>\");\n+   EXPECT_EQ(GetNameInfoRange(Matches[2]), \"<input.cc:6:14, col:15>\");\n+ }\n++\n++TEST(Decl, getQualifiedNameAsString) {\n++  llvm::Annotations Code(R\"cpp(\n++namespace x::y {\n++  template <class T> class Foo { Foo() {} };\n +}\n++)cpp\");\n++\n++  auto AST = tooling::buildASTFromCode(Code.code());\n++  ASTContext &Ctx = AST->getASTContext();\n +\n-+declare void @free(ptr)\n-+declare ptr @malloc(i32)\n-+declare void @print(i32)\n-+declare void @foo([2 x ptr])\n-diff -ruN --strip-trailing-cr a/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir b/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir\n---- a/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir\n-+++ b/mlir/test/Dialect/Linalg/linalg-morph-category-ops.mlir\n-@@ -2,7 +2,7 @@\n- // RUN: mlir-opt %s -linalg-morph-ops=named-to-category | FileCheck %s  --check-prefix=NAMED_TO_CATEGORY\n- \n- // RUN: mlir-opt %s -linalg-morph-ops=named-to-category |  \\\n--// RUN:   mlir-opt %s -linalg-morph-ops=category-to-generic | FileCheck %s  --check-prefix=CATEGORY_TO_GENERIC\n-+// RUN:   mlir-opt -linalg-morph-ops=category-to-generic | FileCheck %s  --check-prefix=CATEGORY_TO_GENERIC\n- \n- func.func @exp(%A : tensor<16x8xf32>, %B : tensor<16x8xf32>) ->  tensor<16x8xf32> {\n-   %exp = linalg.exp ins(%A : tensor<16x8xf32>) outs(%B :  tensor<16x8xf32>) -> tensor<16x8xf32>\n++  auto const *FD = selectFirst<CXXConstructorDecl>(\n++      \"ctor\", match(cxxConstructorDecl().bind(\"ctor\"), Ctx));\n++  ASSERT_NE(FD, nullptr);\n++  ASSERT_EQ(FD->getQualifiedNameAsString(), \"x::y::Foo::Foo<T>\");\n++}\n+diff -ruN --strip-trailing-cr a/libcxx/include/tuple b/libcxx/include/tuple\n+--- a/libcxx/include/tuple\n++++ b/libcxx/include/tuple\n+@@ -516,6 +516,7 @@\n+ \n+ struct __forward_args {};\n+ struct __value_init {};\n++struct __from_tuple {};\n+ \n+ template <size_t... _Indx, class... _Tp>\n+ struct _LIBCPP_DECLSPEC_EMPTY_BASES\n+@@ -538,7 +539,7 @@\n+       : __tuple_leaf<_Indx, _Tp>(__uses_alloc_ctor<_Tp, _Alloc, _Args>(), __alloc, std::forward<_Args>(__args))... {}\n+ \n+   template <class _Tuple>\n+-  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX14 __tuple_impl(_Tuple&& __t) noexcept(\n++  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX14 __tuple_impl(__from_tuple, _Tuple&& __t) noexcept(\n+       (__all<is_nothrow_constructible<\n+            _Tp,\n+            typename tuple_element<_Indx, typename __make_tuple_types<_Tuple>::type>::type>::value...>::value))\n+@@ -547,7 +548,8 @@\n+                 std::get<_Indx>(__t)))... {}\n+ \n+   template <class _Alloc, class _Tuple>\n+-  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX14 __tuple_impl(allocator_arg_t, const _Alloc& __a, _Tuple&& __t)\n++  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX14\n++  __tuple_impl(allocator_arg_t, const _Alloc& __a, __from_tuple, _Tuple&& __t)\n+       : __tuple_leaf<_Indx, _Tp>(\n+             __uses_alloc_ctor<_Tp,\n+                               _Alloc,\n+@@ -673,13 +675,13 @@\n+             template <class...> class _And                                  = _And,\n+             __enable_if_t< _And<is_copy_constructible<_Tp>...>::value, int> = 0>\n+   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX20 tuple(allocator_arg_t, const _Alloc& __alloc, const tuple& __t)\n+-      : __base_(allocator_arg_t(), __alloc, __t) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), __t) {}\n+ \n+   template <class _Alloc,\n+             template <class...> class _And                                  = _And,\n+             __enable_if_t< _And<is_move_constructible<_Tp>...>::value, int> = 0>\n+   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX20 tuple(allocator_arg_t, const _Alloc& __alloc, tuple&& __t)\n+-      : __base_(allocator_arg_t(), __alloc, std::move(__t)) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), std::move(__t)) {}\n+ \n+   // tuple(const tuple<U...>&) constructors (including allocator_arg_t variants)\n+ \n+@@ -712,7 +714,7 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX14 explicit(_Not<_Lazy<_And, is_convertible<const _Up&, _Tp>...> >::value)\n+       tuple(const tuple<_Up...>& __t) noexcept(_And<is_nothrow_constructible<_Tp, const _Up&>...>::value)\n+-      : __base_(__t) {}\n++      : __base_(__from_tuple(), __t) {}\n+ \n+   template <class... _Up,\n+             class _Alloc,\n+@@ -720,33 +722,33 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX20 explicit(_Not<_Lazy<_And, is_convertible<const _Up&, _Tp>...> >::value)\n+       tuple(allocator_arg_t, const _Alloc& __a, const tuple<_Up...>& __t)\n+-      : __base_(allocator_arg_t(), __a, __t) {}\n++      : __base_(allocator_arg_t(), __a, __from_tuple(), __t) {}\n+ \n+ #    if _LIBCPP_STD_VER >= 23\n+   // tuple(tuple<U...>&) constructors (including allocator_arg_t variants)\n+ \n+   template <class... _Up, enable_if_t< _EnableCtorFromUTypesTuple<tuple<_Up...>&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_Lazy<_And, is_convertible<_Up&, _Tp>...>::value) tuple(tuple<_Up...>& __t)\n+-      : __base_(__t) {}\n++      : __base_(__from_tuple(), __t) {}\n+ \n+   template <class _Alloc, class... _Up, enable_if_t< _EnableCtorFromUTypesTuple<tuple<_Up...>&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_Lazy<_And, is_convertible<_Up&, _Tp>...>::value)\n+       tuple(allocator_arg_t, const _Alloc& __alloc, tuple<_Up...>& __t)\n+-      : __base_(allocator_arg_t(), __alloc, __t) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), __t) {}\n+ #    endif // _LIBCPP_STD_VER >= 23\n+ \n+   // tuple(tuple<U...>&&) constructors (including allocator_arg_t variants)\n+   template <class... _Up, __enable_if_t< _And< _EnableCtorFromUTypesTuple<tuple<_Up...>&&> >::value, int> = 0>\n+   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX14 explicit(_Not<_Lazy<_And, is_convertible<_Up, _Tp>...> >::value)\n+       tuple(tuple<_Up...>&& __t) noexcept(_And<is_nothrow_constructible<_Tp, _Up>...>::value)\n+-      : __base_(std::move(__t)) {}\n++      : __base_(__from_tuple(), std::move(__t)) {}\n+ \n+   template <class _Alloc,\n+             class... _Up,\n+             __enable_if_t< _And< _EnableCtorFromUTypesTuple<tuple<_Up...>&&> >::value, int> = 0>\n+   _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_SINCE_CXX20 explicit(_Not<_Lazy<_And, is_convertible<_Up, _Tp>...> >::value)\n+       tuple(allocator_arg_t, const _Alloc& __a, tuple<_Up...>&& __t)\n+-      : __base_(allocator_arg_t(), __a, std::move(__t)) {}\n++      : __base_(allocator_arg_t(), __a, __from_tuple(), std::move(__t)) {}\n+ \n+ #    if _LIBCPP_STD_VER >= 23\n+   // tuple(const tuple<U...>&&) constructors (including allocator_arg_t variants)\n+@@ -754,14 +756,14 @@\n+   template <class... _Up, enable_if_t< _EnableCtorFromUTypesTuple<const tuple<_Up...>&&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_Lazy<_And, is_convertible<const _Up&&, _Tp>...>::value)\n+       tuple(const tuple<_Up...>&& __t)\n+-      : __base_(std::move(__t)) {}\n++      : __base_(__from_tuple(), std::move(__t)) {}\n+ \n+   template <class _Alloc,\n+             class... _Up,\n+             enable_if_t< _EnableCtorFromUTypesTuple<const tuple<_Up...>&&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_Lazy<_And, is_convertible<const _Up&&, _Tp>...>::value)\n+       tuple(allocator_arg_t, const _Alloc& __alloc, const tuple<_Up...>&& __t)\n+-      : __base_(allocator_arg_t(), __alloc, std::move(__t)) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), std::move(__t)) {}\n+ #    endif // _LIBCPP_STD_VER >= 23\n+ \n+   // tuple(const pair<U1, U2>&) constructors (including allocator_arg_t variants)\n+@@ -796,7 +798,7 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX14 explicit(_Not<_BothImplicitlyConvertible<const pair<_Up1, _Up2>&> >::value)\n+       tuple(const pair<_Up1, _Up2>& __p) noexcept(_NothrowConstructibleFromPair<const pair<_Up1, _Up2>&>::value)\n+-      : __base_(__p) {}\n++      : __base_(__from_tuple(), __p) {}\n+ \n+   template <class _Alloc,\n+             class _Up1,\n+@@ -806,7 +808,7 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX20 explicit(_Not<_BothImplicitlyConvertible<const pair<_Up1, _Up2>&> >::value)\n+       tuple(allocator_arg_t, const _Alloc& __a, const pair<_Up1, _Up2>& __p)\n+-      : __base_(allocator_arg_t(), __a, __p) {}\n++      : __base_(allocator_arg_t(), __a, __from_tuple(), __p) {}\n+ \n+ #    if _LIBCPP_STD_VER >= 23\n+   // tuple(pair<U1, U2>&) constructors (including allocator_arg_t variants)\n+@@ -814,7 +816,7 @@\n+   template <class _U1, class _U2, enable_if_t< _EnableCtorFromPair<pair<_U1, _U2>&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_BothImplicitlyConvertible<pair<_U1, _U2>&>::value)\n+       tuple(pair<_U1, _U2>& __p)\n+-      : __base_(__p) {}\n++      : __base_(__from_tuple(), __p) {}\n+ \n+   template <class _Alloc,\n+             class _U1,\n+@@ -822,7 +824,7 @@\n+             enable_if_t< _EnableCtorFromPair<std::pair<_U1, _U2>&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_BothImplicitlyConvertible<pair<_U1, _U2>&>::value)\n+       tuple(allocator_arg_t, const _Alloc& __alloc, pair<_U1, _U2>& __p)\n+-      : __base_(allocator_arg_t(), __alloc, __p) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), __p) {}\n+ #    endif\n+ \n+   // tuple(pair<U1, U2>&&) constructors (including allocator_arg_t variants)\n+@@ -834,7 +836,7 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX14 explicit(_Not<_BothImplicitlyConvertible<pair<_Up1, _Up2>&&> >::value)\n+       tuple(pair<_Up1, _Up2>&& __p) noexcept(_NothrowConstructibleFromPair<pair<_Up1, _Up2>&&>::value)\n+-      : __base_(std::move(__p)) {}\n++      : __base_(__from_tuple(), std::move(__p)) {}\n+ \n+   template <class _Alloc,\n+             class _Up1,\n+@@ -844,7 +846,7 @@\n+   _LIBCPP_HIDE_FROM_ABI\n+   _LIBCPP_CONSTEXPR_SINCE_CXX20 explicit(_Not<_BothImplicitlyConvertible<pair<_Up1, _Up2>&&> >::value)\n+       tuple(allocator_arg_t, const _Alloc& __a, pair<_Up1, _Up2>&& __p)\n+-      : __base_(allocator_arg_t(), __a, std::move(__p)) {}\n++      : __base_(allocator_arg_t(), __a, __from_tuple(), std::move(__p)) {}\n+ \n+ #    if _LIBCPP_STD_VER >= 23\n+   // tuple(const pair<U1, U2>&&) constructors (including allocator_arg_t variants)\n+@@ -852,7 +854,7 @@\n+   template <class _U1, class _U2, enable_if_t< _EnableCtorFromPair<const pair<_U1, _U2>&&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_BothImplicitlyConvertible<const pair<_U1, _U2>&&>::value)\n+       tuple(const pair<_U1, _U2>&& __p)\n+-      : __base_(std::move(__p)) {}\n++      : __base_(__from_tuple(), std::move(__p)) {}\n+ \n+   template <class _Alloc,\n+             class _U1,\n+@@ -860,7 +862,7 @@\n+             enable_if_t< _EnableCtorFromPair<const pair<_U1, _U2>&&>::value>* = nullptr>\n+   _LIBCPP_HIDE_FROM_ABI constexpr explicit(!_BothImplicitlyConvertible<const pair<_U1, _U2>&&>::value)\n+       tuple(allocator_arg_t, const _Alloc& __alloc, const pair<_U1, _U2>&& __p)\n+-      : __base_(allocator_arg_t(), __alloc, std::move(__p)) {}\n++      : __base_(allocator_arg_t(), __alloc, __from_tuple(), std::move(__p)) {}\n+ #    endif // _LIBCPP_STD_VER >= 23\n+ \n+   // [tuple.assign]\n+diff -ruN --strip-trailing-cr a/libcxx/test/std/utilities/tuple/tuple.tuple/move_ctor_sfinae.compile.pass.cpp b/libcxx/test/std/utilities/tuple/tuple.tuple/move_ctor_sfinae.compile.pass.cpp\n+--- a/libcxx/test/std/utilities/tuple/tuple.tuple/move_ctor_sfinae.compile.pass.cpp\n++++ b/libcxx/test/std/utilities/tuple/tuple.tuple/move_ctor_sfinae.compile.pass.cpp\n+@@ -0,0 +1,27 @@\n++//===----------------------------------------------------------------------===//\n++//\n++// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.\n++// See https://llvm.org/LICENSE.txt for license information.\n++// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception\n++//\n++//===----------------------------------------------------------------------===//\n++\n++// Ensure that tuple's move constructor properly SFINAES.\n++// This is a regression test for https://github.com/llvm/llvm-project/pull/151654#issuecomment-3205410955\n++\n++// UNSUPPORTED: c++03, c++11, c++14\n++\n++#include <tuple>\n++#include <variant>\n++#include <type_traits>\n++\n++struct S {\n++  S(const S&)            = delete;\n++  S& operator=(const S&) = delete;\n++  S(S&&)                 = default;\n++  S& operator=(S&&)      = default;\n++};\n++\n++using T = std::tuple<const std::variant<S>>;\n++\n++void func() { (void)std::is_trivially_move_constructible<T>::value; }\n+diff -ruN --strip-trailing-cr a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n+--- a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n++++ b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n+@@ -1735,11 +1735,11 @@\n+   }\n+ \n+   // Sort them before value searching is working properly.\n+-  m_func_full_names.Sort();\n++  m_func_full_names.Sort(std::less<uint32_t>());\n+   m_func_full_names.SizeToFit();\n+-  m_func_method_names.Sort();\n++  m_func_method_names.Sort(std::less<uint32_t>());\n+   m_func_method_names.SizeToFit();\n+-  m_func_base_names.Sort();\n++  m_func_base_names.Sort(std::less<uint32_t>());\n+   m_func_base_names.SizeToFit();\n+ }\n+ \n+@@ -2426,7 +2426,7 @@\n+ \n+   // After calling Append(), the type-name map needs to be sorted again to be\n+   // able to look up a type by its name.\n+-  m_type_base_names.Sort();\n++  m_type_base_names.Sort(std::less<uint32_t>());\n+ \n+   // Now that we know the forward -> full mapping of all type indices, we can\n+   // re-write all the indices.  At the end of this process, we want a mapping\n+diff -ruN --strip-trailing-cr a/mlir/include/mlir/AsmParser/AsmParser.h b/mlir/include/mlir/AsmParser/AsmParser.h\n+--- a/mlir/include/mlir/AsmParser/AsmParser.h\n++++ b/mlir/include/mlir/AsmParser/AsmParser.h\n+@@ -53,8 +53,7 @@\n+ /// null terminated.\n+ Attribute parseAttribute(llvm::StringRef attrStr, MLIRContext *context,\n+                          Type type = {}, size_t *numRead = nullptr,\n+-                         bool isKnownNullTerminated = false,\n+-                         llvm::StringMap<Attribute> *attributesCache = nullptr);\n++                         bool isKnownNullTerminated = false);\n+ \n+ /// This parses a single MLIR type to an MLIR context if it was valid. If not,\n+ /// an error diagnostic is emitted to the context.\n+diff -ruN --strip-trailing-cr a/mlir/lib/AsmParser/DialectSymbolParser.cpp b/mlir/lib/AsmParser/DialectSymbolParser.cpp\n+--- a/mlir/lib/AsmParser/DialectSymbolParser.cpp\n++++ b/mlir/lib/AsmParser/DialectSymbolParser.cpp\n+@@ -245,15 +245,6 @@\n+       return nullptr;\n+   }\n+ \n+-  if constexpr (std::is_same_v<Symbol, Attribute>) {\n+-    auto &cache = p.getState().symbols.attributesCache;\n+-    auto cacheIt = cache.find(symbolData);\n+-    // Skip cached attribute if it has type.\n+-    if (cacheIt != cache.end() && !p.getToken().is(Token::colon))\n+-      return cacheIt->second;\n+-\n+-    return cache[symbolData] = createSymbol(dialectName, symbolData, loc);\n+-  }\n+   return createSymbol(dialectName, symbolData, loc);\n+ }\n+ \n+@@ -346,7 +337,6 @@\n+ template <typename T, typename ParserFn>\n+ static T parseSymbol(StringRef inputStr, MLIRContext *context,\n+                      size_t *numReadOut, bool isKnownNullTerminated,\n+-                     llvm::StringMap<Attribute> *attributesCache,\n+                      ParserFn &&parserFn) {\n+   // Set the buffer name to the string being parsed, so that it appears in error\n+   // diagnostics.\n+@@ -358,9 +348,6 @@\n+   SourceMgr sourceMgr;\n+   sourceMgr.AddNewSourceBuffer(std::move(memBuffer), SMLoc());\n+   SymbolState aliasState;\n+-  if (attributesCache)\n+-    aliasState.attributesCache = *attributesCache;\n+-\n+   ParserConfig config(context);\n+   ParserState state(sourceMgr, config, aliasState, /*asmState=*/nullptr,\n+                     /*codeCompleteContext=*/nullptr);\n+@@ -371,11 +358,6 @@\n+   if (!symbol)\n+     return T();\n+ \n+-  if constexpr (std::is_same_v<T, Attribute>) {\n+-    if (attributesCache)\n+-      *attributesCache = state.symbols.attributesCache;\n+-  }\n+-\n+   // Provide the number of bytes that were read.\n+   Token endTok = parser.getToken();\n+   size_t numRead =\n+@@ -392,15 +374,13 @@\n+ \n+ Attribute mlir::parseAttribute(StringRef attrStr, MLIRContext *context,\n+                                Type type, size_t *numRead,\n+-                               bool isKnownNullTerminated,\n+-                               llvm::StringMap<Attribute> *attributesCache) {\n++                               bool isKnownNullTerminated) {\n+   return parseSymbol<Attribute>(\n+-      attrStr, context, numRead, isKnownNullTerminated, attributesCache,\n++      attrStr, context, numRead, isKnownNullTerminated,\n+       [type](Parser &parser) { return parser.parseAttribute(type); });\n+ }\n+ Type mlir::parseType(StringRef typeStr, MLIRContext *context, size_t *numRead,\n+                      bool isKnownNullTerminated) {\n+   return parseSymbol<Type>(typeStr, context, numRead, isKnownNullTerminated,\n+-                           /*attributesCache=*/nullptr,\n+                            [](Parser &parser) { return parser.parseType(); });\n+ }\n+diff -ruN --strip-trailing-cr a/mlir/lib/AsmParser/ParserState.h b/mlir/lib/AsmParser/ParserState.h\n+--- a/mlir/lib/AsmParser/ParserState.h\n++++ b/mlir/lib/AsmParser/ParserState.h\n+@@ -40,9 +40,6 @@\n+ \n+   /// A map from unique integer identifier to DistinctAttr.\n+   DenseMap<uint64_t, DistinctAttr> distinctAttributes;\n+-\n+-  /// A map from unique string identifier to Attribute.\n+-  llvm::StringMap<Attribute> attributesCache;\n+ };\n+ \n+ //===----------------------------------------------------------------------===//\n+diff -ruN --strip-trailing-cr a/mlir/lib/Bytecode/Reader/BytecodeReader.cpp b/mlir/lib/Bytecode/Reader/BytecodeReader.cpp\n+--- a/mlir/lib/Bytecode/Reader/BytecodeReader.cpp\n++++ b/mlir/lib/Bytecode/Reader/BytecodeReader.cpp\n+@@ -895,10 +895,6 @@\n+   SmallVector<AttrEntry> attributes;\n+   SmallVector<TypeEntry> types;\n+ \n+-  /// The map of cached attributes, used to avoid re-parsing the same\n+-  /// attribute multiple times.\n+-  llvm::StringMap<Attribute> attributesCache;\n+-\n+   /// A location used for error emission.\n+   Location fileLoc;\n+ \n+@@ -1239,7 +1235,7 @@\n+         ::parseType(asmStr, context, &numRead, /*isKnownNullTerminated=*/true);\n+   else\n+     result = ::parseAttribute(asmStr, context, Type(), &numRead,\n+-                              /*isKnownNullTerminated=*/true, &attributesCache);\n++                              /*isKnownNullTerminated=*/true);\n+   if (!result)\n+     return failure();\n+ \n+diff -ruN --strip-trailing-cr a/mlir/lib/Conversion/GPUCommon/GPUToLLVMConversion.cpp b/mlir/lib/Conversion/GPUCommon/GPUToLLVMConversion.cpp\n+--- a/mlir/lib/Conversion/GPUCommon/GPUToLLVMConversion.cpp\n++++ b/mlir/lib/Conversion/GPUCommon/GPUToLLVMConversion.cpp\n+@@ -532,6 +532,9 @@\n+     // Vector transfer ops with rank > 1 should be lowered with VectorToSCF.\n+     vector::populateVectorTransferLoweringPatterns(patterns,\n+                                                    /*maxTransferRank=*/1);\n++    // Transform N-D vector.from_elements to 1-D vector.from_elements before\n++    // conversion.\n++    vector::populateVectorFromElementsLoweringPatterns(patterns);\n+     if (failed(applyPatternsGreedily(getOperation(), std::move(patterns))))\n+       return signalPassFailure();\n+   }\n+diff -ruN --strip-trailing-cr a/mlir/lib/Conversion/GPUToNVVM/LowerGpuOpsToNVVMOps.cpp b/mlir/lib/Conversion/GPUToNVVM/LowerGpuOpsToNVVMOps.cpp\n+--- a/mlir/lib/Conversion/GPUToNVVM/LowerGpuOpsToNVVMOps.cpp\n++++ b/mlir/lib/Conversion/GPUToNVVM/LowerGpuOpsToNVVMOps.cpp\n+@@ -27,6 +27,7 @@\n+ #include \"mlir/Dialect/Math/IR/Math.h\"\n+ #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+ #include \"mlir/Dialect/NVGPU/IR/NVGPUDialect.h\"\n++#include \"mlir/Dialect/Vector/Transforms/LoweringPatterns.h\"\n+ #include \"mlir/Transforms/DialectConversion.h\"\n+ #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+ \n+@@ -369,6 +370,9 @@\n+     {\n+       RewritePatternSet patterns(m.getContext());\n+       populateGpuRewritePatterns(patterns);\n++      // Transform N-D vector.from_elements to 1-D vector.from_elements before\n++      // conversion.\n++      vector::populateVectorFromElementsLoweringPatterns(patterns);\n+       if (failed(applyPatternsGreedily(m, std::move(patterns))))\n+         return signalPassFailure();\n+     }\n+diff -ruN --strip-trailing-cr a/mlir/test/IR/recursive-distinct-attr.mlir b/mlir/test/IR/recursive-distinct-attr.mlir\n+--- a/mlir/test/IR/recursive-distinct-attr.mlir\n++++ b/mlir/test/IR/recursive-distinct-attr.mlir\n+@@ -1,13 +0,0 @@\n+-// RUN: mlir-opt -emit-bytecode %s | mlir-opt --mlir-print-debuginfo | FileCheck %s\n+-\n+-// Verify that the distinct attribute which is used transitively\n+-// through two aliases does not end up duplicated when round-tripped\n+-// through bytecode.\n+-\n+-// CHECK: distinct[0]\n+-// CHECK-NOT: distinct[1]\n+-#attr_ugly = #test<attr_ugly begin distinct[0]<> end>\n+-#attr_ugly1 = #test<attr_ugly begin #attr_ugly end>\n+-\n+-module attributes {test.alias = #attr_ugly, test.alias1 = #attr_ugly1} {\n+-}\n+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n+--- a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n++++ b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n+@@ -5718,6 +5718,7 @@\n+         \":NVGPUDialect\",\n+         \":NVVMDialect\",\n+         \":TransformUtils\",\n++        \":VectorTransforms\",\n+     ],\n+ )\n+ "
        },
        {
            "sha": "8bcb8f958a7a2ba6bc07a53baa9adfcb2978a328",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"fc44a4fcd3c54be927c15ddd9211aca1501633e7\"\n-    LLVM_SHA256 = \"d228aebe5583c69c4e48fd7a8e149e3d22ee6dafaeae94009467143d32d9bfc4\"\n+    LLVM_COMMIT = \"a6da68ed36d7ecb9edf00262d2a2c1129689399f\"\n+    LLVM_SHA256 = \"a5ba622b3a1342fdb763dfa29e1cd70838731932a8cc662fcac4910d67048613\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "5afdeffee932391267a2e40bdc4509db5b14179b",
            "filename": "third_party/xla/third_party/py/BUILD.bazel",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2FBUILD.bazel",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2FBUILD.bazel",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fpy%2FBUILD.bazel?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -65,3 +65,9 @@ py_binary(\n     main = \"unpack_wheel_and_unzip_archive_files.py\",\n     visibility = [\"//visibility:public\"],\n )\n+\n+py_library(\n+    name = \"setup_py_nvidia_dependencies_util\",\n+    srcs = [\"setup_py_nvidia_dependencies_util.py\"],\n+    visibility = [\"//visibility:public\"],\n+)"
        },
        {
            "sha": "6b80837d9a7b55e2c8bff383e9949e931b6af97d",
            "filename": "third_party/xla/third_party/py/python_wheel.bzl",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2Fpython_wheel.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2Fpython_wheel.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fpy%2Fpython_wheel.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -257,3 +257,23 @@ It recursively traverses `deps` attribute of the target and collects paths to\n files that are in `data` attribute. Then it filters all files that do not match\n the provided extensions.\n \"\"\"  # buildifier: disable=no-effect\n+\n+def _nvidia_wheel_versions_repository_impl(repository_ctx):\n+    \"\"\"Repository rule for storing NVIDIA wheel versions.\"\"\"\n+    versions_source = repository_ctx.attr.versions_source\n+\n+    versions_file_content = repository_ctx.read(\n+        repository_ctx.path(versions_source),\n+    )\n+    repository_ctx.file(\n+        \"versions.bzl\",\n+        \"NVIDIA_WHEEL_VERSIONS = '''%s'''\" % versions_file_content,\n+    )\n+    repository_ctx.file(\"BUILD\", \"\")\n+\n+nvidia_wheel_versions_repository = repository_rule(\n+    implementation = _nvidia_wheel_versions_repository_impl,\n+    attrs = {\n+        \"versions_source\": attr.label(mandatory = True, allow_single_file = True),\n+    },\n+)"
        },
        {
            "sha": "fd2c585b666f92ad3f52422d024e28bc6f49df66",
            "filename": "third_party/xla/third_party/py/setup_py_nvidia_dependencies_util.py",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2Fsetup_py_nvidia_dependencies_util.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fpy%2Fsetup_py_nvidia_dependencies_util.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fpy%2Fsetup_py_nvidia_dependencies_util.py?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,76 @@\n+# Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+# ==============================================================================\n+\"\"\"Utility function for updating setup.py with NVIDIA wheel versions.\n+\n+The content of the setup.py file is updated with the NVIDIA wheel versions\n+provided in the nvidia_wheel_versions_data string.\n+\n+The setup.py file is expected to have the following lines:\n+\n+```\n+# Mandatory placeholders\n+cuda_version = 0  # placeholder\n+cuda_wheel_suffix = ''  # placeholder\n+\n+# Optional placeholders (add only those that are needed)\n+nvidia_cublas_version = ''  # placeholder\n+\n+EXTRA_PACKAGES = {\n+    'and-cuda': [\n+        f'nvidia-cublas{cuda_wheel_suffix}{nvidia_cublas_version}',\n+        # add more wheels here\n+    ],\n+}\n+```\n+\"\"\"\n+\n+import re\n+\n+# Regex to capture wheel name and its version constraint\n+# Example: \"nvidia-cublas-cu12>=12.1.3.1 ; sys_platform == 'linux'\"\n+NVIDIA_WHEEL_VERSIONS_PATTERN = re.compile(r\"^([a-z0-9_-]+)(\\W*[0-9\\.]*.*)$\")\n+\n+\n+def get_setup_py_content_with_nvidia_wheel_versions(\n+    setup_py_content: str, cuda_version: str, nvidia_wheel_versions_data: str\n+) -> str:\n+  nvidia_wheel_versions = {\"12\": {}, \"13\": {}}\n+  for line in nvidia_wheel_versions_data.splitlines():\n+    match = NVIDIA_WHEEL_VERSIONS_PATTERN.match(line)\n+    if match:\n+      wheel_name = match.group(1).replace(\"-\", \"_\")\n+      for suffix, version in {\"_cu12\": \"12\", \"_cu13\": \"13\", \"\": \"13\"}.items():\n+        if not wheel_name.endswith(suffix):\n+          continue\n+        wheel_name = wheel_name.replace(suffix, \"\") + \"_version\"\n+        nvidia_wheel_versions[version][wheel_name] = match.group(2).strip()\n+        break\n+\n+  setup_py_content = setup_py_content.replace(\n+      \"cuda_version = 0  # placeholder\", f\"cuda_version = {cuda_version}\"\n+  )\n+  setup_py_content = setup_py_content.replace(\n+      \"cuda_wheel_suffix = ''  # placeholder\",\n+      \"cuda_wheel_suffix = '-cu12'\" if cuda_version == \"12\" else \"cuda_wheel_suffix = ''\",\n+  )\n+  for version_name, version_value in nvidia_wheel_versions[\n+      str(cuda_version)\n+  ].items():\n+    setup_py_content = setup_py_content.replace(\n+        f\"{version_name} = ''  # placeholder\",\n+        f\"{version_name} = '{version_value}'\",\n+    )\n+\n+  return setup_py_content"
        },
        {
            "sha": "e3a5e229e79df1c3329c602356b7693409e70f58",
            "filename": "third_party/xla/third_party/raft/cudart_utils.hpp.patch",
            "status": "added",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fcudart_utils.hpp.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fcudart_utils.hpp.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fcudart_utils.hpp.patch?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,39 @@\n+diff --git a/cpp/include/raft/util/cudart_utils.hpp b/cpp/include/raft/util/cudart_utils.hpp\n+--- a/cpp/include/raft/util/cudart_utils.hpp\n++++ b/cpp/include/raft/util/cudart_utils.hpp\n+@@ -21,6 +21,7 @@\n+ \n+ #include <rmm/cuda_stream_view.hpp>\n+ \n++#include <cuda_bf16.h>\n+ #include <cuda_fp16.h>\n+ #include <cuda_runtime_api.h>\n+ \n+@@ -456,4 +457,27 @@ constexpr inline auto upper_bound<half>(\n+   return static_cast<half>(__half_constexpr{0x7c00u});\n+ }\n+ \n++/**\n++ * This is a hack to allow constexpr definition of `bfloat16` constants.\n++ *\n++ * Same reasoning as for `half`: CUDAs `__nv_bfloat16` has no constexpr constructor.\n++ */\n++struct __bfloat16_constexpr : __nv_bfloat16 {  // NOLINT\n++  constexpr explicit inline __bfloat16_constexpr(uint16_t u) : __nv_bfloat16() { __x = u; }\n++};\n++\n++template <>\n++constexpr inline auto lower_bound<__nv_bfloat16>() -> __nv_bfloat16\n++{\n++  // Negative infinity in bfloat16 (sign=1, exp=all ones, mantissa=0)\n++  return static_cast<__nv_bfloat16>(__bfloat16_constexpr{0xff80u});\n++}\n++\n++template <>\n++constexpr inline auto upper_bound<__nv_bfloat16>() -> __nv_bfloat16\n++{\n++  // Positive infinity in bfloat16 (sign=0, exp=all ones, mantissa=0)\n++  return static_cast<__nv_bfloat16>(__bfloat16_constexpr{0x7f80u});\n++}\n++\n+ }  // namespace raft"
        },
        {
            "sha": "614d94dc657d1028d5008d9c4c50bd0521c0f949",
            "filename": "third_party/xla/third_party/raft/vectorized.cuh.patch",
            "status": "added",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fvectorized.cuh.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fvectorized.cuh.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fvectorized.cuh.patch?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,45 @@\n+diff --git a/cpp/include/raft/util/vectorized.cuh b/cpp/include/raft/util/vectorized.cuh\n+--- a/cpp/include/raft/util/vectorized.cuh\n++++ b/cpp/include/raft/util/vectorized.cuh\n+@@ -134,6 +134,22 @@ struct IOType<__half, 8> {\n+   typedef uint4 Type;\n+ };\n+ template <>\n++struct IOType<__nv_bfloat16, 1> {\n++  typedef __nv_bfloat16 Type;\n++};\n++template <>\n++struct IOType<__nv_bfloat16, 2> {\n++  typedef __nv_bfloat162 Type;\n++};\n++template <>\n++struct IOType<__nv_bfloat16, 4> {\n++  typedef uint2 Type;\n++};\n++template <>\n++struct IOType<__nv_bfloat16, 8> {\n++  typedef uint4 Type;\n++};\n++template <>\n+ struct IOType<__half2, 1> {\n+   typedef __half2 Type;\n+ };\n+@@ -146,6 +162,18 @@ struct IOType<__half2, 4> {\n+   typedef uint4 Type;\n+ };\n+ template <>\n++struct IOType<__nv_bfloat162, 1> {\n++  typedef __nv_bfloat162 Type;\n++};\n++template <>\n++struct IOType<__nv_bfloat162, 2> {\n++  typedef uint2 Type;\n++};\n++template <>\n++struct IOType<__nv_bfloat162, 4> {\n++  typedef uint4 Type;\n++};\n++template <>\n+ struct IOType<int32_t, 1> {\n+   typedef int32_t Type;\n+ };"
        },
        {
            "sha": "674c0a57083d57908b7f7bcf850b5999243b26bf",
            "filename": "third_party/xla/third_party/raft/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fraft%2Fworkspace.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -15,6 +15,8 @@ def repo():\n         urls = tf_mirror_urls(\"https://github.com/rapidsai/raft/archive/refs/tags/v{version}.tar.gz\".format(version = RAFT_VERSION)),\n         build_file = \"//third_party/raft:raft.BUILD\",\n         patch_file = [\n+            \"//third_party/raft:cudart_utils.hpp.patch\",\n+            \"//third_party/raft:vectorized.cuh.patch\",\n             \"//third_party/raft:logger_macros.hpp.patch\",\n             \"//third_party/raft:select_k_runner.hpp.patch\",\n             \"//third_party/raft:select_k_runner.cu.cc.patch\","
        },
        {
            "sha": "bebb8df2ff530a67e5df92b9bc2641f88a50d0ed",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 1188,
            "deletions": 4644,
            "changes": 5832,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "dc1fc1de452b6e4f24f5c88b6697390dd1877b82",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"e99cfa73916a8758e35015d61767ba7e986fc79d\"\n-    SHARDY_SHA256 = \"973ba2b5c77337157e37ff331a111873ac6eddf9831555b3c18391e910673a6d\"\n+    SHARDY_COMMIT = \"a95b171d7845fd58403315388b2c31da71d4a277\"\n+    SHARDY_SHA256 = \"d3f7bee0b0e73d9553f7566d31071d7e2c336c7a429ebf362b90996c6c4018a4\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "f94d85a1689c3200de9888f5afe987cc5e0df1f9",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl801607173.patch",
            "status": "added",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl801607173.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl801607173.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl801607173.patch?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,41 @@\n+\n+--- a/third_party/amd/lib/TritonAMDGPUToLLVM/AtomicRMWOpsEmitter.cpp\t2025-07-31 00:13:23.000000000 -0700\n++++ b/third_party/amd/lib/TritonAMDGPUToLLVM/AtomicRMWOpsEmitter.cpp\t2025-08-31 17:53:42.000000000 -0700\n+@@ -405,12 +405,31 @@\n+   Value mask = targetInfo.ballot(rewriter, loc, i64_ty, done);\n+   Value start = loopBody->getArgument(0);\n+   Value cnt = b.trunc(i32_ty, generatePopcount64(rewriter, mask));\n+-  Value mbcntLoRes = rewriter\n+-                         .create<ROCDL::MbcntLoOp>(\n+-                             loc, i32_ty, b.trunc(i32_ty, mask), b.i32_val(0))\n+-                         ->getResult(0);\n+-  Value idx = rewriter.create<ROCDL::MbcntHiOp>(\n+-      loc, i32_ty, b.trunc(i32_ty, b.lshr(mask, b.i64_val(32))), mbcntLoRes);\n++\n++  NamedAttribute noundef = rewriter.getNamedAttr(\n++      LLVM::LLVMDialect::getNoUndefAttrName(), rewriter.getUnitAttr());\n++  NamedAttribute lowRange = rewriter.getNamedAttr(\n++      LLVM::LLVMDialect::getRangeAttrName(),\n++      LLVM::ConstantRangeAttr::get(rewriter.getContext(), APInt::getZero(32),\n++                                   APInt(32, 32)));\n++  NamedAttribute highRange = rewriter.getNamedAttr(\n++      LLVM::LLVMDialect::getRangeAttrName(),\n++      LLVM::ConstantRangeAttr::get(rewriter.getContext(), APInt::getZero(32),\n++                                   APInt(32, 64)));\n++\n++  Value mbcntLoRes =\n++      ROCDL::MbcntLoOp::create(\n++          rewriter, loc, i32_ty, b.trunc(i32_ty, mask), b.i32_val(0),\n++          /*arg_attrs=*/{},\n++          /*res_attrs=*/\n++          rewriter.getArrayAttr(\n++              rewriter.getDictionaryAttr({noundef, lowRange})))\n++          ->getResult(0);\n++  Value idx = ROCDL::MbcntHiOp::create(\n++      rewriter, loc, i32_ty, b.trunc(i32_ty, b.lshr(mask, b.i64_val(32))),\n++      mbcntLoRes,\n++      /*arg_attrs=*/{},\n++      rewriter.getArrayAttr(rewriter.getDictionaryAttr({noundef, highRange})));\n+   Value base = b.add(start, cnt);\n+   Value leader = b.icmp_eq(idx, b.i32_val(0));\n+   cnt = b.sub(cnt, idx);"
        },
        {
            "sha": "fecb1f1dfac00a0f277c363e7a1e9615b4cf0809",
            "filename": "third_party/xla/third_party/triton/llvm_integration/series.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fseries.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -8,5 +8,6 @@ LLVM nor MLIR integrator, please do not add any patches to this list.\n \"\"\"\n \n llvm_patch_list = [\n+    \"//third_party/triton:llvm_integration/cl801607173.patch\",\n     # Add new patches just above this line\n ]"
        },
        {
            "sha": "24f533bed5a173877374b9ab6f2b40a9b4486598",
            "filename": "third_party/xla/third_party/tsl/tsl/platform/strcat.cc",
            "status": "modified",
            "additions": 58,
            "deletions": 63,
            "changes": 121,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -21,30 +21,17 @@ limitations under the License.\n #include <string.h>\n \n #include <algorithm>\n+#include <initializer_list>\n+#include <string>\n \n #include \"absl/meta/type_traits.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/tsl/platform/logging.h\"\n \n namespace tsl {\n namespace strings {\n \n-AlphaNum::AlphaNum(absl::Hex hex) {\n-  char *const end = &digits_[kFastToBufferSize];\n-  char *writer = end;\n-  uint64 value = hex.value;\n-  uint64 width = hex.width;\n-  // We accomplish minimum width by OR'ing in 0x10000 to the user's value,\n-  // where 0x10000 is the smallest hex number that is as wide as the user\n-  // asked for.\n-  uint64 mask = (static_cast<uint64>(1) << (width - 1) * 4) | value;\n-  static const char hexdigits[] = \"0123456789abcdef\";\n-  do {\n-    *--writer = hexdigits[value & 0xF];\n-    value >>= 4;\n-    mask >>= 4;\n-  } while (mask != 0);\n-  piece_ = absl::string_view(writer, end - writer);\n-}\n \n // ----------------------------------------------------------------------\n // StrCat()\n@@ -56,14 +43,15 @@ AlphaNum::AlphaNum(absl::Hex hex) {\n // Append is merely a version of memcpy that returns the address of the byte\n // after the area just overwritten.  It comes in multiple flavors to minimize\n // call overhead.\n-static char *Append1(char *out, const AlphaNum &x) {\n+static char* Append1(char* out, const absl::AlphaNum& x) {\n   if (x.data() == nullptr) return out;\n \n   memcpy(out, x.data(), x.size());\n   return out + x.size();\n }\n \n-static char *Append2(char *out, const AlphaNum &x1, const AlphaNum &x2) {\n+static char* Append2(char* out, const absl::AlphaNum& x1,\n+                     const absl::AlphaNum& x2) {\n   if (x1.data() != nullptr) {\n     memcpy(out, x1.data(), x1.size());\n     out += x1.size();\n@@ -75,8 +63,9 @@ static char *Append2(char *out, const AlphaNum &x1, const AlphaNum &x2) {\n   return out + x2.size();\n }\n \n-static char *Append4(char *out, const AlphaNum &x1, const AlphaNum &x2,\n-                     const AlphaNum &x3, const AlphaNum &x4) {\n+static char* Append4(char* out, const absl::AlphaNum& x1,\n+                     const absl::AlphaNum& x2, const absl::AlphaNum& x3,\n+                     const absl::AlphaNum& x4) {\n   if (x1.data() != nullptr) {\n     memcpy(out, x1.data(), x1.size());\n     out += x1.size();\n@@ -98,28 +87,31 @@ static char *Append4(char *out, const AlphaNum &x1, const AlphaNum &x2,\n   return out + x4.size();\n }\n \n-string StrCat(const AlphaNum &a) { return string(a.data(), a.size()); }\n+std::string StrCat(const absl::AlphaNum& a) {\n+  return std::string(a.data(), a.size());\n+}\n \n-string StrCat(const AlphaNum &a, const AlphaNum &b) {\n-  string result(a.size() + b.size(), '\\0');\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b) {\n+  std::string result(a.size() + b.size(), '\\0');\n   char *const begin = &*result.begin();\n   char *out = Append2(begin, a, b);\n   DCHECK_EQ(out, begin + result.size());\n   return result;\n }\n \n-string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c) {\n-  string result(a.size() + b.size() + c.size(), '\\0');\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+                   const absl::AlphaNum& c) {\n+  std::string result(a.size() + b.size() + c.size(), '\\0');\n   char *const begin = &*result.begin();\n   char *out = Append2(begin, a, b);\n   out = Append1(out, c);\n   DCHECK_EQ(out, begin + result.size());\n   return result;\n }\n \n-string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c,\n-              const AlphaNum &d) {\n-  string result(a.size() + b.size() + c.size() + d.size(), '\\0');\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+                   const absl::AlphaNum& c, const absl::AlphaNum& d) {\n+  std::string result(a.size() + b.size() + c.size() + d.size(), '\\0');\n   char *const begin = &*result.begin();\n   char *out = Append4(begin, a, b, c, d);\n   DCHECK_EQ(out, begin + result.size());\n@@ -148,8 +140,9 @@ struct ResizeUninitializedTraits<\n   }\n };\n \n-static inline void STLStringResizeUninitialized(string *s, size_t new_size) {\n-  ResizeUninitializedTraits<string>::Resize(s, new_size);\n+static inline void STLStringResizeUninitialized(std::string* s,\n+                                                size_t new_size) {\n+  ResizeUninitializedTraits<std::string>::Resize(s, new_size);\n }\n \n // Used to ensure exponential growth so that the amortized complexity of\n@@ -180,10 +173,10 @@ void STLStringResizeUninitializedAmortized(string_type *s, size_t new_size) {\n namespace internal {\n \n // Do not call directly - these are not part of the public API.\n-string CatPieces(std::initializer_list<absl::string_view> pieces) {\n+std::string CatPieces(std::initializer_list<absl::string_view> pieces) {\n   size_t total_size = 0;\n   for (const absl::string_view piece : pieces) total_size += piece.size();\n-  string result(total_size, '\\0');\n+  std::string result(total_size, '\\0');\n \n   char *const begin = &*result.begin();\n   char *out = begin;\n@@ -203,7 +196,7 @@ string CatPieces(std::initializer_list<absl::string_view> pieces) {\n #define DCHECK_NO_OVERLAP(dest, src) \\\n   DCHECK_GE(uintptr_t((src).data() - (dest).data()), uintptr_t((dest).size()))\n \n-void AppendPieces(string *result,\n+void AppendPieces(std::string* result,\n                   std::initializer_list<absl::string_view> pieces) {\n   size_t old_size = result->size();\n   size_t total_size = old_size;\n@@ -225,47 +218,49 @@ void AppendPieces(string *result,\n \n }  // namespace internal\n \n-void StrAppend(string *result, const AlphaNum &a) {\n-  DCHECK_NO_OVERLAP(*result, a);\n-  result->append(a.data(), a.size());\n+void StrAppend(std::string* dest, const absl::AlphaNum& a) {\n+  DCHECK_NO_OVERLAP(*dest, a);\n+  dest->append(a.data(), a.size());\n }\n \n-void StrAppend(string *result, const AlphaNum &a, const AlphaNum &b) {\n-  DCHECK_NO_OVERLAP(*result, a);\n-  DCHECK_NO_OVERLAP(*result, b);\n-  string::size_type old_size = result->size();\n-  STLStringResizeUninitializedAmortized(result, old_size + a.size() + b.size());\n-  char *const begin = &*result->begin();\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b) {\n+  DCHECK_NO_OVERLAP(*dest, a);\n+  DCHECK_NO_OVERLAP(*dest, b);\n+  std::string::size_type old_size = dest->size();\n+  STLStringResizeUninitializedAmortized(dest, old_size + a.size() + b.size());\n+  char* const begin = &*dest->begin();\n   char *out = Append2(begin + old_size, a, b);\n-  DCHECK_EQ(out, begin + result->size());\n+  DCHECK_EQ(out, begin + dest->size());\n }\n \n-void StrAppend(string *result, const AlphaNum &a, const AlphaNum &b,\n-               const AlphaNum &c) {\n-  DCHECK_NO_OVERLAP(*result, a);\n-  DCHECK_NO_OVERLAP(*result, b);\n-  DCHECK_NO_OVERLAP(*result, c);\n-  string::size_type old_size = result->size();\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b, const absl::AlphaNum& c) {\n+  DCHECK_NO_OVERLAP(*dest, a);\n+  DCHECK_NO_OVERLAP(*dest, b);\n+  DCHECK_NO_OVERLAP(*dest, c);\n+  std::string::size_type old_size = dest->size();\n   STLStringResizeUninitializedAmortized(\n-      result, old_size + a.size() + b.size() + c.size());\n-  char *const begin = &*result->begin();\n+      dest, old_size + a.size() + b.size() + c.size());\n+  char* const begin = &*dest->begin();\n   char *out = Append2(begin + old_size, a, b);\n   out = Append1(out, c);\n-  DCHECK_EQ(out, begin + result->size());\n+  DCHECK_EQ(out, begin + dest->size());\n }\n \n-void StrAppend(string *result, const AlphaNum &a, const AlphaNum &b,\n-               const AlphaNum &c, const AlphaNum &d) {\n-  DCHECK_NO_OVERLAP(*result, a);\n-  DCHECK_NO_OVERLAP(*result, b);\n-  DCHECK_NO_OVERLAP(*result, c);\n-  DCHECK_NO_OVERLAP(*result, d);\n-  string::size_type old_size = result->size();\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b, const absl::AlphaNum& c,\n+               const absl::AlphaNum& d) {\n+  DCHECK_NO_OVERLAP(*dest, a);\n+  DCHECK_NO_OVERLAP(*dest, b);\n+  DCHECK_NO_OVERLAP(*dest, c);\n+  DCHECK_NO_OVERLAP(*dest, d);\n+  std::string::size_type old_size = dest->size();\n   STLStringResizeUninitializedAmortized(\n-      result, old_size + a.size() + b.size() + c.size() + d.size());\n-  char *const begin = &*result->begin();\n+      dest, old_size + a.size() + b.size() + c.size() + d.size());\n+  char* const begin = &*dest->begin();\n   char *out = Append4(begin + old_size, a, b, c, d);\n-  DCHECK_EQ(out, begin + result->size());\n+  DCHECK_EQ(out, begin + dest->size());\n }\n \n }  // namespace strings"
        },
        {
            "sha": "4c7f9a7a6f7576b2d6a2d8d39ae79b8d1db9fc0e",
            "filename": "third_party/xla/third_party/tsl/tsl/platform/strcat.h",
            "status": "modified",
            "additions": 34,
            "deletions": 79,
            "changes": 113,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #ifndef TENSORFLOW_TSL_PLATFORM_STRCAT_H_\n #define TENSORFLOW_TSL_PLATFORM_STRCAT_H_\n \n+#include <initializer_list>\n #include <string>\n \n #include \"absl/base/attributes.h\"\n@@ -32,7 +33,7 @@ limitations under the License.\n \n // The AlphaNum type was designed to be used as the parameter type for StrCat().\n // Any routine accepting either a string or a number may accept it.\n-// The basic idea is that by accepting a \"const AlphaNum &\" as an argument\n+// The basic idea is that by accepting a \"const absl::AlphaNum& \" as an argument\n // to your function, your callers will automatically convert bools, integers,\n // and floating point values to strings for you.\n //\n@@ -79,60 +80,7 @@ using absl::kZeroPad7;\n using absl::kZeroPad8;\n using absl::kZeroPad9;\n using Hex ABSL_DEPRECATE_AND_INLINE() = absl::Hex;\n-\n-class AlphaNum {\n-  // NOLINTBEGIN(google-explicit-constructor)\n- public:\n-  // No bool ctor -- bools convert to an integral type.\n-  // A bool ctor would also convert incoming pointers (bletch).\n-  AlphaNum(int i32)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastInt32ToBufferLeft(i32, digits_)) {}\n-  AlphaNum(unsigned int u32)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastUInt32ToBufferLeft(u32, digits_)) {}\n-  AlphaNum(long x)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastInt64ToBufferLeft(x, digits_)) {}\n-  AlphaNum(unsigned long x)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastUInt64ToBufferLeft(x, digits_)) {}\n-  AlphaNum(long long int i64)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastInt64ToBufferLeft(i64, digits_)) {}\n-  AlphaNum(unsigned long long int u64)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FastUInt64ToBufferLeft(u64, digits_)) {}\n-\n-  AlphaNum(float f)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FloatToBuffer(f, digits_)) {}\n-  AlphaNum(double f)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, DoubleToBuffer(f, digits_)) {}\n-  AlphaNum(bfloat16 bf)  // NOLINT(runtime/explicit)\n-      : piece_(digits_, FloatToBuffer(static_cast<float>(bf), digits_)) {}\n-\n-  AlphaNum(absl::Hex hex);  // NOLINT(runtime/explicit)\n-\n-  AlphaNum(const char *c_str) : piece_(c_str) {}  // NOLINT(runtime/explicit)\n-  AlphaNum(const absl::string_view &pc)\n-      : piece_(pc) {}               // NOLINT(runtime/explicit)\n-  AlphaNum(const std::string &str)  // NOLINT(runtime/explicit)\n-      : piece_(str) {}\n-  AlphaNum(const tstring &str)  // NOLINT(runtime/explicit)\n-      : piece_(str) {}\n-  template <typename A>\n-  AlphaNum(const std::basic_string<char, std::char_traits<char>, A> &str)\n-      : piece_(str) {}  // NOLINT(runtime/explicit)\n-\n-  absl::string_view::size_type size() const { return piece_.size(); }\n-  const char *data() const { return piece_.data(); }\n-  absl::string_view Piece() const { return piece_; }\n-\n- private:\n-  absl::string_view piece_;\n-  char digits_[kFastToBufferSize];\n-\n-  // Use \":\" not ':'\n-  AlphaNum(char c);  // NOLINT(runtime/explicit)\n-\n-  // NOLINTEND(google-explicit-constructor)\n-  AlphaNum(const AlphaNum &) = delete;\n-  void operator=(const AlphaNum &) = delete;\n-};\n+using AlphaNum ABSL_DEPRECATE_AND_INLINE() = absl::AlphaNum;\n \n // ----------------------------------------------------------------------\n // StrCat()\n@@ -159,15 +107,17 @@ class AlphaNum {\n \n // For performance reasons, we have specializations for <= 4 args.\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a) TF_MUST_USE_RESULT;\n+std::string StrCat(const absl::AlphaNum& a) TF_MUST_USE_RESULT;\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a, const AlphaNum &b) TF_MUST_USE_RESULT;\n+std::string StrCat(const absl::AlphaNum& a,\n+                   const absl::AlphaNum& b) TF_MUST_USE_RESULT;\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a, const AlphaNum &b,\n-                   const AlphaNum &c) TF_MUST_USE_RESULT;\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+                   const absl::AlphaNum& c) TF_MUST_USE_RESULT;\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c,\n-                   const AlphaNum &d) TF_MUST_USE_RESULT;\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+                   const absl::AlphaNum& c,\n+                   const absl::AlphaNum& d) TF_MUST_USE_RESULT;\n \n namespace internal {\n \n@@ -181,17 +131,19 @@ void AppendPieces(std::string *dest,\n // Support 5 or more arguments\n template <typename... AV>\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c,\n-                   const AlphaNum &d, const AlphaNum &e,\n-                   const AV &...args) TF_MUST_USE_RESULT;\n+std::string\n+    StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+           const absl::AlphaNum& c, const absl::AlphaNum& d,\n+           const absl::AlphaNum& e, const AV&... args) TF_MUST_USE_RESULT;\n \n template <typename... AV>\n ABSL_DEPRECATED(\"Use absl::StrCat() instead.\")\n-std::string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c,\n-                   const AlphaNum &d, const AlphaNum &e, const AV &...args) {\n-  return internal::CatPieces({a.Piece(), b.Piece(), c.Piece(), d.Piece(),\n-                              e.Piece(),\n-                              static_cast<const AlphaNum &>(args).Piece()...});\n+std::string StrCat(const absl::AlphaNum& a, const absl::AlphaNum& b,\n+                   const absl::AlphaNum& c, const absl::AlphaNum& d,\n+                   const absl::AlphaNum& e, const AV&... args) {\n+  return internal::CatPieces(\n+      {a.Piece(), b.Piece(), c.Piece(), d.Piece(), e.Piece(),\n+       static_cast<const absl::AlphaNum&>(args).Piece()...});\n }\n \n // ----------------------------------------------------------------------\n@@ -216,25 +168,28 @@ std::string StrCat(const AlphaNum &a, const AlphaNum &b, const AlphaNum &c,\n // ----------------------------------------------------------------------\n \n ABSL_DEPRECATED(\"Use absl::StrAppend() instead.\")\n-void StrAppend(std::string *dest, const AlphaNum &a);\n+void StrAppend(std::string* dest, const absl::AlphaNum& a);\n ABSL_DEPRECATED(\"Use absl::StrAppend() instead.\")\n-void StrAppend(std::string *dest, const AlphaNum &a, const AlphaNum &b);\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b);\n ABSL_DEPRECATED(\"Use absl::StrAppend() instead.\")\n-void StrAppend(std::string *dest, const AlphaNum &a, const AlphaNum &b,\n-               const AlphaNum &c);\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b, const absl::AlphaNum& c);\n ABSL_DEPRECATED(\"Use absl::StrAppend() instead.\")\n-void StrAppend(std::string *dest, const AlphaNum &a, const AlphaNum &b,\n-               const AlphaNum &c, const AlphaNum &d);\n+void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+               const absl::AlphaNum& b, const absl::AlphaNum& c,\n+               const absl::AlphaNum& d);\n \n // Support 5 or more arguments\n template <typename... AV>\n ABSL_DEPRECATED(\"Use absl::StrAppend() instead.\")\n-inline void StrAppend(std::string *dest, const AlphaNum &a, const AlphaNum &b,\n-                      const AlphaNum &c, const AlphaNum &d, const AlphaNum &e,\n-                      const AV &...args) {\n+inline void StrAppend(std::string* dest, const absl::AlphaNum& a,\n+                      const absl::AlphaNum& b, const absl::AlphaNum& c,\n+                      const absl::AlphaNum& d, const absl::AlphaNum& e,\n+                      const AV&... args) {\n   internal::AppendPieces(dest,\n                          {a.Piece(), b.Piece(), c.Piece(), d.Piece(), e.Piece(),\n-                          static_cast<const AlphaNum &>(args).Piece()...});\n+                          static_cast<const absl::AlphaNum&>(args).Piece()...});\n }\n \n }  // namespace strings"
        },
        {
            "sha": "63930612a2aa622bcbfa4d9180a67bfd33e683b4",
            "filename": "third_party/xla/third_party/tsl/tsl/platform/strcat_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftsl%2Ftsl%2Fplatform%2Fstrcat_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -70,15 +70,12 @@ TEST(StrCat, Floats) {\n   const int s = 0;\n   const float f = 1.5f;\n   const double d = 1.5;\n-  const bfloat16 bf(1.5f);\n \n   string answer;\n   answer = StrCat(s, f);\n   EXPECT_EQ(answer, \"01.5\");\n   answer = StrCat(s, d);\n   EXPECT_EQ(answer, \"01.5\");\n-  answer = StrCat(s, bf);\n-  EXPECT_EQ(answer, \"01.5\");\n }\n \n TEST(StrCat, Nulls) {\n@@ -175,12 +172,12 @@ TEST(StrCat, Basics) {\n \n   float f = 100000.5;\n   result = StrCat(\"A hundred K and a half is \", f);\n-  EXPECT_EQ(result, \"A hundred K and a half is 100000.5\");\n+  EXPECT_EQ(result, \"A hundred K and a half is 100000\");\n \n   double d = f;\n   d *= d;\n   result = StrCat(\"A hundred K and a half squared is \", d);\n-  EXPECT_EQ(result, \"A hundred K and a half squared is 10000100000.25\");\n+  EXPECT_EQ(result, \"A hundred K and a half squared is 1.00001e+10\");\n \n   result = StrCat(1, 2, 333, 4444, 55555, 666666, 7777777, 88888888, 999999999);\n   EXPECT_EQ(result, \"12333444455555666666777777788888888999999999\");\n@@ -306,14 +303,14 @@ TEST(StrAppend, Basics) {\n   float f = 100000.5;\n   old_size = result.size();\n   StrAppend(&result, \"A hundred K and a half is \", f);\n-  EXPECT_EQ(result.substr(old_size), \"A hundred K and a half is 100000.5\");\n+  EXPECT_EQ(result.substr(old_size), \"A hundred K and a half is 100000\");\n \n   double d = f;\n   d *= d;\n   old_size = result.size();\n   StrAppend(&result, \"A hundred K and a half squared is \", d);\n   EXPECT_EQ(result.substr(old_size),\n-            \"A hundred K and a half squared is 10000100000.25\");\n+            \"A hundred K and a half squared is 1.00001e+10\");\n \n   // Test 9 arguments, the old maximum\n   old_size = result.size();"
        },
        {
            "sha": "716fc3cadf3388097886cac1e981102c88eb380e",
            "filename": "third_party/xla/tools/toolchains/remote_config/configs.bzl",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -50,7 +50,7 @@ def initialize_rbe_configs():\n     # The `ml-build-rbe` image is identical to the `ml-build` image except for the base image.\n     # The `ml-build`'s base image is a standard `ubuntu22.04` image.\n     # The `ml-build-rbe`'s base image is `nvidia/cuda:12.3.2-base-ubuntu22.04` which has nvidia driver installed.\n-    ml_build_rbe_config(\"docker://us-central1-docker.pkg.dev/tensorflow-sigs/tensorflow/ml-build-rbe@sha256:aaeb29799463729092c05f5ac8393113b3bb5d1ecf085f9f1f2016e3a1ece11c\")\n+    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-rbe@sha256:7bae9f7604645cbad40b11a22294f5058db16022315d52a130b832d07e54c9ef\")\n \n     # TF-Version-Specific SIG Build RBE Configs. The crosstool generated from these\n     # configs are python-version-independent because they only care about the"
        },
        {
            "sha": "4d7dd8743074501eeaf0f133163a2d7a3a8bb272",
            "filename": "third_party/xla/workspace0.bzl",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fworkspace0.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fworkspace0.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fworkspace0.bzl?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -140,10 +140,10 @@ def workspace():\n     if \"rules_ml_toolchain\" not in native.existing_rules():\n         http_archive(\n             name = \"rules_ml_toolchain\",\n-            sha256 = \"e7e44c4e349a1c1f31398bd2257c51432e73ea0e7e24cce67090b68b0b50007e\",\n-            strip_prefix = \"rules_ml_toolchain-55dcd0a52c7e0f9eec9927a32512229c09ac3b3e\",\n+            sha256 = \"1a855dd94eebedae69d1804e8837ad70b8018358a0a03eea0bec71d7dc2b096a\",\n+            strip_prefix = \"rules_ml_toolchain-d321763a84c900bc29b4f5459a4f81fad19b2356\",\n             urls = [\n-                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/55dcd0a52c7e0f9eec9927a32512229c09ac3b3e.tar.gz\",\n+                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/d321763a84c900bc29b4f5459a4f81fad19b2356.tar.gz\",\n             ],\n         )\n "
        },
        {
            "sha": "0b663c9955447e4b09a7b4d39aade1cc03755e28",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -42,7 +42,7 @@ struct AutotuneConfig {\n   bool skip_failing_configs = true;\n   // Whether to check the correctness of the output buffers and OOM reads on\n   // Input Buffers.\n-  bool check_buffers = false;\n+  bool check_buffers = true;\n   // Relative tolerance for correctness check.\n   float relative_tolerance = 1e-6;\n   // Whether to crash the process on check failure."
        },
        {
            "sha": "07b7bf37969f271b4366b9ead045699729597d9c",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 29,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -68,6 +68,12 @@ std::unique_ptr<google::protobuf::Any> GetTestConfig(std::string name) {\n   return any;\n }\n \n+AutotuneConfig GetTestAutotuneConfig() {\n+  AutotuneConfig config;\n+  config.check_buffers = false;\n+  return config;\n+}\n+\n class MockCodegenBackend : public CodegenBackend {\n  public:\n   MOCK_METHOD(absl::string_view, name, (), (const, override));\n@@ -91,10 +97,6 @@ class MockCodegenBackendWithWrongResults : public MockCodegenBackend {\n \n class MockProfiler : public Profiler {\n  public:\n-  MOCK_METHOD(absl::StatusOr<std::vector<absl::StatusOr<ProfileResult>>>,\n-              ProfileWithSharedBuffers,\n-              (std::vector<std::unique_ptr<Executable>> executables),\n-              (override));\n   MOCK_METHOD(absl::StatusOr<ProfileResult>, Profile,\n               (Executable * executable, const InputBuffers& buffers),\n               (override));\n@@ -165,7 +167,7 @@ absl::StatusOr<std::unique_ptr<Autotuner>> SetupAutotunerWithExpectations(\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend));\n   return Autotuner::Create(std::move(backends), std::move(profiler),\n-                           AutotuneConfig(), std::move(cache_manager));\n+                           GetTestAutotuneConfig(), std::move(cache_manager));\n }\n \n constexpr absl::string_view kHlo = R\"(\n@@ -179,11 +181,15 @@ constexpr absl::string_view kHlo = R\"(\n   }\n   )\";\n \n-class AutotunerTest : public HloHardwareIndependentTestBase {};\n+class AutotunerTest : public HloHardwareIndependentTestBase {\n+ public:\n+  AutotunerTest() { config_ = GetTestAutotuneConfig(); }\n+  AutotuneConfig config_;\n+};\n \n TEST_F(AutotunerTest, NoCodegenBackend) {\n   auto device_description = CreateDummyDeviceDescription();\n-  auto autotuner = Autotuner::Create({}, nullptr, AutotuneConfig(),\n+  auto autotuner = Autotuner::Create({}, nullptr, config_,\n                                      std::make_unique<MockAutotunerCache>());\n   EXPECT_THAT(autotuner, StatusIs(absl::StatusCode::kInvalidArgument));\n }\n@@ -192,8 +198,8 @@ TEST_F(AutotunerTest, NoCacheManager) {\n   auto device_description = CreateDummyDeviceDescription();\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::make_unique<MockCodegenBackend>());\n-  auto autotuner = Autotuner::Create(std::move(backends), nullptr,\n-                                     AutotuneConfig(), nullptr);\n+  auto autotuner =\n+      Autotuner::Create(std::move(backends), nullptr, config_, nullptr);\n   EXPECT_THAT(autotuner, IsOk());\n }\n \n@@ -213,8 +219,8 @@ TEST_F(AutotunerTest, AutotuneButNoSupportedConfigs) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache_manager)));\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::move(cache_manager)));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()),\n               absl_testing::StatusIs(absl::StatusCode::kInternal));\n@@ -241,8 +247,8 @@ TEST_F(AutotunerTest, AutotuneButNoCompiledConfigs) {\n   backends.push_back(std::move(backend));\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache_manager)));\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::move(cache_manager)));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()),\n               absl_testing::StatusIs(absl::StatusCode::kInternal));\n@@ -280,8 +286,8 @@ TEST_F(AutotunerTest, AutotuneAppliesBestConfigAndSkipsNonCompilableConfig) {\n   backends.push_back(std::move(backend));\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache_manager)));\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::move(cache_manager)));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), absl_testing::IsOk());\n }\n@@ -318,9 +324,8 @@ TEST_F(AutotunerTest, AutotuneAppliesBestConfigUsingThreadPool) {\n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"test\", 2);\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache_manager),\n-                        &thread_pool));\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::move(cache_manager), &thread_pool));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), absl_testing::IsOk());\n }\n@@ -333,7 +338,7 @@ TEST_F(AutotunerTest, AutotuneModuleFindsNoInstructionsToAutotune) {\n   auto device_description = CreateDummyDeviceDescription();\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), nullptr, AutotuneConfig(),\n+      Autotuner::Create(std::move(backends), nullptr, config_,\n                         std::make_unique<MockAutotunerCache>()));\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n@@ -395,19 +400,20 @@ TEST_F(AutotunerTest, CacheHit) {\n   EXPECT_CALL(*backend, name()).WillRepeatedly(Return(\"mock_backend\"));\n \n   auto profiler = std::make_unique<MockProfiler>();\n-  EXPECT_CALL(*profiler, ProfileWithSharedBuffers).Times(0);\n \n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend));\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache_manager)));\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n+                        std::move(cache_manager)));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n }\n \n TEST_F(AutotunerTest, AutotuneWithBufferCheck) {\n+  config_.check_buffers = true;\n+\n   std::vector<std::unique_ptr<BackendConfig>> configs_1;\n   configs_1.push_back(GetTestConfig(\"test_config_1\"));\n   auto backend_1 = std::make_unique<MockCodegenBackend>();\n@@ -444,11 +450,9 @@ TEST_F(AutotunerTest, AutotuneWithBufferCheck) {\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend_1));\n   backends.push_back(std::move(backend_2));\n-  AutotuneConfig config;\n-  config.check_buffers = true;\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler), config,\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n                         std::make_unique<MockAutotunerCache>()));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());\n@@ -487,12 +491,11 @@ TEST_F(AutotunerTest, AutotuneWithScratchBytesOptimization) {\n \n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   backends.push_back(std::move(backend_1));\n-  AutotuneConfig config;\n-  config.optimize_scratch_bytes = true;\n-  config.scratch_bytes_window_size_us = 2;\n+  config_.optimize_scratch_bytes = true;\n+  config_.scratch_bytes_window_size_us = 2;\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto autotuner,\n-      Autotuner::Create(std::move(backends), std::move(profiler), config,\n+      Autotuner::Create(std::move(backends), std::move(profiler), config_,\n                         std::make_unique<MockAutotunerCache>()));\n   auto dummy_instr = HloInstruction::CreateConstant(LiteralUtil::CreateR0(1));\n   EXPECT_THAT(autotuner->Autotune(dummy_instr.get()), IsOk());"
        },
        {
            "sha": "4944c296ac82e0f02e9266a8010c01c078ce110d",
            "filename": "third_party/xla/xla/backends/autotuner/profiler.h",
            "status": "modified",
            "additions": 0,
            "deletions": 21,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fprofiler.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,7 +18,6 @@ limitations under the License.\n \n #include <memory>\n #include <optional>\n-#include <vector>\n \n #include \"absl/log/check.h\"\n #include \"absl/status/statusor.h\"\n@@ -65,26 +64,6 @@ class Profiler {\n     return Profile(executable.get(), *buffers);\n   }\n \n-  // Profiles multiple executables with shared buffers. This guarantees that\n-  // the provided executables have same arguments. This is important for\n-  // autotuning as we run same instruction with different configs.\n-  // Note that an executable can still fail during runtime even if it compiled\n-  // successfully, which is why the return type is a vector of StatusOr.\n-  virtual absl::StatusOr<std::vector<absl::StatusOr<ProfileResult>>>\n-  ProfileWithSharedBuffers(\n-      std::vector<std::unique_ptr<Executable>> executables) {\n-    std::vector<absl::StatusOr<ProfileResult>> results;\n-    if (executables.empty()) {\n-      return results;\n-    }\n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<InputBuffers> buffers,\n-                        CreateInputBuffers(executables[0].get()));\n-    for (auto& executable : executables) {\n-      results.push_back(Profile(executable.get(), *buffers));\n-    }\n-    return results;\n-  }\n-\n   // Creates Input buffers for a given executable on the device. The buffers\n   // are created with the same shape as the input parameters of the executable.\n   virtual absl::StatusOr<std::unique_ptr<InputBuffers>> CreateInputBuffers("
        },
        {
            "sha": "21b9158558a1ef470e4505d79783caf2d349310e",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/cpu_profiler_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fcpu_profiler_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -54,39 +54,6 @@ class CpuProfilerTest : public HloHardwareIndependentTestBase {\n   ProfileOptions profile_options_;\n };\n \n-TEST_F(CpuProfilerTest, ProfileWithSharedBuffers) {\n-  constexpr absl::string_view kHloModule = R\"(\n-        HloModule module\n-        ENTRY main {\n-          ROOT c = s32[] constant(1)\n-        }\n-      )\";\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> hlo_module,\n-                          ParseAndReturnVerifiedModule(kHloModule));\n-\n-  std::vector<std::unique_ptr<Executable>> executables;\n-\n-  TF_ASSERT_OK_AND_ASSIGN(executables.emplace_back(),\n-                          CompileHloModule(std::move(hlo_module)));\n-\n-  auto profiler = CpuProfiler::Create(profile_options_);\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n-                                             std::move(executables)));\n-\n-  // We expect only one profile because we only have one executable.\n-  EXPECT_EQ(profiles.size(), 1);\n-  TF_EXPECT_OK(profiles[0].status());\n-}\n-\n-TEST_F(CpuProfilerTest, ProfileWithSharedBuffersWithoutExecutable) {\n-  auto profiler = CpuProfiler::Create(profile_options_);\n-  TF_ASSERT_OK_AND_ASSIGN(auto profiles,\n-                          profiler->ProfileWithSharedBuffers({}));\n-\n-  // No executable means no profiles.\n-  EXPECT_EQ(profiles.size(), 0);\n-}\n-\n TEST_F(CpuProfilerTest, CreateInputBuffersAndProfile) {\n   constexpr absl::string_view kHloModule = R\"(\n         HloModule module"
        },
        {
            "sha": "d8984847035da02173bc9022e525834543f6afdd",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/llvm_kernel_autotuner.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fllvm_kernel_autotuner.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -50,9 +50,11 @@ absl::StatusOr<bool> LlvmKernelAutotuner::Run(\n   std::vector<std::unique_ptr<CodegenBackend>> codegen_backends;\n   codegen_backends.push_back(std::move(backend));\n \n+  AutotuneConfig autotune_config;\n+  autotune_config.check_buffers = false;\n   TF_ASSIGN_OR_RETURN(std::unique_ptr<Autotuner> autotuner,\n                       Autotuner::Create(std::move(codegen_backends),\n-                                        std::move(profiler), AutotuneConfig(),\n+                                        std::move(profiler), autotune_config,\n                                         /*cache=*/nullptr));\n \n   bool hlo_changed = false;"
        },
        {
            "sha": "8bebf90d6e63384f3fb0e72a41c99dbf7ac5e2ba",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -514,7 +514,6 @@ xla_cc_test(\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n-        \"@com_google_absl//absl/types:span\",\n     ],\n )\n "
        },
        {
            "sha": "9f04c66b2d474bcd984592910c1f065f323b0fe2",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/tanh_benchmark_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Ftanh_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Ftanh_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Ftanh_benchmark_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -19,7 +19,6 @@ limitations under the License.\n \n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n #include \"xla/backends/cpu/benchmarks/hlo_benchmark_runner.h\"\n #include \"xla/backends/cpu/benchmarks/multi_benchmark_config.h\"\n #include \"xla/literal.h\"\n@@ -75,7 +74,7 @@ static void BM_TanhF16(benchmark::State& state) {\n }\n \n static void BM_TanhF64(benchmark::State& state, HloBenchmarkOptions options) {\n-  int64_t d0 = state.range(0);\n+  const int64_t d0 = state.range(0);\n \n   absl::string_view hlo = R\"(\n     HloModule tanh_f64_$d0\n@@ -94,6 +93,9 @@ static void BM_TanhF64(benchmark::State& state, HloBenchmarkOptions options) {\n   std::vector<const Literal*> args = {&p0};\n   CHECK_OK(\n       RunHloBenchmark(state, hlo, args, {{\"$d0\", absl::StrCat(d0)}}, options));\n+\n+  state.SetItemsProcessed(state.iterations() * d0);\n+  state.SetBytesProcessed(state.iterations() * d0 * sizeof(double));\n }\n \n #define REGISTER_TANH_BENCHMARK(NAME) \\"
        },
        {
            "sha": "b51dc944b7840d3c22dd4bfdea6dc07443c0dc50",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 1,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -28,8 +28,13 @@ limitations under the License.\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"llvm/ADT/StringRef.h\"\n+#include \"llvm/IR/BasicBlock.h\"\n+#include \"llvm/IR/FMF.h\"\n+#include \"llvm/IR/Function.h\"\n+#include \"llvm/IR/Instruction.h\"\n #include \"llvm/IR/Metadata.h\"\n #include \"llvm/IR/Module.h\"\n+#include \"llvm/Support/Casting.h\"\n #include \"mlir/Conversion/AffineToStandard/AffineToStandard.h\"\n #include \"mlir/Conversion/ComplexToStandard/ComplexToStandard.h\"\n #include \"mlir/Conversion/MathToLLVM/MathToLLVM.h\"\n@@ -56,6 +61,7 @@ limitations under the License.\n #include \"mlir/IR/Visitors.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/WalkResult.h\"\n #include \"mlir/Target/LLVMIR/Dialect/Builtin/BuiltinToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Export.h\"\n@@ -132,7 +138,6 @@ static void AddLoopTransformationPasses(mlir::OpPassManager& pm,\n   pm.addPass(mlir::mhlo::createConvertToSignlessPass());\n   pm.addPass(emitters::CreatePropagateSliceIndicesPass());\n   pm.addPass(emitters::CreateFlattenTensorsPass());\n-  pm.addPass(emitters::createPropagateAliasScopesPass());\n   // We need LICM before unswitching loops, because our loop unswitcher only\n   // detects for loops with a single if inside them.\n   pm.addPass(mlir::createLoopInvariantCodeMotionPass());\n@@ -201,6 +206,19 @@ static int GetLlvmFunctionDefCount(mlir::ModuleOp m) {\n   return count;\n };\n \n+static void ApplyFastMathFlags(llvm::Module& llvm_module,\n+                               const llvm::FastMathFlags& fast_math_flags) {\n+  for (llvm::Function& function : llvm_module) {\n+    for (llvm::BasicBlock& basic_block : function) {\n+      for (llvm::Instruction& instruction : basic_block) {\n+        if (llvm::isa<llvm::FPMathOperator>(instruction)) {\n+          instruction.setFastMathFlags(fast_math_flags);\n+        }\n+      }\n+    }\n+  }\n+}\n+\n FusionCompiler::FusionCompiler(mlir::MLIRContext* context, Options options,\n                                CompilationHooks hooks)\n     : options_(std::move(options)),\n@@ -299,6 +317,10 @@ absl::StatusOr<std::unique_ptr<llvm::Module>> FusionCompiler::Compile(\n \n   llvm_module->setDataLayout(llvm_module->getDataLayout());\n \n+  if (options_.fast_math_flags.any()) {\n+    ApplyFastMathFlags(*llvm_module, options_.fast_math_flags);\n+  }\n+\n   return llvm_module;\n }\n "
        },
        {
            "sha": "434a25bb634ed4ec549343d641e18458e897917f",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n \n #include \"absl/functional/any_invocable.h\"\n #include \"absl/status/statusor.h\"\n+#include \"llvm/IR/FMF.h\"\n #include \"llvm/IR/LLVMContext.h\"\n #include \"llvm/IR/Module.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n@@ -46,6 +47,7 @@ class FusionCompiler {\n     int32_t vector_width;\n     int32_t verification_level;\n     bool fast_min_max;\n+    llvm::FastMathFlags fast_math_flags;\n   };\n \n   FusionCompiler(mlir::MLIRContext* context, Options options,"
        },
        {
            "sha": "4801d69499e782586cc7dd87324098bc144b6ee5",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -175,11 +175,13 @@ Thunk::ExecuteSession::ExecuteSession(int64_t max_workers,\n       split_threshold_(split_threshold) {}\n \n // Encodes thunk info into the TraceMe compatible format.\n-std::string Thunk::TraceMeEncode() const {\n+std::string Thunk::TraceMeEncode(int64_t run_id, int64_t device_ordinal) const {\n   return tsl::profiler::TraceMeEncode(info_.op_name,\n                                       {{\"hlo_op\", info_.op_name},\n                                        {\"hlo_module\", info_.module_name},\n-                                       {\"program_id\", info_.module_id}});\n+                                       {\"program_id\", info_.module_id},\n+                                       {\"run_id\", run_id},\n+                                       {\"device_ordinal\", device_ordinal}});\n }\n \n std::ostream& operator<<(std::ostream& os, Thunk::Kind kind) {"
        },
        {
            "sha": "df4e276b19663ee52d24515bbb771ba56af985f4",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -277,6 +277,8 @@ class Thunk {\n     CollectiveExecuteParams* collective_params = nullptr;\n     CustomCallExecuteParams* custom_call_params = nullptr;\n     XnnParams* xnn_params = nullptr;\n+    int64_t run_id = -1;          // -1 means no run id is set.\n+    int64_t device_ordinal = -1;  // -1 means no device ordinal is set.\n     ExecuteSession session = ExecuteSession(ExecuteSession::kMaxWorkers,\n                                             ExecuteSession::kSplitThreshold);\n   };\n@@ -347,7 +349,7 @@ class Thunk {\n \n   // Encodes thunk info into the TraceMe compatible format. Used by\n   // ThunkExecutor to create TraceMe annotations for profiler.\n-  std::string TraceMeEncode() const;\n+  std::string TraceMeEncode(int64_t run_id, int64_t device_ordinal) const;\n \n   Kind kind_;\n   Info info_;"
        },
        {
            "sha": "00f8555ff4ea7600ac4fc778cfbf040a241dd77e",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk_executor.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_executor.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -225,8 +225,9 @@ tsl::AsyncValueRef<Thunk::ExecuteEvent> ThunkExecutor::TracedExecute(\n   }\n \n   // Create a producer traceme to capture the start event.\n-  tsl::profiler::TraceMeProducer producer([&] { return thunk.TraceMeEncode(); },\n-                                          tsl::profiler::ContextType::kGeneric);\n+  tsl::profiler::TraceMeProducer producer(\n+      [&] { return thunk.TraceMeEncode(params.run_id, params.device_ordinal); },\n+      tsl::profiler::ContextType::kGeneric);\n \n   auto execute_event = thunk.Execute(params);\n "
        },
        {
            "sha": "5d5ef0c1ed20c2d494a24f9c595b40676ff3bf48",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 16,
            "deletions": 2,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -45,13 +45,18 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n+        \"//xla/backends/gpu/codegen/triton:support\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:compiler\",\n+        \"//xla/service:hlo_cost_analysis\",\n+        \"//xla/service:instruction_fusion\",\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu:ir_emission_utils\",\n+        \"//xla/service/gpu/model:fusion_analysis_cache\",\n+        \"//xla/service/gpu/model:gpu_indexing_performance_model\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n@@ -61,6 +66,7 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@llvm-project//mlir:IR\",\n     ],\n )\n \n@@ -86,11 +92,13 @@ xla_test(\n         \"//xla/service:executable\",\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/service/gpu:nvptx_compiler_impl\",\n         \"//xla/stream_executor:device_description_proto_cc\",\n         \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_googletest//:gtest_main\",\n@@ -759,5 +767,11 @@ xla_cc_binary(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@local_tsl//tsl/platform:platform_port\",\n-    ] + if_cuda_is_configured([\":factory_cuda\"]) + if_rocm_is_configured([\":factory_rocm\"]),\n+    ] + if_cuda_is_configured([\n+        \":factory_cuda\",\n+        \"//xla/stream_executor/cuda:all_runtime\",\n+    ]) + if_rocm_is_configured([\n+        \":factory_rocm\",\n+        \"//xla/stream_executor/rocm:all_runtime\",\n+    ]),\n )"
        },
        {
            "sha": "981421f5bb6ce7f9a2ec3c2d470670ccf7b0523a",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.cc",
            "status": "modified",
            "additions": 53,
            "deletions": 70,
            "changes": 123,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -28,14 +28,21 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/types/span.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n #include \"xla/autotuning.pb.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/backends/gpu/codegen/triton/support.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/utils/hlo_traversal.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n+#include \"xla/service/gpu/model/fusion_analysis_cache.h\"\n+#include \"xla/service/gpu/model/gpu_indexing_performance_model.h\"\n+#include \"xla/service/instruction_fusion.h\"\n #include \"xla/shape.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -46,43 +53,6 @@ namespace xla {\n namespace gpu {\n \n namespace {\n-// Computes a tile size for a given dimension `dim` such that:\n-// - It is a power of two,\n-// - It is at least `dim` (i.e.,  dim),\n-// - It does not exceed `max_tile_size`.\n-//\n-// - Special cases:\n-//     - If dim is a power of two  max_tile_size, it returns dim.\n-//     - If dim is not a power of two, it returns the next power of two  dim,\n-//       capped at max_tile_size.\n-//     - If dim <= 1, it returns dim.\n-//     - If dim >= max_tile_size, it returns max_tile_size.\n-//\n-// Parameters:\n-// - dim: the size of the dimension to tile (must be  0).\n-// - max_tile_size: the maximum allowed tile size (must be  1).\n-//\n-// Returns:\n-// - If dim <= 1: returns dim.\n-// - If dim >= max_tile_size: returns max_tile_size.\n-// - Otherwise: returns the smallest power of two  dim, but  max_tile_size.\n-//\n-// Examples:\n-//   GetTileSize(1, 16)   => 1\n-//   GetTileSize(7, 16)   => 8\n-//   GetTileSize(8, 16)   => 8\n-//   GetTileSize(16, 16)  => 16\n-//   GetTileSize(20, 16)  => 16\n-constexpr int64_t GetTileSize(int64_t dim, int max_tile_size) {\n-  if (dim <= 1) {\n-    return dim;\n-  }\n-  if (dim >= max_tile_size) {\n-    return max_tile_size;\n-  }\n-  return 1LL << static_cast<int64_t>(std::ceil(std::log2(dim)));\n-}\n-\n // Helper: resets all variable dimensions after 'index' to zero\n void ResetTrailingDimensions(const std::vector<int64_t>& input,\n                              std::vector<int64_t>& current, int64_t index) {\n@@ -243,13 +213,14 @@ void ExtendConfigsWithTma(\n absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>>\n BlockLevelEmitterBackend::GetSupportedConfigs(const HloInstruction& instr) {\n   // When use_default_config_ is true, we only return a single config for the\n-  // autotuner to use. It is expected that the default config exists already\n-  // in the HLO fusion and therefore fails if a default config cannot be\n-  // constructed.\n+  // autotuner to use. This is useful to autotune against other backends.\n   if (use_default_config_) {\n-    TF_ASSIGN_OR_RETURN(auto config, GetDefaultConfig(instr));\n+    auto config = GetDefaultConfig(instr);\n+    if (!config.ok()) {\n+      return std::vector<std::unique_ptr<BackendConfig>>();\n+    }\n     std::vector<std::unique_ptr<BackendConfig>> configs;\n-    configs.push_back(std::move(config));\n+    configs.push_back(std::move(config.value()));\n     return configs;\n   }\n \n@@ -328,6 +299,34 @@ BlockLevelEmitterBackend::GetSupportedConfigs(const HloInstruction& instr) {\n   return configs;\n }\n \n+absl::StatusOr<BlockLevelFusionConfig>\n+BlockLevelEmitterBackend::GetCostModelConfig(\n+    const HloInstruction& instr) const {\n+  auto device_info = target_config().device_description;\n+  HloFusionAnalysisCache fusion_analysis_cache(device_info);\n+  mlir::MLIRContext ctx;\n+  GpuPerformanceModelWithIndexingAnalysis indexing_performance_model(\n+      &device_info, &fusion_analysis_cache, shape_size_fn_, &ctx);\n+\n+  auto fusion_adaptor =\n+      HloFusionAdaptor::ForInstruction(Cast<HloFusionInstruction>(&instr));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      TiledRunTimeDataOrError tiled_runtime_data_or_error,\n+      indexing_performance_model.TryFindBestTilingForFusion(*fusion_adaptor));\n+\n+  if (const auto* fusion_decision =\n+          std::get_if<FusionDecision>(&tiled_runtime_data_or_error)) {\n+    return absl::InvalidArgumentError(absl::StrCat(\n+        \"Can't rewrite fusion \", instr.ToString(),\n+        \" because tiling search failed: \", fusion_decision->Explain()));\n+  }\n+  TiledRunTimeData tiled_runtime_data =\n+      std::get<TiledRunTimeData>(std::move(tiled_runtime_data_or_error));\n+\n+  return tiled_runtime_data.block_level_parameters.ToBlockLevelFusionConfig();\n+}\n+\n absl::StatusOr<std::unique_ptr<BackendConfig>>\n BlockLevelEmitterBackend::GetDefaultConfig(const HloInstruction& instr) {\n   if (!IsSupported(instr)) {\n@@ -355,33 +354,16 @@ BlockLevelEmitterBackend::GetDefaultConfig(const HloInstruction& instr) {\n       }\n     }\n   }\n-  // No explicit config found - construct a default one.\n-  BlockLevelFusionConfig config;\n-  // Flatten the output shape(s) of the instruction.\n-  const auto shapes = FlatListOfShapes(instr);\n-  for (const absl::Span<const int64_t> shape : shapes) {\n-    Tile* output_tile = config.add_output_tiles();\n-    for (const int64_t dim : shape) {\n-      // Choose a tile size as the nearest power-of-two <= `dim`, capped at 16.\n-      output_tile->add_sizes(GetTileSize(dim, /*max_tile_size=*/16));\n-    }\n-  }\n-  // Set default kernel execution parameters.\n-  config.set_num_warps(1);           // Number of warps per block.\n-  config.set_num_ctas(1);            // Number of thread blocks (CTAs).\n-  config.set_num_stages(1);          // Number of pipeline stages.\n-  config.set_is_tma_allowed(false);  // Can codegen attempt to use TMA?\n+\n+  // No explicit config found - create one from the cost model if possible.\n+  TF_ASSIGN_OR_RETURN(BlockLevelFusionConfig config, GetCostModelConfig(instr));\n   auto any = std::make_unique<google::protobuf::Any>();\n   any->PackFrom(config);\n   return any;\n }\n \n absl::Status BlockLevelEmitterBackend::ApplyConfig(\n     HloInstruction& instr, const BackendConfig& config) {\n-  if (!IsSupported(instr)) {\n-    return absl::InvalidArgumentError(\n-        \"BlockLevelEmitterBackend does not support this instruction.\");\n-  }\n   // Object nesting structure:\n   // HloInstruction\n   //  GpuBackendConfig\n@@ -399,25 +381,26 @@ absl::Status BlockLevelEmitterBackend::ApplyConfig(\n                       instr.backend_config<GpuBackendConfig>());\n   FusionBackendConfig& backend_config =\n       *gpu_backend_config.mutable_fusion_backend_config();\n+  backend_config.set_kind(kTritonFusionKind);\n   // Overwrite the block-level fusion config with the new one provided.\n   *backend_config.mutable_block_level_fusion_config() =\n       block_level_fusion_config;\n   // Re-attach the modified GPU config back to the instruction.\n   TF_RETURN_IF_ERROR(instr.set_backend_config(std::move(gpu_backend_config)));\n+  instr.set_fusion_kind(HloInstruction::FusionKind::kCustom);\n   return absl::OkStatus();\n }\n \n bool BlockLevelEmitterBackend::IsSupported(const HloInstruction& instr) {\n   if (instr.opcode() != HloOpcode::kFusion) {\n     return false;\n   }\n-  auto gpu_config = instr.backend_config<GpuBackendConfig>();\n-  if (!gpu_config.ok()) {\n-    return false;\n-  }\n-  const FusionBackendConfig& backend_config =\n-      gpu_config->fusion_backend_config();\n-  return backend_config.kind() == kTritonFusionKind;\n+  const HloComputation* fusion_computation =\n+      Cast<HloFusionInstruction>(&instr)->fused_instructions_computation();\n+  return IsTritonSupportedComputation(\n+             *fusion_computation,\n+             target_config().device_description.gpu_compute_capability())\n+      .CanFuse();\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "c93e71980cf0d5bd880e014929ea72ae110e7798",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter.h",
            "status": "modified",
            "additions": 13,
            "deletions": 2,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_BACKENDS_GPU_AUTOTUNER_BLOCK_LEVEL_EMITTER_H_\n \n #include <memory>\n+#include <utility>\n #include <vector>\n \n #include \"absl/base/nullability.h\"\n@@ -26,6 +27,8 @@ limitations under the License.\n #include \"xla/backends/gpu/autotuner/gpu_codegen_backend.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/compiler.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/xla.pb.h\"\n \n@@ -42,10 +45,13 @@ class BlockLevelEmitterBackend : public GpuCodegenBackend {\n   explicit BlockLevelEmitterBackend(\n       stream_executor::StreamExecutor* absl_nonnull stream_executor,\n       const DebugOptions* absl_nonnull debug_options,\n-      Compiler* absl_nonnull compiler, bool use_default_config = false)\n+      Compiler* absl_nonnull compiler,\n+      HloCostAnalysis::ShapeSizeFunction shape_size_fn,\n+      bool use_default_config = false)\n       : GpuCodegenBackend(\"BlockLevelEmitter\", stream_executor, debug_options,\n                           compiler),\n-        use_default_config_(use_default_config) {}\n+        use_default_config_(use_default_config),\n+        shape_size_fn_(std::move(shape_size_fn)) {}\n \n   // Returns all supported block-level tiling configurations for the given\n   // instruction.\n@@ -64,12 +70,17 @@ class BlockLevelEmitterBackend : public GpuCodegenBackend {\n   bool IsSupported(const HloInstruction& instr);\n \n  private:\n+  absl::StatusOr<BlockLevelFusionConfig> GetCostModelConfig(\n+      const HloInstruction& instr) const;\n   // If true, the backend will return a single default configuration in\n   // GetSupportedConfigs instead of generating all supported configurations.\n   // This is useful to autotune between different backends without increasing\n   // compile time by too much. It will use the default config, likely already\n   // assigned by the cost model.\n   bool use_default_config_;\n+  // A function which returns the size in bytes of the top-level buffer of a\n+  // shape.\n+  HloCostAnalysis::ShapeSizeFunction shape_size_fn_;\n };\n \n }  // namespace gpu"
        },
        {
            "sha": "6213a5a23f499b86d628d7802ba780f0da5e2d0c",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/block_level_emitter_test.cc",
            "status": "modified",
            "additions": 52,
            "deletions": 134,
            "changes": 186,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fblock_level_emitter_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/substitute.h\"\n #include \"xla/autotuning.pb.h\"\n@@ -29,6 +30,7 @@ limitations under the License.\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/nvptx_compiler.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n@@ -41,7 +43,6 @@ namespace xla {\n namespace gpu {\n \n using ::tsl::proto_testing::EqualsProto;\n-using ::tsl::testing::IsOk;\n \n // Counts the number of configs with is_tma_allowed set to true.\n int CountTmaAllowed(\n@@ -68,7 +69,8 @@ class TritonBlockLevelFusionEmitterBackendTest\n                      .value()\n                      ->ExecutorForDevice(0)\n                      .value(),\n-                 &debug_options_, &compiler_) {\n+                 &debug_options_, &compiler_,\n+                 compiler_.ShapeSizeBytesFunction()) {\n     // TODO(b/315957220): Remove the experimental flags once TMA is enabled by\n     // default.\n     debug_options_.set_xla_gpu_experimental_enable_triton_tma(true);\n@@ -134,12 +136,10 @@ ENTRY %main {\n // BlockLevelFusionConfig when the backend config does not specify\n // a block_level_fusion_config.\n //\n-// The HLO module contains a fusion instruction with a Triton backend config,\n-// but without the detailed block_level_fusion_config settings. This test\n-// verifies that the backend creates a reasonable default config.\n+// We do not test the exact contents of the config here as this is a call to the\n+// cost model, which has its own tests.\n TEST_F(TritonBlockLevelFusionEmitterBackendTest, GetDefaultConfig_Fallback) {\n-  // Parse an HLO module with a fusion instruction having a Triton backend\n-  // config that lacks an explicit block_level_fusion_config.\n+  // Parse an HLO module with a fusion instruction lacking any backend config.\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(R\"(\n HloModule m\n@@ -150,106 +150,8 @@ HloModule m\n \n ENTRY %main {\n   %p0 = f32[16,1,64]{2,1,0} parameter(0), metadata={op_name=\"a\"}\n-  ROOT %wrapped_transpose = f32[64,1,16]{2,1,0} fusion(%p0), kind=kCustom,\n-  calls=%wrapped_transpose_computation,\n-  metadata={op_name=\"a\"},\n-  backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n-}\n-)\"));\n-\n-  // Call GetDefaultConfig on the root instruction (the fusion op).\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<BackendConfig> config,\n-      backend_.GetDefaultConfig(\n-          *(module->entry_computation()->root_instruction())));\n-  // Verify that the returned config is indeed a BlockLevelFusionConfig.\n-  BlockLevelFusionConfig block_level_fusion_config;\n-  ASSERT_TRUE(config->UnpackTo(&block_level_fusion_config));\n-  // Verify that the default config contains default tiles sizes for the\n-  // dimensions of the input.\n-  EXPECT_THAT(block_level_fusion_config, EqualsProto(R\"pb(\n-                output_tiles { sizes: 16 sizes: 1 sizes: 16 }\n-                num_warps: 1\n-                num_ctas: 1\n-                num_stages: 1\n-              )pb\"));\n-}\n-\n-// Tests that GetDefaultConfig correctly handles shapes containing zero-sized\n-// dimensions.\n-//\n-// The HLO module defines a fusion instruction with an input tensor that has a\n-// zero-sized dimension (dimension size 0). The backend config specifies a\n-// Triton fusion kind but does not include a block-level fusion config. This\n-// test verifies that the default config is generated correctly and handles\n-// zero-sized dimensions by preserving them in the output tile sizes.\n-TEST_F(TritonBlockLevelFusionEmitterBackendTest,\n-       GetDefaultConfig_Fallback_ZeroDim) {\n-  // Parse an HLO module with a fusion instruction that has a zero-sized\n-  // dimension in the input shape.\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(R\"(\n-HloModule m\n-%wrapped_transpose_computation {\n-  %param_0 = f32[5,0,10]{2,1,0} parameter(0)\n-  ROOT %transpose.3.1 = f32[10,0,5]{2,1,0} transpose(%param_0), dimensions={2,1,0}\n-}\n-\n-ENTRY %main {\n-  %p0 = f32[5,0,10]{2,1,0} parameter(0), metadata={op_name=\"a\"}\n-  ROOT %wrapped_transpose = f32[10,0,5]{2,1,0} fusion(%p0), kind=kCustom,\n-  calls=%wrapped_transpose_computation,\n-  metadata={op_name=\"a\"},\n-  backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n-}\n-)\"));\n-\n-  // Call GetDefaultConfig on the root instruction (the fusion op).\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      std::unique_ptr<BackendConfig> config,\n-      backend_.GetDefaultConfig(\n-          *(module->entry_computation()->root_instruction())));\n-  // Verify that the returned config is indeed a BlockLevelFusionConfig.\n-  BlockLevelFusionConfig block_level_fusion_config;\n-  ASSERT_TRUE(config->UnpackTo(&block_level_fusion_config));\n-  // Verify the default output tile sizes:\n-  // - The tile size for the dimension with size 10 is 16\n-  // - The zero-sized dimension remains zero\n-  // - The tile size for the dimension with size 5 is 8.\n-  // Also verify default tuning parameters: 1 warp, 1 CTA, 1 stage.\n-  EXPECT_THAT(block_level_fusion_config, EqualsProto(R\"pb(\n-                output_tiles { sizes: 16 sizes: 0 sizes: 8 }\n-                num_warps: 1\n-                num_ctas: 1\n-                num_stages: 1\n-              )pb\"));\n-}\n-\n-// Tests that GetDefaultConfig correctly generates default block-level fusion\n-// configurations for a fusion instruction that returns a tuple of two array\n-// shapes.\n-TEST_F(TritonBlockLevelFusionEmitterBackendTest,\n-       GetDefaultConfig_Fallback_tuple2) {\n-  // Parse and verify an HLO module with a fusion instruction that returns a\n-  // tuple of two array shapes.\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(R\"(\n-HloModule m\n-%wrapped_transpose_computation {\n-  %param_0 = f32[16,64]{1,0} parameter(0)\n-  %param_1 = f32[32,12]{1,0} parameter(1)\n-  %transpose.3.1 = f32[64,16]{1,0} transpose(%param_0), dimensions={1,0}\n-  %transpose.4.1 = f32[12,32]{1,0} transpose(%param_1), dimensions={1,0}\n-  ROOT %tu = (f32[64,16]{1,0}, f32[12,32]{1,0}) tuple(%transpose.3.1, %transpose.4.1)\n-}\n-\n-ENTRY %main {\n-  %p0 = f32[16,64]{1,0} parameter(0), metadata={op_name=\"a\"}\n-  %p1 = f32[32,12]{1,0} parameter(1), metadata={op_name=\"b\"}\n-  ROOT %wrapped_transpose = (f32[64,16]{1,0}, f32[12,32]{1,0}) fusion(%p0, %p1), kind=kCustom,\n-  calls=%wrapped_transpose_computation,\n-  metadata={op_name=\"ab\"},\n-  backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n+  ROOT %wrapped_transpose = f32[64,1,16]{2,1,0} fusion(%p0), kind=kInput,\n+  calls=%wrapped_transpose_computation\n }\n )\"));\n \n@@ -261,15 +163,11 @@ ENTRY %main {\n   // Verify that the returned config is indeed a BlockLevelFusionConfig.\n   BlockLevelFusionConfig block_level_fusion_config;\n   ASSERT_TRUE(config->UnpackTo(&block_level_fusion_config));\n-  // Check that the config correctly includes tiling info for both tuple\n-  // elements\n-  EXPECT_THAT(block_level_fusion_config, EqualsProto(R\"pb(\n-                output_tiles { sizes: 16 sizes: 16 }\n-                output_tiles { sizes: 16 sizes: 16 }\n-                num_warps: 1\n-                num_ctas: 1\n-                num_stages: 1\n-              )pb\"));\n+  // Verify the config is reasonable.\n+  EXPECT_GE(block_level_fusion_config.output_tiles_size(), 1);\n+  EXPECT_GE(block_level_fusion_config.num_warps(), 1);\n+  EXPECT_GE(block_level_fusion_config.num_ctas(), 1);\n+  EXPECT_GE(block_level_fusion_config.num_stages(), 1);\n }\n \n // Tests that `GetSupportedConfigs` returns a correct list of valid backend\n@@ -291,10 +189,8 @@ HloModule m\n \n ENTRY %main {\n   %p0 = f32[16,1,64]{2,1,0} parameter(0), metadata={op_name=\"a\"}\n-  ROOT %wrapped_transpose = f32[64,1,16]{2,1,0} fusion(%p0), kind=kCustom,\n-  calls=%wrapped_transpose_computation,\n-  metadata={op_name=\"a\"},\n-  backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n+  ROOT %wrapped_transpose = f32[64,1,16]{2,1,0} fusion(%p0), kind=kInput,\n+  calls=%wrapped_transpose_computation\n }\n )\"));\n \n@@ -451,10 +347,8 @@ HloModule m\n \n ENTRY %main {\n   %p0 = f32[16,64]{1,0} parameter(0), metadata={op_name=\"a\"}\n-  ROOT %wrapped_transpose = f32[64,16]{1,0} fusion(%p0), kind=kCustom,\n-  calls=%wrapped_transpose_computation,\n-  metadata={op_name=\"a\"},\n-  backend_config={\"fusion_backend_config\":{\"kind\":\"__triton\"}}\n+  ROOT %wrapped_transpose = f32[64,16]{1,0} fusion(%p0), kind=kInput,\n+  calls=%wrapped_transpose_computation\n }\n )\"));\n \n@@ -469,15 +363,6 @@ ENTRY %main {\n   // Verify that the returned config is indeed a BlockLevelFusionConfig.\n   BlockLevelFusionConfig block_level_fusion_config;\n   ASSERT_TRUE(config->UnpackTo(&block_level_fusion_config));\n-  // Verify the contents of the default config:\n-  // - output_tiles: shape is tiled into [16,16] blocks\n-  // - num_warps, num_ctas, num_stages are all 1 (basic launch setup)\n-  EXPECT_THAT(block_level_fusion_config, EqualsProto(R\"pb(\n-                output_tiles { sizes: 16 sizes: 16 }\n-                num_warps: 1\n-                num_ctas: 1\n-                num_stages: 1\n-              )pb\"));\n \n   // Apply the generated config to the fusion instruction.\n   EXPECT_THAT(backend_.ApplyConfig(*instr, *config), absl_testing::IsOk());\n@@ -487,6 +372,9 @@ ENTRY %main {\n   EXPECT_THAT(\n       gpu_backend_config.fusion_backend_config().block_level_fusion_config(),\n       EqualsProto(block_level_fusion_config));\n+  EXPECT_EQ(gpu_backend_config.fusion_backend_config().kind(),\n+            kTritonFusionKind);\n+  EXPECT_EQ(instr->fusion_kind(), HloInstruction::FusionKind::kCustom);\n }\n \n TEST_F(TritonBlockLevelFusionEmitterBackendTest, Compile) {\n@@ -531,10 +419,40 @@ ENTRY %main {\n   EXPECT_THAT(executable, absl_testing::IsOk());\n }\n \n+TEST_F(TritonBlockLevelFusionEmitterBackendTest,\n+       CompileThroughCostModelConfig) {\n+  // Parse an HLO module without any assigned backend config.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule m\n+%wrapped_transpose_computation {\n+  %param_0 = f32[16,64]{1,0} parameter(0)\n+  ROOT %transpose.3.1 = f32[64,16]{1,0} transpose(%param_0), dimensions={1,0}\n+}\n+\n+ENTRY %main {\n+  %p0 = f32[16,64]{1,0} parameter(0)\n+  ROOT %wrapped_transpose = f32[64,16]{1,0} fusion(%p0), kind=kCustom,\n+  calls=%wrapped_transpose_computation\n+}\n+)\"));\n+  // Call GetDefaultConfig on the root instruction (the fusion op).\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<BackendConfig> config,\n+      backend_.GetDefaultConfig(\n+          *(module->entry_computation()->root_instruction())));\n+  // Attempt to compile the root instruction using the retrieved backend config.\n+  absl::StatusOr<std::unique_ptr<Executable>> executable = backend_.Compile(\n+      *(module->entry_computation()->root_instruction()), *config);\n+  // Verify that compilation succeeded and returned a valid executable.\n+  EXPECT_THAT(executable, absl_testing::IsOk());\n+}\n+\n TEST_F(TritonBlockLevelFusionEmitterBackendTest, UseDefaultConfigFlag) {\n   auto backend = BlockLevelEmitterBackend(\n       PlatformUtil::GetDefaultPlatform().value()->ExecutorForDevice(0).value(),\n-      &debug_options_, &compiler_, /*use_default_config=*/true);\n+      &debug_options_, &compiler_, compiler_.ShapeSizeBytesFunction(),\n+      /*use_default_config=*/true);\n   // Parse an HLO module containing a kCustom Triton fusion with a backend\n   // config that includes block-level tiling parameters.\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,"
        },
        {
            "sha": "b3fe67edbca4a48a6b2010cc806ed404f8248cd6",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 8,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -100,14 +100,17 @@ std::unique_ptr<GpuProfiler> GpuProfiler::Create(\n     active_allocator = owned_allocator.get();\n   }\n \n-  auto stream = stream_executor->CreateStream();\n+  // TODO(b/442997461): Create a new stream using\n+  // `stream_executor->CreateStream()` instead of reusing the allocator stream\n+  // once we can handle cuBLAS using multiple streams.\n+  auto stream = active_allocator->GetStream(stream_executor->device_ordinal());\n   if (!stream.ok()) {\n     LOG(ERROR) << \"Failed to create stream: \" << stream.status();\n     return nullptr;\n   }\n   return absl::WrapUnique(new GpuProfiler(stream_executor, active_allocator,\n                                           std::move(owned_allocator),\n-                                          std::move(stream.value()), options));\n+                                          stream.value(), options));\n }\n \n absl::StatusOr<std::unique_ptr<InputBuffers>> GpuProfiler::CreateInputBuffers(\n@@ -119,7 +122,7 @@ absl::StatusOr<std::unique_ptr<InputBuffers>> GpuProfiler::CreateInputBuffers(\n           RedzoneBuffers::BuffersToCreate::kAllInputs,\n           options_.should_init_buffers,\n           /*should_check_correctness=*/true, options_.redzone_padding_bytes,\n-          allocator_, stream_.get()));\n+          allocator_, stream_));\n   auto gpu_buffers = std::make_unique<GpuInputBuffers>();\n   gpu_buffers->redzone_buffers = std::move(buffers);\n   return gpu_buffers;\n@@ -175,7 +178,7 @@ absl::StatusOr<ExecutionOutput> GpuProfiler::Execute(\n \n   ExecutableRunOptions run_options;\n   run_options.set_device_ordinal(stream_executor_->device_ordinal());\n-  run_options.set_stream(stream_.get());\n+  run_options.set_stream(stream_);\n   run_options.set_allocator(allocator_);\n   run_options.set_gpu_executable_run_options(&gpu_opts);\n   run_options.set_execution_profile(profile);\n@@ -205,10 +208,9 @@ absl::Status GpuProfiler::CheckOutputBuffer(ScopedShapedBuffer& output,\n                                             float rtol) {\n   BufferComparator comparator(output.on_device_shape(), rtol);\n \n-  TF_ASSIGN_OR_RETURN(\n-      bool outputs_match,\n-      comparator.CompareEqual(stream_.get(), output.root_buffer(),\n-                              reference.root_buffer()));\n+  TF_ASSIGN_OR_RETURN(bool outputs_match,\n+                      comparator.CompareEqual(stream_, output.root_buffer(),\n+                                              reference.root_buffer()));\n   if (outputs_match) {\n     return absl::OkStatus();\n   }"
        },
        {
            "sha": "7ff255465de85b5f7ea82bf66ff45f4737a893b9",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -63,11 +63,11 @@ class GpuProfiler : public Profiler {\n   explicit GpuProfiler(\n       se::StreamExecutor* stream_executor, se::DeviceMemoryAllocator* allocator,\n       std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator,\n-      std::unique_ptr<se::Stream> stream, ProfileOptions options)\n+      se::Stream* stream, ProfileOptions options)\n       : stream_executor_(stream_executor),\n         allocator_(allocator),\n         owned_allocator_(std::move(owned_allocator)),\n-        stream_(std::move(stream)),\n+        stream_(stream),\n         options_(options) {}\n \n   absl::StatusOr<ExecutionOutput> Execute(Executable* executable,\n@@ -77,7 +77,7 @@ class GpuProfiler : public Profiler {\n   se::StreamExecutor* stream_executor_;\n   se::DeviceMemoryAllocator* allocator_;\n   std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator_;\n-  std::unique_ptr<se::Stream> stream_;\n+  se::Stream* stream_;\n   ProfileOptions options_;\n };\n "
        },
        {
            "sha": "f3828419f64e4b4e3ea277a989db8c11ef0dc2aa",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -36,10 +36,19 @@ limitations under the License.\n namespace xla {\n namespace gpu {\n \n+// Returns true if the given instruction is a fusion instruction that is\n+// supported by the native emitter backend.\n+//\n+// There is no guarantee that the native emitter backend can actually compile if\n+// it has a config for another backend, and we currently don't have an easy way\n+// to check that. Therefore, we only support fusions that are already set up to\n+// go through the native emitter.\n bool IsSupported(const HloInstruction& instr) {\n-  return instr.opcode() == HloOpcode::kFusion &&\n-         // TODO: b/440062644 - Support multi-output fusions.\n-         !Cast<HloFusionInstruction>(&instr)->IsMultiOutputFusion();\n+  if (instr.opcode() != HloOpcode::kFusion) {\n+    return false;\n+  }\n+  auto fusion_kind = Cast<HloFusionInstruction>(&instr)->fusion_kind();\n+  return fusion_kind != HloInstruction::FusionKind::kCustom;\n }\n \n absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>>"
        },
        {
            "sha": "e3547074701b6e770e748fb3660bd57b4a948332",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 14,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -59,18 +59,11 @@ HloModule m\n \n ENTRY %entry_computation (p0: f32[32,4096,2048]) -> f32[32,2048] {\n   %p0 = f32[32,4096,2048]{2,1,0} parameter(0)\n-  ROOT %reduce_fusion = f32[32,2048]{1,0} fusion(%p0), kind=kCustom,\n-    calls=%fused_reduce.clone,\n-    backend_config={ \"fusion_backend_config\": {\n-      \"kind\":\"__triton\",\n-      \"block_level_fusion_config\":{\n-        \"num_warps\":\"8\",\"output_tiles\":[{\"sizes\":[\"1\",\"4\"]}],\n-        \"num_ctas\":1,\"num_stages\":1,\"is_tma_allowed\":false\n-      }\n-    }}\n+  ROOT %reduce_fusion = f32[32,2048]{1,0} fusion(%p0), kind=kInput,\n+    calls=%fused_reduce.clone\n })\";\n \n-const char kMultiOutputFusionHlo[] = R\"(\n+const char kCustomFusionHlo[] = R\"(\n HloModule m\n \n %fused_add_and_sub (p0: f32[32,16], p1: f32[32,16]) -> (f32[32,16], f32[32,16]) {\n@@ -136,15 +129,15 @@ TEST_F(NativeEmitterBackendTest, GetSupportedConfigs) {\n }\n \n TEST_F(NativeEmitterBackendTest,\n-       GetSupportedConfigsDoesNotSupportMultiOutputFusions) {\n+       GetSupportedConfigsDoesNotSupportKCustomFusions) {\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(kMultiOutputFusionHlo));\n+                          ParseAndReturnVerifiedModule(kCustomFusionHlo));\n   auto fusion_instruction = module->entry_computation()->root_instruction();\n   // Call GetSupportedConfigs on the fusion instruction.\n   TF_ASSERT_OK_AND_ASSIGN(std::vector<std::unique_ptr<BackendConfig>> configs,\n                           backend_.GetSupportedConfigs(*(fusion_instruction)));\n-  // GetSupportedConfigs should return an empty vector as it doesn't support\n-  // multi-output fusions.\n+  // GetSupportedConfigs should return an empty vector as it doesn't support the\n+  // fusion.\n   ASSERT_TRUE(configs.empty());\n }\n "
        },
        {
            "sha": "500a98c3b2ce79dda46ae25829f58cda03ff4e4b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_s16.hlo",
            "status": "modified",
            "additions": 2,
            "deletions": 6,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s16.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s16.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_s16.hlo?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -11,7 +11,6 @@ fusion {\n // CHECK-SAME:      %[[OUTPU:.*]]: tensor<4x2x6x10x64xi16>\n \n // CHECK-DAG:  %[[C1:.*]] = arith.constant 1 : index\n-// CHECK-DAG:  %[[VC0:.*]] = arith.constant dense<0> : vector<2x2xi16>\n \n // CHECK:  xla_gpu.allocate_shared : tensor<64x64xi16>\n \n@@ -27,22 +26,19 @@ fusion {\n // CHECK:        %[[V0:.*]] = vector.transfer_read %[[SHMEM_SYNC]]\n // CHECK-SAME:     : tensor<64x64xi16>, vector<2xi16>\n // CHECK:        %[[V1:.*]] = vector.extract %[[V0]][0] : i16 from vector<2xi16>\n-// CHECK:        %[[V2:.*]] = vector.insert %[[V1]], %[[VC0]] [0, 0]\n // CHECK:        %[[V3:.*]] = vector.extract %[[V0]][1] : i16 from vector<2xi16>\n-// CHECK:        %[[V4:.*]] = vector.insert %[[V3]], %[[V2]] [1, 0]\n // CHECK:        %[[V5:.*]] = arith.addi\n \n // Reading the second horizontal vector.\n // CHECK:        %[[V6:.*]] = vector.transfer_read %[[SHMEM_SYNC]][%[[V5]]\n // CHECK-SAME:     : tensor<64x64xi16>, vector<2xi16>\n // CHECK:        %[[V7:.*]] = vector.extract %{{.*}}[0] : i16 from vector<2xi16>\n-// CHECK:        %[[V8:.*]] = vector.insert %{{.*}}[0, 1]\n // CHECK:        %[[V9:.*]] = vector.extract %{{.*}}[1] : i16 from vector<2xi16>\n-// CHECK:        %[[V10:.*]] = vector.insert %{{.*}}[1, 1]\n+// CHECK:        %[[V10:.*]] = vector.from_elements %[[V1]], %[[V7]], %[[V3]], %[[V9]] : vector<2x2xi16>\n \n // Writing back the transpose <VECTOR_SIZE x VECTOR_SIZE> vector.\n // CHECK:        xla.loop\n // CHECK:          vector.extract %[[V10]]\n // CHECK:          tensor.insert\n // CHECK:          xla.yield %{{.*}} : tensor<4x2x6x10x64xi16>\n-// CHECK:        }\n\\ No newline at end of file\n+// CHECK:        }"
        },
        {
            "sha": "fbf32f148feff1b013459e101c08b044eddd078b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/tests/transpose/packed_transpose_two_heroes.hlo",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_two_heroes.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_two_heroes.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftests%2Ftranspose%2Fpacked_transpose_two_heroes.hlo?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -12,8 +12,9 @@ fusion {\n   ROOT tuple = (s16[4,2,6,10,64], bf16[4,2,6,10,64]) tuple(tr0, tr1)\n }\n \n-// CHECK-DAG:  arith.constant dense<0> : vector<2x2xi16>\n-// CHECK-DAG:  arith.constant dense<0.000000e+00> : vector<2x2xbf16>\n-\n // CHECK:  xla_gpu.allocate_shared : tensor<64x64xi16>\n-// CHECK:  xla_gpu.allocate_shared : tensor<64x64xbf16>\n\\ No newline at end of file\n+// CHECK:  xla_gpu.allocate_shared : tensor<64x64xbf16>\n+// CHECK:      vector.from_elements\n+// CHECK-SAME:   vector<2x2xi16>\n+// CHECK:      vector.from_elements\n+// CHECK-SAME:   vector<2x2xbf16>"
        },
        {
            "sha": "50e5868b6908e8797478c4c691fb2a72832e2eec",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/convert_index_type.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -85,13 +85,13 @@ class RewriteIndexBinaryElementwiseOp\n \n     Type index_type = IndexType::get(op->getContext());\n     Type dst_type = b.getIntegerType(index_bitwidth_);\n-    auto lhs = b.create<arith::IndexCastUIOp>(dst_type, op->getOperand(0));\n-    auto rhs = b.create<arith::IndexCastUIOp>(dst_type, op->getOperand(1));\n+    auto lhs = b.create<arith::IndexCastOp>(dst_type, op->getOperand(0));\n+    auto rhs = b.create<arith::IndexCastOp>(dst_type, op->getOperand(1));\n     auto new_op = b.create<BinaryElementwiseOp>(lhs, rhs);\n \n     rewriter.replaceAllUsesWith(\n         op.getResult(),\n-        b.create<arith::IndexCastUIOp>(index_type, new_op.getResult()));\n+        b.create<arith::IndexCastOp>(index_type, new_op.getResult()));\n \n     return mlir::success();\n   }\n@@ -115,9 +115,10 @@ struct ConvertIndexTypePass\n                  RewriteIndexBinaryElementwiseOp<arith::DivSIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::MulIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::RemUIOp>,\n+                 RewriteIndexBinaryElementwiseOp<arith::RemSIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::SubIOp>>(\n         ctx, *index_bitwidth);\n-    arith::IndexCastUIOp::getCanonicalizationPatterns(patterns, ctx);\n+    arith::IndexCastOp::getCanonicalizationPatterns(patterns, ctx);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "aa5e9f627c5c7fb086be95e4898caf92437fe2a0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/tests/convert_index_type.mlir",
            "status": "modified",
            "additions": 21,
            "deletions": 21,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -7,10 +7,10 @@ func.func @addi_default(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @addi_default\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -24,10 +24,10 @@ module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<index, 32 : i32>>\n \n // CHECK-LABEL: @addi_32\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i32\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i32\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i32\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i32\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[V2]] : i32\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i32 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i32 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -43,9 +43,9 @@ module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<index, 32 : i32>>\n // CHECK-LABEL: @addi_const\n // CHECK-SAME: (%[[ARG0:.*]]: index) -> index {\n // CHECK: %[[C:.*]] = arith.constant 4 : i32\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i32\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i32\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[C]] : i32\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i32 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i32 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -59,10 +59,10 @@ func.func @divui(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @divui\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i8\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i8\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i8\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i8\n // CHECK: %[[RI:.*]] = arith.divui %[[V1]], %[[V2]] : i8\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i8 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i8 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -74,10 +74,10 @@ func.func @muli(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @muli\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.muli %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n \n@@ -90,10 +90,10 @@ func.func @remui(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @remui\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.remui %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -105,10 +105,10 @@ func.func @subi(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @subi\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.subi %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -128,5 +128,5 @@ func.func @complex(%arg0: index, %arg1: index, %arg2: index) -> index {\n // CHECK: arith.muli %{{.*}} : i64\n // CHECK: arith.muli %{{.*}} : i64\n // CHECK: arith.remui %{{.*}} : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %{{.*}} : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %{{.*}} : i64 to index\n // CHECK: return %[[R]] : index"
        },
        {
            "sha": "27785cd15f7fc65cc294b5a10ba65453aecacb41",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -159,7 +159,7 @@ Value Cast(EmitterLocOpBuilder& b, Value value, Type dst_element_ty) {\n   }\n \n   if (src_ty.isIndex() || dst_ty.isIndex()) {\n-    return b.create<ma::IndexCastUIOp>(dst_ty, value);\n+    return b.create<ma::IndexCastOp>(dst_ty, value);\n   }\n \n   // All operations on bf16 are done through f32."
        },
        {
            "sha": "b52094c3c4a74e334030e4ff9e61b10513fb6f27",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 27,
            "changes": 60,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -179,7 +179,7 @@ Value EmitClampedIndex(EmitterLocOpBuilder b, Value value, int64_t lower,\n       value, CreateConst(b, value.getType(), lower).UnwrapUnsafe());\n   clamped_index = b.create<arith::MinSIOp>(\n       clamped_index, CreateConst(b, value.getType(), upper).UnwrapUnsafe());\n-  return b.create<arith::IndexCastUIOp>(b.getIndexType(), clamped_index);\n+  return b.create<arith::IndexCastOp>(b.getIndexType(), clamped_index);\n }\n \n absl::StatusOr<SmallVector<Value>> ComputeOffsetsForTile(\n@@ -236,7 +236,7 @@ class TileInfo {\n   ValueRange offsets() const { return offsets_; }\n \n   // Tile strides. Its size is equal to the rank of the output shape.\n-  ValueRange tile_strides() const { return tile_strides_; }\n+  ArrayRef<int64_t> tile_strides() const { return tile_strides_; }\n \n   // The original shape of the tensor.\n   ArrayRef<int64_t> original_shape() const { return original_shape_; }\n@@ -255,13 +255,14 @@ class TileInfo {\n \n  private:\n   SmallVector<Value> offsets_;\n-  SmallVector<Value> tile_strides_;\n+  SmallVector<int64_t> tile_strides_;\n   SmallVector<int64_t> original_shape_;\n   SmallVector<int64_t> padded_tile_sizes_;\n   SmallVector<int64_t> minor_to_major_layout_;\n   Type storage_type_;\n \n-  explicit TileInfo(SmallVector<Value> offsets, SmallVector<Value> tile_strides,\n+  explicit TileInfo(SmallVector<Value> offsets,\n+                    SmallVector<int64_t> tile_strides,\n                     SmallVector<int64_t> original_shape,\n                     SmallVector<int64_t> padded_tile_sizes,\n                     SmallVector<int64_t> minor_to_major_layout,\n@@ -291,7 +292,7 @@ absl::StatusOr<TileInfo> TileInfo::Construct(\n                       TritonType(b, shape.element_type()));\n   auto storage_type = StorageType(expected_element_type);\n \n-  auto tile_strides = CreateIndexValues(b, tiled_hlo.tile_strides());\n+  auto tile_strides = tiled_hlo.tile_strides();\n   auto minor_to_major_layout = llvm::to_vector(LayoutUtil::MinorToMajor(shape));\n \n   return TileInfo(offsets, tile_strides, original_shape, padded_tile_sizes,\n@@ -352,11 +353,13 @@ ScalarOrTensor EmitParameterExtract(EmitterLocOpBuilder b,\n         ttir::EvictionPolicy::NORMAL, /*isVolatile=*/false));\n   }\n \n-  return ScalarOrTensor(b.create<mtx::ExtractOp>(\n+  return ScalarOrTensor(mtx::ExtractOp::create(\n+      b,\n       mlir::RankedTensorType::get(tile_info.padded_tile_sizes(),\n                                   tile_info.storage_type()),\n-      parent_base_ptr, tile_info.offsets(), tile_info.tile_strides(),\n-      tile_info.original_shape(), tile_info.minor_to_major_layout()));\n+      parent_base_ptr, tile_info.offsets(), tile_info.padded_tile_sizes(),\n+      tile_info.tile_strides(), tile_info.original_shape(),\n+      tile_info.minor_to_major_layout()));\n }\n \n absl::StatusOr<ScalarOrTensor> EmitScope(\n@@ -687,6 +690,7 @@ absl::StatusOr<ScalarOrTensor> EmitTiledBitcast(\n \n   // Any Bitcast is decomposable to a transpose+reshape+transpose.\n   auto trt = ShapeUtil::DecomposeBitcastToTrt(input_shape, output_shape);\n+  TF_RET_CHECK(trt.has_value());\n \n   // When replacing the `bitcast` with `transpose` + `reshape` + `transpose` we\n   // need to provide the tile sizes at output of each op. We already have the\n@@ -702,22 +706,22 @@ absl::StatusOr<ScalarOrTensor> EmitTiledBitcast(\n   // different, even in rank, compared to the tile sizes of the final shape of\n   // the bitcast, so it's not possible to easily propagate them from the output.\n   std::vector<int64_t> transpose1_tile_sizes =\n-      Permute(tiled_bitcast.operand(0)->tile_sizes(), trt.transpose1_dims);\n+      Permute(tiled_bitcast.operand(0)->tile_sizes(), trt->transpose1_dims);\n   Value normalized_input =\n-      trt.IsTranspose1Identity()\n+      trt->IsTranspose1Identity()\n           ? input\n           : EmitTiledTranspose(b, transpose1_tile_sizes,\n-                               llvm::to_vector(trt.transpose1_dims), input);\n+                               llvm::to_vector(trt->transpose1_dims), input);\n \n   // Like the first transpose above, the tile sizes after the second transpose\n   // are a permutation (according to transpose2_dims) of the tile sizes of\n   // the reshape. Since we know the tile sizes of the final transpose and need\n   // the tile sizes of the reshape, we compute the tile sizes backwards, taking\n   // the inverse permutation.\n   std::vector<int64_t> reshape_tile_sizes =\n-      PermuteInverse(tiled_bitcast.tile_sizes(), trt.transpose2_dims);\n+      PermuteInverse(tiled_bitcast.tile_sizes(), trt->transpose2_dims);\n   Value normalized_reshape;\n-  if (ShapeUtil::Equal(trt.transpose1_shape, trt.reshape_shape)) {\n+  if (ShapeUtil::Equal(trt->transpose1_shape, trt->reshape_shape)) {\n     normalized_reshape = normalized_input;\n   } else {\n     TF_ASSIGN_OR_RETURN(auto reshape,\n@@ -729,10 +733,10 @@ absl::StatusOr<ScalarOrTensor> EmitTiledBitcast(\n   // The final transpose simply uses the tile sizes computed for the original\n   // bitcast by the tiling analysis.\n   return ScalarOrTensor{\n-      trt.IsTranspose2Identity()\n+      trt->IsTranspose2Identity()\n           ? normalized_reshape\n           : EmitTiledTranspose(b, tiled_bitcast.tile_sizes(),\n-                               llvm::to_vector(trt.transpose2_dims),\n+                               llvm::to_vector(trt->transpose2_dims),\n                                normalized_reshape)};\n }\n \n@@ -1659,8 +1663,8 @@ absl::Status EmitGeneric(mlir::OpBuilder builder,\n            \"non-empty.\";\n \n     mtx::InsertOp::create(b, result.UnwrapTensor(), parent_base_ptr,\n-                          tile_info.offsets(), tile_info.tile_strides(),\n-                          tile_info.original_shape(),\n+                          tile_info.offsets(), tile_info.padded_tile_sizes(),\n+                          tile_info.tile_strides(), tile_info.original_shape(),\n                           tile_info.minor_to_major_layout());\n   }\n \n@@ -1864,7 +1868,7 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n   EmitReturnOp(b, fusion_kind);\n \n   if (DumpingEnabledForHloModule(*hlo_computation->parent())) {\n-    auto suffix = absl::StrCat(fusion->name(), \".before_validation.ttir\");\n+    auto suffix = absl::StrCat(fusion->name(), \".before_validation.ttir.txt\");\n     DumpToFileInDirOrStdout(\n         *hlo_computation->parent(), \"\", suffix,\n         DumpTritonIR(triton_module.get(),\n@@ -1897,10 +1901,8 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> CreateTritonModule(\n                               ->config()\n                               .debug_options()\n                               .xla_gpu_unsupported_annotate_with_emitter_loc());\n-  // TODO(loislo): Remove this dump once we have the Triton IR dump in\n-  // CompileTritonToLLVM after the Triton optimization passes.\n   if (DumpingEnabledForHloModule(*hlo_computation->parent())) {\n-    std::string suffix = absl::StrCat(fusion->name(), \".ttir\");\n+    std::string suffix = absl::StrCat(fusion->name(), \".ttir.txt\");\n     DumpToFileInDirOrStdout(\n         *hlo_computation->parent(), \"\", suffix,\n         DumpTritonIR(triton_module.get(),\n@@ -1983,9 +1985,13 @@ absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n \n   std::optional<llvm::raw_fd_ostream> log_stream;\n   if (should_dump_mlir_passes) {\n-    std::string outputs_dir;\n-    if (!tsl::io::GetTestUndeclaredOutputsDir(&outputs_dir)) {\n-      outputs_dir = hlo_config.debug_options().xla_dump_to();\n+    std::string outputs_dir = hlo_config.debug_options().xla_dump_to();\n+    if (outputs_dir == \"sponge\") {\n+      if (!tsl::io::GetTestUndeclaredOutputsDir(&outputs_dir)) {\n+        LOG(ERROR) << \"Failed to get test undeclared outputs dir. Lets skip \"\n+                      \"dumping triton passes.\";\n+        outputs_dir = \"\";\n+      }\n     }\n     if (!outputs_dir.empty()) {\n       const std::string basename =\n@@ -2015,6 +2021,9 @@ absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n     }\n   }\n \n+  pm.addPass(mlir::triton::xla::CreateTritonXLASqueezeDimsPass());\n+  pm.addPass(mlir::triton::xla::CreateTritonXLAFoldTransposePass());\n+\n   if (is_xla_fusion) {\n     pm.addPass(\n         mlir::triton::xla::CreateInt4ToPackedInt4RewritePass(device_info));\n@@ -2023,9 +2032,6 @@ absl::StatusOr<TritonWrapperResult> CompileTritonToLLVM(\n   pm.addPass(mlir::triton::xla::CreateTritonXLAExtractInsertToTritonPass(\n       device_info, block_level_parameters.is_tma_allowed));\n \n-  pm.addPass(mlir::triton::xla::CreateTritonXLASqueezeDimsPass());\n-  pm.addPass(mlir::triton::xla::CreateTritonXLAFoldTransposePass());\n-\n   // Lower affine expressions into arithmetic ops.\n   pm.addPass(mlir::createLowerAffinePass());\n "
        },
        {
            "sha": "0abd3f5e8cc4a755e98c86b01da31c0c23ef3967",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -356,7 +356,7 @@ ENTRY e {\n     CHECK: %[[V2:.*]] = tensor.extract %[[ARG2]][] : tensor<i32>\n     CHECK: %[[CLAMP0:.*]] = arith.maxsi %[[V2]], %[[c0]] : i32\n     CHECK: %[[CLAMP1:.*]] = arith.minsi %[[CLAMP0]], %[[c3]] : i32\n-    CHECK: %[[OFFSET:.*]] = arith.index_castui %[[CLAMP1]] : i32 to index\n+    CHECK: %[[OFFSET:.*]] = arith.index_cast %[[CLAMP1]] : i32 to index\n     CHECK: triton_xla.extract from %[[ARG1]] {{.*}} [%[[OFFSET]], 0, 0] [1, 32, 32] [0, 1, 1]\n     CHECK: tt.dot\n   )\"));"
        },
        {
            "sha": "de121a2267532ca18979fa938e1632a7816c96bf",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -879,8 +879,7 @@ ENTRY main {\n                                           \"triton_softmax_computation\", R\"(\n CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}})\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-NEXT:       triton_xla.extract from %[[P0]]\n CHECK-SAME:       [%[[PID_INDEX]], 0] [1, 128] [1, 1]\n CHECK:            tt.reduce\n@@ -938,8 +937,7 @@ CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-DAG:        triton_xla.extract from %[[P0]] {{.*}} [%[[PID_INDEX]], 0] [1, 128] [1, 1] : tensor<1x128xf32>\n CHECK-DAG:        triton_xla.extract from %[[P1]] {{.*}} [0] [128] [1] : tensor<128xf32>\n CHECK:            tt.reduce\n@@ -999,8 +997,7 @@ CHECK:        #[[MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 125),\n CHECK:        #[[MAP1:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 mod 125), domain: pid_0 in [0, 1249]\">\n CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}})\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[PID_INDEX]]\n CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[PID_INDEX]]\n CHECK:            triton_xla.extract from %[[P0]] {{.*}} [%[[ROW_INDEX]], %[[COL_INDEX]], 0] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n@@ -1728,7 +1725,7 @@ ENTRY main {\n // CHECK-SAME:  : tensor<32xf32>\n \n // CHECK: %[[IOTA:.*]] = tt.make_range {end = 32 : i32, start = 0 : i32}\n-// CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_castui %[[TILE_OFFSET]]\n+// CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n // CHECK: %[[THRESHOLD:.*]] = arith.subi %[[C17]], %[[TILE_OFFSET_I32]]\n // CHECK: %[[THRESHOLD_SPLAT:.*]] = tt.splat %[[THRESHOLD]]\n // CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]"
        },
        {
            "sha": "f67b4eaba79170a585b41d0e6ee3490df909276d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -96,7 +96,6 @@ cc_library(\n         \"@llvm-project//mlir:InferTypeOpInterface\",\n         \"@llvm-project//mlir:SideEffectInterfaces\",\n         \"@llvm-project//mlir:Support\",\n-        \"@llvm-project//mlir:ViewLikeInterface\",\n         \"@triton//:TritonDialects\",\n     ],\n )"
        },
        {
            "sha": "2964fae0a79c218068df3d07d9d0a9e4c9538d75",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/tests/canonicalize.mlir",
            "status": "modified",
            "additions": 15,
            "deletions": 28,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,32 +1,19 @@\n-// RUN: xla-opt %s --split-input-file --canonicalize | FileCheck %s\n+// RUN: xla-opt %s --canonicalize | FileCheck %s\n \n-tt.func @xla_triton_extract(%arg0: !tt.ptr<bf16>, %i : index)\n-    -> tensor<16x64xbf16> {\n+// CHECK-LABEL: xla_triton_extract_insert\n+tt.func @xla_triton_extract_insert(%arg0: !tt.ptr<bf16>, %arg1: index) {\n   %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c128 = arith.constant 128 : index\n-  %extracted_tensor = triton_xla.extract from %arg0 as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n-      [%c0, %i] [16, 64] [%c128, %c1] {noinline = false} : tensor<16x64xbf16>\n-  tt.return %extracted_tensor : tensor<16x64xbf16>\n-}\n-// CHECK-LABEL: xla_triton_extract\n-\n-// CHECK:       triton_xla.extract\n-// CHECK-SAME:    [0, %{{.*}}] [16, 64] [128, 1]\n-// CHECK-SAME:    {noinline = false}\n-\n-// -----\n-\n-tt.func @xla_triton_insert(%src: tensor<16x64xbf16>, %dst: !tt.ptr<bf16>,\n-    %j: index) {\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c64 = arith.constant 64 : index\n-  triton_xla.insert %src into %dst as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n-    [%c0, %c0][16, 64][%j, %c1] {noinline = false} : tensor<16x64xbf16>\n+  // CHECK:       triton_xla.extract\n+  // CHECK-SAME:    [%arg1, 0] [16, 64] [128, 1]\n+  // CHECK-SAME:    {noinline = false}\n+  %tile = triton_xla.extract from %arg0\n+      as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n+      [%arg1, %c0] [16, 64] [128, 1] {noinline = false} : tensor<16x64xbf16>\n+  // CHECK:       triton_xla.insert\n+  // CHECK-SAME:    [0, %arg1] [16, 64] [1, 1]\n+  // CHECK-SAME:    {noinline = false}\n+  triton_xla.insert %tile into %arg0\n+      as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n+      [%c0, %arg1][16, 64][1, 1] {noinline = false} : tensor<16x64xbf16>\n   tt.return\n }\n-// CHECK-LABEL: xla_triton_insert\n-// CHECK:       triton_xla.insert\n-// CHECK-SAME:    [0, 0] [16, 64] [%{{.*}}, 1]\n-// CHECK-SAME:    {noinline = false}"
        },
        {
            "sha": "06d645febdf17ae3f87955f1098b5ce789732ac3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/tests/invalid.mlir",
            "status": "modified",
            "additions": 18,
            "deletions": 18,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Finvalid.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Finvalid.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Finvalid.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,63 +1,63 @@\n // RUN: xla-opt --split-input-file --verify-diagnostics %s\n \n func.func @extract_0d(%arg0: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{cannot extract a 0-d tensor}}\n+  // expected-error @+1 {{unsupported 0-d tensor}}\n   %0 = triton_xla.extract from %arg0 as memref<bf16, #triton_xla.layout<[]>> [][][] : tensor<bf16>\n   return\n }\n \n // -----\n \n func.func @insert_0d(%arg0: tensor<bf16>, %arg1: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{cannot insert a 0-d tensor}}\n+  // expected-error @+1 {{unsupported 0-d tensor}}\n   triton_xla.insert %arg0 into %arg1 as memref<bf16, #triton_xla.layout<[]>> [][][] : tensor<bf16>\n   return\n }\n \n // -----\n \n-func.func @extract_wrong_rank(%arg0: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{shape attribute has a wrong size}}\n-  %0 = triton_xla.extract from %arg0 as memref<bf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n+func.func @extract_wrong_layout(%arg0: !tt.ptr<bf16>) {\n+  // expected-error @+1 {{layout has 0 dimensions, but shape has 1}}\n+  %0 = triton_xla.extract from %arg0 as memref<8xbf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n   return\n }\n \n // -----\n \n-func.func @extract_wrong_shape(%arg0: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{shape size must match operand size}}\n-  %0 = triton_xla.extract from %arg0 as memref<16xbf16, #triton_xla.layout<[0]>> [0][16][1] : tensor<8xbf16>\n+func.func @insert_wrong_layout(%arg0: tensor<8xbf16>, %arg1: !tt.ptr<bf16>) {\n+  // expected-error @+1 {{layout has 0 dimensions, but shape has 1}}\n+  triton_xla.insert %arg0 into %arg1 as memref<8xbf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n   return\n }\n \n // -----\n \n-func.func @extract_wrong_layout(%arg0: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{layout has 0 dimensions, but shape has 1}}\n-  %0 = triton_xla.extract from %arg0 as memref<8xbf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n+func.func @extract_wrong_rank(%arg0: !tt.ptr<bf16>) {\n+  // expected-error @+1 {{expected 0 offset values, got 1}}\n+  %0 = triton_xla.extract from %arg0 as memref<bf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n   return\n }\n \n // -----\n \n func.func @insert_wrong_rank(%arg0: tensor<8xbf16>, %arg1: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{shape attribute has a wrong size}}\n+  // expected-error @+1 {{expected 0 offset values, got 1}}\n   triton_xla.insert %arg0 into %arg1 as memref<bf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n   return\n }\n \n // -----\n \n-func.func @insert_wrong_shape(%arg0: tensor<8xbf16>, %arg1: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{shape size must match operand size}}\n-  triton_xla.insert %arg0 into %arg1 as memref<16xbf16, #triton_xla.layout<[0]>> [0][16][1] : tensor<8xbf16>\n+func.func @extract_wrong_shape(%arg0: !tt.ptr<bf16>) {\n+  // expected-error @+1 {{expected type to be 'tensor<16xbf16>'}}\n+  %0 = triton_xla.extract from %arg0 as memref<16xbf16, #triton_xla.layout<[0]>> [0][16][1] : tensor<8xbf16>\n   return\n }\n \n // -----\n \n-func.func @insert_wrong_layout(%arg0: tensor<8xbf16>, %arg1: !tt.ptr<bf16>) {\n-  // expected-error @+1 {{layout has 0 dimensions, but shape has 1}}\n-  triton_xla.insert %arg0 into %arg1 as memref<8xbf16, #triton_xla.layout<[]>> [0][8][1] : tensor<8xbf16>\n+func.func @insert_wrong_shape(%arg0: tensor<8xbf16>, %arg1: !tt.ptr<bf16>) {\n+  // expected-error @+1 {{expected type to be 'tensor<16xbf16>'}}\n+  triton_xla.insert %arg0 into %arg1 as memref<16xbf16, #triton_xla.layout<[0]>> [0][16][1] : tensor<8xbf16>\n   return\n }"
        },
        {
            "sha": "d8c7e1318f95234c71f3cab2d611be7d5bb46753",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/tests/ops.mlir",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fops.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -10,8 +10,8 @@\n tt.func @xla_triton_extract(%src: !tt.ptr<bf16>, %i : index) -> tensor<16x64xbf16> {\n   // CHECK: triton_xla.extract\n   %extracted_tensor = triton_xla.extract from %src\n-    as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n-    [0, %i] [16, 64] [128, 1] : tensor<16x64xbf16>\n+    as memref<512x1x128xbf16, #triton_xla.layout<[2, 1, 0]>>\n+    [0, 0, %i] [16, 1, 64] [128, 1, 1] : tensor<16x64xbf16>\n   tt.return %extracted_tensor : tensor<16x64xbf16>\n }\n \n@@ -20,6 +20,6 @@ tt.func @xla_triton_insert(%src: tensor<16x64xbf16>, %dst: !tt.ptr<bf16>, %j: in\n   // CHECK: triton_xla.insert\n   triton_xla.insert %src into %dst\n     as memref<512x128xbf16, #triton_xla.layout<[0, 1]>>\n-    [0, 0][16, 64][%j, 1] : tensor<16x64xbf16>\n+    [%j, 0][16, 64][1, 1] : tensor<16x64xbf16>\n   tt.return\n }"
        },
        {
            "sha": "1f1a00741bf05d23e7354e134e0c778741afdf9d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_attrs.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_attrs.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_attrs.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_attrs.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include <cstdint>\n \n #include \"llvm/ADT/STLExtras.h\"\n+#include \"mlir/Dialect/Utils/IndexingUtils.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n@@ -109,6 +110,10 @@ LogicalResult LayoutAttr::verifyLayout(\n                  << \" dimensions, but shape has \" << shape.size();\n     return failure();\n   }\n+  if (!isPermutationVector(getMinorToMajor().asArrayRef())) {\n+    emit_error() << \"layout is not a permutation\";\n+    return failure();\n+  }\n   return success();\n }\n "
        },
        {
            "sha": "322c84686817c6ed94b13d105e7c27c5d7ce0b6a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_ops.cc",
            "status": "modified",
            "additions": 89,
            "deletions": 86,
            "changes": 175,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,14 +18,15 @@ limitations under the License.\n #include <cassert>\n #include <cstdint>\n \n-#include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/ADT/TypeSwitch.h\"  // IWYU pragma: keep\n+#include \"llvm/Support/ErrorHandling.h\"\n #include \"llvm/Support/LogicalResult.h\"\n #include \"mlir/Dialect/Utils/StaticValueUtils.h\"\n #include \"mlir/IR/Builders.h\"  // IWYU pragma: keep\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/DialectImplementation.h\"  // IWYU pragma: keep\n #include \"mlir/IR/MLIRContext.h\"  // IWYU pragma: keep\n #include \"mlir/IR/OperationSupport.h\"\n@@ -80,18 +81,53 @@ void printAsMemRefType(OpAsmPrinter& printer, Operation* op, PointerType type,\n                              memory_space);\n }\n \n-LogicalResult verifyShapeMatchesSizes(Operation* op,\n-                                      ArrayRef<int64_t> shape_sizes,\n-                                      ArrayRef<OpFoldResult> operand_sizes) {\n-  for (auto [shape_size, operand_size] :\n-       llvm::zip_equal(shape_sizes, operand_sizes)) {\n-    auto attr =\n-        dyn_cast_if_present<IntegerAttr>(dyn_cast<Attribute>(operand_size));\n-    if (attr && shape_size != ShapedType::kDynamic &&\n-        shape_size != attr.getValue()) {\n-      return op->emitError(\"shape size must match operand size\");\n-    }\n+static LogicalResult produceSliceErrorMsg(SliceVerificationResult result,\n+                                          Operation* op,\n+                                          RankedTensorType expected_type) {\n+  switch (result) {\n+    case SliceVerificationResult::Success:\n+      return success();\n+    case SliceVerificationResult::RankTooLarge:\n+      return op->emitError(\"expected rank to be smaller or equal to \")\n+             << \"the other rank. \";\n+    case SliceVerificationResult::SizeMismatch:\n+      return op->emitError(\"expected type to be \")\n+             << expected_type << \" or a rank-reduced version. (size mismatch) \";\n+    case SliceVerificationResult::ElemTypeMismatch:\n+      return op->emitError(\"expected element type to be \")\n+             << expected_type.getElementType();\n+    default:\n+      llvm_unreachable(\"unexpected extract_slice op verification result\");\n+  }\n+}\n+\n+static LogicalResult verifyExtractInsert(\n+    Operation* op, RankedTensorType tensor_type, PointerType pointer_type,\n+    DenseI64ArrayAttr layout, ArrayRef<int64_t> shape, ArrayRef<int64_t> sizes,\n+    ArrayRef<int64_t> strides) {\n+  if (tensor_type.getRank() == 0) {\n+    return op->emitError(\"unsupported 0-d tensor\");\n+  }\n+  if (ShapedType::isDynamicShape(sizes)) {\n+    return op->emitError(\"dynamic sizes are not supported\");\n+  }\n+  if (ShapedType::isDynamicShape(strides)) {\n+    return op->emitError(\"dynamic strides are not supported\");\n   }\n+  if (failed(LayoutAttr::get(op->getContext(), layout).verifyLayout(shape, [&] {\n+        return op->emitError();\n+      }))) {\n+    return failure();\n+  }\n+  auto expected_type =\n+      RankedTensorType::get(sizes, pointer_type.getPointeeType());\n+  SliceVerificationResult result =\n+      isRankReducedType(expected_type, tensor_type);\n+  if (result != SliceVerificationResult::Success) {\n+    return produceSliceErrorMsg(result, op, expected_type);\n+  }\n+  // Note: other than tensor.extract/insert, offsets, sizes, strides may run\n+  // out-of-bounds with respect to the source/destination.\n   return success();\n }\n \n@@ -105,45 +141,32 @@ void ExtractOp::getAsmResultNames(\n }\n \n LogicalResult ExtractOp::verify() {\n-  int64_t rank = getType().getRank();\n-  if (rank == 0) {\n-    return emitError(\"cannot extract a 0-d tensor\");\n-  }\n-  if (rank != getSrcShape().size()) {\n-    return emitError(\"shape attribute has a wrong size\");\n-  }\n-  if (rank != getSrcLayout().size()) {\n-    return emitError(\"layout attribute has a wrong size\");\n-  }\n-  if (getType().getElementType() != getSrc().getType().getPointeeType()) {\n-    return emitError(\"src pointee type must match result element type\");\n-  }\n-  return verifyShapeMatchesSizes(getOperation(), getType().getShape(),\n-                                 getMixedSizes());\n+  return verifyExtractInsert(getOperation(), getType(), getSrc().getType(),\n+                             getSrcLayoutAttr(), getSrcShape(),\n+                             getStaticSizes(), getStaticStrides());\n }\n \n void ExtractOp::build(OpBuilder& b, OperationState& result,\n                       RankedTensorType result_type, Value src,\n-                      ArrayRef<OpFoldResult> offsets,\n-                      ArrayRef<OpFoldResult> strides, ArrayRef<int64_t> shape,\n-                      ArrayRef<int64_t> layout) {\n-  SmallVector<int64_t> static_offsets, static_strides;\n-  SmallVector<Value> dynamic_offsets, dynamic_strides;\n+                      ArrayRef<OpFoldResult> offsets, ArrayRef<int64_t> sizes,\n+                      ArrayRef<int64_t> strides, ArrayRef<int64_t> src_shape,\n+                      ArrayRef<int64_t> src_layout) {\n+  SmallVector<int64_t> static_offsets;\n+  SmallVector<Value> dynamic_offsets;\n   dispatchIndexOpFoldResults(offsets, dynamic_offsets, static_offsets);\n-  dispatchIndexOpFoldResults(strides, dynamic_strides, static_strides);\n-  build(b, result, result_type, src, dynamic_offsets, {}, dynamic_strides,\n-        b.getDenseI64ArrayAttr(static_offsets),\n-        b.getDenseI64ArrayAttr(result_type.getShape()),\n-        b.getDenseI64ArrayAttr(static_strides), b.getDenseI64ArrayAttr(shape),\n-        b.getDenseI64ArrayAttr(layout));\n+  build(b, result, result_type, src, dynamic_offsets, /*sizes=*/{},\n+        /*strides=*/{}, b.getDenseI64ArrayAttr(static_offsets),\n+        b.getDenseI64ArrayAttr(sizes), b.getDenseI64ArrayAttr(strides),\n+        b.getDenseI64ArrayAttr(src_shape), b.getDenseI64ArrayAttr(src_layout));\n }\n \n void ExtractOp::build(OpBuilder& b, OperationState& result,\n                       RankedTensorType result_type, Value src,\n-                      ValueRange offsets, ValueRange strides,\n-                      ArrayRef<int64_t> shape, ArrayRef<int64_t> layout) {\n-  build(b, result, result_type, src, getAsOpFoldResult(offsets),\n-        getAsOpFoldResult(strides), shape, layout);\n+                      ValueRange offsets, ArrayRef<int64_t> sizes,\n+                      ArrayRef<int64_t> strides, ArrayRef<int64_t> shape,\n+                      ArrayRef<int64_t> layout) {\n+  build(b, result, result_type, src, getAsOpFoldResult(offsets), sizes, strides,\n+        shape, layout);\n }\n \n class ExtractOpOffsetsSizesStridesFolder final\n@@ -154,18 +177,15 @@ class ExtractOpOffsetsSizesStridesFolder final\n   LogicalResult matchAndRewrite(ExtractOp op,\n                                 PatternRewriter &rewriter) const override {\n     SmallVector<OpFoldResult> mixed_offsets(op.getMixedOffsets());\n-    SmallVector<OpFoldResult> mixed_strides(op.getMixedStrides());\n-\n-    // No constant operands were folded, just return;\n-    if (failed(foldDynamicIndexList(mixed_offsets, /*onlyNonNegative=*/true)) &&\n-        failed(foldDynamicIndexList(mixed_strides))) {\n+    if (failed(foldDynamicIndexList(mixed_offsets, /*onlyNonNegative=*/true))) {\n+      // No constant operands were folded, just return;\n       return failure();\n     }\n     // Create the new op in canonical form.\n     auto disable_attrs = to_vector(op->getDiscardableAttrs());\n     auto new_op = rewriter.replaceOpWithNewOp<ExtractOp>(\n-        op, op.getType(), op.getSrc(), mixed_offsets, mixed_strides,\n-        op.getSrcShape(), op.getSrcLayout());\n+        op, op.getType(), op.getSrc(), mixed_offsets, op.getStaticSizes(),\n+        op.getStaticStrides(), op.getSrcShape(), op.getSrcLayout());\n     new_op->setDiscardableAttrs(disable_attrs);\n     return success();\n   }\n@@ -181,45 +201,30 @@ void ExtractOp::getCanonicalizationPatterns(RewritePatternSet &results,\n //===----------------------------------------------------------------------===//\n \n LogicalResult InsertOp::verify() {\n-  int64_t rank = getSrc().getType().getRank();\n-  if (rank == 0) {\n-    return emitError(\"cannot insert a 0-d tensor\");\n-  }\n-  if (rank != getDstShape().size()) {\n-    return emitError(\"shape attribute has a wrong size\");\n-  }\n-  if (rank != getDstLayout().size()) {\n-    return emitError(\"layout attribute has a wrong size\");\n-  }\n-  if (getSrc().getType().getElementType() !=\n-      getDst().getType().getPointeeType()) {\n-    return emitError(\"dst pointee type must match src element type\");\n-  }\n-  return verifyShapeMatchesSizes(getOperation(), getSrc().getType().getShape(),\n-                                 getMixedSizes());\n+  return verifyExtractInsert(\n+      getOperation(), getSrc().getType(), getDst().getType(),\n+      getDstLayoutAttr(), getDstShape(), getStaticSizes(), getStaticStrides());\n }\n \n void InsertOp::build(OpBuilder& b, OperationState& result, Value src, Value dst,\n-                     ArrayRef<OpFoldResult> offsets,\n-                     ArrayRef<OpFoldResult> strides, ArrayRef<int64_t> shape,\n-                     ArrayRef<int64_t> layout) {\n-  RankedTensorType src_type = mlir::cast<RankedTensorType>(src.getType());\n-  SmallVector<int64_t> static_offsets, static_strides;\n-  SmallVector<Value> dynamic_offsets, dynamic_strides;\n+                     ArrayRef<OpFoldResult> offsets, ArrayRef<int64_t> sizes,\n+                     ArrayRef<int64_t> strides, ArrayRef<int64_t> dst_shape,\n+                     ArrayRef<int64_t> dst_layout) {\n+  SmallVector<int64_t> static_offsets;\n+  SmallVector<Value> dynamic_offsets;\n   dispatchIndexOpFoldResults(offsets, dynamic_offsets, static_offsets);\n-  dispatchIndexOpFoldResults(strides, dynamic_strides, static_strides);\n-  build(b, result, {}, src, dst, dynamic_offsets, {}, dynamic_strides,\n-        b.getDenseI64ArrayAttr(static_offsets),\n-        b.getDenseI64ArrayAttr(src_type.getShape()),\n-        b.getDenseI64ArrayAttr(static_strides), b.getDenseI64ArrayAttr(shape),\n-        b.getDenseI64ArrayAttr(layout));\n+  build(b, result, /*resultTypes=*/{}, src, dst, dynamic_offsets, /*sizes=*/{},\n+        /*strides=*/{}, b.getDenseI64ArrayAttr(static_offsets),\n+        b.getDenseI64ArrayAttr(sizes), b.getDenseI64ArrayAttr(strides),\n+        b.getDenseI64ArrayAttr(dst_shape), b.getDenseI64ArrayAttr(dst_layout));\n }\n \n void InsertOp::build(OpBuilder& b, OperationState& result, Value src, Value dst,\n-                     ValueRange offsets, ValueRange strides,\n-                     ArrayRef<int64_t> shape, ArrayRef<int64_t> layout) {\n-  build(b, result, src, dst, getAsOpFoldResult(offsets),\n-        getAsOpFoldResult(strides), shape, layout);\n+                     ValueRange offsets, ArrayRef<int64_t> sizes,\n+                     ArrayRef<int64_t> strides, ArrayRef<int64_t> shape,\n+                     ArrayRef<int64_t> layout) {\n+  build(b, result, src, dst, getAsOpFoldResult(offsets), sizes, strides, shape,\n+        layout);\n }\n \n class InsertOpOffsetsSizesStridesFolder final\n@@ -230,17 +235,15 @@ class InsertOpOffsetsSizesStridesFolder final\n   LogicalResult matchAndRewrite(InsertOp op,\n                                 PatternRewriter &rewriter) const override {\n     SmallVector<OpFoldResult> mixed_offsets(op.getMixedOffsets());\n-    SmallVector<OpFoldResult> mixed_strides(op.getMixedStrides());\n     // No constant operands were folded, just return;\n-    if (failed(foldDynamicIndexList(mixed_offsets, /*onlyNonNegative=*/true)) &&\n-        failed(foldDynamicIndexList(mixed_strides))) {\n+    if (failed(foldDynamicIndexList(mixed_offsets, /*onlyNonNegative=*/true))) {\n       return failure();\n     }\n     // Create the new op in canonical form.\n     auto disable_attrs = to_vector(op->getDiscardableAttrs());\n     auto new_op = rewriter.replaceOpWithNewOp<InsertOp>(\n-        op, op.getSrc(), op.getDst(), mixed_offsets, mixed_strides,\n-        op.getDstShape(), op.getDstLayout());\n+        op, op.getSrc(), op.getDst(), mixed_offsets, op.getStaticSizes(),\n+        op.getStaticStrides(), op.getDstShape(), op.getDstLayout());\n     new_op->setDiscardableAttrs(disable_attrs);\n     return success();\n   }"
        },
        {
            "sha": "f0845e2fbea0bb02b5de3eac83651da0195ff6dc",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_ops.td",
            "status": "modified",
            "additions": 26,
            "deletions": 14,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -84,13 +84,13 @@ def TTXLA_ExtractOp : TTXLA_OpWithOffsetSizesAndStrides<\"extract\", [\n   }];\n   let builders = [\n     OpBuilder<(ins \"RankedTensorType\":$result_type, \"Value\":$src,\n-      \"ValueRange\":$offsets,  \"ValueRange\":$strides,\n-      CArg<\"ArrayRef<int64_t>\">:$src_shape,\n-      CArg<\"ArrayRef<int64_t>\">:$src_layout)>,\n+      \"ValueRange\":$offsets, \"ArrayRef<int64_t>\":$sizes,\n+      \"ArrayRef<int64_t>\":$strides, \"ArrayRef<int64_t>\":$src_shape,\n+      \"ArrayRef<int64_t>\":$src_layout)>,\n     OpBuilder<(ins \"RankedTensorType\":$result_type, \"Value\":$src,\n-      \"ArrayRef<OpFoldResult>\":$offsets,  \"ArrayRef<OpFoldResult>\":$strides,\n-      CArg<\"ArrayRef<int64_t>\">:$src_shape,\n-      CArg<\"ArrayRef<int64_t>\">:$src_layout)>\n+      \"ArrayRef<OpFoldResult>\":$offsets, \"ArrayRef<int64_t>\":$sizes,\n+      \"ArrayRef<int64_t>\":$strides, \"ArrayRef<int64_t>\":$src_shape,\n+      \"ArrayRef<int64_t>\":$src_layout)>\n   ];\n \n   let arguments = (ins\n@@ -117,7 +117,7 @@ def TTXLA_ExtractOp : TTXLA_OpWithOffsetSizesAndStrides<\"extract\", [\n     /// Return the expected rank of each of the `static_offsets`, `static_sizes`\n     /// and `static_strides` attributes.\n     std::array<unsigned, 3> getArrayAttrMaxRanks() {\n-      unsigned rank = getType().getRank();\n+      unsigned rank = getSrcShape().size();\n       return {rank, rank, rank};\n     }\n     /// Return the number of leading operands before the `offsets`, `sizes` and\n@@ -145,13 +145,13 @@ def TTXLA_InsertOp : TTXLA_OpWithOffsetSizesAndStrides<\"insert\"> {\n   }];\n   let builders = [\n     OpBuilder<(ins \"Value\":$src, \"Value\":$dst,\n-      \"ValueRange\":$offsets,  \"ValueRange\":$strides,\n-      CArg<\"ArrayRef<int64_t>\">:$dst_shape,\n-      CArg<\"ArrayRef<int64_t>\">:$dst_layout)>,\n+      \"ValueRange\":$offsets, \"ArrayRef<int64_t>\":$sizes,\n+      \"ArrayRef<int64_t>\":$strides, \"ArrayRef<int64_t>\":$dst_shape,\n+      \"ArrayRef<int64_t>\":$dst_layout)>,\n     OpBuilder<(ins \"Value\":$src, \"Value\":$dst,\n-      \"ArrayRef<OpFoldResult>\":$offsets,  \"ArrayRef<OpFoldResult>\":$strides,\n-      CArg<\"ArrayRef<int64_t>\">:$dst_shape,\n-      CArg<\"ArrayRef<int64_t>\">:$dst_layout)>\n+      \"ArrayRef<OpFoldResult>\":$offsets, \"ArrayRef<int64_t>\":$sizes,\n+      \"ArrayRef<int64_t>\":$strides, \"ArrayRef<int64_t>\":$dst_shape,\n+      \"ArrayRef<int64_t>\":$dst_layout)>\n   ];\n \n   let arguments = (ins\n@@ -180,7 +180,7 @@ def TTXLA_InsertOp : TTXLA_OpWithOffsetSizesAndStrides<\"insert\"> {\n     /// Return the expected rank of each of the `static_offsets`, `static_sizes`\n     /// and `static_strides` attributes.\n     std::array<unsigned, 3> getArrayAttrMaxRanks() {\n-      unsigned rank = getSrc().getType().getRank();\n+      unsigned rank = getDstShape().size();\n       return {rank, rank, rank};\n     }\n     /// Return the number of leading operands before the `offsets`, `sizes` and\n@@ -198,4 +198,16 @@ def TTXLA_SqueezeDimsOp : TTXLA_Op<\"squeeze_dims\", [\n     let assemblyFormat = \"$src attr-dict `:` type($src) `->` type($result)\";\n }\n \n+def TTXLA_GetTidOp : TTXLA_Op<\"get_tid\", [Pure]> {\n+  let summary = \"Get the thread ID within a triton kernel.\";\n+  let description = [{\n+    This operation returns the thread ID within a kernel.\n+    Only the X dimension is supported. The result is a 32-bit\n+    integer which in CUDA terms is threadIdx.x.\n+  }];\n+  let arguments = (ins);\n+  let results = (outs I32:$result);\n+  let assemblyFormat = \"attr-dict `:` functional-type(operands, $result)\";\n+}\n+\n #endif // XLA_BACKENDS_GPU_CODEGEN_TRITON_IR_TRITON_XLA_OPS_TD_"
        },
        {
            "sha": "b355ffa33aa1a3ab2a62322e8e3f70fc5e0401ef",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -496,8 +496,9 @@ CodegenDecision IsTritonSupportedDot(\n // - of kind `__triton_nested_gemm_fusion`;\n // - to have a single user that is either a `dot` or a `concatenate`;\n // - calls a supported computation.\n-CodegenDecision IsSupportedFusion(const HloFusionInstruction& hlo,\n-                                  const se::GpuComputeCapability& capability) {\n+CodegenDecision IsTritonSupportedFusion(\n+    const HloFusionInstruction& hlo,\n+    const se::GpuComputeCapability& capability) {\n   // TODO(b/393299275): test cases when there are multiple dot users of the\n   // same fusion.\n   if (hlo.user_count() != 1) {\n@@ -659,8 +660,8 @@ CodegenDecision IsTritonSupportedInstructionImpl(\n       return IsTritonSupportedDot(*Cast<HloDotInstruction>(&instr),\n                                   gpu_version);\n     case HloOpcode::kFusion:\n-      return IsSupportedFusion(*Cast<HloFusionInstruction>(&instr),\n-                               gpu_version);\n+      return IsTritonSupportedFusion(*Cast<HloFusionInstruction>(&instr),\n+                                     gpu_version);\n     default:\n       // Not all instructions have a special handling.\n       break;\n@@ -688,10 +689,12 @@ namespace internal {\n bool IsTritonUnsupportedOpcode(HloOpcode opcode) {\n   switch (opcode) {\n     case HloOpcode::kDynamicReshape:\n+    case HloOpcode::kDynamicSlice:\n     case HloOpcode::kDynamicUpdateSlice:\n     case HloOpcode::kGather:\n     case HloOpcode::kRaggedDot:\n     case HloOpcode::kReduceWindow:\n+    case HloOpcode::kScaledDot:\n     case HloOpcode::kScatter:\n     case HloOpcode::kSelectAndScatter:\n     case HloOpcode::kSetDimensionSize:"
        },
        {
            "sha": "0bfd6ca81cc7b2776fb50df85622e988ef81ebe6",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/support_test.cc",
            "status": "modified",
            "additions": 54,
            "deletions": 6,
            "changes": 60,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fsupport_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/backends/gpu/codegen/triton/support.h\"\n \n+#include <algorithm>\n #include <array>\n #include <cstdint>\n #include <iterator>\n@@ -124,6 +125,10 @@ bool DoesOpSupportType(HloOpcode opcode, PrimitiveType type) {\n       return type == F32 || type == F64;\n     case HloOpcode::kDot:\n       return type != PRED;\n+    case HloOpcode::kScaledDot:\n+      static constexpr std::array types = {F4E2M1FN, F8E4M3FN, F8E5M2, BF16};\n+      return std::any_of(types.begin(), types.end(),\n+                         [&](auto t) { return t == type; });\n     case HloOpcode::kBatchNormInference:\n     case HloOpcode::kBatchNormTraining:\n     case HloOpcode::kBatchNormGrad:\n@@ -2316,6 +2321,39 @@ INSTANTIATE_TEST_SUITE_P(\n         ::testing::ValuesIn(AllDevicesToTest())),\n     DotPrecisionAlgorithmTestName);\n \n+class ScaledDotTest : public TritonSupportTest,\n+                      public ::testing::WithParamInterface<PrimitiveType> {};\n+\n+TEST_P(ScaledDotTest, ScaledDotOperandTypes) {\n+  const std::string kHloTestTemplate = R\"(\n+HloModule ScaledDotOperandTypes\n+\n+ENTRY triton_computation {\n+  lhs = $0[16, 32] parameter(0)\n+  lhs_scale = f8e8m0fnu[16, 1] parameter(1)\n+  rhs = $0[32, 16] parameter(2)\n+  rhs_scale = f8e8m0fnu[1, 16] parameter(3)\n+  ROOT dot = f32[16, 16] scaled-dot(lhs, lhs_scale, rhs, rhs_scale),\n+      lhs_contracting_dims={1},\n+      rhs_contracting_dims={0}\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      TestedInstruction ti,\n+      ParseTemplateAndGetInstruction(kHloTestTemplate, GetParam(),\n+                                     HloOpcode::kScaledDot,\n+                                     /*use_nested_gemm_fusions=*/true));\n+  RunSupportTest(std::move(ti), /*output_tile_sizes=*/{16, 16},\n+                 se::CudaComputeCapability::Hopper());\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(\n+    ScaledDotTest, ScaledDotTest,\n+    ::testing::ValuesIn(AllOpSupportedTypes(HloOpcode::kScaledDot)),\n+    [](const ::testing::TestParamInfo<PrimitiveType>& info) {\n+      return primitive_util::LowercasePrimitiveTypeName(info.param);\n+    });\n+\n class FusionKindsTest\n     : public TritonSupportTest,\n       public ::testing::WithParamInterface<\n@@ -2519,7 +2557,6 @@ TEST_P(BitcastConvertTest, BitcastConvertDisguisedAsBitcast) {\n \n   const int bit_width_in = primitive_util::BitWidth(data_type_in);\n   const int bit_width_out = primitive_util::BitWidth(data_type_out);\n-  ExpectedFailMode fail_mode = ExpectedFailMode::kFail;\n   std::vector<int64_t> output_tile_sizes = {1, 32};\n   std::string hlo_text;\n   const std::string data_type_in_str =\n@@ -2543,7 +2580,6 @@ ENTRY triton_computation {\n   ROOT bc = $1[33, $2] bitcast(parameter)\n })\",\n         data_type_in_str, data_type_out_str, bit_width_in / bit_width_out);\n-    fail_mode = ExpectedFailMode::kFailOrCrash;\n   } else {  // bit_width_in < bit_width_out\n     hlo_text = absl::Substitute(\n         R\"(\n@@ -2553,14 +2589,13 @@ ENTRY triton_computation {\n })\",\n         data_type_in_str, bit_width_out / bit_width_in, data_type_out_str);\n     output_tile_sizes = {1};\n-    fail_mode = ExpectedFailMode::kFailOrCrash;\n   }\n \n   TF_ASSERT_OK_AND_ASSIGN(TestedInstruction ti,\n                           ParseTemplateAndGetInstruction(hlo_text, data_type_in,\n                                                          HloOpcode::kBitcast));\n \n-  RunSupportTest(std::move(ti), output_tile_sizes, cc, fail_mode);\n+  RunSupportTest(std::move(ti), output_tile_sizes, cc);\n }\n \n INSTANTIATE_TEST_SUITE_P(\n@@ -3407,21 +3442,36 @@ INSTANTIATE_TEST_SUITE_P(ConvolutionTestSuiteCcOnly, ConvolutionTestCcOnly,\n                          ::testing::ValuesIn(AllDevicesToTest()),\n                          TritonSupportTestDeviceToString);\n \n+// This denotes opcodes that are explicitly not supported by the generic Triton\n+// emitter, and have also not been tested at all in the support test. If you\n+// are adding a new opcode that can't be easily added to other parametrized\n+// tests (e.g. adding tests to unary elementwise ops should be simple enough\n+// that adding them here is probably not necessary), add it here to ensure that\n+// the support test invariants are preserved.\n constexpr std::array kUnsupportedOps = {\n     // clang-format off\n     // go/keep-sorted start\n     HloOpcode::kDynamicReshape,\n+    HloOpcode::kDynamicSlice,\n     HloOpcode::kDynamicUpdateSlice,\n     HloOpcode::kGather,\n     HloOpcode::kRaggedDot,\n     HloOpcode::kReduceWindow,\n+    HloOpcode::kScaledDot,\n     HloOpcode::kScatter,\n     HloOpcode::kSelectAndScatter,\n     HloOpcode::kSetDimensionSize,\n     // go/keep-sorted end\n     // clang-format on\n };\n \n+// This function returns the set of opcodes that have explicit corresponding\n+// tests in this file. *DO NOT* add opcodes here unless you're also adding\n+// sufficiently exhaustive tests for them.\n+//\n+// Also prefer to create `kTestedOps*` constants capturing each opcode group,\n+// in order to help ascertain that opcodes are not mistakenly added here and\n+// left untested.\n absl::flat_hash_set<HloOpcode> AllTestedOpcodes() {\n   absl::flat_hash_set<HloOpcode> ret;\n   ret.insert(kTestedOpsBitcastReshape.begin(), kTestedOpsBitcastReshape.end());\n@@ -3462,7 +3512,6 @@ absl::flat_hash_set<HloOpcode> AllTestedOpcodes() {\n   ret.emplace(HloOpcode::kCustomCall);\n   ret.emplace(HloOpcode::kDomain);\n   ret.emplace(HloOpcode::kDot);\n-  ret.emplace(HloOpcode::kDynamicSlice);  // TODO(b/417172838): add tests.\n   ret.emplace(HloOpcode::kFft);\n   ret.emplace(HloOpcode::kFusion);\n   ret.emplace(HloOpcode::kGetDimensionSize);\n@@ -3473,7 +3522,6 @@ absl::flat_hash_set<HloOpcode> AllTestedOpcodes() {\n   ret.emplace(HloOpcode::kReverse);\n   ret.emplace(HloOpcode::kRngBitGenerator);\n   ret.emplace(HloOpcode::kRngGetAndUpdateState);\n-  ret.emplace(HloOpcode::kScaledDot);\n   ret.emplace(HloOpcode::kSort);\n   ret.emplace(HloOpcode::kStochasticConvert);\n   ret.emplace(HloOpcode::kTopK);"
        },
        {
            "sha": "d5d8b9f1ed19bc0f2da15da09e5649ccaf26386c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -37,19 +37,18 @@ cc_library(\n         \"round_f32_to_tf32_for_tf32_dot_pass.cc\",\n         \"triton_xla_extract_insert_to_triton_pass.cc\",\n         \"triton_xla_fold_transpose_pass.cc\",\n+        \"triton_xla_lower_get_tid_pass.cc\",\n         \"triton_xla_squeeze_dims_pass.cc\",\n     ],\n     hdrs = [\"passes.h\"],\n     deps = [\n         \":passes_inc_gen\",\n         \"//xla:permutation_util\",\n-        \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla/backends/gpu/codegen/triton:emitter_helpers\",\n         \"//xla/backends/gpu/codegen/triton/ir:triton_xla\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/codegen/emitters/ir:xla\",\n-        \"//xla/hlo/analysis:indexing_analysis\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\","
        },
        {
            "sha": "8bd7312fa52d9a2c0f144ea7f090290105d3866f",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/int4_passes.cc",
            "status": "modified",
            "additions": 66,
            "deletions": 33,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fint4_passes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fint4_passes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fint4_passes.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"llvm/ADT/DenseSet.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n@@ -39,7 +40,6 @@ limitations under the License.\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n-#include \"mlir/IR/ImplicitLocOpBuilder.h\"\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/Operation.h\"\n #include \"mlir/IR/OperationSupport.h\"\n@@ -217,30 +217,45 @@ class TritonXlaExtractOpConversionPattern\n         getTypeConverter()->convertType(op.getType()));\n \n     ImplicitLocOpBuilder builder(op.getLoc(), r);\n-    // We can safely assume these are static because they were checked in\n-    // GetPackedDimension.\n-    SmallVector<int64_t, 2> tile_strides(adaptor.getStaticStrides());\n \n-    // The stride of the i8 tensor is half of the i4 tensor but at least 1.\n-    SmallVector<Value, 2> tile_strides_values;\n-    for (auto stride : tile_strides) {\n-      tile_strides_values.push_back(builder.create<ma::ConstantOp>(\n-          builder.getIndexAttr(ceil(stride / 2.0))));\n+    std::optional<llvm::SmallDenseSet<unsigned>> optional_mask =\n+        computeRankReductionMask(op.getStaticSizes(), op.getType().getShape());\n+    if (!optional_mask) {\n+      return r.notifyMatchFailure(op, \"Unsupported rank reduction.\");\n+    }\n+    // Convert the packed dimension to the rank-expanded src type.\n+    int packed_dimension = converter_.packed_dimension();\n+    for (auto dim : *optional_mask) {\n+      if (dim > packed_dimension) {\n+        break;\n+      }\n+      ++packed_dimension;\n     }\n \n-    // We update the offset of the packed dimension to be half of the original\n-    // offset.\n-    SmallVector<Value, 2> tile_offsets_values = op.getOffsetsAsValues(builder);\n-    tile_offsets_values[converter_.packed_dimension()] =\n-        div(r, tile_offsets_values[converter_.packed_dimension()], 2);\n+    // We update values of the packed dimension to be half of the original.\n+    SmallVector<Value> offsets = op.getOffsetsAsValues(builder);\n+    offsets[packed_dimension] = div(r, offsets[packed_dimension], 2);\n+\n+    // We checked in GetPackedDimension that the sizes are static and\n+    // the packed dimension is even.\n+    SmallVector<int64_t> sizes(op.getStaticSizes());\n+    sizes[packed_dimension] = sizes[packed_dimension] / 2;\n+\n+    // We checked in GetPackedDimension that the strides are static and\n+    // the packed dimension is one.\n+    SmallVector<int64_t> strides(op.getStaticStrides());\n \n-    SmallVector<int64_t> shape = llvm::to_vector(adaptor.getSrcShape());\n-    shape[converter_.packed_dimension()] =\n-        (shape[converter_.packed_dimension()] + 1) / 2;\n+    SmallVector<int64_t> src_shape(adaptor.getSrcShape());\n+    src_shape[packed_dimension] = (src_shape[packed_dimension] + 1) / 2;\n \n-    r.replaceOpWithNewOp<mtx::ExtractOp>(\n-        op, new_result_type, adaptor.getSrc(), tile_offsets_values,\n-        tile_strides_values, shape, adaptor.getSrcLayout());\n+    // Note: above, we assume that offsets are even, which we check only if it's\n+    // static. We also assume that the residual size is even, which we don't\n+    // check at all. TODO(csigg): see IsOffsetDivisibilityGuaranteed() for how\n+    // we could cover more cases. For the others, maybe emit a cf.assert.\n+\n+    r.replaceOpWithNewOp<mtx::ExtractOp>(op, new_result_type, adaptor.getSrc(),\n+                                         offsets, sizes, op.getStaticStrides(),\n+                                         src_shape, adaptor.getSrcLayout());\n     return success();\n   }\n \n@@ -614,30 +629,48 @@ absl::StatusOr<int> GetPackedDimension(MLIRContext *ctx,\n \n     if (extract_op) {\n       // Make sure the packed dimension is not dynamic and has a stride of 1.\n-      auto tile_strides = extract_op.getStaticStrides();\n-      auto tile_sizes = extract_op.getStaticSizes();\n-      auto original_shape = extract_op.getSrcShape();\n+      auto offsets = extract_op.getStaticOffsets();\n+      auto sizes = extract_op.getStaticSizes();\n+      auto strides = extract_op.getStaticStrides();\n \n-      if (mlir::ShapedType::isDynamicShape(tile_strides) ||\n-          mlir::ShapedType::isDynamicShape(tile_sizes) ||\n-          mlir::ShapedType::isDynamicShape(original_shape)) {\n+      if (ShapedType::isDynamicShape(strides) ||\n+          ShapedType::isDynamicShape(sizes)) {\n         return absl::InvalidArgumentError(\n             \"dynamic shapes, tile strides, and tile sizes not supported\");\n       }\n \n       for (auto dim : extract_op.getSrcLayout()) {\n-        if (tile_strides[dim] == 1 && tile_sizes[dim] > 1 &&\n-            original_shape[dim] > 1) {\n-          return dim;\n+        if (extract_op.getSrcShape()[dim] == 1) {\n+          continue;\n+        }\n+        if (strides[dim] != 1) {\n+          return absl::InvalidArgumentError(\n+              \"Minor-most non-unit dimension has non-unit stride.\");\n+        }\n+        if (sizes[dim] % 2 != 0) {\n+          return absl::InvalidArgumentError(\n+              \"Minor-most non-unit dimension has odd size.\");\n+        }\n+        if (!ShapedType::isDynamic(offsets[dim]) && offsets[dim] % 2 != 0) {\n+          return absl::InvalidArgumentError(\n+              \"Minor-most non-unit dimension has odd offset.\");\n+        }\n+        std::optional<llvm::SmallDenseSet<unsigned>> optional_mask =\n+            computeRankReductionMask(sizes, extract_op.getType().getShape());\n+        if (!optional_mask) {\n+          return absl::InvalidArgumentError(\"Unsupported rank reduction.\");\n         }\n+        auto mask = llvm::to_vector(*optional_mask);\n+        // Convert the packed dimension to the rank-reduced dst type.\n+        return dim - (absl::c_upper_bound(mask, dim) - mask.begin());\n       }\n \n       return absl::InvalidArgumentError(\"Failed to find a packed dimension.\");\n     }\n   }\n   std::string not_found_message =\n       \"No MakeTensorPtrOp or mlir::triton::xla::ExtractOp found\";\n-  LOG(FATAL) << not_found_message;\n+  LOG(ERROR) << not_found_message;\n   return absl::InvalidArgumentError(not_found_message);\n }\n \n@@ -746,7 +779,7 @@ class PlainInt4ToPackedInt4RewritePass\n     normalize_patterns.add(SitofpToExtFpSitofpRewrite);\n     if (failed(applyPatternsGreedily(module, std::move(normalize_patterns)))) {\n       VLOG(5) << \"failed to apply patterns\";\n-      signalPassFailure();\n+      return signalPassFailure();\n     }\n \n     auto ext_ops = FindInt4ExtSIOp(module);\n@@ -760,7 +793,7 @@ class PlainInt4ToPackedInt4RewritePass\n       if (!packed_dimension_result.ok()) {\n         VLOG(5) << \"failed to get packed dimension: \"\n                 << packed_dimension_result.status();\n-        signalPassFailure();\n+        return signalPassFailure();\n       };\n       packed_dimension = packed_dimension_result.value();\n     }\n@@ -803,7 +836,7 @@ class PlainInt4ToPackedInt4RewritePass\n         patterns, converter);\n     if (failed(applyPartialConversion(module, target, std::move(patterns)))) {\n       VLOG(5) << \"failed to apply partial conversion\";\n-      signalPassFailure();\n+      return signalPassFailure();\n     }\n   }\n   // The default value is true, which means that bf16x2 instructions are used"
        },
        {
            "sha": "2f8efd9cf030a91416fbf6df016be55a9c1c3a4f",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -40,6 +40,7 @@ std::unique_ptr<mlir::Pass> CreateInt4ToPackedInt4RewritePass(\n     const stream_executor::DeviceDescription& device_description);\n std::unique_ptr<mlir::Pass> CreateRoundF32ToTF32ForTf32DotRewritePass();\n std::unique_ptr<mlir::Pass> CreateExtractTmaInfoPass();\n+std::unique_ptr<mlir::Pass> CreateTritonXLALowerGetTidPass();\n \n // Returns true if the `op` contains an operation in it's regions that satisfies\n // the `fn`."
        },
        {
            "sha": "935ad48be46ae3f89d021f22f9c0b4872650c8aa",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -38,7 +38,8 @@ def TritonXLASqueezeDimsPass : Pass<\"triton-xla-squeeze-dims\", \"mlir::ModuleOp\">\n     This pass tries to remove size-1 dimensions from tensors.\n   }];\n   let dependentDialects = [\n-    \"::mlir::triton::xla::XlaTritonDialect\"\n+    \"::mlir::triton::xla::XlaTritonDialect\",\n+    \"triton::TritonDialect\"\n   ];\n   let options = [\n     Option<\"finalize_\", \"finalize\", \"bool\", \"true\",\n@@ -104,4 +105,14 @@ def RoundF32ToTF32ForTf32DotRewritePass\n   let constructor = \"CreateRoundF32ToTF32ForTf32DotRewritePass()\";\n }\n \n+def TritonXLALowerGetTidPass\n+    : Pass<\"triton-xla-get-tid\", \"mlir::ModuleOp\"> {\n+  let summary = \"Lower get_tid to the PTX intrinsic.\";\n+  let description = [{\n+    This pass lowers get_tid to the PTX intrinsic by loading the thread ID from\n+    the register and returning it.\n+  }];\n+  let constructor = \"CreateTritonXLALowerGetTidPass()\";\n+}\n+\n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_PASSES_TD_"
        },
        {
            "sha": "153d844599b98fcbfdf96f9952b12073a6d2bceb",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/int4_packed_dim.mlir",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fint4_packed_dim.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fint4_packed_dim.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fint4_packed_dim.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -116,12 +116,12 @@ tt.func @major_3d(%arg0: !tt.ptr<i4>) -> (tensor<8x8x8xi8>) {\n // CHECK-LABEL: @triton_xla_extract_2d\n func.func @triton_xla_extract_2d(%arg0: !tt.ptr<i4>) -> (tensor<16x16xi8>) {\n   // CHECK: %[[EXTRACT:.*]] = triton_xla.extract from %arg0\n-  // CHECK-SAME: as memref<128x64xi8, #triton_xla.layout<[1, 0]>>\n-  // CHECK-SAME: [0, 0] [16, 8] [1, 1] : tensor<16x8xi8>\n+  // CHECK-SAME: as memref<128x8x64xi8, #triton_xla.layout<[2, 1, 0]>>\n+  // CHECK-SAME: [0, 0, 0] [16, 1, 8] [1, 1, 1] : tensor<16x8xi8>\n   %c0 = arith.constant 0 : index\n   %extracted_tensor = triton_xla.extract from %arg0\n-      as memref<128x128xi4, #triton_xla.layout<[1, 0]>>\n-      [0, %c0] [16, 16] [1, 1] : tensor<16x16xi4>\n+      as memref<128x8x128xi4, #triton_xla.layout<[2, 1, 0]>>\n+      [0, 0, %c0] [16, 1, 16] [1, 1, 1] : tensor<16x16xi4>\n   %ext = arith.extsi %extracted_tensor : tensor<16x16xi4> to tensor<16x16xi8>\n   // CHECK: %[[SHLI:.*]] = arith.shli %[[EXTRACT]]\n   // CHECK: %[[SHRI_LO:.*]] = arith.shrsi %[[SHLI]]"
        },
        {
            "sha": "fc20b19831ea5b02330ea44389a80bc5f87da72e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_extract_insert_to_triton.mlir",
            "status": "modified",
            "additions": 50,
            "deletions": 86,
            "changes": 136,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -8,30 +8,27 @@\n \n func.func @lower_extract_insert(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n   %extracted_tensor = triton_xla.extract from %arg0\n-      as memref<512x128xbf16, #triton_xla.layout<[1, 0]>>\n-      [0, 0] [16, 64] [1, 1] : tensor<16x64xbf16>\n+      as memref<512x8x128xbf16, #triton_xla.layout<[2, 1, 0]>>\n+      [0, 3, 0] [16, 1, 64] [1, 1, 1] : tensor<16x64xbf16>\n   triton_xla.insert %extracted_tensor into %arg1\n-      as memref<256x256xbf16, #triton_xla.layout<[1, 0]>>\n-      [0, 0] [16, 64] [1, 1] : tensor<16x64xbf16>\n+      as memref<256x16x256xbf16, #triton_xla.layout<[2, 1, 0]>>\n+      [0, 5, 0] [16, 1, 64] [1, 1, 1] : tensor<16x64xbf16>\n   func.return\n }\n \n-// CHECK-LABEL: tt.func @lower_extract_insert\n-// CHECK-SAME:  %[[ARG_0:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %[[ARG_1:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}\n-// CHECK:         %[[ADDPTR_0:.*]] = tt.addptr %[[ARG_0]]\n-// CHECK:         %[[PTR_0:.*]] = tt.make_tensor_ptr %[[ADDPTR_0]]\n-// CHECK:         %[[LOAD:.*]] = tt.load %[[PTR_0]]\n-// CHECK:         %[[ADDPTR_1:.*]] = tt.addptr %[[ARG_1]]\n-// CHECK:         %[[PTR_1:.*]] = tt.make_tensor_ptr %[[ADDPTR_1]]\n-// CHECK:         tt.store %[[PTR_1]], %[[LOAD]]\n-// CHECK:       tt.return\n+// CHECK-LABEL: tt.func @lower_extract_insert(\n+// CHECK-SAME:      %arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32},\n+// CHECK-SAME:      %arg1: !tt.ptr<bf16> {tt.divisibility = 16 : i32}) {\n+// CHECK:         %[[LOAD:.*]] = tt.load\n+// CHECK:         tt.store {{.*}}, %[[LOAD]]\n+// CHECK:         tt.return\n \n // CHECK-TMA-LABEL: tt.func @lower_extract_insert\n-// CHECK-TMA-SAME:  %[[ARG_0:.*]]: !tt.tensordesc<tensor<16x64xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [512, 128], tile_shape = [16, 64], tile_strides = [1, 1], layout = [1, 0], element_byte_size = 2>},\n-// CHECK-TMA-SAME:  %[[ARG_1:.*]]: !tt.tensordesc<tensor<16x64xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [256, 256], tile_shape = [16, 64], tile_strides = [1, 1], layout = [1, 0], element_byte_size = 2>}\n-// CHECK-TMA:    %[[LOAD:.*]] = tt.descriptor_load %[[ARG_0]]\n-// CHECK-TMA:    tt.descriptor_store %[[ARG_1]][{{.*}}], %[[LOAD]]\n-// CHECK-TMA:    tt.return\n+// CHECK-TMA-SAME:      %arg0: !tt.tensordesc<tensor<16x1x64xbf16>>\n+// CHECK-TMA-SAME:      %arg1: !tt.tensordesc<tensor<16x1x64xbf16>>\n+// CHECK-TMA:         %[[LOAD:.*]] = tt.descriptor_load %arg0\n+// CHECK-TMA:         tt.descriptor_store %arg1[{{.*}}],\n+// CHECK-TMA:         tt.return\n \n // -----\n \n@@ -46,10 +43,8 @@ func.func @non_perfect_tile_shape(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n }\n \n // CHECK-LABEL: tt.func @non_perfect_tile_shape\n-// CHECK:        tt.load {{.*}} {\n-// CHECK-SAME:     boundaryCheck = array<i32: 0, 1>, padding = 1 : i32\n-// CHECK:        tt.store {{.*}}, {{.*}} {\n-// CHECK-SAME:     boundaryCheck = array<i32: 0, 1>\n+// CHECK:         %[[LOAD:.*]] = tt.load {{.*}}, %{{.*}}, %{{.*}} :\n+// CHECK:         tt.store {{.*}}, %[[LOAD]], %{{.*}} :\n \n // -----\n \n@@ -64,9 +59,7 @@ func.func @incompatible_tma_global_strides(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<\n }\n \n // CHECK-TMA-LABEL: tt.func @incompatible_tma_global_strides\n-// CHECK-TMA:         tt.make_tensor_ptr\n // CHECK-TMA:         tt.load\n-// CHECK-TMA:         tt.make_tensor_ptr\n // CHECK-TMA:         tt.store\n \n // -----\n@@ -78,7 +71,7 @@ module {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32xf32>\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<64xf32, #triton_xla.layout<[0]>>\n@@ -95,10 +88,8 @@ module {\n \n // CHECK-LABEL:   tt.func @slice_with_tiling_that_needs_padding_has_boundary_checks\n // CHECK-COUNT-1: tt.load\n-// CHECK:         tt.store\n-// CHECK-SAME:    boundaryCheck = array<i32: 0>\n-// CHECK:         tt.store\n-// CHECK-SAME:    boundaryCheck = array<i32: 0>\n+// CHECK:         tt.store {{.*}}, %{{.*}}, %{{.*}}\n+// CHECK:         tt.store {{.*}}, %{{.*}}, %{{.*}}\n \n // -----\n \n@@ -109,7 +100,7 @@ module {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32xf32>\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<64xf32, #triton_xla.layout<[0]>>\n@@ -126,10 +117,8 @@ module {\n \n // CHECK-LABEL:   tt.func @slice_with_extra_output_that_can_reuse_tile_due_to_padding\n // CHECK-COUNT-1: tt.load\n-// CHECK:         tt.store\n-// CHECK-SAME:    boundaryCheck = array<i32: 0>\n-// CHECK:         tt.store\n-// CHECK-NOT:     boundaryCheck = array<i32: 0>\n+// CHECK:         tt.store {{.*}}, %{{.*}}, %{{.*}}\n+// CHECK:         tt.store {{.*}}, %{{.*}} :\n \n // -----\n \n@@ -145,27 +134,6 @@ func.func @extract_with_non_unit_minor_dim_stride(%arg0: !tt.ptr<bf16>,\n }\n \n // CHECK-LABEL: tt.func @extract_with_non_unit_minor_dim_stride\n-// CHECK-TMA:   tt.make_tensor_ptr\n-// CHECK-TMA:   tt.load\n-// CHECK-TMA:   tt.descriptor_store\n-\n-// -----\n-\n-func.func @extract_with_non_static_strides(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n-  %0 = tt.get_program_id x : i32\n-  %1 = arith.extsi %0 : i32 to i64\n-  %2 = arith.index_castui %1 : i64 to index\n-  %extracted_tensor = triton_xla.extract from %arg0\n-      as memref<1024x1024xbf16, #triton_xla.layout<[1, 0]>>\n-      [0, 0] [16, 64] [%2, 1] : tensor<16x64xbf16>\n-  triton_xla.insert %extracted_tensor into %arg1\n-      as memref<256x256xbf16, #triton_xla.layout<[1, 0]>>\n-      [0, 0] [16, 64] [1, 1] : tensor<16x64xbf16>\n-  func.return\n-}\n-\n-// CHECK-LABEL: tt.func @extract_with_non_static_strides\n-// CHECK-TMA:   tt.make_tensor_ptr\n // CHECK-TMA:   tt.load\n // CHECK-TMA:   tt.descriptor_store\n \n@@ -182,19 +150,18 @@ func.func @lower_extract_insert_1d(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n }\n \n // CHECK-LABEL: tt.func @lower_extract_insert_1d\n-// CHECK-SAME:  %[[ARG_0:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %[[ARG_1:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}\n-// CHECK:         %[[PTR_0:.*]] = tt.make_tensor_ptr %[[ARG_0]]\n-// CHECK:         %[[LOAD:.*]] = tt.load %[[PTR_0]]\n-// CHECK:         %[[PTR_1:.*]] = tt.make_tensor_ptr %[[ARG_1]]\n-// CHECK:         tt.store %[[PTR_1]], %[[LOAD]]\n-// CHECK:       tt.return\n+// CHECK-SAME:      %arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32},\n+// CHECK-SAME:      %arg1: !tt.ptr<bf16> {tt.divisibility = 16 : i32}\n+// CHECK:         %[[LOAD:.*]] = tt.load\n+// CHECK:         tt.store {{.*}}, %[[LOAD]]\n+// CHECK:         tt.return\n \n // CHECK-TMA-LABEL: tt.func @lower_extract_insert_1d\n-// CHECK-TMA-SAME:  %[[ARG_0:.*]]: !tt.tensordesc<tensor<16xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [128], tile_shape = [16], tile_strides = [1], layout = [0], element_byte_size = 2>},\n-// CHECK-TMA-SAME:  %[[ARG_1:.*]]: !tt.tensordesc<tensor<16xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [256], tile_shape = [16], tile_strides = [1], layout = [0], element_byte_size = 2>}\n-// CHECK-TMA:    %[[LOAD:.*]] = tt.descriptor_load %[[ARG_0]]\n-// CHECK-TMA:    tt.descriptor_store %[[ARG_1]][{{.*}}], %[[LOAD]]\n-// CHECK-TMA:    tt.return\n+// CHECK-TMA-SAME:      %arg0: !tt.tensordesc<tensor<16xbf16>>\n+// CHECK-TMA-SAME:      %arg1: !tt.tensordesc<tensor<16xbf16>>\n+// CHECK-TMA:         %[[LOAD:.*]] = tt.descriptor_load %arg0\n+// CHECK-TMA:         tt.descriptor_store %arg1[{{.*}}], %[[LOAD]]\n+// CHECK-TMA:         tt.return\n \n // -----\n \n@@ -209,21 +176,18 @@ func.func @lower_extract_insert_5d(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n }\n \n // CHECK-LABEL: tt.func @lower_extract_insert_5d\n-// CHECK-SAME:  %[[ARG_0:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}, %[[ARG_1:.*]]: !tt.ptr<bf16> {tt.divisibility = 16 : i32}\n-// CHECK:         %[[ADDPTR_0:.*]] = tt.addptr %[[ARG_0]]\n-// CHECK:         %[[PTR_0:.*]] = tt.make_tensor_ptr %[[ADDPTR_0]]\n-// CHECK:         %[[LOAD:.*]] = tt.load %[[PTR_0]]\n-// CHECK:         %[[ADDPTR_1:.*]] = tt.addptr %[[ARG_1]]\n-// CHECK:         %[[PTR_1:.*]] = tt.make_tensor_ptr %[[ADDPTR_1]]\n-// CHECK:         tt.store %[[PTR_1]], %[[LOAD]]\n-// CHECK:       tt.return\n+// CHECK-SAME:      %arg0: !tt.ptr<bf16> {tt.divisibility = 16 : i32},\n+// CHECK-SAME:      %arg1: !tt.ptr<bf16> {tt.divisibility = 16 : i32}\n+// CHECK:         %[[LOAD:.*]] = tt.load\n+// CHECK:         tt.store {{.*}}, %[[LOAD]]\n+// CHECK:         tt.return\n \n // CHECK-TMA-LABEL: tt.func @lower_extract_insert_5d\n-// CHECK-TMA-SAME:  %[[ARG_0:.*]]: !tt.tensordesc<tensor<8x8x8x8x8xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [16, 16, 16, 16, 16], tile_shape = [8, 8, 8, 8, 8], tile_strides = [1, 1, 1, 1, 1], layout = [4, 3, 2, 1, 0], element_byte_size = 2>},\n-// CHECK-TMA-SAME:  %[[ARG_1:.*]]: !tt.tensordesc<tensor<8x8x8x8x8xbf16>> {tt.nv_tma_desc = 1 : i32, tt.tma_descriptor = #triton_xla.tma_descriptor<global_shape = [32, 32, 32, 32, 32], tile_shape = [8, 8, 8, 8, 8], tile_strides = [1, 1, 1, 1, 1], layout = [4, 3, 2, 1, 0], element_byte_size = 2>}\n-// CHECK-TMA:    %[[LOAD:.*]] = tt.descriptor_load %[[ARG_0]]\n-// CHECK-TMA:    tt.descriptor_store %[[ARG_1]][{{.*}}], %[[LOAD]]\n-// CHECK-TMA:    tt.return\n+// CHECK-TMA-SAME:      %arg0: !tt.tensordesc<tensor<8x8x8x8x8xbf16>>\n+// CHECK-TMA-SAME:      %arg1: !tt.tensordesc<tensor<8x8x8x8x8xbf16>>\n+// CHECK-TMA:         %[[LOAD:.*]] = tt.descriptor_load %arg0\n+// CHECK-TMA:         tt.descriptor_store %arg1[{{.*}}], %[[LOAD]]\n+// CHECK-TMA:         tt.return\n \n // -----\n \n@@ -238,7 +202,8 @@ func.func @extract_insert_with_zero_stride(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<\n }\n \n // CHECK-TMA-LABEL: tt.func @extract_insert_with_zero_stride\n-// CHECK-TMA-SAME:  %[[ARG_0:.*]]: !tt.tensordesc{{.*}} tile_strides = [1, 1], {{.*}} %[[ARG_1:.*]]: !tt.tensordesc{{.*}} tile_strides = [1, 1]\n+// CHECK-TMA-SAME:      %arg0: !tt.tensordesc<tensor<1x64xbf16>>\n+// CHECK-TMA-SAME:      %arg1: !tt.tensordesc<tensor<1x64xbf16>>\n \n // -----\n \n@@ -254,9 +219,8 @@ func.func @incompatible_tma_const_offset_not_divisible_by_16_bytes(\n }\n \n // CHECK-TMA-LABEL: tt.func @incompatible_tma_const_offset_not_divisible_by_16_bytes\n-// CHECK-TMA:   tt.make_tensor_ptr\n-// CHECK-TMA:   tt.load\n-// CHECK-TMA:   tt.descriptor_store\n+// CHECK-TMA:         tt.load\n+// CHECK-TMA:         tt.descriptor_store\n \n // -----\n \n@@ -268,7 +232,7 @@ module {\n             %arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<16x16xbf16, #triton_xla.layout<[1, 0]>>\n@@ -284,5 +248,5 @@ module {\n }\n \n // CHECK-TMA-LABEL: tt.func @incompatible_tma_dynamic_offset_not_divisible_by_16_bytes\n-// CHECK-TMA:   tt.make_tensor_ptr\n-// CHECK-TMA:   tt.load\n+// CHECK-TMA:         tt.load\n+// CHECK-TMA:         tt.descriptor_store"
        },
        {
            "sha": "9dada12395378e9cb59232a0f31e16630a167124",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_fold_transpose.mlir",
            "status": "modified",
            "additions": 15,
            "deletions": 56,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,71 +1,30 @@\n // RUN: xla-opt %s --triton-xla-fold-transpose | FileCheck %s\n \n-// CHECK-LABEL: func @fold_transpose_of_load_ptr\n-tt.func @fold_transpose_of_load_ptr(%arg0: !tt.ptr<f32>, %arg1: i32) -> tensor<8x4xf32> {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  // CHECK:      %[[PTR:.*]] = tt.make_tensor_ptr %arg0,\n-  // CHECK-SAME:     [%c8_i64, %c4_i64], [%c1_i64, %c8_i64], [%c0_i32, %c0_i32]\n-  // CHECK-SAME:     {order = array<i32: 1, 0>} : <tensor<8x4xf32>>\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c8_i64], [%c8_i64, %c1_i64], [%c0_i32, %c0_i32] {order = array<i32: 1, 0>} : <tensor<4x8xf32>>\n-  // CHECK:      %[[LOAD:.*]] = tt.load %[[PTR]]\n-  // CHECK-SAME:     {boundaryCheck = array<i32: 0>, padding = 1 : i32} : !tt.ptr<tensor<8x4xf32>>\n-  %1 = tt.load %0 {boundaryCheck = array<i32: 1>, padding = 1 : i32} : !tt.ptr<tensor<4x8xf32>>\n-  // CHECK-NOT:  tt.trans\n-  %2 = tt.trans %1 {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n-  tt.return %2 : tensor<8x4xf32>\n-}\n-\n-// CHECK-LABEL: func @fold_transpose_of_load_ptr_with_mask\n-tt.func @fold_transpose_of_load_ptr_with_mask(%arg0: !tt.ptr<f32>, %arg1: tensor<4x8xi1>) -> tensor<8x4xf32> {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c8_i64], [%c8_i64, %c1_i64], [%c0_i32, %c0_i32] {order = array<i32: 2, 1, 0>} : <tensor<4x8xf32>>\n-  // CHECK: tt.load {{.*}}, %arg1 : !tt.ptr<tensor<4x8xf32>>\n-  %1 = tt.load %0, %arg1 : !tt.ptr<tensor<4x8xf32>>\n-  // CHECK: tt.trans\n-  %2 = tt.trans %1 {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n-  tt.return %2 : tensor<8x4xf32>\n+// CHECK-LABEL: func @fold_transpose_of_extract\n+func.func @fold_transpose_of_extract(%arg0: !tt.ptr<f32>, %arg1: i32) -> tensor<8x4xf32> {\n+  // CHECK: %[[EXTRACT:.*]] = triton_xla.extract from %arg0\n+  // CHECK-SAME: as memref<16x8x4xf32, #triton_xla.layout<[0, 2, 1]>>\n+  // CHECK-SAME: [0, 0, 0] [8, 1, 4] [1, 1, 1] : tensor<8x4xf32>\n+  %0 = triton_xla.extract from %arg0\n+    as memref<4x8x16xf32, #triton_xla.layout<[2, 0, 1]>>\n+    [0, 0, 0] [4, 1, 8] [1, 1, 1] : tensor<4x8xf32>\n+  %1 = tt.trans %0 {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n+  // CHECK: return %[[EXTRACT]] : tensor<8x4xf32>\n+  return %1 : tensor<8x4xf32>\n }\n \n // CHECK-LABEL: func @push_transpose_up_through_elementwise\n-tt.func @push_transpose_up_through_elementwise(%arg0: tensor<4x8xf32>) -> tensor<8x4xf32> {\n+func.func @push_transpose_up_through_elementwise(%arg0: tensor<4x8xf32>) -> tensor<8x4xf32> {\n   // CHECK: arith.negf {{.*}} : tensor<8x4xf32>\n   %0 = arith.negf %arg0 : tensor<4x8xf32>\n   %1 = tt.trans %0 {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n-  tt.return %1 : tensor<8x4xf32>\n+  return %1 : tensor<8x4xf32>\n }\n \n // CHECK-LABEL: func @push_transpose_up_through_reshape\n-tt.func @push_transpose_up_through_reshape(%arg0: tensor<4x8x2xf32>) -> tensor<16x4xf32> {\n+func.func @push_transpose_up_through_reshape(%arg0: tensor<4x8x2xf32>) -> tensor<16x4xf32> {\n   // CHECK: tt.reshape {{.*}} : tensor<8x2x4xf32> -> tensor<16x4xf32>\n   %0 = tt.reshape %arg0 : tensor<4x8x2xf32> -> tensor<4x16xf32>\n   %1 = tt.trans %0 {order = array<i32: 1, 0>} : tensor<4x16xf32> -> tensor<16x4xf32>\n-  tt.return %1 : tensor<16x4xf32>\n-}\n-\n-// CHECK-LABEL: func @push_transpose_up_through_join_of_inline_asm\n-tt.func @push_transpose_up_through_join_of_inline_asm(%arg0: tensor<4x8xf32>) -> tensor<8x4x2xf32> {\n-  // CHECK: tt.elementwise_inline_asm {{.*}} : tensor<8x4xf32> -> tensor<8x4xf32>, tensor<8x4xf32>\n-  %0:2 = tt.elementwise_inline_asm \"\" {constraints = \"\", packed_element = 1 : i32, pure = true} %arg0 : tensor<4x8xf32> -> tensor<4x8xf32>, tensor<4x8xf32>\n-  // CHECK: tt.join {{.*}} : tensor<8x4xf32> -> tensor<8x4x2xf32>\n-  %1 = tt.join %0#0, %0#1 : tensor<4x8xf32> -> tensor<4x8x2xf32>\n-  %2 = tt.trans %1 {order = array<i32: 1, 0, 2>} : tensor<4x8x2xf32> -> tensor<8x4x2xf32>\n-  tt.return %2 : tensor<8x4x2xf32>\n-}\n-\n-// CHECK-LABEL: func @push_transpose_up_through_int4_unpack\n-tt.func @push_transpose_up_through_int4_unpack(%arg0: tensor<8x4xi8>) -> tensor<4x16xbf16> {\n-  // CHECK: tt.trans {{.*}} : tensor<8x4xi8> -> tensor<4x8xi8>\n-  // CHECK-NOT: tt.trans\n-  %0:2 = tt.elementwise_inline_asm \"\" {constraints = \"\", packed_element = 1 : i32, pure = true} %arg0 : tensor<8x4xi8> -> tensor<8x4xbf16>, tensor<8x4xbf16>\n-  %1 = tt.join %0#0, %0#1 : tensor<8x4xbf16> -> tensor<8x4x2xbf16>\n-  %2 = tt.trans %1 {order = array<i32: 0, 2, 1>} : tensor<8x4x2xbf16> -> tensor<8x2x4xbf16>\n-  %3 = tt.reshape %2 : tensor<8x2x4xbf16> -> tensor<16x4xbf16>\n-  %4 = tt.trans %3 {order = array<i32: 1, 0>} : tensor<16x4xbf16> -> tensor<4x16xbf16>\n-  tt.return %4 : tensor<4x16xbf16>\n+  return %1 : tensor<16x4xf32>\n }"
        },
        {
            "sha": "9b0f728111a8b836f8c3a4b83f609779cb9b05d3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_get_tid.mlir",
            "status": "added",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_get_tid.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_get_tid.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_get_tid.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,11 @@\n+// RUN: xla-opt %s --triton-xla-get-tid | FileCheck %s\n+\n+// CHECK-LABEL: tt.func @kernel()\n+tt.func @kernel() -> i32 {\n+  // CHECK-NOT: triton_xla.get_flat_tid\n+  // CHECK: %[[TID:.*]] = tt.elementwise_inline_asm\n+  // CHECK-SAME: mov.u32 $0, %tid.x;\n+  // CHECK: tt.return %[[TID]] : i32\n+  %0 = triton_xla.get_tid : () -> i32\n+  tt.return %0 : i32\n+}\n\\ No newline at end of file"
        },
        {
            "sha": "6359143e9f7e6f7d5d1c050f3f306705120f1327",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_squeeze_dims.mlir",
            "status": "modified",
            "additions": 74,
            "deletions": 135,
            "changes": 209,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -5,57 +5,57 @@\n // RUN: | FileCheck %s --check-prefix=FINALIZE\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_elementwise\n-tt.func @push_squeeze_dims_up_through_elementwise(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n+func.func @push_squeeze_dims_up_through_elementwise(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n   // CHECK: arith.negf {{.*}} : tensor<4x8xf32>\n   %0 = arith.negf %arg0 : tensor<4x1x8xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %1 : tensor<4x8xf32>\n+  return %1 : tensor<4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_multiple_results\n-tt.func @push_squeeze_dims_up_through_multiple_results(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n+func.func @push_squeeze_dims_up_through_multiple_results(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n   // CHECK: tt.elementwise_inline_asm {{.*}} : tensor<4x8xf32> -> tensor<4x8xf32>, tensor<4x8xf32>\n   %0:2 = tt.elementwise_inline_asm \"\" {constraints = \"\", packed_element = 1 : i32, pure = true} %arg0 : tensor<4x1x8xf32> -> tensor<4x1x8xf32>, tensor<4x1x8xf32>\n   %1 = triton_xla.squeeze_dims %0#0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %1 : tensor<4x8xf32>\n+  return %1 : tensor<4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_broadcast\n-tt.func @push_squeeze_dims_up_through_broadcast(%arg0: tensor<1x4x1x8xf32>) -> tensor<4x16x8xf32> {\n+func.func @push_squeeze_dims_up_through_broadcast(%arg0: tensor<1x4x1x8xf32>) -> tensor<4x16x8xf32> {\n   // CHECK: tt.broadcast {{.*}} : tensor<4x1x8xf32> -> tensor<4x16x8xf32>\n   %0 = tt.broadcast %arg0 : tensor<1x4x1x8xf32> -> tensor<1x4x16x8xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 0 : i32} : tensor<1x4x16x8xf32> -> tensor<4x16x8xf32>\n-  tt.return %1 : tensor<4x16x8xf32>\n+  return %1 : tensor<4x16x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_trans\n-tt.func @push_squeeze_dims_up_through_trans(%arg0: tensor<4x1x8xf32>) -> tensor<8x4xf32> {\n+func.func @push_squeeze_dims_up_through_trans(%arg0: tensor<4x1x8xf32>) -> tensor<8x4xf32> {\n   // CHECK: tt.trans {{.*}} {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n   %0 = tt.trans %arg0 {order = array<i32: 2, 0, 1>} : tensor<4x1x8xf32> -> tensor<8x4x1xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 2 : i32} : tensor<8x4x1xf32> -> tensor<8x4xf32>\n-  tt.return %1 : tensor<8x4xf32>\n+  return %1 : tensor<8x4xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_join\n-tt.func @push_squeeze_dims_up_through_join(%arg0: tensor<1x4xf32>, %arg1: tensor<1x4xf32>) -> tensor<4x2xf32> {\n+func.func @push_squeeze_dims_up_through_join(%arg0: tensor<1x4xf32>, %arg1: tensor<1x4xf32>) -> tensor<4x2xf32> {\n   // CHECK-DAG: tt.join {{.*}} : tensor<4xf32> -> tensor<4x2xf32>\n   %0 = tt.join %arg0, %arg1 : tensor<1x4xf32> -> tensor<1x4x2xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 0 : i32} : tensor<1x4x2xf32> -> tensor<4x2xf32>\n-  tt.return %1 : tensor<4x2xf32>\n+  return %1 : tensor<4x2xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_reduce\n-tt.func @push_squeeze_dims_up_through_reduce(%arg0: tensor<8x4x1xf32>) -> tensor<8xf32> {\n+func.func @push_squeeze_dims_up_through_reduce(%arg0: tensor<8x4x1xf32>) -> tensor<8xf32> {\n   // CHECK: \"tt.reduce\"({{.*}}) <{axis = 1 : i32}> ({\n   %0 = \"tt.reduce\"(%arg0) <{axis = 1 : i32}> ({\n   ^bb0(%arg1: f32, %arg2: f32):\n@@ -64,59 +64,59 @@ tt.func @push_squeeze_dims_up_through_reduce(%arg0: tensor<8x4x1xf32>) -> tensor\n   // CHECK: }) : (tensor<8x4xf32>) -> tensor<8xf32>\n   }) : (tensor<8x4x1xf32>) -> tensor<8x1xf32>\n   %2 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<8x1xf32> -> tensor<8xf32>\n-  tt.return %2 : tensor<8xf32>\n+  return %2 : tensor<8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @fold_squeeze_of_expand_cancelling\n-tt.func @fold_squeeze_of_expand_cancelling(%arg0: tensor<4x8xf32>) -> tensor<4x8xf32> {\n+func.func @fold_squeeze_of_expand_cancelling(%arg0: tensor<4x8xf32>) -> tensor<4x8xf32> {\n   // CHECK-NOT: tt.expand_dims\n   // CHECK-NOT: triton_xla.squeeze_dims\n   %0 = tt.expand_dims %arg0 {axis = 1 : i32} : tensor<4x8xf32> -> tensor<4x1x8xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %1 : tensor<4x8xf32>\n+  return %1 : tensor<4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @fold_squeeze_of_expand_swapping\n-tt.func @fold_squeeze_of_expand_swapping(%arg0: tensor<4x1x8xf32>) -> tensor<1x4x8xf32> {\n+func.func @fold_squeeze_of_expand_swapping(%arg0: tensor<4x1x8xf32>) -> tensor<1x4x8xf32> {\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n   // CHECK: tt.expand_dims {{.*}} {axis = 0 : i32} : tensor<4x8xf32> -> tensor<1x4x8xf32>\n   %0 = tt.expand_dims %arg0 {axis = 0 : i32} : tensor<4x1x8xf32> -> tensor<1x4x1x8xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 2 : i32} : tensor<1x4x1x8xf32> -> tensor<1x4x8xf32>\n-  tt.return %1 : tensor<1x4x8xf32>\n+  return %1 : tensor<1x4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @squeeze_reshape\n-tt.func @squeeze_reshape(%arg0: tensor<4x1x1xf32>) -> tensor<4xf32> {\n+func.func @squeeze_reshape(%arg0: tensor<4x1x1xf32>) -> tensor<4xf32> {\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 1 : i32} : tensor<4x1x1xf32> -> tensor<4x1xf32>\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 1 : i32} : tensor<4x1xf32> -> tensor<4xf32>\n   %0 = tt.reshape %arg0 : tensor<4x1x1xf32> -> tensor<4xf32>\n-  tt.return %0 : tensor<4xf32>\n+  return %0 : tensor<4xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @expand_reshape\n-tt.func @expand_reshape(%arg0: tensor<4xf32>) -> tensor<4x1x1xf32> {\n+func.func @expand_reshape(%arg0: tensor<4xf32>) -> tensor<4x1x1xf32> {\n   %0 = tt.reshape %arg0 : tensor<4xf32> -> tensor<4x1x1xf32>\n   // CHECK: tt.expand_dims {{.*}} {axis = 1 : i32} : tensor<4xf32> -> tensor<4x1xf32>\n   // CHECK: tt.expand_dims {{.*}} {axis = 1 : i32} : tensor<4x1xf32> -> tensor<4x1x1xf32>\n-  tt.return %0 : tensor<4x1x1xf32>\n+  return %0 : tensor<4x1x1xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @skip_reshape_with_attr\n-tt.func @skip_reshape_with_attr(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n+func.func @skip_reshape_with_attr(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n   // CHECK-NOT: triton_xla.squeeze_dims\n   // CHECK: tt.reshape {{.*}} allow_reorder : tensor<4x1xf32> -> tensor<4xf32>\n   %0 = tt.reshape %arg0 allow_reorder : tensor<4x1xf32> -> tensor<4xf32>\n-  tt.return %0 : tensor<4xf32>\n+  return %0 : tensor<4xf32>\n }\n \n // -----\n@@ -126,140 +126,81 @@ tt.func @skip_reshape_with_attr(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n module attributes {\"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 1 : i32} {\n // CHECK-LABEL: func @reshape_with_encoding\n // CHECK-SAME:    tensor<1x32xf32, #[[ARG_ENC:.+]]>) -> tensor<32xf32, #[[RES_ENC:.+]]>\n-tt.func @reshape_with_encoding(%arg0: tensor<1x32xf32, #arg_enc>) -> tensor<32xf32, #res_enc> {\n+func.func @reshape_with_encoding(%arg0: tensor<1x32xf32, #arg_enc>) -> tensor<32xf32, #res_enc> {\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 0 : i32} :\n   // CHECK-SAME: tensor<1x32xf32, #[[ARG_ENC]]> -> tensor<32xf32, #[[RES_ENC]]>\n   %0 = tt.reshape %arg0 : tensor<1x32xf32, #arg_enc> -> tensor<32xf32, #res_enc>\n-  tt.return %0 : tensor<32xf32, #res_enc>\n+  return %0 : tensor<32xf32, #res_enc>\n }\n }\n \n // -----\n \n-// CHECK-LABEL: func @fold_squeeze_dims_of_load_ptr\n-tt.func @fold_squeeze_dims_of_load_ptr(%arg0: !tt.ptr<f32>, %arg1: i32) -> tensor<4x8xf32> {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c3_i32 = arith.constant 3 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  %c16_i64 = arith.constant 16 : i64\n-  %c128_i64 = arith.constant 128 : i64\n-  // CHECK: %[[ADDPTR:.*]] = tt.addptr %arg0, %c24_i64\n-  // CHECK: tt.make_tensor_ptr %[[ADDPTR]], {{.*}} {order = array<i32: 1, 0>} : <tensor<4x8xf32>>\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c16_i64, %c8_i64], [%c128_i64, %c8_i64, %c1_i64], [%c0_i32, %c3_i32, %c0_i32] {order = array<i32: 2, 1, 0>} : <tensor<4x1x8xf32>>\n-  // CHECK: tt.load {{.*}} {boundaryCheck = array<i32: 1>, padding = 1 : i32} : !tt.ptr<tensor<4x8xf32>>\n-  %1 = tt.load %0 {boundaryCheck = array<i32: 2>, padding = 1 : i32} : !tt.ptr<tensor<4x1x8xf32>>\n-  // CHECK-NOT: triton_xla.squeeze_dims\n-  %2 = triton_xla.squeeze_dims %1 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %2 : tensor<4x8xf32>\n-}\n-\n-// -----\n-\n-// CHECK-LABEL: func @squeeze_dims_of_load_ptr_with_boundary_check\n-tt.func @squeeze_dims_of_load_ptr_with_boundary_check(%arg0: !tt.ptr<f32>) -> tensor<4x8xf32> {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c1_i64, %c8_i64], [%c8_i64, %c8_i64, %c1_i64], [%c0_i32, %c0_i32, %c0_i32] {order = array<i32: 2, 1, 0>} : <tensor<4x1x8xf32>>\n-  // CHECK: tt.load {{.*}} {boundaryCheck = array<i32: 1>} : !tt.ptr<tensor<4x1x8xf32>>\n-  %1 = tt.load %0 {boundaryCheck = array<i32: 1>} : !tt.ptr<tensor<4x1x8xf32>>\n-  // CHECK: triton_xla.squeeze_dims\n-  %2 = triton_xla.squeeze_dims %1 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %2 : tensor<4x8xf32>\n-}\n-\n-// -----\n-\n-// CHECK-LABEL: func @squeeze_dims_of_load_ptr_with_mask\n-tt.func @squeeze_dims_of_load_ptr_with_mask(%arg0: !tt.ptr<f32>, %arg1: tensor<4x1x8xi1>) -> tensor<4x8xf32> {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c1_i64, %c8_i64], [%c8_i64, %c8_i64, %c1_i64], [%c0_i32, %c0_i32, %c0_i32] {order = array<i32: 2, 1, 0>} : <tensor<4x1x8xf32>>\n-  // CHECK: tt.load {{.*}}, %arg1 : !tt.ptr<tensor<4x1x8xf32>>\n-  %1 = tt.load %0, %arg1 : !tt.ptr<tensor<4x1x8xf32>>\n-  // CHECK: triton_xla.squeeze_dims\n-  %2 = triton_xla.squeeze_dims %1 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %2 : tensor<4x8xf32>\n+// CHECK-LABEL: func @fold_squeeze_dims_of_extract\n+func.func @fold_squeeze_dims_of_extract(%arg0: !tt.ptr<f32>, %arg1: i32) -> tensor<4x8xf32> {\n+  // CHECK: %[[EXTRACT:.*]] = triton_xla.extract from %arg0\n+  // CHECK-SAME: as memref<4x16x8xf32, #triton_xla.layout<[2, 1, 0]>>\n+  // CHECK-SAME: [0, 3, 0] [4, 1, 8] [1, 1, 1] : tensor<4x8xf32>\n+  %0 = triton_xla.extract from %arg0\n+    as memref<4x16x8xf32, #triton_xla.layout<[2, 1, 0]>>\n+    [0, 3, 0] [4, 1, 8] [1, 1, 1] : tensor<4x1x8xf32>\n+  %1 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n+  // CHECK: return %[[EXTRACT]]\n+  return %1 : tensor<4x8xf32>\n }\n \n // -----\n \n-// CHECK-LABEL: func @squeeze_store\n-tt.func @squeeze_store(%arg0: !tt.ptr<f32>, %arg1: tensor<4x1x8xf32>) {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c3_i32 = arith.constant 3 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %c8_i64 = arith.constant 8 : i64\n-  %c16_i64 = arith.constant 16 : i64\n-  %c128_i64 = arith.constant 128 : i64\n-  // CHECK-DAG: triton_xla.squeeze_dims {{.*}} {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  // CHECK-DAG: %[[ADDPTR:.*]] = tt.addptr %arg0, %c24_i64\n-  // CHECK-DAG: tt.make_tensor_ptr %[[ADDPTR]], {{.*}} {order = array<i32: 1, 0>} : <tensor<4x8xf32>>\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c16_i64, %c8_i64], [%c128_i64, %c8_i64, %c1_i64], [%c0_i32, %c3_i32, %c0_i32] {order = array<i32: 2, 1, 0>} : <tensor<4x1x8xf32>>\n-  // CHECK: tt.store {{.*}} {boundaryCheck = array<i32: 1>} : !tt.ptr<tensor<4x8xf32>>\n-  tt.store %0, %arg1 {boundaryCheck = array<i32: 2>} : !tt.ptr<tensor<4x1x8xf32>>\n-  tt.return\n+// CHECK-LABEL: func @squeeze_insert\n+func.func @squeeze_insert(%arg0: !tt.ptr<f32>, %arg1: tensor<4x1x8xf32>) {\n+  // CHECK: %[[SRC:.*]] = triton_xla.squeeze_dims %arg1 {axis = 1 : i32}\n+  // CHECK: triton_xla.insert %[[SRC]] into %arg0\n+  // CHECK-SAME: as memref<4x16x8xf32, #triton_xla.layout<[2, 1, 0]>>\n+  // CHECK-SAME: [0, 3, 0] [4, 1, 8] [1, 1, 1] : tensor<4x8xf32>\n+  triton_xla.insert %arg1 into %arg0\n+    as memref<4x16x8xf32, #triton_xla.layout<[2, 1, 0]>>\n+    [0, 3, 0] [4, 1, 8] [1, 1, 1] : tensor<4x1x8xf32>\n+  return\n }\n \n // -----\n \n-// CHECK-LABEL: func @squeeze_store_unit_tensor\n-tt.func @squeeze_store_unit_tensor(%arg0: !tt.ptr<f32>, %arg1: tensor<1x1xf32>) {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %0 = tt.make_tensor_ptr %arg0, [%c1_i64, %c1_i64], [%c1_i64, %c1_i64], [%c0_i32, %c0_i32] {order = array<i32: 0>} : <tensor<1x1xf32>>\n+// CHECK-LABEL: func @squeeze_insert_unit_tensor\n+func.func @squeeze_insert_unit_tensor(%arg0: !tt.ptr<f32>, %arg1: tensor<1x1xf32>) {\n   // CHECK: triton_xla.squeeze_dims\n-  // CHECK: tt.store {{.*}} : !tt.ptr<tensor<1xf32>>\n-  tt.store %0, %arg1 : !tt.ptr<tensor<1x1xf32>>\n-  tt.return\n-}\n-\n-// -----\n-\n-// CHECK-LABEL: func @squeeze_store_with_mask\n-tt.func @squeeze_store_with_mask(%arg0: !tt.ptr<f32>, %arg1: tensor<4x1xf32>, %arg2: tensor<4x1xi1>) {\n-  %c0_i32 = arith.constant 0 : i32\n-  %c1_i64 = arith.constant 1 : i64\n-  %c4_i64 = arith.constant 4 : i64\n-  %0 = tt.make_tensor_ptr %arg0, [%c4_i64, %c1_i64], [%c1_i64, %c1_i64], [%c0_i32, %c0_i32] {order = array<i32: 0>} : <tensor<4x1xf32>>\n-  // CHECK-NOT: triton_xla.squeeze_dims\n-  // CHECK: tt.store {{.*}} : !tt.ptr<tensor<4x1xf32>>\n-  tt.store %0, %arg1, %arg2 : !tt.ptr<tensor<4x1xf32>>\n-  tt.return\n+  // CHECK: triton_xla.insert {{.*}} : tensor<1xf32>\n+  triton_xla.insert %arg1 into %arg0\n+    as memref<1x1xf32,#triton_xla.layout<[0, 1]>> \n+    [0, 0] [1, 1] [1, 1] : tensor<1x1xf32>\n+  return\n }\n \n // -----\n \n // CHECK-LABEL: func @reorder_squeeze_dims\n-tt.func @reorder_squeeze_dims(%arg0: tensor<4x1x8x1xf32>) -> tensor<4x8xf32> {\n+func.func @reorder_squeeze_dims(%arg0: tensor<4x1x8x1xf32>) -> tensor<4x8xf32> {\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 1 : i32} : tensor<4x1x8x1xf32> -> tensor<4x8x1xf32>\n   // CHECK: triton_xla.squeeze_dims {{.*}} {axis = 2 : i32} : tensor<4x8x1xf32> -> tensor<4x8xf32>\n   %0 = triton_xla.squeeze_dims %arg0 {axis = 3 : i32} : tensor<4x1x8x1xf32> -> tensor<4x1x8xf32>\n   %1 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %1 : tensor<4x8xf32>\n+  return %1 : tensor<4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @diamond\n-tt.func @diamond(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n+func.func @diamond(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n   // CHECK-NOT: arith.negf {{.*}} : tensor<4x1x8xf32>\n   %0 = arith.negf %arg0 : tensor<4x1x8xf32>\n   %1 = arith.addf %0, %0 : tensor<4x1x8xf32>\n   %2 = triton_xla.squeeze_dims %1 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %2 : tensor<4x8xf32>\n+  return %2 : tensor<4x8xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @insert_expand_dims\n-tt.func @insert_expand_dims(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n+func.func @insert_expand_dims(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n   // CHECK: %[[NEGF:.*]] = arith.negf {{.*}} : tensor<4xf32>\n   // CHECK-NOT: arith.negf\n   // CHECK: tt.expand_dims %[[NEGF]] {axis = 1 : i32} : tensor<4xf32> -> tensor<4x1xf32>\n@@ -272,39 +213,37 @@ tt.func @insert_expand_dims(%arg0: tensor<4x1xf32>) -> tensor<4xf32> {\n   %3 = tt.expand_dims %1 {axis = 1 : i32} : tensor<4xf32> -> tensor<4x1xf32>\n   %4 = arith.addf %0, %3 : tensor<4x1xf32>\n   %5 = triton_xla.squeeze_dims %4 {axis = 1 : i32} : tensor<4x1xf32> -> tensor<4xf32>\n-  tt.return %5 : tensor<4xf32>\n+  return %5 : tensor<4xf32>\n }\n \n // -----\n \n // CHECK-LABEL: func @push_squeeze_dims_up_through_if\n-tt.func @push_squeeze_dims_up_through_if(%arg0: tensor<16xf32>,\n-    %arg1: tensor<16xf32>, %arg2: tensor<4x1xf32>, %arg3: tensor<4x1xf32>,\n-    %cond: i1) -> (tensor<16xf32>, tensor<4xf32>) {\n+func.func @push_squeeze_dims_up_through_if(\n+    %arg0: tensor<16xf32>, %arg1: tensor<4x1xf32>, %cond: i1\n+) -> (tensor<16xf32>, tensor<4xf32>) {\n+  // CHECK: scf.if %{{.*}} -> (tensor<16xf32>, tensor<4xf32>) {\n   %if:2 = scf.if %cond -> (tensor<16xf32>, tensor<4x1xf32>) {\n-    scf.yield %arg0, %arg2 : tensor<16xf32>, tensor<4x1xf32>\n+    // CHECK: %[[SQUEEZE:.*]] = triton_xla.squeeze_dims\n+    // CHECK: scf.yield %arg0, %[[SQUEEZE]] : tensor<16xf32>, tensor<4xf32>\n+    scf.yield %arg0, %arg1 : tensor<16xf32>, tensor<4x1xf32>\n   } else {\n-    scf.yield %arg1, %arg3 : tensor<16xf32>, tensor<4x1xf32>\n+    // CHECK: %[[SQUEEZE:.*]] = triton_xla.squeeze_dims\n+    // CHECK: scf.yield %arg0, %[[SQUEEZE]] : tensor<16xf32>, tensor<4xf32>\n+    scf.yield %arg0, %arg1 : tensor<16xf32>, tensor<4x1xf32>\n   }\n+  // CHECK-NOT: triton_xla.squeeze_dims\n   %squeeze = triton_xla.squeeze_dims %if#1 {axis = 1 : i32}\n-    : tensor<4x1xf32> -> tensor<4xf32>\n-  tt.return %if#0, %squeeze : tensor<16xf32>, tensor<4xf32>\n+      : tensor<4x1xf32> -> tensor<4xf32>\n+  // CHECK: return\n+  return %if#0, %squeeze : tensor<16xf32>, tensor<4xf32>\n }\n-// CHECK:        scf.if %{{.*}} -> (tensor<16xf32>, tensor<4xf32>) {\n-// CHECK-NEXT:    %[[SQUEEZE:.*]] = triton_xla.squeeze_dims\n-// CHECK-NEXT:    scf.yield %arg0, %[[SQUEEZE]] : tensor<16xf32>, tensor<4xf32>\n-// CHECK-NEXT:   } else {\n-// CHECK-NEXT:    %[[SQUEEZE:.*]] = triton_xla.squeeze_dims\n-// CHECK-NEXT:    scf.yield %arg1, %[[SQUEEZE]] : tensor<16xf32>, tensor<4xf32>\n-// CHECK-NEXT:  }\n-// CHECK-NOT:   triton_xla.squeeze_dims\n-// CHECK:       tt.return\n \n // -----\n \n // FINALIZE-LABEL: func @squeeze_dims_to_reshape\n-tt.func @squeeze_dims_to_reshape(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n+func.func @squeeze_dims_to_reshape(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32> {\n   // FINALIZE: tt.reshape {{.*}} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n   %0 = triton_xla.squeeze_dims %arg0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n-  tt.return %0 : tensor<4x8xf32>\n+  return %0 : tensor<4x8xf32>\n }"
        },
        {
            "sha": "7c2dac722ba345ed5a62559161ce625076a945f0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_extract_insert_to_triton_pass.cc",
            "status": "modified",
            "additions": 266,
            "deletions": 262,
            "changes": 528,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -14,13 +14,18 @@ limitations under the License.\n ==============================================================================*/\n \n #include <algorithm>\n+#include <cstddef>\n #include <cstdint>\n #include <memory>\n #include <numeric>\n #include <optional>\n #include <utility>\n #include <vector>\n \n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+// Above header needs to be included first to avoid 'major' macro collision.\n+\n+#include \"absl/algorithm/container.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n@@ -31,6 +36,7 @@ limitations under the License.\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/Support/CommandLine.h\"\n #include \"mlir/Analysis/SliceAnalysis.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n #include \"mlir/IR/AffineExpr.h\"\n@@ -52,10 +58,7 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/codegen/emitters/ir/xla_ops.h\"\n-#include \"xla/hlo/analysis/indexing_analysis.h\"\n #include \"xla/permutation_util.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n \n@@ -74,18 +77,12 @@ PointerType GetTensorPtrType(Type type) {\n                           mlir::NVVM::kGlobalMemorySpace);\n }\n \n-bool AreRankedTensors(ArrayRef<Type> types) {\n-  return llvm::all_of(types, [](mlir::Type type) {\n-    return mlir::isa<mlir::RankedTensorType>(type);\n-  });\n-}\n-\n-SmallVector<Value> IndexCastUI(::xla::EmitterLocOpBuilder& builder, Type type,\n-                               ValueRange values) {\n+SmallVector<Value> IndexCast(::xla::EmitterLocOpBuilder& builder, Type type,\n+                             ValueRange values) {\n   SmallVector<Value> result;\n   result.reserve(values.size());\n   for (auto value : values) {\n-    result.push_back(builder.create<arith::IndexCastUIOp>(type, value));\n+    result.push_back(builder.create<arith::IndexCastOp>(type, value));\n   }\n   return result;\n }\n@@ -185,6 +182,7 @@ bool CanUseTma(bool tma_enabled,\n   // used or not.\n   SmallVector<int64_t> canonical_tile_strides(tile_strides.begin(),\n                                               tile_strides.end());\n+  // TODO(csigg): canonicalize_status is ignored.\n   auto canonicalize_status = CanonicalizeTileStrides(canonical_tile_strides,\n                                                      tile_shape, original_shape,\n                                                      /*validate=*/false);\n@@ -214,98 +212,6 @@ bool CanUseTma(bool tma_enabled,\n   return true;\n }\n \n-SmallVector<int32_t> ComputeBoundaryChecks(\n-    const ArrayRef<int64_t>& original_shape,\n-    const ArrayRef<int64_t>& tile_shape) {\n-  SmallVector<int32_t> boundary_checks;\n-  for (auto [dim_idx, sizes] :\n-       llvm::enumerate(llvm::zip(original_shape, tile_shape))) {\n-    auto [dim_size, tile_size] = sizes;\n-    if (dim_size % tile_size) {\n-      boundary_checks.push_back(dim_idx);\n-    }\n-  }\n-  return boundary_checks;\n-}\n-\n-// TensorPtr is intended to wrap the base pointer of the TiledHloInstruction and\n-// the necessary offsets so that Triton can compute the pointer to the\n-// block specific to the given pid. This option would yield simpler code,\n-// but cannot handle all combinations of strides and offsets, because Triton\n-// always multiplies the offset by the stride. E.g., it's not possible to\n-// slice [10] with [1:5:2] because the offset is misaligned with regards to the\n-// stride.\n-//\n-// Instead, we output a TensorPtr that points directly to the tile specific\n-// to the pid. All offset computation is done in advance. MakeTensorPtrOp\n-// sees 0 offsets. This allows Triton to read any block regardless of\n-// strides size or offsets. To make sure that masking is correct, we compute\n-// a \"residual shape\" which is the original parent shape minus the offsets.\n-SmallVector<Value> ComputeResidualShape(::xla::EmitterLocOpBuilder& builder,\n-                                        ArrayRef<int64_t> original_shape,\n-                                        ValueRange tile_offsets) {\n-  SmallVector<Value> residual_shape;\n-  for (auto [dim_idx, shape_and_tile_offset] :\n-       llvm::enumerate(llvm::zip(original_shape, tile_offsets))) {\n-    auto [shape, tile_offset] = shape_and_tile_offset;\n-    Value size =\n-        ::xla::gpu::triton::CreateConst(builder, builder.getI64Type(), shape)\n-            .UnwrapScalar();\n-    // Offsets are necessarily positive since they represent a distance\n-    // between 0 and the size of the tensor on the given axis. Therefore, it\n-    // is safe to use 'IndexCastUI' here. This allows index canonicalizations\n-    // later on.\n-    Value offset =\n-        builder.create<arith::IndexCastUIOp>(builder.getI64Type(), tile_offset);\n-    residual_shape.push_back(builder.create<arith::SubIOp>(size, offset));\n-  }\n-\n-  return residual_shape;\n-}\n-\n-// Compute physical strides of the tile. `tile_strides` contains strides for\n-// individual dimensions. We need to convert them to strides in the buffer\n-// taking into account physical layout. Note that we should pass in the\n-// minor-to-major layout for this to work correctly.\n-SmallVector<Value> ComputeStrides(::xla::EmitterLocOpBuilder& builder,\n-                                  ArrayRef<int64_t> original_shape,\n-                                  ValueRange tile_strides,\n-                                  ArrayRef<int64_t> minor_to_major_layout) {\n-  SmallVector<Value> strides(tile_strides.size());\n-  int64_t current_stride = 1;\n-  for (int64_t cur_dim : minor_to_major_layout) {\n-    strides[cur_dim] = builder.create<arith::MulIOp>(\n-        builder.create<arith::IndexCastUIOp>(builder.getI64Type(),\n-                                             tile_strides[cur_dim]),\n-        ::xla::gpu::triton::CreateConst(builder, builder.getI64Type(),\n-                                        current_stride)\n-            .UnwrapScalar());\n-    current_stride *= original_shape[cur_dim];\n-  }\n-  return strides;\n-}\n-\n-// Based on the multi-dimensional offsets and layout of the shape, we compute\n-// a linear offset. We do this because we move the pointer to the correct\n-// position via tt.addptr prior to calling tt.make_tensor_ptr.\n-Value ComputeLinearOffset(::xla::EmitterLocOpBuilder& builder,\n-                          Type element_type, ValueRange offsets,\n-                          llvm::ArrayRef<int64_t> shape,\n-                          llvm::ArrayRef<int64_t> layout) {\n-  ::xla::Shape xla_shape = ::xla::ShapeUtil::MakeShapeWithDenseLayout(\n-      xgt::GetPrimitiveType(element_type).value(), shape, layout);\n-\n-  ::xla::Shape linear_shape = ::xla::ShapeUtil::MakeShape(\n-      xla_shape.element_type(), {::xla::ShapeUtil::ElementsIn(xla_shape)});\n-  auto bitcast_map =\n-      ::xla::GetBitcastMap(xla_shape, linear_shape, builder.getContext());\n-\n-  return builder.create<arith::IndexCastUIOp>(\n-      builder.getI64Type(),\n-      builder.create<::xla::ApplyIndexingOp>(offsets, bitcast_map)\n-          .getResult(0));\n-}\n-\n // Add TMA attributes to the corresponding argument in the function.\n void AddTmaAttributes(::xla::EmitterLocOpBuilder& builder,\n                       const TypedValue<PointerType>& pointer,\n@@ -328,42 +234,39 @@ void AddTmaAttributes(::xla::EmitterLocOpBuilder& builder,\n           pointer.getType().getPointeeType().getIntOrFloatBitWidth() / 8));\n }\n \n-// Normalized layout is in the form of [N-1, N-2, ... 1, 0]. It is identical\n-// to HLO's layout.\n-bool IsNormalizedLayout(ArrayRef<int64_t> layout) {\n-  for (auto&& [idx, layout_entry] : llvm::enumerate(layout)) {\n-    if (layout_entry != layout.size() - 1 - idx) {\n+// Checks whether 'layout' is the default HLO layout in major-to-minor order,\n+// i.e. iff it's [N-1, N-2, ... 1, 0].\n+bool IsMajorToMinorLayout(ArrayRef<int64_t> layout) {\n+  for (auto [i, value] : llvm::enumerate(layout)) {\n+    if (value != layout.size() - 1 - i) {\n       return false;\n     }\n   }\n   return true;\n }\n \n-// Permutes the given array based on the given layout.\n+// Returns 'values' in major-to-minor order given minor-to-major 'layout'.\n template <typename T>\n-SmallVector<T> NormalizeImpl(ArrayRef<T> values, ArrayRef<int64_t> layout) {\n-  if (IsNormalizedLayout(layout)) {\n+SmallVector<T> GetMajorToMinorOrder(ArrayRef<T> values,\n+                                    ArrayRef<int64_t> layout) {\n+  if (IsMajorToMinorLayout(layout)) {\n     return llvm::to_vector(values);\n   }\n \n   auto reversed_layout = llvm::to_vector(layout);\n   std::reverse(reversed_layout.begin(), reversed_layout.end());\n-  std::vector<T> normalized_values = ::xla::Permute(values, reversed_layout);\n-  return SmallVector<T>(normalized_values.begin(), normalized_values.end());\n-}\n-\n-SmallVector<Value> Normalize(ValueRange values, ArrayRef<int64_t> layout) {\n-  SmallVector<Value> values_vec = llvm::to_vector(values);\n-  return NormalizeImpl<Value>(values_vec, layout);\n+  std::vector<T> vector = ::xla::Permute(values, reversed_layout);\n+  return SmallVector<T>(vector.begin(), vector.end());\n }\n \n-SmallVector<int64_t> Normalize(ArrayRef<int64_t> values,\n-                               ArrayRef<int64_t> layout) {\n-  return NormalizeImpl<int64_t>(values, layout);\n+// Returns 'values' in major-to-minor order given minor-to-major 'layout'.\n+SmallVector<Value> GetMajorToMinorOrder(ValueRange values,\n+                                        ArrayRef<int64_t> layout) {\n+  return GetMajorToMinorOrder(ArrayRef<Value>(llvm::to_vector(values)), layout);\n }\n \n // Given the layout of a tensor, return the inverse permutation required to\n-// transpose an already normalized tensor to the original tensor.\n+// transpose an already major-to-minor tensor to the original tensor.\n SmallVector<int32_t> GetInverseLayoutPermutation(ArrayRef<int64_t> layout) {\n   auto reversed_layout = llvm::to_vector(layout);\n   std::reverse(reversed_layout.begin(), reversed_layout.end());\n@@ -372,45 +275,6 @@ SmallVector<int32_t> GetInverseLayoutPermutation(ArrayRef<int64_t> layout) {\n   return SmallVector<int32_t>(permutation.begin(), permutation.end());\n }\n \n-Value CreateAddPtrOp(::xla::EmitterLocOpBuilder& builder,\n-                     const TypedValue<PointerType>& pointer, ValueRange offsets,\n-                     llvm::ArrayRef<int64_t> shape,\n-                     llvm::ArrayRef<int64_t> layout) {\n-  auto linear_offset = ComputeLinearOffset(\n-      builder, pointer.getType().getPointeeType(), offsets, shape, layout);\n-  return builder.create<AddPtrOp>(pointer.getType(), pointer, linear_offset);\n-}\n-\n-Value CreateMakeTensorPtrOp(::xla::EmitterLocOpBuilder& builder, Value ptr,\n-                            ArrayRef<int64_t> original_shape,\n-                            ArrayRef<int64_t> tile_shape,\n-                            SmallVector<Value> offsets,\n-                            SmallVector<Value> tile_strides,\n-                            ArrayRef<int64_t> layout) {\n-  SmallVector<Value> residual_shape =\n-      ComputeResidualShape(builder, original_shape, offsets);\n-\n-  // Offsets are always passed as 0 since we are using \"residual shape\".\n-  SmallVector<Value> zero_offsets(\n-      tile_shape.size(),\n-      ::xla::gpu::triton::CreateConst(builder, builder.getI32Type(), 0)\n-          .UnwrapScalar());\n-\n-  SmallVector<Value> strides =\n-      ComputeStrides(builder, original_shape, tile_strides, layout);\n-\n-  // Strides already encode the layout, so we can use the default order.\n-  // Note that the order attribute is ignored in the Triton lowering.\n-  SmallVector<int32_t> dim_order(layout.size());\n-  std::iota(dim_order.rbegin(), dim_order.rend(), 0);\n-\n-  return builder\n-      .create<MakeTensorPtrOp>(ptr, residual_shape, strides, zero_offsets,\n-                               llvm::to_vector_of<int32_t>(tile_shape),\n-                               dim_order)\n-      .getResult();\n-}\n-\n // Rewrite func.func to tt.func.\n class RewriteFuncOp : public mlir::OpRewritePattern<func::FuncOp> {\n  public:\n@@ -434,12 +298,12 @@ class RewriteFuncOp : public mlir::OpRewritePattern<func::FuncOp> {\n         auto tma_descriptor = mlir::cast<TmaDescriptorAttr>(attr);\n         auto layout = tma_descriptor.getLayout();\n         auto block_shape = tma_descriptor.getTileShape();\n-        SmallVector<int64_t> normalized_block_shape =\n-            Normalize(block_shape, layout);\n+        SmallVector<int64_t> ordered_block_shape =\n+            GetMajorToMinorOrder(block_shape, layout);\n \n         operand_type = TensorDescType::get(\n             builder.getContext(),\n-            RankedTensorType::get(normalized_block_shape, element_type));\n+            RankedTensorType::get(ordered_block_shape, element_type));\n         // !tt.tensordesc<tensor<block_shape x element_type>> -> !tt.ptr<>\n         cast_to_orig_type = builder.create<mlir::UnrealizedConversionCastOp>(\n             operand_type, func_arg);\n@@ -500,6 +364,140 @@ class RewriteFuncOp : public mlir::OpRewritePattern<func::FuncOp> {\n   }\n };\n \n+// Compute the strides of a dense tensor given its shape and layout.\n+SmallVector<int64_t> ComputeStrides(ArrayRef<int64_t> shape,\n+                                    ArrayRef<int64_t> layout) {\n+  CHECK_EQ(shape.size(), layout.size());\n+  SmallVector<int64_t> result(shape.size());\n+  int64_t stride = 1;\n+  for (int64_t dim : layout) {\n+    result[dim] = stride;\n+    stride *= shape[dim];\n+  }\n+  return result;\n+}\n+\n+// Returns the set of not-reduced dimensions.\n+SmallVector<unsigned> GetRetainedDims(ArrayRef<unsigned> reduced_dims,\n+                                      size_t rank) {\n+  SmallVector<unsigned> result;\n+  result.reserve(rank);\n+  for (auto [i, dim] : llvm::enumerate(reduced_dims)) {\n+    for (unsigned j = result.size() + i; j < dim; ++j) {\n+      result.push_back(j);\n+    }\n+  }\n+  while (result.size() < rank) {\n+    result.push_back(result.size() + reduced_dims.size());\n+  }\n+  return result;\n+}\n+\n+// Expands the value in all dimensions except `dim` and broadcasts the result\n+// to the provided tile shape.\n+Value ExpandAndBroadcastValue(::xla::EmitterLocOpBuilder& builder, Value value,\n+                              int dim, RankedTensorType tile_type) {\n+  for (int i = 0; i < tile_type.getRank(); ++i) {\n+    if (i != dim) {\n+      value = builder.create<ExpandDimsOp>(value, i);\n+    }\n+  }\n+  return BroadcastOp::create(builder, tile_type, value);\n+}\n+\n+// Returns a pair of tensors:\n+// - The first tensor is a tensor of pointers to load/store.\n+// - The second tensor is a tensor of in-bounds predicates.\n+static std::pair<Value, Value> CreateTensorOfPointersAndMask(\n+    ::xla::EmitterLocOpBuilder& builder, Value base_ptr,\n+    ArrayRef<int64_t> original_shape, ArrayRef<int64_t> layout,\n+    ValueRange offsets, ArrayRef<int64_t> sizes, ArrayRef<int64_t> strides,\n+    ArrayRef<unsigned> reduced_dims, ArrayRef<int64_t> tile_shape) {\n+  CHECK_EQ(original_shape.size(), layout.size());\n+  CHECK_EQ(original_shape.size(), offsets.size());\n+  CHECK_EQ(original_shape.size(), sizes.size());\n+  CHECK_EQ(original_shape.size(), strides.size());\n+  CHECK_EQ(original_shape.size(), reduced_dims.size() + tile_shape.size());\n+\n+  SmallVector<int64_t> shape_strides = ComputeStrides(original_shape, layout);\n+  SmallVector<unsigned> retained_dims =\n+      GetRetainedDims(reduced_dims, tile_shape.size());\n+\n+  Type i64_type = builder.getI64Type();\n+  auto i64_tile_type = RankedTensorType::get(tile_shape, i64_type);\n+\n+  // Combines the values using op, if rhs is present. Otherwise returns lhs.\n+  auto add_if = [&](auto op, Value lhs, Value rhs) -> Value {\n+    if (rhs) {\n+      return decltype(op)::create(builder, lhs.getType(), lhs, rhs);\n+    }\n+    return lhs;\n+  };\n+\n+  SmallVector<Value> cast_offsets = IndexCast(builder, i64_type, offsets);\n+\n+  Value range_tile, mask_tile;\n+  for (auto [i, dim] : llvm::enumerate(retained_dims)) {\n+    auto i64_row_type = RankedTensorType::get({sizes[dim]}, i64_type);\n+\n+    // Create iota range row tensor.\n+    Value range = MakeRangeOp::create(\n+        builder, i64_row_type.clone(builder.getI32Type()), 0, sizes[dim]);\n+    range = arith::ExtSIOp::create(builder, i64_row_type, range);\n+\n+    // Multiply range by tile stride.\n+    Value stride = arith::ConstantOp::create(\n+        builder, DenseIntElementsAttr::get(i64_row_type, strides[dim]));\n+    range = arith::MulIOp::create(builder, range, stride);\n+\n+    // Expand and broadcast range to tile shape.\n+    range = ExpandAndBroadcastValue(builder, range, i, i64_tile_type);\n+\n+    Value mask;\n+    if (original_shape[dim] % sizes[dim] != 0) {\n+      // Imperfect tiling, create a mask for values that are inside bounds.\n+      Value upper_bound =\n+          arith::ConstantIntOp::create(builder, i64_type, original_shape[dim]);\n+      upper_bound =\n+          arith::SubIOp::create(builder, upper_bound, cast_offsets[dim]);\n+      upper_bound = SplatOp::create(builder, i64_tile_type, upper_bound);\n+      mask = arith::CmpIOp::create(builder, arith::CmpIPredicate::slt, range,\n+                                   upper_bound);\n+\n+      // Combine mask with previous iteration.\n+      mask_tile = add_if(arith::AndIOp(), mask, mask_tile);\n+    }\n+\n+    // Multiply range by shape strides.\n+    Value shape_stride = arith::ConstantOp::create(\n+        builder, DenseIntElementsAttr::get(i64_tile_type, shape_strides[dim]));\n+    range = arith::MulIOp::create(builder, range, shape_stride);\n+\n+    // Combine range with previous iteration.\n+    range_tile = add_if(arith::AddIOp(), range, range_tile);\n+  }\n+\n+  // Sum up block-uniform offsets multiplied by strides.\n+  Value block_offset;\n+  for (auto [cast_offset, shape_stride] :\n+       llvm::zip_equal(cast_offsets, shape_strides)) {\n+    Value offset = arith::MulIOp::create(\n+        builder, cast_offset,\n+        arith::ConstantIntOp::create(builder, i64_type, shape_stride));\n+    // Combine offset with previous iteration.\n+    block_offset = add_if(arith::AddIOp(), offset, block_offset);\n+  }\n+  // Add the accumulated offsets to the base pointer.\n+  Value block_ptr = add_if(AddPtrOp(), base_ptr, block_offset);\n+\n+  // Splat block-uniform pointer and add range offsets.\n+  auto ptr_tile_type = RankedTensorType::get(tile_shape, base_ptr.getType());\n+  Value ptr_tile = SplatOp::create(builder, ptr_tile_type, block_ptr);\n+  ptr_tile = add_if(AddPtrOp(), ptr_tile, range_tile);\n+\n+  return std::make_pair(ptr_tile, mask_tile);\n+}\n+\n class RewriteExtract : public mlir::OpRewritePattern<ExtractOp> {\n  public:\n   RewriteExtract(mlir::MLIRContext* context,\n@@ -519,7 +517,7 @@ class RewriteExtract : public mlir::OpRewritePattern<ExtractOp> {\n   // With TMA:\n   // tt.descriptor_load.\n   // Offsets are resolved in tt.descriptor_load.\n-  // If the layout is not normalized, we insert a transpose to ensure that\n+  // If the layout is not major-to-minor, we insert a transpose to ensure that\n   // the tile loaded in both TMA and non-TMA cases is the same:\n   // tt.descriptor_load + tt.transpose.\n   mlir::LogicalResult matchAndRewrite(\n@@ -531,64 +529,67 @@ class RewriteExtract : public mlir::OpRewritePattern<ExtractOp> {\n     ArrayRef<int64_t> src_layout = op.getSrcLayout();\n \n     auto offsets = op.getOffsetsAsValues(builder);\n-    if (CanUseTma(tma_enabled_, *device_description_, src_shape, tile_shape,\n-                  op.getStaticStrides(), offsets, op.getSrc(), src_layout)) {\n-      SmallVector<int64_t> strides = llvm::to_vector(op.getStaticStrides());\n-      if (auto result = CanonicalizeTileStrides(strides, tile_shape, src_shape);\n+    auto sizes = op.getStaticSizes();\n+    auto strides = to_vector(op.getStaticStrides());\n+\n+    if (CanUseTma(tma_enabled_, *device_description_, src_shape, sizes, strides,\n+                  offsets, op.getSrc(), src_layout)) {\n+      if (auto result = CanonicalizeTileStrides(strides, sizes, src_shape);\n           !result.ok()) {\n         return rewriter.notifyMatchFailure(op, result.message());\n       }\n \n-      AddTmaAttributes(builder, op.getSrc(), src_shape, src_layout, tile_shape,\n+      AddTmaAttributes(builder, op.getSrc(), src_shape, src_layout, sizes,\n                        strides);\n \n-      SmallVector<int64_t> normalized_tile_shape =\n-          Normalize(tile_shape, src_layout);\n-      auto normalized_tile_type = RankedTensorType::get(\n-          normalized_tile_shape, tile_type.getElementType());\n-      auto normalized_offsets = Normalize(offsets, src_layout);\n-\n-      // tensor -> !tt.tensordesc<tile_type>\n-      auto cast_to_tensor_desc =\n-          builder\n-              .create<mlir::UnrealizedConversionCastOp>(\n-                  TensorDescType::get(builder.getContext(),\n-                                      normalized_tile_type),\n-                  op.getSrc())\n-              .getResult(0);\n-\n-      auto descriptor_load = builder.create<DescriptorLoadOp>(\n-          normalized_tile_type, cast_to_tensor_desc,\n-          IndexCastUI(builder, builder.getI32Type(), normalized_offsets));\n-\n-      // Insert a transpose if the layout is not normalized.\n-      if (!IsNormalizedLayout(src_layout)) {\n-        // Transpose an already normalized tensor back to the original layout.\n-        auto transpose =\n-            builder.create<TransOp>(op.getType(), descriptor_load,\n-                                    GetInverseLayoutPermutation(src_layout));\n-        rewriter.replaceOp(op, transpose);\n-        return mlir::success();\n+      auto ordered_offsets = GetMajorToMinorOrder(offsets, src_layout);\n+      auto ordered_sizes = GetMajorToMinorOrder(sizes, src_layout);\n+      auto ordered_type =\n+          tile_type.clone(GetMajorToMinorOrder(sizes, src_layout));\n+\n+      // ptr -> !tt.tensordesc<tile_type>\n+      auto desc_type = TensorDescType::get(builder.getContext(), ordered_type);\n+      auto cast_to_tensor_desc = mlir::UnrealizedConversionCastOp::create(\n+          builder, desc_type, op.getSrc());\n+\n+      Value result = DescriptorLoadOp::create(\n+          builder, ordered_type, cast_to_tensor_desc.getResult(0),\n+          IndexCast(builder, builder.getI32Type(), ordered_offsets));\n+\n+      // Insert a transpose if the layout is not major-to-minor.\n+      if (!IsMajorToMinorLayout(src_layout)) {\n+        result = TransOp::create(builder, result,\n+                                 GetInverseLayoutPermutation(src_layout));\n+      }\n+      // Insert a reshape if the result is rank-reduced.\n+      if (sizes.size() != tile_shape.size()) {\n+        result = ReshapeOp::create(builder, tile_shape, result,\n+                                   /*allowReorder=*/false);\n       }\n \n-      rewriter.replaceOp(op, descriptor_load);\n+      rewriter.replaceOp(op, result);\n       return mlir::success();\n     }\n \n-    auto ptr =\n-        CreateAddPtrOp(builder, op.getSrc(), offsets, src_shape, src_layout);\n-    auto strides = op.getStridesAsValues(builder);\n-    ptr = CreateMakeTensorPtrOp(builder, ptr, src_shape, tile_shape, offsets,\n-                                strides, src_layout);\n-    auto boundary_checks = ComputeBoundaryChecks(src_shape, tile_shape);\n-    std::optional<PaddingOption> padding;\n-    if (!boundary_checks.empty()) {\n-      padding = PaddingOption::PAD_ZERO;\n+    // Compute the set of reduced dimensions.\n+    auto reduction_mask = mlir::computeRankReductionMask(sizes, tile_shape);\n+    if (!reduction_mask) {\n+      return rewriter.notifyMatchFailure(op, \"Unsupported rank reduction.\");\n+    }\n+    SmallVector<unsigned> reduced_dims = to_vector(*reduction_mask);\n+    absl::c_sort(reduced_dims);\n+\n+    auto [ptr, mask] = CreateTensorOfPointersAndMask(\n+        builder, op.getSrc(), src_shape, src_layout, offsets, sizes, strides,\n+        reduced_dims, tile_shape);\n+    Value other;\n+    if (mask) {\n+      other = builder.create<arith::ConstantOp>(builder.getZeroAttr(\n+          RankedTensorType::get(tile_shape, tile_type.getElementType())));\n     }\n-    auto load =\n-        builder.create<LoadOp>(ptr, boundary_checks, padding,\n-                               CacheModifier::NONE, EvictionPolicy::NORMAL,\n-                               /*isVolatile=*/false);\n+    auto load = builder.create<LoadOp>(ptr, mask, other, CacheModifier::NONE,\n+                                       EvictionPolicy::NORMAL,\n+                                       /*isVolatile=*/false);\n     rewriter.replaceOp(op, load);\n     return mlir::success();\n   }\n@@ -616,9 +617,9 @@ class RewriteInsert : public mlir::OpRewritePattern<InsertOp> {\n   // With TMA:\n   // tt.descriptor_store.\n   // Offsets are resolved in tt.descriptor_store.\n-  // If the layout is not normalized, we insert a transpose to to be compatible\n-  // with TMA's physical restrictions.\n-  // tt.transpose + tt.descriptor_store.\n+  // If the layout is not major-to-minor, we insert a transpose to to be\n+  // compatible with TMA's physical restrictions. tt.transpose +\n+  // tt.descriptor_store.\n   mlir::LogicalResult matchAndRewrite(\n       InsertOp op, mlir::PatternRewriter& rewriter) const override {\n     ::xla::EmitterLocOpBuilder builder(op.getLoc(), rewriter);\n@@ -628,53 +629,57 @@ class RewriteInsert : public mlir::OpRewritePattern<InsertOp> {\n     ArrayRef<int64_t> dst_layout = op.getDstLayout();\n \n     auto offsets = op.getOffsetsAsValues(builder);\n-    if (CanUseTma(tma_enabled_, *device_description_, dst_shape, tile_shape,\n-                  op.getStaticStrides(), offsets, op.getDst(), dst_layout)) {\n-      SmallVector<int64_t> strides = llvm::to_vector(op.getStaticStrides());\n-      if (auto result = CanonicalizeTileStrides(strides, tile_shape, dst_shape);\n+    auto sizes = op.getStaticSizes();\n+    auto strides = to_vector(op.getStaticStrides());\n+\n+    // Compute the set of reduced dimensions.\n+    auto reduction_mask = mlir::computeRankReductionMask(sizes, tile_shape);\n+    if (!reduction_mask) {\n+      return rewriter.notifyMatchFailure(op, \"Unsupported rank reduction.\");\n+    }\n+    SmallVector<unsigned> reduced_dims = to_vector(*reduction_mask);\n+    absl::c_sort(reduced_dims);\n+\n+    if (CanUseTma(tma_enabled_, *device_description_, dst_shape, sizes, strides,\n+                  offsets, op.getDst(), dst_layout)) {\n+      if (auto result = CanonicalizeTileStrides(strides, sizes, dst_shape);\n           !result.ok()) {\n         return rewriter.notifyMatchFailure(op, result.message());\n       }\n \n-      AddTmaAttributes(builder, op.getDst(), dst_shape, dst_layout, tile_shape,\n+      AddTmaAttributes(builder, op.getDst(), dst_shape, dst_layout, sizes,\n                        strides);\n \n-      SmallVector<int64_t> normalized_tile_shape =\n-          Normalize(tile_shape, dst_layout);\n-      auto normalized_tile_type = RankedTensorType::get(\n-          normalized_tile_shape, tile_type.getElementType());\n-      auto normalized_offsets = Normalize(offsets, dst_layout);\n-\n-      // tensor -> !tt.tensordesc<tile_type>\n-      auto cast_to_tensor_desc =\n-          builder\n-              .create<mlir::UnrealizedConversionCastOp>(\n-                  TensorDescType::get(builder.getContext(),\n-                                      normalized_tile_type),\n-                  op.getDst())\n-              .getResult(0);\n-\n-      // Insert a transpose if the layout is not normalized.\n-      auto src = op.getSrc();\n-      if (!IsNormalizedLayout(dst_layout)) {\n-        // Transpose to a normalized tensor by simply reversing the layout.\n+      // ptr -> !tt.tensordesc<tile_type>\n+      auto desc_type = TensorDescType::get(\n+          builder.getContext(),\n+          tile_type.clone(GetMajorToMinorOrder(sizes, dst_layout)));\n+      auto cast_to_tensor_desc = mlir::UnrealizedConversionCastOp::create(\n+          builder, desc_type, op.getDst());\n+\n+      Value src = op.getSrc();\n+      // Insert a expand_dims if the source is rank-reduced.\n+      for (auto dim : reduced_dims) {\n+        src = ExpandDimsOp::create(builder, src, dim);\n+      }\n+      // Insert a transpose if the layout is not major-to-minor.\n+      if (!IsMajorToMinorLayout(dst_layout)) {\n+        // Transpose to a major-to-minor tensor by simply reversing the layout.\n         auto transpose_order = llvm::to_vector_of<int32_t>(dst_layout);\n         std::reverse(transpose_order.begin(), transpose_order.end());\n-        src = builder.create<TransOp>(normalized_tile_type, op.getSrc(),\n-                                      transpose_order);\n+        src = builder.create<TransOp>(src, transpose_order);\n       }\n-      builder.create<DescriptorStoreOp>(\n-          cast_to_tensor_desc, src,\n-          IndexCastUI(builder, builder.getI32Type(), normalized_offsets));\n+\n+      auto ordered_offsets = GetMajorToMinorOrder(offsets, dst_layout);\n+      DescriptorStoreOp::create(\n+          builder, cast_to_tensor_desc.getResult(0), src,\n+          IndexCast(builder, builder.getI32Type(), ordered_offsets));\n     } else {\n-      auto ptr =\n-          CreateAddPtrOp(builder, op.getDst(), offsets, dst_shape, dst_layout);\n-      auto strides = op.getStridesAsValues(builder);\n-      ptr = CreateMakeTensorPtrOp(builder, ptr, dst_shape, tile_shape, offsets,\n-                                  strides, dst_layout);\n-      builder.create<StoreOp>(ptr, op.getSrc(),\n-                              ComputeBoundaryChecks(dst_shape, tile_shape),\n-                              CacheModifier::NONE, EvictionPolicy::NORMAL);\n+      auto [ptr, mask] = CreateTensorOfPointersAndMask(\n+          builder, op.getDst(), dst_shape, dst_layout, offsets, sizes, strides,\n+          reduced_dims, tile_shape);\n+      StoreOp::create(builder, ptr, op.getSrc(), mask, CacheModifier::NONE,\n+                      EvictionPolicy::NORMAL);\n     }\n     rewriter.eraseOp(op);\n     return mlir::success();\n@@ -700,9 +705,9 @@ class RewriteScalarInsert : public mlir::OpRewritePattern<tensor::InsertOp> {\n     auto cast_dst_to_tensor_ptr_type =\n         builder.create<mlir::UnrealizedConversionCastOp>(ptr_type, op.getDest())\n             .getResult(0);\n-    builder.create<StoreOp>(cast_dst_to_tensor_ptr_type, op.getScalar(),\n-                            /*boundary_checks=*/std::vector<int32_t>{},\n-                            CacheModifier::NONE, EvictionPolicy::NORMAL);\n+    StoreOp::create(builder, cast_dst_to_tensor_ptr_type, op.getScalar(),\n+                    /*boundary_checks=*/std::vector<int32_t>{},\n+                    CacheModifier::NONE, EvictionPolicy::NORMAL);\n     rewriter.replaceOp(op, op.getDest());\n     return mlir::success();\n   }\n@@ -721,13 +726,12 @@ class RewriteScalarExtract : public mlir::OpRewritePattern<tensor::ExtractOp> {\n     }\n     ::xla::EmitterLocOpBuilder builder(op.getLoc(), rewriter);\n     auto ptr_type = GetTensorPtrType(op.getType());\n-    auto cast_src_to_tensor_ptr_type =\n-        builder\n-            .create<mlir::UnrealizedConversionCastOp>(ptr_type, op.getTensor())\n-            .getResult(0);\n-    auto scalar =\n-        builder.create<LoadOp>(cast_src_to_tensor_ptr_type, CacheModifier::NONE,\n-                               EvictionPolicy::NORMAL, /*isVolatile=*/false);\n+    auto cast_src_to_tensor_ptr_type = mlir::UnrealizedConversionCastOp::create(\n+                                           builder, ptr_type, op.getTensor())\n+                                           .getResult(0);\n+    auto scalar = LoadOp::create(builder, cast_src_to_tensor_ptr_type,\n+                                 CacheModifier::NONE, EvictionPolicy::NORMAL,\n+                                 /*isVolatile=*/false);\n     rewriter.replaceOp(op, scalar.getResult());\n     return mlir::success();\n   }"
        },
        {
            "sha": "a62104f679ac8371250f8207c4b84e412b02b6f1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_fold_transpose_pass.cc",
            "status": "modified",
            "additions": 68,
            "deletions": 81,
            "changes": 149,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -13,16 +13,20 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <cstddef>\n #include <cstdint>\n #include <memory>\n+#include <optional>\n #include <type_traits>\n #include <utility>\n \n #include \"absl/algorithm/container.h\"\n #include \"llvm/ADT/ArrayRef.h\"\n+#include \"llvm/ADT/DenseSet.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/OpDefinition.h\"\n #include \"mlir/IR/OperationSupport.h\"\n #include \"mlir/IR/PatternMatch.h\"\n@@ -32,6 +36,7 @@ limitations under the License.\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Support/LogicalResult.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"xla/util.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n@@ -44,56 +49,77 @@ namespace mlir::triton::xla {\n \n namespace {\n \n-template <typename T>\n-auto ApplyPermutation(T input, ArrayRef<int32_t> perm) {\n-  SmallVector<std::decay_t<decltype(*input.begin())>> result;\n-  result.reserve(perm.size());\n-  for (int32_t p : perm) {\n-    result.push_back(input[p]);\n+LogicalResult FoldTransposeOfExtract(TransOp op, PatternRewriter& rewriter) {\n+  auto extract = op.getSrc().getDefiningOp<ExtractOp>();\n+  if (!extract) {\n+    return rewriter.notifyMatchFailure(op, \"Transpose source is not extract.\");\n+  }\n+\n+  // Compute the dimensions dropped from the source.\n+  std::optional<llvm::SmallDenseSet<unsigned>> reduction_mask =\n+      computeRankReductionMask(extract.getStaticSizes(),\n+                               extract.getType().getShape());\n+  if (!reduction_mask) {\n+    return rewriter.notifyMatchFailure(op, \"Unsupported rank reduction.\");\n+  }\n+  SmallVector<unsigned> reduced_dims = to_vector(*reduction_mask);\n+  absl::c_sort(reduced_dims);\n+\n+  // Compute the set of not-reduced dimensions.\n+  size_t dst_rank = extract.getType().getRank();\n+  SmallVector<unsigned> retained_dims;\n+  retained_dims.reserve(dst_rank);\n+  for (auto [i, dim] : llvm::enumerate(reduced_dims)) {\n+    for (unsigned j = retained_dims.size() + i; j < dim; ++j) {\n+      retained_dims.push_back(j);\n+    }\n   }\n-  return result;\n-}\n-\n-LogicalResult FoldTransposeOfLoad(TransOp op, PatternRewriter& rewriter) {\n-  auto load = op.getSrc().getDefiningOp<LoadOp>();\n-  if (!load) {\n-    return rewriter.notifyMatchFailure(op, \"Transpose source is not a load.\");\n+  while (retained_dims.size() < dst_rank) {\n+    retained_dims.push_back(retained_dims.size() + reduced_dims.size());\n   }\n-  auto make_ptr = load.getPtr().getDefiningOp<MakeTensorPtrOp>();\n-  if (!make_ptr) {\n-    return rewriter.notifyMatchFailure(op, \"Expected load of make_tensor_ptr.\");\n+\n+  // Compute the permutation of source dimensions.\n+  size_t src_rank = extract.getSrcShape().size();\n+  SmallVector<int32_t> permutation;\n+  permutation.reserve(src_rank);\n+  for (auto [src_dim, dst_dim] :\n+       llvm::zip_equal(retained_dims, op.getOrder())) {\n+    while (permutation.size() < src_dim) {\n+      permutation.push_back(permutation.size());\n+    }\n+    permutation.push_back(retained_dims[dst_dim]);\n   }\n-  if (load.getMask() || load.getOther()) {\n-    return rewriter.notifyMatchFailure(op, \"Unsupported load.\");\n+  while (permutation.size() < src_rank) {\n+    permutation.push_back(permutation.size());\n   }\n \n-  auto apply_order = [&](auto range) {\n-    return ApplyPermutation(range, op.getOrder());\n+  auto permute = [&](auto range) {\n+    SmallVector<std::decay_t<decltype(*range.begin())>> result;\n+    result.reserve(range.size());\n+    for (int32_t dim : permutation) {\n+      result.push_back(range[dim]);\n+    }\n+    return result;\n   };\n \n-  auto ptr_type =\n-      PointerType::get(op.getType(), make_ptr.getType().getAddressSpace());\n-  auto new_make_ptr = rewriter.create<MakeTensorPtrOp>(\n-      make_ptr.getLoc(), ptr_type, make_ptr.getBase(),\n-      apply_order(make_ptr.getShape()), apply_order(make_ptr.getStrides()),\n-      // Leave original order, it's unused but checked to be default elsewhere.\n-      apply_order(make_ptr.getOffsets()), make_ptr.getOrderAttr());\n-\n-  SmallVector<bool> boundary_check_bits(op.getType().getRank());\n-  for (auto dim : load.getBoundaryCheck()) {\n-    boundary_check_bits[dim] = true;\n-  }\n-  SmallVector<int32_t> new_boundary_check;\n-  for (auto [dim, value] : llvm::enumerate(apply_order(boundary_check_bits))) {\n-    if (value) {\n-      new_boundary_check.push_back(dim);\n-    }\n+  SmallVector<int32_t> inv_permutation(permutation.size());\n+  for (auto [i, dim] : llvm::enumerate(permutation)) {\n+    inv_permutation[dim] = i;\n+  }\n+\n+  SmallVector<int64_t> layout;\n+  layout.reserve(extract.getSrcLayout().size());\n+  for (auto dim : extract.getSrcLayout()) {\n+    layout.push_back(inv_permutation[dim]);\n   }\n-  auto new_load = rewriter.create<LoadOp>(\n-      load.getLoc(), new_make_ptr, new_boundary_check, load.getPadding(),\n-      load.getCache(), load.getEvict(), load.getIsVolatile());\n \n-  rewriter.replaceOp(op, new_load.getResult());\n+  rewriter.replaceOpWithNewOp<ExtractOp>(\n+      op, op.getType(), extract.getSrc(), permute(extract.getMixedOffsets()),\n+      permute(extract.getStaticSizes()), permute(extract.getStaticStrides()),\n+      permute(extract.getSrcShape()), layout);\n+  if (extract->use_empty()) {\n+    rewriter.eraseOp(extract);\n+  }\n   return success();\n }\n \n@@ -181,44 +207,6 @@ LogicalResult PushTransposeUpThroughReshape(TransOp op,\n   return success();\n }\n \n-LogicalResult PushTransposeUpThroughJoinOfInlineAsm(TransOp op,\n-                                                    PatternRewriter& rewriter) {\n-  auto join = op.getSrc().getDefiningOp<JoinOp>();\n-  if (!join) {\n-    return rewriter.notifyMatchFailure(op, \"Transpose source is not a join.\");\n-  }\n-  if (op.getOrder().back() + 1 != op.getOrder().size()) {\n-    return rewriter.notifyMatchFailure(op, \"Transposes last dimension.\");\n-  }\n-  auto inline_asm = join.getLhs().getDefiningOp<ElementwiseInlineAsmOp>();\n-  if (!inline_asm || join.getRhs().getDefiningOp() != inline_asm) {\n-    return rewriter.notifyMatchFailure(op, \"Join source is not an inline asm.\");\n-  }\n-\n-  SmallVector<Value> new_operands;\n-  new_operands.reserve(inline_asm->getNumOperands());\n-  auto order = op.getOrder().drop_back();\n-  for (Value operand : inline_asm->getOperands()) {\n-    if (auto tensor_type = dyn_cast<RankedTensorType>(operand.getType())) {\n-      operand = rewriter.create<TransOp>(inline_asm->getLoc(), operand, order);\n-    }\n-    new_operands.push_back(operand);\n-  }\n-\n-  Operation* new_inline_asm = rewriter.clone(*inline_asm.getOperation());\n-  new_inline_asm->setOperands(new_operands);\n-  for (Value result : new_inline_asm->getResults()) {\n-    if (auto tensor_type = dyn_cast<RankedTensorType>(result.getType())) {\n-      auto shape = ApplyPermutation(tensor_type.getShape(), order);\n-      result.setType(tensor_type.clone(shape));\n-    }\n-  }\n-  rewriter.replaceOpWithNewOp<JoinOp>(op, op.getType(),\n-                                      new_inline_asm->getResults());\n-\n-  return success();\n-}\n-\n class TritonXLAFoldTransposePass\n     : public impl::TritonXLAFoldTransposePassBase<TritonXLAFoldTransposePass> {\n  public:\n@@ -227,10 +215,9 @@ class TritonXLAFoldTransposePass\n  private:\n   void runOnOperation() override {\n     RewritePatternSet patterns(&getContext());\n-    patterns.add(FoldTransposeOfLoad);\n+    patterns.add(FoldTransposeOfExtract);\n     patterns.add(PushTransposeUpThroughElementwise);\n     patterns.add(PushTransposeUpThroughReshape);\n-    patterns.add(PushTransposeUpThroughJoinOfInlineAsm);\n     if (failed(applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n       return signalPassFailure();\n     }"
        },
        {
            "sha": "8ab68caf2cb233b278ae4b628b1ebb84b7800c41",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_get_tid_pass.cc",
            "status": "added",
            "additions": 81,
            "deletions": 0,
            "changes": 81,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_get_tid_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_get_tid_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_get_tid_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,81 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <memory>\n+#include <utility>\n+\n+#include \"absl/strings/string_view.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/Location.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+\n+namespace mlir::triton::xla {\n+\n+#define GEN_PASS_DEF_TRITONXLALOWERGETTIDPASS\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+LogicalResult LowerGetTidOp(GetTidOp get_flat_tid, PatternRewriter& rewriter) {\n+  mlir::OpBuilder::InsertionGuard guard(rewriter);\n+  rewriter.setInsertionPoint(get_flat_tid);\n+  const Location loc = get_flat_tid.getLoc();\n+\n+  const mlir::Type i32_type = rewriter.getI32Type();\n+  const absl::string_view get_tid_asm = R\"(\n+    mov.u32 $0, %tid.x;\n+  )\";\n+  auto tid_op = rewriter.create<mlir::triton::ElementwiseInlineAsmOp>(\n+      loc,\n+      /*result_types=*/i32_type,\n+      /*asm_string=*/rewriter.getStringAttr(get_tid_asm),\n+      /*constraints=*/rewriter.getStringAttr(\"=r\"),\n+      /*pure=*/rewriter.getBoolAttr(true),\n+      /*packed_element=*/rewriter.getI32IntegerAttr(1),\n+      /*args*/ mlir::ValueRange{});\n+  rewriter.replaceOp(get_flat_tid, tid_op->getResults());\n+  return success();\n+}\n+\n+class TritonXLALowerGetTidPass\n+    : public impl::TritonXLALowerGetTidPassBase<TritonXLALowerGetTidPass> {\n+ public:\n+  using Base::Base;\n+\n+ private:\n+  void runOnOperation() override {\n+    RewritePatternSet patterns(&getContext());\n+    patterns.add(LowerGetTidOp);\n+    if (failed(applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      return signalPassFailure();\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<Pass> CreateTritonXLALowerGetTidPass() {\n+  return std::make_unique<TritonXLALowerGetTidPass>();\n+}\n+\n+}  // namespace mlir::triton::xla"
        },
        {
            "sha": "01c2bed678eb630a4ca7d5cacf2e9641f0246e4c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_squeeze_dims_pass.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 101,
            "changes": 124,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n #include <cstdint>\n #include <iterator>\n #include <memory>\n-#include <numeric>\n #include <optional>\n #include <utility>\n \n@@ -46,7 +45,6 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n-#include \"triton/Dialect/Triton/IR/Types.h\"\n \n namespace mlir::triton::xla {\n \n@@ -73,7 +71,7 @@ SmallVector<uint32_t> GetDimsToSqueeze(RankedTensorType type) {\n // Returns the axis of first squeeze_dims user.\n std::optional<uint32_t> GetSqueezeDimsUserAxis(Operation* op) {\n   for (Operation* user : op->getUsers()) {\n-    if (auto op = dyn_cast<SqueezeDimsOp>(user); op) {\n+    if (auto op = dyn_cast<SqueezeDimsOp>(user)) {\n       return op.getAxis();\n     }\n   }\n@@ -109,7 +107,7 @@ void ReplaceOpWithExpandDimsOf(PatternRewriter& rewriter, Operation* op,\n \n // Returns a new container with the given dimensions removed.\n template <typename ContainerT>\n-auto SqueezeElements(ContainerT elements, ArrayRef<uint32_t> squeeze_dims) {\n+auto SqueezeElements(ContainerT&& elements, ArrayRef<uint32_t> squeeze_dims) {\n   CHECK(absl::c_is_sorted(squeeze_dims));\n   auto it = elements.begin();\n   SmallVector<typename std::iterator_traits<decltype(it)>::value_type> result;\n@@ -123,23 +121,6 @@ auto SqueezeElements(ContainerT elements, ArrayRef<uint32_t> squeeze_dims) {\n   return result;\n }\n \n-// Returns a new boundary check with the given dimensions removed.\n-SmallVector<int32_t> SqueezeBoundaryCheck(ArrayRef<int32_t> boundary_check,\n-                                          ArrayRef<uint32_t> squeeze_dims) {\n-  CHECK(absl::c_is_sorted(boundary_check));\n-  CHECK(absl::c_is_sorted(squeeze_dims));\n-  SmallVector<int32_t> result;\n-  auto it = squeeze_dims.begin();\n-  for (int32_t dim : boundary_check) {\n-    it = std::lower_bound(it, squeeze_dims.end(), dim);\n-    if (it != squeeze_dims.end() && *it == dim) {\n-      continue;\n-    }\n-    result.push_back(dim - (it - squeeze_dims.begin()));\n-  }\n-  return result;\n-}\n-\n // Returns a new tensor type with the given dimensions removed.\n RankedTensorType SqueezeTensorType(RankedTensorType type,\n                                    ArrayRef<uint32_t> squeeze_dims) {\n@@ -169,97 +150,38 @@ Value SqueezeTensorValue(PatternRewriter& rewriter, Value value,\n   return value;\n }\n \n-// Returns a new pointer by applying the given offsets and strides for the\n-// given dimensions.\n-Value SqueezePointer(PatternRewriter& rewriter, Location loc, Value base,\n-                     ValueRange offsets, ValueRange strides,\n-                     ArrayRef<uint32_t> squeeze_dims) {\n-  for (auto dim : squeeze_dims) {\n-    Value extsi = rewriter.create<arith::ExtSIOp>(loc, rewriter.getI64Type(),\n-                                                  offsets[dim]);\n-    Value muli = rewriter.create<arith::MulIOp>(loc, extsi, strides[dim]);\n-    base = rewriter.create<AddPtrOp>(loc, base.getType(), base, muli);\n-  }\n-  return base;\n-}\n-\n-// Rewrites tt.make_tensor_ptr with unit dimensions. Returns the\n-// new MakeTensorPtrOp result and the dimensions that were removed.\n-Value SqueezeMakeTensorPtr(PatternRewriter& rewriter, MakeTensorPtrOp op,\n-                           ArrayRef<uint32_t> squeeze_dims) {\n-  auto tensor_type = cast<RankedTensorType>(op.getType().getPointeeType());\n-  auto squeeze_type = SqueezeTensorType(tensor_type, squeeze_dims);\n-  auto ptr_type =\n-      PointerType::get(squeeze_type, op.getType().getAddressSpace());\n-\n-  // Strides already encode the layout, so we can use the default order.\n-  // Note that the order attribute is ignored in the Triton lowering.\n-  SmallVector<int32_t> order(squeeze_type.getShape().size());\n-  std::iota(order.rbegin(), order.rend(), 0);\n-\n-  OpBuilder::InsertionGuard guard = SetInsertionPoint(rewriter, op);\n-  // Add the offsets along the dimensions to squeeze to the base pointer.\n-  Value base = SqueezePointer(rewriter, op.getLoc(), op.getBase(),\n-                              op.getOffsets(), op.getStrides(), squeeze_dims);\n-  return rewriter.create<MakeTensorPtrOp>(\n-      op.getLoc(), ptr_type, base, SqueezeElements(op.getShape(), squeeze_dims),\n-      SqueezeElements(op.getStrides(), squeeze_dims),\n-      SqueezeElements(op.getOffsets(), squeeze_dims), order);\n-}\n-\n-// Folds squeeze_dims into tt.load(tt.make_tensor_ptr).\n-// TODO(csigg): Add support for tt.load(tt.make_tensor_descriptor).\n-LogicalResult FoldSqueezeDimsOfLoad(LoadOp op, PatternRewriter& rewriter) {\n-  if (op.getMask() || op.getOther()) {\n-    return rewriter.notifyMatchFailure(op, \"Unsupported load.\");\n-  }\n+// Folds squeeze_dims into extract.\n+LogicalResult FoldSqueezeDimsOfExtract(ExtractOp op,\n+                                       PatternRewriter& rewriter) {\n   std::optional<uint32_t> axis = GetSqueezeDimsUserAxis(op);\n   if (!axis) {\n     return rewriter.notifyMatchFailure(op, \"No squeeze_dims users.\");\n   }\n-  if (absl::c_contains(op.getBoundaryCheck(), *axis)) {\n-    return rewriter.notifyMatchFailure(op, \"Boundary check contains axis.\");\n-  }\n-  auto make_tensor_ptr = op.getPtr().getDefiningOp<MakeTensorPtrOp>();\n-  if (!make_tensor_ptr) {\n-    return rewriter.notifyMatchFailure(\n-        op, \"Expected ptr to be defined by make_tensor_ptr.\");\n-  }\n \n-  Value pointer = SqueezeMakeTensorPtr(rewriter, make_tensor_ptr, *axis);\n-  Value new_load = rewriter.create<LoadOp>(\n-      op.getLoc(), pointer, SqueezeBoundaryCheck(op.getBoundaryCheck(), *axis),\n-      op.getPadding(), op.getCache(), op.getEvict(), op.getIsVolatile());\n-  ReplaceOpWithExpandDimsOf(rewriter, op, new_load, *axis);\n+  Value new_op = rewriter.create<ExtractOp>(\n+      op.getLoc(), SqueezeTensorType(op.getType(), *axis), op.getSrc(),\n+      op.getMixedOffsets(), op.getStaticSizes(), op.getStaticStrides(),\n+      op.getSrcShape(), op.getSrcLayout());\n+  ReplaceOpWithExpandDimsOf(rewriter, op, new_op, *axis);\n+  rewriter.eraseOp(op);\n   return success();\n }\n \n-// Extracts unit dimensions from tt.store and prepends them as squeeze_dims.\n-LogicalResult SqueezeStore(StoreOp op, PatternRewriter& rewriter) {\n-  if (op.getMask()) {\n-    return rewriter.notifyMatchFailure(op, \"Unsupported store.\");\n-  }\n-  auto make_tensor_ptr = op.getPtr().getDefiningOp<MakeTensorPtrOp>();\n-  if (!make_tensor_ptr) {\n-    return rewriter.notifyMatchFailure(\n-        op, \"Expected ptr to be defined by make_tensor_ptr.\");\n-  }\n-  auto tensor_type = dyn_cast<RankedTensorType>(op.getValue().getType());\n-  if (!tensor_type || tensor_type.getRank() == 0) {\n-    return rewriter.notifyMatchFailure(op, \"Expected tensor type.\");\n+// Extracts unit dimensions from insert and prepends them as squeeze_dims.\n+LogicalResult SqueezeInsert(InsertOp op, PatternRewriter& rewriter) {\n+  if (op.getSrc().getType().getRank() == 0) {\n+    return rewriter.notifyMatchFailure(op, \"Expected non-scalar source.\");\n   }\n \n-  auto squeeze_dims = GetDimsToSqueeze(tensor_type);\n+  auto squeeze_dims = GetDimsToSqueeze(op.getSrc().getType());\n   if (squeeze_dims.empty()) {\n-    return rewriter.notifyMatchFailure(op, \"No unit dimensions.\");\n+    return rewriter.notifyMatchFailure(op, \"No dimensions to squeeze.\");\n   }\n \n-  Value pointer = SqueezeMakeTensorPtr(rewriter, make_tensor_ptr, squeeze_dims);\n-  Value value = SqueezeTensorValue(rewriter, op.getValue(), squeeze_dims);\n-  rewriter.replaceOpWithNewOp<StoreOp>(\n-      op, pointer, value,\n-      SqueezeBoundaryCheck(op.getBoundaryCheck(), squeeze_dims), op.getCache(),\n-      op.getEvict());\n+  Value src = SqueezeTensorValue(rewriter, op.getSrc(), squeeze_dims);\n+  rewriter.replaceOpWithNewOp<InsertOp>(\n+      op, src, op.getDst(), op.getMixedOffsets(), op.getStaticSizes(),\n+      op.getStaticStrides(), op.getDstShape(), op.getDstLayout());\n   return success();\n }\n \n@@ -589,8 +511,8 @@ class TritonXLASqueezeDimsPass\n  private:\n   void runOnOperation() override {\n     RewritePatternSet patterns(&getContext());\n-    patterns.add(FoldSqueezeDimsOfLoad);\n-    patterns.add(SqueezeStore);\n+    patterns.add(FoldSqueezeDimsOfExtract);\n+    patterns.add(SqueezeInsert);\n     patterns.add(SqueezeReshapeOperand);\n     patterns.add(ExpandReshapeResult);\n     patterns.add<PushSqueezeDimsUpThroughElementwise>(&getContext());"
        },
        {
            "sha": "769319c3b490667d77fea0df49ec377cd7fc754a",
            "filename": "third_party/xla/xla/backends/gpu/collectives/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -351,6 +351,7 @@ cc_library(\n         \"//xla/service:global_device_id\",\n         \"//xla/service/gpu:gpu_executable_run_options\",\n         \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:gpu_stream\",\n@@ -360,7 +361,9 @@ cc_library(\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/cleanup\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/debugging:leak_check\",\n         \"@com_google_absl//absl/functional:any_invocable\","
        },
        {
            "sha": "ac652f4a19e75a85bb37b755d5f5040ed3e894da",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator.cc",
            "status": "modified",
            "additions": 88,
            "deletions": 47,
            "changes": 135,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <tuple>\n #include <utility>\n #include <vector>\n \n@@ -31,6 +32,7 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/str_join.h\"\n+#include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n@@ -181,11 +183,12 @@ class NcclCommunicator::NcclRegisteredBufferHandle\n  public:\n   NcclRegisteredBufferHandle(NcclCommunicator& comm, void* handle,\n                              tsl::AsyncValue::Executor* executor,\n-                             bool symmetric_handle)\n+                             bool symmetric_handle, int device_ordinal)\n       : comm_(comm),\n         handle_(handle),\n         executor_(),\n-        symmetric_handle_(symmetric_handle) {}\n+        symmetric_handle_(symmetric_handle),\n+        device_ordinal_(device_ordinal) {}\n \n   ~NcclRegisteredBufferHandle() override {\n     if (auto status = Unregister(); !status.ok()) {\n@@ -195,13 +198,14 @@ class NcclCommunicator::NcclRegisteredBufferHandle\n \n   absl::Status Unregister() final {\n     VLOG(3) << absl::StreamFormat(\n-        \"Deregister buffer for NCCL communicator; handle=%p; comm=%p\", handle_,\n-        comm_.comm_);\n+        \"[%d] Deregister buffer for NCCL communicator; handle=%p; comm=%p\",\n+        device_ordinal_, handle_, comm_.comm_);\n     if (!symmetric_handle_) {\n #if (NCCL_VERSION_CODE >= 21901)\n       auto f = [this]() -> absl::Status {\n         if (comm_.canceling_.load()) {\n-          return FailedPrecondition(\"NcclCommunicator aborted\");\n+          return FailedPrecondition(\"[%d] NcclCommunicator aborted\",\n+                                    device_ordinal_);\n         }\n         XLA_NCCL_RETURN_IF_ERROR(ncclCommDeregister(comm_.comm(), handle_));\n         return comm_.PollUntilDone();\n@@ -211,17 +215,20 @@ class NcclCommunicator::NcclRegisteredBufferHandle\n       }\n       return BlockAndGet(tsl::MakeAsyncValueRef(*executor_, f));\n #else\n-      return Unimplemented(\"NCCL version does not support ncclCommDeregister\");\n+      return Unimplemented(\n+          \"[%d] NCCL version does not support ncclCommDeregister\",\n+          device_ordinal_);\n #endif  // NCCL_VERSION_CODE >= 21901\n     } else {\n       VLOG(3) << absl::StreamFormat(\n-          \"Deregister symmetric buffer for NCCL communicator; handle=%p; \"\n+          \"[%d] Deregister symmetric buffer for NCCL communicator; handle=%p; \"\n           \"comm=%p\",\n-          handle_, comm_.comm_);\n+          device_ordinal_, handle_, comm_.comm_);\n #if (NCCL_VERSION_CODE >= 22700)\n       auto f = [this]() -> absl::Status {\n         if (comm_.canceling_.load()) {\n-          return FailedPrecondition(\"NcclCommunicator aborted\");\n+          return FailedPrecondition(\"[%d] NcclCommunicator aborted\",\n+                                    device_ordinal_);\n         }\n         XLA_NCCL_RETURN_IF_ERROR(\n             ncclCommWindowDeregister(comm_.comm(), *(ncclWindow_t*)(handle_)));\n@@ -233,7 +240,8 @@ class NcclCommunicator::NcclRegisteredBufferHandle\n       return BlockAndGet(tsl::MakeAsyncValueRef(*executor_, f));\n #else\n       return Unimplemented(\n-          \"NCCL version does not support ncclCommWindowDeregister\");\n+          \"[%d] NCCL version does not support ncclCommWindowDeregister\",\n+          device_ordinal_);\n #endif  // NCCL_VERSION_CODE >= 22700\n     }\n   }\n@@ -243,6 +251,7 @@ class NcclCommunicator::NcclRegisteredBufferHandle\n   void* handle_;\n   tsl::AsyncValue::Executor* executor_;\n   bool symmetric_handle_;\n+  int device_ordinal_;\n };\n \n //==-----------------------------------------------------------------------===//\n@@ -347,24 +356,51 @@ absl::StatusOr<size_t> NcclCommunicator::NumRanks() const {\n   }));\n }\n \n-absl::StatusOr<std::unique_ptr<Communicator::RegisteredBufferHandle>>\n-NcclCommunicator::RegisterBuffer(stream_executor::DeviceMemoryBase buffer) {\n-  return RegisterBuffer(buffer, /*use_symmetric_buffer=*/false);\n+absl::Status NcclCommunicator::RegisterBufferOnce(\n+    se::DeviceMemoryBase buffer_range, int device_ordinal,\n+    bool use_symmetric_buffer) {\n+  bool need_reg = false;\n+  {\n+    absl::MutexLock lock(&registered_buffers_.mu);\n+    if (!registered_buffers_.range_to_handle.contains(buffer_range.opaque())) {\n+      need_reg = true;\n+    } else {\n+      VLOG(5) << \"[\" << device_ordinal\n+              << \"] Buffer range: \" << buffer_range.opaque()\n+              << \" with size: \" << buffer_range.size()\n+              << \" is already registered.\";\n+    }\n+  }\n+  if (need_reg) {\n+    VLOG(5) << \"[\" << device_ordinal << \"] Registering \"\n+            << buffer_range.opaque() << \" with size: \" << buffer_range.size()\n+            << \", is symmetric: \" << (use_symmetric_buffer ? \"true\" : \"false\");\n+    // Symmetric buffer registration is a collective operation,\n+    // we need to do that before locking on a global.\n+    TF_ASSIGN_OR_RETURN(\n+        auto handle,\n+        RegisterBuffer(buffer_range, device_ordinal, use_symmetric_buffer));\n+    absl::MutexLock lock(&registered_buffers_.mu);\n+    registered_buffers_.range_to_handle[buffer_range.opaque()] =\n+        std::move(handle);\n+  }\n+  return absl::OkStatus();\n }\n \n absl::StatusOr<std::unique_ptr<Communicator::RegisteredBufferHandle>>\n NcclCommunicator::RegisterBuffer(stream_executor::DeviceMemoryBase buffer,\n+                                 int device_ordinal,\n                                  bool use_symmetric_buffer) {\n #if (NCCL_VERSION_CODE >= 21901)\n   using Handle = std::unique_ptr<Communicator::RegisteredBufferHandle>;\n \n   if (!use_symmetric_buffer) {\n-    return BlockAndGet(\n-        Execute<Handle>([&buffer, this]() -> absl::StatusOr<Handle> {\n+    return BlockAndGet(Execute<Handle>(\n+        [&buffer, device_ordinal, this]() -> absl::StatusOr<Handle> {\n           VLOG(3) << absl::StreamFormat(\n-              \"Register buffer for NCCL communicator; buffer=%p; size=%d; \"\n+              \"[%d] Register buffer for NCCL communicator; buffer=%p; size=%d; \"\n               \"comm=%p\",\n-              buffer.opaque(), buffer.size(), comm_);\n+              device_ordinal, buffer.opaque(), buffer.size(), comm_);\n           if (canceling_.load()) {\n             return absl::FailedPreconditionError(\"NcclCommunicator aborted\");\n           }\n@@ -375,34 +411,39 @@ NcclCommunicator::RegisterBuffer(stream_executor::DeviceMemoryBase buffer,\n             TF_RETURN_IF_ERROR(PollUntilDone());\n           }\n           return std::make_unique<NcclRegisteredBufferHandle>(\n-              *this, handle, executor_.get(), /*symmetric_buffer= */ false);\n+              *this, handle, executor_.get(), /*symmetric_buffer= */ false,\n+              device_ordinal);\n         }));\n #else\n-  return Unimplemented(\"NCCL version does not support ncclCommRegister\");\n+  return Unimplemented(\"[%d] NCCL version does not support ncclCommRegister\",\n+                       device_ordinal);\n #endif  // NCCL_VERSION_CODE >= 21901\n   } else {\n #if (NCCL_VERSION_CODE >= 22700)\n-    return BlockAndGet(\n-        Execute<Handle>([&buffer, this]() -> absl::StatusOr<Handle> {\n-          VLOG(3) << absl::StreamFormat(\n-              \"Register symmetric buffer for NCCL communicator; buffer=%p; \"\n-              \"size=%d; \"\n-              \"comm=%p\",\n-              buffer.opaque(), buffer.size(), comm_);\n-          void* handle = nullptr;\n-          XLA_NCCL_RETURN_IF_ERROR(ncclGroupStart());\n-          XLA_NCCL_RETURN_IF_ERROR(ncclCommWindowRegister(\n-              comm_, buffer.opaque(), buffer.size(), (ncclWindow_t*)&handle,\n-              NCCL_WIN_COLL_SYMMETRIC));\n-          XLA_NCCL_RETURN_IF_ERROR(ncclGroupEnd());\n-          if (group_nesting_level_ == 0) {\n-            TF_RETURN_IF_ERROR(PollUntilDone());\n-          }\n-          return std::make_unique<NcclRegisteredBufferHandle>(\n-              *this, handle, executor_.get(), /*symmetric_buffer= */ true);\n-        }));\n+    return BlockAndGet(Execute<Handle>([&buffer, device_ordinal,\n+                                        this]() -> absl::StatusOr<Handle> {\n+      VLOG(3) << absl::StreamFormat(\n+          \"[%d] Register symmetric buffer for NCCL communicator; buffer=%p; \"\n+          \"size=%d; \"\n+          \"comm=%p\",\n+          device_ordinal, buffer.opaque(), buffer.size(), comm_);\n+      void* handle = nullptr;\n+      XLA_NCCL_RETURN_IF_ERROR(ncclGroupStart());\n+      XLA_NCCL_RETURN_IF_ERROR(ncclCommWindowRegister(\n+          comm_, buffer.opaque(), buffer.size(), (ncclWindow_t*)&handle,\n+          NCCL_WIN_COLL_SYMMETRIC));\n+      XLA_NCCL_RETURN_IF_ERROR(ncclGroupEnd());\n+      if (group_nesting_level_ == 0) {\n+        TF_RETURN_IF_ERROR(PollUntilDone());\n+      }\n+      return std::make_unique<NcclRegisteredBufferHandle>(\n+          *this, handle, executor_.get(), /*symmetric_buffer= */ true,\n+          device_ordinal);\n+    }));\n #else\n-  return Unimplemented(\"NCCL version does not support ncclCommWindowRegister\");\n+  return Unimplemented(\n+      \"[%d] NCCL version does not support ncclCommWindowRegister\",\n+      device_ordinal);\n #endif  // NCCL_VERSION_CODE >= 22700\n   }\n }\n@@ -529,7 +570,7 @@ absl::Status NcclCommunicator::LaunchAllReduce(\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL AllReduce operation on device #%d; send_buffer=%p; \"\n+      \"[%d] Launch NCCL AllReduce operation; send_buffer=%p; \"\n       \"recv_buffer=%p; dtype=%s; count=%d; reduction_kind=%s; comm=%p; \"\n       \"stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n@@ -559,7 +600,7 @@ absl::Status NcclCommunicator::LaunchBroadcast(se::DeviceMemoryBase send_buffer,\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL Broadcast operation on device #%d; send_buffer=%p; \"\n+      \"[%d] Launch NCCL Broadcast operation; send_buffer=%p; \"\n       \"recv_buffer=%p; dtype=%s; count=%d; root=%d; comm=%p; \"\n       \"stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n@@ -587,7 +628,7 @@ absl::Status NcclCommunicator::LaunchReduceScatter(\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL ReduceScatter operation on device #%d; send_buffer=%p; \"\n+      \"[%d] Launch NCCL ReduceScatter operation; send_buffer=%p; \"\n       \"recv_buffer=%p; dtype=%s; count=%d; reduction_kind=%s; comm=%p; \"\n       \"stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n@@ -617,7 +658,7 @@ absl::Status NcclCommunicator::LaunchAllGather(se::DeviceMemoryBase send_buffer,\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL AllGather operation on device #%d; send_buffer=%p; \"\n+      \"[%d] Launch NCCL AllGather operation; send_buffer=%p; \"\n       \"recv_buffer=%p; dtype=%s; count=%d; comm=%p; stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n       recv_buffer.opaque(), primitive_util::LowercasePrimitiveTypeName(dtype),\n@@ -648,7 +689,7 @@ absl::Status NcclCommunicator::LaunchAllToAll(\n   };\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL AllToAll operation on device #%d; send_buffers=[%s]; \"\n+      \"[%d] Launch NCCL AllToAll operation; send_buffers=[%s]; \"\n       \"recv_buffers=[%s]; dtype=%s; count=%d; comm=%p; stream=%p\",\n       stream->parent()->device_ordinal(),\n       absl::StrJoin(send_buffers, \", \", buffer_formatter),\n@@ -703,7 +744,7 @@ absl::Status NcclCommunicator::LaunchCollectivePermute(\n   };\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL CollectivePermute operation on device #%d; send_buffer=%p; \"\n+      \"[%d] Launch NCCL CollectivePermute operation; send_buffer=%p; \"\n       \"recv_buffer=%p; dtype=%s; source_rank=%s; target_ranks=[%s]; count=%d; \"\n       \"comm=%p; stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n@@ -747,7 +788,7 @@ absl::Status NcclCommunicator::LaunchSend(se::DeviceMemoryBase send_buffer,\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL Send operation on device #%d; send_buffer=%p; dtype=%s; \"\n+      \"[%d] Launch NCCL Send operation; send_buffer=%p; dtype=%s; \"\n       \"count=%d; peer=%d; comm=%p; stream=%p\",\n       stream->parent()->device_ordinal(), send_buffer.opaque(),\n       primitive_util::LowercasePrimitiveTypeName(dtype), count, peer.value(),\n@@ -774,7 +815,7 @@ absl::Status NcclCommunicator::LaunchRecv(se::DeviceMemoryBase recv_buffer,\n   se::Stream* stream = ToStream(executor);\n \n   VLOG(3) << absl::StreamFormat(\n-      \"Launch NCCL Recv operation on device #%d; recv_buffer=%p; dtype=%s; \"\n+      \"[%d] Launch NCCL Recv operation; recv_buffer=%p; dtype=%s; \"\n       \"count=%d; peer=%d; comm=%p; stream=%p\",\n       stream->parent()->device_ordinal(), recv_buffer.opaque(),\n       primitive_util::LowercasePrimitiveTypeName(dtype), count, peer.value(),"
        },
        {
            "sha": "ed0947ed6529594eb4b81e4fd8483755ffc3ec72",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator.h",
            "status": "modified",
            "additions": 25,
            "deletions": 5,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -21,13 +21,17 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <tuple>\n #include <utility>\n \n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_communicator.h\"\n #include \"xla/core/collectives/communicator.h\"\n@@ -79,11 +83,12 @@ class NcclCommunicator : public GpuCommunicator {\n   absl::Status HealthCheck() const final;\n   absl::StatusOr<size_t> NumRanks() const final;\n \n-  absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>> RegisterBuffer(\n-      se::DeviceMemoryBase buffer) final;\n-\n-  absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>> RegisterBuffer(\n-      se::DeviceMemoryBase buffer, bool use_symmetric_buffer) final;\n+  // Since each XLA buffer is a slice into a larger BFCAllocator chunk, first\n+  // get the base address of buffer. We will use the base address to keep track\n+  // of which chunks we have registered.\n+  absl::Status RegisterBufferOnce(se::DeviceMemoryBase buffer_range,\n+                                  int device_ordinal,\n+                                  bool use_symmetric_buffer) final;\n \n   tsl::AsyncValueRef<Communicator::Event> GroupExecute(\n       absl::AnyInvocable<absl::Status(GpuCommunicator*)> f) final;\n@@ -134,6 +139,10 @@ class NcclCommunicator : public GpuCommunicator {\n   ncclComm_t comm() const { return comm_; }\n \n  private:\n+  absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>> RegisterBuffer(\n+      se::DeviceMemoryBase buffer, int device_ordinal,\n+      bool use_symmetric_buffer);\n+\n   class NcclRegisteredBufferHandle;\n \n   explicit NcclCommunicator(ncclComm_t comm,\n@@ -227,6 +236,17 @@ class NcclCommunicator : public GpuCommunicator {\n \n   // Nesting level of current NCCL group\n   int group_nesting_level_ = 0;\n+\n+  // Keep track of which communicators we have registered for already.\n+  // Each ncclMemAlloc'd buffer needs to be registered once per comm.\n+  struct RegisteredBuffers {\n+    absl::Mutex mu;\n+    // Buffer range to the registered buffer handle.\n+    absl::flat_hash_map<void*,\n+                        std::unique_ptr<Communicator::RegisteredBufferHandle>>\n+        range_to_handle ABSL_GUARDED_BY(mu);\n+  };\n+  RegisteredBuffers registered_buffers_;\n };\n \n }  // namespace xla::gpu"
        },
        {
            "sha": "8172412d2f3f70b35e8c876aa0f97d9173688e56",
            "filename": "third_party/xla/xla/backends/gpu/collectives/nccl_communicator_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fnccl_communicator_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -152,7 +152,7 @@ TEST(NcclCommunicator, OperationsFailAfterAbort) {\n     ASSERT_THAT((*comm)->Abort(), absl_testing::IsOk());\n     AssertAborted((*comm)->HealthCheck());\n     AssertAborted((*comm)->NumRanks().status());\n-    AssertAborted((*comm)->RegisterBuffer(buf).status());\n+    AssertAborted((*comm)->RegisterBufferOnce(buf, 0, false));\n     AssertEventAborted(\n         (*comm)->AllReduce(buf, buf, dtype, count, rk, executor));\n     AssertEventAborted("
        },
        {
            "sha": "ecdb6f81deae30daa5502755821d15ef4c46b79b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -870,14 +870,14 @@ cuda_library(\n         \"-DLIBCUDACXX_ENABLE_EXPERIMENTAL_MEMORY_RESOURCE\",\n     ],\n     tags = [\"cuda-only\"],\n-    textual_hdrs = [\"raft_vectorized_bf16.h\"],\n     deps = [\n         \"//xla:status_macros\",\n         \"//xla:types\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "a26ece5e80a68384e92e3a8c702141eb574ff7ad",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -109,8 +109,7 @@ absl::Status RunAllGather(std::vector<DeviceBufferPair>& buffers,\n                           se::Stream& stream, Communicator* comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"[\" << device_ordinal\n-          << \"] Performing all-gather from device ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing all-gather\";\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n   auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);"
        },
        {
            "sha": "07822b776729b8a82defa712d29b7b1838db5be5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -87,8 +87,7 @@ absl::Status RunAllReduce(ReductionKind reduction_kind,\n                           se::Stream& stream, Communicator* comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"[\" << device_ordinal\n-          << \"] Performing all-reduce from device ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing all-reduce\";\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n \n@@ -105,8 +104,7 @@ absl::Status RunAllReduce(ReductionKind reduction_kind,\n         return absl::OkStatus();\n       });\n   tsl::BlockUntilReady(event);\n-  VLOG(3) << \"[\" << device_ordinal\n-          << \"] Done performing all-reduce for ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Done performing all-reduce\";\n   if (event.IsError()) {\n     return event.GetError();\n   }\n@@ -237,8 +235,7 @@ absl::Status RunReduceScatter(ReductionKind reduction_kind,\n                               se::Stream& stream, Communicator* comm,\n                               bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing reduce-scatter from device ordinal: \"\n-          << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing reduce-scatter\";\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n \n@@ -263,7 +260,7 @@ absl::Status RunReduceScatter(ReductionKind reduction_kind,\n         return absl::OkStatus();\n       });\n   tsl::BlockUntilReady(event);\n-  VLOG(3) << \"Done performing reduce-scatter for ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Done performing reduce-scatter\";\n   if (event.IsError()) {\n     return event.GetError();\n   }"
        },
        {
            "sha": "c444a04436b471857e8bc182a829f5fbc4fb1f6e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -288,8 +288,9 @@ absl::Status CollectiveKernelThunk::ExecuteOnStream(\n       AllReduceLaunchDimensions(buffer.element_count, kNumRanks, strategy);\n   // In case of two-shot we want to increment in multiples of 2.\n   state->invocation_count += 1 + static_cast<uint32_t>(strategy);\n-  VLOG(3) << \"Performing one-shot all-reduce from device ordinal: \"\n-          << device_ordinal << \" for clique \" << clique_key.ToString();\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing one-shot all-reduce for clique \"\n+          << clique_key.ToString();\n   // TODO(b/407736956): Change this to emitted kernel.\n   return RunAllReduceKernel(\n       /*stream=*/stream,"
        },
        {
            "sha": "328f150947075125f7fe985cb0a387a1c3667a33",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -380,10 +380,8 @@ absl::Status RunCollectivePermute(\n   //\n \n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing collective permute from device ordinal: \"\n-          << device_ordinal << \" current_id \" << current_id;\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n-                                          use_symmetric_buffer));\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing collective permute, current_id \" << current_id;\n \n   std::optional<int64_t> source_id = source_target.source;\n   std::optional<int64_t> target_id = source_target.target;\n@@ -424,6 +422,8 @@ absl::Status RunCollectivePermute(\n         }\n       }\n     } else {\n+      TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n+                                              use_symmetric_buffer));\n       auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n       tsl::AsyncValueRef<Communicator::Event> event = gpu_comm->GroupExecute(\n           [source_rank, &buffers, &src_addrs, &dest_addrs, &target_ranks,"
        },
        {
            "sha": "33bdf47056e5002445bff8f7f8c3c4c9ba018f80",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 55,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -351,57 +351,21 @@ absl::StatusOr<std::vector<DeviceBufferPair>> ConvertToDeviceBuffers(\n   return device_buffers;\n }\n \n-absl::Status RegisterBufferOnce(se::StreamExecutor* executor,\n-                                Communicator* comm, se::DeviceMemoryBase buffer,\n-                                bool use_symmetric_buffer) {\n-  // Keep track of which communicators we have registered for already.\n-  // Each ncclMemAlloc'd buffer needs to be registered once per comm.\n-  struct RegisteredBuffers {\n-    absl::Mutex mu;\n-    // Device ordinal, communicator, and base pointer address.\n-    absl::flat_hash_set<std::tuple<int, uint64_t, Communicator*, void*>> records\n-        ABSL_GUARDED_BY(mu);\n-    // Buffers could be deregistered with ncclCommDeregister.\n-    std::vector<std::unique_ptr<Communicator::RegisteredBufferHandle>> handles\n-        ABSL_GUARDED_BY(mu);\n-  };\n-  static auto& all_registered = *new RegisteredBuffers;\n-\n-  // Since each XLA buffer is a slice into a larger BFCAllocator chunk, first\n-  // get the base address of buffer. We will use the base address to keep track\n-  // of which chunks we have registered.\n-  TF_ASSIGN_OR_RETURN(se::DeviceMemoryBase base_buffer,\n-                      executor->GetMemoryRange(buffer));\n-  bool need_reg = false;\n-  {\n-    absl::MutexLock lock(&all_registered.mu);\n-    if (!all_registered.records.contains({executor->device_ordinal(),\n-                                          buffer.size(), comm,\n-                                          buffer.opaque()})) {\n-      need_reg = true;\n-    } else {\n-      VLOG(5) << \"[\" << executor->device_ordinal()\n-              << \"] Buffer: \" << buffer.opaque()\n-              << \" with size: \" << buffer.size()\n-              << \" and base pointer: \" << base_buffer.opaque()\n-              << \" is already registered.\";\n-    }\n-  }\n-  if (need_reg) {\n-    VLOG(5) << \"[\" << executor->device_ordinal() << \"] Registering \"\n-            << buffer.opaque() << \" with size: \" << buffer.size()\n-            << \" and base pointer: \" << base_buffer.opaque()\n-            << \", is symmetric: \" << (use_symmetric_buffer ? \"true\" : \"false\");\n-    // Symmetric buffer registration is a collective operation,\n-    // we need to do that before locking on a global.\n-    TF_ASSIGN_OR_RETURN(auto handle,\n-                        comm->RegisterBuffer(buffer, use_symmetric_buffer));\n-    absl::MutexLock lock(&all_registered.mu);\n-    all_registered.handles.push_back(std::move(handle));\n-    all_registered.records.insert(\n-        {executor->device_ordinal(), buffer.size(), comm, buffer.opaque()});\n-  }\n-  return absl::OkStatus();\n+absl::Status MaybeRegisterBuffer(se::StreamExecutor* executor,\n+                                 const se::DeviceMemoryBase& buffer,\n+                                 Communicator* comm,\n+                                 bool use_symmetric_buffer) {\n+  TF_ASSIGN_OR_RETURN(auto range, executor->GetMemoryRange(buffer));\n+  VLOG(1) << \"[\" << executor->device_ordinal()\n+          << \"] Registering range: \" << range.opaque()\n+          << \" with size: \" << range.size()\n+          << \" for buffer: \" << buffer.opaque()\n+          << \" with size: \" << buffer.size()\n+          << \" is symmetric: \" << (use_symmetric_buffer ? \"true\" : \"false\");\n+  // If the collective memory buffer is a slice of a larger preallocated buffer,\n+  // we need to register the entire preallocated buffer once.\n+  return comm->RegisterBufferOnce(range, executor->device_ordinal(),\n+                                  use_symmetric_buffer);\n }\n \n absl::Status MaybeRegisterBuffers(se::StreamExecutor* executor,\n@@ -410,12 +374,12 @@ absl::Status MaybeRegisterBuffers(se::StreamExecutor* executor,\n                                   bool use_symmetric_buffer) {\n   for (int i = 0; i < buffers.size(); ++i) {\n     if (buffers[i].source_memory_space == kCollectiveMemorySpaceColor) {\n-      TF_RETURN_IF_ERROR(RegisterBufferOnce(\n-          executor, comm, buffers[i].source_buffer, use_symmetric_buffer));\n+      TF_RETURN_IF_ERROR(MaybeRegisterBuffer(executor, buffers[i].source_buffer,\n+                                             comm, use_symmetric_buffer));\n     }\n     if (buffers[i].destination_memory_space == kCollectiveMemorySpaceColor) {\n-      TF_RETURN_IF_ERROR(RegisterBufferOnce(\n-          executor, comm, buffers[i].destination_buffer, use_symmetric_buffer));\n+      TF_RETURN_IF_ERROR(MaybeRegisterBuffer(\n+          executor, buffers[i].destination_buffer, comm, use_symmetric_buffer));\n     }\n   }\n   return absl::OkStatus();"
        },
        {
            "sha": "167278e306d7dd67c50c3f792463e4809d4a2434",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_test.cc",
            "status": "modified",
            "additions": 153,
            "deletions": 0,
            "changes": 153,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -60,6 +60,24 @@ static se::StreamExecutor* GpuExecutor() {\n   return platform->ExecutorForDevice(0).value();\n }\n \n+// Some of the tests rely on CUDA 12.9+ features.\n+bool IsAtLeastCuda12900(const se::StreamExecutor* stream_executor) {\n+  const auto& device_description = stream_executor->GetDeviceDescription();\n+  const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n+      &device_description.gpu_compute_capability());\n+  if (cuda_cc != nullptr) {\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n+        stream_executor::SemanticVersion(12, 9, 0)) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n // Give a short alias to synchronization mode.\n static constexpr auto serialize =\n     CommandBufferCmdExecutor::SynchronizationMode::kSerialize;\n@@ -685,6 +703,141 @@ TEST(CommandBufferCmdTest, RecordExecutorsWithDependencies) {\n   ASSERT_EQ(dst, std::vector<int32_t>(length, 2));\n }\n \n+TEST(CommandBufferCmdTest, NestedChildCmdCreateAndUpdate) {\n+  se::StreamExecutor* stream_executor = GpuExecutor();\n+  if (!IsAtLeastCuda12900(stream_executor)) {\n+    GTEST_SKIP() << \"Child command is not supported for CUDA < 12.9\";\n+  }\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_executor->CreateStream());\n+\n+  // Prepare device memory for three buffers.\n+  int64_t length = 4;\n+  int64_t byte_length = sizeof(int32_t) * length;\n+  se::DeviceMemory<int32_t> a = stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> b = stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> c = stream_executor->AllocateArray<int32_t>(length);\n+\n+  // Initialize a = 1s, b = 0s, c = 0s.\n+  TF_ASSERT_OK(stream->Memset32(&a, /*pattern=*/1, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&b, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&c, byte_length));\n+\n+  // Buffer allocations.\n+  BufferAllocation alloc_a(/*index=*/0, byte_length, /*color=*/0);\n+  BufferAllocation alloc_b(/*index=*/1, byte_length, /*color=*/0);\n+  BufferAllocation alloc_c(/*index=*/2, byte_length, /*color=*/0);\n+\n+  BufferAllocation::Slice slice_a(&alloc_a, 0, byte_length);\n+  BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n+  BufferAllocation::Slice slice_c(&alloc_c, 0, byte_length);\n+\n+  // Inner child: c = a (device-to-device memcpy)\n+  CommandBufferCmdSequence inner_seq;\n+  inner_seq.Emplace<MemcpyDeviceToDeviceCmd>(slice_c, slice_a, byte_length);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor inner_executor,\n+      CommandBufferCmdExecutor::Create(std::move(inner_seq), serialize));\n+\n+  // Middle child wraps inner.\n+  CommandBufferCmdSequence middle_seq;\n+  middle_seq.Emplace<ChildCmd>(std::move(inner_executor));\n+  // Add a couple of extra commands that don't affect `c`.\n+  middle_seq.Emplace<Memset32Cmd>(slice_b, /*bit_pattern=*/3);\n+  middle_seq.Emplace<MemcpyDeviceToDeviceCmd>(slice_b, slice_b, byte_length);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor middle_executor,\n+      CommandBufferCmdExecutor::Create(std::move(middle_seq), serialize));\n+\n+  // Outer child wraps middle.\n+  CommandBufferCmdSequence outer_seq;\n+  outer_seq.Emplace<ChildCmd>(std::move(middle_executor));\n+  // Add a couple more commands at the outer level that still don't affect `c`.\n+  outer_seq.Emplace<MemzeroCmd>(slice_b);\n+  outer_seq.Emplace<EmptyCmd>();\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      CommandBufferCmdExecutor outer_executor,\n+      CommandBufferCmdExecutor::Create(std::move(outer_seq), serialize));\n+\n+  // Prepare state and params; ChildCmd requires initialization to create a\n+  // nested buffer.\n+  CommandBufferCmd::StateManager state;\n+  Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n+  se::StreamExecutorMemoryAllocator allocator(stream_executor);\n+  BufferAllocations allocations({a, b, c}, 0, &allocator);\n+  TF_ASSERT_OK(outer_executor.Initialize(\n+      {stream_executor, source, &allocations, stream.get(), stream.get()},\n+      state));\n+\n+  // allocations already created above\n+  ServiceExecutableRunOptions run_options;\n+  Thunk::ExecuteParams exec_params = Thunk::ExecuteParams::Create(\n+      run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n+  CommandBufferCmd::RecordParams record_params = {state};\n+\n+  // Create a command buffer and record the nested ChildCmd (Create).\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto command_buffer,\n+      stream_executor->CreateCommandBuffer(se::CommandBuffer::Mode::kPrimary));\n+  TF_ASSERT_OK(outer_executor.Record(exec_params, record_params,\n+                                     CommandBufferCmd::RecordCreate{},\n+                                     command_buffer.get(), /*finalize=*/true));\n+  TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n+\n+  // Verify c == a (all ones).\n+  std::vector<int32_t> dst(length, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst.data(), c, byte_length));\n+  ASSERT_EQ(dst, std::vector<int32_t>(length, 1));\n+\n+  // Also verify a == 1s and b == 0s.\n+  {\n+    std::vector<int32_t> a_host(length, 0);\n+    std::vector<int32_t> b_host(length, 0);\n+    TF_ASSERT_OK(stream->Memcpy(a_host.data(), a, byte_length));\n+    TF_ASSERT_OK(stream->Memcpy(b_host.data(), b, byte_length));\n+    ASSERT_EQ(a_host, std::vector<int32_t>(length, 1));\n+    ASSERT_EQ(b_host, std::vector<int32_t>(length, 0));\n+  }\n+\n+  // Now update: change a and c buffers and record an update on the same command\n+  // buffer.\n+  se::DeviceMemory<int32_t> a2 =\n+      stream_executor->AllocateArray<int32_t>(length);\n+  se::DeviceMemory<int32_t> c2 =\n+      stream_executor->AllocateArray<int32_t>(length);\n+  TF_ASSERT_OK(stream->Memset32(&a2, /*pattern=*/7, byte_length));\n+  TF_ASSERT_OK(stream->MemZero(&c2, byte_length));\n+\n+  BufferAllocations allocations2({a2, b, c2}, 0, &allocator);\n+  Thunk::ExecuteParams exec_params2 = Thunk::ExecuteParams::Create(\n+      run_options, allocations2, stream.get(), stream.get(), nullptr, nullptr);\n+\n+  // Indicate which allocations changed to ensure update is not skipped.\n+  std::vector<BufferAllocation::Index> updated_allocs = {0, 2};\n+  CommandBufferCmd::RecordParams record_params2 = {state,\n+                                                   std::move(updated_allocs)};\n+\n+  TF_ASSERT_OK(outer_executor.Record(exec_params2, record_params2,\n+                                     CommandBufferCmd::RecordCreate{},\n+                                     command_buffer.get(), /*finalize=*/true));\n+  TF_ASSERT_OK(command_buffer->Submit(stream.get()));\n+\n+  // Verify c2 == a2 (all sevens).\n+  std::vector<int32_t> dst2(length, 0);\n+  TF_ASSERT_OK(stream->Memcpy(dst2.data(), c2, byte_length));\n+  ASSERT_EQ(dst2, std::vector<int32_t>(length, 7));\n+\n+  // Also verify a2 == 7s and b == 0s.\n+  {\n+    std::vector<int32_t> a2_host(length, 0);\n+    std::vector<int32_t> b_host(length, 0);\n+    TF_ASSERT_OK(stream->Memcpy(a2_host.data(), a2, byte_length));\n+    TF_ASSERT_OK(stream->Memcpy(b_host.data(), b, byte_length));\n+    ASSERT_EQ(a2_host, std::vector<int32_t>(length, 7));\n+    ASSERT_EQ(b_host, std::vector<int32_t>(length, 0));\n+  }\n+}\n+\n //===----------------------------------------------------------------------===//\n // Performance benchmarks below\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "17703c280d0135857fe54d402e43f0f6a911f1db",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 272,
            "changes": 272,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -871,15 +871,12 @@ TEST(CommandBufferThunkTest, ChildGemmCmd) {\n       run_options, allocations, stream.get(), stream.get(), nullptr, nullptr);\n \n   Thunk::ExecutableSource source = {/*text=*/\"\", /*binary=*/{}};\n-  VLOG(0) << \"Initialize thunk\";\n   TF_ASSERT_OK(thunk.Initialize(\n       {stream_executor, source, &allocations, stream.get(), stream.get()}));\n \n-  VLOG(0) << \"Initialize done\";\n   // Execute command buffer thunk and verify that it executed a GEMM.\n   TF_ASSERT_OK(thunk.ExecuteOnStream(params));\n \n-  VLOG(0) << \"Execute thunk done\";\n   TF_ASSERT_OK(stream->BlockHostUntilDone());\n \n   // Copy `out` data back to host.\n@@ -1570,114 +1567,6 @@ TEST(CommandBufferThunkTest, WhileCmd) {\n   ASSERT_EQ(dst, std::vector<int32_t>(4, 15));\n }\n \n-class CmdBufferTest : public HloPjRtInterpreterReferenceMixin<HloPjRtTestBase> {\n- public:\n-  DebugOptions GetDebugOptionsForTest() const override {\n-    DebugOptions debug_options = HloPjRtTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_gpu_autotune_level(0);\n-    debug_options.set_xla_gpu_enable_dynamic_slice_fusion(true);\n-    debug_options.set_xla_gpu_graph_min_graph_size(1);\n-    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n-    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLAS);\n-    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLASLT);\n-    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUSTOM_CALL);\n-    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUDNN);\n-    debug_options.add_xla_gpu_enable_command_buffer(\n-        DebugOptions::DYNAMIC_SLICE_FUSION);\n-    return debug_options;\n-  }\n-};\n-\n-TEST_F(CmdBufferTest, DynamicSliceFusionCmd) {\n-  // Hlo generated by below jax code\n-  // def scan_body(carry, x):\n-  //     sliced_x = lax.slice(x, (0, 0), (128, 128))\n-  //     result = jnp.dot(carry, sliced_x)\n-  //     new_carry = result\n-  //     return new_carry, result\n-  // @jax.jit\n-  // def run_scan(initial_carry, xs):\n-  //     final_carry, outputs = lax.scan(scan_body, initial_carry, xs, length=2)\n-  //     return final_carry, outputs\n-\n-  const char* module_str = R\"(\n-HloModule jit_run_scan\n-\n-None.7 {\n-  Arg_0.8 = f32[128,128]{1,0} parameter(0)\n-  Arg_1.9 = f32[128,128]{1,0} parameter(1)\n-  dot.10 = f32[128,128]{1,0} dot(Arg_0.8, Arg_1.9), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  ROOT tuple.11 = (f32[128,128]{1,0}, f32[128,128]{1,0}) tuple(dot.10, dot.10)\n-}\n-\n-region_0.12 {\n-  arg_tuple.13 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) parameter(0)\n-  get-tuple-element.14 = s32[] get-tuple-element(arg_tuple.13), index=0\n-  constant.18 = s32[] constant(1)\n-  add.34 = s32[] add(get-tuple-element.14, constant.18)\n-  get-tuple-element.15 = f32[128,128]{1,0} get-tuple-element(arg_tuple.13), index=1\n-  get-tuple-element.17 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.13), index=3\n-  constant.20 = s32[] constant(0)\n-  compare.21 = pred[] compare(get-tuple-element.14, constant.20), direction=LT\n-  constant.19 = s32[] constant(2)\n-  add.22 = s32[] add(get-tuple-element.14, constant.19)\n-  select.23 = s32[] select(compare.21, add.22, get-tuple-element.14)\n-  dynamic-slice.24 = f32[1,128,128]{2,1,0} dynamic-slice(get-tuple-element.17, select.23, constant.20, constant.20), dynamic_slice_sizes={1,128,128}\n-  reshape.25 = f32[128,128]{1,0} reshape(dynamic-slice.24)\n-  call.26 = (f32[128,128]{1,0}, f32[128,128]{1,0}) call(get-tuple-element.15, reshape.25), to_apply=None.7\n-  get-tuple-element.27 = f32[128,128]{1,0} get-tuple-element(call.26), index=0\n-  get-tuple-element.16 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.13), index=2\n-  get-tuple-element.28 = f32[128,128]{1,0} get-tuple-element(call.26), index=1\n-  reshape.29 = f32[1,128,128]{2,1,0} reshape(get-tuple-element.28)\n-  compare.30 = pred[] compare(get-tuple-element.14, constant.20), direction=LT\n-  add.31 = s32[] add(get-tuple-element.14, constant.19)\n-  select.32 = s32[] select(compare.30, add.31, get-tuple-element.14)\n-  dynamic-update-slice.33 = f32[2,128,128]{2,1,0} dynamic-update-slice(get-tuple-element.16, reshape.29, select.32, constant.20, constant.20)\n-  ROOT tuple.35 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) tuple(add.34, get-tuple-element.27, dynamic-update-slice.33, get-tuple-element.17)\n-} // region_0.12\n-\n-region_1.36 {\n-  arg_tuple.37 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) parameter(0)\n-  get-tuple-element.39 = f32[128,128]{1,0} get-tuple-element(arg_tuple.37), index=1\n-  get-tuple-element.40 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.37), index=2\n-  get-tuple-element.41 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.37), index=3\n-  get-tuple-element.38 = s32[] get-tuple-element(arg_tuple.37), index=0\n-  constant.42 = s32[] constant(2)\n-  ROOT compare.43 = pred[] compare(get-tuple-element.38, constant.42), direction=LT\n-} // region_1.36\n-\n-ENTRY main.49 {\n-  constant.3 = s32[] constant(0)\n-  Arg_0.1 = f32[128,128]{1,0} parameter(0)\n-  constant.4 = f32[] constant(0)\n-  broadcast.5 = f32[2,128,128]{2,1,0} broadcast(constant.4), dimensions={}\n-  Arg_1.2 = f32[2,128,128]{2,1,0} parameter(1)\n-  tuple.6 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) tuple(constant.3, Arg_0.1, broadcast.5, Arg_1.2)\n-  while.44 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) while(tuple.6), condition=region_1.36, body=region_0.12\n-  get-tuple-element.45 = s32[] get-tuple-element(while.44), index=0\n-  get-tuple-element.46 = f32[128,128]{1,0} get-tuple-element(while.44), index=1\n-  get-tuple-element.47 = f32[2,128,128]{2,1,0} get-tuple-element(while.44), index=2\n-  ROOT tuple.48 = (f32[128,128]{1,0}, f32[2,128,128]{2,1,0}) tuple(get-tuple-element.46, get-tuple-element.47)\n-}\n-)\";\n-\n-  // running with module without exclusive lock on GpuExecutable\n-  HloModuleConfig config;\n-  auto debug_options = GetDebugOptionsForTest();\n-  debug_options.set_xla_gpu_require_exclusive_lock(false);\n-  config.set_debug_options(debug_options);\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(module_str, config));\n-  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n-\n-  // running with module with exclusive lock on GpuExecutable\n-  debug_options.set_xla_gpu_require_exclusive_lock(true);\n-  config.set_debug_options(debug_options);\n-  TF_ASSERT_OK_AND_ASSIGN(module,\n-                          ParseAndReturnVerifiedModule(module_str, config));\n-  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n-}\n-\n TEST(CommandBufferThunkTest, ToStringPrintsNestedThunks) {\n   BufferAllocation alloc_a(/*index=*/0, /*size=*/4, /*color=*/0);\n   BufferAllocation::Slice slice_a(&alloc_a, /*offset=*/0, /*size=*/4);\n@@ -1696,165 +1585,4 @@ TEST(CommandBufferThunkTest, ToStringPrintsNestedThunks) {\n       absl::StrContains(thunk.ToString(/*indent=*/1), \"    kMemset32BitValue\"));\n }\n \n-TEST_F(CmdBufferTest, ControlDependencyTest) {\n-  const char* module_str = R\"(\n-HloModule m\n-\n-%x (a: f32[3200,6400]) -> f32[3200,6400] {\n-  %a = f32[3200,6400]{1,0} parameter(0)\n-  ROOT %b = f32[3200,6400]{1,0} negate(%a)\n-}\n-\n-%y (a.1: f32[3200,6400]) -> f32[3200,6400] {\n-  %a.1 = f32[3200,6400]{1,0} parameter(0)\n-  ROOT %b.1 = f32[3200,6400]{1,0} add(%a.1, %a.1)\n-}\n-\n-%command_buffer (p: f32[3200,6400], p.1: f32[3200,6400]) -> (f32[3200,6400], f32[3200,6400]) {\n-  %p = f32[3200,6400]{1,0} parameter(0)\n-  %p.1 = f32[3200,6400]{1,0} parameter(1)\n-  %b.2 = f32[3200,6400]{1,0} fusion(%p), kind=kLoop, calls=%x\n-  %c = f32[3200,6400]{1,0} fusion(%p.1), kind=kLoop, calls=%y, control-predecessors={%b.2}\n-  ROOT %tuple = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) tuple(%b.2, %c)\n-}\n-\n-ENTRY %e (m: f32[3200,6400], n: f32[3200,6400]) -> (f32[3200,6400], f32[3200,6400]) {\n-  %m = f32[3200,6400]{1,0} parameter(0)\n-  %n = f32[3200,6400]{1,0} parameter(1)\n-  %call = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) call(%m, %n), to_apply=%command_buffer\n-  %get-tuple-element = f32[3200,6400]{1,0} get-tuple-element(%call), index=0\n-  %get-tuple-element.1 = f32[3200,6400]{1,0} get-tuple-element(%call), index=1\n-  ROOT %t = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) tuple(%get-tuple-element, %get-tuple-element.1)\n-}\n-)\";\n-\n-  // running with module without exclusive lock on GpuExecutable\n-  HloModuleConfig config;\n-  auto debug_options = GetDebugOptionsForTest();\n-  debug_options.set_xla_disable_all_hlo_passes(true);\n-  config.set_debug_options(debug_options);\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(module_str, config));\n-  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n-}\n-\n-TEST_F(CmdBufferTest, DynamicSliceCopyFusionCmd) {\n-  const char* module_str = R\"(\n-    dynamic_slice {\n-      p0 = s32[4,8,8]{2,1,0} parameter(0)\n-      p1 = s32[] parameter(1)\n-      c1 = s32[] constant(1)\n-      p2 = s32[] parameter(2)\n-\n-      p1p1 = s32[] add(p1, c1)\n-\n-      // Test all supported kinds of offsets: derived from the while loop's\n-      // induction variable (p1p1), constant (c1) and always clamped to 0, so\n-      // the value is irrelevant (p2).\n-      ROOT slice = s32[1,1,8] dynamic-slice(p0, p1p1, c1, p2),\n-          dynamic_slice_sizes={1,1,8}\n-    }\n-\n-    remainder {\n-      p0 = s32[] parameter(0)\n-      c5 = s32[] constant(5)\n-      // We take the value modulo 5 to test for correct clamping (the offset 4\n-      // must get clamped to 3, since it's greater or equal than the dimension\n-      // size).\n-      ROOT remainder = s32[] remainder(p0, c5)\n-    }\n-\n-    add {\n-      p0 = s32[] parameter(0)\n-      c1 = s32[] constant(1)\n-      ROOT sum = s32[] add(p0, c1)\n-    }\n-\n-    add_slices {\n-      p0 = s32[1,1,8] parameter(0)\n-      p1 = s32[1,1,8] parameter(1)\n-      ROOT sum = s32[1,1,8] add(p0, p1)\n-    }\n-\n-    times_two {\n-      p0 = s32[] parameter(0)\n-      ROOT sum = s32[] add(p0, p0)\n-    }\n-\n-    body {\n-      p0 = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) parameter(0)\n-      ivar = s32[] get-tuple-element(p0), index=0\n-      input = s32[4,8,8]{2,1,0} get-tuple-element(p0), index=1\n-\n-      ivar_copy = s32[] copy(ivar)\n-      acc = s32[1,1,8] get-tuple-element(p0), index=2\n-      acc_copy = s32[1,1,8] copy(acc)\n-\n-      offset1 = s32[] fusion(ivar_copy), kind=kLoop, calls=remainder\n-      offset2 = s32[] get-tuple-element(p0), index=3\n-\n-      slice = s32[1,1,8] fusion(input, offset1, offset2), kind=kLoop, calls=dynamic_slice,\n-          backend_config={\"fusion_backend_config\":{\n-              \"kind\":\"__dynamic_memcpy\",\n-              \"dynamic_memcpy_config\":{\n-                  \"depends_on_loop\":true,\n-                  \"src_offset_bytes\":[\"288\",\"544\",\"800\",\"800\",\"800\",\"288\"],\n-                  \"dst_offset_bytes\":[\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"]}}}\n-      next_ivar = s32[] fusion(ivar_copy), kind=kLoop, calls=add\n-      next_offset_2 = s32[] fusion(offset2), kind=kLoop, calls=times_two\n-\n-      next_acc = s32[1,1,8] fusion(acc_copy, slice), kind=kLoop, calls=add_slices\n-      ROOT result = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[])\n-          tuple(next_ivar, input, next_acc, next_offset_2)\n-    }\n-\n-    compare {\n-      p0 = s32[] parameter(0)\n-      c6 = s32[] constant(6)\n-      ROOT cmp = pred[] compare(p0, c6), direction=LT\n-    }\n-\n-    condition {\n-      p0 = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) parameter(0)\n-      ivar = s32[] get-tuple-element(p0), index=0\n-      ROOT cmp = pred[] fusion(ivar), kind=kLoop, calls=compare\n-    }\n-\n-    zero {\n-      c0 = s32[] constant(0)\n-      ROOT bc = s32[1,1,8] broadcast(c0), dimensions={}\n-    }\n-\n-    input {\n-      iota = s32[256] iota(), iota_dimension=0\n-      ROOT bc = s32[4,8,8]{2,1,0} bitcast(iota)\n-    }\n-\n-    ENTRY main {\n-      input = s32[4,8,8]{2,1,0} fusion(), kind=kLoop, calls=input\n-      init_acc = s32[1,1,8] fusion(), kind=kLoop, calls=zero\n-      c0 = s32[] constant(0)\n-      c1 = s32[] constant(1)\n-      tuple = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) tuple(c0, input, init_acc, c1)\n-      ROOT while = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) while(tuple),\n-          condition=condition, body=body,\n-          backend_config={\"known_trip_count\":{\"n\":\"6\"},\n-                          \"known_init_step\":{\"init\":\"0\",\"step\":\"1\"},\n-                          \"known_induction_variable\":{\"tuple_index\":\"0\"}}\n-    }\n-)\";\n-\n-  // running with module without exclusive lock on GpuExecutable\n-  HloModuleConfig config;\n-  auto debug_options = GetDebugOptionsForTest();\n-  debug_options.set_xla_gpu_require_exclusive_lock(false);\n-  debug_options.add_xla_gpu_enable_command_buffer(\n-      DebugOptions::DYNAMIC_SLICE_COPY_FUSION);\n-  config.set_debug_options(debug_options);\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(module_str, config));\n-  EXPECT_TRUE(\n-      RunAndCompareNoHloPasses(std::move(module), ErrorSpec{1e-3, 2e-3}));\n-}\n-\n }  // namespace xla::gpu"
        },
        {
            "sha": "13920c71beef38d9a18ebc82ac4c8267ed515188",
            "filename": "third_party/xla/xla/backends/gpu/runtime/raft_vectorized_bf16.h",
            "status": "removed",
            "additions": 0,
            "deletions": 56,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fraft_vectorized_bf16.h?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,56 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_\n-\n-#pragma once\n-#include \"third_party/gpus/cuda/include/cuda_bf16.h\"\n-#include \"raft/util/vectorized.cuh\"\n-\n-namespace raft {\n-\n-template <>\n-struct IOType<__nv_bfloat16, 1> {\n-  typedef __nv_bfloat16 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat16, 2> {\n-  typedef __nv_bfloat162 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat16, 4> {\n-  typedef uint2 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat16, 8> {\n-  typedef uint4 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat162, 1> {\n-  typedef __nv_bfloat162 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat162, 2> {\n-  typedef uint2 Type;\n-};\n-template <>\n-struct IOType<__nv_bfloat162, 4> {\n-  typedef uint4 Type;\n-};\n-\n-}  // namespace raft\n-\n-#endif  // XLA_BACKENDS_GPU_RUNTIME_RAFT_VECTORIZED_BF16_H_"
        },
        {
            "sha": "3ea99af65d570eaeb6572160619e1d1638c22a88",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 19,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #include <array>\n #include <cstddef>\n #include <cstdint>\n+#include <type_traits>\n \n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n@@ -37,7 +38,7 @@ namespace xla::gpu {\n \n namespace {\n \n-template <typename T>\n+template <int64_t kVectorSize>\n absl::Status LaunchTypedKernel(\n     se::Stream* stream, se::StreamExecutor* executor,\n     const se::ThreadDim& thread_dims, const se::BlockDim& block_dims,\n@@ -50,8 +51,9 @@ absl::Status LaunchTypedKernel(\n     se::DeviceMemoryBase output_offsets_buffer, int64_t num_updates_per_output,\n     int64_t num_row_elements) {\n   TF_ASSIGN_OR_RETURN(\n-      auto kernel, se::gpu::GpuKernelRegistry::GetGlobalRegistry()\n-                       .LoadKernel<se::gpu::RaggedAllToAllKernel<T>>(executor));\n+      auto kernel,\n+      se::gpu::GpuKernelRegistry::GetGlobalRegistry()\n+          .LoadKernel<se::gpu::RaggedAllToAllKernel<kVectorSize>>(executor));\n \n   return kernel.Launch(thread_dims, block_dims, stream, input_buffer,\n                        output_ptrs, input_offsets_buffer, send_sizes_buffer,\n@@ -63,11 +65,10 @@ absl::Status LaunchTypedKernel(\n \n bool IsRaggedAllToAllKernelSupported(int64_t num_outputs,\n                                      PrimitiveType element_type) {\n-  int bit_width = primitive_util::BitWidth(element_type);\n-\n   return num_outputs <= stream_executor::gpu::kMaxNumRaggedAllToAllOutputPtrs &&\n-         (bit_width == 8 || bit_width == 16 || bit_width == 32 ||\n-          bit_width == 64);\n+         // Currently, the kernel doesn't support data types that are smaller\n+         // than 1 byte.\n+         primitive_util::BitWidth(element_type) % 8 == 0;\n }\n \n absl::Status RunRaggedAllToAllKernel(\n@@ -94,11 +95,11 @@ absl::Status RunRaggedAllToAllKernel(\n   int64_t num_blocks_x = num_updates_per_output * num_outputs;\n \n   int64_t num_vectorized_row_elements = num_row_elements;\n-  int64_t vectorized_bitwidth = xla::primitive_util::BitWidth(element_type);\n+  int64_t vector_size_bytes = xla::primitive_util::BitWidth(element_type) / 8;\n \n-  while (num_vectorized_row_elements % 2 == 0 && vectorized_bitwidth < 64) {\n+  while (num_vectorized_row_elements % 2 == 0 && vector_size_bytes < 8) {\n     num_vectorized_row_elements /= 2;\n-    vectorized_bitwidth *= 2;\n+    vector_size_bytes *= 2;\n   }\n \n   // blockIdx.y and threadIdx.x are used to iterate over the elements of the\n@@ -122,21 +123,21 @@ absl::Status RunRaggedAllToAllKernel(\n \n   auto launch_kernel = [&](auto type) -> absl::Status {\n     using T = decltype(type);\n-    return LaunchTypedKernel<T>(\n+    return LaunchTypedKernel<T::value>(\n         stream, executor, thread_dims, block_dims, input_buffer, output_ptrs,\n         input_offsets_buffer, send_sizes_buffer, output_offsets_buffer,\n         num_updates_per_output, num_vectorized_row_elements);\n   };\n \n-  switch (vectorized_bitwidth) {\n+  switch (vector_size_bytes) {\n+    case 1:\n+      return launch_kernel(std::integral_constant<int64_t, 1>{});\n+    case 2:\n+      return launch_kernel(std::integral_constant<int64_t, 2>{});\n+    case 4:\n+      return launch_kernel(std::integral_constant<int64_t, 4>{});\n     case 8:\n-      return launch_kernel(uint8_t{});\n-    case 16:\n-      return launch_kernel(uint16_t{});\n-    case 32:\n-      return launch_kernel(uint32_t{});\n-    case 64:\n-      return launch_kernel(uint64_t{});\n+      return launch_kernel(std::integral_constant<int64_t, 8>{});\n     default:\n       return absl::InvalidArgumentError(absl::StrCat(\n           \"Unsupported element type: \","
        },
        {
            "sha": "9ceb364e0d649bcefe7e29c26547db4027eefcc5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -153,9 +153,6 @@ absl::Status RunRaggedAllToAll(\n   VLOG(3) << \"[\" << device_ordinal\n           << \"] Performing ragged-all-to-all from device ordinal: \"\n           << device_ordinal;\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), original_buffers,\n-                                          comm, use_symmetric_buffer));\n-\n   TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n \n   std::vector<DeviceBufferPair> buffers = original_buffers;\n@@ -325,8 +322,6 @@ absl::Status RunMemCpyRaggedAllToAll(\n     se::Event* start_event, se::Event* end_event) {\n   int device_ordinal = stream.parent()->device_ordinal();\n   VLOG(3) << \"[\" << device_ordinal << \"] Performing mem-copy-ragged-all-to-all\";\n-  TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm));\n-\n   TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n \n   PrimitiveType element_type = buffers[0].element_type;"
        },
        {
            "sha": "0e1e35b14e20af6fd88298a133b38f1e3d29e8cf",
            "filename": "third_party/xla/xla/backends/gpu/runtime/recv_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -99,9 +99,6 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n           << CollectiveOpGroupModeToString(config_.config.group_mode) << \" (\"\n           << hlo_name_ << \")\";\n \n-  TF_RETURN_IF_ERROR(\n-      MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n-\n   const std::optional<int64_t> source_id = source_target.source;\n   se::DeviceMemoryBase dest_addr = buffer.destination_buffer;\n \n@@ -132,6 +129,8 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n       ++(*counter);\n     }\n     if (should_run) {\n+      TF_RETURN_IF_ERROR(\n+          MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n       auto event = comm_handle.comm->Recv(\n           dest_addr, buffer.element_type, buffer.element_count,\n           RankId(*source_id), GpuCollectives::On(stream));"
        },
        {
            "sha": "ad734835cada8b2aa5d6292049712b6f0bc946cd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_raft.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -36,9 +36,6 @@ limitations under the License.\n #include \"raft/matrix/select_k.cuh\"\n #include \"raft/matrix/select_k_types.hpp\"\n #include \"xla/backends/gpu/runtime/select_k_exec.h\"\n-// NOTE: This include is required for vectorized BF16 GPU runtime support.\n-// It will no longer be needed after upgrading to raft v25.10.00.\n-#include \"xla/backends/gpu/runtime/raft_vectorized_bf16.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\""
        },
        {
            "sha": "403e401793c1f04c01848e2072b14d09d068367c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -99,9 +99,6 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n           << CollectiveOpGroupModeToString(config_.config.group_mode) << \" (\"\n           << hlo_name_ << \")\";\n \n-  TF_RETURN_IF_ERROR(\n-      MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n-\n   const std::optional<int64_t> target_id = source_target.target;\n   se::DeviceMemoryBase src_addr = buffer.source_buffer;\n \n@@ -133,6 +130,8 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n     }\n \n     if (should_run) {\n+      TF_RETURN_IF_ERROR(\n+          MaybeRegisterBuffers(stream.parent(), {buffer}, comm_handle.comm));\n       auto event = comm_handle.comm->Send(\n           src_addr, buffer.element_type, buffer.element_count,\n           RankId(*target_id), GpuCollectives::On(stream));"
        },
        {
            "sha": "268beec5c3b832d9249c63d6188a8f8cb0f8d0fc",
            "filename": "third_party/xla/xla/backends/profiler/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -482,6 +482,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n         \"@local_tsl//tsl/platform:abi\","
        },
        {
            "sha": "eef2447d9140189c3785ffa34efcd012a9d79008",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_collector.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_format.h\"\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n@@ -679,6 +680,7 @@ class EventInQueue {\n \n void PmSamples::PopulateCounterLine(XPlaneBuilder* plane,\n                                     uint64_t start_gpu_time_ns) {\n+  absl::flat_hash_map<std::string, int> skipped_nan_count_per_metric;\n   XLineBuilder line = plane->GetOrCreateCounterLine();\n   std::vector<std::pair<XEventMetadata*, XStatMetadata*>> counter_metadata;\n   counter_metadata.reserve(metrics_.size());\n@@ -690,6 +692,7 @@ void PmSamples::PopulateCounterLine(XPlaneBuilder* plane,\n     DCHECK_EQ(metrics_.size(), sampler_range.metric_values.size());\n     for (int i = 0; i < sampler_range.metric_values.size(); ++i) {\n       if (std::isnan(sampler_range.metric_values[i])) {\n+        ++skipped_nan_count_per_metric[counter_metadata[i].first->name()];\n         continue;\n       }\n       XEventBuilder event = line.AddEvent(\n@@ -702,6 +705,13 @@ void PmSamples::PopulateCounterLine(XPlaneBuilder* plane,\n                          sampler_range.metric_values[i]);\n     }\n   }\n+  for (const auto& [metric, count] : skipped_nan_count_per_metric) {\n+    plane->AddStatValue(\n+        *plane->GetOrCreateStatMetadata(tsl::profiler::GetStatTypeStr(\n+            tsl::profiler::StatType::kNanCounterEvents)),\n+        absl::StrFormat(\"Skipped %d NaN counter events for %s: \", count,\n+                        metric));\n+  }\n }\n \n size_t PmSamples::GetNumSamples() const { return sampler_ranges_.size(); }"
        },
        {
            "sha": "7de2faf6969069a4f3b2d8e9d7da6015a363d758",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_tracer_options_utils.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,11 +18,14 @@ limitations under the License.\n #include <cstdint>\n #include <functional>\n #include <string>\n+#include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/strings/ascii.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_join.h\"\n+#include \"absl/strings/str_split.h\"\n #include \"absl/strings/string_view.h\"\n #include \"third_party/gpus/cuda/extras/CUPTI/include/cupti_activity.h\"\n #include \"xla/backends/profiler/gpu/cupti_collector.h\"\n@@ -79,6 +82,24 @@ absl::Status UpdateCuptiTracerOptionsFromProfilerOptions(\n                        }\n                      }));\n \n+  TF_RETURN_IF_ERROR(SetValue<std::string>(\n+      profile_options, \"gpu_pm_sample_counters\", input_keys,\n+      [&](const std::string& value) {\n+        std::vector<std::string> metrics;\n+        for (absl::string_view metric :\n+             absl::StrSplit(value, ',', absl::SkipEmpty())) {\n+          metrics.push_back(std::string(absl::StripAsciiWhitespace(metric)));\n+        }\n+        tracer_options.pm_sampler_options.metrics = metrics;\n+        tracer_options.pm_sampler_options.enable = !metrics.empty();\n+      }));\n+\n+  TF_RETURN_IF_ERROR(SetValue<int64_t>(\n+      profile_options, \"gpu_pm_sample_interval_us\", input_keys,\n+      [&](int64_t value) {\n+        tracer_options.pm_sampler_options.sample_interval_ns = value * 1000;\n+      }));\n+\n   if (!input_keys.empty()) {\n     return absl::InvalidArgumentError(absl::StrCat(\n         \"Parsing advanced_configuration failed for CUPTI tracer. The following \""
        },
        {
            "sha": "cf1d9cfe6a36b5df31ca1722f5ea7dfb8085c0bf",
            "filename": "third_party/xla/xla/codegen/emitter_loc_op_builder.h",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitter_loc_op_builder.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -185,6 +185,33 @@ class EmitterLocOpBuilder : public mlir::ImplicitLocOpBuilder {\n         std::forward<Arg6>(arg6));\n   }\n \n+  template <typename OpTy, typename Arg0, typename Arg1, typename Arg2,\n+            typename Arg3, typename Arg4, typename Arg5, typename Arg6,\n+            typename Arg7>\n+  OpTy create(Arg0&& arg0, Arg1&& arg1, Arg2&& arg2, Arg3&& arg3, Arg4&& arg4,\n+              Arg5&& arg5, Arg6&& arg6, Arg7&& arg7,\n+              SourceLocation location = SourceLocation::current()) {\n+    return OpBuilder::create<OpTy>(\n+        Loc(location), std::forward<Arg0>(arg0), std::forward<Arg1>(arg1),\n+        std::forward<Arg2>(arg2), std::forward<Arg3>(arg3),\n+        std::forward<Arg4>(arg4), std::forward<Arg5>(arg5),\n+        std::forward<Arg6>(arg6), std::forward<Arg7>(arg7));\n+  }\n+\n+  template <typename OpTy, typename Arg0, typename Arg1, typename Arg2,\n+            typename Arg3, typename Arg4, typename Arg5, typename Arg6,\n+            typename Arg7, typename Arg8>\n+  OpTy create(Arg0&& arg0, Arg1&& arg1, Arg2&& arg2, Arg3&& arg3, Arg4&& arg4,\n+              Arg5&& arg5, Arg6&& arg6, Arg7&& arg7, Arg8&& arg8,\n+              SourceLocation location = SourceLocation::current()) {\n+    return OpBuilder::create<OpTy>(\n+        Loc(location), std::forward<Arg0>(arg0), std::forward<Arg1>(arg1),\n+        std::forward<Arg2>(arg2), std::forward<Arg3>(arg3),\n+        std::forward<Arg4>(arg4), std::forward<Arg5>(arg5),\n+        std::forward<Arg6>(arg6), std::forward<Arg7>(arg7),\n+        std::forward<Arg8>(arg8));\n+  }\n+\n   mlir::Location current_loc() const { return current_loc_; }\n \n   bool annotate_loc() const { return annotate_loc_; }"
        },
        {
            "sha": "99853eb64a26f052972e27816d4476de54d9dd85",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -62,7 +62,6 @@ cc_library(\n         \":atomic_rmw_utils\",\n         \":convert_pure_call_ops_pass\",\n         \":passes_inc_gen\",\n-        \":propagate_alias_scopes\",  # buildcleaner: keep\n         \":simplify_affine_pass\",\n         \":simplify_arith_pass\",\n         \"//xla:shape_util\",\n@@ -199,25 +198,6 @@ cc_library(\n     ],\n )\n \n-cc_library(\n-    name = \"propagate_alias_scopes\",\n-    srcs = [\"propagate_alias_scopes.cc\"],\n-    deps = [\n-        \":passes_inc_gen\",\n-        \"@com_google_absl//absl/container:flat_hash_map\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@llvm-project//llvm:Support\",\n-        \"@llvm-project//mlir:CallOpInterfaces\",\n-        \"@llvm-project//mlir:FuncDialect\",\n-        \"@llvm-project//mlir:IR\",\n-        \"@llvm-project//mlir:LLVMDialect\",\n-        \"@llvm-project//mlir:Pass\",\n-        \"@llvm-project//mlir:SCFDialect\",\n-        \"@llvm-project//mlir:Support\",\n-        \"@llvm-project//mlir:TensorDialect\",\n-    ],\n-)\n-\n cc_library(\n     name = \"pass_pipelines\",\n     srcs = [\"pass_pipelines.cc\"],"
        },
        {
            "sha": "a4affb0c614cecf5682b7c61e3bd66be7d02ea20",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/passes.td",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -203,20 +203,6 @@ def MergePointersToSameSlicePass :\n   let constructor = \"CreateMergePointersToSameSlicePass()\";\n }\n \n-def PropagateAliasScopesPass :\n-   Pass<\"xla-propagate-alias-scopes\", \"mlir::ModuleOp\"> {\n-  let summary = \"Propagates alias scopes from function args to tensor modifications.\";\n-\n-  let description = [{\n-      Propagates alias scopes from function args to tensor modifications.\n-  }];\n-\n-  let dependentDialects = [\n-    \"mlir::func::FuncDialect\",\n-    \"mlir::LLVM::LLVMDialect\",\n-  ];\n-}\n-\n def PropagateSliceIndicesPass :\n    Pass<\"xla-propagate-slice-indices\", \"mlir::ModuleOp\"> {\n   let summary = \"Propagates slice indices from the entry function to all callees.\";"
        },
        {
            "sha": "2f2710bad1854132f4c3597cbf24636fdc5cc763",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/propagate_alias_scopes.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 262,
            "changes": 262,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpropagate_alias_scopes.cc?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,262 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/container/flat_hash_map.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"llvm/ADT/STLExtras.h\"\n-#include \"llvm/ADT/SmallVector.h\"\n-#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMAttrs.h\"\n-#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n-#include \"mlir/Dialect/SCF/IR/SCF.h\"\n-#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n-#include \"mlir/IR/Attributes.h\"\n-#include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n-#include \"mlir/IR/MLIRContext.h\"\n-#include \"mlir/IR/Value.h\"\n-#include \"mlir/IR/Visitors.h\"\n-#include \"mlir/Interfaces/CallInterfaces.h\"\n-#include \"mlir/Pass/Pass.h\"  // IWYU pragma: keep\n-#include \"mlir/Support/LLVM.h\"\n-\n-namespace xla::emitters {\n-\n-#define GEN_PASS_DECL_PROPAGATEALIASSCOPESPASS\n-#define GEN_PASS_DEF_PROPAGATEALIASSCOPESPASS\n-#include \"xla/codegen/emitters/transforms/passes.h.inc\"\n-\n-auto kSliceIndexAttrName = \"xla.slice_index\";\n-auto kInvariantAttrName = \"xla.invariant\";\n-\n-class PropagateAliasScopesPass final\n-    : public impl::PropagateAliasScopesPassBase<PropagateAliasScopesPass> {\n- public:\n-  using PropagateAliasScopesPassBase::PropagateAliasScopesPassBase;\n-\n-  void runOnOperation() override;\n-\n- private:\n-  // Main callback for the walking the ops withing the function.\n-  mlir::WalkResult WalkCallback(mlir::Operation* op);\n-  // Propagate the slice index to the arguments of the function.\n-  mlir::WalkResult WalkCall(mlir::CallOpInterface call_op);\n-  // Propagate the slice index to the iter-args of the for loop.\n-  mlir::WalkResult WalkFor(mlir::scf::ForOp for_op);\n-  // Add the noalias scope to the extract op.\n-  mlir::WalkResult WalkExtract(mlir::tensor::ExtractOp extract_op);\n-  // Add the alias & noalias scope to the insert op.\n-  mlir::WalkResult WalkInsert(mlir::tensor::InsertOp insert_op);\n-\n-  // Initialize mapping from value to slice index and slice index to alias\n-  // scope.\n-  void InitializeBookeeping(mlir::func::FuncOp func_op);\n-  void InitializeAliasScopeBookeeping(mlir::func::FuncOp func_op);\n-  void InitializeNoAliasScopeBookeeping(mlir::MLIRContext* context);\n-\n- private:\n-  // Value to the slice index of the function argument.\n-  llvm::DenseMap<mlir::Value, int64_t> value_to_index_;\n-  // Slice index to the alias scope attribute.\n-  absl::flat_hash_map<int64_t, mlir::LLVM::AliasScopeAttr> index_to_alias_;\n-  // Slice index to the set of no alias scope attributes.\n-  absl::flat_hash_map<int64_t, mlir::ArrayAttr> index_to_no_alias_;\n-};\n-\n-static void SetAliasScopeMetadata(\n-    mlir::Operation& op, const mlir::LLVM::AliasScopeAttr& alias_scope) {\n-  op.setAttr(mlir::LLVM::LLVMDialect::getAliasScopesAttrName(),\n-             mlir::ArrayAttr::get(op.getContext(), alias_scope));\n-}\n-\n-static void SetNoAliasScopeMetadata(mlir::Operation& op,\n-                                    mlir::ArrayAttr alias_scopes) {\n-  if (alias_scopes.empty()) {\n-    return;\n-  }\n-  op.setAttr(mlir::LLVM::LLVMDialect::getNoAliasAttrName(), alias_scopes);\n-}\n-\n-void PropagateAliasScopesPass::runOnOperation() {\n-  mlir::ModuleOp module_op = getOperation();\n-\n-  mlir::func::FuncOp entry;\n-  for (auto func : getOperation().getOps<mlir::func::FuncOp>()) {\n-    if (func->getAttr(\"xla.entry\")) {\n-      entry = func;\n-      break;\n-    }\n-  }\n-\n-  if (!entry) {\n-    getOperation()->emitOpError(\"No entry function found.\");\n-    signalPassFailure();\n-    return;\n-  }\n-\n-  InitializeBookeeping(entry);\n-\n-  module_op->walk<mlir::WalkOrder::PreOrder>(\n-      [this](mlir::Operation* op) { return WalkCallback(op); });\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkCallback(mlir::Operation* op) {\n-  if (auto call_op = mlir::dyn_cast_or_null<mlir::CallOpInterface>(op)) {\n-    return WalkCall(call_op);\n-  }\n-\n-  if (auto for_op = mlir::dyn_cast_or_null<mlir::scf::ForOp>(op)) {\n-    return WalkFor(for_op);\n-  }\n-\n-  if (auto insert_op = mlir::dyn_cast_or_null<mlir::tensor::InsertOp>(op)) {\n-    return WalkInsert(insert_op);\n-  }\n-\n-  if (auto extract_op = mlir::dyn_cast_or_null<mlir::tensor::ExtractOp>(op)) {\n-    return WalkExtract(extract_op);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkCall(\n-    mlir::CallOpInterface call_op) {\n-  mlir::func::FuncOp callee =\n-      mlir::dyn_cast<mlir::func::FuncOp>(call_op.resolveCallable());\n-  if (!callee) {\n-    // Could be a call to an external function.\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  // Forward the slice index to the arguments of the callee.\n-  for (auto [arg, operand] :\n-       llvm::zip(callee.getArguments(), call_op.getArgOperands())) {\n-    auto slice_index_itr = value_to_index_.find(operand);\n-    if (slice_index_itr != value_to_index_.end()) {\n-      value_to_index_.insert({arg, slice_index_itr->second});\n-    }\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkFor(mlir::scf::ForOp for_op) {\n-  // Forward the slice index to the iter-args of the for loop.\n-  for (auto [arg, operand] :\n-       llvm::zip(for_op.getRegionIterArgs(), for_op.getInitArgs())) {\n-    auto slice_index_itr = value_to_index_.find(operand);\n-    if (slice_index_itr != value_to_index_.end()) {\n-      value_to_index_.insert({arg, slice_index_itr->second});\n-    }\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkExtract(\n-    mlir::tensor::ExtractOp extract_op) {\n-  auto index_itr = value_to_index_.find(extract_op.getTensor());\n-  if (index_itr == value_to_index_.end()) {\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  int64_t slice_index = index_itr->second;\n-\n-  if (auto no_alias_itr = index_to_no_alias_.find(slice_index);\n-      no_alias_itr != index_to_no_alias_.end()) {\n-    SetNoAliasScopeMetadata(*extract_op, no_alias_itr->second);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-mlir::WalkResult PropagateAliasScopesPass::WalkInsert(\n-    mlir::tensor::InsertOp insert_op) {\n-  auto index_itr = value_to_index_.find(insert_op.getDest());\n-  if (index_itr == value_to_index_.end()) {\n-    return mlir::WalkResult::advance();\n-  }\n-\n-  int64_t slice_index = index_itr->second;\n-\n-  if (const auto alias_itr = index_to_alias_.find(slice_index);\n-      alias_itr != index_to_alias_.end()) {\n-    SetAliasScopeMetadata(*insert_op, alias_itr->second);\n-  }\n-\n-  if (auto no_alias_itr = index_to_no_alias_.find(slice_index);\n-      no_alias_itr != index_to_no_alias_.end()) {\n-    SetNoAliasScopeMetadata(*insert_op, no_alias_itr->second);\n-  }\n-\n-  return mlir::WalkResult::advance();\n-}\n-\n-void PropagateAliasScopesPass::InitializeBookeeping(\n-    mlir::func::FuncOp func_op) {\n-  InitializeAliasScopeBookeeping(func_op);\n-  InitializeNoAliasScopeBookeeping(func_op.getContext());\n-}\n-\n-void PropagateAliasScopesPass::InitializeAliasScopeBookeeping(\n-    mlir::func::FuncOp func_op) {\n-  value_to_index_.clear();\n-  index_to_alias_.clear();\n-\n-  auto domain = mlir::LLVM::AliasScopeDomainAttr::get(func_op.getContext());\n-  for (mlir::BlockArgument arg : func_op.getArguments()) {\n-    auto slice_index_attr = func_op.getArgAttrOfType<mlir::IntegerAttr>(\n-        arg.getArgNumber(), kSliceIndexAttrName);\n-    if (!slice_index_attr) {\n-      continue;\n-    }\n-\n-    value_to_index_.insert({arg, slice_index_attr.getInt()});\n-\n-    // We only need to set the alias scope for arguments that are written to.\n-    if (func_op.getArgAttr(arg.getArgNumber(), kInvariantAttrName)) {\n-      continue;\n-    }\n-\n-    int64_t slice_index = slice_index_attr.getInt();\n-    auto scope = mlir::LLVM::AliasScopeAttr::get(\n-        domain, mlir::StringAttr::get(\n-                    func_op.getContext(),\n-                    absl::StrCat(kSliceIndexAttrName, \"=\", slice_index)));\n-    index_to_alias_.insert({slice_index, scope});\n-  }\n-}\n-\n-void PropagateAliasScopesPass::InitializeNoAliasScopeBookeeping(\n-    mlir::MLIRContext* context) {\n-  index_to_no_alias_.clear();\n-\n-  for (const auto& [value, slice_index] : value_to_index_) {\n-    std::vector<mlir::Attribute> no_alias;\n-    for (const auto& [inner_slice_index, no_alias_scope] : index_to_alias_) {\n-      if (inner_slice_index != slice_index) {\n-        no_alias.push_back(no_alias_scope);\n-      }\n-    }\n-    index_to_no_alias_.insert(\n-        {slice_index, mlir::ArrayAttr::get(context, no_alias)});\n-  }\n-}\n-\n-}  // namespace xla::emitters"
        },
        {
            "sha": "f221ba99db070fcae2f9fc2b0e1a0343ecf0b840",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/tests/propagate_alias_scopes.mlir",
            "status": "removed",
            "additions": 0,
            "deletions": 97,
            "changes": 97,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fpropagate_alias_scopes.mlir?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,97 +0,0 @@\n-// RUN: emitters_opt %s -split-input-file -xla-propagate-alias-scopes | FileCheck %s\n-\n-func.func @nested_for(\n-    %arg0: tensor<8x128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128x8xf32> {xla.slice_index = 1 : index}) -> tensor<128x8xf32>\n-    attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c8 = arith.constant 8 : index\n-  %c128 = arith.constant 128 : index\n-  %0 = scf.for %arg2 = %c0 to %c128 step %c1\n-      iter_args(%arg3 = %arg1) -> (tensor<128x8xf32>) {\n-    %1 = scf.for %arg4 = %c0 to %c8 step %c1\n-        iter_args(%arg5 = %arg3) -> (tensor<128x8xf32>) {\n-      %extracted = tensor.extract %arg0[%arg4, %arg2] : tensor<8x128xf32>\n-      %inserted = tensor.insert %extracted into\n-        %arg5[%arg2, %arg4] : tensor<128x8xf32>\n-      scf.yield %inserted : tensor<128x8xf32>\n-    }\n-    scf.yield %1 : tensor<128x8xf32>\n-  }\n-  func.return %0 : tensor<128x8xf32>\n-}\n-// CHECK-LABEL: func.func @nested_for\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE:[a-z0-9_]+]]\n-// CHECK: tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE]]\n-\n-// -----\n-\n-func.func @multi_output(\n-    %arg0: tensor<8x128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128x8xf32> {xla.slice_index = 1 : index},\n-    %arg2: tensor<128x8xf32> {xla.slice_index = 2 : index}\n-  ) -> (tensor<128x8xf32>, tensor<128x8xf32>) attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c8 = arith.constant 8 : index\n-  %c128 = arith.constant 128 : index\n-  %outer_res_0, %outer_res_1 = scf.for %outer_idx = %c0 to %c128 step %c1\n-      iter_args(%arg1_0 = %arg1, %arg2_0 = %arg2)\n-      -> (tensor<128x8xf32>, tensor<128x8xf32>) {\n-    %inner_res_0, %inner_res_1 = scf.for %inner_idx = %c0 to %c8 step %c1\n-        iter_args(%arg1_1 = %arg1_0, %arg2_1 = %arg2_0)\n-        -> (tensor<128x8xf32>, tensor<128x8xf32>) {\n-      %extracted = tensor.extract %arg0[%inner_idx, %outer_idx] : tensor<8x128xf32>\n-      %inserted_0 = tensor.insert %extracted into\n-        %arg1_1[%outer_idx, %inner_idx] : tensor<128x8xf32>\n-      %inserted_1 = tensor.insert %extracted into\n-        %arg2_1[%outer_idx, %inner_idx] : tensor<128x8xf32>\n-      scf.yield %inserted_0, %inserted_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-    }\n-    scf.yield %inner_res_0, %inner_res_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-  }\n-  func.return %outer_res_0, %outer_res_1 : tensor<128x8xf32>, tensor<128x8xf32>\n-}\n-// CHECK-LABEL: func.func @multi_output\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE_1:[a-z0-9_]+]],\n-// CHECK-SAME: #[[ALIAS_SCOPE_2:[a-z0-9_]+]]\n-// CHECK-DAG : tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE_1]]],\n-// CHECK-DAG-SAME: llvm.noalias = [#[[ALIAS_SCOPE_2]]]\n-// CHECK-DAG : tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE_2]]],\n-// CHECK-DAG-SAME: llvm.noalias = [#[[ALIAS_SCOPE_1]]]\n-\n-// -----\n-\n-func.func @sub_call(\n-    %arg0: tensor<128xf32> {xla.invariant, xla.slice_index = 0 : index},\n-    %arg1: tensor<128xf32> {xla.slice_index = 1 : index}) -> tensor<128xf32>\n-    attributes { xla.entry }\n-{\n-  %c0 = arith.constant 0 : index\n-  %c1 = arith.constant 1 : index\n-  %c128 = arith.constant 128 : index\n-  %0 = scf.for %index = %c0 to %c128 step %c1\n-      iter_args(%arg3 = %arg1) -> (tensor<128xf32>) {\n-    %result = xla.pure_call @sub_call_sub(%index, %arg0, %arg1)\n-      : (index, tensor<128xf32>, tensor<128xf32>) -> tensor<128xf32>\n-    scf.yield %result : tensor<128xf32>\n-  }\n-  func.return %0 : tensor<128xf32>\n-}\n-\n-func.func @sub_call_sub(\n-    %index: index, %arg0: tensor<128xf32>, %arg1: tensor<128xf32>\n-  ) -> tensor<128xf32>\n-{\n-  %extracted = tensor.extract %arg0[%index] : tensor<128xf32>\n-  %inserted = tensor.insert %extracted into %arg1[%index] : tensor<128xf32>\n-  func.return %inserted : tensor<128xf32>\n-}\n-\n-// CHECK-LABEL: func.func @sub_call\n-// CHECK-LABEL: func.func @sub_call_sub\n-// CHECK: tensor.extract {{.*}}llvm.noalias = [#[[ALIAS_SCOPE:[a-z0-9_]+]]\n-// CHECK: tensor.insert {{.*}}alias_scopes = [#[[ALIAS_SCOPE]]"
        },
        {
            "sha": "af1179e932bd7acaca66619345504fc5adc2e631",
            "filename": "third_party/xla/xla/codegen/intrinsic/simple_jit_runner.cc",
            "status": "modified",
            "additions": 73,
            "deletions": 0,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/base/call_once.h\"\n+#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"llvm/ADT/StringMap.h\"\n #include \"llvm/ExecutionEngine/JITEventListener.h\"\n@@ -34,6 +35,7 @@ limitations under the License.\n #include \"llvm/ExecutionEngine/Orc/ThreadSafeModule.h\"\n #include \"llvm/ExecutionEngine/SectionMemoryManager.h\"\n #include \"llvm/IR/BasicBlock.h\"\n+#include \"llvm/IR/Constants.h\"\n #include \"llvm/IR/DerivedTypes.h\"\n #include \"llvm/IR/Function.h\"\n #include \"llvm/IR/IRBuilder.h\"\n@@ -45,6 +47,7 @@ limitations under the License.\n #include \"llvm/IR/Verifier.h\"\n #include \"llvm/MC/TargetRegistry.h\"\n #include \"llvm/Support/Alignment.h\"\n+#include \"llvm/Support/Casting.h\"\n #include \"llvm/Support/Errc.h\"\n #include \"llvm/Support/Error.h\"\n #include \"llvm/Support/ErrorHandling.h\"\n@@ -255,4 +258,74 @@ std::unique_ptr<llvm::TargetMachine> CreateHostTargetMachine() {\n   LOG_IF(FATAL, !target_machine) << \"Failed to create target machine\";\n   return target_machine;\n }\n+// Creates a new LLVM function that wraps an existing function by unrolling\n+// calls in a sequence.\n+//\n+// This function takes an `original_func` and generates a new function with an\n+// identical signature. Instead of a loop, the new function's body consists of\n+// an explicitly unrolled sequence of `unroll_factor` calls to the original\n+// function. This avoids loop overhead and is suitable for small K.\n+//\n+// `vector_size`: The size of the vectors being processed.\n+// Returns a pointer to the newly created unrolled wrapper function.\n+llvm::Function* CreateKTimesWrapper(llvm::Module* module,\n+                                    llvm::Function* original_func,\n+                                    int unroll_factor, size_t vector_size) {\n+  CHECK_GE(unroll_factor, 1);\n+\n+  llvm::LLVMContext& ctx = module->getContext();\n+  llvm::IRBuilder<> builder(ctx);\n+\n+  llvm::FunctionType* func_type = original_func->getFunctionType();\n+  std::string wrapper_name =\n+      std::string(original_func->getName()) + \"_unrolled_k_times\";\n+  llvm::Function* wrapper_func = llvm::Function::Create(\n+      func_type, llvm::Function::InternalLinkage, wrapper_name, module);\n+\n+  llvm::BasicBlock* entry =\n+      llvm::BasicBlock::Create(ctx, \"entry\", wrapper_func);\n+  builder.SetInsertPoint(entry);\n+\n+  // Collect the wrapper's arguments to be used as the base for each call.\n+  std::vector<llvm::Value*> wrapper_args;\n+  for (auto& arg : wrapper_func->args()) {\n+    wrapper_args.push_back(&arg);\n+  }\n+\n+  llvm::Value* last_result = nullptr;\n+  CHECK(!wrapper_args.empty()) << \"Function has no arguments.\";\n+  llvm::Type* scalar_type =\n+      llvm::cast<llvm::VectorType>(wrapper_args[0]->getType())\n+          ->getElementType();\n+  CHECK(scalar_type->isFloatingPointTy())\n+      << \"Only floating point types are supported.\";\n+  // Perturb the first argument by adding a small constant to\n+  // prevent the compiler from optimizing. The delta value is not important.\n+  llvm::Value* delta = llvm::ConstantFP::get(scalar_type, 0.000001);\n+\n+  // Use a C++ loop to generate an unrolled sequence of LLVM instructions.\n+  for (int k = 0; k < unroll_factor; ++k) {\n+    std::vector<llvm::Value*> call_args = wrapper_args;  // Reset to base args\n+\n+    // Perturb the first argument: arg0 + (k * 0.000001f)\n+    llvm::Value* k_fp =\n+        llvm::ConstantFP::get(scalar_type, static_cast<double>(k));\n+\n+    llvm::Value* offset_scalar = builder.CreateFMul(k_fp, delta);\n+    llvm::Value* offset_vec = builder.CreateVectorSplat(\n+        llvm::ElementCount::getFixed(vector_size), offset_scalar);\n+\n+    // Create the new argument for this specific call\n+    call_args[0] = builder.CreateFAdd(wrapper_args[0], offset_vec,\n+                                      \"perturbed.arg.\" + std::to_string(k));\n+\n+    last_result = builder.CreateCall(original_func, call_args,\n+                                     \"call.\" + std::to_string(k));\n+  }\n+\n+  // After the loop, `last_result` holds the result of the final call.\n+  builder.CreateRet(last_result);\n+\n+  return wrapper_func;\n+}\n }  // namespace xla::codegen::intrinsic"
        },
        {
            "sha": "f84fb55aacdc1916962d8c7d05ae04d0c76e431d",
            "filename": "third_party/xla/xla/codegen/intrinsic/simple_jit_runner.h",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Fsimple_jit_runner.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -152,6 +152,22 @@ class JitRunner {\n \n std::unique_ptr<llvm::TargetMachine> CreateHostTargetMachine();\n \n+// Creates a new LLVM function that wraps an existing function by\n+// unrolling calls in a sequence.\n+//\n+// This function takes an `original_func` and generates a new function with an\n+// identical signature. Instead of a loop, the new function's body consists of\n+// an explicitly unrolled sequence of `unroll_factor` calls to the original\n+// function. This avoids loop overhead and is suitable for small K.\n+// This primarily serves as a knob to attempt to reduce the dependence of very\n+// small kernels on memory bandwidth.\n+//\n+// `vector_size`: The size of the vectors being processed.\n+// Returns a pointer to the newly created unrolled wrapper function.\n+llvm::Function* CreateKTimesWrapper(llvm::Module* module,\n+                                    llvm::Function* original_func,\n+                                    int unroll_factor, size_t vector_size);\n+\n }  // namespace xla::codegen::intrinsic\n \n #endif  // XLA_CODEGEN_INTRINSIC_SIMPLE_JIT_RUNNER_H_"
        },
        {
            "sha": "af5fd0e8d22b3bc70d1e0dd4d1be445faca3832b",
            "filename": "third_party/xla/xla/core/collectives/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -73,6 +73,7 @@ cc_library(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/service:collective_ops_utils\",\n         \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:platform\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/status\","
        },
        {
            "sha": "901eda21d2d50a564e4392ab69304a8d6e90b932",
            "filename": "third_party/xla/xla/core/collectives/communicator.h",
            "status": "modified",
            "additions": 7,
            "deletions": 21,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2Fcommunicator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2Fcommunicator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcore%2Fcollectives%2Fcommunicator.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/platform.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/chain.h\"\n #include \"xla/util.h\"\n@@ -66,30 +67,15 @@ class Communicator {\n     virtual absl::Status Unregister() = 0;\n   };\n \n-  // Register `buffer` for efficient collective operations (i.e. on NCCL backend\n-  // it registers the buffer for zero-copy collective operations).\n-  virtual absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>>\n-  RegisterBuffer(stream_executor::DeviceMemoryBase buffer) {\n+  // Register `buffer_range` once for efficient collective operations (i.e. on\n+  // NCCL backend it registers the buffer for zero-copy collective operations).\n+  //\n+  virtual absl::Status RegisterBufferOnce(se::DeviceMemoryBase buffer_range,\n+                                          int device_ordinal,\n+                                          bool use_symmetric_buffer) {\n     return Unimplemented(\"User-managed buffer registration is not supported\");\n   }\n \n-  // Register `buffer` for efficient collective operations (i.e. on NCCL backend\n-  // it registers the buffer for zero-copy collective operations).\n-  // If `use_symmetric_buffer` is true, the buffer is registered as a symmetric\n-  // buffer.\n-  virtual absl::StatusOr<std::unique_ptr<RegisteredBufferHandle>>\n-  RegisterBuffer(stream_executor::DeviceMemoryBase buffer,\n-                 bool use_symmetric_buffer) {\n-    return Unimplemented(\"User-managed buffer registration is not supported\");\n-  }\n-\n-  // Register `buffer` for efficient collective operations (i.e. on NVSHMEM\n-  // backend it registers the buffer for unregistered nvshmem buffers).\n-  virtual absl::Status RegisterBuffer(void* addr, size_t length) {\n-    return absl::UnimplementedError(\n-        \"User-managed buffer registration is not supported\");\n-  }\n-\n   // Abort any uncompleted operations and destroys the underlying communicator\n   // object. It is undefined behavior to use the communicator after calling\n   // this method."
        },
        {
            "sha": "2785e7fc1fd36fd16afc7d9853cd3f676c1ce60c",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -432,7 +432,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_enable_fast_math(false);\n   opts.set_xla_gpu_experimental_parallel_collective_overlap_limit(1);\n   opts.set_xla_pjrt_allow_auto_layout_in_hlo(false);\n-  opts.set_xla_gpu_enable_scatter_determinism_expander(true);\n+  opts.set_xla_gpu_enable_scatter_determinism_expander(false);\n   opts.set_xla_gpu_unsupported_enable_ragged_all_to_all_decomposer(false);\n   opts.set_xla_gpu_unsupported_use_all_reduce_one_shot_kernel(false);\n   opts.set_xla_gpu_unsupported_use_ragged_all_to_all_one_shot_kernel(true);"
        },
        {
            "sha": "4b05a2c9ae1fdd7b085c9fb2e3d0462bdd8feb0d",
            "filename": "third_party/xla/xla/ffi/ffi_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fffi%2Fffi_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1046,7 +1046,7 @@ TEST(FfiTest, AsyncHandler) {\n   auto fn = [&](const Eigen::ThreadPoolDevice* device) {\n     auto async_value = tsl::MakeConstructedAsyncValueRef<tsl::Chain>();\n \n-    device->enqueueNoNotification([&, async_value]() mutable {\n+    device->enqueueNoNotification([&value, async_value]() {\n       value = 42;\n       async_value.SetStateConcrete();\n     });"
        },
        {
            "sha": "85925718216ad9ef2982be006792d533763bc092",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dataflow_analysis.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -329,7 +329,7 @@ HloValue& HloDataflowAnalysis::GetValueDefinedAt(\n HloValue* HloDataflowAnalysis::NewHloValue(HloInstruction* instruction,\n                                            const ShapeIndex& index,\n                                            bool is_phi) {\n-  const int64_t value_id = next_value_id_++;\n+  const int64_t value_id = NewValueId();\n   auto result =\n       values_.insert({value_id, std::make_unique<HloValue>(\n                                     value_id, instruction, index, is_phi)});"
        },
        {
            "sha": "8c88c63e1dcffba32eb5f60257d10fa84c2a4098",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dataflow_analysis.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -126,6 +126,9 @@ class HloDataflowAnalysis {\n   // Returns a vector of all HloValues stabily sorted by HloValue::Id.\n   const std::vector<HloValue*>& values() const { return values_vector_; }\n \n+  // Returns a new value Id to use.\n+  HloValue::Id NewValueId() { return next_value_id_++; }\n+\n   // Returns the call graph used for computing the dataflow.\n   const CallGraph& call_graph() const { return *call_graph_; }\n "
        },
        {
            "sha": "24397d64f4011581303c7df27971f439e222297c",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_reachability.h",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_reachability.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_reachability.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_reachability.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -132,7 +132,13 @@ class HloReachabilityMap {\n \n   // Checks if an instruction is in the Reachability map.\n   bool IsPresent(const HloInstruction* instruction) const {\n-    return indices_.contains(GetKey(instruction));\n+    // If we cannot construct the key, then the instruction is not in the\n+    // reachability map.\n+    return (instruction == nullptr\n+                ? false\n+                : (instruction->GetModule() != nullptr\n+                       ? indices_.contains(GetKey(instruction))\n+                       : false));\n   }\n \n   // Replace the instruction \"original\" with \"replacement\" in the reachability"
        },
        {
            "sha": "9e6d6f9abb1c174f8b1de87d831de952acf92c94",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1267,9 +1267,12 @@ IndexingMap GetBitcastMap(const Shape& input_shape, const Shape& output_shape,\n                           MLIRContext* mlir_context) {\n   ShapeUtil::BitcastDecomposition decomposed_bitcast =\n       ShapeUtil::DecomposeBitcast(input_shape, output_shape);\n+  if (!decomposed_bitcast.has_value()) {\n+    return IndexingMap::GetUndefined();\n+  }\n \n   if (std::holds_alternative<ShapeUtil::BitcastDecompositionTranspose>(\n-          decomposed_bitcast)) {\n+          *decomposed_bitcast)) {\n     auto permutation = ShapeUtil::DeduceTransposeDimensionsForBitcast(\n         input_shape, output_shape);\n     CHECK(permutation.has_value())\n@@ -1280,15 +1283,15 @@ IndexingMap GetBitcastMap(const Shape& input_shape, const Shape& output_shape,\n         input_shape.dimensions(), {});\n   }\n   if (std::holds_alternative<ShapeUtil::BitcastDecompositionReshape>(\n-          decomposed_bitcast)) {\n+          *decomposed_bitcast)) {\n     // Note: ComputeReshapeIndexingMap assumes it's computing an output->input\n     // indexing, so input and output are reversed.\n     return IndexingMap::FromTensorSizes(\n         ComputeReshapeIndexingMap(output_shape, input_shape, mlir_context),\n         input_shape.dimensions(), {});\n   }\n   // `trt` stands for transpose-reshape-transpose decomposition of bitcast.\n-  auto trt = std::get<ShapeUtil::BitcastDecompositionTrt>(decomposed_bitcast);\n+  auto trt = std::get<ShapeUtil::BitcastDecompositionTrt>(*decomposed_bitcast);\n   auto transpose_map_1 =\n       ComputeTransposeIndexingMap(trt.transpose1_dims, mlir_context);\n   auto reshape_map = ComputeReshapeIndexingMap("
        },
        {
            "sha": "297264c02bef0a75218904941c222b6fed4c79ea",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/stablehlo_utils.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fstablehlo_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fstablehlo_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fstablehlo_utils.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -49,7 +49,6 @@ absl::StatusOr<std::unique_ptr<xla::HloModule>> ConvertShardyToHlo(\n   // need to add an option to to convert to custom call @Sharding.\n   xla::sdy::StablehloExportPipelineOptions options;\n   options.keepHloShardingConstraints = true;\n-  options.keepShardMapBodyAsFunc = true;\n   xla::sdy::addStablehloExportPipeline(pm, options);\n \n   mlir::BaseScopedDiagnosticHandler diagnostic_handler("
        },
        {
            "sha": "33ddc2e1ebada9f618740b160614c74466ec17c2",
            "filename": "third_party/xla/xla/hlo/ir/hlo_casting_utils.h",
            "status": "modified",
            "additions": 17,
            "deletions": 7,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_casting_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_casting_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_casting_utils.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -48,39 +48,49 @@ inline std::string WrongCastError(const HloInstruction* instr) {\n       \"HloInstruction '%s' is of type '%s' and cannot be downcasted to '%s.'\",\n       instr->name(), TypeName(instr), TypeName<T>());\n }\n+\n+template <typename T, typename I>\n+inline T* CastImpl(I* instr) {\n+  CHECK(instr != nullptr);\n+  CHECK(T::ClassOf(instr)) << cast_internal::WrongCastError<T>(instr);\n+  return tsl::down_cast<T*>(instr);\n+}\n+\n+template <typename T, typename I>\n+inline T* DynCastImpl(I* instr) {\n+  CHECK(instr != nullptr);\n+  return !T::ClassOf(instr) ? nullptr : tsl::down_cast<T*>(instr);\n+}\n }  // namespace cast_internal\n \n // Downcasts a const HloInstruction pointer. Dies if argument is nullptr or\n // TargetClass::ClassOf() does not match. Similar to LLVM's cast.\n template <typename T>\n const T* Cast(const HloInstruction* instr) {\n-  CHECK(instr != nullptr);\n-  CHECK(T::ClassOf(instr)) << cast_internal::WrongCastError<T>(instr);\n-  return tsl::down_cast<const T*>(instr);\n+  return cast_internal::CastImpl<const T>(instr);\n }\n \n // Downcasts a non-const HloInstruction pointer. Dies if argument is nullptr or\n // TargetClass::ClassOf() does not match. Similar to LLVM's cast.\n template <typename T>\n T* Cast(HloInstruction* instr) {\n-  return const_cast<T*>(Cast<T>(const_cast<const HloInstruction*>(instr)));\n+  return cast_internal::CastImpl<T>(instr);\n }\n \n // Downcasts a const HloInstruction pointer or returns nullptr if\n // TargetClass::ClassOf() does not match. Dies if argument is nullptr. Similar\n // to LLVM's dyn_cast.\n template <typename T>\n const T* DynCast(const HloInstruction* i) {\n-  CHECK(i != nullptr);\n-  return !T::ClassOf(i) ? nullptr : tsl::down_cast<const T*>(i);\n+  return cast_internal::DynCastImpl<const T>(i);\n }\n \n // Downcasts a non-const HloInstruction pointer or returns nullptr if\n // TargetClass::ClassOf() does not match. Dies if argument is nullptr. Similar\n // to LLVM's dyn_cast.\n template <typename T>\n T* DynCast(HloInstruction* i) {\n-  return const_cast<T*>(DynCast<T>(const_cast<const HloInstruction*>(i)));\n+  return cast_internal::DynCastImpl<T>(i);\n }\n \n }  // namespace xla"
        },
        {
            "sha": "fd8bb74e39895dc2e9b09babfa374d1610a9a9fb",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_main.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 4,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_main.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -128,12 +128,28 @@ absl::StatusOr<std::unique_ptr<HloModule>> LoadHLOModule(\n     return BuildHloModule(snapshot.hlo().hlo_module());\n   }\n   if (!hlo_path.hlo_proto.empty()) {\n-    return ReadModuleFromBinaryProtoFile(hlo_path.hlo_proto,\n-                                         xla::GetDebugOptionsFromFlags());\n+    absl::StatusOr<std::unique_ptr<HloModule>> module =\n+        ReadModuleFromBinaryProtoFile(hlo_path.hlo_proto,\n+                                      xla::GetDebugOptionsFromFlags());\n+    if (module.ok()) {\n+      return module;\n+    }\n+    LOG(INFO) << \"Failed to read \" << hlo_path.hlo_proto\n+              << \" as a binary proto, attempting to read as text proto.\";\n+    return ReadModuleFromTextProtoFile(hlo_path.hlo_proto,\n+                                       xla::GetDebugOptionsFromFlags());\n   }\n   if (!hlo_path.hlo_module_proto.empty()) {\n-    return ReadModuleFromModuleBinaryProtofile(hlo_path.hlo_module_proto,\n-                                               xla::GetDebugOptionsFromFlags());\n+    absl::StatusOr<std::unique_ptr<HloModule>> module =\n+        ReadModuleFromModuleBinaryProtofile(hlo_path.hlo_module_proto,\n+                                            xla::GetDebugOptionsFromFlags());\n+    if (module.ok()) {\n+      return module;\n+    }\n+    LOG(INFO) << \"Failed to read \" << hlo_path.hlo_module_proto\n+              << \" as a binary proto, attempting to read as text proto.\";\n+    return ReadModuleFromModuleTextProtoFile(hlo_path.hlo_module_proto,\n+                                             xla::GetDebugOptionsFromFlags());\n   }\n   if (!hlo_path.hlo_text.empty()) {\n     return ReadModuleFromHloTextFile("
        },
        {
            "sha": "5430c227a16f3e22eff6f91ac8f92bb2767bea3f",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_result.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 18,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -42,6 +42,39 @@ bool IsChangedInstruction(const HloInstructionNode* left_node,\n \n }  // namespace\n \n+void DiffResult::AddUnchangedInstruction(const HloInstruction* left,\n+                                         const HloInstruction* right) {\n+  unchanged_instructions[left] = right;\n+  left_diff_codes[left] = DiffType::kUnchanged;\n+  right_diff_codes[right] = DiffType::kUnchanged;\n+}\n+\n+void DiffResult::AddChangedInstruction(const HloInstruction* left,\n+                                       const HloInstruction* right) {\n+  changed_instructions[left] = right;\n+  left_diff_codes[left] = DiffType::kChanged;\n+  right_diff_codes[right] = DiffType::kChanged;\n+}\n+\n+void DiffResult::AddMovedInstruction(const HloInstruction* left,\n+                                     const HloInstruction* right) {\n+  moved_instructions[left] = right;\n+  left_diff_codes[left] = DiffType::kUnchanged;\n+  right_diff_codes[right] = DiffType::kUnchanged;\n+}\n+\n+void DiffResult::AddUnmatchedInstruction(const HloInstruction* left,\n+                                         const HloInstruction* right) {\n+  if (left != nullptr) {\n+    left_module_unmatched_instructions.insert(left);\n+    left_diff_codes[left] = DiffType::kUnmatched;\n+  }\n+  if (right != nullptr) {\n+    right_module_unmatched_instructions.insert(right);\n+    right_diff_codes[right] = DiffType::kUnmatched;\n+  }\n+}\n+\n std::unique_ptr<const DiffResult> ConstructDiffResult(\n     const HloGumgraph& left_graph, const HloGumgraph& right_graph,\n     const HloGumgraphMappings& mappings) {\n@@ -64,8 +97,7 @@ std::unique_ptr<const DiffResult> ConstructDiffResult(\n \n     // The node is unmatched\n     if (!mappings.InstructionMapContainsLeft(left_node)) {\n-      diff_result->left_module_unmatched_instructions.insert(\n-          left_node->instruction);\n+      diff_result->AddUnmatchedInstruction(left_node->instruction, nullptr);\n       continue;\n     }\n \n@@ -84,19 +116,19 @@ std::unique_ptr<const DiffResult> ConstructDiffResult(\n         mapping_props->matcher_debug_info;\n \n     if (IsChangedInstruction(left_node, right_node)) {\n-      diff_result->changed_instructions[left_node->instruction] =\n-          right_node->instruction;\n+      diff_result->AddChangedInstruction(left_node->instruction,\n+                                         right_node->instruction);\n       continue;\n     }\n     // If node position is unchanged, add to unchanged instructions.\n     if (mapping_props->unchanged) {\n-      diff_result->unchanged_instructions[left_node->instruction] =\n-          right_node->instruction;\n+      diff_result->AddUnchangedInstruction(left_node->instruction,\n+                                           right_node->instruction);\n       continue;\n     }\n     // TODO(b/369851244): Add moved instructions to diff result.\n-    diff_result->unchanged_instructions[left_node->instruction] =\n-        right_node->instruction;\n+    diff_result->AddUnchangedInstruction(left_node->instruction,\n+                                         right_node->instruction);\n   }\n \n   for (const HloInstructionNode* right_node : right_all_nodes) {\n@@ -106,8 +138,7 @@ std::unique_ptr<const DiffResult> ConstructDiffResult(\n     diff_result->node_props_right.insert(\n         {right_node->instruction, right_node->props});\n     if (!mappings.InstructionMapContainsRight(right_node)) {\n-      diff_result->right_module_unmatched_instructions.insert(\n-          right_node->instruction);\n+      diff_result->AddUnmatchedInstruction(nullptr, right_node->instruction);\n     }\n   }\n \n@@ -160,20 +191,21 @@ DiffResult DiffResult::FromProto(const DiffResultProto& proto,\n   DiffResult diff_result;\n   for (const MatchedInstructionPairProto& pair :\n        proto.unchanged_instructions()) {\n-    diff_result.unchanged_instructions[left_instructions_by_name[pair.left()]] =\n-        right_instructions_by_name[pair.right()];\n+    diff_result.AddUnchangedInstruction(\n+        left_instructions_by_name[pair.left()],\n+        right_instructions_by_name[pair.right()]);\n   }\n   for (const MatchedInstructionPairProto& pair : proto.changed_instructions()) {\n-    diff_result.changed_instructions[left_instructions_by_name[pair.left()]] =\n-        right_instructions_by_name[pair.right()];\n+    diff_result.AddChangedInstruction(left_instructions_by_name[pair.left()],\n+                                      right_instructions_by_name[pair.right()]);\n   }\n   for (const std::string& name : proto.left_unmatched_instructions()) {\n-    diff_result.left_module_unmatched_instructions.insert(\n-        left_instructions_by_name[name]);\n+    diff_result.AddUnmatchedInstruction(left_instructions_by_name[name],\n+                                        nullptr);\n   }\n   for (const std::string& name : proto.right_unmatched_instructions()) {\n-    diff_result.right_module_unmatched_instructions.insert(\n-        right_instructions_by_name[name]);\n+    diff_result.AddUnmatchedInstruction(nullptr,\n+                                        right_instructions_by_name[name]);\n   }\n \n   return diff_result;"
        },
        {
            "sha": "6bcacf6b074da93215e44371a1d7cfc8ce8aa529",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_result.h",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,6 +17,7 @@\n #ifndef XLA_HLO_TOOLS_HLO_DIFF_HLO_DIFF_RESULT_H_\n #define XLA_HLO_TOOLS_HLO_DIFF_HLO_DIFF_RESULT_H_\n \n+#include <cstdint>\n #include <memory>\n #include <string>\n #include <utility>\n@@ -32,6 +33,8 @@\n namespace xla {\n namespace hlo_diff {\n \n+enum DiffType : uint8_t { kUnchanged, kChanged, kUnmatched, kMoved };\n+\n // Result of diff'ng the left and right HLO modules. Contains the matched and\n // unmatched instructions in the two modules.\n struct DiffResult {\n@@ -48,6 +51,10 @@ struct DiffResult {\n   absl::flat_hash_set<const HloInstruction*>\n       right_module_unmatched_instructions;\n \n+  // Diff codes.\n+  absl::flat_hash_map<const HloInstruction*, DiffType> left_diff_codes;\n+  absl::flat_hash_map<const HloInstruction*, DiffType> right_diff_codes;\n+\n   // Debug info.\n   absl::flat_hash_map<std::pair<const HloInstruction*, const HloInstruction*>,\n                       MatcherType>\n@@ -60,6 +67,16 @@ struct DiffResult {\n   absl::flat_hash_map<const HloInstruction*, HloInstructionNodeProps>\n       node_props_right;\n \n+  // Methods to add diffs.\n+  void AddUnchangedInstruction(const HloInstruction* left,\n+                               const HloInstruction* right);\n+  void AddChangedInstruction(const HloInstruction* left,\n+                             const HloInstruction* right);\n+  void AddMovedInstruction(const HloInstruction* left,\n+                           const HloInstruction* right);\n+  void AddUnmatchedInstruction(const HloInstruction* left,\n+                               const HloInstruction* right);\n+\n   // Converts the diff result to a proto.\n   DiffResultProto ToProto() const;\n "
        },
        {
            "sha": "7c9342a555182bc5120c11f642befa93bcd31c26",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_result_test.cc",
            "status": "modified",
            "additions": 70,
            "deletions": 0,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_result_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -102,6 +102,23 @@ ENTRY entry {\n               UnorderedElementsAre(Pair(\n                   Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n                   Pointee(Property(&HloInstruction::name, \"parameter.1\")))));\n+\n+  EXPECT_THAT(diff_result->left_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kUnchanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kChanged)));\n+  EXPECT_THAT(diff_result->right_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kUnchanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kChanged)));\n }\n \n TEST_F(HloDiffTest, MatchedDifferentFingerprintMarkAsChanged) {\n@@ -169,6 +186,23 @@ ENTRY entry {\n   //             UnorderedElementsAre(\n   //                 Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n   //                      Pointee(Property(&HloInstruction::name, \"add.0\")))));\n+\n+  EXPECT_THAT(diff_result->left_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kChanged)));\n+  EXPECT_THAT(diff_result->right_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kChanged),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kChanged)));\n }\n \n TEST_F(HloDiffTest, UnmatchedInstructionsMarkAsUnmatched) {\n@@ -226,6 +260,23 @@ ENTRY entry {\n               UnorderedElementsAre(\n                   Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n                   Pointee(Property(&HloInstruction::name, \"parameter.1\"))));\n+\n+  EXPECT_THAT(diff_result->left_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kUnmatched),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kUnmatched),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kUnchanged)));\n+  EXPECT_THAT(diff_result->right_diff_codes,\n+              UnorderedElementsAre(\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+                       DiffType::kUnmatched),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"parameter.1\")),\n+                       DiffType::kUnmatched),\n+                  Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+                       DiffType::kUnchanged)));\n }\n \n TEST_F(HloDiffTest, ShortFormConstantsMatched) {\n@@ -298,6 +349,25 @@ ENTRY entry {\n                Pointee(Property(&HloInstruction::name, \"parameter.0\"))),\n           Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n                Pointee(Property(&HloInstruction::name, \"add.0\")))));\n+\n+  EXPECT_THAT(\n+      diff_result->left_diff_codes,\n+      UnorderedElementsAre(\n+          Pair(Pointee(Property(&HloInstruction::name, \"constant.2958\")),\n+               DiffType::kUnchanged),\n+          Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+               DiffType::kUnchanged),\n+          Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+               DiffType::kUnchanged)));\n+  EXPECT_THAT(\n+      diff_result->right_diff_codes,\n+      UnorderedElementsAre(\n+          Pair(Pointee(Property(&HloInstruction::name, \"constant.2958\")),\n+               DiffType::kUnchanged),\n+          Pair(Pointee(Property(&HloInstruction::name, \"parameter.0\")),\n+               DiffType::kUnchanged),\n+          Pair(Pointee(Property(&HloInstruction::name, \"add.0\")),\n+               DiffType::kUnchanged)));\n }\n \n TEST_F(HloDiffTest, DiffResultToAndFromProtoWorks) {"
        },
        {
            "sha": "cd8ecf1bbc8af47aefb12ae7368aeb7cbb13df1f",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_summary.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 53,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -116,35 +116,23 @@ MainMatchedComputationResult FindMainMatchedComputation(\n   return result;\n }\n \n-uint64_t GetDiffTypeFingerprint(\n-    const HloInstruction* instruction,\n-    const absl::flat_hash_set<const HloInstruction*>& changed_instructions,\n-    const absl::flat_hash_set<const HloInstruction*>& unmatched_instructions) {\n-  if (changed_instructions.contains(instruction)) {\n-    return DiffCode::kChanged;\n-  }\n-  if (unmatched_instructions.contains(instruction)) {\n-    return DiffCode::kUnmatched;\n-  }\n-  return DiffCode::kUnchanged;\n-}\n-\n struct DiffFingerprint {\n   bool all_unchanged;\n   uint64_t diff_fingerprint;\n };\n \n DiffFingerprint ComputationDiffFingerprint(\n     const xla::HloComputation* computation,\n-    const absl::flat_hash_set<const HloInstruction*>& changed_instructions,\n-    const absl::flat_hash_set<const HloInstruction*>& unmatched_instructions) {\n+    const absl::flat_hash_map<const HloInstruction*, DiffType>& diff_codes) {\n   absl::flat_hash_map<const HloInstruction*, uint64_t> subgraph_fingerprint;\n   bool all_unchanged = true;\n   for (auto* instruction : computation->MakeInstructionPostOrder()) {\n     uint64_t fp = static_cast<uint64_t>(instruction->opcode());\n-    uint64_t diff_type_fp = GetDiffTypeFingerprint(\n-        instruction, changed_instructions, unmatched_instructions);\n-    all_unchanged = all_unchanged && (diff_type_fp == DiffCode::kUnchanged);\n+    uint64_t diff_type_fp = DiffType::kUnchanged;\n+    if (auto it = diff_codes.find(instruction); it != diff_codes.end()) {\n+      diff_type_fp = it->second;\n+    }\n+    all_unchanged = all_unchanged && (diff_type_fp == DiffType::kUnchanged);\n     fp = tsl::FingerprintCat64(fp, diff_type_fp);\n     for (const HloInstruction* operand : instruction->operands()) {\n       fp = tsl::FingerprintCat64(fp, subgraph_fingerprint.at(operand));\n@@ -162,8 +150,7 @@ DiffFingerprint ComputationDiffFingerprint(\n // Split the computations into left and right computations.\n ComputationGroup SplitComputations(\n     const std::vector<const HloComputation*>& computations,\n-    const absl::flat_hash_map<const HloComputation*, const ComputationSummary>&\n-        computation_summaries) {\n+    const ComputationSummaryMap& computation_summaries) {\n   ComputationGroup result;\n   for (const HloComputation* computation : computations) {\n     if (auto it = computation_summaries.find(computation);\n@@ -180,9 +167,7 @@ ComputationGroup SplitComputations(\n \n // Returns the connected components of the given computation summary.\n absl::flat_hash_map<uint64_t, std::vector<ComputationGroup>>\n-FindConnectedComponents(\n-    absl::flat_hash_map<const HloComputation*, const ComputationSummary>\n-        computation_summary) {\n+FindConnectedComponents(const ComputationSummaryMap& computation_summary) {\n   ConnectedComponentsFinder cc;\n   std::vector<std::vector<const HloComputation*>> unmatched_computations;\n   absl::flat_hash_map<uint64_t, std::vector<ComputationGroup>> result;\n@@ -258,8 +243,7 @@ DiffMetrics GetDiffMetrics(const ComputationGroup& computation_group,\n }\n \n std::vector<ComputationDiffPattern> FindComputationDiffPatterns(\n-    const absl::flat_hash_map<const HloComputation*, const ComputationSummary>&\n-        computation_summary,\n+    const ComputationSummaryMap& computation_summary,\n     const DiffResult& diff_result) {\n   std::vector<ComputationDiffPattern> result;\n   absl::flat_hash_map<uint64_t, std::vector<ComputationGroup>>\n@@ -276,18 +260,15 @@ std::vector<ComputationDiffPattern> FindComputationDiffPatterns(\n }\n \n // Summarizes all computations in the given graph.\n-absl::flat_hash_map<const HloComputation*, const ComputationSummary>\n-SummarizeAllComputationsInGraph(\n+ComputationSummaryMap SummarizeAllComputationsInGraph(\n     const HloModule& module, const InstructionBimap& mapping,\n-    const absl::flat_hash_set<const HloInstruction*>& changed_instructions,\n-    const absl::flat_hash_set<const HloInstruction*>& unmatched_instructions,\n+    const absl::flat_hash_map<const HloInstruction*, DiffType>& diff_codes,\n     DiffSide side) {\n-  absl::flat_hash_map<const HloComputation*, const ComputationSummary> result;\n+  ComputationSummaryMap result;\n   for (const HloComputation* computation : module.computations()) {\n     const MainMatchedComputationResult mmc =\n         FindMainMatchedComputation(computation, mapping, side);\n-    DiffFingerprint dfp = ComputationDiffFingerprint(\n-        computation, changed_instructions, unmatched_instructions);\n+    DiffFingerprint dfp = ComputationDiffFingerprint(computation, diff_codes);\n     ComputationSummary summary;\n     summary.side = side;\n     summary.main_matched_computation = mmc.main_matched_computation;\n@@ -301,6 +282,19 @@ SummarizeAllComputationsInGraph(\n   return result;\n }\n \n+// Returns the computation summary.\n+ComputationSummaryMap GetComputationSummary(const HloModule& left_module,\n+                                            const HloModule& right_module,\n+                                            const DiffResult& diff_result) {\n+  ComputationSummaryMap summary;\n+  InstructionBimap mapping = ConstructInstructionBimap(diff_result);\n+  summary.merge(SummarizeAllComputationsInGraph(\n+      left_module, mapping, diff_result.left_diff_codes, DiffSide::kLeft));\n+  summary.merge(SummarizeAllComputationsInGraph(\n+      right_module, mapping, diff_result.right_diff_codes, DiffSide::kRight));\n+  return summary;\n+}\n+\n // Logs the computation group.\n void LogComputationGroup(const ComputationGroup& computation_group) {\n   std::vector<std::string> computations_str(\n@@ -340,27 +334,10 @@ std::unique_ptr<const DiffSummary> ConstructDiffSummary(\n     const HloModule& left_module, const HloModule& right_module,\n     const DiffResult& diff_result) {\n   auto summary = std::make_unique<DiffSummary>();\n-  absl::flat_hash_set<const HloInstruction*> left_changed_instructions;\n-  absl::flat_hash_set<const HloInstruction*> right_changed_instructions;\n-  absl::flat_hash_set<const HloInstruction*> left_unmatched_instructions;\n-  absl::flat_hash_set<const HloInstruction*> right_unmatched_instructions;\n-  for (auto const& [left, right] : diff_result.changed_instructions) {\n-    left_changed_instructions.insert(left);\n-    right_changed_instructions.insert(right);\n-  }\n-  InstructionBimap mapping = ConstructInstructionBimap(diff_result);\n-  left_unmatched_instructions.insert(\n-      diff_result.left_module_unmatched_instructions.begin(),\n-      diff_result.left_module_unmatched_instructions.end());\n-  right_unmatched_instructions.insert(\n-      diff_result.right_module_unmatched_instructions.begin(),\n-      diff_result.right_module_unmatched_instructions.end());\n-  summary->computation_summary.merge(SummarizeAllComputationsInGraph(\n-      left_module, mapping, left_changed_instructions,\n-      left_unmatched_instructions, DiffSide::kLeft));\n-  summary->computation_summary.merge(SummarizeAllComputationsInGraph(\n-      right_module, mapping, right_changed_instructions,\n-      right_unmatched_instructions, DiffSide::kRight));\n+\n+  // Summarize the computations.\n+  summary->computation_summary =\n+      GetComputationSummary(left_module, right_module, diff_result);\n \n   // Group the computations by their diff fingerprint.\n   summary->computation_diff_patterns ="
        },
        {
            "sha": "772ab30e359615836b216a983107a13b40bd006a",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_summary.h",
            "status": "modified",
            "additions": 4,
            "deletions": 8,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,12 +29,6 @@\n namespace xla {\n namespace hlo_diff {\n \n-enum DiffCode : uint8_t {\n-  kUnchanged,\n-  kChanged,\n-  kUnmatched,\n-};\n-\n enum class DiffSide : std::uint8_t { kLeft, kRight };\n \n struct ComputationSummary {\n@@ -83,14 +77,16 @@ struct ComputationDiffPattern {\n // Teach the gunit to print the diff pattern.\n void PrintTo(const ComputationDiffPattern& diff_pattern, std::ostream* os);\n \n+using ComputationSummaryMap =\n+    absl::flat_hash_map<const HloComputation*, const ComputationSummary>;\n+\n //  Summary of the diff result of the left and right HLO modules.\n struct DiffSummary {\n   // The computation diff patterns found in the diff result.\n   std::vector<ComputationDiffPattern> computation_diff_patterns;\n \n   // Summary of each computation.\n-  absl::flat_hash_map<const HloComputation*, const ComputationSummary>\n-      computation_summary;\n+  ComputationSummaryMap computation_summary;\n };\n \n // Constructs the diff summary from the diff result."
        },
        {
            "sha": "ae69c53460a02dfb49adcabeeab41d8c29e8fc2c",
            "filename": "third_party/xla/xla/hlo/tools/hlo_diff/hlo_diff_summary_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_diff%2Fhlo_diff_summary_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -522,16 +522,16 @@ TEST_F(HloDiffTest, DiffSummaryFromDiffResultProtoWorks) {\n     add.0 = f32[] add(parameter.1, parameter.0)\n   }\n   )\"));\n-  diff_result.unchanged_instructions.insert(\n-      {module_l->entry_computation()->root_instruction(),\n-       module_r->entry_computation()->root_instruction()});\n-  diff_result.changed_instructions.insert(\n-      {module_l->entry_computation()->parameter_instruction(0),\n-       module_r->entry_computation()->parameter_instruction(1)});\n-  diff_result.left_module_unmatched_instructions.insert(\n-      module_l->entry_computation()->parameter_instruction(1));\n-  diff_result.right_module_unmatched_instructions.insert(\n-      module_r->entry_computation()->parameter_instruction(0));\n+  diff_result.AddUnchangedInstruction(\n+      module_l->entry_computation()->root_instruction(),\n+      module_r->entry_computation()->root_instruction());\n+  diff_result.AddChangedInstruction(\n+      module_l->entry_computation()->parameter_instruction(0),\n+      module_r->entry_computation()->parameter_instruction(1));\n+  diff_result.AddUnmatchedInstruction(\n+      module_l->entry_computation()->parameter_instruction(1), nullptr);\n+  diff_result.AddUnmatchedInstruction(\n+      nullptr, module_r->entry_computation()->parameter_instruction(0));\n \n   DiffResultProto proto = diff_result.ToProto();\n   DiffResult diff_result_from_proto ="
        },
        {
            "sha": "daae5d0c7b83dda20e441988f75710ddf0c52247",
            "filename": "third_party/xla/xla/hlo/transforms/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -182,6 +182,8 @@ xla_cc_test(\n     srcs = [\"memory_space_propagation_test.cc\"],\n     deps = [\n         \":memory_space_propagation\",\n+        \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/parser:hlo_parser\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n         \"//xla/tsl/lib/core:status_test_util\","
        },
        {
            "sha": "d5637aa6ddeef177bd08ad6df068faa9ace873b7",
            "filename": "third_party/xla/xla/hlo/transforms/memory_space_propagation.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -32,6 +32,30 @@ limitations under the License.\n \n namespace xla {\n \n+bool MemorySpacePropagation::RunOnComputation(HloComputation* computation) {\n+  CHECK(dataflow_analysis_ != nullptr);\n+  bool modified = false;\n+  // Propagate the parameter subshapes.\n+  for (int parameter_idx = 0; parameter_idx < computation->num_parameters();\n+       ++parameter_idx) {\n+    ShapeUtil::ForEachLeafShape(\n+        computation->parameter_instruction(parameter_idx)->shape(),\n+        [&](const Shape& sub_shape, const ShapeIndex& index) {\n+          modified |= Propagate(\n+              index, computation->parameter_instruction(parameter_idx),\n+              sub_shape);\n+        });\n+  }\n+  // Propagate output subshapes.\n+  ShapeUtil::ForEachLeafShape(\n+      computation->root_instruction()->shape(),\n+      [&](const Shape& sub_shape, const ShapeIndex& index) {\n+        modified |=\n+            Propagate(index, computation->root_instruction(), sub_shape);\n+      });\n+  return modified;\n+}\n+\n absl::StatusOr<bool> MemorySpacePropagation::Run(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n@@ -101,6 +125,13 @@ bool MemorySpacePropagation::Propagate(ShapeIndexView index,\n     if (src_split_config.has_value()) {\n       shape->mutable_layout()->add_split_configs(*src_split_config);\n     }\n+\n+    if (instruction->opcode() == HloOpcode::kDynamicUpdateSlice) {\n+      auto op_0 = instruction->mutable_operand(0);\n+      op_0->mutable_shape()->mutable_layout()->set_memory_space(\n+          src_shape.layout().memory_space());\n+      op_0->mutable_shape()->mutable_layout()->clear_split_configs();\n+    }\n     modified = true;\n \n     // For fusion outputs, propagate the memory space to the fusion root."
        },
        {
            "sha": "33b4f08c4e31ec9edf84201d391a1dfb2b7cbf85",
            "filename": "third_party/xla/xla/hlo/transforms/memory_space_propagation.h",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,13 +16,14 @@ limitations under the License.\n #ifndef XLA_HLO_TRANSFORMS_MEMORY_SPACE_PROPAGATION_H_\n #define XLA_HLO_TRANSFORMS_MEMORY_SPACE_PROPAGATION_H_\n \n-#include <cstdint>\n #include <memory>\n+#include <utility>\n \n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/hlo/analysis/hlo_dataflow_analysis.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/pass/hlo_pass_interface.h\"\n #include \"xla/shape.h\"\n@@ -33,13 +34,20 @@ namespace xla {\n // split config) in the layout to the fusion computations.\n class MemorySpacePropagation : public HloModulePass {\n  public:\n+  explicit MemorySpacePropagation(\n+      std::unique_ptr<HloDataflowAnalysis> dataflow_analysis = nullptr)\n+      : dataflow_analysis_(std::move(dataflow_analysis)) {}\n   ~MemorySpacePropagation() override = default;\n   absl::string_view name() const override { return \"memory-space-propagation\"; }\n   using HloPassInterface::Run;\n   absl::StatusOr<bool> Run(\n       HloModule* module,\n       const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n \n+  // Propagates the memory space (and associated split config) in the layout to\n+  // a given fusion computation. Returns true if the computation is modified.\n+  bool RunOnComputation(HloComputation* computation);\n+\n  private:\n   // Given the shape index (operand or output) and its corresponding instruction\n   // in the fused computation (parameter or root), propagates the memory space"
        },
        {
            "sha": "e2a46b570a86d46a077ceda7f139fb96e8483a79",
            "filename": "third_party/xla/xla/hlo/transforms/memory_space_propagation_test.cc",
            "status": "modified",
            "additions": 176,
            "deletions": 0,
            "changes": 176,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fmemory_space_propagation_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -15,10 +15,15 @@ limitations under the License.\n \n #include \"xla/hlo/transforms/memory_space_propagation.h\"\n \n+#include <memory>\n+#include <utility>\n+\n #include <gtest/gtest.h>\n #include \"absl/hash/hash.h\"\n #include \"absl/status/status.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/analysis/hlo_dataflow_analysis.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/parser/hlo_parser.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n@@ -37,6 +42,19 @@ class MemorySpacePropagationTest : public HloHardwareIndependentTestBase {\n     return verifier_.Run(module).status();\n   }\n \n+ protected:\n+  // Returns a dataflow analysis for the given module.\n+  std::unique_ptr<HloDataflowAnalysis> GetDataflowAnalysis(\n+      const HloModule& module) {\n+    if (auto status_or =\n+            HloDataflowAnalysis::Run(module, /*ssa_form=*/false,\n+                                     /*bitcast_defines_value=*/true);\n+        status_or.ok()) {\n+      return std::move(status_or.value());\n+    }\n+    return nullptr;\n+  }\n+\n  private:\n   HloVerifier verifier_;\n };\n@@ -416,5 +434,163 @@ TEST_F(MemorySpacePropagationTest, BitcastInFusion) {\n   EXPECT_EQ(absl::HashOf(*module), absl::HashOf(*ref));\n }\n \n+// This test tests RunOnComputation. The parameters do _not_ get the memory\n+// space propagated from the operands. The operations in the fusion get the\n+// memory space propagated from the parameters.\n+TEST_F(MemorySpacePropagationTest, RunOnComputationPropagateFromParameters) {\n+  absl::string_view hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)S(1)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %tuple = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%param_1.3, %param_2.3)\n+      %gte_1.3 = s32[6]{0:T(128)} get-tuple-element(%tuple), index=0\n+      %neg_1.3 = s32[6]{0:T(128)} negate(%gte_1.3)\n+      ROOT %root = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      %param1_copy = s32[6]{0:T(128)S(1)} copy(%param1)\n+      ROOT %fusion = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) fusion(%param0, %param1_copy), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  absl::string_view expected_hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)S(1)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %tuple = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) tuple(%param_1.3, %param_2.3)\n+      %gte_1.3 = s32[6]{0:T(128)S(1)} get-tuple-element(%tuple), index=0\n+      %neg_1.3 = s32[6]{0:T(128)} negate(%gte_1.3)\n+      ROOT %root = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      %param1_copy = s32[6]{0:T(128)S(1)} copy(%param1)\n+      ROOT %fusion = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) fusion(%param0, %param1_copy), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  auto dataflow_analysis = GetDataflowAnalysis(*module);\n+  MemorySpacePropagation memory_space_propagation(std::move(dataflow_analysis));\n+  HloComputation* computation =\n+      module->GetComputationWithName(\"fused_computation\");\n+  EXPECT_TRUE(memory_space_propagation.RunOnComputation(computation));\n+  TF_ASSERT_OK_AND_ASSIGN(auto ref,\n+                          ParseAndReturnVerifiedModule(expected_hlo_string));\n+  EXPECT_EQ(absl::HashOf(*module), absl::HashOf(*ref));\n+}\n+\n+// This test tests that the parameters in nested fusions get the memory space\n+// propagated from the operands.\n+TEST_F(MemorySpacePropagationTest, RunOnComputationFromParametersNestedFusion) {\n+  absl::string_view hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %nested_fusion {\n+      %param_1.3 = s32[6]{0:T(128)} parameter(0)\n+      ROOT %neg_1.3 = s32[6]{0:T(128)} negate(%param_1.3)\n+    }\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)S(1)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %tuple = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%param_1.3, %param_2.3)\n+      %gte_1.3 = s32[6]{0:T(128)} get-tuple-element(%tuple), index=0\n+      %neg_1.3 = s32[6]{0:T(128)} fusion(%gte_1.3), kind=kLoop, calls=%nested_fusion\n+      ROOT %root = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      ROOT %fusion = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) fusion(%param0, %param1), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  absl::string_view expected_hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %nested_fusion {\n+      %param_1.3 = s32[6]{0:T(128)S(1)} parameter(0)\n+      ROOT %neg_1.3 = s32[6]{0:T(128)} negate(%param_1.3)\n+    }\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)S(1)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %tuple = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) tuple(%param_1.3, %param_2.3)\n+      %gte_1.3 = s32[6]{0:T(128)S(1)} get-tuple-element(%tuple), index=0\n+      %neg_1.3 = s32[6]{0:T(128)} fusion(%gte_1.3), kind=kLoop, calls=%nested_fusion\n+      ROOT %root = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      ROOT %fusion = (s32[6]{0:T(128)}, s32[6]{0:T(128)}) fusion(%param0, %param1), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  auto dataflow_analysis = GetDataflowAnalysis(*module);\n+  MemorySpacePropagation memory_space_propagation(std::move(dataflow_analysis));\n+  HloComputation* computation =\n+      module->GetComputationWithName(\"fused_computation\");\n+  EXPECT_TRUE(memory_space_propagation.RunOnComputation(computation));\n+  TF_ASSERT_OK_AND_ASSIGN(auto ref,\n+                          ParseAndReturnVerifiedModule(expected_hlo_string));\n+  EXPECT_EQ(absl::HashOf(*module), absl::HashOf(*ref));\n+}\n+\n+// This test tests that the operations in the fusion get the memory space\n+// propagated from the output.\n+TEST_F(MemorySpacePropagationTest, RunOnComputationPropagateFromOutput) {\n+  absl::string_view hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %neg_1.3 = s32[6]{0:T(128)} negate(%param_1.3)\n+      ROOT %root = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      ROOT %fusion = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) fusion(%param0, %param1), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  absl::string_view expected_hlo_string = R\"(\n+    HloModule NoMemorySpace\n+\n+    %fused_computation {\n+      %param_1.3 = s32[6]{0:T(128)} parameter(0)\n+      %param_2.3 = s32[6]{0:T(128)} parameter(1)\n+      %neg_1.3 = s32[6]{0:T(128)S(1)} negate(%param_1.3)\n+      ROOT %root = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) tuple(%neg_1.3, %param_2.3)\n+    }\n+    ENTRY %entry {\n+      %param0 = s32[6]{0:T(128)} parameter(0)\n+      %param1 = s32[6]{0:T(128)} parameter(1)\n+      ROOT %fusion = (s32[6]{0:T(128)S(1)}, s32[6]{0:T(128)}) fusion(%param0, %param1), kind=kLoop, calls=%fused_computation\n+    }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  auto dataflow_analysis = GetDataflowAnalysis(*module);\n+  MemorySpacePropagation memory_space_propagation(std::move(dataflow_analysis));\n+  HloComputation* computation =\n+      module->GetComputationWithName(\"fused_computation\");\n+  EXPECT_TRUE(memory_space_propagation.RunOnComputation(computation));\n+  TF_ASSERT_OK_AND_ASSIGN(auto ref,\n+                          ParseAndReturnVerifiedModule(expected_hlo_string));\n+  EXPECT_EQ(absl::HashOf(*module), absl::HashOf(*ref));\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "f5dacc832824cf4489f55c070fc4444f47508da2",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -949,7 +949,6 @@ xla_cc_test(\n         \"//xla/service:buffer_value\",\n         \"//xla/service:hlo_cost_analysis\",\n         \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\","
        },
        {
            "sha": "22ee78c284f79960b194a9a1d40b44c6566ae73a",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 13,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1591,6 +1591,11 @@ MemoryUsageTracker::PickRematerializationCandidates(\n   for (auto* start_item = instruction_list.first_skip_node();\n        start_item != nullptr;\n        start_item = instruction_list.next_skip_node(start_item)) {\n+    if (start_item->instruction->IsDead()) {\n+      // This should only happen in peak priority mode because it does not run a\n+      // DCE pass to remove dead instructions in between certain remat calls.\n+      continue;\n+    }\n     std::vector<HloRematItem*> block =\n         GetInitialBlock(instruction_list, *this, start_item, min_block_size);\n     if (block.size() < min_block_size) {\n@@ -2505,8 +2510,7 @@ RematPeakAggressively(\n               << max_block_size;\n     }\n     if (instructions_added.remat_count > 0) {\n-      VLOG(2) << \"Instructions were rematerialized, readjusting schedule\";\n-\n+      VLOG(2) << \"Instructions were rematerialized\";\n       // Found a valid block. Reset to start looking for single\n       // instructions again.\n       remat->UpdateMaxRematerializedBlockSize(max_block_size);\n@@ -2673,20 +2677,28 @@ HloRematerialization::PeakPrioritySubPass(\n \n   // Update peak memory used by computation.\n   computation_peak_memory_.at(computation) = peak_memory_during_remat;\n+  RematSubpassResult remat_subpass_result{\n+      // NOLINTNEXTLINE (-Wpre-c++20-compat-pedantic)\n+      .status = RematSubpassStatus::kUnchanged,\n+      .peak_memory_during_remat = peak_memory_during_remat,\n+      .peak_memory_instruction = peak_memory_instruction,\n+  };\n   if (module_changed_in_this_subpass && over_memory_limit) {\n-    return RematSubpassResult::kChangedButOverMemoryLimit;\n+    remat_subpass_result.status =\n+        RematSubpassStatus::kChangedButOverMemoryLimit;\n   }\n   if (module_changed_in_this_subpass && !over_memory_limit) {\n-    return RematSubpassResult::kChangedAndUnderMemoryLimit;\n+    remat_subpass_result.status =\n+        RematSubpassStatus::kChangedAndUnderMemoryLimit;\n   }\n-  return RematSubpassResult::kUnchanged;\n+  return remat_subpass_result;\n }\n \n absl::StatusOr<bool> HloRematerialization::RematerializeComputationPeakPriority(\n     HloComputation* computation, HloSchedule* schedule,\n     int64_t memory_limit_bytes, int64_t min_remat_size,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n-  VLOG(2) << \"Rematerializing Using Peak Priority\";\n+  VLOG(1) << \"Rematerializing Using Peak Priority\";\n   // If memory limit is zero, cost savings estimates don't work because the cost\n   // is defined as memory_limit_bytes / memory_reduced. Bounds it to a large\n   // enough value for cost differences to be comparable.\n@@ -2736,19 +2748,22 @@ absl::StatusOr<bool> HloRematerialization::RematerializeComputationPeakPriority(\n       &remat_move_instructions,\n       &execution_threads};\n \n-  RematSubpassResult remat_subpass_result =\n-      RematSubpassResult::kChangedButOverMemoryLimit;\n+  RematSubpassStatus remat_subpass_status;\n   bool changed = false;\n-  while (remat_subpass_result ==\n-         RematSubpassResult::kChangedButOverMemoryLimit) {\n+  do {\n     TF_ASSIGN_OR_RETURN(\n-        remat_subpass_result,\n+        RematSubpassResult remat_subpass_result,\n         PeakPrioritySubPass(peak_memory_instruction, rematerialization_state,\n                             computation, call_graph_node, min_remat_size,\n                             peak_memory_during_remat, memory_limit_bytes,\n                             execution_threads));\n-    changed |= (remat_subpass_result != RematSubpassResult::kUnchanged);\n-  }\n+    changed |= (remat_subpass_result.status != RematSubpassStatus::kUnchanged);\n+    remat_subpass_status = remat_subpass_result.status;\n+    peak_memory_during_remat = remat_subpass_result.peak_memory_during_remat;\n+    peak_memory_instruction = remat_subpass_result.peak_memory_instruction;\n+  } while (remat_subpass_status ==\n+           RematSubpassStatus::kChangedButOverMemoryLimit);\n+\n   rematerialized_computations_.insert(computation);\n   return changed;\n }"
        },
        {
            "sha": "9ef2558bfabe7349d69af294e8b9c088ec2bde96",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization.h",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -155,8 +155,11 @@ class HloRematerialization : public HloModulePass {\n     const ShapeSizeFunction size_function;\n \n     // The threshold number of bytes to reduce memory use to via\n-    // rematerialization. Size of aliased outputs should be subtracted\n-    // from this.\n+    // rematerialization. This limit is adjusted in the pass by subtracting the\n+    // size of all module outputs. Callers should consider reducing the amount\n+    // of available memory by also subtracting the size of module parameters,\n+    // and to add the size of aliased outputs to avoid subtracting twice for\n+    // parameter and output.\n     int64_t memory_limit_bytes;\n \n     // Maximum number of consecutive instructions to consider for\n@@ -254,12 +257,18 @@ class HloRematerialization : public HloModulePass {\n     int64_t remat_instructions_count;\n   };\n \n-  enum class RematSubpassResult : char {\n+  enum class RematSubpassStatus : char {\n     kUnchanged,\n     kChangedButOverMemoryLimit,\n     kChangedAndUnderMemoryLimit,\n   };\n \n+  struct RematSubpassResult {\n+    RematSubpassStatus status = RematSubpassStatus::kUnchanged;\n+    int64_t peak_memory_during_remat = 0;\n+    const HloInstruction* peak_memory_instruction = nullptr;\n+  };\n+\n   // Holds the memory usage and instruction at a given program point (usually\n   // the peak memory).\n   struct MemoryUsageAndInstruction {"
        },
        {
            "sha": "9ed9a62fd76ad138717a3a979ad4a4b887d1b105",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/hlo_rematerialization_test.cc",
            "status": "modified",
            "additions": 86,
            "deletions": 4,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fhlo_rematerialization_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -47,7 +47,6 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -57,15 +56,17 @@ namespace {\n \n namespace op = xla::testing::opcode_matchers;\n \n+using ::absl_testing::IsOkAndHolds;\n using ::testing::_;\n using ::testing::Contains;\n using ::testing::ElementsAre;\n using ::testing::Eq;\n using ::testing::HasSubstr;\n using ::testing::Not;\n using ::testing::Pair;\n+using ::testing::Property;\n+using ::testing::StrEq;\n using ::testing::UnorderedElementsAre;\n-using tsl::testing::IsOkAndHolds;\n \n class AsyncRematerializationTest : public RematerializationTestBase {\n  protected:\n@@ -1652,8 +1653,8 @@ e {\n           /*min_remat_size=*/0, /*compact_shape_function=*/nullptr),\n       sizes);\n   EXPECT_THAT(remat.Run(module.get(), {HloInstruction::kMainExecutionThread}),\n-              IsOkAndHolds(true));\n-  EXPECT_THAT(HloDCE().Run(module.get()), IsOkAndHolds(false));\n+              absl_testing::IsOkAndHolds(true));\n+  EXPECT_THAT(HloDCE().Run(module.get()), absl_testing::IsOkAndHolds(false));\n }\n \n TEST_F(RecomputeAndCompressHloRematerializationTest,\n@@ -1907,5 +1908,86 @@ ENTRY %entry (param.0: f32[], param.1: f32[]) -> f32[1024] {\n   }\n }\n \n+TEST_F(RecomputeAndCompressHloRematerializationTest,\n+       PeakFirstRematerializesAtSamePeak) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule fusion, is_scheduled=true\n+\n+%call_convoluted (param_0: f32[1024], param_1: f32[1024]) -> f32[1024] {\n+  %constant_source_8 = f32[] constant(8)\n+  %constant_source_8_user = f32[1024]{0} broadcast(%constant_source_8), dimensions={}\n+  %param_0 = f32[1024]{0} parameter(0)\n+  %constant_source_8_user_2 = f32[1024]{0} broadcast(%constant_source_8), dimensions={}\n+  %param_1 = f32[1024]{0} parameter(1)\n+  %res_param_add = f32[1024]{0} add(%param_0, %param_1)\n+  %constant.anon = f32[] constant(1)\n+  %constant_0 = f32[16384]{0} broadcast(%constant.anon), dimensions={}\n+  %op_1 = f32[16384]{0} tanh(%constant_0)\n+  %op_2 = f32[16384]{0} tanh(%op_1)\n+  %op_3 = f32[16384]{0} tanh(%op_2)\n+  %op_4 = f32[16384]{0} tanh(%op_3)\n+  %tan_res = f32[1024]{0} slice(%op_4), slice={[0:1024]}\n+  %res_1 = f32[1024]{0} add(%res_param_add, %tan_res)\n+  %res_3 = f32[1024]{0} add(%constant_source_8_user, %res_1)\n+  %res_3_2 = f32[1024]{0} add(%constant_source_8_user_2, %res_3)\n+  %constant_x = f32[1024]{0} broadcast(%constant_source_8), dimensions={}\n+  %constant_x_and_res_param_add = f32[1024]{0} add(%constant_x, %res_param_add)\n+  %res_4 = f32[1024]{0} add(%res_3_2, %constant_x_and_res_param_add)\n+  ROOT %res = f32[1024]{0} add(%res_3, %res_4)\n+}\n+\n+%call_comp (p: f32[1024], p_2: f32[1024]) -> f32[1024] {\n+  %p = f32[1024]{0} parameter(0)\n+  %p_2 = f32[1024]{0} parameter(1)\n+  %call_convoluted = f32[1024]{0} call(%p, %p_2), to_apply=%call_convoluted\n+  ROOT %n = f32[1024]{0} negate(%call_convoluted)\n+}\n+\n+%add_mul_comp (p0: f32[], p1: f32[]) -> f32[1024] {\n+  %p0 = f32[] parameter(0)\n+  %p1 = f32[] parameter(1)\n+  %p0_bcast = f32[1024]{0} broadcast(%p0), dimensions={}\n+  %p1_bcast = f32[1024]{0} broadcast(%p1), dimensions={}\n+  %res_comp = f32[1024]{0} call(%p0_bcast, %p1_bcast), to_apply=%call_comp\n+  ROOT %res_mul = f32[1024]{0} multiply(%res_comp, %res_comp)\n+}\n+\n+ENTRY %entry (param.0: f32[], param.1: f32[]) -> f32[1024] {\n+  %param.0 = f32[] parameter(0)\n+  %param.1 = f32[] parameter(1)\n+  %res = f32[1024]{0} call(%param.0, %param.1), to_apply=%add_mul_comp\n+  ROOT %res_2 = f32[1024]{0} negate(%res)\n+}\n+)\"));\n+\n+  // Rematerialize with a low memory limit and min_remat_size.\n+  EXPECT_THAT(RunHloRematerialization(\n+                  /*memory_limit_bytes=*/0, module.get(),\n+                  /*min_remat_size=*/0,\n+                  HloRematerialization::RematAlgorithm::kPeakPriority),\n+              IsOkAndHolds(true));\n+\n+  const std::vector<HloInstruction*>& call_convoluted_instructions =\n+      module->schedule()\n+          .sequence(module->GetComputationWithName(\"call_convoluted\"))\n+          .instructions();\n+\n+  EXPECT_THAT(call_convoluted_instructions,\n+              AllOf(\n+                  // Should remat a large instruction.\n+                  Not(Contains(Property(&HloInstruction::name,\n+                                        StrEq(\"constant_source_8_user\")))),\n+                  // Should not remat after a peak\n+                  Not(Contains(Property(&HloInstruction::name,\n+                                        StrEq(\"constant_x.remat2\")))),\n+                  // Should remat both constant_source_8_user even with them\n+                  // being associated with the same peak.\n+                  Contains(Property(&HloInstruction::name,\n+                                    StrEq(\"constant_source_8_user.remat\"))),\n+                  Contains(Property(&HloInstruction::name,\n+                                    StrEq(\"constant_source_8_user_2.remat\")))));\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "223ebfa1758d566ceb03e25ee1db3a17e1c8173e",
            "filename": "third_party/xla/xla/layout_util.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flayout_util.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -506,6 +506,21 @@ absl::Status LayoutUtil::CopyLayoutBetweenShapes(const Shape& src, Shape* dst) {\n   return ret;\n }\n \n+Layout LayoutUtil::MoveDimToMinor(const Layout& layout, const int64_t dim) {\n+  if (dim == MinorToMajor(layout).front()) {\n+    return layout;\n+  }\n+  Layout result = layout;\n+  result.clear_minor_to_major();\n+  result.add_minor_to_major(dim);\n+  for (int64_t current_dim : MinorToMajor(layout)) {\n+    if (current_dim != dim) {\n+      result.add_minor_to_major(current_dim);\n+    }\n+  }\n+  return result;\n+}\n+\n /*static*/ int64_t LayoutUtil::LinearIndex(const Shape& shape,\n                                            absl::Span<const int64_t> indices) {\n   CHECK(shape.IsArray());"
        },
        {
            "sha": "e5f807c0286eb34853f9587543ba91eba94e34de",
            "filename": "third_party/xla/xla/layout_util.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flayout_util.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -235,6 +235,10 @@ class LayoutUtil {\n   // layout `layout` as the most major dimension.\n   static Layout MoveDimToMajor(const Layout& layout, int64_t dim);\n \n+  // Constructs a new layout by making the given dimension in the given\n+  // layout the minor most.\n+  static Layout MoveDimToMinor(const Layout& layout, int64_t dim);\n+\n   // Returns the linearized index of the cell at the given indices. The unit\n   // of the offset is in elements of the shape.\n   //"
        },
        {
            "sha": "3107b88330824c0bc9bd9bcf0ad50cc20a41935c",
            "filename": "third_party/xla/xla/layout_util_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Flayout_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flayout_util_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -438,6 +438,13 @@ TEST_F(LayoutUtilTest, MoveDimToMajor) {\n   EXPECT_EQ(new_layout, LayoutUtil::MakeLayout({2, 0, 1}));\n }\n \n+TEST_F(LayoutUtilTest, MoveDimToMinor) {\n+  const Layout layout = LayoutUtil::MakeLayout({2, 0, 3, 1});\n+  EXPECT_EQ(LayoutUtil::MoveDimToMinor(layout, 2), layout);\n+  EXPECT_EQ(LayoutUtil::MoveDimToMinor(layout, 3),\n+            LayoutUtil::MakeLayout({3, 2, 0, 1}));\n+}\n+\n TEST_F(LayoutUtilTest, StridesIsMajorToMinor) {\n   std::vector<int64_t> byte_strides = {3960, 440, 44, 4};\n   EXPECT_TRUE(LayoutUtil::ByteStridesIsMajorToMinor("
        },
        {
            "sha": "b847b95271696339ffd81939083aa90e85f614ac",
            "filename": "third_party/xla/xla/mlir_hlo/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -410,6 +410,7 @@ cc_library(\n     strip_include_prefix = \".\",\n     deps = [\n         \":mlir_hlo\",\n+        \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:FuncTransforms\",\n         \"@llvm-project//mlir:IR\","
        },
        {
            "sha": "0e13dcb3c39a9950c68600207a00c4646d62ee33",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/utils/type_conversion.cc",
            "status": "modified",
            "additions": 59,
            "deletions": 2,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Futils%2Ftype_conversion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Futils%2Ftype_conversion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Futils%2Ftype_conversion.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -15,19 +15,26 @@ limitations under the License.\n \n #include \"mhlo/utils/type_conversion.h\"\n \n-#include <optional>\n+#include <cassert>\n+#include <cstddef>\n \n+#include \"llvm/ADT/STLExtras.h\"\n #include \"mhlo/IR/hlo_ops.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/Func/Transforms/FuncConversions.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Dialect.h\"\n+#include \"mlir/IR/Location.h\"\n #include \"mlir/IR/TypeUtilities.h\"\n #include \"mlir/IR/Types.h\"\n #include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n #include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n \n namespace mlir {\n@@ -94,6 +101,55 @@ Value scalarToTensor(OpBuilder& builder, Type type,\n   return result;\n }\n \n+// Flatten the given value ranges into a single vector of values.\n+SmallVector<Value> flattenValues(ArrayRef<ValueRange> values) {\n+  SmallVector<Value> result;\n+  for (const auto& vals : values) llvm::append_range(result, vals);\n+  return result;\n+}\n+\n+// Exact same as `CallOpSignatureConversion`, except this one preserves\n+// discardable attributes.\n+struct CallOpSignatureConversion : public OpConversionPattern<func::CallOp> {\n+  using OpConversionPattern<func::CallOp>::OpConversionPattern;\n+\n+  /// Hook for derived classes to implement combined matching and rewriting.\n+  LogicalResult matchAndRewrite(\n+      func::CallOp callOp, OneToNOpAdaptor adaptor,\n+      ConversionPatternRewriter& rewriter) const override {\n+    // Convert the original function results. Keep track of how many result\n+    // types an original result type is converted into.\n+    SmallVector<size_t> numResultsReplacements;\n+    SmallVector<Type, 1> convertedResults;\n+    size_t numFlattenedResults = 0;\n+    for (auto [idx, type] : llvm::enumerate(callOp.getResultTypes())) {\n+      if (failed(typeConverter->convertTypes(type, convertedResults)))\n+        return failure();\n+      numResultsReplacements.push_back(convertedResults.size() -\n+                                       numFlattenedResults);\n+      numFlattenedResults = convertedResults.size();\n+    }\n+\n+    // Substitute with the new result types from the corresponding FuncType\n+    // conversion.\n+    auto newCallOp = func::CallOp::create(rewriter, callOp.getLoc(),\n+                                          callOp.getCallee(), convertedResults,\n+                                          flattenValues(adaptor.getOperands()));\n+    newCallOp->setAttrs(callOp->getAttrs());\n+    SmallVector<ValueRange> replacements;\n+    size_t offset = 0;\n+    for (int i = 0, e = callOp->getNumResults(); i < e; ++i) {\n+      replacements.push_back(\n+          newCallOp->getResults().slice(offset, numResultsReplacements[i]));\n+      offset += numResultsReplacements[i];\n+    }\n+    assert(offset == convertedResults.size() &&\n+           \"expected that all converted results are used\");\n+    rewriter.replaceOpWithMultiple(callOp, replacements);\n+    return success();\n+  }\n+};\n+\n }  // namespace\n \n RemoveSignTypeConverter::RemoveSignTypeConverter() {\n@@ -232,7 +288,8 @@ void registerFuncOpsForTypeConversion(ConversionTarget& target,\n   });\n   populateFunctionOpInterfaceTypeConversionPattern<func::FuncOp>(patterns,\n                                                                  converter);\n-  populateCallOpTypeConversionPattern(patterns, converter);\n+  patterns.add<mhlo::CallOpSignatureConversion>(converter,\n+                                                patterns.getContext());\n   populateReturnOpTypeConversionPattern(patterns, converter);\n }\n "
        },
        {
            "sha": "413cd48e22b6be3298de914e365e682dea1ad01f",
            "filename": "third_party/xla/xla/mlir_hlo/tests/Dialect/mhlo/stablehlo-legalize-to-hlo.mlir",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fmhlo%2Fstablehlo-legalize-to-hlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fmhlo%2Fstablehlo-legalize-to-hlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fmhlo%2Fstablehlo-legalize-to-hlo.mlir?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -2468,6 +2468,23 @@ func.func @type_tuple(%arg0: tuple<tensor<f32>>) -> tuple<!stablehlo.token> {\n \n // -----\n \n+// ============ TYPES ============\n+// Tests how StableHLO types are legalized to MHLO types.\n+\n+\n+// Make sure discardable attributes on CallOps with token types are preserved\n+// CHECK-LABEL: preserve_discardable_attrs_on_call\n+func.func @preserve_discardable_attrs_on_call(%arg0: !stablehlo.token {mhlo.sharding = \"{replicated}\"}) -> !stablehlo.token {\n+  // CHECK: \"func.call\"(%arg1) <{callee = @calling_func}> {mhlo.sharding = \"{manual}\"} : (!mhlo.token) -> !mhlo.token\n+  %0 = call @calling_func(%arg0) {mhlo.sharding = \"{manual}\"} : (!stablehlo.token) -> !stablehlo.token\n+  return %0 : !stablehlo.token\n+}\n+func.func @calling_func(%arg0: !stablehlo.token {mhlo.sharding = \"{manual}\"}) -> (!stablehlo.token {mhlo.sharding = \"{manual}\"}) {\n+  return %arg0 : !stablehlo.token\n+}\n+\n+// -----\n+\n // ============ NEGATIVE TESTS ============\n // Some ops, attributes and types used in StableHLO programs are not supported in MHLO.\n // For those cases, we have negative tests below."
        },
        {
            "sha": "43b46a8deab6fa35ea4182931243f0dbcf4027c9",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api.h",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -663,8 +663,7 @@ struct PJRT_Client_Compile_Args {\n   // `program->format` and `program->format_size` are owned by the caller.\n   const PJRT_Program* program;\n   // TODO(b/240560013): consider putting some of option fields in priv.\n-  // Serialized CompileOptionsProto\n-  // (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/pjrt/compile_options.proto)\n+  // Serialized CompileOptionsProto.\n   const char* compile_options;\n   size_t compile_options_size;\n   PJRT_LoadedExecutable* executable;  // out\n@@ -1868,7 +1867,6 @@ struct PJRT_Executable_DeserializeAndLoad_Args {\n   PJRT_LoadedExecutable* loaded_executable;  // out\n   // Serialized CompileOptionsProto or null (to use the options\n   // from the serialized executable).\n-  // (https://github.com/openxla/xla/blob/main/xla/pjrt/compile_options.proto)\n   const char* overridden_serialized_compile_options;\n   size_t overridden_serialized_compile_options_size;\n };\n@@ -2423,8 +2421,7 @@ struct PJRT_Compile_Args {\n   // `program->format` and `program->format_size` are owned by the caller.\n   const PJRT_Program* program;\n   // TODO(b/240560013): consider putting some of option fields in priv.\n-  // Serialized CompileOptionsProto\n-  // (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/pjrt/compile_options.proto)\n+  // Serialized CompileOptionsProto.\n   const char* compile_options;\n   size_t compile_options_size;\n   // Optionally provided for performance-guided optimizations."
        },
        {
            "sha": "d9078e79b7f2d5b6bc7da488c246bfd2aefb8033",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -935,7 +935,7 @@ FieldOffsetsAndSizesForVersion(int major_version, int minor_version) {\n     if (minor_version >= 73) {\n       add_field(\"PJRT_Client_UpdateGlobalProcessInfo\", kFnPtrSize);\n     }\n-    if (minor_version >= 74) {\n+    if (minor_version >= 75) {\n       add_field(\"PJRT_TopologyDescription_Deserialize\", kFnPtrSize);\n     }\n     return version_offsets_and_sizes;"
        },
        {
            "sha": "52a6070f0a51c3741f249afa3fbd406040738918",
            "filename": "third_party/xla/xla/pjrt/cpu/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -79,6 +79,7 @@ cc_library(\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/base:no_destructor\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\",\n@@ -145,6 +146,7 @@ cc_library(\n         \"//xla:cpu_function_runtime\",\n         \"//xla:debug_options_flags\",\n         \"//xla:executable_run_options\",\n+        \"//xla:execution_options_util\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n@@ -163,6 +165,7 @@ cc_library(\n         \"//xla/hlo/builder:xla_computation\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/ir:hlo_module_group\",\n+        \"//xla/pjrt:abstract_tracked_device_buffer\",\n         \"//xla/pjrt:async_work_runner\",\n         \"//xla/pjrt:common_pjrt_client\",\n         \"//xla/pjrt:device_event\",\n@@ -184,6 +187,7 @@ cc_library(\n         \"//xla/pjrt/dump\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_client_options\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_execute_options\",\n+        \"//xla/pjrt/plugin/xla_cpu:cpu_memory\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_topology\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_topology_description\",\n         \"//xla/pjrt/proto:compile_options_proto_cc\",\n@@ -256,6 +260,7 @@ xla_cc_test(\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt:pjrt_executable\",\n         \"//xla/pjrt/plugin/xla_cpu:cpu_client_options\",\n+        \"//xla/pjrt/plugin/xla_cpu:cpu_memory\",\n         \"//xla/pjrt/plugin/xla_cpu:xla_cpu_pjrt_client\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/tests:literal_test_util\",\n@@ -270,6 +275,7 @@ xla_cc_test(\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_googletest//:gtest\","
        },
        {
            "sha": "7f5c1f29955817a70626596a67d62b2b049d2b30",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.cc",
            "status": "modified",
            "additions": 78,
            "deletions": 28,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -54,7 +54,6 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/thunk_executor.h\"\n #include \"xla/backends/cpu/runtime/xfeed_manager.h\"\n #include \"xla/client/executable_build_options.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/debug_options_flags.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n@@ -66,6 +65,7 @@ limitations under the License.\n #include \"xla/layout_util.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/common_pjrt_client.h\"\n #include \"xla/pjrt/cpu/abstract_cpu_buffer.h\"\n #include \"xla/pjrt/cpu/cpu_async_execution_tracker.h\"\n@@ -81,13 +81,13 @@ limitations under the License.\n #include \"xla/pjrt/layout_mode.h\"\n #include \"xla/pjrt/mlir_to_hlo.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n-#include \"xla/pjrt/pjrt_client_utils.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_execute_options.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_memory.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology_description.h\"\n #include \"xla/pjrt/proto/compile_options.pb.h\"\n@@ -96,15 +96,12 @@ limitations under the License.\n #include \"xla/pjrt/thread_pool_async_work_runner.h\"\n #include \"xla/pjrt/transpose.h\"\n #include \"xla/pjrt/utils.h\"\n-#include \"xla/primitive_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/cpu/cpu_compiler.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/cpu/cpu_executable_run_options.h\"\n-#include \"xla/service/custom_call_status.h\"\n-#include \"xla/service/custom_call_status_internal.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/hlo.pb.h\"\n@@ -131,8 +128,6 @@ limitations under the License.\n #include \"tsl/platform/denormal.h\"\n #include \"tsl/platform/fingerprint.h\"\n #include \"tsl/platform/setround.h\"\n-#include \"tsl/profiler/lib/connected_traceme.h\"\n-#include \"tsl/profiler/lib/context_types.h\"\n #include \"tsl/profiler/lib/traceme.h\"\n \n #define EIGEN_USE_THREADS\n@@ -147,6 +142,46 @@ static int CpuDeviceCount() {\n   return GetDebugOptionsFromFlags().xla_force_host_platform_device_count();\n }\n \n+namespace {\n+\n+// A custom memory allocator function passed via the CPU client options.\n+using CustomAllocatorFn =\n+    std::function<absl::StatusOr<std::unique_ptr<CpuMemory>>(size_t size_bytes,\n+                                                             size_t alignment)>;\n+\n+// A custom raw memory that wraps a CpuMemory allocated by the user.\n+class CustomMemory final : public CpuDeviceMemory::RawMemory {\n+ public:\n+  explicit CustomMemory(std::unique_ptr<CpuMemory> mem)\n+      : mem_(std::move(mem)) {}\n+\n+  void* base() const final { return mem_->base(); }\n+  size_t size_bytes() const final { return mem_->size_bytes(); }\n+\n+ private:\n+  std::unique_ptr<CpuMemory> mem_;\n+};\n+\n+// A custom raw memory allocator that wraps an allocation function passed via\n+// the client options.\n+class CustomAllocator final : public CpuDeviceMemory::Allocator {\n+ public:\n+  explicit CustomAllocator(CustomAllocatorFn allocator_fn)\n+      : allocator_fn_(std::move(allocator_fn)) {}\n+\n+  absl::StatusOr<std::unique_ptr<CpuDeviceMemory::RawMemory>> Allocate(\n+      size_t size_bytes, size_t alignment) const final {\n+    TF_ASSIGN_OR_RETURN(std::unique_ptr<CpuMemory> mem,\n+                        allocator_fn_(size_bytes, alignment));\n+    return std::make_unique<CustomMemory>(std::move(mem));\n+  }\n+\n+ private:\n+  CustomAllocatorFn allocator_fn_;\n+};\n+\n+}  // namespace\n+\n absl::StatusOr<std::unique_ptr<PjRtClient>> GetPjRtCpuClient(\n     CpuClientOptions options) {\n   // Need at least CpuDeviceCount threads to launch one collective.\n@@ -161,9 +196,13 @@ absl::StatusOr<std::unique_ptr<PjRtClient>> GetPjRtCpuClient(\n     devices.push_back(std::move(device));\n   }\n \n+  std::unique_ptr<CpuDeviceMemory::Allocator> allocator =\n+      options.allocator ? std::make_unique<CustomAllocator>(options.allocator)\n+                        : CpuDeviceMemory::MakeDefaultAllocator();\n+\n   return std::unique_ptr<PjRtClient>(new PjRtCpuClient(\n-      options.process_id, std::move(devices), std::move(options.collectives),\n-      num_threads, options.asynchronous,\n+      options.process_id, std::move(devices), std::move(allocator),\n+      std::move(options.collectives), num_threads, options.asynchronous,\n       std::move(options.customize_hlo_module_config)));\n }\n \n@@ -197,12 +236,14 @@ static std::vector<CpuTopology::CpuDevice> GetCpuDevices(\n \n PjRtCpuClient::PjRtCpuClient(\n     int process_index, std::vector<std::unique_ptr<PjRtCpuDevice>> devices,\n+    std::shared_ptr<CpuDeviceMemory::Allocator> allocator,\n     std::shared_ptr<cpu::CpuCollectives> collectives, size_t num_threads,\n     bool asynchronous,\n     std::function<void(HloModuleConfig&)> customize_hlo_module_config)\n     : process_index_(process_index),\n       owned_devices_(std::move(devices)),\n       computation_placer_(std::make_unique<ComputationPlacer>()),\n+      allocator_(std::move(allocator)),\n       eigen_intraop_pool_(new tsl::thread::ThreadPool(\n           tsl::Env::Default(), GetThreadOptions(), \"XLAEigen\",\n           std::min(num_threads, kMaxIntraOpThreads))),\n@@ -857,8 +898,9 @@ absl::StatusOr<std::unique_ptr<PjRtBuffer>> PjRtCpuClient::CreateErrorBuffer(\n   }\n   // Create a dummy buffer because the rest of the code expects a buffer\n   // regardless of whether the definition event is an error.\n-  TF_ASSIGN_OR_RETURN(auto buffer,\n-                      CpuDeviceMemory::Allocate(ShapeUtil::ByteSizeOf(shape)));\n+  TF_ASSIGN_OR_RETURN(\n+      auto buffer,\n+      CpuDeviceMemory::Allocate(ShapeUtil::ByteSizeOf(shape), *allocator_));\n   return std::make_unique<CommonPjRtBufferImpl>(\n       shape,\n       std::make_unique<TrackedCpuDeviceBuffer>(\n@@ -964,7 +1006,8 @@ PjRtCpuClient::AllocateRawBuffer(PjRtMemorySpace* memory_space,\n                                  tsl::AsyncValueRef<bool> allocate_after) {\n   CHECK(allocate_after == nullptr) << \"allocate_after is not supported for \"\n                                       \"PjRtCpuClient.\";\n-  return xla::CpuRawBuffer::Allocate(memory_space, on_device_bytes_count);\n+  return xla::CpuRawBuffer::Allocate(memory_space, on_device_bytes_count,\n+                                     *allocator_);\n }\n \n absl::StatusOr<int64_t> PjRtCpuClient::GetOnDeviceBytesCount(\n@@ -1077,10 +1120,10 @@ struct BufferAlloc {\n   absl::InlinedVector<tsl::AsyncValueRef<CpuDeviceMemory>, 4> buffers;\n   absl::InlinedVector<size_t, 4> allocation_sizes;\n \n-  void Allocate() {\n+  void Allocate(const CpuDeviceMemory::Allocator& allocator) {\n     for (int i = 0; i < buffers.size(); ++i) {\n-      auto status = CpuDeviceMemory::AllocateInto(allocation_sizes[i],\n-                                                  buffers[i].AsPtr());\n+      auto status = CpuDeviceMemory::AllocateInto(\n+          allocation_sizes[i], buffers[i].AsPtr(), allocator);\n       if (!status.ok()) {\n         buffers[i].SetError(status);\n         return;\n@@ -1097,10 +1140,10 @@ struct BufferAllocAndCopy {\n   absl::InlinedVector<tsl::AsyncValueRef<CpuDeviceMemory>, 4> dst_buffers;\n   absl::InlinedVector<size_t, 4> allocation_sizes;\n \n-  void AllocateAndCopy() {\n+  void AllocateAndCopy(const CpuDeviceMemory::Allocator& allocator) {\n     for (int i = 0; i < src_buffers.size(); ++i) {\n-      auto status = CpuDeviceMemory::AllocateInto(allocation_sizes[i],\n-                                                  dst_buffers[i].AsPtr());\n+      auto status = CpuDeviceMemory::AllocateInto(\n+          allocation_sizes[i], dst_buffers[i].AsPtr(), allocator);\n       if (!status.ok()) {\n         dst_buffers[i].SetError(status);\n         return;\n@@ -1413,12 +1456,12 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n     tuple_index_table = CpuDeviceMemory::CreateDelayedMemory();\n     tsl::RunWhenReady(\n         absl::MakeConstSpan(leaf_buffers),\n-        [buffers = leaf_buffers,\n-         tuple_index_table = tuple_index_table]() mutable {\n+        [buffers = leaf_buffers, tuple_index_table,\n+         allocator = client()->allocator()]() mutable {\n           size_t index_table_byte_size = buffers.size() * sizeof(void*);\n           // We assume tuple table allocations will not fail.\n-          CHECK_OK(CpuDeviceMemory::AllocateInto(index_table_byte_size,\n-                                                 tuple_index_table.AsPtr()));\n+          CHECK_OK(CpuDeviceMemory::AllocateInto(\n+              index_table_byte_size, tuple_index_table.AsPtr(), *allocator));\n           uintptr_t* index_table =\n               reinterpret_cast<uintptr_t*>(tuple_index_table->untyped_data());\n           for (int i = 0; i < buffers.size(); ++i) {\n@@ -1529,8 +1572,8 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n     tsl::AsyncValueRef<cpu::Thunk::ExecuteEvent> thunks_execute_event;\n \n     // Immediately allocate memory and prepare for computation.\n-    buffer_alloc.Allocate();\n-    buffer_alloc_and_copy.AllocateAndCopy();\n+    buffer_alloc.Allocate(*client()->allocator());\n+    buffer_alloc_and_copy.AllocateAndCopy(*client()->allocator());\n     for (const auto& buffer_info : buffer_table) {\n       CHECK(buffer_info.buffer.IsAvailable());\n       if (buffer_info.buffer.IsError()) {\n@@ -1575,7 +1618,10 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n           &task_runner,\n           &collective_params,\n           &custom_call_execute_params,\n-          xnn_params ? &*xnn_params : nullptr};\n+          xnn_params ? &*xnn_params : nullptr,\n+          run_options.run_id().ToInt(),\n+          run_options.device_ordinal(),\n+      };\n \n       thunks_execute_event = cpu_executable->thunks().Execute(execute_params);\n \n@@ -1641,13 +1687,14 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n          donation_transactions = std::move(donation_transactions),\n          scoped_async_execution = std::move(scoped_async_execution),\n          input_deps_avs = std::move(input_deps_avs_copy),\n+         allocator = client()->allocator(),\n          eigen_device = client()->eigen_intraop_device()]() mutable {\n           // Because `input_deps` contains the definition events of all inputs,\n           // when it is ready, all input buffers must have been allocated. So,\n           // we are safe to allocate and copy memory here. Since `execute_event`\n           // may error out, we need to do it early.\n-          buffer_alloc.Allocate();\n-          buffer_alloc_and_copy.AllocateAndCopy();\n+          buffer_alloc.Allocate(*allocator);\n+          buffer_alloc_and_copy.AllocateAndCopy(*allocator);\n \n           for (const auto& av : input_deps_avs) {\n             if (auto* error = av->GetErrorIfPresent()) {\n@@ -1710,7 +1757,10 @@ absl::StatusOr<PjRtLoadedExecutable::Result> PjRtCpuExecutable::ExecuteHelper(\n                   &task_runner,\n                   &*collective_params,\n                   &*custom_call_params,\n-                  *xnn_params ? &**xnn_params : nullptr};\n+                  *xnn_params ? &**xnn_params : nullptr,\n+                  run_options.run_id().ToInt(),\n+                  run_options.device_ordinal(),\n+              };\n \n               auto thunks_execute_event =\n                   cpu_executable->thunks().Execute(execute_params);"
        },
        {
            "sha": "8104de7d126472a9e4c55d48cacd186482d24c59",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client.h",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -47,17 +47,18 @@ limitations under the License.\n #include \"xla/literal.h\"\n #include \"xla/pjrt/async_work_runner.h\"\n #include \"xla/pjrt/common_pjrt_client.h\"\n-#include \"xla/pjrt/cpu/abstract_cpu_buffer.h\"\n #include \"xla/pjrt/cpu/cpu_device.h\"\n #include \"xla/pjrt/cpu/cpu_event.h\"\n #include \"xla/pjrt/cpu/tracked_cpu_device_buffer.h\"\n+#include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology_description.h\"\n+#include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/pjrt/transpose.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/compiler.h\"\n@@ -68,7 +69,7 @@ limitations under the License.\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/shape.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n-#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -246,6 +247,7 @@ class PjRtCpuClient final : public CommonPjRtClient {\n \n   PjRtCpuClient(\n       int process_index, std::vector<std::unique_ptr<PjRtCpuDevice>> devices,\n+      std::shared_ptr<CpuDeviceMemory::Allocator> allocator,\n       std::shared_ptr<cpu::CpuCollectives> collectives, size_t num_threads,\n       bool asynchronous,\n       std::function<void(HloModuleConfig&)> customize_hlo_module_config);\n@@ -257,6 +259,8 @@ class PjRtCpuClient final : public CommonPjRtClient {\n       CompileOptions options,\n       const AotCompilationOptions* absl_nullable aot_options = nullptr);\n \n+  CpuDeviceMemory::Allocator* allocator() const { return allocator_.get(); }\n+\n   int process_index_;\n   // Includes all devices, including non-addressable devices.\n   std::vector<std::unique_ptr<PjRtCpuDevice>> owned_devices_;\n@@ -273,6 +277,10 @@ class PjRtCpuClient final : public CommonPjRtClient {\n   // Pointers to `owned_memory_spaces_`.\n   std::vector<PjRtMemorySpace*> memory_spaces_;\n \n+  // A memory allocator used to allocate host memory for PjRtBuffers, and\n+  // temporary allocations passed to XLA:CPU executable.\n+  std::shared_ptr<CpuDeviceMemory::Allocator> allocator_;\n+\n   // TODO(zhangqiaorjc): Use tsl::compat::EigenHostContextThreadPool.\n   std::unique_ptr<tsl::thread::ThreadPool> eigen_intraop_pool_;\n   std::unique_ptr<Eigen::ThreadPoolDevice> eigen_intraop_device_;"
        },
        {
            "sha": "8f9d0c0d8cdb66b7ad743d824ca3b4d5b0b76471",
            "filename": "third_party/xla/xla/pjrt/cpu/cpu_client_test.cc",
            "status": "modified",
            "additions": 39,
            "deletions": 1,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fcpu_client_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -13,6 +13,10 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <array>\n+\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_memory.h\"\n #ifndef _WIN32\n #include <unistd.h>\n #endif\n@@ -70,7 +74,6 @@ using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n using ::testing::HasSubstr;\n using ::testing::IsFalse;\n-using ::tsl::testing::IsOkAndHolds;\n \n static absl::Status TestError(ffi::AnyBuffer, ffi::Result<ffi::AnyBuffer>,\n                               ffi::Result<ffi::AnyBuffer>) {\n@@ -987,6 +990,41 @@ TEST(PjRtCpuClientTest, SubByteLiteralToBufferRoundtrip) {\n   EXPECT_TRUE(LiteralTestUtil::Equal(literal, literal_result));\n }\n \n+TEST(PjRtCpuClientTest, CustomAllocator) {\n+  alignas(64) std::array<float, 4> data;\n+\n+  class CustomMemory : public CpuMemory {\n+   public:\n+    CustomMemory(void* base, size_t size_bytes)\n+        : base_(base), size_bytes_(size_bytes) {}\n+\n+    void* base() const final { return base_; }\n+    size_t size_bytes() const final { return size_bytes_; }\n+\n+   private:\n+    void* base_;\n+    size_t size_bytes_;\n+  };\n+\n+  CpuClientOptions options;\n+  options.allocator = [&](size_t size_bytes, size_t alignment) {\n+    return std::make_unique<CustomMemory>(&data, sizeof(data));\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto client, GetPjRtCpuClient(options));\n+  xla::Shape shape = xla::ShapeUtil::MakeShape(F32, {4});\n+  TF_ASSERT_OK_AND_ASSIGN(auto literal, xla::MakeFakeLiteral(shape));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto buffer,\n+      client->BufferFromHostLiteral(literal, client->memory_spaces()[0]));\n+  TF_ASSERT_OK_AND_ASSIGN(auto received_literal, buffer->ToLiteralSync());\n+\n+  // Check that buffer was constructed in the data array provided by the custom\n+  // allocator.\n+  EXPECT_THAT(data, ElementsAreArray(literal.data<float>()));\n+}\n+\n }  // namespace\n \n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "8244bf3d89ddf1cca468bac2eeaaae7a7d84b18a",
            "filename": "third_party/xla/xla/pjrt/cpu/raw_buffer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/alignment.h\"\n #include \"xla/cpu_function_runtime.h\"\n #include \"xla/layout.h\"\n #include \"xla/layout_util.h\"\n@@ -104,8 +105,10 @@ PjRtFuture<> CpuTrackedDeviceEvent::GetReadyFuture() {\n }\n \n /*static*/ absl::StatusOr<tsl::RCReference<CpuRawBuffer>>\n-CpuRawBuffer::Allocate(PjRtMemorySpace* memory_space, size_t size_bytes) {\n-  TF_ASSIGN_OR_RETURN(auto memory, CpuDeviceMemory::Allocate(size_bytes));\n+CpuRawBuffer::Allocate(PjRtMemorySpace* memory_space, size_t size_bytes,\n+                       const CpuDeviceMemory::Allocator& allocator) {\n+  TF_ASSIGN_OR_RETURN(auto memory,\n+                      CpuDeviceMemory::Allocate(size_bytes, allocator));\n   return tsl::MakeRef<CpuRawBuffer>(memory_space, std::move(memory));\n }\n "
        },
        {
            "sha": "c98e0ef05081337a0cc4642bead8654337983f62",
            "filename": "third_party/xla/xla/pjrt/cpu/raw_buffer.h",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Fraw_buffer.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdint>\n+#include <optional>\n #include <utility>\n \n #include \"absl/functional/any_invocable.h\"\n@@ -32,6 +33,7 @@ limitations under the License.\n #include \"xla/pjrt/cpu/cpu_event.h\"\n #include \"xla/pjrt/cpu/tracked_cpu_device_buffer.h\"\n #include \"xla/pjrt/device_event.h\"\n+#include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_future.h\"\n #include \"xla/pjrt/raw_buffer.h\"\n #include \"xla/pjrt/transpose.h\"\n@@ -96,7 +98,9 @@ class CpuRawBuffer : public CommonPjRtRawBuffer {\n \n   // Allocates owning memory.\n   static absl::StatusOr<tsl::RCReference<CpuRawBuffer>> Allocate(\n-      PjRtMemorySpace* memory_space, size_t size_bytes);\n+      PjRtMemorySpace* memory_space, size_t size_bytes,\n+      const CpuDeviceMemory::Allocator& allocator =\n+          CpuDeviceMemory::DefaultAllocator());\n \n   // Imports foreign memory.\n   static absl::StatusOr<tsl::RCReference<CpuRawBuffer>> ImportForeignMemory("
        },
        {
            "sha": "8d2ae5382969c55bfaf4b771dae046c46f0cd92d",
            "filename": "third_party/xla/xla/pjrt/cpu/tracked_cpu_device_buffer.cc",
            "status": "modified",
            "additions": 86,
            "deletions": 19,
            "changes": 105,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/no_destructor.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/log/check.h\"\n@@ -39,6 +40,7 @@ limitations under the License.\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"tsl/platform/casts.h\"\n #include \"tsl/platform/mem.h\"\n@@ -67,23 +69,73 @@ tsl::AsyncValueRef<CpuEvent> AfterAll(\n \n   return std::move(after_all).AsRef();\n }\n+\n+//===----------------------------------------------------------------------===//\n+// Default CpuDeviceMemory::RawMemory allocator.\n+//===----------------------------------------------------------------------===//\n+\n+class AlignedMemory final : public CpuDeviceMemory::RawMemory {\n+ public:\n+  AlignedMemory(void* base, size_t size_bytes)\n+      : base_(base), size_bytes_(size_bytes) {}\n+\n+  ~AlignedMemory() final {\n+    tsl::port::AlignedSizedFree(base_, cpu::MinAlign(), size_bytes_);\n+  }\n+\n+  void* base() const final { return base_; }\n+  size_t size_bytes() const final { return size_bytes_; }\n+\n+ private:\n+  void* base_;\n+  size_t size_bytes_;\n+};\n+\n+class AlignedAllocator final : public CpuDeviceMemory::Allocator {\n+ public:\n+  absl::StatusOr<std::unique_ptr<CpuDeviceMemory::RawMemory>> Allocate(\n+      size_t size_bytes, size_t alignment) const final {\n+    if (void* base = tsl::port::AlignedMalloc(size_bytes, alignment)) {\n+      return std::make_unique<AlignedMemory>(base, size_bytes);\n+    }\n+    return ResourceExhausted(\"Out of memory allocating %d bytes.\", size_bytes);\n+  }\n+};\n+\n }  // namespace\n \n+CpuDeviceMemory::Allocator& CpuDeviceMemory::DefaultAllocator() {\n+  static absl::NoDestructor<AlignedAllocator> allocator;\n+  return *allocator;\n+}\n+\n+std::unique_ptr<CpuDeviceMemory::Allocator>\n+CpuDeviceMemory::MakeDefaultAllocator() {\n+  return std::make_unique<AlignedAllocator>();\n+}\n+\n+//===----------------------------------------------------------------------===//\n+// CpuDeviceMemory implementations.\n+//===----------------------------------------------------------------------===//\n+\n class CpuDeviceMemoryOwned final : public CpuDeviceMemory {\n  public:\n-  CpuDeviceMemoryOwned(void* base, size_t size) : CpuDeviceMemory(base, size) {}\n+  explicit CpuDeviceMemoryOwned(std::unique_ptr<RawMemory> mem)\n+      : mem_(std::move(mem)) {}\n \n-  ~CpuDeviceMemoryOwned() final {\n-    CHECK_NE(untyped_data(), nullptr);\n-    tsl::port::AlignedSizedFree(untyped_data(), cpu::MinAlign(), size_bytes());\n-  }\n+  void* untyped_data() const final { return mem_->base(); }\n+  size_t size_bytes() const final { return mem_->size_bytes(); }\n+\n+ private:\n+  std::unique_ptr<RawMemory> mem_;\n };\n \n class CpuDeviceMemoryForeign final : public CpuDeviceMemory {\n  public:\n   CpuDeviceMemoryForeign(void* base, size_t size,\n                          absl::AnyInvocable<void() &&> on_delete_callback)\n-      : CpuDeviceMemory(base, size),\n+      : base_(base),\n+        size_bytes_(size),\n         on_delete_callback_(std::move(on_delete_callback)) {}\n \n   ~CpuDeviceMemoryForeign() final {\n@@ -92,14 +144,26 @@ class CpuDeviceMemoryForeign final : public CpuDeviceMemory {\n     }\n   }\n \n+  void* untyped_data() const final { return base_; }\n+  size_t size_bytes() const final { return size_bytes_; }\n+\n  private:\n+  void* base_;\n+  size_t size_bytes_;\n   absl::AnyInvocable<void() &&> on_delete_callback_;\n };\n \n class CpuDeviceMemoryConstant final : public CpuDeviceMemory {\n  public:\n   CpuDeviceMemoryConstant(void* base, size_t size)\n-      : CpuDeviceMemory(base, size) {}\n+      : base_(base), size_bytes_(size) {}\n+\n+  void* untyped_data() const final { return base_; }\n+  size_t size_bytes() const final { return size_bytes_; }\n+\n+ private:\n+  void* base_;\n+  size_t size_bytes_;\n };\n \n tsl::AsyncValueRef<CpuDeviceMemory> CpuDeviceMemory::CreateDelayedMemory() {\n@@ -119,27 +183,30 @@ tsl::AsyncValueRef<CpuDeviceMemory> CpuDeviceMemory::CreateConstantMemory(\n \n // Allocates owning memory wrapped in an available `AsyncValueRef`.\n absl::StatusOr<tsl::AsyncValueRef<CpuDeviceMemory>> CpuDeviceMemory::Allocate(\n-    size_t size_bytes) {\n-  if (void* data = tsl::port::AlignedMalloc(size_bytes, cpu::MinAlign())) {\n-    return tsl::MakeAvailableAsyncValueRef<CpuDeviceMemoryOwned>(data,\n-                                                                 size_bytes);\n-  }\n-  return ResourceExhausted(\"Out of memory allocating %d bytes.\", size_bytes);\n+    size_t size_bytes, const Allocator& allocator) {\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<RawMemory> mem,\n+                      allocator.Allocate(size_bytes, cpu::MinAlign()));\n+  return tsl::MakeAvailableAsyncValueRef<CpuDeviceMemoryOwned>(std::move(mem));\n }\n \n absl::Status CpuDeviceMemory::AllocateInto(\n-    size_t size_bytes, tsl::AsyncValuePtr<CpuDeviceMemory> delayed_memory) {\n+    size_t size_bytes, tsl::AsyncValuePtr<CpuDeviceMemory> delayed_memory,\n+    const Allocator& allocator) {\n   auto owned_memory = delayed_memory.DynCast<CpuDeviceMemoryOwned>();\n   if (!owned_memory) {\n     return Internal(\"Delayed memory is not a CpuDeviceMemoryOwned\");\n   }\n-  if (void* data = tsl::port::AlignedMalloc(size_bytes, cpu::MinAlign())) {\n-    owned_memory.emplace(data, size_bytes);\n-    return absl::OkStatus();\n-  }\n-  return ResourceExhausted(\"Out of memory allocating %d bytes.\", size_bytes);\n+\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<RawMemory> mem,\n+                      allocator.Allocate(size_bytes, cpu::MinAlign()));\n+  owned_memory.emplace(std::move(mem));\n+  return absl::OkStatus();\n }\n \n+//===----------------------------------------------------------------------===//\n+// TrackedCpuDeviceBuffer.\n+//===----------------------------------------------------------------------===//\n+\n TrackedCpuDeviceBuffer::TrackedCpuDeviceBuffer(\n     bool owns_buffers, tsl::AsyncValueRef<CpuDeviceMemory> buffer,\n     absl::InlinedVector<tsl::AsyncValueRef<CpuEvent>, 4> definition_events)"
        },
        {
            "sha": "e5754d1443591c929e29da2af53de78341779543",
            "filename": "third_party/xla/xla/pjrt/cpu/tracked_cpu_device_buffer.h",
            "status": "modified",
            "additions": 69,
            "deletions": 8,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcpu%2Ftracked_cpu_device_buffer.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,6 +18,8 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdlib>\n+#include <memory>\n+#include <vector>\n \n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n@@ -26,21 +28,49 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/cpu/cpu_event.h\"\n+#include \"xla/pjrt/device_event.h\"\n+#include \"xla/pjrt/pjrt_future.h\"\n+#include \"xla/pjrt/raw_buffer.h\"\n+#include \"xla/tsl/concurrency/async_value.h\"\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n+#include \"xla/tsl/concurrency/ref_count.h\"\n \n namespace xla {\n \n // A region of device memory that can be used to construct PjRt buffers. Device\n // memory can be either owned or non-owned.\n+//\n+// CpuDeviceMemory has an asynchronous memory allocation semantics, as the size\n+// of the allocation might depend on a result of another computation (pending\n+// async value), and must be delayed until the async value becomes available.\n+//\n+// Synchronous allocations of the raw memory (same semantics as `aligned_malloc`\n+// and `free`) is handled via the `CpuDeviceMemory::Allocator` interface.\n+//\n+// Types of CpuDeviceMemory:\n+//\n+//   OWNED:    raw memory was allocated for the CpuDeviceMemory and will be\n+//             freed when when CpuDeviceMemory is destroyed.\n+//\n+//   FOREIGN:  raw memory was allocated by another entity (i.e. it can be a view\n+//             into a buffer owned by a different runtime) and the owner will be\n+//             notified via the on_delete_callback when CpuDeviceMemory is\n+//             destroyed.\n+//\n+//   CONSTANT: raw memory has a lifetime that is not bound to the\n+//             CpuDeviceMemory (i.e. a global static).\n+//\n class CpuDeviceMemory {\n  public:\n+  class Allocator;\n+\n   virtual ~CpuDeviceMemory() = default;\n \n   CpuDeviceMemory(const CpuDeviceMemory&) = delete;\n   CpuDeviceMemory& operator=(const CpuDeviceMemory&) = delete;\n \n-  void* untyped_data() const { return base_; }\n-  size_t size_bytes() const { return size_bytes_; }\n+  virtual void* untyped_data() const = 0;\n+  virtual size_t size_bytes() const = 0;\n \n   // Creates an unavailable AsyncValueRef placeholder for a delayed\n   // memory allocation (see `AllocateInto` below).\n@@ -59,18 +89,49 @@ class CpuDeviceMemory {\n \n   // Allocates owning memory wrapped in an available `AsyncValueRef`.\n   static absl::StatusOr<tsl::AsyncValueRef<CpuDeviceMemory>> Allocate(\n-      size_t size_bytes);\n+      size_t size_bytes, const Allocator& allocator = DefaultAllocator());\n \n   // Allocates owning memory into the previously created delayed memory\n   // placeholder (see `CreateDelayedMemory` above).\n   static absl::Status AllocateInto(\n-      size_t size_bytes, tsl::AsyncValuePtr<CpuDeviceMemory> delayed_memory);\n+      size_t size_bytes, tsl::AsyncValuePtr<CpuDeviceMemory> delayed_memory,\n+      const Allocator& allocator = DefaultAllocator());\n+\n+  //===--------------------------------------------------------------------===//\n+  // Custom raw memory allocation APIs.\n+  //===--------------------------------------------------------------------===//\n+\n+  // Default allocator uses aligned allocation and free APIs from tsl.\n+  static Allocator& DefaultAllocator();\n+\n+  // Returns a new instance of the default allocator.\n+  static std::unique_ptr<Allocator> MakeDefaultAllocator();\n+\n+  // A raw memory allocation that can be used to construct a CpuDeviceMemory.\n+  class RawMemory {\n+   public:\n+    virtual ~RawMemory() = default;\n+    virtual void* base() const = 0;\n+    virtual size_t size_bytes() const = 0;\n+  };\n+\n+  // A raw memory allocator that allocates memory buffers for constructing\n+  // CpuDeviceMemory.\n+  //\n+  // This is a virtual interface to allow for different memory allocation\n+  // strategies, e.g. aligned_alloc, pre-mapped DMA buffers, etc. For example,\n+  // when XLA:CPU is running as a part of host-offloading computation, we want\n+  // all buffers used by XLA:CPU to be pre-mapped with the accelerator device,\n+  // so that we can issue zero-copy DMA transfers operations if needed.\n+  class Allocator {\n+   public:\n+    virtual ~Allocator() = default;\n+    virtual absl::StatusOr<std::unique_ptr<RawMemory>> Allocate(\n+        size_t size_bytes, size_t alignment) const = 0;\n+  };\n \n  protected:\n-  CpuDeviceMemory(void* base, size_t size) : base_(base), size_bytes_(size) {}\n-\n-  void* base_;\n-  size_t size_bytes_;\n+  CpuDeviceMemory() = default;\n };\n \n // A class that represents a CPU device buffer: it can be a single memory region"
        },
        {
            "sha": "5612b7b26e521fb2d3e0425676e1652827047e07",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1847,9 +1847,8 @@ StreamExecutorGpuClient::RunAsync(\n                                  ? run_options->device_ordinal()\n                                  : executor->device_ordinal();\n \n-  XLA_SCOPED_LOGGING_TIMER(\n-      absl::StrCat(\"GpuExecutable::ExecuteAsyncOnStreamImpl(\",\n-                   gpu_exec->module_name(), \")\"));\n+  XLA_SCOPED_LOGGING_TIMER(absl::StrCat(\n+      \"GpuExecutable::ExecuteAsyncOnStreamImpl(\", gpu_exec->name(), \")\"));\n \n   // GpuExecutable always bound to a single GpuContext during its execution, so\n   // we activate it once to skip expensive context activations later."
        },
        {
            "sha": "9e47386e8a01d1ded9587ca8d5f1dab3d12ebb23",
            "filename": "third_party/xla/xla/pjrt/pjrt_future.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <atomic>\n #include <cstdint>\n #include <memory>\n+#include <tuple>\n #include <utility>\n \n #include \"absl/base/no_destructor.h\"\n@@ -41,11 +42,13 @@ absl::NoDestructor<tsl::AsyncValueOwningRef<absl::Status>>\n \n namespace {\n struct State {\n-  explicit State(int32_t size)\n-      : pending_count(size), promise(PjRtFuture<>::CreatePromise()) {}\n+  explicit State(int32_t size) : pending_count(size) {\n+    std::tie(promise, future) = PjRtFuture<>::MakePromise();\n+  }\n \n   std::atomic<int32_t> pending_count;\n   PjRtFuture<>::Promise promise;\n+  PjRtFuture<> future;\n \n   absl::Mutex mu;\n   absl::Status status ABSL_GUARDED_BY(&mu);\n@@ -56,7 +59,8 @@ PjRtFuture<> JoinFutures(absl::Span<const PjRtFuture<>> futures) {\n   VLOG(2) << \"xla::JoinFutures: \" << futures.size() << \" futures\";\n   if (futures.empty()) {\n     return PjRtFuture<>(absl::OkStatus());\n-  } else if (futures.size() == 1) {\n+  }\n+  if (futures.size() == 1) {\n     return futures.front();\n   }\n \n@@ -86,7 +90,7 @@ PjRtFuture<> JoinFutures(absl::Span<const PjRtFuture<>> futures) {\n     });\n   }\n \n-  return PjRtFuture<>(state->promise);\n+  return std::move(state->future);\n }\n \n }  // namespace xla"
        },
        {
            "sha": "15c72fed708e51ddf1f28d13bbe979cffc6adcac",
            "filename": "third_party/xla/xla/pjrt/pjrt_future.h",
            "status": "modified",
            "additions": 145,
            "deletions": 57,
            "changes": 202,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -221,7 +221,25 @@ class PjRtFutureBase : public PjRtFutureMoveControl<is_move_only> {\n     Promise(const Promise& other) = default;\n     Promise& operator=(const Promise& other) = default;\n \n-    operator bool() const { return static_cast<bool>(promise_); }  // NOLINT\n+    explicit operator bool() const { return static_cast<bool>(promise_); }\n+\n+    // Returns if this promise is the unique reference to the underlying value.\n+    // That is, this method returns true only if all of the following conditions\n+    // are satisfied:\n+    //\n+    // - The promise is the only reference to the underlying value, i.e., there\n+    //   are no other promises or futures associated with this value.\n+    // - There are no OnReady callbacks registered to this promise.\n+    //\n+    // This may be used by the caller of `Set()` to short-circuit the work to\n+    // fulfill the promise if no one will ever consume the value. Even in that\n+    // case, consider fulfilling the promise with an error (e.g., `CANCELLED`)\n+    // instead of dropping the promise without fulfilling it in order to make\n+    // debugging easier. Also, be aware that the current promise may still be\n+    // used to mint a future.\n+    bool IsUniqueReference() const {\n+      return async_value()->IsUnique() && !async_value()->HasWaiter();\n+    }\n \n    protected:\n     explicit Promise(tsl::AsyncValueRef<T> promise)\n@@ -233,16 +251,16 @@ class PjRtFutureBase : public PjRtFutureMoveControl<is_move_only> {\n       promise_.template emplace<Args...>(std::forward<Args>(args)...);\n     }\n \n-    // Releases the underlying AsyncValueRef container to the caller.\n-    tsl::AsyncValueRef<T> release() { return std::move(promise_); }\n+    // Takes a reference to the underlying AsyncValueRef container.\n+    tsl::AsyncValueRef<T> ref() const { return promise_; }\n \n     // Returns a pointer to the underlying AsyncValue that can be used to\n     // track completion of a promise. It is undefined behavior to access the\n     // value stored in the AsyncValue.\n     tsl::AsyncValue* async_value() const { return promise_.GetAsyncValue(); }\n \n #ifndef NDEBUG\n-    int64_t AddFuture() { return num_futures_->fetch_add(1); }\n+    int64_t AddFuture() const { return num_futures_->fetch_add(1); }\n #endif\n \n    private:\n@@ -320,6 +338,12 @@ class PjRtFutureBase : public PjRtFutureMoveControl<is_move_only> {\n     }\n   }\n \n+  // Returns a PjRtFuture<> that becomes ready when *this is ready. If *this\n+  // completes with an error, the returned future will also be an error.\n+  //\n+  // This function defined out of line as it requires PjRtFuture<> definition.\n+  PjRtFuture<> GetReadyFuture() const;\n+\n   // Registers callback to be called once the promise is ready, with the final\n   // value.\n   //\n@@ -366,6 +390,16 @@ class PjRtFutureBase : public PjRtFutureMoveControl<is_move_only> {\n         });\n   }\n \n+ protected:\n+  // Returns a placeholder error that can be used when short-circuiting promises\n+  // with no other references.\n+  static absl::Status AbortedError() {\n+    return absl::AbortedError(\n+        \"Fulfilling the promise with an aborted error since the value is no \"\n+        \"longer referenced by any futures or OnReady callbacks; if this error \"\n+        \"is exposed to any future, that indicates a bug\");\n+  }\n+\n  private:\n   tsl::AsyncValueRef<T> promise_;\n \n@@ -442,6 +476,14 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n     return Promise(tsl::MakeUnconstructedAsyncValueRef<absl::StatusOr<T>>());\n   }\n \n+  // Returns a pair of connected Promise and PjRtFuture<T>. Setting the returned\n+  // promise will fulfill the connected future.\n+  static std::pair<Promise, PjRtFuture<T>> MakePromise() {\n+    Promise promise(tsl::MakeUnconstructedAsyncValueRef<absl::StatusOr<T>>());\n+    PjRtFuture<T> future(promise);\n+    return std::make_pair(std::move(promise), std::move(future));\n+  }\n+\n   // Bring PjRtFutureBase constructors in scope.\n   using Base::Base;\n \n@@ -451,10 +493,10 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n   // - on_block_start is called before Await starts to block.\n   //  - on_block_end is called after Await finishes blocking.\n   explicit PjRtFuture(\n-      Promise promise,\n+      const Promise& promise,\n       PjRtFutureHelpers::OnBlockStartFn on_block_start = nullptr,\n       PjRtFutureHelpers::OnBlockEndFn on_block_end = nullptr)\n-      : Base(promise.release(), std::move(on_block_start),\n+      : Base(promise.ref(), std::move(on_block_start),\n              std::move(on_block_end)) {\n #ifndef NDEBUG\n     if constexpr (is_move_only) {\n@@ -465,6 +507,7 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n   }\n \n   using Base::Await;\n+  using Base::GetReadyFuture;\n   using Base::OnReady;\n \n   // Returns an PjRtFuture<R> that is constructed from the result of invoking\n@@ -482,18 +525,21 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n             std::enable_if_t<!is_move_only && std::is_constructible_v<R, U>>* =\n                 nullptr>\n   PjRtFuture<R> Map(F&& f) const& {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n     using Value = const absl::StatusOr<T>&;\n-    OnReady([promise, f = std::forward<F>(f)](Value value) mutable {\n-      if (ABSL_PREDICT_TRUE(value.ok())) {\n+    OnReady([promise = std::move(promise),\n+             f = std::forward<F>(f)](Value value) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(value.ok())) {\n         promise.emplace(absl::in_place_t{}, f(*value));\n       } else {\n         promise.Set(value.status());\n       }\n     });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // Returns an PjRtFuture<R> that is constructed from the result of invoking\n@@ -511,24 +557,26 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n                 F, std::conditional_t<is_move_only, T, const T&>>,\n             std::enable_if_t<std::is_constructible_v<R, U>>* = nullptr>\n   PjRtFuture<R> Map(F&& f) && {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n     using Value = std::conditional_t<is_move_only, absl::StatusOr<T>,\n                                      const absl::StatusOr<T>&>;\n-    std::move(*this).OnReady(\n-        [promise, f = std::forward<F>(f)](Value value) mutable {\n-          if (ABSL_PREDICT_TRUE(value.ok())) {\n-            if constexpr (is_move_only) {\n-              promise.emplace(absl::in_place_t{}, f(std::move(*value)));\n-            } else {\n-              promise.emplace(absl::in_place_t{}, f(*value));\n-            }\n-          } else {\n-            promise.Set(value.status());\n-          }\n-        });\n+    std::move(*this).OnReady([promise = std::move(promise),\n+                              f = std::forward<F>(f)](Value value) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(value.ok())) {\n+        if constexpr (is_move_only) {\n+          promise.emplace(absl::in_place_t{}, f(std::move(*value)));\n+        } else {\n+          promise.emplace(absl::in_place_t{}, f(*value));\n+        }\n+      } else {\n+        promise.Set(value.status());\n+      }\n+    });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // Returns an PjRtFuture<R> that is constructed from the result of invoking\n@@ -549,11 +597,14 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n                        std::is_constructible_v<R, typename U::value_type>>* =\n           nullptr>\n   PjRtFuture<R> TryMap(F&& f) const& {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n     using Value = const absl::StatusOr<T>&;\n-    OnReady([promise, f = std::forward<F>(f)](Value value) mutable {\n-      if (ABSL_PREDICT_TRUE(value.ok())) {\n+    OnReady([promise = std::move(promise),\n+             f = std::forward<F>(f)](Value value) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(value.ok())) {\n         auto result = f(*value);\n         if (ABSL_PREDICT_TRUE(result.ok())) {\n           promise.emplace(absl::in_place_t{}, *std::move(result));\n@@ -565,7 +616,7 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n       }\n     });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // Returns an PjRtFuture<R> that is constructed from the result of invoking\n@@ -587,31 +638,33 @@ class PjRtFuture : public internal::PjRtFutureBase<absl::StatusOr<T>> {\n                 is_status_or<U> &&\n                 std::is_constructible_v<R, typename U::value_type>>* = nullptr>\n   PjRtFuture<R> TryMap(F&& f) && {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n     using Value = std::conditional_t<is_move_only, absl::StatusOr<T>,\n                                      const absl::StatusOr<T>&>;\n-    std::move(*this).OnReady(\n-        [promise, f = std::forward<F>(f)](Value value) mutable {\n-          if (ABSL_PREDICT_TRUE(value.ok())) {\n-            auto result = [&] {\n-              if constexpr (is_move_only) {\n-                return f(std::move(*value));\n-              } else {\n-                return f(*value);\n-              }\n-            }();\n-            if (ABSL_PREDICT_TRUE(result.ok())) {\n-              promise.emplace(absl::in_place_t{}, *std::move(result));\n-            } else {\n-              promise.Set(std::move(result).status());\n-            }\n+    std::move(*this).OnReady([promise = std::move(promise),\n+                              f = std::forward<F>(f)](Value value) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(value.ok())) {\n+        auto result = [&] {\n+          if constexpr (is_move_only) {\n+            return f(std::move(*value));\n           } else {\n-            promise.Set(value.status());\n+            return f(*value);\n           }\n-        });\n+        }();\n+        if (ABSL_PREDICT_TRUE(result.ok())) {\n+          promise.emplace(absl::in_place_t{}, *std::move(result));\n+        } else {\n+          promise.Set(std::move(result).status());\n+        }\n+      } else {\n+        promise.Set(value.status());\n+      }\n+    });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // A `Map` overload that automatically infers the type of result from `f`.\n@@ -681,6 +734,14 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n     return Promise(tsl::MakeUnconstructedAsyncValueRef<absl::Status>());\n   }\n \n+  // Returns a pair of connected Promise and PjRtFuture<>. Setting the returned\n+  // promise will fulfill the connected future.\n+  static std::pair<Promise, PjRtFuture<>> MakePromise() {\n+    Promise promise(tsl::MakeUnconstructedAsyncValueRef<absl::Status>());\n+    PjRtFuture<> future(promise);\n+    return std::make_pair(std::move(promise), std::move(future));\n+  }\n+\n   // Bring PjRtFutureBase constructors in scope.\n   using Base::Base;\n \n@@ -690,10 +751,10 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n   // - on_block_start is called before Await starts to block.\n   // - on_block_end is called after Await finishes blocking.\n   explicit PjRtFuture(\n-      Promise promise,\n+      const Promise& promise,\n       PjRtFutureHelpers::OnBlockStartFn on_block_start = nullptr,\n       PjRtFutureHelpers::OnBlockEndFn on_block_end = nullptr)\n-      : Base(promise.release(), std::move(on_block_start),\n+      : Base(promise.ref(), std::move(on_block_start),\n              std::move(on_block_end)) {}\n \n   // Constructor for a future that is immediately ready with a given status.\n@@ -723,17 +784,20 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n   //\n   template <typename R, typename F, typename U = std::invoke_result_t<F>>\n   PjRtFuture<R> Map(F&& f) {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n-    OnReady([promise, f = std::forward<F>(f)](absl::Status status) mutable {\n-      if (ABSL_PREDICT_TRUE(status.ok())) {\n+    OnReady([promise = std::move(promise),\n+             f = std::forward<F>(f)](absl::Status status) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(status.ok())) {\n         promise.emplace(absl::in_place_t{}, f());\n       } else {\n         promise.Set(std::move(status));\n       }\n     });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // Returns an PjRtFuture<R> that is constructed from the result of invoking\n@@ -753,10 +817,13 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n                 is_status_or<U> &&\n                 std::is_constructible_v<R, typename U::value_type>>* = nullptr>\n   PjRtFuture<R> TryMap(F&& f) {\n-    auto promise = PjRtFuture<R>::CreatePromise();\n+    auto [promise, future] = PjRtFuture<R>::MakePromise();\n \n-    OnReady([promise, f = std::forward<F>(f)](absl::Status status) mutable {\n-      if (ABSL_PREDICT_TRUE(status.ok())) {\n+    OnReady([promise = std::move(promise),\n+             f = std::forward<F>(f)](absl::Status status) mutable {\n+      if (ABSL_PREDICT_FALSE(promise.IsUniqueReference())) {\n+        promise.Set(Base::AbortedError());\n+      } else if (ABSL_PREDICT_TRUE(status.ok())) {\n         auto result = f();\n         if (ABSL_PREDICT_TRUE(result.ok())) {\n           promise.emplace(absl::in_place_t{}, *std::move(result));\n@@ -768,7 +835,7 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n       }\n     });\n \n-    return PjRtFuture<R>(promise);\n+    return std::move(future);\n   }\n \n   // A `Map` overload that automatically infers the type of result from `f`.\n@@ -806,6 +873,27 @@ class PjRtFuture<void> : public internal::PjRtFutureBase<absl::Status> {\n       ready_promise_;\n };\n \n+//===----------------------------------------------------------------------===//\n+// internal::PjRtFutureBase<T> implementation.\n+//===----------------------------------------------------------------------===//\n+\n+namespace internal {\n+\n+template <typename T, bool is_move_only>\n+PjRtFuture<> PjRtFutureBase<T, is_move_only>::GetReadyFuture() const {\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n+  promise_.AndThen(\n+      [self = promise_.AsPtr(), promise = std::move(promise)]() mutable {\n+        if constexpr (std::is_same_v<T, absl::Status>) {\n+          promise.Set(*self);\n+        } else {\n+          promise.Set(self->status());\n+        }\n+      });\n+  return std::move(future);\n+}\n+\n+}  // namespace internal\n }  // namespace xla\n \n #endif  // XLA_PJRT_PJRT_FUTURE_H_"
        },
        {
            "sha": "d463d2438976c5829018cb43b409e4e46247f850",
            "filename": "third_party/xla/xla/pjrt/pjrt_future_test.cc",
            "status": "modified",
            "additions": 160,
            "deletions": 67,
            "changes": 227,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_future_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -40,8 +40,7 @@ TEST(PjRtFutureTest, ValueConstructedFuture) {\n }\n \n TEST(PjRtFutureTest, StatelessFuture) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n \n   EXPECT_FALSE(future.IsReady());\n   promise.Set();\n@@ -53,9 +52,48 @@ TEST(PjRtFutureTest, StatelessFuture) {\n       [](absl::Status status) { EXPECT_EQ(status, absl::OkStatus()); });\n }\n \n+TEST(PjRtFutureTest, StatefulFutureToStateless) {\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n+  PjRtFuture<> ready_future = future.GetReadyFuture();\n+\n+  EXPECT_FALSE(ready_future.IsReady());\n+  promise.Set(42);\n+  EXPECT_EQ(ready_future.Await(), absl::OkStatus());\n+}\n+\n+TEST(PjRtFutureTest, StatefulFutureToStatelessError) {\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n+  PjRtFuture<> ready_future = future.GetReadyFuture();\n+\n+  EXPECT_FALSE(ready_future.IsReady());\n+  promise.Set(absl::InternalError(\"test\"));\n+  EXPECT_EQ(ready_future.Await(), absl::InternalError(\"test\"));\n+}\n+\n+TEST(PjRtFutureTest, MoveOnlyFutureToStateless) {\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n+  PjRtFuture<> ready_future = future.GetReadyFuture();\n+\n+  EXPECT_FALSE(future.IsReady());\n+  EXPECT_FALSE(ready_future.IsReady());\n+\n+  promise.Set(std::make_unique<int32_t>(42));\n+  EXPECT_EQ(ready_future.Await(), absl::OkStatus());\n+}\n+\n+TEST(PjRtFutureTest, MoveOnlyFutureToStatelessError) {\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n+  PjRtFuture<> ready_future = future.GetReadyFuture();\n+\n+  EXPECT_FALSE(future.IsReady());\n+  EXPECT_FALSE(ready_future.IsReady());\n+\n+  promise.Set(absl::InternalError(\"test\"));\n+  EXPECT_EQ(ready_future.Await(), absl::InternalError(\"test\"));\n+}\n+\n TEST(PjRtFutureTest, CopyableFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n \n   PjRtFuture<int32_t> copy_constructed(future);\n   PjRtFuture<int32_t> copy_assigned = future;\n@@ -68,8 +106,7 @@ TEST(PjRtFutureTest, CopyableFuture) {\n }\n \n TEST(PjRtFutureTest, MoveConstructedFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n   PjRtFuture<std::unique_ptr<int32_t>> move_constructed(std::move(future));\n \n@@ -79,8 +116,7 @@ TEST(PjRtFutureTest, MoveConstructedFuture) {\n }\n \n TEST(PjRtFutureTest, MoveAssignedFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n   PjRtFuture<std::unique_ptr<int32_t>> move_assigned = std::move(future);\n \n@@ -90,8 +126,7 @@ TEST(PjRtFutureTest, MoveAssignedFuture) {\n }\n \n TEST(PjRtFutureTest, AwaitMoveOnlyFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n   promise.Set(std::make_unique<int32_t>(42));\n \n@@ -100,8 +135,7 @@ TEST(PjRtFutureTest, AwaitMoveOnlyFuture) {\n }\n \n TEST(PjRtFutureTest, OnReadyRvalueFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n \n   promise.Set(42);\n \n@@ -110,8 +144,7 @@ TEST(PjRtFutureTest, OnReadyRvalueFuture) {\n }\n \n TEST(PjRtFutureTest, OnReadyMoveOnlyFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n   promise.Set(std::make_unique<int32_t>(42));\n \n@@ -120,9 +153,40 @@ TEST(PjRtFutureTest, OnReadyMoveOnlyFuture) {\n   });\n }\n \n+TEST(PjRtFutureTest, UnlinkedPromiseIsUnique) {\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n+  EXPECT_FALSE(promise.IsUniqueReference());\n+  future = {};\n+  EXPECT_TRUE(promise.IsUniqueReference());\n+}\n+\n+TEST(PjRtFutureTest, PromiseIsUnique) {\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n+\n+  // Future is linked to the promise object.\n+  EXPECT_FALSE(promise.IsUniqueReference());\n+\n+  // Future is destroyed, but we added a callback to underlying value.\n+  future.OnReady([](const absl::Status&) {});\n+  future = {};\n+  EXPECT_FALSE(promise.IsUniqueReference());\n+\n+  // Once promise is fulfilled, the callback is executed, and because we\n+  // destroyed the future, the underlying value is not referenced by anyone\n+  // else, and the promise becomes unique.\n+  promise.Set();\n+  EXPECT_TRUE(promise.IsUniqueReference());\n+\n+  {  // Making a copy of the promise makes it not unique.\n+    auto copy = promise;\n+    EXPECT_FALSE(promise.IsUniqueReference());\n+    EXPECT_FALSE(copy.IsUniqueReference());\n+  }\n+  EXPECT_TRUE(promise.IsUniqueReference());\n+}\n+\n TEST(PjRtFutureTest, MapCopyableFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<float> mapped = future.Map([](int32_t v) { return v * 2.0f; });\n \n   EXPECT_FALSE(future.IsReady());\n@@ -141,8 +205,7 @@ TEST(PjRtFutureTest, MapCopyableFuture) {\n }\n \n TEST(PjRtFutureTest, MapCopyableFutureError) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<float> mapped = future.Map([](int32_t v) { return v * 2.0f; });\n \n   promise.Set(absl::InternalError(\"test\"));\n@@ -151,9 +214,8 @@ TEST(PjRtFutureTest, MapCopyableFutureError) {\n }\n \n TEST(PjRtFutureTest, MapMoveOnlyFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n   PjRtFuture<std::unique_ptr<float>> mapped =\n       std::move(future).Map([](std::unique_ptr<int32_t> v) {\n         return std::make_unique<float>(*v * 2.0f);\n@@ -168,8 +230,7 @@ TEST(PjRtFutureTest, MapMoveOnlyFuture) {\n }\n \n TEST(PjRtFutureTest, MapMoveOnlyFutureError) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n   PjRtFuture<std::unique_ptr<float>> mapped =\n       std::move(future).Map([](std::unique_ptr<int32_t> v) {\n         return std::make_unique<float>(*v * 2.0f);\n@@ -186,8 +247,7 @@ TEST(PjRtFutureTest, MapCopyableWithInplaceConstructor) {\n     int32_t v;\n   };\n \n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<Struct> mapped = future.Map<Struct>([](int32_t v) { return v; });\n \n   promise.Set(42);\n@@ -201,8 +261,7 @@ TEST(PjRtFutureTest, MapMoveOnlyWithInplaceConstructor) {\n     int32_t v;\n   };\n \n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n   PjRtFuture<Struct> mapped = std::move(future).Map<Struct>(\n       [](std::unique_ptr<int32_t> v) { return *v; });\n \n@@ -211,9 +270,34 @@ TEST(PjRtFutureTest, MapMoveOnlyWithInplaceConstructor) {\n   EXPECT_EQ(mapped.Await()->v, 42);\n }\n \n+TEST(PjRtFutureTest, MapUnusedResult) {\n+  auto promise = PjRtFuture<int>::CreatePromise();\n+  PjRtFuture<int> future(promise);\n+\n+  bool called = false;\n+  future.Map([&](int) {\n+    called = true;\n+    return 2;\n+  });\n+  promise.Set(1);\n+  EXPECT_FALSE(called);\n+}\n+\n+TEST(PjRtFutureTest, MapStatusUnusedResult) {\n+  auto promise = PjRtFuture<>::CreatePromise();\n+  PjRtFuture<> future(promise);\n+\n+  bool called = false;\n+  future.Map([&]() {\n+    called = true;\n+    return 2;\n+  });\n+  promise.Set();\n+  EXPECT_FALSE(called);\n+}\n+\n TEST(PjRtFutureTest, TryMapCopyableFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<float> mapped = future.TryMap(\n       [](int32_t v) -> absl::StatusOr<float> { return v * 2.0f; });\n \n@@ -233,8 +317,7 @@ TEST(PjRtFutureTest, TryMapCopyableFuture) {\n }\n \n TEST(PjRtFutureTest, TryMapCopyableFutureForwardError) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<float> mapped = future.TryMap(\n       [](int32_t v) -> absl::StatusOr<float> { return v * 2.0f; });\n \n@@ -244,8 +327,7 @@ TEST(PjRtFutureTest, TryMapCopyableFutureForwardError) {\n }\n \n TEST(PjRtFutureTest, TryMapCopyableFutureCreateError) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n   PjRtFuture<float> mapped =\n       future.TryMap([](int32_t v) -> absl::StatusOr<float> {\n         return absl::InternalError(\"test\");\n@@ -257,9 +339,8 @@ TEST(PjRtFutureTest, TryMapCopyableFutureCreateError) {\n }\n \n TEST(PjRtFutureTest, TryMapMoveOnlyFuture) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n   PjRtFuture<std::unique_ptr<float>> mapped = std::move(future).TryMap(\n       [](std::unique_ptr<int32_t> v) -> absl::StatusOr<std::unique_ptr<float>> {\n         return std::make_unique<float>(*v * 2.0f);\n@@ -274,9 +355,8 @@ TEST(PjRtFutureTest, TryMapMoveOnlyFuture) {\n }\n \n TEST(PjRtFutureTest, TryMapMoveOnlyFutureForwardError) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n   PjRtFuture<std::unique_ptr<float>> mapped = std::move(future).TryMap(\n       [](std::unique_ptr<int32_t> v) -> absl::StatusOr<std::unique_ptr<float>> {\n         return std::make_unique<float>(*v * 2.0f);\n@@ -291,9 +371,8 @@ TEST(PjRtFutureTest, TryMapMoveOnlyFutureForwardError) {\n }\n \n TEST(PjRtFutureTest, TryMapMoveOnlyFutureCreateError) {\n-  auto promise = PjRtFuture<std::unique_ptr<int32_t>>::CreatePromise();\n+  auto [promise, future] = PjRtFuture<std::unique_ptr<int32_t>>::MakePromise();\n \n-  PjRtFuture<std::unique_ptr<int32_t>> future(promise);\n   PjRtFuture<std::unique_ptr<float>> mapped = std::move(future).TryMap(\n       [](std::unique_ptr<int32_t> v) -> absl::StatusOr<std::unique_ptr<float>> {\n         return absl::InternalError(\"test\");\n@@ -307,10 +386,35 @@ TEST(PjRtFutureTest, TryMapMoveOnlyFutureCreateError) {\n   EXPECT_EQ(mapped.Await().status(), absl::InternalError(\"test\"));\n }\n \n-TEST(PjRtFutureTest, StatelessError) {\n+TEST(PjRtFutureTest, TryMapUnusedResult) {\n+  auto promise = PjRtFuture<int>::CreatePromise();\n+  PjRtFuture<int> future(promise);\n+\n+  bool called = false;\n+  future.TryMap([&](int) -> absl::StatusOr<int> {\n+    called = true;\n+    return 2;\n+  });\n+  promise.Set(1);\n+  EXPECT_FALSE(called);\n+}\n+\n+TEST(PjRtFutureTest, TryMapStatusUnusedResult) {\n   auto promise = PjRtFuture<>::CreatePromise();\n   PjRtFuture<> future(promise);\n \n+  bool called = false;\n+  future.TryMap([&]() -> absl::StatusOr<int> {\n+    called = true;\n+    return 2;\n+  });\n+  promise.Set();\n+  EXPECT_FALSE(called);\n+}\n+\n+TEST(PjRtFutureTest, StatelessError) {\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n+\n   EXPECT_FALSE(future.IsReady());\n   promise.Set(absl::InternalError(\"test\"));\n   EXPECT_TRUE(future.IsReady());\n@@ -342,8 +446,7 @@ TEST(PjRtFutureTest, StatelessImmediate) {\n }\n \n TEST(PjRtFutureTest, MapStatelessFuture) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped = future.Map([]() { return 42.0f; });\n \n   EXPECT_FALSE(future.IsReady());\n@@ -358,8 +461,7 @@ TEST(PjRtFutureTest, MapStatelessFuture) {\n }\n \n TEST(PjRtFutureTest, MapStatelessFutureError) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped = future.Map([]() { return 42.0f; });\n \n   EXPECT_FALSE(future.IsReady());\n@@ -374,8 +476,7 @@ TEST(PjRtFutureTest, MapStatelessFutureError) {\n }\n \n TEST(PjRtFutureTest, TryMapStatelessFuture) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped =\n       future.TryMap([]() -> absl::StatusOr<float> { return 42.0f; });\n \n@@ -391,8 +492,7 @@ TEST(PjRtFutureTest, TryMapStatelessFuture) {\n }\n \n TEST(PjRtFutureTest, TryMapStatelessFutureForwardError) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped =\n       future.TryMap([]() -> absl::StatusOr<float> { return 42.0f; });\n \n@@ -402,8 +502,7 @@ TEST(PjRtFutureTest, TryMapStatelessFutureForwardError) {\n }\n \n TEST(PjRtFutureTest, TryMapStatelessFutureCreateError) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped = future.TryMap(\n       []() -> absl::StatusOr<float> { return absl::InternalError(\"test\"); });\n \n@@ -413,8 +512,7 @@ TEST(PjRtFutureTest, TryMapStatelessFutureCreateError) {\n }\n \n TEST(PjRtFutureTest, MapToStatelessFuture) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n   PjRtFuture<float> mapped = future.MapTo(42.0f);\n \n   EXPECT_FALSE(future.IsReady());\n@@ -429,8 +527,7 @@ TEST(PjRtFutureTest, MapToStatelessFuture) {\n }\n \n TEST(PjRtFutureTest, StatefulFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n \n   EXPECT_FALSE(future.IsReady());\n   promise.Set(42);\n@@ -440,8 +537,7 @@ TEST(PjRtFutureTest, StatefulFuture) {\n }\n \n TEST(PjRtFutureTest, StatusFuture) {\n-  auto promise = PjRtFuture<>::CreatePromise();\n-  PjRtFuture<> future(promise);\n+  auto [promise, future] = PjRtFuture<>::MakePromise();\n \n   EXPECT_FALSE(future.IsReady());\n   promise.Set(absl::OkStatus());\n@@ -452,8 +548,7 @@ TEST(PjRtFutureTest, StatusFuture) {\n }\n \n TEST(PjRtFutureTest, StatusOrFuture) {\n-  auto promise = PjRtFuture<int32_t>::CreatePromise();\n-  PjRtFuture<int32_t> future(promise);\n+  auto [promise, future] = PjRtFuture<int32_t>::MakePromise();\n \n   EXPECT_FALSE(future.IsReady());\n   promise.Set(42);\n@@ -467,12 +562,11 @@ TEST(PjRtFutureTest, JoinFutures) {\n   EXPECT_TRUE(empty_join.IsReady());\n   EXPECT_EQ(empty_join.Await(), absl::OkStatus());\n \n-  auto promise0 = PjRtFuture<>::CreatePromise();\n-  auto promise1 = PjRtFuture<>::CreatePromise();\n+  auto [promise0, future0] = PjRtFuture<>::MakePromise();\n+  auto [promise1, future1] = PjRtFuture<>::MakePromise();\n \n-  std::vector<PjRtFuture<>> futures0 = {PjRtFuture<>(promise0)};\n-  std::vector<PjRtFuture<>> futures1 = {PjRtFuture<>(promise0),\n-                                        PjRtFuture<>(promise1)};\n+  std::vector<PjRtFuture<>> futures0 = {future0};\n+  std::vector<PjRtFuture<>> futures1 = {future0, future1};\n \n   auto join_one = JoinFutures(futures0);\n   EXPECT_FALSE(join_one.IsReady());\n@@ -495,12 +589,11 @@ TEST(PjRtFutureTest, JoinErrors) {\n   EXPECT_TRUE(empty_join.IsReady());\n   EXPECT_EQ(empty_join.Await(), absl::OkStatus());\n \n-  auto promise0 = PjRtFuture<>::CreatePromise();\n-  auto promise1 = PjRtFuture<>::CreatePromise();\n+  auto [promise0, future0] = PjRtFuture<>::MakePromise();\n+  auto [promise1, future1] = PjRtFuture<>::MakePromise();\n \n-  std::vector<PjRtFuture<>> futures0 = {PjRtFuture<>(promise0)};\n-  std::vector<PjRtFuture<>> futures1 = {PjRtFuture<>(promise0),\n-                                        PjRtFuture<>(promise1)};\n+  std::vector<PjRtFuture<>> futures0 = {future0};\n+  std::vector<PjRtFuture<>> futures1 = {future0, future1};\n \n   auto join_one = JoinFutures(futures0);\n   EXPECT_FALSE(join_one.IsReady());"
        },
        {
            "sha": "0b86952bbfb7c416fea347547ca9c93a658207c9",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -2562,12 +2562,7 @@ absl::Status PjRtStreamExecutorLoadedExecutable::SetUpDonation(\n }\n \n absl::string_view PjRtStreamExecutorLoadedExecutable::name() const {\n-  Executable* executable = executables_[0]->executable();\n-  if (executable->has_module()) {\n-    return executable->module().name();\n-  } else {\n-    return \"<unknown executable>\";\n-  }\n+  return executables_[0]->executable()->name();\n }\n \n absl::Span<int const>\n@@ -3091,8 +3086,8 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n           << \", run_id=\" << run_options.run_id().ToInt();\n \n   if (VLOG_IS_ON(2)) {\n-    auto executable_name =\n-        executables_[executable_idx]->executable()->module().name();\n+    absl::string_view executable_name =\n+        executables_[executable_idx]->executable()->name();\n     absl::Status host_callback_status = run_options.stream()->DoHostCallback(\n         [executable_name, launch_id(run_options.run_id().ToInt()), device]() {\n           VLOG(2) << \"Start device execution for \" << executable_name\n@@ -3111,8 +3106,8 @@ PjRtStreamExecutorLoadedExecutable::EnqueueExecution(\n                         std::move(execution_inputs), run_options);\n \n   if (VLOG_IS_ON(2)) {\n-    auto executable_name =\n-        executables_[executable_idx]->executable()->module().name();\n+    absl::string_view executable_name =\n+        executables_[executable_idx]->executable()->name();\n     absl::Status host_callback_status = run_options.stream()->DoHostCallback(\n         [executable_name, launch_id(run_options.run_id().ToInt()), device]() {\n           VLOG(2) << \"Finish device execution for \" << executable_name"
        },
        {
            "sha": "353c839aefdad95109472f9b4928761c7b7e03a2",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/BUILD",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -10,11 +10,10 @@ package(\n \n cc_library(\n     name = \"xla_cpu_pjrt_client\",\n-    srcs = [\n-        \"xla_cpu_pjrt_client.cc\",\n-    ],\n+    srcs = [\"xla_cpu_pjrt_client.cc\"],\n     hdrs = [\"xla_cpu_pjrt_client.h\"],\n     deps = [\n+        \":cpu_client_options\",\n         \"//xla/pjrt:pjrt_client\",\n         \"//xla/pjrt/cpu:cpu_client\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -34,13 +33,19 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"cpu_memory\",\n+    hdrs = [\"cpu_memory.h\"],\n+)\n+\n cc_library(\n     name = \"cpu_client_options\",\n-    srcs = [],\n     hdrs = [\"cpu_client_options.h\"],\n     deps = [\n+        \":cpu_memory\",\n         \"//xla/backends/cpu/collectives:cpu_collectives\",\n         \"//xla/service:hlo_module_config\",\n+        \"@com_google_absl//absl/status:statusor\",\n     ],\n )\n \n@@ -60,7 +65,6 @@ cc_library(\n \n cc_library(\n     name = \"cpu_execute_options\",\n-    srcs = [],\n     hdrs = [\"cpu_execute_options.h\"],\n     deps = [\n         \"//xla/backends/cpu/collectives:cpu_collectives\","
        },
        {
            "sha": "d9e71ff37fca3951bc857fa736c8ddea275a9642",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/cpu_client_options.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_client_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_client_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_client_options.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,11 +16,14 @@ limitations under the License.\n #ifndef XLA_PJRT_PLUGIN_XLA_CPU_CPU_CLIENT_OPTIONS_H_\n #define XLA_PJRT_PLUGIN_XLA_CPU_CPU_CLIENT_OPTIONS_H_\n \n+#include <cstddef>\n #include <functional>\n #include <memory>\n #include <optional>\n \n+#include \"absl/status/statusor.h\"\n #include \"xla/backends/cpu/collectives/cpu_collectives.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_memory.h\"\n #include \"xla/service/hlo_module_config.h\"\n \n namespace xla {\n@@ -50,6 +53,13 @@ struct CpuClientOptions {\n   // If defined this function will be called on the HloModuleConfig before\n   // compilation, and allows users to set custom flags.\n   std::function<void(HloModuleConfig&)> customize_hlo_module_config;\n+\n+  // If defined this function will be called by PjRtClient to allocate memory\n+  // for constructed PjRtBuffers and a temporary allocation passed to XLA:CPU\n+  // executable.\n+  std::function<absl::StatusOr<std::unique_ptr<CpuMemory>>(size_t size_bytes,\n+                                                           size_t alignment)>\n+      allocator;\n };\n \n }  // namespace xla"
        },
        {
            "sha": "325c22f156d6b93b93cc99c7ccbbbadc43c1813b",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/cpu_memory.h",
            "status": "added",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_memory.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_memory.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_memory.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,35 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_PJRT_PLUGIN_XLA_CPU_CPU_MEMORY_H_\n+#define XLA_PJRT_PLUGIN_XLA_CPU_CPU_MEMORY_H_\n+\n+#include <cstddef>\n+\n+namespace xla {\n+\n+// A region of cpu memory that can be used by XLA:CPU PjRt client as a storage\n+// for PjRt buffers and also as a temporary allocation for XLA:CPU program.\n+class CpuMemory {\n+ public:\n+  virtual ~CpuMemory() = default;\n+\n+  virtual void* base() const = 0;\n+  virtual size_t size_bytes() const = 0;\n+};\n+\n+}  // namespace xla\n+\n+#endif  // XLA_PJRT_PLUGIN_XLA_CPU_CPU_MEMORY_H_"
        },
        {
            "sha": "46bba270f027494472d9971032a22718f2186bfd",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/xla_cpu_pjrt_client.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/pjrt/cpu/cpu_client.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n \n namespace xla {\n "
        },
        {
            "sha": "17a2ce2fa29a6d16bb627f4440e13975ab215e23",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/xla_cpu_pjrt_client.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fxla_cpu_pjrt_client.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -19,8 +19,8 @@ limitations under the License.\n #include <memory>\n \n #include \"absl/status/statusor.h\"\n-#include \"xla/pjrt/cpu/cpu_client.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/plugin/xla_cpu/cpu_client_options.h\"\n \n namespace xla {\n "
        },
        {
            "sha": "97443a1b0b99751fae33716a813633b25efb7c31",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -540,6 +540,7 @@ xla_cc_test(\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:cord\",\n         \"@com_google_absl//absl/strings:string_view\","
        },
        {
            "sha": "7afc72615831c4846a0c708bfc9e98323b3e4dc9",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/basic_string_array_test.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 19,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fbasic_string_array_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fbasic_string_array_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fbasic_string_array_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/algorithm/container.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"absl/strings/cord.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n@@ -58,7 +59,6 @@ namespace {\n using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n using ::testing::HasSubstr;\n-using ::tsl::testing::StatusIs;\n \n // ////////////////////////////////////////////////////////////////////////////\n //\n@@ -109,8 +109,8 @@ absl::StatusOr<std::pair<tsl::RCReference<BasicStringArray>,\n CreateNonReadyTestArray(\n     Client* client, Device* const device,\n     BasicStringArray::OnDoneWithBuffer on_done_with_buffer) {\n-  auto buffers_promise = Future<BasicStringArray::Buffers>::CreatePromise();\n-  auto buffers_future = Future<BasicStringArray::Buffers>(buffers_promise);\n+  auto [buffers_promise, buffers_future] =\n+      Future<BasicStringArray::Buffers>::MakePromise();\n   Shape shape({1});\n   ShardingRef sharding = SingleDeviceSharding::Create(device, MemoryKind());\n \n@@ -158,19 +158,20 @@ TEST(BasicStringArrayTest, Destruction) {\n   BasicStringArray::OnDoneWithBuffer on_done_with_buffer =\n       [&on_done_with_buffer_called]() { on_done_with_buffer_called.Notify(); };\n \n-  auto array_creation_status_promise = PjRtFuture<>::CreatePromise();\n+  auto [array_creation_promise, array_creation_future] =\n+      PjRtFuture<>::MakePromise();\n \n-  tsl::Env::Default()->SchedClosure(([&]() {\n-    auto array = CreateTestArray(client.get(),\n-                                 Future<BasicStringArray::Buffers>(buffers),\n-                                 std::move(on_done_with_buffer));\n-\n-    array_creation_status_promise.Set(array.status());\n-    // `array` goes out of scope and gets destroyed.\n-  }));\n+  tsl::Env::Default()->SchedClosure(\n+      ([&, promise = std::move(array_creation_promise)]() mutable {\n+        auto array = CreateTestArray(client.get(),\n+                                     Future<BasicStringArray::Buffers>(buffers),\n+                                     std::move(on_done_with_buffer));\n+        promise.Set(array.status());\n+        // `array` goes out of scope and gets destroyed.\n+      }));\n \n   // Make sure that the array has been created successfully.\n-  TF_ASSERT_OK(Future<>(array_creation_status_promise).Await());\n+  TF_ASSERT_OK(array_creation_future.Await());\n \n   // Destruction must release the buffer. That is, the `on_done_with_buffer`\n   // callback must be called.\n@@ -237,8 +238,8 @@ TEST(BasicStringArrayTest, Delete) {\n TEST(GetReadyFutureTest, SuccessCase) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n   // Make a BasicStringArray with a future that is not ready.\n-  auto promise = Future<BasicStringArray::Buffers>::CreatePromise();\n-  auto buffers_future = Future<BasicStringArray::Buffers>(promise);\n+  auto [promise, buffers_future] =\n+      Future<BasicStringArray::Buffers>::MakePromise();\n   TF_ASSERT_OK_AND_ASSIGN(auto array,\n                           CreateTestArray(client.get(), buffers_future,\n                                           /*on_done_with_buffer=*/nullptr));\n@@ -250,15 +251,16 @@ TEST(GetReadyFutureTest, SuccessCase) {\n   // Make the buffers future ready asynchronously.\n   BasicStringArray::Buffers buffers;\n   buffers.push_back({absl::Cord(\"abc\"), absl::Cord(\"def\")});\n-  tsl::Env::Default()->SchedClosure([&]() { promise.Set(buffers); });\n+  tsl::Env::Default()->SchedClosure(\n+      [&, promise = std::move(promise)]() mutable { promise.Set(buffers); });\n   TF_EXPECT_OK(ready_future.Await());\n }\n \n TEST(GetReadyFutureTest, FailureCases) {\n   TF_ASSERT_OK_AND_ASSIGN(auto client, test_util::GetClient());\n   // Make a BasicStringArray with a future that is not ready.\n-  auto promise = Future<BasicStringArray::Buffers>::CreatePromise();\n-  auto buffers_future = Future<BasicStringArray::Buffers>(promise);\n+  auto [promise, buffers_future] =\n+      Future<BasicStringArray::Buffers>::MakePromise();\n   TF_ASSERT_OK_AND_ASSIGN(auto array,\n                           CreateTestArray(client.get(), buffers_future,\n                                           /*on_done_with_buffer=*/nullptr));\n@@ -269,7 +271,9 @@ TEST(GetReadyFutureTest, FailureCases) {\n \n   // Make the buffers future ready with an error asynchronously\n   tsl::Env::Default()->SchedClosure(\n-      [&]() { promise.Set(absl::InternalError(\"injected error\")); });\n+      [&, promise = std::move(promise)]() mutable {\n+        promise.Set(absl::InternalError(\"injected error\"));\n+      });\n \n   EXPECT_THAT(ready_future.Await(),\n               absl_testing::StatusIs(absl::StatusCode::kInternal));"
        },
        {
            "sha": "a61dce6cad519e29c8d163c6f9dc187d11638e2d",
            "filename": "third_party/xla/xla/runtime/execution_graph.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fruntime%2Fexecution_graph.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -285,8 +285,11 @@ std::string ExecutionGraph::ToString() const {\n   };\n \n   std::string out;\n-  absl::StrAppendFormat(&out, \"ExecutionGraph: %d nodes, is_sequential=%v\\n\",\n-                        nodes_defs_.size(), is_sequential_);\n+  absl::StrAppendFormat(&out,\n+                        \"ExecutionGraph: %d nodes, #source_nodes=%d \"\n+                        \"#sink_nodes=%d, is_sequential=%v\\n\",\n+                        nodes_defs_.size(), source_.size(), sink_.size(),\n+                        is_sequential_);\n \n   for (NodeId i = 0; i < nodes_defs_.size(); ++i) {\n     const NodeDef& def = nodes_defs_[i];"
        },
        {
            "sha": "b6c5a7613bdd570d14edc8fb726a3e9e1515ea1f",
            "filename": "third_party/xla/xla/service/call_inliner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -308,7 +308,7 @@ bool CallInliner::IsInlineableCallOp(HloInstruction* instruction) const {\n   if (instruction->GetModule()->config().use_shardy_partitioner() &&\n       (absl::StrContains(instruction->to_apply()->name(), \"shmap_body\") ||\n        absl::StrContains(instruction->to_apply()->name(),\n-                         sdy::kManualComputationBodyFuncName.str()))) {\n+                         sdy::kManualComputationFuncName.str()))) {\n     // TODO(b/436603025). Remove this special handling by marking the\n     // instruction as uninlineable with the frontend attribute.\n     //\n@@ -318,7 +318,7 @@ bool CallInliner::IsInlineableCallOp(HloInstruction* instruction) const {\n     // - shmap_body: We do not want to inline the bodies of JAX shard maps to\n     //   import them into an `sdy.ManualComputationOp`. This is for the MHLO\n     //   round-trip pipeline\n-    // - kManualComputationBodyFuncName: Same as shmap_body except for the SDY\n+    // - kManualComputationFuncName: Same as shmap_body except for the SDY\n     //   round-trip pipeline.\n     return false;\n   }"
        },
        {
            "sha": "2a0490b70291630ee24c8b344ecfc800a0cfd8d2",
            "filename": "third_party/xla/xla/service/copy_insertion.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1297,8 +1297,7 @@ absl::Status CopyInsertion::AddSpecialCaseCopies(\n       HloPosition position = value2->defining_position();\n       for (const HloUse& use : value->GetUses()) {\n         // We already handle the copy of pin custom-call operands and shouldn't\n-        // add\n-        // another copy here.\n+        // add another copy here.\n         if (!use.instruction->IsCustomCall(kPinCustomCallTarget) &&\n             use.instruction == position.instruction) {\n           VLOG(3) << \"Same instruction: \" << position.instruction->ToString();"
        },
        {
            "sha": "884f22eca086562b7f8380181b6ae9d08e129b17",
            "filename": "third_party/xla/xla/service/copy_insertion_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcopy_insertion_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -103,7 +103,7 @@ class CopyInsertionTest : public HloHardwareIndependentTestBase {\n   }\n \n   const Shape scalar_shape_ = ShapeUtil::MakeShape(F32, {});\n-  const AliasInfo alias_info_;\n+  AliasInfo alias_info_;\n };\n \n TEST_F(CopyInsertionTest, SingleParameter) {"
        },
        {
            "sha": "d772df146e08c49bcba405cd491b42957cd26ecc",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -338,6 +338,7 @@ cc_library(\n         \"//xla/service/llvm_ir:llvm_command_line_options\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/service/spmd:stateful_rng_spmd_partitioner\",\n+        \"//xla/service/spmd/shardy:constants\",\n         \"//xla/service/spmd/shardy:shardy_xla_pass\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -998,6 +999,7 @@ cc_library(\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/service:pattern_matcher\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n@@ -2074,14 +2076,17 @@ xla_test(\n         \"//xla/backends/cpu/codegen:fusion_compiler\",\n         \"//xla/codegen:llvm_kernel_definition\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:threadpool_interface\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n         \"@llvm-project//llvm:JITLink\",\n+        \"@llvm-project//llvm:ir_headers\",\n         \"@llvm-project//mlir:IR\",\n     ],\n )"
        },
        {
            "sha": "a38ddd6408e83c5950d6b57de52abda4f8d5ec99",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -43,6 +43,7 @@ limitations under the License.\n #include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/match.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/str_join.h\"\n@@ -217,6 +218,7 @@ limitations under the License.\n #include \"xla/service/sharding_propagation.h\"\n #include \"xla/service/sharding_remover.h\"\n #include \"xla/service/slow_operation_alarm.h\"\n+#include \"xla/service/spmd/shardy/constants.h\"\n #include \"xla/service/spmd/shardy/shardy_xla_pass.h\"\n #include \"xla/service/spmd/stateful_rng_spmd_partitioner.h\"\n #include \"xla/service/topk_rewriter.h\"\n@@ -560,6 +562,16 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n     }\n     spmd_pipeline.AddPass<spmd::StatefulRngSpmdPartitioner>(\n         num_partitions, module->config().replica_count());\n+    spmd_pipeline.AddPass<xla::CallInliner>(\n+        /*single_call_site=*/false,\n+        /*update_domain=*/false,\n+        /*composites_to_preserve=*/absl::flat_hash_set<std::string>{},\n+        /*uniquify_channel_ids=*/false,\n+        /*should_inline=*/\n+        [](const xla::CallGraph& call_graph, xla::HloInstruction* instruction) {\n+          return absl::StrContains(instruction->to_apply()->name(),\n+                                   sdy::kInlineableManualComputationFuncName);\n+        });\n     TF_RETURN_IF_ERROR(spmd_pipeline.Run(module).status());\n   } else {\n     HloPassPipeline sharding_removal_pipeline(\"sharding-removal\");\n@@ -620,6 +632,10 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n                                 target_machine_features)\n                 .value_or(false);\n   };\n+\n+  // xla::cpu::GetDotImplementationStrategy (used by call_library_for_dot)\n+  // relies on the canonical form of dots.\n+  pipeline.AddPass<DotDecomposer>();\n   pipeline.AddPass<OperandUpcaster>(upcaster_filter);\n \n   // Expand random number generation."
        },
        {
            "sha": "34a365187a0096c811be79812bccaf64254ff0af",
            "filename": "third_party/xla/xla/service/cpu/cpu_runtime.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -110,11 +110,6 @@ extern const char* const kEigenConv3DF16SymbolName =\n     \"__xla_cpu_runtime_EigenConv3DF16\";\n extern const char* const kEigenConv3DF32SymbolName =\n     \"__xla_cpu_runtime_EigenConv3DF32\";\n-extern const char* const kLegacyDuccFftSymbolName =\n-    \"__xla_cpu_runtime_LegacyDuccFft\";\n-extern const char* const kDuccFftSymbolName = \"__xla_cpu_runtime_DuccFft\";\n-extern const char* const kDuccSingleThreadedFftSymbolName =\n-    \"__xla_cpu_runtime_DuccSingleThreadedFft\";\n extern const char* const kEigenSingleThreadedMatMulF8E4M3FNSymbolName =\n     \"__xla_cpu_runtime_EigenSingleThreadedMatMulF8E4M3FN\";\n extern const char* const kEigenSingleThreadedMatMulF8E5M2SymbolName ="
        },
        {
            "sha": "8b9f5f3de90deed7fbec7022a24fe96c957c349f",
            "filename": "third_party/xla/xla/service/cpu/cpu_runtime.h",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -56,9 +56,6 @@ extern const char* const kEigenConv2DF16SymbolName;\n extern const char* const kEigenConv2DF32SymbolName;\n extern const char* const kEigenConv3DF16SymbolName;\n extern const char* const kEigenConv3DF32SymbolName;\n-extern const char* const kLegacyDuccFftSymbolName;\n-extern const char* const kDuccFftSymbolName;\n-extern const char* const kDuccSingleThreadedFftSymbolName;\n extern const char* const kEigenSingleThreadedMatMulF16SymbolName;\n extern const char* const kEigenSingleThreadedMatMulF32SymbolName;\n extern const char* const kEigenSingleThreadedMatMulF64SymbolName;"
        },
        {
            "sha": "c3d0a307f119d6d83fa07fe4a9f47b1039d5441a",
            "filename": "third_party/xla/xla/service/cpu/ir_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 49,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fir_emitter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -992,55 +992,7 @@ absl::Status IrEmitter::HandleConvolution(HloInstruction* convolution) {\n }\n \n absl::Status IrEmitter::HandleFft(HloInstruction* fft) {\n-  auto operand = fft->operand(0);\n-  TF_RETURN_IF_ERROR(ElementTypesSameAndSupported(\n-      /*instruction=*/*fft, /*operands=*/{operand},\n-      /*supported_types=*/{F32, F64, C64, C128}));\n-  TF_RET_CHECK(LayoutUtil::IsMonotonicWithDim0Major(operand->shape().layout()));\n-  TF_RET_CHECK(LayoutUtil::IsMonotonicWithDim0Major(fft->shape().layout()));\n-  VLOG(3) << \"operand=\" << ShapeUtil::HumanStringWithLayout(operand->shape());\n-  VLOG(3) << \"fft=\" << ShapeUtil::HumanStringWithLayout(fft->shape());\n-\n-  llvm::Value* operand_address = GetEmittedValueFor(operand);\n-  TF_RETURN_IF_ERROR(EmitTargetAddressForOp(fft));\n-\n-  const std::vector<int64_t>& fft_length = fft->fft_length();\n-  const int fft_rank = fft_length.size();\n-\n-  // Flatten operand batches.\n-  absl::InlinedVector<int64_t, 4> operand_shape_flat(fft_rank + 1);\n-  int64_t input_batch = 1;\n-  int64_t input_batch_length = fft->shape().dimensions().size() - fft_rank;\n-  for (int i = 0; i < input_batch_length; i++) {\n-    input_batch *= operand->shape().dimensions(i);\n-  }\n-  operand_shape_flat[0] = input_batch;\n-  for (int i = 0; i < fft_rank; ++i) {\n-    operand_shape_flat[i + 1] =\n-        operand->shape().dimensions(i + input_batch_length);\n-  }\n-\n-  // Args have been computed, make the call.\n-  bool multi_threaded_eigen =\n-      hlo_module_config_.debug_options().xla_cpu_multi_thread_eigen();\n-  const char* fn_name = multi_threaded_eigen\n-                            ? runtime::kLegacyDuccFftSymbolName\n-                            : runtime::kDuccSingleThreadedFftSymbolName;\n-  auto* fft_lengths =\n-      EmitGlobalForLiteral(LiteralUtil::CreateR1<int64_t>(fft_length));\n-  auto* input_shape =\n-      EmitGlobalForLiteral(LiteralUtil::CreateR1<int64_t>(operand_shape_flat));\n-  EmitCallToFunc(fn_name,\n-                 {GetExecutableRunOptionsArgument(), GetEmittedValueFor(fft),\n-                  operand_address, b()->getInt32(fft->fft_type()),\n-                  b()->getInt32(operand->shape().element_type() == F64 ||\n-                                operand->shape().element_type() == C128),\n-                  b()->getInt32(fft_rank), input_shape, fft_lengths},\n-                 b()->getVoidTy(), /*does_not_throw=*/true,\n-                 /*only_accesses_arg_memory=*/false,\n-                 /*only_accesses_inaccessible_mem_or_arg_mem=*/true);\n-\n-  return absl::OkStatus();\n+  return Unimplemented(\"Fft is not implemented in the legacy emitter\");\n }\n \n absl::Status IrEmitter::HandleAllReduceSingleReplica(HloInstruction* crs) {"
        },
        {
            "sha": "9abba57fce23c2ec4b303ff45f50e19f93f79888",
            "filename": "third_party/xla/xla/service/cpu/parallel_fusion_emitter_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 8,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fparallel_fusion_emitter_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,21 +17,26 @@ limitations under the License.\n \n #include <cstdint>\n #include <functional>\n+#include <string>\n #include <utility>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status_matchers.h\"\n #include \"absl/strings/string_view.h\"\n #include \"llvm/ExecutionEngine/Orc/ThreadSafeModule.h\"\n+#include \"llvm/IR/FMF.h\"\n+#include \"llvm/IR/Module.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"xla/backends/cpu/codegen/fusion_compiler.h\"\n #include \"xla/codegen/llvm_kernel_definition.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n@@ -61,6 +66,7 @@ FusionCompiler::Options CreateDefaultOptions() {\n   options.vector_width = 128;\n   options.verification_level = 1;\n   options.fast_min_max = false;\n+  options.fast_math_flags = llvm::FastMathFlags::getFast();\n \n   return options;\n }\n@@ -92,14 +98,14 @@ TEST_F(ParallelFusionEmitterTest, HappyPathSingleFusion) {\n   constexpr absl::string_view expected_name = \"root_fusion\";\n   constexpr absl::string_view trivial_fusion = R\"(\n     add1 {\n-      p = s32[] parameter(0)\n-      c = s32[] constant(1)\n-      ROOT a = s32[] add(p, c)\n+      p = f32[] parameter(0)\n+      c = f32[] constant(1)\n+      ROOT a = f32[] add(p, c)\n     }\n \n     ENTRY main {\n-      p = s32[] parameter(0)\n-      ROOT root_fusion = s32[] fusion(p), kind=kLoop, calls=add1\n+      p = f32[] parameter(0)\n+      ROOT root_fusion = f32[] fusion(p), kind=kLoop, calls=add1\n     })\";\n \n   TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n@@ -122,10 +128,14 @@ TEST_F(ParallelFusionEmitterTest, HappyPathSingleFusion) {\n   auto [spec, source] = std::move(lowered_kernel).ReleaseStorage();\n   EXPECT_EQ(spec.name(), expected_name);\n \n-  llvm::orc::ThreadSafeModule llvm_module =\n+  llvm::orc::ThreadSafeModule thread_safe_llvm_module =\n       std::move(source).thread_safe_module();\n-  EXPECT_NE(llvm_module.getModuleUnlocked()->getFunction(expected_name),\n-            nullptr);\n+  llvm::Module* llvm_module = thread_safe_llvm_module.getModuleUnlocked();\n+  EXPECT_NE(llvm_module->getFunction(expected_name), nullptr);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      bool passed,\n+      RunFileCheck(llvm_ir::DumpToString(*llvm_module), \"CHECK: fadd fast\"));\n+  EXPECT_TRUE(passed);\n }\n \n TEST_F(ParallelFusionEmitterTest, FusionsAreSorted) {"
        },
        {
            "sha": "d032db343c362c4b867580f407cd1ccf3e73be41",
            "filename": "third_party/xla/xla/service/cpu/small_while_loop_hoisting_pass.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -42,14 +42,12 @@ static bool InstructionIsUnavailable(const HloInstruction* instr) {\n   // The following instructions are not currently supported by the call thunk\n   // emitter due to how the legacy & thunk emitters interact; specifically,\n   // how the run options are passed.\n-  // Convolution & Dot may or may not call into Eigen depending on the shape,\n-  // Eigen requires a thread pool to be passed so we conservatively exclude it.\n-  // (This could be relaxed with a little work to make it optional if required).\n   switch (instr->opcode()) {\n     case HloOpcode::kCustomCall:\n     case HloOpcode::kInfeed:\n     case HloOpcode::kOutfeed:\n     case HloOpcode::kScatter:\n+    case HloOpcode::kFft:\n       return true;\n     default:\n       return IsCollective(instr);"
        },
        {
            "sha": "3df9b4031c8ca28a3a6d0acbeecac2a841b68ed1",
            "filename": "third_party/xla/xla/service/cpu/small_while_loop_hoisting_pass_test.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 0,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fsmall_while_loop_hoisting_pass_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -157,5 +157,42 @@ TEST_F(SmallWhileLoopHoistingPassTest, NoInOutFeedWhileLoopHoisting) {\n   EXPECT_FALSE(changed);\n }\n \n+TEST_F(SmallWhileLoopHoistingPassTest, NoFftWhileLoopHoisting) {\n+  constexpr absl::string_view hlo_string = R\"(\n+    HloModule fft_module\n+\n+    %body_comp (arg_tuple.3: (s32[], c64[30])) -> (s32[], c64[30]) {\n+      %arg_tuple.3 = (s32[], c64[30]{0}) parameter(0)\n+      %get-tuple-element.4 = s32[] get-tuple-element(%arg_tuple.3), index=0\n+      %constant.6 = s32[] constant(1)\n+      %add.14 = s32[] add(%get-tuple-element.4, %constant.6)\n+      %get-tuple-element.5 = c64[30]{0} get-tuple-element(%arg_tuple.3), index=1\n+      %fft.10 = c64[30]{0} fft(%get-tuple-element.5), fft_type=FFT, fft_length={30}\n+      ROOT %tuple.15 = (s32[], c64[30]{0}) tuple(%add.14, %get-tuple-element.5)\n+    }\n+\n+    %condition_comp (arg_tuple.17: (s32[], c64[30])) -> pred[] {\n+      %arg_tuple.17 = (s32[], c64[30]{0}) parameter(0)\n+      %get-tuple-element.18 = s32[] get-tuple-element(%arg_tuple.17), index=0\n+      %constant.20 = s32[] constant(10)\n+      ROOT %lt.21 = pred[] compare(%get-tuple-element.18, %constant.20), direction=LT\n+    }\n+\n+    ENTRY %main.27 (args_0_.1: c64[30]) -> c64[30] {\n+      %constant.2 = s32[] constant(0)\n+      %args_0_.1 = c64[30]{0} parameter(0)\n+      %while.23 = (s32[], c64[30]{0}) tuple(%constant.2, %args_0_.1)\n+      %while.24 = (s32[], c64[30]{0}) while(%while.23), condition=%condition_comp, body=%body_comp\n+      %while.25 = s32[] get-tuple-element(%while.24), index=0\n+      ROOT %while.26 = c64[30]{0} get-tuple-element(%while.24), index=1\n+    }\n+    )\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> m,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunSmallWhileLoopHoistingPass(m.get()));\n+  EXPECT_FALSE(changed);\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "7eb7a0e441e84942eff2085e3b863a03bbf47bc5",
            "filename": "third_party/xla/xla/service/cpu/tests/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -183,8 +183,15 @@ xla_cc_test(\n     srcs = [\"tree_reduction_rewriter_test.cc\"],\n     deps = [\n         \":cpu_codegen_test_main\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:filecheck\",\n+        \"//xla/hlo/transforms/simplifiers:tree_reduction_rewriter\",\n         \"//xla/service/cpu:cpu_compiler\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n     ],\n )\n "
        },
        {
            "sha": "3f62aa6ac503ed0db0589169bbc4a23f330ff5ff",
            "filename": "third_party/xla/xla/service/cpu/tests/tree_reduction_rewriter_test.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 9,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Ftree_reduction_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Ftree_reduction_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Ftree_reduction_rewriter_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -13,15 +13,39 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include \"xla/hlo/transforms/simplifiers/tree_reduction_rewriter.h\"\n+\n+#include <memory>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/service/cpu/tests/cpu_codegen_test.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n \n namespace xla {\n namespace cpu {\n \n namespace {\n \n-class TreeReductionRewriterTest : public CpuCodegenTest {};\n+class TreeReductionRewriterTest : public CpuCodegenTest {\n+ public:\n+  void MatchTreeReducedHlo(absl::string_view hlo, absl::string_view pattern) {\n+    TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> optimized_module,\n+                            ParseAndReturnVerifiedModule(hlo));\n+\n+    TreeReductionRewriter tree_reduction_rewriter;\n+    TF_ASSERT_OK(tree_reduction_rewriter.Run(optimized_module.get()));\n+\n+    absl::StatusOr<bool> filecheck_result =\n+        RunFileCheck(optimized_module->ToString(), pattern);\n+    TF_ASSERT_OK(filecheck_result.status());\n+    EXPECT_TRUE(filecheck_result.value());\n+  }\n+};\n \n TEST_F(TreeReductionRewriterTest, SimpleRewrite) {\n   const char* hlo_text = R\"(\n@@ -40,8 +64,8 @@ ENTRY main {\n }\n   )\";\n \n-  MatchOptimizedHlo(hlo_text,\n-                    R\"(\n+  MatchTreeReducedHlo(hlo_text,\n+                      R\"(\n ; CHECK-LABEL: ENTRY %main (input: f32[1000]) -> f32[] {\n ; CHECK-NEXT:    [[INSTR_0:%[^ ]+]] = f32[1000]{0} parameter(0)\n ; CHECK-NEXT:    [[INSTR_1:%[^ ]+]] = f32[] constant(0)\n@@ -67,8 +91,8 @@ ENTRY main {\n }\n   )\";\n \n-  MatchOptimizedHlo(hlo_text,\n-                    R\"(\n+  MatchTreeReducedHlo(hlo_text,\n+                      R\"(\n ; CHECK:    [[INSTR_0:%[^ ]+]] = f32[4,4]{1,0} reduce-window([[INSTR_1:%[^ ]+]], [[INSTR_2:%[^ ]+]]), window={size=32x32 stride=32x32 pad=14_14x14_14}, to_apply=[[INSTR_3:%[^ ]+]]\n ; CHECK-NEXT: ROOT [[INSTR_4:%[^ ]+]] = f32[] reduce([[INSTR_0]], [[INSTR_2]]), dimensions={0,1}, to_apply=[[INSTR_3]]\n       )\");\n@@ -91,8 +115,8 @@ ENTRY main {\n }\n   )\";\n \n-  MatchOptimizedHlo(hlo_text,\n-                    R\"(\n+  MatchTreeReducedHlo(hlo_text,\n+                      R\"(\n ; CHECK:    [[INSTR_0:%[^ ]+]] = f32[32,1]{1,0} reduce-window([[INSTR_1:%[^ ]+]], [[INSTR_2:%[^ ]+]]), window={size=32x31 stride=32x31 pad=12_12x0_0}, to_apply=[[INSTR_3:%[^ ]+]]\n ; CHECK-NEXT: ROOT [[INSTR_4:%[^ ]+]] = f32[] reduce([[INSTR_0]], [[INSTR_2]]), dimensions={0,1}, to_apply=[[INSTR_3]]\n       )\");\n@@ -115,8 +139,8 @@ ENTRY main {\n }\n   )\";\n \n-  MatchOptimizedHlo(hlo_text,\n-                    R\"(\n+  MatchTreeReducedHlo(hlo_text,\n+                      R\"(\n // CHECK: ROOT [[INSTR_0:%[^ ]+]] = f32[] reduce([[INSTR_1:%[^ ]+]], [[INSTR_2:%[^ ]+]]), dimensions={0,1}, to_apply=[[INSTR_3:%[^ ]+]]\n       )\");\n }"
        },
        {
            "sha": "fdcfd7d7b5de445945ad4d5e55bbdc4fb12a946b",
            "filename": "third_party/xla/xla/service/cpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fthunk_emitter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -103,6 +103,7 @@ limitations under the License.\n #include \"xla/service/dump.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/service/hlo_module_config.h\"\n+#include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/service/pattern_matcher.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -258,7 +259,8 @@ static FusionCompiler::Options FusionCompilerOptions(\n   return FusionCompiler::Options{\n       debug_options.xla_cpu_prefer_vector_width(),\n       debug_options.xla_cpu_emitter_verification_level(),\n-      debug_options.xla_cpu_enable_fast_min_max()};\n+      debug_options.xla_cpu_enable_fast_min_max(),\n+      llvm_ir::GetCpuFastMathFlags(config)};\n }\n \n static FusionCompiler FusionCompilerFactory(mlir::MLIRContext* context,"
        },
        {
            "sha": "b5ecc6bc89e0c683f15d7f0af79cae9e6454cba5",
            "filename": "third_party/xla/xla/service/executable.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n@@ -378,6 +379,13 @@ class Executable {\n     return hlo_module_->compute_computation_layout();\n   }\n \n+  virtual absl::string_view name() const {\n+    if (has_module()) {\n+      return module().name();\n+    }\n+    return \"<unknown executable>\";\n+  }\n+\n   // Returns the size of the executable in bytes. Returns -1 if this query is\n   // not supported by the executable.\n   //"
        },
        {
            "sha": "3f1a2edd8b71917184c1eb0dac842a5b2ca95cd2",
            "filename": "third_party/xla/xla/service/gather_expander_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 19,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgather_expander_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgather_expander_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgather_expander_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -282,7 +282,7 @@ HloModule GatherWithBatchDims\n \n ENTRY main {\n   operand = s32[5,2] parameter(0)\n-  indices = s32[5,1] parameter(1)\n+  indices = s64[5,1] parameter(1)\n   ROOT gather = s32[5,1] gather(operand, indices),\n       offset_dims={1},\n       collapsed_slice_dims={},\n@@ -294,33 +294,33 @@ ENTRY main {\n }\n )\";\n   const std::string expected = R\"(\n-  //CHECK: (s32[], s32[5,2], s32[5,1], s32[5,1])) -> (s32[], s32[5,2], s32[5,1], s32[5,1]) {\n-  //CHECK: %[[PARAM:.*]] = (s32[], s32[5,2], s32[5,1], s32[5,1]) parameter(0)\n-  //CHECK: %[[I:.*]] = s32[] get-tuple-element(%[[PARAM]]), index=\n+  //CHECK: (s32[], s32[5,2], s64[5,1], s32[5,1])) -> (s32[], s32[5,2], s64[5,1], s32[5,1]) {\n+  //CHECK: %[[PARAM:.*]] = (s32[], s32[5,2], s64[5,1], s32[5,1]) parameter(0)\n+  //CHECK: %[[I_0:.*]] = s32[] get-tuple-element(%[[PARAM]]), index=0\n   //CHECK: %[[CONSTANT1:.*]] = s32[] constant(1)\n-  //CHECK: %[[I_PLUS_1:.*]] = s32[] add(%[[I]], %[[CONSTANT1]])\n+  //CHECK: %[[I_PLUS_1:.*]] = s32[] add(%[[I_0]], %[[CONSTANT1]])\n   //CHECK: %[[OPERAND:.*]] = s32[5,2] get-tuple-element(%[[PARAM]]), index=1\n-  //CHECK: %[[START_INDICES:.*]] = s32[5,1] get-tuple-element(%[[PARAM]]), index=2\n+  //CHECK: %[[START_INDICES:.*]] = s64[5,1] get-tuple-element(%[[PARAM]]), index=2\n   //CHECK: %[[RESULT:.*]] = s32[5,1] get-tuple-element(%[[PARAM]]), index=3\n-\n-  //CHECK: %[[I_1D_1:.*]] = s32[1] broadcast(%[[I]])\n-  //CHECK: %[[I_1D_2:.*]] = s32[1] broadcast(%[[I]])\n+  //CHECK: %[[CONVERT:.*]] = s64[] convert(%[[I_0]])\n+  //CHECK: %[[I_1D_1:.*]] = s64[1] broadcast(%[[CONVERT]])\n+  //CHECK: %[[I_1D_2:.*]] = s32[1] broadcast(%[[I_0]])\n \n   //CHECK: %[[START_INDICES_INDEX_D1_PAD:.*]] = s32[] constant(0)\n   //CHECK: %[[START_INDICES_INDEX_VECTOR:.*]] = s32[2] pad(%[[I_1D_2]], %[[START_INDICES_INDEX_D1_PAD]]), padding=0_1\n   //CHECK: %[[START_INDICES_INDEX_D0_SLICE:.*]] = s32[1] slice(%[[START_INDICES_INDEX_VECTOR]]), slice={[0:1]}\n   //CHECK: %[[START_INDICES_INDEX_D0:.*]] = s32[] reshape(%[[START_INDICES_INDEX_D0_SLICE]])\n   //CHECK: %[[START_INDICES_INDEX_D1_SLICE:.*]] = s32[1] slice(%[[START_INDICES_INDEX_VECTOR]]), slice={[1:2]}\n   //CHECK: %[[START_INDICES_INDEX_D1:.*]] = s32[] reshape(%[[START_INDICES_INDEX_D1_SLICE]])\n-  //CHECK: %[[INDEX_VECTOR:.*]] = s32[1,1] dynamic-slice(%[[START_INDICES]], %[[START_INDICES_INDEX_D0]], %[[START_INDICES_INDEX_D1]])\n-\n-  //CHECK: %[[OFFSET_RAW:.*]] = s32[1] reshape(%[[INDEX_VECTOR]])\n-  //CHECK: %[[OFFSET:.*]] = s32[1] slice(%[[OFFSET_RAW]])\n-  //CHECK: %[[OPERAND_INDEX:.*]] = s32[2] concatenate(%[[I_1D_1]], %[[OFFSET]])\n-  //CHECK: %[[OPERAND_INDEX_D0_RAW:.*]] = s32[1] slice(%[[OPERAND_INDEX]]), slice={[0:1]}\n-  //CHECK: %[[OPERAND_INDEX_D0:.*]] = s32[] reshape(%[[OPERAND_INDEX_D0_RAW]])\n-  //CHECK: %[[OPERAND_INDEX_D1_RAW:.*]] = s32[1] slice(%[[OPERAND_INDEX]]), slice={[1:2]}\n-  //CHECK: %[[OPERAND_INDEX_D1:.*]] = s32[] reshape(%[[OPERAND_INDEX_D1_RAW]])\n+  //CHECK: %[[INDEX_VECTOR:.*]] = s64[1,1] dynamic-slice(%[[START_INDICES]], %[[START_INDICES_INDEX_D0]], %[[START_INDICES_INDEX_D1]])\n+\n+  //CHECK: %[[OFFSET_RAW:.*]] = s64[1] reshape(%[[INDEX_VECTOR]])\n+  //CHECK: %[[OFFSET:.*]] = s64[1] slice(%[[OFFSET_RAW]])\n+  //CHECK: %[[OPERAND_INDEX:.*]] = s64[2] concatenate(%[[I_1D_1]], %[[OFFSET]])\n+  //CHECK: %[[OPERAND_INDEX_D0_RAW:.*]] = s64[1] slice(%[[OPERAND_INDEX]]), slice={[0:1]}\n+  //CHECK: %[[OPERAND_INDEX_D0:.*]] = s64[] reshape(%[[OPERAND_INDEX_D0_RAW]])\n+  //CHECK: %[[OPERAND_INDEX_D1_RAW:.*]] = s64[1] slice(%[[OPERAND_INDEX]]), slice={[1:2]}\n+  //CHECK: %[[OPERAND_INDEX_D1:.*]] = s64[] reshape(%[[OPERAND_INDEX_D1_RAW]])\n   //CHECK: %[[RESULT_SLICE_RAW0:.*]] = s32[1,1] dynamic-slice(%[[OPERAND]], %[[OPERAND_INDEX_D0]], %[[OPERAND_INDEX_D1]])\n \n   //CHECK: %[[RESULT_SLICE_RAW1:.*]] = s32[1] reshape(%[[RESULT_SLICE_RAW0]])\n@@ -333,7 +333,7 @@ ENTRY main {\n   //CHECK: %[[RESULT_INDEX_D1:.*]] = s32[] reshape(%[[RESULT_INDEX_D1_SLICE]])\n   //CHECK: %[[UPDATED_RESULT:.*]] = s32[5,1] dynamic-update-slice(%[[RESULT]], %[[RESULT_SLICE]], %[[RESULT_INDEX_D0]], %[[RESULT_INDEX_D1]])\n \n-  //CHECK: ROOT %{{.*}} = (s32[], s32[5,2], s32[5,1], s32[5,1]) tuple(%[[I_PLUS_1]], %[[OPERAND]], %[[START_INDICES]], %[[UPDATED_RESULT]])\n+  //CHECK: ROOT %{{.*}} = (s32[], s32[5,2], s64[5,1], s32[5,1]) tuple(%[[I_PLUS_1]], %[[OPERAND]], %[[START_INDICES]], %[[UPDATED_RESULT]])\n )\";\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,"
        },
        {
            "sha": "024483703b5b3157b9007673ae7e9adcf84db2ab",
            "filename": "third_party/xla/xla/service/gather_scatter_utils.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 3,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgather_scatter_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgather_scatter_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgather_scatter_utils.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -75,9 +75,9 @@ std::vector<HloInstruction*> GenerateExplicitBatchDimIndices(\n       break;\n     }\n \n-    HloInstruction* divisor =\n-        computation->AddInstruction(HloInstruction::CreateConstant(\n-            LiteralUtil::CreateR0<int32_t>(start_indices_shape.dimensions(i))));\n+    HloInstruction* divisor = computation->AddInstruction(\n+        HloInstruction::CreateConstant(LiteralUtil::CreateR0(\n+            shape.element_type(), start_indices_shape.dimensions(i))));\n     if (it != start_indices_batching_dims.end()) {\n       explicit_batch_dim_indices[it - start_indices_batching_dims.begin()] =\n           computation->AddInstruction(HloInstruction::CreateBinary(\n@@ -195,6 +195,13 @@ absl::StatusOr<HloInstruction*> ExpandIndexVectorIntoOperandSpace(\n       computation->AddInstruction(HloInstruction::CreateConstant(\n           LiteralUtil::CreateFromDimensions(index_shape.element_type(), {1})));\n \n+  if (induction_var->shape().element_type() != index_shape.element_type()) {\n+    induction_var =\n+        induction_var->parent()->AddInstruction(HloInstruction::CreateConvert(\n+            ShapeUtil::ChangeElementType(induction_var->shape(),\n+                                         index_shape.element_type()),\n+            induction_var));\n+  }\n   // We extract out individual components from the smaller index and concatenate\n   // them (interspersing zeros as needed) into the larger index.\n   std::vector<HloInstruction*> expanded_index_components;"
        },
        {
            "sha": "b07afc7f547d3d098f3a9fd35d421ef364d0ce26",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1893,12 +1893,12 @@ cc_library(\n         \"//xla/service:call_inliner\",\n         \"//xla/service:dump\",\n         \"//xla/service:float_support\",\n+        \"//xla/service:hlo_cost_analysis\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:hlo_verifier\",\n         \"//xla/service/gpu/autotuning:autotuner_pass\",\n         \"//xla/service/gpu/autotuning:autotuner_util\",\n         \"//xla/service/gpu/autotuning:conv_algorithm_picker\",\n-        \"//xla/service/gpu/autotuning:gemm_algorithm_picker\",\n         \"//xla/service/gpu/autotuning:gemm_fusion_autotuner\",\n         \"//xla/service/gpu/llvm_gpu_backend:nvptx_backend\",\n         \"//xla/service/gpu/llvm_gpu_backend:nvptx_utils\",\n@@ -2141,7 +2141,6 @@ cc_library(\n         \"//xla/service/gpu/autotuning:autotuner_pass\",\n         \"//xla/service/gpu/autotuning:autotuner_util\",\n         \"//xla/service/gpu/autotuning:conv_algorithm_picker\",\n-        \"//xla/service/gpu/autotuning:gemm_algorithm_picker\",\n         \"//xla/service/gpu/autotuning:gemm_fusion_autotuner\",\n         \"//xla/service/gpu/llvm_gpu_backend:amdgpu_backend\",\n         \"//xla/service/gpu/transforms:algebraic_simplifier\",\n@@ -2152,9 +2151,11 @@ cc_library(\n         \"//xla/service/gpu/transforms:gpusolver_rewriter\",\n         \"//xla/service/gpu/transforms:triangular_solve_rewriter\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:dnn\",\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/rocm:rocm_platform_id\",\n         \"//xla/stream_executor/rocm:rocm_solver_context\",\n         \"//xla/tsl/platform:env\",\n@@ -2309,6 +2310,8 @@ cc_library(\n         \"//xla/hlo/transforms/simplifiers:reshape_mover\",\n         \"//xla/hlo/transforms/simplifiers:sort_simplifier\",\n         \"//xla/hlo/transforms/simplifiers:tuple_simplifier\",\n+        \"//xla/service:call_graph\",\n+        \"//xla/service:call_inliner\",\n         \"//xla/service:conditional_simplifier\",\n         \"//xla/service:gather_expander\",\n         \"//xla/service:hlo_module_config\",\n@@ -2319,10 +2322,13 @@ cc_library(\n         \"//xla/service/gpu/transforms:algebraic_simplifier\",\n         \"//xla/service/spmd:collective_permute_motion\",\n         \"//xla/service/spmd:stateful_rng_spmd_partitioner\",\n+        \"//xla/service/spmd/shardy:constants\",\n         \"//xla/service/spmd/shardy:shardy_xla_pass\",\n         \"//xla/stream_executor:device_description\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/functional:function_ref\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/strings\",\n     ],\n )\n "
        },
        {
            "sha": "b16d1e508631e2a55946f8552487947311927dfe",
            "filename": "third_party/xla/xla/service/gpu/amdgpu_compiler.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 18,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Famdgpu_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -47,7 +47,6 @@ limitations under the License.\n #include \"xla/service/gpu/autotuning/autotuner_pass.h\"\n #include \"xla/service/gpu/autotuning/autotuner_util.h\"\n #include \"xla/service/gpu/autotuning/conv_algorithm_picker.h\"\n-#include \"xla/service/gpu/autotuning/gemm_algorithm_picker.h\"\n #include \"xla/service/gpu/autotuning/gemm_fusion_autotuner.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n #include \"xla/service/gpu/cublas_padding_requirements.h\"\n@@ -253,7 +252,8 @@ absl::Status AMDGPUCompiler::AddConvAndGemmAutotuningPasses(\n           .debug_options()\n           .xla_gpu_experimental_disable_binary_libraries() ||\n       debug_options.xla_gpu_autotune_level() == 0 ||\n-      debug_options.xla_gpu_exclude_nondeterministic_ops()) {\n+      debug_options.xla_gpu_exclude_nondeterministic_ops() ||\n+      stream_exec == nullptr) {\n     return absl::OkStatus();\n   }\n \n@@ -264,22 +264,18 @@ absl::Status AMDGPUCompiler::AddConvAndGemmAutotuningPasses(\n   std::vector<std::unique_ptr<CodegenBackend>> backends;\n   // TODO: b/407494793 - Add proper support for ROCM. Currently the Cublas\n   // backend uses the same API as rocBLAS.\n-  if (debug_options.xla_gpu_experimental_use_autotuner_pass()) {\n-    backends.push_back(\n-        std::make_unique<CublasBackend>(stream_exec, &debug_options, this));\n-    auto should_autotune = [](const HloInstruction& instruction) -> bool {\n-      return instruction.opcode() == HloOpcode::kCustomCall &&\n-             IsCublasGemm(instruction);\n-    };\n-    TF_ASSIGN_OR_RETURN(\n-        std::unique_ptr<AutotunerPass> autotuner_pass,\n-        AutotunerPass::Create(std::move(backends), debug_options,\n-                              options.device_allocator, stream_exec,\n-                              thread_pool, should_autotune));\n-    pipeline->AddPass(std::move(autotuner_pass));\n-  } else {\n-    pipeline->AddPass<GemmAlgorithmPicker>(autotune_config);\n-  }\n+  backends.push_back(\n+      std::make_unique<CublasBackend>(stream_exec, &debug_options, this));\n+  auto should_autotune = [](const HloInstruction& instruction) -> bool {\n+    return instruction.opcode() == HloOpcode::kCustomCall &&\n+           IsCublasGemm(instruction);\n+  };\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<AutotunerPass> autotuner_pass,\n+      AutotunerPass::Create(std::move(backends), debug_options, stream_exec,\n+                            thread_pool, should_autotune,\n+                            options.device_allocator));\n+  pipeline->AddPass(std::move(autotuner_pass));\n \n   return absl::OkStatus();\n }"
        },
        {
            "sha": "e80950768e0586af0319bbaa65318fec225fcb17",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 76,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -346,50 +346,6 @@ xla_test(\n     ],\n )\n \n-cc_library(\n-    name = \"gemm_algorithm_picker\",\n-    srcs = [\"gemm_algorithm_picker.cc\"],\n-    hdrs = [\"gemm_algorithm_picker.h\"],\n-    tags = [\"gpu\"],\n-    deps = [\n-        \":autotuner_util\",\n-        \":redzone_buffers\",\n-        \"//xla:autotune_results_proto_cc\",\n-        \"//xla:autotuning_proto_cc\",\n-        \"//xla:shape_util\",\n-        \"//xla:util\",\n-        \"//xla:xla_proto_cc\",\n-        \"//xla/backends/gpu/runtime:buffer_comparator\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/hlo/pass:hlo_pass\",\n-        \"//xla/service:hlo_module_config\",\n-        \"//xla/service/gpu:backend_configs_cc\",\n-        \"//xla/service/gpu:cublas_cudnn\",\n-        \"//xla/service/gpu:matmul_utils\",\n-        \"//xla/service/gpu:stream_executor_util\",\n-        \"//xla/stream_executor:blas\",\n-        \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:device_memory\",\n-        \"//xla/stream_executor:device_memory_allocator\",\n-        \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/stream_executor/gpu:redzone_allocator\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:logging\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"//xla/tsl/util/proto:proto_utils\",\n-        \"@com_google_absl//absl/container:flat_hash_set\",\n-        \"@com_google_absl//absl/functional:overload\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:str_format\",\n-        \"@com_google_absl//absl/synchronization\",\n-        \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/profiler/lib:scoped_annotation\",\n-    ],\n-)\n-\n cc_library(\n     name = \"autotuner_status_key\",\n     srcs = [\"autotuner_status_key.cc\"],\n@@ -565,38 +521,6 @@ xla_test(\n     ],\n )\n \n-xla_test(\n-    name = \"gemm_algorithm_picker_test\",\n-    srcs = [\"gemm_algorithm_picker_test.cc\"],\n-    backends = [\n-        \"v100\",\n-        \"amdgpu_any\",\n-    ],\n-    deps = [\n-        \":autotuner_util\",\n-        \":gemm_algorithm_picker\",\n-        \"//xla:autotune_results_proto_cc\",\n-        \"//xla:xla_proto_cc\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/hlo/testlib:pattern_matcher_gmock\",\n-        \"//xla/service:pattern_matcher\",\n-        \"//xla/service/gpu:backend_configs_cc\",\n-        \"//xla/service/gpu/transforms:gemm_rewriter\",\n-        \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:platform\",\n-        \"//xla/stream_executor:semantic_version\",\n-        \"//xla/tests:hlo_test_base\",\n-        \"//xla/tsl/lib/core:status_test_util\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"//xla/tsl/platform:test\",\n-        \"//xla/tsl/platform:test_main\",\n-        \"//xla/tsl/protobuf:dnn_proto_cc\",\n-        \"@com_google_absl//absl/functional:overload\",\n-        \"@com_google_absl//absl/log\",\n-        \"@com_google_absl//absl/strings:string_view\",\n-    ],\n-)\n-\n cc_library(\n     name = \"conv_algorithm_picker\",\n     srcs = [\"conv_algorithm_picker.cc\"],"
        },
        {
            "sha": "93b2b5618ecd7b0fceb58138c6d6d186a5951fca",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -45,9 +45,13 @@ namespace gpu {\n \n absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n     std::vector<std::unique_ptr<CodegenBackend>> backends,\n-    const DebugOptions& debug_options, se::DeviceMemoryAllocator* allocator,\n+    const DebugOptions& debug_options,\n     stream_executor::StreamExecutor* stream_executor,\n-    tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune) {\n+    tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune,\n+    se::DeviceMemoryAllocator* allocator) {\n+  // At least one of stream_executor or allocator must be provided.\n+  CHECK(stream_executor != nullptr || allocator != nullptr);\n+\n   std::unique_ptr<GpuProfiler> profiler =\n       GpuProfiler::Create(stream_executor, ProfileOptions(), allocator);\n \n@@ -77,10 +81,17 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n     TF_ASSIGN_OR_RETURN(cache, FileBasedAutotunerCache::Create(cache_config));\n   }\n \n+  AutotuneConfig autotune_config;\n+  autotune_config.check_buffers = debug_options.xla_gpu_autotune_level() >= 4;\n+  autotune_config.relative_tolerance =\n+      debug_options.xla_gpu_autotune_gemm_rtol();\n+  autotune_config.crash_on_check_failure =\n+      debug_options.xla_gpu_crash_on_verification_failures();\n+\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<Autotuner> autotuner,\n       Autotuner::Create(std::move(backends), std::move(profiler),\n-                        AutotuneConfig(), std::move(cache), thread_pool));\n+                        autotune_config, std::move(cache), thread_pool));\n   return absl::WrapUnique(\n       new AutotunerPass(std::move(autotuner), should_autotune));\n }"
        },
        {
            "sha": "fa0c6535e0e9bc018e7415d3c2bf2bfb2a1d595f",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -39,9 +39,9 @@ class AutotunerPass : public HloModulePass {\n  public:\n   static absl::StatusOr<std::unique_ptr<AutotunerPass>> Create(\n       std::vector<std::unique_ptr<CodegenBackend>> backends,\n-      const DebugOptions& debug_options, se::DeviceMemoryAllocator* allocator,\n-      se::StreamExecutor* stream_executor, tsl::thread::ThreadPool* thread_pool,\n-      InstructionFilterFn should_autotune);\n+      const DebugOptions& debug_options, se::StreamExecutor* stream_executor,\n+      tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune,\n+      se::DeviceMemoryAllocator* allocator = nullptr);\n \n   absl::string_view name() const override { return \"autotuner\"; }\n "
        },
        {
            "sha": "1cb3dfb96129143aa90177e60e83610bdb42f1d1",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -114,9 +114,9 @@ TEST_F(AutotunerPassTest, CublasGemmIsAutotuned) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<AutotunerPass> pass,\n       AutotunerPass::Create(std::move(backends),\n-                            module->config().debug_options(), allocator_.get(),\n-                            stream_executor_, &thread_pool,\n-                            IsCublasGemmInstruction));\n+                            module->config().debug_options(), stream_executor_,\n+                            &thread_pool, IsCublasGemmInstruction,\n+                            allocator_.get()));\n   EXPECT_THAT(pass->Run(module.get(), /*execution_threads=*/{}),\n               tsl::testing::IsOkAndHolds(true));\n   // Verify that the backend config has been updated in the HLO.\n@@ -144,8 +144,8 @@ TEST_F(AutotunerPassTest, CublasGemmIsNotAutotunedWhenFilterReturnsFalse) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<AutotunerPass> pass,\n       AutotunerPass::Create(std::move(backends),\n-                            module->config().debug_options(), allocator_.get(),\n-                            stream_executor_, &thread_pool, should_autotune));\n+                            module->config().debug_options(), stream_executor_,\n+                            &thread_pool, should_autotune, allocator_.get()));\n   EXPECT_THAT(pass->Run(module.get(), /*execution_threads=*/{}),\n               tsl::testing::IsOkAndHolds(true));\n   // Verify that the backend config has *not* been updated in the HLO.\n@@ -180,8 +180,8 @@ TEST_F(AutotunerPassTest, CublasGemmIsAutotunedAndCached) {\n         std::unique_ptr<AutotunerPass> pass,\n         AutotunerPass::Create(std::move(backends),\n                               module->config().debug_options(),\n-                              allocator_.get(), stream_executor_, &thread_pool,\n-                              IsCublasGemmInstruction));\n+                              stream_executor_, &thread_pool,\n+                              IsCublasGemmInstruction, allocator_.get()));\n     EXPECT_THAT(pass->Run(module.get(), /*execution_threads=*/{}),\n                 tsl::testing::IsOkAndHolds(true));\n   }\n@@ -236,8 +236,8 @@ TEST_F(AutotunerPassTest, CublasGemmIsAutotunedAndCached) {\n         std::unique_ptr<AutotunerPass> pass2,\n         AutotunerPass::Create(std::move(backends2),\n                               module->config().debug_options(),\n-                              allocator_.get(), stream_executor_, &thread_pool,\n-                              IsCublasGemmInstruction));\n+                              stream_executor_, &thread_pool,\n+                              IsCublasGemmInstruction, allocator_.get()));\n     EXPECT_THAT(pass2->Run(module.get(), /*execution_threads=*/{}),\n                 tsl::testing::IsOkAndHolds(true));\n   }"
        },
        {
            "sha": "664123e3cc3df52c33c4c7512c9ffc66484e6ef5",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 530,
            "changes": 530,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.cc?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,530 +0,0 @@\n-/* Copyright 2019 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/autotuning/gemm_algorithm_picker.h\"\n-\n-#include <algorithm>\n-#include <cstddef>\n-#include <cstdint>\n-#include <optional>\n-#include <string>\n-#include <utility>\n-#include <variant>\n-#include <vector>\n-\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"absl/functional/overload.h\"\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/str_format.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"absl/synchronization/mutex.h\"\n-#include \"absl/types/span.h\"\n-#include \"xla/autotuning.pb.h\"\n-#include \"xla/backends/gpu/runtime/buffer_comparator.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/service/gpu/autotuning/autotuner_util.h\"\n-#include \"xla/service/gpu/autotuning/redzone_buffers.h\"\n-#include \"xla/service/gpu/backend_configs.pb.h\"\n-#include \"xla/service/gpu/cublas_cudnn.h\"\n-#include \"xla/service/gpu/matmul_utils.h\"\n-#include \"xla/service/gpu/stream_executor_util.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/blas.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n-#include \"xla/stream_executor/gpu/redzone_allocator.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/logging.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/tsl/util/proto/proto_utils.h\"\n-#include \"xla/util.h\"\n-#include \"xla/xla.pb.h\"\n-#include \"tsl/profiler/lib/scoped_annotation.h\"\n-\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-using se::gpu::BlasLt;\n-\n-absl::StatusOr<BlasLt::Epilogue> AsBlasLtEpilogue(\n-    GemmBackendConfig_Epilogue epilogue) {\n-  switch (epilogue) {\n-    case GemmBackendConfig::DEFAULT:\n-      return BlasLt::Epilogue::kDefault;\n-    case GemmBackendConfig::RELU:\n-      return BlasLt::Epilogue::kReLU;\n-    case GemmBackendConfig::GELU:\n-      return BlasLt::Epilogue::kGELU;\n-    case GemmBackendConfig::GELU_AUX:\n-      return BlasLt::Epilogue::kGELUWithAux;\n-    case GemmBackendConfig::BIAS:\n-      return BlasLt::Epilogue::kBias;\n-    case GemmBackendConfig::BIAS_RELU:\n-      return BlasLt::Epilogue::kBiasThenReLU;\n-    case GemmBackendConfig::BIAS_GELU:\n-      return BlasLt::Epilogue::kBiasThenGELU;\n-    case GemmBackendConfig::BIAS_GELU_AUX:\n-      return BlasLt::Epilogue::kBiasThenGELUWithAux;\n-    case GemmBackendConfig::SILU:\n-      return BlasLt::Epilogue::kSILU;\n-    case GemmBackendConfig::BIAS_SILU:\n-      return BlasLt::Epilogue::kBiasThenSILU;\n-    default:\n-      return Internal(\"Unsupported Epilogue.\");\n-  }\n-}\n-\n-class GemmAutotuner {\n-  const AutotuneConfig& autotune_config_;\n-  RedzoneBuffers rz_buffers_;\n-  se::Stream* stream_ = nullptr;\n-  bool deterministic_ops_ = false;\n-  size_t solutions_limit_ = 0;\n-  size_t num_algorithms_left_ = 0;\n-\n- public:\n-  explicit GemmAutotuner(const AutotuneConfig& autotune_config)\n-      : autotune_config_(autotune_config) {}\n-\n-  const AutotuneConfig& config() const { return autotune_config_; }\n-\n-  size_t num_algorithms_left() const { return num_algorithms_left_; }\n-\n-  absl::StatusOr<AutotuneResult> operator()(const HloInstruction* gemm,\n-                                            const AutotuneCacheKey& key) {\n-    num_algorithms_left_ = 0;\n-    if (autotune_config_.IsDeviceless()) {\n-      // Return empty result, will tune at runtime.\n-      return AutotuneResult{};\n-    }\n-    VLOG(3) << \"Starting autotune of GemmThunk \" << gemm->ToString();\n-\n-    TF_ASSIGN_OR_RETURN(stream_, autotune_config_.GetStream());\n-    const DebugOptions& debug_options =\n-        gemm->GetModule()->config().debug_options();\n-    deterministic_ops_ = RequireDeterminism(gemm->GetModule()->config());\n-    solutions_limit_ = debug_options.xla_gpu_autotune_max_solutions();\n-\n-    TF_ASSIGN_OR_RETURN(auto gemm_config,\n-                        GemmConfig::For(gemm, stream_->parent()\n-                                                  ->GetDeviceDescription()\n-                                                  .gpu_compute_capability()));\n-\n-    // Don't run autotuning concurrently on the same GPU.\n-    absl::MutexLock gpu_lock(&GetGpuMutex(stream_->parent()));\n-\n-    bool should_init_buffers = autotune_config_.should_init_buffers();\n-    bool should_check_correctness = autotune_config_.should_check_correctness();\n-    int redzone_padding_bytes = debug_options.xla_gpu_redzone_padding_bytes();\n-    TF_ASSIGN_OR_RETURN(se::Stream * stream, autotune_config_.GetStream());\n-    TF_ASSIGN_OR_RETURN(\n-        rz_buffers_,\n-        RedzoneBuffers::FromInstruction(\n-            *gemm, autotune_config_.GetAllocator(), stream,\n-            RedzoneBuffers::kAllInputsAllOutputs, should_init_buffers,\n-            should_check_correctness, redzone_padding_bytes));\n-\n-    return IsCublasLtMatmul(*gemm) || IsCublasLtMatmulF8(*gemm)\n-               ? TuneGpuBlasLt(gemm, gemm_config)\n-               : TuneGpuBlas(gemm, gemm_config);\n-  }\n-\n- private:\n-  se::DeviceMemoryBase LhsBuffer() { return rz_buffers_.input_buffers().at(0); }\n-  se::DeviceMemoryBase RhsBuffer() { return rz_buffers_.input_buffers().at(1); }\n-  se::DeviceMemoryBase OutputBuffer() {\n-    return rz_buffers_.output_buffers().at(0);\n-  }\n-\n-  const Shape& GetOutputShape(const HloInstruction* gemm) {\n-    return gemm->shape().IsTuple() ? gemm->shape().tuple_shapes(0)\n-                                   : gemm->shape();\n-  }\n-\n-  absl::StatusOr<AutotuneResult> TuneGpuBlasLt(const HloInstruction* gemm,\n-                                               const GemmConfig& gemm_config) {\n-    auto workspace_buffer = rz_buffers_.output_buffers().at(\n-        gemm->shape().tuple_shapes().size() - 1);\n-\n-    GpuBackendConfig gpu_config =\n-        gemm->backend_config<GpuBackendConfig>().value();\n-    const GemmBackendConfig& backend_config = gpu_config.gemm_backend_config();\n-\n-    bool has_matrix_bias = gemm_config.beta != 0.;\n-\n-    TF_ASSIGN_OR_RETURN(\n-        bool has_vector_bias,\n-        gpublas_lt::EpilogueAddsVectorBias(backend_config.epilogue()));\n-\n-    TF_ASSIGN_OR_RETURN(\n-        bool has_aux_output,\n-        gpublas_lt::EpilogueHasAuxiliaryOutput(backend_config.epilogue()));\n-\n-    TF_ASSIGN_OR_RETURN(auto epilogue,\n-                        AsBlasLtEpilogue(backend_config.epilogue()));\n-\n-    se::DeviceMemoryBase a_scale_buffer, b_scale_buffer, c_scale_buffer,\n-        d_scale_buffer, d_amax_buffer, bias_buffer, aux_buffer;\n-\n-    int64_t input_buffer_idx = 2;  // lhs is at 0, rhs is at 1\n-    if (has_vector_bias) {\n-      if (has_matrix_bias) {\n-        input_buffer_idx++;\n-      }\n-      bias_buffer = rz_buffers_.input_buffers().at(input_buffer_idx++);\n-    }\n-    // In the current GemmRewriter design for FP8, the a/b scales remain active\n-    // even when they are not used. Consequently, we must inform the autotuner\n-    // so it can choose algorithms that properly support a/b scales.\n-    if (xla::primitive_util::IsF8Type(\n-            gemm->operand(0)->shape().element_type()) &&\n-        xla::primitive_util::IsF8Type(\n-            gemm->operand(1)->shape().element_type())) {\n-      a_scale_buffer = rz_buffers_.input_buffers().at(input_buffer_idx++);\n-      b_scale_buffer = rz_buffers_.input_buffers().at(input_buffer_idx++);\n-    }\n-\n-    if (has_aux_output) {\n-      aux_buffer = rz_buffers_.output_buffers().at(1);\n-    }\n-\n-    TF_ASSIGN_OR_RETURN(auto plan,\n-                        BlasLt::GetMatmulPlan(stream_, gemm_config, epilogue));\n-\n-    TF_ASSIGN_OR_RETURN(\n-        auto algorithms,\n-        plan->GetAlgorithms(stream_, GemmConfig::kNumAlgorithms,\n-                            /*max_workspace_size*/ workspace_buffer.size()));\n-\n-    auto tuned_func = [&](const BlasLt::MatmulAlgorithm& algorithm)\n-        -> absl::StatusOr<se::blas::ProfileResult> {\n-      // Run a warmup iteration without the profiler active.\n-      TF_RETURN_IF_ERROR(plan->SetAlgorithm(algorithm));\n-      TF_RETURN_IF_ERROR(plan->ExecuteOnStream(\n-          stream_, LhsBuffer(), RhsBuffer(), OutputBuffer(), OutputBuffer(),\n-          bias_buffer, aux_buffer, a_scale_buffer, b_scale_buffer,\n-          c_scale_buffer, d_scale_buffer, d_amax_buffer, workspace_buffer));\n-      se::blas::ProfileResult profile_result;\n-      profile_result.set_warmup_run_executed(true);\n-      TF_RETURN_IF_ERROR(plan->ExecuteOnStream(\n-          stream_, LhsBuffer(), RhsBuffer(), OutputBuffer(), OutputBuffer(),\n-          bias_buffer, aux_buffer, a_scale_buffer, b_scale_buffer,\n-          c_scale_buffer, d_scale_buffer, d_amax_buffer, workspace_buffer,\n-          &profile_result));\n-      return std::move(profile_result);\n-    };\n-\n-    return GetBestAlgorithm<BlasLt::MatmulAlgorithm>(\n-        gemm, algorithms, gemm_config.beta, /*return_algo_index*/ true,\n-        tuned_func);\n-  }\n-\n-  absl::StatusOr<AutotuneResult> TuneGpuBlas(const HloInstruction* gemm,\n-                                             const GemmConfig& gemm_config) {\n-    auto workspace_buffer = rz_buffers_.output_buffers().at(1);\n-\n-    std::vector<se::blas::AlgorithmType> algorithms;\n-    TF_ASSIGN_OR_RETURN(GemmConfig::DescriptorsTuple desc,\n-                        gemm_config.GetMatrixDescriptors(\n-                            LhsBuffer(), RhsBuffer(), OutputBuffer()));\n-\n-    auto blas = stream_->parent()->AsBlas();\n-    if (blas == nullptr) {\n-      return absl::InternalError(\"No BLAS support for stream\");\n-    }\n-    blas->GetBlasGemmAlgorithms(stream_, desc.lhs, desc.rhs, &desc.output,\n-                                &gemm_config.alpha, &gemm_config.beta,\n-                                &algorithms);\n-\n-    auto tuned_func = [&](const se::blas::AlgorithmType& algorithm)\n-        -> absl::StatusOr<se::blas::ProfileResult> {\n-      // Do a warm-up run first, without a profile result. RunGemm swallows\n-      // error codes when profile_result is passed, as it is in the measurement\n-      // below, but not otherwise. It is, therefore, consistent to ignore the\n-      // error code here.\n-      static_cast<void>(RunGemm(gemm_config, LhsBuffer(), RhsBuffer(),\n-                                OutputBuffer(), workspace_buffer,\n-                                deterministic_ops_, stream_, algorithm));\n-      se::blas::ProfileResult profile_result;\n-      // Allow GpuTimer to use its delay kernel implementation to improve\n-      // accuracy.\n-      profile_result.set_warmup_run_executed(true);\n-      // We expect GemmWithAlgorithm to fail sometimes -- in fact, it will fail\n-      // for all algorithms if we're targeting < sm_50. But because we pass a\n-      // non-null ProfileResult, DoGemmWithAlgorithm should always return true,\n-      // and the actual success-ness is returned in ProfileResult::is_valid.\n-      TF_RETURN_IF_ERROR(RunGemm(gemm_config, LhsBuffer(), RhsBuffer(),\n-                                 OutputBuffer(), workspace_buffer,\n-                                 deterministic_ops_, stream_, algorithm,\n-                                 &profile_result));\n-      return std::move(profile_result);\n-    };\n-\n-    return GetBestAlgorithm<se::blas::AlgorithmType>(\n-        gemm, algorithms, gemm_config.beta, /*return_algo_index*/ false,\n-        tuned_func);\n-  }\n-\n-  // Returns the index (into `algorithms`) of the fastest algorithm.\n-  template <typename AlgoT, typename TunedFunc>\n-  absl::StatusOr<AutotuneResult> GetBestAlgorithm(\n-      const HloInstruction* gemm, absl::Span<const AlgoT> algorithms,\n-      double beta, bool return_algo_index, TunedFunc&& run_benchmark) {\n-    static_assert(std::is_invocable_r_v<absl::StatusOr<se::blas::ProfileResult>,\n-                                        TunedFunc, const AlgoT&>,\n-                  \"Tuned function has incorrect prototype!\");\n-\n-    if (!stream_->parent()->SynchronizeAllActivity()) {\n-      return Internal(\"Failed to synchronize GPU for autotuning.\");\n-    }\n-    tsl::profiler::ScopedAnnotation annotation([&] {\n-      return absl::StrFormat(\"XlaAutotunerMeasurement:#hlo_op=%s#\",\n-                             gemm->name());\n-    });\n-\n-    auto& hlo_module_config = gemm->GetModule()->mutable_config();\n-    const auto& output_shape = GetOutputShape(gemm);\n-\n-    se::DeviceMemoryBase reference_buffer;\n-    if (autotune_config_.should_check_correctness()) {\n-      TF_ASSIGN_OR_RETURN(reference_buffer,\n-                          rz_buffers_.RedzoneAllocator().AllocateBytes(\n-                              ShapeUtil::ByteSizeOf(output_shape)));\n-    }\n-\n-    // Do not print error messages if should_skip_wrong_results() is ON.\n-    BufferComparator comparator(\n-        output_shape,\n-        hlo_module_config.debug_options().xla_gpu_autotune_gemm_rtol(),\n-        /* verbose */ !autotune_config_.should_skip_wrong_results());\n-    std::vector<AutotuneResult> results;\n-    results.reserve(algorithms.size());\n-    std::optional<int64_t> reference_algorithm;\n-\n-    auto num = algorithms.size();\n-    if (solutions_limit_ > 0) num = std::min(num, solutions_limit_);\n-    for (size_t i = 0; i < num; i++) {\n-      const AlgoT& algorithm = algorithms[i];\n-      // Make sure the output buffer always has the same value if we use\n-      // the bias parameter.\n-      if (autotune_config_.should_reinit_output_buffer() && beta != 0) {\n-        int64_t rng_state = 0;\n-        InitializeBuffer(stream_, output_shape.element_type(), &rng_state,\n-                         OutputBuffer());\n-      }\n-      TF_ASSIGN_OR_RETURN(auto profile_result, run_benchmark(algorithm));\n-\n-      AutotuneResult& result = results.emplace_back();\n-      result.mutable_gemm()->set_algorithm(profile_result.algorithm());\n-\n-      if (!profile_result.is_valid()) {  // Unsupported algorithm.\n-        result.mutable_failure()->set_kind(AutotuneResult::DISQUALIFIED);\n-        continue;\n-      }\n-\n-      VLOG(2) << \"gemm algorithm \" << profile_result.algorithm() << \" took \"\n-              << profile_result.elapsed_time_in_ms() << \"ms\";\n-\n-      *result.mutable_run_time() = tsl::proto_utils::ToDurationProto(\n-          absl::Milliseconds(profile_result.elapsed_time_in_ms()));\n-\n-      if (!autotune_config_.should_check_correctness()) {\n-        num_algorithms_left_++;\n-        continue;\n-      }\n-      TF_ASSIGN_OR_RETURN(\n-          se::RedzoneAllocator::RedzoneCheckStatus rz_check_status,\n-          rz_buffers_.RedzoneAllocator().CheckRedzones());\n-\n-      if (!rz_check_status.ok()) {\n-        result.mutable_failure()->set_kind(AutotuneResult::REDZONE_MODIFIED);\n-        *result.mutable_failure()->mutable_msg() =\n-            rz_check_status.RedzoneFailureMsg();\n-        LOG(ERROR) << \"Detected out-of-bounds write in gemm buffer\";\n-        CHECK(!autotune_config_.should_crash_on_check_failure());\n-        continue;\n-      }\n-\n-      num_algorithms_left_++;\n-      if (!reference_algorithm) {\n-        TF_RETURN_IF_ERROR(stream_->Memcpy(&reference_buffer, OutputBuffer(),\n-                                           OutputBuffer().size()));\n-        reference_algorithm = profile_result.algorithm();\n-        continue;\n-      }\n-      // Perform the comparison versus the reference algorithm.\n-      TF_ASSIGN_OR_RETURN(\n-          bool outputs_match,\n-          comparator.CompareEqual(stream_, /*current=*/OutputBuffer(),\n-                                  /*expected=*/reference_buffer));\n-      if (!outputs_match) {\n-        LOG(ERROR) << \"Results mismatch between different GEMM algorithms. \"\n-                   << \"This is likely a bug/unexpected loss of precision.\";\n-        CHECK(!autotune_config_.should_crash_on_check_failure());\n-\n-        // By default, autotuner does NOT really skip wrong results, but\n-        // merely prints out the above error message: this may lead to a\n-        // great confusion. When should_skip_wrong_results() is set to true,\n-        // solutions with accuracy problems will be disqualified.\n-        auto kind = AutotuneResult::WRONG_RESULT;\n-        if (autotune_config_.should_skip_wrong_results()) {\n-          kind = AutotuneResult::DISQUALIFIED;\n-          num_algorithms_left_--;  // Decrement again since we disqualified it.\n-        }\n-        result.mutable_failure()->set_kind(kind);\n-        result.mutable_failure()->mutable_reference_gemm()->set_algorithm(\n-            *reference_algorithm);\n-      }\n-    }  // for algorithms\n-\n-    absl::StatusOr<AutotuneResult> best =\n-        PickBestResult(results, gemm->ToString(), hlo_module_config);\n-    if (best.ok()) {\n-      // Note that, cublas-lt returns an opaque object as an algorithm ID,\n-      // therefore we need to convert it to the index from the algorithms list\n-      // (otherwise, we cannot store this ID inside a gemm_backend_config).\n-      // In contrast, legacy cublas returns a 32-bit integer algorithm ID which\n-      // can be readily stored inside an HLO (hence return_algo_index is false\n-      // for cublas case).\n-      if (!return_algo_index) return best;\n-      // Otherwise, map a real algorithm ID to its index among the results.\n-      for (size_t i = 0; i < results.size(); ++i) {\n-        if (best->gemm().algorithm() == results[i].gemm().algorithm()) {\n-          best->mutable_gemm()->set_algorithm(i);\n-          return best;\n-        }\n-      }\n-      return Internal(\"unknown best algorithm\");\n-    }\n-    LOG(WARNING) << \"Failed to find best cuBLAS algorithm, GEMM performance \"\n-                    \"might be suboptimal: \"\n-                 << best.status();\n-    return AutotuneResult{};\n-  }  // GetBestAlgorithm\n-};  // class GemmAutotuner\n-\n-// Do Gemm Autotune without stream executor. Use results from autotune cache\n-// only.\n-absl::StatusOr<bool> RunOnInstruction(HloInstruction* gemm,\n-                                      GemmAutotuner& autotuner) {\n-  VLOG(3) << \"Loading the autotune result of GemmThunk \" << gemm->ToString();\n-\n-  GpuBackendConfig gpu_config =\n-      gemm->backend_config<GpuBackendConfig>().value();\n-  GemmBackendConfig& backend_config = *gpu_config.mutable_gemm_backend_config();\n-\n-  // Degenerate gemms replaced with memzero operation, no need to auto tune it.\n-  if (backend_config.alpha_real() == 0.0 &&\n-      backend_config.alpha_imag() == 0.0 && backend_config.beta() == 0.0) {\n-    VLOG(3) << \"Skip degenerate gemm instruction auto tuning\";\n-    return false;\n-  }\n-\n-  const AutotuneConfig& config = autotuner.config();\n-  AutotuneCacheKey key(config.GetDeviceDescription(), *gemm);\n-  TF_ASSIGN_OR_RETURN(AutotuneResult algorithm,\n-                      AutotunerUtil::Autotune(\n-                          gemm, config, [&] { return autotuner(gemm, key); }));\n-\n-  auto old_algorithm = backend_config.selected_algorithm();\n-  bool update_algorithm =\n-      IsCublasLtMatmulF8(*gemm) ||\n-      std::visit(absl::Overload(\n-                     [](const se::CudaComputeCapability& cc) {\n-                       // We only set the 'algorithm' field on\n-                       // non-Ampere architectures, as for Ampere\n-                       // it's ignored in any case.\n-                       return !cc.IsAtLeast(se::CudaComputeCapability::kAmpere);\n-                     },\n-                     [](const se::RocmComputeCapability&) {\n-                       return true;  // TODO: not decided yet\n-                     }),\n-                 config.GetGpuComputeCapability());\n-\n-  if (update_algorithm) {\n-    int64_t new_algorithm{};\n-    if (algorithm.has_gemm()) {\n-      new_algorithm = algorithm.gemm().algorithm();\n-    } else {\n-      // NOTE: runtime autotuning is no longer available => set to default\n-      new_algorithm = se::blas::kDefaultAlgorithm;\n-    }\n-\n-    if (new_algorithm == old_algorithm &&\n-        backend_config.has_selected_algorithm()) {\n-      // We don't need to update the backend config if the algorithm was not\n-      // changed unless previously the algorithm wasn't set explicitly.\n-      return false;\n-    }\n-\n-    backend_config.set_selected_algorithm(new_algorithm);\n-    TF_RETURN_IF_ERROR(gemm->set_backend_config(gpu_config));\n-    return true;  // We changed `gemm`\n-  }\n-\n-  return false;  // No change to `gemm`\n-}\n-\n-absl::StatusOr<bool> RunOnComputation(HloComputation* computation,\n-                                      GemmAutotuner& autotuner,\n-                                      size_t* num_algorithms_left) {\n-  bool changed = false;\n-\n-  for (HloInstruction* instr : computation->instructions()) {\n-    if (IsCublasGemm(*instr)) {\n-      TF_ASSIGN_OR_RETURN(bool result, RunOnInstruction(instr, autotuner));\n-      // Gathering statistics on the algorithms left after tuning (for testing)\n-      *num_algorithms_left =\n-          std::max(*num_algorithms_left, autotuner.num_algorithms_left());\n-      changed |= result;\n-    }\n-  }\n-  return changed;\n-}\n-\n-}  // namespace\n-\n-absl::StatusOr<bool> GemmAlgorithmPicker::Run(\n-    HloModule* module,\n-    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n-  XLA_SCOPED_LOGGING_TIMER(\n-      absl::StrCat(\"GemmAlgorithmPicker for \", module->name()));\n-\n-  num_algorithms_left_ = 0;\n-  if (module->config().debug_options().xla_gpu_autotune_level() == 0) {\n-    VLOG(2) << \"GEMM auto-tuning disabled, GemmAlgorithmPicker returning early\";\n-    return false;\n-  }\n-  GemmAutotuner autotuner(config_);\n-  bool changed = false;\n-  for (HloComputation* computation :\n-       module->MakeNonfusionComputations(execution_threads)) {\n-    TF_ASSIGN_OR_RETURN(bool result, RunOnComputation(computation, autotuner,\n-                                                      &num_algorithms_left_));\n-    changed |= result;\n-  }\n-  return changed;\n-}\n-\n-}  // namespace gpu\n-}  // namespace xla"
        },
        {
            "sha": "8f74c23456d66417f16fbe4e198b714edb7a6931",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.h",
            "status": "removed",
            "additions": 0,
            "deletions": 71,
            "changes": 71,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker.h?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,71 +0,0 @@\n-/* Copyright 2019 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-#ifndef XLA_SERVICE_GPU_AUTOTUNING_GEMM_ALGORITHM_PICKER_H_\n-#define XLA_SERVICE_GPU_AUTOTUNING_GEMM_ALGORITHM_PICKER_H_\n-\n-#include <cstddef>\n-#include <functional>\n-#include <optional>\n-\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"xla/autotune_results.pb.h\"\n-#include \"xla/autotuning.pb.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/hlo/pass/hlo_pass_interface.h\"\n-#include \"xla/service/gpu/autotuning/autotuner_util.h\"\n-#include \"xla/service/gpu/autotuning/redzone_buffers.h\"\n-#include \"xla/service/hlo_module_config.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/stream_executor/blas.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n-#include \"xla/stream_executor/gpu/redzone_allocator.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n-\n-namespace xla {\n-namespace gpu {\n-\n-// GemmAlgorithmPicker supports two modes: device and deviceless.\n-// In device mode, we run autotuning on the device and store autotune results.\n-// In deviceless mode, we pass in some information related to the device and\n-// use stored autotune results to rewrite Gemm instructions. If the required\n-// autotune result is not stored, then algorithm is set to kRuntimeAutotuning.\n-class GemmAlgorithmPicker : public HloModulePass {\n- public:\n-  explicit GemmAlgorithmPicker(AutotuneConfig config) : config_(config) {}\n-\n-  absl::string_view name() const override { return \"gemm-algorithm-picker\"; }\n-\n-  size_t num_algorithms_left() const { return num_algorithms_left_; }\n-\n-  using HloPassInterface::Run;\n-  absl::StatusOr<bool> Run(\n-      HloModule* module,\n-      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n-\n- private:\n-  AutotuneConfig config_;\n-  // The number of valid algorithms used for autotuning (from the last call),\n-  // to be used for testing purposes.\n-  size_t num_algorithms_left_ = 0;\n-};\n-\n-}  // namespace gpu\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_GPU_AUTOTUNING_GEMM_ALGORITHM_PICKER_H_"
        },
        {
            "sha": "881995f6fef7ca3ec97810a4a253b5047297be3b",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_algorithm_picker_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 337,
            "changes": 337,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c235d2cd077040f16951b51ff0f29bc7318a5cd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_algorithm_picker_test.cc?ref=9c235d2cd077040f16951b51ff0f29bc7318a5cd",
            "patch": "@@ -1,337 +0,0 @@\n-/* Copyright 2022 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/autotuning/gemm_algorithm_picker.h\"\n-\n-#include <cstddef>\n-#include <cstdint>\n-#include <string>\n-#include <variant>\n-\n-#include \"absl/functional/overload.h\"\n-#include \"absl/log/log.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/autotune_results.pb.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n-#include \"xla/service/gpu/autotuning/autotuner_util.h\"\n-#include \"xla/service/gpu/backend_configs.pb.h\"\n-#include \"xla/service/gpu/transforms/gemm_rewriter.h\"\n-#include \"xla/service/pattern_matcher.h\"\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/platform.h\"\n-#include \"xla/stream_executor/semantic_version.h\"\n-#include \"xla/tests/hlo_test_base.h\"\n-#include \"xla/tsl/lib/core/status_test_util.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/tsl/platform/test.h\"\n-#include \"xla/tsl/protobuf/dnn.pb.h\"\n-#include \"xla/xla.pb.h\"\n-\n-namespace xla::gpu {\n-namespace {\n-\n-namespace m = ::xla::match;\n-\n-class GemmAlgorithmPickerTest : public HloTestBase,\n-                                public ::testing::WithParamInterface<bool> {\n- public:\n-  GemmAlgorithmPickerTest() { AutotunerUtil::ClearAutotuneResults(); }\n-\n-  DebugOptions GetDebugOptionsForTest() const override {\n-    DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_gpu_enable_cublaslt(GetParam());\n-    debug_options.set_xla_gpu_enable_triton_gemm(false);\n-    return debug_options;\n-  }\n-\n-  se::StreamExecutor* stream_exec() {\n-    return backend().default_stream_executor();\n-  }\n-  const se::DeviceDescription& device_desc() {\n-    return stream_exec()->GetDeviceDescription();\n-  }\n-  const se::GpuComputeCapability& gpu_comp() {\n-    return device_desc().gpu_compute_capability();\n-  }\n-\n-  void SetUp() override {\n-    absl::string_view name =\n-        ::testing::UnitTest::GetInstance()->current_test_info()->name();\n-    // We need special handling for BlasGetVersion test.\n-    bool blas_get_version = name.rfind(\"BlasGetVersion\") == 0;\n-\n-    std::visit(\n-        absl::Overload(\n-            [&](const se::CudaComputeCapability& cc) {\n-              if (!blas_get_version && cc.IsAtLeastAmpere()) {\n-                GTEST_SKIP()\n-                    << \"Skipping this test for Ampere+ as it is supported \"\n-                       \"and recommended with the Nvidia Volta+ GPUs.\";\n-              }\n-            },\n-            [&](const se::RocmComputeCapability& cc) {\n-              if (blas_get_version) {\n-                if (device_desc().runtime_version() <\n-                    stream_executor::SemanticVersion{6, 2, 0}) {\n-                  GTEST_SKIP()\n-                      << \"This API is not available on ROCM 6.1 and below.\";\n-                }\n-              } else if (GetDebugOptionsForTest().xla_gpu_enable_cublaslt() &&\n-                         !cc.has_hipblaslt()) {\n-                GTEST_SKIP() << \"No gpublas-lt support on this architecture!\";\n-              }\n-            }),\n-        gpu_comp());\n-  }\n-};\n-\n-TEST_P(GemmAlgorithmPickerTest, BlasGetVersion) {\n-  auto* blas = stream_exec()->AsBlas();\n-  ASSERT_TRUE(blas != nullptr);\n-  std::string version;\n-  ASSERT_TRUE(blas->GetVersion(&version).ok());\n-  VLOG(0) << \"Blas version: \" << version;\n-  ASSERT_TRUE(!version.empty());\n-}\n-\n-TEST_P(GemmAlgorithmPickerTest, SkipAlgorithmsWithAccuracyCheck) {\n-  constexpr absl::string_view kHlo = R\"(\n-HloModule module\n-\n-ENTRY main {\n-  %arg0 = f32[100,100]{1,0} parameter(0)\n-  %arg1 = f32[100,100]{1,0} parameter(1)\n-  ROOT %dot = f32[100,100]{1,0} dot(arg0, arg1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-})\";\n-\n-  auto module_cfg = GetModuleConfigForTest();\n-  auto debug_opts = module_cfg.debug_options();\n-  size_t num_left1 = 0, num_left2 = 0;\n-\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(kHlo, module_cfg));\n-\n-  {\n-    // Run first with default settings (autotune level = 4), keep the number of\n-    // algorithms left after autotuning\n-    TF_ASSERT_OK_AND_ASSIGN(\n-        bool changed,\n-        RunHloPass(\n-            GemmRewriter(\n-                gpu_comp(),\n-                /*toolkit_version=*/stream_executor::SemanticVersion{12, 4, 0}),\n-            module.get()));\n-\n-    AutotuneConfig cfg = AutotuneConfig::FromDebugOptions(\n-        DeviceOrDevicelessConfig{DeviceConfig{stream_exec(), nullptr}},\n-        debug_opts);\n-    GemmAlgorithmPicker gpicker(cfg);\n-    // Note that, we do not care if the algorithm index has been changed:\n-    // the thing matters is the # of algorithms left after sorting out.\n-    TF_ASSERT_OK_AND_ASSIGN(changed, RunHloPass(gpicker, module.get()));\n-    num_left1 = gpicker.num_algorithms_left();\n-    if (num_left1 < 2) {\n-      GTEST_SKIP() << \"Too few algorithms left after the first step\";\n-    }\n-\n-    // Test that the function to get current stream value works fine:\n-    auto* blas = stream_exec()->AsBlas();\n-    ASSERT_TRUE(blas != nullptr);\n-    TF_ASSERT_OK_AND_ASSIGN(bool is_main_stream, blas->IsMainStreamSet());\n-    // ROCM only: CUDA blas API does not reset stream after each blas call.\n-    if (std::holds_alternative<se::RocmComputeCapability>(gpu_comp())) {\n-      ASSERT_TRUE(is_main_stream);\n-    }\n-  }\n-\n-  // Clear cache before the second run!\n-  AutotunerUtil::ClearAutotuneResults();\n-  {\n-    // Run once again but now with autotune level 5 and embarrassingly tight\n-    // rtol which shall disqualify most of the algorithms.\n-\n-    // Note that, we have \"two sources of truth\" for GemmAlgorithmPicker: i.e.,\n-    // debug_options are used to initialize both 'HloModuleConfig' and also\n-    // 'AutotuneConfig'.\n-    debug_opts.set_xla_gpu_autotune_gemm_rtol(1e-12);\n-    debug_opts.set_xla_gpu_autotune_level(5);\n-    module->mutable_config().set_debug_options(debug_opts);\n-    TF_ASSERT_OK_AND_ASSIGN(\n-        bool changed,\n-        RunHloPass(\n-            GemmRewriter(\n-                gpu_comp(),\n-                /*toolkit_version=*/stream_executor::SemanticVersion{12, 4, 0}),\n-            module.get()));\n-\n-    AutotuneConfig cfg = AutotuneConfig::FromDebugOptions(\n-        DeviceOrDevicelessConfig{DeviceConfig{stream_exec(), nullptr}},\n-        debug_opts);\n-    GemmAlgorithmPicker gpicker(cfg);\n-    TF_ASSERT_OK_AND_ASSIGN(changed, RunHloPass(gpicker, module.get()));\n-    num_left2 = gpicker.num_algorithms_left();\n-  }\n-  // Assert that we have fewer algorithms left after the second run.\n-  ASSERT_TRUE(num_left1 > num_left2);\n-}\n-\n-TEST_P(GemmAlgorithmPickerTest, SetAlgorithm) {\n-  constexpr absl::string_view kHlo = R\"(\n-HloModule module\n-\n-ENTRY main {\n-  %arg0 = f32[100,100]{1,0} parameter(0)\n-  %arg1 = f32[100,100]{1,0} parameter(1)\n-  ROOT %dot = f32[100,100]{1,0} dot(arg0, arg1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-})\";\n-\n-  auto module_cfg = GetModuleConfigForTest();\n-  TF_ASSERT_OK_AND_ASSIGN(auto m,\n-                          ParseAndReturnVerifiedModule(kHlo, module_cfg));\n-\n-  bool changed = false;\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      changed,\n-      RunHloPass(\n-          GemmRewriter(\n-              gpu_comp(),\n-              /*toolkit_version=*/stream_executor::SemanticVersion{12, 4, 0}),\n-          m.get()));\n-  changed = false;\n-  DebugOptions opts;\n-  AutotuneConfig cfg = AutotuneConfig::FromDebugOptions(\n-      DeviceOrDevicelessConfig{DeviceConfig{stream_exec(), nullptr}}, opts);\n-  TF_ASSERT_OK_AND_ASSIGN(changed,\n-                          RunHloPass(GemmAlgorithmPicker(cfg), m.get()));\n-  ASSERT_TRUE(changed);\n-\n-  AutotuneResults results;\n-  TF_ASSERT_OK(AutotunerUtil::SerializeAutotuneResults(&results));\n-  ASSERT_EQ(results.results_size(), 1);\n-  auto& result = *results.mutable_results(0)->mutable_result();\n-  int64_t old_algo_id = result.algorithm().algo_id();\n-  int64_t new_algo_id = old_algo_id + 1;\n-  result.mutable_gemm()->set_algorithm(new_algo_id);\n-\n-  AutotunerUtil::ClearAutotuneResults();\n-  TF_ASSERT_OK(AutotunerUtil::LoadAutotuneResults(results));\n-\n-  // Now send the same module through GemmAlgorithmPicker again.  The dot should\n-  // have the new algorithm.\n-  TF_ASSERT_OK_AND_ASSIGN(m, ParseAndReturnVerifiedModule(kHlo, module_cfg));\n-  changed = false;\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      changed,\n-      RunHloPass(\n-          GemmRewriter(gpu_comp(),\n-                       /*toolkit_version=*/se::SemanticVersion{12, 4, 0}),\n-          m.get()));\n-  changed = false;\n-  TF_ASSERT_OK_AND_ASSIGN(changed,\n-                          RunHloPass(GemmAlgorithmPicker(cfg), m.get()));\n-  ASSERT_TRUE(changed);\n-\n-  SCOPED_TRACE(m->ToString());\n-  HloInstruction* dot;\n-  ASSERT_THAT(m->entry_computation()->root_instruction(),\n-              GmockMatch(m::GetTupleElement(m::CustomCall(&dot), 0)));\n-\n-  TF_ASSERT_OK_AND_ASSIGN(GpuBackendConfig gpu_config,\n-                          dot->backend_config<GpuBackendConfig>());\n-  const GemmBackendConfig& config = gpu_config.gemm_backend_config();\n-  EXPECT_EQ(config.selected_algorithm(), new_algo_id);\n-}\n-\n-TEST_P(GemmAlgorithmPickerTest, GetAlgorithmWithoutDevice) {\n-  constexpr absl::string_view kHlo = R\"(\n-HloModule module\n-\n-ENTRY main {\n-  %arg0 = f32[100,100]{1,0} parameter(0)\n-  %arg1 = f32[100,100]{1,0} parameter(1)\n-  ROOT %dot = f32[100,100]{1,0} dot(arg0, arg1), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-})\";\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      auto m, ParseAndReturnVerifiedModule(kHlo, GetModuleConfigForTest()));\n-\n-  bool changed = false;\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      changed,\n-      RunHloPass(\n-          GemmRewriter(\n-              gpu_comp(),\n-              /*toolkit_version=*/stream_executor::SemanticVersion{12, 4, 0}),\n-          m.get()));\n-  changed = false;\n-\n-  DebugOptions opts;\n-  AutotuneConfig cfg = AutotuneConfig::FromDebugOptions(\n-      DeviceOrDevicelessConfig{DeviceConfig{stream_exec(), nullptr}}, opts);\n-\n-  TF_ASSERT_OK_AND_ASSIGN(changed,\n-                          RunHloPass(GemmAlgorithmPicker(cfg), m.get()));\n-  ASSERT_TRUE(changed);\n-\n-  AutotuneResults results;\n-  TF_ASSERT_OK(AutotunerUtil::SerializeAutotuneResults(&results));\n-  ASSERT_EQ(results.results_size(), 1);\n-  auto& result = *results.mutable_results(0)->mutable_result();\n-  int64_t old_algo_id = result.algorithm().algo_id();\n-  int64_t new_algo_id = old_algo_id + 1;\n-  result.mutable_gemm()->set_algorithm(new_algo_id);\n-\n-  AutotunerUtil::ClearAutotuneResults();\n-  TF_ASSERT_OK(AutotunerUtil::LoadAutotuneResults(results));\n-\n-  auto module_cfg = GetModuleConfigForTest();\n-  // Now send the same module through GemmAlgorithmPicker again.  The dot should\n-  // have the new algorithm.\n-  TF_ASSERT_OK_AND_ASSIGN(m, ParseAndReturnVerifiedModule(kHlo, module_cfg));\n-  changed = false;\n-\n-  DevicelessConfig deviceless_config{device_desc()};\n-  AutotuneConfig deviceless_cfg = AutotuneConfig::FromDebugOptions(\n-      DeviceOrDevicelessConfig{deviceless_config}, opts);\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      changed,\n-      RunHloPass(\n-          GemmRewriter(\n-              gpu_comp(),\n-              /*toolkit_version=*/stream_executor::SemanticVersion{12, 4, 0}),\n-          m.get()));\n-  changed = false;\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      changed, RunHloPass(GemmAlgorithmPicker(deviceless_cfg), m.get()))\n-  ASSERT_TRUE(changed);\n-\n-  SCOPED_TRACE(m->ToString());\n-  HloInstruction* dot;\n-\n-  ASSERT_THAT(m->entry_computation()->root_instruction(),\n-              GmockMatch(m::GetTupleElement(m::CustomCall(&dot), 0)));\n-\n-  TF_ASSERT_OK_AND_ASSIGN(GpuBackendConfig gpu_config,\n-                          dot->backend_config<GpuBackendConfig>());\n-  const GemmBackendConfig& config = gpu_config.gemm_backend_config();\n-\n-  EXPECT_EQ(config.selected_algorithm(), new_algo_id);\n-}\n-\n-INSTANTIATE_TEST_SUITE_P(GemmAlgorithmPickerTestSuite, GemmAlgorithmPickerTest,\n-                         ::testing::Bool());\n-\n-}  // namespace\n-}  // namespace xla::gpu"
        },
        {
            "sha": "ba3bff99166c770e0bf67c1a79f2838036a32356",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 7,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1229,12 +1229,8 @@ void AddCollectiveCombinerPasses(\n     const GpuCompiler::CompileOptions& options) {\n   const DebugOptions& opts = module.config().debug_options();\n \n-  bool enable_heuristic_collective_combining =\n-      opts.xla_gpu_experimental_enable_heuristic_collective_combining() &&\n-      !IsNVLinkConnected(module.config(), device_description,\n-                         options.slice_size);\n-\n-  if (enable_heuristic_collective_combining) {\n+  if (EnableHeuristicCollectiveCombining(module.config(), device_description,\n+                                         options.slice_size)) {\n     pipeline.AddPass<CollectiveCombinerAnnotator>(device_description,\n                                                   alias_info, pointer_size);\n   }\n@@ -1601,6 +1597,13 @@ absl::Status GpuCompiler::OptimizeHloModule(\n       RunCollectiveScheduleLinearizerPasses(hlo_module, stream_exec));\n \n   TF_RETURN_IF_ERROR(RunAsyncDotPasses(hlo_module));\n+  {\n+    HloPassPipeline pipeline(\"autotune-fusion-emitters\");\n+    TF_RETURN_IF_ERROR(AddFusionAutotuningPass(\n+        &pipeline, hlo_module, options, thread_pool.get_mutable(), stream_exec,\n+        ShapeSizeBytesFunction()));\n+    TF_RETURN_IF_ERROR(pipeline.Run(hlo_module).status());\n+  }\n \n   return absl::OkStatus();\n }  // NOLINT(readability/fn_size)\n@@ -2927,8 +2930,18 @@ absl::Status GpuCompiler::RunPostSchedulingPipelines(\n       CreateHloAnalysisOpts(*module, gpu_device_info, ShapeSizeBytesFunction());\n   HloCostAnalysis hlo_cost_analysis(hlo_cost_analysis_opts);\n   // `HloRematerialization` options initialization.\n+  // `scheduler_mem_limit` cannot directly be reused for HloRematerialization.\n+  // It reduces the memory limit by the size of the output, which is done again\n+  // in HloRematerialization. So to account for that, add back the size of the\n+  // output.\n+  int64_t remat_mem_limit = scheduler_mem_limit;\n+  ShapeUtil::ForEachSubshape(\n+      module->result_shape(),\n+      [&](const Shape& subshape, const ShapeIndex& /*index*/) {\n+        remat_mem_limit += ShapeSizeBytesFunction()(subshape);\n+      });\n   HloRematerialization::Options remat_opts = CreateRematOpts(\n-      *module, gpu_device_info, hlo_cost_analysis, scheduler_mem_limit);\n+      *module, gpu_device_info, hlo_cost_analysis, remat_mem_limit);\n   {\n     HloPassPipeline& pipeline =\n         main_pipeline.AddPass<HloPassPipeline>(\"remat-pipeline\");"
        },
        {
            "sha": "6ed4274dadc248bbd57d777a4f3353bde99530dd",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -49,6 +49,7 @@ limitations under the License.\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n #include \"tsl/platform/threadpool.h\"\n@@ -180,6 +181,14 @@ class GpuCompiler : public LLVMCompiler {\n     return absl::OkStatus();\n   }\n \n+  virtual absl::Status AddFusionAutotuningPass(\n+      HloPassPipeline* pipeline, HloModule* hlo_module,\n+      const CompileOptions& options, tsl::thread::ThreadPool* thread_pool,\n+      stream_executor::StreamExecutor* stream_executor,\n+      HloCostAnalysis::ShapeSizeFunction shape_size_fn) {\n+    return absl::OkStatus();\n+  }\n+\n   // Runs cuDNN fusion and custom call compiler passes.\n   virtual absl::Status RunCudnnCompilerPasses(HloModule* module,\n                                               se::StreamExecutor* stream_exec,"
        },
        {
            "sha": "0842e2fb678f66bebd6c8393260e9d79c30755a5",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/annotation.h\"\n@@ -120,7 +121,7 @@ class GpuExecutable : public Executable {\n   // This should be called after set_ir_module_string.\n   const std::string& ir_module_string() const { return ir_module_string_; }\n \n-  const std::string& module_name() const { return module_name_; }\n+  absl::string_view name() const override { return module_name_; }\n \n   xla::Shape result_shape() const override { return program_shape_.result(); }\n "
        },
        {
            "sha": "983bda47d5a7af2866dec082bfaf7cac98e008f1",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -174,5 +174,16 @@ TEST(GpuExecutableTest, ComputeComputationLayout) {\n             ShapeLayout(ShapeUtil::MakeShape(F64, {2})));\n }\n \n+TEST(GpuExecutableTest, ExecutableName) {\n+  GpuExecutable::Params params;\n+  params.module_name = \"test_module\";\n+  params.executable =\n+      std::make_unique<SequentialThunk>(Thunk::ThunkInfo{}, ThunkSequence{});\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<GpuExecutable> executable,\n+                          GpuExecutable::Create(std::move(params)));\n+  EXPECT_THAT(executable->name(), \"test_module\");\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "8b1e5ee5874aada474bba137315143dfcc072134",
            "filename": "third_party/xla/xla/service/gpu/gpu_spmd_pipeline.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_spmd_pipeline.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,9 +17,12 @@ limitations under the License.\n \n #include <cstdint>\n #include <optional>\n+#include <string>\n \n+#include \"absl/container/flat_hash_set.h\"\n #include \"absl/functional/function_ref.h\"\n #include \"absl/log/check.h\"\n+#include \"absl/strings/match.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_schedule.h\"\n@@ -32,13 +35,16 @@ limitations under the License.\n #include \"xla/hlo/transforms/simplifiers/reshape_mover.h\"\n #include \"xla/hlo/transforms/simplifiers/sort_simplifier.h\"\n #include \"xla/hlo/transforms/simplifiers/tuple_simplifier.h\"\n+#include \"xla/service/call_graph.h\"\n+#include \"xla/service/call_inliner.h\"\n #include \"xla/service/conditional_simplifier.h\"\n #include \"xla/service/gather_expander.h\"\n #include \"xla/service/gpu/transforms/algebraic_simplifier.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/scatter_expander.h\"\n #include \"xla/service/sharding_propagation.h\"\n #include \"xla/service/spmd/collective_permute_motion.h\"\n+#include \"xla/service/spmd/shardy/constants.h\"\n #include \"xla/service/spmd/shardy/shardy_xla_pass.h\"\n #include \"xla/service/spmd/stateful_rng_spmd_partitioner.h\"\n #include \"xla/service/while_loop_constant_sinking.h\"\n@@ -128,6 +134,20 @@ void AddSPMDPasses(\n       /*disable_ag_rewrite_for_multiple_consumers=*/true,\n       /*enable_partial_windowed_einsums=*/true, oper_size_threshold,\n       max_windowed_einsum_iteration);\n+  // NOTE: even though the inliner is called in `RunPreSPMDPartitionerPasses`,\n+  // it doesn't inline functions needed for ShardyXLA. ShardyXLA will also leave\n+  // functions called `kInlineableManualComputationFuncName` not inlined, so\n+  // we need to call the inliner again here.\n+  spmd_pipeline.AddPass<xla::CallInliner>(\n+      /*single_call_site=*/false,\n+      /*update_domain=*/false,\n+      /*composites_to_preserve=*/absl::flat_hash_set<std::string>{},\n+      /*uniquify_channel_ids=*/false,\n+      /*should_inline=*/\n+      [](const xla::CallGraph& call_graph, xla::HloInstruction* instruction) {\n+        return absl::StrContains(instruction->to_apply()->name(),\n+                                 sdy::kInlineableManualComputationFuncName);\n+      });\n   spmd_pipeline.AddPass<CollectivePermuteMotion>();\n }\n "
        },
        {
            "sha": "fb17d23a340bbff85f4c459b3d4f8a7195efdd17",
            "filename": "third_party/xla/xla/service/gpu/model/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -787,7 +787,6 @@ cc_library(\n         \":symbolic_tiled_hlo_instruction\",\n         \":tiled_hlo_instruction_or_computation\",\n         \"//xla:shape_util\",\n-        \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla/hlo/analysis:indexing_analysis\",\n         \"//xla/hlo/ir:hlo\",\n@@ -809,7 +808,6 @@ cc_library(\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:IR\",\n@@ -835,7 +833,6 @@ xla_cc_test(\n         \"//xla/service:instruction_fusion\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -976,10 +973,11 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:hlo_proto_cc\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/strings\",\n-        \"@local_tsl//tsl/platform:logging\",\n         \"@local_tsl//tsl/platform:protobuf\",\n     ],\n )\n@@ -1020,6 +1018,8 @@ cc_library(\n         \"//xla/service:interpreter_plugin\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tests:test_utils\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status:statusor\","
        },
        {
            "sha": "9dcf72827b51f4d45e3a9bb00a5e969c295c97de",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_expr.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 7,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <cmath>\n #include <cstddef>\n #include <cstdint>\n+#include <functional>\n #include <numeric>\n #include <optional>\n #include <string>\n@@ -561,16 +562,12 @@ int64_t SymbolicExpr::GetValue() const { return impl_->value_; }\n \n bool SymbolicExpr::operator<(const SymbolicExpr& other) const {\n   CHECK(*this && other);\n+  if (this == &other) {\n+    return false;\n+  }\n   SymbolicExprType lhs_type = GetType();\n   SymbolicExprType rhs_type = other.GetType();\n \n-  const bool lhs_is_const = (lhs_type == SymbolicExprType::kConstant);\n-  const bool rhs_is_const = (rhs_type == SymbolicExprType::kConstant);\n-  if (lhs_is_const != rhs_is_const) {\n-    // Non-constants come before constants.\n-    return rhs_is_const;\n-  }\n-\n   if (lhs_type != rhs_type) {\n     return lhs_type < rhs_type;\n   }\n@@ -581,6 +578,11 @@ bool SymbolicExpr::operator<(const SymbolicExpr& other) const {\n       return GetValue() < other.GetValue();\n     case SymbolicExprType::kAdd:\n     case SymbolicExprType::kMul:\n+    case SymbolicExprType::kFloorDiv:\n+    case SymbolicExprType::kCeilDiv:\n+    case SymbolicExprType::kMod:\n+    case SymbolicExprType::kMax:\n+    case SymbolicExprType::kMin:\n       if (GetLHS() != other.GetLHS()) {\n         return GetLHS() < other.GetLHS();\n       }\n@@ -902,5 +904,29 @@ SymbolicExpr SymbolicExprContext::Parse(absl::string_view expr_str) {\n   return Parser(expr_str, this).Parse();\n }\n \n+void SymbolicExpr::Walk(\n+    const std::function<void(SymbolicExpr)>& callback) const {\n+  if (!*this) {\n+    return;\n+  }\n+\n+  switch (GetType()) {\n+    case SymbolicExprType::kConstant:\n+    case SymbolicExprType::kVariable:\n+      break;\n+    case SymbolicExprType::kAdd:\n+    case SymbolicExprType::kMul:\n+    case SymbolicExprType::kFloorDiv:\n+    case SymbolicExprType::kCeilDiv:\n+    case SymbolicExprType::kMod:\n+    case SymbolicExprType::kMin:\n+    case SymbolicExprType::kMax:\n+      GetLHS().Walk(callback);\n+      GetRHS().Walk(callback);\n+      break;\n+  }\n+  callback(*this);\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "134205625f149d8b03ef0c841b3b8d2a0306dc3e",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_expr.h",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_SERVICE_GPU_MODEL_EXPERIMENTAL_SYMBOLIC_EXPR_H_\n \n #include <cstdint>\n+#include <functional>\n #include <string>\n \n #include \"absl/strings/string_view.h\"\n@@ -37,15 +38,15 @@ class SymbolicExprStorage;\n typedef int64_t VariableID;\n \n enum class SymbolicExprType {\n-  kConstant,\n-  kVariable,\n   kAdd,\n   kMul,\n+  kMod,\n   kFloorDiv,\n   kCeilDiv,\n-  kMod,\n   kMax,\n   kMin,\n+  kVariable,\n+  kConstant,  // Constant should be the last type for the comparator.\n   // TODO(karupayun): Add kIn operator.\n   // kIn,  // 'var in [a, b]' .\n };\n@@ -86,6 +87,10 @@ class SymbolicExpr {\n \n   void GetUsedVariables(llvm::DenseSet<VariableID>& used_vars) const;\n \n+  // Traverses the expression tree and calls the callback for each\n+  // subexpression in postorder.\n+  void Walk(const std::function<void(SymbolicExpr)>& callback) const;\n+\n   SymbolicExpr operator+(int64_t v) const;\n   SymbolicExpr operator+(SymbolicExpr other) const;\n   SymbolicExpr operator-() const;"
        },
        {
            "sha": "6c53efb39ed2c4a7367fab7f847177d4691e9f6c",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_expr_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_expr_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -266,6 +266,15 @@ TEST_F(SymbolicExprTest, Canonicalization_DivMod) {\n   EXPECT_EQ(((v0 * 6).ceilDiv(-3)).Canonicalize().ToString(), \"(v0 * -2)\");\n }\n \n+TEST_F(SymbolicExprTest, Walk) {\n+  SymbolicExpr expr = (v0 + 42) * v1;\n+  std::vector<std::string> visited_exprs;\n+  expr.Walk([&](SymbolicExpr e) { visited_exprs.push_back(e.ToString()); });\n+\n+  EXPECT_THAT(visited_exprs, ::testing::ElementsAre(\"v0\", \"42\", \"(v0 + 42)\",\n+                                                    \"v1\", \"((v0 + 42) * v1)\"));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "6f8cc928f0d82c66eaabd1ca3f2b08a1ec4b3ddd",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_map.cc",
            "status": "modified",
            "additions": 82,
            "deletions": 0,
            "changes": 82,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/service/gpu/model/experimental/symbolic_map.h\"\n \n+#include <cstddef>\n #include <cstdint>\n #include <iterator>\n #include <string>\n@@ -170,6 +171,17 @@ SymbolicMap SymbolicMap::Compose(const SymbolicMap& other) const {\n                                this_symbol_replacements, new_dims, new_syms);\n }\n \n+SymbolicMap SymbolicMap::GetSubMap(\n+    absl::Span<const size_t> result_indices) const {\n+  llvm::SmallVector<SymbolicExpr> sub_exprs;\n+  sub_exprs.reserve(result_indices.size());\n+  for (unsigned int index : result_indices) {\n+    CHECK_LT(index, exprs_.size()) << \"Result index out of bounds\";\n+    sub_exprs.push_back(exprs_[index]);\n+  }\n+  return SymbolicMap(ctx_, num_dimensions_, num_symbols_, std::move(sub_exprs));\n+}\n+\n SymbolicMap SymbolicMap::Replace(SymbolicExpr expr,\n                                  SymbolicExpr replacement) const {\n   llvm::SmallVector<SymbolicExpr> new_exprs;\n@@ -223,5 +235,75 @@ llvm::SmallBitVector GetUnusedSymbolsBitVector(const SymbolicMap& map) {\n   return unused_symbols;\n }\n \n+SymbolicMap CompressDims(const SymbolicMap& map,\n+                         const llvm::SmallBitVector& unused_dims) {\n+  CHECK_EQ(map.GetNumDims(), unused_dims.size());\n+\n+  if (unused_dims.none()) {\n+    return map;\n+  }\n+\n+  // Assert that all dimensions marked as unused are actually unused.\n+  llvm::SmallBitVector actual_unused_dims = GetUnusedDimensionsBitVector(map);\n+  for (int i = 0; i < map.GetNumDims(); ++i) {\n+    if (unused_dims[i]) {\n+      CHECK(actual_unused_dims[i])\n+          << \"Attempting to compress a used dimension: \" << i;\n+    }\n+  }\n+\n+  int64_t new_num_dims = map.GetNumDims() - unused_dims.count();\n+  llvm::SmallVector<SymbolicExpr> dim_replacements(map.GetNumDims());\n+\n+  int64_t current_new_dim_idx = 0;\n+  for (int i = 0; i < map.GetNumDims(); ++i) {\n+    if (!unused_dims[i]) {\n+      dim_replacements[i] =\n+          map.GetContext()->CreateVariable(current_new_dim_idx++);\n+    }\n+  }\n+  auto sym_replacements =\n+      CreateVariableRange(map.GetContext(), map.GetNumSymbols(), new_num_dims);\n+\n+  return map.ReplaceDimsAndSymbols(dim_replacements, sym_replacements,\n+                                   new_num_dims, map.GetNumSymbols());\n+}\n+\n+SymbolicMap CompressSymbols(const SymbolicMap& map,\n+                            const llvm::SmallBitVector& unused_symbols) {\n+  CHECK_EQ(map.GetNumSymbols(), unused_symbols.size());\n+\n+  if (unused_symbols.none()) {\n+    return map;\n+  }\n+\n+  // Assert that all symbols marked as unused are actually unused.\n+  llvm::SmallBitVector actual_unused_symbols = GetUnusedSymbolsBitVector(map);\n+  for (int i = 0; i < map.GetNumSymbols(); ++i) {\n+    if (unused_symbols[i]) {\n+      CHECK(actual_unused_symbols[i])\n+          << \"Attempting to compress a used symbol: \" << i;\n+    }\n+  }\n+\n+  int64_t num_dims = map.GetNumDims();\n+  int64_t new_num_symbols = map.GetNumSymbols() - unused_symbols.count();\n+\n+  auto dim_replacements = CreateVariableRange(map.GetContext(), num_dims);\n+\n+  llvm::SmallVector<SymbolicExpr> sym_replacements(map.GetNumSymbols());\n+  int64_t current_new_sym_idx = 0;\n+  for (int i = 0; i < map.GetNumSymbols(); ++i) {\n+    if (!unused_symbols[i]) {\n+      sym_replacements[i] =\n+          map.GetContext()->CreateVariable(num_dims + current_new_sym_idx++);\n+    }\n+  }\n+  CHECK_EQ(current_new_sym_idx, new_num_symbols);\n+\n+  return map.ReplaceDimsAndSymbols(dim_replacements, sym_replacements, num_dims,\n+                                   new_num_symbols);\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "44811dfd299a479dd8ccf12c513eaf98cd8edbb3",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_map.h",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_MODEL_EXPERIMENTAL_SYMBOLIC_MAP_H_\n #define XLA_SERVICE_GPU_MODEL_EXPERIMENTAL_SYMBOLIC_MAP_H_\n \n+#include <cstddef>\n #include <cstdint>\n #include <string>\n \n@@ -39,6 +40,12 @@ class SymbolicMap {\n   SymbolicExprContext* GetContext() const { return ctx_; }\n   int64_t GetNumDims() const { return num_dimensions_; }\n   int64_t GetNumSymbols() const { return num_symbols_; }\n+  SymbolicExpr GetDimExpression(unsigned idx) const {\n+    return ctx_->CreateVariable(idx);\n+  }\n+  SymbolicExpr GetSymbolExpression(unsigned idx) const {\n+    return ctx_->CreateVariable(num_dimensions_ + idx);\n+  }\n   int64_t GetNumResults() const { return exprs_.size(); }\n   const llvm::SmallVector<SymbolicExpr>& GetResults() const { return exprs_; }\n   SymbolicExpr GetResult(unsigned idx) const { return exprs_[idx]; }\n@@ -82,6 +89,9 @@ class SymbolicMap {\n   // this.compose(other): (d0, s0, s1, s2) -> (d0 * 2 + 3 * s1 + s0, d0 + s2)\n   SymbolicMap Compose(const SymbolicMap& other) const;\n \n+  // Creates a new SymbolicMap with a subset of the results of this map.\n+  SymbolicMap GetSubMap(absl::Span<const size_t> result_indices) const;\n+\n   SymbolicMap Replace(SymbolicExpr expr, SymbolicExpr replacement) const;\n \n   bool operator==(const SymbolicMap& other) const;\n@@ -110,6 +120,16 @@ llvm::SmallBitVector GetUnusedDimensionsBitVector(const SymbolicMap& map);\n // the map.\n llvm::SmallBitVector GetUnusedSymbolsBitVector(const SymbolicMap& map);\n \n+// Creates a new SymbolicMap with unused dimensions removed.\n+// Expressions are updated to use the new dimension indices.\n+SymbolicMap CompressDims(const SymbolicMap& map,\n+                         const llvm::SmallBitVector& unused_dims);\n+\n+// Creates a new SymbolicMap with unused symbols removed.\n+// Expressions are updated to use the new symbol indices.\n+SymbolicMap CompressSymbols(const SymbolicMap& map,\n+                            const llvm::SmallBitVector& unused_symbols);\n+\n }  // namespace gpu\n }  // namespace xla\n "
        },
        {
            "sha": "2d8df62429469f3cac0258f617b3426c1d2d63a9",
            "filename": "third_party/xla/xla/service/gpu/model/experimental/symbolic_map_test.cc",
            "status": "modified",
            "additions": 73,
            "deletions": 0,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fexperimental%2Fsymbolic_map_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -26,6 +26,19 @@ namespace {\n \n using ::testing::ElementsAre;\n \n+TEST(SymbolicMapTest, GetSymbolAndDimExpressions) {\n+  SymbolicExprContext ctx;\n+  SymbolicExpr d0 = ctx.CreateVariable(0);\n+  SymbolicExpr d1 = ctx.CreateVariable(1);\n+  SymbolicExpr s0 = ctx.CreateVariable(2);\n+  SymbolicExpr s1 = ctx.CreateVariable(3);\n+  SymbolicMap map = SymbolicMap::Get(&ctx, 2, 2, {d0 + s0, d1 * s1});\n+  EXPECT_EQ(map.GetSymbolExpression(0), s0);\n+  EXPECT_EQ(map.GetSymbolExpression(1), s1);\n+  EXPECT_EQ(map.GetDimExpression(0), d0);\n+  EXPECT_EQ(map.GetDimExpression(1), d1);\n+}\n+\n TEST(SymbolicMapTest, ToString) {\n   SymbolicExprContext ctx;\n   SymbolicExpr d0 = ctx.CreateVariable(0);\n@@ -262,6 +275,66 @@ TEST(SymbolicMapTest, GetUnusedVariables) {\n   EXPECT_FALSE(no_dim_symbols[1]);\n }\n \n+TEST(SymbolicMapTest, CompressDims) {\n+  SymbolicExprContext ctx;\n+  SymbolicExpr d0 = ctx.CreateVariable(0);\n+  [[maybe_unused]] SymbolicExpr d1 = ctx.CreateVariable(1);  // Unused\n+  SymbolicExpr d2 = ctx.CreateVariable(2);\n+  SymbolicExpr s0 = ctx.CreateVariable(3);\n+\n+  // Map: (d0, d1, d2)[s0] -> {d0 + d2, s0 * 5}\n+  SymbolicMap map = SymbolicMap::Get(&ctx, 3, 1, {d0 + d2, s0 * 5});\n+\n+  // Remove d1\n+  llvm::SmallBitVector unused_dims = GetUnusedDimensionsBitVector(map);\n+  SymbolicMap compressed = CompressDims(map, unused_dims);\n+\n+  EXPECT_EQ(compressed.GetNumDims(), 2);\n+  EXPECT_EQ(compressed.GetNumSymbols(), 1);\n+\n+  SymbolicExpr new_d0 = ctx.CreateVariable(0);\n+  SymbolicExpr new_d1 = ctx.CreateVariable(1);\n+  SymbolicExpr new_s0 = ctx.CreateVariable(2);\n+  EXPECT_THAT(compressed.GetResults(),\n+              ElementsAre(new_d0 + new_d1, new_s0 * 5));\n+\n+  // Check that we can't remove used dimensions.\n+  unused_dims.reset();\n+  unused_dims[0] = true;\n+  EXPECT_DEATH(CompressDims(map, unused_dims),\n+               \"Attempting to compress a used dimension: 0\");\n+}\n+\n+TEST(SymbolicMapTest, CompressSymbols) {\n+  SymbolicExprContext ctx;\n+  SymbolicExpr d0 = ctx.CreateVariable(0);\n+  SymbolicExpr s0 = ctx.CreateVariable(1);\n+  [[maybe_unused]] SymbolicExpr s1 = ctx.CreateVariable(2);  // Unused\n+  SymbolicExpr s2 = ctx.CreateVariable(3);\n+\n+  // Map: (d0)[s0, s1, s2] -> {d0 + s2, s0 * 5}\n+  SymbolicMap map = SymbolicMap::Get(&ctx, 1, 3, {d0 + s2, s0 * 5});\n+\n+  // Remove s1 (the only unused symbol)\n+  llvm::SmallBitVector unused_symbols = GetUnusedSymbolsBitVector(map);\n+  SymbolicMap compressed = CompressSymbols(map, unused_symbols);\n+\n+  EXPECT_EQ(compressed.GetNumDims(), 1);\n+  EXPECT_EQ(compressed.GetNumSymbols(), 2);\n+\n+  SymbolicExpr new_d0 = ctx.CreateVariable(0);\n+  SymbolicExpr new_s0 = ctx.CreateVariable(1);\n+  SymbolicExpr new_s1 = ctx.CreateVariable(2);  // Original s2\n+  EXPECT_THAT(compressed.GetResults(),\n+              ElementsAre(new_d0 + new_s1, new_s0 * 5));\n+\n+  // Check that we can't remove used symbols.\n+  unused_symbols.reset();\n+  unused_symbols[2] = true;\n+  EXPECT_DEATH(CompressSymbols(map, unused_symbols),\n+               \"Attempting to compress a used symbol: 2\");\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "b9e3bcd81e80a13ce228eecbc5e84348b186320c",
            "filename": "third_party/xla/xla/service/gpu/model/hlo_op_profiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -42,10 +42,10 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tests/test_utils.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/statusor.h\"\n \n #ifdef GOOGLE_CUDA\n #include \"xla/backends/profiler/gpu/cupti_collector.h\""
        },
        {
            "sha": "e280890141cb620ba4c17562df0efde571c090fd",
            "filename": "third_party/xla/xla/service/gpu/model/hlo_op_profiles.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -20,13 +20,14 @@ limitations under the License.\n #include <utility>\n #include <variant>\n \n+#include \"absl/log/check.h\"\n #include \"absl/memory/memory.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/gpu/model/hlo_op_profile.pb.h\"\n #include \"xla/service/gpu/model/hlo_op_profiles_data.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"tsl/platform/logging.h\"\n #include \"tsl/platform/protobuf.h\"\n \n namespace xla {\n@@ -54,8 +55,8 @@ namespace gpu {\n     absl::string_view default_profile_name) {\n   ProfilesNestedMap profiles_map;\n   DeviceHloInstructionProfiles all_device_profiles;\n-  CHECK(tsl::protobuf::TextFormat::ParseFromString(\n-      std::string(profiles_text_proto), &all_device_profiles));\n+  CHECK(tsl::protobuf::TextFormat::ParseFromString(profiles_text_proto,\n+                                                   &all_device_profiles));\n   for (const auto& device_profile : all_device_profiles.entries()) {\n     for (const auto& entry : device_profile.second.entries()) {\n       auto op_code = StringToHloOpcode(entry.instruction().opcode()).value();"
        },
        {
            "sha": "94a9f1f603168e80f6961362ae2af06cb8b373a0",
            "filename": "third_party/xla/xla/service/gpu/model/hlo_op_profiles.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiles.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -22,11 +22,12 @@ limitations under the License.\n #include <utility>\n \n #include \"absl/container/flat_hash_map.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/gpu/model/hlo_op_profile.pb.h\"\n #include \"xla/service/hlo.pb.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/types.h\"\n+#include \"xla/types.h\"  // IWYU pragma: export\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {"
        },
        {
            "sha": "b4a164698c9c7df0def886787c270eea463fd358",
            "filename": "third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 20,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -129,6 +129,11 @@ struct OutputTilingInfo {\n   }\n };\n \n+bool IsSomeDot(const HloInstruction* hlo) {\n+  return hlo->opcode() == HloOpcode::kDot ||\n+         hlo->opcode() == HloOpcode::kScaledDot;\n+}\n+\n llvm::SmallVector<int64_t> GetNumberOfTilesPerDimension(\n     const TiledHloInstruction& tiled_hlo_instr) {\n   llvm::SmallVector<int64_t> result;\n@@ -605,7 +610,7 @@ bool ShouldDerivationSimplifyPointDimensions(const HloFusionAdaptor& fusion) {\n       continue;\n     }\n \n-    if (instruction_adaptor.opcode() == HloOpcode::kDot) {\n+    if (IsSomeDot(&instruction_adaptor.instruction())) {\n       return false;\n     }\n \n@@ -671,7 +676,7 @@ absl::Status PopulateNestedParameters(\n       continue;\n     }\n \n-    if (instruction_adaptor.opcode() == HloOpcode::kDot) {\n+    if (IsSomeDot(&instruction_adaptor.instruction())) {\n       int64_t num_parameters = instruction_adaptor.instruction()\n                                    .dot_dimension_numbers()\n                                    .lhs_contracting_dimensions()\n@@ -894,7 +899,7 @@ std::vector<int64_t> InputSpaceForParameterMapping(\n \n   for (const auto& [hlo, num_parameters] : parameter_mapping) {\n     // TODO(b/419026602): handle reductions.\n-    if (hlo->opcode() == HloOpcode::kDot) {\n+    if (IsSomeDot(hlo)) {\n       auto contracting_dimensions =\n           hlo->dot_dimension_numbers().lhs_contracting_dimensions();\n       // First, we need to add the contracting dimensions of the `dot`\n@@ -1044,22 +1049,36 @@ IndexingMap InsertTilingParameterForContractingDimensions(\n   // TODO(b/419026602): handle reductions here as well once priority fusion can\n   // handle it. By adding a special path for reductions, we can handle them\n   // here as well, even without nests.\n-  if (consumer->opcode() == HloOpcode::kDot) {\n-    CHECK(operand_index == 0 || operand_index == 1);\n-    absl::Span<const int64_t> contracting_dimensions =\n-        operand_index == 0\n-            ? consumer->dot_dimension_numbers().lhs_contracting_dimensions()\n-            : consumer->dot_dimension_numbers().rhs_contracting_dimensions();\n+  if (IsSomeDot(consumer)) {\n+    absl::Span<const int64_t> contracting_dimensions;\n+    if (consumer->opcode() == HloOpcode::kScaledDot) {\n+      CHECK(operand_index >= 0 && operand_index <= 3);\n+      contracting_dimensions =\n+          operand_index <= 1\n+              ? consumer->dot_dimension_numbers().lhs_contracting_dimensions()\n+              : consumer->dot_dimension_numbers().rhs_contracting_dimensions();\n+    }\n+    if (consumer->opcode() == HloOpcode::kDot) {\n+      CHECK(operand_index == 0 || operand_index == 1);\n+      contracting_dimensions =\n+          operand_index == 0\n+              ? consumer->dot_dimension_numbers().lhs_contracting_dimensions()\n+              : consumer->dot_dimension_numbers().rhs_contracting_dimensions();\n+    }\n \n     absl::flat_hash_map<int64_t, int64_t> parameter_index_by_symbol_position;\n     std::vector<int64_t> symbols_to_remove;\n     parameter_index_by_symbol_position.reserve(contracting_dimensions.size());\n     symbols_to_remove.reserve(contracting_dimensions.size());\n     for (auto [parameter_index, contracting_dimension] :\n          llvm::enumerate(contracting_dimensions)) {\n-      auto symbol = mlir::dyn_cast<mlir::AffineSymbolExpr>(\n-          outermost_fusion_root_to_operand.GetAffineMap().getResult(\n-              contracting_dimension));\n+      auto affine_map = outermost_fusion_root_to_operand.GetAffineMap();\n+      auto result = affine_map.getResults()[contracting_dimension];\n+      auto symbol = mlir::dyn_cast<mlir::AffineSymbolExpr>(result);\n+      if (!symbol) {\n+        auto binary_expr = mlir::cast<mlir::AffineBinaryOpExpr>(result);\n+        symbol = mlir::dyn_cast<mlir::AffineSymbolExpr>(binary_expr.getLHS());\n+      }\n       // This can only occur if the wrong arguments were passed to this\n       // function, and our traversal logic is broken.\n       CHECK(symbol);  // Crash OK\n@@ -1837,10 +1856,17 @@ std::string SymbolicTileAnalysis::ToString() const {\n namespace {\n \n // The possible tiles sizes for one dimension.\n-std::vector<int64_t> PossibleTileSizesForOneDimension(int64_t dim_size) {\n-  CHECK_GE(dim_size, 1);\n-\n+absl::StatusOr<std::vector<int64_t>> PossibleTileSizesForOneDimension(\n+    int64_t dim_size) {\n+  if (dim_size < 0) {\n+    return absl::InvalidArgumentError(\"Dimension size must be non-negative.\");\n+  }\n   std::vector<int64_t> result;\n+  if (dim_size == 0) {\n+    result.push_back(0);\n+    return result;\n+  }\n+\n   result.reserve(absl::bit_width(static_cast<uint64_t>(dim_size)));\n   for (int64_t tile_size = 1; tile_size < dim_size; tile_size *= 2) {\n     result.push_back(tile_size);\n@@ -1853,13 +1879,13 @@ std::vector<int64_t> PossibleTileSizesForOneDimension(int64_t dim_size) {\n \n namespace detail {\n \n-std::vector<FlatTiling> GetFlatTilingsForInputSpace(\n+absl::StatusOr<std::vector<FlatTiling>> GetFlatTilingsForInputSpace(\n     absl::Span<const int64_t> input_space) {\n   std::vector<FlatTiling> flat_tilings;\n   flat_tilings.push_back({});\n   for (int parameter_size : input_space) {\n-    std::vector<int64_t> possible_tile_sizes =\n-        PossibleTileSizesForOneDimension(parameter_size);\n+    TF_ASSIGN_OR_RETURN(std::vector<int64_t> possible_tile_sizes,\n+                        PossibleTileSizesForOneDimension(parameter_size));\n     std::vector<FlatTiling> extended_tilings;\n     extended_tilings.reserve(flat_tilings.size() * possible_tile_sizes.size());\n     for (const FlatTiling& flat_tile_sizes : flat_tilings) {\n@@ -1883,8 +1909,10 @@ absl::StatusOr<std::vector<Tiling>> SymbolicTileAnalysis::GetValidTilings()\n       tiling_specification_.parameter_mapping();\n \n   std::vector<Tiling> tilings;\n-  for (const FlatTiling& flat_tile_sizes : detail::GetFlatTilingsForInputSpace(\n-           InputSpaceForParameterMapping(parameter_mapping))) {\n+  TF_ASSIGN_OR_RETURN(std::vector<FlatTiling> flat_tilings,\n+                      detail::GetFlatTilingsForInputSpace(\n+                          InputSpaceForParameterMapping(parameter_mapping)));\n+  for (const FlatTiling& flat_tile_sizes : flat_tilings) {\n     TF_ASSIGN_OR_RETURN(\n         Tiling tiling,\n         Tiling::Unflatten(flat_tile_sizes, tiling_specification_));"
        },
        {
            "sha": "c5d6c171948cf108e917c7d37dff9237cf23613f",
            "filename": "third_party/xla/xla/service/gpu/model/symbolic_tile_analysis.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -430,7 +430,7 @@ class SymbolicTileAnalysis {\n namespace detail {\n \n // Only exposed for testing.\n-std::vector<FlatTiling> GetFlatTilingsForInputSpace(\n+absl::StatusOr<std::vector<FlatTiling>> GetFlatTilingsForInputSpace(\n     absl::Span<const int64_t> input_space);\n \n }  // namespace detail"
        },
        {
            "sha": "02cfd70fccd4970468b7ee0fc4ffaa10b20cb8f7",
            "filename": "third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",
            "status": "modified",
            "additions": 106,
            "deletions": 39,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -50,23 +50,21 @@ limitations under the License.\n #include \"xla/service/instruction_fusion.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n \n namespace xla {\n namespace gpu {\n namespace {\n \n+using absl_testing::IsOkAndHolds;\n using detail::GetFlatTilingsForInputSpace;\n using ::testing::ElementsAre;\n using ::testing::ElementsAreArray;\n using ::testing::ExplainMatchResult;\n using ::testing::IsEmpty;\n using ::testing::Matcher;\n using ::testing::Not;\n-using ::tsl::testing::IsOkAndHolds;\n-using ::tsl::testing::StatusIs;\n using TilingVector = std::vector<FlatTiling>;\n \n MATCHER_P3(MatchTiledHloInstructionImpl, tile_sizes, tile_strides,\n@@ -855,6 +853,68 @@ ENTRY main {\n   )\"));\n }\n \n+TEST_F(SymbolicTileAnalysisTest, ScaledDotOffsetIndexingIsCorrect) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+fusion {\n+  lhs = f8e4m3fn[128,64] parameter(0)\n+  lhs_scale = f8e8m0fnu[128,2] parameter(1)\n+  rhs = f8e4m3fn[64,128] parameter(2)\n+  rhs_scale = f8e8m0fnu[2,128] parameter(3)\n+  ROOT dot = f32[128,128] scaled-dot(lhs, lhs_scale, rhs, rhs_scale),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY main {\n+  p0 = f8e4m3fn[128,64] parameter(0)\n+  p1 = f8e8m0fnu[128,2] parameter(1)\n+  p2 = f8e4m3fn[64,128] parameter(2)\n+  p3 = f8e8m0fnu[2,128] parameter(3)\n+  ROOT fusion = f32[128,128] fusion(p0, p1, p2, p3), kind=kLoop, calls=fusion\n+})\"));\n+  std::optional<SymbolicTileAnalysis> analysis = TryAnalyzeModule(module.get());\n+  ASSERT_TRUE(analysis.has_value());\n+  const HloInstruction* dot_hlo =\n+      module->entry_computation()->root_instruction()->fused_expression_root();\n+  constexpr int64_t kContractingTileSize = 32;\n+  constexpr int64_t kLhsTileSize = 16;\n+  constexpr int64_t kRhsTileSize = 16;\n+  Tiling tiling(Tiling::TileMapping{\n+      {dot_hlo, {kContractingTileSize, kLhsTileSize, kRhsTileSize}}});\n+  TF_ASSERT_OK_AND_ASSIGN(TiledHloComputation tiled_hlo_computation,\n+                          analysis->ComputeTiledHloInstructions(\n+                              tiling,\n+                              /*constraints_are_known_satisfied=*/false,\n+                              /*compute_all_tile_offset_indexing_maps=*/true));\n+\n+  const TiledHloInstruction* dot = tiled_hlo_computation.GetRoots()[0];\n+  EXPECT_THAT(*dot, MatchTiledHloInstruction(\n+                        /*tile_sizes=*/{16, 16}, /*tile_strides=*/{1, 1},\n+                        /*tile_offsets_indexing=*/R\"(\n+    (pid_0) -> ((pid_0 floordiv 8) * 16, (pid_0 mod 8) * 16),\n+    domain:\n+    pid_0 in [0, 63]\n+  )\"));\n+\n+  const TiledHloInstruction* lhs = dot->operand(0);\n+  EXPECT_THAT(*lhs, MatchTiledHloInstruction(\n+                        /*tile_sizes=*/{16, 32}, /*tile_strides=*/{1, 1},\n+                        /*tile_offsets_indexing=*/R\"(\n+    (pid_0) -> ((pid_0 floordiv 8) * 16, 0),\n+    domain:\n+    pid_0 in [0, 63]\n+  )\"));\n+\n+  const TiledHloInstruction* rhs = dot->operand(2);\n+  EXPECT_THAT(*rhs, MatchTiledHloInstruction(\n+                        /*tile_sizes=*/{32, 16}, /*tile_strides=*/{1, 1},\n+                        /*tile_offsets_indexing=*/R\"(\n+    (pid_0) -> (0, (pid_0 mod 8) * 16),\n+    domain:\n+    pid_0 in [0, 63]\n+  )\"));\n+}\n+\n TEST_F(SymbolicTileAnalysisTest, DoesNotBailOutOnConstrainedReshape) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n                           ParseAndReturnVerifiedModule(R\"(\n@@ -1080,51 +1140,58 @@ ENTRY main {\n }\n \n TEST(GetValidTilingsTest, ReturnsOneTilingWhenRankIsZero) {\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({}), TilingVector{FlatTiling{}});\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({}),\n+              IsOkAndHolds(TilingVector{FlatTiling{}}));\n }\n \n TEST(GetValidTilingsTest, ReturnsPowersOfTwoAndTheDimSizeForRankOne) {\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({1}), TilingVector{{1}});\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({2}), TilingVector({{1}, {2}}));\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({3}), TilingVector({{1}, {2}, {3}}));\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({4}), TilingVector({{1}, {2}, {4}}));\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({5}),\n-            TilingVector({{1}, {2}, {4}, {5}}));\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({11}),\n-            TilingVector({{1}, {2}, {4}, {8}, {11}}));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({1}),\n+              IsOkAndHolds(TilingVector{{1}}));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({2}),\n+              IsOkAndHolds(TilingVector({{1}, {2}})));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({3}),\n+              IsOkAndHolds(TilingVector({{1}, {2}, {3}})));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({4}),\n+              IsOkAndHolds(TilingVector({{1}, {2}, {4}})));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({5}),\n+              IsOkAndHolds(TilingVector({{1}, {2}, {4}, {5}})));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({11}),\n+              IsOkAndHolds(TilingVector({{1}, {2}, {4}, {8}, {11}})));\n }\n \n TEST(GetValidTilingsTest, CreatesCartesianProductForRankTwo) {\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({3, 4}), TilingVector({{1, 1},\n-                                                               {1, 2},\n-                                                               {1, 4},\n-                                                               {2, 1},\n-                                                               {2, 2},\n-                                                               {2, 4},\n-                                                               {3, 1},\n-                                                               {3, 2},\n-                                                               {3, 4}}));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({3, 4}),\n+              IsOkAndHolds(TilingVector({{1, 1},\n+                                         {1, 2},\n+                                         {1, 4},\n+                                         {2, 1},\n+                                         {2, 2},\n+                                         {2, 4},\n+                                         {3, 1},\n+                                         {3, 2},\n+                                         {3, 4}})));\n }\n \n TEST(GetValidTilingsTest, CreatesCartesianProductForRankThree) {\n-  EXPECT_EQ(GetFlatTilingsForInputSpace({3, 4, 2}), TilingVector({{1, 1, 1},\n-                                                                  {1, 1, 2},\n-                                                                  {1, 2, 1},\n-                                                                  {1, 2, 2},\n-                                                                  {1, 4, 1},\n-                                                                  {1, 4, 2},\n-                                                                  {2, 1, 1},\n-                                                                  {2, 1, 2},\n-                                                                  {2, 2, 1},\n-                                                                  {2, 2, 2},\n-                                                                  {2, 4, 1},\n-                                                                  {2, 4, 2},\n-                                                                  {3, 1, 1},\n-                                                                  {3, 1, 2},\n-                                                                  {3, 2, 1},\n-                                                                  {3, 2, 2},\n-                                                                  {3, 4, 1},\n-                                                                  {3, 4, 2}}));\n+  EXPECT_THAT(GetFlatTilingsForInputSpace({3, 4, 2}),\n+              IsOkAndHolds(TilingVector({{1, 1, 1},\n+                                         {1, 1, 2},\n+                                         {1, 2, 1},\n+                                         {1, 2, 2},\n+                                         {1, 4, 1},\n+                                         {1, 4, 2},\n+                                         {2, 1, 1},\n+                                         {2, 1, 2},\n+                                         {2, 2, 1},\n+                                         {2, 2, 2},\n+                                         {2, 4, 1},\n+                                         {2, 4, 2},\n+                                         {3, 1, 1},\n+                                         {3, 1, 2},\n+                                         {3, 2, 1},\n+                                         {3, 2, 2},\n+                                         {3, 4, 1},\n+                                         {3, 4, 2}})));\n }\n \n // Helper to transform a sequence of `Tiling`s into a sequence of equivalent"
        },
        {
            "sha": "d456c45b5a51f74d1ed1e8b01fdf2fe4c032907b",
            "filename": "third_party/xla/xla/service/gpu/nvptx_compiler.cc",
            "status": "modified",
            "additions": 79,
            "deletions": 30,
            "changes": 109,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -41,9 +41,14 @@ limitations under the License.\n #include \"llvm/Support/SourceMgr.h\"\n #include \"llvm/Support/raw_ostream.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/backends/gpu/autotuner/block_level_emitter.h\"\n #include \"xla/backends/gpu/autotuner/cublas.h\"\n #include \"xla/backends/gpu/autotuner/cublaslt.h\"\n+#include \"xla/backends/gpu/autotuner/native_emitter.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/pass/hlo_pass_fix.h\"\n #include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n@@ -62,7 +67,6 @@ limitations under the License.\n #include \"xla/service/gpu/autotuning/autotuner_pass.h\"\n #include \"xla/service/gpu/autotuning/autotuner_util.h\"\n #include \"xla/service/gpu/autotuning/conv_algorithm_picker.h\"\n-#include \"xla/service/gpu/autotuning/gemm_algorithm_picker.h\"\n #include \"xla/service/gpu/autotuning/gemm_fusion_autotuner.h\"\n #include \"xla/service/gpu/cublas_cudnn.h\"\n #include \"xla/service/gpu/cublas_padding_requirements.h\"\n@@ -88,6 +92,7 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/cudnn_vectorize_convolutions.h\"\n #include \"xla/service/gpu/transforms/gpusolver_rewriter.h\"\n #include \"xla/service/gpu/transforms/triangular_solve_rewriter.h\"\n+#include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/hlo_verifier.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n@@ -356,41 +361,30 @@ absl::Status NVPTXCompiler::AddConvAndGemmAutotuningPasses(\n           .debug_options()\n           .xla_gpu_experimental_disable_binary_libraries() ||\n       debug_options.xla_gpu_autotune_level() == 0 ||\n-      debug_options.xla_gpu_exclude_nondeterministic_ops()) {\n+      debug_options.xla_gpu_exclude_nondeterministic_ops() ||\n+      stream_exec == nullptr) {\n     return absl::OkStatus();\n   }\n \n   // TODO(b/407495801): Cached Gemm as well as Conv autotuning results are\n   // loaded in the GpuConvAlgorithmPicker but should be loaded in the autotuner.\n   pipeline->AddPass<GpuConvAlgorithmPicker>(autotune_config);\n \n-  if (debug_options.xla_gpu_experimental_use_autotuner_pass()) {\n-    std::vector<std::unique_ptr<CodegenBackend>> backends;\n-    backends.push_back(\n-        std::make_unique<CublasBackend>(stream_exec, &debug_options, this));\n-    backends.push_back(\n-        std::make_unique<CublasLtBackend>(stream_exec, &debug_options, this));\n-    auto should_autotune = [](const HloInstruction& instruction) -> bool {\n-      return instruction.opcode() == HloOpcode::kCustomCall &&\n-             IsCublasGemm(instruction);\n-    };\n-    TF_ASSIGN_OR_RETURN(\n-        std::unique_ptr<AutotunerPass> autotuner_pass,\n-        AutotunerPass::Create(std::move(backends), debug_options,\n-                              options.device_allocator, stream_exec,\n-                              thread_pool, should_autotune));\n-    pipeline->AddPass(std::move(autotuner_pass));\n-  } else {\n-    // On Ampere or later, GemmAlgorithmPicker just provides a way to \"warmup\"\n-    // the\n-    // execution. But we already do that during GemmFusionAutotuner pass. In\n-    // that case, we do a recursive compilation call that has\n-    // 'is_autotuning_compilation' set to true.\n-    if (!std::get<se::CudaComputeCapability>(gpu_version).IsAtLeastAmpere() ||\n-        options.is_autotuning_compilation) {\n-      pipeline->AddPass<GemmAlgorithmPicker>(autotune_config);\n-    }\n-  }\n+  std::vector<std::unique_ptr<CodegenBackend>> backends;\n+  backends.push_back(\n+      std::make_unique<CublasBackend>(stream_exec, &debug_options, this));\n+  backends.push_back(\n+      std::make_unique<CublasLtBackend>(stream_exec, &debug_options, this));\n+  auto should_autotune = [](const HloInstruction& instruction) -> bool {\n+    return instruction.opcode() == HloOpcode::kCustomCall &&\n+           IsCublasGemm(instruction);\n+  };\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<AutotunerPass> autotuner_pass,\n+      AutotunerPass::Create(std::move(backends), debug_options, stream_exec,\n+                            thread_pool, should_autotune,\n+                            options.device_allocator));\n+  pipeline->AddPass(std::move(autotuner_pass));\n   return absl::OkStatus();\n }\n \n@@ -405,6 +399,59 @@ absl::Status NVPTXCompiler::AddGemmFusionAutotuningPasses(\n   return absl::OkStatus();\n }\n \n+namespace {\n+\n+// Returns true if the instruction is a fusion that would go through the native\n+// emitter, but may benefit from going through the block-level emitter.\n+// Currently, we only do this for reductions and transposes.\n+bool ShouldAutotuneBetweenFusionEmitters(const HloInstruction& instruction) {\n+  if (instruction.opcode() != HloOpcode::kFusion) {\n+    return false;\n+  }\n+  auto fusion = Cast<const HloFusionInstruction>(&instruction);\n+  // kCustom fusions have already been assigned to a backend and we don't want\n+  // to override it.\n+  if (fusion->fusion_kind() == HloInstruction::FusionKind::kCustom) {\n+    return false;\n+  }\n+  return absl::c_any_of(\n+      fusion->fused_instructions_computation()->instructions(),\n+      HloPredicateIsOp<HloOpcode::kReduce, HloOpcode::kTranspose>);\n+}\n+\n+}  // namespace\n+\n+absl::Status NVPTXCompiler::AddFusionAutotuningPass(\n+    HloPassPipeline* pipeline, HloModule* hlo_module,\n+    const CompileOptions& options, tsl::thread::ThreadPool* thread_pool,\n+    stream_executor::StreamExecutor* stream_executor,\n+    HloCostAnalysis::ShapeSizeFunction shape_size_fn) {\n+  if (stream_executor == nullptr) {\n+    return absl::OkStatus();\n+  }\n+  const DebugOptions& debug_options = hlo_module->config().debug_options();\n+  if (debug_options.xla_gpu_autotune_level() == 0 ||\n+      debug_options.xla_gpu_exclude_nondeterministic_ops() ||\n+      !debug_options.xla_gpu_experimental_enable_fusion_autotuner()) {\n+    return absl::OkStatus();\n+  }\n+\n+  std::vector<std::unique_ptr<CodegenBackend>> backends;\n+  backends.push_back(std::make_unique<BlockLevelEmitterBackend>(\n+      stream_executor, &debug_options, this, shape_size_fn,\n+      /*use_default_config=*/true));\n+  backends.push_back(std::make_unique<NativeEmitterBackend>(\n+      stream_executor, &debug_options, this));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<AutotunerPass> autotuner_pass,\n+      AutotunerPass::Create(std::move(backends), debug_options, stream_executor,\n+                            thread_pool, ShouldAutotuneBetweenFusionEmitters,\n+                            options.device_allocator));\n+  pipeline->AddPass(std::move(autotuner_pass));\n+  return absl::OkStatus();\n+}\n+\n absl::Status NVPTXCompiler::RunCudnnCompilerPasses(\n     HloModule* module, se::StreamExecutor* stream_exec,\n     BinaryMap* dnn_compiled_graphs) {\n@@ -693,7 +740,9 @@ absl::StatusOr<std::vector<uint8_t>> NVPTXCompiler::LinkModules(\n     const stream_executor::DeviceDescription& device_description,\n     se::StreamExecutor* stream_exec, std::vector<std::vector<uint8_t>> modules,\n     const DebugOptions& debug_options) {\n-  if (modules.empty()) return std::vector<uint8_t>{};\n+  if (modules.empty()) {\n+    return std::vector<uint8_t>{};\n+  }\n \n   auto cc = std::get<stream_executor::CudaComputeCapability>(\n       device_description.gpu_compute_capability());"
        },
        {
            "sha": "516c80929616bb4cac7953dd55747c44808b9856",
            "filename": "third_party/xla/xla/service/gpu/nvptx_compiler.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -82,6 +82,12 @@ class NVPTXCompiler : public GpuCompiler {\n       const se::SemanticVersion& toolkit_version,\n       se::StreamExecutor* stream_executor) override;\n \n+  absl::Status AddFusionAutotuningPass(\n+      HloPassPipeline* pipeline, HloModule* hlo_module,\n+      const CompileOptions& options, tsl::thread::ThreadPool* thread_pool,\n+      stream_executor::StreamExecutor* stream_executor,\n+      HloCostAnalysis::ShapeSizeFunction shape_size_fn) override;\n+\n   absl::Status RunCudnnCompilerPasses(HloModule* module,\n                                       se::StreamExecutor* stream_exec,\n                                       BinaryMap* dnn_compiled_graphs) override;"
        },
        {
            "sha": "7e5f4f0f2add68d8176f042c677b268f96fb918e",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -156,9 +156,12 @@ xla_test(\n     deps = [\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/tests:hlo_pjrt_interpreter_reference_mixin\",\n         \"//xla/tests:hlo_pjrt_test_base\",\n         \"//xla/tests:literal_test_util\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n     ],"
        },
        {
            "sha": "853b21f6f8ecc41d82ed96a0eaf392451902ee61",
            "filename": "third_party/xla/xla/service/gpu/tests/command_buffer_test.cc",
            "status": "modified",
            "additions": 267,
            "deletions": 3,
            "changes": 270,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fcommand_buffer_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -20,16 +20,21 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/service/hlo_module_config.h\"\n+#include \"xla/tests/hlo_pjrt_interpreter_reference_mixin.h\"\n #include \"xla/tests/hlo_pjrt_test_base.h\"\n #include \"xla/tests/literal_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n \n namespace xla::gpu {\n namespace {\n \n-class CommandBufferTest : public HloPjRtTestBase,\n-                          public ::testing::WithParamInterface<\n-                              DebugOptions::CommandBufferSchedulingMode> {\n+class CommandBufferTest\n+    : public HloPjRtInterpreterReferenceMixin<HloPjRtTestBase>,\n+      public ::testing::WithParamInterface<\n+          DebugOptions::CommandBufferSchedulingMode> {\n+ protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloPjRtTestBase::GetDebugOptionsForTest();\n     debug_options.set_xla_gpu_command_buffer_scheduling_mode(GetParam());\n@@ -274,6 +279,265 @@ TEST_P(CommandBufferTest, WhileLoop) {\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n }\n \n+TEST_P(CommandBufferTest, ControlDependencyTest) {\n+  constexpr absl::string_view module_str = R\"(\n+HloModule m\n+\n+%x (a: f32[3200,6400]) -> f32[3200,6400] {\n+  %a = f32[3200,6400]{1,0} parameter(0)\n+  ROOT %b = f32[3200,6400]{1,0} negate(%a)\n+}\n+\n+%y (a.1: f32[3200,6400]) -> f32[3200,6400] {\n+  %a.1 = f32[3200,6400]{1,0} parameter(0)\n+  ROOT %b.1 = f32[3200,6400]{1,0} add(%a.1, %a.1)\n+}\n+\n+%command_buffer (p: f32[3200,6400], p.1: f32[3200,6400]) -> (f32[3200,6400], f32[3200,6400]) {\n+  %p = f32[3200,6400]{1,0} parameter(0)\n+  %p.1 = f32[3200,6400]{1,0} parameter(1)\n+  %b.2 = f32[3200,6400]{1,0} fusion(%p), kind=kLoop, calls=%x\n+  %c = f32[3200,6400]{1,0} fusion(%p.1), kind=kLoop, calls=%y, control-predecessors={%b.2}\n+  ROOT %tuple = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) tuple(%b.2, %c)\n+}\n+\n+ENTRY %e (m: f32[3200,6400], n: f32[3200,6400]) -> (f32[3200,6400], f32[3200,6400]) {\n+  %m = f32[3200,6400]{1,0} parameter(0)\n+  %n = f32[3200,6400]{1,0} parameter(1)\n+  %call = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) call(%m, %n), to_apply=%command_buffer\n+  %get-tuple-element = f32[3200,6400]{1,0} get-tuple-element(%call), index=0\n+  %get-tuple-element.1 = f32[3200,6400]{1,0} get-tuple-element(%call), index=1\n+  ROOT %t = (f32[3200,6400]{1,0}, f32[3200,6400]{1,0}) tuple(%get-tuple-element, %get-tuple-element.1)\n+}\n+  )\";\n+\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_disable_all_hlo_passes(true);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str, config));\n+  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n+}\n+\n+TEST_P(CommandBufferTest, DynamicSliceFusionCmd) {\n+  // Hlo generated by the following JAX program:\n+  // def scan_body(carry, x):\n+  //     sliced_x = lax.slice(x, (0, 0), (128, 128))\n+  //     result = jnp.dot(carry, sliced_x)\n+  //     new_carry = result\n+  //     return new_carry, result\n+  // @jax.jit\n+  // def run_scan(initial_carry, xs):\n+  //     final_carry, outputs = lax.scan(scan_body, initial_carry, xs, length=2)\n+  //     return final_carry, outputs\n+\n+  constexpr absl::string_view module_str = R\"(\n+HloModule jit_run_scan\n+\n+None.7 {\n+  Arg_0.8 = f32[128,128]{1,0} parameter(0)\n+  Arg_1.9 = f32[128,128]{1,0} parameter(1)\n+  dot.10 = f32[128,128]{1,0} dot(Arg_0.8, Arg_1.9), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  ROOT tuple.11 = (f32[128,128]{1,0}, f32[128,128]{1,0}) tuple(dot.10, dot.10)\n+}\n+\n+region_0.12 {\n+  arg_tuple.13 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) parameter(0)\n+  get-tuple-element.14 = s32[] get-tuple-element(arg_tuple.13), index=0\n+  constant.18 = s32[] constant(1)\n+  add.34 = s32[] add(get-tuple-element.14, constant.18)\n+  get-tuple-element.15 = f32[128,128]{1,0} get-tuple-element(arg_tuple.13), index=1\n+  get-tuple-element.17 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.13), index=3\n+  constant.20 = s32[] constant(0)\n+  compare.21 = pred[] compare(get-tuple-element.14, constant.20), direction=LT\n+  constant.19 = s32[] constant(2)\n+  add.22 = s32[] add(get-tuple-element.14, constant.19)\n+  select.23 = s32[] select(compare.21, add.22, get-tuple-element.14)\n+  dynamic-slice.24 = f32[1,128,128]{2,1,0} dynamic-slice(get-tuple-element.17, select.23, constant.20, constant.20), dynamic_slice_sizes={1,128,128}\n+  reshape.25 = f32[128,128]{1,0} reshape(dynamic-slice.24)\n+  call.26 = (f32[128,128]{1,0}, f32[128,128]{1,0}) call(get-tuple-element.15, reshape.25), to_apply=None.7\n+  get-tuple-element.27 = f32[128,128]{1,0} get-tuple-element(call.26), index=0\n+  get-tuple-element.16 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.13), index=2\n+  get-tuple-element.28 = f32[128,128]{1,0} get-tuple-element(call.26), index=1\n+  reshape.29 = f32[1,128,128]{2,1,0} reshape(get-tuple-element.28)\n+  compare.30 = pred[] compare(get-tuple-element.14, constant.20), direction=LT\n+  add.31 = s32[] add(get-tuple-element.14, constant.19)\n+  select.32 = s32[] select(compare.30, add.31, get-tuple-element.14)\n+  dynamic-update-slice.33 = f32[2,128,128]{2,1,0} dynamic-update-slice(get-tuple-element.16, reshape.29, select.32, constant.20, constant.20)\n+  ROOT tuple.35 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) tuple(add.34, get-tuple-element.27, dynamic-update-slice.33, get-tuple-element.17)\n+} // region_0.12\n+\n+region_1.36 {\n+  arg_tuple.37 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) parameter(0)\n+  get-tuple-element.39 = f32[128,128]{1,0} get-tuple-element(arg_tuple.37), index=1\n+  get-tuple-element.40 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.37), index=2\n+  get-tuple-element.41 = f32[2,128,128]{2,1,0} get-tuple-element(arg_tuple.37), index=3\n+  get-tuple-element.38 = s32[] get-tuple-element(arg_tuple.37), index=0\n+  constant.42 = s32[] constant(2)\n+  ROOT compare.43 = pred[] compare(get-tuple-element.38, constant.42), direction=LT\n+} // region_1.36\n+\n+ENTRY main.49 {\n+  constant.3 = s32[] constant(0)\n+  Arg_0.1 = f32[128,128]{1,0} parameter(0)\n+  constant.4 = f32[] constant(0)\n+  broadcast.5 = f32[2,128,128]{2,1,0} broadcast(constant.4), dimensions={}\n+  Arg_1.2 = f32[2,128,128]{2,1,0} parameter(1)\n+  tuple.6 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) tuple(constant.3, Arg_0.1, broadcast.5, Arg_1.2)\n+  while.44 = (s32[], f32[128,128]{1,0}, f32[2,128,128]{2,1,0}, f32[2,128,128]{2,1,0}) while(tuple.6), condition=region_1.36, body=region_0.12\n+  get-tuple-element.45 = s32[] get-tuple-element(while.44), index=0\n+  get-tuple-element.46 = f32[128,128]{1,0} get-tuple-element(while.44), index=1\n+  get-tuple-element.47 = f32[2,128,128]{2,1,0} get-tuple-element(while.44), index=2\n+  ROOT tuple.48 = (f32[128,128]{1,0}, f32[2,128,128]{2,1,0}) tuple(get-tuple-element.46, get-tuple-element.47)\n+}\n+  )\";\n+\n+  // Run twice toggling exclusive lock to match original test behavior.\n+  HloModuleConfig config;\n+  auto debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_require_exclusive_lock(false);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLAS);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLASLT);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUSTOM_CALL);\n+  debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUDNN);\n+  debug_options.add_xla_gpu_enable_command_buffer(\n+      DebugOptions::DYNAMIC_SLICE_FUSION);\n+  config.set_debug_options(debug_options);\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(module_str, config));\n+  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n+\n+  debug_options.set_xla_gpu_require_exclusive_lock(true);\n+  config.set_debug_options(debug_options);\n+  TF_ASSERT_OK_AND_ASSIGN(module,\n+                          ParseAndReturnVerifiedModule(module_str, config));\n+  EXPECT_TRUE(RunAndCompare(std::move(module), ErrorSpec{1e-3, 2e-3}));\n+}\n+\n+TEST_P(CommandBufferTest, DynamicSliceCopyFusionCmd) {\n+  constexpr absl::string_view hlo_text = R\"(\n+    dynamic_slice {\n+      p0 = s32[4,8,8]{2,1,0} parameter(0)\n+      p1 = s32[] parameter(1)\n+      c1 = s32[] constant(1)\n+      p2 = s32[] parameter(2)\n+\n+      p1p1 = s32[] add(p1, c1)\n+\n+      // Test all supported kinds of offsets: derived from the while loop's\n+      // induction variable (p1p1), constant (c1) and always clamped to 0, so\n+      // the value is irrelevant (p2).\n+      ROOT slice = s32[1,1,8] dynamic-slice(p0, p1p1, c1, p2),\n+          dynamic_slice_sizes={1,1,8}\n+    }\n+\n+    remainder {\n+      p0 = s32[] parameter(0)\n+      c5 = s32[] constant(5)\n+      // We take the value modulo 5 to test for correct clamping (the offset 4\n+      // must get clamped to 3, since it's greater or equal than the dimension\n+      // size).\n+      ROOT remainder = s32[] remainder(p0, c5)\n+    }\n+\n+    add {\n+      p0 = s32[] parameter(0)\n+      c1 = s32[] constant(1)\n+      ROOT sum = s32[] add(p0, c1)\n+    }\n+\n+    add_slices {\n+      p0 = s32[1,1,8] parameter(0)\n+      p1 = s32[1,1,8] parameter(1)\n+      ROOT sum = s32[1,1,8] add(p0, p1)\n+    }\n+\n+    times_two {\n+      p0 = s32[] parameter(0)\n+      ROOT sum = s32[] add(p0, p0)\n+    }\n+\n+    body {\n+      p0 = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) parameter(0)\n+      ivar = s32[] get-tuple-element(p0), index=0\n+      input = s32[4,8,8]{2,1,0} get-tuple-element(p0), index=1\n+\n+      ivar_copy = s32[] copy(ivar)\n+      acc = s32[1,1,8] get-tuple-element(p0), index=2\n+      acc_copy = s32[1,1,8] copy(acc)\n+\n+      offset1 = s32[] fusion(ivar_copy), kind=kLoop, calls=remainder\n+      offset2 = s32[] get-tuple-element(p0), index=3\n+\n+      slice = s32[1,1,8] fusion(input, offset1, offset2), kind=kLoop, calls=dynamic_slice,\n+          backend_config={\"fusion_backend_config\":{\n+              \"kind\":\"__dynamic_memcpy\",\n+              \"dynamic_memcpy_config\":{\n+                  \"depends_on_loop\":true,\n+                  \"src_offset_bytes\":[\"288\",\"544\",\"800\",\"800\",\"800\",\"288\"],\n+                  \"dst_offset_bytes\":[\"0\",\"0\",\"0\",\"0\",\"0\",\"0\"]}}}\n+      next_ivar = s32[] fusion(ivar_copy), kind=kLoop, calls=add\n+      next_offset_2 = s32[] fusion(offset2), kind=kLoop, calls=times_two\n+\n+      next_acc = s32[1,1,8] fusion(acc_copy, slice), kind=kLoop, calls=add_slices\n+      ROOT result = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[])\n+          tuple(next_ivar, input, next_acc, next_offset_2)\n+    }\n+\n+    compare {\n+      p0 = s32[] parameter(0)\n+      c6 = s32[] constant(6)\n+      ROOT cmp = pred[] compare(p0, c6), direction=LT\n+    }\n+\n+    condition {\n+      p0 = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) parameter(0)\n+      ivar = s32[] get-tuple-element(p0), index=0\n+      ROOT cmp = pred[] fusion(ivar), kind=kLoop, calls=compare\n+    }\n+\n+    zero {\n+      c0 = s32[] constant(0)\n+      ROOT bc = s32[1,1,8] broadcast(c0), dimensions={}\n+    }\n+\n+    input {\n+      iota = s32[256] iota(), iota_dimension=0\n+      ROOT bc = s32[4,8,8]{2,1,0} bitcast(iota)\n+    }\n+\n+    ENTRY main {\n+      input = s32[4,8,8]{2,1,0} fusion(), kind=kLoop, calls=input\n+      init_acc = s32[1,1,8] fusion(), kind=kLoop, calls=zero\n+      c0 = s32[] constant(0)\n+      c1 = s32[] constant(1)\n+      tuple = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) tuple(c0, input, init_acc, c1)\n+      ROOT while = (s32[], s32[4,8,8]{2,1,0}, s32[1,1,8], s32[]) while(tuple),\n+          condition=condition, body=body,\n+          backend_config={\"known_trip_count\":{\"n\":\"6\"},\n+                          \"known_init_step\":{\"init\":\"0\",\"step\":\"1\"},\n+                          \"known_induction_variable\":{\"tuple_index\":\"0\"}}\n+    }\n+  )\";\n+\n+  HloModuleConfig config;\n+  DebugOptions debug_options = GetDebugOptionsForTest();\n+  debug_options.set_xla_gpu_require_exclusive_lock(false);\n+  debug_options.add_xla_gpu_enable_command_buffer(\n+      DebugOptions::DYNAMIC_SLICE_COPY_FUSION);\n+  config.set_debug_options(debug_options);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_text, config));\n+\n+  EXPECT_TRUE(\n+      RunAndCompareNoHloPasses(std::move(module), ErrorSpec{1e-3, 2e-3}));\n+}\n+\n INSTANTIATE_TEST_SUITE_P(CommandBufferTests, CommandBufferTest,\n                          ::testing::Values(DebugOptions::LHS,\n                                            DebugOptions::CONCURRENT));"
        },
        {
            "sha": "dc56f417e3397be0d70525a9cfcf3633967da0df",
            "filename": "third_party/xla/xla/service/gpu/tests/gpu_fused_mha_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_fused_mha_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1695,11 +1695,17 @@ absl::string_view GetModuleFlashAttentionBMMScaleSoftmaxBMMCommonF8() {\n // BMM1 - Scale - Softmax - BMM2 fp8\n TEST_F(FlashAttentionBMMScaleSoftmaxBMMF8,\n        Flash_Attention_Inference_BMM1_NoMask_Softmax_BMM2_BNTH_F8) {\n-  if (skip_reason_) GTEST_SKIP() << *skip_reason_;\n+  if (skip_reason_) {\n+    GTEST_SKIP() << *skip_reason_;\n+  }\n   if (GetDnnVersionInfoOrDefault(backend().default_stream_executor()) <\n       se::dnn::VersionInfo(9, 1, 0)) {\n     GTEST_SKIP() << \"Flash Attention requires cuDNN >= 9.1.0.\";\n   }\n+  if (GetDnnVersionInfoOrDefault(backend().default_stream_executor()) ==\n+      se::dnn::VersionInfo(9, 10, 0)) {\n+    GTEST_SKIP() << \"Flash Attention is not supported in cuDNN 9.10.0.\";\n+  }\n   auto cc = GetCudaComputeCapability();\n   if (!cc.IsAtLeastHopper()) {\n     GTEST_SKIP() << \"Flash Attention fp8 requires at least Hopper.\";\n@@ -1872,11 +1878,17 @@ TEST_F(FlashAttentionBMMScaleSoftmaxBMMF8,\n \n TEST_F(FlashAttentionBMMScaleSoftmaxBMMF8,\n        Flash_Attention_Inference_BMM1_NoMask_Softmax_BMM2_BTNH_F8) {\n-  if (skip_reason_) GTEST_SKIP() << *skip_reason_;\n+  if (skip_reason_) {\n+    GTEST_SKIP() << *skip_reason_;\n+  }\n   if (GetDnnVersionInfoOrDefault(backend().default_stream_executor()) <\n       se::dnn::VersionInfo(9, 1, 0)) {\n     GTEST_SKIP() << \"Flash Attention requires cuDNN >= 9.1.0.\";\n   }\n+  if (GetDnnVersionInfoOrDefault(backend().default_stream_executor()) ==\n+      se::dnn::VersionInfo(9, 10, 0)) {\n+    GTEST_SKIP() << \"Flash Attention is not supported in cuDNN 9.10.0.\";\n+  }\n   auto cc = GetCudaComputeCapability();\n   if (!cc.IsAtLeastHopper()) {\n     GTEST_SKIP() << \"Flash Attention fp8 requires at least Hopper.\";"
        },
        {
            "sha": "7b85daad2430c2194b400cc776245fcce7b4135b",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1,11 +1,16 @@\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n+load(\"//xla:lit.bzl\", \"enforce_glob\", \"lit_test_suite\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n load(\n     \"//xla/stream_executor:build_defs.bzl\",\n     \"if_gpu_is_configured\",\n )\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n load(\"//xla/tsl:tsl.bzl\", \"if_google\", \"if_oss\")\n+load(\n+    \"//xla/tsl/platform:build_config_root.bzl\",\n+    \"tf_gpu_tests_tags\",\n+)\n load(\n     \"//xla/tsl/platform/default:cuda_build_defs.bzl\",\n     \"if_cuda_is_configured\",\n@@ -1912,6 +1917,31 @@ xla_cc_test(\n     ],\n )\n \n+lit_test_suite(\n+    name = \"hlo_lit_tests\",\n+    srcs = enforce_glob(\n+        [\n+            \"layout_assignment_v100.hlo\",\n+            \"layout_assignment_a100.hlo\",\n+            \"layout_assignment_h100.hlo\",\n+        ],\n+        include = [\n+            \"*.hlo\",\n+        ],\n+    ),\n+    cfg = \"//xla:lit.cfg.py\",\n+    data = [\n+        \"//xla/tools/hlo_opt:gpu_specs/a100_pcie_80.txtpb\",\n+        \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n+        \"//xla/tools/hlo_opt:gpu_specs/v100.txtpb\",\n+    ],\n+    default_tags = tf_gpu_tests_tags(),\n+    tools = [\n+        \"//xla/tools:hlo-opt\",\n+        \"@llvm-project//llvm:FileCheck\",\n+    ],\n+)\n+\n cc_library(\n     name = \"move_copy_to_users\",\n     srcs = [\"move_copy_to_users.cc\"],"
        },
        {
            "sha": "1a9ec1a8817a012138a60aa817d97f40f47f7ce8",
            "filename": "third_party/xla/xla/service/gpu/transforms/block_scaling_rewriter.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"xla/hlo/builder/lib/constants.h\"\n #include \"xla/hlo/builder/xla_builder.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n@@ -53,6 +54,34 @@ absl::StatusOr<HloInstruction*> ExpandInstructionUsingBuilder(\n       HloComputation * computation,\n       XlaComputationToHloComputation(xla_computation,\n                                      old_instruction->parent()->parent()));\n+\n+  // Fix broadcast layouts (they cannot be inferred correctly).\n+  for (HloInstruction* instruction : computation->instructions()) {\n+    auto broadcast = DynCast<HloBroadcastInstruction>(instruction);\n+    if (broadcast != nullptr && !LayoutUtil::IsMonotonicWithDim0Major(\n+                                    broadcast->operand(0)->shape().layout())) {\n+      // Previous instruction is a convert, next one is a reshape.\n+      int rank = broadcast->shape().dimensions().size();\n+      const HloInstruction* convert = broadcast->operand(0);\n+      CHECK(convert->opcode() == HloOpcode::kConvert &&\n+            convert->shape().dimensions().size() == rank - 1);\n+      HloInstruction* reshape = broadcast->users()[0];\n+      CHECK(reshape->opcode() == HloOpcode::kReshape &&\n+            reshape->shape().dimensions().size() == rank - 1);\n+\n+      // Increase the layout index of the dimensions after the last one.\n+      // Example: {2,0,1} -> {3,0,2,1}\n+      int last_idx = convert->shape().layout().minor_to_major().back();\n+      auto broadcast_layout = broadcast->mutable_shape()->mutable_layout();\n+      for (int i = 0; i < rank - 1; ++i) {\n+        int idx = convert->shape().layout().minor_to_major(i);\n+        broadcast_layout->set_minor_to_major(i, idx + (idx >= last_idx));\n+      }\n+      broadcast_layout->set_minor_to_major(rank - 1, last_idx);\n+      *reshape->mutable_shape()->mutable_layout() = convert->shape().layout();\n+    }\n+  }\n+\n   return old_instruction->parent()->AddInstruction(HloInstruction::CreateCall(\n       old_instruction->shape(), old_instruction->operands(), computation));\n }"
        },
        {
            "sha": "ccd3e271a2b744aa9cb7b32e11be76bcdd524347",
            "filename": "third_party/xla/xla/service/gpu/transforms/block_scaling_rewriter_test.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fblock_scaling_rewriter_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -115,6 +115,41 @@ ENTRY main {\n })\");\n }\n \n+TEST_F(BlockScalingRewriterTest, ExpandBlockScaledDotNonDefaultLayout) {\n+  constexpr absl::string_view hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  %lhs = f8e4m3fn[4,16,256]{2,0,1} parameter(0)\n+  %rhs = f8e4m3fn[4,32,256]{0,1,2} parameter(1)\n+  %lhs_scale = f8e5m2[4,16,8]{2,0,1} parameter(2)\n+  %rhs_scale = f8e5m2[4,32,8]{0,1,2} parameter(3)\n+  ROOT %result = f32[4,16,32] custom-call(%lhs, %rhs, %lhs_scale, %rhs_scale),\n+      custom_call_target=\"__op$block_scaled_dot\"\n+})\";\n+\n+  BlockScalingRewriter pass(/*allow_cudnn=*/false);\n+  RunAndFilecheckHloRewrite(hlo_string, std::move(pass), R\"(\n+  CHECK: [[lhs_quant:%.+]] = f8e4m3fn[4,16,256]{2,0,1} parameter(0)\n+  CHECK: [[lhs_quant_cvt:%.+]] = f32[4,16,256]{2,0,1} convert([[lhs_quant]])\n+  CHECK: [[lhs_scale:%.+]] = f8e5m2[4,16,8]{2,0,1} parameter(2)\n+  CHECK: [[lhs_scale_cvt:%.+]] = f32[4,16,8]{2,0,1} convert([[lhs_scale]])\n+  CHECK: [[lhs_scale_bc:%.+]] = f32[4,16,8,32]{3,0,2,1} broadcast([[lhs_scale_cvt]])\n+  CHECK: [[lhs_scale_rs:%.+]] = f32[4,16,256]{2,0,1} reshape([[lhs_scale_bc]])\n+  CHECK: [[lhs:%.+]] = f32[4,16,256]{2,0,1} multiply([[lhs_quant_cvt]], [[lhs_scale_rs]])\n+  CHECK: [[rhs_quant:%.+]] = f8e4m3fn[4,32,256]{0,1,2} parameter(1)\n+  CHECK: [[rhs_quant_cvt:%.+]] = f32[4,32,256]{0,1,2} convert([[rhs_quant]])\n+  CHECK: [[rhs_scale:%.+]] = f8e5m2[4,32,8]{0,1,2} parameter(3)\n+  CHECK: [[rhs_scale_cvt:%.+]] = f32[4,32,8]{0,1,2} convert([[rhs_scale]])\n+  CHECK: [[rhs_scale_bc:%.+]] = f32[4,32,8,32]{0,1,3,2} broadcast([[rhs_scale_cvt]])\n+  CHECK: [[rhs_scale_rs:%.+]] = f32[4,32,256]{0,1,2} reshape([[rhs_scale_bc]])\n+  CHECK: [[rhs:%.+]] = f32[4,32,256]{0,1,2} multiply([[rhs_quant_cvt]], [[rhs_scale_rs]])\n+  CHECK: ROOT {{.+}} = f32[4,16,32]{2,1,0} dot([[lhs]], [[rhs]])\n+  CHECK-SAME: lhs_batch_dims={0}, lhs_contracting_dims={2}\n+  CHECK-SAME: rhs_batch_dims={0}, rhs_contracting_dims={2}\n+})\");\n+}\n+\n TEST_F(BlockScalingRewriterTest, ExpandBlockScaledDotQuantizedLhs) {\n   constexpr absl::string_view hlo_string = R\"(\n HloModule test"
        },
        {
            "sha": "344e399448c1488b77b9ccb104cf5df7a7cb7e9e",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_backend_assigner.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -44,6 +44,11 @@ bool IsCollectiveOp(const HloInstruction* instr) {\n                           HloOpcode::kCollectivePermuteStart>(instr);\n }\n \n+bool IsAllReduceOp(const HloInstruction* instr) {\n+  return HloPredicateIsOp<HloOpcode::kAllReduce, HloOpcode::kAllReduceStart>(\n+      instr);\n+}\n+\n int64_t GetShapeSize(const Shape& shape) {\n   if (shape.IsTuple()) {\n     int64_t size_in_bytes = 0;\n@@ -93,7 +98,8 @@ absl::StatusOr<bool> CollectiveBackendAssigner::Run(\n               << \" threshold_in_bytes_=\" << threshold_in_bytes_;\n       bool use_nvshmem = (num_visible_devices_per_process_ == 1 ||\n                           comm_type == GPUCommunicationType::SINGLE_HOST) &&\n-                         GetShapeSize(instr->shape()) < threshold_in_bytes_;\n+                         (!IsAllReduceOp(instr) ||\n+                          GetShapeSize(instr->shape()) < threshold_in_bytes_);\n       if (!use_nvshmem) {\n         continue;\n       }"
        },
        {
            "sha": "fef570812387d0b465dffab64bb6f7c6dab71819",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_backend_assigner_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_backend_assigner_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -126,7 +126,7 @@ TEST_F(CollectiveBackendAssignerTest, SmallCollectivePermuteUsesNvshmem) {\n               absl_testing::IsOkAndHolds(CollectiveBackendConfig::NVSHMEM));\n }\n \n-TEST_F(CollectiveBackendAssignerTest, LargeCollectivePermuteUsesDefault) {\n+TEST_F(CollectiveBackendAssignerTest, LargeCollectivePermuteUsesNvshmem) {\n   absl::string_view kHloText = R\"(\n     HloModule m\n \n@@ -139,12 +139,12 @@ TEST_F(CollectiveBackendAssignerTest, LargeCollectivePermuteUsesDefault) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(kHloText));\n   EXPECT_THAT(RunCollectiveBackendAssigner(module.get()),\n-              absl_testing::IsOkAndHolds(false));\n+              absl_testing::IsOkAndHolds(true));\n \n   const HloInstruction* permute =\n       module->entry_computation()->root_instruction();\n   EXPECT_THAT(GetCollectiveBackendConfig(permute),\n-              absl_testing::IsOkAndHolds(CollectiveBackendConfig::DEFAULT));\n+              absl_testing::IsOkAndHolds(CollectiveBackendConfig::NVSHMEM));\n }\n \n }  // namespace"
        },
        {
            "sha": "87cbe7e60944aebc1ef2ecaa819366db88ccd336",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 11,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -163,23 +163,31 @@ absl::StatusOr<GPUCommunicationType> CommunicationType(\n   return GPUCommunicationType::UNDEFINED;\n }\n \n-bool IsNVLinkConnected(const HloModuleConfig& config,\n-                       const se::DeviceDescription& device_description,\n-                       int64_t nvlink_slice_size) {\n+bool EnableHeuristicCollectiveCombining(\n+    const HloModuleConfig& config,\n+    const se::DeviceDescription& device_description,\n+    int64_t nvlink_slice_size) {\n+  if (!config.debug_options()\n+           .xla_gpu_experimental_enable_heuristic_collective_combining()) {\n+    return false;\n+  }\n   se::CudaComputeCapability cc = device_description.cuda_compute_capability();\n-  // NVLink is only available on Ampere/Hopper/Blackwell GPUs.\n-  if (!(cc.IsHopper() || cc.IsAmpere() || cc.IsBlackwell())) {\n+  // Heuristic collective combining is not turned on before Ampere GPUs.\n+  if (!cc.IsAtLeastAmpere()) {\n     return false;\n   }\n   int hlo_device_count = config.num_partitions() * config.replica_count();\n   if (hlo_device_count <= nvlink_slice_size) {\n-    VLOG(1) << \"NVLink connected: HLO device count \" << hlo_device_count\n-            << \" <= NVLink slice size \" << nvlink_slice_size;\n-    return true;\n+    VLOG(1) << \"Disabled heuristic collective combining for intra-NVLink \"\n+               \"domain communication: HLO device count \"\n+            << hlo_device_count << \" <= NVLink slice size \"\n+            << nvlink_slice_size;\n+    return false;\n   }\n-  VLOG(1) << \"Not NVLink connected: HLO device count \" << hlo_device_count\n-          << \" > NVLink slice size \" << nvlink_slice_size;\n-  return false;\n+  VLOG(1) << \"Enabled heuristic collective combining for inter-NVLink domain \"\n+             \"communication: HLO device count \"\n+          << hlo_device_count << \" > NVLink slice size \" << nvlink_slice_size;\n+  return true;\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "ee30564790b22be8eecc6cc5bfadcb21ec97a406",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils.h",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -48,9 +48,12 @@ enum class GPUTopologyType {\n   MULTI_HOST = 2,\n };\n \n-bool IsNVLinkConnected(const HloModuleConfig& config,\n-                       const se::DeviceDescription& device_description,\n-                       int64_t nvlink_slice_size);\n+// Returns true if heuristic collective combining is enabled.\n+// Heuristic collective combining enables more aggressive optimizations based\n+// on the platform and HLO's topology.\n+bool EnableHeuristicCollectiveCombining(\n+    const HloModuleConfig& config,\n+    const se::DeviceDescription& device_description, int64_t nvlink_slice_size);\n \n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "4ea078660717c0c60a64a50cae8d45214a442b2e",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_ops_utils_test.cc",
            "status": "modified",
            "additions": 110,
            "deletions": 62,
            "changes": 172,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_ops_utils_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -37,84 +37,132 @@ namespace {\n using ::absl_testing::IsOkAndHolds;\n using ::testing::Test;\n \n-bool IsNVLinkConnected(se::CudaComputeCapability compute_capability,\n-                       int num_partitions, int replica_count,\n-                       int64_t nvlink_slice_size) {\n+bool EnableHeuristicCollectiveCombining(\n+    se::CudaComputeCapability compute_capability, int num_partitions,\n+    int replica_count, int64_t nvlink_slice_size) {\n   HloModuleConfig config;\n+  config.mutable_debug_options()\n+      .set_xla_gpu_experimental_enable_heuristic_collective_combining(true);\n   config.set_num_partitions(num_partitions);\n   config.set_replica_count(replica_count);\n   se::DeviceDescription device_description =\n       TestGpuDeviceInfo::RTXA6000DeviceInfo(compute_capability);\n-  return xla::gpu::IsNVLinkConnected(config, device_description,\n-                                     nvlink_slice_size);\n+  return xla::gpu::EnableHeuristicCollectiveCombining(\n+      config, device_description, nvlink_slice_size);\n }\n \n-TEST(IsNVLinkConnectedTest, SingleHostSingleDevice) {\n-  // H100/B200\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n+TEST(EnableHeuristicCollectiveCombiningTest, SingleHostSingleDevice) {\n+  // B200\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/1, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n }\n \n-TEST(IsNVLinkConnectedTest, SingleHostMultiDevices) {\n-  // H100/B200\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/8, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                /*num_partitions=*/1, /*replica_count=*/8,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/8, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/8));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                /*num_partitions=*/1, /*replica_count=*/8,\n-                                /*nvlink_slice_size=*/8));\n-\n+TEST(EnableHeuristicCollectiveCombiningTest, SingleHostMultiDevices) {\n+  // B200\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/8,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/8,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/8,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/8,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/1, /*replica_count=*/16,\n-                                /*nvlink_slice_size=*/16));\n-  EXPECT_TRUE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                /*num_partitions=*/16, /*replica_count=*/1,\n-                                /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/16));\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n }\n \n-TEST(IsNVLinkConnectedTest, MultiHosts) {\n-  // H100/B200\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                 /*num_partitions=*/16, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Hopper(),\n-                                 /*num_partitions=*/1, /*replica_count=*/16,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                 /*num_partitions=*/16, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Blackwell(),\n-                                 /*num_partitions=*/1, /*replica_count=*/16,\n-                                 /*nvlink_slice_size=*/8));\n-\n+TEST(EnableHeuristicCollectiveCombiningTest, MultiHosts) {\n+  // B200\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Blackwell(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/8));\n+  // H100\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/16,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Hopper(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/16,\n+                                         /*nvlink_slice_size=*/8));\n   // A100\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                 /*num_partitions=*/1, /*replica_count=*/32,\n-                                 /*nvlink_slice_size=*/16));\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Ampere(),\n-                                 /*num_partitions=*/32, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/16));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/32,\n+                                         /*nvlink_slice_size=*/16));\n+  EXPECT_TRUE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Ampere(),\n+                                         /*num_partitions=*/32,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/16));\n+}\n+\n+TEST(EnableHeuristicCollectiveCombiningTest, UnsupportedGPU) {\n+  EXPECT_FALSE(\n+      EnableHeuristicCollectiveCombining(se::CudaComputeCapability::Volta(),\n+                                         /*num_partitions=*/1,\n+                                         /*replica_count=*/1,\n+                                         /*nvlink_slice_size=*/8));\n }\n \n-TEST(IsNVLinkConnectedTest, UnsupportedGPU) {\n-  EXPECT_FALSE(IsNVLinkConnected(se::CudaComputeCapability::Volta(),\n-                                 /*num_partitions=*/1, /*replica_count=*/1,\n-                                 /*nvlink_slice_size=*/8));\n+TEST(EnableHeuristicCollectiveCombiningTest, DisabledByFlag) {\n+  HloModuleConfig config;\n+  config.mutable_debug_options()\n+      .set_xla_gpu_experimental_enable_heuristic_collective_combining(false);\n+  config.set_num_partitions(16);\n+  config.set_replica_count(1);\n+  se::DeviceDescription device_description =\n+      TestGpuDeviceInfo::RTXA6000DeviceInfo(\n+          se::CudaComputeCapability::Blackwell());\n+  EXPECT_FALSE(xla::gpu::EnableHeuristicCollectiveCombining(\n+      config, device_description, /*nvlink_slice_size=*/8));\n }\n \n class CommunicationTypeTest : public Test {"
        },
        {
            "sha": "d3287bb27e4f8f707b5a5428f42992465971c649",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_fusion_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_fusion_compiler.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -248,6 +248,9 @@ class GemmDimensionAdapter {\n                        lhs_noncontracting_index,\n                        dot_.shape().dimensions_size() - 1};\n         break;\n+      case TritonFusionAnalysis::Scope::LHS_SCALE:\n+      case TritonFusionAnalysis::Scope::RHS_SCALE:\n+        LOG(FATAL) << \"Unsupported scope.\";\n     }\n \n     Result result;"
        },
        {
            "sha": "b24f5470c118132d08b1f06aab2cdb07970e76b9",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -563,6 +563,22 @@ absl::Status GpuLayoutAssignment::AddBackendConstraints(\n           auto indices_buffer,\n           points_to_analysis_->GetBufferDefinedAt(instruction, {1}));\n       TF_RETURN_IF_ERROR(SetBufferLayout(default_layout, *indices_buffer));\n+    } else if (HloPredicateIsOp<HloOpcode::kBitcastConvert>(instruction)) {\n+      Shape operand_shape = instruction->operand(0)->shape();\n+      Shape output_shape = instruction->shape();\n+      // Make the added or removed dimension the minor most to give the\n+      // operation a chance to become a no-op (bitcast).\n+      if (operand_shape.dimensions().size() >\n+          output_shape.dimensions().size()) {\n+        *operand_shape.mutable_layout() = LayoutUtil::MoveDimToMinor(\n+            operand_shape.layout(), operand_shape.dimensions().size() - 1);\n+        TF_RETURN_IF_ERROR(SetOperandLayout(operand_shape, instruction, 0));\n+      } else if (operand_shape.dimensions().size() <\n+                 output_shape.dimensions().size()) {\n+        *output_shape.mutable_layout() = LayoutUtil::MoveDimToMinor(\n+            output_shape.layout(), output_shape.dimensions().size() - 1);\n+        TF_RETURN_IF_ERROR(SetInstructionLayout(output_shape, instruction));\n+      }\n     } else if (HloPredicateIsOp<HloOpcode::kTriangularSolve>(instruction)) {\n       // TODO(phawkins): Ideally we would relax this constraint. What we\n       // actually want is that:"
        },
        {
            "sha": "f5f35fca937004f6b68b704e080b01054527d615",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_a100.hlo",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_a100.hlo?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,18 @@\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/a100_pcie_80.txtpb --split-input-file | FileCheck %s\n+\n+// CHECK: fused_transpose\n+// CHECK-NEXT: bf16[3,3,16,32]{3,2,1,0} parameter(0)\n+// CHECK-NEXT: bf16[144,32]{1,0} bitcast\n+// CHECK-NEXT: bf16[32,144]{1,0} transpose\n+// CHECK-SAME: dimensions={1,0}\n+// CHECK: (bf16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call\n+// CHECK-SAME: window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\n+\n+HloModule ConvCuDNN\n+\n+ENTRY main {\n+  Arg_0.1 = bf16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n+  Arg_1.2 = bf16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n+  ROOT convolution.3 = bf16[1,64,64,32]{3,2,1,0} convolution(Arg_0.1, Arg_1.2),\n+    window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f\n+}"
        },
        {
            "sha": "07b3a04afabf741606df6b62ee47a8bc190b2450",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_h100.hlo",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_h100.hlo?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,18 @@\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/h100_sxm.txtpb --split-input-file | FileCheck %s\n+\n+// CHECK: fused_transpose\n+// CHECK-NEXT: f8e4m3fn[3,3,16,32]{3,2,1,0} parameter(0)\n+// CHECK-NEXT: f8e4m3fn[144,32]{1,0} bitcast\n+// CHECK-NEXT: f8e4m3fn[32,144]{1,0} transpose\n+// CHECK-SAME: dimensions={1,0}\n+// CHECK: (f8e4m3fn[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call\n+// CHECK-SAME: window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\n+\n+HloModule ConvCuDNN\n+\n+ENTRY main {\n+  Arg_0.1 = f8e4m3fn[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n+  Arg_1.2 = f8e4m3fn[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n+  ROOT convolution.3 = f8e4m3fn[1,64,64,32]{3,2,1,0} convolution(Arg_0.1, Arg_1.2),\n+    window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f\n+}"
        },
        {
            "sha": "8b4a046c9c8d4c72a7584429ac6fe326ec6899a7",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_test.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 78,
            "changes": 123,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -53,7 +53,6 @@ namespace {\n \n namespace m = ::xla::match;\n using ::testing::NotNull;\n-using ::tsl::testing::IsOkAndHolds;\n \n class LayoutAssignmentTest : public HloTestBase {\n  public:\n@@ -458,6 +457,51 @@ TEST_F(LayoutAssignmentTest, TopKLayout) {\n                       .WithShape(F32, {6, 2048}, {1, 0}))));\n }\n \n+TEST_F(LayoutAssignmentTest,\n+       BitcastConvertFromNarrowerTypeGetsOptimalInputLayout) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+e {\n+  a = s4[3,5,2]{0,1,2:E(4)} parameter(0)\n+  b = s8[3,5]{0,1} bitcast-convert(a)\n+})\"));\n+\n+  ComputationLayout computation_layout(\n+      module->entry_computation()->ComputeProgramShape(),\n+      /*ignore_layouts=*/false);\n+  GpuLayoutAssignment layout_assignment(\n+      &computation_layout, GetGpuComputeCapability(), GetDnnVersion(),\n+      GetDeviceDescription());\n+  EXPECT_THAT(layout_assignment.Run(module.get()),\n+              absl_testing::IsOkAndHolds(true));\n+  EXPECT_THAT(\n+      module->entry_computation()->root_instruction(),\n+      GmockMatch(m::BitcastConvert(\n+          m::Copy(m::Parameter()).WithShape(S4, {3, 5, 2}, {2, 0, 1}))));\n+}\n+\n+TEST_F(LayoutAssignmentTest,\n+       BitcastConvertToNarrowerTypeGetsOptimalOutputLayout) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+e {\n+  a = s8[3,5] parameter(0)\n+  b = s4[3,5,2]{0,1,2} bitcast-convert(a)\n+})\"));\n+\n+  ComputationLayout computation_layout(\n+      module->entry_computation()->ComputeProgramShape(),\n+      /*ignore_layouts=*/false);\n+  GpuLayoutAssignment layout_assignment(\n+      &computation_layout, GetGpuComputeCapability(), GetDnnVersion(),\n+      GetDeviceDescription());\n+  EXPECT_THAT(layout_assignment.Run(module.get()),\n+              absl_testing::IsOkAndHolds(true));\n+  EXPECT_THAT(module->entry_computation()->root_instruction(),\n+              GmockMatch(m::Copy(m::BitcastConvert(m::Parameter())\n+                                     .WithShape(S4, {3, 5, 2}, {2, 0, 1}))));\n+}\n+\n TEST_F(LayoutAssignmentTest, FftLayout) {\n   const char* hlo_text = R\"(\n   HloModule Fft_module\n@@ -652,83 +696,6 @@ ENTRY entry {\n       absl_testing::IsOkAndHolds(true));\n }\n \n-TEST_F(LayoutAssignmentTest, ConvCuDNNF8) {\n-  if (!GetCudaComputeCapability().IsAtLeast(\n-          se::CudaComputeCapability::kHopper)) {\n-    GTEST_SKIP() << \"FP8 convolutions require HOPPER or newer archiecture.\";\n-  }\n-\n-  const char* hlo = R\"(\n-\n-  HloModule jit_conv_general_dilated\n-\n-  ENTRY main.4 {\n-    Arg_0 = f8e4m3fn[1,64,64,16]{3,2,1,0} parameter(0)\n-    Arg_1 = f8e4m3fn[3,3,16,32]{3,2,1,0} parameter(1)\n-    ROOT conv = f8e4m3fn[1,64,64,32]{3,2,1,0} convolution(Arg_0, Arg_1), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f\n-  }\n-)\";\n-\n-  MatchOptimizedHlo(hlo, R\"(\n-  // CHECK: [[P0:%[^ ]+]] = f8e4m3fn[1,64,64,16]{3,2,1,0} parameter(0)\n-  // CHECK: [[P1:%[^ ]+]] = f8e4m3fn[3,3,16,32]{3,2,1,0} parameter(1)\n-  // CHECK-NEXT: [[P2:%[^ ]+]] = f8e4m3fn[32,3,3,16]{3,2,1,0} transpose([[P1]]), dimensions={3,0,1,2}\n-  // CHECK-NEXT: [[CONV:%[^ ]+]] = (f8e4m3fn[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call([[P0]], [[P2]]), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForwardGraph\"\n-  )\");\n-}\n-\n-TEST_F(LayoutAssignmentTest, ConvCuDNNBF16) {\n-  if (!GetCudaComputeCapability().IsAtLeast(\n-          se::CudaComputeCapability::kAmpere)) {\n-    GTEST_SKIP() << \"Conv with Bfloat16 uses NHWC layout for \"\n-                    \"architectures with Tensor Cores.\";\n-  }\n-\n-  const char* hlo = R\"(\n-\n-  HloModule jit_conv_general_dilated\n-\n-  ENTRY main.4 {\n-    Arg_0.1 = bf16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n-    Arg_1.2 = bf16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n-    ROOT convolution.3 = bf16[1,64,64,32]{3,2,1,0} convolution(Arg_0.1, Arg_1.2), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f, metadata={op_name=\"jit(conv_general_dilated)/jit(main)/conv_general_dilated[window_strides=(1, 1) padding=((1, 1), (1, 1)) lhs_dilation=(1, 1) rhs_dilation=(1, 1) dimension_numbers=ConvDimensionNumbers(lhs_spec=(0, 3, 1, 2), rhs_spec=(3, 2, 0, 1), out_spec=(0, 3, 1, 2)) feature_group_count=1 batch_group_count=1 lhs_shape=(1, 64, 64, 16) rhs_shape=(3, 3, 16, 32) precision=None preferred_element_type=None]\" source_file=\"/usr/local/lib/python3.8/dist-packages/flax/linen/linear.py\" source_line=438}\n-  }\n-)\";\n-\n-  MatchOptimizedHlo(hlo, R\"(\n-  // CHECK: [[P0:%[^ ]+]] = bf16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n-  // CHECK: [[P1:%[^ ]+]] = bf16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n-  // CHECK-NEXT: [[P2:%[^ ]+]] = bf16[32,3,3,16]{3,2,1,0} transpose([[P1]]), dimensions={3,0,1,2}\n-  // CHECK-NEXT: %cudnn-conv.1 = (bf16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call([[P0]], [[P2]]), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\"\n-  )\");\n-}\n-\n-TEST_F(LayoutAssignmentTest, ConvCuDNNFP16) {\n-  if (!GetCudaComputeCapability().IsAtLeast(\n-          se::CudaComputeCapability::kVolta)) {\n-    GTEST_SKIP() << \"Conv with FP16 uses NHWC layout for \"\n-                    \"architectures with Tensor Cores.\";\n-  }\n-\n-  const char* hlo = R\"(\n-\n-  HloModule jit_conv_general_dilated\n-\n-  ENTRY main.4 {\n-    Arg_0.1 = f16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n-    Arg_1.2 = f16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n-    ROOT convolution.3 = f16[1,64,64,32]{3,2,1,0} convolution(Arg_0.1, Arg_1.2), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f\n-  }\n-)\";\n-\n-  MatchOptimizedHlo(hlo, R\"(\n-  // CHECK: [[P0:%[^ ]+]] = f16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n-  // CHECK: [[P1:%[^ ]+]] = f16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n-  // CHECK-NEXT: [[P2:%[^ ]+]] = f16[32,3,3,16]{3,2,1,0} transpose([[P1]]), dimensions={3,0,1,2}\n-  // CHECK-NEXT: %cudnn-conv.1 = (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call([[P0]], [[P2]]), window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\"\n-  )\");\n-}\n-\n TEST_F(LayoutAssignmentTest, ReduceOperandLayout) {\n   const char* module_str = R\"(\n scalar_add_computation {"
        },
        {
            "sha": "f91bea89a7cce5ca6659fd6c7d9713df4c754ee5",
            "filename": "third_party/xla/xla/service/gpu/transforms/layout_assignment_v100.hlo",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Flayout_assignment_v100.hlo?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -0,0 +1,18 @@\n+// RUN: hlo-opt %s --platform=gpu --stage=hlo --xla_gpu_target_config_filename=%S/../../../tools/hlo_opt/gpu_specs/v100.txtpb --split-input-file | FileCheck %s\n+\n+// CHECK: fused_transpose\n+// CHECK-NEXT: f16[3,3,16,32]{3,2,1,0} parameter(0)\n+// CHECK-NEXT: f16[144,32]{1,0} bitcast\n+// CHECK-NEXT: f16[32,144]{1,0} transpose\n+// CHECK-SAME: dimensions={1,0}\n+// CHECK: (f16[1,64,64,32]{3,2,1,0}, u8[0]{0}) custom-call\n+// CHECK-SAME: window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_o01i->b01f, custom_call_target=\"__cudnn$convForward\n+\n+HloModule ConvCuDNN\n+\n+ENTRY main {\n+  Arg_0.1 = f16[1,64,64,16]{3,2,1,0} parameter(0), sharding={replicated}\n+  Arg_1.2 = f16[3,3,16,32]{3,2,1,0} parameter(1), sharding={replicated}\n+  ROOT convolution.3 = f16[1,64,64,32]{3,2,1,0} convolution(Arg_0.1, Arg_1.2),\n+    window={size=3x3 pad=1_1x1_1}, dim_labels=b01f_01io->b01f\n+}"
        },
        {
            "sha": "674c917d19437e05984e26c142d65506a39f29d1",
            "filename": "third_party/xla/xla/service/gpu/triton_fusion_analysis.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 5,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -194,13 +194,17 @@ absl::StatusOr<TritonFusionAnalysis> TritonFusionAnalysis::Execute(\n   TritonFusionAnalysis analysis;\n   const HloInstruction* dot =\n       hlo_query::GetFirstInstructionWithOpcode(computation, HloOpcode::kDot);\n+  if (dot == nullptr) {\n+    dot = hlo_query::GetFirstInstructionWithOpcode(computation,\n+                                                   HloOpcode::kScaledDot);\n+  }\n   TF_RET_CHECK(dot != nullptr);\n   TF_RETURN_IF_ERROR(analysis.ExecuteForDotFusion(*dot, split_k));\n   return analysis;\n }\n \n absl::StatusOr<TritonFusionAnalysis> TritonFusionAnalysis::Execute(\n-    const HloDotInstruction& dot, int split_k) {\n+    const HloInstruction& dot, int split_k) {\n   TritonFusionAnalysis analysis;\n   TF_RETURN_IF_ERROR(analysis.ExecuteForDotFusion(dot, split_k));\n   return analysis;\n@@ -233,9 +237,19 @@ bool TritonFusionAnalysis::IsBatchDimMinorForInt4Parameter(\n \n absl::Status TritonFusionAnalysis::ExecuteForDotFusion(\n     const HloInstruction& dot, const int split_k) {\n+  is_scaled_dot_ = dot.opcode() == HloOpcode::kScaledDot;\n+\n   DotRequirements lhs_requirements(kNoSplitRequirement);\n-  for (const Scope scope : {Scope::LHS, Scope::RHS}) {\n-    const int operand_number = static_cast<int>(scope);\n+  for (const Scope scope :\n+       {Scope::LHS, Scope::RHS, Scope::LHS_SCALE, Scope::RHS_SCALE}) {\n+    int operand_number = static_cast<int>(scope);\n+    if (operand_number >= dot.operand_count()) {\n+      continue;  // Scale operands are optional.\n+    }\n+    if (is_scaled_dot_ && (operand_number == 1 || operand_number == 2)) {\n+      // Operands for scaled dot: (lhs, lhs_scale, rhs, rhs_scale)\n+      operand_number = 3 - operand_number;\n+    }\n     TF_ASSIGN_OR_RETURN(auto context, FusionContext::FromDotOperand(\n                                           dot, operand_number, split_k));\n     TF_RETURN_IF_ERROR(context.PropagateDimensionOrdersToParameters(\n@@ -297,8 +311,10 @@ absl::Status TritonFusionAnalysis::ExecuteForDotFusion(\n \n std::optional<TritonFusionAnalysis::Scope>\n TritonFusionAnalysis::QueryInstructionScope(const HloInstruction& hlo) const {\n-  for (const Scope& scope : {Scope::LHS, Scope::RHS, Scope::OUTPUT}) {\n-    if (iter_specs_.at(scope).count(&hlo) > 0) {\n+  for (const Scope& scope : {Scope::LHS, Scope::RHS, Scope::OUTPUT,\n+                             Scope::LHS_SCALE, Scope::RHS_SCALE}) {\n+    auto it = iter_specs_.find(scope);\n+    if (it != iter_specs_.end() && it->second.count(&hlo) > 0) {\n       return scope;\n     }\n   }\n@@ -336,6 +352,10 @@ std::string ScopeToString(TritonFusionAnalysis::Scope s) {\n       return \"LHS\";\n     case TritonFusionAnalysis::Scope::RHS:\n       return \"RHS\";\n+    case TritonFusionAnalysis::Scope::LHS_SCALE:\n+      return \"LHS_SCALE\";\n+    case TritonFusionAnalysis::Scope::RHS_SCALE:\n+      return \"RHS_SCALE\";\n     case TritonFusionAnalysis::Scope::OUTPUT:\n       return \"OUTPUT\";\n   }"
        },
        {
            "sha": "5ec02dbd325a1e3666a762a54563237384bc32fe",
            "filename": "third_party/xla/xla/service/gpu/triton_fusion_analysis.h",
            "status": "modified",
            "additions": 15,
            "deletions": 4,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -46,13 +46,20 @@ class TritonFusionAnalysis {\n \n   // Execute the analysis of a dot instruction until it reaches the computation\n   // boundaries.\n-  static absl::StatusOr<TritonFusionAnalysis> Execute(\n-      const HloDotInstruction& dot, int split_k = 1);\n+  static absl::StatusOr<TritonFusionAnalysis> Execute(const HloInstruction& dot,\n+                                                      int split_k = 1);\n \n   // A scope is an HLO graph that can be tiled efficiently using same or\n   // compatible tile shapes on all operations. GEMM dot fusion has 3 scopes\n-  // defined by left operand, right operand and output.\n-  enum class Scope { LHS = 0, RHS = 1, OUTPUT = 2 };\n+  // defined by left operand, right operand and output. GEMM scaled dot fusion\n+  // has 5 scopes (also includes scale operands).\n+  enum class Scope {\n+    LHS = 0,\n+    RHS = 1,\n+    LHS_SCALE = 2,\n+    RHS_SCALE = 3,\n+    OUTPUT = 4,\n+  };\n \n   using IterationSpecByInstructionMap =\n       ConstHloInstructionMap<TensorIterationSpec>;\n@@ -90,10 +97,14 @@ class TritonFusionAnalysis {\n   bool IsBatchDimMinorForInt4Parameter(const HloInstruction& dot,\n                                        Scope scope) const;\n \n+  bool is_scaled_dot() const { return is_scaled_dot_; }\n+\n  private:\n   IterationSpecByInstructionByScopeMap iter_specs_;\n   // HLO computation parameters per scope.\n   std::map<Scope, ConstHloInstructionSet> parameters_;\n+  // Scaled dot has additional scale scopes.\n+  bool is_scaled_dot_ = false;\n };\n \n // The details of the Triton fusion / tiling propagation are in a separate"
        },
        {
            "sha": "403bbcd36eb6e439e141af2f30e33ecd2987b192",
            "filename": "third_party/xla/xla/service/gpu/triton_fusion_analysis_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftriton_fusion_analysis_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -919,6 +919,38 @@ triton_gemm_dot {\n                             /*broadcast_multiplier=*/1)));\n }\n \n+TEST_F(TritonDotAnalysisTest, ScaledDotIsSupported) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule test\n+\n+scaled_dot {\n+  %lhs = f32[4,128,1024] parameter(0)\n+  %lhs_scale = f32[4,128,32] parameter(1)\n+  %rhs = f32[4,1024,256] parameter(2)\n+  %rhs_scale = f32[4,32,256] parameter(3)\n+  ROOT %dot = f32[4,128,256] scaled-dot(%lhs, %lhs_scale, %rhs, %rhs_scale),\n+      lhs_batch_dims={0}, lhs_contracting_dims={2},\n+      rhs_batch_dims={0}, rhs_contracting_dims={1}\n+})\"));\n+  const HloComputation* dot_computation = *module->computations().begin();\n+  TF_ASSERT_OK_AND_ASSIGN(const auto analysis,\n+                          TritonFusionAnalysis::Execute(*dot_computation));\n+  const HloInstruction* lhs = dot_computation->parameter_instruction(0);\n+  const HloInstruction* lhs_scale = dot_computation->parameter_instruction(1);\n+  const HloInstruction* rhs = dot_computation->parameter_instruction(2);\n+  const HloInstruction* rhs_scale = dot_computation->parameter_instruction(3);\n+\n+  using Scope = TritonFusionAnalysis::Scope;\n+  EXPECT_EQ(*analysis.ScopeParameters(Scope::LHS).begin(), lhs);\n+  EXPECT_EQ(*analysis.ScopeParameters(Scope::LHS_SCALE).begin(), lhs_scale);\n+  EXPECT_EQ(*analysis.ScopeParameters(Scope::RHS).begin(), rhs);\n+  EXPECT_EQ(*analysis.ScopeParameters(Scope::RHS_SCALE).begin(), rhs_scale);\n+  for (const auto& hlo : dot_computation->instructions()) {\n+    EXPECT_TRUE(analysis.QueryInstructionScope(*hlo).has_value());\n+  }\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "892d340fb8e581444800df409ca417b0df1439ed",
            "filename": "third_party/xla/xla/service/hlo_module_util.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -130,6 +130,19 @@ absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleBinaryProtofile(\n   return HloModule::CreateFromProto(module_proto, module_config);\n }\n \n+absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleTextProtoFile(\n+    absl::string_view hlo_file, const DebugOptions& debug_options) {\n+  HloModuleProto module_proto;\n+  TF_RETURN_IF_ERROR(tsl::ReadTextProto(tsl::Env::Default(),\n+                                        std::string(hlo_file), &module_proto));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      HloModuleConfig module_config,\n+      HloModule::CreateModuleConfigFromProto(module_proto, debug_options));\n+\n+  return HloModule::CreateFromProto(module_proto, module_config);\n+}\n+\n absl::StatusOr<std::unique_ptr<HloModuleConfig>> CreateModuleConfig(\n     const ProgramShape& program_shape,\n     absl::Span<const Shape* const> argument_shapes,"
        },
        {
            "sha": "79cfa7582680e4b60b7e0e1282e3a7f869878bdd",
            "filename": "third_party/xla/xla/service/hlo_module_util.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_util.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -80,6 +80,12 @@ absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromTextProtoFile(\n     absl::string_view hlo_file,\n     const DebugOptions& debug_options = DebugOptions::default_instance());\n \n+// Reads the proto file in xla.HloModuleProto format, creates and returns the\n+// HloModule.\n+absl::StatusOr<std::unique_ptr<HloModule>> ReadModuleFromModuleTextProtoFile(\n+    absl::string_view hlo_file,\n+    const DebugOptions& debug_options = DebugOptions::default_instance());\n+\n // Creates an HloModuleConfig for a given program shape and arguments.\n // If execution_options does not set num_replicas, default_num_replicas is used.\n // num_threads is optional; if not given, intra_op_parallelism_threads not set."
        },
        {
            "sha": "8dd878c9ff7c6bae167a6e45b0c590f5dcc63a9f",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 329,
            "deletions": 353,
            "changes": 682,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66",
            "patch": "@@ -1920,6 +1920,7 @@ absl::Status CheckMixedPrecisionOperands(const HloInstruction* instruction) {\n     case HloOpcode::kConvolution:\n     case HloOpcode::kDot:\n     case HloOpcode::kRaggedDot:\n+    case HloOpcode::kScaledDot:\n     case HloOpcode::kAllReduce:\n     case HloOpcode::kAllReduceStart:\n     case HloOpcode::kAllReduceDone:\n@@ -3141,359 +3142,6 @@ absl::Status CheckElementwiseInstruction(HloInstruction* instruction) {\n   return absl::OkStatus();\n }\n \n-// Visitor which verifies various fields on the HLO instruction. This class does\n-// not check result shape as that is checked in the ShapeVerifier.\n-class InstructionVerifier : public DfsHloVisitorWithDefault {\n- public:\n-  InstructionVerifier(const HloModule* module, const HloVerifierOpts& opts)\n-      : opts_(opts) {\n-    // TODO(b/258285553): Eliminate this check when all paths that enable SPMD\n-    // partitioning also set the num_partitions correctly.\n-    const int64_t num_partitions = module->config().num_partitions();\n-    if (module->config().use_spmd_partitioning() &&\n-        opts.verify_sharding_device_numbers && num_partitions > 1) {\n-      num_devices_ = module->config().num_partitions();\n-    }\n-  }\n-\n-  absl::Status DefaultAction(HloInstruction*) override {\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleFusion(HloInstruction* fusion) override {\n-    TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(fusion));\n-    return CheckFusionInstruction(fusion);\n-  }\n-\n-  absl::Status HandleBroadcast(HloInstruction* broadcast) override {\n-    // If you see this failure then someone has confused the difference\n-    // between the HLO broadcast op, and the UserComputation broadcast\n-    // op. See https://groups.google.com/forum/#!topic/xla-dev/9LqijHmTt_I\n-    // or ComputationLowerer::Visit()\n-    TF_RET_CHECK(broadcast->dimensions().size() ==\n-                 broadcast->operand(0)->shape().dimensions().size())\n-        << \"Broadcast HLO (\" << broadcast->ToShortString()\n-        << \") has invalid number of dimensions: \"\n-        << broadcast->dimensions().size()\n-        << \" != \" << broadcast->operand(0)->shape().dimensions().size();\n-    if (opts_.verify_broadcast_dimensions_order) {\n-      TF_RET_CHECK(absl::c_is_sorted(broadcast->dimensions()))\n-          << \"Broadcast dimensions should be ordered, got: \"\n-          << broadcast->ToString();\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleBitcastConvert(HloInstruction* c) override {\n-    // Shape verifier will check all we need.\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleWhile(HloInstruction* xla_while) override {\n-    auto* while_cond = xla_while->while_condition();\n-    auto* while_body = xla_while->while_body();\n-    if (while_cond->num_parameters() != 1) {\n-      return FailedPrecondition(\n-          \"While condition must have exactly 1 parameter; had %d : %s\",\n-          while_cond->num_parameters(), while_cond->ToString());\n-    }\n-    if (while_body->num_parameters() != 1) {\n-      return FailedPrecondition(\n-          \"While body must have exactly 1 parameter; had %d : %s\",\n-          while_body->num_parameters(), while_body->ToString());\n-    }\n-    if (xla_while->operand_count() != 1) {\n-      return FailedPrecondition(\n-          \"While loop must have exactly one operand; had %d : %s\",\n-          xla_while->operand_count(), xla_while->ToString());\n-    }\n-    // Allow kWhile to contain computations on separate thread.\n-    TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(xla_while));\n-\n-    // Verify consistency of sharding of while instructions and related\n-    // instructions (parameters, root) in its called computations.\n-    TF_RETURN_IF_ERROR(VerifyConsistentSharding(\n-        xla_while, {xla_while, xla_while->while_body()->root_instruction(),\n-                    xla_while->while_body()->parameter_instruction(0),\n-                    xla_while->while_condition()->parameter_instruction(0)}));\n-\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleCall(HloInstruction* call) override {\n-    if (opts_.verify_call_nested_computation_thread_name) {\n-      return CheckCallableInstructionThreadName(call);\n-    }\n-\n-    // As opposed to other callable instructions, nothing respects input/output\n-    // aliasing for call instructions, so make sure it's not set.\n-    const HloCallableInstruction* callable =\n-        DynCast<const HloCallableInstruction>(call);\n-    TF_RET_CHECK(callable != nullptr);\n-    TF_RET_CHECK(callable->output_to_operand_aliasing().empty())\n-        << \"Call instruction \" << call->ToString()\n-        << \" may not have an output-to-operand aliasing set.\";\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleConditional(HloInstruction* conditional) override {\n-    const std::vector<HloComputation*> branch_computations =\n-        conditional->branch_computations();\n-    std::vector<const HloInstruction*> sharding_check_instructions;\n-    sharding_check_instructions.reserve(branch_computations.size() + 1);\n-    sharding_check_instructions.push_back(conditional);\n-\n-    for (const HloComputation* branch_computation : branch_computations) {\n-      if (branch_computation->num_parameters() != 1) {\n-        return FailedPrecondition(\n-            \"Branch computation %s of %s must have 1 parameter instead of %d\",\n-            branch_computation->name(), conditional->ToString(),\n-            branch_computation->num_parameters());\n-      }\n-      sharding_check_instructions.push_back(\n-          branch_computation->root_instruction());\n-    }\n-    // Allow kConditional to contain computations on separate thread.\n-    TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(conditional));\n-\n-    // Verify consistency of sharding of conditional instructions and roots of\n-    // its branches.\n-    TF_RETURN_IF_ERROR(\n-        VerifyConsistentSharding(conditional, sharding_check_instructions));\n-\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleElementwiseUnary(HloInstruction* instruction) override {\n-    TF_RETURN_IF_ERROR(CheckUnaryOpWithResultAccuracy(instruction));\n-    return CheckElementwiseInstruction(instruction);\n-  }\n-\n-  absl::Status HandleElementwiseBinary(HloInstruction* instruction) override {\n-    return CheckElementwiseInstruction(instruction);\n-  }\n-\n-  absl::Status HandleGetTupleElement(HloInstruction* gte) override {\n-    TF_RET_CHECK(gte->operand(0)->shape().IsTuple());\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleTranspose(HloInstruction* transpose) override {\n-    const Shape& shape = transpose->shape();\n-    const HloInstruction* operand = transpose->operand(0);\n-    TF_RET_CHECK(shape.dimensions().size() == transpose->dimensions().size());\n-    TF_RET_CHECK(shape.dimensions().size() ==\n-                 transpose->operand(0)->shape().dimensions().size());\n-    TF_RET_CHECK(std::equal(\n-        shape.dimensions().begin(), shape.dimensions().end(),\n-        Permute(operand->shape().dimensions(), transpose->dimensions())\n-            .begin()))\n-        << \"shape: \" << shape << \", operand->shape(): \" << shape\n-        << \", dimensions: {\" << absl::StrJoin(transpose->dimensions(), \", \")\n-        << \"}\";\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleAllReduce(HloInstruction* crs) override {\n-    if (crs->channel_id().has_value()) {\n-      TF_RET_CHECK(crs->channel_id().value() > 0)\n-          << \"All reduce channel id must be greater than 0 for \"\n-          << crs->ToShortString();\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleReshape(HloInstruction* hlo) override {\n-    if (opts_.verify_reshape_is_bitcast && !hlo->IsFused()) {\n-      TF_RET_CHECK(\n-          ShapeUtil::ReshapeIsBitcast(hlo->operand(0)->shape(), hlo->shape()))\n-          << \"Reshape should be a physical bitcast, got: \" << hlo->ToString();\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleCustomCall(HloInstruction* hlo) override {\n-    if (opts_.verify_call_nested_computation_thread_name) {\n-      // Allow kCustomCall to contain computations on separate thread.\n-      return CheckCallableInstructionThreadName(hlo);\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status HandleScatter(HloInstruction* scatter) override {\n-    int64_t rank = scatter->operand(0)->shape().dimensions().size();\n-    for (int64_t operand_dim :\n-         scatter->scatter_dimension_numbers().scatter_dims_to_operand_dims()) {\n-      if (operand_dim > rank) {\n-        return absl::OutOfRangeError(absl::StrCat(\n-            \"The provided scatter_dims_to_operand_dim was out of range.\",\n-            \" (operand_dim: \", operand_dim, \", rank: \", rank, \")\"));\n-      }\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status Preprocess(HloInstruction* instruction) override {\n-    auto [it, inserted] =\n-        instructions_by_name_.emplace(instruction->name(), instruction);\n-    TF_RET_CHECK(inserted) << \"HLO has name that is not unique within module:\\n\"\n-                           << instruction->ToString() << \" in computation: \"\n-                           << instruction->parent()->name()\n-                           << \"\\nPrevious HLO with same name:\\n\"\n-                           << it->second->ToString() << \" in computation: \"\n-                           << it->second->parent()->name();\n-\n-    if (instruction->has_sharding()) {\n-      absl::Status status =\n-          instruction->sharding().Validate(instruction->shape(), num_devices_);\n-      if (!status.ok()) {\n-        return absl::Status(\n-            status.code(),\n-            absl::StrCat(\"Invalid sharding for instruction: \",\n-                         instruction->ToString(), \": \", status.message()));\n-      }\n-    }\n-\n-    if (opts_.verify_call_nested_computation_thread_name &&\n-        instruction->has_to_apply() &&\n-        xla::GetInstructionCallContext(instruction->opcode()) !=\n-            xla::CallContext::kEmbedded &&\n-        instruction->to_apply()->execution_thread() !=\n-            instruction->parent()->execution_thread()) {\n-      return Internal(\n-          \"Non-Embedded context callable instruction %s to_apply computation \"\n-          \"execution thread does not match (%s vs %s)\",\n-          instruction->name(), instruction->to_apply()->execution_thread(),\n-          instruction->parent()->execution_thread());\n-    }\n-\n-    return absl::OkStatus();\n-  }\n-\n-  absl::Status Postprocess(HloInstruction* instruction) override {\n-    if (opts_.verify_no_host_memory_space) {\n-      TF_RETURN_IF_ERROR(VerifyNoHostMemorySpace(instruction));\n-    }\n-    if (!opts_.InstructionCanChangeLayout(instruction) &&\n-        instruction->shape().IsArray() && instruction->shape().has_layout()) {\n-      const Shape& result_shape = instruction->shape();\n-      const Layout& result_layout = result_shape.layout();\n-      for (HloInstruction* operand : instruction->operands()) {\n-        const Shape& operand_shape = operand->shape();\n-        if (operand_shape.IsArray() &&\n-            operand_shape.dimensions().size() ==\n-                result_shape.dimensions().size() &&\n-            operand_shape.has_layout()) {\n-          const Layout& operand_layout = operand_shape.layout();\n-          Layout::Equal equal_predicate =\n-              Layout::Equal().IgnoreTiles().IgnoreMemorySpace();\n-          if (instruction->opcode() == HloOpcode::kConvert ||\n-              instruction->opcode() == HloOpcode::kCompare ||\n-              instruction->opcode() == HloOpcode::kIsFinite ||\n-              (instruction->opcode() == HloOpcode::kSelect &&\n-               operand_shape.element_type() == PRED) ||\n-              instruction->opcode() == HloOpcode::kScatter) {\n-            // Some instructions can change element_size_in_bits\n-            // Select instructions ignore element_size_in_bits for predicate\n-            equal_predicate.IgnoreElementSize();\n-          } else if (instruction->opcode() == HloOpcode::kDynamicSlice ||\n-                     instruction->opcode() == HloOpcode::kDynamicUpdateSlice ||\n-                     instruction->opcode() == HloOpcode::kCopy) {\n-            TF_RETURN_IF_ERROR(HostOffloadInstructionCanChangeMemorySpace(\n-                instruction, operand_layout.memory_space(),\n-                result_layout.memory_space()));\n-            equal_predicate.IgnoreMemorySpace();\n-          }\n-          TF_RET_CHECK(equal_predicate(result_layout, operand_layout))\n-              << \"Instruction shouldn't change layouts \"\n-              << instruction->ToString() << \" From \" << result_shape << \" To \"\n-              << operand_shape;\n-        }\n-      }\n-    }\n-    return absl::OkStatus();\n-  }\n-\n- private:\n-  static absl::Status VerifyConsistentSharding(\n-      const HloInstruction* parent,\n-      absl::Span<const HloInstruction* const> instructions) {\n-    const HloInstruction* common_sharding_inst = nullptr;\n-    for (const HloInstruction* check_inst : instructions) {\n-      if (!check_inst->has_sharding()) {\n-        continue;\n-      }\n-      if (!common_sharding_inst) {\n-        common_sharding_inst = check_inst;\n-        continue;\n-      }\n-      TF_RET_CHECK(check_inst->sharding() == common_sharding_inst->sharding())\n-          << \"Inconsistent \" << parent->opcode()\n-          << \" sharding among instructions: \\n\"\n-          << common_sharding_inst->ToString() << \"\\n\"\n-          << check_inst->ToString();\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  // Verifies whether a given `instruction` is permitted to change the layout\n-  // memory space from `operand_memory_space` to `result_memory_space`.\n-  // Returns absl::OkStatus() if the instruction's layout changes are valid;\n-  // otherwise, returns an appropriate error status.\n-  static absl::Status HostOffloadInstructionCanChangeMemorySpace(\n-      const HloInstruction* instruction, const int64_t operand_memory_space,\n-      const int64_t result_memory_space) {\n-    TF_RET_CHECK(!(operand_memory_space == Layout::kGenericFastMemorySpace &&\n-                   result_memory_space != Layout::kGenericFastMemorySpace) ||\n-                 (operand_memory_space != Layout::kGenericFastMemorySpace &&\n-                  result_memory_space == Layout::kGenericFastMemorySpace))\n-        << \"Instruction shouldn't change layout memory space between generic \"\n-           \"fast memory space and others for instruction: \"\n-        << instruction->ToString();\n-\n-    if (instruction->opcode() == HloOpcode::kDynamicSlice) {\n-      TF_RET_CHECK(!(operand_memory_space == Layout::kDefaultMemorySpace &&\n-                     result_memory_space == Layout::kHostMemorySpace))\n-          << \"DynamicSlice instruction shouldn't change layout memory \"\n-          << \"space from device to host: \" << instruction->ToString();\n-    } else if (instruction->opcode() == HloOpcode::kDynamicUpdateSlice) {\n-      TF_RET_CHECK(!(operand_memory_space == Layout::kHostMemorySpace &&\n-                     result_memory_space == Layout::kDefaultMemorySpace))\n-          << \"DynamicUpdateSlice instruction shouldn't change layout \"\n-          << \"memory space from host to device: \" << instruction->ToString();\n-    } else if (instruction->opcode() != HloOpcode::kCopy) {\n-      return absl::InvalidArgumentError(\n-          absl::StrCat(\"Instruction shouldn't change layout memory space: \",\n-                       instruction->ToString()));\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  // Returns an error status if an instruction or any operand contains host\n-  // memory space.\n-  static absl::Status VerifyNoHostMemorySpace(\n-      const HloInstruction* instruction) {\n-    return ShapeUtil::ForEachSubshapeWithStatus(\n-        instruction->shape(),\n-        [&](const Shape& subshape, const ShapeIndex& index) -> absl::Status {\n-          if (subshape.has_layout()) {\n-            const Layout& result_layout = subshape.layout();\n-            if (result_layout.memory_space() == Layout::kHostMemorySpace) {\n-              return absl::InternalError(absl::StrCat(\n-                  \"Instruction shouldn't have the layout of host memory \"\n-                  \"space: \",\n-                  instruction->ToString()));\n-            }\n-          }\n-          return absl::OkStatus();\n-        });\n-  }\n-\n-  absl::flat_hash_map<std::string, const HloInstruction*> instructions_by_name_;\n-  const HloVerifierOpts& opts_;\n-  std::optional<int64_t> num_devices_;\n-};\n-\n bool IsCollectivesGroupComputation(HloComputation* computation) {\n   auto maybe_caller = computation->GetUniqueCaller(HloOpcode::kAsyncStart);\n   if (!maybe_caller.has_value()) {\n@@ -3829,6 +3477,334 @@ absl::Status VerifyBuffers(const HloModule& module, bool layout_sentitive) {\n \n }  // namespace\n \n+absl::Status InstructionVerifier::DefaultAction(HloInstruction*) {\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleFusion(HloInstruction* fusion) {\n+  TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(fusion));\n+  return CheckFusionInstruction(fusion);\n+}\n+\n+absl::Status InstructionVerifier::HandleBroadcast(HloInstruction* broadcast) {\n+  // If you see this failure then someone has confused the difference\n+  // between the HLO broadcast op, and the UserComputation broadcast\n+  // op. See https://groups.google.com/forum/#!topic/xla-dev/9LqijHmTt_I\n+  // or ComputationLowerer::Visit()\n+  TF_RET_CHECK(broadcast->dimensions().size() ==\n+               broadcast->operand(0)->shape().dimensions().size())\n+      << \"Broadcast HLO (\" << broadcast->ToShortString()\n+      << \") has invalid number of dimensions: \"\n+      << broadcast->dimensions().size()\n+      << \" != \" << broadcast->operand(0)->shape().dimensions().size();\n+  if (opts_.verify_broadcast_dimensions_order) {\n+    TF_RET_CHECK(absl::c_is_sorted(broadcast->dimensions()))\n+        << \"Broadcast dimensions should be ordered, got: \"\n+        << broadcast->ToString();\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleBitcastConvert(HloInstruction* c) {\n+  // Shape verifier will check all we need.\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleWhile(HloInstruction* xla_while) {\n+  auto* while_cond = xla_while->while_condition();\n+  auto* while_body = xla_while->while_body();\n+  if (while_cond->num_parameters() != 1) {\n+    return FailedPrecondition(\n+        \"While condition must have exactly 1 parameter; had %d : %s\",\n+        while_cond->num_parameters(), while_cond->ToString());\n+  }\n+  if (while_body->num_parameters() != 1) {\n+    return FailedPrecondition(\n+        \"While body must have exactly 1 parameter; had %d : %s\",\n+        while_body->num_parameters(), while_body->ToString());\n+  }\n+  if (xla_while->operand_count() != 1) {\n+    return FailedPrecondition(\n+        \"While loop must have exactly one operand; had %d : %s\",\n+        xla_while->operand_count(), xla_while->ToString());\n+  }\n+  // Allow kWhile to contain computations on separate thread.\n+  TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(xla_while));\n+\n+  // Verify consistency of sharding of while instructions and related\n+  // instructions (parameters, root) in its called computations.\n+  TF_RETURN_IF_ERROR(VerifyConsistentSharding(\n+      xla_while, {xla_while, xla_while->while_body()->root_instruction(),\n+                  xla_while->while_body()->parameter_instruction(0),\n+                  xla_while->while_condition()->parameter_instruction(0)}));\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleCall(HloInstruction* call) {\n+  if (opts_.verify_call_nested_computation_thread_name) {\n+    return CheckCallableInstructionThreadName(call);\n+  }\n+\n+  // As opposed to other callable instructions, nothing respects input/output\n+  // aliasing for call instructions, so make sure it's not set.\n+  const HloCallableInstruction* callable =\n+      DynCast<const HloCallableInstruction>(call);\n+  TF_RET_CHECK(callable != nullptr);\n+  TF_RET_CHECK(callable->output_to_operand_aliasing().empty())\n+      << \"Call instruction \" << call->ToString()\n+      << \" may not have an output-to-operand aliasing set.\";\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleConditional(\n+    HloInstruction* conditional) {\n+  const std::vector<HloComputation*> branch_computations =\n+      conditional->branch_computations();\n+  std::vector<const HloInstruction*> sharding_check_instructions;\n+  sharding_check_instructions.reserve(branch_computations.size() + 1);\n+  sharding_check_instructions.push_back(conditional);\n+\n+  for (const HloComputation* branch_computation : branch_computations) {\n+    if (branch_computation->num_parameters() != 1) {\n+      return FailedPrecondition(\n+          \"Branch computation %s of %s must have 1 parameter instead of %d\",\n+          branch_computation->name(), conditional->ToString(),\n+          branch_computation->num_parameters());\n+    }\n+    sharding_check_instructions.push_back(\n+        branch_computation->root_instruction());\n+  }\n+  // Allow kConditional to contain computations on separate thread.\n+  TF_RETURN_IF_ERROR(CheckCallableInstructionThreadName(conditional));\n+\n+  // Verify consistency of sharding of conditional instructions and roots of\n+  // its branches.\n+  TF_RETURN_IF_ERROR(\n+      VerifyConsistentSharding(conditional, sharding_check_instructions));\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleElementwiseUnary(\n+    HloInstruction* instruction) {\n+  TF_RETURN_IF_ERROR(CheckUnaryOpWithResultAccuracy(instruction));\n+  return CheckElementwiseInstruction(instruction);\n+}\n+\n+absl::Status InstructionVerifier::HandleElementwiseBinary(\n+    HloInstruction* instruction) {\n+  return CheckElementwiseInstruction(instruction);\n+}\n+\n+absl::Status InstructionVerifier::HandleGetTupleElement(HloInstruction* gte) {\n+  TF_RET_CHECK(gte->operand(0)->shape().IsTuple());\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleTranspose(HloInstruction* transpose) {\n+  const Shape& shape = transpose->shape();\n+  const HloInstruction* operand = transpose->operand(0);\n+  TF_RET_CHECK(shape.dimensions().size() == transpose->dimensions().size());\n+  TF_RET_CHECK(shape.dimensions().size() ==\n+               transpose->operand(0)->shape().dimensions().size());\n+  TF_RET_CHECK(std::equal(\n+      shape.dimensions().begin(), shape.dimensions().end(),\n+      Permute(operand->shape().dimensions(), transpose->dimensions()).begin()))\n+      << \"shape: \" << shape << \", operand->shape(): \" << shape\n+      << \", dimensions: {\" << absl::StrJoin(transpose->dimensions(), \", \")\n+      << \"}\";\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleAllReduce(HloInstruction* crs) {\n+  if (crs->channel_id().has_value()) {\n+    TF_RET_CHECK(crs->channel_id().value() > 0)\n+        << \"All reduce channel id must be greater than 0 for \"\n+        << crs->ToShortString();\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleReshape(HloInstruction* hlo) {\n+  if (opts_.verify_reshape_is_bitcast && !hlo->IsFused()) {\n+    TF_RET_CHECK(\n+        ShapeUtil::ReshapeIsBitcast(hlo->operand(0)->shape(), hlo->shape()))\n+        << \"Reshape should be a physical bitcast, got: \" << hlo->ToString();\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleCustomCall(HloInstruction* hlo) {\n+  if (opts_.verify_call_nested_computation_thread_name) {\n+    // Allow kCustomCall to contain computations on separate thread.\n+    return CheckCallableInstructionThreadName(hlo);\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HandleScatter(HloInstruction* scatter) {\n+  int64_t rank = scatter->operand(0)->shape().dimensions().size();\n+  for (int64_t operand_dim :\n+       scatter->scatter_dimension_numbers().scatter_dims_to_operand_dims()) {\n+    if (operand_dim > rank) {\n+      return absl::OutOfRangeError(absl::StrCat(\n+          \"The provided scatter_dims_to_operand_dim was out of range.\",\n+          \" (operand_dim: \", operand_dim, \", rank: \", rank, \")\"));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::Preprocess(HloInstruction* instruction) {\n+  auto [it, inserted] =\n+      instructions_by_name_.emplace(instruction->name(), instruction);\n+  TF_RET_CHECK(inserted) << \"HLO has name that is not unique within module:\\n\"\n+                         << instruction->ToString()\n+                         << \" in computation: \" << instruction->parent()->name()\n+                         << \"\\nPrevious HLO with same name:\\n\"\n+                         << it->second->ToString()\n+                         << \" in computation: \" << it->second->parent()->name();\n+\n+  if (instruction->has_sharding()) {\n+    absl::Status status =\n+        instruction->sharding().Validate(instruction->shape(), num_devices_);\n+    if (!status.ok()) {\n+      return absl::Status(\n+          status.code(),\n+          absl::StrCat(\"Invalid sharding for instruction: \",\n+                       instruction->ToString(), \": \", status.message()));\n+    }\n+  }\n+\n+  if (opts_.verify_call_nested_computation_thread_name &&\n+      instruction->has_to_apply() &&\n+      xla::GetInstructionCallContext(instruction->opcode()) !=\n+          xla::CallContext::kEmbedded &&\n+      instruction->to_apply()->execution_thread() !=\n+          instruction->parent()->execution_thread()) {\n+    return Internal(\n+        \"Non-Embedded context callable instruction %s to_apply computation \"\n+        \"execution thread does not match (%s vs %s)\",\n+        instruction->name(), instruction->to_apply()->execution_thread(),\n+        instruction->parent()->execution_thread());\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::Postprocess(HloInstruction* instruction) {\n+  if (opts_.verify_no_host_memory_space) {\n+    TF_RETURN_IF_ERROR(VerifyNoHostMemorySpace(instruction));\n+  }\n+  if (!opts_.InstructionCanChangeLayout(instruction) &&\n+      instruction->shape().IsArray() && instruction->shape().has_layout()) {\n+    const Shape& result_shape = instruction->shape();\n+    const Layout& result_layout = result_shape.layout();\n+    for (HloInstruction* operand : instruction->operands()) {\n+      const Shape& operand_shape = operand->shape();\n+      if (operand_shape.IsArray() &&\n+          operand_shape.dimensions().size() ==\n+              result_shape.dimensions().size() &&\n+          operand_shape.has_layout()) {\n+        const Layout& operand_layout = operand_shape.layout();\n+        Layout::Equal equal_predicate =\n+            Layout::Equal().IgnoreTiles().IgnoreMemorySpace();\n+        if (instruction->opcode() == HloOpcode::kConvert ||\n+            instruction->opcode() == HloOpcode::kCompare ||\n+            instruction->opcode() == HloOpcode::kIsFinite ||\n+            (instruction->opcode() == HloOpcode::kSelect &&\n+             operand_shape.element_type() == PRED) ||\n+            instruction->opcode() == HloOpcode::kScatter) {\n+          // Some instructions can change element_size_in_bits\n+          // Select instructions ignore element_size_in_bits for predicate\n+          equal_predicate.IgnoreElementSize();\n+        } else if (instruction->opcode() == HloOpcode::kDynamicSlice ||\n+                   instruction->opcode() == HloOpcode::kDynamicUpdateSlice ||\n+                   instruction->opcode() == HloOpcode::kCopy) {\n+          TF_RETURN_IF_ERROR(HostOffloadInstructionCanChangeMemorySpace(\n+              instruction, operand_layout.memory_space(),\n+              result_layout.memory_space()));\n+          equal_predicate.IgnoreMemorySpace();\n+        }\n+        TF_RET_CHECK(equal_predicate(result_layout, operand_layout))\n+            << \"Instruction shouldn't change layouts \"\n+            << instruction->ToString() << \" From \" << result_shape << \" To \"\n+            << operand_shape;\n+      }\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::VerifyConsistentSharding(\n+    const HloInstruction* parent,\n+    absl::Span<const HloInstruction* const> instructions) {\n+  const HloInstruction* common_sharding_inst = nullptr;\n+  for (const HloInstruction* check_inst : instructions) {\n+    if (!check_inst->has_sharding()) {\n+      continue;\n+    }\n+    if (!common_sharding_inst) {\n+      common_sharding_inst = check_inst;\n+      continue;\n+    }\n+    TF_RET_CHECK(check_inst->sharding() == common_sharding_inst->sharding())\n+        << \"Inconsistent \" << parent->opcode()\n+        << \" sharding among instructions: \\n\"\n+        << common_sharding_inst->ToString() << \"\\n\"\n+        << check_inst->ToString();\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::HostOffloadInstructionCanChangeMemorySpace(\n+    const HloInstruction* instruction, const int64_t operand_memory_space,\n+    const int64_t result_memory_space) {\n+  TF_RET_CHECK(!(operand_memory_space == Layout::kGenericFastMemorySpace &&\n+                 result_memory_space != Layout::kGenericFastMemorySpace) ||\n+               (operand_memory_space != Layout::kGenericFastMemorySpace &&\n+                result_memory_space == Layout::kGenericFastMemorySpace))\n+      << \"Instruction shouldn't change layout memory space between generic \"\n+         \"fast memory space and others for instruction: \"\n+      << instruction->ToString();\n+\n+  if (instruction->opcode() == HloOpcode::kDynamicSlice) {\n+    TF_RET_CHECK(!(operand_memory_space == Layout::kDefaultMemorySpace &&\n+                   result_memory_space == Layout::kHostMemorySpace))\n+        << \"DynamicSlice instruction shouldn't change layout memory \"\n+        << \"space from device to host: \" << instruction->ToString();\n+  } else if (instruction->opcode() == HloOpcode::kDynamicUpdateSlice) {\n+    TF_RET_CHECK(!(operand_memory_space == Layout::kHostMemorySpace &&\n+                   result_memory_space == Layout::kDefaultMemorySpace))\n+        << \"DynamicUpdateSlice instruction shouldn't change layout \"\n+        << \"memory space from host to device: \" << instruction->ToString();\n+  } else if (instruction->opcode() != HloOpcode::kCopy) {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Instruction shouldn't change layout memory space: \",\n+                     instruction->ToString()));\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::Status InstructionVerifier::VerifyNoHostMemorySpace(\n+    const HloInstruction* instruction) {\n+  return ShapeUtil::ForEachSubshapeWithStatus(\n+      instruction->shape(),\n+      [&](const Shape& subshape, const ShapeIndex& index) -> absl::Status {\n+        if (subshape.has_layout()) {\n+          const Layout& result_layout = subshape.layout();\n+          if (result_layout.memory_space() == Layout::kHostMemorySpace) {\n+            return absl::InternalError(absl::StrCat(\n+                \"Instruction shouldn't have the layout of host memory \"\n+                \"space: \",\n+                instruction->ToString()));\n+          }\n+        }\n+        return absl::OkStatus();\n+      });\n+}\n+\n absl::StatusOr<bool> HloVerifier::Run(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {"
        },
        {
            "sha": "4e58a97ff7bfccb8d18bed8d6223f763cb79b7a7",
            "filename": "third_party/xla/xla/service/hlo_verifier.h",
            "status": "modified",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "9c44bb05811d196d1dbdedae00bd6901c78011f6",
            "filename": "third_party/xla/xla/service/hlo_verifier_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "4cc6507e5f2ae35e73d12662cdc9a138ccfe9e01",
            "filename": "third_party/xla/xla/service/layout_normalization.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 2,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "cbb8fcabbed34b96ca86770e7b47e669d7035518",
            "filename": "third_party/xla/xla/service/layout_normalization_test.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 24,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "fc1a80067ea6d38513079d8c409b782b47f1c658",
            "filename": "third_party/xla/xla/service/llvm_ir/ir_array.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fir_array.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fir_array.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fir_array.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "bfb59838981d8e25fbf1c070fdde5d1bca14a18d",
            "filename": "third_party/xla/xla/service/memory_space_assignment/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "6441d9cecd16a9814434cb84094abfd45c9f0ad7",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 386,
            "deletions": 140,
            "changes": 526,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "89cadcb1effa88457e83f34434f704b659ab6a38",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 27,
            "deletions": 18,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "7f9b61d25d4a0e6fb817419c5daaad35c001b4a7",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "a37f7f7faf5ab5a9965909b37aae56736c4b27fd",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "c6c3555a002ffa1050adbb53b29735b36410b41e",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation_value.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "92e59c2be4d0c2a62f87e3f33f406802a64a8792",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.proto",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "42c31500ed8ff0d33f08e53d29fce4c09a700ba3",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 466,
            "deletions": 156,
            "changes": 622,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "3511c5440c2fe8d9a0e5e74dbfa7fc32352a83ac",
            "filename": "third_party/xla/xla/service/memory_space_assignment/options.h",
            "status": "modified",
            "additions": 23,
            "deletions": 19,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "cadfeb695760db9ada753b366c0b519728b81ead",
            "filename": "third_party/xla/xla/service/scatter_expander_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 26,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_expander_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_expander_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_expander_test.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "1b8157ba6ce700409f811fb07dd7c418990cb661",
            "filename": "third_party/xla/xla/service/service.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fservice.cc?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        },
        {
            "sha": "62a9a9ff76df9105b1217e5af6532be1b0d3bca0",
            "filename": "third_party/xla/xla/service/spmd/shardy/constants.h",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fconstants.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/682659f1d20f53d82008992cc183a09a70ee2a66/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fconstants.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fshardy%2Fconstants.h?ref=682659f1d20f53d82008992cc183a09a70ee2a66"
        }
    ],
    "stats": {
        "total": 49960,
        "additions": 32428,
        "deletions": 17532
    }
}