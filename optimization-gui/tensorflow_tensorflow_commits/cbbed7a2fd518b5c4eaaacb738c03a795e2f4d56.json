{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 823350718",
    "sha": "cbbed7a2fd518b5c4eaaacb738c03a795e2f4d56",
    "files": [
        {
            "sha": "0c43379259ea6ea33a97f3dc54cf95746e1bdf1c",
            "filename": "third_party/xla/xla/hlo/tools/hlo_translate.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 6,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cbbed7a2fd518b5c4eaaacb738c03a795e2f4d56/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_translate.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cbbed7a2fd518b5c4eaaacb738c03a795e2f4d56/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_translate.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftools%2Fhlo_translate.cc?ref=cbbed7a2fd518b5c4eaaacb738c03a795e2f4d56",
            "patch": "@@ -121,15 +121,18 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> GetModuleFromHLOText(\n   auto status = ConvertHloToMlirHlo(*module, hlo_module.get(),\n                                     /*import_all_computations=*/true,\n                                     /*flatten_computation_args_result*/ true);\n-  if (!status.ok()) return status;\n+  if (!status.ok()) {\n+    return status;\n+  }\n   return module;\n }\n \n absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> GetModuleFromHLOProto(\n     const std::string& content, mlir::MLIRContext* context, bool emit_mhlo) {\n   xla::HloProto hlo_proto;\n-  if (!LoadHloProto(content, &hlo_proto))\n+  if (!LoadHloProto(content, &hlo_proto)) {\n     return absl::InvalidArgumentError(kLoadHloError);\n+  }\n \n   // For emitting StableHLO, use new APIs by defualt.\n   if (!emit_mhlo) {\n@@ -143,7 +146,9 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> GetModuleFromHLOProto(\n       ConvertHloToMlirHlo(module.get(), hlo_proto.mutable_hlo_module(),\n                           /*import_all_computations=*/true,\n                           /*flatten_computation_args_result=*/true);\n-  if (!status.ok()) return status;\n+  if (!status.ok()) {\n+    return status;\n+  }\n   return module;\n }\n \n@@ -164,7 +169,9 @@ mlir::OwningOpRef<mlir::ModuleOp> GetModuleFromHloInput(\n \n   // Try HLO Text\n   auto module_from_text = GetModuleFromHLOText(content, context, emit_mhlo);\n-  if (module_from_text.ok()) return std::move(module_from_text).value();\n+  if (module_from_text.ok()) {\n+    return std::move(module_from_text).value();\n+  }\n   if (module_from_text.status().message().rfind(kLoadHloError, 0) != 0) {\n     emitError() << \"Failed to convert HLO to MLIR: \"\n                 << module_from_text.status().message();\n@@ -174,7 +181,9 @@ mlir::OwningOpRef<mlir::ModuleOp> GetModuleFromHloInput(\n   // Try HLO Proto\n   auto module_from_proto =\n       GetModuleFromHLOProto(std::string(content), context, emit_mhlo);\n-  if (module_from_proto.ok()) return std::move(module_from_proto).value();\n+  if (module_from_proto.ok()) {\n+    return std::move(module_from_proto).value();\n+  }\n   if (module_from_text.status().message().rfind(kLoadHloError, 0) != 0) {\n     emitError() << \"Failed to convert HLO to MLIR: \"\n                 << module_from_proto.status().message();\n@@ -195,7 +204,9 @@ static mlir::OwningOpRef<mlir::ModuleOp> HloToMlirTranslate(\n   mlir::OwningOpRef<mlir::ModuleOp> module =\n       GetModuleFromHloInput(sourceMgr, context, emit_mhlo);\n \n-  if (!module) return nullptr;\n+  if (!module) {\n+    return nullptr;\n+  }\n \n   return module;\n }"
        }
    ],
    "stats": {
        "total": 23,
        "additions": 17,
        "deletions": 6
    }
}