{
    "author": "yangustc07",
    "message": "Add testDifferentDatasetIdsForSameJob test.\n\nThis verifies behavior when creating iterators with the same job_name\nbut different dataset IDs.\n\nPiperOrigin-RevId: 816921861",
    "sha": "bcb2962ee50a5116b90b73c1adba8be7e527fc9a",
    "files": [
        {
            "sha": "a88a167b75b3cadaadf7b511bf73441e7e823288",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/dynamic_sharding_test.py",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcb2962ee50a5116b90b73c1adba8be7e527fc9a/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcb2962ee50a5116b90b73c1adba8be7e527fc9a/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py?ref=bcb2962ee50a5116b90b73c1adba8be7e527fc9a",
            "patch": "@@ -465,6 +465,44 @@ def testMultipleRegistration(self):\n     output.extend(self.getIteratorOutput(iter2))\n     self.assertEqual(sorted(output), list(range(100)))\n \n+  @combinations.generate(test_base.default_test_combinations())\n+  def testDifferentDatasetIdsForSameJob(self):\n+    cluster = data_service_test_base.TestCluster(num_workers=2)\n+    dataset = dataset_ops.Dataset.range(100)\n+    dataset_id1 = data_service_ops.register_dataset(\n+        cluster.dispatcher_address(), dataset, dataset_id=\"dataset_id1\"\n+    )\n+    dataset1 = data_service_ops.from_dataset_id(\n+        data_service_ops.ShardingPolicy.DYNAMIC,\n+        cluster.dispatcher_address(),\n+        dataset_id1,\n+        element_spec=dataset.element_spec,\n+        job_name=\"shared_job\",\n+    )\n+\n+    dataset_id2 = data_service_ops.register_dataset(\n+        cluster.dispatcher_address(), dataset, dataset_id=\"dataset_id2\"\n+    )\n+    dataset2 = data_service_ops.from_dataset_id(\n+        data_service_ops.ShardingPolicy.DYNAMIC,\n+        cluster.dispatcher_address(),\n+        dataset_id2,\n+        element_spec=dataset.element_spec,\n+        job_name=\"shared_job\",\n+    )\n+\n+    output = []\n+    iter1 = self.getNext(dataset1)\n+    iter2 = self.getNext(dataset2)\n+    for _ in range(5):\n+      output.append(self.evaluate(iter1()))\n+      output.append(self.evaluate(iter2()))\n+    output.extend(self.getIteratorOutput(iter1))\n+    output.extend(self.getIteratorOutput(iter2))\n+    # Produces 2 copies of the dataset because `from_dataset_id` prepends the\n+    # dataset ID to the job name.\n+    self.assertCountEqual(output, list(range(100)) * 2)\n+\n \n class DynamicShardingFilesTest(data_service_test_base.TestBase,\n                                tf_record_test_base.TFRecordTestBase,"
        }
    ],
    "stats": {
        "total": 38,
        "additions": 38,
        "deletions": 0
    }
}