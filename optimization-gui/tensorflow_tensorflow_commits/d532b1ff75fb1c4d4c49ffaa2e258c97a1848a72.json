{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 828856193",
    "sha": "d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
    "files": [
        {
            "sha": "74c888d37de7845bd13d16f716e6b683b7406039",
            "filename": "tensorflow/compiler/tf2xla/kernels/all_reduce_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fall_reduce_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fall_reduce_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fall_reduce_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -94,9 +94,9 @@ class CollectiveReduceV2Op : public XlaOpKernel {\n \n  private:\n   DataType dtype_ = DT_INVALID;\n-  string merge_op_name_;\n-  string final_op_name_;\n-  string communication_hint_;\n+  std::string merge_op_name_;\n+  std::string final_op_name_;\n+  std::string communication_hint_;\n \n   CollectiveReduceV2Op(const CollectiveReduceV2Op&) = delete;\n   void operator=(const CollectiveReduceV2Op&) = delete;"
        },
        {
            "sha": "240a099f075aa28071cfca948a32686014e43a5e",
            "filename": "tensorflow/compiler/tf2xla/kernels/batch_norm_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbatch_norm_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbatch_norm_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbatch_norm_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -48,7 +48,7 @@ class FusedBatchNormOp : public XlaOpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"is_training\", &is_training_));\n     OP_REQUIRES_OK(\n         ctx, ctx->GetAttr(\"exponential_avg_factor\", &exponential_avg_factor_));\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(\n         ctx, FormatFromString(data_format_str, &data_format_),\n@@ -61,7 +61,7 @@ class FusedBatchNormOp : public XlaOpKernel {\n                   errors::InvalidArgument(\n                       \"FusedBatchNormEx supports at most 1 side input.\"));\n       add_side_input_ = (num_side_inputs == 1);\n-      string activation_mode;\n+      std::string activation_mode;\n       OP_REQUIRES_OK(ctx, ctx->GetAttr(\"activation_mode\", &activation_mode));\n       OP_REQUIRES(ctx,\n                   activation_mode == \"Identity\" || activation_mode == \"Relu\",\n@@ -249,7 +249,7 @@ class FusedBatchNormGradOp : public XlaOpKernel {\n   explicit FusedBatchNormGradOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"epsilon\", &epsilon_));\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"is_training\", &is_training_));\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(\n         ctx, FormatFromString(data_format_str, &data_format_),"
        },
        {
            "sha": "94486a104152ea1b29d5b054a8bc154dc534870c",
            "filename": "tensorflow/compiler/tf2xla/kernels/bcast_ops.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbcast_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbcast_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbcast_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -66,9 +66,11 @@ class BCastArgsOp : public XlaOpKernel {\n     Tensor output(val_type, TensorShape({len}));\n     for (int64_t i = 0; i < len; ++i) {\n       if (val_type == DT_INT32) {\n-        output.flat<int32>()(i) = static_cast<int32>(bcast.output_shape()[i]);\n+        output.flat<int32_t>()(i) =\n+            static_cast<int32_t>(bcast.output_shape()[i]);\n       } else {\n-        output.flat<int64>()(i) = static_cast<int64>(bcast.output_shape()[i]);\n+        output.flat<int64_t>()(i) =\n+            static_cast<int64_t>(bcast.output_shape()[i]);\n       }\n     }\n     ctx->SetConstantOutput(0, output);\n@@ -129,9 +131,9 @@ class BCastGradArgsOp : public XlaOpKernel {\n     Tensor constant(val_type, TensorShape({len}));\n     for (int64_t i = 0; i < len; ++i) {\n       if (val_type == DT_INT32) {\n-        constant.flat<int32>()(i) = static_cast<int32>(v[i]);\n+        constant.flat<int32_t>()(i) = static_cast<int32_t>(v[i]);\n       } else {\n-        constant.flat<int64>()(i) = static_cast<int64>(v[i]);\n+        constant.flat<int64_t>()(i) = static_cast<int64_t>(v[i]);\n       }\n     }\n     ctx->SetConstantOutput(idx, constant);"
        },
        {
            "sha": "bf428711664d7616886fbf7ef8f642a5e9960f43",
            "filename": "tensorflow/compiler/tf2xla/kernels/bias_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbias_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbias_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbias_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -28,7 +28,7 @@ namespace {\n class BiasOp : public XlaOpKernel {\n  public:\n   explicit BiasOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n-    string data_format;\n+    std::string data_format;\n     if (ctx->GetAttr(\"data_format\", &data_format).ok()) {\n       OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                   errors::InvalidArgument(\"Invalid data format\"));"
        },
        {
            "sha": "7d323b16d8856e0f8b78456dc99db661afe06ca4",
            "filename": "tensorflow/compiler/tf2xla/kernels/bucketize_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbucketize_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbucketize_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fbucketize_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -55,7 +55,7 @@ class BucketizeOp : public XlaOpKernel {\n                                         /*broadcast_dimensions=*/{0}),\n                                 xla::S32);\n     xla::XlaOp buckets = xla::Reduce(\n-        comparison, /*init_value=*/xla::ConstantR0<int32>(builder, 0),\n+        comparison, /*init_value=*/xla::ConstantR0<int32_t>(builder, 0),\n         /*computation=*/xla::CreateScalarAddComputation(xla::S32, builder),\n         /*dimensions_to_reduce=*/{0});\n     context->SetOutput(0, buckets);"
        },
        {
            "sha": "da40d84e73f063395a1636bc58ccc55578c514cb",
            "filename": "tensorflow/compiler/tf2xla/kernels/case_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -66,7 +66,7 @@ XlaCaseOp::GetPrunedBranchesAndIndex(XlaOpKernelContext* ctx) {\n     return {unpruned_branches_, ctx->Input(0)};\n   }\n \n-  int32_t branch_index = branch_index_literal.Get<int32>({});\n+  int32_t branch_index = branch_index_literal.Get<int32_t>({});\n   if (branch_index < 0 || branch_index >= unpruned_branches_.size()) {\n     branch_index = unpruned_branches_.size() - 1;\n   }\n@@ -187,7 +187,8 @@ void XlaCaseOp::Compile(XlaOpKernelContext* ctx) {\n \n       // Add any TensorArray gradients touched by the then/else computation to\n       // the enclosing graph.\n-      for (const string& grad_source : update.tensor_array_gradients_accessed) {\n+      for (const std::string& grad_source :\n+           update.tensor_array_gradients_accessed) {\n         VLOG(5) << \"TensorArray \" << resource->name() << \" accessed gradient \"\n                 << grad_source;\n         XlaResource* gradient;\n@@ -289,7 +290,7 @@ void XlaCaseOp::Compile(XlaOpKernelContext* ctx) {\n       // Set token input for this \"case\" op.\n       std::vector<xla::XlaOp> token_inputs;\n       token_inputs.reserve(token_input_nodes_.size());\n-      for (const string& node_name : token_input_nodes_) {\n+      for (const std::string& node_name : token_input_nodes_) {\n         auto token_or = compiler->GetNodeToken(node_name);\n         OP_REQUIRES_OK(ctx, token_or.status());\n         token_inputs.push_back(token_or.value());"
        },
        {
            "sha": "6574fb4aac4c5ee0c41e93e7386f7ed37e155cc7",
            "filename": "tensorflow/compiler/tf2xla/kernels/case_op.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcase_op.h?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -65,8 +65,8 @@ class XlaCaseOp : public XlaOpKernel {\n   DataTypeVector input_types_;\n   DataTypeVector output_types_;\n   bool has_token_input_output_;\n-  std::vector<string> token_input_nodes_;\n-  string original_node_name_;\n+  std::vector<std::string> token_input_nodes_;\n+  std::string original_node_name_;\n   // Whether to propagate compile time consts into the cond branches.\n   // This is not supported by default now since it may cause HBM memory\n   // overheads."
        },
        {
            "sha": "2c69974d8373dc1fff22ee2800dcc9ada2485217",
            "filename": "tensorflow/compiler/tf2xla/kernels/categorical_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcategorical_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcategorical_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fcategorical_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -185,7 +185,7 @@ class StatelessCategoricalOp : public CategoricalOp {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessCategoricalOp(const StatelessCategoricalOp&) = delete;\n   void operator=(const StatelessCategoricalOp&) = delete;"
        },
        {
            "sha": "7ab53f7ad89e75e5cf665f69c9e16a98fafdcf4f",
            "filename": "tensorflow/compiler/tf2xla/kernels/const_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconst_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconst_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconst_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -38,7 +38,7 @@ template <typename DstT,\n                                   std::is_same<DstT, bfloat16>::value>::type* =\n               nullptr>\n DstT CastTo(int32_t src) {\n-  return absl::bit_cast<DstT>(static_cast<uint16>(src));\n+  return absl::bit_cast<DstT>(static_cast<uint16_t>(src));\n }\n \n // Returns scalar constant with the value in the tensor, if the given proto has"
        },
        {
            "sha": "59f72e630c0f757285f7665e3283798666ea3e21",
            "filename": "tensorflow/compiler/tf2xla/kernels/conv_op_helpers.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -163,8 +163,8 @@ absl::Status CheckConvAttrs(const ConvOpAttrs& attrs) {\n absl::Status ConvBackpropComputeDimensionsV2XlaShapes(\n     absl::string_view label, int num_spatial_dims,\n     const xla::Shape& input_shape, const xla::Shape& filter_shape,\n-    const xla::Shape& out_backprop_shape, absl::Span<const int32> dilations,\n-    const std::vector<int32>& strides, Padding padding,\n+    const xla::Shape& out_backprop_shape, absl::Span<const int32_t> dilations,\n+    const std::vector<int32_t>& strides, Padding padding,\n     TensorFormat data_format, ConvBackpropDimensions* dims,\n     absl::Span<const int64_t> explicit_paddings) {\n   TensorShape input_tensor_shape, filter_tensor_shape,\n@@ -203,7 +203,7 @@ absl::StatusOr<ConvOpAttrs> ConvOpAttrs::Create(int num_spatial_dims,\n         ctx->GetAttr(\"explicit_paddings\", &attrs.explicit_paddings));\n   }\n \n-  string data_format;\n+  std::string data_format;\n   TF_RETURN_IF_ERROR(ctx->GetAttr(\"data_format\", &data_format));\n   if (!FormatFromString(data_format, &attrs.data_format)) {\n     return errors::InvalidArgument(\"Invalid data format: \", data_format);\n@@ -231,7 +231,7 @@ absl::StatusOr<ConvNDOpAttrs> ConvNDOpAttrs::Create(OpKernelConstruction* ctx) {\n         ctx->GetAttr(\"explicit_paddings\", &attrs.explicit_paddings));\n   }\n \n-  string data_format_str;\n+  std::string data_format_str;\n   TF_RETURN_IF_ERROR(ctx->GetAttr(\"data_format\", &data_format_str));\n   if (!(data_format_str == \"CHANNELS_LAST\" ||\n         data_format_str == \"CHANNELS_FIRST\")) {"
        },
        {
            "sha": "e64cebe3970cd86e8a070a90fb52c1a110213d23",
            "filename": "tensorflow/compiler/tf2xla/kernels/conv_op_helpers.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_op_helpers.h?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -54,8 +54,8 @@ struct ConvOpAttrs {\n \n   bool depthwise;\n   int num_spatial_dims;\n-  std::vector<int32> dilations;\n-  std::vector<int32> strides;\n+  std::vector<int32_t> dilations;\n+  std::vector<int32_t> strides;\n   Padding padding;\n   std::vector<int64_t> explicit_paddings;\n   TensorFormat data_format;\n@@ -68,8 +68,8 @@ struct ConvNDOpAttrs {\n \n   int groups;\n   int batch_dims;\n-  std::vector<int32> dilations;\n-  std::vector<int32> strides;\n+  std::vector<int32_t> dilations;\n+  std::vector<int32_t> strides;\n   Padding padding;\n   std::vector<int64_t> explicit_paddings;\n   TensorFormat data_format;"
        },
        {
            "sha": "82fdf8ea577e393338fcd8c518875d029e25ab49",
            "filename": "tensorflow/compiler/tf2xla/kernels/conv_ops.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fconv_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -92,9 +92,9 @@ class ConvNDOp : public XlaOpKernel {\n     ConvOpAttrs forward_attrs;\n     forward_attrs.depthwise = false;\n     forward_attrs.num_spatial_dims = num_spatial_dims;\n-    forward_attrs.dilations = attrs_.dilations.empty()\n-                                  ? std::vector<int32>(num_spatial_dims + 2, 1)\n-                                  : attrs_.dilations;\n+    forward_attrs.dilations =\n+        attrs_.dilations.empty() ? std::vector<int32_t>(num_spatial_dims + 2, 1)\n+                                 : attrs_.dilations;\n     forward_attrs.strides = attrs_.strides;\n     forward_attrs.padding = attrs_.padding;\n     forward_attrs.explicit_paddings = attrs_.explicit_paddings;"
        },
        {
            "sha": "27818415169dbee5d28cd16cd6938c075408b28c",
            "filename": "tensorflow/compiler/tf2xla/kernels/data_format_ops.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdata_format_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdata_format_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdata_format_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -36,9 +36,9 @@ class DataFormatDimMapOp : public XlaOpKernel {\n  public:\n   explicit DataFormatDimMapOp(OpKernelConstruction* context)\n       : XlaOpKernel(context) {\n-    string src_format;\n+    std::string src_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"src_format\", &src_format));\n-    string dst_format;\n+    std::string dst_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"dst_format\", &dst_format));\n     OP_REQUIRES(context, src_format.size() == 4 || src_format.size() == 5,\n                 errors::InvalidArgument(\n@@ -69,9 +69,9 @@ class DataFormatDimMapOp : public XlaOpKernel {\n   void Compile(XlaOpKernelContext* context) override {\n     auto builder = context->builder();\n     xla::XlaOp dst_indices =\n-        xla::ConstantR1(builder, absl::Span<const int32>(dst_idx_));\n+        xla::ConstantR1(builder, absl::Span<const int32_t>(dst_idx_));\n     const int dims = dst_idx_.size();\n-    xla::XlaOp rank = xla::ConstantR0<int32>(builder, dims);\n+    xla::XlaOp rank = xla::ConstantR0<int32_t>(builder, dims);\n     xla::XlaOp src_indices =\n         (xla::ConvertElementType(context->Input(0), xla::S32) + rank) % rank;\n     xla::XlaOp output =\n@@ -81,7 +81,7 @@ class DataFormatDimMapOp : public XlaOpKernel {\n   }\n \n  private:\n-  std::vector<int32> dst_idx_;\n+  std::vector<int32_t> dst_idx_;\n \n   DataFormatDimMapOp(const DataFormatDimMapOp&) = delete;\n   void operator=(const DataFormatDimMapOp&) = delete;\n@@ -146,13 +146,13 @@ class DataFormatVecPermuteOp : public XlaOpKernel {\n               input_tensor_shape.DebugString()));\n     }\n \n-    string src_format_str = src_format_;\n-    string dst_format_str = dst_format_;\n+    std::string src_format_str = src_format_;\n+    std::string dst_format_str = dst_format_;\n     if (input_tensor_shape.dim_size(0) == spatial_dim_count) {\n       // If the input is a vector of size spatial_dim_count, treat the elements\n       // as spatial dimensions.\n       auto keep_only_spatial_dimensions =\n-          [spatial_dim_count](string* format_str) -> void {\n+          [spatial_dim_count](std::string* format_str) -> void {\n         auto new_end =\n             std::remove_if(format_str->begin(), format_str->end(),\n                            [spatial_dim_count](const char dim) {\n@@ -164,7 +164,7 @@ class DataFormatVecPermuteOp : public XlaOpKernel {\n       keep_only_spatial_dimensions(&src_format_str);\n       keep_only_spatial_dimensions(&dst_format_str);\n     }\n-    std::vector<int32> dst_indices(dim0);\n+    std::vector<int32_t> dst_indices(dim0);\n     for (int i = 0; i < dim0; ++i) {\n       for (int j = 0; j < dim0; ++j) {\n         if (src_format_str[i] == dst_format_str[j]) {\n@@ -174,14 +174,14 @@ class DataFormatVecPermuteOp : public XlaOpKernel {\n       }\n     }\n     xla::XlaOp indices =\n-        xla::ConstantR1(builder, absl::Span<const int32>(dst_indices));\n+        xla::ConstantR1(builder, absl::Span<const int32_t>(dst_indices));\n     xla::XlaOp output = xla::TorchIndexSelect(ctx->Input(0), indices, 0);\n     ctx->SetOutput(0, output);\n   }\n \n  private:\n-  string src_format_;\n-  string dst_format_;\n+  std::string src_format_;\n+  std::string dst_format_;\n \n   DataFormatVecPermuteOp(const DataFormatVecPermuteOp&) = delete;\n   void operator=(const DataFormatVecPermuteOp&) = delete;"
        },
        {
            "sha": "7e93ed9c32e12688e38f9a1ba70a0304263fe5dc",
            "filename": "tensorflow/compiler/tf2xla/kernels/depthtospace_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdepthtospace_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdepthtospace_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdepthtospace_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -31,7 +31,7 @@ namespace {\n class DepthToSpaceOp : public XlaOpKernel {\n  public:\n   explicit DepthToSpaceOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));"
        },
        {
            "sha": "bc03e14556f9cbe64f4bbca859fd3693026e5c7c",
            "filename": "tensorflow/compiler/tf2xla/kernels/dequantize_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdequantize_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdequantize_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdequantize_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -42,7 +42,7 @@ float get_fullrange() {\n class DequantizeOp : public XlaOpKernel {\n  public:\n   explicit DequantizeOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n-    string mode_string;\n+    std::string mode_string;\n     int axis;\n     bool narrow_range;\n "
        },
        {
            "sha": "a5665baa6e3dc51e28cc28b24b3c4d0edb8b7357",
            "filename": "tensorflow/compiler/tf2xla/kernels/device_index_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdevice_index_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdevice_index_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdevice_index_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -39,11 +39,11 @@ class DeviceIndexOp : public XlaOpKernel {\n     // When compiling we are not executing on any physical device, so we return\n     // a sentinel value (size of the list of devices).\n     ctx->SetOutput(\n-        0, xla::ConstantR0<int32>(ctx->builder(), device_names_.size()));\n+        0, xla::ConstantR0<int32_t>(ctx->builder(), device_names_.size()));\n   }\n \n  private:\n-  std::vector<string> device_names_;\n+  std::vector<std::string> device_names_;\n };\n \n REGISTER_XLA_OP(Name(\"DeviceIndex\"), DeviceIndexOp);"
        },
        {
            "sha": "ae7488ad1e1cbd27be055a0eee82ef5fd3c0f6db",
            "filename": "tensorflow/compiler/tf2xla/kernels/dynamic_partition_op.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_partition_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_partition_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_partition_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -54,8 +54,8 @@ class DynamicPartitionOp : public XlaOpKernel {\n   xla::XlaOp CountS32(XlaOpKernelContext* ctx, xla::XlaOp input,\n                       int64_t target) {\n     xla::XlaOp equal_dim =\n-        xla::Compare(input, xla::ConstantR0<int32>(ctx->builder(), target), {},\n-                     xla::ComparisonDirection::kEq);\n+        xla::Compare(input, xla::ConstantR0<int32_t>(ctx->builder(), target),\n+                     {}, xla::ComparisonDirection::kEq);\n     xla::XlaOp casted = xla::ConvertElementType(equal_dim, xla::S32);\n     return xla::ReduceAll(\n         casted, xla::Zero(ctx->builder(), xla::S32),\n@@ -178,8 +178,9 @@ class DynamicPartitionOp : public XlaOpKernel {\n       } else {\n         xla::XlaOp length;\n         if (count_diff != 0) {\n-          length = xla::Div(partition_length[i],\n-                            xla::ConstantR0<int32>(ctx->builder(), count_diff));\n+          length =\n+              xla::Div(partition_length[i],\n+                       xla::ConstantR0<int32_t>(ctx->builder(), count_diff));\n         } else {\n           length = CountS32(ctx, ctx->Input(1), /*target=*/i);\n         }"
        },
        {
            "sha": "edf9afb5ae14fb7c8dc32a8e3905fd91d6bfda77",
            "filename": "tensorflow/compiler/tf2xla/kernels/dynamic_stitch_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_stitch_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_stitch_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fdynamic_stitch_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -145,8 +145,8 @@ class DynamicStitchOp : public XlaOpKernel {\n \n     // Construct the reverse mapping, for each index, of which slice of which\n     // input it comes from.\n-    std::vector<int32> src_input_vector(number_of_indices);\n-    std::vector<int32> src_slice_vector(number_of_indices);\n+    std::vector<int32_t> src_input_vector(number_of_indices);\n+    std::vector<int32_t> src_slice_vector(number_of_indices);\n     std::vector<bool> src_index_used(number_of_indices);\n     int index_used_count = 0;\n     for (int input_num = 0; input_num < indices.size(); input_num++) {"
        },
        {
            "sha": "b9ca65cfbd637176b74c8fb63a784a86f836273a",
            "filename": "tensorflow/compiler/tf2xla/kernels/extract_image_patches_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fextract_image_patches_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fextract_image_patches_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fextract_image_patches_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -179,9 +179,9 @@ class ExtractImagePatchesOp : public XlaOpKernel {\n   }\n \n  protected:\n-  std::vector<int32> ksizes_;\n-  std::vector<int32> dilations_;\n-  std::vector<int32> strides_;\n+  std::vector<int32_t> ksizes_;\n+  std::vector<int32_t> dilations_;\n+  std::vector<int32_t> strides_;\n   Padding padding_;\n \n  private:"
        },
        {
            "sha": "8075982c766a97acda97206661296a768e5ba3e0",
            "filename": "tensorflow/compiler/tf2xla/kernels/fused_conv_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Ffused_conv_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Ffused_conv_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Ffused_conv_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -154,7 +154,7 @@ class FusedConv2DInt8Op : public XlaOpKernel {\n \n     // Un-vectorize NCHW_VECT_C to NCHW.\n     TensorFormat orig_data_format = conv_attrs_.data_format;\n-    int64 vect_width = -1;\n+    int64_t vect_width = -1;\n     switch (conv_attrs_.data_format) {\n       case FORMAT_NCHW_VECT_C:\n         vect_width = conv_input_shape.dimensions(4);"
        },
        {
            "sha": "e94f74d1fed8ef0747b11ac87df241e46faacf9a",
            "filename": "tensorflow/compiler/tf2xla/kernels/gather_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -275,7 +275,7 @@ class GatherOp : public XlaOpKernel {\n \n   // The number of batch dimensions, as passed in the batch_dims attribute.\n   // It must be less than or equal to rank(indices).\n-  int32 batch_dims_ = 0;\n+  int32_t batch_dims_ = 0;\n };\n \n REGISTER_XLA_OP(Name(\"Gather\"), MlirXlaOpKernel);"
        },
        {
            "sha": "2aec21a6db5888ef09caebf769402106e1cfa260",
            "filename": "tensorflow/compiler/tf2xla/kernels/gather_scatter_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_scatter_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_scatter_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fgather_scatter_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -28,7 +28,7 @@ namespace {\n class GatherOp : public XlaOpKernel {\n  public:\n   explicit GatherOp(OpKernelConstruction* context) : XlaOpKernel(context) {\n-    string dnums_attr;\n+    std::string dnums_attr;\n     OP_REQUIRES_OK(context, context->GetAttr(\"dimension_numbers\", &dnums_attr));\n     OP_REQUIRES(\n         context, dnums_.ParsePartialFromString(dnums_attr),\n@@ -60,7 +60,7 @@ class ScatterOp : public XlaOpKernel {\n   explicit ScatterOp(OpKernelConstruction* context) : XlaOpKernel(context) {\n     OP_REQUIRES_OK(\n         context, context->GetAttr(\"update_computation\", &update_computation_));\n-    string dnums_attr;\n+    std::string dnums_attr;\n     OP_REQUIRES_OK(context, context->GetAttr(\"dimension_numbers\", &dnums_attr));\n     OP_REQUIRES(\n         context, dnums_.ParsePartialFromString(dnums_attr),"
        },
        {
            "sha": "56c86d3d5972270e89817cb59eb235a032527423",
            "filename": "tensorflow/compiler/tf2xla/kernels/if_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -84,7 +84,8 @@ static absl::StatusOr<bool> PopulateTensorArrayGradients(\n \n       // Add any TensorArray gradients touched by the then/else computation to\n       // the enclosing graph.\n-      for (const string& grad_source : update.tensor_array_gradients_accessed) {\n+      for (const std::string& grad_source :\n+           update.tensor_array_gradients_accessed) {\n         VLOG(5) << \"TensorArray \" << resource->name() << \" accessed gradient \"\n                 << grad_source;\n         XlaResource* gradient;\n@@ -318,7 +319,7 @@ void XlaIfOp::Compile(XlaOpKernelContext* ctx) {\n     if (has_token_input_output_ && i == num_inputs - 1) {\n       // Set token input for this \"if\" op.\n       std::vector<xla::XlaOp> token_inputs;\n-      for (const string& node_name : token_input_nodes_) {\n+      for (const std::string& node_name : token_input_nodes_) {\n         auto token_or = compiler->GetNodeToken(node_name);\n         OP_REQUIRES_OK(ctx, token_or.status());\n         token_inputs.push_back(token_or.value());"
        },
        {
            "sha": "c11cfcb08e0b099fc88a405dd31ea47671ed957e",
            "filename": "tensorflow/compiler/tf2xla/kernels/if_op.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fif_op.h?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -61,8 +61,8 @@ class XlaIfOp : public XlaOpKernel {\n   DataTypeVector output_types_;\n   std::vector<PartialTensorShape> output_shapes_;\n   bool has_token_input_output_;\n-  std::vector<string> token_input_nodes_;\n-  string original_node_name_;\n+  std::vector<std::string> token_input_nodes_;\n+  std::string original_node_name_;\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "a2676e095b91b7e5dbf6faaae587e199ae505cad",
            "filename": "tensorflow/compiler/tf2xla/kernels/image_ops.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 14,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -352,10 +352,11 @@ struct WhileCondFn {\n                                         xla::XlaBuilder* cond_builder) const {\n     xla::XlaOp row_idx = values[0];\n     xla::XlaOp row_in_bounds =\n-        xla::Lt(row_idx, xla::ConstantR0<int32>(cond_builder, num_boxes));\n+        xla::Lt(row_idx, xla::ConstantR0<int32_t>(cond_builder, num_boxes));\n     xla::XlaOp num_outputs_so_far = values[1];\n-    xla::XlaOp results_not_full = xla::Lt(\n-        num_outputs_so_far, xla::ConstantR0<int32>(cond_builder, output_size));\n+    xla::XlaOp results_not_full =\n+        xla::Lt(num_outputs_so_far,\n+                xla::ConstantR0<int32_t>(cond_builder, output_size));\n     return xla::And(row_in_bounds, results_not_full);\n   }\n };\n@@ -375,7 +376,7 @@ struct SuppressBodyFn {\n     auto num_outputs_so_far = values[1];\n     auto iou_mask = values[2];\n     auto included_iou = values[3];\n-    auto zero = xla::ConstantR0<int32>(builder, 0);\n+    auto zero = xla::ConstantR0<int32_t>(builder, 0);\n     // Determine if current elem is active using a slice.\n     // TODO(b/118437727): The only reason we need an explicit vector is because\n     // some old GCCs can't deduce the right type for MakeConstSpan, and\n@@ -386,7 +387,7 @@ struct SuppressBodyFn {\n     active_elem = xla::Reshape(active_elem, {});\n     // Increment output count iff current elem is not suppressed.\n     num_outputs_so_far = xla::Select(\n-        active_elem, num_outputs_so_far + xla::ConstantR0<int32>(builder, 1),\n+        active_elem, num_outputs_so_far + xla::ConstantR0<int32_t>(builder, 1),\n         num_outputs_so_far);\n     // Slice out the row_idx.\n     auto row_iou = xla::DynamicSlice(iou_mask, {row_idx, zero}, {1, num_boxes});\n@@ -412,7 +413,7 @@ struct SuppressBodyFn {\n     }\n     included_iou =\n         xla::Select(cond, xla::And(included_iou, supp_mask), included_iou);\n-    row_idx = row_idx + xla::ConstantR0<int32>(builder, 1);\n+    row_idx = row_idx + xla::ConstantR0<int32_t>(builder, 1);\n     return std::vector<xla::XlaOp>{row_idx, num_outputs_so_far, iou_mask,\n                                    included_iou};\n   }\n@@ -456,7 +457,7 @@ class NonMaxSuppressionOp : public XlaOpKernel {\n                 errors::InvalidArgument(\n                     \"scores size \", std::to_string(scores_shape.dim_size(0)),\n                     \" must equal number of boxes \", std::to_string(num_boxes)));\n-    OP_REQUIRES(context, num_boxes <= kint32max,\n+    OP_REQUIRES(context, num_boxes <= std::numeric_limits<int32_t>::max(),\n                 errors::InvalidArgument(\"XLA compilation requires number of \"\n                                         \"boxes to be <= kint32max, got \",\n                                         num_boxes));\n@@ -477,7 +478,7 @@ class NonMaxSuppressionOp : public XlaOpKernel {\n     OP_REQUIRES(\n         context, output_size >= 0,\n         errors::InvalidArgument(\"Need output_size >= 0, got \", output_size));\n-    OP_REQUIRES(context, output_size <= kint32max,\n+    OP_REQUIRES(context, output_size <= std::numeric_limits<int32_t>::max(),\n                 errors::InvalidArgument(\"Need output_size <= kint32Max, got \",\n                                         output_size));\n     const xla::XlaOp score_thresh = context->Input(\"score_threshold\");\n@@ -564,8 +565,8 @@ class NonMaxSuppressionOp : public XlaOpKernel {\n \n     std::vector<xla::XlaOp> init_values;\n     init_values.reserve(4);\n-    init_values.push_back(xla::ConstantR0<int32>(builder, 0));  // col_idx\n-    init_values.push_back(xla::ConstantR0<int32>(builder, 0));  // num_outputs\n+    init_values.push_back(xla::ConstantR0<int32_t>(builder, 0));  // col_idx\n+    init_values.push_back(xla::ConstantR0<int32_t>(builder, 0));  // num_outputs\n     init_values.push_back(iou_thresh_mask);\n     init_values.push_back(included_iou);\n \n@@ -595,17 +596,17 @@ class NonMaxSuppressionOp : public XlaOpKernel {\n     // can be suppressed by score threshold.\n     xla::XlaOp ones_included = xla::Select(\n         included,\n-        xla::Broadcast(xla::ConstantR0<int32>(builder, 1), {num_boxes}),\n-        xla::Broadcast(xla::ConstantR0<int32>(builder, 0), {num_boxes}));\n+        xla::Broadcast(xla::ConstantR0<int32_t>(builder, 1), {num_boxes}),\n+        xla::Broadcast(xla::ConstantR0<int32_t>(builder, 0), {num_boxes}));\n     // num_valid is scalar. Value should be bound by output_size.\n \n     xla::XlaOp num_valid_total = xla::Reduce(\n         ones_included,\n         /*init_value=*/xla::ConstantR0<int>(builder, 0),\n         /*computation=*/CreateScalarAddComputation(xla::S32, builder),\n         /*dimensions_to_reduce=*/{0});\n-    xla::XlaOp num_valid =\n-        xla::Min(num_valid_total, xla::ConstantR0<int32>(builder, output_size));\n+    xla::XlaOp num_valid = xla::Min(\n+        num_valid_total, xla::ConstantR0<int32_t>(builder, output_size));\n \n     // Re-index into the original scores input tensor, using a Gather.\n     // Boxes were suppressed in the sorted domain."
        },
        {
            "sha": "9959f8d4e44be62a888052fd4a2a112395b8bc16",
            "filename": "tensorflow/compiler/tf2xla/kernels/image_resize_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_resize_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_resize_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fimage_resize_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -120,8 +120,8 @@ ResizeConvolutionDims ComputeResizeConvolutionParameters(\n       const int64_t out_size_factor =\n           align_corners ? out_size[i] - 1 : out_size[i];\n \n-      int64_t gcd = MathUtil::GCD(static_cast<uint64>(in_size_factor),\n-                                  static_cast<uint64>(out_size_factor));\n+      int64_t gcd = MathUtil::GCD(static_cast<uint64_t>(in_size_factor),\n+                                  static_cast<uint64_t>(out_size_factor));\n       dims.stride[i] = in_size_factor / gcd;\n       dims.kernel_size[i] = out_size_factor / gcd;\n     }"
        },
        {
            "sha": "5b730cc0a9076d88b9544cbfef2b437b65468ae2",
            "filename": "tensorflow/compiler/tf2xla/kernels/in_topk_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fin_topk_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fin_topk_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fin_topk_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -96,7 +96,7 @@ class InTopKOp : public XlaOpKernel {\n         xla::CreateScalarAddComputation(xla::S32, xla_builder), {1});\n \n     xla::XlaOp result =\n-        xla::And(xla::Lt(num_gt_r1, xla::ConstantR0<int32>(xla_builder, k)),\n+        xla::And(xla::Lt(num_gt_r1, xla::ConstantR0<int32_t>(xla_builder, k)),\n                  xla::IsFinite(targets_values_r1));\n \n     context->SetOutput(0, result);"
        },
        {
            "sha": "390bc09c33057de28bb9ca88f057a9b022513b92",
            "filename": "tensorflow/compiler/tf2xla/kernels/light_outside_compilation.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flight_outside_compilation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flight_outside_compilation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flight_outside_compilation.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -464,7 +464,7 @@ class TfCallbackDevice : public DeviceBase {\n     set_tensorflow_accelerator_device_info(&accelerator_device_info_);\n   }\n \n-  const string& name() const override { return name_; }\n+  const std::string& name() const override { return name_; }\n \n   PerOpGpuDevice* MakeGpuDevice() override {\n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM"
        },
        {
            "sha": "aabbd8d3b0514e3c79548fabacebc3fd6b48c059",
            "filename": "tensorflow/compiler/tf2xla/kernels/listdiff_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flistdiff_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flistdiff_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Flistdiff_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -60,7 +60,7 @@ class ListDiffOp : public XlaOpKernel {\n     absl::Status status;\n     switch (val_type) {\n       case DT_INT32:\n-        status = ListDiffWithIndexType<int32>(context, idx_type);\n+        status = ListDiffWithIndexType<int32_t>(context, idx_type);\n         break;\n       case DT_INT64:\n         status = ListDiffWithIndexType<int64_t>(context, idx_type);\n@@ -111,7 +111,7 @@ class ListDiffOp : public XlaOpKernel {\n                                      DataType idx_type) {\n     switch (idx_type) {\n       case DT_INT32:\n-        return ListDiff<Tval, int32>(context);\n+        return ListDiff<Tval, int32_t>(context);\n       case DT_INT64:\n         return ListDiff<Tval, int64_t>(context);\n       default:"
        },
        {
            "sha": "8e7c966bdf35fce974395b345b007eda4af59108",
            "filename": "tensorflow/compiler/tf2xla/kernels/matrix_diag_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fmatrix_diag_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fmatrix_diag_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fmatrix_diag_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -57,7 +57,7 @@ static inline bool IsLeftAligned(int diag_index, bool left_align_superdiagonal,\n void ReadAlignment(OpKernelConstruction* context,\n                    bool* left_align_superdiagonal,\n                    bool* left_align_subdiagonal) {\n-  string align;\n+  std::string align;\n   OP_REQUIRES_OK(context, context->GetAttr(\"align\", &align));\n \n   *left_align_superdiagonal = align == \"LEFT_LEFT\" || align == \"LEFT_RIGHT\";"
        },
        {
            "sha": "215de2bc5067e428461beef5fe0f8de516f44f2e",
            "filename": "tensorflow/compiler/tf2xla/kernels/one_hot_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fone_hot_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fone_hot_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fone_hot_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -78,7 +78,7 @@ class OneHotOp : public XlaOpKernel {\n   }\n \n  private:\n-  int32 axis_;\n+  int32_t axis_;\n \n   OneHotOp(const OneHotOp&) = delete;\n   void operator=(const OneHotOp&) = delete;"
        },
        {
            "sha": "15b2b5f9d2ebbb4d209bf7c825b926ebda36fb18",
            "filename": "tensorflow/compiler/tf2xla/kernels/pad_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpad_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpad_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpad_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -113,7 +113,7 @@ class PadOp : public XlaOpKernel {\n         high_pad_size = xla::Reshape(high_pad_size, {});\n         high_pad_size = xla::ConvertElementType(high_pad_size, xla::S32);\n         // Low pad has to be static.\n-        xla::XlaOp low_pad_size = xla::ConstantR0<int32>(\n+        xla::XlaOp low_pad_size = xla::ConstantR0<int32_t>(\n             ctx->builder(), pad_literal.Get<int64_t>({i, 0}));\n         xla::XlaOp input_size = xla::GetDimensionSize(input, i);\n         xla::XlaOp total_size = low_pad_size + input_size + high_pad_size;\n@@ -122,7 +122,7 @@ class PadOp : public XlaOpKernel {\n                 total_size, xla::ValueInferenceMode::kUpperBound);\n         OP_REQUIRES_OK(ctx, size_upper_bound_status_or.status());\n         auto size_upper_bound =\n-            size_upper_bound_status_or.value().Get<int32>({});\n+            size_upper_bound_status_or.value().Get<int32_t>({});\n         OP_REQUIRES(\n             ctx, size_upper_bound.has_value(),\n             errors::InvalidArgument("
        },
        {
            "sha": "77db609d9976149ed3e47cb8249f1094cabc2273",
            "filename": "tensorflow/compiler/tf2xla/kernels/pooling_ops.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpooling_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpooling_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fpooling_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -88,8 +88,8 @@ class PoolingOp : public XlaOpKernel {\n         num_spatial_dims_(num_spatial_dims),\n         reduction_type_(reduction_type) {\n     if (ctx->num_inputs() == 1) {\n-      std::vector<int32> ksize_int;\n-      std::vector<int32> stride_int;\n+      std::vector<int32_t> ksize_int;\n+      std::vector<int32_t> stride_int;\n       OP_REQUIRES_OK(ctx, ctx->GetAttr(\"ksize\", &ksize_int));\n       OP_REQUIRES(ctx, ksize_int.size() == num_dims(),\n                   errors::InvalidArgument(\"Sliding window ksize field must \"\n@@ -255,15 +255,15 @@ class MaxPoolOp : public PoolingOp {\n           ctx->builder()->GetShape(pooling);\n       OP_REQUIRES_OK(ctx, result_shape.status());\n \n-      int64 num_channels = result_shape->dimensions(1);\n+      int64_t num_channels = result_shape->dimensions(1);\n       OP_REQUIRES(\n           ctx, num_channels % *vect_width == 0,\n           errors::FailedPrecondition(\"Result of NCHW_VECT_C op must have \"\n                                      \"channels multiple of \",\n                                      *vect_width, \", but was \", num_channels));\n \n-      absl::InlinedVector<int64, 5> new_dims(result_shape->dimensions().begin(),\n-                                             result_shape->dimensions().end());\n+      absl::InlinedVector<int64_t, 5> new_dims(\n+          result_shape->dimensions().begin(), result_shape->dimensions().end());\n       new_dims[1] /= *vect_width;\n       new_dims.insert(new_dims.begin() + 2, *vect_width);\n       pooling =\n@@ -298,7 +298,7 @@ class AvgPoolOp : public PoolingOp {\n       : PoolingOp(ctx, /*num_spatial_dims=*/num_spatial_dims,\n                   /*reduction_type=*/\n                   XlaHelpers::SumAccumulationType(ctx->input_type(0))) {\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -466,7 +466,7 @@ class MaxPool2DGradOp : public MaxPoolGradOp {\n  public:\n   explicit MaxPool2DGradOp(OpKernelConstruction* ctx)\n       : MaxPoolGradOp(ctx, /*num_spatial_dims=*/2) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -505,7 +505,7 @@ class AvgPoolGradOp : public XlaOpKernel {\n                 errors::Unimplemented(\n                     \"Pooling is not yet supported on the batch dimension.\"));\n \n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -561,7 +561,7 @@ class AvgPoolGradOp : public XlaOpKernel {\n  protected:\n   const int num_spatial_dims_;\n   std::vector<int64_t> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_ = FORMAT_NHWC;\n };\n@@ -677,7 +677,7 @@ class MaxPoolGradGradOp : public XlaOpKernel {\n \n     auto b = ctx->builder();\n \n-    auto sixteen = xla::ConstantR0<uint32>(b, 16);\n+    auto sixteen = xla::ConstantR0<uint32_t>(b, 16);\n     // in (f32) -> round to 7 mantissa bits (bf16)-> 16-high-bit u32.\n     //\n     // NOTE: Use a ReducePrecision operation instead of a cast to BF16 and back\n@@ -702,7 +702,7 @@ class MaxPoolGradGradOp : public XlaOpKernel {\n       const xla::Shape scalar = xla::ShapeUtil::MakeShape(xla::F32, {});\n       auto lhs = xla::Parameter(rb.get(), 0, scalar, \"lhs\");\n       auto rhs = xla::Parameter(rb.get(), 1, scalar, \"rhs\");\n-      auto sixteen = xla::ConstantR0<int32>(rb.get(), 16);\n+      auto sixteen = xla::ConstantR0<int32_t>(rb.get(), 16);\n       auto lhs_criteria =\n           xla::ShiftLeft(xla::ShiftRightLogical(\n                              xla::BitcastConvertType(lhs, xla::S32), sixteen),\n@@ -749,7 +749,7 @@ class MaxPool2DGradGradOp : public MaxPoolGradGradOp {\n  public:\n   explicit MaxPool2DGradGradOp(OpKernelConstruction* ctx)\n       : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/2) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -767,7 +767,7 @@ class MaxPool3DGradGradOp : public MaxPoolGradGradOp {\n  public:\n   explicit MaxPool3DGradGradOp(OpKernelConstruction* ctx)\n       : MaxPoolGradGradOp(ctx, /*num_spatial_dims=*/3) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(ctx, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));"
        },
        {
            "sha": "961fce9caa77288140e279fc930059753c43b7ce",
            "filename": "tensorflow/compiler/tf2xla/kernels/quantize_and_dequantize_op.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fquantize_and_dequantize_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fquantize_and_dequantize_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fquantize_and_dequantize_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -113,7 +113,7 @@ class QuantizeAndDequantizeOp : public XlaOpKernel {\n           errors::Internal(\"Expected 4 inputs to QuantizeAndDequantize\"));\n       num_bits = ctx->Input(3);\n     } else {\n-      num_bits = xla::ConstantR0<int32>(b, num_bits_);\n+      num_bits = xla::ConstantR0<int32_t>(b, num_bits_);\n     }\n \n     const xla::XlaOp zero = XlaHelpers::Zero(b, data_type);\n@@ -129,17 +129,17 @@ class QuantizeAndDequantizeOp : public XlaOpKernel {\n     xla::XlaOp min_quantized, max_quantized;\n     if (signed_input_) {\n       if (narrow_range_) {\n-        min_quantized =\n-            -Pow(two, ConvertElementType(\n-                          num_bits - xla::ConstantR0<int32>(b, 1), xla_type)) +\n-            one;\n+        min_quantized = -Pow(two, ConvertElementType(\n+                                      num_bits - xla::ConstantR0<int32_t>(b, 1),\n+                                      xla_type)) +\n+                        one;\n       } else {\n         min_quantized =\n             -Pow(two, ConvertElementType(\n-                          num_bits - xla::ConstantR0<int32>(b, 1), xla_type));\n+                          num_bits - xla::ConstantR0<int32_t>(b, 1), xla_type));\n       }\n       max_quantized =\n-          Pow(two, ConvertElementType(num_bits - xla::ConstantR0<int32>(b, 1),\n+          Pow(two, ConvertElementType(num_bits - xla::ConstantR0<int32_t>(b, 1),\n                                       xla_type)) -\n           one;\n     } else {\n@@ -222,7 +222,7 @@ class QuantizeAndDequantizeV2Op : public QuantizeAndDequantizeOp {\n     OP_REQUIRES(ctx, num_bits_ > 0 && num_bits_ < (signed_input_ ? 62 : 63),\n                 errors::InvalidArgument(\"num_bits is out of range: \", num_bits_,\n                                         \" with signed_input_ \", signed_input_));\n-    string round_mode_string;\n+    std::string round_mode_string;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"round_mode\", &round_mode_string));\n     OP_REQUIRES(\n         ctx,"
        },
        {
            "sha": "dea3ecf85af7b8f24622e8efe53e605f202d29d3",
            "filename": "tensorflow/compiler/tf2xla/kernels/random_ops_util.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -140,7 +140,7 @@ absl::StatusOr<int> GetAlgId(XlaOpKernelContext* ctx, int alg_input_idx) {\n   if (alg_dtype == DT_INT32) {\n     return alg_literal.Get<int>({});\n   } else {\n-    return alg_literal.Get<int64>({});\n+    return alg_literal.Get<int64_t>({});\n   }\n }\n \n@@ -172,7 +172,7 @@ DataType MaybeConvertBF16ToF32(DataType const& dtype) {\n }\n \n absl::StatusOr<xla::XlaOp> BuildUniformRandoms(\n-    XlaOpKernelContext* ctx, DataType dtype, string device_type_string,\n+    XlaOpKernelContext* ctx, DataType dtype, std::string device_type_string,\n     TensorShape shape,\n     std::function<xla::XlaOp(xla::XlaBuilder*, xla::PrimitiveType)> lo_fn,\n     std::function<xla::XlaOp(xla::XlaBuilder*, xla::PrimitiveType)> hi_fn) {\n@@ -190,7 +190,7 @@ absl::StatusOr<xla::XlaOp> BuildUniformRandoms(\n \n absl::StatusOr<xla::XlaOp> BuildUniformRandoms(XlaOpKernelContext* ctx,\n                                                DataType dtype,\n-                                               string device_type_string,\n+                                               std::string device_type_string,\n                                                xla::Shape xla_shape,\n                                                xla::XlaOp lo, xla::XlaOp hi) {\n   xla::XlaOp key = ctx->Input(kRandomKeyInputIdx);"
        },
        {
            "sha": "5fb7aa4822834cb5ec7ea3a36450361570610531",
            "filename": "tensorflow/compiler/tf2xla/kernels/random_ops_util.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Frandom_ops_util.h?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -73,7 +73,7 @@ DataType MaybeConvertBF16ToF32(DataType const& dtype);\n // type, in the given low and high range, where low and high are expressed in\n // XLA functions.\n absl::StatusOr<xla::XlaOp> BuildUniformRandoms(\n-    XlaOpKernelContext* ctx, DataType dtype, string device_type_string,\n+    XlaOpKernelContext* ctx, DataType dtype, std::string device_type_string,\n     TensorShape shape,\n     std::function<xla::XlaOp(xla::XlaBuilder*, xla::PrimitiveType)> lo,\n     std::function<xla::XlaOp(xla::XlaBuilder*, xla::PrimitiveType)> hi);\n@@ -82,7 +82,7 @@ absl::StatusOr<xla::XlaOp> BuildUniformRandoms(\n // ops.\n absl::StatusOr<xla::XlaOp> BuildUniformRandoms(XlaOpKernelContext* ctx,\n                                                DataType dtype,\n-                                               string device_type_string,\n+                                               std::string device_type_string,\n                                                xla::Shape xla_shape,\n                                                xla::XlaOp lo, xla::XlaOp hi);\n }  // namespace tensorflow"
        },
        {
            "sha": "3bfe9e384405b2a2c9356f1460a5695dab4ae138",
            "filename": "tensorflow/compiler/tf2xla/kernels/reduction_ops_common.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freduction_ops_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freduction_ops_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freduction_ops_common.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -119,7 +119,7 @@ void XlaReductionOp::Compile(XlaOpKernelContext* ctx) {\n     }\n   }\n \n-  string desc = ctx->op_kernel().name();\n+  std::string desc = ctx->op_kernel().name();\n \n   xla::XlaBuilder* const b = ctx->builder();\n   // Construct the builder for the reduction lambda."
        },
        {
            "sha": "a1dd0164e73fc71df07fd2ca925721b653d3eb49",
            "filename": "tensorflow/compiler/tf2xla/kernels/resampler_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fresampler_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fresampler_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fresampler_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -311,7 +311,7 @@ XlaOp CalculateGradData(XlaOpKernelContext* ctx, XlaOp grad_output, XlaOp ratio,\n       xla::Pad(grad_data, xla::Zero(ctx->builder(), warp_type),\n                xla::MakeEdgePaddingConfig({{0, 0}, {1, 1}, {1, 1}, {0, 0}}));\n \n-  auto shifting_value = xla::ConstantR1<int32>(\n+  auto shifting_value = xla::ConstantR1<int32_t>(\n       ctx->builder(), {/*batch=*/0, /*x(width)=*/1, /*y(height)=*/1});\n   auto shifted_gather_indices =\n       xla::Add(gather_indices, shifting_value, {last_warp_dim});\n@@ -384,7 +384,7 @@ XlaOp CalculateGradWarp(XlaOpKernelContext* ctx, XlaOp grad_output, XlaOp ratio,\n       xla::Pad(data, xla::Zero(ctx->builder(), data_type),\n                xla::MakeEdgePaddingConfig({{0, 0}, {1, 1}, {1, 1}, {0, 0}}));\n \n-  auto shifting_value = xla::ConstantR1<int32>(\n+  auto shifting_value = xla::ConstantR1<int32_t>(\n       ctx->builder(), {/*batch=*/0, /*x(width)=*/1, /*y(height)=*/1});\n   auto shifted_gather_indices =\n       xla::Add(gather_indices, shifting_value, {last_warp_dim});"
        },
        {
            "sha": "5c77a4dfe299349a37190ce5fcdb63a7a1e55448",
            "filename": "tensorflow/compiler/tf2xla/kernels/reverse_sequence_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freverse_sequence_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freverse_sequence_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Freverse_sequence_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -134,8 +134,8 @@ class ReverseSequenceOp : public XlaOpKernel {\n   }\n \n  private:\n-  int32 batch_dim_;\n-  int32 seq_dim_;\n+  int32_t batch_dim_;\n+  int32_t seq_dim_;\n };\n \n REGISTER_XLA_OP(Name(\"ReverseSequence\"), ReverseSequenceOp);"
        },
        {
            "sha": "32b75c26c702120d2583b8ce6112f7762ef3b9be",
            "filename": "tensorflow/compiler/tf2xla/kernels/sendrecv_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsendrecv_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsendrecv_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsendrecv_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -35,7 +35,7 @@ class SendOp : public XlaOpKernel {\n   void Compile(XlaOpKernelContext* ctx) override;\n \n  private:\n-  string tensor_name_;\n+  std::string tensor_name_;\n \n   SendOp(const SendOp&) = delete;\n   void operator=(const SendOp&) = delete;\n@@ -60,7 +60,7 @@ class RecvOp : public XlaOpKernel {\n   void Compile(XlaOpKernelContext* ctx) override;\n \n  private:\n-  string tensor_name_;\n+  std::string tensor_name_;\n   xla::Shape shape_;\n \n   RecvOp(const RecvOp&) = delete;"
        },
        {
            "sha": "d24d1688d188a61047b5dc03c585acd54e822be6",
            "filename": "tensorflow/compiler/tf2xla/kernels/sequence_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsequence_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsequence_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsequence_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -104,7 +104,8 @@ class RangeOp : public XlaOpKernel {\n     absl::StatusOr<xla::XlaOp> output;\n     switch (type) {\n       case DT_INT32:\n-        output = CreateRangeTensor<int32>(start, limit, delta, ctx->builder());\n+        output =\n+            CreateRangeTensor<int32_t>(start, limit, delta, ctx->builder());\n         break;\n       case DT_INT64:\n         output ="
        },
        {
            "sha": "07bf81e9d76b58a5485011ffc99ec44b6f401c0b",
            "filename": "tensorflow/compiler/tf2xla/kernels/shape_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -109,7 +109,7 @@ class XlaSetBoundOp : public XlaOpKernel {\n                                 bound_shape.DebugString()));\n     int64_t bound;\n     OP_REQUIRES_OK(ctx, ctx->ConstantInputAsIntScalar(\"bound\", &bound));\n-    xla::Literal bound_literal = xla::LiteralUtil::CreateR0<int32>(bound);\n+    xla::Literal bound_literal = xla::LiteralUtil::CreateR0<int32_t>(bound);\n     xla::XlaOp result = xla::CustomCall(\n         ctx->builder(), \"SetBound\", {ctx->Input(\"input\")},\n         ctx->InputXlaShape(\"input\").value(), \"\", false, {}, &bound_literal);"
        },
        {
            "sha": "beb38ce9a273ea01908e4fdd509ff9444eb32047",
            "filename": "tensorflow/compiler/tf2xla/kernels/shape_util.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fshape_util.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -33,15 +33,15 @@ absl::Status TensorShapeToConstant(const TensorShape& input_shape,\n                                    Tensor* shape_constant) {\n   const int dims = input_shape.dims();\n   if (shape_constant->dtype() == DT_INT32) {\n-    auto vec = shape_constant->vec<int32>();\n+    auto vec = shape_constant->vec<int32_t>();\n     for (int i = 0; i < dims; ++i) {\n       int64_t dim_size = input_shape.dim_size(i);\n-      if (!FastBoundsCheck(dim_size, std::numeric_limits<int32>::max())) {\n+      if (!FastBoundsCheck(dim_size, std::numeric_limits<int32_t>::max())) {\n         return errors::InvalidArgument(\n             \"Shape with out_type=int32 does not support tensors > int32max\",\n             \" but dim \", i, \" is \", dim_size);\n       }\n-      vec(i) = static_cast<int32>(dim_size);\n+      vec(i) = static_cast<int32_t>(dim_size);\n     }\n   } else {\n     auto vec = shape_constant->vec<int64_t>();"
        },
        {
            "sha": "0ee9173cda69e3ca5ed11e38ac243f6d243e5238",
            "filename": "tensorflow/compiler/tf2xla/kernels/sharding_util_ops.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsharding_util_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsharding_util_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fsharding_util_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -101,8 +101,8 @@ absl::Status GetAndValidateAttributes(OpKernelConstruction* ctx,\n   return absl::OkStatus();\n }\n \n-std::vector<int64_t> GetSliceIndices(absl::Span<const int64> num_partitions,\n-                                     absl::Span<const int64> slice_shape,\n+std::vector<int64_t> GetSliceIndices(absl::Span<const int64_t> num_partitions,\n+                                     absl::Span<const int64_t> slice_shape,\n                                      const int index) {\n   DCHECK_EQ(num_partitions.size(), slice_shape.size());\n \n@@ -213,7 +213,7 @@ class XlaSplitNDBaseOp : public XlaOpKernel {\n       // Calculate paddings necessary for slice instead of padding input and\n       // slicing subsequently to reduce temporary memory allocation.\n       for (int dim = 0; dim < rank; ++dim) {\n-        const int64 dim_size = input_shape.dim_size(dim);\n+        const int64_t dim_size = input_shape.dim_size(dim);\n         if (slice_start_indices[dim] >= dim_size) {\n           // Complete padding.\n           slice_start_indices[dim] = dim_size;\n@@ -387,9 +387,9 @@ class XlaConcatNDBaseOp : public XlaOpKernel {\n \n       std::vector<xla::XlaOp> update_slice_start_indices;\n       update_slice_start_indices.reserve(rank);\n-      for (int64 start_index : slice_start_indices) {\n+      for (int64_t start_index : slice_start_indices) {\n         update_slice_start_indices.push_back(\n-            xla::ConstantR0<int32>(ctx->builder(), start_index));\n+            xla::ConstantR0<int32_t>(ctx->builder(), start_index));\n       }\n       output = xla::DynamicUpdateSlice(output, input_slice,\n                                        update_slice_start_indices);"
        },
        {
            "sha": "b0e337cec20c333ca176833b417f47ba8ac70f5e",
            "filename": "tensorflow/compiler/tf2xla/kernels/slice_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fslice_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fslice_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fslice_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -180,8 +180,8 @@ class SliceOp : public XlaOpKernel {\n               xla::Reshape(xla::Slice(ctx->Input(2), {i}, {i + 1}, {1}), {});\n           if (constant_size_is_minus_one && size[i] == -1) {\n             // size = input_.dim_size(i) - begin[i]\n-            dynamic_size = xla::ConstantR0<int32>(ctx->builder(),\n-                                                  input_shape.dim_size(i)) -\n+            dynamic_size = xla::ConstantR0<int32_t>(ctx->builder(),\n+                                                    input_shape.dim_size(i)) -\n                            begin_indices[i];\n           }\n           auto constant_size = ctx->value_inference().AnalyzeConstant(\n@@ -192,7 +192,7 @@ class SliceOp : public XlaOpKernel {\n             // triggered when some dimensions's slice sizes are constant while\n             // some are dynamic.\n             sliced = xla::SliceInDim(\n-                sliced, 0, constant_size->Get<int32>({}).value(), 1, i);\n+                sliced, 0, constant_size->Get<int32_t>({}).value(), 1, i);\n           } else {\n             // We gave a generous bound (same as input) to the output, try reset\n             // the bound if a tighter one can be found."
        },
        {
            "sha": "180ba322f0fdd08f9c7d7d681f3a47208c0cc439",
            "filename": "tensorflow/compiler/tf2xla/kernels/spacetodepth_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspacetodepth_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspacetodepth_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspacetodepth_op.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -34,7 +34,7 @@ namespace {\n class SpaceToDepthOp : public XlaOpKernel {\n  public:\n   explicit SpaceToDepthOp(OpKernelConstruction* ctx) : XlaOpKernel(ctx) {\n-    string data_format_str;\n+    std::string data_format_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"data_format\", &data_format_str));\n     OP_REQUIRES(ctx, FormatFromString(data_format_str, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));"
        },
        {
            "sha": "f6d468131ac94e5c644db6a734cc3e9b35d4278b",
            "filename": "tensorflow/compiler/tf2xla/kernels/spmd_manual_sharding_ops.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspmd_manual_sharding_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspmd_manual_sharding_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fspmd_manual_sharding_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -69,8 +69,8 @@ class XlaSpmdFullToShardShapeOp : public XlaOpKernel {\n   }\n \n  private:\n-  string manual_sharding_str_;\n-  int32 single_dim_;\n+  std::string manual_sharding_str_;\n+  int32_t single_dim_;\n   std::vector<int64_t> unspecified_dims_;\n   XlaSpmdFullToShardShapeOp(const XlaSpmdFullToShardShapeOp&) = delete;\n   void operator=(const XlaSpmdFullToShardShapeOp&) = delete;\n@@ -120,8 +120,8 @@ class XlaSpmdShardToFullShapeOp : public XlaOpKernel {\n \n  private:\n   TensorShape full_shape_;\n-  string manual_sharding_str_;\n-  int32 single_dim_;\n+  std::string manual_sharding_str_;\n+  int32_t single_dim_;\n   std::vector<int64_t> unspecified_dims_;\n   XlaSpmdShardToFullShapeOp(const XlaSpmdShardToFullShapeOp&) = delete;\n   void operator=(const XlaSpmdShardToFullShapeOp&) = delete;"
        },
        {
            "sha": "4672477be3534b235b852d4b8f85e55ae0f8705d",
            "filename": "tensorflow/compiler/tf2xla/kernels/stack_ops.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstack_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstack_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstack_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -120,7 +120,7 @@ class StackOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string stack_name_;\n+  std::string stack_name_;\n \n   StackOp(const StackOp&) = delete;\n   void operator=(const StackOp&) = delete;\n@@ -152,7 +152,7 @@ class StackPushOp : public XlaOpKernel {\n \n     // start_indices of the DynamicUpdateSlice are [index, 0, 0, ..., 0].\n     std::vector<xla::XlaOp> start_indices(elem_shape.dims() + 1,\n-                                          xla::ConstantR0<int32>(b, 0));\n+                                          xla::ConstantR0<int32_t>(b, 0));\n     start_indices[0] = index;\n \n     TensorShape slice_shape = elem_shape;\n@@ -164,7 +164,7 @@ class StackPushOp : public XlaOpKernel {\n     OP_REQUIRES_OK(ctx,\n                    resource->SetValue(xla::Tuple(\n                        b, {xla::DynamicUpdateSlice(ta, update, start_indices),\n-                           xla::Add(index, xla::ConstantR0<int32>(b, 1))})));\n+                           xla::Add(index, xla::ConstantR0<int32_t>(b, 1))})));\n \n     ctx->SetOutput(0, value);\n   }\n@@ -204,12 +204,12 @@ class StackPopOp : public XlaOpKernel {\n     xla::XlaOp ta = xla::GetTupleElement(state, 0);\n     xla::XlaOp index = xla::GetTupleElement(state, 1);\n \n-    index = Sub(index, xla::ConstantR0<int32>(b, 1));\n+    index = Sub(index, xla::ConstantR0<int32_t>(b, 1));\n     OP_REQUIRES_OK(ctx, resource->SetValue(xla::Tuple(b, {ta, index})));\n \n     // start_indices of the DynamicSlice are [index, 0, 0, ..., 0].\n     std::vector<xla::XlaOp> start_indices(stack_shape.dims(),\n-                                          xla::ConstantR0<int32>(b, 0));\n+                                          xla::ConstantR0<int32_t>(b, 0));\n     start_indices[0] = index;\n \n     auto slice_shape = stack_shape.dim_sizes();"
        },
        {
            "sha": "80047c5f17cc98dfde677a836a78626a346a1a2f",
            "filename": "tensorflow/compiler/tf2xla/kernels/stateful_random_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateful_random_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateful_random_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateful_random_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -511,7 +511,7 @@ class RngSkipOp : public XlaOpKernel {\n REGISTER_XLA_OP(Name(\"RngSkip\").CompileTimeConstantInput(\"algorithm\"),\n                 RngSkipOp<>);\n \n-using RngReadAndSkipOp = RngSkipOp<int32, true>;\n+using RngReadAndSkipOp = RngSkipOp<int32_t, true>;\n \n REGISTER_XLA_OP(Name(\"RngReadAndSkip\").CompileTimeConstantInput(\"alg\"),\n                 RngReadAndSkipOp);"
        },
        {
            "sha": "246981c3465ef1ef0ba4ce2e4f4ec05d4fc6bd3c",
            "filename": "tensorflow/compiler/tf2xla/kernels/stateless_random_ops.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateless_random_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateless_random_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fkernels%2Fstateless_random_ops.cc?ref=d532b1ff75fb1c4d4c49ffaa2e258c97a1848a72",
            "patch": "@@ -76,7 +76,7 @@ xla::XlaOp MaybeConvertF32ToBF16(xla::XlaOp input, DataType dtype) {\n     // `BitcastConvertType(ConvertElementType(u32, U16), BF16)`, to avoid the\n     // unclear `ConvertElementType(f32, BF16)` behavior.\n     xla::XlaOp output = xla::BitcastConvertType(input, xla::U32) &\n-                        xla::ConstantR0<uint32>(builder, 0xFFFF0000);\n+                        xla::ConstantR0<uint32_t>(builder, 0xFFFF0000);\n     return xla::ConvertElementType(xla::BitcastConvertType(output, xla::F32),\n                                    xla::BF16);\n   } else {\n@@ -184,7 +184,7 @@ class StatelessRandomUniformOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessRandomUniformOp(const StatelessRandomUniformOp&) = delete;\n   void operator=(const StatelessRandomUniformOp&) = delete;\n@@ -240,7 +240,7 @@ class StatelessRandomUniformIntOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessRandomUniformIntOp(const StatelessRandomUniformIntOp&) = delete;\n   void operator=(const StatelessRandomUniformIntOp&) = delete;\n@@ -283,7 +283,7 @@ class StatelessRandomUniformFullIntOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessRandomUniformFullIntOp(const StatelessRandomUniformFullIntOp&) =\n       delete;\n@@ -336,7 +336,7 @@ class StatelessRandomNormalOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessRandomNormalOp(const StatelessRandomNormalOp&) = delete;\n   void operator=(const StatelessRandomNormalOp&) = delete;\n@@ -384,7 +384,7 @@ class StatelessTruncatedNormalOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessTruncatedNormalOp(const StatelessTruncatedNormalOp&) = delete;\n   void operator=(const StatelessTruncatedNormalOp&) = delete;\n@@ -449,7 +449,7 @@ class StatelessParameterizedTruncatedNormalOp : public XlaOpKernel {\n \n  private:\n   DataType dtype_;\n-  string device_type_string_;\n+  std::string device_type_string_;\n \n   StatelessParameterizedTruncatedNormalOp(\n       const StatelessParameterizedTruncatedNormalOp&) = delete;"
        }
    ],
    "stats": {
        "total": 309,
        "additions": 158,
        "deletions": 151
    }
}