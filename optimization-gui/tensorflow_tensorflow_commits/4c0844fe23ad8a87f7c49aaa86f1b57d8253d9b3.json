{
    "author": "ermilovmaxim",
    "message": "override Thunk::buffer_uses where needed. Part 1\n\nPiperOrigin-RevId: 839986365",
    "sha": "4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
    "files": [
        {
            "sha": "78a2f067e66ec71e67ad0f356f54a180b8123843",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -450,6 +450,7 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -589,6 +590,7 @@ cc_library(\n         \":thunk_proto_cc\",\n         \":while_thunk\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:event\",\n@@ -829,6 +831,7 @@ cc_library(\n     deps = [\n         \":thunk\",\n         \":thunk_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:matmul_utils\",\n@@ -936,6 +939,7 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:util\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:gpu_transfer_manager\",\n@@ -1958,6 +1962,7 @@ cc_library(\n     deps = [\n         \":thunk\",\n         \":thunk_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:computation_placer_hdr\",\n@@ -2281,6 +2286,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:stream_executor_h\",\n@@ -2371,6 +2377,7 @@ cc_library(\n     deps = [\n         \":thunk\",\n         \":thunk_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:buffer_assignment_proto_cc\",\n         \"//xla/stream_executor:device_memory\","
        },
        {
            "sha": "312574a4a91037bbc43903e08a6d6d9dbd6c65d1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/conditional_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n \n@@ -79,6 +80,12 @@ class ConditionalThunk : public Thunk {\n \n   bool branch_index_is_bool() const { return branch_index_is_bool_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(branch_index_buffer_index_),\n+    };\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   // Deserializes a ConditionalThunk from its proto representation."
        },
        {
            "sha": "381c426a66f35fc94ac37cb78ef9276383a84de2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/copy_thunk.h",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcopy_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcopy_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcopy_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/event.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -62,6 +63,13 @@ class DeviceToDeviceCopyThunk : public Thunk {\n   }\n   uint64_t size_bytes() const { return mem_size_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(source_buffer_),\n+        BufferUse::Write(destination_buffer_),\n+    };\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   static absl::StatusOr<std::unique_ptr<DeviceToDeviceCopyThunk>> FromProto(\n@@ -119,6 +127,13 @@ class CopyThunk : public Thunk {\n   }\n   uint64_t size_bytes() const { return mem_size_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(source_buffer_),\n+        BufferUse::Write(destination_buffer_),\n+    };\n+  }\n+\n   bool operator==(const CopyThunk& other) const {\n     return source() == other.source() && destination() == other.destination() &&\n            size_bytes() == other.size_bytes();\n@@ -285,6 +300,13 @@ class DynamicMemcpyThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(source_buffer_),\n+        BufferUse::Write(destination_buffer_),\n+    };\n+  }\n+\n  private:\n   const BufferAllocation::Slice source_buffer_;\n   const BufferAllocation::Slice destination_buffer_;"
        },
        {
            "sha": "6b2b46a5b82c99e26a4bb0bf7f897bcb3c52a1b0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cudnn_thunk.h",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcudnn_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/dnn.h\"\n \n@@ -53,6 +54,20 @@ class CuDnnThunk : public Thunk {\n     return args_;\n   }\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res;\n+    res.reserve(args_.size());\n+\n+    for (int i = 0; i < args_.size(); i++) {\n+      if (output_args_[i]) {\n+        res.push_back(BufferUse::Write(args_[i]));\n+        continue;\n+      }\n+      res.push_back(BufferUse::Read(args_[i]));\n+    }\n+    return res;\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   static absl::StatusOr<std::unique_ptr<CuDnnThunk>> FromProto("
        },
        {
            "sha": "95d0eae52067f0f241579c179d4f0c1c10b97eb6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gemm_thunk.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgemm_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgemm_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgemm_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n \n@@ -57,6 +58,14 @@ class GemmThunk : public Thunk {\n   }\n   bool deterministic() const { return deterministic_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(lhs_buffer_),\n+        BufferUse::Read(rhs_buffer_),\n+        BufferUse::Write(output_buffer_),\n+    };\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<GemmThunk>> FromProto(\n       ThunkInfo thunk_info, const GemmThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "6ea7852250bd4a67ca3a67060854125bf3261a7e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/infeed_thunk.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Finfeed_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n \n namespace xla {\n@@ -43,6 +44,14 @@ class InfeedThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res;\n+    res.reserve(dest_slices_.size());\n+    for (const ShapedSlice& shaped_slice : dest_slices_) {\n+      res.push_back(BufferUse::Write(shaped_slice.slice, shaped_slice.shape));\n+    }\n+    return res;\n+  }\n   static absl::StatusOr<std::unique_ptr<InfeedThunk>> FromProto(\n       ThunkInfo thunk_info, const InfeedThunkProto& thunk_proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "6b627180c9f5af84a7d512bc0042d2a45296f2aa",
            "filename": "third_party/xla/xla/backends/gpu/runtime/memset_thunk.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fmemset_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -43,6 +43,12 @@ class MemzeroThunk : public Thunk {\n \n   const BufferAllocation::Slice& destination() const { return dest_; }\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Write(dest_),\n+    };\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<MemzeroThunk>> FromProto(\n       ThunkInfo thunk_info, const MemzeroThunkProto& thunk_proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "6137d86d3b38846c267d084235773df7664e9015",
            "filename": "third_party/xla/xla/backends/gpu/runtime/replica_id_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Freplica_id_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Freplica_id_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Freplica_id_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n \n namespace xla {\n@@ -40,6 +41,12 @@ class ReplicaOrPartitionIdThunk : public Thunk {\n                             const BufferAllocation::Slice& dest)\n       : Thunk(kind, thunk_info), dest_(dest) {}\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Write(dest_),\n+    };\n+  }\n+\n  private:\n   const BufferAllocation::Slice dest_;\n };"
        },
        {
            "sha": "cb4e449e4a8bb19cef73c8f21749ec20d985aaf5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 5,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -384,16 +384,21 @@ TEST_F(ThunkBufferDebugPassTest, RecursivelyInsertsBuffersDebugChecksumThunks) {\n       new_thunks,\n       ElementsAre(\n           IsCustomCallThunkWithTargetName(\"xla_gpu_buffer_debug_log_init\"),\n-          ThunkKindIs(Thunk::Kind::kWhile),\n+          ThunkKindIs(Thunk::Kind::kSequential),\n           IsCustomCallThunkWithTargetName(\"xla_gpu_buffer_debug_log_dump\")));\n \n   {\n-    ASSERT_EQ(new_thunks[1]->kind(), Thunk::Kind::kWhile);\n+    ASSERT_EQ(new_thunks[1]->kind(), Thunk::Kind::kSequential);\n+    const SequentialThunk& top_seq_thunk =\n+        static_cast<const SequentialThunk&>(*new_thunks[1]);\n+\n+    ASSERT_EQ(top_seq_thunk.thunks()[1]->kind(), Thunk::Kind::kWhile);\n     const WhileThunk& while_thunk =\n-        static_cast<const WhileThunk&>(*new_thunks[1]);\n+        static_cast<const WhileThunk&>(*top_seq_thunk.thunks()[1]);\n+\n     EXPECT_THAT(while_thunk.body_thunk_sequence()->thunks(),\n                 ElementsAre(ThunkKindIs(Thunk::Kind::kSequential),\n-                            Pointer(conditional_thunk_ptr)));\n+                            ThunkKindIs(Thunk::Kind::kSequential)));\n     const SequentialThunk& condition_fake_thunk_sequence =\n         static_cast<const SequentialThunk&>(\n             *while_thunk.condition_thunk_sequence()->thunks()[0]);\n@@ -414,10 +419,18 @@ TEST_F(ThunkBufferDebugPassTest, RecursivelyInsertsBuffersDebugChecksumThunks) {\n                     IsChecksumThunkChecking(SliceList{{0, slice_while_body}})));\n \n     ASSERT_EQ(while_thunk.body_thunk_sequence()->thunks()[1]->kind(),\n+              Thunk::Kind::kSequential);\n+    const SequentialThunk& condition_warpper_thunk =\n+        static_cast<const SequentialThunk&>(\n+            *while_thunk.body_thunk_sequence()->thunks()[1]);\n+\n+    ASSERT_EQ(condition_warpper_thunk.thunks()[1]->kind(),\n               Thunk::Kind::kConditional);\n     const ConditionalThunk& conditional_thunk =\n         static_cast<const ConditionalThunk&>(\n-            *while_thunk.body_thunk_sequence()->thunks()[1]);\n+            *condition_warpper_thunk.thunks()[1]);\n+    EXPECT_EQ(&conditional_thunk, conditional_thunk_ptr);\n+\n     EXPECT_THAT(conditional_thunk.branch_thunks(),\n                 ElementsAre(ThunkKindIs(Thunk::Kind::kSequential),\n                             ThunkKindIs(Thunk::Kind::kSequential)));"
        },
        {
            "sha": "51d0cf5ad532f4743454367a46f264f9664e8401",
            "filename": "third_party/xla/xla/backends/gpu/runtime/while_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.h?ref=4c0844fe23ad8a87f7c49aaa86f1b57d8253d9b3",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n \n@@ -100,6 +101,12 @@ class WhileThunk : public Thunk {\n \n   std::string ToString(int indent) const override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(condition_result_buffer_index_),\n+    };\n+  }\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   // Deserializes a WhileThunk from its proto representation."
        }
    ],
    "stats": {
        "total": 112,
        "additions": 107,
        "deletions": 5
    }
}