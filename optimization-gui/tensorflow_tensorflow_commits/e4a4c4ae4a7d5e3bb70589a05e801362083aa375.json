{
    "author": "golechwierowicz",
    "message": "[XLA:GPU] Flip unified cost model on.\n\nPiperOrigin-RevId: 805452494",
    "sha": "e4a4c4ae4a7d5e3bb70589a05e801362083aa375",
    "files": [
        {
            "sha": "2d8ac38048c9652e8f678056bd070b423f225169",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e4a4c4ae4a7d5e3bb70589a05e801362083aa375/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e4a4c4ae4a7d5e3bb70589a05e801362083aa375/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=e4a4c4ae4a7d5e3bb70589a05e801362083aa375",
            "patch": "@@ -290,7 +290,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_dump_latency_hiding_schedule(false);\n   opts.set_xla_gpu_enable_latency_hiding_scheduler(false);\n   opts.set_xla_gpu_enable_analytical_latency_estimator(false);\n-  opts.set_xla_gpu_enable_analytical_sol_latency_estimator(false);\n+  opts.set_xla_gpu_enable_analytical_sol_latency_estimator(true);\n   auto* sol_estimator_defaults =\n       opts.mutable_xla_gpu_analytical_latency_estimator_options();\n   sol_estimator_defaults->emplace(kSolNcclOpLaunchUs, \"-1\");"
        },
        {
            "sha": "c53b4324c64b67ec6b91a7164ae0d4da8a80ca94",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e4a4c4ae4a7d5e3bb70589a05e801362083aa375/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e4a4c4ae4a7d5e3bb70589a05e801362083aa375/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=e4a4c4ae4a7d5e3bb70589a05e801362083aa375",
            "patch": "@@ -1289,13 +1289,13 @@ async_call {\n       \"precision_config\":{\"operand_precision\":[\"DEFAULT\",\"DEFAULT\"]},\n       \"lhs_stride\":\"1024\",\"rhs_stride\":\"1024\"}}\n   ROOT get-tuple-element = f32[32,32] get-tuple-element(gemm), index=0\n-}, execution_thread=\"explicit\"\n+}\n \n ENTRY main {\n   p0 = f32[32,32] parameter(0)\n   p1 = f32[32,32] parameter(1)\n   call-start = ((f32[32,32], f32[32,32]), f32[32,32]) call-start(p0, p1),\n-    async_execution_thread=\"explicit\", to_apply=async_call,\n+    to_apply=async_call,\n     frontend_attributes={_xla_stream_annotation=\"1\"}\n   ROOT call-done = f32[32,32]{1,0} call-done(call-start),\n     frontend_attributes={_xla_stream_annotation=\"1\"},\n@@ -1636,7 +1636,6 @@ TEST_F(PassOrderTest, LHSRunsIfProfileDataIsAvailable) {\n       \"latency-hiding-scheduler\",\n   };\n   CompileModule(config);\n-  EXPECT_THAT(optimized_module_, Not(HasExpectedPasses(kExpectedPasses)));\n \n   // Make sure we turn the LHS on with we schedule with profile data.\n   const absl::string_view kProfile = R\"pb("
        }
    ],
    "stats": {
        "total": 7,
        "additions": 3,
        "deletions": 4
    }
}