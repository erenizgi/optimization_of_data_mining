{
    "author": "mgoldfarb-nvidia",
    "message": "PR #31074: Expose num_repeats_with_profiler option to Python HLO Runner interface\n\nImported from GitHub PR https://github.com/openxla/xla/pull/31074\n\nüìù Summary of Changes\nExposes the `num_repeats_with_profiler` which was missed in the first PR.\n\nüéØ Justification\nEnables profiling with more than 1 iteration.\n\nüöÄ Kind of Contribution\n‚ôªÔ∏è Cleanup\nCopybara import of the project:\n\n--\n8960d9b3cd4606646b5e44e030134ea347ed8904 by Michael Goldfarb <mgoldfarb@nvidia.com>:\n\nExpose num_repeats_with_profiler option to Python HLO Runner interface\n\nMerging this change closes #31074\n\nPiperOrigin-RevId: 804792478",
    "sha": "247e2ce7c87dda40afda924238e96da6ce882a40",
    "files": [
        {
            "sha": "72051a4ad4ac46434a969c0a1136dd783fce7e79",
            "filename": "third_party/xla/xla/tools/multihost_hlo_runner/python_hlo_runner.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/247e2ce7c87dda40afda924238e96da6ce882a40/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/247e2ce7c87dda40afda924238e96da6ce882a40/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Fmultihost_hlo_runner%2Fpython_hlo_runner.cc?ref=247e2ce7c87dda40afda924238e96da6ce882a40",
            "patch": "@@ -75,6 +75,7 @@ struct PyHloRunnerConfig {\n   bool use_layouts_from_hlo_module = false;\n   bool force_auto_layout = false;\n   int32_t num_repeats = 1;\n+  int32_t num_repeats_with_profiler = 1;\n   std::string execution_options_path = \"\";\n   int64_t gpu_client_initialization_timeout_sec = 300;\n   float gpu_client_mem_fraction = GpuAllocatorConfig{}.memory_fraction;\n@@ -104,6 +105,8 @@ absl::StatusOr<FunctionalHloRunner::RunningOptions> RunningOptionsFromFlags(\n   out.module_argument_mode = opts.hlo_argument_mode;\n   out.module_output_mode = opts.output_mode;\n   out.num_repeats = static_cast<size_t>(opts.num_repeats);\n+  out.num_repeats_with_profiler =\n+      static_cast<size_t>(opts.num_repeats_with_profiler);\n   out.log_input_output_mode =\n       opts.log_output ? FunctionalHloRunner::LogOutputMode::kLogOutput\n                       : FunctionalHloRunner::LogOutputMode::kNotLogOutput;\n@@ -386,6 +389,8 @@ NB_MODULE(py_hlo_multihost_runner, m) {\n               &PyHloRunnerConfig::use_layouts_from_hlo_module)\n       .def_rw(\"force_auto_layout\", &PyHloRunnerConfig::force_auto_layout)\n       .def_rw(\"num_repeats\", &PyHloRunnerConfig::num_repeats)\n+      .def_rw(\"num_repeats_with_profiler\",\n+              &PyHloRunnerConfig::num_repeats_with_profiler)\n       .def_rw(\"gpu_client_initialization_timeout_sec\",\n               &PyHloRunnerConfig::gpu_client_initialization_timeout_sec)\n       .def_rw(\"gpu_client_mem_fraction\","
        }
    ],
    "stats": {
        "total": 5,
        "additions": 5,
        "deletions": 0
    }
}