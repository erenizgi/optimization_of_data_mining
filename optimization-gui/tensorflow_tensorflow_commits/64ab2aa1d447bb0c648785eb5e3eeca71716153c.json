{
    "author": "apivovarov",
    "message": "Add SelectKThunk and select_k_exec() for GPU-agnostic TopK execution.\n\n- Introduce SelectKThunk and select_k_exec() for GPU-agnostic TopK execution.\n- Link select_k_exec() to select_k_exec_raft if CUDA is available, or select_k_exec_stub otherwise.\n\nTesting note:\n\nVery few XLA thunks have standalone unit tests. We have a tendency to write e2e HLO runnable tests. e2e HLO runnable tests will be created in the next PR which integrates SelectKThunk into IrEmitterUnnested::EmitTopKCustomCall\n\nPiperOrigin-RevId: 800196416",
    "sha": "64ab2aa1d447bb0c648785eb5e3eeca71716153c",
    "files": [
        {
            "sha": "bfb3c271d7b671d89db2e470f37e0e80423390c6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 49,
            "deletions": 7,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -863,16 +863,18 @@ xla_cc_test(\n )\n \n cuda_library(\n-    name = \"raft_select_k_exec\",\n-    srcs = [\"raft_select_k_exec.cc\"],\n-    hdrs = [\"raft_select_k_exec.h\"],\n+    name = \"select_k_exec_raft\",\n+    srcs = [\"select_k_exec_raft.cc\"],\n+    hdrs = [\"select_k_exec.h\"],\n     copts = [\n         \"-fexceptions\",\n         \"-DLIBCUDACXX_ENABLE_EXPERIMENTAL_MEMORY_RESOURCE\",\n     ],\n     tags = [\"cuda-only\"],\n     textual_hdrs = [\"raft_vectorized_bf16.h\"],\n     deps = [\n+        \"//xla:status_macros\",\n+        \"//xla:types\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:scratch_allocator\",\n@@ -888,17 +890,31 @@ cuda_library(\n     ],\n )\n \n+cuda_library(\n+    name = \"select_k_exec_stub\",\n+    srcs = [\"select_k_exec_stub.cc\"],\n+    hdrs = [\"select_k_exec.h\"],\n+    deps = [\n+        \"//xla:types\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/status\",\n+    ],\n+)\n+\n xla_test(\n-    name = \"raft_select_k_exec_test\",\n-    srcs = [\"raft_select_k_exec_test.cc\"],\n+    name = \"select_k_exec_raft_test\",\n+    srcs = [\"select_k_exec_raft_test.cc\"],\n     backends = [\n         \"gpu\",\n     ],\n     tags = [\n         \"cuda-only\",\n     ],\n     deps = [\n-        \":raft_select_k_exec\",\n+        \":select_k_exec_raft\",\n+        \"//xla:types\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/service:platform_util\",\n@@ -916,10 +932,36 @@ xla_test(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_config_cuda//cuda:cuda_headers\",\n     ],\n )\n \n+cc_library(\n+    name = \"select_k_thunk\",\n+    srcs = [\"select_k_thunk.cc\"],\n+    hdrs = [\"select_k_thunk.h\"],\n+    tags = [\"gpu\"],\n+    deps = [\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla:shape_util\",\n+        \"//xla:types\",\n+        \"//xla/codegen/emitters:kernel_arguments\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:device_memory_allocator\",\n+        \"//xla/stream_executor:stream\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n+    ] + if_cuda_is_configured(\n+        [\":select_k_exec_raft\"],\n+        no_cuda = [\":select_k_exec_stub\"],\n+    ),\n+)\n+\n cc_library(\n     name = \"memset_thunk\",\n     srcs = [\"memset_thunk.cc\"],"
        },
        {
            "sha": "931b3f52a0a5b1b2cb7b931377aa34932df57cd7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec.h",
            "status": "renamed",
            "additions": 12,
            "deletions": 11,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec.h?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -13,8 +13,8 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#ifndef XLA_BACKENDS_GPU_RUNTIME_RAFT_SELECT_K_EXEC_H_\n-#define XLA_BACKENDS_GPU_RUNTIME_RAFT_SELECT_K_EXEC_H_\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_\n \n #include <cstdint>\n \n@@ -25,7 +25,7 @@ limitations under the License.\n \n namespace xla::gpu {\n \n-// Launches a RAFT Top-K selection on GPU for a batch of matrices.\n+// Launches a Top-K selection on GPU for a batch of matrices.\n //\n // Args:\n //   device_ordinal: GPU device index to run the operation on.\n@@ -41,14 +41,15 @@ namespace xla::gpu {\n // Returns:\n //   absl::Status indicating success or failure of the operation.\n template <typename T>\n-absl::Status raft_select_k_exec(\n-    int device_ordinal, ::stream_executor::DeviceMemoryAllocator* allocator,\n-    ::stream_executor::Stream* stream,\n-    ::stream_executor::DeviceMemoryBase data_in,\n-    ::stream_executor::DeviceMemoryBase data_out,\n-    ::stream_executor::DeviceMemoryBase indices_out, std::uint32_t batch,\n-    std::uint32_t n, std::uint32_t k);\n+absl::Status select_k_exec(int device_ordinal,\n+                           ::stream_executor::DeviceMemoryAllocator* allocator,\n+                           ::stream_executor::Stream* stream,\n+                           ::stream_executor::DeviceMemoryBase data_in,\n+                           ::stream_executor::DeviceMemoryBase data_out,\n+                           ::stream_executor::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k);\n \n }  // namespace xla::gpu\n \n-#endif  // XLA_BACKENDS_GPU_RUNTIME_RAFT_SELECT_K_EXEC_H_\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SELECT_K_EXEC_H_",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/raft_select_k_exec.h"
        },
        {
            "sha": "3b1abda8626dc4ff215217ff75cd3265868cd16b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_raft.cc",
            "status": "renamed",
            "additions": 38,
            "deletions": 21,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft.cc?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -13,13 +13,12 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/gpu/runtime/raft_select_k_exec.h\"\n-\n #include <cstddef>\n #include <cstdint>\n #include <exception>\n #include <memory>\n #include <optional>\n+#include <string>\n #include <utility>\n \n #include \"absl/base/optimization.h\"\n@@ -36,14 +35,17 @@ limitations under the License.\n #include \"raft/core/resources.hpp\"\n #include \"raft/matrix/select_k.cuh\"\n #include \"raft/matrix/select_k_types.hpp\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n // NOTE: This include is required for vectorized BF16 GPU runtime support.\n // It will no longer be needed after upgrading to raft v25.10.00.\n #include \"xla/backends/gpu/runtime/raft_vectorized_bf16.h\"\n+#include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/types.h\"\n \n namespace xla::gpu {\n namespace se = ::stream_executor;\n@@ -236,21 +238,16 @@ SelectAlgo choose_select_k_algorithm<nv_bfloat16>(uint32_t rows, uint32_t cols,\n \n // Host-side entry point for raft select_k\n template <typename T>\n-absl::Status raft_select_k_exec(\n-    int device_ordinal, se::DeviceMemoryAllocator* allocator,\n-    se::Stream* stream, se::DeviceMemoryBase data_in,\n-    se::DeviceMemoryBase data_out, se::DeviceMemoryBase indices_out,\n-    std::uint32_t batch, std::uint32_t n, std::uint32_t k) {\n-  // Validate input sizes\n-  DCHECK_EQ(data_in.size(), static_cast<uint64_t>(batch) * n * sizeof(T));\n-  DCHECK_EQ(data_out.size(), static_cast<uint64_t>(batch) * k * sizeof(T));\n-  DCHECK_EQ(indices_out.size(),\n-            static_cast<uint64_t>(batch) * k * sizeof(uint32_t));\n-  DCHECK_GE(n, k);\n-\n+absl::Status select_k_exec(int device_ordinal,\n+                           se::DeviceMemoryAllocator* allocator,\n+                           se::Stream* stream, se::DeviceMemoryBase data_in,\n+                           se::DeviceMemoryBase data_out,\n+                           se::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k) {\n   // Pick the most suitable algorithm\n   SelectAlgo algo = choose_select_k_algorithm<T>(batch, n, k);\n-  VLOG(3) << \"raft_select_k_exec: \"\n+  VLOG(3) << \"select_k_exec_raft: \"\n           << \"device_ordinal: \" << device_ordinal << \", \"\n           << \"data_in: \" << data_in.opaque() << \" (\" << data_in.size() << \"B)\"\n           << \", data_out: \" << data_out.opaque() << \" (\" << data_out.size()\n@@ -263,13 +260,16 @@ absl::Status raft_select_k_exec(\n   // Retrieve or create RAFT resource for this stream\n   cudaStream_t cuda_stream =\n       reinterpret_cast<cudaStream_t>(stream->platform_specific_handle().stream);\n-  DCHECK(cuda_stream != nullptr);\n+  TF_RET_CHECK(cuda_stream != nullptr)\n+      << \"Failed to cast se::Stream to cudaStream_t.\";\n   RaftStreamResource* resContainer =\n       stream->GetOrCreateResource<RaftStreamResource>(\n           [device_ordinal, allocator, cuda_stream] {\n             return RaftStreamResource::Create(device_ordinal, allocator,\n                                               cuda_stream);\n           });\n+  TF_RET_CHECK(resContainer != nullptr)\n+      << \"Failed to create or retrieve RaftStreamResource\";\n \n   try {\n     // Wrap raw device pointers in RAFT matrix views\n@@ -303,14 +303,31 @@ absl::Status raft_select_k_exec(\n }\n \n // Explicit instantiations for supported types\n-template absl::Status raft_select_k_exec<float>(\n-    int, se::DeviceMemoryAllocator*, se::Stream*, se::DeviceMemoryBase,\n-    se::DeviceMemoryBase, se::DeviceMemoryBase, std::uint32_t, std::uint32_t,\n-    std::uint32_t);\n+template absl::Status select_k_exec<float>(int, se::DeviceMemoryAllocator*,\n+                                           se::Stream*, se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase, std::uint32_t,\n+                                           std::uint32_t, std::uint32_t);\n \n-template absl::Status raft_select_k_exec<nv_bfloat16>(\n+template absl::Status select_k_exec<nv_bfloat16>(\n     int, se::DeviceMemoryAllocator*, se::Stream*, se::DeviceMemoryBase,\n     se::DeviceMemoryBase, se::DeviceMemoryBase, std::uint32_t, std::uint32_t,\n     std::uint32_t);\n \n+// Explicit specializations for xla::bfloat16\n+template <>\n+absl::Status select_k_exec<::xla::bfloat16>(\n+    int device_ordinal, se::DeviceMemoryAllocator* allocator,\n+    se::Stream* stream, se::DeviceMemoryBase data_in,\n+    se::DeviceMemoryBase data_out, se::DeviceMemoryBase indices_out,\n+    std::uint32_t batch, std::uint32_t n, std::uint32_t k) {\n+  // Sanity check: Eigen::bfloat16 and nv_bfloat16 must be binary-compatible\n+  static_assert(sizeof(::xla::bfloat16) == sizeof(nv_bfloat16),\n+                \"xla::bfloat16 and nv_bfloat16 must have the same size\");\n+\n+  // Just forward to the nv_bfloat16 instantiation\n+  return select_k_exec<nv_bfloat16>(device_ordinal, allocator, stream, data_in,\n+                                    data_out, indices_out, batch, n, k);\n+}\n+\n }  // namespace xla::gpu",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/raft_select_k_exec.cc"
        },
        {
            "sha": "940acd1c9805a0558709094b7a6bd0d5d7131f76",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_raft_test.cc",
            "status": "renamed",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_raft_test.cc?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -13,8 +13,6 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/gpu/runtime/raft_select_k_exec.h\"\n-\n #include <algorithm>\n #include <cstdint>\n #include <cstring>\n@@ -29,7 +27,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/ascii.h\"\n #include \"absl/types/span.h\"\n-#include \"third_party/gpus/cuda/include/cuda_bf16.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/platform.h\"\n@@ -38,6 +36,7 @@ limitations under the License.\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/types.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n \n@@ -65,7 +64,7 @@ struct MaskFor<float> {\n };\n \n template <>\n-struct MaskFor<nv_bfloat16> {\n+struct MaskFor<::xla::bfloat16> {\n   using type = uint16_t;\n   static constexpr type kStartBits = 0x3C00;  // bfloat16: 1/128\n };\n@@ -126,9 +125,9 @@ void RunSelectKTest() {\n   TF_ASSERT_OK(stream->MemcpyH2D(absl::Span<const T>(h_data_in), &d_data_in));\n \n   // Run raft select_k\n-  TF_ASSERT_OK(raft_select_k_exec<T>(device_ordinal, &allocator, stream.get(),\n-                                     d_data_in, d_data_out, d_indices_out,\n-                                     batch, n, k));\n+  TF_ASSERT_OK(select_k_exec<T>(device_ordinal, &allocator, stream.get(),\n+                                d_data_in, d_data_out, d_indices_out, batch, n,\n+                                k));\n \n   // Copy results back to host\n   std::vector<T> h_data_out(batch * k);\n@@ -150,6 +149,8 @@ void RunSelectKTest() {\n \n TEST(RaftSelectKExecTest, SelectKFloat) { RunSelectKTest<float>(); }\n \n-TEST(RaftSelectKExecTest, SelectKBFloat16) { RunSelectKTest<nv_bfloat16>(); }\n+TEST(RaftSelectKExecTest, SelectKBFloat16) {\n+  RunSelectKTest<::xla::bfloat16>();\n+}\n \n }  // namespace xla::gpu",
            "previous_filename": "third_party/xla/xla/backends/gpu/runtime/raft_select_k_exec_test.cc"
        },
        {
            "sha": "6094f3a0215210c5c3831731d18dbb4cae6b736c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_exec_stub.cc",
            "status": "added",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_exec_stub.cc?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -0,0 +1,52 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/types.h\"\n+\n+namespace xla::gpu {\n+namespace se = ::stream_executor;\n+\n+template <typename T>\n+absl::Status select_k_exec(int device_ordinal,\n+                           se::DeviceMemoryAllocator* allocator,\n+                           se::Stream* stream, se::DeviceMemoryBase data_in,\n+                           se::DeviceMemoryBase data_out,\n+                           se::DeviceMemoryBase indices_out,\n+                           std::uint32_t batch, std::uint32_t n,\n+                           std::uint32_t k) {\n+  return absl::UnimplementedError(\n+      \"select_k_exec is not implemented on this platform\");\n+}\n+\n+// Explicit instantiations for supported dtypes.\n+template absl::Status select_k_exec<float>(int, se::DeviceMemoryAllocator*,\n+                                           se::Stream*, se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase,\n+                                           se::DeviceMemoryBase, std::uint32_t,\n+                                           std::uint32_t, std::uint32_t);\n+\n+template absl::Status select_k_exec<::xla::bfloat16>(\n+    int, se::DeviceMemoryAllocator*, se::Stream*, se::DeviceMemoryBase,\n+    se::DeviceMemoryBase, se::DeviceMemoryBase, std::uint32_t, std::uint32_t,\n+    std::uint32_t);\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "055ecc4baf88d5a1c3cf454e49f214be03b66f7c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_thunk.cc",
            "status": "added",
            "additions": 102,
            "deletions": 0,
            "changes": 102,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.cc?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -0,0 +1,102 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/select_k_thunk.h\"\n+\n+#include <cstdint>\n+#include <string>\n+\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/backends/gpu/runtime/select_k_exec.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/primitive_util.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/device_memory_allocator.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/types.h\"\n+\n+namespace xla::gpu {\n+\n+//===----------------------------------------------------------------------===//\n+// SelectKThunk\n+//===----------------------------------------------------------------------===//\n+\n+SelectKThunk::SelectKThunk(const HloInstruction* inst, std::uint32_t batch_size,\n+                           std::uint32_t num_elements, std::uint32_t k,\n+                           xla::PrimitiveType dtype,\n+                           const emitters::KernelArguments& kernel_arguments)\n+    : Thunk(Kind::kSelectK, Thunk::ThunkInfo::WithProfileAnnotation(inst)),\n+      batch_size_(batch_size),\n+      num_elements_(num_elements),\n+      k_(k),\n+      dtype_(dtype),\n+      args_(kernel_arguments.GetArgumentBufferSlices()) {\n+  CHECK_EQ(args_.size(), 3)\n+      << \"SelectKThunk expects exactly 3 buffer arguments \"\n+         \"(input_data, output_data, output_indices)\";\n+}\n+\n+std::string SelectKThunk::ToString(int indent) const {\n+  const std::string indent_str(indent * 2, ' ');\n+  return absl::StrCat(indent_str, \"SelectKThunk(batch_size=\", batch_size_,\n+                      \", num_elements=\", num_elements_, \", k=\", k_,\n+                      \", dtype=\", dtype_, \")\");\n+}\n+\n+// Execute the TopK operation on the GPU stream.\n+// Maps kernel arguments to device memory and dispatches the appropriate\n+// select_k_exec implementation based on the platform and data type.\n+absl::Status SelectKThunk::ExecuteOnStream(const ExecuteParams& params) {\n+  VLOG(3) << \"Launching \" << ToString(0);\n+\n+  // Map buffer slices to device memory.\n+  absl::InlinedVector<se::DeviceMemoryBase, 3> buffer_args;\n+  for (const BufferAllocation::Slice& arg : args_) {\n+    se::DeviceMemoryBase buf = params.buffer_allocations->GetDeviceAddress(arg);\n+    VLOG(3) << \"  Arg: alloc #\" << arg.index() << \", offset: \" << arg.offset()\n+            << \": \" << buf.opaque() << \" (\" << buf.size() << \"B)\";\n+    buffer_args.push_back(buf);\n+  }\n+\n+  int device_ordinal = params.buffer_allocations->device_ordinal();\n+  se::DeviceMemoryAllocator* allocator =\n+      params.buffer_allocations->memory_allocator();\n+  se::Stream* stream = params.stream;\n+\n+  // Dispatch to the correct typed implementation based on dtype.\n+  switch (dtype_) {\n+    case PrimitiveType::F32:\n+      return select_k_exec<float>(\n+          device_ordinal, allocator, stream, buffer_args[0], buffer_args[1],\n+          buffer_args[2], batch_size_, num_elements_, k_);\n+    case PrimitiveType::BF16:\n+      return select_k_exec<::xla::bfloat16>(\n+          device_ordinal, allocator, stream, buffer_args[0], buffer_args[1],\n+          buffer_args[2], batch_size_, num_elements_, k_);\n+    default:\n+      return absl::UnimplementedError(\n+          absl::StrCat(\"SelectKThunk: Unsupported dtype: \",\n+                       primitive_util::LowercasePrimitiveTypeName(dtype_)));\n+  }\n+}\n+}  // namespace xla::gpu"
        },
        {
            "sha": "f4164a80e566eeb4c2a61150104b01faabc84fcc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/select_k_thunk.h",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fselect_k_thunk.h?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -0,0 +1,76 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/status/status.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/types.h\"  // IWYU pragma: keep\n+\n+namespace xla::gpu {\n+\n+//===----------------------------------------------------------------------===//\n+// SelectKThunk\n+//===----------------------------------------------------------------------===//\n+\n+// SelectKThunk executes the select_k operation on the provided inputs\n+class SelectKThunk : public Thunk {\n+ public:\n+  // Constructor.\n+  // Parameters:\n+  //   inst             - The HLO instruction that generated this thunk.\n+  //   batch_size       - Number of batches in the input tensor.\n+  //   num_elements     - Number of elements in each batch.\n+  //   k                - Number of top elements to select.\n+  //   dtype            - Data type of elements (e.g., F32, BF16).\n+  //   kernel_arguments - Kernel arguments holding buffer slices for\n+  //                      inputs/outputs.\n+  SelectKThunk(const HloInstruction* inst, std::uint32_t batch_size,\n+               std::uint32_t num_elements, std::uint32_t k,\n+               xla::PrimitiveType dtype,\n+               const emitters::KernelArguments& kernel_arguments);\n+\n+  std::string ToString(int indent) const override;\n+\n+  // Executes the TopK operation on the given stream.\n+  absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n+\n+  const std::vector<BufferAllocation::Slice>& arguments() const {\n+    return args_;\n+  }\n+\n+ private:\n+  std::uint32_t batch_size_;\n+  std::uint32_t num_elements_;\n+  std::uint32_t k_;\n+  xla::PrimitiveType dtype_;\n+\n+  // Buffer slices passed to the kernel as arguments.\n+  std::vector<BufferAllocation::Slice> args_;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SELECT_K_THUNK_H_"
        },
        {
            "sha": "b0dcda96cc07f65b257afd0a1102ca32ee05e61e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -309,6 +309,7 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kReduceScatterDone);\n     CASE(kReduceScatterStart);\n     CASE(kReplicaId);\n+    CASE(kSelectK);\n     CASE(kSend);\n     CASE(kSendDone);\n     CASE(kSequential);"
        },
        {
            "sha": "aff6cba8f1addf9a4d7ff1b4c2d47e2a1696a830",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64ab2aa1d447bb0c648785eb5e3eeca71716153c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=64ab2aa1d447bb0c648785eb5e3eeca71716153c",
            "patch": "@@ -190,6 +190,7 @@ class Thunk {\n     kReduceScatterDone,\n     kReduceScatterStart,\n     kReplicaId,\n+    kSelectK,\n     kSend,\n     kSendDone,\n     kSequential,"
        }
    ],
    "stats": {
        "total": 387,
        "additions": 340,
        "deletions": 47
    }
}