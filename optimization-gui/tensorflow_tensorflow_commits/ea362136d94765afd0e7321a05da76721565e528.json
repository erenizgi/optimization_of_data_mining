{
    "author": "ermilovmaxim",
    "message": "Allow serialization for sync collectives\n\nPiperOrigin-RevId: 846790089",
    "sha": "ea362136d94765afd0e7321a05da76721565e528",
    "files": [
        {
            "sha": "c2dfc808d40e076e7986e1c71867e4ca56d7345f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -121,11 +121,15 @@ AllGatherStartThunk::FromProto(\n     buffers.push_back(buffer);\n   }\n \n-  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n-      async_events_map[AsyncEventsUniqueId{\n-          thunk_proto.async_events_unique_id()}];\n-  if (!async_events) {\n-    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n   }\n \n   return std::make_unique<AllGatherStartThunk>(\n@@ -142,10 +146,9 @@ absl::StatusOr<ThunkProto> AllGatherStartThunk::ToProto() const {\n       proto.mutable_all_gather_start_thunk();\n \n   std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n-  if (!async_events_id.has_value()) {\n-    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n   }\n-  thunk_proto->set_async_events_unique_id(async_events_id->value());\n \n   for (const Buffer& buffer : buffers_) {\n     ASSIGN_OR_RETURN(*thunk_proto->add_buffers(), buffer.ToProto());"
        },
        {
            "sha": "33f9802818b17f628abbf6c70437cab95963f768",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -259,11 +259,15 @@ AllReduceStartThunk::FromProto(\n     buffers.push_back(buffer);\n   }\n \n-  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n-      async_events_map[AsyncEventsUniqueId{\n-          thunk_proto.async_events_unique_id()}];\n-  if (!async_events) {\n-    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n   }\n \n   CollectiveConfig config =\n@@ -290,10 +294,9 @@ absl::StatusOr<ThunkProto> AllReduceStartThunk::ToProto() const {\n       proto.mutable_all_reduce_start_thunk();\n \n   std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n-  if (!async_events_id.has_value()) {\n-    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n   }\n-  thunk_proto->set_async_events_unique_id(async_events_id->value());\n \n   for (const Buffer& buffer : buffers_) {\n     ASSIGN_OR_RETURN(*thunk_proto->add_buffers(), buffer.ToProto());"
        },
        {
            "sha": "2aa2cc91c0e3f83bf670e8060d931726dc54512c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk_test.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk_test.cc?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -70,5 +70,35 @@ TEST(CollectiveThunkTest, ProtoRoundTrip) {\n   EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n }\n \n+TEST(CollectiveThunkTest, SyncCollective) {\n+  ThunkProto proto = tsl::proto_testing::ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info {\n+          profile_annotation: \"partition_id_profile_annotation\"\n+          execution_stream_id: 2\n+        }\n+        all_reduce_start_thunk {\n+          collective_config {}\n+          reduction_kind: 1\n+        }\n+      )pb\");\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = proto.thunk_info().profile_annotation();\n+  thunk_info.execution_stream_id = xla::gpu::ExecutionStreamId{\n+      static_cast<xla::gpu::ExecutionStreamId::ValueType>(\n+          proto.thunk_info().execution_stream_id())};\n+\n+  CollectiveThunk::AsyncEventsMap async_events_map;\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0)};\n+\n+  ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<AllReduceStartThunk> thunk,\n+      AllReduceStartThunk::FromProto(thunk_info, proto.all_reduce_start_thunk(),\n+                                     buffer_allocations, async_events_map));\n+  ASSERT_EQ(thunk->async_events(), nullptr);\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "8d68160cc8b2be93fb6edd6418b71b939d649ac4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -297,11 +297,15 @@ AllToAllStartThunk::FromProto(\n     buffers.push_back(buffer);\n   }\n \n-  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n-      async_events_map[AsyncEventsUniqueId{\n-          thunk_proto.async_events_unique_id()}];\n-  if (!async_events) {\n-    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n   }\n \n   CollectiveConfig config =\n@@ -320,10 +324,9 @@ absl::StatusOr<ThunkProto> AllToAllStartThunk::ToProto() const {\n   AllToAllStartThunkProto* thunk_proto = proto.mutable_all_to_all_start_thunk();\n \n   std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n-  if (!async_events_id.has_value()) {\n-    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n   }\n-  thunk_proto->set_async_events_unique_id(async_events_id->value());\n \n   for (const Buffer& buffer : buffers_) {\n     ASSIGN_OR_RETURN(*thunk_proto->add_buffers(), buffer.ToProto());"
        },
        {
            "sha": "8ddff57556d6b8edd97b41d60a8be733295d4821",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 7,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -539,8 +539,8 @@ absl::StatusOr<ThunkProto> CollectiveDoneThunk::ToProto() const {\n   thunk_proto->set_async_stream_kind(stream_kind_);\n \n   std::optional<AsyncEventsUniqueId> async_events_id = GetAsyncEventsUniqueId();\n-  if (!async_events_id.has_value()) {\n-    return absl::FailedPreconditionError(\"AsyncEvents is not set.\");\n+  if (async_events_id.has_value()) {\n+    thunk_proto->set_async_events_unique_id(async_events_id->value());\n   }\n   thunk_proto->set_async_events_unique_id(async_events_id->value());\n   thunk_proto->set_thunk_kind(Thunk::KindToProto(kind()));\n@@ -551,11 +551,15 @@ absl::StatusOr<std::unique_ptr<CollectiveDoneThunk>>\n CollectiveDoneThunk::FromProto(\n     ThunkInfo thunk_info, const CollectiveDoneThunkProto& thunk_proto,\n     CollectiveThunk::AsyncEventsMap& async_events_map) {\n-  std::shared_ptr<CollectiveThunk::AsyncEvents>& async_events =\n-      async_events_map[AsyncEventsUniqueId{\n-          thunk_proto.async_events_unique_id()}];\n-  if (!async_events) {\n-    async_events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+  std::shared_ptr<CollectiveThunk::AsyncEvents> async_events;\n+  if (thunk_proto.has_async_events_unique_id()) {\n+    std::shared_ptr<CollectiveThunk::AsyncEvents>& events =\n+        async_events_map[AsyncEventsUniqueId{\n+            thunk_proto.async_events_unique_id()}];\n+    if (!events) {\n+      events = std::make_shared<CollectiveThunk::AsyncEvents>();\n+    }\n+    async_events = events;\n   }\n \n   ASSIGN_OR_RETURN(Thunk::Kind kind,"
        },
        {
            "sha": "d7af07c98214dd29bad1ba731bd86744b29cea2e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ea362136d94765afd0e7321a05da76721565e528/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=ea362136d94765afd0e7321a05da76721565e528",
            "patch": "@@ -400,7 +400,7 @@ message CollectiveThunkProto {\n }\n \n message AllGatherStartThunkProto {\n-  uint64 async_events_unique_id = 1;\n+  optional uint64 async_events_unique_id = 1;\n   CollectiveConfigProto collective_config = 2;\n   repeated CollectiveBufferProto buffers = 3;\n }\n@@ -414,7 +414,7 @@ enum ReductionKindProto {\n }\n \n message AllReduceStartThunkProto {\n-  uint64 async_events_unique_id = 1;\n+  optional uint64 async_events_unique_id = 1;\n   CollectiveConfigProto collective_config = 2;\n   repeated CollectiveBufferProto buffers = 3;\n \n@@ -427,7 +427,7 @@ message AllReduceStartThunkProto {\n }\n \n message AllToAllStartThunkProto {\n-  uint64 async_events_unique_id = 1;\n+  optional uint64 async_events_unique_id = 1;\n   CollectiveConfigProto collective_config = 2;\n   repeated CollectiveBufferProto buffers = 3;\n \n@@ -438,7 +438,7 @@ message AllToAllStartThunkProto {\n message CollectiveDoneThunkProto {\n   ThunkKindProto thunk_kind = 1;\n   AsyncStreamKind async_stream_kind = 2;\n-  uint64 async_events_unique_id = 3;\n+  optional uint64 async_events_unique_id = 3;\n }\n \n message ThunkProto {"
        }
    ],
    "stats": {
        "total": 113,
        "additions": 78,
        "deletions": 35
    }
}