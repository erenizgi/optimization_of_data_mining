{
    "author": "beckerhe",
    "message": "Refactor: Make Executable::hlo_module_ private and use accessors.\n\nThis change makes the `hlo_module_` member of the `Executable` class private and updates all call sites to use the new `has_module()` and `module()` accessor methods. This improves encapsulation.\n\nPiperOrigin-RevId: 839199935",
    "sha": "4d08bf84aab81277b049343d0dac82b5e3effba5",
    "files": [
        {
            "sha": "37d0a13f8febe1c2d9d922e80f763ceb140cf886",
            "filename": "third_party/xla/xla/backends/interpreter/executable_base.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fexecutable_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fexecutable_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Finterpreter%2Fexecutable_base.cc?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -148,8 +148,8 @@ absl::StatusOr<ExecutionOutput> InterpreterExecutableBase::ExecuteAsyncOnStream(\n \n   // Transform the result literal back into a ShapedBuffer.\n   const HloInputOutputAliasConfig& alias_config =\n-      hlo_module_ == nullptr ? HloInputOutputAliasConfig()\n-                             : hlo_module_->input_output_alias_config();\n+      has_module() ? module().input_output_alias_config()\n+                   : HloInputOutputAliasConfig();\n   TF_ASSIGN_OR_RETURN(ExecutionOutput result,\n                       AllocateOutputMemoryWithInputReuse(\n                           result_literal.shape(), alias_config,"
        },
        {
            "sha": "4afd353e9b9cbfc857cc7ec2e657d6a054f8b02a",
            "filename": "third_party/xla/xla/service/cpu/cpu_executable.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_executable.cc?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -323,7 +323,7 @@ absl::StatusOr<ExecutionOutput> CpuExecutable::CreateResultShapedBuffer(\n                          stream->parent()->device_ordinal());\n   const HloInputOutputAliasConfig& input_output_alias =\n       module().input_output_alias_config();\n-  HloInstruction* root = hlo_module_->entry_computation()->root_instruction();\n+  HloInstruction* root = module().entry_computation()->root_instruction();\n   const Shape& root_shape = root->shape();\n \n   // Move se::OwningDeviceMemory values which contain the array(s) of the result\n@@ -425,8 +425,8 @@ absl::StatusOr<ExecutionOutput> CpuExecutable::ExecuteAsyncOnStream(\n     return Unimplemented(\"Points-to set of root instruction is ambiguous\");\n   }\n \n-  if (hlo_module_) {\n-    const HloComputation* entry_comp = hlo_module_->entry_computation();\n+  if (has_module()) {\n+    const HloComputation* entry_comp = module().entry_computation();\n     CHECK_EQ(entry_comp->num_parameters(), arguments.size())\n         << \"Wrong number of arguments passed when running executable\";\n     for (int64_t i = 0; i < entry_comp->num_parameters(); ++i) {"
        },
        {
            "sha": "9a811da10b69771a2997443cf825b53c1b7dde19",
            "filename": "third_party/xla/xla/service/executable.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fexecutable.h?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -456,14 +456,14 @@ class Executable {\n     return absl::OkStatus();\n   }\n \n- protected:\n+ private:\n   // HloModule this was compiled from. BufferAssignment keeps pointers to\n   // HloInstructions owned by the HloModule so we need to keep the HloModule\n   // around if we keep the BufferAssignment around.\n   //\n   // This member may be nullptr, if the given executable type doesn't need it\n   // for execution.\n-  const std::shared_ptr<HloModule> hlo_module_;\n+  std::shared_ptr<HloModule> hlo_module_;\n \n   // Execution count, used to generate a unique filename for each dumped\n   // execution.\n@@ -475,7 +475,6 @@ class Executable {\n   // Generic debug information as a string.\n   std::string debug_info_;\n \n- private:\n   // The serialized HLO proto. Non-null only if dumping snapshots is enabled.\n   // This field may also be only partially set: if only\n   // hlo_proto_->buffer_assignment is set and hlo_proto_->hlo_module isn't, the"
        },
        {
            "sha": "af25680e1e4f5a573447e03c9ae19694bd47e790",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -1235,8 +1235,8 @@ absl::StatusOr<GpuExecutableProto> GpuExecutable::ToProto() const {\n         allocation->ToProto());\n   }\n \n-  if (hlo_module_ != nullptr) {\n-    *proto.mutable_hlo_module_with_config() = hlo_module_->ToProtoWithConfig();\n+  if (has_module()) {\n+    *proto.mutable_hlo_module_with_config() = module().ToProtoWithConfig();\n   }\n \n   proto.mutable_output_info_map()->Reserve(output_info_.size());"
        },
        {
            "sha": "569585e777e49da0599e9db91fd087bf4cf311aa",
            "filename": "third_party/xla/xla/stream_executor/tpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2FBUILD?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -615,16 +615,15 @@ cc_library(\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "d4ac0c53642fbccb1fca5c5b75518242ddc4233d",
            "filename": "third_party/xla/xla/stream_executor/tpu/tpu_executable_interface.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_executable_interface.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4d08bf84aab81277b049343d0dac82b5e3effba5/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_executable_interface.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Ftpu%2Ftpu_executable_interface.cc?ref=4d08bf84aab81277b049343d0dac82b5e3effba5",
            "patch": "@@ -41,10 +41,9 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/logging.h\"  // IWYU pragma: keep\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla::legacy {\n \n@@ -218,11 +217,10 @@ absl::StatusOr<ExecutionOutput> TpuExecutableInterface::ExecuteAsyncOnStream(\n   se::Stream* stream = run_options->stream();\n \n   CHECK_NE(run_options->allocator(), nullptr);\n-  const Shape& shape =\n-      hlo_module_ == nullptr ? ShapeUtil::MakeNil() : result_shape();\n+  const Shape& shape = !has_module() ? ShapeUtil::MakeNil() : result_shape();\n   const HloInputOutputAliasConfig& alias_config =\n-      hlo_module_ == nullptr ? HloInputOutputAliasConfig()\n-                             : hlo_module_->input_output_alias_config();\n+      !has_module() ? HloInputOutputAliasConfig()\n+                    : module().input_output_alias_config();\n   TF_ASSIGN_OR_RETURN(\n       ExecutionOutput result,\n       AllocateOutputMemoryWithInputReuse(\n@@ -232,9 +230,9 @@ absl::StatusOr<ExecutionOutput> TpuExecutableInterface::ExecuteAsyncOnStream(\n   // Address of the buffer in TPU memory that is being speculated.\n   std::vector<se::DeviceMemoryBase> cross_program_prefetch_addrs;\n   std::vector<uint32_t> cross_program_prefetch_offsets;\n-  if (hlo_module_) {\n+  if (has_module()) {\n     for (const auto& [parameter, index, offset] :\n-         hlo_module_->CrossProgramPrefetches()) {\n+         module().CrossProgramPrefetches()) {\n       CHECK_LT(parameter, arguments.size());\n       // Ensure the cross program prefetched buffer doesn't alias with any\n       // program outputs. If the input and output aliased, the buffer could be"
        }
    ],
    "stats": {
        "total": 40,
        "additions": 18,
        "deletions": 22
    }
}