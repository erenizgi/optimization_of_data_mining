{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Use linalg DPS for elementwise ops.\n\nOnce we use DPS for all ops we get a few advantages:\n1. It allows us to massage the IR to reuse buffers.\n2. We can fuse ops to share loops to avoid materializing intermediated values in some cases.\n3. We can start vectorizing after bufferization which gives us more control over vectorization strategy.\n\nPiperOrigin-RevId: 831775464",
    "sha": "e6d6b2de71904170972d2c9dace94bacf8b51b56",
    "files": [
        {
            "sha": "e6bf1a1b7e7ffdc4996cf5c728562668fbfa764c",
            "filename": "third_party/xla/xla/backends/cpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2FBUILD?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -248,6 +248,7 @@ cc_library(\n         \"@llvm-project//mlir:VectorTransforms\",\n         \"@local_tsl//tsl/profiler/lib:traceme\",\n         \"@local_tsl//tsl/profiler/lib:traceme_encode\",\n+        \"@stablehlo//:linalg_passes\",\n         \"@stablehlo//:stablehlo_ops\",\n         \"@stablehlo//:stablehlo_passes\",\n     ],"
        },
        {
            "sha": "f3fcd4e6b4798ba8e5e213df31769376a5dd450d",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -64,6 +64,7 @@ limitations under the License.\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/Transforms/InlinerInterfaceImpl.h\"\n #include \"mlir/Dialect/Linalg/IR/Linalg.h\"\n+#include \"mlir/Dialect/Linalg/Passes.h\"\n #include \"mlir/Dialect/Linalg/Transforms/BufferizableOpInterfaceImpl.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n #include \"mlir/Dialect/MemRef/Transforms/AllocationOpInterfaceImpl.h\"\n@@ -93,6 +94,7 @@ limitations under the License.\n #include \"mlir/Target/LLVMIR/Dialect/LLVMIR/LLVMToLLVMIRTranslation.h\"\n #include \"mlir/Target/LLVMIR/Export.h\"\n #include \"mlir/Transforms/Passes.h\"\n+#include \"stablehlo/conversions/linalg/transforms/Passes.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n #include \"stablehlo/transforms/Passes.h\"\n #include \"xla/backends/cpu/codegen/emitters/ir/xla_cpu_dialect.h\"\n@@ -310,14 +312,18 @@ static void AddTiledOptimizationPasses(mlir::OpPassManager& pm) {\n   pm.addPass(CreateShloToVectorPass());\n   pm.addPass(CreateXTileToVectorPass());\n   pm.addPass(mlir::createCanonicalizerPass());\n-  pm.addPass(CreateElementalTensorToVectorPass());\n   pm.addPass(CreateLowerXTileEntryPass());\n   pm.addNestedPass<mlir::func::FuncOp>(\n       mlir::vector::createLowerVectorMultiReductionPass(\n           mlir::vector::VectorMultiReductionLowering::InnerParallel));\n   pm.addPass(CreateTensorOpsToVectorPass());\n \n+  pm.addPass(mlir::createConvertElementwiseToLinalgPass());\n+  pm.addPass(mlir::createLinalgElementwiseOpFusionPass());\n+\n   AddBufferizationPasses(pm);\n+\n+  pm.addPass(CreateLinalgElementwiseToVectorPass());\n }\n \n // Lowering passes for the tiled emitter."
        },
        {
            "sha": "4ca6030449b4be4ec4104a81cd8fc205a2efeab8",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -48,7 +48,7 @@ cc_library(\n cc_library(\n     name = \"passes\",\n     srcs = [\n-        \"elemental_tensor_to_vector.cc\",\n+        \"linalg_elementwise_to_vector_pass.cc\",\n         \"lower_xtile_entry.cc\",\n         \"memref_copy_to_loops.cc\",\n         \"shlo_to_vector.cc\",\n@@ -68,15 +68,16 @@ cc_library(\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:ArithDialect\",\n-        \"@llvm-project//mlir:ArithOpsIncGen\",\n         \"@llvm-project//mlir:BufferizationDialect\",\n         \"@llvm-project//mlir:DataLayoutInterfaces\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:FuncTransforms\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:LLVMDialect\",\n+        \"@llvm-project//mlir:LinalgDialect\",\n+        \"@llvm-project//mlir:LinalgTransforms\",\n+        \"@llvm-project//mlir:LinalgUtils\",\n         \"@llvm-project//mlir:MathDialect\",\n-        \"@llvm-project//mlir:MathOpsIncGen\",\n         \"@llvm-project//mlir:MemRefDialect\",\n         \"@llvm-project//mlir:MemRefUtils\",\n         \"@llvm-project//mlir:Pass\","
        },
        {
            "sha": "f208e43a1dfa469dd1219ecfc2b3992ef26e1f61",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/elemental_tensor_to_vector.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 199,
            "changes": 199,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Felemental_tensor_to_vector.cc?ref=5f530aea57dcdeeb36328cf94b3b5622f3d21abe",
            "patch": "@@ -1,199 +0,0 @@\n-/* Copyright 2025 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include <cassert>\n-#include <cstdint>\n-#include <memory>\n-#include <utility>\n-\n-#include \"llvm/Support/LogicalResult.h\"\n-#include \"mlir/Dialect/Arith/IR/Arith.h\"\n-#include \"mlir/Dialect/Func/Transforms/FuncConversions.h\"\n-#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n-#include \"mlir/IR/Builders.h\"\n-#include \"mlir/IR/BuiltinAttributes.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n-#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n-#include \"mlir/IR/BuiltinTypes.h\"\n-#include \"mlir/IR/PatternMatch.h\"\n-#include \"mlir/IR/Types.h\"\n-#include \"mlir/IR/Value.h\"\n-#include \"mlir/IR/ValueRange.h\"\n-#include \"mlir/IR/Visitors.h\"\n-#include \"mlir/Interfaces/DataLayoutInterfaces.h\"\n-#include \"mlir/Pass/Pass.h\"\n-#include \"mlir/Support/LLVM.h\"\n-#include \"mlir/Transforms/DialectConversion.h\"\n-#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n-#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n-\n-namespace xla::cpu {\n-\n-#define GEN_PASS_DECL_ELEMENTALTENSORTOVECTORPASS\n-#define GEN_PASS_DEF_ELEMENTALTENSORTOVECTORPASS\n-#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n-\n-namespace {\n-\n-// This converter defines the rules for mapping types from the source (tensors)\n-// to the target (vectors).\n-class TensorToVectorTypeConverter : public mlir::TypeConverter {\n- public:\n-  TensorToVectorTypeConverter() {\n-    // Keep all non-tensor types as-is.\n-    addConversion([](mlir::Type type) { return type; });\n-\n-    // Convert RankedTensorType to VectorType.\n-    addConversion([](mlir::RankedTensorType type) -> mlir::Type {\n-      // We can only convert tensors with a static shape to vectors.\n-      if (!type.hasStaticShape()) {\n-        return nullptr;  // Return null if the type cannot be converted.\n-      }\n-      return mlir::VectorType::get(type.getShape(), type.getElementType());\n-    });\n-\n-    addSourceMaterialization([](mlir::OpBuilder& builder,\n-                                mlir::Type result_type, mlir::ValueRange inputs,\n-                                mlir::Location loc) -> mlir::Value {\n-      if (inputs.size() != 1) {\n-        return nullptr;\n-      }\n-\n-      return WriteVectorToTensor(builder, inputs.front());\n-    });\n-\n-    addTargetMaterialization([](mlir::OpBuilder& builder,\n-                                mlir::Type result_type, mlir::ValueRange inputs,\n-                                mlir::Location loc) -> mlir::Value {\n-      if (inputs.size() != 1) {\n-        return nullptr;\n-      }\n-\n-      return ReadTensorToVector(builder, inputs.front());\n-    });\n-  }\n-\n- private:\n-  static llvm::SmallVector<mlir::Value> MakeZeroIndices(\n-      mlir::OpBuilder& builder, mlir::Location loc, int64_t rank) {\n-    return llvm::SmallVector<mlir::Value>(\n-        rank, mlir::arith::ConstantIndexOp::create(builder, loc, 0));\n-  }\n-};\n-\n-// A generic pattern to convert an elemental op from tensor-based to\n-// vector-based.\n-template <typename ElementalOp>\n-class ElementalOpConversion : public mlir::OpConversionPattern<ElementalOp> {\n- public:\n-  using mlir::OpConversionPattern<ElementalOp>::OpConversionPattern;\n-\n-  mlir::LogicalResult matchAndRewrite(\n-      ElementalOp op, typename ElementalOp::Adaptor adaptor,\n-      mlir::ConversionPatternRewriter& rewriter) const override {\n-    llvm::SmallVector<mlir::Type> new_result_types;\n-    mlir::LogicalResult results_ok = this->getTypeConverter()->convertTypes(\n-        op->getResultTypes(), new_result_types);\n-    if (results_ok.failed()) {\n-      return rewriter.notifyMatchFailure(op, \"could not convert result type\");\n-    }\n-\n-    rewriter.replaceOpWithNewOp<ElementalOp>(\n-        op, new_result_types, adaptor.getOperands(), op->getAttrs());\n-    return mlir::success();\n-  }\n-};\n-\n-// We need to specify the ConstantOp conversion explicitly as it doesn't follow\n-// the simple operands & results of the other Arith ops.\n-template <>\n-class ElementalOpConversion<mlir::arith::ConstantOp>\n-    : public mlir::OpConversionPattern<mlir::arith::ConstantOp> {\n- public:\n-  using mlir::OpConversionPattern<mlir::arith::ConstantOp>::OpConversionPattern;\n-\n-  mlir::LogicalResult matchAndRewrite(\n-      mlir::arith::ConstantOp op,\n-      typename mlir::arith::ConstantOp::Adaptor adaptor,\n-      mlir::ConversionPatternRewriter& rewriter) const override {\n-    mlir::Type new_type = getTypeConverter()->convertType(op.getType());\n-    mlir::ShapedType shaped_type = mlir::dyn_cast<mlir::ShapedType>(new_type);\n-    if (!shaped_type) {\n-      return rewriter.notifyMatchFailure(op, \"could not convert result type\");\n-    }\n-\n-    auto dense_attr = mlir::dyn_cast<mlir::DenseElementsAttr>(op.getValue());\n-    rewriter.replaceOpWithNewOp<mlir::arith::ConstantOp>(\n-        op, new_type, dense_attr.reshape(shaped_type));\n-    return mlir::success();\n-  }\n-};\n-\n-template <typename... ElementalOps>\n-void AddAElementalOpConversionsImpl(\n-    mlir::ConversionTarget& target, mlir::RewritePatternSet& patterns,\n-    TensorToVectorTypeConverter& typeConverter) {\n-  target.addDynamicallyLegalOp<ElementalOps...>(\n-      [&](mlir::Operation* op) { return typeConverter.isLegal(op); });\n-  patterns.add<ElementalOpConversion<ElementalOps>...>(typeConverter,\n-                                                       patterns.getContext());\n-}\n-\n-void AddArithOpConversions(mlir::ConversionTarget& target,\n-                           mlir::RewritePatternSet& patterns,\n-                           TensorToVectorTypeConverter& typeConverter) {\n-  AddAElementalOpConversionsImpl<\n-#define GET_OP_LIST\n-#include \"mlir/Dialect/Arith/IR/ArithOps.cpp.inc\"\n-#undef GET_OP_LIST\n-      >(target, patterns, typeConverter);\n-}\n-\n-void AddMathOpConversions(mlir::ConversionTarget& target,\n-                          mlir::RewritePatternSet& patterns,\n-                          TensorToVectorTypeConverter& typeConverter) {\n-  AddAElementalOpConversionsImpl<\n-#define GET_OP_LIST\n-#include \"mlir/Dialect/Math/IR/MathOps.cpp.inc\"\n-#undef GET_OP_LIST\n-      >(target, patterns, typeConverter);\n-}\n-\n-struct ElementalTensorToVectorPass\n-    : public impl::ElementalTensorToVectorPassBase<\n-          ElementalTensorToVectorPass> {\n-  void runOnOperation() override {\n-    auto* context = &getContext();\n-    mlir::ModuleOp module = getOperation();\n-\n-    mlir::ConversionTarget target(*context);\n-    mlir::RewritePatternSet patterns(context);\n-    TensorToVectorTypeConverter typeConverter;\n-    AddArithOpConversions(target, patterns, typeConverter);\n-    AddMathOpConversions(target, patterns, typeConverter);\n-\n-    if (failed(applyPartialConversion(module, target, std::move(patterns)))) {\n-      signalPassFailure();\n-    }\n-  }\n-};\n-\n-}  // namespace\n-\n-std::unique_ptr<mlir::Pass> CreateElementalTensorToVectorPass() {\n-  return std::make_unique<ElementalTensorToVectorPass>();\n-}\n-\n-}  // namespace xla::cpu"
        },
        {
            "sha": "4126bc4a17df23518edff75b4d95c52dac9aca83",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/linalg_elementwise_to_vector_pass.cc",
            "status": "added",
            "additions": 110,
            "deletions": 0,
            "changes": 110,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flinalg_elementwise_to_vector_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flinalg_elementwise_to_vector_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flinalg_elementwise_to_vector_pass.cc?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -0,0 +1,110 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cassert>\n+#include <memory>\n+#include <utility>\n+\n+#include \"mlir/Dialect/Func/Transforms/FuncConversions.h\"\n+#include \"mlir/Dialect/Linalg/IR/Linalg.h\"\n+#include \"mlir/Dialect/Linalg/Transforms/Transforms.h\"\n+#include \"mlir/Dialect/Linalg/Utils/Utils.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Types.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n+\n+namespace xla::cpu {\n+\n+#define GEN_PASS_DECL_LINALGELEMENTWISETOVECTORPASS\n+#define GEN_PASS_DEF_LINALGELEMENTWISETOVECTORPASS\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+class ElementwiseToVectorPattern\n+    : public mlir::OpInterfaceRewritePattern<mlir::linalg::LinalgOp> {\n+ public:\n+  using OpInterfaceRewritePattern::OpInterfaceRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::linalg::LinalgOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    if (!mlir::linalg::isElementwise(op)) {\n+      return rewriter.notifyMatchFailure(op, \"Op is not elementwise\");\n+    }\n+\n+    // Is this possible?\n+    if (op.getDpsInits().empty()) {\n+      return rewriter.notifyMatchFailure(op, \"op has no outputs\");\n+    }\n+\n+    auto result_type =\n+        mlir::dyn_cast<mlir::ShapedType>(op.getDpsInits().front().getType());\n+    if (!result_type) {\n+      return rewriter.notifyMatchFailure(op, \"could not convert result type\");\n+    }\n+    if (!result_type.hasStaticShape()) {\n+      return rewriter.notifyMatchFailure(op,\n+                                         \"only static shapes are supported\");\n+    }\n+\n+    // The default linalg vectorization is very naive and just replaces the\n+    // elementwise op with a transfer_read -> super_vector -> transfer_write,\n+    // but this works as a first pass.\n+    // TODO(willfroom): replace this with explicit loops on natural vector\n+    // sizes.\n+    mlir::FailureOr<mlir::linalg::VectorizationResult> result =\n+        mlir::linalg::vectorize(rewriter, op);\n+\n+    if (mlir::failed(result)) {\n+      return rewriter.notifyMatchFailure(op, \"could not vectorize\");\n+    }\n+\n+    rewriter.replaceOp(op, result->replacements);\n+    return mlir::success();\n+  }\n+};\n+\n+struct LinalgElementwiseToVectorPass\n+    : public impl::LinalgElementwiseToVectorPassBase<\n+          LinalgElementwiseToVectorPass> {\n+  void runOnOperation() override {\n+    mlir::MLIRContext* context = &getContext();\n+    mlir::RewritePatternSet patterns(context);\n+    patterns.add<ElementwiseToVectorPattern>(context);\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      signalPassFailure();\n+      return;\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateLinalgElementwiseToVectorPass() {\n+  return std::make_unique<LinalgElementwiseToVectorPass>();\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "9238e4d7875617e9bbbd1f64a0864354956a9fea",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -34,7 +34,7 @@ namespace xla::cpu {\n #define GEN_PASS_DECL\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n \n-std::unique_ptr<mlir::Pass> CreateElementalTensorToVectorPass();\n+std::unique_ptr<mlir::Pass> CreateLinalgElementwiseToVectorPass();\n std::unique_ptr<mlir::Pass> CreateLowerXTileEntryPass();\n std::unique_ptr<mlir::Pass> CreateShloToVectorPass();\n std::unique_ptr<mlir::Pass> CreateXTileToVectorPass();"
        },
        {
            "sha": "805e0162748c91f75cd7ac25caf2eb6002bb8c82",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 6,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -56,16 +56,13 @@ def ShloToVectorPass : Pass<\"xtile-cpu-shlo-to-vector\", \"mlir::ModuleOp\"> {\n   ];\n }\n \n-def ElementalTensorToVectorPass : Pass<\"xtile-cpu-elemental-tensor-to-vector\",\n+def LinalgElementwiseToVectorPass : Pass<\"xtile-cpu-linalg-elementwise-to-vector\",\n                                        \"mlir::ModuleOp\"> {\n-  let summary = \"Lowering arith & math ops with tensor types to vector types\";\n+  let summary = \"Convert elementwise linalg ops to vector ops\";\n \n-  let constructor = \"CreateElementalTensorToVectorPass()\";\n+  let constructor = \"CreateLinalgElementwiseToVectorPass()\";\n \n   let dependentDialects = [\n-    \"mlir::arith::ArithDialect\",\n-    \"mlir::math::MathDialect\",\n-    \"mlir::tensor::TensorDialect\",\n     \"mlir::vector::VectorDialect\",\n   ];\n }"
        },
        {
            "sha": "d8a7e8410cf8c9345117cf58f38ddc4a42fabb79",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/arith_to_vector.mlir",
            "status": "removed",
            "additions": 0,
            "deletions": 383,
            "changes": 383,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Farith_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Farith_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Farith_to_vector.mlir?ref=5f530aea57dcdeeb36328cf94b3b5622f3d21abe",
            "patch": "@@ -1,383 +0,0 @@\n-// RUN: fusion_compiler_opt %s --xtile-cpu-elemental-tensor-to-vector -split-input-file | FileCheck %s\n-\n-func.func @addf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.addf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %add = arith.addf %lhs, %rhs : tensor<1024xf32>\n-  return %add : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @addi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.addi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %add = arith.addi %lhs, %rhs : tensor<1024xi32>\n-  return %add : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @addiu(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> (tensor<1024xi32>, tensor<1024xi1>) {\n-  // CHECK: arith.addui_extended %{{.*}}, %{{.*}} : vector<1024xi32>, vector<1024xi1>\n-  %add, %carry = arith.addui_extended %lhs, %rhs : tensor<1024xi32>, tensor<1024xi1>\n-  return %add, %carry : tensor<1024xi32>, tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @andi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.andi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %and = arith.andi %lhs, %rhs : tensor<1024xi32>\n-  return %and : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @bitcast(%arg0 : tensor<1024xi32>) -> tensor<1024xf32> {\n-  // CHECK: arith.bitcast %{{.*}} : vector<1024xi32> to vector<1024xf32>\n-  %cast = arith.bitcast %arg0 : tensor<1024xi32> to tensor<1024xf32>\n-  return %cast : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @ceildivsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.ceildivsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %div = arith.ceildivsi %lhs, %rhs : tensor<1024xi32>\n-  return %div : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @ceildivui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.ceildivui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %div = arith.ceildivui %lhs, %rhs : tensor<1024xi32>\n-  return %div : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @cmpf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xi1> {\n-  // CHECK: arith.cmpf oeq, %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %cmp = arith.cmpf oeq, %lhs, %rhs : tensor<1024xf32>\n-  return %cmp : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @cmpi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi1> {\n-  // CHECK: arith.cmpi eq, %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %cmp = arith.cmpi eq, %lhs, %rhs : tensor<1024xi32>\n-  return %cmp : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @constant() -> tensor<1024xf32> {\n-  // CHECK: arith.constant dense<1.000000e+00> : vector<1024xf32>\n-  %const = arith.constant dense<1.0> : tensor<1024xf32>\n-  return %const : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @divf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.divf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %div = arith.divf %lhs, %rhs : tensor<1024xf32>\n-  return %div : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @divsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.divsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %div = arith.divsi %lhs, %rhs : tensor<1024xi32>\n-  return %div : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @divui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.divui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %div = arith.divui %lhs, %rhs : tensor<1024xi32>\n-  return %div : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @extf(%arg0 : tensor<1024xf32>) -> tensor<1024xf64> {\n-  // CHECK: arith.extf %{{.*}} : vector<1024xf32> to vector<1024xf64>\n-  %ext = arith.extf %arg0 : tensor<1024xf32> to tensor<1024xf64>\n-  return %ext : tensor<1024xf64>\n-}\n-\n-// -----\n-\n-func.func @extsi(%arg0 : tensor<1024xi16>) -> tensor<1024xi32> {\n-  // CHECK: arith.extsi %{{.*}} : vector<1024xi16> to vector<1024xi32>\n-  %ext = arith.extsi %arg0 : tensor<1024xi16> to tensor<1024xi32>\n-  return %ext : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @extui(%arg0 : tensor<1024xi16>) -> tensor<1024xi32> {\n-  // CHECK: arith.extui %{{.*}} : vector<1024xi16> to vector<1024xi32>\n-  %ext = arith.extui %arg0 : tensor<1024xi16> to tensor<1024xi32>\n-  return %ext : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @fptosi(%arg0 : tensor<1024xf32>) -> tensor<1024xi32> {\n-  // CHECK: arith.fptosi %{{.*}} : vector<1024xf32> to vector<1024xi32>\n-  %cast = arith.fptosi %arg0 : tensor<1024xf32> to tensor<1024xi32>\n-  return %cast : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @fptoui(%arg0 : tensor<1024xf32>) -> tensor<1024xi32> {\n-  // CHECK: arith.fptoui %{{.*}} : vector<1024xf32> to vector<1024xi32>\n-  %cast = arith.fptoui %arg0 : tensor<1024xf32> to tensor<1024xi32>\n-  return %cast : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @floordivsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.floordivsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %div = arith.floordivsi %lhs, %rhs : tensor<1024xi32>\n-  return %div : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @index_cast(%arg0 : tensor<1024xi32>) -> tensor<1024xindex> {\n-  // CHECK: arith.index_cast %{{.*}} : vector<1024xi32> to vector<1024xindex>\n-  %cast = arith.index_cast %arg0 : tensor<1024xi32> to tensor<1024xindex>\n-  return %cast : tensor<1024xindex>\n-}\n-\n-// -----\n-\n-func.func @index_castui(%arg0 : tensor<1024xi32>) -> tensor<1024xindex> {\n-  // CHECK: arith.index_castui %{{.*}} : vector<1024xi32> to vector<1024xindex>\n-  %cast = arith.index_castui %arg0 : tensor<1024xi32> to tensor<1024xindex>\n-  return %cast : tensor<1024xindex>\n-}\n-\n-// -----\n-\n-func.func @maxnumf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.maxnumf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %max = arith.maxnumf %lhs, %rhs : tensor<1024xf32>\n-  return %max : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @maxsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.maxsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %max = arith.maxsi %lhs, %rhs : tensor<1024xi32>\n-  return %max : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @maxui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.maxui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %max = arith.maxui %lhs, %rhs : tensor<1024xi32>\n-  return %max : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @maximumf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.maximumf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %max = arith.maximumf %lhs, %rhs : tensor<1024xf32>\n-  return %max : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @minnumf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.minnumf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %min = arith.minnumf %lhs, %rhs : tensor<1024xf32>\n-  return %min : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @minsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.minsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %min = arith.minsi %lhs, %rhs : tensor<1024xi32>\n-  return %min : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @minui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.minui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %min = arith.minui %lhs, %rhs : tensor<1024xi32>\n-  return %min : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @minimumf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.minimumf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %min = arith.minimumf %lhs, %rhs : tensor<1024xf32>\n-  return %min : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @mulf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.mulf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %mul = arith.mulf %lhs, %rhs : tensor<1024xf32>\n-  return %mul : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @muli(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.muli %{{.*}}, %{{.*}} overflow<nsw, nuw> : vector<1024xi32>\n-  %mul = arith.muli %lhs, %rhs overflow<nsw, nuw> : tensor<1024xi32>\n-  return %mul : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @mului_ext(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> (tensor<1024xi32>, tensor<1024xi32>) {\n-  // CHECK: arith.mulsi_extended %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %low, %high = arith.mulsi_extended %lhs, %rhs : tensor<1024xi32>\n-  return %low, %high : tensor<1024xi32>, tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @negf(%arg0 : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.negf %{{.*}} : vector<1024xf32>\n-  %neg = arith.negf %arg0 : tensor<1024xf32>\n-  return %neg : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @ori(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.ori %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %or = arith.ori %lhs, %rhs : tensor<1024xi32>\n-  return %or : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @remf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.remf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %rem = arith.remf %lhs, %rhs : tensor<1024xf32>\n-  return %rem : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @remsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.remsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %rem = arith.remsi %lhs, %rhs : tensor<1024xi32>\n-  return %rem : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @remui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.remui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %rem = arith.remui %lhs, %rhs : tensor<1024xi32>\n-  return %rem : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @sitofp(%arg0 : tensor<1024xi32>) -> tensor<1024xf32> {\n-  // CHECK: arith.sitofp %{{.*}} : vector<1024xi32> to vector<1024xf32>\n-  %cast = arith.sitofp %arg0 : tensor<1024xi32> to tensor<1024xf32>\n-  return %cast : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @select(%cond : tensor<1024xi1>, %true_val : tensor<1024xf32>, %false_val : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.select %{{.*}}, %{{.*}}, %{{.*}} : vector<1024xi1>, vector<1024xf32>\n-  %sel = arith.select %cond, %true_val, %false_val : tensor<1024xi1>, tensor<1024xf32>\n-  return %sel : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @shli(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.shli %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %shl = arith.shli %lhs, %rhs : tensor<1024xi32>\n-  return %shl : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @shrsi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.shrsi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %shr = arith.shrsi %lhs, %rhs : tensor<1024xi32>\n-  return %shr : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @shrui(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.shrui %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %shr = arith.shrui %lhs, %rhs : tensor<1024xi32>\n-  return %shr : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @subf(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: arith.subf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %sub = arith.subf %lhs, %rhs : tensor<1024xf32>\n-  return %sub : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @subi(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.subi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %sub = arith.subi %lhs, %rhs : tensor<1024xi32>\n-  return %sub : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @truncf(%arg0 : tensor<1024xf64>) -> tensor<1024xf32> {\n-  // CHECK: arith.truncf %{{.*}} : vector<1024xf64> to vector<1024xf32>\n-  %trunc = arith.truncf %arg0 : tensor<1024xf64> to tensor<1024xf32>\n-  return %trunc : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @trunci(%arg0 : tensor<1024xi32>) -> tensor<1024xi16> {\n-  // CHECK: arith.trunci %{{.*}} : vector<1024xi32> to vector<1024xi16>\n-  %trunc = arith.trunci %arg0 : tensor<1024xi32> to tensor<1024xi16>\n-  return %trunc : tensor<1024xi16>\n-}\n-\n-// -----\n-\n-func.func @uitofp(%arg0 : tensor<1024xi32>) -> tensor<1024xf32> {\n-  // CHECK: arith.uitofp %{{.*}} : vector<1024xi32> to vector<1024xf32>\n-  %cast = arith.uitofp %arg0 : tensor<1024xi32> to tensor<1024xf32>\n-  return %cast : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @xori(%lhs : tensor<1024xi32>, %rhs : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: arith.xori %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %xor = arith.xori %lhs, %rhs : tensor<1024xi32>\n-  return %xor : tensor<1024xi32>\n-}\n\\ No newline at end of file"
        },
        {
            "sha": "d1ec75fd8a426a90473df5a041f18873004a1233",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/linalg_elementwise_to_vector_pass.mlir",
            "status": "added",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Flinalg_elementwise_to_vector_pass.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e6d6b2de71904170972d2c9dace94bacf8b51b56/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Flinalg_elementwise_to_vector_pass.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Flinalg_elementwise_to_vector_pass.mlir?ref=e6d6b2de71904170972d2c9dace94bacf8b51b56",
            "patch": "@@ -0,0 +1,16 @@\n+// RUN: fusion_compiler_opt %s -xtile-cpu-linalg-elementwise-to-vector -split-input-file | FileCheck %s\n+\n+func.func @elementwise_add_to_vector(\n+    %lhs : memref<8x1024xf32>,\n+    %rhs : memref<8x1024xf32>,\n+    %out : memref<8x1024xf32>) {\n+  // CHECK: %1 = vector.transfer_read %arg0\n+  // CHECK: %2 = vector.transfer_read %arg1\n+  // CHECK: %3 = arith.addf {{.*}} : vector<8x1024xf32>\n+  // CHECK: vector.transfer_write %{{.*}}, %arg2{{.*}} :\n+  // CHECK-SAME: vector<8x1024xf32>, memref<8x1024xf32>\n+  linalg.elementwise kind=#linalg.elementwise_kind<add>\n+    ins(%lhs, %rhs : memref<8x1024xf32>, memref<8x1024xf32>)\n+    outs(%out : memref<8x1024xf32>)\n+  return\n+}"
        },
        {
            "sha": "d85d978ab6643977517a1bc6143c72cbe5a86dff",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/math_to_vector.mlir",
            "status": "removed",
            "additions": 0,
            "deletions": 367,
            "changes": 367,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmath_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5f530aea57dcdeeb36328cf94b3b5622f3d21abe/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmath_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fmath_to_vector.mlir?ref=5f530aea57dcdeeb36328cf94b3b5622f3d21abe",
            "patch": "@@ -1,367 +0,0 @@\n-// RUN: fusion_compiler_opt %s --xtile-cpu-elemental-tensor-to-vector -split-input-file | FileCheck %s\n-\n-func.func @absf(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.absf %{{.*}} : vector<1024xf32>\n-  %abs = math.absf %input : tensor<1024xf32>\n-  return %abs : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @absi(%input : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: math.absi %{{.*}} : vector<1024xi32>\n-  %abs = math.absi %input : tensor<1024xi32>\n-  return %abs : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @acos(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.acos %{{.*}} : vector<1024xf32>\n-  %res = math.acos %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @acosh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.acosh %{{.*}} : vector<1024xf32>\n-  %res = math.acosh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @asin(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.asin %{{.*}} : vector<1024xf32>\n-  %res = math.asin %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @asinh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.asinh %{{.*}} : vector<1024xf32>\n-  %res = math.asinh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @atan2(%input1 : tensor<1024xf32>, %input2 : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.atan2 %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %res = math.atan2 %input1, %input2 : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @atan(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.atan %{{.*}} : vector<1024xf32>\n-  %res = math.atan %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @atanh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.atanh %{{.*}} : vector<1024xf32>\n-  %res = math.atanh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @cbrt(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.cbrt %{{.*}} : vector<1024xf32>\n-  %res = math.cbrt %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @ceil(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.ceil %{{.*}} : vector<1024xf32>\n-  %res = math.ceil %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @clampf(%input : tensor<1024xf32>, %low : tensor<1024xf32>, %high : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.clampf %{{.*}} to [%{{.*}}, %{{.*}}] : vector<1024xf32>\n-  %res = math.clampf %input to [%low, %high] : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @copysign(%mag : tensor<1024xf32>, %sign : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.copysign %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %res = math.copysign %mag, %sign : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @cos(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.cos %{{.*}} : vector<1024xf32>\n-  %res = math.cos %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @cosh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.cosh %{{.*}} : vector<1024xf32>\n-  %res = math.cosh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @ctlz(%input : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: math.ctlz %{{.*}} : vector<1024xi32>\n-  %res = math.ctlz %input : tensor<1024xi32>\n-  return %res : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @cttz(%input : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: math.cttz %{{.*}} : vector<1024xi32>\n-  %res = math.cttz %input : tensor<1024xi32>\n-  return %res : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @ctpop(%input : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: math.ctpop %{{.*}} : vector<1024xi32>\n-  %res = math.ctpop %input : tensor<1024xi32>\n-  return %res : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @erf(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.erf %{{.*}} : vector<1024xf32>\n-  %res = math.erf %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @erfc(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.erfc %{{.*}} : vector<1024xf32>\n-  %res = math.erfc %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @exp2(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.exp2 %{{.*}} : vector<1024xf32>\n-  %res = math.exp2 %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @expm1(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.expm1 %{{.*}} : vector<1024xf32>\n-  %res = math.expm1 %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @exp(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.exp %{{.*}} : vector<1024xf32>\n-  %res = math.exp %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @fpowi(%base : tensor<1024xf32>, %exp : tensor<1024xi32>) -> tensor<1024xf32> {\n-  // CHECK: math.fpowi %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %res = math.fpowi %base, %exp : tensor<1024xf32>, tensor<1024xi32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @floor(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.floor %{{.*}} : vector<1024xf32>\n-  %res = math.floor %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @fma(%a : tensor<1024xf32>, %b : tensor<1024xf32>, %c : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.fma %{{.*}}, %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %res = math.fma %a, %b, %c : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @ipowi(%base : tensor<1024xi32>, %exp : tensor<1024xi32>) -> tensor<1024xi32> {\n-  // CHECK: math.ipowi %{{.*}}, %{{.*}} : vector<1024xi32>\n-  %res = math.ipowi %base, %exp : tensor<1024xi32>\n-  return %res : tensor<1024xi32>\n-}\n-\n-// -----\n-\n-func.func @isfinite(%input : tensor<1024xf32>) -> tensor<1024xi1> {\n-  // CHECK: math.isfinite %{{.*}} : vector<1024xf32>\n-  %res = math.isfinite %input : tensor<1024xf32>\n-  return %res : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @isinf(%input : tensor<1024xf32>) -> tensor<1024xi1> {\n-  // CHECK: math.isinf %{{.*}} : vector<1024xf32>\n-  %res = math.isinf %input : tensor<1024xf32>\n-  return %res : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @isnan(%input : tensor<1024xf32>) -> tensor<1024xi1> {\n-  // CHECK: math.isnan %{{.*}} : vector<1024xf32>\n-  %res = math.isnan %input : tensor<1024xf32>\n-  return %res : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @isnormal(%input : tensor<1024xf32>) -> tensor<1024xi1> {\n-  // CHECK: math.isnormal %{{.*}} : vector<1024xf32>\n-  %res = math.isnormal %input : tensor<1024xf32>\n-  return %res : tensor<1024xi1>\n-}\n-\n-// -----\n-\n-func.func @log10(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.log10 %{{.*}} : vector<1024xf32>\n-  %res = math.log10 %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @log1p(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.log1p %{{.*}} : vector<1024xf32>\n-  %res = math.log1p %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @log2(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.log2 %{{.*}} : vector<1024xf32>\n-  %res = math.log2 %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @log(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.log %{{.*}} : vector<1024xf32>\n-  %res = math.log %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @powf(%base : tensor<1024xf32>, %exp : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.powf %{{.*}}, %{{.*}} : vector<1024xf32>\n-  %res = math.powf %base, %exp : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @roundeven(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.roundeven %{{.*}} : vector<1024xf32>\n-  %res = math.roundeven %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @round(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.round %{{.*}} : vector<1024xf32>\n-  %res = math.round %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @rsqrt(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.rsqrt %{{.*}} : vector<1024xf32>\n-  %res = math.rsqrt %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @sin(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.sin %{{.*}} : vector<1024xf32>\n-  %res = math.sin %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @sincos(%input : tensor<1024xf32>) -> (tensor<1024xf32>, tensor<1024xf32>) {\n-  // CHECK: math.sincos %{{.*}} : vector<1024xf32>\n-  %sin, %cos = math.sincos %input : tensor<1024xf32>\n-  return %sin, %cos : tensor<1024xf32>, tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @sinh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.sinh %{{.*}} : vector<1024xf32>\n-  %res = math.sinh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @sqrt(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.sqrt %{{.*}} : vector<1024xf32>\n-  %res = math.sqrt %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @tan(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.tan %{{.*}} : vector<1024xf32>\n-  %res = math.tan %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @tanh(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.tanh %{{.*}} : vector<1024xf32>\n-  %res = math.tanh %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n-\n-// -----\n-\n-func.func @trunc(%input : tensor<1024xf32>) -> tensor<1024xf32> {\n-  // CHECK: math.trunc %{{.*}} : vector<1024xf32>\n-  %res = math.trunc %input : tensor<1024xf32>\n-  return %res : tensor<1024xf32>\n-}\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 1102,
        "additions": 142,
        "deletions": 960
    }
}