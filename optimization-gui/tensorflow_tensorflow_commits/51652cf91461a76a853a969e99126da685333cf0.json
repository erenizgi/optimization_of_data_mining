{
    "author": "beckerhe",
    "message": "Add serialization support for CuBlasLtMatmulThunk\n\nThis is adding functions ToProto and FromProto to GpuBlasLtMatmulThunk as well as to all helper data structures.\n\nIt also wires up the thunk type in the common thunk proto deserialization function.\n\nPiperOrigin-RevId: 814094654",
    "sha": "51652cf91461a76a853a969e99126da685333cf0",
    "files": [
        {
            "sha": "99b268963e5b2e287b8eeef4e499cb7f34d7b1cf",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -741,6 +741,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/types:span\",\n     ],\n )\n \n@@ -776,12 +777,14 @@ xla_test(\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/time\",\n         \"@com_google_googletest//:gtest_main\",\n+        \"@com_google_protobuf//:protobuf\",\n     ],\n )\n \n@@ -2235,6 +2238,7 @@ cc_library(\n         \":copy_thunk\",\n         \":cudnn_thunk\",\n         \":gemm_thunk\",\n+        \":gpublas_lt_matmul_thunk\",\n         \":infeed_thunk\",\n         \":kernel_thunk\",\n         \":memset_thunk\","
        },
        {
            "sha": "a81eb8fc1f91a54bce949d90ddd06ad2f5064a52",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.cc",
            "status": "modified",
            "additions": 122,
            "deletions": 1,
            "changes": 123,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -16,15 +16,16 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h\"\n \n #include <cstdint>\n+#include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n \n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -159,5 +160,125 @@ absl::Status CublasLtMatmulThunk::Initialize(const InitializeParams& params) {\n   return absl::OkStatus();\n }\n \n+absl::StatusOr<ThunkProto> CublasLtMatmulThunk::ToProto() const {\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  CublasLtMatmulThunkProto* cublas_lt_matmul_thunk =\n+      proto.mutable_cublas_lt_matmul_thunk();\n+  *cublas_lt_matmul_thunk->mutable_gemm_config() = gemm_config_.ToProto();\n+  cublas_lt_matmul_thunk->set_epilogue(\n+      stream_executor::gpu::BlasLt::EpilogueToProto(epilogue_));\n+  cublas_lt_matmul_thunk->set_algorithm_idx(algorithm_idx_);\n+  cublas_lt_matmul_thunk->set_canonical_hlo(canonical_hlo_);\n+  TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_a(), a_.ToProto());\n+  TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_b(), b_.ToProto());\n+  TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_c(), c_.ToProto());\n+  TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_d(), d_.ToProto());\n+  if (bias_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_bias(),\n+                        bias_.ToProto());\n+  }\n+  if (aux_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_aux(), aux_.ToProto());\n+  }\n+  if (a_scale_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_a_scale(),\n+                        a_scale_.ToProto());\n+  }\n+  if (b_scale_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_b_scale(),\n+                        b_scale_.ToProto());\n+  }\n+  if (c_scale_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_c_scale(),\n+                        c_scale_.ToProto());\n+  }\n+  if (d_scale_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_d_scale(),\n+                        d_scale_.ToProto());\n+  }\n+  if (d_amax_.allocation() != nullptr) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_d_amax(),\n+                        d_amax_.ToProto());\n+  }\n+  if (workspace_.has_value()) {\n+    TF_ASSIGN_OR_RETURN(*cublas_lt_matmul_thunk->mutable_workspace(),\n+                        workspace_->ToProto());\n+  }\n+  return proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<Thunk>> CublasLtMatmulThunk::FromProto(\n+    Thunk::ThunkInfo thunk_info, const CublasLtMatmulThunkProto& proto,\n+    absl::Span<const BufferAllocation> allocations) {\n+  TF_ASSIGN_OR_RETURN(\n+      stream_executor::gpu::GemmConfig gemm_config,\n+      stream_executor::gpu::GemmConfig::FromProto(proto.gemm_config()));\n+  TF_ASSIGN_OR_RETURN(\n+      stream_executor::gpu::BlasLt::Epilogue epilogue,\n+      stream_executor::gpu::BlasLt::EpilogueFromProto(proto.epilogue()));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice a,\n+      BufferAllocation::Slice::FromProto(proto.a(), allocations));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice b,\n+      BufferAllocation::Slice::FromProto(proto.b(), allocations));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice c,\n+      BufferAllocation::Slice::FromProto(proto.c(), allocations));\n+  TF_ASSIGN_OR_RETURN(\n+      BufferAllocation::Slice d,\n+      BufferAllocation::Slice::FromProto(proto.d(), allocations));\n+\n+  BufferAllocation::Slice bias;\n+  if (proto.has_bias()) {\n+    TF_ASSIGN_OR_RETURN(\n+        bias, BufferAllocation::Slice::FromProto(proto.bias(), allocations));\n+  }\n+  BufferAllocation::Slice aux;\n+  if (proto.has_aux()) {\n+    TF_ASSIGN_OR_RETURN(\n+        aux, BufferAllocation::Slice::FromProto(proto.aux(), allocations));\n+  }\n+  BufferAllocation::Slice a_scale;\n+  if (proto.has_a_scale()) {\n+    TF_ASSIGN_OR_RETURN(a_scale, BufferAllocation::Slice::FromProto(\n+                                     proto.a_scale(), allocations));\n+  }\n+  BufferAllocation::Slice b_scale;\n+  if (proto.has_b_scale()) {\n+    TF_ASSIGN_OR_RETURN(b_scale, BufferAllocation::Slice::FromProto(\n+                                     proto.b_scale(), allocations));\n+  }\n+  BufferAllocation::Slice c_scale;\n+  if (proto.has_c_scale()) {\n+    TF_ASSIGN_OR_RETURN(c_scale, BufferAllocation::Slice::FromProto(\n+                                     proto.c_scale(), allocations));\n+  }\n+  BufferAllocation::Slice d_scale;\n+  if (proto.has_d_scale()) {\n+    TF_ASSIGN_OR_RETURN(d_scale, BufferAllocation::Slice::FromProto(\n+                                     proto.d_scale(), allocations));\n+  }\n+  BufferAllocation::Slice d_amax;\n+  if (proto.has_d_amax()) {\n+    TF_ASSIGN_OR_RETURN(d_amax, BufferAllocation::Slice::FromProto(\n+                                    proto.d_amax(), allocations));\n+  }\n+  std::optional<BufferAllocation::Slice> workspace;\n+  if (proto.has_workspace()) {\n+    TF_ASSIGN_OR_RETURN(workspace, BufferAllocation::Slice::FromProto(\n+                                       proto.workspace(), allocations));\n+  }\n+  return std::make_unique<CublasLtMatmulThunk>(\n+      std::move(thunk_info), std::move(proto.canonical_hlo()),\n+      xla::gpu::GemmConfig(std::move(gemm_config)), std::move(epilogue),\n+      proto.algorithm_idx(), std::move(a), std::move(b), std::move(c),\n+      std::move(d), std::move(bias), std::move(aux), std::move(a_scale),\n+      std::move(b_scale), std::move(c_scale), std::move(d_scale),\n+      std::move(d_amax), std::move(workspace));\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "ff47b9e600e414166ff6adb0821c25e7c4a32b89",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -17,11 +17,13 @@ limitations under the License.\n #define XLA_BACKENDS_GPU_RUNTIME_GPUBLAS_LT_MATMUL_THUNK_H_\n \n #include <cstdint>\n+#include <memory>\n #include <optional>\n #include <string>\n \n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -55,6 +57,11 @@ class CublasLtMatmulThunk : public Thunk {\n     return workspace_;\n   }\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+  static absl::StatusOr<std::unique_ptr<Thunk>> FromProto(\n+      Thunk::ThunkInfo thunk_info, const CublasLtMatmulThunkProto& proto,\n+      absl::Span<const BufferAllocation> allocations);\n+\n  protected:\n   CublasLtMatmulThunk(const CublasLtMatmulThunk& rhs);\n "
        },
        {
            "sha": "830a8b2647cb3e073ffd4daf30bf7f80fa91111a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk_test.cc",
            "status": "modified",
            "additions": 79,
            "deletions": 0,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -25,13 +25,15 @@ limitations under the License.\n #include <variant>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/time/clock.h\"\n #include \"absl/time/time.h\"\n+#include \"google/protobuf/text_format.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/error_spec.h\"\n@@ -59,11 +61,14 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n #include \"xla/xla.pb.h\"\n \n namespace xla::gpu {\n \n namespace {\n+using absl_testing::IsOkAndHolds;\n+using tsl::proto_testing::EqualsProto;\n \n class GpuBlasLtMatmulThunkTest : public HloTestBase {\n  public:\n@@ -378,5 +383,79 @@ TEST_F(GpuBlasLtMatmulThunkTest, CacheUnitTest) {\n   EXPECT_TRUE(size.has_value() && static_cast<int>(*size <= mod));\n }\n \n+TEST_F(GpuBlasLtMatmulThunkTest, ThunkProtoSerialization) {\n+  constexpr absl::string_view kCublasLtMatmulThunkProtoText = R\"pb(\n+    gemm_config {\n+      lhs_layout {\n+        order: ORDER_ROW_MAJOR\n+        num_rows: 101\n+        num_cols: 407\n+        batch_size: 1\n+        leading_dim_stride: 407\n+        dtype: F32\n+      }\n+      rhs_layout {\n+        order: ORDER_ROW_MAJOR\n+        num_rows: 407\n+        num_cols: 400\n+        batch_size: 1\n+        leading_dim_stride: 400\n+        dtype: F32\n+      }\n+      c_layout {\n+        order: ORDER_ROW_MAJOR\n+        num_rows: 101\n+        num_cols: 400\n+        batch_size: 1\n+        leading_dim_stride: 400\n+        dtype: F32\n+      }\n+      output_layout {\n+        order: ORDER_ROW_MAJOR\n+        num_rows: 101\n+        num_cols: 400\n+        batch_size: 1\n+        leading_dim_stride: 400\n+        dtype: F32\n+      }\n+      alpha_real: 1\n+      algorithm: -1\n+    }\n+    epilogue: EPILOGUE_DEFAULT\n+    canonical_hlo: \"(f32[101,400]{1,0}, s8[33554432]{0}) custom-call(f32[101,407]{1,0}, f32[407,400]{1,0}), custom_call_target=\\\"__cublas$lt$matmul\\\", backend_config={\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[],\\\"gemm_backend_config\\\":{\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"],\\\"lhs_batch_dimensions\\\":[],\\\"rhs_batch_dimensions\\\":[]},\\\"alpha_imag\\\":0,\\\"precision_config\\\":{\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"],\\\"algorithm\\\":\\\"ALG_UNSET\\\"},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"lhs_stride\\\":\\\"41107\\\",\\\"rhs_stride\\\":\\\"162800\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"damax_output\\\":false},\\\"force_earliest_schedule\\\":false,\\\"reification_cost\\\":[]}\"\n+    a { size: 164428 buffer_allocation_index: 3 }\n+    b { size: 651200 buffer_allocation_index: 4 }\n+    c { size: 161600 buffer_allocation_index: 5 }\n+    d { size: 161600 buffer_allocation_index: 5 }\n+  )pb\";\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = \"test\";\n+  thunk_info.execution_stream_id = 0;\n+\n+  CublasLtMatmulThunkProto proto;\n+  ASSERT_TRUE(google::protobuf::TextFormat::ParseFromString(kCublasLtMatmulThunkProtoText,\n+                                                  &proto));\n+\n+  std::vector<BufferAllocation> allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/1, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/2, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/3, /*size=*/164428, /*color=*/0),\n+      BufferAllocation(/*index=*/4, /*size=*/651200, /*color=*/0),\n+      BufferAllocation(/*index=*/5, /*size=*/161600, /*color=*/0),\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Thunk> thunk,\n+      CublasLtMatmulThunk::FromProto(thunk_info, proto, allocations));\n+\n+  ThunkProto reference_thunk_proto;\n+  *reference_thunk_proto.mutable_thunk_info() = thunk_info.ToProto();\n+  *reference_thunk_proto.mutable_cublas_lt_matmul_thunk() = proto;\n+  EXPECT_THAT(thunk->ToProto(),\n+              IsOkAndHolds(EqualsProto(reference_thunk_proto)));\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "57f3afa120d208bf7a14c2de595ebf615e2d86f2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -147,6 +147,25 @@ message SelectKThunkProto {\n   // TODO(upwind): Add fields for SelectKThunkProto.\n }\n \n+message CublasLtMatmulThunkProto {\n+  xla.GemmConfigProto gemm_config = 1;\n+  xla.BlasLtEpilogueProto epilogue = 2;\n+  int64 algorithm_idx = 3;\n+  string canonical_hlo = 4;\n+  xla.buffer_assignment.BufferAllocationSliceProto a = 5;\n+  xla.buffer_assignment.BufferAllocationSliceProto b = 6;\n+  xla.buffer_assignment.BufferAllocationSliceProto c = 7;\n+  xla.buffer_assignment.BufferAllocationSliceProto d = 8;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto bias = 9;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto aux = 10;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto a_scale = 11;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto b_scale = 12;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto c_scale = 13;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto d_scale = 14;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto d_amax = 15;\n+  optional xla.buffer_assignment.BufferAllocationSliceProto workspace = 16;\n+}\n+\n message ThunkProto {\n   ThunkInfoProto thunk_info = 1;\n \n@@ -171,6 +190,7 @@ message ThunkProto {\n     MemzeroThunkProto memzero_thunk = 19;\n     SelectKThunkProto select_k_thunk = 20;\n     InfeedThunkProto infeed_thunk = 21;\n+    CublasLtMatmulThunkProto cublas_lt_matmul_thunk = 22;\n   }\n }\n "
        },
        {
            "sha": "550c7790eed7862191d0c146076ec0a92b2b8f1c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/cudnn_thunk.h\"\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n+#include \"xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h\"\n #include \"xla/backends/gpu/runtime/infeed_thunk.h\"\n #include \"xla/backends/gpu/runtime/kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/memset_thunk.h\"\n@@ -151,6 +152,12 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n         std::move(thunk_info), thunk_proto.infeed_thunk(), buffer_allocations);\n   }\n \n+  if (thunk_proto.has_cublas_lt_matmul_thunk()) {\n+    return CublasLtMatmulThunk::FromProto(std::move(thunk_info),\n+                                          thunk_proto.cublas_lt_matmul_thunk(),\n+                                          buffer_allocations);\n+  }\n+\n   std::optional<absl::string_view> unsupported_thunk_type =\n       GetStoredThunkTypeName(thunk_proto);\n "
        },
        {
            "sha": "8da57e53483d5716bc24fad3aa76ad7d38204805",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization_test.cc",
            "status": "modified",
            "additions": 67,
            "deletions": 0,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -414,6 +414,73 @@ TEST(ThunkProtoDeserializationTest, CudnnThunk) {\n   EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n }\n \n+TEST(ThunkProtoDeserializationTest, CublasLtMatmulThunk) {\n+  ThunkProto proto;\n+  ASSERT_TRUE(tsl::protobuf::TextFormat::ParseFromString(\n+      R\"pb(\n+        thunk_info { profile_annotation: \"custom-call.4\" }\n+        cublas_lt_matmul_thunk {\n+          gemm_config {\n+            lhs_layout {\n+              order: ORDER_ROW_MAJOR\n+              num_rows: 101\n+              num_cols: 407\n+              batch_size: 1\n+              leading_dim_stride: 407\n+              dtype: F32\n+            }\n+            rhs_layout {\n+              order: ORDER_ROW_MAJOR\n+              num_rows: 407\n+              num_cols: 400\n+              batch_size: 1\n+              leading_dim_stride: 400\n+              dtype: F32\n+            }\n+            c_layout {\n+              order: ORDER_ROW_MAJOR\n+              num_rows: 101\n+              num_cols: 400\n+              batch_size: 1\n+              leading_dim_stride: 400\n+              dtype: F32\n+            }\n+            output_layout {\n+              order: ORDER_ROW_MAJOR\n+              num_rows: 101\n+              num_cols: 400\n+              batch_size: 1\n+              leading_dim_stride: 400\n+              dtype: F32\n+            }\n+            alpha_real: 1\n+            algorithm: -1\n+          }\n+          epilogue: EPILOGUE_DEFAULT\n+          canonical_hlo: \"(f32[101,400]{1,0}, s8[33554432]{0}) custom-call(f32[101,407]{1,0}, f32[407,400]{1,0}), custom_call_target=\\\"__cublas$lt$matmul\\\", backend_config={\\\"operation_queue_id\\\":\\\"0\\\",\\\"wait_on_operation_queues\\\":[],\\\"gemm_backend_config\\\":{\\\"alpha_real\\\":1,\\\"beta\\\":0,\\\"dot_dimension_numbers\\\":{\\\"lhs_contracting_dimensions\\\":[\\\"1\\\"],\\\"rhs_contracting_dimensions\\\":[\\\"0\\\"],\\\"lhs_batch_dimensions\\\":[],\\\"rhs_batch_dimensions\\\":[]},\\\"alpha_imag\\\":0,\\\"precision_config\\\":{\\\"operand_precision\\\":[\\\"DEFAULT\\\",\\\"DEFAULT\\\"],\\\"algorithm\\\":\\\"ALG_UNSET\\\"},\\\"epilogue\\\":\\\"DEFAULT\\\",\\\"lhs_stride\\\":\\\"41107\\\",\\\"rhs_stride\\\":\\\"162800\\\",\\\"grad_x\\\":false,\\\"grad_y\\\":false,\\\"damax_output\\\":false},\\\"force_earliest_schedule\\\":false,\\\"reification_cost\\\":[]}\"\n+          a { size: 164428 buffer_allocation_index: 3 }\n+          b { size: 651200 buffer_allocation_index: 4 }\n+          c { size: 161600 buffer_allocation_index: 5 }\n+          d { size: 161600 buffer_allocation_index: 5 }\n+        }\n+      )pb\",\n+      &proto));\n+\n+  std::vector<BufferAllocation> allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/1, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/2, /*size=*/4, /*color=*/0),  // UNUSED\n+      BufferAllocation(/*index=*/3, /*size=*/164428, /*color=*/0),\n+      BufferAllocation(/*index=*/4, /*size=*/651200, /*color=*/0),\n+      BufferAllocation(/*index=*/5, /*size=*/161600, /*color=*/0),\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Thunk> thunk,\n+                          DeserializeThunkProto(proto, allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n TEST(ThunkProtoDeserializationTest, EmptyThunkImplReturnsAnError) {\n   ThunkProto proto;\n   CHECK(tsl::protobuf::TextFormat::ParseFromString("
        },
        {
            "sha": "a6a9f5859fcb09a701e0e029306ffc2a67a04576",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -487,9 +487,14 @@ xla_cc_test(\n         \":gpu_blas_lt_proto_cc\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/stream_executor:blas\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_googletest//:gtest_main\",\n+        \"@com_google_protobuf//:protobuf\",\n     ],\n )\n "
        },
        {
            "sha": "2df49a47abe288b86e573c5f78d8ceadf121a834",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.cc",
            "status": "modified",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -359,5 +359,66 @@ xla::GemmConfigProto GemmConfig::ToProto() const {\n   return proto;\n }\n \n+absl::StatusOr<BlasLt::Epilogue> BlasLt::EpilogueFromProto(\n+    const xla::BlasLtEpilogueProto& proto) {\n+  switch (proto) {\n+    case xla::BlasLtEpilogueProto::EPILOGUE_DEFAULT:\n+      return Epilogue::kDefault;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_RELU:\n+      return Epilogue::kReLU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS:\n+      return Epilogue::kBias;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_RELU:\n+      return Epilogue::kBiasThenReLU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_GELU:\n+      return Epilogue::kGELU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_SILU:\n+      return Epilogue::kSILU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_SILU_WITH_AUX:\n+      return Epilogue::kSILUWithAux;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_GELU_WITH_AUX:\n+      return Epilogue::kGELUWithAux;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU:\n+      return Epilogue::kBiasThenGELU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU:\n+      return Epilogue::kBiasThenSILU;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU_WITH_AUX:\n+      return Epilogue::kBiasThenGELUWithAux;\n+    case xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU_WITH_AUX:\n+      return Epilogue::kBiasThenSILUWithAux;\n+    default:\n+      return absl::InvalidArgumentError(\"Unsupported epilogue type\");\n+  }\n+}\n+\n+xla::BlasLtEpilogueProto BlasLt::EpilogueToProto(Epilogue epilogue) {\n+  switch (epilogue) {\n+    case Epilogue::kDefault:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_DEFAULT;\n+    case Epilogue::kReLU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_RELU;\n+    case Epilogue::kBias:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS;\n+    case Epilogue::kBiasThenReLU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_RELU;\n+    case Epilogue::kGELU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_GELU;\n+    case Epilogue::kSILU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_SILU;\n+    case Epilogue::kSILUWithAux:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_SILU_WITH_AUX;\n+    case Epilogue::kGELUWithAux:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_GELU_WITH_AUX;\n+    case Epilogue::kBiasThenGELU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU;\n+    case Epilogue::kBiasThenSILU:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU;\n+    case Epilogue::kBiasThenGELUWithAux:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU_WITH_AUX;\n+    case Epilogue::kBiasThenSILUWithAux:\n+      return xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU_WITH_AUX;\n+  }\n+}\n+\n }  // namespace gpu\n }  // namespace stream_executor"
        },
        {
            "sha": "03df028088e7314acdc764b3958cb13b49c764cb",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.h?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -152,6 +152,10 @@ struct BlasLt {\n     kBiasThenSILUWithAux = kBiasThenSILU | 1024,\n   };\n \n+  static absl::StatusOr<Epilogue> EpilogueFromProto(\n+      const xla::BlasLtEpilogueProto& proto);\n+  static xla::BlasLtEpilogueProto EpilogueToProto(Epilogue epilogue);\n+\n   // Describes the location of pointers for the scaling factors alpha and beta.\n   enum class PointerMode {\n     kHost,"
        },
        {
            "sha": "17f1e6f105e132f846d67c88fabebc3bb337096f",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt.proto",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt.proto?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -51,3 +51,18 @@ message GemmConfigProto {\n   bool grad_y = 12;\n   xla.BlasComputationTypeProto compute_type = 13;\n }\n+\n+enum BlasLtEpilogueProto {\n+  EPILOGUE_DEFAULT = 0;\n+  EPILOGUE_RELU = 1;\n+  EPILOGUE_BIAS = 2;\n+  EPILOGUE_BIAS_THEN_RELU = 3;\n+  EPILOGUE_GELU = 4;\n+  EPILOGUE_SILU = 5;\n+  EPILOGUE_SILU_WITH_AUX = 6;\n+  EPILOGUE_GELU_WITH_AUX = 7;\n+  EPILOGUE_BIAS_THEN_GELU = 8;\n+  EPILOGUE_BIAS_THEN_SILU = 9;\n+  EPILOGUE_BIAS_THEN_GELU_WITH_AUX = 10;\n+  EPILOGUE_BIAS_THEN_SILU_WITH_AUX = 11;\n+}"
        },
        {
            "sha": "f128497a2cedeeab53973a9866e6a4289c584d4b",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_blas_lt_test.cc",
            "status": "modified",
            "additions": 80,
            "deletions": 0,
            "changes": 80,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/51652cf91461a76a853a969e99126da685333cf0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_blas_lt_test.cc?ref=51652cf91461a76a853a969e99126da685333cf0",
            "patch": "@@ -15,14 +15,23 @@ limitations under the License.\n #include \"xla/stream_executor/gpu/gpu_blas_lt.h\"\n \n #include <optional>\n+#include <string>\n+#include <vector>\n \n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"google/protobuf/descriptor.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/gpu/gpu_blas_lt.pb.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace stream_executor::gpu {\n+using absl_testing::StatusIs;\n+using ::testing::ValuesIn;\n \n // Helper to compare MatrixLayout structs.\n void ExpectMatrixLayoutEq(const MatrixLayout& lhs, const MatrixLayout& rhs) {\n@@ -111,4 +120,75 @@ TEST(GemmConfigTest, ProtoConversionWithOptionals) {\n   ExpectGemmConfigEq(original_config, round_tripped_config);\n }\n \n+TEST(EpilogueTest, ToProtoSucceedsForValidValues) {\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kDefault),\n+            xla::BlasLtEpilogueProto::EPILOGUE_DEFAULT);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kReLU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_RELU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBias),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBiasThenReLU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_RELU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kGELU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_GELU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kSILU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_SILU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kSILUWithAux),\n+            xla::BlasLtEpilogueProto::EPILOGUE_SILU_WITH_AUX);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kGELUWithAux),\n+            xla::BlasLtEpilogueProto::EPILOGUE_GELU_WITH_AUX);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBiasThenGELU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBiasThenSILU),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBiasThenGELUWithAux),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_GELU_WITH_AUX);\n+  EXPECT_EQ(BlasLt::EpilogueToProto(BlasLt::Epilogue::kBiasThenSILUWithAux),\n+            xla::BlasLtEpilogueProto::EPILOGUE_BIAS_THEN_SILU_WITH_AUX);\n+}\n+\n+using EpilogueFromProtoTest =\n+    ::testing::TestWithParam<xla::BlasLtEpilogueProto>;\n+\n+TEST_P(EpilogueFromProtoTest, SucceedsForValidValue) {\n+  TF_EXPECT_OK(BlasLt::EpilogueFromProto(GetParam()));\n+}\n+\n+std::vector<xla::BlasLtEpilogueProto> EnumerateBlasLtEpilogueProtoValues() {\n+  const google::protobuf::EnumDescriptor* descriptor =\n+      xla::BlasLtEpilogueProto_descriptor();\n+  std::vector<xla::BlasLtEpilogueProto> values;\n+  for (int i = 0; i < descriptor->value_count(); ++i) {\n+    values.push_back(\n+        static_cast<xla::BlasLtEpilogueProto>(descriptor->value(i)->number()));\n+  }\n+  return values;\n+}\n+\n+std::string ToString(const xla::BlasLtEpilogueProto& proto) {\n+  const google::protobuf::EnumDescriptor* descriptor =\n+      xla::BlasLtEpilogueProto_descriptor();\n+  const google::protobuf::EnumValueDescriptor* value =\n+      descriptor->FindValueByNumber(proto);\n+  if (value == nullptr) {\n+    return absl::StrCat(\"Unknown(\", proto, \")\");\n+  }\n+  return std::string(value->name());\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(\n+    EpilogueFromProtoTests, EpilogueFromProtoTest,\n+    ValuesIn(EnumerateBlasLtEpilogueProtoValues()),\n+    [](const testing::TestParamInfo<xla::BlasLtEpilogueProto>& info) {\n+      return ToString(info.param);\n+    });\n+\n+TEST(BlasLtTest, EpilogueFromProtoReturnsErrorForInvalidValues) {\n+  constexpr int kInvalidProtoValue = 123456789;\n+  EXPECT_FALSE(xla::BlasLtEpilogueProto_IsValid(kInvalidProtoValue));\n+  EXPECT_THAT(BlasLt::EpilogueFromProto(\n+                  static_cast<xla::BlasLtEpilogueProto>(kInvalidProtoValue)),\n+              StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n }  // namespace stream_executor::gpu"
        }
    ],
    "stats": {
        "total": 472,
        "additions": 471,
        "deletions": 1
    }
}