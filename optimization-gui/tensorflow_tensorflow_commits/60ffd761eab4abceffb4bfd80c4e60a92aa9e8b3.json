{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 815594508",
    "sha": "60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3",
    "files": [
        {
            "sha": "b002cbb427bc9c394c311bf9af415c5b71de76c1",
            "filename": "tensorflow/core/tpu/kernels/tpu_compilation_cache_grpc.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_compilation_cache_grpc.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_compilation_cache_grpc.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_compilation_cache_grpc.cc?ref=60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3",
            "patch": "@@ -44,8 +44,8 @@ grpc::TpuCompilationCacheService::NewStub(\n     const std::shared_ptr< ::grpc::ChannelInterface>& channel,\n     const ::grpc::StubOptions& options) {\n   (void)options;\n-  std::unique_ptr<grpc::TpuCompilationCacheService::Stub> stub(\n-      new grpc::TpuCompilationCacheService::Stub(channel));\n+  std::unique_ptr<grpc::TpuCompilationCacheService::Stub> stub =\n+      std::make_unique<grpc::TpuCompilationCacheService::Stub>(channel);\n   return stub;\n }\n "
        },
        {
            "sha": "da20c0e355e79459be9b3f6c09d0fb8c7f46ceb4",
            "filename": "tensorflow/core/tpu/kernels/tpu_functional_ops.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_functional_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_functional_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftpu%2Fkernels%2Ftpu_functional_ops.cc?ref=60ffd761eab4abceffb4bfd80c4e60a92aa9e8b3",
            "patch": "@@ -1259,7 +1259,7 @@ void TPUPartitionedCallOp::ComputeAsync(OpKernelContext* ctx,\n   // Initialize the ordinal selector with information from the graph if it is\n   // the first time we are running this op.\n   absl::call_once(ordinal_selector_once_, [&]() {\n-    std::unique_ptr<Graph> graph(new Graph(flib_def_.get()));\n+    std::unique_ptr<Graph> graph = std::make_unique<Graph>(flib_def_.get());\n     bool enable_spmd_xla_partitioning = false;\n     TPUMetadata tpu_metadata;\n     {\n@@ -1313,7 +1313,7 @@ void TPUPartitionedCallOp::ComputeAsync(OpKernelContext* ctx,\n \n     tsl::profiler::TraceMe trace_me(\n         \"TPUPartitionedCallOp-RewriteAndInstantiateFunctions\");\n-    std::unique_ptr<Graph> graph(new Graph(flib_def_.get()));\n+    std::unique_ptr<Graph> graph = std::make_unique<Graph>(flib_def_.get());\n     bool enable_spmd_xla_partitioning = false;\n     TPUMetadata tpu_metadata;\n     OP_REQUIRES_OK_ASYNC(\n@@ -1415,7 +1415,8 @@ absl::Status TPUPartitionedCallOp::InitializeVarOnTPU(\n     OpKernelContext* ctx, const core::RefCountPtr<Var>& var, NodeDef* ndef,\n     int device_ordinal, bool fast_mem) {\n   const string device = strings::StrCat(kTPUDeviceNamePrefix, device_ordinal);\n-  std::unique_ptr<Graph> init_graph(new Graph(OpRegistry::Global()));\n+  std::unique_ptr<Graph> init_graph =\n+      std::make_unique<Graph>(OpRegistry::Global());\n   TF_ASSIGN_OR_RETURN(Node * init_handle, init_graph->AddNode(*ndef));\n   init_handle->set_assigned_device_name(device);\n \n@@ -1496,7 +1497,8 @@ absl::Status TPUPartitionedCallOp::InitializeShardedVarOnTPU(\n     OpKernelContext* ctx, const core::RefCountPtr<Var>& var,\n     std::vector<NodeDef>& ndefs, int split_dim,\n     const std::vector<string>& tpu_devices) {\n-  std::unique_ptr<Graph> init_graph(new Graph(OpRegistry::Global()));\n+  std::unique_ptr<Graph> init_graph =\n+      std::make_unique<Graph>(OpRegistry::Global());\n   int num_cores = ndefs.size();\n   string cpu_device = \"/device:CPU:0\";\n \n@@ -2512,7 +2514,7 @@ absl::Status TPUPartitionedCallOp::PartitionHelper(\n \n   const FunctionLibraryDefinition* flib_def = &graph->flib_def();\n   for (auto& partition : partitions) {\n-    std::unique_ptr<Graph> subgraph(new Graph(flib_def));\n+    std::unique_ptr<Graph> subgraph = std::make_unique<Graph>(flib_def);\n     GraphConstructorOptions opts;\n     opts.allow_internal_ops = true;\n     opts.expect_device_spec = true;"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 9,
        "deletions": 7
    }
}