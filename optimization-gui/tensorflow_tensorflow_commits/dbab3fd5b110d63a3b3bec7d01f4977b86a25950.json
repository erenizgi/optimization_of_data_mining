{
    "author": "metaflow",
    "message": "[XLA:GPU] add an overview for thunks\n\nmoved buffer assignment before thunk emission, added a diagram, rewording\n\nPiperOrigin-RevId: 836520366",
    "sha": "dbab3fd5b110d63a3b3bec7d01f4977b86a25950",
    "files": [
        {
            "sha": "c6e4c729b4228a30bd4dc50b0edd1fd4ac59a566",
            "filename": "third_party/xla/docs/hlo_to_thunks.md",
            "status": "modified",
            "additions": 173,
            "deletions": 51,
            "changes": 224,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fhlo_to_thunks.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fhlo_to_thunks.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fhlo_to_thunks.md?ref=dbab3fd5b110d63a3b3bec7d01f4977b86a25950",
            "patch": "@@ -1,28 +1,37 @@\n # From HLO to Thunks\n \n+This document outlines the journey of an XLA *High Level Optimizer* (HLO) module\n+from its initial state to a final executable. Sometimes we will omit the\n+\"module\" and refer to it just as \"HLO\".\n+\n+![hlo_to_thunks](./images/hlo_to_thunks.svg \"High level diagram of HLO to thunk path\")\n+\n ## Pre-optimization HLO\n-We start with pre-optimization HLO. Pre-optimization HLO does not contain ops\n-that are considered internal to XLA, e.g. `fusion` or `bitcast`. Ops don't have\n-a layout at this stage, or if they have, it will be ignored. Pre-optimization\n-HLO is usually produced by higher level frameworks like Tensorflow and JAX.\n-When using the XLA flag `-xla_dump_to`, the pre-optimization HLO is dumped to a\n-file with file name suffix “before_optimizations.txt”.\n+\n+We start with pre-optimization HLO module. Pre-optimization HLO does not contain\n+operations (*ops*) that are considered internal to XLA, such as `fusion` or\n+`bitcast`. Ops don't have a layout at this stage, or if they do, it will be\n+ignored. Pre-optimization HLO is usually produced by higher-level frameworks\n+like TensorFlow and JAX. When using the XLA flag `-xla_dump_to`, the\n+pre-optimization HLO is dumped to a file with file name suffix\n+“before_optimizations.txt”.\n \n ## Optimize HLO Module\n \n-The XLA:GPU pipeline will turn the pre-optimization HLO into optimized HLO by\n+The XLA:GPU pipeline turns the pre-optimization HLO into optimized HLO by\n running a sequence of passes. The passes can be grouped together semantically\n and run in the following order:\n \n ### Sharding related passes\n \n-[Shardy Partitioner](https://openxla.org/shardy/overview) or SPMD sharding.\n+This includes passes like the [Shardy\n+Partitioner](https://openxla.org/shardy/overview) or those for SPMD sharding.\n \n-### Optimization passes.\n+### Optimization passes\n \n This can include both legalization passes and simplification passes.\n \n-### Collective optimization passes.\n+### Collective optimization passes\n \n Similar to **Optimization passes**, but focuses on collective ops.\n \n@@ -42,10 +51,10 @@ by the layout permutation in minor to major order. In this example, the most\n minor dimension is 30, the second most minor dimension is 10, and the major\n dimension is 20.\n \n-The goal of the layout assignment is to minimize the number of physical\n-transpositions that are required using a greedy strategy. It starts off with\n-certain layout constraints (e.g. CuDNN/cuBLAS libraries expect consecutive\n-dimensions) and propagates layout “down”, and then “up” the HLO graph. At the\n+The goal of layout assignment is to minimize the number of required physical\n+transpositions using a greedy strategy. It starts with certain layout\n+constraints (e.g., cuDNN/cuBLAS libraries expect consecutive dimensions) and\n+propagates layouts “down” and then “up” the HLO graph. At the\n end of layout propagation, some instructions may have conflicting layouts, one\n propagated from an operand, one propagated from a user. To resolve this\n conflict, a `copy` HLO instruction is inserted that changes the layout from the\n@@ -56,10 +65,10 @@ operand layout to the instruction layout.\n Given that it is somewhat difficult to figure out the physical shape, layout\n normalization attempts to rewrite the shape such that it uses the default layout\n `{rank-1, rank-2, …, 0}`. In the example above, the normalized shape would be\n-`f32[20,10,30]{2,1,0}`. Copy ops that change layouts are rewritten to a\n-combination of `transpose` + `bitcast`. Given that currently we cannot normalize\n-all ops, there are still some ops that may have non-default layouts, most\n-notably `gather` and `dot`. At the boundaries between normalized ops and\n+`f32[20,10,30]{2,1,0}`. Copy ops that change layouts are rewritten as a\n+combination of `transpose` and `bitcast`. Given that currently we cannot\n+normalize all ops, there are still some ops that may have non-default layouts,\n+most notably `gather` and `dot`. At the boundaries between normalized ops and\n non-normalized ops there will be `bitcast` ops that represent a transpose, i.e.\n a transpose with a layout assigned that makes it a no-op physically.\n \n@@ -74,10 +83,10 @@ turns a reshape into a sequence of `transpose`, reshape `bitcast` and\n ### Post layout assignment optimization passes\n \n The most important passes here are Triton fusions (GEMM fusions +\n-Softmax/Layernorm fusions) or rewrites to library calls. But also Autotuning\n-runs in this step, where we pick the best algorithm for convolutions or dots, or\n-the best tiling for dots handled by the legacy Triton GEMM emitter, or whether\n-we should use Triton or Cublas for a certain dot fusion.\n+Softmax/Layernorm fusions) or rewrites to library calls. Autotuning also runs in\n+this step, where XLA chooses chooses between different emitters, picks the best\n+algorithm for convolutions or dots, finds the best tiling for fusions handled by\n+the Triton emitter etc.\n \n ### Fusion passes\n \n@@ -88,15 +97,15 @@ would allow duplicating ops with several users if the op can be fused into all\n users. We would also allow extending existing Triton Softmax fusions if\n possible.\n \n-`Multi-Output` fusion is a separate pass that allows to fuse ops/fusions\n-together that share an operand, or fuse operands/operand fusions into users\n-without duplication but instead adding extra output(s) so other users of the op\n-to be fused can be redirected to this output. This pass needs to be careful not\n-to introduce cycles into the HLO graph.\n+`Multi-Output` fusion is a separate pass that allows fusing ops/fusions that\n+share an operand. It can also fuse operands/operand fusions into users without\n+duplication by adding extra output(s), so other users of the op to be fused can\n+be redirected to these outputs. This pass needs to be careful not to introduce\n+cycles into the HLO graph.\n \n- After Multi-Output fusion, we run common subexpression elimination (`HloCSE`\n- pass) which will potentially merge previously duplicated ops back together if\n- they ended up in the same fusion.\n+After Multi-Output fusion, common subexpression elimination (`HloCSE` pass)\n+runs, potentially merging previously duplicated ops back together if they ended\n+up in the same fusion.\n \n ### Several post-fusion passes\n \n@@ -114,34 +123,32 @@ passes that actually change the HloModule, you can use the flag\n certain passes).\n \n ## Scheduling\n-An HloModule without schedule still has some degree of freedom in which order\n-the ops are processed. Basically any topological sort according to\n-operand/result relationship and control dependencies is ok. The scheduling\n-enforces a certain order. This influences the amount of memory that is required,\n-because we cannot reuse a buffer as long as not all readers of that buffer have\n-been processed. In an initial step, we try different scheduler algorithms and\n-pick the schedule that minimizes peak memory consumption.\n-\n-As a follow-up, we run the `LatencyHidingScheduler` pass that tries to maximize\n-compute-communication overlap but may increase memory usage again.\n \n-After scheduling, we run `HloRematerialization` which attempts to reduce memory\n-usage in case peak memory consumption is higher than the amount of memory we\n-have available. This is at the cost of performance, as e.g. some fusions might\n-be split and some ops might be duplicated to have shorter buffer lifetimes. If\n-rematerialization is happening, it would potentially make sense to look if there\n-are ways at model side to reduce the amount of memory required (e.g. smaller\n-batch sizes).\n+An HLO Module without a schedule still has some degree of freedom in the order\n+in which ops are processed. Any topological sort respecting operand/result\n+relationships and control dependencies is valid. Scheduling determines what\n+specific order to use. The main concern at this stage is the maximum memory\n+consumption that depends on the lifetime of tensors. In an initial step, we try\n+different scheduler algorithms and pick the schedule that should minimize the\n+peak memory consumption. Note that at this point we don't work with a physical\n+buffers yet (that will happen in \"Buffer Assignment\") and simulate the memory\n+usage.\n \n-## Thunks and CommandBuffers\n+Then `LatencyHidingScheduler` pass runs and tries to maximize\n+compute-communication overlap. But that may increase memory usage again.\n \n-TBD\n+Finally, in case peak memory consumption is higher than the amount of memory we\n+have available we run `HloRematerialization`. This pass attempts to reduce\n+memory usage at the cost of performance, as e.g. some fusions might be split and\n+some ops might be duplicated to have shorter buffer lifetimes. If\n+rematerialization occurs, it might be beneficial to investigate ways to reduce\n+memory requirements on the model side (e.g., using smaller batch sizes).\n \n-## BufferAssignment\n+## Buffer Assignment\n \n Immediately before we lower to LLVM IR, we run the buffer assignment passes that\n will assign buffer slices to each instruction in the HLO graph. The buffer\n-assignment runs in several steps.\n+assignment runs in several steps:\n \n 1. `HloDataflowAnalysis` assigns `HloValues` (essentially logical buffers) to\n instructions. For in-place ops, the `HloValue` of an operand can be reused. An\n@@ -158,3 +165,118 @@ the start time of the other `HloBuffer`). When using the flag `-xla_dump_to`,\n some information about buffer assignment is dumped to a file with the name\n suffix \"after_optimizations-buffer-assignment.txt\".\n \n+## Thunks\n+\n+After an HLO graph is optimized and scheduled, it is lowered into a\n+linear sequence of thunks for a specific backend (CPU or GPU).\n+\n+In XLA, a **Thunk** is an abstraction of a self-contained unit of work that the\n+runtime executes. It might be a specific operation, library call, control-flow\n+construct, collective communication, and so on. A **Thunk Sequence** represents\n+the entire executable for a specific backend.\n+\n+Examples of concrete thunk types include `KernelThunk` (for launching a compiled\n+kernel), `GemmThunk` (for a cuBLAS matrix multiplication), `ConvolutionThunk`\n+(for a cuDNN convolution), and control-flow thunks like `WhileThunk` and\n+`ConditionalThunk`.\n+\n+### Thunk Emission\n+\n+The process of converting a scheduled HLO computation into a thunk sequence is\n+called \"thunk emission\". This is handled by a dedicated emitter class in each\n+backend.\n+\n+For the GPU Backend, this is handled by\n+[IrEmitterUnnested](https://github.com/openxla/xla/tree/main/xla/service/gpu/ir_emitter_unnested.h).\n+`EmitHloComputation` iterates through the scheduled list of HLO Instructions in\n+a computation and dispatches to a specialized `Emit...` method (e.g.,\n+`EmitFusion`, `EmitConvolutionThunk`, `EmitWhile`). Each of these methods\n+constructs the appropriate Thunk object(s) and appends them to the\n+thunk sequence.\n+\n+For the CPU Backend,\n+[ThunkEmitter](https://github.com/openxla/xla/tree/main/xla/service/cpu/thunk_emitter.h)\n+performs this role and is organized in a similar manner. Final `ThunkSequence`\n+is embedded in the `CpuExecutable`.\n+\n+Note that each instruction in the entry computation of an HLO module might\n+correspond to none (`kTuple`, `kConstant`, ..), one, or multiple (for example\n+sort instruction) thunks in the final thunk sequence.\n+\n+### Command Buffers: Optimizing Execution on the GPU\n+\n+Modern GPU hardware allows recording a sequence of GPU operations (kernel\n+launches, memory copies, etc.) once and then replaying the sequence multiple\n+times with minimal CPU overhead. This is a critical performance optimization,\n+especially for workloads with many small, fast-launching kernels. XLA uses\n+**Command Buffer** as an abstraction of CUDA Graphs or HIP Graphs. The core\n+interface is defined in\n+[GpuCommandBuffer](https://github.com/openxla/xla/tree/main/xla/stream_executor/gpu/gpu_command_buffer.h).\n+\n+A command buffer is represented in a thunk sequence by\n+[CommandBufferThunk](https://github.com/openxla/xla/tree/main/xla/backends/gpu/runtime/command_buffer_thunk.h).\n+\n+The emitter does not produce this thunk directly from HLO instructions. Instead,\n+this is done by\n+[CommandBufferConversionPass](https://github.com/openxla/xla/tree/main/xla/backends/gpu/runtime/command_buffer_conversion_pass.h)\n+that runs on the ThunkSequence itself.\n+\n+The pass identifies contiguous sub-sequences of compatible thunks (e.g., a\n+series of `KernelThunk`s and `GemmThunk`s). It then replaces the found\n+sub-sequence with a single `CommandBufferThunk`. The new thunk encapsulates the\n+logic of the original thunks as a list of lightweight CommandBufferCmd objects.\n+When a `CommandBufferThunk` executes for the first time on a given GPU stream,\n+it \"records\" its sequence of commands into a hardware command buffer. On all\n+subsequent executions, it simply issues a single command to the GPU to \"replay\"\n+the recorded sequence. This avoids the CPU overhead of launching each individual\n+kernel.\n+\n+## Executable\n+\n+The final product of the XLA compilation pipeline is a self-contained,\n+platform-specific\n+[Executable](https://github.com/openxla/xla/tree/main/xla/service/executable.h).\n+This object encapsulates all the information needed to run the compiled program\n+on a target device, such as a CPU or GPU. It is the bridge between the compiler\n+and the runtime. Modern runtimes like PJRT use slightly higher-level\n+abstractions (see\n+[PjRtExecutable](https://github.com/openxla/xla/tree/main/xla/pjrt/pjrt_executable.h)),\n+but these ultimately wrap a backend-specific executable.\n+\n+An `Executable` contains several key pieces of information generated\n+during compilation. While the exact contents vary by backend, they generally\n+include:\n+\n+- Compiled Code: This is the low-level machine code that will run on the device.\n+  For CPUs, this is typically one or more object files. For GPUs, this is the\n+  compiled device code in PTX or HSACO format, which is loaded onto the GPU at\n+  runtime.\n+\n+- Execution Plan (ThunkSequence): The core of the runtime logic. This is a\n+  linear sequence of Thunk objects. Each thunk represents a single unit of work,\n+  such as launching a kernel, calling a library function (e.g., cuBLAS), or\n+  handling control flow. The runtime executes the program by iterating through\n+  this sequence.\n+\n+- Memory Layout (BufferAssignment): This critical piece of metadata, produced by\n+  the BufferAssigner, describes the complete memory layout for the computation.\n+  It specifies the size of every buffer and how memory is allocated and reused\n+  for parameters, outputs, and temporary values. The runtime uses this to\n+  allocate device memory and pass the correct pointers to each thunk.\n+\n+- (optional) HLO Module: For debugging and profiling, the executable often\n+  retains a reference to the final, optimized HloModule that it was compiled\n+  from.\n+\n+The creation of the final executable is orchestrated by the compiler for each\n+specific backend. The `RunBackend` method of a Compiler implementation is the\n+final step in the compilation process, which packages all the compiled artifacts\n+into an Executable object.\n+[GpuCompiler](https://github.com/openxla/xla/tree/main/xla/service/gpu/gpu_compiler.cc)\n+and\n+[CpuCompiler](https://github.com/openxla/xla/tree/main/xla/service/cpu/cpu_compiler.cc)\n+target GPU and CPU respectively.\n+\n+When a user calls `Execute...` on an executable, the runtime uses the\n+`BufferAssignment` to allocate memory, and then invokes the `ThunkSequence` to\n+launch the operations on the device using the compiled code."
        },
        {
            "sha": "c832b5b0442ad2c94be99d6c71afd4e7f885edfc",
            "filename": "third_party/xla/docs/images/hlo_to_thunks.mermaid.txt",
            "status": "added",
            "additions": 37,
            "deletions": 0,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.mermaid.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.mermaid.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.mermaid.txt?ref=dbab3fd5b110d63a3b3bec7d01f4977b86a25950",
            "patch": "@@ -0,0 +1,37 @@\n+graph TD\n+    %% Artifacts (Data - Rounded Box Shape)\n+    InitialHlo(\"Unoptimized HLO\")\n+    OptimizedHlo(\"Optimized and scheduled HLO\")\n+    BufferAssignment(\"BufferAssignment\")\n+    ThunkSequence(\"ThunkSequence\")\n+    LlvmIr(\"LLVM IR\")\n+    MachineCode(\"Machine Code<br/><i>PTX, obj, ..</i>\")\n+    Executable(\"Executable\")\n+\n+    %% Stages (Processes - Subroutine Shape)\n+    HloPasses[[1. HLO Optimization<br/>& Scheduling]]\n+    BufferAssigner[[2. Buffer Assignment]]\n+    ThunkEmitter[[3. Thunk Emission]]\n+    LlvmCompiler[[4. LLVM Compilation]]\n+    ExecutableBuilder[[5. Executable Creation]]\n+\n+    %% Edges (Flow of Artifacts through Stages)\n+    InitialHlo --> HloPasses\n+    HloPasses --> OptimizedHlo\n+\n+    OptimizedHlo --> BufferAssigner\n+    BufferAssigner --> BufferAssignment\n+\n+    OptimizedHlo --> ThunkEmitter\n+    BufferAssignment --> ThunkEmitter\n+    ThunkEmitter --> ThunkSequence\n+    ThunkEmitter --> LlvmIr\n+\n+    LlvmIr --> LlvmCompiler\n+    LlvmCompiler --> MachineCode\n+\n+    MachineCode --> ExecutableBuilder\n+    ThunkSequence --> ExecutableBuilder\n+    BufferAssignment --> ExecutableBuilder\n+\n+    ExecutableBuilder --> Executable\n\\ No newline at end of file"
        },
        {
            "sha": "31456f2bcb5a96777a6127c75894dd98d69f0a94",
            "filename": "third_party/xla/docs/images/hlo_to_thunks.svg",
            "status": "added",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.svg",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbab3fd5b110d63a3b3bec7d01f4977b86a25950/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.svg",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fimages%2Fhlo_to_thunks.svg?ref=dbab3fd5b110d63a3b3bec7d01f4977b86a25950",
            "patch": "@@ -0,0 +1,3 @@\n+<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n+<?xml-stylesheet href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.6.0/css/all.min.css\" type=\"text/css\"?>\n+<svg aria-roledescription=\"flowchart-v2\" role=\"graphics-document document\" viewBox=\"-8 -8 460.6640625 993\" style=\"max-width: 100%;\" xmlns=\"http://www.w3.org/2000/svg\" width=\"100%\" id=\"graph-div\" height=\"100%\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style>#graph-div{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}#graph-div .error-icon{fill:#552222;}#graph-div .error-text{fill:#552222;stroke:#552222;}#graph-div .edge-thickness-normal{stroke-width:2px;}#graph-div .edge-thickness-thick{stroke-width:3.5px;}#graph-div .edge-pattern-solid{stroke-dasharray:0;}#graph-div .edge-pattern-dashed{stroke-dasharray:3;}#graph-div .edge-pattern-dotted{stroke-dasharray:2;}#graph-div .marker{fill:#333333;stroke:#333333;}#graph-div .marker.cross{stroke:#333333;}#graph-div svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#graph-div .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#graph-div .cluster-label text{fill:#333;}#graph-div .cluster-label span,#graph-div p{color:#333;}#graph-div .label text,#graph-div span,#graph-div p{fill:#333;color:#333;}#graph-div .node rect,#graph-div .node circle,#graph-div .node ellipse,#graph-div .node polygon,#graph-div .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#graph-div .flowchart-label text{text-anchor:middle;}#graph-div .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#graph-div .node .label{text-align:center;}#graph-div .node.clickable{cursor:pointer;}#graph-div .arrowheadPath{fill:#333333;}#graph-div .edgePath .path{stroke:#333333;stroke-width:2.0px;}#graph-div .flowchart-link{stroke:#333333;fill:none;}#graph-div .edgeLabel{background-color:#e8e8e8;text-align:center;}#graph-div .edgeLabel rect{opacity:0.5;background-color:#e8e8e8;fill:#e8e8e8;}#graph-div .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#graph-div .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#graph-div .cluster text{fill:#333;}#graph-div .cluster span,#graph-div p{color:#333;}#graph-div div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#graph-div .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#graph-div :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}</style><g><marker orient=\"auto\" markerHeight=\"12\" markerWidth=\"12\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"6\" viewBox=\"0 0 10 10\" class=\"marker flowchart\" id=\"graph-div_flowchart-pointEnd\"><path style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 0 0 L 10 5 L 0 10 z\"></path></marker><marker orient=\"auto\" markerHeight=\"12\" markerWidth=\"12\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"4.5\" viewBox=\"0 0 10 10\" class=\"marker flowchart\" id=\"graph-div_flowchart-pointStart\"><path style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 0 5 L 10 10 L 10 0 z\"></path></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"11\" viewBox=\"0 0 10 10\" class=\"marker flowchart\" id=\"graph-div_flowchart-circleEnd\"><circle style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" r=\"5\" cy=\"5\" cx=\"5\"></circle></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5\" refX=\"-1\" viewBox=\"0 0 10 10\" class=\"marker flowchart\" id=\"graph-div_flowchart-circleStart\"><circle style=\"stroke-width: 1; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" r=\"5\" cy=\"5\" cx=\"5\"></circle></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5.2\" refX=\"12\" viewBox=\"0 0 11 11\" class=\"marker cross flowchart\" id=\"graph-div_flowchart-crossEnd\"><path style=\"stroke-width: 2; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 1,1 l 9,9 M 10,1 l -9,9\"></path></marker><marker orient=\"auto\" markerHeight=\"11\" markerWidth=\"11\" markerUnits=\"userSpaceOnUse\" refY=\"5.2\" refX=\"-1\" viewBox=\"0 0 11 11\" class=\"marker cross flowchart\" id=\"graph-div_flowchart-crossStart\"><path style=\"stroke-width: 2; stroke-dasharray: 1, 0;\" class=\"arrowMarkerPath\" d=\"M 1,1 l 9,9 M 10,1 l -9,9\"></path></marker><g class=\"root\"><g class=\"clusters\"></g><g class=\"edgePaths\"><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-InitialHlo LE-HloPasses\" id=\"L-InitialHlo-HloPasses-0\" d=\"M230.543,39L230.543,43.167C230.543,47.333,230.543,55.667,230.609,63.2C230.675,70.734,230.807,77.467,230.873,80.834L230.939,84.201\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-HloPasses LE-OptimizedHlo\" id=\"L-HloPasses-OptimizedHlo-0\" d=\"M231.043,152.5L230.96,156.583C230.876,160.667,230.71,168.833,230.626,176.2C230.543,183.567,230.543,190.133,230.543,193.417L230.543,196.7\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-OptimizedHlo LE-BufferAssigner\" id=\"L-OptimizedHlo-BufferAssigner-0\" d=\"M285.06,241L296.709,245.167C308.358,249.333,331.655,257.667,343.37,265.2C355.085,272.734,355.217,279.467,355.283,282.834L355.349,286.201\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-BufferAssigner LE-BufferAssignment\" id=\"L-BufferAssigner-BufferAssignment-0\" d=\"M355.453,330.5L355.37,334.583C355.286,338.667,355.12,346.833,355.036,354.2C354.953,361.567,354.953,368.133,354.953,371.417L354.953,374.7\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-OptimizedHlo LE-ThunkEmitter\" id=\"L-OptimizedHlo-ThunkEmitter-0\" d=\"M201.023,241L194.715,245.167C188.407,249.333,175.791,257.667,169.484,269.25C163.176,280.833,163.176,295.667,163.176,310.5C163.176,325.333,163.176,340.167,163.176,355C163.176,369.833,163.176,384.667,163.176,399.5C163.176,414.333,163.176,429.167,163.989,439.974C164.803,450.782,166.43,457.564,167.244,460.955L168.057,464.346\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-BufferAssignment LE-ThunkEmitter\" id=\"L-BufferAssignment-ThunkEmitter-0\" d=\"M329.815,419L324.443,423.167C319.072,427.333,308.329,435.667,292.221,443.779C276.113,451.891,254.64,459.781,243.904,463.727L233.167,467.672\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-ThunkEmitter LE-ThunkSequence\" id=\"L-ThunkEmitter-ThunkSequence-0\" d=\"M211.017,508.5L218.913,512.583C226.808,516.667,242.599,524.833,250.495,536.333C258.391,547.833,258.391,562.667,258.391,577.5C258.391,592.333,258.391,607.167,258.391,622C258.391,636.833,258.391,651.667,258.391,666.5C258.391,681.333,258.391,696.167,258.391,708.867C258.391,721.567,258.391,732.133,258.391,737.417L258.391,742.7\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-ThunkEmitter LE-LlvmIr\" id=\"L-ThunkEmitter-LlvmIr-0\" d=\"M136.334,508.5L128.272,512.583C120.21,516.667,104.085,524.833,96.023,532.2C87.961,539.567,87.961,546.133,87.961,549.417L87.961,552.7\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-LlvmIr LE-LlvmCompiler\" id=\"L-LlvmIr-LlvmCompiler-0\" d=\"M87.961,597L87.961,601.167C87.961,605.333,87.961,613.667,88.027,621.2C88.093,628.734,88.225,635.467,88.291,638.834L88.357,642.201\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-LlvmCompiler LE-MachineCode\" id=\"L-LlvmCompiler-MachineCode-0\" d=\"M88.461,686.5L88.378,690.583C88.294,694.667,88.128,702.833,88.044,710.2C87.961,717.567,87.961,724.133,87.961,727.417L87.961,730.7\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-MachineCode LE-ExecutableBuilder\" id=\"L-MachineCode-ExecutableBuilder-0\" d=\"M87.961,799L87.961,803.167C87.961,807.333,87.961,815.667,103.148,823.857C118.336,832.048,148.71,840.095,163.897,844.119L179.085,848.143\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-ThunkSequence LE-ExecutableBuilder\" id=\"L-ThunkSequence-ExecutableBuilder-0\" d=\"M258.391,787L258.391,793.167C258.391,799.333,258.391,811.667,258.457,821.2C258.523,830.734,258.655,837.467,258.721,840.834L258.787,844.201\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-BufferAssignment LE-ExecutableBuilder\" id=\"L-BufferAssignment-ExecutableBuilder-0\" d=\"M359.335,419L360.271,423.167C361.208,427.333,363.08,435.667,364.017,447.25C364.953,458.833,364.953,473.667,364.953,488.5C364.953,503.333,364.953,518.167,364.953,533C364.953,547.833,364.953,562.667,364.953,577.5C364.953,592.333,364.953,607.167,364.953,622C364.953,636.833,364.953,651.667,364.953,666.5C364.953,681.333,364.953,696.167,364.953,713C364.953,729.833,364.953,748.667,364.953,767.5C364.953,786.333,364.953,805.167,355.87,818.485C346.788,831.803,328.622,839.606,319.539,843.507L310.456,847.408\"></path><path marker-end=\"url(#graph-div_flowchart-pointEnd)\" style=\"fill:none;\" class=\"edge-thickness-normal edge-pattern-solid flowchart-link LS-ExecutableBuilder LE-Executable\" id=\"L-ExecutableBuilder-Executable-0\" d=\"M258.891,888.5L258.807,892.583C258.724,896.667,258.557,904.833,258.474,912.2C258.391,919.567,258.391,926.133,258.391,929.417L258.391,932.7\"></path></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g transform=\"translate(0, 0)\" class=\"label\"><foreignObject height=\"0\" width=\"0\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"edgeLabel\"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g transform=\"translate(230.54296875, 19.5)\" data-id=\"InitialHlo\" data-node=\"true\" id=\"flowchart-InitialHlo-3111\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"139.78125\" y=\"-19.5\" x=\"-69.890625\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-62.390625, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"124.78125\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Unoptimized HLO</span></div></foreignObject></g></g><g transform=\"translate(230.54296875, 221.5)\" data-id=\"OptimizedHlo\" data-node=\"true\" id=\"flowchart-OptimizedHlo-3112\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"230.4375\" y=\"-19.5\" x=\"-115.21875\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-107.71875, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"215.4375\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Optimized and scheduled HLO</span></div></foreignObject></g></g><g transform=\"translate(354.953125, 399.5)\" data-id=\"BufferAssignment\" data-node=\"true\" id=\"flowchart-BufferAssignment-3113\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"140.390625\" y=\"-19.5\" x=\"-70.1953125\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-62.6953125, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"125.390625\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">BufferAssignment</span></div></foreignObject></g></g><g transform=\"translate(258.390625, 767.5)\" data-id=\"ThunkSequence\" data-node=\"true\" id=\"flowchart-ThunkSequence-3114\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"126.78125\" y=\"-19.5\" x=\"-63.390625\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-55.890625, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"111.78125\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">ThunkSequence</span></div></foreignObject></g></g><g transform=\"translate(87.9609375, 577.5)\" data-id=\"LlvmIr\" data-node=\"true\" id=\"flowchart-LlvmIr-3115\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"68.328125\" y=\"-19.5\" x=\"-34.1640625\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-26.6640625, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"53.328125\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">LLVM IR</span></div></foreignObject></g></g><g transform=\"translate(87.9609375, 767.5)\" data-id=\"MachineCode\" data-node=\"true\" id=\"flowchart-MachineCode-3116\" class=\"node default default flowchart-label\"><rect height=\"63\" width=\"114.078125\" y=\"-31.5\" x=\"-57.0390625\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-49.5390625, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"99.078125\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Machine Code<br/><i>PTX, obj, ..</i></span></div></foreignObject></g></g><g transform=\"translate(258.390625, 957.5)\" data-id=\"Executable\" data-node=\"true\" id=\"flowchart-Executable-3117\" class=\"node default default flowchart-label\"><rect height=\"39\" width=\"94.09375\" y=\"-19.5\" x=\"-47.046875\" ry=\"5\" rx=\"5\" style=\"\" class=\"basic label-container\"></rect><g transform=\"translate(-39.546875, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"79.09375\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">Executable</span></div></foreignObject></g></g><g transform=\"translate(230.54296875, 120.5)\" data-id=\"HloPasses\" data-node=\"true\" id=\"flowchart-HloPasses-3118\" class=\"node default default flowchart-label\"><polygon style=\"\" transform=\"translate(-80.46875,31.5)\" class=\"label-container\" points=\"0,0 160.9375,0 160.9375,-63 0,-63 0,0 -8,0 168.9375,0 168.9375,-63 -8,-63 -8,0\"></polygon><g transform=\"translate(-72.96875, -24)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"48\" width=\"145.9375\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">1. HLO Optimization<br/>&amp; Scheduling</span></div></foreignObject></g></g><g transform=\"translate(354.953125, 310.5)\" data-id=\"BufferAssigner\" data-node=\"true\" id=\"flowchart-BufferAssigner-3119\" class=\"node default default flowchart-label\"><polygon style=\"\" transform=\"translate(-81.7109375,19.5)\" class=\"label-container\" points=\"0,0 163.421875,0 163.421875,-39 0,-39 0,0 -8,0 171.421875,0 171.421875,-39 -8,-39 -8,0\"></polygon><g transform=\"translate(-74.2109375, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"148.421875\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">2. Buffer Assignment</span></div></foreignObject></g></g><g transform=\"translate(173.17578125, 488.5)\" data-id=\"ThunkEmitter\" data-node=\"true\" id=\"flowchart-ThunkEmitter-3120\" class=\"node default default flowchart-label\"><polygon style=\"\" transform=\"translate(-71.734375,19.5)\" class=\"label-container\" points=\"0,0 143.46875,0 143.46875,-39 0,-39 0,0 -8,0 151.46875,0 151.46875,-39 -8,-39 -8,0\"></polygon><g transform=\"translate(-64.234375, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"128.46875\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">3. Thunk Emission</span></div></foreignObject></g></g><g transform=\"translate(87.9609375, 666.5)\" data-id=\"LlvmCompiler\" data-node=\"true\" id=\"flowchart-LlvmCompiler-3121\" class=\"node default default flowchart-label\"><polygon style=\"\" transform=\"translate(-79.9609375,19.5)\" class=\"label-container\" points=\"0,0 159.921875,0 159.921875,-39 0,-39 0,0 -8,0 167.921875,0 167.921875,-39 -8,-39 -8,0\"></polygon><g transform=\"translate(-72.4609375, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"144.921875\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">4. LLVM Compilation</span></div></foreignObject></g></g><g transform=\"translate(258.390625, 868.5)\" data-id=\"ExecutableBuilder\" data-node=\"true\" id=\"flowchart-ExecutableBuilder-3122\" class=\"node default default flowchart-label\"><polygon style=\"\" transform=\"translate(-89.578125,19.5)\" class=\"label-container\" points=\"0,0 179.15625,0 179.15625,-39 0,-39 0,0 -8,0 187.15625,0 187.15625,-39 -8,-39 -8,0\"></polygon><g transform=\"translate(-82.078125, -12)\" style=\"\" class=\"label\"><rect></rect><foreignObject height=\"24\" width=\"164.15625\"><div style=\"display: inline-block; white-space: nowrap;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span class=\"nodeLabel\">5. Executable Creation</span></div></foreignObject></g></g></g></g></g></svg>\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 264,
        "additions": 213,
        "deletions": 51
    }
}