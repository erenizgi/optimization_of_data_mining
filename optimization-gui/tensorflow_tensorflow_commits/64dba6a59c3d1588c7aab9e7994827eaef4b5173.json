{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 850378015",
    "sha": "64dba6a59c3d1588c7aab9e7994827eaef4b5173",
    "files": [
        {
            "sha": "13c238b60d8f492b1ecee2b7911aec063898c330",
            "filename": "tensorflow/core/kernels/decode_wav_op.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdecode_wav_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdecode_wav_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdecode_wav_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -40,15 +40,15 @@ class DecodeWavOp : public OpKernel {\n     OP_REQUIRES(context, TensorShapeUtils::IsScalar(contents.shape()),\n                 errors::InvalidArgument(\"contents must be scalar, got shape \",\n                                         contents.shape().DebugString()));\n-    const string& wav_string = contents.scalar<tstring>()();\n+    const std::string& wav_string = contents.scalar<tstring>()();\n     OP_REQUIRES(context, wav_string.size() <= std::numeric_limits<int>::max(),\n                 errors::InvalidArgument(\"WAV contents are too large for int: \",\n                                         wav_string.size()));\n \n     std::vector<float> decoded_samples;\n-    uint32 decoded_sample_count;\n-    uint16 decoded_channel_count;\n-    uint32 decoded_sample_rate;\n+    uint32_t decoded_sample_count;\n+    uint16_t decoded_channel_count;\n+    uint32_t decoded_sample_rate;\n     OP_REQUIRES_OK(context,\n                    wav::DecodeLin16WaveAsFloatVector(\n                        wav_string, &decoded_samples, &decoded_sample_count,\n@@ -112,12 +112,12 @@ class DecodeWavOp : public OpKernel {\n     Tensor* sample_rate_output = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(1, TensorShape({}),\n                                                      &sample_rate_output));\n-    sample_rate_output->flat<int32>()(0) = decoded_sample_rate;\n+    sample_rate_output->flat<int32_t>()(0) = decoded_sample_rate;\n   }\n \n  private:\n-  int32 desired_channels_;\n-  int32 desired_samples_;\n+  int32_t desired_channels_;\n+  int32_t desired_samples_;\n };\n REGISTER_KERNEL_BUILDER(Name(\"DecodeWav\").Device(DEVICE_CPU), DecodeWavOp);\n "
        },
        {
            "sha": "2ff5ee6211cd4426a3e2990baf2b8b7419151bde",
            "filename": "tensorflow/core/kernels/depthwise_conv_op.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdepthwise_conv_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -284,7 +284,7 @@ class DepthwiseConv2dNativeOp : public BinaryOp<T> {\n   explicit DepthwiseConv2dNativeOp(OpKernelConstruction* context)\n       : BinaryOp<T>(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"strides\", &strides_));\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -385,17 +385,17 @@ class DepthwiseConv2dNativeOp : public BinaryOp<T> {\n     const int64_t input_rows_raw = GetTensorDim(input, data_format_, 'H');\n     OP_REQUIRES(\n         context,\n-        FastBoundsCheck(input_rows_raw, std::numeric_limits<int32>::max()),\n+        FastBoundsCheck(input_rows_raw, std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\"Input rows too large\"));\n-    const int32_t input_rows = static_cast<int32>(input_rows_raw);\n+    const int32_t input_rows = static_cast<int32_t>(input_rows_raw);\n     const int32_t filter_rows = filter.dim_size(0);\n \n     const int64_t input_cols_raw = GetTensorDim(input, data_format_, 'W');\n     OP_REQUIRES(\n         context,\n-        FastBoundsCheck(input_cols_raw, std::numeric_limits<int32>::max()),\n+        FastBoundsCheck(input_cols_raw, std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\"Input cols too large\"));\n-    const int32_t input_cols = static_cast<int32>(input_cols_raw);\n+    const int32_t input_cols = static_cast<int32_t>(input_cols_raw);\n     const int32_t filter_cols = filter.dim_size(1);\n \n     // The first dimension for input is batch.\n@@ -425,7 +425,7 @@ class DepthwiseConv2dNativeOp : public BinaryOp<T> {\n         context,\n         (!std::is_same<Device, GPUDevice>::value ||\n          FastBoundsCheck(out_shape.num_elements(),\n-                         std::numeric_limits<int32>::max())),\n+                         std::numeric_limits<int32_t>::max())),\n         errors::InvalidArgument(\"Output elements too large for GPU kernel\"));\n \n     Tensor* output = nullptr;"
        },
        {
            "sha": "3d4a0618f57d5e42f87329f1127480f46fe9414b",
            "filename": "tensorflow/core/kernels/dynamic_partition_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdynamic_partition_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -57,7 +57,7 @@ class DynamicPartitionOp_Shared : public OpKernel {\n \n     // Count how many occurrences of each partition id we have in partitions\n     absl::InlinedVector<int, 32UL> partition_count(num_partitions_);\n-    auto e_partitions = (*partitions)->flat<int32>();\n+    auto e_partitions = (*partitions)->flat<int32_t>();\n     const int64_t N = e_partitions.dimension(0);\n     for (int64_t i = 0; i < N; i++) {\n       const int32_t p = internal::SubtleMustCopy(e_partitions(i));\n@@ -98,7 +98,7 @@ class DynamicPartitionOp : public DynamicPartitionOp_Shared {\n     if (!c->status().ok()) return;\n     if (num_partitions_ == 0 || data->NumElements() == 0) return;\n \n-    auto e_partitions = partitions->flat<int32>();\n+    auto e_partitions = partitions->flat<int32_t>();\n     const int64_t N = e_partitions.dimension(0);\n     absl::InlinedVector<int, 32UL> output_index(num_partitions_);\n "
        },
        {
            "sha": "f5a9828fdf2e03842a35a97acb22181312865961",
            "filename": "tensorflow/core/kernels/dynamic_stitch_op.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdynamic_stitch_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Fdynamic_stitch_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdynamic_stitch_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -45,7 +45,7 @@ template <class T>\n class DynamicStitchOpImplBase : public OpKernel {\n  public:\n   explicit DynamicStitchOpImplBase(OpKernelConstruction* c,\n-                                   const string& op_name)\n+                                   const std::string& op_name)\n       : OpKernel(c) {\n     // Compute expected input signature\n     const DataType dt = DataTypeToEnum<T>::v();\n@@ -95,8 +95,8 @@ class DynamicStitchOpImplBase : public OpKernel {\n     }\n     for (const Tensor& indices : *indices_inputs) {\n       if (indices.NumElements() > 0) {\n-        Eigen::Tensor<int32, 0, Eigen::RowMajor> m =\n-            indices.flat<int32>().maximum();\n+        Eigen::Tensor<int32_t, 0, Eigen::RowMajor> m =\n+            indices.flat<int32_t>().maximum();\n         max_index = std::max(m(), max_index);\n       }\n       if (data_elements_size) {\n@@ -107,7 +107,7 @@ class DynamicStitchOpImplBase : public OpKernel {\n     *first_dim_size = max_index + 1;\n \n     for (const Tensor& indices : *indices_inputs) {\n-      auto indices_vec = indices.flat<int32>();\n+      auto indices_vec = indices.flat<int32_t>();\n \n       for (int i = 0; i < indices_vec.size(); i++) {\n         int32_t index = internal::SubtleMustCopy(indices_vec(i));\n@@ -204,7 +204,7 @@ class DynamicStitchOpGPU : public DynamicStitchOpImplBase<T> {\n       // implicitly using atomics to make sure the last index is the final\n       // write.\n       const int slice_size = merged->flat_outer_dims<T>().dimension(1);\n-      GpuDeviceArrayOnHost<int32> indices_flat(c, first_dim_size);\n+      GpuDeviceArrayOnHost<int32_t> indices_flat(c, first_dim_size);\n       GpuDeviceArrayOnHost<const T*> data_flat(c, data_elements_size);\n       OP_REQUIRES_OK(c, indices_flat.Init());\n       OP_REQUIRES_OK(c, data_flat.Init());\n@@ -218,7 +218,7 @@ class DynamicStitchOpGPU : public DynamicStitchOpImplBase<T> {\n       // sum of indices_inputs[i].NumElements() for compute indices_flat value.\n       int32_t base_size = 0;\n       for (int i = 0; i < indices_inputs.size(); ++i) {\n-        auto indices_vec = indices_inputs[i].flat<int32>();\n+        auto indices_vec = indices_inputs[i].flat<int32_t>();\n         auto data_ptr_base = data_inputs[i].template flat<T>().data();\n         for (int j = 0; j < indices_vec.size(); ++j) {\n           // indices_flat's indices represent the indices of output.\n@@ -276,7 +276,7 @@ class DynamicStitchOpImplCPU : public DynamicStitchOpImplBase<T> {\n       const size_t slice_bytes = slice_size * sizeof(T);\n       auto OnInputNumber = [&](int input_num) {\n         const Tensor& indices = indices_inputs[input_num];\n-        auto indices_vec = indices.flat<int32>();\n+        auto indices_vec = indices.flat<int32_t>();\n         const Tensor& data = data_inputs[input_num];\n         auto data_flat =\n             data.shaped<T, 2>({indices_vec.dimension(0), slice_size});"
        },
        {
            "sha": "2684eb8855121dadc3a94fdc82a1bb708da4d914",
            "filename": "tensorflow/core/kernels/fact_op.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffact_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffact_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ffact_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -60,14 +60,14 @@ static constexpr const char* const kFacts1[] = {\n     \"\\\"^x\\x7fo+#\",\n     \"Moell*Bcd~ed*bky*}xc~~od*~}e*zkzoxy*~bk~*kxo*noy~cdon*~e*xo|ef\\x7f~cedcpo*\"\n     \"gkibcdo*fokxdcdm$*Dehens*ade}y*}bcib*~}e$\"};\n-static constexpr uint64 kNum1 = sizeof(kFacts1) / sizeof(kFacts1[0]);\n+static constexpr uint64_t kNum1 = sizeof(kFacts1) / sizeof(kFacts1[0]);\n \n static constexpr const char* const kFacts2[] = {\n     \"Yoxmos*Hxcd*kdn*Hk~gkd*bk|o*do|ox*hood*yood*k~*~bo*ykgo*zfkio*k~*~bo*ykgo*\"\n     \"~cgo$\"};\n-static constexpr uint64 kNum2 = sizeof(kFacts2) / sizeof(kFacts2[0]);\n+static constexpr uint64_t kNum2 = sizeof(kFacts2) / sizeof(kFacts2[0]);\n \n-static void E(string* s) {\n+static void E(std::string* s) {\n   for (size_t j = 0; j < s->size(); ++j) {\n     (*s)[j] ^= '\\n';\n   }\n@@ -81,13 +81,13 @@ class FactOpKernel : public OpKernel {\n \n  protected:\n   void Compute(OpKernelContext* context, const char* const facts[],\n-               uint64 count) {\n+               uint64_t count) {\n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(\n         context, context->allocate_output(0, TensorShape({}), &output_tensor));\n     auto output = output_tensor->template scalar<tstring>();\n \n-    string coded = facts[context->env()->NowMicros() % count];\n+    std::string coded = facts[context->env()->NowMicros() % count];\n     E(&coded);\n     output() = coded;\n   }\n@@ -118,8 +118,8 @@ REGISTER_KERNEL_BUILDER(Name(\"Fact\").Device(DEVICE_GPU).HostMemory(\"fact\"),\n REGISTER_KERNEL_BUILDER(Name(\"Fact\").Device(DEVICE_DEFAULT).HostMemory(\"fact\"),\n                         FactOpKernel1);\n \n-static string D(const char* s) {\n-  string ret(s);\n+static std::string D(const char* s) {\n+  std::string ret(s);\n   E(&ret);\n   return ret;\n }"
        },
        {
            "sha": "f70939295febd1aa00a5daed43d25d103698828f",
            "filename": "tensorflow/core/kernels/fingerprint_op.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 16,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffingerprint_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffingerprint_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ffingerprint_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -27,7 +27,7 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n template <typename T>\n-inline void CopyToBuffer(const T& value, uint8* output) {\n+inline void CopyToBuffer(const T& value, uint8_t* output) {\n   // Memcpy to string is endian-dependent. We choose little-endian as\n   // standard. On big-endian machines, bytes should be reversed.\n #if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__\n@@ -40,24 +40,24 @@ inline void CopyToBuffer(const T& value, uint8* output) {\n #endif\n }\n \n-void FarmhashFingerprint64(TTypes<uint8, 2>::ConstTensor input,\n-                           TTypes<uint8, 2>::Matrix output) {\n+void FarmhashFingerprint64(TTypes<uint8_t, 2>::ConstTensor input,\n+                           TTypes<uint8_t, 2>::Matrix output) {\n   DCHECK_EQ(output.dimension(0), input.dimension(0));\n-  DCHECK_EQ(output.dimension(1), sizeof(uint64));\n+  DCHECK_EQ(output.dimension(1), sizeof(uint64_t));\n   for (int64_t i = 0; i < output.dimension(0); ++i) {\n-    const uint64 fingerprint =\n+    const uint64_t fingerprint =\n         Fingerprint64({reinterpret_cast<const char*>(&input(i, 0)),\n                        static_cast<std::size_t>(input.dimension(1))});\n     CopyToBuffer(fingerprint, &output(i, 0));\n   }\n }\n \n void FarmhashFingerprint64(TTypes<tstring>::ConstFlat input,\n-                           TTypes<uint8, 2>::Matrix output) {\n+                           TTypes<uint8_t, 2>::Matrix output) {\n   DCHECK_EQ(output.dimension(0), input.dimension(0));\n-  DCHECK_EQ(output.dimension(1), sizeof(uint64));\n+  DCHECK_EQ(output.dimension(1), sizeof(uint64_t));\n   for (int64_t i = 0; i < input.dimension(0); ++i) {\n-    const uint64 fingerprint =\n+    const uint64_t fingerprint =\n         Fingerprint64({input(i).data(), input(i).size()});\n     CopyToBuffer(fingerprint, &output(i, 0));\n   }\n@@ -115,24 +115,25 @@ class FingerprintOp : public OpKernel {\n         // and each row contains the fingerprint value of corresponding string.\n         // To compute fingerprints of multiple strings, this op fingerprints the\n         // buffer containing the string fingerprints.\n-        FarmhashFingerprint64(input.flat<tstring>(), temp.tensor<uint8, 2>());\n-        FarmhashFingerprint64(static_cast<const Tensor&>(temp).shaped<uint8, 2>(\n-                                  {dim0, dim1 * kFingerprintSize}),\n-                              output->matrix<uint8>());\n+        FarmhashFingerprint64(input.flat<tstring>(), temp.tensor<uint8_t, 2>());\n+        FarmhashFingerprint64(\n+            static_cast<const Tensor&>(temp).shaped<uint8_t, 2>(\n+                {dim0, dim1 * kFingerprintSize}),\n+            output->matrix<uint8_t>());\n       } else {\n         // In case dim1 == 1, each string computes into its own fingerprint\n         // value. There is no need to fingerprint twice.\n-        FarmhashFingerprint64(input.flat<tstring>(), output->matrix<uint8>());\n+        FarmhashFingerprint64(input.flat<tstring>(), output->matrix<uint8_t>());\n       }\n     } else {\n-      auto data = input.bit_casted_shaped<uint8, 2>(\n+      auto data = input.bit_casted_shaped<uint8_t, 2>(\n           {dim0, dim1 * DataTypeSize(input.dtype())});\n-      FarmhashFingerprint64(data, output->matrix<uint8>());\n+      FarmhashFingerprint64(data, output->matrix<uint8_t>());\n     }\n   }\n \n  private:\n-  static constexpr int kFingerprintSize = sizeof(uint64);\n+  static constexpr int kFingerprintSize = sizeof(uint64_t);\n };\n \n REGISTER_KERNEL_BUILDER(Name(\"Fingerprint\").Device(tensorflow::DEVICE_CPU),"
        },
        {
            "sha": "cd52ef7f87fda383a2302cbcb8a388a082c4fbbe",
            "filename": "tensorflow/core/kernels/fractional_max_pool_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffractional_max_pool_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/64dba6a59c3d1588c7aab9e7994827eaef4b5173/tensorflow%2Fcore%2Fkernels%2Ffractional_max_pool_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ffractional_max_pool_op.cc?ref=64dba6a59c3d1588c7aab9e7994827eaef4b5173",
            "patch": "@@ -210,7 +210,7 @@ class FractionalMaxPoolOp : public OpKernel {\n       Name(\"FractionalMaxPool\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n       FractionalMaxPoolOp<type>)\n \n-REGISTER_FRACTIONALMAXPOOL(int32);\n+REGISTER_FRACTIONALMAXPOOL(int32_t);\n REGISTER_FRACTIONALMAXPOOL(int64_t);\n REGISTER_FRACTIONALMAXPOOL(float);\n REGISTER_FRACTIONALMAXPOOL(double);\n@@ -239,7 +239,7 @@ class FractionalMaxPoolGradOp : public OpKernel {\n         ConstEigenMatrixMap;\n     typedef Eigen::Map<Eigen::Matrix<T, Eigen::Dynamic, Eigen::Dynamic>>\n         EigenMatrixMap;\n-    typedef Eigen::Map<Eigen::Matrix<int64, Eigen::Dynamic, Eigen::Dynamic>>\n+    typedef Eigen::Map<Eigen::Matrix<int64_t, Eigen::Dynamic, Eigen::Dynamic>>\n         EigenIndexMatrixMap;\n \n     const Tensor& tensor_in = context->input(0);\n@@ -419,7 +419,7 @@ class FractionalMaxPoolGradOp : public OpKernel {\n                               .TypeConstraint<type>(\"T\"), \\\n                           FractionalMaxPoolGradOp<type>)\n \n-REGISTER_FRACTIONALMAXPOOLGRAD(int32);\n+REGISTER_FRACTIONALMAXPOOLGRAD(int32_t);\n REGISTER_FRACTIONALMAXPOOLGRAD(int64_t);\n REGISTER_FRACTIONALMAXPOOLGRAD(float);\n REGISTER_FRACTIONALMAXPOOLGRAD(double);"
        }
    ],
    "stats": {
        "total": 97,
        "additions": 49,
        "deletions": 48
    }
}