{
    "author": "hhb",
    "message": "Implement `LogicalDeviceOfDefaultTypeForId` for GPU / CPU\n\nPiperOrigin-RevId: 821873337",
    "sha": "0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
    "files": [
        {
            "sha": "c83a734ef638722614e36587871de74f246bc0f3",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -474,6 +474,7 @@ cc_library(\n     hdrs = [\"pjrt_compiler.h\"],\n     visibility = internal_visibility([\":friends\"]),\n     deps = [\n+        \":pjrt_common\",\n         \":pjrt_device_description\",\n         \":pjrt_device_dimensions\",\n         \":pjrt_executable\","
        },
        {
            "sha": "3b706f8949a4c06ecb41698b3b7f927a47cbbfc9",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -629,8 +629,10 @@ cc_library(\n         \":gpu_topology\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt:pjrt_compiler\",\n         \"//xla/pjrt:pjrt_device_description\",\n+        \"//xla/pjrt:pjrt_device_dimensions\",\n         \"//xla/pjrt:pjrt_stream_executor_device_description\",\n         \"//xla/stream_executor:device_description_proto_cc\",\n         \"//xla/tsl/lib/strings:proto_serialization\",\n@@ -642,6 +644,7 @@ cc_library(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@local_tsl//tsl/platform:casts\",\n     ],\n )\n \n@@ -651,9 +654,12 @@ xla_cc_test(\n     deps = [\n         \":gpu_topology\",\n         \":se_gpu_topology_description\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt:pjrt_compiler\",\n         \"//xla/pjrt:pjrt_device_description\",\n+        \"//xla/pjrt:pjrt_device_dimensions\",\n         \"//xla/pjrt:pjrt_stream_executor_device_description\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "cddb20b78de0377f8a345caa6017cd9449e67b6b",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_topology_description.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.cc?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -28,14 +28,17 @@ limitations under the License.\n #include \"xla/layout.h\"\n #include \"xla/layout_util.h\"\n #include \"xla/pjrt/gpu/gpu_topology.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/pjrt_stream_executor_device_description.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/strings/proto_serialization.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"tsl/platform/casts.h\"\n \n namespace xla {\n \n@@ -140,6 +143,29 @@ absl::StatusOr<std::string> StreamExecutorGpuTopologyDescription::Serialize()\n   return result;\n }\n \n+absl::StatusOr<std::pair<PjRtDeviceDimensions, int32_t>>\n+StreamExecutorGpuTopologyDescription::LogicalDeviceOfDefaultTypeForId(\n+    xla::PjRtGlobalDeviceId device_id) const {\n+  // TODO: b/435476605 - improve the lookup performance by adding a lookup api\n+  // in pjrt topology description.\n+  for (const auto& device_desc : DeviceDescriptions()) {\n+    if (device_desc->id() == device_id) {\n+      const auto& gpu_device_desc =\n+          tsl::down_cast<const xla::PjRtStreamExecutorDeviceDescription&>(\n+              *device_desc);\n+      const auto& coords = gpu_device_desc.coords();\n+      if (coords.size() != 3) {\n+        return absl::InvalidArgumentError(absl::StrCat(\n+            \"GPU topology must have 3 dimensions, but got \", coords.size()));\n+      }\n+      return std::make_pair(\n+          PjRtDeviceDimensions{coords[0], coords[1], coords[2]}, 0);\n+    }\n+  }\n+  return absl::NotFoundError(absl::StrCat(\"Device id \", device_id.value(),\n+                                          \" not found in GPU topology.\"));\n+}\n+\n absl::StatusOr<Layout> StreamExecutorGpuTopologyDescription::GetDefaultLayout(\n     PrimitiveType element_type, absl::Span<const int64_t> dims) const {\n   Shape shape = ShapeUtil::MakeShape(element_type, dims);"
        },
        {
            "sha": "50cdcd5b5d127ff6e2ddfeeba384e361c391c4ac",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_topology_description.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description.h?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -25,8 +25,10 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/pjrt/gpu/gpu_topology.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/pjrt_stream_executor_device_description.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -100,6 +102,10 @@ class StreamExecutorGpuTopologyDescription : public PjRtTopologyDescription {\n     return 1;\n   }\n \n+  absl::StatusOr<std::pair<PjRtDeviceDimensions, int32_t>>\n+  LogicalDeviceOfDefaultTypeForId(\n+      xla::PjRtGlobalDeviceId device_id) const override;\n+\n   absl::StatusOr<std::string> Serialize() const override;\n \n   const std::optional<stream_executor::GpuTargetConfigProto>& target_config()"
        },
        {
            "sha": "3fdc460ce501a7e93840ef4c347c44e8d4e992b5",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_topology_description_test.cc",
            "status": "modified",
            "additions": 80,
            "deletions": 0,
            "changes": 80,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_topology_description_test.cc?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -16,14 +16,18 @@ limitations under the License.\n #include \"xla/pjrt/gpu/se_gpu_topology_description.h\"\n \n #include <memory>\n+#include <utility>\n #include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"xla/pjrt/gpu/gpu_topology.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/pjrt_stream_executor_device_description.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n namespace {\n@@ -99,5 +103,81 @@ TEST(StreamExecutorGpuTopologyDescriptionTest, AsymmetricTopology) {\n   EXPECT_EQ(device_descs.size(), 0);\n }\n \n+TEST(PjRtTopologyUtilsGPUTest, GetDeviceCoords) {\n+  std::shared_ptr<xla::GpuTopology> gpu_topology =\n+      std::make_shared<xla::GpuTopology>(\n+          /*platform_version=*/\"12.3\", /*num_partitions=*/1,\n+          /*num_hosts_per_partition=*/1, /*num_devices_per_host=*/4);\n+  StreamExecutorGpuTopologyDescription topology_desc(\n+      xla::CudaId(), xla::CudaName(), gpu_topology);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(1)));\n+  auto [device_coords, core_id] = std::move(device_core);\n+  ASSERT_EQ(device_coords, (PjRtDeviceDimensions{0, 0, 1}));\n+  ASSERT_EQ(core_id, 0);\n+}\n+\n+TEST(PjRtTopologyUtilsGPUTest, GetDeviceCoordsSingleHostScopedPartition) {\n+  std::shared_ptr<xla::GpuTopology> gpu_topology =\n+      std::make_shared<xla::GpuTopology>(\n+          /*platform_version=*/\"12.3\", /*num_partitions=*/4,\n+          /*num_hosts_per_partition=*/1, /*num_devices_per_host=*/4);\n+  StreamExecutorGpuTopologyDescription topology_desc(\n+      xla::CudaId(), xla::CudaName(), gpu_topology);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core1,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(1)));\n+  auto [device_coords1, core_id1] = std::move(device_core1);\n+  ASSERT_EQ(device_coords1, (PjRtDeviceDimensions{0, 0, 1}));\n+  ASSERT_EQ(core_id1, 0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core2,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(6)));\n+  auto [device_coords2, core_id2] = std::move(device_core2);\n+  ASSERT_EQ(device_coords2, (PjRtDeviceDimensions{1, 0, 2}));\n+  ASSERT_EQ(core_id2, 0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core3,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(10)));\n+  auto [device_coords3, core_id3] = std::move(device_core3);\n+  ASSERT_EQ(device_coords3, (PjRtDeviceDimensions{2, 0, 2}));\n+  ASSERT_EQ(core_id3, 0);\n+}\n+\n+TEST(PjRtTopologyUtilsGPUTest, GetDeviceCoordsMultipleHostScopedPartition) {\n+  std::shared_ptr<xla::GpuTopology> gpu_topology =\n+      std::make_shared<xla::GpuTopology>(\n+          /*platform_version=*/\"12.3\", /*num_partitions=*/1,\n+          /*num_hosts_per_partition=*/4, /*num_devices_per_host=*/4);\n+  StreamExecutorGpuTopologyDescription topology_desc(\n+      xla::CudaId(), xla::CudaName(), gpu_topology);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core1,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(1)));\n+  auto [device_coords1, core_id1] = std::move(device_core1);\n+  ASSERT_EQ(device_coords1, (PjRtDeviceDimensions{0, 0, 1}));\n+  ASSERT_EQ(core_id1, 0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core2,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(6)));\n+  auto [device_coords2, core_id2] = std::move(device_core2);\n+  ASSERT_EQ(device_coords2, (PjRtDeviceDimensions{0, 1, 2}));\n+  ASSERT_EQ(core_id2, 0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto device_core3,\n+                          topology_desc.LogicalDeviceOfDefaultTypeForId(\n+                              xla::PjRtGlobalDeviceId(10)));\n+  auto [device_coords3, core_id3] = std::move(device_core3);\n+  ASSERT_EQ(device_coords3, (PjRtDeviceDimensions{0, 2, 2}));\n+  ASSERT_EQ(core_id3, 0);\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "333f567be124ae0bdf3d7c94eee091a4b52e208e",
            "filename": "third_party/xla/xla/pjrt/pjrt_compiler.h",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_compiler.h?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n #include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n@@ -156,16 +157,17 @@ class PjRtTopologyDescription {\n \n   // Returns a unique integer ID for the logical device of the default type on\n   // the chip at the given coordinates and with the given core index.\n-  virtual absl::StatusOr<int32_t> IdForLogicalDeviceOfDefaultType(\n-      const PjRtDeviceDimensions& chip, int core_index) const {\n+  virtual absl::StatusOr<xla::PjRtGlobalDeviceId>\n+  IdForLogicalDeviceOfDefaultType(const PjRtDeviceDimensions& chip,\n+                                  int core_index) const {\n     return absl::UnimplementedError(\n         \"IdForLogicalDeviceOfDefaultType is unsupported.\");\n   }\n \n   // Returns the chip coordinates and core index of the logical device of the\n   // default type for the given unique device ID.\n   virtual absl::StatusOr<std::pair<PjRtDeviceDimensions, int32_t>>\n-  LogicalDeviceOfDefaultTypeForId(int device_id) const {\n+  LogicalDeviceOfDefaultTypeForId(xla::PjRtGlobalDeviceId device_id) const {\n     return absl::UnimplementedError(\n         \"LogicalDeviceCoordsOfDefaultTypeForId is unsupported.\");\n   }"
        },
        {
            "sha": "3a8e4e0c984d222985176ea97da489cceec69821",
            "filename": "third_party/xla/xla/pjrt/pjrt_device_dimensions.h",
            "status": "modified",
            "additions": 17,
            "deletions": 1,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions.h?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -34,13 +34,24 @@ namespace xla {\n // Represents device dimensions (e.g., mesh bounds or chip coordinates).\n class PjRtDeviceDimensions {\n  public:\n+  using DimensionsContainer = absl::InlinedVector<int32_t, 4>;\n+  using iterator = DimensionsContainer::iterator;\n+  using const_iterator = DimensionsContainer::const_iterator;\n+\n   PjRtDeviceDimensions() = default;\n   PjRtDeviceDimensions(std::initializer_list<int32_t> dims)\n       : dimensions_(dims) {}\n   explicit PjRtDeviceDimensions(absl::Span<const int32_t> dims)\n       : dimensions_(dims.begin(), dims.end()) {}\n \n   int32_t& operator[](size_t i) { return dimensions_[i]; }\n+\n+  iterator begin() { return dimensions_.begin(); }\n+  const_iterator begin() const { return dimensions_.begin(); }\n+\n+  iterator end() { return dimensions_.end(); }\n+  const_iterator end() const { return dimensions_.end(); }\n+\n   const int32_t& operator[](size_t i) const { return dimensions_[i]; }\n \n   size_t size() const { return dimensions_.size(); }\n@@ -55,6 +66,11 @@ class PjRtDeviceDimensions {\n     return !(a == b);\n   }\n \n+  friend bool operator<(const PjRtDeviceDimensions& a,\n+                        const PjRtDeviceDimensions& b) {\n+    return a.dimensions_ < b.dimensions_;\n+  }\n+\n   friend std::ostream& operator<<(std::ostream& os,\n                                   const PjRtDeviceDimensions& d) {\n     return os << d.ToString();\n@@ -78,7 +94,7 @@ class PjRtDeviceDimensions {\n       absl::string_view text);\n \n  private:\n-  absl::InlinedVector<int32_t, 3> dimensions_;\n+  DimensionsContainer dimensions_;\n };\n \n // Support for absl flags."
        },
        {
            "sha": "d9151caaf449a9fe8228d2198608da774fc8385a",
            "filename": "third_party/xla/xla/pjrt/pjrt_device_dimensions_test.cc",
            "status": "modified",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_device_dimensions_test.cc?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -34,6 +34,30 @@ TEST(PjRtDeviceDimensionsTest, Equality) {\n   EXPECT_NE((PjRtDeviceDimensions{1, 2, 3}), (PjRtDeviceDimensions{1, 2, 4}));\n }\n \n+TEST(PjRtDeviceDimensionsTest, LessThan) {\n+  // Same size comparisons\n+  EXPECT_TRUE((PjRtDeviceDimensions{1, 2, 3}) <\n+              (PjRtDeviceDimensions{1, 2, 4}));\n+  EXPECT_TRUE((PjRtDeviceDimensions{1, 2, 3}) <\n+              (PjRtDeviceDimensions{1, 3, 0}));\n+  EXPECT_TRUE((PjRtDeviceDimensions{1, 2, 3}) <\n+              (PjRtDeviceDimensions{2, 0, 0}));\n+  EXPECT_FALSE((PjRtDeviceDimensions{1, 2, 3}) <\n+               (PjRtDeviceDimensions{1, 2, 3}));\n+  EXPECT_FALSE((PjRtDeviceDimensions{1, 2, 4}) <\n+               (PjRtDeviceDimensions{1, 2, 3}));\n+\n+  // Different size comparisons (shorter is less than longer if prefixes match)\n+  EXPECT_TRUE((PjRtDeviceDimensions{1, 2}) < (PjRtDeviceDimensions{1, 2, 3}));\n+  EXPECT_FALSE((PjRtDeviceDimensions{1, 2, 3}) < (PjRtDeviceDimensions{1, 2}));\n+  EXPECT_TRUE((PjRtDeviceDimensions{}) < (PjRtDeviceDimensions{1}));\n+  EXPECT_FALSE((PjRtDeviceDimensions{1}) < (PjRtDeviceDimensions{}));\n+\n+  // Different size comparisons with different prefixes\n+  EXPECT_TRUE((PjRtDeviceDimensions{1, 1}) < (PjRtDeviceDimensions{1, 2, 3}));\n+  EXPECT_TRUE((PjRtDeviceDimensions{0, 2}) < (PjRtDeviceDimensions{1, 2, 3}));\n+}\n+\n TEST(PjRtDeviceDimensionsTest, Ostream) {\n   std::stringstream ss;\n   ss << PjRtDeviceDimensions{1, 2, 3};\n@@ -105,6 +129,21 @@ TEST(AbslUnparseFlagTest, ConvertsCorrectly) {\n   EXPECT_EQ(AbslUnparseFlag(PjRtDeviceDimensions{0, 0, 0}), \"0,0,0\");\n }\n \n+TEST(PjRtDeviceDimensionsTest, Iterator) {\n+  const PjRtDeviceDimensions const_dims = {4, 5, 6};\n+  int i = 4;\n+  for (int d : const_dims) {\n+    EXPECT_EQ(d, i);\n+    i++;\n+  }\n+\n+  PjRtDeviceDimensions mutable_dims = {7, 8, 9};\n+  for (int& d : mutable_dims) {\n+    d *= 2;\n+  }\n+  EXPECT_EQ(mutable_dims, (PjRtDeviceDimensions{14, 16, 18}));\n+}\n+\n TEST(PjRtDeviceDimensionsTest, SubscriptAccess) {\n   PjRtDeviceDimensions dims = {10, 20, 30};\n   EXPECT_EQ(dims[0], 10);"
        },
        {
            "sha": "88803d710d2aaa7973308a9525dc188ba2bd217f",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2FBUILD?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -81,8 +81,10 @@ cc_library(\n         \":cpu_topology\",\n         \"//xla:shape_util\",\n         \"//xla/pjrt:pjrt_client\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt:pjrt_compiler\",\n         \"//xla/pjrt:pjrt_device_description\",\n+        \"//xla/pjrt:pjrt_device_dimensions\",\n         \"//xla/tsl/lib/strings:proto_serialization\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/status\",\n@@ -115,9 +117,10 @@ xla_cc_test(\n     deps = [\n         \":cpu_topology\",\n         \":cpu_topology_description\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt:pjrt_compiler\",\n+        \"//xla/pjrt:pjrt_device_dimensions\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "3556cccd396d1f73c140acdceb5eef183b0bd209",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/cpu_topology_description.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.cc?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <cstdint>\n #include <memory>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/status/status.h\"\n@@ -27,8 +28,10 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/layout.h\"\n #include \"xla/layout_util.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_device_description.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology.h\"\n #include \"xla/shape.h\"\n@@ -51,6 +54,12 @@ absl::StatusOr<std::string> CpuTopologyDescription::Serialize() const {\n   return result;\n }\n \n+absl::StatusOr<std::pair<PjRtDeviceDimensions, int32_t>>\n+CpuTopologyDescription::LogicalDeviceOfDefaultTypeForId(\n+    xla::PjRtGlobalDeviceId device_id) const {\n+  return std::make_pair(PjRtDeviceDimensions{0, 0, device_id.value()}, 0);\n+}\n+\n std::vector<std::unique_ptr<const PjRtDeviceDescription>>\n CpuTopologyDescription::DeviceDescriptions() const {\n   std::vector<std::unique_ptr<const PjRtDeviceDescription>> devices;"
        },
        {
            "sha": "0aa6531ad2511716a669491bdf63043759c49b9e",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/cpu_topology_description.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description.h?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology.h\"\n \n namespace xla {\n@@ -97,6 +98,10 @@ class CpuTopologyDescription : public PjRtTopologyDescription {\n \n   absl::StatusOr<std::string> Serialize() const override;\n \n+  absl::StatusOr<std::pair<PjRtDeviceDimensions, int32_t>>\n+  LogicalDeviceOfDefaultTypeForId(\n+      xla::PjRtGlobalDeviceId device_id) const override;\n+\n   // Returns vendor specific attributes about the topology.\n   const absl::flat_hash_map<std::string, PjRtDeviceAttribute>& Attributes()\n       const override {"
        },
        {
            "sha": "ec833919529bd78ca811b1bcc35a81fc384da12e",
            "filename": "third_party/xla/xla/pjrt/plugin/xla_cpu/cpu_topology_description_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0e15b80eb6dc6c310139e6b7cb1c8d519665a17d/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fplugin%2Fxla_cpu%2Fcpu_topology_description_test.cc?ref=0e15b80eb6dc6c310139e6b7cb1c8d519665a17d",
            "patch": "@@ -17,11 +17,14 @@ limitations under the License.\n \n #include <memory>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n+#include \"xla/pjrt/pjrt_device_dimensions.h\"\n #include \"xla/pjrt/plugin/xla_cpu/cpu_topology.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n@@ -100,5 +103,18 @@ TEST(CpuTopologyDescriptionTest, FromProto) {\n               ElementsAre(\"attrA\", \"attrB\"));\n }\n \n+TEST(CpuTopologyDescriptionTest, LogicalDeviceOfDefaultTypeForId) {\n+  std::vector<CpuTopology::CpuDevice> cpu_devices = {{0, 0}, {0, 1}};\n+  std::vector<std::string> machine_attributes = {\"attr1\", \"attr2\"};\n+  CpuTopologyDescription topology(xla::CpuId(), \"cpu\", \"1.0\", cpu_devices,\n+                                  machine_attributes);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto device_core,\n+      topology.LogicalDeviceOfDefaultTypeForId(xla::PjRtGlobalDeviceId(1)));\n+  auto [device_coords, core_id] = std::move(device_core);\n+  ASSERT_EQ(device_coords, (PjRtDeviceDimensions{0, 0, 1}));\n+  ASSERT_EQ(core_id, 0);\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 219,
        "additions": 214,
        "deletions": 5
    }
}