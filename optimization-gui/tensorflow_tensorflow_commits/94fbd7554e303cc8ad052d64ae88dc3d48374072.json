{
    "author": "tensorflower-gardener",
    "message": "Reverts fb52ce82754d7ddd0b2d89ae490bed0bde127a4a\n\nPiperOrigin-RevId: 820748684",
    "sha": "94fbd7554e303cc8ad052d64ae88dc3d48374072",
    "files": [
        {
            "sha": "a8dedd0e40997a91e3e0c4a8a3cd741df35108a8",
            "filename": "tensorflow/compiler/aot/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2FBUILD?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -119,20 +119,20 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//llvm:Target\",\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:debug_options_flags\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:status_macros\",\n         \"@local_xla//xla:util\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n-        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n-        \"@local_xla//xla/backends/cpu:buffer_allocation_info_util\",\n         \"@local_xla//xla/backends/cpu/codegen:symbol_name_util\",\n         \"@local_xla//xla/backends/cpu/runtime:thunk_proto_cc\",\n         \"@local_xla//xla/backends/cpu/runtime:thunk_proto_serdes\",\n         \"@local_xla//xla/client:client_library\",\n         \"@local_xla//xla/client:compile_only_client\",\n         \"@local_xla//xla/hlo/builder:xla_computation\",\n         \"@local_xla//xla/service:compiler\",\n+        \"@local_xla//xla/service/cpu:buffer_info_util\",\n         \"@local_xla//xla/service/cpu:cpu_aot_compilation_result\",\n         \"@local_xla//xla/service/cpu:cpu_compiler\",\n         \"@local_xla//xla/service/cpu:cpu_executable\",\n@@ -155,6 +155,7 @@ tf_cc_test(\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Support\",  # fixdeps: keep\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla/service/cpu:cpu_aot_compilation_result\",\n     ] + if_llvm_x86_available(["
        },
        {
            "sha": "054a7fdde77bd98cb8c67e3c29e3a670cfb21bc1",
            "filename": "tensorflow/compiler/aot/codegen.cc",
            "status": "modified",
            "additions": 62,
            "deletions": 64,
            "changes": 126,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -44,11 +44,11 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/allocator.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla_util.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info_util.h\"\n #include \"xla/backends/cpu/runtime/thunk.pb.h\"\n #include \"xla/backends/cpu/runtime/thunk_proto_serdes.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"xla/debug_options_flags.h\"\n+#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/shape.h\"\n@@ -65,7 +65,7 @@ namespace tfcompile {\n \n namespace {\n \n-using xla::cpu::BufferAllocationInfo;\n+using BufferInfo = xla::cpu_function_runtime::BufferInfo;\n \n bool IsAlpha(char c) {\n   return (c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z');\n@@ -117,36 +117,33 @@ absl::Status XLATypeToCpp(xla::PrimitiveType type, string* str) {\n }\n \n // Returns the sum of the size of each buffer in `buffer_infos`.\n-size_t TotalBufferBytes(absl::Span<const BufferAllocationInfo> buffer_infos) {\n-  return std::accumulate(\n-      buffer_infos.begin(), buffer_infos.end(), size_t{0},\n-      [](size_t size, const BufferAllocationInfo& buffer_info) {\n-        return size + buffer_info.size();\n-      });\n+size_t TotalBufferBytes(const std::vector<BufferInfo>& buffer_infos) {\n+  return std::accumulate(buffer_infos.begin(), buffer_infos.end(), size_t{0},\n+                         [](size_t size, const BufferInfo& buffer_info) {\n+                           return size + buffer_info.size();\n+                         });\n }\n \n-// Returns a vector of BufferAllocationInfo instances in `buffer_infos` that are\n-// entry parameter buffers.\n-std::vector<BufferAllocationInfo> ExtractEntryParamBufferAllocationInfos(\n-    absl::Span<const BufferAllocationInfo> buffer_infos) {\n-  std::vector<BufferAllocationInfo> result;\n+// Returns a vector of BufferInfo instances in `buffer_infos` that are entry\n+// parameter buffers.\n+std::vector<BufferInfo> ExtractEntryParamBufferInfos(\n+    const std::vector<BufferInfo>& buffer_infos) {\n+  std::vector<BufferInfo> result;\n   std::copy_if(buffer_infos.begin(), buffer_infos.end(),\n-               std::back_inserter(result),\n-               [](const BufferAllocationInfo& buffer_info) {\n+               std::back_inserter(result), [](const BufferInfo& buffer_info) {\n                  return buffer_info.is_entry_parameter();\n                });\n   return result;\n }\n \n-// Returns a vector of BufferAllocationInfo instances in `buffer_infos` that are\n-// temp buffers.\n-std::vector<BufferAllocationInfo> ExtractTempBufferAllocationInfos(\n-    absl::Span<const BufferAllocationInfo> buffer_infos) {\n-  std::vector<BufferAllocationInfo> result;\n+// Returns a vector of BufferInfo instances in `buffer_infos` that are temp\n+// buffers.\n+std::vector<BufferInfo> ExtractTempBufferInfos(\n+    const std::vector<BufferInfo>& buffer_infos) {\n+  std::vector<BufferInfo> result;\n   std::copy_if(buffer_infos.begin(), buffer_infos.end(),\n-               std::back_inserter(result),\n-               [](const BufferAllocationInfo& buffer_info) {\n-                 return buffer_info.is_temp();\n+               std::back_inserter(result), [](const BufferInfo& buffer_info) {\n+                 return buffer_info.is_temp_buffer();\n                });\n   return result;\n }\n@@ -474,24 +471,25 @@ absl::Status ValidateFeedFetchCppNames(const tf2xla::Config& config) {\n }\n \n // Returns a list of C++ expressions that, when executed, will construct the\n-// BufferAllocationInfo instances in `buffer_infos`.\n-std::vector<string> BufferAllocationInfosToCppExpression(\n-    absl::Span<const BufferAllocationInfo> buffer_infos) {\n+// BufferInfo instances in `buffer_infos`.\n+std::vector<string> BufferInfosToCppExpression(\n+    const std::vector<BufferInfo>& buffer_infos) {\n   std::vector<string> buffer_infos_as_strings;\n-  absl::c_transform(buffer_infos, std::back_inserter(buffer_infos_as_strings),\n-                    [](const BufferAllocationInfo& buffer_info) {\n-                      xla::cpu::BufferAllocationInfo::Encoded encoded =\n-                          buffer_info.Encode();\n-                      auto param_to_str = [](uint32_t param) -> std::string {\n-                        return param == ~0U ? \"~0U\" : absl::StrCat(param, \"U\");\n-                      };\n-                      return absl::StrCat(\n-                          \"::xla::cpu::BufferAllocationInfo(\"\n-                          \"::xla::cpu::BufferAllocationInfo::Encoded{\",\n-                          encoded.packed_kind_and_size, \"ULL, \",\n-                          param_to_str(encoded.entry_param_number), \", \",\n-                          param_to_str(encoded.result_number), \"})\");\n-                    });\n+  std::transform(buffer_infos.begin(), buffer_infos.end(),\n+                 std::back_inserter(buffer_infos_as_strings),\n+                 [](const BufferInfo& buffer_info) {\n+                   xla::cpu_function_runtime::EncodedBufferInfo encoded =\n+                       buffer_info.Encode();\n+                   auto param_to_str = [](uint32_t param) -> std::string {\n+                     return param == ~0U ? \"~0U\" : absl::StrCat(param, \"U\");\n+                   };\n+                   return absl::StrCat(\n+                       \"::xla::cpu_function_runtime::BufferInfo(\"\n+                       \"::xla::cpu_function_runtime::EncodedBufferInfo{\",\n+                       encoded.packed_kind_and_size, \"ULL, \",\n+                       param_to_str(encoded.entry_param_number), \", \",\n+                       param_to_str(encoded.result_param_number), \"})\");\n+                 });\n   return buffer_infos_as_strings;\n }\n \n@@ -661,8 +659,8 @@ absl::Status ExtendRewrites(\n       const std::string function_declarations_from_obj_files,\n       GenFunctionDeclarations(absl::MakeSpan(entry_point_symbols)));\n \n-  int64_t buffer_infos_size = aot_thunks->buffer_allocation_infos().size();\n-  std::optional<size_t> temp_allocation_index =\n+  const int64_t buffer_infos_size = aot_thunks->buffer_infos().size();\n+  const std::optional<size_t> temp_allocation_index =\n       aot_thunks->temp_allocation_index();\n   if (temp_allocation_index.has_value() &&\n       (*temp_allocation_index < 0 ||\n@@ -840,21 +838,21 @@ absl::Status GenerateHeader(\n   TF_RETURN_IF_ERROR(ValidateConfig(config));\n   TF_RETURN_IF_ERROR(ValidateFeedFetchCppNames(config));\n \n-  absl::Span<const BufferAllocationInfo> buffer_infos =\n-      compile_result.aot->buffer_allocation_infos();\n+  const std::vector<BufferInfo>& buffer_infos =\n+      compile_result.aot->buffer_infos();\n \n   const std::vector<int32> arg_index_table =\n-      ::xla::cpu::CreateArgIndexTable(buffer_infos);\n+      ::xla::cpu::CreateArgIndexTableFromBufferInfos(buffer_infos);\n   const std::vector<int32> result_index_table =\n-      ::xla::cpu::CreateResultIndexTable(buffer_infos);\n+      ::xla::cpu::CreateResultIndexTableFromBufferInfos(buffer_infos);\n   std::vector<string> buffer_infos_as_strings =\n-      BufferAllocationInfosToCppExpression(buffer_infos);\n+      BufferInfosToCppExpression(buffer_infos);\n \n   // Compute sizes and generate methods.\n-  std::vector<BufferAllocationInfo> buffer_infos_for_args =\n-      ExtractEntryParamBufferAllocationInfos(buffer_infos);\n-  std::vector<BufferAllocationInfo> buffer_infos_for_temps =\n-      ExtractTempBufferAllocationInfos(buffer_infos);\n+  std::vector<BufferInfo> buffer_infos_for_args =\n+      ExtractEntryParamBufferInfos(buffer_infos);\n+  std::vector<BufferInfo> buffer_infos_for_temps =\n+      ExtractTempBufferInfos(buffer_infos);\n   const xla::ProgramShapeProto& ps = compile_result.program_shape;\n   string methods_arg, methods_result, methods_variable;\n   TF_RETURN_IF_ERROR(GenArgMethods(config, ps, compile_result, &methods_arg));\n@@ -870,13 +868,13 @@ absl::Status GenerateHeader(\n       CheckEqual(ps.result().tuple_shapes_size(), result_index_table.size(),\n                  \"Result number mismatch, proto vs. result_index_table\"));\n   TF_ASSIGN_OR_RETURN(auto program_shape, xla::ProgramShape::FromProto(ps));\n-  const size_t arg_bytes_aligned =\n-      tensorflow::AlignedBufferBytes(buffer_infos_for_args,\n-                                     /*allocate_entry_params=*/true);\n+  const size_t arg_bytes_aligned = tensorflow::AlignedBufferBytes(\n+      buffer_infos_for_args.data(), buffer_infos_for_args.size(),\n+      /*allocate_entry_params=*/true);\n   const size_t arg_bytes_total = TotalBufferBytes(buffer_infos_for_args);\n-  const size_t temp_bytes_aligned =\n-      tensorflow::AlignedBufferBytes(buffer_infos_for_temps,\n-                                     /*allocate_entry_params=*/true);\n+  const size_t temp_bytes_aligned = tensorflow::AlignedBufferBytes(\n+      buffer_infos_for_temps.data(), buffer_infos_for_temps.size(),\n+      /*allocate_entry_params=*/true);\n   const size_t temp_bytes_total = TotalBufferBytes(buffer_infos_for_temps);\n \n   // Create rewrite strings for namespace start and end.\n@@ -982,7 +980,7 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n \n   // Byte size of each argument buffer. There are kNumArgs entries.\n   static const ::int64_t ArgSize(::tensorflow::int32 index) {\n-    return BufferAllocationInfos()[ArgIndexToBufferIndex()[index]].size();\n+    return BufferInfos()[ArgIndexToBufferIndex()[index]].size();\n   }\n \n   // Returns static data used to create an XlaCompiledCpuFunction.\n@@ -991,7 +989,7 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n       XlaCompiledCpuFunction::StaticData* data =\n         new XlaCompiledCpuFunction::StaticData;\n       set_static_data_function_library_symbol_map(data, FunctionLibrarySymbolMap());\n-      set_static_data_buffer_infos(data, BufferAllocationInfos());\n+      set_static_data_buffer_infos(data, BufferInfos());\n       set_static_data_num_buffers(data, kNumBuffers);\n       set_static_data_result_index_table(data, ResultIndexToBufferIndex());\n       set_static_data_num_results(data, kNumResults);\n@@ -1083,12 +1081,12 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n   // Number of buffers for the compiled computation.\n   static constexpr size_t kNumBuffers = {{NUM_BUFFERS}};\n \n-  static const ::xla::cpu::BufferAllocationInfo* BufferAllocationInfos() {\n-    static const ::xla::cpu::BufferAllocationInfo\n-      kBufferAllocationInfos[kNumBuffers] = {\n+  static const ::xla::cpu_function_runtime::BufferInfo* BufferInfos() {\n+    static const ::xla::cpu_function_runtime::BufferInfo\n+      kBufferInfos[kNumBuffers] = {\n {{BUFFER_INFOS_AS_STRING}}\n       };\n-    return kBufferAllocationInfos;\n+    return kBufferInfos;\n   }\n \n   static const ::tensorflow::int32* ResultIndexToBufferIndex() {"
        },
        {
            "sha": "afa5a86af9ef47c4959871eae6b3a96d4f1b5572",
            "filename": "tensorflow/compiler/aot/codegen_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"llvm/Support/TargetSelect.h\"\n #include \"tensorflow/compiler/aot/compile.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/shape_util.h\"\n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n@@ -39,7 +40,7 @@ namespace tensorflow {\n namespace tfcompile {\n namespace {\n \n-using ::xla::cpu::BufferAllocationInfo;\n+using ::xla::cpu_function_runtime::BufferInfo;\n \n void ExpectErrorContains(const absl::Status& status, absl::string_view str) {\n   EXPECT_NE(absl::OkStatus(), status);"
        },
        {
            "sha": "2596317806786ce65b674db763770f3e4812a54b",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -406,9 +406,8 @@ cc_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"@com_google_absl//absl/base:dynamic_annotations\",\n-        \"@com_google_absl//absl/types:span\",\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n-        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n     ],\n )\n \n@@ -420,8 +419,8 @@ tf_cc_test(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:test\",\n         \"//tensorflow/core:test_main\",\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n-        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n     ],\n )\n \n@@ -432,15 +431,14 @@ cc_library(\n     compatible_with = get_compatible_with_portable(),\n     visibility = [\"//visibility:public\"],\n     deps = [\n-        # Keep dependencies to a minimum here; this library is used in every AOT\n-        # binary produced by tfcompile.\n         \":allocator\",\n         \"@com_google_absl//absl/log:check\",\n-        \"@com_google_absl//absl/types:span\",\n         \"@local_xla//xla/service:custom_call_status_internal\",\n+        # Keep dependencies to a minimum here; this library is used in every AOT\n+        # binary produced by tfcompile.\n         \"@local_xla//xla/backends/cpu/runtime:rng_state_lib\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n-        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:executable_run_options\",\n         \"//tensorflow/core/platform:types\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -515,6 +513,7 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:casts\",\n+        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n         \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n@@ -531,6 +530,7 @@ cc_library(\n     ] + if_libtpu(\n         if_false = [\n             \"@local_xla//xla/service:cpu_plugin\",\n+            \"@local_xla//xla/service/cpu:buffer_info_util\",\n             \"@local_xla//xla/service/cpu:cpu_executable\",\n         ],\n         if_true = [],"
        },
        {
            "sha": "7f7c3a351bbe8714fe4f569d8731b64da7b83334",
            "filename": "tensorflow/compiler/tf2xla/allocator.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 13,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -20,9 +20,8 @@ limitations under the License.\n #include <cstdlib>\n \n #include \"absl/base/dynamic_annotations.h\"\n-#include \"absl/types/span.h\"\n #include \"xla/backends/cpu/alignment.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/cpu_function_runtime.h\"\n \n namespace tensorflow {\n \n@@ -65,26 +64,26 @@ size_t align_to(size_t n, size_t align) {\n }  // namespace\n \n size_t AlignedBufferBytes(\n-    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n+    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n     bool allocate_entry_params) {\n   size_t total = 0;\n-  for (size_t i = 0; i < buffers.size(); ++i) {\n+  for (size_t i = 0; i < n; ++i) {\n     bool should_allocate =\n-        buffers[i].is_temp() || buffers[i].is_result() ||\n-        (buffers[i].is_entry_parameter() && allocate_entry_params);\n+        buffer_infos[i].is_temp_buffer() ||\n+        (buffer_infos[i].is_entry_parameter() && allocate_entry_params);\n \n     if (should_allocate) {\n-      total += align_to(buffers[i].size(), xla::cpu::Align());\n+      total += align_to(buffer_infos[i].size(), xla::cpu::Align());\n     }\n   }\n   return total;\n }\n \n void* MallocContiguousBuffers(\n-    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n+    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n     bool allocate_entry_params, void** bufs, bool annotate_initialized) {\n   const size_t total =\n-      tensorflow::AlignedBufferBytes(buffers, allocate_entry_params);\n+      tensorflow::AlignedBufferBytes(buffer_infos, n, allocate_entry_params);\n   void* contiguous = nullptr;\n   if (total > 0) {\n     contiguous = aligned_malloc(total, xla::cpu::Align());\n@@ -95,13 +94,13 @@ void* MallocContiguousBuffers(\n     }\n   }\n   uintptr_t pos = reinterpret_cast<uintptr_t>(contiguous);\n-  for (size_t i = 0; i < buffers.size(); ++i) {\n+  for (size_t i = 0; i < n; ++i) {\n     bool should_allocate =\n-        buffers[i].is_temp() || buffers[i].is_result() ||\n-        (buffers[i].is_entry_parameter() && allocate_entry_params);\n+        buffer_infos[i].is_temp_buffer() ||\n+        (buffer_infos[i].is_entry_parameter() && allocate_entry_params);\n     if (should_allocate) {\n       bufs[i] = reinterpret_cast<void*>(pos);\n-      pos += align_to(buffers[i].size(), xla::cpu::Align());\n+      pos += align_to(buffer_infos[i].size(), xla::cpu::Align());\n     } else {\n       bufs[i] = nullptr;\n     }"
        },
        {
            "sha": "4ed60e4cb65535835e5dcb9d72e6a28592e39263",
            "filename": "tensorflow/compiler/tf2xla/allocator.h",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -18,8 +18,7 @@ limitations under the License.\n \n #include <cstddef>\n \n-#include \"absl/types/span.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/cpu_function_runtime.h\"\n \n namespace tensorflow {\n \n@@ -28,7 +27,7 @@ namespace tensorflow {\n // allocate_entry_params is false, entry parameters.  There are `n` entries in\n // `buffer_infos`.  Each buffer is aligned to Align() byte boundaries.\n size_t AlignedBufferBytes(\n-    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n+    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n     bool allocate_entry_params);\n \n // MallocContiguousBuffers allocates buffers for use by the entry point\n@@ -44,7 +43,7 @@ size_t AlignedBufferBytes(\n // the head of the allocated contiguous block, which should be passed to\n // FreeContiguous when the buffers are no longer in use.\n void* MallocContiguousBuffers(\n-    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n+    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n     bool allocate_entry_params, void** bufs, bool annotate_initialized);\n \n // FreeContiguous frees the contiguous block of memory allocated by"
        },
        {
            "sha": "3e331180a8d5ab1bc33bf43e7f42e46b22b5957e",
            "filename": "tensorflow/compiler/tf2xla/allocator_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 21,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -22,14 +22,14 @@ limitations under the License.\n #include <vector>\n \n #include \"xla/backends/cpu/alignment.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"tensorflow/core/framework/allocator.h\"\n #include \"tensorflow/core/platform/test.h\"\n \n namespace tensorflow {\n namespace {\n \n-using ::xla::cpu::BufferAllocationInfo;\n+using ::xla::cpu_function_runtime::BufferInfo;\n \n TEST(AllocatorTest, AlignmentValue) {\n   // We've chosen 64 byte alignment for the tfcompile runtime to mimic the\n@@ -41,36 +41,33 @@ TEST(AllocatorTest, AlignmentValue) {\n   EXPECT_LE(xla::cpu::MinAlign(), Allocator::kAllocatorAlignment);\n }\n \n-std::vector<BufferAllocationInfo> SizesToBufferAllocationInfos(\n-    const intptr_t* sizes, size_t n) {\n-  std::vector<BufferAllocationInfo> buffer_infos;\n-  std::transform(\n-      sizes, sizes + n, std::back_inserter(buffer_infos), [&](intptr_t size) {\n-        if (size == -1) {\n-          // Use a dummy on-stack buffer allocation to indicate the\n-          // the current slot does not need an allocation.\n-          int64_t on_stack_buffer_size = 4;\n-          return BufferAllocationInfo::ThreadLocal(on_stack_buffer_size);\n-        }\n-        return BufferAllocationInfo::Temp(size);\n-      });\n+std::vector<BufferInfo> SizesToBufferInfos(const intptr_t* sizes, size_t n) {\n+  std::vector<BufferInfo> buffer_infos;\n+  std::transform(sizes, sizes + n, std::back_inserter(buffer_infos),\n+                 [&](intptr_t size) {\n+                   if (size == -1) {\n+                     // Use a dummy on-stack buffer allocation to indicate the\n+                     // the current slot does not need an allocation.\n+                     int64_t on_stack_buffer_size = 4;\n+                     return BufferInfo::MakeOnStackBuffer(on_stack_buffer_size);\n+                   }\n+                   return BufferInfo::MakeTempBuffer(size);\n+                 });\n   return buffer_infos;\n }\n \n // Simple wrappers to make writing tests more ergonomic.\n \n size_t AlignedBufferBytesFromSizes(const intptr_t* sizes, size_t n) {\n-  std::vector<BufferAllocationInfo> buffer_infos =\n-      SizesToBufferAllocationInfos(sizes, n);\n-  return tensorflow::AlignedBufferBytes(buffer_infos,\n+  std::vector<BufferInfo> buffer_infos = SizesToBufferInfos(sizes, n);\n+  return tensorflow::AlignedBufferBytes(buffer_infos.data(), n,\n                                         /*allocate_entry_params=*/false);\n }\n \n void* MallocContiguousBuffersFromSizes(const intptr_t* sizes, size_t n,\n                                        void** bufs, bool annotate_initialized) {\n-  std::vector<BufferAllocationInfo> buffer_infos =\n-      SizesToBufferAllocationInfos(sizes, n);\n-  return tensorflow::MallocContiguousBuffers(buffer_infos,\n+  std::vector<BufferInfo> buffer_infos = SizesToBufferInfos(sizes, n);\n+  return tensorflow::MallocContiguousBuffers(buffer_infos.data(), n,\n                                              /*allocate_entry_params=*/false,\n                                              bufs, annotate_initialized);\n }"
        },
        {
            "sha": "4603bbf119a8bfeae9fa32799fb45cb199d55993",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -25,9 +25,9 @@ limitations under the License.\n \n #include \"absl/log/check.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n #include \"tensorflow/compiler/tf2xla/allocator.h\"\n #include \"xla/backends/cpu/runtime/rng_state_lib.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"tensorflow/core/platform/types.h\"\n \n namespace tensorflow {\n@@ -72,7 +72,7 @@ XlaCompiledCpuFunction::XlaCompiledCpuFunction(const StaticData& static_data,\n       alloc_mode == AllocMode::ARGS_VARIABLES_RESULTS_PROFILES_AND_TEMPS;\n   // Allocate arg and temp buffers.\n   alloc_buffer_table_ = tensorflow::MallocContiguousBuffers(\n-      absl::MakeConstSpan(static_data.buffer_infos_, static_data.num_buffers_),\n+      static_data.buffer_infos_, static_data.num_buffers_,\n       /*allocate_entry_params=*/allocate_entry_params, buffer_table_,\n       /*annotate_initialized=*/true);\n   // If Hlo profiling is enabled the generated code expects an appropriately"
        },
        {
            "sha": "009650d76109bb29af06c56dd26877fe161b832e",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -29,8 +29,8 @@ limitations under the License.\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/cpu/alignment.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/backends/cpu/runtime/rng_state_lib.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/service/custom_call_status_internal.h\"\n #include \"tensorflow/core/platform/types.h\"\n@@ -123,7 +123,7 @@ class XlaCompiledCpuFunction {\n     // End serialized thunk execution specific\n \n     // Contains information about the buffers used by the XLA computation.\n-    const xla::cpu::BufferAllocationInfo* buffer_infos_ = nullptr;\n+    const xla::cpu_function_runtime::BufferInfo* buffer_infos_ = nullptr;\n     int32_t num_buffers_ = 0;\n \n     // Result parameter i is described by\n@@ -251,7 +251,9 @@ class XlaCompiledCpuFunction {\n   // called for each positional argument, in order to set the argument buffers.\n   //\n   // Allocated memory must be aligned to the size specified by\n-  // xla::cpu::MinAlign().\n+  // xla::cpu_function_runtime::MinAlign(). If possible, use the functions in\n+  // tensorflow/compiler/tf2xla/cpu_function_runtime.h to ensure correct\n+  // alignment.\n   //\n   // Aliasing of argument and result buffers is not allowed, and results in\n   // undefined behavior.\n@@ -360,7 +362,7 @@ class XlaCompiledCpuFunction {\n     return temp_allocation_index_;\n   }\n \n-  const xla::cpu::BufferAllocationInfo* buffer_infos() const {\n+  const xla::cpu_function_runtime::BufferInfo* buffer_infos() const {\n     return buffer_infos_;\n   }\n \n@@ -413,7 +415,7 @@ class XlaCompiledCpuFunction {\n \n   static void set_static_data_buffer_infos(\n       StaticData* static_data,\n-      const xla::cpu::BufferAllocationInfo* buffer_infos) {\n+      const xla::cpu_function_runtime::BufferInfo* buffer_infos) {\n     static_data->buffer_infos_ = buffer_infos;\n   }\n \n@@ -529,7 +531,7 @@ class XlaCompiledCpuFunction {\n   void** const buffer_table_;\n \n   // Describes the buffers used by the XLA computation.\n-  const xla::cpu::BufferAllocationInfo* const buffer_infos_;\n+  const xla::cpu_function_runtime::BufferInfo* const buffer_infos_;\n   const int32 num_buffers_;\n \n   // Indices of expanded result tuple."
        },
        {
            "sha": "8be6dafa6ca8c139a624022303365b72c789e9c1",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -32,7 +32,9 @@ limitations under the License.\n #include \"xla/client/client_library.h\"\n #include \"xla/client/executable_build_options.h\"\n #include \"xla/client/local_client.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n+#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/platform_util.h\"\n@@ -62,10 +64,10 @@ absl::StatusOr<size_t> ComputeResultIndex(\n \n // Returns the number of results.\n int CountResults(\n-    absl::Span<const xla::cpu::BufferAllocationInfo> buffer_infos) {\n+    absl::Span<const xla::cpu_function_runtime::BufferInfo> buffer_infos) {\n   int num_results = 0;\n   for (const auto& info : buffer_infos) {\n-    if (info.is_result()) {\n+    if (info.is_result_parameter()) {\n       ++num_results;\n     }\n   }\n@@ -150,18 +152,18 @@ XlaJitCompiledCpuFunction::Compile(\n       cpu_executable->buffer_assignment();\n \n   // Compute buffer infos and the result index, needed to run the raw function.\n-  std::vector<xla::cpu::BufferAllocationInfo> buffer_infos =\n-      xla::cpu::CreateBufferAllocationInfos(cpu_executable->module(),\n-                                            buffer_assignment);\n+  std::vector<xla::cpu_function_runtime::BufferInfo> buffer_infos =\n+      xla::cpu::CreateBufferInfosFromBufferAssignment(cpu_executable->module(),\n+                                                      buffer_assignment);\n \n   std::vector<xla::cpu::BufferAllocationInfo> buffer_allocation_infos =\n       xla::cpu::CreateBufferAllocationInfos(cpu_executable->module(),\n                                             buffer_assignment);\n \n   std::vector<int32> arg_index_table =\n-      xla::cpu::CreateArgIndexTable(buffer_infos);\n+      xla::cpu::CreateArgIndexTableFromBufferInfos(buffer_infos);\n   std::vector<int32> result_index_table =\n-      xla::cpu::CreateResultIndexTable(buffer_infos);\n+      xla::cpu::CreateResultIndexTableFromBufferInfos(buffer_infos);\n   TF_ASSIGN_OR_RETURN(size_t result_index,\n                       ComputeResultIndex(buffer_assignment));\n   const int num_results = CountResults(buffer_infos);"
        },
        {
            "sha": "8d142ffbe3254ff10296a34682b3743633978f03",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -24,8 +24,8 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/xla_compiled_cpu_function_thunks.h\"\n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/client/local_client.h\"\n+#include \"xla/cpu_function_runtime.h\"\n #include \"xla/service/cpu/executable.pb.h\"\n #include \"tensorflow/core/framework/graph.pb.h\"\n #include \"tensorflow/core/platform/types.h\"\n@@ -82,7 +82,7 @@ class XlaJitCompiledCpuFunction {\n   XlaCompiledCpuFunction::StaticData static_data_;\n \n   // The backing array for buffer infos.\n-  std::vector<xla::cpu::BufferAllocationInfo> buffer_infos_;\n+  std::vector<xla::cpu_function_runtime::BufferInfo> buffer_infos_;\n \n   // The backing array for the arg index table.\n   std::vector<int32> arg_index_table_;"
        },
        {
            "sha": "3447105aed663d611b7e18f1e70dbe10b111cab9",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info.h",
            "status": "modified",
            "additions": 2,
            "deletions": 11,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -22,8 +22,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n \n-namespace xla {\n-namespace cpu {\n+namespace xla::cpu {\n \n // `BufferAllocationInfo` stores information about buffer allocations required\n // by an XLA:CPU executable at run time. It corresponds to a `BufferAllocation`\n@@ -194,14 +193,6 @@ class BufferAllocationInfo {\n   int32_t result_number_ = -1;\n };\n \n-}  // namespace cpu\n-\n-// TODO(ezhulenev): This is a temporary hack to keep `tfcompile` code working.\n-namespace cpu_function_runtime {\n-using BufferInfo = ::xla::cpu::BufferAllocationInfo;\n-using EncodedBufferInfo = ::xla::cpu::BufferAllocationInfo::Encoded;\n-}  // namespace cpu_function_runtime\n-\n-}  // namespace xla\n+}  // namespace xla::cpu\n \n #endif  // XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_H_"
        },
        {
            "sha": "6ab0a9ad981ec2068730d51bcf8344b1aac2ad3f",
            "filename": "third_party/xla/xla/cpu_function_runtime.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -22,7 +22,7 @@ limitations under the License.\n #include <cstdlib>\n \n namespace xla {\n-namespace cpu_function_runtime_deprecated {\n+namespace cpu_function_runtime {\n \n struct EncodedBufferInfo {\n   uint64_t packed_kind_and_size = 0;\n@@ -174,7 +174,7 @@ class BufferInfo {\n   int32_t result_param_number_ = -1;\n };\n \n-}  // namespace cpu_function_runtime_deprecated\n+}  // namespace cpu_function_runtime\n }  // namespace xla\n \n #endif  // XLA_CPU_FUNCTION_RUNTIME_H_"
        },
        {
            "sha": "dd43f97694618625b337a5011b55c7e850f137c9",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -170,12 +170,25 @@ cc_library(\n     alwayslink = True,  # Contains per-platform transfer manager registration\n )\n \n+cc_library(\n+    name = \"buffer_info_util\",\n+    srcs = [\"buffer_info_util.cc\"],\n+    hdrs = [\"buffer_info_util.h\"],\n+    deps = [\n+        \"//xla:cpu_function_runtime\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n cc_library(\n     name = \"cpu_compiler_pure\",\n     srcs = [\"cpu_compiler.cc\"],\n     hdrs = [\"cpu_compiler.h\"],\n     copts = tsl_copts(),\n     deps = [\n+        \":buffer_info_util\",\n         \":conv_canonicalization\",\n         \":cpu_aot_compilation_result\",\n         \":cpu_aot_loader\",\n@@ -414,6 +427,7 @@ cc_library(\n     srcs = [\"cpu_aot_compilation_result.cc\"],\n     hdrs = [\"cpu_aot_compilation_result.h\"],\n     deps = [\n+        \":buffer_info_util\",\n         \":cpu_executable\",\n         \":executable_proto_cc\",\n         \"//xla:cpu_function_runtime\","
        },
        {
            "sha": "cbcbdfa853eb7e385fbab792cd66a54cbc65c0fa",
            "filename": "third_party/xla/xla/service/cpu/buffer_info_util.cc",
            "status": "added",
            "additions": 101,
            "deletions": 0,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -0,0 +1,101 @@\n+/* Copyright 2018 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/cpu/buffer_info_util.h\"\n+\n+#include <cassert>\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/types/span.h\"\n+#include \"xla/cpu_function_runtime.h\"\n+\n+namespace xla {\n+namespace cpu {\n+\n+using BufferInfo = cpu_function_runtime::BufferInfo;\n+\n+std::vector<BufferInfo> CreateBufferInfosFromBufferAssignment(\n+    const HloModule& module, const BufferAssignment& buffer_assignment) {\n+  std::vector<BufferInfo> buffer_infos;\n+  for (const BufferAllocation& allocation : buffer_assignment.Allocations()) {\n+    if (allocation.is_thread_local()) {\n+      buffer_infos.push_back(BufferInfo::MakeOnStackBuffer(allocation.size()));\n+    } else if (allocation.is_constant()) {\n+      buffer_infos.push_back(BufferInfo::MakeConstant(allocation.size()));\n+    } else if (allocation.is_entry_computation_parameter()) {\n+      buffer_infos.push_back(BufferInfo::MakeEntryParameter(\n+          /*size=*/allocation.size(),\n+          /*param_number=*/allocation.parameter_number()));\n+    } else {\n+      buffer_infos.push_back(BufferInfo::MakeTempBuffer(allocation.size()));\n+    }\n+  }\n+\n+  // Fill in the result parameters' indices, expanding all tuples.\n+  auto root_instr = module.entry_computation()->root_instruction();\n+  auto output_allocation = buffer_assignment.GetUniqueTopLevelOutputSlice();\n+  if (output_allocation->allocation()->is_tuple()) {\n+    int out_index = 0;\n+    ShapeUtil::ForEachSubshape(\n+        root_instr->shape(),\n+        [&](const Shape& subshape, const ShapeIndex& index) {\n+          if (subshape.IsTuple()) {\n+            return;\n+          }\n+          int64_t result_index =\n+              buffer_assignment.GetUniqueSlice(root_instr, index)->index();\n+          assert(result_index < buffer_infos.size());\n+          buffer_infos[result_index].set_result_parameter_number(out_index++);\n+        });\n+  }\n+\n+  return buffer_infos;\n+}\n+\n+std::vector<int32_t> CreateArgIndexTableFromBufferInfos(\n+    absl::Span<const BufferInfo> buffer_infos) {\n+  std::vector<int32_t> ret;\n+  for (int64_t i = 0; i < buffer_infos.size(); i++) {\n+    if (!buffer_infos[i].is_entry_parameter()) {\n+      continue;\n+    }\n+    uint64_t param_index = buffer_infos[i].entry_parameter_number();\n+    if (param_index >= ret.size()) {\n+      ret.resize(param_index + 1);\n+    }\n+    ret[param_index] = i;\n+  }\n+  return ret;\n+}\n+\n+std::vector<int32_t> CreateResultIndexTableFromBufferInfos(\n+    absl::Span<const BufferInfo> buffer_infos) {\n+  std::vector<int32_t> ret;\n+  for (int64_t i = 0; i < buffer_infos.size(); i++) {\n+    if (!buffer_infos[i].is_result_parameter()) {\n+      continue;\n+    }\n+    uint64_t result_index = buffer_infos[i].result_parameter_number();\n+    if (result_index >= ret.size()) {\n+      ret.resize(result_index + 1);\n+    }\n+    ret[result_index] = i;\n+  }\n+  return ret;\n+}\n+\n+}  // namespace cpu\n+}  // namespace xla"
        },
        {
            "sha": "c21ea2f8459a1b71b7a86fd8a65e2416af802768",
            "filename": "third_party/xla/xla/service/cpu/buffer_info_util.h",
            "status": "added",
            "additions": 48,
            "deletions": 0,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -0,0 +1,48 @@\n+/* Copyright 2018 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_\n+#define XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/types/span.h\"\n+#include \"xla/cpu_function_runtime.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+\n+namespace xla {\n+namespace cpu {\n+// Creates and returns a list of BufferInfo instances containing relevant\n+// information from `buffer_assignment`.\n+std::vector<cpu_function_runtime::BufferInfo>\n+CreateBufferInfosFromBufferAssignment(\n+    const HloModule& module, const BufferAssignment& buffer_assignment);\n+\n+// Creates and returns a table containing the mapping from entry computation\n+// parameters to buffer allocation indices.\n+//\n+// If this function returns V then entry parameter i has buffer allocation index\n+// V[i].\n+std::vector<int32_t> CreateArgIndexTableFromBufferInfos(\n+    absl::Span<const cpu_function_runtime::BufferInfo> buffer_infos);\n+\n+std::vector<int32_t> CreateResultIndexTableFromBufferInfos(\n+    absl::Span<const cpu_function_runtime::BufferInfo> buffer_infos);\n+}  // namespace cpu\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_"
        },
        {
            "sha": "4364bb10510abfeea4d42076fe13bd72100f3791",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -43,6 +43,7 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/compiler.h\"\n+#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/cpu/executable.pb.h\"\n #include \"xla/service/executable.h\"\n@@ -56,6 +57,7 @@ limitations under the License.\n #include \"xla/util.h\"\n \n namespace xla::cpu {\n+using BufferInfo = cpu_function_runtime::BufferInfo;\n \n CpuAotCompilationOptions::CpuAotCompilationOptions(\n     std::string triple, std::string cpu_name, std::string features,\n@@ -86,10 +88,14 @@ CpuAotCompilationResult::Create(\n   TF_ASSIGN_OR_RETURN(ThunkSequenceProto thunk_proto,\n                       thunk_sequence_serdes.ToProto(thunks));\n \n+  std::vector<cpu_function_runtime::BufferInfo> buffer_infos;\n   std::vector<cpu::BufferAllocationInfo> buffer_allocation_infos;\n   std::optional<size_t> temp_allocation_index;\n \n   if (buffer_assignment) {\n+    buffer_infos =\n+        CreateBufferInfosFromBufferAssignment(*hlo_module, *buffer_assignment);\n+\n     buffer_allocation_infos =\n         CreateBufferAllocationInfos(*hlo_module, *buffer_assignment);\n \n@@ -108,19 +114,21 @@ CpuAotCompilationResult::Create(\n   return absl::WrapUnique(new CpuAotCompilationResult(\n       hlo_module, buffer_assignment, function_name, std::move(obj_files),\n       std::move(symbols), thunk_proto, std::move(temp_allocation_index),\n-      std::move(buffer_allocation_infos), std::move(function_library),\n-      std::move(hlo_profile_printer_data)));\n+      std::move(buffer_infos), std::move(buffer_allocation_infos),\n+      std::move(function_library), std::move(hlo_profile_printer_data)));\n }\n \n CpuAotCompilationResult::CpuAotCompilationResult(\n     const HloModule* hlo_module, const BufferAssignment* buffer_assignment,\n     absl::string_view function_name, std::vector<ObjFileProto> obj_files,\n     std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n     std::optional<size_t> temp_allocation_index,\n+    std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n     std::vector<BufferAllocationInfo> buffer_allocation_infos,\n     std::unique_ptr<FunctionLibrary> function_library,\n     std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data)\n     : temp_allocation_index_(temp_allocation_index),\n+      buffer_infos_(std::move(buffer_infos)),\n       buffer_allocation_infos_(std::move(buffer_allocation_infos)),\n       function_library_(std::move(function_library)),\n       hlo_profile_printer_data_(std::move(hlo_profile_printer_data)) {"
        },
        {
            "sha": "16320df6f6fa74da1f682d86e21500c0eb49318a",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -148,6 +148,10 @@ class CpuAotCompilationResult : public AotCompilationResult {\n     return temp_allocation_index_;\n   }\n \n+  const std::vector<cpu_function_runtime::BufferInfo>& buffer_infos() const {\n+    return buffer_infos_;\n+  }\n+\n   absl::Span<const BufferAllocationInfo> buffer_allocation_infos() const {\n     return buffer_allocation_infos_;\n   }\n@@ -184,6 +188,7 @@ class CpuAotCompilationResult : public AotCompilationResult {\n       absl::string_view function_name, std::vector<ObjFileProto> obj_files,\n       std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n       std::optional<size_t> temp_allocation_index,\n+      std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n       std::vector<BufferAllocationInfo> buffer_allocation_infos,\n       std::unique_ptr<FunctionLibrary> function_library,\n       std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data);\n@@ -198,6 +203,7 @@ class CpuAotCompilationResult : public AotCompilationResult {\n   CompilationResultProto proto_;\n   std::unique_ptr<HloModule> module_;\n   std::optional<size_t> temp_allocation_index_;\n+  std::vector<cpu_function_runtime::BufferInfo> buffer_infos_;\n   std::vector<BufferAllocationInfo> buffer_allocation_infos_;\n \n   std::unique_ptr<FunctionLibrary> function_library_;"
        },
        {
            "sha": "bbebba2c8bb55402b63c1201e9eda712505472d7",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/94fbd7554e303cc8ad052d64ae88dc3d48374072/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=94fbd7554e303cc8ad052d64ae88dc3d48374072",
            "patch": "@@ -172,6 +172,7 @@ limitations under the License.\n #include \"xla/service/conditional_simplifier.h\"\n #include \"xla/service/conditional_to_select.h\"\n #include \"xla/service/copy_insertion.h\"\n+#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/conv_canonicalization.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_aot_loader.h\""
        }
    ],
    "stats": {
        "total": 456,
        "additions": 312,
        "deletions": 144
    }
}