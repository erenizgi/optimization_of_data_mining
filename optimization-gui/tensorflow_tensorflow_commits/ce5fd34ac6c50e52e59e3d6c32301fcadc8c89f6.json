{
    "author": "nvgrw",
    "message": "Stop using recordphase in HloRunnerPjRt.\n\nWe are removing this functionality due to the limited utility it provides.\n\nPiperOrigin-RevId: 843399237",
    "sha": "ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6",
    "files": [
        {
            "sha": "2fc73006ca32d46e73e9e5e65d58027af80e196f",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6",
            "patch": "@@ -4529,7 +4529,6 @@ cc_library(\n         \"//xla/pjrt:pjrt_executable\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:recordphase\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:nullability\","
        },
        {
            "sha": "c85e137fe888257e6d0bedc9dbce3e66b7ee2342",
            "filename": "third_party/xla/xla/service/hlo_runner_pjrt.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc?ref=ce5fd34ac6c50e52e59e3d6c32301fcadc8c89f6",
            "patch": "@@ -58,7 +58,6 @@ limitations under the License.\n #include \"xla/status_macros.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/recordphase.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/util.h\"\n@@ -302,9 +301,6 @@ absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n HloRunnerPjRt::TransferLiteralsToDevice(\n     const absl::Span<const ShapeLayout> layouts,\n     const absl::Span<const Literal* const> literals) {\n-  tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_TransferLiteralsToDevice\",\n-                                    /*use_unique_phase_name=*/true);\n-\n   // Note: This function is used for single (default) device execution.\n   if (pjrt_client_->addressable_device_count() <= kDeviceIdx) {\n     return absl::InternalError(\"No addressable devices available\");\n@@ -365,9 +361,6 @@ HloRunnerPjRt::TransferLiteralsToDevice(\n absl::StatusOr<Literal> HloRunnerPjRt::TransferLiteralsFromDevice(\n     absl::Span<const std::unique_ptr<PjRtBuffer>> output_buffers,\n     const bool untuple_result) {\n-  tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_TransferLiteralsFromDevice\",\n-                                    /*use_unique_phase_name=*/true);\n-\n   if (!untuple_result) {\n     // If not flattened, the tuple should only contain arrays with layouts.\n     TF_RET_CHECK(output_buffers.size() == 1)\n@@ -408,9 +401,6 @@ HloRunnerPjRt::ExecuteWithDeviceBuffers(\n     OpaqueExecutable* executable,\n     const std::vector<std::unique_ptr<PjRtBuffer>>& arguments,\n     const ExecuteOptions* execute_options) {\n-  tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_Execute\",\n-                                    /*use_unique_phase_name=*/true);\n-\n   TF_ASSIGN_OR_RETURN(HloRunnerPjRtExecutable* const wrapped_executable,\n                       HloRunnerPjRtExecutable::TryUnwrap(*this, executable));\n   TF_ASSIGN_OR_RETURN(std::vector<std::shared_ptr<HloModule>> hlo_modules,\n@@ -479,9 +469,6 @@ HloRunnerPjRt::ExecuteWithExecutable(OpaqueExecutable* executable,\n absl::StatusOr<std::unique_ptr<OpaqueExecutable>>\n HloRunnerPjRt::CreateExecutable(std::unique_ptr<HloModule> module,\n                                 bool run_hlo_passes) {\n-  tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_Compile\",\n-                                    /*use_unique_phase_name=*/true);\n-\n   TF_ASSIGN_OR_RETURN(\n       CompileOptions compile_options,\n       GenerateDefaultCompileOptions(module.get(), run_hlo_passes));\n@@ -581,8 +568,6 @@ absl::StatusOr<std::vector<Literal>> HloRunnerPjRt::ExecuteReplicated(\n               executable_provider_arg)\n           -> absl::StatusOr<\n               std::vector<std::vector<std::unique_ptr<PjRtBuffer>>>> {\n-        tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_Execute\",\n-                                          /*use_unique_phase_name=*/true);\n         TF_ASSIGN_OR_RETURN(\n             PjRtLoadedExecutable * pjrt_executable,\n             wrapped_executable->GetOrLoadExecutable(pjrt_client_.get()));\n@@ -614,8 +599,6 @@ absl::StatusOr<std::vector<Literal>> HloRunnerPjRt::ExecuteReplicated(\n               executable_provider_arg)\n           -> absl::StatusOr<\n               std::vector<std::vector<std::unique_ptr<PjRtBuffer>>>> {\n-        tsl::recordphase::RecordScoped rs(\"HloRunnerPjRt_Execute\",\n-                                          /*use_unique_phase_name=*/true);\n         TF_RET_CHECK(options.use_threads);\n \n         // The underlying data is modified concurrently. We don't need to"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 0,
        "deletions": 18
    }
}