{
    "author": "beckerhe",
    "message": "Make ptx_kernel_test work on P100\n\nThe embedded PTX string was requesting sm_70 which is not needed and fails on P100 presubmits. Changing the target SM version to 6.0 fixes the issue.\n\nPiperOrigin-RevId: 815661175",
    "sha": "14f6b3d13a1153bad2e31c417cdbae41ac944ca7",
    "files": [
        {
            "sha": "34a3bf55b05785b8829061252cb89ebfddbec234",
            "filename": "third_party/xla/xla/service/gpu/tests/ptx_kernel_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/14f6b3d13a1153bad2e31c417cdbae41ac944ca7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/14f6b3d13a1153bad2e31c417cdbae41ac944ca7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fptx_kernel_test.cc?ref=14f6b3d13a1153bad2e31c417cdbae41ac944ca7",
            "patch": "@@ -39,7 +39,7 @@ TEST_F(PtxKernelE2ETest, ScalarAdd) {\n         backend_config=\"{\n           name = \\\"add_kernel\\\",\n           kernel_type = \\\"ptx\\\",\n-          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  .reg .f32 a, b, c;\\\\n  .reg .u64 addr_a, addr_b, addr_out;\\\\n  \\\\n  ld.param.u64 addr_a, [input_a];\\\\n  ld.param.u64 addr_b, [input_b];\\\\n  ld.param.u64 addr_out, [output];\\\\n  \\\\n  ld.global.f32 a, [addr_a];\\\\n  ld.global.f32 b, [addr_b];\\\\n  add.f32 c, a, b;\\\\n  st.global.f32 [addr_out], c;\\\\n  \\\\n  ret;\\\\n}\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_60\\\\n.address_size 64\\\\n\\\\n.visible .entry add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  .reg .f32 a, b, c;\\\\n  .reg .u64 addr_a, addr_b, addr_out;\\\\n  \\\\n  ld.param.u64 addr_a, [input_a];\\\\n  ld.param.u64 addr_b, [input_b];\\\\n  ld.param.u64 addr_out, [output];\\\\n  \\\\n  ld.global.f32 a, [addr_a];\\\\n  ld.global.f32 b, [addr_b];\\\\n  add.f32 c, a, b;\\\\n  st.global.f32 [addr_out], c;\\\\n  \\\\n  ret;\\\\n}\\\",\n           grid_x = 1, grid_y = 1, grid_z = 1,\n           block_x = 1, block_y = 1, block_z = 1,\n           shared_mem_bytes = 0,\n@@ -65,7 +65,7 @@ TEST_F(PtxKernelE2ETest, TensorAdd) {\n         backend_config=\"{\n           name = \\\"tensor_add_kernel\\\",\n           kernel_type = \\\"ptx\\\",\n-          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_60\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n           grid_x = 1, grid_y = 1, grid_z = 1,\n           block_x = 4, block_y = 1, block_z = 1,\n           shared_mem_bytes = 0,\n@@ -95,7 +95,7 @@ TEST_F(PtxKernelE2ETest, TensorAddWithoutOutputIndices) {\n         backend_config=\"{\n           name = \\\"tensor_add_kernel\\\",\n           kernel_type = \\\"ptx\\\",\n-          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_60\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 input_b,\\\\n    .param .u64 output)\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  ld.param.u64 out_base, [output];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n           grid_x = 1, grid_y = 1, grid_z = 1,\n           block_x = 4, block_y = 1, block_z = 1,\n           shared_mem_bytes = 0\n@@ -124,7 +124,7 @@ TEST_F(PtxKernelE2ETest, TensorAddWithNonTrivialOutputIndices) {\n         backend_config=\"{\n           name = \\\"tensor_add_kernel\\\",\n           kernel_type = \\\"ptx\\\",\n-          kernel_data = \\\".version 7.0\\\\n.target sm_70\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 output,\\\\n    .param .u64 input_b\\\\n    )\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 out_base, [output];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n+          kernel_data = \\\".version 7.0\\\\n.target sm_60\\\\n.address_size 64\\\\n\\\\n.visible .entry tensor_add_kernel(\\\\n    .param .u64 input_a,\\\\n    .param .u64 output,\\\\n    .param .u64 input_b\\\\n    )\\\\n{\\\\n  // Get base pointers\\\\n  .reg .u64 a_base, b_base, out_base;\\\\n  ld.param.u64 a_base, [input_a];\\\\n  ld.param.u64 out_base, [output];\\\\n  ld.param.u64 b_base, [input_b];\\\\n  \\\\n  // Thread ID calculation - just use thread ID directly for this simple case\\\\n  .reg .u32 tid;\\\\n  mov.u32 tid, %tid.x;\\\\n  \\\\n  // Hard-coded array size = 4\\\\n  .reg .pred p;\\\\n  setp.ge.u32 p, tid, 4;\\\\n  @p bra done;\\\\n  \\\\n  // Calculate byte offset (4 bytes per float)\\\\n  .reg .u64 offset;\\\\n  cvt.u64.u32 offset, tid;  // Convert tid to 64-bit\\\\n  mul.lo.u64 offset, offset, 4;  // Each float is 4 bytes\\\\n  \\\\n  // Calculate element addresses\\\\n  .reg .u64 a_addr, b_addr, out_addr;\\\\n  add.u64 a_addr, a_base, offset;\\\\n  add.u64 b_addr, b_base, offset;\\\\n  add.u64 out_addr, out_base, offset;\\\\n  \\\\n  // Load input values\\\\n  .reg .f32 a_val, b_val, result;\\\\n  ld.global.f32 a_val, [a_addr];\\\\n  ld.global.f32 b_val, [b_addr];\\\\n  \\\\n  // Perform addition\\\\n  add.f32 result, a_val, b_val;\\\\n  \\\\n  // Store result\\\\n  st.global.f32 [out_addr], result;\\\\n  \\\\ndone:\\\\n  ret;\\\\n}\\\",\n           grid_x = 1, grid_y = 1, grid_z = 1,\n           block_x = 4, block_y = 1, block_z = 1,\n           shared_mem_bytes = 0,"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}