{
    "author": "loislo",
    "message": "[XLA:GPU] Add infinity and zero counts to GPU buffer float checks.\n\nThis change extends the `BufferDebugFloatCheckEntry` struct to include counts for infinities and zeros. The CUDA kernel for float checking is updated to compute and store these additional counts in the log entries.\n\nPiperOrigin-RevId: 830870471",
    "sha": "2fb4baac5c5971698fadb67d539e3ffd35526581",
    "files": [
        {
            "sha": "9ff067c00b633d737ba57c659941509e0138471c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_structs.h",
            "status": "modified",
            "additions": 10,
            "deletions": 5,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -58,17 +58,22 @@ struct BufferDebugFloatCheckEntry {\n   // An ID that uniquely identifies a log entry within a HLO module execution.\n   BufferDebugLogEntryId entry_id;\n   uint32_t nan_count;\n+  uint32_t inf_count;\n+  uint32_t zero_count;\n \n   template <typename Sink>\n   friend void AbslStringify(Sink& sink,\n                             const BufferDebugFloatCheckEntry& entry) {\n-    absl::Format(&sink, \"{entry_id: %v, nan_count: %u}\", entry.entry_id.value(),\n-                 entry.nan_count);\n+    absl::Format(&sink,\n+                 \"{entry_id: %v, nan_count: %u, inf_count: %u, zero_count: %u}\",\n+                 entry.entry_id.value(), entry.nan_count, entry.inf_count,\n+                 entry.zero_count);\n   }\n \n   bool operator==(const BufferDebugFloatCheckEntry& other) const {\n-    return std::tie(entry_id, nan_count) ==\n-           std::tie(other.entry_id, other.nan_count);\n+    return std::tie(entry_id, nan_count, inf_count, zero_count) ==\n+           std::tie(other.entry_id, other.nan_count, other.inf_count,\n+                    other.zero_count);\n   }\n \n   bool operator!=(const BufferDebugFloatCheckEntry& other) const {\n@@ -78,7 +83,7 @@ struct BufferDebugFloatCheckEntry {\n \n // The struct layout must match on both host and device.\n static_assert(_Alignof(BufferDebugFloatCheckEntry) == _Alignof(uint32_t));\n-static_assert(sizeof(BufferDebugFloatCheckEntry) == sizeof(uint32_t) * 2);\n+static_assert(sizeof(BufferDebugFloatCheckEntry) == sizeof(uint32_t) * 4);\n static_assert(offsetof(BufferDebugFloatCheckEntry, entry_id) == 0);\n static_assert(offsetof(BufferDebugFloatCheckEntry, nan_count) ==\n               sizeof(uint32_t));"
        },
        {
            "sha": "e961ad1b53170324ba7d3b1a325b80b7af75fbba",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk_test.cc?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -100,8 +100,8 @@ class BuffersDebugFloatCheckThunkTest : public ::testing::Test {\n };\n \n TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n-  static constexpr size_t kLogSize =\n-      BufferDebugLog::RequiredSizeForEntries(10, sizeof(BufferDebugLogEntry));\n+  static constexpr size_t kLogSize = BufferDebugLog::RequiredSizeForEntries(\n+      10, sizeof(BufferDebugFloatCheckEntry));\n   static constexpr size_t kInputElems = 1024;\n   static constexpr size_t kInputSizeInBytes = kInputElems * sizeof(float);\n   static constexpr size_t kTotalDeviceMemoryBytes =\n@@ -130,9 +130,10 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   se::DeviceMemoryBase inputs0_mem = allocations.GetDeviceAddress(inputs[0]);\n   se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n   // Initialize the log in device memory\n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLog device_log,\n-                          BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n-                              *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      BufferDebugLog device_log,\n+      BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+          *stream_, se::DeviceMemory<uint8_t>(log_mem)));\n   // Fill inputs with some data\n   {\n     std::vector<Eigen::bfloat16> data(kInputElems, Eigen::bfloat16(0));\n@@ -166,8 +167,8 @@ TEST_F(BuffersDebugFloatCheckThunkTest, CalculatesNanCounts) {\n   TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n   TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n   TF_ASSERT_OK_AND_ASSIGN(\n-      std::vector<BufferDebugLogEntry> entries,\n-      device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+      std::vector<BufferDebugFloatCheckEntry> entries,\n+      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n \n   // BuffersDebugFloatCheckThunk launches a kernel for each input buffer, they\n   // may complete in any order."
        },
        {
            "sha": "162a6333b0e7f20653be6497b6d5f013b04350d6",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda.cu.cc",
            "status": "modified",
            "additions": 60,
            "deletions": 23,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -13,6 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n+#include <cmath>\n #include <cstdint>\n #include <cstdlib>\n #include <cstring>\n@@ -54,6 +55,12 @@ __device__ void WarpReduceSum(unsigned int tid, volatile uint32_t* data) {\n \n __device__ inline bool IsNan(float v) { return isnan(v); }\n __device__ inline bool IsNan(__nv_bfloat16 v) { return __isnan(v); }\n+__device__ inline bool IsInf(float v) { return isinf(v); }\n+__device__ inline bool IsInf(__nv_bfloat16 v) { return __isinf(v); }\n+__device__ inline bool IsZero(float v) { return v == 0.0f; }\n+__device__ inline bool IsZero(__nv_bfloat16 v) {\n+  return v == __nv_bfloat16(0.0f);\n+}\n \n // Calculates count of NaNs of all elements of `input` and puts result in\n // `output`.\n@@ -65,47 +72,74 @@ __device__ inline bool IsNan(__nv_bfloat16 v) { return __isnan(v); }\n // `BLOCK_SIZE` must be a power of 2 no larger than 1024.\n template <typename T, unsigned int BLOCK_SIZE>\n __device__ void ReduceSum(const T* input, uint64_t input_size,\n-                          uint32_t* output) {\n-  __shared__ uint32_t scratch[BLOCK_SIZE];\n+                          uint32_t* nan_counter, uint32_t* inf_counter,\n+                          uint32_t* zero_counter) {\n+  __shared__ uint32_t nan_count[BLOCK_SIZE];\n+  __shared__ uint32_t inf_count[BLOCK_SIZE];\n+  __shared__ uint32_t zero_count[BLOCK_SIZE];\n \n   assert(BlockIdx() == 0);\n   const unsigned int tid = ThreadIdx();\n \n-  scratch[tid] = 0;\n+  nan_count[tid] = 0;\n+  inf_count[tid] = 0;\n+  zero_count[tid] = 0;\n   for (unsigned int i = tid; i < input_size; i += BLOCK_SIZE) {\n     if (IsNan(input[i])) {\n-      scratch[tid]++;\n+      nan_count[tid]++;\n+    }\n+    if (IsInf(input[i])) {\n+      inf_count[tid]++;\n+    }\n+    if (IsZero(input[i])) {\n+      zero_count[tid]++;\n     }\n   }\n \n   __syncthreads();\n \n   if (BLOCK_SIZE >= 1024) {\n     if (tid < 512) {\n-      scratch[tid] += scratch[tid + 512];\n+      nan_count[tid] += nan_count[tid + 512];\n+      inf_count[tid] += inf_count[tid + 512];\n+      zero_count[tid] += zero_count[tid + 512];\n     }\n     __syncthreads();\n   }\n   if (BLOCK_SIZE >= 512) {\n     if (tid < 256) {\n-      scratch[tid] += scratch[tid + 256];\n+      nan_count[tid] += nan_count[tid + 256];\n+      inf_count[tid] += inf_count[tid + 256];\n+      zero_count[tid] += zero_count[tid + 256];\n     }\n     __syncthreads();\n   }\n   if (BLOCK_SIZE >= 256) {\n     if (tid < 128) {\n-      scratch[tid] += scratch[tid + 128];\n+      nan_count[tid] += nan_count[tid + 128];\n+      inf_count[tid] += inf_count[tid + 128];\n+      zero_count[tid] += zero_count[tid + 128];\n     }\n     __syncthreads();\n   }\n   if (BLOCK_SIZE >= 128) {\n     if (tid < 64) {\n-      scratch[tid] += scratch[tid + 64];\n+      nan_count[tid] += nan_count[tid + 64];\n+      inf_count[tid] += inf_count[tid + 64];\n+      zero_count[tid] += zero_count[tid + 64];\n     }\n     __syncthreads();\n   }\n-  if (tid < 32) WarpReduceSum<BLOCK_SIZE>(tid, scratch);\n-  if (tid == 0) *output = scratch[0];\n+  if (tid < 32) {\n+    WarpReduceSum<BLOCK_SIZE>(tid, nan_count);\n+    WarpReduceSum<BLOCK_SIZE>(tid, inf_count);\n+    WarpReduceSum<BLOCK_SIZE>(tid, zero_count);\n+  }\n+  if (tid == 0) {\n+    *nan_counter = nan_count[0];\n+    *inf_counter = inf_count[0];\n+    *zero_counter = zero_count[0];\n+  }\n }\n \n // Attempts to append the NaN count of the `input` buffer to the\n@@ -131,6 +165,8 @@ __global__ void AppendFloatCheck(\n   const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n   const uint64_t input_size = input_size_in_bytes / sizeof(T);\n   uint32_t nan_count = 0;\n+  uint32_t inf_count = 0;\n+  uint32_t zero_count = 0;\n \n   assert(gridDim.x == 1 && gridDim.y == 1 && gridDim.z == 1);\n   if (BlockIdx() != 0) {\n@@ -142,37 +178,38 @@ __global__ void AppendFloatCheck(\n   // > per block limit).\n   switch (block_size) {\n     case 1024:\n-      ReduceSum<T, 1024>(input, input_size, &nan_count);\n+      ReduceSum<T, 1024>(input, input_size, &nan_count, &inf_count,\n+                         &zero_count);\n       break;\n     case 512:\n-      ReduceSum<T, 512>(input, input_size, &nan_count);\n+      ReduceSum<T, 512>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 256:\n-      ReduceSum<T, 256>(input, input_size, &nan_count);\n+      ReduceSum<T, 256>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 128:\n-      ReduceSum<T, 128>(input, input_size, &nan_count);\n+      ReduceSum<T, 128>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 64:\n-      ReduceSum<T, 64>(input, input_size, &nan_count);\n+      ReduceSum<T, 64>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 32:\n-      ReduceSum<T, 32>(input, input_size, &nan_count);\n+      ReduceSum<T, 32>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 16:\n-      ReduceSum<T, 16>(input, input_size, &nan_count);\n+      ReduceSum<T, 16>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 8:\n-      ReduceSum<T, 8>(input, input_size, &nan_count);\n+      ReduceSum<T, 8>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 4:\n-      ReduceSum<T, 4>(input, input_size, &nan_count);\n+      ReduceSum<T, 4>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 2:\n-      ReduceSum<T, 2>(input, input_size, &nan_count);\n+      ReduceSum<T, 2>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     case 1:\n-      ReduceSum<T, 1>(input, input_size, &nan_count);\n+      ReduceSum<T, 1>(input, input_size, &nan_count, &inf_count, &zero_count);\n       break;\n     default:\n       // Unsupported block size.\n@@ -186,8 +223,8 @@ __global__ void AppendFloatCheck(\n #if __CUDA_ARCH__ >= 600\n     const uint32_t write_idx = nan_count_log_write_idx.fetch_add(1);\n     if (nan_count_log_write_idx.load() < log_header->capacity) {\n-      float_check_entries[write_idx] =\n-          xla::gpu::BufferDebugFloatCheckEntry{entry_id, nan_count};\n+      float_check_entries[write_idx] = xla::gpu::BufferDebugFloatCheckEntry{\n+          entry_id, nan_count, inf_count, zero_count};\n     }\n #else\n     // Our toolchains generate a fetch_add PTX instructions with system scope,"
        },
        {
            "sha": "5fccb6de0cd9c60ff74161444823afae25169bf3",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 3,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -121,8 +121,16 @@ class FloatCheckKernelTest : public ::testing::Test {\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsForF32) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n-  std::vector<float> input = {1.0f, std::numeric_limits<float>::quiet_NaN(),\n-                              2.0f, std::numeric_limits<float>::quiet_NaN()};\n+  std::vector<float> input = {\n+      1.0f,\n+      std::numeric_limits<float>::quiet_NaN(),\n+      2.0f,\n+      std::numeric_limits<float>::quiet_NaN(),\n+      0.0f,\n+      std::numeric_limits<float>::infinity(),\n+      std::numeric_limits<float>::infinity(),\n+      std::numeric_limits<float>::infinity(),\n+  };\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n       se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n@@ -136,6 +144,8 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForF32) {\n       device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].nan_count, 2);\n+  EXPECT_EQ(host_log[0].inf_count, 3);\n+  EXPECT_EQ(host_log[0].zero_count, 1);\n }\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n@@ -144,7 +154,12 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n       xla::bfloat16(1.0f),\n       xla::bfloat16(std::numeric_limits<float>::quiet_NaN()),\n       xla::bfloat16(2.0f),\n-      xla::bfloat16(std::numeric_limits<float>::quiet_NaN())};\n+      xla::bfloat16(std::numeric_limits<float>::quiet_NaN()),\n+      xla::bfloat16(0.0f),\n+      xla::bfloat16(std::numeric_limits<float>::infinity()),\n+      xla::bfloat16(std::numeric_limits<float>::infinity()),\n+      xla::bfloat16(std::numeric_limits<float>::infinity()),\n+  };\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n       se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n@@ -158,6 +173,8 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n       device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   EXPECT_EQ(host_log[0].nan_count, 2);\n+  EXPECT_EQ(host_log[0].inf_count, 3);\n+  EXPECT_EQ(host_log[0].zero_count, 1);\n }\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n@@ -166,6 +183,9 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n   input[100] = std::numeric_limits<float>::quiet_NaN();\n   input[200] = std::numeric_limits<float>::quiet_NaN();\n   input[300] = std::numeric_limits<float>::quiet_NaN();\n+  input[400] = 0.0f;\n+  input[600] = std::numeric_limits<float>::infinity();\n+  input[700] = std::numeric_limits<float>::infinity();\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n@@ -182,7 +202,11 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n       device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].nan_count, 3);\n+  EXPECT_EQ(host_log[0].inf_count, 2);\n+  EXPECT_EQ(host_log[0].zero_count, 1);\n   EXPECT_EQ(host_log[1].nan_count, 3);\n+  EXPECT_EQ(host_log[1].inf_count, 2);\n+  EXPECT_EQ(host_log[1].zero_count, 1);\n }\n \n }  // namespace"
        },
        {
            "sha": "57d2fc5b9aedcb96eea8261c8a03639d4dce57d4",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -32,7 +32,6 @@ limitations under the License.\n \n namespace stream_executor::gpu {\n \n-using ::xla::gpu::BufferDebugLogEntry;\n using ::xla::gpu::BufferDebugLogHeader;\n \n absl::StatusOr<BufferDebugLog> BufferDebugLog::CreateOnDevice(\n@@ -50,8 +49,7 @@ absl::StatusOr<BufferDebugLog> BufferDebugLog::CreateOnDevice(\n   }\n \n   const uint32_t max_entries =\n-      (log_buffer.size() - sizeof(BufferDebugLogHeader)) /\n-      sizeof(BufferDebugLogEntry);\n+      (log_buffer.size() - sizeof(BufferDebugLogHeader)) / entry_size;\n   const BufferDebugLogHeader empty_header{\n       /*write_idx=*/0,\n       /*capacity=*/max_entries,"
        },
        {
            "sha": "a4e1ddd31ac1c8ef70938587481223d925599d45",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2fb4baac5c5971698fadb67d539e3ffd35526581/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.h?ref=2fb4baac5c5971698fadb67d539e3ffd35526581",
            "patch": "@@ -32,8 +32,7 @@ namespace stream_executor::gpu {\n // A wrapper over a device memory buffer used to store debug info about contents\n // of buffers (e.g. checksums).\n //\n-// It holds a BufferDebugLogHeader and a variable number of BufferDebugLogEntry\n-// structs.\n+// It holds a BufferDebugLogHeader and a variable number of Entry structs.\n class BufferDebugLog {\n  public:\n   // Returns the number of bytes required to store a log with `entries`\n@@ -100,7 +99,7 @@ class BufferDebugLog {\n         memory_.GetByteSlice(0, sizeof(xla::gpu::BufferDebugLogHeader)));\n   }\n \n-  // Returns a view of the `BufferDebugLogEntry` array.\n+  // Returns a view of the `Entry` array.\n   //\n   // The returned `DeviceMemory` gets invalidated when the `BufferDebugLog` is\n   // destroyed."
        }
    ],
    "stats": {
        "total": 152,
        "additions": 108,
        "deletions": 44
    }
}