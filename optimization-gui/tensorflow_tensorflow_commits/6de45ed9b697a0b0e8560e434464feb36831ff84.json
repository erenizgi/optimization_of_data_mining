{
    "author": "pschuh",
    "message": "Add a lazily populated cache of stream synchronization events.\n\nThis will allow for cheap stream synchronized buffer definition events.\n\nPiperOrigin-RevId: 817315245",
    "sha": "6de45ed9b697a0b0e8560e434464feb36831ff84",
    "files": [
        {
            "sha": "f9243e4d06767dc328b17dc00b8547c027ab10da",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 19,
            "deletions": 2,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -207,8 +207,14 @@ xla_cc_test(\n \n cc_library(\n     name = \"local_device_state\",\n-    srcs = [\"local_device_state.cc\"],\n-    hdrs = [\"local_device_state.h\"],\n+    srcs = [\n+        \"buffer_sequencing_event.cc\",\n+        \"local_device_state.cc\",\n+    ],\n+    hdrs = [\n+        \"buffer_sequencing_event.h\",\n+        \"local_device_state.h\",\n+    ],\n     deps = [\n         \":event_pool\",\n         \":pjrt_common\",\n@@ -217,21 +223,32 @@ cc_library(\n         \"//xla:util\",\n         \"//xla/client:local_client\",\n         \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:event\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/concurrency:async_value\",\n+        \"//xla/tsl/concurrency:ref_count\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:error_codes_proto_impl_cc\",\n         \"//xla/tsl/util:env_var\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/synchronization\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@local_tsl//tsl/profiler/lib:connected_traceme\",\n+        \"@local_tsl//tsl/profiler/lib:context_types_hdrs\",\n         \"@local_tsl//tsl/profiler/lib:traceme\",\n     ],\n )"
        },
        {
            "sha": "7ebea180b415c0dc0bf2fef74f1e952cd9b54682",
            "filename": "third_party/xla/xla/pjrt/buffer_sequencing_event.cc",
            "status": "added",
            "additions": 140,
            "deletions": 0,
            "changes": 140,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.cc?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -0,0 +1,140 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <functional>\n+#include <string>\n+#include <utility>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"xla/pjrt/event_pool.h\"\n+#include \"xla/stream_executor/event.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/concurrency/async_value_ref.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+#include \"tsl/profiler/lib/connected_traceme.h\"\n+#include \"tsl/profiler/lib/context_types.h\"\n+\n+namespace xla {\n+\n+void BufferSequencingEvent::SetSequencingEvent(EventPool::Handle event,\n+                                               se::Stream* stream) {\n+  EventState state;\n+  state.event = std::move(event);\n+  state.definition_stream = stream;\n+  event_.emplace(std::move(state));\n+}\n+\n+void BufferSequencingEvent::SetDefinedStatus(absl::Status status) {\n+  CHECK(!status.ok());\n+  event_.SetError(status);\n+}\n+\n+uint64_t BufferSequencingEvent::sequence_number() const {\n+  return event_->event.sequence_number();\n+}\n+\n+void BufferSequencingEvent::WaitForEventOnStream(se::Stream* stream) {\n+  // We cannot wait for an event until ThenRecordEvent has been called; on GPU\n+  // newly created events are deemed to have already happened past.\n+  tsl::BlockUntilReady(event_);\n+\n+  if (event_.IsError()) {\n+    return;\n+  }\n+  if (event_->definition_stream == stream) {\n+    return;\n+  }\n+\n+  absl::MutexLock lock(&mu_);\n+  // The set of defined streams is expected to be very small indeed (usually\n+  // 1-2), so a simple linear scan should be fast enough.\n+  if (std::find(streams_defined_on_.begin(), streams_defined_on_.end(),\n+                stream) != streams_defined_on_.end()) {\n+    // stream is in streams_defined_on_; it doesn't need to be waited on.\n+    return;\n+  }\n+\n+  stream->WaitFor(event_->event.event()).IgnoreError();\n+  streams_defined_on_.push_back(stream);\n+}\n+\n+absl::Status BufferSequencingEvent::WaitForEventOnExternalStream(\n+    std::intptr_t stream) {\n+  tsl::BlockUntilReady(event_);\n+  if (const auto* error = event_.GetErrorIfPresent()) {\n+    return *error;\n+  }\n+  return event_->event.event()->WaitForEventOnExternalStream(stream);\n+}\n+\n+bool BufferSequencingEvent::IsPredeterminedErrorOrDefinedOn(\n+    se::Stream* stream) {\n+  tsl::BlockUntilReady(event_);\n+  CHECK(event_.IsAvailable());\n+\n+  // IsPredeterminedError\n+  if (event_.IsError()) {\n+    return true;\n+  }\n+\n+  if (event_->definition_stream == stream) {\n+    return true;\n+  }\n+\n+  // The set of defined streams is expected to be very small indeed (usually\n+  // 1-2), so a simple linear scan should be fast enough.\n+  absl::MutexLock lock(&mu_);\n+  return absl::c_find(streams_defined_on_, stream) != streams_defined_on_.end();\n+}\n+\n+bool BufferSequencingEvent::IsComplete() {\n+  tsl::BlockUntilReady(event_);\n+  if (event_.IsError()) {\n+    return true;\n+  }\n+\n+  return event_->event.event()->PollForStatus() == se::Event::Status::kComplete;\n+}\n+\n+void BufferSequencingEvent::ExecuteOrAddToFutureTasks(\n+    const std::string& task_name, std::function<void()> task) {\n+  tsl::profiler::TraceMeProducer producer(\n+      \"BufferSequencingEvent::ExecuteOrAddToFutureTasks\",\n+      tsl::profiler::ContextType::kPjRt);\n+\n+  auto traced_task = [task = std::move(task),\n+                      context_id = producer.GetContextId()]() {\n+    tsl::profiler::TraceMeConsumer consumer(\"BufferSequencingEvent::Execute\",\n+                                            tsl::profiler::ContextType::kPjRt,\n+                                            context_id);\n+    task();\n+  };\n+\n+  // Execute the `task` when definition event becomes available. If it's already\n+  // available, the task will be executed immediately.\n+  event_.AndThen([this, traced_task = std::move(traced_task)]() mutable {\n+    thread_pool_->Schedule(std::move(traced_task));\n+  });\n+}\n+\n+}  // namespace xla"
        },
        {
            "sha": "19527d03276ba9cd79627eb4281611c1415ce0f1",
            "filename": "third_party/xla/xla/pjrt/buffer_sequencing_event.h",
            "status": "added",
            "additions": 172,
            "deletions": 0,
            "changes": 172,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fbuffer_sequencing_event.h?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -0,0 +1,172 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_PJRT_BUFFER_SEQUENCING_EVENT_H_\n+#define XLA_PJRT_BUFFER_SEQUENCING_EVENT_H_\n+\n+#include <cstdint>\n+#include <functional>\n+#include <string>\n+\n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"xla/pjrt/event_pool.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/tsl/concurrency/async_value.h\"\n+#include \"xla/tsl/concurrency/async_value_ref.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n+\n+namespace xla {\n+\n+// A BufferSequencingEvent keeps track of dependencies of a buffer on each\n+// stream it has been used on.\n+//\n+// Each logical buffer in an XLA computation may be defined (i.e., written to)\n+// at most once. We call the operation that writes the buffer's value on some\n+// stream (e.g., a transfer or compute kernel) the buffer's definition event.\n+//\n+// After the operation that populates the value of a buffer has been enqueued on\n+// 'stream', SetSequencingEvent() should also be called to trigger the\n+// definition event after the operation has completed.\n+//\n+// After the buffer is read on 'stream' another event should be added so that\n+// it is possible to sequence buffer donation after all reads have completed.\n+//\n+// Since different streams are not necessarily synchronized with one another,\n+// if we wish to consume the value of the buffer on a different stream, we\n+// should first call WaitForEventOnStream(stream), which add a cross-stream\n+// from 'stream' to the buffer's definition event, causing 'stream' to pause\n+// until the definition event has been triggered, if needed. Operations on\n+// 'stream' may then assume that the buffer is valid and its contents correspond\n+// to the desired buffer.\n+//\n+// The dependency logic caches the set of streams at the tail of which the\n+// definition event is known to have occurred; waiting for the same event on the\n+// same stream causes no additional waiting.\n+class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n+ public:\n+  explicit BufferSequencingEvent(tsl::thread::ThreadPool* thread_pool)\n+      : thread_pool_(thread_pool),\n+        event_(tsl::MakeUnconstructedAsyncValueRef<EventState>()) {}\n+\n+  static tsl::AsyncValueRef<BufferSequencingEvent> Create(\n+      tsl::thread::ThreadPool* thread_pool) {\n+    return tsl::MakeConstructedAsyncValueRef<BufferSequencingEvent>(\n+        thread_pool);\n+  }\n+\n+  // Sets the sequencing event to 'event', which is recorded on 'stream'. Must\n+  // be called at most once. Unblocks any other host threads that are blocked in\n+  // WaitForEventOnStream.\n+  // Do not call directly, use: PjRtStreamExecutorClient::AllocateAndRecordEvent\n+  // or PjRtStreamExecutorClient::ThenRecordEvent.\n+  void SetSequencingEvent(EventPool::Handle event, se::Stream* stream);\n+\n+  // Adds synchronization events to 'stream' that wait for this event to be\n+  // defined on 'stream'. Does nothing if the event is already known to have\n+  // occurred by the tail of 'stream'. If SetSequencingEvent has not yet been\n+  // called, blocks the calling thread until the event has been recorded.\n+  void WaitForEventOnStream(se::Stream* stream);\n+\n+  // Same as WaitForEventOnStream, but takes a raw platform-specific\n+  // stream. Currently on implemented for CUDA and ROCM GPU, where stream is a\n+  // GpuStreamHandle (e.g. a cudaStream_t).\n+  absl::Status WaitForEventOnExternalStream(std::intptr_t stream);\n+\n+  // Returns true if the event is known by the host to have already occurred. If\n+  // SetSequencingEvent has not yet been called, blocks the calling thread\n+  // until the event has been recorded.\n+  bool IsComplete();\n+\n+  // Compares the sequence numbers of two recorded events. It is illegal to call\n+  // the comparison operators unless both events have been recorded.\n+  inline bool operator<(const BufferSequencingEvent& rhs) const {\n+    return sequence_number() < rhs.sequence_number();\n+  }\n+  inline bool operator>(const BufferSequencingEvent& rhs) const {\n+    return rhs < *this;\n+  }\n+  inline bool operator<=(const BufferSequencingEvent& rhs) const {\n+    return !(*this > rhs);\n+  }\n+  inline bool operator>=(const BufferSequencingEvent& rhs) const {\n+    return !(*this < rhs);\n+  }\n+\n+  // Executes the `task` if the event is ready; otherwise adds the `task`\n+  // callback to `event_` async value, to be executed when it becomes\n+  // available.\n+  void ExecuteOrAddToFutureTasks(const std::string& task_name,\n+                                 std::function<void()> task);\n+\n+  bool IsDefined() { return event_.IsAvailable(); }\n+\n+  // Do not call directly. Use PjRtStreamExecutorClient::SetEventAsError.\n+  void SetDefinedStatus(absl::Status status);\n+\n+  absl::Status GetDefinedStatus() {\n+    CHECK(event_.IsAvailable());\n+    if (const auto* error = event_.GetErrorIfPresent()) {\n+      return *error;\n+    }\n+    return absl::OkStatus();\n+  }\n+\n+  bool IsPredeterminedError() { return event_.IsError(); }\n+\n+  // Returns true if either:\n+  // 1. The event IsPredeterminedError\n+  // Or:\n+  // 2. The event is known to have occurred by the tail of 'stream'.\n+  // If SetSequencingEvent and SetDefinedStatus has not yet been called,\n+  // blocks the calling thread until either of those 2 happens.\n+  bool IsPredeterminedErrorOrDefinedOn(se::Stream* stream);\n+\n+  struct EventState {\n+    // An event that is triggered when the content of one or more buffers has\n+    // been read or written. If this event is used as a definition event and is\n+    // nullptr, it is assumed that the buffer's content is always defined for\n+    // example because it uses storage borrowed from elsewhere.\n+    EventPool::Handle event;\n+\n+    se::Stream* definition_stream;\n+  };\n+\n+  se::Stream* definition_stream() const { return event_->definition_stream; }\n+\n+ private:\n+  uint64_t sequence_number() const;\n+\n+  mutable absl::Mutex mu_;\n+  // A list of all streams for which the buffer's content is known to be defined\n+  // at the tail of the queue, i.e., for any newly enqueued command.\n+  absl::InlinedVector<se::Stream*, 2> streams_defined_on_ ABSL_GUARDED_BY(mu_);\n+\n+  tsl::thread::ThreadPool* thread_pool_;\n+\n+  // Indicates if the buffer is in an error status. And error status is used to\n+  // propagate the error to the buffer consumers.\n+  tsl::AsyncValueRef<EventState> event_;\n+};\n+\n+using BufferSequencingEventRef = tsl::AsyncValueRef<BufferSequencingEvent>;\n+\n+}  // namespace xla\n+\n+#endif  // XLA_PJRT_BUFFER_SEQUENCING_EVENT_H_"
        },
        {
            "sha": "39bcd387685afa248e84afbe1a2cabd557f95790",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -235,6 +235,7 @@ xla_test(\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tests:literal_test_util\",\n+        \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "a7166f9b318647389a6e00f227eafb16cba3acfd",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -89,6 +89,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tests/literal_test_util.h\"\n+#include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -2609,6 +2610,40 @@ ENTRY main.5 {\n   TF_EXPECT_OK(client->DmaUnmap(host_dma_ptr.get()));\n }\n \n+TEST(StreamExecutorGpuClientTest, EventCaching) {\n+  TF_ASSERT_OK_AND_ASSIGN(auto client,\n+                          GetStreamExecutorGpuClient(DefaultOptions()));\n+  auto* thread_pool =\n+      tensorflow::down_cast<PjRtStreamExecutorClient*>(client.get())\n+          ->thread_pool();\n+  const auto& device = client->addressable_devices()[0];\n+  LocalDeviceState* local_device_state =\n+      tensorflow::down_cast<const PjRtStreamExecutorDevice*>(device)\n+          ->local_device_state();\n+  ASSERT_TRUE(local_device_state != nullptr);\n+  size_t sync_point0 = local_device_state->GetNextComputeStreamSyncPoint();\n+  TF_ASSERT_OK_AND_ASSIGN(auto event0,\n+                          local_device_state->GetEventForComputeStreamSyncPoint(\n+                              sync_point0, thread_pool));\n+  TF_ASSERT_OK_AND_ASSIGN(auto event1,\n+                          local_device_state->GetEventForComputeStreamSyncPoint(\n+                              sync_point0, thread_pool));\n+  size_t sync_point1 = local_device_state->GetNextComputeStreamSyncPoint();\n+  TF_ASSERT_OK_AND_ASSIGN(auto event2,\n+                          local_device_state->GetEventForComputeStreamSyncPoint(\n+                              sync_point1, thread_pool));\n+  // Events are getting cached.\n+  EXPECT_EQ(&*event0, &*event1);\n+  // New events are getting assigned.\n+  EXPECT_NE(&*event0, &*event2);\n+  tsl::BlockUntilReady(event2);\n+  // sync_point1 is ready, so it is the most recent event.\n+  TF_ASSERT_OK_AND_ASSIGN(auto event3,\n+                          local_device_state->GetEventForComputeStreamSyncPoint(\n+                              sync_point0, thread_pool));\n+  EXPECT_EQ(&*event3, &*event2);\n+}\n+\n struct ShardedAutotuningTestInfo {\n   bool use_xla_computation;\n   int num_active_nodes;"
        },
        {
            "sha": "5391c82dc3395f2345b1bfc4a99e56e6f77493b3",
            "filename": "third_party/xla/xla/pjrt/local_device_state.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 0,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/pjrt/local_device_state.h\"\n \n+#include <cstddef>\n #include <cstdint>\n #include <limits>\n #include <memory>\n@@ -31,12 +32,14 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/client/local_client.h\"\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/worker_thread.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n #include \"xla/tsl/protobuf/error_codes.pb.h\"\n #include \"xla/tsl/util/env_var.h\"\n #include \"xla/util.h\"\n@@ -304,4 +307,58 @@ int LocalDeviceState::GetNewPrngSeed() {\n   return x;\n }\n \n+absl::Status LocalDeviceState::AllocateAndRecordEvent(\n+    BufferSequencingEventRef event, se::Stream* stream) {\n+  auto status = [&]() {\n+    TF_ASSIGN_OR_RETURN(EventPool::Handle device_event,\n+                        event_pool().AllocateEvent(stream->parent()));\n+    event_pool().ThenRecordEvent(stream, device_event);\n+    event->SetSequencingEvent(std::move(device_event), stream);\n+    return ThenExecuteCallback(stream, [event]() { event.SetStateConcrete(); });\n+  }();\n+  if (!status.ok()) {\n+    event.SetError(status);\n+  }\n+  return status;\n+}\n+\n+absl::StatusOr<BufferSequencingEventRef>\n+LocalDeviceState::GetEventForComputeStreamSyncPoint(\n+    size_t sync_point, tsl::thread::ThreadPool* thread_pool) {\n+  mu_.lock();\n+  size_t cur_sync_point = next_compute_stream_sync_point_.load();\n+  if (sync_point < base_compute_event_sequence_id_ + compute_events_.size()) {\n+    BufferSequencingEventRef event;\n+    if (sync_point < base_compute_event_sequence_id_) {\n+      DCHECK_GT(compute_events_.size(), 0);\n+      event = compute_events_.front();\n+    } else {\n+      event = compute_events_[sync_point - base_compute_event_sequence_id_];\n+    }\n+    mu_.unlock();\n+    return event;\n+  }\n+  next_compute_stream_sync_point_.store(cur_sync_point + 1);\n+  auto event = BufferSequencingEvent::Create(thread_pool);\n+  auto status = AllocateAndRecordEvent(event, compute_stream());\n+  if (!status.ok()) {\n+    mu_.unlock();\n+    return status;\n+  }\n+  while (!(cur_sync_point - base_compute_event_sequence_id_ <\n+           compute_events_.size())) {\n+    // Pad for any failed event allocations.\n+    compute_events_.push_back(event);\n+  }\n+  mu_.unlock();\n+  event.AndThen([this, cur_sync_point]() {\n+    absl::MutexLock l(&mu_);\n+    while (base_compute_event_sequence_id_ < cur_sync_point) {\n+      compute_events_.pop_front();\n+      ++base_compute_event_sequence_id_;\n+    }\n+  });\n+  return event;\n+}\n+\n }  // namespace xla"
        },
        {
            "sha": "da3f32d45ac7de26e23cb705031cf0905380b8f4",
            "filename": "third_party/xla/xla/pjrt/local_device_state.h",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_PJRT_LOCAL_DEVICE_STATE_H_\n #define XLA_PJRT_LOCAL_DEVICE_STATE_H_\n \n+#include <deque>\n #include <functional>\n #include <memory>\n #include <optional>\n@@ -26,6 +27,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"xla/client/local_client.h\"\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/semaphore.h\"\n@@ -207,6 +209,19 @@ class LocalDeviceState {\n     return allow_delete_before_fulfill_;\n   }\n \n+  absl::Status AllocateAndRecordEvent(BufferSequencingEventRef event,\n+                                      se::Stream* stream);\n+\n+  size_t GetNextComputeStreamSyncPoint() {\n+    return next_compute_stream_sync_point_.load();\n+  }\n+\n+  // Allows handing out very cheap event ids (GetNextComputeStreamSyncPoint())\n+  // which only incur the expense of constructing a cuda event if they're really\n+  // needed. This allows constructing a definition event per buffer.\n+  absl::StatusOr<BufferSequencingEventRef> GetEventForComputeStreamSyncPoint(\n+      size_t sync_point, tsl::thread::ThreadPool* thread_pool);\n+\n  private:\n   absl::Status SynchronizeAllActivity();\n \n@@ -269,6 +284,10 @@ class LocalDeviceState {\n   std::unique_ptr<WorkerThread> cleanup_thread_;\n \n   bool allow_delete_before_fulfill_ = true;\n+\n+  std::atomic<size_t> next_compute_stream_sync_point_{0};\n+  size_t base_compute_event_sequence_id_ ABSL_GUARDED_BY(mu_) = 0;\n+  std::deque<BufferSequencingEventRef> compute_events_ ABSL_GUARDED_BY(mu_);\n };\n \n }  // namespace xla"
        },
        {
            "sha": "15cb1d1084167e7229e0e8637e7ff249bb72b39f",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 21,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -190,19 +190,7 @@ void PjRtStreamExecutorClient::ThenRecordEvent(BufferSequencingEventRef event,\n absl::Status PjRtStreamExecutorClient::AllocateAndRecordEvent(\n     BufferSequencingEventRef event, LocalDeviceState* local_device,\n     se::Stream* stream) {\n-  auto status = [&]() {\n-    TF_ASSIGN_OR_RETURN(\n-        EventPool::Handle device_event,\n-        local_device->event_pool().AllocateEvent(stream->parent()));\n-    local_device->event_pool().ThenRecordEvent(stream, device_event);\n-    event->SetSequencingEvent(std::move(device_event), stream);\n-    return local_device->ThenExecuteCallback(\n-        stream, [event]() { event.SetStateConcrete(); });\n-  }();\n-  if (!status.ok()) {\n-    event.SetError(status);\n-  }\n-  return status;\n+  return local_device->AllocateAndRecordEvent(event, stream);\n }\n \n void PjRtStreamExecutorClient::SetEventAsError(BufferSequencingEventRef event,\n@@ -2976,10 +2964,9 @@ PjRtStreamExecutorLoadedExecutable::ExecuteHelper(\n   LocalDeviceState* device_state = &(client_->device_state(device_ordinal));\n   se::Stream* stream = device_state->compute_stream();\n \n-  auto definition_event = BufferSequencingEvent::Create(client_->thread_pool());\n-  auto status =\n-      client_->AllocateAndRecordEvent(definition_event, device_state, stream);\n-  if (!status.ok()) {\n+  auto definition_event = device_state->GetEventForComputeStreamSyncPoint(\n+      device_state->GetNextComputeStreamSyncPoint(), client_->thread_pool());\n+  if (!definition_event.ok()) {\n     StallStreamOnError(device_state, stream);\n     for (PjRtStreamExecutorBuffer::ScopedHold& b : device_buffers) {\n       if (b.type() == PjRtStreamExecutorBuffer::ScopedHold::kDonation) {\n@@ -2989,18 +2976,18 @@ PjRtStreamExecutorLoadedExecutable::ExecuteHelper(\n         b.ConfirmDonation();\n       }\n     }\n-    return status;\n+    return definition_event.status();\n   }\n   std::vector<tsl::RCReference<RawSEDeviceMemory>> buffers_to_release;\n   TF_ASSIGN_OR_RETURN(\n       std::vector<std::unique_ptr<PjRtBuffer>> outputs,\n       MakeOutputBuffers(device_ordinal, options, std::move(result_buffer),\n-                        definition_event, device, compute_callbacks,\n+                        *definition_event, device, compute_callbacks,\n                         buffers_to_release));\n \n   for (PjRtStreamExecutorBuffer::ScopedHold& b : device_buffers) {\n     if (b.type() == PjRtStreamExecutorBuffer::ScopedHold::kUsage) {\n-      RecordUsage(std::move(b), device_state, device_state, definition_event,\n+      RecordUsage(std::move(b), device_state, device_state, *definition_event,\n                   stream, &buffers_to_release);\n     } else {\n       CHECK(b.type() == PjRtStreamExecutorBuffer::ScopedHold::kDonation);\n@@ -3015,7 +3002,7 @@ PjRtStreamExecutorLoadedExecutable::ExecuteHelper(\n     compute_callbacks.push_back(\n         [promise = std::move(promise)]() mutable { promise.Set(); });\n   }\n-  definition_event.AndThen(\n+  definition_event->AndThen(\n       [callbacks{std::move(compute_callbacks)},\n        buffers_to_release{std::move(buffers_to_release)}]() mutable {\n         for (auto& fn : callbacks) {"
        },
        {
            "sha": "0d2793e62bd89abedb222aa9c877c38b3dc305c2",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 101,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -51,107 +51,6 @@ limitations under the License.\n \n namespace xla {\n \n-void BufferSequencingEvent::SetSequencingEvent(EventPool::Handle event,\n-                                               se::Stream* stream) {\n-  EventState state;\n-  state.event = std::move(event);\n-  state.definition_stream = stream;\n-  event_.emplace(std::move(state));\n-}\n-\n-void BufferSequencingEvent::SetDefinedStatus(absl::Status status) {\n-  CHECK(!status.ok());\n-  event_.SetError(status);\n-}\n-\n-uint64_t BufferSequencingEvent::sequence_number() const {\n-  return event_->event.sequence_number();\n-}\n-\n-void BufferSequencingEvent::WaitForEventOnStream(se::Stream* stream) {\n-  // We cannot wait for an event until ThenRecordEvent has been called; on GPU\n-  // newly created events are deemed to have already happened past.\n-  tsl::BlockUntilReady(event_);\n-\n-  if (event_.IsError()) {\n-    return;\n-  }\n-  if (event_->definition_stream == stream) {\n-    return;\n-  }\n-\n-  absl::MutexLock lock(&mu_);\n-  // The set of defined streams is expected to be very small indeed (usually\n-  // 1-2), so a simple linear scan should be fast enough.\n-  if (std::find(streams_defined_on_.begin(), streams_defined_on_.end(),\n-                stream) != streams_defined_on_.end()) {\n-    // stream is in streams_defined_on_; it doesn't need to be waited on.\n-    return;\n-  }\n-\n-  stream->WaitFor(event_->event.event()).IgnoreError();\n-  streams_defined_on_.push_back(stream);\n-}\n-\n-absl::Status BufferSequencingEvent::WaitForEventOnExternalStream(\n-    std::intptr_t stream) {\n-  tsl::BlockUntilReady(event_);\n-  if (const auto* error = event_.GetErrorIfPresent()) {\n-    return *error;\n-  }\n-  return event_->event.event()->WaitForEventOnExternalStream(stream);\n-}\n-\n-bool BufferSequencingEvent::IsPredeterminedErrorOrDefinedOn(\n-    se::Stream* stream) {\n-  tsl::BlockUntilReady(event_);\n-  CHECK(event_.IsAvailable());\n-\n-  // IsPredeterminedError\n-  if (event_.IsError()) {\n-    return true;\n-  }\n-\n-  if (event_->definition_stream == stream) {\n-    return true;\n-  }\n-\n-  // The set of defined streams is expected to be very small indeed (usually\n-  // 1-2), so a simple linear scan should be fast enough.\n-  absl::MutexLock lock(&mu_);\n-  return absl::c_find(streams_defined_on_, stream) != streams_defined_on_.end();\n-}\n-\n-bool BufferSequencingEvent::IsComplete() {\n-  tsl::BlockUntilReady(event_);\n-  if (event_.IsError()) {\n-    return true;\n-  }\n-\n-  return event_->event.event()->PollForStatus() == se::Event::Status::kComplete;\n-}\n-\n-void BufferSequencingEvent::ExecuteOrAddToFutureTasks(\n-    const std::string& task_name, std::function<void()> task) {\n-  tsl::profiler::TraceMeProducer producer(\n-      \"BufferSequencingEvent::ExecuteOrAddToFutureTasks\",\n-      tsl::profiler::ContextType::kPjRt);\n-\n-  auto traced_task = [task = std::move(task),\n-                      context_id = producer.GetContextId()]() {\n-    tsl::profiler::TraceMeConsumer consumer(\"BufferSequencingEvent::Execute\",\n-                                            tsl::profiler::ContextType::kPjRt,\n-                                            context_id);\n-    task();\n-  };\n-\n-  // Execute the `task` when definition event becomes available. If it's already\n-  // available, the task will be executed immediately.\n-  event_.AndThen([this, traced_task = std::move(traced_task)]() mutable {\n-    thread_pool_->Schedule(std::move(traced_task));\n-  });\n-}\n-\n ShapedBuffer RawSEDeviceMemory::AsShapedBuffer(\n     PjRtDevice* device, const Shape& on_device_shape) const {\n   ShapedBuffer shaped_buffer(on_device_shape, device->local_device_id().value(),"
        },
        {
            "sha": "faf8d2ea2a6490e67af634b1a980159d8dfa2965",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 1,
            "deletions": 133,
            "changes": 134,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6de45ed9b697a0b0e8560e434464feb36831ff84/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=6de45ed9b697a0b0e8560e434464feb36831ff84",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/event_pool.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n@@ -49,139 +50,6 @@ limitations under the License.\n \n namespace xla {\n \n-// A BufferSequencingEvent keeps track of dependencies of a buffer on each\n-// stream it has been used on.\n-//\n-// Each logical buffer in an XLA computation may be defined (i.e., written to)\n-// at most once. We call the operation that writes the buffer's value on some\n-// stream (e.g., a transfer or compute kernel) the buffer's definition event.\n-//\n-// After the operation that populates the value of a buffer has been enqueued on\n-// 'stream', SetSequencingEvent() should also be called to trigger the\n-// definition event after the operation has completed.\n-//\n-// After the buffer is read on 'stream' another event should be added so that\n-// it is possible to sequence buffer donation after all reads have completed.\n-//\n-// Since different streams are not necessarily synchronized with one another,\n-// if we wish to consume the value of the buffer on a different stream, we\n-// should first call WaitForEventOnStream(stream), which add a cross-stream\n-// from 'stream' to the buffer's definition event, causing 'stream' to pause\n-// until the definition event has been triggered, if needed. Operations on\n-// 'stream' may then assume that the buffer is valid and its contents correspond\n-// to the desired buffer.\n-//\n-// The dependency logic caches the set of streams at the tail of which the\n-// definition event is known to have occurred; waiting for the same event on the\n-// same stream causes no additional waiting.\n-class BufferSequencingEvent : tsl::AsyncPayload::KeepOnError {\n- public:\n-  explicit BufferSequencingEvent(tsl::thread::ThreadPool* thread_pool)\n-      : thread_pool_(thread_pool),\n-        event_(tsl::MakeUnconstructedAsyncValueRef<EventState>()) {}\n-\n-  static tsl::AsyncValueRef<BufferSequencingEvent> Create(\n-      tsl::thread::ThreadPool* thread_pool) {\n-    return tsl::MakeConstructedAsyncValueRef<BufferSequencingEvent>(\n-        thread_pool);\n-  }\n-\n-  // Sets the sequencing event to 'event', which is recorded on 'stream'. Must\n-  // be called at most once. Unblocks any other host threads that are blocked in\n-  // WaitForEventOnStream.\n-  // Do not call directly, use: PjRtStreamExecutorClient::AllocateAndRecordEvent\n-  // or PjRtStreamExecutorClient::ThenRecordEvent.\n-  void SetSequencingEvent(EventPool::Handle event, se::Stream* stream);\n-\n-  // Adds synchronization events to 'stream' that wait for this event to be\n-  // defined on 'stream'. Does nothing if the event is already known to have\n-  // occurred by the tail of 'stream'. If SetSequencingEvent has not yet been\n-  // called, blocks the calling thread until the event has been recorded.\n-  void WaitForEventOnStream(se::Stream* stream);\n-\n-  // Same as WaitForEventOnStream, but takes a raw platform-specific\n-  // stream. Currently on implemented for CUDA and ROCM GPU, where stream is a\n-  // GpuStreamHandle (e.g. a cudaStream_t).\n-  absl::Status WaitForEventOnExternalStream(std::intptr_t stream);\n-\n-  // Returns true if the event is known by the host to have already occurred. If\n-  // SetSequencingEvent has not yet been called, blocks the calling thread\n-  // until the event has been recorded.\n-  bool IsComplete();\n-\n-  // Compares the sequence numbers of two recorded events. It is illegal to call\n-  // the comparison operators unless both events have been recorded.\n-  inline bool operator<(const BufferSequencingEvent& rhs) const {\n-    return sequence_number() < rhs.sequence_number();\n-  }\n-  inline bool operator>(const BufferSequencingEvent& rhs) const {\n-    return rhs < *this;\n-  }\n-  inline bool operator<=(const BufferSequencingEvent& rhs) const {\n-    return !(*this > rhs);\n-  }\n-  inline bool operator>=(const BufferSequencingEvent& rhs) const {\n-    return !(*this < rhs);\n-  }\n-\n-  // Executes the `task` if the event is ready; otherwise adds the `task`\n-  // callback to `event_` async value, to be executed when it becomes\n-  // available.\n-  void ExecuteOrAddToFutureTasks(const std::string& task_name,\n-                                 std::function<void()> task);\n-\n-  bool IsDefined() { return event_.IsAvailable(); }\n-\n-  // Do not call directly. Use PjRtStreamExecutorClient::SetEventAsError.\n-  void SetDefinedStatus(absl::Status status);\n-\n-  absl::Status GetDefinedStatus() {\n-    CHECK(event_.IsAvailable());\n-    if (const auto* error = event_.GetErrorIfPresent()) {\n-      return *error;\n-    }\n-    return absl::OkStatus();\n-  }\n-\n-  bool IsPredeterminedError() { return event_.IsError(); }\n-\n-  // Returns true if either:\n-  // 1. The event IsPredeterminedError\n-  // Or:\n-  // 2. The event is known to have occurred by the tail of 'stream'.\n-  // If SetSequencingEvent and SetDefinedStatus has not yet been called,\n-  // blocks the calling thread until either of those 2 happens.\n-  bool IsPredeterminedErrorOrDefinedOn(se::Stream* stream);\n-\n-  struct EventState {\n-    // An event that is triggered when the content of one or more buffers has\n-    // been read or written. If this event is used as a definition event and is\n-    // nullptr, it is assumed that the buffer's content is always defined for\n-    // example because it uses storage borrowed from elsewhere.\n-    EventPool::Handle event;\n-\n-    se::Stream* definition_stream;\n-  };\n-\n-  se::Stream* definition_stream() const { return event_->definition_stream; }\n-\n- private:\n-  uint64_t sequence_number() const;\n-\n-  mutable absl::Mutex mu_;\n-  // A list of all streams for which the buffer's content is known to be defined\n-  // at the tail of the queue, i.e., for any newly enqueued command.\n-  absl::InlinedVector<se::Stream*, 2> streams_defined_on_ ABSL_GUARDED_BY(mu_);\n-\n-  tsl::thread::ThreadPool* thread_pool_;\n-\n-  // Indicates if the buffer is in an error status. And error status is used to\n-  // propagate the error to the buffer consumers.\n-  tsl::AsyncValueRef<EventState> event_;\n-};\n-\n-using BufferSequencingEventRef = tsl::AsyncValueRef<BufferSequencingEvent>;\n-\n // TODO(parkers): Implement PjRtRawBuffer API.\n class RawSEDeviceMemory : public tsl::ReferenceCounted<RawSEDeviceMemory> {\n  public:"
        }
    ],
    "stats": {
        "total": 709,
        "additions": 452,
        "deletions": 257
    }
}