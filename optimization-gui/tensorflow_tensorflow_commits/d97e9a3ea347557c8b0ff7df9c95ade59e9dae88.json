{
    "author": "beckerhe",
    "message": "Small adjustment to the CUDA version check in CommandBufferThunkTest\n\nThis is the replacing a check for the `DeviceDescription::runtime_version()`\nby a check for the `DeviceDescription::compile_time_toolkit_version()` since the latter determines whether we were able to compile support for newer features in XLA.\n\nThere are cases where these 2 versions are not identical which is why I think it's worth changing it.\n\nPiperOrigin-RevId: 800329722",
    "sha": "d97e9a3ea347557c8b0ff7df9c95ade59e9dae88",
    "files": [
        {
            "sha": "360802e02a27a3d22b85f64f05caac78aa9e37bc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 8,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d97e9a3ea347557c8b0ff7df9c95ade59e9dae88/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d97e9a3ea347557c8b0ff7df9c95ade59e9dae88/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=d97e9a3ea347557c8b0ff7df9c95ade59e9dae88",
            "patch": "@@ -120,10 +120,12 @@ bool IsAtLeastCuda12300(const se::StreamExecutor* stream_executor) {\n   const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n       &device_description.gpu_compute_capability());\n   if (cuda_cc != nullptr) {\n-    if (device_description.driver_version() >=\n-            stream_executor::SemanticVersion(12, 3, 0) &&\n-        device_description.runtime_version() >=\n-            stream_executor::SemanticVersion(12, 3, 0)) {\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n+        stream_executor::SemanticVersion(12, 3, 0)) {\n       return true;\n     }\n   }\n@@ -136,10 +138,12 @@ bool IsAtLeastCuda12900(const se::StreamExecutor* stream_executor) {\n   const auto* cuda_cc = std::get_if<se::CudaComputeCapability>(\n       &device_description.gpu_compute_capability());\n   if (cuda_cc != nullptr) {\n-    if (device_description.driver_version() >=\n-            stream_executor::SemanticVersion(12, 9, 0) &&\n-        device_description.runtime_version() >=\n-            stream_executor::SemanticVersion(12, 9, 0)) {\n+    // We need a recent driver to support the feature at runtime and we need a\n+    // recent version of the toolkit at compile time, so that we have access to\n+    // the driver's headers.\n+    if (std::min(device_description.driver_version(),\n+                 device_description.compile_time_toolkit_version()) >=\n+        stream_executor::SemanticVersion(12, 9, 0)) {\n       return true;\n     }\n   }"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 12,
        "deletions": 8
    }
}