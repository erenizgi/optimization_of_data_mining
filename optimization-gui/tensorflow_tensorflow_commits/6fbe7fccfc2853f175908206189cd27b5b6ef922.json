{
    "author": "tensorflower-gardener",
    "message": "[XLA] Skip tests that depend on binary libraries.\n\nPiperOrigin-RevId: 804527649",
    "sha": "6fbe7fccfc2853f175908206189cd27b5b6ef922",
    "files": [
        {
            "sha": "c3a3390af68e7b8b5c202719d4259c88347ce4a0",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6fbe7fccfc2853f175908206189cd27b5b6ef922/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6fbe7fccfc2853f175908206189cd27b5b6ef922/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=6fbe7fccfc2853f175908206189cd27b5b6ef922",
            "patch": "@@ -424,6 +424,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n \n   opts.set_xla_gpu_experimental_collective_perf_table_path(\"\");\n   opts.set_xla_gpu_experimental_matmul_perf_table_path(\"\");\n+  // TODO(b/366475196): Create XLA GPU without cuDNN, cuBLAS.\n   opts.set_xla_gpu_experimental_disable_binary_libraries(false);\n   // --xla_ignore_channel_id should be kept false by default while channel ids\n   // are load-bearing."
        },
        {
            "sha": "f0ae751b020c0d56eff6aa8902dabd4a77d665b2",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 4,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6fbe7fccfc2853f175908206189cd27b5b6ef922/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6fbe7fccfc2853f175908206189cd27b5b6ef922/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_test.cc?ref=6fbe7fccfc2853f175908206189cd27b5b6ef922",
            "patch": "@@ -284,6 +284,11 @@ constexpr absl::string_view kHloDotFusionWithAlgorithm = R\"(\n )\";\n \n TEST_F(StatelessAutotunerTest, CublasFallbackForTf32Tf32F32X3Algorithm) {\n+  if (GetDebugOptionsForTest()\n+          .xla_gpu_experimental_disable_binary_libraries()) {\n+    GTEST_SKIP() << \"Not supported with cuda binary libraries disabled.\";\n+  }\n+\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(absl::Substitute(\n                        kHloDotFusionWithAlgorithm, \"dot_tf32_tf32_f32_x3\")));\n@@ -296,6 +301,11 @@ TEST_F(StatelessAutotunerTest, CublasFallbackForTf32Tf32F32X3Algorithm) {\n }\n \n TEST_F(StatelessAutotunerTest, CublasFallbackForBf16Bf16F32Algorithm) {\n+  if (GetDebugOptionsForTest()\n+          .xla_gpu_experimental_disable_binary_libraries()) {\n+    GTEST_SKIP() << \"Not supported with cuda binary libraries disabled.\";\n+  }\n+\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto module, ParseAndReturnVerifiedModule(absl::Substitute(\n                        kHloDotFusionWithAlgorithm, \"dot_bf16_bf16_f32\")));\n@@ -788,8 +798,9 @@ ENTRY main {\n }\n \n TEST_F(GemmFusionAutotunerDumpTest, DumpingWorks) {\n-  if (isRocm()) {\n-    GTEST_SKIP() << \"cuBLAS not selected on ROCM.\";\n+  if (isRocm() || GetDebugOptionsForTest()\n+                      .xla_gpu_experimental_disable_binary_libraries()) {\n+    GTEST_SKIP() << \"Not supported on ROCm or with binary libraries disabled.\";\n   }\n   HloModuleConfig config;\n   DebugOptions options = GetDebugOptionsForTest();\n@@ -856,8 +867,9 @@ CHECK: cublas\n }\n \n TEST_F(GemmFusionAutotunerTest, AutotuneCuDnnFusion) {\n-  if (isRocm()) {\n-    GTEST_SKIP() << \"No CuDnnFusion on ROCM.\";\n+  if (isRocm() || GetDebugOptionsForTest()\n+                      .xla_gpu_experimental_disable_binary_libraries()) {\n+    GTEST_SKIP() << \"Not supported on ROCm or with binary libraries disabled.\";\n   }\n   const std::string kHlo = R\"(\n fusion1 {"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 17,
        "deletions": 4
    }
}