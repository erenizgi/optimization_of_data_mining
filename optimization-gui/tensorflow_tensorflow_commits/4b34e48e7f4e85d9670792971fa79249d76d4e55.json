{
    "author": "pifon2a",
    "message": "[XLA:GPU] Add IrEmitterUnnested::EmitHloEntryComputation method.\n\nPiperOrigin-RevId: 836303807",
    "sha": "4b34e48e7f4e85d9670792971fa79249d76d4e55",
    "files": [
        {
            "sha": "cb582e10bb017aa40ea858f36ca0523d25c78437",
            "filename": "third_party/xla/xla/service/gpu/compile_module_to_llvm_ir.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcompile_module_to_llvm_ir.cc?ref=4b34e48e7f4e85d9670792971fa79249d76d4e55",
            "patch": "@@ -196,8 +196,7 @@ absl::StatusOr<std::unique_ptr<SequentialThunk>> LowerHlo(\n     XLA_SCOPED_LOGGING_TIMER(absl::StrCat(\n         \"GpuCompiler::RunBackend - IR emission for \", hlo_module->name()));\n \n-    TF_RETURN_IF_ERROR(\n-        ir_emitter->EmitHloComputation(hlo_module->entry_computation()));\n+    TF_RETURN_IF_ERROR(ir_emitter->EmitHloEntryComputation(hlo_module));\n \n     RemoveUnusedAndUninitializedGlobals(\n         platform_id, options, ir_emitter_context.llvm_module_constants(),"
        },
        {
            "sha": "4ea7a66fb39929c6c1c8097d343d3567035c026a",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=4b34e48e7f4e85d9670792971fa79249d76d4e55",
            "patch": "@@ -3022,8 +3022,7 @@ GpuCompiler::LoadExecutableFromAotResult(\n   }\n \n   auto ir_emitter = IrEmitterUnnested::Create(&ir_emitter_context);\n-  TF_RETURN_IF_ERROR(\n-      ir_emitter->EmitHloComputation(hlo_module->entry_computation()));\n+  TF_RETURN_IF_ERROR(ir_emitter->EmitHloEntryComputation(hlo_module.get()));\n \n   // Get all other fields required by GpuExecutable.\n   std::vector<GpuExecutable::ConstantInfo> constants ="
        },
        {
            "sha": "047bc94d00fd6ca51ec2652b7fb6bcda3a9eb23b",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=4b34e48e7f4e85d9670792971fa79249d76d4e55",
            "patch": "@@ -3416,6 +3416,11 @@ absl::Status IrEmitterUnnested::EmitHloInstruction(\n   return Internal(\"Unhandled HLO instruction\");\n }\n \n+absl::Status IrEmitterUnnested::EmitHloEntryComputation(\n+    const HloModule* module) {\n+  return EmitHloComputation(module->entry_computation());\n+}\n+\n absl::Status IrEmitterUnnested::EmitHloComputation(\n     const HloComputation* computation) {\n   const HloSchedule& schedule = computation->parent()->schedule();"
        },
        {
            "sha": "274d45c18311ee7d3dfbb356aff190e32456933a",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.h",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4b34e48e7f4e85d9670792971fa79249d76d4e55/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h?ref=4b34e48e7f4e85d9670792971fa79249d76d4e55",
            "patch": "@@ -96,6 +96,11 @@ class IrEmitterUnnested : public IrEmitter {\n                                              std::move(thunk_sequence_));\n   }\n \n+  absl::Status EmitHloEntryComputation(const HloModule* module);\n+\n+ private:\n+  explicit IrEmitterUnnested(IrEmitterContext* ir_emitter_context);\n+\n   // Emits code for the given HLO computation.\n   //\n   // Also populates related information to 'ir_emitter_context_' for\n@@ -105,9 +110,6 @@ class IrEmitterUnnested : public IrEmitter {\n   // generated code will have empty 'content'.\n   absl::Status EmitHloComputation(const HloComputation* computation);\n \n- private:\n-  explicit IrEmitterUnnested(IrEmitterContext* ir_emitter_context);\n-\n   absl::Status EmitCommandBufferThunk(const HloInstruction* instr);\n \n   // IrEmitterUnnested handles the following instructions differently from"
        }
    ],
    "stats": {
        "total": 19,
        "additions": 12,
        "deletions": 7
    }
}