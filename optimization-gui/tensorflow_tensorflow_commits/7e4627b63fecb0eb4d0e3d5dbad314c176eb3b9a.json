{
    "author": "majiddadashi",
    "message": "Add support for kTfLiteInt2 type export/import.\n\nThis change introduces a new `kTfLiteInt2` type to the TFLite schema and MLIR converter. It includes:\n-   Adding `INT2` to the flatbuffer schema.\n-   Mapping `TensorType_INT2` to `kTfLiteInt2` in flatbuffer conversions.\n-   Updating `tflite_types.h` to include `kTfLiteInt2`.\n-   Modifying `flatbuffer_export.cc` to handle 2-bit integer types from MLIR and pack them densely.\n-   Generalizing low-bit utility functions (`PackLowBitValuesDensely`, `UnpackDenseLowBitIntoInt8`) to support both 2-bit and 4-bit values.\n-   Updating type conversion utilities to recognize and handle `kTfLiteInt2`.\n-   Adjusting `util.cc` to correctly report the size and byte requirements for `kTfLiteInt2` tensors, considering their dense packing.\n\nPiperOrigin-RevId: 819821231",
    "sha": "7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
    "files": [
        {
            "sha": "ba8cc53e9be441949ef9146576f751335d2fc849",
            "filename": "RELEASE.md",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/RELEASE.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/RELEASE.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/RELEASE.md?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -22,6 +22,7 @@\n * `tf.lite`\n     * Adds int8 and int16x8 support for SQRT operator.\n     * Adds int16x8 support for EQUAL and NOT_EQUAL operators.\n+    * AddsÂ support for int2 type.\n \n ### Bug Fixes and Other Changes\n "
        },
        {
            "sha": "7facd69ecca298449cd703e0817798ee8af685eb",
            "filename": "tensorflow/compiler/mlir/lite/core/api/flatbuffer_conversions.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -341,6 +341,7 @@ using tflite::TensorType_FLOAT16;\n using tflite::TensorType_FLOAT32;\n using tflite::TensorType_FLOAT64;\n using tflite::TensorType_INT16;\n+using tflite::TensorType_INT2;\n using tflite::TensorType_INT32;\n using tflite::TensorType_INT4;\n using tflite::TensorType_INT64;\n@@ -1400,6 +1401,9 @@ absl::Status ConvertTensorType(TensorType tensor_type, TfLiteType* type) {\n     case TensorType_INT4:\n       *type = kTfLiteInt4;\n       return OkStatus();\n+    case TensorType_INT2:\n+      *type = kTfLiteInt2;\n+      return OkStatus();\n     default:\n       *type = kTfLiteNoType;\n       auto error_message ="
        },
        {
            "sha": "f09923dda5fc7c5fb9289b1a97b16d7cce74ccd0",
            "filename": "tensorflow/compiler/mlir/lite/core/c/tflite_types.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fc%2Ftflite_types.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fc%2Ftflite_types.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fcore%2Fc%2Ftflite_types.h?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -64,6 +64,7 @@ typedef enum {\n   kTfLiteUInt16 = 17,\n   kTfLiteInt4 = 18,\n   kTfLiteBFloat16 = 19,\n+  kTfLiteInt2 = 20,\n } TfLiteType;\n // LINT.ThenChange(//tensorflow/lite/profiling/proto/model_runtime_info.proto:EdgeDataType)\n "
        },
        {
            "sha": "41dffc228a6b2ccd7b375a896f5ee2b80a929bdf",
            "filename": "tensorflow/compiler/mlir/lite/flatbuffer_export.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 8,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fflatbuffer_export.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fflatbuffer_export.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fflatbuffer_export.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -217,6 +217,13 @@ static StatusOr<tflite::TensorType> GetTFLiteType(Type type,\n     switch (itype.getWidth()) {\n       case 1:\n         return tflite::TensorType_BOOL;\n+      case 2:\n+        if (itype.isUnsigned()) {\n+          return Status(absl::StatusCode::kInvalidArgument,\n+                        \"Unsupported 2bit unsigned int type\");\n+        } else {\n+          return tflite::TensorType_INT2;\n+        }\n       case 4:\n         if (itype.isUnsigned()) {\n           return Status(absl::StatusCode::kInvalidArgument,\n@@ -879,7 +886,7 @@ class Translator {\n   std::vector<std::unique_ptr<char[], std::function<void(char*)>>>\n       string_buffers_to_delete_;\n   std::vector<std::unique_ptr<std::vector<uint8_t>>>\n-      packed_int4_buffers_to_delete_;\n+      packed_low_bit_buffers_to_delete_;\n \n   // Maps custom options data to corresponding node\n   // Key is set to be the list of input tensor indices and list of output tensor\n@@ -1027,18 +1034,21 @@ std::optional<BufferOffset<tflite::Buffer>> Translator::BuildBuffer(\n   auto type = mlir::cast<TensorType>(value.getType());\n   tflite::TensorType tflite_element_type =\n       GetTFLiteType(type.getElementType()).value();\n-  if (tflite_element_type == tflite::TensorType_INT4) {\n+  if (tflite_element_type == tflite::TensorType_INT4 ||\n+      tflite_element_type == tflite::TensorType_INT2) {\n     std::vector<uint8_t> data;\n     for (mlir::APInt v : attr.getValues<mlir::APInt>()) {\n       data.emplace_back(static_cast<uint8_t>(*(v.getRawData())));\n     }\n-    auto packed_buffer = std::make_unique<std::vector<uint8_t>>(\n-        tflite::PackInt4ValuesDensely(data));\n+    auto packed_buffer =\n+        std::make_unique<std::vector<uint8_t>>(tflite::PackLowBitValuesDensely(\n+            data, /*bit_width=*/(\n+                tflite_element_type == tflite::TensorType_INT4 ? 4 : 2)));\n     if (use_buffer_offset_) {\n       buffer_data_map_[index] =\n           absl::string_view(reinterpret_cast<char*>(packed_buffer->data()),\n                             packed_buffer->size());\n-      packed_int4_buffers_to_delete_.emplace_back(std::move(packed_buffer));\n+      packed_low_bit_buffers_to_delete_.emplace_back(std::move(packed_buffer));\n       return tflite::CreateBuffer(builder_, 0, 1, 1);\n     } else {\n       if (IsModelBiggerThan2GB(packed_buffer->size())) {\n@@ -4239,10 +4249,10 @@ std::optional<std::string> Translator::TranslateInternal() {\n \n   // Free all the buffers/tensors, etc. that were created but were kept around\n   // to copy into the flatbuffer.\n-  for (auto& packed_int4_buffer : packed_int4_buffers_to_delete_) {\n-    packed_int4_buffer.reset();\n+  for (auto& packed_low_bit_buffer : packed_low_bit_buffers_to_delete_) {\n+    packed_low_bit_buffer.reset();\n   }\n-  packed_int4_buffers_to_delete_.clear();\n+  packed_low_bit_buffers_to_delete_.clear();\n \n   for (auto& str_buffer : string_buffers_to_delete_) {\n     str_buffer.reset();"
        },
        {
            "sha": "01a214ab2c03bf7ea1e850cc0088cebe17ee746e",
            "filename": "tensorflow/compiler/mlir/lite/schema/schema.fbs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema.fbs",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema.fbs",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema.fbs?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -59,6 +59,7 @@ enum TensorType : byte {\n   UINT16 = 16,\n   INT4 = 17,\n   BFLOAT16 = 18,\n+  INT2 = 19,\n }\n \n // Custom quantization parameters for experimenting with new quantization"
        },
        {
            "sha": "b04076af12a07400852dd90a59e0c7f93f7f8b23",
            "filename": "tensorflow/compiler/mlir/lite/schema/schema_generated.h",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fschema%2Fschema_generated.h?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -717,11 +717,12 @@ enum TensorType : int8_t {\n   TensorType_UINT16 = 16,\n   TensorType_INT4 = 17,\n   TensorType_BFLOAT16 = 18,\n+  TensorType_INT2 = 19,\n   TensorType_MIN = TensorType_FLOAT32,\n-  TensorType_MAX = TensorType_BFLOAT16\n+  TensorType_MAX = TensorType_INT2\n };\n \n-inline const TensorType (&EnumValuesTensorType())[19] {\n+inline const TensorType (&EnumValuesTensorType())[20] {\n   static const TensorType values[] = {\n     TensorType_FLOAT32,\n     TensorType_FLOAT16,\n@@ -741,13 +742,14 @@ inline const TensorType (&EnumValuesTensorType())[19] {\n     TensorType_UINT32,\n     TensorType_UINT16,\n     TensorType_INT4,\n-    TensorType_BFLOAT16\n+    TensorType_BFLOAT16,\n+    TensorType_INT2\n   };\n   return values;\n }\n \n inline const char * const *EnumNamesTensorType() {\n-  static const char * const names[20] = {\n+  static const char * const names[21] = {\n     \"FLOAT32\",\n     \"FLOAT16\",\n     \"INT32\",\n@@ -767,13 +769,14 @@ inline const char * const *EnumNamesTensorType() {\n     \"UINT16\",\n     \"INT4\",\n     \"BFLOAT16\",\n+    \"INT2\",\n     nullptr\n   };\n   return names;\n }\n \n inline const char *EnumNameTensorType(TensorType e) {\n-  if (::flatbuffers::IsOutRange(e, TensorType_FLOAT32, TensorType_BFLOAT16)) return \"\";\n+  if (::flatbuffers::IsOutRange(e, TensorType_FLOAT32, TensorType_INT2)) return \"\";\n   const size_t index = static_cast<size_t>(e);\n   return EnumNamesTensorType()[index];\n }"
        },
        {
            "sha": "12fab673d6e43b4764c4da9a6583528f6bc4adf2",
            "filename": "tensorflow/compiler/mlir/lite/utils/const_tensor_utils.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconst_tensor_utils.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -301,9 +301,17 @@ StatusOr<mlir::ElementsAttr> ConvertIntBuffer(\n       return mlir::ElementsAttr(\n           DenseElementsAttr::get(shaped_type, ArrayRef<bool>(boolValues)));\n     }\n+    case 2: {\n+      auto i2Values = tflite::UnpackDenseLowBitIntoInt8(\n+          buffer, shaped_type.getNumElements(), /*bit_width=*/2);\n+      // Use `getFromRawBuffer()` instead of `get()` to bypass a templated size\n+      // check which doesn't work with int2 because int2_t doesn't exist.\n+      return mlir::ElementsAttr(DenseElementsAttr::getFromRawBuffer(\n+          shaped_type, ArrayRef<char>(i2Values)));\n+    }\n     case 4: {\n-      auto i4Values =\n-          tflite::UnpackDenseInt4IntoInt8(buffer, shaped_type.getNumElements());\n+      auto i4Values = tflite::UnpackDenseLowBitIntoInt8(\n+          buffer, shaped_type.getNumElements(), /*bit_width=*/4);\n       // Use `getFromRawBuffer()` instead of `get()` to bypass a templated size\n       // check which doesn't work with int4 because int4_t doesn't exist.\n       return mlir::ElementsAttr(DenseElementsAttr::getFromRawBuffer("
        },
        {
            "sha": "d774055fd2928a5fbb429a323c0605a23ab1103c",
            "filename": "tensorflow/compiler/mlir/lite/utils/convert_type.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconvert_type.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconvert_type.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Fconvert_type.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -114,6 +114,8 @@ mlir::Type ConvertElementType(tflite::TensorType type, mlir::Builder builder) {\n       return mlir::ComplexType::get(builder.getF32Type());\n     case tflite::TensorType_COMPLEX128:\n       return mlir::ComplexType::get(builder.getF64Type());\n+    case tflite::TensorType_INT2:\n+      return builder.getIntegerType(2);\n     case tflite::TensorType_INT4:\n       return builder.getIntegerType(4);\n     case tflite::TensorType_INT8:\n@@ -143,7 +145,9 @@ tensorflow::DataType TflTypeToTfType(tflite::TensorType type) {\n       return tensorflow::DT_FLOAT;\n     case tflite::TensorType_FLOAT64:\n       return tensorflow::DT_DOUBLE;\n-    // TODO(b/246806634): Tensorflow DT_INT4 type doesn't exist yet\n+    // TODO(b/246806634): Tensorflow DT_INT2/4 type doesn't exist yet\n+    case tflite::TensorType_INT2:\n+      return tensorflow::DT_INT8;\n     case tflite::TensorType_INT4:\n       return tensorflow::DT_INT8;\n     case tflite::TensorType_INT8:"
        },
        {
            "sha": "d0710f8b4d49d81552aba594cb943416f5f7eb83",
            "filename": "tensorflow/compiler/mlir/lite/utils/low_bit_utils.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -21,39 +21,41 @@ limitations under the License.\n \n namespace tflite {\n \n-std::vector<uint8_t> PackInt4ValuesDensely(std::vector<uint8_t> src_buffer) {\n+std::vector<uint8_t> PackLowBitValuesDensely(std::vector<uint8_t> src_buffer,\n+                                             int bit_width) {\n   auto num_elements = src_buffer.size();\n-  auto packed_size = (num_elements + 1) / 2;\n-  std::vector<uint8_t> packed_buffer((num_elements + 1) / 2);\n+  const int elements_per_byte = 8 / bit_width;\n+  auto packed_size = (num_elements + elements_per_byte - 1) / elements_per_byte;\n+  std::vector<uint8_t> packed_buffer(packed_size, 0);\n+  const uint8_t mask = (1 << bit_width) - 1;\n \n-  for (int i = 0; i < num_elements - 1; i += 2) {\n-    packed_buffer[i / 2] = src_buffer[i] & 0x0F;\n-    packed_buffer[i / 2] |= src_buffer[i + 1] << 4;\n-  }\n-\n-  // Copy the final nibble if the buffer is odd-lengthed\n-  if (num_elements % 2 != 0) {\n-    packed_buffer[packed_size - 1] = src_buffer[num_elements - 1] & 0x0F;\n+  for (int i = 0; i < num_elements; ++i) {\n+    int byte_index = i / elements_per_byte;\n+    int bit_offset = (i % elements_per_byte) * bit_width;\n+    packed_buffer[byte_index] |= (src_buffer[i] & mask) << bit_offset;\n   }\n \n   return packed_buffer;\n }\n \n-std::vector<char> UnpackDenseInt4IntoInt8(\n-    const std::vector<uint8_t>& src_buffer, int64_t num_elements) {\n+std::vector<char> UnpackDenseLowBitIntoInt8(\n+    const std::vector<uint8_t>& src_buffer, int64_t num_elements,\n+    int bit_width) {\n   std::vector<char> unpacked_buffer;\n   unpacked_buffer.reserve(num_elements);\n+  const int elements_per_byte = 8 / bit_width;\n+  const int sign_bit_shift = 8 - bit_width;\n \n   for (uint8_t value : src_buffer) {\n-    // Cast to signed before right-shifting to ensure correct sign extension\n-    unpacked_buffer.push_back(static_cast<int8_t>(value << 4) >> 4);\n-    unpacked_buffer.push_back(static_cast<int8_t>(value) >> 4);\n-  }\n-\n-  // The last element might be a padded zero, so check and pop if needed\n-  if (unpacked_buffer.size() > num_elements) {\n-    assert(unpacked_buffer.size() == num_elements + 1);\n-    unpacked_buffer.pop_back();\n+    for (int i = 0; i < elements_per_byte; ++i) {\n+      if (unpacked_buffer.size() == num_elements) break;\n+      int bit_offset = i * bit_width;\n+      uint8_t extracted_value = (value >> bit_offset);\n+      // Sign extend\n+      unpacked_buffer.push_back(\n+          static_cast<int8_t>(extracted_value << sign_bit_shift) >>\n+          sign_bit_shift);\n+    }\n   }\n \n   return unpacked_buffer;"
        },
        {
            "sha": "f0633410a45c66d923d1fa49255f0fe00a561c8a",
            "filename": "tensorflow/compiler/mlir/lite/utils/low_bit_utils.h",
            "status": "modified",
            "additions": 12,
            "deletions": 11,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Futils%2Flow_bit_utils.h?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -20,17 +20,18 @@ limitations under the License.\n #include <vector>\n \n namespace tflite {\n-// Assumes that `src_tensor` is a buffer where each element is a 4-bit value\n-// stored in 8-bit.\n-// Returns a new buffer that is packed densely with 2 4-bit values in a byte.\n-// The packing format is low-bits-first, i.e. the lower nibble of a byte is\n-// filled first, followed by the upper nibble.\n-std::vector<uint8_t> PackInt4ValuesDensely(std::vector<uint8_t> src_buffer);\n-\n-// Assumes `src_buffer` contains 2 4-bit elements packed in 8-bit.\n-// Returns a vector where each int8 element contains a int4 sign-extended value.\n-std::vector<char> UnpackDenseInt4IntoInt8(\n-    const std::vector<uint8_t>& src_buffer, int64_t num_elements);\n+// Assumes that `src_tensor` is a buffer where each element is a low bit value\n+// (e.g. 2 or 4-bit) stored in 8-bit.\n+// Returns a new buffer that is packed densely.\n+// The packing format is low-bits-first.\n+std::vector<uint8_t> PackLowBitValuesDensely(std::vector<uint8_t> src_buffer,\n+                                             int bit_width);\n+\n+// Assumes `src_buffer` contains densely packed low bit elements.\n+// Returns a vector where each int8 element contains a sign-extended value.\n+std::vector<char> UnpackDenseLowBitIntoInt8(\n+    const std::vector<uint8_t>& src_buffer, int64_t num_elements,\n+    int bit_width);\n }  // namespace tflite\n \n #endif  // TENSORFLOW_COMPILER_MLIR_LITE_UTILS_LOW_BIT_UTILS_H_"
        },
        {
            "sha": "cc31fb4471459228a40bb437649a8fa140b13b8c",
            "filename": "tensorflow/lite/core/api/flatbuffer_conversions.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Fapi%2Fflatbuffer_conversions.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -1088,6 +1088,9 @@ TfLiteStatus ConvertTensorType(TensorType tensor_type, TfLiteType* type,\n     case TensorType_INT4:\n       *type = kTfLiteInt4;\n       return kTfLiteOk;\n+    case TensorType_INT2:\n+      *type = kTfLiteInt2;\n+      return kTfLiteOk;\n     default:\n       *type = kTfLiteNoType;\n       TF_LITE_REPORT_ERROR(error_reporter,"
        },
        {
            "sha": "5d483bdf9774762629097d91e52ab11d4cc9a33d",
            "filename": "tensorflow/lite/core/c/common.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Fc%2Fcommon.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Fc%2Fcommon.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Fc%2Fcommon.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -509,6 +509,8 @@ const char* TfLiteTypeGetName(TfLiteType type) {\n       return \"VARIANT\";\n     case kTfLiteInt4:\n       return \"INT4\";\n+    case kTfLiteInt2:\n+      return \"INT2\";\n   }\n   return \"Unknown type\";\n }"
        },
        {
            "sha": "701c1e0673534f517f01f8cf3135aea1b3d0e13d",
            "filename": "tensorflow/lite/core/tools/verifier.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Ftools%2Fverifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fcore%2Ftools%2Fverifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fcore%2Ftools%2Fverifier.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -428,11 +428,11 @@ bool VerifyNumericTensorBuffer(const Tensor& tensor, const Buffer& buffer,\n     case TensorType_UINT32:\n       bytes_required *= sizeof(uint32_t);\n       break;\n+    case TensorType_INT2:\n+      bytes_required = (bytes_required + 3) / 4;\n+      break;\n     case TensorType_INT4:\n-      // TODO(b/246647008): Multiplying this value by the number of elements\n-      // does not yield the size of a tensor when 4-bit values are packed\n-      // 2 to a byte.\n-      bytes_required *= sizeof(int8_t);\n+      bytes_required = (bytes_required + 1) / 2;\n       break;\n     case TensorType_UINT8:\n       bytes_required *= sizeof(uint8_t);"
        },
        {
            "sha": "9f8ae414fc91774feabc2755a42825ff511eff87",
            "filename": "tensorflow/lite/delegates/flex/util.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fdelegates%2Fflex%2Futil.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fdelegates%2Fflex%2Futil.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fflex%2Futil.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -101,6 +101,9 @@ TF_DataType GetTensorFlowDataType(TfLiteType type) {\n       return TF_INT32;\n     case kTfLiteUInt32:\n       return TF_UINT32;\n+    case kTfLiteInt2:\n+      // TODO(b/246806634): Tensorflow DT_INT2/4 type doesn't exist yet\n+      return TF_INT8;\n     case kTfLiteInt4:\n       // TODO(b/246806634): Tensorflow DT_INT4 type doesn't exist yet\n       return TF_INT8;\n@@ -185,6 +188,8 @@ const char* TfLiteTypeToTfTypeName(TfLiteType type) {\n       return \"int32\";\n     case kTfLiteUInt32:\n       return \"uint32\";\n+    case kTfLiteInt2:\n+      return \"int2\";\n     case kTfLiteInt4:\n       return \"int4\";\n     case kTfLiteUInt8:"
        },
        {
            "sha": "b7a1e544c9666bd235bcbfb928a716f6a3426676",
            "filename": "tensorflow/lite/delegates/gpu/common/model_builder_helper.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fmodel_builder_helper.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fmodel_builder_helper.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fgpu%2Fcommon%2Fmodel_builder_helper.h?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -192,6 +192,8 @@ absl::Status CreateVectorCopyData(const TfLiteTensor& src, T* dst) {\n         return absl::OkStatus();\n       case kTfLiteInt4:\n         return absl::UnimplementedError(\"src can't be int4.\");\n+      case kTfLiteInt2:\n+        return absl::UnimplementedError(\"src can't be int2.\");\n     }\n   }\n }"
        },
        {
            "sha": "a69a6a1fe8418d6ebeef626d4383a8a569921096",
            "filename": "tensorflow/lite/objc/sources/TFLCommonUtil.mm",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fobjc%2Fsources%2FTFLCommonUtil.mm",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fobjc%2Fsources%2FTFLCommonUtil.mm",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fobjc%2Fsources%2FTFLCommonUtil.mm?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -56,6 +56,7 @@ TFLTensorDataType TFLTensorDataTypeFromCTensor(const TfLiteTensor *cTensor) {\n     case kTfLiteUInt32:\n     case kTfLiteUInt64:\n     case kTfLiteInt4:\n+    case kTfLiteInt2:\n     case kTfLiteResource:\n     case kTfLiteVariant:\n       // Not all datatypes are supported in the TfLite Objc API."
        },
        {
            "sha": "99025999e4082cfaf3a3f344a26aa5fd7565dbb1",
            "filename": "tensorflow/lite/optional_debug_tools.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Foptional_debug_tools.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Foptional_debug_tools.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Foptional_debug_tools.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -397,6 +397,8 @@ const char* TensorTypeName(TfLiteType type) {\n       return \"kTfLiteVariant\";\n     case kTfLiteInt4:\n       return \"kTfLiteInt4\";\n+    case kTfLiteInt2:\n+      return \"kTfLiteInt2\";\n   }\n   return \"(invalid)\";\n }"
        },
        {
            "sha": "a2f906903ecdbcf200a2c4fd405e15d378f8a5a3",
            "filename": "tensorflow/lite/profiling/proto/model_runtime_info.proto",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fprofiling%2Fproto%2Fmodel_runtime_info.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fprofiling%2Fproto%2Fmodel_runtime_info.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fprofiling%2Fproto%2Fmodel_runtime_info.proto?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -118,6 +118,7 @@ message Edge {\n     UINT16 = 17;\n     INT4 = 18;\n     BFLOAT16 = 19;\n+    INT2 = 20;\n   }\n   // LINT.ThenChange(//tensorflow/lite/profiling/model_runtime_info.cc:EdgeDataTypeTransform)\n "
        },
        {
            "sha": "096e8a879908a1e00beb2245e02a26532e1d74e3",
            "filename": "tensorflow/lite/python/interpreter_wrapper/numpy.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Fnumpy.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Fnumpy.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fpython%2Finterpreter_wrapper%2Fnumpy.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -55,6 +55,9 @@ int TfLiteTypeToPyArrayType(TfLiteType tf_lite_type) {\n     case kTfLiteInt4:\n       // TODO(b/246806634): NPY_INT4 currently doesn't exist\n       return NPY_BYTE;\n+    case kTfLiteInt2:\n+      // TODO(b/246806634): NPY_INT2 currently doesn't exist\n+      return NPY_BYTE;\n     case kTfLiteUInt8:\n       return NPY_UINT8;\n     case kTfLiteInt8:"
        },
        {
            "sha": "2e9dcd47d22fe3f6c23a194d14031de844e8fbf7",
            "filename": "tensorflow/lite/python/optimize/calibration_wrapper.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fpython%2Foptimize%2Fcalibration_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Fpython%2Foptimize%2Fcalibration_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fpython%2Foptimize%2Fcalibration_wrapper.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -122,6 +122,8 @@ inline TensorType TfLiteTypeToSchemaType(TfLiteType type) {\n       return TensorType_INT32;\n     case kTfLiteUInt32:\n       return TensorType_UINT32;\n+    case kTfLiteInt2:\n+      return TensorType_INT2;\n     case kTfLiteInt4:\n       return TensorType_INT4;\n     case kTfLiteUInt8:"
        },
        {
            "sha": "771f5293b1e4bb9eb2e4de37c0ebb0ce9d20691b",
            "filename": "tensorflow/lite/tools/serialization/enum_mapping.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Ftools%2Fserialization%2Fenum_mapping.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Ftools%2Fserialization%2Fenum_mapping.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Ftools%2Fserialization%2Fenum_mapping.h?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -74,6 +74,8 @@ inline TensorType TfLiteTypeToSchemaType(TfLiteType type) {\n       return TensorType_UINT32;\n     case kTfLiteInt4:\n       return TensorType_INT4;\n+    case kTfLiteInt2:\n+      return TensorType_INT2;\n     case kTfLiteUInt8:\n       return TensorType_UINT8;\n     case kTfLiteInt8:"
        },
        {
            "sha": "05f90d30bce07ac8630ce7030cf261c186371f6a",
            "filename": "tensorflow/lite/util.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 2,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Futil.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a/tensorflow%2Flite%2Futil.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Futil.cc?ref=7e4627b63fecb0eb4d0e3d5dbad314c176eb3b9a",
            "patch": "@@ -133,12 +133,22 @@ TfLiteStatus GetSizeOfType(TfLiteContext* context, const TfLiteType type,\n       // 2 to a byte.\n       *bytes = sizeof(int8_t);\n       break;\n+    case kTfLiteInt2:\n+      // Similar to Int4, Int2 values are packed. Multiple Int2 values\n+      // (specifically 4) are stored within a single byte. However, this\n+      // function is expected to return the size of a single element as if it\n+      // were unpacked. When unpacked, each Int2 value would occupy the space\n+      // of an int8_t to be addressable in memory. The actual packed size\n+      // is handled in the BytesRequired function.\n+      *bytes = sizeof(int8_t);\n+      break;\n     default:\n       if (context) {\n         TF_LITE_KERNEL_LOG(\n             context,\n-            \"Type %d is unsupported. Only float16, float32, float64, int8, \"\n-            \"int16, int32, int64, uint8, uint64, bool, complex64 and \"\n+            \"Type %d is unsupported. Only float16, float32, float64, int2, \"\n+            \"int4, \"\n+            \"int8, int16, int32, int64, uint8, uint64, bool, complex64 and \"\n             \"complex128 supported currently.\",\n             type);\n       }\n@@ -218,6 +228,19 @@ TfLiteStatus BytesRequired(TfLiteType type, const int* dims, size_t dims_size,\n   // Thus the required bytes must be divided by half after everything for int4.\n   if (type == kTfLiteInt4) {\n     *bytes = (*bytes + 1) / 2;\n+  } else if (type == kTfLiteInt2) {\n+    // For kTfLiteInt2, 4 elements are packed into a single byte.\n+    // The '*bytes' variable at this point holds the total number of elements,\n+    // because GetSizeOfType returns sizeof(int8_t) for each Int2 element.\n+    // To get the actual number of bytes needed for the packed representation,\n+    // we need to divide the total number of elements by 4.\n+    // The expression `(*bytes + 3) / 4` implements integer division with\n+    // ceiling, ensuring that we allocate enough bytes to store all elements.\n+    // For example:\n+    // 1 element: (1 + 3) / 4 = 1 byte\n+    // 4 elements: (4 + 3) / 4 = 1 byte\n+    // 5 elements: (5 + 3) / 4 = 2 bytes\n+    *bytes = (*bytes + 3) / 4;\n   }\n \n   return kTfLiteOk;"
        }
    ],
    "stats": {
        "total": 191,
        "additions": 136,
        "deletions": 55
    }
}