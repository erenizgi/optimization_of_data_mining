{
    "author": "akuegel",
    "message": "[XLA:GPU] Enable maximum unroll factor 8 heuristic by default.\n\nThis heuristic should improve runtime on Blackwell architecture for fusions\nwith small data types (<= 16 bits).\n\nPiperOrigin-RevId: 833308087",
    "sha": "dc0aec4e1d66a2fc1a25151e89ae17179ee2ffec",
    "files": [
        {
            "sha": "9036a32be27a74d9b13e18c0e27c13f22efc4f8a",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dc0aec4e1d66a2fc1a25151e89ae17179ee2ffec/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dc0aec4e1d66a2fc1a25151e89ae17179ee2ffec/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=dc0aec4e1d66a2fc1a25151e89ae17179ee2ffec",
            "patch": "@@ -457,7 +457,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_gpu_unsupported_enable_all_reduce_decomposer(false);\n   opts.set_xla_gpu_experimental_use_autotuner_pass(false);\n   opts.set_xla_gpu_experimental_enable_fusion_autotuner(true);\n-  opts.set_xla_gpu_experimental_allow_unroll_factor_eight(false);\n+  opts.set_xla_gpu_experimental_allow_unroll_factor_eight(true);\n   opts.set_xla_gpu_experimental_pack_dot_operands_along_k_dimension(true);\n   opts.set_xla_unsupported_crash_on_hlo_pass_fix_max_iterations(false);\n   opts.set_xla_hlo_pass_fix_detect_cycles(false);"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}