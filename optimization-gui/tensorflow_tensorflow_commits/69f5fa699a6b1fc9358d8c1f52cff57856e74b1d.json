{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 829294787",
    "sha": "69f5fa699a6b1fc9358d8c1f52cff57856e74b1d",
    "files": [
        {
            "sha": "84c420c3ed6f9d524ba53500e868785aa10cec1c",
            "filename": "tensorflow/tools/benchmark/benchmark_model.cc",
            "status": "modified",
            "additions": 63,
            "deletions": 59,
            "changes": 122,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.cc?ref=69f5fa699a6b1fc9358d8c1f52cff57856e74b1d",
            "patch": "@@ -63,9 +63,9 @@ namespace benchmark_model {\n namespace {\n \n absl::Status InitializeVariables(Session* session,\n-                                 const std::vector<string>& init_ops) {\n+                                 const std::vector<std::string>& init_ops) {\n   LOG(INFO) << \"Initializing graph variables\";\n-  for (const string& init_op : init_ops) {\n+  for (const std::string& init_op : init_ops) {\n     TF_RETURN_IF_ERROR(session->Run({}, {}, {init_op}, nullptr));\n   }\n   return absl::OkStatus();\n@@ -85,16 +85,16 @@ void InitializeTensor(const std::vector<float>& initialization_values,\n \n void CreateTensorsFromInputInfo(\n     const std::vector<InputLayerInfo>& inputs,\n-    std::vector<std::pair<string, tensorflow::Tensor> >* input_tensors) {\n+    std::vector<std::pair<std::string, tensorflow::Tensor> >* input_tensors) {\n   for (const InputLayerInfo& input : inputs) {\n     Tensor input_tensor(input.data_type, input.shape);\n     switch (input.data_type) {\n       case DT_INT32: {\n-        InitializeTensor<int32>(input.initialization_values, &input_tensor);\n+        InitializeTensor<int32_t>(input.initialization_values, &input_tensor);\n         break;\n       }\n       case DT_INT64: {\n-        InitializeTensor<int64>(input.initialization_values, &input_tensor);\n+        InitializeTensor<int64_t>(input.initialization_values, &input_tensor);\n         break;\n       }\n       case DT_FLOAT: {\n@@ -106,7 +106,7 @@ void CreateTensorsFromInputInfo(\n         break;\n       }\n       case DT_UINT8: {\n-        InitializeTensor<uint8>(input.initialization_values, &input_tensor);\n+        InitializeTensor<uint8_t>(input.initialization_values, &input_tensor);\n         break;\n       }\n       case DT_BOOL: {\n@@ -131,15 +131,15 @@ void CreateTensorsFromInputInfo(\n \n absl::Status GetOutputShapes(\n     const std::vector<InputLayerInfo>& inputs,\n-    const std::set<string>& wanted_shapes, Session* session,\n-    std::unordered_map<string, TensorShape>* node_shapes) {\n-  std::vector<std::pair<string, tensorflow::Tensor> > input_tensors;\n+    const std::set<std::string>& wanted_shapes, Session* session,\n+    std::unordered_map<std::string, TensorShape>* node_shapes) {\n+  std::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors;\n   CreateTensorsFromInputInfo(inputs, &input_tensors);\n   std::vector<tensorflow::Tensor> output_tensors;\n-  std::vector<string> output_tensor_names;\n-  for (const string& wanted_shape : wanted_shapes) {\n+  std::vector<std::string> output_tensor_names;\n+  for (const std::string& wanted_shape : wanted_shapes) {\n     bool is_input = false;\n-    for (const std::pair<string, tensorflow::Tensor>& input_tensor :\n+    for (const std::pair<std::string, tensorflow::Tensor>& input_tensor :\n          input_tensors) {\n       if (input_tensor.first == wanted_shape) {\n         (*node_shapes)[wanted_shape] = input_tensor.second.shape();\n@@ -155,31 +155,31 @@ absl::Status GetOutputShapes(\n       session->Run(input_tensors, output_tensor_names, {}, &output_tensors));\n   CHECK_EQ(output_tensors.size(), output_tensor_names.size());\n   for (int i = 0; i < output_tensor_names.size(); ++i) {\n-    const string& wanted_shape_name = output_tensor_names[i];\n+    const std::string& wanted_shape_name = output_tensor_names[i];\n     const TensorShape& found_shape = output_tensors[i].shape();\n     (*node_shapes)[wanted_shape_name] = found_shape;\n   }\n   return absl::OkStatus();\n }\n \n-absl::Status CalculateFlops(const GraphDef& graph,\n-                            const std::vector<InputLayerInfo>& inputs,\n-                            Session* session, int64_t* total_flops,\n-                            std::unordered_map<string, int64_t>* flops_by_op) {\n-  std::unordered_set<string> floppable_ops = {\n+absl::Status CalculateFlops(\n+    const GraphDef& graph, const std::vector<InputLayerInfo>& inputs,\n+    Session* session, int64_t* total_flops,\n+    std::unordered_map<std::string, int64_t>* flops_by_op) {\n+  std::unordered_set<std::string> floppable_ops = {\n       \"Conv2D\", \"MatMul\", \"QuantizedConv2D\", \"QuantizedMatMul\",\n       \"DepthwiseConv2dNative\"};\n \n-  std::set<string> wanted_shapes;\n+  std::set<std::string> wanted_shapes;\n   for (const NodeDef& node : graph.node()) {\n     if (floppable_ops.count(node.op())) {\n-      for (const string& input : node.input()) {\n+      for (const std::string& input : node.input()) {\n         wanted_shapes.insert(input);\n       }\n       wanted_shapes.insert(node.name());\n     }\n   }\n-  std::unordered_map<string, TensorShape> found_shapes;\n+  std::unordered_map<std::string, TensorShape> found_shapes;\n   TF_RETURN_IF_ERROR(\n       GetOutputShapes(inputs, wanted_shapes, session, &found_shapes));\n \n@@ -228,10 +228,10 @@ absl::Status CalculateFlops(const GraphDef& graph,\n   return absl::OkStatus();\n }\n \n-void RecordBenchmarkEntry(const string& output_prefix,\n-                          const string& benchmark_name, const string& postfix,\n-                          int num_runs, double total_time_s,\n-                          double throughput = -1.0) {\n+void RecordBenchmarkEntry(const std::string& output_prefix,\n+                          const std::string& benchmark_name,\n+                          const std::string& postfix, int num_runs,\n+                          double total_time_s, double throughput = -1.0) {\n   std::stringstream stream;\n   stream << benchmark_name;\n   if (!postfix.empty()) {\n@@ -262,7 +262,7 @@ void SleepSeconds(double sleep_seconds) {\n \n }  // namespace\n \n-absl::Status InitializeSession(int num_threads, const string& graph,\n+absl::Status InitializeSession(int num_threads, const std::string& graph,\n                                std::unique_ptr<Session>* session,\n                                std::unique_ptr<GraphDef>* graph_def) {\n   LOG(INFO) << \"Loading TensorFlow.\";\n@@ -298,10 +298,11 @@ absl::Status InitializeSession(int num_threads, const string& graph,\n }\n \n absl::Status RunBenchmark(const std::vector<InputLayerInfo>& inputs,\n-                          const std::vector<string>& outputs,\n-                          const std::vector<string>& targets, Session* session,\n-                          StatSummarizer* stats, int64_t* inference_time_us) {\n-  std::vector<std::pair<string, tensorflow::Tensor> > input_tensors;\n+                          const std::vector<std::string>& outputs,\n+                          const std::vector<std::string>& targets,\n+                          Session* session, StatSummarizer* stats,\n+                          int64_t* inference_time_us) {\n+  std::vector<std::pair<std::string, tensorflow::Tensor> > input_tensors;\n   CreateTensorsFromInputInfo(inputs, &input_tensors);\n \n   std::vector<tensorflow::Tensor> output_tensors;\n@@ -337,8 +338,8 @@ absl::Status RunBenchmark(const std::vector<InputLayerInfo>& inputs,\n absl::Status TimeMultipleRuns(double sleep_seconds, int num_runs,\n                               double max_time_s,\n                               const std::vector<InputLayerInfo>& inputs,\n-                              const std::vector<string>& outputs,\n-                              const std::vector<string>& targets,\n+                              const std::vector<std::string>& outputs,\n+                              const std::vector<std::string>& targets,\n                               Session* session, StatSummarizer* stats,\n                               int64_t* total_time_us,\n                               int64_t* actual_num_runs) {\n@@ -384,21 +385,21 @@ absl::Status TimeMultipleRuns(double sleep_seconds, int num_runs,\n }\n \n int Main(int argc, char** argv) {\n-  string graph = \"/data/local/tmp/tensorflow_inception_graph.pb\";\n-  string init_ops_string = \"\";\n-  string input_layer_string = \"input:0\";\n-  string input_layer_shape_string = \"1,224,224,3\";\n-  string input_layer_type_string = \"float\";\n-  string input_layer_values_string = \"\";\n-  string output_layer_string = \"output:0\";\n-  string target_layer_string = \"\";\n+  std::string graph = \"/data/local/tmp/tensorflow_inception_graph.pb\";\n+  std::string init_ops_string = \"\";\n+  std::string input_layer_string = \"input:0\";\n+  std::string input_layer_shape_string = \"1,224,224,3\";\n+  std::string input_layer_type_string = \"float\";\n+  std::string input_layer_values_string = \"\";\n+  std::string output_layer_string = \"output:0\";\n+  std::string target_layer_string = \"\";\n   int max_num_runs = 1000;\n-  string max_time = \"10.0\";\n-  string inference_delay = \"-1.0\";\n-  string inter_benchmark_delay = \"-1.0\";\n+  std::string max_time = \"10.0\";\n+  std::string inference_delay = \"-1.0\";\n+  std::string inter_benchmark_delay = \"-1.0\";\n   int num_threads = -1;\n-  string benchmark_name = \"\";\n-  string output_prefix = \"\";\n+  std::string benchmark_name = \"\";\n+  std::string output_prefix = \"\";\n   bool show_sizes = false;\n   bool show_run_order = true;\n   int run_order_limit = 0;\n@@ -446,24 +447,27 @@ int Main(int argc, char** argv) {\n       Flag(\"show_flops\", &show_flops, \"whether to estimate the model's FLOPs\"),\n       Flag(\"warmup_runs\", &warmup_runs, \"how many runs to initialize model\"),\n   };\n-  string usage = Flags::Usage(argv[0], flag_list);\n+  std::string usage = Flags::Usage(argv[0], flag_list);\n   const bool parse_result = Flags::Parse(&argc, argv, flag_list);\n \n   if (!parse_result) {\n     LOG(ERROR) << usage;\n     return -1;\n   }\n \n-  std::vector<string> init_ops = str_util::Split(init_ops_string, ',');\n-  std::vector<string> input_layers = str_util::Split(input_layer_string, ',');\n-  std::vector<string> input_layer_shapes =\n+  std::vector<std::string> init_ops = str_util::Split(init_ops_string, ',');\n+  std::vector<std::string> input_layers =\n+      str_util::Split(input_layer_string, ',');\n+  std::vector<std::string> input_layer_shapes =\n       str_util::Split(input_layer_shape_string, ':');\n-  std::vector<string> input_layer_types =\n+  std::vector<std::string> input_layer_types =\n       str_util::Split(input_layer_type_string, ',');\n-  std::vector<string> input_layer_values =\n+  std::vector<std::string> input_layer_values =\n       str_util::Split(input_layer_values_string, ':');\n-  std::vector<string> output_layers = str_util::Split(output_layer_string, ',');\n-  std::vector<string> target_layers = str_util::Split(target_layer_string, ',');\n+  std::vector<std::string> output_layers =\n+      str_util::Split(output_layer_string, ',');\n+  std::vector<std::string> target_layers =\n+      str_util::Split(target_layer_string, ',');\n   if ((input_layers.size() != input_layer_shapes.size()) ||\n       (input_layers.size() != input_layer_types.size())) {\n     LOG(ERROR) << \"There must be the same number of items in --input_layer,\"\n@@ -552,9 +556,9 @@ int Main(int argc, char** argv) {\n     CHECK(DataTypeFromString(input_layer_types[n], &input.data_type))\n         << input_layer_types[n] << \" was an invalid type\";\n \n-    std::vector<string> split_layer_shapes =\n+    std::vector<std::string> split_layer_shapes =\n         str_util::Split(input_layer_shapes[n], ',');\n-    for (const string& layer_shape : split_layer_shapes) {\n+    for (const std::string& layer_shape : split_layer_shapes) {\n       int32_t tmp;\n       CHECK(absl::SimpleAtoi(layer_shape, &tmp))\n           << \"Incorrect size string specified: \" << input_layer_shapes[n];\n@@ -568,11 +572,11 @@ int Main(int argc, char** argv) {\n     }\n     input.name = input_layers[n];\n     if (n < input_layer_values.size()) {\n-      std::vector<string> string_tokens =\n+      std::vector<std::string> string_tokens =\n           str_util::Split(input_layer_values[n], ',');\n       input.initialization_values.clear();\n       input.initialization_values.reserve(string_tokens.size());\n-      for (const string& str_val : string_tokens) {\n+      for (const std::string& str_val : string_tokens) {\n         float val;\n         CHECK(absl::SimpleAtof(str_val, &val))\n             << \"Incorrect initialization values string specified: \"\n@@ -641,14 +645,14 @@ int Main(int argc, char** argv) {\n \n   if (show_flops) {\n     int64_t total_flops;\n-    std::unordered_map<string, int64_t> flops_by_op;\n+    std::unordered_map<std::string, int64_t> flops_by_op;\n     absl::Status flop_status = CalculateFlops(*graph_def, inputs, session.get(),\n                                               &total_flops, &flops_by_op);\n     if (!flop_status.ok()) {\n       LOG(ERROR) << \"FLOPs calculation failed with \" << flop_status;\n       return -1;\n     }\n-    string pretty_flops;\n+    std::string pretty_flops;\n     if (total_flops < 1000) {\n       pretty_flops = absl::StrCat(total_flops, \" FLOPs\");\n     } else if (total_flops < (1000 * 1000)) {"
        },
        {
            "sha": "de476688339044eefccccd8179fdbb13799cf04d",
            "filename": "tensorflow/tools/benchmark/benchmark_model.h",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model.h?ref=69f5fa699a6b1fc9358d8c1f52cff57856e74b1d",
            "patch": "@@ -33,29 +33,30 @@ namespace benchmark_model {\n \n // Used to help construct dummy inputs for the benchmarking.\n struct InputLayerInfo {\n-  string name;\n+  std::string name;\n   DataType data_type;\n   TensorShape shape;\n   std::vector<float> initialization_values;\n };\n \n // Loads a model from disk into a new session.\n-absl::Status InitializeSession(int num_threads, const string& graph,\n+absl::Status InitializeSession(int num_threads, const std::string& graph,\n                                std::unique_ptr<Session>* session,\n                                std::unique_ptr<GraphDef>* graph_def);\n \n // Does a single run of the model that's been loaded into the given session.\n absl::Status RunBenchmark(const std::vector<InputLayerInfo>& inputs,\n-                          const std::vector<string>& outputs,\n-                          const std::vector<string>& targets, Session* session,\n-                          StatSummarizer* stats, int64_t* inference_time_us);\n+                          const std::vector<std::string>& outputs,\n+                          const std::vector<std::string>& targets,\n+                          Session* session, StatSummarizer* stats,\n+                          int64_t* inference_time_us);\n \n // Runs the model multiple time, keeping track of timing information.\n absl::Status TimeMultipleRuns(double sleep_seconds, int num_runs,\n                               double max_time_s,\n                               const std::vector<InputLayerInfo>& inputs,\n-                              const std::vector<string>& outputs,\n-                              const std::vector<string>& targets,\n+                              const std::vector<std::string>& outputs,\n+                              const std::vector<std::string>& targets,\n                               Session* session, StatSummarizer* stats,\n                               int64_t* total_time_us, int64_t* actual_num_runs);\n "
        },
        {
            "sha": "d09558ed194feac2697a0ea56fd4778ebfdf7ef2",
            "filename": "tensorflow/tools/benchmark/benchmark_model_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/69f5fa699a6b1fc9358d8c1f52cff57856e74b1d/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Fbenchmark%2Fbenchmark_model_test.cc?ref=69f5fa699a6b1fc9358d8c1f52cff57856e74b1d",
            "patch": "@@ -39,7 +39,7 @@ namespace {\n \n void CreateTestGraph(const ::tensorflow::Scope& root,\n                      benchmark_model::InputLayerInfo* input,\n-                     string* output_name, GraphDef* graph_def) {\n+                     std::string* output_name, GraphDef* graph_def) {\n   // Create a simple graph and write it to filename_pb.\n   const int input_width = 400;\n   const int input_height = 10;\n@@ -59,15 +59,15 @@ void CreateTestGraph(const ::tensorflow::Scope& root,\n }\n \n TEST(BenchmarkModelTest, InitializeAndRun) {\n-  const string dir = testing::TmpDir();\n-  const string filename_pb = io::JoinPath(dir, \"graphdef.pb\");\n+  const std::string dir = testing::TmpDir();\n+  const std::string filename_pb = io::JoinPath(dir, \"graphdef.pb\");\n   auto root = Scope::NewRootScope().ExitOnError();\n \n   benchmark_model::InputLayerInfo input;\n-  string output_name;\n+  std::string output_name;\n   GraphDef graph_def;\n   CreateTestGraph(root, &input, &output_name, &graph_def);\n-  string graph_def_serialized;\n+  std::string graph_def_serialized;\n   graph_def.SerializeToString(&graph_def_serialized);\n   TF_ASSERT_OK(\n       WriteStringToFile(Env::Default(), filename_pb, graph_def_serialized));\n@@ -88,12 +88,12 @@ TEST(BenchmarkModelTest, InitializeAndRun) {\n }\n \n TEST(BenchmarkModeTest, TextProto) {\n-  const string dir = testing::TmpDir();\n-  const string filename_txt = io::JoinPath(dir, \"graphdef.pb.txt\");\n+  const std::string dir = testing::TmpDir();\n+  const std::string filename_txt = io::JoinPath(dir, \"graphdef.pb.txt\");\n   auto root = Scope::NewRootScope().ExitOnError();\n \n   benchmark_model::InputLayerInfo input;\n-  string output_name;\n+  std::string output_name;\n   GraphDef graph_def;\n   CreateTestGraph(root, &input, &output_name, &graph_def);\n   TF_ASSERT_OK(WriteTextProto(Env::Default(), filename_txt, graph_def));"
        }
    ],
    "stats": {
        "total": 153,
        "additions": 79,
        "deletions": 74
    }
}