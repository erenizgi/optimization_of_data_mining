{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@a1de9aca1150\n\nUpdates LLVM usage to match\n[a1de9aca1150](https://github.com/llvm/llvm-project/commit/a1de9aca1150)\n\nPiperOrigin-RevId: 807656101",
    "sha": "9c0b717b934b02ff28d9ae6a468c7a60c7994009",
    "files": [
        {
            "sha": "398055687ae8d4f2bb5da9386ea75eb1fe6c4a96",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 816,
            "deletions": 462,
            "changes": 1278,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -34,18 +34,6 @@ diff -ruN --strip-trailing-cr a/clang/include/clang/Analysis/FlowSensitive/Stora\n    llvm::iterator_range<FieldToLoc::const_iterator> children() const {\n      return {Children.begin(), Children.end()};\n    }\n-diff -ruN --strip-trailing-cr a/clang/include/clang/AST/DeclCXX.h b/clang/include/clang/AST/DeclCXX.h\n---- a/clang/include/clang/AST/DeclCXX.h\n-+++ b/clang/include/clang/AST/DeclCXX.h\n-@@ -3826,7 +3826,7 @@\n- \n- public:\n-   EnumDecl *getEnumDecl() const {\n--    return cast<clang::EnumType>(EnumType->getType())->getOriginalDecl();\n-+    return EnumType->getType()->castAs<clang::EnumType>()->getOriginalDecl();\n-   }\n- \n-   static UsingEnumDecl *Create(ASTContext &C, DeclContext *DC,\n diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n --- a/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n +++ b/clang/lib/Analysis/FlowSensitive/Transfer.cpp\n@@ -165,326 +153,19 @@ diff -ruN --strip-trailing-cr a/clang/lib/Analysis/FlowSensitive/Transfer.cpp b/\n    void VisitConditionalOperator(const ConditionalOperator *S) {\n      const Environment *TrueEnv = StmtToEnv.getEnvironment(*S->getTrueExpr());\n      const Environment *FalseEnv = StmtToEnv.getEnvironment(*S->getFalseExpr());\n-diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTImporter.cpp b/clang/lib/AST/ASTImporter.cpp\n---- a/clang/lib/AST/ASTImporter.cpp\n-+++ b/clang/lib/AST/ASTImporter.cpp\n-@@ -1740,10 +1740,21 @@\n- }\n- \n- ExpectedType ASTNodeImporter::VisitTagType(const TagType *T) {\n--  Expected<TagDecl *> ToDeclOrErr = import(T->getOriginalDecl());\n-+  TagDecl *DeclForType = T->getOriginalDecl();\n-+  Expected<TagDecl *> ToDeclOrErr = import(DeclForType);\n-   if (!ToDeclOrErr)\n-     return ToDeclOrErr.takeError();\n- \n-+  if (DeclForType->isUsed()) {\n-+    // If there is a definition of the 'OriginalDecl', it should be imported to\n-+    // have all information for the type in the \"To\" AST. (In some cases no\n-+    // other reference may exist to the definition decl and it would not be\n-+    // imported otherwise.)\n-+    Expected<TagDecl *> ToDefDeclOrErr = import(DeclForType->getDefinition());\n-+    if (!ToDefDeclOrErr)\n-+      return ToDefDeclOrErr.takeError();\n-+  }\n-+\n-   if (T->isCanonicalUnqualified())\n-     return Importer.getToContext().getCanonicalTagType(*ToDeclOrErr);\n- \n-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaDecl.cpp b/clang/lib/Sema/SemaDecl.cpp\n---- a/clang/lib/Sema/SemaDecl.cpp\n-+++ b/clang/lib/Sema/SemaDecl.cpp\n-@@ -5291,10 +5291,8 @@\n-     //   UNION_TYPE;   <- where UNION_TYPE is a typedef union.\n-     if ((Tag && Tag->getDeclName()) ||\n-         DS.getTypeSpecType() == DeclSpec::TST_typename) {\n--      RecordDecl *Record = dyn_cast_or_null<RecordDecl>(Tag);\n--      if (!Record)\n--        Record = DS.getRepAsType().get()->getAsRecordDecl();\n--\n-+      RecordDecl *Record = Tag ? dyn_cast<RecordDecl>(Tag)\n-+                               : DS.getRepAsType().get()->getAsRecordDecl();\n-       if (Record && getLangOpts().MicrosoftExt) {\n-         Diag(DS.getBeginLoc(), diag::ext_ms_anonymous_record)\n-             << Record->isUnion() << DS.getSourceRange();\n-@@ -18052,7 +18050,8 @@\n-           }\n-         }\n-       } else if (auto *RD = dyn_cast<CXXRecordDecl>(PrevDecl);\n--                 RD && RD->isInjectedClassName()) {\n-+                 TUK == TagUseKind::Reference && RD &&\n-+                 RD->isInjectedClassName()) {\n-         // If lookup found the injected class name, the previous declaration is\n-         // the class being injected into.\n-         PrevDecl = cast<TagDecl>(RD->getDeclContext());\n-@@ -18544,8 +18543,14 @@\n-   if (PrevDecl)\n-     CheckRedeclarationInModule(New, PrevDecl);\n- \n--  if (TUK == TagUseKind::Definition && (!SkipBody || !SkipBody->ShouldSkip))\n--    New->startDefinition();\n-+  if (TUK == TagUseKind::Definition) {\n-+    if (!SkipBody || !SkipBody->ShouldSkip) {\n-+      New->startDefinition();\n-+    } else {\n-+      New->setCompleteDefinition();\n-+      New->demoteThisDefinitionToDeclaration();\n-+    }\n-+  }\n- \n-   ProcessDeclAttributeList(S, New, Attrs);\n-   AddPragmaAttributes(S, New);\n-diff -ruN --strip-trailing-cr a/clang/lib/Sema/SemaType.cpp b/clang/lib/Sema/SemaType.cpp\n---- a/clang/lib/Sema/SemaType.cpp\n-+++ b/clang/lib/Sema/SemaType.cpp\n-@@ -9878,7 +9878,14 @@\n-   S.DiagnoseUseOfDecl(ED, Loc);\n- \n-   QualType Underlying = ED->getIntegerType();\n--  assert(!Underlying.isNull());\n-+  if (Underlying.isNull()) {\n-+    // This is an enum without a fixed underlying type which we skipped parsing\n-+    // the body because we saw its definition previously in another module.\n-+    // Use the definition's integer type in that case.\n-+    assert(ED->isThisDeclarationADemotedDefinition());\n-+    Underlying = ED->getDefinition()->getIntegerType();\n-+    assert(!Underlying.isNull());\n-+  }\n- \n-   return Underlying;\n- }\n-diff -ruN --strip-trailing-cr a/clang/lib/Serialization/ASTReaderDecl.cpp b/clang/lib/Serialization/ASTReaderDecl.cpp\n---- a/clang/lib/Serialization/ASTReaderDecl.cpp\n-+++ b/clang/lib/Serialization/ASTReaderDecl.cpp\n-@@ -2107,6 +2107,8 @@\n-     auto *Def = DD.Definition;\n-     DD = std::move(MergeDD);\n-     DD.Definition = Def;\n-+    while ((Def = Def->getPreviousDecl()))\n-+      cast<CXXRecordDecl>(Def)->DefinitionData = &DD;\n-     return;\n+diff -ruN --strip-trailing-cr a/clang/lib/AST/ASTContext.cpp b/clang/lib/AST/ASTContext.cpp\n+--- a/clang/lib/AST/ASTContext.cpp\n++++ b/clang/lib/AST/ASTContext.cpp\n+@@ -5316,7 +5316,8 @@\n    }\n  \n-diff -ruN --strip-trailing-cr a/clang/test/Analysis/ctu-import-type-decl-definition.c b/clang/test/Analysis/ctu-import-type-decl-definition.c\n---- a/clang/test/Analysis/ctu-import-type-decl-definition.c\n-+++ b/clang/test/Analysis/ctu-import-type-decl-definition.c\n-@@ -0,0 +1,43 @@\n-+// RUN: rm -rf %t\n-+// RUN: mkdir -p %t\n-+// RUN: split-file %s %t\n-+\n-+// RUN: %clang_cc1 -emit-pch -o %t/import.c.ast %t/import.c\n-+\n-+// RUN: %clang_extdef_map -- -x c %t/import.c >> %t/externalDefMap.txt\n-+// RUN: sed -i 's/$/.ast/' %t/externalDefMap.txt\n-+\n-+// RUN: %clang_cc1 -analyze \\\n-+// RUN:   -analyzer-checker=core \\\n-+// RUN:   -analyzer-config experimental-enable-naive-ctu-analysis=true \\\n-+// RUN:   -analyzer-config display-ctu-progress=true \\\n-+// RUN:   -analyzer-config ctu-dir=%t \\\n-+// RUN:   -verify %t/main.c\n-+\n-+//--- main.c\n-+\n-+// expected-no-diagnostics\n-+\n-+typedef struct X_s X_t;\n-+unsigned long f_import(struct X_s *xPtr);\n-+\n-+static void freeWriteFileResources(struct X_s *xPtr) {\n-+  f_import(xPtr);\n-+}\n-+\n-+//--- import.c\n-+\n-+typedef struct Y_s Y_t;\n-+\n-+struct Y_s {\n-+};\n-+\n-+struct X_s {\n-+  Y_t y;\n-+};\n-+\n-+unsigned long f_import(struct X_s *xPtr) {\n-+  if (xPtr != 0) {\n-+  }\n-+  return 0;\n-+}\n-diff -ruN --strip-trailing-cr a/clang/test/AST/ast-dump-decl.cpp b/clang/test/AST/ast-dump-decl.cpp\n---- a/clang/test/AST/ast-dump-decl.cpp\n-+++ b/clang/test/AST/ast-dump-decl.cpp\n-@@ -990,3 +990,18 @@\n-   // CHECK-NEXT:    `-RecordType [[TestInjectedClassName_RT]] 'A' injected\n-   // CHECK-NEXT:      `-CXXRecord [[TestInjectedClassName_RD]] 'A'\n- } // namespace InjectedClassName\n-+\n-+namespace TestGH155936 {\n-+  struct Foo {\n-+    struct A {\n-+      struct Foo {};\n-+    };\n-+  };\n-+  // CHECK-LABEL: Dumping TestGH155936:\n-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-6]]:10 struct Foo definition\n-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:3, col:10> col:10 implicit struct Foo\n-+  // CHECK: CXXRecordDecl 0x{{.+}} <{{.+}}> line:[[@LINE-7]]:12 struct A definition\n-+  // CHECK: CXXRecordDecl 0x{{.+}} <col:5, col:12> col:12 implicit struct A\n-+  // CHECK: CXXRecordDecl 0x{{.+}} <line:[[@LINE-8]]:7, col:19> col:14 struct Foo definition\n-+  // CHECH: CXXRecordDecl 0x{{.+}} <col:9, col:16> col:16 implicit struct Foo\n-+} // namspace GH155936\n-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH154840.cpp b/clang/test/Modules/GH154840.cpp\n---- a/clang/test/Modules/GH154840.cpp\n-+++ b/clang/test/Modules/GH154840.cpp\n-@@ -0,0 +1,97 @@\n-+// RUN: rm -rf %t\n-+// RUN: mkdir -p %t\n-+// RUN: split-file %s %t\n-+// RUN: cd %t\n-+//\n-+// RUN: %clang_cc1 -fmodule-name=A -fno-cxx-modules -emit-module -fmodules -xc++ A.cppmap -o A.pcm\n-+// RUN: %clang_cc1 -fmodule-name=B -fno-cxx-modules -emit-module -fmodules -xc++ B.cppmap -o B.pcm -fmodule-file=A.pcm\n-+// RUN: %clang_cc1 -fmodule-name=C -fno-cxx-modules -emit-module -fmodules -xc++ C.cppmap -o C.pcm -fmodule-file=A.pcm\n-+// RUN: %clang_cc1 -fmodule-name=D -fno-cxx-modules -emit-module -fmodules -xc++ D.cppmap -o D.pcm -fmodule-file=A.pcm\n-+// RUN: %clang_cc1 -fmodule-name=E -fno-cxx-modules -emit-module -fmodules -xc++ E.cppmap -o E.pcm -fmodule-file=D.pcm -fmodule-file=B.pcm -fmodule-file=C.pcm\n-+// RUN: %clang_cc1 -fno-cxx-modules -fmodules -fmodule-file=B.pcm -fmodule-file=E.pcm -emit-llvm -o /dev/null S.cpp\n-+\n-+//--- A.h\n-+namespace std {\n-+\n-+template <class T> void zz(T);\n-+\n-+template <class> struct vec {\n-+  struct w {};\n-+  struct xx {};\n-+\n-+  vec(vec &) { init(); }\n-+  constexpr vec &operator=(const vec &);\n-+  template <class U> constexpr void pb(U);\n-+  constexpr void init();\n-+\n-+  w s;\n-+};\n-+\n-+template <class T> constexpr void vec<T>::init() {\n-+  xx yy;\n-+  zz(yy);\n-+}\n-+\n-+template <class T> constexpr vec<T> &vec<T>::operator=(const vec &) {\n-+  pb(s);\n-+  return *this;\n-+}\n-+\n-+template <class T> template <class U> constexpr void vec<T>::pb(U) { init(); }\n-+} // namespace std\n-+\n-+//--- A.cppmap\n-+module \"A\" {\n-+  header \"A.h\"\n-+}\n-+\n-+//--- X.h\n-+#pragma clang module import A\n-+\n-+namespace project {\n-+  class thing : std::vec<thing> {};\n-+} // namespace project\n-+\n-+//--- B.h\n-+#include \"X.h\"\n-+\n-+//--- B.cppmap\n-+module \"B\" {\n-+  header \"B.h\"\n-+}\n-+\n-+//--- C.h\n-+#include \"X.h\"\n-+\n-+//--- C.cppmap\n-+module \"C\" {\n-+  header \"C.h\"\n-+}\n-+\n-+//--- D.h\n-+#include \"X.h\"\n-+\n-+//--- D.cppmap\n-+module \"D\" {\n-+  header \"D.h\"\n-+}\n-+\n-+//--- Y.h\n-+#include \"X.h\"\n-+struct other {\n-+  other() : data(data) {}\n-+  std::vec<project::thing> data;\n-+};\n-+\n-+//--- E.h\n-+#include \"Y.h\"\n-+\n-+//--- E.cppmap\n-+module \"E\" {\n-+  header \"E.h\"\n-+}\n-+\n-+//--- S.cpp\n-+#pragma clang module import A\n-+#pragma clang module import E\n-+void func(std::vec<project::thing> *a, std::vec<project::thing> *b) { *a = *b; }\n-diff -ruN --strip-trailing-cr a/clang/test/Modules/GH155028-1.cpp b/clang/test/Modules/GH155028-1.cpp\n---- a/clang/test/Modules/GH155028-1.cpp\n-+++ b/clang/test/Modules/GH155028-1.cpp\n-@@ -0,0 +1,17 @@\n-+// RUN: %clang_cc1 -std=c++20 -verify %s\n-+// expected-no-diagnostics\n-+\n-+#pragma clang module build M\n-+module \"M\" {\n-+  module \"A\" {}\n-+  module \"B\" {}\n-+}\n-+#pragma clang module contents\n-+#pragma clang module begin M.A\n-+enum E1 {};\n-+#pragma clang module end\n-+#pragma clang module begin M.B\n-+enum E1 {};\n-+using T = __underlying_type(E1);\n-+#pragma clang module end\n-+#pragma clang module endbuild\n-diff -ruN --strip-trailing-cr a/clang/test/Sema/GH155794.c b/clang/test/Sema/GH155794.c\n---- a/clang/test/Sema/GH155794.c\n-+++ b/clang/test/Sema/GH155794.c\n-@@ -0,0 +1,6 @@\n-+// RUN: %clang_cc1 -fsyntax-only -verify -Wno-everything %s\n-+\n-+struct S {\n-+  enum e1 {} // expected-error {{use of empty enum}} expected-error {{expected ';' after enum}}\n-+  enum e2 {} // expected-error {{use of empty enum}}\n-+}; // expected-error {{expected member name or ';' after declaration specifiers}}\n-diff -ruN --strip-trailing-cr a/clang/test/SemaTemplate/using-decl.cpp b/clang/test/SemaTemplate/using-decl.cpp\n---- a/clang/test/SemaTemplate/using-decl.cpp\n-+++ b/clang/test/SemaTemplate/using-decl.cpp\n-@@ -14,3 +14,15 @@\n-   }\n-   void e() { c<int>(); }\n- }\n-+\n-+namespace UsingUsingEnum {\n-+  namespace foo {\n-+    enum class EnumOne {};\n-+  }\n-+  using foo::EnumOne;\n-+\n-+  template <class> void t() {\n-+    using enum EnumOne;\n-+  }\n-+  template void t<void>();\n-+} // namespace UsingUsingEnum\n+   llvm::FoldingSetNodeID ID;\n+-  TypedefType::Profile(ID, Keyword, Qualifier, Decl, UnderlyingType);\n++  TypedefType::Profile(ID, Keyword, Qualifier, Decl,\n++                       *TypeMatchesDeclOrNone ? QualType() : UnderlyingType);\n+ \n+   void *InsertPos = nullptr;\n+   if (FoldingSetPlaceholder<TypedefType> *Placeholder =\n diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n --- a/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n +++ b/clang/unittests/Analysis/FlowSensitive/TransferTest.cpp\n@@ -814,151 +495,824 @@ diff -ruN --strip-trailing-cr a/clang/unittests/Analysis/FlowSensitive/TransferT\n  TEST(TransferTest, IntegralCast) {\n    std::string Code = R\"(\n      void target(int Foo) {\n-diff -ruN --strip-trailing-cr a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py\n---- a/clang-tools-extra/test/clang-tidy/check_clang_tidy.py\n-+++ b/clang-tools-extra/test/clang-tidy/check_clang_tidy.py\n-@@ -391,9 +391,7 @@\n-     args, extra_args = parser.parse_known_args()\n-     if args.std is None:\n-         _, extension = os.path.splitext(args.assume_filename or args.input_file_name)\n--        args.std = [\n--            \"c++11-or-later\" if extension in [\".cpp\", \".hpp\", \".mm\"] else \"c99-or-later\"\n--        ]\n-+        args.std = [\"c99-or-later\" if extension in [\".c\", \".m\"] else \"c++11-or-later\"]\n- \n-     return (args, extra_args)\n- \n-diff -ruN --strip-trailing-cr a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n---- a/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n-+++ b/lldb/source/Plugins/SymbolFile/NativePDB/SymbolFileNativePDB.cpp\n-@@ -1735,11 +1735,11 @@\n-   }\n+diff -ruN --strip-trailing-cr a/llvm/include/llvm/Linker/IRMover.h b/llvm/include/llvm/Linker/IRMover.h\n+--- a/llvm/include/llvm/Linker/IRMover.h\n++++ b/llvm/include/llvm/Linker/IRMover.h\n+@@ -10,6 +10,7 @@\n+ #define LLVM_LINKER_IRMOVER_H\n  \n-   // Sort them before value searching is working properly.\n--  m_func_full_names.Sort();\n-+  m_func_full_names.Sort(std::less<uint32_t>());\n-   m_func_full_names.SizeToFit();\n--  m_func_method_names.Sort();\n-+  m_func_method_names.Sort(std::less<uint32_t>());\n-   m_func_method_names.SizeToFit();\n--  m_func_base_names.Sort();\n-+  m_func_base_names.Sort(std::less<uint32_t>());\n-   m_func_base_names.SizeToFit();\n- }\n+ #include \"llvm/ADT/ArrayRef.h\"\n++#include \"llvm/ADT/DenseMap.h\"\n+ #include \"llvm/ADT/DenseSet.h\"\n+ #include \"llvm/ADT/FunctionExtras.h\"\n+ #include \"llvm/Support/Compiler.h\"\n+@@ -19,6 +20,8 @@\n+ class Error;\n+ class GlobalValue;\n+ class Metadata;\n++class MDNode;\n++class NamedMDNode;\n+ class Module;\n+ class StructType;\n+ class TrackingMDRef;\n+@@ -67,6 +70,8 @@\n+   using LazyCallback =\n+       llvm::unique_function<void(GlobalValue &GV, ValueAdder Add)>;\n  \n-@@ -2426,7 +2426,7 @@\n++  using NamedMDNodesT = DenseMap<const NamedMDNode *, DenseSet<const MDNode *>>;\n++\n+   /// Move in the provide values in \\p ValuesToLink from \\p Src.\n+   ///\n+   /// - \\p AddLazyFor is a call back that the IRMover will call when a global\n+@@ -86,6 +91,7 @@\n+   Module &Composite;\n+   IdentifiedStructTypeSet IdentifiedStructTypes;\n+   MDMapT SharedMDs; ///< A Metadata map to use for all calls to \\a move().\n++  NamedMDNodesT NamedMDNodes; ///< Cache for IRMover::linkNamedMDNodes().\n+ };\n  \n-   // After calling Append(), the type-name map needs to be sorted again to be\n-   // able to look up a type by its name.\n--  m_type_base_names.Sort();\n-+  m_type_base_names.Sort(std::less<uint32_t>());\n+ } // End llvm namespace\n+diff -ruN --strip-trailing-cr a/llvm/lib/Linker/IRMover.cpp b/llvm/lib/Linker/IRMover.cpp\n+--- a/llvm/lib/Linker/IRMover.cpp\n++++ b/llvm/lib/Linker/IRMover.cpp\n+@@ -293,7 +293,7 @@\n+   std::unique_ptr<Module> SrcM;\n  \n-   // Now that we know the forward -> full mapping of all type indices, we can\n-   // re-write all the indices.  At the end of this process, we want a mapping\n-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp\n---- a/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp\n-+++ b/lldb/tools/lldb-dap/Handler/ModuleSymbolsRequestHandler.cpp\n-@@ -60,7 +60,7 @@\n-     if (!symbol.IsValid())\n-       continue;\n+   // Lookup table to optimize IRMover::linkNamedMDNodes().\n+-  DenseMap<StringRef, DenseSet<MDNode *>> NamedMDNodes;\n++  IRMover::NamedMDNodesT &NamedMDNodes;\n  \n--    Symbol dap_symbol;\n-+    Symbol dap_symbol = {};\n-     dap_symbol.id = symbol.GetID();\n-     dap_symbol.type = symbol.GetType();\n-     dap_symbol.isDebug = symbol.IsDebug();\n-diff -ruN --strip-trailing-cr a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts\n---- a/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts\n-+++ b/lldb/tools/lldb-dap/src-ts/ui/symbols-provider.ts\n-@@ -61,18 +61,18 @@\n-       return;\n-     }\n+   /// See IRMover::move().\n+   IRMover::LazyCallback AddLazyFor;\n+@@ -440,10 +440,12 @@\n+   IRLinker(Module &DstM, MDMapT &SharedMDs,\n+            IRMover::IdentifiedStructTypeSet &Set, std::unique_ptr<Module> SrcM,\n+            ArrayRef<GlobalValue *> ValuesToLink,\n+-           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport)\n+-      : DstM(DstM), SrcM(std::move(SrcM)), AddLazyFor(std::move(AddLazyFor)),\n+-        TypeMap(Set), GValMaterializer(*this), LValMaterializer(*this),\n+-        SharedMDs(SharedMDs), IsPerformingImport(IsPerformingImport),\n++           IRMover::LazyCallback AddLazyFor, bool IsPerformingImport,\n++           IRMover::NamedMDNodesT &NamedMDNodes)\n++      : DstM(DstM), SrcM(std::move(SrcM)), NamedMDNodes(NamedMDNodes),\n++        AddLazyFor(std::move(AddLazyFor)), TypeMap(Set),\n++        GValMaterializer(*this), LValMaterializer(*this), SharedMDs(SharedMDs),\n++        IsPerformingImport(IsPerformingImport),\n+         Mapper(ValueMap, RF_ReuseAndMutateDistinctMDs | RF_IgnoreMissingLocals,\n+                &TypeMap, &GValMaterializer),\n+         IndirectSymbolMCID(Mapper.registerAlternateMappingContext(\n+@@ -1138,7 +1140,7 @@\n  \n--    this.showSymbolsForModule(session, selectedModule.module);\n-+    await this.showSymbolsForModule(session, selectedModule.module);\n-   }\n+     NamedMDNode *DestNMD = DstM.getOrInsertNamedMetadata(NMD.getName());\n  \n-   private async showSymbolsForModule(session: vscode.DebugSession, module: DebugProtocol.Module) {\n-     try {\n-       const symbols = await this.getSymbolsForModule(session, module.id.toString());\n--      this.showSymbolsInNewTab(module.name.toString(), symbols);\n-+      await this.showSymbolsInNewTab(module.name.toString(), symbols);\n-     } catch (error) {\n-       if (error instanceof Error) {\n--        vscode.window.showErrorMessage(\"Failed to retrieve symbols: \" + error.message);\n-+        await vscode.window.showErrorMessage(\"Failed to retrieve symbols: \" + error.message);\n+-    auto &Inserted = NamedMDNodes[DestNMD->getName()];\n++    auto &Inserted = NamedMDNodes[DestNMD];\n+     if (Inserted.empty()) {\n+       // Must be the first module, copy everything from DestNMD.\n+       Inserted.insert(DestNMD->operands().begin(), DestNMD->operands().end());\n+@@ -1683,6 +1685,6 @@\n+                     LazyCallback AddLazyFor, bool IsPerformingImport) {\n+   IRLinker TheIRLinker(Composite, SharedMDs, IdentifiedStructTypes,\n+                        std::move(Src), ValuesToLink, std::move(AddLazyFor),\n+-                       IsPerformingImport);\n++                       IsPerformingImport, NamedMDNodes);\n+   return TheIRLinker.run();\n+ }\n+diff -ruN --strip-trailing-cr a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n+--- a/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n++++ b/llvm/lib/Transforms/Vectorize/SLPVectorizer.cpp\n+@@ -5574,7 +5574,23 @@\n+       if (auto *SD = dyn_cast<ScheduleData>(Data)) {\n+         SD->setScheduled(/*Scheduled=*/true);\n+         LLVM_DEBUG(dbgs() << \"SLP:   schedule \" << *SD << \"\\n\");\n+-        ProcessBundleMember(SD, {});\n++        SmallVector<std::unique_ptr<ScheduleBundle>> PseudoBundles;\n++        SmallVector<ScheduleBundle *> Bundles;\n++        Instruction *In = SD->getInst();\n++        if (R.isVectorized(In)) {\n++          ArrayRef<TreeEntry *> Entries = R.getTreeEntries(In);\n++          for (TreeEntry *TE : Entries) {\n++            if (!isa<ExtractValueInst, ExtractElementInst, CallBase>(In) &&\n++                In->getNumOperands() != TE->getNumOperands())\n++              continue;\n++            auto &BundlePtr =\n++                PseudoBundles.emplace_back(std::make_unique<ScheduleBundle>());\n++            BundlePtr->setTreeEntry(TE);\n++            BundlePtr->add(SD);\n++            Bundles.push_back(BundlePtr.get());\n++          }\n++        }\n++        ProcessBundleMember(SD, Bundles);\n        } else {\n--        vscode.window.showErrorMessage(\"Failed to retrieve symbols due to an unknown error.\");\n-+        await vscode.window.showErrorMessage(\"Failed to retrieve symbols due to an unknown error.\");\n-       }\n-       \n-       return;\n-@@ -106,7 +106,7 @@\n-     const symbolsTableScriptPath = panel.webview.asWebviewUri(vscode.Uri.joinPath(this.getExtensionResourcePath(), \"symbols-table-view.js\"));\n- \n-     panel.webview.html = getSymbolsTableHTMLContent(tabulatorJsPath, tabulatorCssPath, symbolsTableScriptPath);\n--    panel.webview.postMessage({ command: \"updateSymbols\", symbols: symbols });\n-+    await panel.webview.postMessage({ command: \"updateSymbols\", symbols: symbols });\n-   }\n+         ScheduleBundle &Bundle = *cast<ScheduleBundle>(Data);\n+         Bundle.setScheduled(/*Scheduled=*/true);\n+@@ -20772,6 +20788,14 @@\n+           continue;\n+         }\n+         auto *SD = cast<ScheduleData>(SE);\n++        if (SD->hasValidDependencies() &&\n++            (!S.areInstructionsWithCopyableElements() ||\n++             !S.isCopyableElement(SD->getInst())) &&\n++            !getScheduleCopyableData(SD->getInst()).empty() && EI.UserTE &&\n++            EI.UserTE->hasState() &&\n++            (!EI.UserTE->hasCopyableElements() ||\n++             !EI.UserTE->isCopyableElement(SD->getInst())))\n++          SD->clearDirectDependencies();\n+         for (const Use &U : SD->getInst()->operands()) {\n+           unsigned &NumOps =\n+               UserOpToNumOps\n+@@ -20853,23 +20877,7 @@\n+   for (Value *V : VL) {\n+     if (S.isNonSchedulable(V))\n+       continue;\n+-    // For copybales with parent nodes, which do not need to be scheduled, the\n+-    // parents should not be commutative, otherwise may incorrectly handle deps\n+-    // because of the potential reordering of commutative operations.\n+-    if ((S.isCopyableElement(V) && EI.UserTE && !EI.UserTE->isGather() &&\n+-         EI.UserTE->hasState() && EI.UserTE->doesNotNeedToSchedule() &&\n+-         any_of(EI.UserTE->Scalars,\n+-                [&](Value *V) {\n+-                  if (isa<PoisonValue>(V))\n+-                    return false;\n+-                  auto *I = dyn_cast<Instruction>(V);\n+-                  return isCommutative(\n+-                      (I && EI.UserTE->isAltShuffle())\n+-                          ? EI.UserTE->getMatchingMainOpOrAltOp(I)\n+-                          : EI.UserTE->getMainOp(),\n+-                      V);\n+-                })) ||\n+-        !extendSchedulingRegion(V, S)) {\n++    if (!extendSchedulingRegion(V, S)) {\n+       // If the scheduling region got new instructions at the lower end (or it\n+       // is a new region for the first bundle). This makes it necessary to\n+       // recalculate all dependencies.\n+@@ -21889,6 +21897,10 @@\n+     return TryProcessInstruction(BitWidth);\n+   case Instruction::ZExt:\n+   case Instruction::SExt:\n++    if (E.UserTreeIndex.UserTE && E.UserTreeIndex.UserTE->hasState() &&\n++        E.UserTreeIndex.UserTE->getOpcode() == Instruction::BitCast &&\n++        E.UserTreeIndex.UserTE->getMainOp()->getType()->isFPOrFPVectorTy())\n++      return false;\n+     IsProfitableToDemote = true;\n+     return TryProcessInstruction(BitWidth);\n+ \n+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n+--- a/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n++++ b/llvm/test/Transforms/SLPVectorizer/X86/copyable-with-non-scheduled-parent-node.ll\n+@@ -4,20 +4,15 @@\n+ define i64 @test(ptr %a) {\n+ ; CHECK-LABEL: define i64 @test(\n+ ; CHECK-SAME: ptr [[A:%.*]]) #[[ATTR0:[0-9]+]] {\n+-; CHECK-NEXT:    [[TMP1:%.*]] = add i64 0, 0\n+ ; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr [[A]], align 4\n+-; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[TMP2]], 0\n+-; CHECK-NEXT:    [[TMP4:%.*]] = add i64 1, [[TMP1]]\n+-; CHECK-NEXT:    [[TMP5:%.*]] = ashr i64 0, 1\n+-; CHECK-NEXT:    [[TMP6:%.*]] = ashr i64 0, 0\n++; CHECK-NEXT:    [[TMP7:%.*]] = insertelement <4 x i64> <i64 poison, i64 0, i64 0, i64 0>, i64 [[TMP2]], i32 0\n++; CHECK-NEXT:    [[TMP3:%.*]] = add <4 x i64> zeroinitializer, [[TMP7]]\n++; CHECK-NEXT:    [[TMP4:%.*]] = add <4 x i64> <i64 0, i64 0, i64 0, i64 1>, [[TMP3]]\n++; CHECK-NEXT:    [[TMP5:%.*]] = shufflevector <4 x i64> [[TMP4]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP6:%.*]] = shufflevector <6 x i64> [[TMP5]], <6 x i64> <i64 0, i64 0, i64 undef, i64 undef, i64 undef, i64 undef>, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 6, i32 7>\n+ ; CHECK-NEXT:    br label %[[BB7:.*]]\n+ ; CHECK:       [[BB7]]:\n+-; CHECK-NEXT:    [[TMP8:%.*]] = phi i64 [ [[TMP3]], [[TMP0:%.*]] ]\n+-; CHECK-NEXT:    [[TMP9:%.*]] = phi i64 [ 0, [[TMP0]] ]\n+-; CHECK-NEXT:    [[TMP10:%.*]] = phi i64 [ [[TMP6]], [[TMP0]] ]\n+-; CHECK-NEXT:    [[TMP11:%.*]] = phi i64 [ [[TMP5]], [[TMP0]] ]\n+-; CHECK-NEXT:    [[TMP12:%.*]] = phi i64 [ 0, [[TMP0]] ]\n+-; CHECK-NEXT:    [[TMP13:%.*]] = phi i64 [ [[TMP4]], [[TMP0]] ]\n++; CHECK-NEXT:    [[TMP8:%.*]] = phi <6 x i64> [ [[TMP6]], [[TMP0:%.*]] ]\n+ ; CHECK-NEXT:    ret i64 0\n+ ;\n+   %1 = add i64 0, 0\n+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n+--- a/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n++++ b/llvm/test/Transforms/SLPVectorizer/X86/original-inst-scheduled-after-copyable.ll\n+@@ -0,0 +1,89 @@\n++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n++; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu -slp-threshold=-10 < %s | FileCheck %s\n++\n++define void @test(ptr %0, i32 %1, i32 %2) {\n++; CHECK-LABEL: define void @test(\n++; CHECK-SAME: ptr [[TMP0:%.*]], i32 [[TMP1:%.*]], i32 [[TMP2:%.*]]) {\n++; CHECK-NEXT:  [[ENTRY:.*:]]\n++; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr i8, ptr [[TMP0]], i64 48\n++; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr i8, ptr [[TMP0]], i64 56\n++; CHECK-NEXT:    [[TMP7:%.*]] = and i32 [[TMP2]], [[TMP1]]\n++; CHECK-NEXT:    [[ADD_NARROWED_I_I:%.*]] = shl i32 [[TMP1]], 1\n++; CHECK-NEXT:    [[TMP10:%.*]] = lshr i32 [[TMP7]], 1\n++; CHECK-NEXT:    [[TMP18:%.*]] = zext i32 [[ADD_NARROWED_I_I]] to i64\n++; CHECK-NEXT:    [[TMP19:%.*]] = add i64 [[TMP18]], -1\n++; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP19]] to i32\n++; CHECK-NEXT:    [[TMP28:%.*]] = insertelement <2 x i32> poison, i32 [[TMP21]], i32 0\n++; CHECK-NEXT:    [[TMP11:%.*]] = shufflevector <2 x i32> [[TMP28]], <2 x i32> poison, <2 x i32> zeroinitializer\n++; CHECK-NEXT:    [[TMP12:%.*]] = and <2 x i32> [[TMP11]], splat (i32 -2)\n++; CHECK-NEXT:    [[TMP13:%.*]] = insertelement <2 x i32> <i32 poison, i32 -2>, i32 [[TMP1]], i32 0\n++; CHECK-NEXT:    [[TMP14:%.*]] = or <2 x i32> [[TMP13]], [[TMP12]]\n++; CHECK-NEXT:    [[TMP15:%.*]] = xor <2 x i32> [[TMP13]], [[TMP12]]\n++; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i32> [[TMP14]], <2 x i32> [[TMP15]], <2 x i32> <i32 0, i32 3>\n++; CHECK-NEXT:    [[TMP17:%.*]] = load <2 x i32>, ptr [[TMP5]], align 8\n++; CHECK-NEXT:    [[TMP32:%.*]] = insertelement <2 x i32> <i32 1, i32 poison>, i32 [[TMP1]], i32 1\n++; CHECK-NEXT:    [[TMP33:%.*]] = and <2 x i32> [[TMP17]], [[TMP32]]\n++; CHECK-NEXT:    call void @llvm.stackrestore.p0(ptr null)\n++; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <2 x i32> [[TMP33]], <2 x i32> poison, <2 x i32> <i32 poison, i32 0>\n++; CHECK-NEXT:    [[TMP34:%.*]] = insertelement <2 x i32> [[TMP20]], i32 [[TMP10]], i32 0\n++; CHECK-NEXT:    [[TMP22:%.*]] = zext <2 x i32> [[TMP34]] to <2 x i64>\n++; CHECK-NEXT:    [[TMP23:%.*]] = zext <2 x i32> [[TMP33]] to <2 x i64>\n++; CHECK-NEXT:    [[TMP35:%.*]] = shl <2 x i64> [[TMP23]], splat (i64 1)\n++; CHECK-NEXT:    [[TMP25:%.*]] = or <2 x i64> [[TMP35]], [[TMP22]]\n++; CHECK-NEXT:    [[TMP26:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>\n++; CHECK-NEXT:    [[TMP27:%.*]] = trunc <2 x i64> [[TMP25]] to <2 x i32>\n++; CHECK-NEXT:    [[TMP24:%.*]] = tail call i32 asm sideeffect \"\", \"=r,0,~{dirflag},~{fpsr},~{flags}\"(i32 0)\n++; CHECK-NEXT:    store <2 x i32> [[TMP16]], ptr [[TMP3]], align 16\n++; CHECK-NEXT:    [[TMP29:%.*]] = shufflevector <2 x i32> [[TMP32]], <2 x i32> poison, <2 x i32> <i32 1, i32 1>\n++; CHECK-NEXT:    [[TMP30:%.*]] = and <2 x i32> [[TMP29]], [[TMP26]]\n++; CHECK-NEXT:    [[TMP31:%.*]] = or <2 x i32> [[TMP30]], [[TMP27]]\n++; CHECK-NEXT:    store <2 x i32> [[TMP31]], ptr [[TMP5]], align 8\n++; CHECK-NEXT:    ret void\n++;\n++entry:\n++  %3 = getelementptr i8, ptr %0, i64 48\n++  %4 = getelementptr i8, ptr %0, i64 52\n++  %5 = getelementptr i8, ptr %0, i64 56\n++  %6 = getelementptr i8, ptr %0, i64 60\n++  %.pre21.i = load i32, ptr %5, align 8\n++  %.pre23.i = load i32, ptr %6, align 4\n++  %7 = and i32 %2, %1\n++  %8 = and i32 %.pre21.i, 1\n++  %9 = and i32 %1, %.pre23.i\n++  call void @llvm.stackrestore.p0(ptr null)\n++  %add.narrowed.i.i = shl i32 %1, 1\n++  %10 = lshr i32 %7, 1\n++  %11 = zext i32 %10 to i64\n++  %12 = zext i32 %8 to i64\n++  %reass.add1.i = shl i64 %12, 1\n++  %13 = or i64 %reass.add1.i, %11\n++  %14 = trunc i64 %13 to i32\n++  %15 = zext i32 %9 to i64\n++  %reass.add2.i = shl i64 %15, 1\n++  %16 = or i64 %reass.add2.i, %12\n++  %17 = trunc i64 %16 to i32\n++  %18 = zext i32 %add.narrowed.i.i to i64\n++  %19 = add i64 %18, -1\n++  %20 = trunc i64 %19 to i32\n++  %21 = trunc i64 %19 to i32\n++  %22 = trunc i64 %13 to i32\n++  %23 = trunc i64 %16 to i32\n++  %24 = tail call i32 asm sideeffect \"\", \"=r,0,~{dirflag},~{fpsr},~{flags}\"(i32 0)\n++  %25 = and i32 %20, -2\n++  %26 = or i32 %1, %25\n++  store i32 %26, ptr %3, align 16\n++  %27 = and i32 %21, -2\n++  %28 = xor i32 %27, -2\n++  store i32 %28, ptr %4, align 4\n++  %29 = and i32 %1, %14\n++  %30 = or i32 %29, %22\n++  store i32 %30, ptr %5, align 8\n++  %31 = and i32 %1, %17\n++  %32 = or i32 %31, %23\n++  store i32 %32, ptr %6, align 4\n++  ret void\n++}\n++\n++declare void @llvm.stackrestore.p0(ptr) #0\n++\n++attributes #0 = { nocallback nofree nosync nounwind willreturn }\n+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n+--- a/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n++++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-bitcast-with-fp.ll\n+@@ -0,0 +1,36 @@\n++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n++; RUN: opt -S --passes=slp-vectorizer -mtriple=x86_64-unknown-linux-gnu < %s | FileCheck %s\n++\n++define i1 @test(i32 %0) {\n++; CHECK-LABEL: define i1 @test(\n++; CHECK-SAME: i32 [[TMP0:%.*]]) {\n++; CHECK-NEXT:  [[ENTRY:.*:]]\n++; CHECK-NEXT:    [[CONV22_I_I:%.*]] = sext i32 [[TMP0]] to i64\n++; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64 [[CONV22_I_I]] to double\n++; CHECK-NEXT:    [[TMP2:%.*]] = fadd double [[TMP1]], 0.000000e+00\n++; CHECK-NEXT:    [[ADD_I_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP2]]\n++; CHECK-NEXT:    [[TMP3:%.*]] = bitcast double [[ADD_I_I_I]] to i64\n++; CHECK-NEXT:    [[CMP3998_I_I:%.*]] = icmp ne i64 [[TMP3]], [[CONV22_I_I]]\n++; CHECK-NEXT:    [[CONV22_1_I_I:%.*]] = sext i32 0 to i64\n++; CHECK-NEXT:    [[TMP4:%.*]] = bitcast i64 [[CONV22_1_I_I]] to double\n++; CHECK-NEXT:    [[TMP5:%.*]] = fadd double [[TMP4]], 0.000000e+00\n++; CHECK-NEXT:    [[ADD_I_1_I_I:%.*]] = select i1 false, double 0.000000e+00, double [[TMP5]]\n++; CHECK-NEXT:    [[TMP6:%.*]] = bitcast double [[ADD_I_1_I_I]] to i64\n++; CHECK-NEXT:    [[CMP3998_1_I_I:%.*]] = icmp ne i64 [[TMP6]], [[CONV22_1_I_I]]\n++; CHECK-NEXT:    ret i1 [[CMP3998_1_I_I]]\n++;\n++entry:\n++  %conv22.i.i = sext i32 %0 to i64\n++  %1 = bitcast i64 %conv22.i.i to double\n++  %2 = fadd double %1, 0.000000e+00\n++  %add.i.i.i = select i1 false, double 0.000000e+00, double %2\n++  %3 = bitcast double %add.i.i.i to i64\n++  %cmp3998.i.i = icmp ne i64 %3, %conv22.i.i\n++  %conv22.1.i.i = sext i32 0 to i64\n++  %4 = bitcast i64 %conv22.1.i.i to double\n++  %5 = fadd double %4, 0.000000e+00\n++  %add.i.1.i.i = select i1 false, double 0.000000e+00, double %5\n++  %6 = bitcast double %add.i.1.i.i to i64\n++  %cmp3998.1.i.i = icmp ne i64 %6, %conv22.1.i.i\n++  ret i1 %cmp3998.1.i.i\n++}\n+diff -ruN --strip-trailing-cr a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n+--- a/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n++++ b/llvm/test/Transforms/SLPVectorizer/X86/parent-node-non-schedulable.ll\n+@@ -0,0 +1,172 @@\n++; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5\n++; RUN: opt -S --passes=slp-vectorizer -S -mtriple=i686-unknown-linux-android29 -mattr=+sse2 < %s | FileCheck %s\n++\n++define void @test(ptr %0, i64 %1, i64 %2, i1 %3, i64 %4, i64 %5) {\n++; CHECK-LABEL: define void @test(\n++; CHECK-SAME: ptr [[TMP0:%.*]], i64 [[TMP1:%.*]], i64 [[TMP2:%.*]], i1 [[TMP3:%.*]], i64 [[TMP4:%.*]], i64 [[TMP5:%.*]]) #[[ATTR0:[0-9]+]] {\n++; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr i8, ptr [[TMP0]], i32 240\n++; CHECK-NEXT:    [[TMP8:%.*]] = getelementptr i8, ptr [[TMP0]], i32 128\n++; CHECK-NEXT:    [[TMP9:%.*]] = insertelement <4 x i64> poison, i64 [[TMP1]], i32 0\n++; CHECK-NEXT:    [[TMP10:%.*]] = shufflevector <4 x i64> [[TMP9]], <4 x i64> poison, <4 x i32> zeroinitializer\n++; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <4 x i64> <i64 1, i64 1, i64 1, i64 poison>, i64 [[TMP2]], i32 3\n++; CHECK-NEXT:    [[TMP12:%.*]] = add <4 x i64> [[TMP10]], [[TMP11]]\n++; CHECK-NEXT:    [[TMP13:%.*]] = load <2 x i64>, ptr [[TMP7]], align 4\n++; CHECK-NEXT:    [[TMP14:%.*]] = load i64, ptr null, align 4\n++; CHECK-NEXT:    [[TMP15:%.*]] = load <2 x i64>, ptr [[TMP8]], align 4\n++; CHECK-NEXT:    [[TMP16:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> [[TMP15]], <6 x i32> <i32 0, i32 1, i32 poison, i32 3, i32 2, i32 2>\n++; CHECK-NEXT:    [[TMP17:%.*]] = insertelement <6 x i64> poison, i64 [[TMP14]], i32 0\n++; CHECK-NEXT:    [[TMP18:%.*]] = shufflevector <6 x i64> [[TMP17]], <6 x i64> poison, <6 x i32> <i32 poison, i32 poison, i32 0, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP19:%.*]] = shufflevector <6 x i64> [[TMP16]], <6 x i64> [[TMP18]], <6 x i32> <i32 0, i32 1, i32 8, i32 3, i32 4, i32 5>\n++; CHECK-NEXT:    [[TMP20:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <6 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 0>\n++; CHECK-NEXT:    [[TMP21:%.*]] = shufflevector <6 x i64> [[TMP20]], <6 x i64> <i64 0, i64 0, i64 0, i64 0, i64 0, i64 poison>, <6 x i32> <i32 6, i32 7, i32 8, i32 9, i32 10, i32 0>\n++; CHECK-NEXT:    [[TMP22:%.*]] = add <6 x i64> [[TMP19]], [[TMP21]]\n++; CHECK-NEXT:    [[TMP23:%.*]] = shufflevector <2 x i64> [[TMP13]], <2 x i64> poison, <4 x i32> <i32 0, i32 1, i32 0, i32 1>\n++; CHECK-NEXT:    [[TMP24:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP23]], <4 x i32> <i32 0, i32 1, i32 4, i32 5>\n++; CHECK-NEXT:    [[TMP25:%.*]] = sub <4 x i64> zeroinitializer, [[TMP24]]\n++; CHECK-NEXT:    [[TMP26:%.*]] = sub <6 x i64> zeroinitializer, [[TMP22]]\n++; CHECK-NEXT:    [[TMP27:%.*]] = shufflevector <6 x i64> [[TMP19]], <6 x i64> poison, <2 x i32> <i32 2, i32 2>\n++; CHECK-NEXT:    [[TMP28:%.*]] = add <2 x i64> [[TMP27]], splat (i64 1)\n++; CHECK-NEXT:    [[TMP29:%.*]] = ashr <2 x i64> [[TMP28]], splat (i64 14)\n++; CHECK-NEXT:    [[TMP30:%.*]] = shufflevector <6 x i64> [[TMP26]], <6 x i64> poison, <14 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP31:%.*]] = shufflevector <4 x i64> [[TMP12]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP32:%.*]] = shufflevector <14 x i64> [[TMP30]], <14 x i64> [[TMP31]], <14 x i32> <i32 14, i32 15, i32 16, i32 17, i32 poison, i32 poison, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP33:%.*]] = shufflevector <4 x i64> [[TMP25]], <4 x i64> poison, <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP34:%.*]] = shufflevector <14 x i64> [[TMP32]], <14 x i64> [[TMP33]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 14, i32 15, i32 16, i32 17, i32 8, i32 9, i32 10, i32 11, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP35:%.*]] = shufflevector <2 x i64> [[TMP29]], <2 x i64> poison, <14 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP36:%.*]] = shufflevector <14 x i64> [[TMP34]], <14 x i64> [[TMP35]], <14 x i32> <i32 0, i32 1, i32 2, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 10, i32 11, i32 14, i32 15>\n++; CHECK-NEXT:    br i1 [[TMP3]], label %[[BB52:.*]], label %[[BB37:.*]]\n++; CHECK:       [[BB37]]:\n++; CHECK-NEXT:    [[TMP38:%.*]] = add <4 x i64> [[TMP10]], splat (i64 1)\n++; CHECK-NEXT:    [[TMP39:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> poison, <2 x i32> zeroinitializer\n++; CHECK-NEXT:    [[TMP40:%.*]] = add <2 x i64> [[TMP39]], splat (i64 1)\n++; CHECK-NEXT:    [[TMP41:%.*]] = lshr <2 x i64> [[TMP39]], splat (i64 1)\n++; CHECK-NEXT:    [[TMP42:%.*]] = add <2 x i64> [[TMP40]], [[TMP41]]\n++; CHECK-NEXT:    [[TMP43:%.*]] = shufflevector <4 x i64> [[TMP10]], <4 x i64> [[TMP11]], <10 x i32> <i32 0, i32 7, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <10 x i64> [[TMP43]], i64 [[TMP4]], i32 6\n++; CHECK-NEXT:    [[TMP45:%.*]] = insertelement <10 x i64> [[TMP44]], i64 [[TMP5]], i32 7\n++; CHECK-NEXT:    [[TMP46:%.*]] = shufflevector <4 x i64> [[TMP38]], <4 x i64> poison, <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 0, i32 1, i32 2, i32 3, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP47:%.*]] = shufflevector <2 x i64> [[TMP42]], <2 x i64> poison, <10 x i32> <i32 0, i32 1, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison, i32 poison>\n++; CHECK-NEXT:    [[TMP48:%.*]] = shufflevector <10 x i64> [[TMP46]], <10 x i64> [[TMP47]], <10 x i32> <i32 poison, i32 poison, i32 poison, i32 poison, i32 4, i32 5, i32 6, i32 7, i32 10, i32 11>\n++; CHECK-NEXT:    [[TMP49:%.*]] = shufflevector <10 x i64> [[TMP48]], <10 x i64> [[TMP45]], <10 x i32> <i32 10, i32 11, i32 4, i32 5, i32 6, i32 7, i32 16, i32 17, i32 8, i32 9>\n++; CHECK-NEXT:    [[TMP50:%.*]] = shufflevector <10 x i64> [[TMP49]], <10 x i64> poison, <14 x i32> <i32 0, i32 1, i32 0, i32 2, i32 0, i32 3, i32 4, i32 5, i32 6, i32 7, i32 8, i32 9, i32 0, i32 0>\n++; CHECK-NEXT:    [[TMP51:%.*]] = ashr <14 x i64> [[TMP50]], splat (i64 2)\n++; CHECK-NEXT:    br label %[[BB52]]\n++; CHECK:       [[BB52]]:\n++; CHECK-NEXT:    [[TMP53:%.*]] = phi <14 x i64> [ [[TMP51]], %[[BB37]] ], [ [[TMP36]], [[TMP6:%.*]] ]\n++; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <14 x i64> [[TMP53]], i32 0\n++; CHECK-NEXT:    [[TMP55:%.*]] = extractelement <14 x i64> [[TMP53]], i32 13\n++; CHECK-NEXT:    [[TMP56:%.*]] = or i64 [[TMP54]], [[TMP55]]\n++; CHECK-NEXT:    [[TMP57:%.*]] = extractelement <14 x i64> [[TMP53]], i32 4\n++; CHECK-NEXT:    [[TMP58:%.*]] = extractelement <14 x i64> [[TMP53]], i32 12\n++; CHECK-NEXT:    [[TMP59:%.*]] = or i64 [[TMP57]], [[TMP58]]\n++; CHECK-NEXT:    [[TMP60:%.*]] = extractelement <14 x i64> [[TMP53]], i32 1\n++; CHECK-NEXT:    [[TMP61:%.*]] = extractelement <14 x i64> [[TMP53]], i32 2\n++; CHECK-NEXT:    [[TMP62:%.*]] = or i64 [[TMP60]], [[TMP61]]\n++; CHECK-NEXT:    [[TMP63:%.*]] = or i64 [[TMP59]], [[TMP56]]\n++; CHECK-NEXT:    [[TMP64:%.*]] = extractelement <14 x i64> [[TMP53]], i32 5\n++; CHECK-NEXT:    [[TMP65:%.*]] = extractelement <14 x i64> [[TMP53]], i32 8\n++; CHECK-NEXT:    [[TMP66:%.*]] = or i64 [[TMP64]], [[TMP65]]\n++; CHECK-NEXT:    [[TMP67:%.*]] = extractelement <14 x i64> [[TMP53]], i32 3\n++; CHECK-NEXT:    [[TMP68:%.*]] = or i64 [[TMP67]], [[TMP62]]\n++; CHECK-NEXT:    [[TMP69:%.*]] = extractelement <14 x i64> [[TMP53]], i32 9\n++; CHECK-NEXT:    [[TMP70:%.*]] = or i64 [[TMP69]], [[TMP66]]\n++; CHECK-NEXT:    [[TMP71:%.*]] = extractelement <14 x i64> [[TMP53]], i32 6\n++; CHECK-NEXT:    [[TMP72:%.*]] = or i64 [[TMP71]], [[TMP70]]\n++; CHECK-NEXT:    [[TMP73:%.*]] = or i64 [[TMP63]], [[TMP72]]\n++; CHECK-NEXT:    [[TMP74:%.*]] = extractelement <14 x i64> [[TMP53]], i32 10\n++; CHECK-NEXT:    [[TMP75:%.*]] = or i64 [[TMP74]], [[TMP73]]\n++; CHECK-NEXT:    store i64 [[TMP68]], ptr [[TMP0]], align 4\n++; CHECK-NEXT:    [[TMP76:%.*]] = extractelement <14 x i64> [[TMP53]], i32 11\n++; CHECK-NEXT:    store i64 [[TMP76]], ptr null, align 4\n++; CHECK-NEXT:    [[TMP77:%.*]] = extractelement <14 x i64> [[TMP53]], i32 7\n++; CHECK-NEXT:    store i64 [[TMP77]], ptr [[TMP0]], align 4\n++; CHECK-NEXT:    store i64 [[TMP75]], ptr null, align 4\n++; CHECK-NEXT:    ret void\n++;\n++  %7 = getelementptr i8, ptr %0, i32 248\n++  %8 = load i64, ptr %7, align 4\n++  %9 = getelementptr i8, ptr %0, i32 240\n++  %10 = load i64, ptr %9, align 4\n++  %11 = load i64, ptr null, align 4\n++  %12 = add i64 %1, 1\n++  %13 = add i64 %1, 1\n++  %14 = add i64 %1, %2\n++  %15 = getelementptr i8, ptr %0, i32 136\n++  %16 = load i64, ptr %15, align 4\n++  %17 = getelementptr i8, ptr %0, i32 128\n++  %18 = load i64, ptr %17, align 4\n++  %19 = add i64 %18, %1\n++  %20 = sub i64 0, %18\n++  %21 = sub i64 0, %16\n++  %22 = sub i64 0, %11\n++  %23 = add i64 %1, 1\n++  %24 = sub i64 0, %1\n++  %25 = sub i64 0, %1\n++  %26 = sub i64 0, %10\n++  %27 = sub i64 0, %8\n++  %28 = sub i64 0, %19\n++  %29 = add i64 %11, 1\n++  %30 = ashr i64 %29, 14\n++  %31 = add i64 %11, 1\n++  %32 = ashr i64 %31, 14\n++  br i1 %3, label %58, label %33\n++\n++33:\n++  %34 = ashr i64 %2, 2\n++  %35 = ashr i64 %1, 2\n++  %36 = add i64 %1, 1\n++  %37 = ashr i64 %36, 2\n++  %38 = add i64 %1, 1\n++  %39 = lshr i64 %1, 1\n++  %40 = add i64 %38, %39\n++  %41 = ashr i64 %40, 2\n++  %42 = add i64 %1, 1\n++  %43 = lshr i64 %1, 1\n++  %44 = add i64 %42, %43\n++  %45 = ashr i64 %44, 2\n++  %46 = ashr i64 %5, 2\n++  %47 = ashr i64 %4, 2\n++  %48 = ashr i64 %1, 2\n++  %49 = ashr i64 %1, 2\n++  %50 = ashr i64 %1, 2\n++  %51 = ashr i64 %1, 2\n++  %52 = add i64 %1, 1\n++  %53 = ashr i64 %52, 2\n++  %54 = add i64 %1, 1\n++  %55 = ashr i64 %54, 2\n++  %56 = add i64 %1, 1\n++  %57 = ashr i64 %56, 2\n++  br label %58\n++\n++58:\n++  %59 = phi i64 [ %51, %33 ], [ %24, %6 ]\n++  %60 = phi i64 [ %50, %33 ], [ %32, %6 ]\n++  %61 = phi i64 [ %53, %33 ], [ %25, %6 ]\n++  %62 = phi i64 [ %55, %33 ], [ %26, %6 ]\n++  %63 = phi i64 [ %57, %33 ], [ %27, %6 ]\n++  %64 = phi i64 [ %49, %33 ], [ %30, %6 ]\n++  %65 = phi i64 [ %48, %33 ], [ %23, %6 ]\n++  %66 = phi i64 [ %47, %33 ], [ %22, %6 ]\n++  %67 = phi i64 [ %46, %33 ], [ %21, %6 ]\n++  %68 = phi i64 [ %45, %33 ], [ %20, %6 ]\n++  %69 = phi i64 [ %41, %33 ], [ %28, %6 ]\n++  %70 = phi i64 [ %34, %33 ], [ %12, %6 ]\n++  %71 = phi i64 [ %35, %33 ], [ %13, %6 ]\n++  %72 = phi i64 [ %37, %33 ], [ %14, %6 ]\n++  %73 = or i64 %65, %64\n++  %74 = or i64 %59, %60\n++  %75 = or i64 %70, %71\n++  %76 = or i64 %74, %73\n++  %77 = or i64 %61, %66\n++  %78 = or i64 %72, %75\n++  %79 = or i64 %67, %77\n++  %80 = or i64 %62, %79\n++  %81 = or i64 %76, %80\n++  %82 = or i64 %68, %81\n++  store i64 %78, ptr %0, align 4\n++  store i64 %69, ptr null, align 4\n++  store i64 %63, ptr %0, align 4\n++  store i64 %82, ptr null, align 4\n++  ret void\n++}\n++\n+diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRCore.cpp b/mlir/lib/Bindings/Python/IRCore.cpp\n+--- a/mlir/lib/Bindings/Python/IRCore.cpp\n++++ b/mlir/lib/Bindings/Python/IRCore.cpp\n+@@ -1079,23 +1079,38 @@\n+ PyModule::PyModule(PyMlirContextRef contextRef, MlirModule module)\n+     : BaseContextObject(std::move(contextRef)), module(module) {}\n+ \n+-PyModule::~PyModule() { mlirModuleDestroy(module); }\n++PyModule::~PyModule() {\n++  nb::gil_scoped_acquire acquire;\n++  auto &liveModules = getContext()->liveModules;\n++  assert(liveModules.count(module.ptr) == 1 &&\n++         \"destroying module not in live map\");\n++  liveModules.erase(module.ptr);\n++  mlirModuleDestroy(module);\n++}\n+ \n+ PyModuleRef PyModule::forModule(MlirModule module) {\n+   MlirContext context = mlirModuleGetContext(module);\n+   PyMlirContextRef contextRef = PyMlirContext::forContext(context);\n+ \n+-  // Create.\n+-  PyModule *unownedModule = new PyModule(std::move(contextRef), module);\n+-  // Note that the default return value policy on cast is `automatic_reference`,\n+-  // which means \"does not take ownership, does not call delete/dtor\".\n+-  // We use `take_ownership`, which means \"Python will call the C++ destructor\n+-  // and delete operator when the Python wrapper is garbage collected\", because\n+-  // MlirModule actually wraps OwningOpRef<ModuleOp> (see mlirModuleCreateParse\n+-  // etc).\n+-  nb::object pyRef = nb::cast(unownedModule, nb::rv_policy::take_ownership);\n+-  unownedModule->handle = pyRef;\n+-  return PyModuleRef(unownedModule, std::move(pyRef));\n++  nb::gil_scoped_acquire acquire;\n++  auto &liveModules = contextRef->liveModules;\n++  auto it = liveModules.find(module.ptr);\n++  if (it == liveModules.end()) {\n++    // Create.\n++    PyModule *unownedModule = new PyModule(std::move(contextRef), module);\n++    // Note that the default return value policy on cast is automatic_reference,\n++    // which does not take ownership (delete will not be called).\n++    // Just be explicit.\n++    nb::object pyRef = nb::cast(unownedModule, nb::rv_policy::take_ownership);\n++    unownedModule->handle = pyRef;\n++    liveModules[module.ptr] =\n++        std::make_pair(unownedModule->handle, unownedModule);\n++    return PyModuleRef(unownedModule, std::move(pyRef));\n++  }\n++  // Use existing.\n++  PyModule *existing = it->second.second;\n++  nb::object pyRef = nb::borrow<nb::object>(it->second.first);\n++  return PyModuleRef(existing, std::move(pyRef));\n+ }\n+ \n+ nb::object PyModule::createFromCapsule(nb::object capsule) {\n+@@ -2019,7 +2034,7 @@\n+ // PyInsertionPoint.\n+ //------------------------------------------------------------------------------\n+ \n+-PyInsertionPoint::PyInsertionPoint(PyBlock &block) : block(block) {}\n++PyInsertionPoint::PyInsertionPoint(const PyBlock &block) : block(block) {}\n  \n-   private getExtensionResourcePath(): vscode.Uri {\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel\n-@@ -58,6 +58,7 @@\n-         \"Refactoring\",\n-         \"Sema\",\n-         \"Serialization\",\n-+        \"Trap\",\n-     ] for out in [\n-         (\n-             \"include/clang/Basic/Diagnostic%sKinds.inc\" % c,\n-diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n---- a/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n-+++ b/utils/bazel/llvm-project-overlay/mlir/BUILD.bazel\n-@@ -4167,6 +4167,7 @@\n-         \":VectorToSCF\",\n-         \":VectorToSPIRV\",\n-         \":VectorToXeGPU\",\n-+        \":XeGPUToXeVM\",\n-         \":XeVMToLLVM\",\n-     ],\n+ PyInsertionPoint::PyInsertionPoint(PyOperationBase &beforeOperationBase)\n+     : refOperation(beforeOperationBase.getOperation().getRef()),\n+@@ -2073,6 +2088,19 @@\n+   return PyInsertionPoint{block, std::move(terminatorOpRef)};\n+ }\n+ \n++PyInsertionPoint PyInsertionPoint::after(PyOperationBase &op) {\n++  PyOperation &operation = op.getOperation();\n++  PyBlock block = operation.getBlock();\n++  MlirOperation nextOperation = mlirOperationGetNextInBlock(operation);\n++  if (mlirOperationIsNull(nextOperation))\n++    return PyInsertionPoint(block);\n++  PyOperationRef nextOpRef = PyOperation::forOperation(\n++      block.getParentOperation()->getContext(), nextOperation);\n++  return PyInsertionPoint{block, std::move(nextOpRef)};\n++}\n++\n++size_t PyMlirContext::getLiveModuleCount() { return liveModules.size(); }\n++\n+ nb::object PyInsertionPoint::contextEnter(nb::object insertPoint) {\n+   return PyThreadContextEntry::pushInsertionPoint(insertPoint);\n+ }\n+@@ -2912,6 +2940,7 @@\n+              PyMlirContextRef ref = PyMlirContext::forContext(self.get());\n+              return ref.releaseObject();\n+            })\n++      .def(\"_get_live_module_count\", &PyMlirContext::getLiveModuleCount)\n+       .def_prop_ro(MLIR_PYTHON_CAPI_PTR_ATTR, &PyMlirContext::getCapsule)\n+       .def(MLIR_PYTHON_CAPI_FACTORY_ATTR, &PyMlirContext::createFromCapsule)\n+       .def(\"__enter__\", &PyMlirContext::contextEnter)\n+@@ -3861,6 +3890,8 @@\n+                   nb::arg(\"block\"), \"Inserts at the beginning of the block.\")\n+       .def_static(\"at_block_terminator\", &PyInsertionPoint::atBlockTerminator,\n+                   nb::arg(\"block\"), \"Inserts before the block terminator.\")\n++      .def_static(\"after\", &PyInsertionPoint::after, nb::arg(\"operation\"),\n++                  \"Inserts after the operation.\")\n+       .def(\"insert\", &PyInsertionPoint::insert, nb::arg(\"operation\"),\n+            \"Inserts an operation.\")\n+       .def_prop_ro(\n+diff -ruN --strip-trailing-cr a/mlir/lib/Bindings/Python/IRModule.h b/mlir/lib/Bindings/Python/IRModule.h\n+--- a/mlir/lib/Bindings/Python/IRModule.h\n++++ b/mlir/lib/Bindings/Python/IRModule.h\n+@@ -218,6 +218,10 @@\n+   /// Gets the count of live context objects. Used for testing.\n+   static size_t getLiveCount();\n+ \n++  /// Gets the count of live modules associated with this context.\n++  /// Used for testing.\n++  size_t getLiveModuleCount();\n++\n+   /// Enter and exit the context manager.\n+   static nanobind::object contextEnter(nanobind::object context);\n+   void contextExit(const nanobind::object &excType,\n+@@ -244,6 +248,14 @@\n+   static nanobind::ft_mutex live_contexts_mutex;\n+   static LiveContextMap &getLiveContexts();\n+ \n++  // Interns all live modules associated with this context. Modules tracked\n++  // in this map are valid. When a module is invalidated, it is removed\n++  // from this map, and while it still exists as an instance, any\n++  // attempt to access it will raise an error.\n++  using LiveModuleMap =\n++      llvm::DenseMap<const void *, std::pair<nanobind::handle, PyModule *>>;\n++  LiveModuleMap liveModules;\n++\n+   bool emitErrorDiagnostics = false;\n+ \n+   MlirContext context;\n+@@ -821,7 +833,7 @@\n+ public:\n+   /// Creates an insertion point positioned after the last operation in the\n+   /// block, but still inside the block.\n+-  PyInsertionPoint(PyBlock &block);\n++  PyInsertionPoint(const PyBlock &block);\n+   /// Creates an insertion point positioned before a reference operation.\n+   PyInsertionPoint(PyOperationBase &beforeOperationBase);\n+ \n+@@ -829,6 +841,9 @@\n+   static PyInsertionPoint atBlockBegin(PyBlock &block);\n+   /// Shortcut to create an insertion point before the block terminator.\n+   static PyInsertionPoint atBlockTerminator(PyBlock &block);\n++  /// Shortcut to create an insertion point to the node after the specified\n++  /// operation.\n++  static PyInsertionPoint after(PyOperationBase &op);\n+ \n+   /// Inserts an operation.\n+   void insert(PyOperationBase &operationBase);\n+diff -ruN --strip-trailing-cr a/mlir/test/python/ir/insertion_point.py b/mlir/test/python/ir/insertion_point.py\n+--- a/mlir/test/python/ir/insertion_point.py\n++++ b/mlir/test/python/ir/insertion_point.py\n+@@ -63,6 +63,34 @@\n+ run(test_insert_before_operation)\n+ \n+ \n++# CHECK-LABEL: TEST: test_insert_after_operation\n++def test_insert_after_operation():\n++    ctx = Context()\n++    ctx.allow_unregistered_dialects = True\n++    with Location.unknown(ctx):\n++        module = Module.parse(\n++            r\"\"\"\n++      func.func @foo() -> () {\n++        \"custom.op1\"() : () -> ()\n++        \"custom.op2\"() : () -> ()\n++      }\n++    \"\"\"\n++        )\n++        entry_block = module.body.operations[0].regions[0].blocks[0]\n++        custom_op1 = entry_block.operations[0]\n++        custom_op2 = entry_block.operations[1]\n++        InsertionPoint.after(custom_op1).insert(Operation.create(\"custom.op3\"))\n++        InsertionPoint.after(custom_op2).insert(Operation.create(\"custom.op4\"))\n++        # CHECK: \"custom.op1\"\n++        # CHECK: \"custom.op3\"\n++        # CHECK: \"custom.op2\"\n++        # CHECK: \"custom.op4\"\n++        module.operation.print()\n++\n++\n++run(test_insert_after_operation)\n++\n++\n+ # CHECK-LABEL: TEST: test_insert_at_block_begin\n+ def test_insert_at_block_begin():\n+     ctx = Context()\n+@@ -111,14 +139,24 @@\n+     \"\"\"\n+         )\n+         entry_block = module.body.operations[0].regions[0].blocks[0]\n++        return_op = entry_block.operations[1]\n+         ip = InsertionPoint.at_block_terminator(entry_block)\n+         assert ip.block == entry_block\n+-        assert ip.ref_operation == entry_block.operations[1]\n+-        ip.insert(Operation.create(\"custom.op2\"))\n++        assert ip.ref_operation == return_op\n++        custom_op2 = Operation.create(\"custom.op2\")\n++        ip.insert(custom_op2)\n++        InsertionPoint.after(custom_op2).insert(Operation.create(\"custom.op3\"))\n+         # CHECK: \"custom.op1\"\n+         # CHECK: \"custom.op2\"\n++        # CHECK: \"custom.op3\"\n+         module.operation.print()\n+ \n++        try:\n++            InsertionPoint.after(return_op).insert(Operation.create(\"custom.op4\"))\n++        except IndexError as e:\n++            # CHECK: ERROR: Cannot insert operation at the end of a block that already has a terminator.\n++            print(f\"ERROR: {e}\")\n++\n+ \n+ run(test_insert_at_terminator)\n+ \n+@@ -187,10 +225,16 @@\n+         with InsertionPoint(entry_block):\n+             Operation.create(\"custom.op2\")\n+             with InsertionPoint.at_block_begin(entry_block):\n+-                Operation.create(\"custom.opa\")\n++                custom_opa = Operation.create(\"custom.opa\")\n+                 Operation.create(\"custom.opb\")\n+             Operation.create(\"custom.op3\")\n++            with InsertionPoint.after(custom_opa):\n++                Operation.create(\"custom.op4\")\n++                Operation.create(\"custom.op5\")\n++\n+         # CHECK: \"custom.opa\"\n++        # CHECK: \"custom.op4\"\n++        # CHECK: \"custom.op5\"\n+         # CHECK: \"custom.opb\"\n+         # CHECK: \"custom.op1\"\n+         # CHECK: \"custom.op2\"\n+diff -ruN --strip-trailing-cr a/mlir/test/python/ir/module.py b/mlir/test/python/ir/module.py\n+--- a/mlir/test/python/ir/module.py\n++++ b/mlir/test/python/ir/module.py\n+@@ -121,6 +121,7 @@\n+ def testModuleOperation():\n+     ctx = Context()\n+     module = Module.parse(r\"\"\"module @successfulParse {}\"\"\", ctx)\n++    assert ctx._get_live_module_count() == 1\n+     op1 = module.operation\n+     # CHECK: module @successfulParse\n+     print(op1)\n+@@ -145,6 +146,7 @@\n+     op1 = None\n+     op2 = None\n+     gc.collect()\n++    assert ctx._get_live_module_count() == 0\n+ \n+ \n+ # CHECK-LABEL: TEST: testModuleCapsule\n+@@ -152,17 +154,17 @@\n+ def testModuleCapsule():\n+     ctx = Context()\n+     module = Module.parse(r\"\"\"module @successfulParse {}\"\"\", ctx)\n++    assert ctx._get_live_module_count() == 1\n+     # CHECK: \"mlir.ir.Module._CAPIPtr\"\n+     module_capsule = module._CAPIPtr\n+     print(module_capsule)\n+     module_dup = Module._CAPICreate(module_capsule)\n+-    assert module is not module_dup\n++    assert module is module_dup\n+     assert module == module_dup\n+-    module._clear_mlir_module()\n+-    assert module != module_dup\n+     assert module_dup.context is ctx\n+     # Gc and verify destructed.\n+     module = None\n+     module_capsule = None\n+     module_dup = None\n+     gc.collect()\n++    assert ctx._get_live_module_count() == 0\n+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n+--- a/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n++++ b/utils/bazel/llvm-project-overlay/libc/BUILD.bazel\n+@@ -3749,6 +3749,14 @@\n  )\n-@@ -13945,6 +13946,37 @@\n+ \n+ libc_math_function(\n++    name = \"fmodbf16\",\n++    additional_deps = [\n++        \":__support_fputil_bfloat16\",\n++        \":__support_fputil_generic_fmod\",\n++    ],\n++)\n++\n++libc_math_function(\n+     name = \"fmodf\",\n+     additional_deps = [\n+         \":__support_fputil_generic_fmod\",\n+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n+--- a/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n++++ b/utils/bazel/llvm-project-overlay/libc/test/src/math/smoke/BUILD.bazel\n+@@ -739,6 +739,16 @@\n  )\n  \n- cc_library(\n-+    name = \"XeGPUToXeVM\",\n-+    srcs = glob([\n-+        \"lib/Conversion/XeGPUToXeVM/*.cpp\",\n-+    ]),\n-+    hdrs = glob([\n-+        \"include/mlir/Conversion/XeGPUToXeVM/*.h\",\n-+    ]),\n-+    includes = [\"include\"],\n+ math_test(\n++    name = \"fmodbf16\",\n++    hdrs = [\n++        \"FModTest.h\",\n++    ],\n +    deps = [\n-+        \":ArithDialect\",\n-+        \":ConversionPassIncGen\",\n-+        \":ConvertToLLVMInterface\",\n-+        \":GPUDialect\",\n-+        \":IR\",\n-+        \":IndexDialect\",\n-+        \":LLVMCommonConversion\",\n-+        \":LLVMDialect\",\n-+        \":MemRefDialect\",\n-+        \":Pass\",\n-+        \":SCFDialect\",\n-+        \":SCFTransforms\",\n-+        \":Support\",\n-+        \":TransformUtils\",\n-+        \":VectorDialect\",\n-+        \":XeGPUDialect\",\n-+        \":XeVMDialect\",\n-+        \"//llvm:Support\",\n++        \"//libc:__support_fputil_bfloat16\",\n +    ],\n +)\n +\n-+cc_library(\n-     name = \"XeVMToLLVM\",\n-     srcs = glob([\n-         \"lib/Conversion/XeVMToLLVM/*.cpp\",\n++math_test(\n+     name = \"fmodf\",\n+     hdrs = [\"FModTest.h\"],\n+ )\n+diff -ruN --strip-trailing-cr a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n+--- a/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n++++ b/utils/bazel/llvm-project-overlay/llvm/BUILD.bazel\n+@@ -2223,7 +2223,6 @@\n+             \"lib/Target/AArch64/AArch64GenDisassemblerTables.inc\": [\n+                 \"-gen-disassembler\",\n+                 \"-ignore-non-decodable-operands\",\n+-                \"-ignore-fully-defined-operands\",\n+             ],\n+             \"lib/Target/AArch64/AArch64GenSystemOperands.inc\": [\"-gen-searchable-tables\"],\n+             \"lib/Target/AArch64/AArch64GenExegesis.inc\": [\"-gen-exegesis\"],"
        },
        {
            "sha": "f6711969e254d466aebc24385e4f5cac16d4327d",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"5bca8f2f97d23c3562544e959702826eb20696af\"\n-    LLVM_SHA256 = \"d0e5d52ce939c396f3fa8533d7a1f911ed059e072d4797e3f9cb15043a6fd113\"\n+    LLVM_COMMIT = \"a1de9aca1150bd749a3cdad1d1e26eb6a8855fe2\"\n+    LLVM_SHA256 = \"4b99bf2c212bcd27ac90315f6d8ce82f2d0aeaea257c9b49ddf29ef7a1bba175\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "2408ca2fd57a49d2d1ed2104295b5923280356c8",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 1551,
            "deletions": 2376,
            "changes": 3927,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009"
        },
        {
            "sha": "ec20f64c70b0de2b465bd4c79e0570405eb0cdc2",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"0b8873d121008abc3edf7db2281f2b48cc647978\"\n-    SHARDY_SHA256 = \"cd1d0ebe479387adc4206257b8fe2853d14129ee294e7d9bebe4a3fc7670d7ca\"\n+    SHARDY_COMMIT = \"3c58c0b99d9842432f330a6b173f79bdad0c1a39\"\n+    SHARDY_SHA256 = \"807469420030067bf93f88ffb06cb303a4735170cc7cc99cc618aaf2bf0cecb4\"\n \n     tf_http_archive(\n         name = \"shardy\","
        },
        {
            "sha": "a8075e2d4bc5db1222521bb1c400409beafa260d",
            "filename": "third_party/xla/third_party/stablehlo/temporary.patch",
            "status": "modified",
            "additions": 165,
            "deletions": 0,
            "changes": 165,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fstablehlo%2Ftemporary.patch?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -1,3 +1,168 @@\n+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir\n+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir\n++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_quant_ops_to_tosa_rescale.mlir\n+@@ -11,10 +11,10 @@\n+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = \"tosa.const\"() <{values = dense<1431655765> : tensor<1xi32>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.add %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>\n+   %0 = \"stablehlo.add\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>\n+@@ -32,10 +32,10 @@\n+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = \"tosa.const\"() <{values = dense<1431655765> : tensor<1xi32>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT13]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT11]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.subtract %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT50]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>\n+   %0 = \"stablehlo.subtract\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>\n+@@ -52,10 +52,10 @@\n+   // CHECK-DAG: %[[MULTIPLIER_2:.+]] = \"tosa.const\"() <{values = dense<1717986918> : tensor<1xi32>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.multiply %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_1]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-1>>\n+   %0 = \"stablehlo.multiply\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-1>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-1>>\n+@@ -74,10 +74,10 @@\n+   // CHECK-DAG: %[[ZP_MINUS_2:.+]] = \"tosa.const\"() <{values = dense<-2> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT30]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.divide %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_2]], %[[SHIFT37]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>\n+   %0 = \"stablehlo.divide\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>\n+@@ -97,10 +97,10 @@\n+   // CHECK-DAG: %[[SHIFT12:.+]] = \"tosa.const\"() <{values = dense<12> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.maximum %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>\n+   %0 = \"stablehlo.maximum\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>\n+@@ -120,10 +120,10 @@\n+   // CHECK-DAG: %[[SHIFT12:.+]] = \"tosa.const\"() <{values = dense<12> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK-DAG: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK-DAG: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.minimum %[[V0]], %[[V1]] : tensor<2x2xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V2]], %[[MULTIPLIER_1]], %[[SHIFT51]], %[[ZP_0]], %[[ZP_MINUS_3]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<2x2x!quant.uniform<i8:f32, 1.500000e-01:-3>>\n+   %0 = \"stablehlo.minimum\"(%arg0, %arg1) : (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<2x2x!quant.uniform<i8:f32, 0.075:-2>>)\n+             -> tensor<2x2x!quant.uniform<i8:f32, 1.5e-01:-3>>\n+@@ -140,9 +140,9 @@\n+   // CHECK-DAG: %[[SHIFT30:.+]] = \"tosa.const\"() <{values = dense<30> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT30]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V1:.+]] = stablehlo.abs %[[V0]] : tensor<20x20xi32>\n+-  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V3:.+]] = tosa.rescale %[[V1]], %[[MULTIPLIER_1]], %[[SHIFT33]], %[[ZP_0]], %[[ZP_MINUS_128]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: return %[[V3]] : tensor<20x20x!quant.uniform<i8:f32, 1.500000e-01:-128>>\n+   %0 = \"stablehlo.abs\"(%arg0) : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>) -> tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>\n+   return %0 : tensor<20x20x!quant.uniform<i8:f32, 1.5e-01:-128>>\n+@@ -159,8 +159,8 @@\n+   // CHECK-DAG: %[[SHIFT12:.+]] = \"tosa.const\"() <{values = dense<12> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_MINUS_1:.+]] = \"tosa.const\"() <{values = dense<-1> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT12]], %[[ZP_MINUS_1]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT10]], %[[ZP_MINUS_2]], %[[ZP_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.compare GE, %[[V0]], %[[V1]], TOTALORDER :\n+   // CHECK: return %[[V2]]\n+   %0 = stablehlo.compare GE, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i8:f32, 0.025:-1>>, tensor<20x20x!quant.uniform<i8:f32, 0.075:-2>>) -> tensor<20x20xi1>\n+@@ -177,8 +177,8 @@\n+   // CHECK-DAG: %[[SHIFT15:.+]] = \"tosa.const\"() <{values = dense<15> : tensor<1xi8>}>\n+   // CHECK-DAG: %[[ZP16_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi16>}>\n+   // CHECK-DAG: %[[ZP32_0:.+]] = \"tosa.const\"() <{values = dense<0> : tensor<1xi32>}>\n+-  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n+-  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true}\n++  // CHECK: %[[V0:.+]] = tosa.rescale %arg0, %[[MULTIPLIER_2]], %[[SHIFT17]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n++  // CHECK: %[[V1:.+]] = tosa.rescale %arg1, %[[MULTIPLIER_1]], %[[SHIFT15]], %[[ZP16_0]], %[[ZP32_0]] {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true}\n+   // CHECK: %[[V2:.+]] = stablehlo.compare LT, %[[V0]], %[[V1]], TOTALORDER :\n+   // CHECK: return %[[V2]]\n+   %0 = stablehlo.compare LT, %arg0, %arg1, TOTALORDER : (tensor<20x20x!quant.uniform<i16:f32, 0.025:0>>, tensor<20x20x!quant.uniform<i16:f32, 0.075:0>>) -> tensor<20x20xi1>\n+diff --ruN a/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir b/stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir\n+--- stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir\n++++ stablehlo/stablehlo/conversions/tosa/tests/legalize_tosa_rescale_to_stablehlo.mlir\n+@@ -7,7 +7,7 @@\n+   %shift = \"tosa.const\"() {values = dense<13> : tensor<1xi8>} : () -> tensor<1xi8>\n+   %input_zp = \"tosa.const\"() {values = dense<-1> : tensor<1xi8>} : () -> tensor<1xi8>\n+   %output_zp = \"tosa.const\"() {values = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\n+-  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = \"SINGLE_ROUND\", scale32 = true} :\n++  %0 = tosa.rescale %arg0, %multiplier, %shift, %input_zp, %output_zp {input_unsigned = false, output_unsigned = false, per_channel = false, rounding_mode = SINGLE_ROUND, scale32 = true} :\n+             (tensor<2x2x!quant.uniform<i8:f32, 0.025:-1>>, tensor<1xi32>, tensor<1xi8>, tensor<1xi8>, tensor<1xi32>) -> tensor<2x2xi32>\n+ \n+   // convert input quantized type to storage type\n+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp\n+--- stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp\n++++ stablehlo/stablehlo/conversions/tosa/transforms/StablehloQuantLegalizeToTosaRescale.cpp\n+@@ -70,12 +70,14 @@\n+       outputZpVal.has_value() &&\n+       \"buildRescale: Failed to create output zero-point tensor for RescaleOp.\");\n+ \n+-  std::string roundingMode = doubleRound ? \"DOUBLE_ROUND\" : \"SINGLE_ROUND\";\n++  auto roundingMode =\n++      doubleRound ? RoundingMode::DOUBLE_ROUND : RoundingMode::SINGLE_ROUND;\n+ \n+   auto rescale_op = rewriter.create<RescaleOp>(\n+       loc, outputType, inputVal, multiplierVal, shiftVal, inputZpVal.value(),\n+       outputZpVal.value(), rewriter.getBoolAttr(scale32),\n+-      rewriter.getStringAttr(roundingMode), rewriter.getBoolAttr(perChannel),\n++      RoundingModeAttr::get(rewriter.getContext(), roundingMode),\n++      rewriter.getBoolAttr(perChannel),\n+       /*input_unsigned=*/rewriter.getBoolAttr(false),\n+       /*output_unsigned=*/rewriter.getBoolAttr(false));\n+ \n+diff --ruN a/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp b/stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp\n+--- stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp\n++++ stablehlo/stablehlo/conversions/tosa/transforms/TosaRescaleLegalizeToStablehlo.cpp\n+@@ -68,7 +68,7 @@\n+   auto roundingMode = op.getRoundingMode();\n+   bool perChannel = op.getPerChannel();\n+ \n+-  if (perChannel || roundingMode != \"SINGLE_ROUND\" || !scale32) {\n++  if (perChannel || roundingMode != RoundingMode::SINGLE_ROUND || !scale32) {\n+     return rewriter.notifyMatchFailure(\n+         op,\n+         \"per_channel, double_round, or scale32=false are not yet supported\");\n diff --ruN a/stablehlo/stablehlo/dialect/StablehloOps.cpp b/stablehlo/stablehlo/dialect/StablehloOps.cpp\n --- stablehlo/stablehlo/dialect/StablehloOps.cpp\n +++ stablehlo/stablehlo/dialect/StablehloOps.cpp"
        },
        {
            "sha": "8377a5c230db874965d5c1518caa5f37f38fdbd0",
            "filename": "third_party/xla/xla/service/gpu/target_constants.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftarget_constants.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftarget_constants.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftarget_constants.h?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -30,7 +30,7 @@ inline const char* TargetTriple() {\n // NVPTXTargetMachine.cpp.\n inline const char* DataLayout() {\n   static constexpr char kDataLayout[] =\n-      \"e-p6:32:32-i64:64-i128:128-v16:16-v32:32-n16:32:64\";\n+      \"e-p6:32:32-i64:64-i128:128-i256:256-v16:16-v32:32-n16:32:64\";\n   return kDataLayout;\n }\n }  // namespace nvptx"
        },
        {
            "sha": "7dd144a60be19dd24ca606ace97c8a35636d02da",
            "filename": "third_party/xla/xla/service/gpu/tests/gpu_index_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_index_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9c0b717b934b02ff28d9ae6a468c7a60c7994009/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_index_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fgpu_index_test.cc?ref=9c0b717b934b02ff28d9ae6a468c7a60c7994009",
            "patch": "@@ -105,7 +105,7 @@ TEST_F(GpuIndexTest, CompatibleUseLinearIndexWithReshapeAndBroadcast) {\n                      R\"(\n ; CHECK: %[[urem1:.*]] = urem i{{[0-9]*}} %[[linear_index:.*]], 14\n ; CHECK: %[[idx1:.*]] = zext nneg i{{[0-9]*}} %[[urem1]] to i64\n-; CHECK: getelementptr inbounds{{( nuw)?}} [14 x float], ptr{{( addrspace\\(1\\))?}} %[[alloc:.*]], i64 0, i64 %[[idx1]]\n+; CHECK: getelementptr inbounds{{( nuw)?}} float, ptr{{( addrspace\\(1\\))?}} %[[alloc:.*]], i64 %[[idx1]]\n       )\",\n                      /*match_optimized_ir=*/true);\n }"
        }
    ],
    "stats": {
        "total": 5382,
        "additions": 2538,
        "deletions": 2844
    }
}