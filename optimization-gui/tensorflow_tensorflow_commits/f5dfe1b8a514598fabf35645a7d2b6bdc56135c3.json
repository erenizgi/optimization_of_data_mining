{
    "author": "chhe7",
    "message": "Add an option to preserve specific ops during TF executor graph pruning.\n\nPiperOrigin-RevId: 811654575",
    "sha": "f5dfe1b8a514598fabf35645a7d2b6bdc56135c3",
    "files": [
        {
            "sha": "3ee49777a7ddc8b15bb7bc8ee122e0e1c1fa3cba",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/optimize.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5dfe1b8a514598fabf35645a7d2b6bdc56135c3/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Foptimize.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5dfe1b8a514598fabf35645a7d2b6bdc56135c3/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Foptimize.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Foptimize.cc?ref=f5dfe1b8a514598fabf35645a7d2b6bdc56135c3",
            "patch": "@@ -39,7 +39,7 @@ namespace {\n #include \"tensorflow/compiler/mlir/tensorflow/transforms/generated_optimize.inc\"\n \n // Returns a TF Constant tensor with the passed in values.\n-TF::ConstOp GetI64ConstantTensor(PatternRewriter &rewriter,\n+TF::ConstOp GetI64ConstantTensor(PatternRewriter& rewriter,\n                                  ArrayRef<int64_t> values, Location location) {\n   auto cst_attr = rewriter.getI64TensorAttr(values);\n   return TF::ConstOp::create(rewriter, location, cst_attr.getType(), cst_attr);\n@@ -51,11 +51,11 @@ class SimplifyBroadcastReshape : public OpRewritePattern<BroadcastToOp> {\n   using OpRewritePattern<BroadcastToOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(BroadcastToOp op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // Only rewrite if the Broadcast has only one consumer.\n     if (!op.getOutput().hasOneUse()) return failure();\n \n-    Operation *user = *op.getOutput().getUsers().begin();\n+    Operation* user = *op.getOutput().getUsers().begin();\n \n     auto reshape_op = llvm::dyn_cast_or_null<ReshapeOp>(user);\n     if (!reshape_op) return failure();\n@@ -140,7 +140,7 @@ class SimplifyBroadcastReshape : public OpRewritePattern<BroadcastToOp> {\n // Canonicalize operations in functions.\n struct TensorFlowOptimizePass\n     : public impl::TensorFlowOptimizePassBase<TensorFlowOptimizePass> {\n-  LogicalResult initialize(MLIRContext *context) override {\n+  LogicalResult initialize(MLIRContext* context) override {\n     RewritePatternSet pattern_list(context);\n     populateWithGenerated(pattern_list);\n     pattern_list.add<SimplifyBroadcastReshape>(context);\n@@ -158,15 +158,16 @@ struct TensorFlowOptimizePass\n \n }  // namespace\n \n-void CreateTFStandardPipeline(OpPassManager &pm,\n-                              const StandardPipelineOptions &options) {\n-  OpPassManager &func_pm = pm.nest<func::FuncOp>();\n+void CreateTFStandardPipeline(OpPassManager& pm,\n+                              const StandardPipelineOptions& options) {\n+  OpPassManager& func_pm = pm.nest<func::FuncOp>();\n \n   // First operates on the executor dialect:\n   // - remove dead islands.\n   // - fuse islands as much as possible.\n   // - materialize the eventual \"pass-through\" ops by inlining their content.\n-  func_pm.addPass(tf_executor::CreateTFExecutorGraphPruningPass());\n+  func_pm.addPass(\n+      tf_executor::CreateTFExecutorGraphPruningPass(options.ops_to_preserve));\n   func_pm.addPass(tf_executor::CreateTFExecutorIslandCoarseningPass());\n   func_pm.addPass(CreateMaterializePassthroughOpPass());\n   if (options.form_clusters) pm.addPass(TFDevice::CreateClusterFormationPass());"
        },
        {
            "sha": "004434d460969a54df4f372d07441f3c3cfe55d6",
            "filename": "tensorflow/compiler/mlir/tensorflow/transforms/passes.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5dfe1b8a514598fabf35645a7d2b6bdc56135c3/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5dfe1b8a514598fabf35645a7d2b6bdc56135c3/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Ftensorflow%2Ftransforms%2Fpasses.h?ref=f5dfe1b8a514598fabf35645a7d2b6bdc56135c3",
            "patch": "@@ -182,6 +182,11 @@ struct StandardPipelineOptions\n       llvm::cl::desc(\n           \"Enable StableHLO shape propagation in the TF shape inference pass.\"),\n       llvm::cl::init(false)};\n+  ListOption<std::string> ops_to_preserve{\n+      *this, \"ops-to-preserve\",\n+      llvm::cl::desc(\n+          \"list of ops to preserve during graph pruning. This is \"\n+          \"useful for keeping ops with side effects, e.g. DebugIdentityOp.\")};\n };\n \n // Propagates the pass manager with the passes involved in transforming or"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 14,
        "deletions": 8
    }
}