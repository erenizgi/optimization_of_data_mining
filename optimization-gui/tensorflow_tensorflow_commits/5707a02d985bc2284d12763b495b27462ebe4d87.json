{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Enable `chlo.asinh` -> `kAsinh` `HloInstruction` lowering.\n\nPiperOrigin-RevId: 821610794",
    "sha": "5707a02d985bc2284d12763b495b27462ebe4d87",
    "files": [
        {
            "sha": "de72215604a0dc552fcff5b85efcad113e9a3ae5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/optimize_loops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -54,6 +54,7 @@ bool IsExpensiveToUnroll(mlir::Operation* op) {\n       mlir::math::AcosOp,\n       mlir::math::AcoshOp,\n       mlir::math::AsinOp,\n+      mlir::math::AsinhOp,\n       mlir::math::AtanhOp,\n       mlir::math::SinhOp,\n       mlir::scf::ForOp"
        },
        {
            "sha": "2c7d5c3d272b1c08430ec3912797dce335ddd39e",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -1275,7 +1275,11 @@ XlaOp Acosh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n // If x is negative, the above would give us some trouble; we can't approximate\n // the result as x + abs(x) = 0!  But we're saved by the fact that asinh(-x) =\n // -asinh(x).\n-XlaOp Asinh(XlaOp x) {\n+XlaOp Asinh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n+            bool expand) {\n+  if (!expand) {\n+    return x.builder()->UnaryOp(HloOpcode::kAsinh, x, result_accuracy);\n+  }\n   XlaBuilder* b = x.builder();\n   auto do_it = [&](XlaOp x) -> absl::StatusOr<XlaOp> {\n     TF_ASSIGN_OR_RETURN(auto shape, b->GetShape(x));"
        },
        {
            "sha": "921e7cd3f4a0f2bb9fd1d391ca55cccf8cebae55",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -104,7 +104,9 @@ XlaOp Acosh(XlaOp x,\n             bool expand = true);\n \n // Computes the inverse hyperbolic sine of 'x'.\n-XlaOp Asinh(XlaOp x);\n+XlaOp Asinh(XlaOp x,\n+            const std::optional<ResultAccuracy>& result_accuracy = std::nullopt,\n+            bool expand = true);\n \n // Computes the inverse hyperbolic tangent of 'x'.\n XlaOp Atanh(XlaOp x,"
        },
        {
            "sha": "6c6428ba1ca2f425b14c1a2c728e0d45ccf5168a",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -2729,6 +2729,7 @@ std::unique_ptr<HloInstruction> HloInstruction::CloneWithNewOperands(\n     // Unary ops.\n     case HloOpcode::kAbs:\n     case HloOpcode::kAsin:\n+    case HloOpcode::kAsinh:\n     case HloOpcode::kAcos:\n     case HloOpcode::kAcosh:\n     case HloOpcode::kAtanh:"
        },
        {
            "sha": "5fe06a738604528ed59a0488d8e9598c0cb33ff7",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/gen_hlo_op_writer.td",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -204,6 +204,7 @@ defvar CustomHloConverterOps = [\n   MHLO_AllReduceOp,\n   MHLO_AllToAllOp,\n   MHLO_AsinOp,\n+  MHLO_AsinhOp,\n   MHLO_AsyncDoneOp,\n   MHLO_AsyncStartOp,\n   MHLO_AsyncUpdateOp,"
        },
        {
            "sha": "76c487bb4fd99fbd11df5c28134026dca0abad35",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -5236,6 +5236,17 @@ LogicalResult ExportXlaOp(AsinOp op, OpLoweringContext ctx) {\n   return success();\n }\n \n+LogicalResult ExportXlaOp(AsinhOp op, OpLoweringContext ctx) {\n+  auto& value_map = *ctx.values;\n+  xla::XlaOp operand;\n+  if (failed(GetXlaOp(op.getOperand(), value_map, &operand, op))) {\n+    return failure();\n+  }\n+  value_map[op] =\n+      xla::Asinh(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n+  return success();\n+}\n+\n LogicalResult ExportXlaOp(AcosOp op, OpLoweringContext ctx) {\n   return ExportElementwiseXlaOp<AcosOp, xla::Acos>(op, ctx);\n }"
        },
        {
            "sha": "a5d320ac8841ca65c164ffa38ceba61a9909f36b",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -13,6 +13,7 @@ lit_test_suite(\n             \"acos.mlir\",\n             \"acosh.mlir\",\n             \"asin.mlir\",\n+            \"asinh.mlir\",\n             \"add.mlir\",\n             \"atanh.mlir\",\n             \"attributes.mlir\","
        },
        {
            "sha": "8dbd0ca95037ba19303adf7e5586549de8a72917",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/asinh.mlir",
            "status": "added",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fasinh.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fasinh.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fasinh.mlir?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -0,0 +1,7 @@\n+// RUN: xla-translate -mlir-hlo-to-hlo-text %s | FileCheck %s\n+\n+func.func @main(%arg0: tensor<4xf32>) -> tensor<4xf32> {\n+  // CHECK: f32[4] asinh\n+  %0 = \"mhlo.asinh\"(%arg0) : (tensor<4xf32>) -> tensor<4xf32>\n+  func.return %0 : tensor<4xf32>\n+}"
        },
        {
            "sha": "7e780ce90d52c1fe595418a810d96896fe173610",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 4,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -50,15 +50,16 @@ namespace mhlo {\n namespace {\n \n ChloLegalizeToHighLevelMhloPassOptions FromPassOptions(\n-    bool enableAcosh, bool enableAcos, bool enableAsin, bool enableAtanh,\n-    bool enableCosh, bool enableSinh) {\n+    bool enableAcosh, bool enableAcos, bool enableAsin, bool enableAsinh,\n+    bool enableAtanh, bool enableCosh, bool enableSinh) {\n   ChloLegalizeToHighLevelMhloPassOptions options;\n   options.enable_acosh_ = enableAcosh;\n   options.enable_acos_ = enableAcos;\n   options.enable_atanh_ = enableAtanh;\n   options.enable_cosh_ = enableCosh;\n   options.enable_sinh_ = enableSinh;\n   options.enable_asin_ = enableAsin;\n+  options.enable_asinh_ = enableAsinh;\n   return options;\n }\n \n@@ -86,6 +87,10 @@ static bool qualifiesForDirectMhloLoweringAsin(chlo::AsinOp op) {\n   return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n+static bool qualifiesForDirectMhloLoweringAsinh(chlo::AsinhOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+}\n+\n struct ChloLegalizeToHighLevelMhloPass\n     : public impl::ChloLegalizeToHighLevelMhloPassBase<\n           ChloLegalizeToHighLevelMhloPass> {\n@@ -102,8 +107,9 @@ struct ChloLegalizeToHighLevelMhloPass\n \n     chlo::populateChloToHighLevelMhloOpPatterns(\n         &context, &conversionPatterns,\n-        FromPassOptions(enable_acosh_, enable_acos_, enable_atanh_,\n-                        enable_cosh_, enable_sinh_, enable_asin_));\n+        FromPassOptions(enable_acosh_, enable_acos_, enable_asin_,\n+                        enable_asinh_, enable_atanh_, enable_cosh_,\n+                        enable_sinh_));\n \n     // Consider the mhlo dialect legal for tests. Also add helper dialects\n     // that are needed by the patterns.\n@@ -140,6 +146,12 @@ struct ChloLegalizeToHighLevelMhloPass\n         return !qualifiesForDirectMhloLoweringAsin(op);\n       });\n     }\n+    if (enable_asinh_) {\n+      conversionTarget.addDynamicallyLegalOp<chlo::AsinhOp>(\n+          [](chlo::AsinhOp op) {\n+            return !qualifiesForDirectMhloLoweringAsinh(op);\n+          });\n+    }\n     conversionTarget\n         .addIllegalOp<chlo::TopKOp, chlo::ErfOp, chlo::RaggedDotOp>();\n \n@@ -291,6 +303,15 @@ LogicalResult convertAsinChloToMhlo(chlo::AsinOp op,\n   return success();\n }\n \n+LogicalResult convertAsinhChloToMhlo(chlo::AsinhOp op,\n+                                     PatternRewriter& rewriter) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringAsinh(op)) {\n+    return failure();\n+  }\n+  rewriter.replaceOpWithNewOp<mhlo::AsinhOp>(op, op->getOperands());\n+  return success();\n+}\n+\n }  // namespace\n \n ChloLegalizeToHighLevelMhloPassOptions getDefaultChloToHighLevelMhloOptions() {\n@@ -305,6 +326,7 @@ ChloLegalizeToHighLevelMhloPassOptions getGpuChloToHighLevelMhloOptions() {\n   opts.enable_cosh_ = true;\n   opts.enable_sinh_ = true;\n   opts.enable_asin_ = true;\n+  opts.enable_asinh_ = true;\n   return opts;\n }\n \n@@ -337,6 +359,9 @@ void populateChloToHighLevelMhloOpPatterns(\n   if (options.enable_asin_) {\n     patterns->add(mhlo::convertAsinChloToMhlo, kBenefit);\n   }\n+  if (options.enable_asinh_) {\n+    patterns->add(mhlo::convertAsinhChloToMhlo, kBenefit);\n+  }\n   patterns->add(mhlo::convertRaggedDotChloToMhlo, kBenefit);\n   populateWithGenerated(*patterns);\n }"
        },
        {
            "sha": "e52bab960be48f87f3417e73209dada5b0f38305",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 3,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -140,6 +140,11 @@ std::optional<int64_t> getPublicFeaturesNotInStablehlo(HloOpTy hloOp) {\n     // Version 1: Initial version for AsinOp.\n     return 1;\n   }\n+  // StableHLO doesn't support Asinh yet.\n+  if constexpr (std::is_same<HloOpTy, mhlo::AsinhOp>::value) {\n+    // Version 1: Initial version for AsinhOp.\n+    return 1;\n+  }\n   return std::nullopt;\n }\n \n@@ -475,6 +480,7 @@ LogicalResult convertAttributes(ConversionPatternRewriter& rewriter,\n                   !std::is_same<HloOpTy, mhlo::CoshOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::SinhOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::AsinOp>::value &&\n+                  !std::is_same<HloOpTy, mhlo::AsinhOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::ErfOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::TopKOp>::value) {\n       if (!stablehloAttr) {\n@@ -769,9 +775,9 @@ void populateHloToStablehloPatterns(RewritePatternSet* patterns,\n       allowXlaFeatures);\n \n   populateHloToStablehloCustomCallPatterns<\n-      mhlo::AcosOp, mhlo::AcoshOp, mhlo::AsinOp, mhlo::AtanhOp, mhlo::CoshOp,\n-      mhlo::SinhOp, mhlo::ErfOp, mhlo::TopKOp>(patterns, converter, context,\n-                                               allowExperimentalFeatures);\n+      mhlo::AcosOp, mhlo::AcoshOp, mhlo::AsinOp, mhlo::AsinhOp, mhlo::AtanhOp,\n+      mhlo::CoshOp, mhlo::SinhOp, mhlo::ErfOp, mhlo::TopKOp>(\n+      patterns, converter, context, allowExperimentalFeatures);\n }\n \n }  // namespace stablehlo"
        },
        {
            "sha": "a05157ea49352115ed7f5886976a5addbbcea73c",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -34,7 +34,9 @@ def ChloLegalizeToHighLevelMhloPass : Pass<\"chlo-legalize-to-high-level-mhlo\", \"\n     Option<\"enable_sinh_\", \"enable-sinh\", \"bool\", /*default=*/\"false\",\n            \"Enable chlo.sinh to mhlo.sinh lowering.\">,\n     Option<\"enable_asin_\", \"enable-asin\", \"bool\", /*default=*/\"false\",\n-           \"Enable chlo.asin to mhlo.asin lowering.\">\n+           \"Enable chlo.asin to mhlo.asin lowering.\">,\n+    Option<\"enable_asinh_\", \"enable-asinh\", \"bool\", /*default=*/\"false\",\n+           \"Enable chlo.asinh to mhlo.asinh lowering.\">\n   ];\n   let dependentDialects = [\"mhlo::MhloDialect\"];\n }"
        },
        {
            "sha": "37257ab812512a129a3b5885bc307470df9ca34e",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_preserve_high_level_ops.cpp",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -284,6 +284,15 @@ struct AsinOpToCustomCallPattern : public OpRewritePattern<chlo::AsinOp> {\n   }\n };\n \n+struct AsinhOpToCustomCallPattern : public OpRewritePattern<chlo::AsinhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::AsinhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOperationInCustomCall(rewriter, op, \"mhlo.asinh\",\n+                                         /*version=*/1);\n+  }\n+};\n+\n ///////\n // CHLO to CompositeOp Patterns\n ///////\n@@ -375,6 +384,14 @@ struct AsinOpToCompositePattern : public OpRewritePattern<chlo::AsinOp> {\n   }\n };\n \n+struct AsinhOpToCompositePattern : public OpRewritePattern<chlo::AsinhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::AsinhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOpInComposite(op, /*version=*/1, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloPreserveHighLevelOpsPass\n@@ -400,6 +417,7 @@ struct ChloPreserveHighLevelOpsPass\n       patterns.add<\n         AcosOpToCustomCallPattern,\n         AsinOpToCustomCallPattern,\n+        AsinhOpToCustomCallPattern,\n         AcoshOpToCustomCallPattern,\n         AtanhOpToCustomCallPattern,\n         CoshOpToCustomCallPattern,\n@@ -411,6 +429,7 @@ struct ChloPreserveHighLevelOpsPass\n       patterns.add<\n         AcosOpToCompositePattern,\n         AsinOpToCompositePattern,\n+        AsinhOpToCompositePattern,\n         AcoshOpToCompositePattern,\n         AtanhOpToCompositePattern,\n         CoshOpToCompositePattern,"
        },
        {
            "sha": "f40d19946241e7b452005ea2b37636233284443f",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_recompose_ops.cpp",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -344,6 +344,22 @@ struct AsinOpRecomposePattern\n   }\n };\n \n+struct AsinhOpRecomposePattern\n+    : public OpRewritePattern<stablehlo::CompositeOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n+                                PatternRewriter& rewriter) const override {\n+    if (op.getName() != \"chlo.asinh\") {\n+      return rewriter.notifyMatchFailure(op, \"not a chlo.asinh\");\n+    }\n+    if (op.getVersion() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"unsupported version for chlo.asinh composite\");\n+    }\n+    return recomposeChloOpFromCompositeOp<chlo::AsinhOp>(op, rewriter);\n+  }\n+};\n+\n struct ErfOpRecomposePattern : public OpRewritePattern<stablehlo::CompositeOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n@@ -493,6 +509,16 @@ struct AsinOpCustomCallRecomposePattern\n   }\n };\n \n+struct AsinhOpCustomCallRecomposePattern\n+    : public OpRewritePattern<stablehlo::CustomCallOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CustomCallOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return recomposeChloOpFromCustomCall<chlo::AsinhOp>(\n+        op, {\"mhlo.asinh\", \"chlo.asinh\"}, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloRecomposeOpsPass\n@@ -515,6 +541,7 @@ struct ChloRecomposeOpsPass\n     patterns.add<\n       AcosOpCustomCallRecomposePattern,\n       AsinOpCustomCallRecomposePattern,\n+      AsinhOpCustomCallRecomposePattern,\n       AcoshOpCustomCallRecomposePattern,\n       AtanhOpCustomCallRecomposePattern,\n       CoshOpCustomCallRecomposePattern,\n@@ -528,6 +555,7 @@ struct ChloRecomposeOpsPass\n     patterns.add<\n       AcosOpRecomposePattern,\n       AsinOpRecomposePattern,\n+      AsinhOpRecomposePattern,\n       AcoshOpRecomposePattern,\n       AtanhOpRecomposePattern,\n       CoshOpRecomposePattern,"
        },
        {
            "sha": "20786d052801e5a377c9b20296101e9c05c40494",
            "filename": "third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -1,5 +1,5 @@\n // RUN: mlir-hlo-opt --chlo-legalize-to-hlo --split-input-file -verify-diagnostics %s | FileCheck %s --dump-input-context=20\n-// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh enable-cosh enable-sinh enable-asin\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n+// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh enable-cosh enable-sinh enable-asin enable-asinh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n \n // CHECK-LABEL: func.func @asin_bf16(\n // CHECK-SAME:    %[[TMP_arg0:.*]]: tensor<bf16>\n@@ -411,8 +411,10 @@ func.func @asin_complex_f64_dynamic(%arg : tensor<?xcomplex<f64>>) -> tensor<?xc\n // -----\n \n // CHECK-LABEL: @asinh_bf16\n+// CHECK-HIGH-LEVEL-LABEL: @asinh_bf16\n // CHECK-SAME: %[[ARG:.*]]: tensor<bf16>\n func.func @asinh_bf16(%arg : tensor<bf16>) -> tensor<bf16> {\n+  // CHECK-HIGH-LEVEL: mhlo.asinh\n   // Check for the bf16-specific max value.\n   // CHECK: mhlo.constant dense<3.389{{.*}}e+38>\n   %result = \"chlo.asinh\"(%arg) : (tensor<bf16>) -> tensor<bf16>\n@@ -422,8 +424,10 @@ func.func @asinh_bf16(%arg : tensor<bf16>) -> tensor<bf16> {\n // -----\n \n // CHECK-LABEL: @asinh_f16\n+// CHECK-HIGH-LEVEL-LABEL: @asinh_f16\n // CHECK-SAME: %[[ARG:.*]]: tensor<f16>\n func.func @asinh_f16(%arg : tensor<f16>) -> tensor<f16> {\n+  // CHECK-HIGH-LEVEL: mhlo.asinh\n   // Check for the f16-specific max value.\n   // CHECK: mhlo.constant dense<6.550{{.*}}e+04>\n   %result = \"chlo.asinh\"(%arg) : (tensor<f16>) -> tensor<f16>\n@@ -433,8 +437,10 @@ func.func @asinh_f16(%arg : tensor<f16>) -> tensor<f16> {\n // -----\n \n // CHECK-LABEL: @asinh_f32\n+// CHECK-HIGH-LEVEL-LABEL: @asinh_f32\n // CHECK-SAME: %[[ARG:.*]]: tensor<f32>\n func.func @asinh_f32(%arg : tensor<f32>) -> tensor<f32> {\n+  // CHECK-HIGH-LEVEL: mhlo.asinh\n   // Check for the f32-specific max value.\n   // CHECK: mhlo.constant dense<3.402{{.*}}E+38>\n   %result = \"chlo.asinh\"(%arg) : (tensor<f32>) -> tensor<f32>\n@@ -444,8 +450,10 @@ func.func @asinh_f32(%arg : tensor<f32>) -> tensor<f32> {\n // -----\n \n // CHECK-LABEL:  @asinh_f64\n+// CHECK-HIGH-LEVEL-LABEL: @asinh_f64\n // CHECK-SAME:   %[[VAL_0:.*]]: tensor<f64>) -> tensor<f64> {\n func.func @asinh_f64(%arg : tensor<f64>) -> tensor<f64> {\n+  // CHECK-HIGH-LEVEL: mhlo.asinh\n   // CHECK:   %[[VAL_1:.*]] = mhlo.sign %[[VAL_0]] : tensor<f64>\n   // CHECK:   %[[VAL_2:.*]] = mhlo.abs %[[VAL_0]] : tensor<f64>\n   // CHECK:   %[[VAL_3:.*]] = mhlo.constant dense<1.7976931348623157E+308> : tensor<f64>"
        },
        {
            "sha": "979150d3a1fc95c309988c7d484fc02926e38fba",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_preserve_high_level_ops.mlir",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -133,6 +133,16 @@ func.func @asin_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n \n // -----\n \n+// CHECK-LABEL: func @asinh_preserve\n+func.func @asinh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-CC: stablehlo.custom_call @mhlo.asinh(%arg0) {mhlo.attributes = {}, mhlo.version = 1 : i64} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  // CHECK: stablehlo.composite \"chlo.asinh\" %arg0 {decomposition = @chlo.asinh.impl, version = 1 : i32}\n+  %0 = chlo.asinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @tan_no_preserve\n func.func @tan_no_preserve(%arg0: tensor<16xf32>) -> tensor<?xf32> {\n   // CHECK: chlo.tan"
        },
        {
            "sha": "5a16a15ad5878874515cf5786066aff10dbc17e0",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_recompose_ops.mlir",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -108,6 +108,21 @@ func.func private @chlo.asin.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20\n \n // -----\n \n+// CHECK-LABEL: func @asinh_recompose_composite\n+func.func @asinh_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-NEXT: chlo.asinh\n+  // CHECK-NOT: stablehlo.composite\n+  %0 = stablehlo.composite \"chlo.asinh\" %arg0 {decomposition = @chlo.asinh.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+// CHECK-NOT: @chlo.asinh.impl\n+func.func private @chlo.asinh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  %0 = chlo.asinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_composite\n func.func @ragged_dot_recompose_composite(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>\n@@ -225,6 +240,20 @@ func.func @asin_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16\n \n // -----\n \n+// CHECK-LABEL: @asinh_recompose_cc\n+func.func @asinh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK: %0 = chlo.asinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  %0 = \"stablehlo.custom_call\"(%arg0) {\n+    backend_config = \"\",\n+    call_target_name = \"mhlo.asinh\",\n+    mhlo.attributes = {},\n+    mhlo.version = 1 : i64\n+  } : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  func.return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_cc\n func.func @ragged_dot_recompose_cc(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>"
        },
        {
            "sha": "dc6a0d6ee4d6e3c6d1d4eb20c26f24f5d4071c82",
            "filename": "third_party/xla/xla/tests/complex_unary_op_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Ftests%2Fcomplex_unary_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Ftests%2Fcomplex_unary_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcomplex_unary_op_test.cc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -123,8 +123,10 @@ TEST_F(ComplexUnaryOpTest, AsinTest) {\n }\n \n TEST_F(ComplexUnaryOpTest, AsinhTest) {\n-  UnaryTestHelper<complex_unary_op_samples::Asinh<float>>(Asinh);\n-  UnaryTestHelper<complex_unary_op_samples::Asinh<double>>(Asinh);\n+  UnaryTestHelper<complex_unary_op_samples::Asinh<float>>(\n+      [](XlaOp x) { return Asinh(x); });\n+  UnaryTestHelper<complex_unary_op_samples::Asinh<double>>(\n+      [](XlaOp x) { return Asinh(x); });\n }\n \n }  // namespace"
        },
        {
            "sha": "9c8edb44f03a367e915c34b6310cfa24b31d364a",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_ops.inc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5707a02d985bc2284d12763b495b27462ebe4d87/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc?ref=5707a02d985bc2284d12763b495b27462ebe4d87",
            "patch": "@@ -199,7 +199,9 @@ DEFINE_UNARY_TEST_OP(\n DEFINE_UNARY_TEST_OP(\n     AcoshOp, { return [](XlaOp x) { return Acosh(x); }; },\n     { return std::acosh; });\n-DEFINE_UNARY_TEST_OP(AsinhOp, { return Asinh; }, { return std::asinh; });\n+DEFINE_UNARY_TEST_OP(\n+    AsinhOp, { return [](XlaOp x) { return Asinh(x); }; },\n+    { return std::asinh; });\n DEFINE_UNARY_TEST_OP(\n     AtanhOp, { return [](XlaOp x) { return Atanh(x); }; },\n     { return std::atanh; });"
        }
    ],
    "stats": {
        "total": 187,
        "additions": 173,
        "deletions": 14
    }
}