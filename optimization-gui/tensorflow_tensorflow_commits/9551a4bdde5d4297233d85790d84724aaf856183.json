{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Parameterize Fission Backend tests and extend for Custom Kernels.\n\nPiperOrigin-RevId: 834240377",
    "sha": "9551a4bdde5d4297233d85790d84724aaf856183",
    "files": [
        {
            "sha": "eb531a742ec5184042dce9820b80cce9d71a48b9",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=9551a4bdde5d4297233d85790d84724aaf856183",
            "patch": "@@ -827,6 +827,7 @@ xla_test(\n     tags = [\"cuda-only\"],\n     deps = [\n         \":cublas\",\n+        \":custom_kernel\",\n         \":fission_backend\",\n         \":gpu_codegen_backend\",\n         \"//xla/backends/autotuner:codegen_backend\",\n@@ -838,6 +839,7 @@ xla_test(\n         \"//xla/service:executable\",\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:nvptx_compiler_impl\",\n+        \"//xla/service/gpu/transforms:custom_kernel_fusion_rewriter\",\n         \"//xla/service/gpu/transforms:dot_algorithm_rewriter\",\n         \"//xla/service/gpu/transforms:gemm_rewriter\",\n         \"//xla/stream_executor:device_description\","
        },
        {
            "sha": "aa166da4c5342fa9e9e87bacf5e64015fab13a6e",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/custom_kernel.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcustom_kernel.cc?ref=9551a4bdde5d4297233d85790d84724aaf856183",
            "patch": "@@ -46,15 +46,14 @@ using CustomKernelBackendConfig = AutotuneResult::CustomKernelFusionKey;\n \n bool CustomKernelBackend::IsSupported(const HloInstruction& instr) {\n   if (instr.opcode() != HloOpcode::kFusion) {\n-    LOG(ERROR)\n-        << \"CustomKernelBackend doesn't support non-fusion instructions.\";\n+    VLOG(1) << \"CustomKernelBackend doesn't support non-fusion instructions.\";\n     return false;\n   }\n \n   if (instr.backend_config<GpuBackendConfig>()\n           ->fusion_backend_config()\n           .kind() != kCustomFusionKind) {\n-    LOG(ERROR) << \"CustomKernelBackend expected a custom fusion.\";\n+    VLOG(1) << \"CustomKernelBackend expected a custom fusion.\";\n     return false;\n   }\n "
        },
        {
            "sha": "0c62f6bc8d160726a4a4c640300f624412a45f41",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission_backend.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.cc?ref=9551a4bdde5d4297233d85790d84724aaf856183",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_clone_context.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n@@ -46,6 +47,11 @@ namespace {\n // computation.\n absl::Status InlineFissionedComputation(HloInstruction* fusion_instr,\n                                         HloComputation* fissioned_computation) {\n+  if (fusion_instr->opcode() != HloOpcode::kFusion) {\n+    return absl::InvalidArgumentError(\"Not a fusion instruction.\");\n+  }\n+  HloModule* original_module = fusion_instr->GetModule();\n+  HloCloneContext clone_context(original_module);\n   absl::flat_hash_map<const HloInstruction*, HloInstruction*>\n       cloned_instructions;\n   HloComputation* parent_computation = fusion_instr->parent();\n@@ -64,7 +70,7 @@ absl::Status InlineFissionedComputation(HloInstruction* fusion_instr,\n     }\n     HloInstruction* new_instruction = parent_computation->AddInstruction(\n         instruction_to_clone->CloneWithNewOperands(\n-            instruction_to_clone->shape(), new_operands));\n+            instruction_to_clone->shape(), new_operands, &clone_context));\n     cloned_instructions[instruction_to_clone] = new_instruction;\n   }\n   HloInstruction* new_root =\n@@ -102,8 +108,6 @@ absl::StatusOr<std::unique_ptr<BackendConfig>> FissionBackend::GetDefaultConfig(\n   TF_ASSIGN_OR_RETURN(HloInstruction * supported_instr,\n                       FindFirstSupportedInstruction(hlo_module.get()));\n   return codegen_backend_->GetDefaultConfig(*supported_instr);\n-\n-  return absl::InvalidArgumentError(\"No supported configs found.\");\n }\n \n absl::StatusOr<std::unique_ptr<HloModule>> FissionBackend::RunHloPasses("
        },
        {
            "sha": "248b76c99059488a2d94361ec44641946b6e6c11",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission_backend_test.cc",
            "status": "modified",
            "additions": 110,
            "deletions": 35,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9551a4bdde5d4297233d85790d84724aaf856183/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc?ref=9551a4bdde5d4297233d85790d84724aaf856183",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/backends/gpu/autotuner/fission_backend.h\"\n \n+#include <functional>\n #include <memory>\n #include <string>\n #include <utility>\n@@ -27,6 +28,7 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/backends/gpu/autotuner/cublas.h\"\n+#include \"xla/backends/gpu/autotuner/custom_kernel.h\"\n #include \"xla/backends/gpu/autotuner/gpu_codegen_backend.h\"\n #include \"xla/hlo/analysis/symbolic_expr.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -36,6 +38,7 @@ limitations under the License.\n #include \"xla/service/compiler.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/nvptx_compiler.h\"\n+#include \"xla/service/gpu/transforms/custom_kernel_fusion_rewriter.h\"\n #include \"xla/service/gpu/transforms/dot_algorithm_rewriter.h\"\n #include \"xla/service/gpu/transforms/gemm_rewriter.h\"\n #include \"xla/service/platform_util.h\"\n@@ -89,82 +92,127 @@ const char kUnsupportedFusionHlo[] = R\"(\n       kind=kCustom, calls=computation\n   })\";\n \n-class CublasFissionTest : public HloHardwareIndependentTestBase {\n- protected:\n-  DebugOptions debug_options_;\n-  NVPTXCompiler compiler_;\n-  se::StreamExecutor* stream_executor_;\n-  Compiler::GpuTargetConfig target_config_;\n-  se::DeviceDescription device_description_;\n-  std::unique_ptr<HloPassPipeline> rewriter_pipeline_;\n-  std::unique_ptr<GpuCodegenBackend> cublas_backend_;\n-  std::unique_ptr<FissionBackend> fission_backend_;\n-  mlir::MLIRContext mlir_context_;\n-  SymbolicExprContext symbolic_expr_context_{&mlir_context_};\n+struct FissionTestParams {\n+  std::string test_name;\n+  std::string hlo_string;\n+  // Factory function to create the rewriter pipeline.\n+  std::function<std::unique_ptr<HloPassPipeline>(\n+      const se::DeviceDescription& device_description)>\n+      pipeline_factory;\n+  // Factory function to create the underlying codegen backend.\n+  std::function<std::unique_ptr<GpuCodegenBackend>(\n+      se::StreamExecutor*, const DebugOptions*, Compiler*,\n+      const Compiler::GpuTargetConfig*)>\n+      backend_factory;\n+  // Substrings expected to be in the module after ApplyConfig.\n+  std::vector<std::string> expected_module_substrings;\n+  std::string expected_backend_name;\n+};\n \n-  std::unique_ptr<HloPassPipeline> GetCublasRewriterPipeline() {\n+class FissionTest : public HloHardwareIndependentTestBase,\n+                    public ::testing::WithParamInterface<FissionTestParams> {\n+ public:\n+  // Static helper to create the Cublas rewriter pipeline.\n+  static std::unique_ptr<HloPassPipeline> GetCublasRewriterPipeline(\n+      const se::DeviceDescription& device_description) {\n     auto pipeline = std::make_unique<HloPassPipeline>(\"fission_pipeline\");\n     pipeline->AddPass(std::make_unique<DotAlgorithmRewriter>());\n     for (GemmRewriterOptions::DType dtype :\n          {GemmRewriterOptions::DType::kFp8Only,\n           GemmRewriterOptions::DType::kNonFp8Only}) {\n       auto gemm_rewriter = std::make_unique<GemmRewriter>(\n-          device_description_.gpu_compute_capability(),\n-          device_description_.runtime_version(), GemmRewriterOptions{dtype});\n+          device_description.gpu_compute_capability(),\n+          device_description.runtime_version(), GemmRewriterOptions{dtype});\n       pipeline->AddPass(std::move(gemm_rewriter));\n     }\n     return pipeline;\n   }\n \n-  CublasFissionTest()\n+  // Static helper to create the Custom Kernel rewriter pipeline.\n+  static std::unique_ptr<HloPassPipeline> GetCustomKernelRewriterPipeline(\n+      const se::DeviceDescription& device_description) {\n+    auto pipeline = std::make_unique<HloPassPipeline>(\"fission_pipeline\");\n+    pipeline->AddPass(\n+        std::make_unique<CustomKernelFusionRewriter>(&device_description));\n+    return pipeline;\n+  }\n+\n+  // Static helper to create a CublasBackend.\n+  static std::unique_ptr<GpuCodegenBackend> CreateCublasBackend(\n+      se::StreamExecutor* stream_executor, const DebugOptions* debug_options,\n+      Compiler* compiler, const Compiler::GpuTargetConfig* target_config) {\n+    return std::make_unique<CublasBackend>(stream_executor, debug_options,\n+                                           compiler, target_config);\n+  }\n+\n+  // Static helper to create a CustomKernelBackend.\n+  static std::unique_ptr<GpuCodegenBackend> CreateCustomKernelBackend(\n+      se::StreamExecutor* stream_executor, const DebugOptions* debug_options,\n+      Compiler* compiler, const Compiler::GpuTargetConfig* target_config) {\n+    return std::make_unique<CustomKernelBackend>(stream_executor, debug_options,\n+                                                 compiler, target_config);\n+  }\n+\n+ protected:\n+  DebugOptions debug_options_;\n+  NVPTXCompiler compiler_;\n+  se::StreamExecutor* stream_executor_;\n+  Compiler::GpuTargetConfig target_config_;\n+  se::DeviceDescription device_description_;\n+  std::unique_ptr<HloPassPipeline> rewriter_pipeline_;\n+  std::unique_ptr<GpuCodegenBackend> base_codegen_backend_;\n+  std::unique_ptr<FissionBackend> fission_backend_;\n+  mlir::MLIRContext mlir_context_;\n+  SymbolicExprContext symbolic_expr_context_{&mlir_context_};\n+\n+  FissionTest()\n       : stream_executor_(PlatformUtil::GetDefaultPlatform()\n                              .value()\n                              ->ExecutorForDevice(0)\n                              .value()),\n         target_config_(stream_executor_),\n         device_description_(stream_executor_->GetDeviceDescription()),\n-        rewriter_pipeline_(GetCublasRewriterPipeline()),\n-        cublas_backend_(std::make_unique<CublasBackend>(\n+        rewriter_pipeline_(GetParam().pipeline_factory(device_description_)),\n+        base_codegen_backend_(GetParam().backend_factory(\n             stream_executor_, &debug_options_, &compiler_, &target_config_)),\n         fission_backend_(std::make_unique<FissionBackend>(\n             &debug_options_, &compiler_, &target_config_,\n-            std::move(cublas_backend_), std::move(rewriter_pipeline_),\n+            std::move(base_codegen_backend_), std::move(rewriter_pipeline_),\n             &symbolic_expr_context_, stream_executor_)) {}\n };\n \n-TEST_F(CublasFissionTest, CanCreateFissionBackend) {\n-  EXPECT_EQ(fission_backend_->name(), \"Cublas_fission\");\n+TEST_P(FissionTest, CanCreateFissionBackend) {\n+  EXPECT_EQ(fission_backend_->name(), GetParam().expected_backend_name);\n }\n \n-TEST_F(CublasFissionTest, GetSupportedConfigs) {\n+TEST_P(FissionTest, GetSupportedConfigs) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kTritonFusionHlo));\n+                          ParseAndReturnVerifiedModule(GetParam().hlo_string));\n   absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>> configs =\n       fission_backend_->GetSupportedConfigs(\n           (*module->entry_computation()->root_instruction()));\n   EXPECT_THAT(configs, IsOkAndHolds(testing::SizeIs(1)));\n }\n \n-TEST_F(CublasFissionTest, GetSupportedConfigsForUnsupportedInstruction) {\n+TEST_P(FissionTest, GetSupportedConfigsUnsupportedFusion) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(kUnsupportedFusionHlo));\n-  HloInstruction* unsupported_instr =\n-      module->entry_computation()->root_instruction();\n   absl::StatusOr<std::vector<std::unique_ptr<BackendConfig>>> configs =\n-      fission_backend_->GetSupportedConfigs(*unsupported_instr);\n+      fission_backend_->GetSupportedConfigs(\n+          (*module->entry_computation()->root_instruction()));\n   EXPECT_THAT(configs, IsOkAndHolds(testing::IsEmpty()));\n }\n \n-TEST_F(CublasFissionTest, GetDefaultConfig) {\n+TEST_P(FissionTest, GetDefaultConfig) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kTritonFusionHlo));\n+                          ParseAndReturnVerifiedModule(GetParam().hlo_string));\n   HloInstruction* fusion = module->entry_computation()->root_instruction();\n   EXPECT_THAT(fission_backend_->GetDefaultConfig(*fusion), IsOk());\n }\n \n-TEST_F(CublasFissionTest, Compile) {\n+TEST_P(FissionTest, Compile) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kTritonFusionHlo));\n+                          ParseAndReturnVerifiedModule(GetParam().hlo_string));\n   HloInstruction* fusion = module->entry_computation()->root_instruction();\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<BackendConfig> config,\n                           fission_backend_->GetDefaultConfig(*fusion));\n@@ -174,18 +222,45 @@ TEST_F(CublasFissionTest, Compile) {\n   EXPECT_NE(executable, nullptr);\n }\n \n-TEST_F(CublasFissionTest, ApplyConfig) {\n+TEST_P(FissionTest, ApplyConfig) {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n-                          ParseAndReturnVerifiedModule(kTritonFusionHlo));\n+                          ParseAndReturnVerifiedModule(GetParam().hlo_string));\n   HloInstruction* fusion = module->entry_computation()->root_instruction();\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<BackendConfig> config,\n                           fission_backend_->GetDefaultConfig(*fusion));\n   EXPECT_THAT(fission_backend_->ApplyConfig(*fusion, *config), IsOk());\n   std::string module_str = module->ToString();\n-  EXPECT_THAT(module_str, HasSubstr(\"custom_call_target=\\\"__cublas$gemm\\\"\"));\n-  EXPECT_THAT(module_str, HasSubstr(\"\\\"selected_algorithm\\\":\\\"-1\\\"\"));\n+  for (const std::string& expected_substr :\n+       GetParam().expected_module_substrings) {\n+    EXPECT_THAT(module_str, HasSubstr(expected_substr));\n+  }\n }\n \n+INSTANTIATE_TEST_SUITE_P(\n+    FissionTests, FissionTest,\n+    ::testing::ValuesIn<FissionTestParams>({\n+        {\"TritonFusion_Cublas\",\n+         kTritonFusionHlo,\n+         &FissionTest::GetCublasRewriterPipeline,\n+         &FissionTest::CreateCublasBackend,\n+         /*expected_module_substrings=*/\n+         {\"custom_call_target=\\\"__cublas$gemm\\\"\",\n+          \"\\\"selected_algorithm\\\":\\\"-1\\\"\"},\n+         /*expected_backend_name=*/\"Cublas_fission\"},\n+        {\"TritonFusion_CustomKernel\",\n+         kTritonFusionHlo,\n+         &FissionTest::GetCustomKernelRewriterPipeline,\n+         &FissionTest::CreateCustomKernelBackend,\n+         /*expected_module_substrings=*/\n+         {\n+             \"\\\"kind\\\":\\\"__custom_fusion\\\"\",\n+         },\n+         /*expected_backend_name=*/\"CustomKernel_fission\"},\n+    }),\n+    [](const ::testing::TestParamInfo<FissionTest::ParamType>& info) {\n+      return info.param.test_name;\n+    });\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 162,
        "additions": 121,
        "deletions": 41
    }
}