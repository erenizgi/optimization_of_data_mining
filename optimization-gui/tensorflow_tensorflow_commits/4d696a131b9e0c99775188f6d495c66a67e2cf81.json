{
    "author": "chsigg",
    "message": "Remove obsolete Triton LLVM integration patches.\n\nThese patches are no longer needed as the upstream changes they addressed have been integrated.\n\nPiperOrigin-RevId: 799595782",
    "sha": "4d696a131b9e0c99775188f6d495c66a67e2cf81",
    "files": [
        {
            "sha": "6863f76f3a931e91bcae2648a907e7c4a9a04786",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl776164071.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 101,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl776164071.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,101 +0,0 @@\n-\n---- a/include/triton/Conversion/TritonGPUToLLVM/PatternTritonGPUOpToLLVM.h\t2025-03-25 07:48:50.000000000 -0700\n-+++ b/include/triton/Conversion/TritonGPUToLLVM/PatternTritonGPUOpToLLVM.h\t2025-06-26 09:20:47.000000000 -0700\n-@@ -95,7 +95,8 @@\n- void populateFuncOpConversionPattern(LLVMTypeConverter &typeConverter,\n-                                      RewritePatternSet &patterns,\n-                                      const TargetInfoBase &targetInfo,\n--                                     PatternBenefit benefit);\n-+                                     PatternBenefit benefit,\n-+                                     SymbolTableCollection *symbolTables);\n- \n- void populatePrintOpToLLVMPattern(LLVMTypeConverter &typeConverter,\n-                                   RewritePatternSet &patterns,\n-\n---- a/lib/Conversion/TritonGPUToLLVM/FuncOpToLLVM.cpp\t2025-04-25 05:19:43.000000000 -0700\n-+++ b/lib/Conversion/TritonGPUToLLVM/FuncOpToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -7,7 +7,8 @@\n- FailureOr<LLVM::LLVMFuncOp>\n- convertFuncOpToLLVMFuncOp(FunctionOpInterface funcOp,\n-                           ConversionPatternRewriter &rewriter,\n--                          const LLVMTypeConverter &converter);\n-+                          const LLVMTypeConverter &converter,\n-+                          SymbolTableCollection *symbolTables);\n- }\n- \n- namespace {\n-@@ -33,8 +34,10 @@\n- /// information.\n- struct FuncOpConversion : public ConvertOpToLLVMPattern<triton::FuncOp> {\n-   FuncOpConversion(LLVMTypeConverter &converter,\n--                   const TargetInfoBase &targetInfo, PatternBenefit benefit)\n--      : ConvertOpToLLVMPattern(converter, benefit), targetInfo(targetInfo) {}\n-+                   const TargetInfoBase &targetInfo, PatternBenefit benefit,\n-+                   SymbolTableCollection *symbolTables)\n-+      : ConvertOpToLLVMPattern(converter, benefit), targetInfo(targetInfo),\n-+        symbolTables(symbolTables) {}\n- \n-   /// Only retain those attributes that are not constructed by\n-   /// `LLVMFuncOp::build`. If `filterArgAttrs` is set, also filter out argument\n-@@ -152,7 +155,7 @@\n- \n-     FailureOr<LLVM::LLVMFuncOp> maybeNewFuncOp =\n-         mlir::convertFuncOpToLLVMFuncOp(amendedFuncOp, rewriter,\n--                                        *getTypeConverter());\n-+                                        *getTypeConverter(), symbolTables);\n-     if (failed(maybeNewFuncOp)) {\n-       return failure();\n-     }\n-@@ -202,12 +205,16 @@\n- \n- private:\n-   const TargetInfoBase &targetInfo;\n-+  // Store a pointer to the single, pass-wide symbol table\n-+  SymbolTableCollection *symbolTables;\n- };\n- \n- } // namespace\n- \n- void mlir::triton::populateFuncOpConversionPattern(\n-     LLVMTypeConverter &typeConverter, RewritePatternSet &patterns,\n--    const TargetInfoBase &targetInfo, PatternBenefit benefit) {\n--  patterns.add<FuncOpConversion>(typeConverter, targetInfo, benefit);\n-+    const TargetInfoBase &targetInfo, PatternBenefit benefit,\n-+    SymbolTableCollection *symbolTables) {\n-+  patterns.add<FuncOpConversion>(typeConverter, targetInfo, benefit,\n-+                                 symbolTables);\n- }\n-\n---- a/third_party/amd/lib/TritonAMDGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-02 05:51:09.000000000 -0700\n-+++ b/third_party/amd/lib/TritonAMDGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -110,7 +110,8 @@\n-       TritonLLVMFunctionConversionTarget funcTarget(*context);\n-       RewritePatternSet funcPatterns(context);\n-       mlir::triton::populateFuncOpConversionPattern(\n--          typeConverter, funcPatterns, targetInfo, patternBenefitDefault);\n-+          typeConverter, funcPatterns, targetInfo, patternBenefitDefault,\n-+          /*symTable=*/nullptr);\n-       mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n-                                                             funcPatterns);\n-       if (failed(\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TritonGPUToLLVM.cpp\t2025-04-11 01:29:32.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TritonGPUToLLVM.cpp\t2025-06-26 09:20:48.000000000 -0700\n-@@ -79,6 +79,7 @@\n-   void runOnOperation() override {\n-     MLIRContext *context = &getContext();\n-     ModuleOp mod = getOperation();\n-+\n-     TargetInfo targetInfo(computeCapability, ptxVersion);\n- \n-     // Allocate shared memory and set barrier\n-@@ -94,7 +95,8 @@\n-     TritonLLVMFunctionConversionTarget funcTarget(*context);\n-     RewritePatternSet funcPatterns(context);\n-     mlir::triton::populateFuncOpConversionPattern(\n--        typeConverter, funcPatterns, targetInfo, patternBenefitDefault);\n-+        typeConverter, funcPatterns, targetInfo, patternBenefitDefault,\n-+        /*symTable=*/nullptr);\n-     mlir::cf::populateControlFlowToLLVMConversionPatterns(typeConverter,\n-                                                           funcPatterns);\n-     if (failed("
        },
        {
            "sha": "5d6498d902ffb325445409382be204a60b3a4de2",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl789494309.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 20,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl789494309.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,20 +0,0 @@\n-\n---- a/third_party/amd/include/TritonAMDGPUToLLVM/Passes.h\t2025-06-02 05:51:09.000000000 -0700\n-+++ b/third_party/amd/include/TritonAMDGPUToLLVM/Passes.h\t2025-07-31 15:53:03.000000000 -0700\n-@@ -1,13 +1,14 @@\n- #ifndef TRITON_THIRD_PARTY_AMD_INCLUDE_TRITONAMDGPUTOLLVM_PASSES_H_\n- #define TRITON_THIRD_PARTY_AMD_INCLUDE_TRITONAMDGPUTOLLVM_PASSES_H_\n- \n-+#include <memory>\n-+\n-+#include \"llvm/IR/Function.h\"\n- #include \"mlir/Conversion/LLVMCommon/TypeConverter.h\"\n- #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n- #include \"mlir/Pass/Pass.h\"\n- #include \"mlir/Transforms/DialectConversion.h\"\n- \n--#include <memory>\n--\n- namespace mlir {\n- \n- class ModuleOp;"
        },
        {
            "sha": "409aeb6a0ae232a9ae87ea7edd2f82c023df5ca6",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl791659411.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl791659411.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,12 +0,0 @@\n-diff --git a/BUILD b/BUILD\n-index 246fe7e5f..6dba44973 100644\n---- a/BUILD\n-+++ b/BUILD\n-@@ -951,6 +951,7 @@ cc_library(\n-         \":triton_conversion_triton_to_triton_gpu_passes_inc_gen\",\n-         \":triton_nvidia_gpu_transforms_inc_gen\",\n-         \"@llvm-project//mlir:AllPassesAndDialects\",\n-+        \"@llvm-project//mlir:RegisterAllPasses\",\n-         \"@triton//test:TritonTestAnalysis\",\n-         \"@triton//test:TritonTestDialect\",\n-         \"@triton//third_party/amd:TritonAMDGPU\","
        },
        {
            "sha": "560286b054bafaf64b45ad158beecc15a61a5c34",
            "filename": "third_party/xla/third_party/triton/llvm_integration/cl793679540.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 95,
            "changes": 95,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fcl793679540.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,95 +0,0 @@\n-\n---- a/test/Conversion/tritongpu_to_llvm_hopper.mlir\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/test/Conversion/tritongpu_to_llvm_hopper.mlir\t2025-08-11 09:50:34.000000000 -0700\n-@@ -285,7 +285,7 @@\n- // CHECK-LABEL: distribute_to_shared_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @distribute_to_shared_st_matrix_local_store(%a: tensor<64x128xf16, #linear>) {\n--    // CHECK-COUNT-8: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-8: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x128xf16, #linear> -> !ttg.memdesc<64x128xf16, #shared, #smem, mutable>\n-@@ -317,7 +317,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store(%a: tensor<64x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x32xf16, #linear> -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-@@ -339,7 +339,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store(%a: tensor<32x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<32x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<32x32xf16, #linear> -> !ttg.memdesc<32x32xf16, #shared, #smem, mutable>\n-@@ -355,7 +355,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_x2_local_store_fp8\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_x2_local_store_fp8(%a: tensor<64x16xf8E4M3FNUZ, #linear>) {\n--    // CHECK-COUNT-1: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>} :\n-+    // CHECK-COUNT-1: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>} :\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x16xf8E4M3FNUZ, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x16xf8E4M3FNUZ, #linear> -> !ttg.memdesc<64x16xf8E4M3FNUZ, #shared, #smem, mutable>\n-@@ -371,7 +371,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_local_store_fp32\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_local_store_fp32(%a: tensor<64x16xf32, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<row>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<row>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x16xf32, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x16xf32, #linear> -> !ttg.memdesc<64x16xf32, #shared, #smem, mutable>\n-@@ -388,7 +388,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_trans_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_trans_local_store(%a: tensor<64x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<64x32xf16, #linear> -> !ttg.memdesc<64x32xf16, #shared, #smem, mutable>\n-@@ -410,7 +410,7 @@\n- // CHECK-LABEL: linear_to_swizzled_st_matrix_trans_local_store\n- module attributes {\"ttg.target\" = \"cuda:90\", \"ttg.num-ctas\" = 1 : i32, \"ttg.num-warps\" = 4 : i32, \"ttg.threads-per-warp\" = 32 : i32} {\n-   tt.func @linear_to_swizzled_st_matrix_trans_local_store(%a: tensor<16x32xf16, #linear>) {\n--    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {layout = #nvvm.mma_layout<col>}\n-+    // CHECK-COUNT-2: nvvm.stmatrix %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}}, %{{.*}} {eltType = #nvvm.ld_st_matrix_elt_type<b16>, layout = #nvvm.mma_layout<col>, shape = #nvvm.ld_st_matrix_shape<m = 8, n = 8>}\n-     //          CHECK: llvm.return\n-     %b = ttg.local_alloc {allocation.offset = 0 : i32} : () -> !ttg.memdesc<16x32xf16, #shared, #smem, mutable>\n-     ttg.local_store %a, %b : tensor<16x32xf16, #linear> -> !ttg.memdesc<16x32xf16, #shared, #smem, mutable>\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/MemoryOpToLLVM.cpp\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/MemoryOpToLLVM.cpp\t2025-08-11 09:50:35.000000000 -0700\n-@@ -220,7 +220,9 @@\n-         }\n-         inputs.push_back(b.bitcast(input, i32_ty));\n-       }\n--      rewriter.create<NVVM::StMatrixOp>(loc, vecAddr, inputs, layout);\n-+      auto shapeAttr = NVVM::LdStMatrixShapeAttr::get(ctx, /*m=*/8, /*n=*/8);\n-+      rewriter.create<NVVM::StMatrixOp>(loc, vecAddr, inputs, layout, shapeAttr,\n-+                                        NVVM::LdStMatrixEltType::B16);\n-     } else {\n-       Type matTy = nVecs == 1\n-                        ? i32_ty\n-\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TargetInfo.cpp\t2025-07-31 00:13:23.000000000 -0700\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/TargetInfo.cpp\t2025-08-11 09:50:35.000000000 -0700\n-@@ -550,7 +550,10 @@\n-     }\n-     inputs.push_back(b.bitcast(input, i32_ty));\n-   }\n--  rewriter.create<NVVM::StMatrixOp>(loc, ptr, inputs, NVVM::MMALayout::row);\n-+  auto shapeAttr =\n-+      NVVM::LdStMatrixShapeAttr::get(rewriter.getContext(), /*m=*/8, /*n=*/8);\n-+  rewriter.create<NVVM::StMatrixOp>(loc, ptr, inputs, NVVM::MMALayout::row,\n-+                                    shapeAttr, NVVM::LdStMatrixEltType::B16);\n- }\n- \n- std::string TargetInfo::getMulhiFuncName(Type resultElementTy) const {"
        },
        {
            "sha": "bef272c563b2ada8e669cd7b3ed82b6c78e0bd6a",
            "filename": "third_party/xla/third_party/triton/llvm_integration/mem_sync_scope_agent_to_device.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Fmem_sync_scope_agent_to_device.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,24 +0,0 @@\n-b/433429549: Fix the issue where AtomicRMWOp with 2 bf16 elements was not being\n-translated correctly. The sync scope for NV should be device, not agent.\n-\n-diff --git a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n---- a/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n-+++ b/third_party/nvidia/lib/TritonNVIDIAGPUToLLVM/LoadStoreOpToLLVM.cpp\n-@@ -923,7 +923,7 @@ struct AtomicRMWOpConversion\n-         Value atom = rewriter\n-                          .create<LLVM::AtomicRMWOp>(\n-                              loc, *llvmAtomicBinOp, rmwPtr, valElements[i],\n--                             *llvmAtomicMemOrdering, StringRef(\"agent\"))\n-+                             *llvmAtomicMemOrdering, StringRef(\"device\"))\n-                          .getResult();\n-         // Handle the 2 bf16 case\n-         if (packed == 2 && valueElemNBits == 16) {\n-@@ -931,7 +931,7 @@ struct AtomicRMWOpConversion\n-                             .create<LLVM::AtomicRMWOp>(\n-                                 loc, *llvmAtomicBinOp, ptrElements[i + 1],\n-                                 valElements[i + 1], *llvmAtomicMemOrdering,\n--                                StringRef(\"agent\"))\n-+                                StringRef(\"device\"))\n-                             .getResult();\n-           auto vecTy = vec_ty(valueElemTy, vec);\n-           auto tmp ="
        },
        {
            "sha": "64504cb7208283181079c09b6ae1b68843094a6f",
            "filename": "third_party/xla/third_party/triton/llvm_integration/tritongpu-to-ptx-mmav3.patch",
            "status": "removed",
            "additions": 0,
            "deletions": 33,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dda334b1cedbdeb03f031a435cae8712265c5d1c/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Ftriton%2Fllvm_integration%2Ftritongpu-to-ptx-mmav3.patch?ref=dda334b1cedbdeb03f031a435cae8712265c5d1c",
            "patch": "@@ -1,33 +0,0 @@\n-The PTX generated for this test is sensitive to the LLVM version. Newer versions\n-of the NVPTX backend may use 'prmt.b32' instead of 'bfe.u32' for byte extraction\n-and 'setp.eq.b32' instead of 'setp.eq.s32' for equality comparisons. A later\n-update (probably https://github.com/llvm/llvm-project/commit/f480e1b8258eac3565b3ffaf3f8ed0f77eb87fee)\n-optimized the number of prmt instructions generated for this code, so the\n-number of 'prmt.b32' instructions went from 64 to 48.\n-  The checks below have been updated to match the internal codegen as we think\n-  that they are just optimizations.\n-\n---- a/test/Conversion/tritongpu_to_ptx_mmav3.mlir\t2025-07-31 05:01:16.000000000 -0700\n-+++ b/test/Conversion/tritongpu_to_ptx_mmav3.mlir\t2025-08-06 05:43:00.000000000 -0700\n-@@ -57,7 +57,7 @@\n- \n-     // CHECK: mov.u32       [[TID:%.*]], %tid.x;\n-     // CHECK: and.b32       [[L0_VAL:%.*]], [[TID]], 1;\n--    // CHECK: setp.eq.s32   [[L0_OFF:%.*]], [[L0_VAL]], 0;\n-+    // CHECK: setp.eq.b32   [[L0_OFF:%.*]], [[L0_VAL]], 0;\n- \n-     // This is used to perform 16 independent selects in stage 1.\n- \n-@@ -106,10 +106,10 @@\n-     // the predicate (step 3).\n- \n-     // CHECK-DAG: and.b32           [[L1_VAL:%.*]], [[TID]], 2;\n--    // CHECK-DAG: setp.eq.s32       [[L1_OFF:%.*]], [[L1_VAL]], 0;\n-+    // CHECK-DAG: setp.eq.b32       [[L1_OFF:%.*]], [[L1_VAL]], 0;\n-     // CHECK-COUNT-16: selp.b32     {{.*}}, {{.*}}, [[L1_OFF]];\n- \n--    // CHECK-COUNT-64: bfe.u32\n-+    // CHECK-COUNT-48: prmt.b32\n-     // CHECK-COUNT-64: st.volatile.global.b8\n- \n-     %0 = ttg.convert_layout %arg0 : tensor<128x64xf8E5M2, #mma> -> tensor<128x64xf8E5M2, #dot_op>"
        }
    ],
    "stats": {
        "total": 285,
        "additions": 0,
        "deletions": 285
    }
}