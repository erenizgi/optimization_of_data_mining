{
    "author": "seantalts",
    "message": "[XLA:CPU] Generalize Fxx to F8 conversions in XLA intrinsics.\n\nThis change refactors the F16 to F8E4M3FN intrinsic into a more general `EmitFxxToF8E` function. This new function can handle conversions from F16, F32, and F64 to various F8 formats (E5M2, E4M3, E4M3FN, etc.). The `HandleHalfwayPointsFxToF8` helper was also refactored to be non-templated and dynamically calculate halfway points instead of using fixed arrays per type.\n\nThis EmitFxxToF8E function can now handle all but one F8 type dynamically including fn and fnuz variants and has a fast path for the special case where the bias is the same and we can just bitshift the exponent bits over.\n\nPiperOrigin-RevId: 810217185",
    "sha": "833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
    "files": [
        {
            "sha": "8faa2c373e246121810e584d3a963647b677f82f",
            "filename": "third_party/xla/xla/codegen/intrinsic/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2FBUILD?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -63,11 +63,16 @@ cc_library(\n     hdrs = [\"fptrunc.h\"],\n     deps = [\n         \":intrinsic\",\n+        \"//xla:shape_util\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Support\","
        },
        {
            "sha": "f5bdb4d0d8df6b55dbe6d78addb5deba6e9d5350",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc.cc",
            "status": "modified",
            "additions": 268,
            "deletions": 100,
            "changes": 368,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -15,7 +15,15 @@ limitations under the License.\n \n #include \"xla/codegen/intrinsic/fptrunc.h\"\n \n+#include <cstdint>\n+#include <optional>\n+#include <string>\n+#include <vector>\n+\n #include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"llvm/ADT/APFloat.h\"\n #include \"llvm/ADT/APInt.h\"\n #include \"llvm/ADT/FloatingPointMode.h\"\n #include \"llvm/IR/Argument.h\"\n@@ -28,8 +36,11 @@ limitations under the License.\n #include \"llvm/IR/Type.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"xla/codegen/intrinsic/intrinsic.h\"\n+#include \"xla/primitive_util.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/status.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n@@ -116,102 +127,6 @@ static llvm::Function* ExtendF8e5m2ToF16(llvm::Module* module, Type from,\n   return func;\n }\n \n-static llvm::Function* TruncateF16ToF8e4m3fn(llvm::Module* module, Type from,\n-                                             Type to) {\n-  llvm::LLVMContext& context = module->getContext();\n-  llvm::IRBuilder<> b(context);\n-  llvm::Function* func = CreateFunction(module, from, to);\n-  llvm::BasicBlock* entry_bb = llvm::BasicBlock::Create(context, \"entry\", func);\n-  b.SetInsertPoint(entry_bb);\n-  llvm::Value* f16_value = func->getArg(0);\n-\n-  using llvm::APInt;\n-  using llvm::Value;\n-\n-  llvm::Type* i8_ty = to.to_ir_type(context);\n-  llvm::Type* i16_ty = Type(U16, from.vector_width()).to_ir_type(context);\n-  auto i8_const = [&](int val) { return llvm::ConstantInt::get(i8_ty, val); };\n-  auto i16_const = [&](int val) { return llvm::ConstantInt::get(i16_ty, val); };\n-\n-  // Cast the input value to an integer for bitwise manipulation. Get the\n-  // absolute value of the input value.\n-  //   f16_as_int = bitcast(f16_value, int)\n-  //   f16_abs_bits = f16_as_int & 0x7FFF\n-  Value* f16_as_int = b.CreateBitCast(f16_value, i16_ty);\n-  llvm::Value* f16_abs_bits = b.CreateAnd(f16_as_int, i16_const(0x7FFF));\n-\n-  // Get the sign.\n-  //   f8_sign = (f16_as_int & 0x8000) >> 8\n-  Value* f16_sign = b.CreateAnd(f16_as_int, i16_const(0x8000));\n-  f16_sign = b.CreateLShr(f16_sign, i16_const(8));\n-  Value* f8_sign = b.CreateTrunc(f16_sign, i8_ty);\n-\n-  // Truncate the mantissa to 3 bits. ReducePrecision cannot deal with\n-  // f8E4M3FN's NaN representations, so don't use ReducePrecision to handle\n-  // exponent reduction. Denormal values are not handled properly here and are\n-  // dealt with later in this function.\n-  absl::StatusOr<Value*> f16_reduced_statusor =\n-      llvm_ir::EmitReducePrecisionIR(/*src_ty=*/F16, f16_value,\n-                                     /*dest_exponent_bits=*/5,\n-                                     /*dest_mantissa_bits=*/3,\n-                                     /*quiet_nans=*/false, &b);\n-  CHECK_OK(f16_reduced_statusor.status());  // Crash OK\n-  Value* f16_reduced = f16_reduced_statusor.value();\n-  f16_reduced = b.CreateBitCast(f16_reduced, i16_ty);\n-\n-  // Remove the sign bit.\n-  //   f16_reduced = f16_reduced & 0x7FFF\n-  f16_reduced = b.CreateAnd(f16_reduced, i16_const(0x7FFF));\n-\n-  // Bits of the F16 representation of the smallest F8 normal value.\n-  constexpr int min_normal_value = 0x2400;\n-\n-  // Round values smaller than the smallest F8 normal value up to the smallest\n-  // F8 normal value. The case where we round to a denormal value is handled\n-  // later.\n-  //    f16_reduced = max(f16_reduced, min_normal_value)\n-  f16_reduced =\n-      b.CreateSelect(b.CreateICmpULT(f16_reduced, i16_const(min_normal_value)),\n-                     i16_const(min_normal_value), f16_reduced);\n-\n-  constexpr int exponent_bias_difference = 15 - 7;\n-  constexpr int f8_exponent_bits = 4;\n-  constexpr int f16_mantissa_bits = 10;\n-  constexpr int f8_mantissa_bits = 3;\n-  constexpr int mantissa_bits_difference = f16_mantissa_bits - f8_mantissa_bits;\n-\n-  // Adjust the exponent by subtracting the difference in exponent bias.\n-  //   f16_reduced -= (exponent_bias_difference << f16_mantissa_bits)\n-  f16_reduced = b.CreateSub(\n-      f16_reduced, i16_const(exponent_bias_difference << f16_mantissa_bits));\n-\n-  // Shift to convert to F8.\n-  //   f8_bits = f16_reduced >> mantissa_bits_difference;\n-  Value* f8_bits =\n-      b.CreateLShr(f16_reduced, i16_const(mantissa_bits_difference));\n-  f8_bits = b.CreateTrunc(f8_bits, i8_ty);\n-\n-  // Bits of the highest F16 value that gets converted to a finite F8 value.\n-  // In binary: 0 10111 1101111111\n-  constexpr int max_finite_value = 0x5F7F;\n-\n-  // If we're above the maximum F8 value, output NaN.\n-  //   f8_bits = f16_abs_bits > max_finite_value ? 0x7F : f8_bits\n-  f8_bits =\n-      b.CreateSelect(b.CreateICmpUGT(f16_abs_bits, i16_const(max_finite_value)),\n-                     i8_const(0x7F), f8_bits);\n-\n-  // Handle F16 values that are halfway between denormal F8 values.\n-  f8_bits = llvm_ir::HandleHalfwayPointsFxToF8<F16, f8_exponent_bits>(\n-      f16_abs_bits, f8_bits, from.vector_width(), &b);\n-\n-  // Set the sign bit.\n-  //   f8_bits |= f8_sign\n-  f8_bits = b.CreateOr(f8_bits, f8_sign);\n-  b.CreateRet(f8_bits);\n-  return func;\n-}\n-\n static llvm::Function* ExtendF8e4m3fnToF16(llvm::Module* module, Type from,\n                                            Type to) {\n   llvm::LLVMContext& context = module->getContext();\n@@ -221,7 +136,6 @@ static llvm::Function* ExtendF8e4m3fnToF16(llvm::Module* module, Type from,\n   b.SetInsertPoint(entry_bb);\n   llvm::Value* f8_value = func->getArg(0);\n \n-  using llvm::APInt;\n   using llvm::Value;\n \n   llvm::Type* i8_type = from.to_ir_type(context);\n@@ -314,10 +228,267 @@ static llvm::Function* ExtendF8e4m3fnToF16(llvm::Module* module, Type from,\n   return func;\n }\n \n+// For debugging purposes; print floating point values to stdout.\n+void EmitPrintf(llvm::Module* module, Type ty, llvm::Value* value,\n+                llvm::IRBuilder<>* b) {\n+  llvm::FunctionType* printf_type = llvm::FunctionType::get(\n+      b->getInt32Ty(), {b->getInt8Ty()->getPointerTo()}, true);\n+  llvm::FunctionCallee printf =\n+      module->getOrInsertFunction(\"printf\", printf_type);\n+  std::string format_str = \"FpTrunc Printf \" + ty.name() + \" \";\n+  if (ty.element_type() == F16) {\n+    ty = Type(F32, ty.vector_width());\n+    value = b->CreateFPExt(value, b->getFloatTy());\n+  }\n+  for (int i = 0; i < ty.vector_width().value_or(1); ++i) {\n+    switch (ty.element_type()) {\n+      case F32:\n+        format_str += \"%f \";\n+        break;\n+      case F64:\n+        format_str += \"%F \";\n+        break;\n+      default:\n+        LOG(FATAL) << \"Unsupported type: \" << ty.name();\n+    }\n+  }\n+  format_str += \"\\n\";\n+\n+  llvm::Value* format_str_ptr = b->CreateGlobalString(format_str);\n+  std::vector<llvm::Value*> args = {format_str_ptr};\n+  if (ty.vector_width().has_value()) {\n+    for (int i = 0; i < ty.vector_width().value(); ++i) {\n+      args.push_back(b->CreateExtractElement(value, i));\n+    }\n+  } else {\n+    args.push_back(value);\n+  }\n+  b->CreateCall(printf, args);\n+}\n+\n+// Converts a floating-point value to an 8-bit floating-point value with\n+// specified properties.\n+//\n+// This function is vector-capable. If `from_type` is a vector type, it will\n+// generate vector instructions for the conversion.\n+absl::StatusOr<llvm::Function*> EmitFxxToF8E(llvm::Module* module,\n+                                             const Type& from, const Type& to) {\n+  llvm::LLVMContext& context = module->getContext();\n+  llvm::IRBuilder<> b(context);\n+  if (!from.is_scalar() && !from.is_vector()) {\n+    return absl::InvalidArgumentError(\"from_type must be a scalar or vector.\");\n+  }\n+  TF_RETURN_IF_ERROR(Type::VerifySameWidth(from, to));\n+\n+  llvm::Function* func = CreateFunction(module, from, to);\n+  llvm::BasicBlock* entry_bb = llvm::BasicBlock::Create(context, \"entry\", func);\n+  b.SetInsertPoint(entry_bb);\n+  llvm::Value* from_value = func->getArg(0);\n+\n+  const PrimitiveType fx_type = from.element_type();\n+  if (fx_type != F16 && fx_type != F32 && fx_type != F64) {\n+    return absl::InvalidArgumentError(\"from_type must be F16, F32, or F64.\");\n+  }\n+\n+  const uint64_t fx_width = primitive_util::BitWidth(fx_type);\n+  const uint64_t fx_bias = primitive_util::ExponentBias(fx_type);\n+  const uint64_t fx_mantissa_bits =\n+      primitive_util::SignificandWidth(fx_type) - 1;\n+  const uint64_t fx_exp_bits = primitive_util::ExponentWidth(fx_type);\n+  const uint64_t f8_exp_bits = primitive_util::ExponentWidth(to.element_type());\n+  const bool is_fnuz = !primitive_util::HasInfinity(to.element_type()) &&\n+                       !primitive_util::HasNegativeZero(to.element_type());\n+  // HACK: The F8E4M3FNUZ format has a max value of 240, which implies a bias\n+  // of 8. The value in primitive_util is 7.\n+  // Verified with ml_dtypes\n+  int f8_bias = primitive_util::ExponentBias(to.element_type());\n+  if (to.element_type() == F8E4M3FNUZ) {\n+    f8_bias = 8;\n+  }\n+\n+  const uint64_t f8_mantissa_bits =\n+      primitive_util::SignificandWidth(to.element_type()) - 1;\n+  const uint64_t exponent_bias_difference = fx_bias - f8_bias;\n+\n+  const PrimitiveType ix_primitive_type =\n+      primitive_util::UnsignedIntegralTypeForBitWidth(fx_width);\n+  llvm::Type* ix_type =\n+      Type(ix_primitive_type, from.vector_width()).to_ir_type(context);\n+  llvm::Type* i8_type = to.to_ir_type(context);\n+\n+  auto make_const = [&](uint64_t val, llvm::Type* type) -> llvm::Constant* {\n+    llvm::IntegerType* scalar_ty =\n+        llvm::IntegerType::get(context, type->getScalarSizeInBits());\n+    llvm::Constant* scalar_const = llvm::ConstantInt::get(scalar_ty, val);\n+    if (type->isVectorTy()) {\n+      auto vec_ty = llvm::cast<llvm::FixedVectorType>(type);\n+      return llvm::ConstantVector::getSplat(vec_ty->getElementCount(),\n+                                            scalar_const);\n+    }\n+    return scalar_const;\n+  };\n+\n+  auto ix_const = [&](uint64_t val) { return make_const(val, ix_type); };\n+  auto i8_const = [&](uint64_t val) { return make_const(val, i8_type); };\n+\n+  // If biases and exponent widths are identical (e.g., F16 -> F8E5M2),\n+  // we can delegate all logic to EmitReducePrecisionIR and do a simple shift.\n+  if (fx_bias == f8_bias && fx_exp_bits == f8_exp_bits) {\n+    LOG(INFO) << \"Using fast path for \" << from.name() << \" -> \" << to.name();\n+    TF_ASSIGN_OR_RETURN(\n+        llvm::Value * reduced_precision,\n+        llvm_ir::EmitReducePrecisionIR(\n+            /*src_ty=*/fx_type, from_value,\n+            /*dest_exponent_bits=*/f8_exp_bits,  // <-- Pass DEST exp bits\n+            /*dest_mantissa_bits=*/f8_mantissa_bits,\n+            /*quiet_nans=*/true, &b));\n+\n+    // Bitcast to integer to perform the shift.\n+    llvm::Value* as_int = b.CreateBitCast(reduced_precision, ix_type);\n+\n+    // Shift the 8 relevant bits (1 sign + 5 exp + 2 mantissa for F8E5M2)\n+    // into position. The shift amount is the difference in mantissa bits.\n+    const uint64_t mantissa_shift = fx_mantissa_bits - f8_mantissa_bits;\n+    llvm::Value* shifted = b.CreateLShr(as_int, ix_const(mantissa_shift));\n+\n+    // Truncate from i16/i32/i64 down to i8.\n+    llvm::Value* truncated = b.CreateTrunc(shifted, i8_type);\n+\n+    b.CreateRet(truncated);\n+    return func;  // We are done, skip the general \"slow\" logic.\n+  }\n+\n+  llvm::Constant* nosign_mask = ix_const((1ULL << (fx_width - 1)) - 1);\n+  llvm::Constant* sign_mask = ix_const(1ULL << (fx_width - 1));\n+  llvm::Constant* min_normal_value =\n+      ix_const((exponent_bias_difference + 1) << fx_mantissa_bits);\n+\n+  using llvm::Value;\n+  Value* fx_as_int = b.CreateBitCast(from_value, ix_type);\n+  Value* fx_abs_bits = b.CreateAnd(fx_as_int, nosign_mask);\n+\n+  Value* fx_sign = b.CreateAnd(fx_as_int, sign_mask);\n+  fx_sign = b.CreateLShr(fx_sign, ix_const(fx_width - 8));\n+  Value* f8_sign = b.CreateTrunc(fx_sign, i8_type);\n+\n+  // To avoid `ReducePrecision`'s assumptions, we only use it for mantissa\n+  // rounding, keeping the original exponent bits.\n+  absl::StatusOr<Value*> fx_reduced_statusor = llvm_ir::EmitReducePrecisionIR(\n+      /*src_ty=*/fx_type, from_value,\n+      /*dest_exponent_bits=*/primitive_util::ExponentWidth(fx_type),\n+      /*dest_mantissa_bits=*/f8_mantissa_bits,\n+      /*quiet_nans=*/true, &b);\n+  TF_CHECK_OK(fx_reduced_statusor.status());  // Crash OK\n+  Value* fx_reduced = b.CreateBitCast(fx_reduced_statusor.value(), ix_type);\n+  fx_reduced = b.CreateAnd(fx_reduced, nosign_mask);\n+\n+  // Round small values up to the minimum normal F8 value.\n+  fx_reduced = b.CreateSelect(b.CreateICmpULT(fx_reduced, min_normal_value),\n+                              min_normal_value, fx_reduced);\n+\n+  // Adjust the exponent bias.\n+  fx_reduced = b.CreateSub(\n+      fx_reduced, ix_const(exponent_bias_difference << fx_mantissa_bits));\n+  // Shift mantissa into place.\n+  Value* f8_bits_shifted =\n+      b.CreateLShr(fx_reduced, ix_const(fx_mantissa_bits - f8_mantissa_bits));\n+  Value* f8_bits = b.CreateTrunc(f8_bits_shifted, i8_type);\n+\n+  // Calculate the threshold for overflow. This is the largest value that maps\n+  // to a finite F8 value, including a rounding component.\n+  const bool has_inf = primitive_util::HasInfinity(to.element_type());\n+  const uint64_t max_finite_f8_exp =\n+      has_inf ? (1ULL << f8_exp_bits) - 2 : (1ULL << f8_exp_bits) - 1;\n+  const uint64_t max_finite_f8_man = (1ULL << f8_mantissa_bits) - 1;\n+  const uint64_t max_finite_fx_exp =\n+      max_finite_f8_exp + exponent_bias_difference;\n+  const uint64_t man_shift = fx_mantissa_bits - f8_mantissa_bits;\n+  const uint64_t max_finite_value_exp = max_finite_fx_exp << fx_mantissa_bits;\n+  const uint64_t max_finite_value_man = max_finite_f8_man << man_shift;\n+  const uint64_t rounding_bits = (1ULL << man_shift) - 1;\n+  const uint64_t max_finite_value =\n+      max_finite_value_exp | max_finite_value_man | rounding_bits;\n+  Value* is_overflow = b.CreateICmpUGT(fx_abs_bits, ix_const(max_finite_value));\n+\n+  // Handle format-specific overflow behavior.\n+  if (has_inf) {\n+    // For standard formats, overflow becomes infinity.\n+    // Also propagate Inf/NaN.\n+    const uint64_t fx_exp_mask =\n+        ((1ULL << primitive_util::ExponentWidth(fx_type)) - 1)\n+        << fx_mantissa_bits;\n+    Value* is_inf_or_nan_input = b.CreateICmpEQ(\n+        b.CreateAnd(fx_abs_bits, ix_const(fx_exp_mask)), ix_const(fx_exp_mask));\n+\n+    const uint64_t fx_mantissa_mask = (1ULL << fx_mantissa_bits) - 1;\n+    Value* fx_mantissa = b.CreateAnd(fx_abs_bits, ix_const(fx_mantissa_mask));\n+    Value* is_nan_input = b.CreateAnd(is_inf_or_nan_input,\n+                                      b.CreateICmpNE(fx_mantissa, ix_const(0)));\n+\n+    const uint64_t f8_exp_mask = ((1ULL << f8_exp_bits) - 1)\n+                                 << f8_mantissa_bits;\n+    const uint64_t f8_qnan_mantissa = 1ULL << (f8_mantissa_bits - 1);\n+    const uint64_t f8_nan_pattern = f8_exp_mask | f8_qnan_mantissa;\n+    // If the input is NaN, the output is NaN.\n+    // If the input is Inf or overflows, the output is Inf.\n+    // Otherwise, it's the computed finite value.\n+    Value* finite_or_inf =\n+        b.CreateSelect(is_overflow, i8_const(f8_exp_mask), f8_bits);\n+    Value* inf_or_nan = b.CreateSelect(is_nan_input, i8_const(f8_nan_pattern),\n+                                       i8_const(f8_exp_mask));\n+    f8_bits = b.CreateSelect(is_inf_or_nan_input, inf_or_nan, finite_or_inf);\n+  } else {\n+    // For fn/fnuz formats, overflow and input Inf/NaN become NaN.\n+    const uint64_t fx_exp_mask =\n+        ((1ULL << primitive_util::ExponentWidth(fx_type)) - 1)\n+        << fx_mantissa_bits;\n+    Value* is_inf_or_nan_input = b.CreateICmpEQ(\n+        b.CreateAnd(fx_abs_bits, ix_const(fx_exp_mask)), ix_const(fx_exp_mask));\n+\n+    const uint64_t f8_nan_pattern =\n+        is_fnuz ? 0x80 : (1ULL << (f8_exp_bits + f8_mantissa_bits)) - 1;\n+\n+    Value* is_special = b.CreateOr(is_overflow, is_inf_or_nan_input);\n+    f8_bits = b.CreateSelect(is_special, i8_const(f8_nan_pattern), f8_bits);\n+\n+    if (is_fnuz) {\n+      // For FNUZ, the NaN value is used for all special cases, and it is\n+      // unsigned.\n+      f8_sign = b.CreateSelect(is_special, i8_const(0), f8_sign);\n+    }\n+  }\n+\n+  // Handle halfway points for denormals.\n+  f8_bits = llvm_ir::HandleHalfwayPointsFxToF8(\n+      /*fx_type=*/fx_type, /*f8_exponent_bits=*/f8_exp_bits,\n+      /*f8_mantissa_bits=*/f8_mantissa_bits, /*f8_bias=*/f8_bias,\n+      /*fx_abs_bits=*/fx_abs_bits, /*f8_bits=*/f8_bits,\n+      /*vector_width=*/from.vector_width(), &b);\n+\n+  // For FNUZ types, -0.0 should become +0.0. Since f8_bits is derived from\n+  // fx_abs_bits, it will be 0 if the input is +/-0.0. We just need to\n+  // ensure the sign bit is not set in this case.\n+  if (is_fnuz) {\n+    Value* is_zero = b.CreateICmpEQ(fx_abs_bits, ix_const(0));\n+    f8_sign = b.CreateSelect(is_zero, i8_const(0), f8_sign);\n+  }\n+\n+  // Apply the sign bit.\n+  f8_bits = b.CreateOr(f8_bits, f8_sign);\n+\n+  b.CreateRet(f8_bits);\n+  return func;\n+}\n+\n absl::StatusOr<llvm::Function*> FpTrunc::CreateDefinition(llvm::Module* module,\n                                                           Type from, Type to) {\n   TF_RETURN_IF_ERROR(Type::VerifySameWidth(from, to));\n \n+  if (primitive_util::IsF8Type(to.element_type()) &&\n+      (from.element_type() == F16 || from.element_type() == F32 ||\n+       from.element_type() == F64)) {\n+    return EmitFxxToF8E(module, from, to);\n+  }\n   if (from.element_type() == F32 && to.element_type() == BF16) {\n     return TruncateF32ToBf16(module, from, to);\n   }\n@@ -327,9 +498,6 @@ absl::StatusOr<llvm::Function*> FpTrunc::CreateDefinition(llvm::Module* module,\n   if (from.element_type() == F8E4M3FN && to.element_type() == F16) {\n     return ExtendF8e4m3fnToF16(module, from, to);\n   }\n-  if (from.element_type() == F16 && to.element_type() == F8E4M3FN) {\n-    return TruncateF16ToF8e4m3fn(module, from, to);\n-  }\n \n   return Internal(\"Unsupported fptrunc conversion: from=%s to=%s\", from.name(),\n                   to.name());"
        },
        {
            "sha": "f9034589f18ffce332f62883df7ad235d0aa8468",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc.h",
            "status": "modified",
            "additions": 15,
            "deletions": 5,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc.h?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -36,7 +36,7 @@ class FpTrunc : public Intrinsic<FpTrunc> {\n   static constexpr bool kLastArgIsReturnType = true;\n   static constexpr int8_t kNumArgs = 2;  // Second arg is the return type.\n   static std::vector<std::vector<Type>> SupportedVectorTypes() {\n-    return {\n+    std::vector<std::vector<Type>> supported_types = {\n         {Type::S(xla::F32), Type::S(xla::BF16)},\n         {Type::V(xla::F32, 2), Type::V(xla::BF16, 2)},\n         {Type::V(xla::F32, 4), Type::V(xla::BF16, 4)},\n@@ -49,11 +49,21 @@ class FpTrunc : public Intrinsic<FpTrunc> {\n         {Type::V(F8E4M3FN, 2), Type::V(F16, 2)},\n         {Type::V(F8E4M3FN, 4), Type::V(F16, 4)},\n         {Type::V(F8E4M3FN, 8), Type::V(F16, 8)},\n-        {Type::S(F16), Type::S(F8E4M3FN)},\n-        {Type::V(F16, 2), Type::V(F8E4M3FN, 2)},\n-        {Type::V(F16, 4), Type::V(F8E4M3FN, 4)},\n-        {Type::V(F16, 8), Type::V(F8E4M3FN, 8)},\n     };\n+\n+    // Handle all FxxToF8e conversions.\n+    for (PrimitiveType fx_type : {F16, F32, F64}) {\n+      for (PrimitiveType f8_type : {F8E4M3, F8E4M3FN, F8E4M3B11FNUZ, F8E3M4,\n+                                    F8E4M3FNUZ, F8E5M2, F8E5M2FNUZ}) {\n+        // Not yet supported: F8E8M0FNU\n+        supported_types.push_back({Type::S(fx_type), Type::S(f8_type)});\n+        for (int8_t vector_width : {2, 4, 8}) {\n+          supported_types.push_back(\n+              {Type::V(fx_type, vector_width), Type::V(f8_type, vector_width)});\n+        }\n+      }\n+    }\n+    return supported_types;\n   }\n \n   static absl::StatusOr<llvm::Function*> CreateDefinition(llvm::Module* module,"
        },
        {
            "sha": "d04f22c6ba913e4afb0691865c2cf7cce660bd20",
            "filename": "third_party/xla/xla/codegen/intrinsic/fptrunc_test.cc",
            "status": "modified",
            "additions": 303,
            "deletions": 0,
            "changes": 303,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic%2Ffptrunc_test.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n \n #include <array>\n #include <cstdint>\n+#include <limits>\n #include <memory>\n #include <utility>\n \n@@ -189,4 +190,306 @@ TEST(FpTruncExecutionTest, F8e4m3fnToF16_Vector4) {\n   EXPECT_EQ(actuals[3], static_cast<int16_t>(0b0011100000000000));\n }\n \n+TEST(FpTruncExecutionTest, F32ToF8e4m3fn) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E4M3FN));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E4M3FN)));\n+  EXPECT_EQ(fptrunc(0x7FFFFFFF), 0x7F);  // overflows\n+  EXPECT_EQ(fptrunc(0x0), 0x0);\n+\n+  EXPECT_EQ(fptrunc(-2.0f), static_cast<int8_t>(0b11000000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00110000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10110000));\n+  EXPECT_EQ(fptrunc(0.125f), static_cast<int8_t>(0b00100000));\n+\n+  // Test denormals (exponent all 0s) round to 0 in fp8e4m3fn.\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::denorm_min()), 0);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::min()), 0);\n+  // largest f32 denormal:\n+  EXPECT_EQ(fptrunc(1.17549e-38f), 0);\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e3m4) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E3M4));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E3M4)));\n+  EXPECT_EQ(fptrunc(0x0), 0x0);\n+  EXPECT_EQ(fptrunc(-2.0f), static_cast<int8_t>(0b11000000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00100000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10100000));\n+  EXPECT_EQ(fptrunc(0.0156f), static_cast<int8_t>(0b00000001));\n+\n+  // test underflow, denormals\n+  const float smallest_pos_subnormal_f8e3m4 = 0.015625;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal_f8e3m4),\n+            static_cast<int8_t>(0b00000001));\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal_f8e3m4),\n+            static_cast<int8_t>(0b00000001));\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal_f8e3m4 / 2.0f - eps),\n+            static_cast<int8_t>(0b00000000));\n+\n+  // test overflows and infinities\n+  const int8_t inf = static_cast<int8_t>(0b01110000);\n+  const int8_t neg_inf = static_cast<int8_t>(0b11110000);\n+  const float max_f8e3m4 = 15.5;\n+  EXPECT_EQ(fptrunc(max_f8e3m4 + 1.0f), inf);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), inf);\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), neg_inf);\n+\n+  // test nan prop\n+  const int8_t nan = static_cast<int8_t>(0b01111000);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+TEST(FpTruncExecutionTest, F32ToF8e4m3) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E4M3));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E4M3)));\n+\n+  // Test basic values\n+  EXPECT_EQ(fptrunc(0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(16.0f), static_cast<int8_t>(0b01011000));\n+  EXPECT_EQ(fptrunc(-16.0f), static_cast<int8_t>(0b11011000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00110000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10110000));\n+\n+  // Test underflow and subnormals\n+  // Smallest positive subnormal for f8e4m3 is 2^-9\n+  const float smallest_pos_subnormal_f8e4m3 = 0.001953125f;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal_f8e4m3),\n+            static_cast<int8_t>(0b00000001));\n+\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal_f8e4m3 / 2.0f - eps),\n+            static_cast<int8_t>(0b00000000));\n+\n+  // Test overflows and infinities\n+  const int8_t pos_inf = static_cast<int8_t>(0b01111000);\n+  const int8_t neg_inf = static_cast<int8_t>(0b11111000);\n+  const float max_f8e4m3 = 448.0f;\n+  EXPECT_EQ(fptrunc(max_f8e4m3 + 1.0f), pos_inf);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), pos_inf);\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), neg_inf);\n+\n+  // Test NaN propagation\n+  const int8_t nan = static_cast<int8_t>(0x7C);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e4m3fnuz) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E4M3FNUZ));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E4M3FNUZ)));\n+\n+  EXPECT_EQ(fptrunc(0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(16.0f), static_cast<int8_t>(0b01100000));\n+  EXPECT_EQ(fptrunc(-16.0f), static_cast<int8_t>(0b11100000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00111000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10111000));\n+\n+  // Test underflow and subnormals (FNUZ formats often support subnormals)\n+  const float smallest_pos_subnormal = 0.0009765625f;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal), static_cast<int8_t>(0b00000001));\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal * 2.0f),\n+            static_cast<int8_t>(0b00000010));\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal / 2.0f - eps), 0x0);\n+\n+  // Test overflows (clamps to nan, no infinity)\n+  const float max_val = 240.0f;\n+  EXPECT_EQ(fptrunc(max_val), static_cast<int8_t>(0b01111111));\n+  EXPECT_EQ(fptrunc(-max_val), static_cast<int8_t>(0b11111111));\n+  const int8_t nan = static_cast<int8_t>(0b10000000);\n+  EXPECT_EQ(fptrunc(max_val + 10.0f), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), nan);\n+  EXPECT_EQ(fptrunc(-(max_val + 10.0f)), nan);\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), nan);\n+\n+  // Test NaN propagation\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e4m3fnuz_Vector4) {\n+  JitRunner jit = CreateJitRunner(Type::V(F32, 4), Type::V(F8E4M3FNUZ, 4));\n+  auto fptrunc = jit.GetVectorizedFn<4, int8_t, float>(\n+      FpTrunc::Name(Type::V(F32, 4), Type::V(F8E4M3FNUZ, 4)));\n+  std::array<float, 4> vals = {500, 16.0f, -0.5f, -240.0f};\n+  std::array<int8_t, 4> actuals = fptrunc(vals);\n+  EXPECT_EQ(actuals[0], static_cast<int8_t>(0b10000000));\n+  EXPECT_EQ(actuals[1], static_cast<int8_t>(0b01100000));\n+  EXPECT_EQ(actuals[2], static_cast<int8_t>(0b10111000));\n+  EXPECT_EQ(actuals[3], static_cast<int8_t>(0b11111111));\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e4m3fnuz_Vector8) {\n+  JitRunner jit = CreateJitRunner(Type::V(F32, 8), Type::V(F8E4M3FNUZ, 8));\n+  auto fptrunc = jit.GetVectorizedFn<8, int8_t, float>(\n+      FpTrunc::Name(Type::V(F32, 8), Type::V(F8E4M3FNUZ, 8)));\n+  std::array<float, 8> vals = {500,   16.0f,  -0.5f,  -240.0f,\n+                               -1.0f, -16.0f, 240.0f, 242.0f};\n+  std::array<int8_t, 8> actuals = fptrunc(vals);\n+  EXPECT_EQ(actuals[0], static_cast<int8_t>(0b10000000));\n+  EXPECT_EQ(actuals[1], static_cast<int8_t>(0b01100000));\n+  EXPECT_EQ(actuals[2], static_cast<int8_t>(0b10111000));\n+  EXPECT_EQ(actuals[3], static_cast<int8_t>(0b11111111));\n+  EXPECT_EQ(actuals[4], static_cast<int8_t>(0b11000000));\n+  EXPECT_EQ(actuals[5], static_cast<int8_t>(0b11100000));\n+  EXPECT_EQ(actuals[6], static_cast<int8_t>(0b01111111));\n+\n+  // 242.0f rounds down to 240.0f:\n+  EXPECT_EQ(actuals[7], static_cast<int8_t>(0b01111111));\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e4m3fn_Vector8) {\n+  JitRunner jit = CreateJitRunner(Type::V(F32, 8), Type::V(F8E4M3FN, 8));\n+  auto fptrunc = jit.GetVectorizedFn<8, int8_t, float>(\n+      FpTrunc::Name(Type::V(F32, 8), Type::V(F8E4M3FN, 8)));\n+  std::array<float, 8> vals = {500,   16.0f,  -0.5f, -240.0f,\n+                               -1.0f, -16.0f, 0.5f,  242.0f};\n+  std::array<int8_t, 8> actuals = fptrunc(vals);\n+  EXPECT_EQ(actuals[0], static_cast<int8_t>(0b10000000));  // 500 -> NaN\n+  EXPECT_EQ(actuals[1], static_cast<int8_t>(0b01011000));  // 16.0f\n+  EXPECT_EQ(actuals[2], static_cast<int8_t>(0b10110000));  // -0.5f\n+  EXPECT_EQ(actuals[3], static_cast<int8_t>(0b11110111));  // -240.0f\n+  EXPECT_EQ(actuals[4], static_cast<int8_t>(0b10111000));  // -1.0f\n+  EXPECT_EQ(actuals[5], static_cast<int8_t>(0b11011000));  // -16.0f\n+  EXPECT_EQ(actuals[6], static_cast<int8_t>(0b00110000));  // 0.5f\n+\n+  // 242.0f rounds down to 240.0f:\n+  EXPECT_EQ(actuals[7], static_cast<int8_t>(0b01110111));\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e4m3b11fnuz) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E4M3B11FNUZ));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E4M3B11FNUZ)));\n+\n+  // Test basic values (bias of 11 shifts the range)\n+  EXPECT_EQ(fptrunc(0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(16.0f), static_cast<int8_t>(0b01111000));\n+  EXPECT_EQ(fptrunc(-16.0f), static_cast<int8_t>(0b11111000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b01010000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b11010000));\n+\n+  // Test underflow and subnormals\n+  // Smallest subnormal is 0.125 * 2^(1-11) = 2^-3 * 2^-10 = 2^-13\n+  constexpr float smallest_pos_subnormal = 0.0001220703125f;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal), static_cast<int8_t>(0b00000001));\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal * 2.0f),\n+            static_cast<int8_t>(0b00000010));\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal / 2.0f - eps), 0x0);\n+\n+  // Test overflows (clamps to nan, no infinity)\n+  // Max value is (1 + 7/8) * 2^(15-11) = 1.875 * 16 = 30\n+  const float max_val = 30.0f;\n+  EXPECT_EQ(fptrunc(max_val), static_cast<int8_t>(0b01111111));\n+  EXPECT_EQ(fptrunc(-max_val), static_cast<int8_t>(0b11111111));\n+  const int8_t nan = static_cast<int8_t>(0b10000000);\n+  EXPECT_EQ(fptrunc(max_val + 1.0f), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), nan);\n+  EXPECT_EQ(fptrunc(-(max_val + 1.0f)), nan);\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), nan);\n+  EXPECT_EQ(fptrunc(166.0f), nan);\n+\n+  // Test NaN propagation\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e5m2) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E5M2));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E5M2)));\n+\n+  // Test basic values (bias of 15)\n+  EXPECT_EQ(fptrunc(0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(16.0f), static_cast<int8_t>(0b01001100));\n+  EXPECT_EQ(fptrunc(-16.0f), static_cast<int8_t>(0b11001100));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00111000));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10111000));\n+\n+  // Test underflow and subnormals\n+  // Smallest subnormal is 0.25 * 2^(1-15) = 2^-2 * 2^-14 = 2^-16\n+  constexpr float smallest_pos_subnormal = 0.0000152587890625f;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal), static_cast<int8_t>(0b00000001));\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal * 2.0f),\n+            static_cast<int8_t>(0b00000010));\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal / 2.0f - eps), 0x0);\n+\n+  // Test overflows (goes to infinity)\n+  // Max value is (1 + 3/4) * 2^(30-15) = 1.75 * 2^15 = 57344\n+  const float max_val = 57344.0f;\n+  EXPECT_EQ(fptrunc(max_val), static_cast<int8_t>(0b01111011));\n+  EXPECT_EQ(fptrunc(-max_val), static_cast<int8_t>(0b11111011));\n+  const int8_t pos_inf = static_cast<int8_t>(0b01111100);\n+  const int8_t neg_inf = static_cast<int8_t>(0b11111100);\n+  EXPECT_EQ(fptrunc(max_val * 2.0f), pos_inf);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), pos_inf);\n+  EXPECT_EQ(fptrunc(-max_val * 2.0f), neg_inf);\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), neg_inf);\n+\n+  // Test NaN propagation\n+  const int8_t nan = static_cast<int8_t>(0b01111110);  // Canonical qNaN\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+\n+TEST(FpTruncExecutionTest, F32ToF8e5m2fnuz) {\n+  JitRunner jit = CreateJitRunner(Type::S(F32), Type::S(F8E5M2FNUZ));\n+  auto fptrunc = jit.GetScalarFn<int8_t(float)>(\n+      FpTrunc::Name(Type::S(F32), Type::S(F8E5M2FNUZ)));\n+\n+  // Test basic values (bias of 16 shifts the range)\n+  EXPECT_EQ(fptrunc(0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(-0.0f), 0x0);\n+  EXPECT_EQ(fptrunc(16.0f), static_cast<int8_t>(0b01010000));\n+  EXPECT_EQ(fptrunc(-16.0f), static_cast<int8_t>(0b11010000));\n+  EXPECT_EQ(fptrunc(0.5f), static_cast<int8_t>(0b00111100));\n+  EXPECT_EQ(fptrunc(-0.5f), static_cast<int8_t>(0b10111100));\n+\n+  // Test underflow and subnormals\n+  // Smallest subnormal is 0.25 * 2^(1-16) = 2^-2 * 2^-15 = 2^-17\n+  constexpr float smallest_pos_subnormal = 0.00000762939453125f;\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal), static_cast<int8_t>(0b00000001));\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal * 2.0f),\n+            static_cast<int8_t>(0b00000010));\n+  const float eps = std::numeric_limits<float>::epsilon();\n+  EXPECT_EQ(fptrunc(smallest_pos_subnormal / 2.0f - eps), 0x0);\n+\n+  // Test overflows (clamps to nan, no infinity)\n+  // Max value is (1 + 3/4) * 2^(30-16) = 1.75 * 2^14 = 28672\n+  const float max_val = 57344.0f;\n+  EXPECT_EQ(fptrunc(max_val), static_cast<int8_t>(0b01111111));\n+  EXPECT_EQ(fptrunc(-max_val), static_cast<int8_t>(0b11111111));\n+  const int8_t nan = static_cast<int8_t>(0b10000000);\n+  EXPECT_EQ(fptrunc(max_val * 2.0f), nan);  // Overflow\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::infinity()), nan);\n+  EXPECT_EQ(fptrunc(-max_val * 2.0f), nan);  // Overflow\n+  EXPECT_EQ(fptrunc(-std::numeric_limits<float>::infinity()), nan);\n+\n+  // Test NaN propagation\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::quiet_NaN()), nan);\n+  EXPECT_EQ(fptrunc(std::numeric_limits<float>::signaling_NaN()), nan);\n+}\n+\n+TEST(FpTruncExecutionTest, F16ToF8e5m2fnuz) {\n+  JitRunner jit = CreateJitRunner(Type::S(F16), Type::S(F8E5M2FNUZ));\n+  auto fptrunc = jit.GetScalarFn<int8_t(int16_t)>(\n+      FpTrunc::Name(Type::S(F16), Type::S(F8E5M2FNUZ)) + \"_itofp\");\n+\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0x00)),\n+            static_cast<int8_t>(0b00000000));\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b1100000000000000)),\n+            static_cast<int8_t>(0b11000100));  // -2.0\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b0011100000000000)),\n+            0b00111100);  // 0.5\n+  EXPECT_EQ(fptrunc(static_cast<int16_t>(0b1011100000000000)),\n+            static_cast<int8_t>(0b10111100));  // -0.5\n+}\n+\n }  // namespace xla::codegen::intrinsics"
        },
        {
            "sha": "bebc567013abcb042c8dbd24587fd36fa46fb157",
            "filename": "third_party/xla/xla/codegen/intrinsic_lib.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fintrinsic_lib.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -227,6 +227,19 @@ GetCalledApproximatableFunctions(\n   return called_targets;\n }\n \n+bool ElementTypesMatch(const std::vector<Type>& types1,\n+                       const std::vector<Type>& types2) {\n+  if (types1.size() != types2.size()) {\n+    return false;\n+  }\n+  for (int i = 0; i < types1.size(); ++i) {\n+    if (types1[i].element_type() != types2[i].element_type()) {\n+      return false;\n+    }\n+  }\n+  return true;\n+}\n+\n }  // anonymous namespace\n \n std::vector<llvm::VecDesc> IntrinsicFunctionLib::Vectorizations() {\n@@ -238,8 +251,7 @@ std::vector<llvm::VecDesc> IntrinsicFunctionLib::Vectorizations() {\n          math_func->SupportedVectorTypes(options_.features)) {\n       for (const auto& vector_types :\n            math_func->SupportedVectorTypes(options_.features)) {\n-        if (target_types.front().element_type() !=\n-            vector_types.front().element_type()) {\n+        if (!ElementTypesMatch(target_types, vector_types)) {\n           continue;\n         }\n         absl::string_view target_name = intrinsic::StringInterner::Get().Intern("
        },
        {
            "sha": "0d6cc05745fe3f3bb472e21347bd68df4c6bcedf",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -4176,7 +4176,6 @@ cc_library(\n         \"//xla/service/llvm_ir:loop_emitter\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\","
        },
        {
            "sha": "a4a8d11ee9dfd10dfa1ed3144194ac274ee3f6f3",
            "filename": "third_party/xla/xla/service/elemental_ir_emitter.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 224,
            "changes": 281,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Felemental_ir_emitter.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -21,15 +21,13 @@ limitations under the License.\n #include <functional>\n #include <limits>\n #include <memory>\n-#include <optional>\n #include <string>\n #include <tuple>\n #include <utility>\n #include <vector>\n \n // IWYU pragma: no_include \"llvm/IR/Intrinsics.gen.inc\"\n #include \"absl/algorithm/container.h\"\n-#include \"absl/base/macros.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n@@ -39,9 +37,7 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"llvm/ADT/APFloat.h\"\n #include \"llvm/ADT/APInt.h\"\n-#include \"llvm/ADT/FloatingPointMode.h\"\n #include \"llvm/IR/BasicBlock.h\"\n #include \"llvm/IR/Constant.h\"\n #include \"llvm/IR/Constants.h\"\n@@ -86,148 +82,25 @@ using llvm_ir::IrArray;\n using llvm_ir::IrName;\n using llvm_ir::SetToFirstInsertPoint;\n using xla::float8_fnuz_ir_emitter::EmitF8fnuzToFloating;\n-using xla::float8_fnuz_ir_emitter::EmitFloatingToF8fnuz;\n \n using IntrinsicType = xla::codegen::intrinsics::Type;\n+using FpTrunc = xla::codegen::intrinsics::FpTrunc;\n \n namespace {\n \n-absl::StatusOr<llvm::Value*> EmitF16ToF8e5m2(llvm::Value* f16_value,\n-                                             llvm::IRBuilderBase* b) {\n-  TF_ASSIGN_OR_RETURN(\n-      llvm::Value * reduced_precision,\n-      EmitReducePrecisionIR(\n-          /*src_ty=*/F16, f16_value,\n-          /*dest_exponent_bits=*/primitive_util::ExponentWidth(F8E5M2),\n-          /*dest_mantissa_bits=*/primitive_util::SignificandWidth(F8E5M2) - 1,\n-          /*quiet_nans=*/true, b));\n-  llvm::Value* as_int16 = b->CreateBitCast(reduced_precision, b->getInt16Ty());\n-  llvm::Value* shifted = b->CreateLShr(as_int16, 8);\n-  llvm::Value* truncated = b->CreateTrunc(shifted, b->getInt8Ty());\n-  return b->CreateBitCast(truncated, b->getInt8Ty());\n-}\n-\n llvm::Value* EmitF8e5m2ToF16(llvm::Value* f8_value, llvm::IRBuilderBase* b) {\n   llvm::Value* as_int8 = b->CreateBitCast(f8_value, b->getInt8Ty());\n   llvm::Value* as_int16 = b->CreateZExt(as_int8, b->getInt16Ty());\n   llvm::Value* shifted = b->CreateShl(as_int16, 8);\n   return b->CreateBitCast(shifted, b->getHalfTy());\n }\n \n-// Convert a float \"fx_value\" of type \"fx_type\" to an F8e \"f8_exponent_bits\"\n-// bits wide.\n-template <PrimitiveType fx_type, int f8_exponent_bits>\n-absl::StatusOr<llvm::Value*> EmitFxToF8e(llvm::Value* fx_value,\n-                                         llvm::IRBuilderBase* b) {\n-  static_assert(fx_type == F16 || fx_type == F32 || fx_type == F64);\n-  static_assert(3 <= f8_exponent_bits && f8_exponent_bits <= 4);\n-\n-  constexpr int f8_mantissa_bits = 7 - f8_exponent_bits;\n-  constexpr int f8_bias = (1 << (f8_exponent_bits - 1)) - 1;\n-\n-  const uint64_t fx_width = primitive_util::BitWidth(fx_type);\n-  const uint64_t fx_bias = primitive_util::ExponentBias(fx_type);\n-  const uint64_t fx_mantissa_bits =\n-      primitive_util::SignificandWidth(fx_type) - 1;\n-\n-  const uint64_t exponent_bias_difference = fx_bias - f8_bias;\n-\n-  using llvm::APInt;\n-  using llvm::Value;\n-\n-  const llvm::fltSemantics* fx_semantics;\n-  llvm::IntegerType* ix_type;\n-\n-  if constexpr (fx_type == F16) {\n-    ix_type = b->getInt16Ty();\n-    fx_semantics = &llvm::APFloat::IEEEhalf();\n-  } else if constexpr (fx_type == F32) {\n-    ix_type = b->getInt32Ty();\n-    fx_semantics = &llvm::APFloat::IEEEsingle();\n-  } else if constexpr (fx_type == F64) {\n-    ix_type = b->getInt64Ty();\n-    fx_semantics = &llvm::APFloat::IEEEdouble();\n-  }\n-\n-  auto ix_const = [ix_type](uint64_t val) {\n-    return llvm::ConstantInt::get(ix_type, val);\n-  };\n-\n-  llvm::IntegerType* i8_type = b->getInt8Ty();\n-  llvm::Constant* infinity = llvm::ConstantInt::get(\n-      ix_type, llvm::APFloat::getInf(*fx_semantics).bitcastToAPInt());\n-  llvm::ConstantInt* nosign_mask =\n-      ix_const(ix_type->getBitMask() ^ ix_type->getSignBit());\n-  llvm::ConstantInt* sign_mask = ix_const(ix_type->getSignBit());\n-  llvm::ConstantInt* sign_shift = ix_const(fx_width - 8);\n-  llvm::ConstantInt* fx_exponent_bias_difference =\n-      ix_const(exponent_bias_difference << fx_mantissa_bits);\n-  llvm::ConstantInt* fx_doubled_exponent_bias_difference =\n-      ix_const(exponent_bias_difference << (fx_mantissa_bits + 1));\n-  llvm::ConstantInt* mantissa_bits_difference =\n-      ix_const(fx_mantissa_bits - f8_mantissa_bits);\n-  llvm::ConstantInt* min_normal_value =\n-      ix_const((exponent_bias_difference + 1) << fx_mantissa_bits);\n-\n-  // Cast the input value to an integer for bitwise manipulation. Get the\n-  // absolute value of the input value.\n-  //   fx_as_int = bitcast(fx_value, int)\n-  //   fx_abs_bits = fx_as_int & nosign_mask\n-  Value* fx_as_int = b->CreateBitCast(fx_value, ix_type);\n-  llvm::Value* fx_abs_bits = b->CreateAnd(fx_as_int, nosign_mask);\n-\n-  // Get the sign.\n-  //   f8_sign = (fx_as_int & sign_mask) >> sign_shift\n-  Value* fx_sign = b->CreateAnd(fx_as_int, sign_mask);\n-  fx_sign = b->CreateLShr(fx_sign, sign_shift);\n-  Value* f8_sign = b->CreateTrunc(fx_sign, i8_type);\n-\n-  // Truncate the mantissa to f8 mantissa bits and exponent to f8 exponent bits\n-  // Denormal values are not handled properly here and are\n-  // dealt with later in this function.\n-  absl::StatusOr<Value*> fx_reduced_statusor = EmitReducePrecisionIR(\n-      /*src_ty=*/fx_type, fx_value,\n-      /*dest_exponent_bits=*/f8_exponent_bits,\n-      /*dest_mantissa_bits=*/f8_mantissa_bits,\n-      /*quiet_nans=*/true, b);\n-  CHECK_OK(fx_reduced_statusor.status());  // Crash OK\n-  Value* fx_reduced = fx_reduced_statusor.value();\n-  fx_reduced = b->CreateBitCast(fx_reduced, ix_type);\n-\n-  // Remove the sign bit.\n-  //   fx_reduced = fx_reduced & nosign_mask\n-  fx_reduced = b->CreateAnd(fx_reduced, nosign_mask);\n-\n-  // Round values smaller than the smallest F8 normal value up to the smallest\n-  // F8 normal value. The case where we round to a denormal value is handled\n-  // later.\n-  //    fx_reduced = max(fx_reduced, min_normal_value)\n-  fx_reduced = b->CreateSelect(b->CreateICmpULT(fx_reduced, min_normal_value),\n-                               min_normal_value, fx_reduced);\n-\n-  // Adjust the exponent by subtracting the difference in exponent bias:\n-  //   fx_reduced -= (exponent_bias_difference << fx_mantissa_bits)\n-  // For infinity/NaN values, subtract twice the difference in exponent bias\n-  // to ensure the leading exponent bit(s) of fx_reduced are set to zero.\n-  fx_reduced = b->CreateSub(\n-      fx_reduced, b->CreateSelect(b->CreateICmpULT(fx_reduced, infinity),\n-                                  fx_exponent_bias_difference,\n-                                  fx_doubled_exponent_bias_difference));\n-\n-  // Shift to convert to F8.\n-  //   fx_reduced = fx_reduced >> mantissa_bits_difference;\n-  fx_reduced = b->CreateLShr(fx_reduced, mantissa_bits_difference);\n-\n-  Value* f8_bits = b->CreateTrunc(fx_reduced, i8_type);\n-\n-  // Handle Fx values that are halfway between denormal F8 values.\n-  f8_bits = llvm_ir::HandleHalfwayPointsFxToF8<fx_type, f8_exponent_bits>(\n-      fx_abs_bits, f8_bits, std::nullopt, b);\n-\n-  // Set the sign bit.\n-  //   f8_bits |= f8_sign\n-  f8_bits = b->CreateOr(f8_bits, f8_sign);\n-  return f8_bits;\n+llvm::Value* EmitFxToF8e(llvm::Module* module, PrimitiveType fx_type,\n+                         PrimitiveType f8_type, llvm::Value* fx_value,\n+                         llvm::IRBuilderBase* b) {\n+  llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+      module, IntrinsicType::S(fx_type), IntrinsicType::S(f8_type));\n+  return b->CreateCall(fptrunc, {fx_value});\n }\n \n template <int f8_exponent_bits>\n@@ -360,51 +233,13 @@ llvm::Value* EmitToF16F8e(llvm::Value* f8_value, llvm::IRBuilderBase* b) {\n   return b->CreateBitCast(f16_as_int, b->getHalfTy());\n }\n \n-llvm::Value* EmitF16ToF8e4m3fn(llvm::Value* f16_value, llvm::Module* module,\n-                               llvm::IRBuilderBase* b) {\n-  llvm::Function* fptrunc =\n-      codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-          module, IntrinsicType::S(F16), IntrinsicType::S(F8E4M3FN));\n-  return b->CreateCall(fptrunc, {f16_value});\n-}\n llvm::Value* EmitF8e4m3fnToF16(llvm::Value* f8_value, llvm::Module* module,\n                                llvm::IRBuilderBase* b) {\n-  llvm::Function* fptrunc =\n-      codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-          module, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n+  llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+      module, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n   return b->CreateCall(fptrunc, {f8_value});\n }\n \n-llvm::Value* EmitF16ToF8e4m3b11fnuz(llvm::Value* f16_value,\n-                                    llvm::Module* module,\n-                                    llvm::IRBuilderBase* b) {\n-  using llvm::APInt;\n-  using llvm::Value;\n-\n-  llvm::IntegerType* i8_type = b->getInt8Ty();\n-  auto i8_const = [i8_type](int val) {\n-    return llvm::ConstantInt::get(i8_type, val);\n-  };\n-  auto type = f16_value->getType();\n-  auto f16_abs_value = llvm_ir::EmitCallToIntrinsic(llvm::Intrinsic::fabs,\n-                                                    {f16_value}, {type}, b);\n-  auto f16_zero_or_underflow = llvm::ConstantFP::get(type, 0x1.004p-14);\n-  auto is_zero = b->CreateFCmpOLT(f16_abs_value, f16_zero_or_underflow);\n-  auto f8_overflow_threshold = llvm::ConstantFP::get(type, 0x1.fp+4);\n-  auto no_overflow = b->CreateFCmpOLT(f16_abs_value, f8_overflow_threshold);\n-\n-  // Re-scale the f16, then convert as-if it were e4m3fn.\n-  f16_value = b->CreateFMul(\n-      f16_value, llvm::ConstantFP::get(f16_value->getType(), 1 << (11 - 7)));\n-  auto* f8_value = EmitF16ToF8e4m3fn(f16_value, module, b);\n-\n-  // e4m3b11 overflows to NaN.\n-  f8_value = b->CreateSelect(no_overflow, f8_value, i8_const(0x80));\n-  // e4m3b11 has no negative zero.\n-  f8_value = b->CreateSelect(is_zero, i8_const(0x00), f8_value);\n-  return f8_value;\n-}\n-\n llvm::Value* EmitF8e4m3b11fnuzToF16(llvm::Value* f8_value, llvm::Module* module,\n                                     llvm::IRBuilderBase* b) {\n   using llvm::APInt;\n@@ -734,27 +569,25 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitIntegerUnaryOp(\n       }\n       if (primitive_util::IsFloatingPointType(to_type)) {\n         if (to_type == F8E5M2) {\n-          return EmitF16ToF8e5m2(\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              b_);\n+          operand_value = EmitIntegralToFloating(operand_value, from_type, F16,\n+                                                 module_, b_);\n+          return EmitFxToF8e(module_, F16, F8E5M2, operand_value, b_);\n         }\n         if (to_type == F8E4M3) {\n-          return EmitFxToF8e<F16, 4>(\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              b_);\n+          return EmitFxToF8e(module_, F16, F8E4M3,\n+                             EmitIntegralToFloating(operand_value, from_type,\n+                                                    F16, module_, b_),\n+                             b_);\n         }\n         if (to_type == F8E4M3FN) {\n           operand_value = EmitIntegralToFloating(operand_value, from_type, F16,\n                                                  module_, b_);\n-          return EmitF16ToF8e4m3fn(operand_value, module_, b_);\n+          return EmitFxToF8e(module_, F16, F8E4M3FN, operand_value, b_);\n         }\n         if (to_type == F8E4M3B11FNUZ) {\n-          return EmitF16ToF8e4m3b11fnuz(\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              module_, b_);\n+          operand_value = EmitIntegralToFloating(operand_value, from_type, F16,\n+                                                 module_, b_);\n+          return EmitFxToF8e(module_, F16, F8E4M3B11FNUZ, operand_value, b_);\n         }\n         if (to_type == F4E2M1FN) {\n           return EmitF16ToF4e2m1fn(\n@@ -769,17 +602,15 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitIntegerUnaryOp(\n               b_);\n         }\n         if (to_type == F8E5M2FNUZ || to_type == F8E4M3FNUZ) {\n-          return EmitFloatingToF8fnuz(\n-              F16,\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              to_type, b_);\n+          operand_value = EmitIntegralToFloating(operand_value, from_type, F16,\n+                                                 module_, b_);\n+          return EmitFxToF8e(module_, F16, to_type, operand_value, b_);\n         }\n         if (to_type == F8E3M4) {\n-          return EmitFxToF8e<F16, 3>(\n-              EmitIntegralToFloating(operand_value, from_type, F16, module_,\n-                                     b_),\n-              b_);\n+          return EmitFxToF8e(module_, F16, F8E3M4,\n+                             EmitIntegralToFloating(operand_value, from_type,\n+                                                    F16, module_, b_),\n+                             b_);\n         }\n         return EmitIntegralToFloating(operand_value, from_type, to_type,\n                                       module_, b_);\n@@ -898,9 +729,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n       // This is enabled explicitly by a flag only for XLA:CPU backend.\n       if (options_.xla_cpu_use_truncate_f32_to_bf16_conversion) {\n         if (from_type == F32 && to_type == BF16) {\n-          llvm::Function* fptrunc =\n-              codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-                  module_, IntrinsicType::S(F32), IntrinsicType::S(BF16));\n+          llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+              module_, IntrinsicType::S(F32), IntrinsicType::S(BF16));\n           return b_->CreateCall(fptrunc, {operand_value});\n         }\n         if (from_type == BF16 && to_type == F32) {\n@@ -926,9 +756,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n       }\n       if (from_type == F8E5M2) {\n         TF_RET_CHECK(to_type != F8E5M2);\n-        llvm::Function* fptrunc =\n-            codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-                module_, IntrinsicType::S(F8E5M2), IntrinsicType::S(F16));\n+        llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+            module_, IntrinsicType::S(F8E5M2), IntrinsicType::S(F16));\n         operand_value = b_->CreateCall(fptrunc, {operand_value});\n         from_type = F16;\n         if (from_type == to_type) {\n@@ -945,9 +774,8 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n       }\n       if (from_type == F8E4M3FN) {\n         TF_RET_CHECK(to_type != F8E4M3FN);\n-        llvm::Function* fptrunc =\n-            codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-                module_, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n+        llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+            module_, IntrinsicType::S(F8E4M3FN), IntrinsicType::S(F16));\n         operand_value = b_->CreateCall(fptrunc, {operand_value});\n         from_type = F16;\n         if (from_type == to_type) {\n@@ -1028,21 +856,21 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n               operand_value,\n               llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n         }\n-        return EmitF16ToF8e5m2(operand_value, b_);\n+        return EmitFxToF8e(module_, F16, F8E5M2, operand_value, b_);\n       }\n       if (to_type == F8E4M3) {\n         switch (from_type) {\n           case F16:\n-            return EmitFxToF8e<F16, 4>(operand_value, b_);\n+            return EmitFxToF8e(module_, F16, F8E4M3, operand_value, b_);\n           case F32:\n-            return EmitFxToF8e<F32, 4>(operand_value, b_);\n+            return EmitFxToF8e(module_, F32, F8E4M3, operand_value, b_);\n           case F64:\n-            return EmitFxToF8e<F64, 4>(operand_value, b_);\n+            return EmitFxToF8e(module_, F64, F8E4M3, operand_value, b_);\n           case BF16:\n             operand_value = b_->CreateFPCast(\n                 operand_value,\n                 llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n-            return EmitFxToF8e<F16, 4>(operand_value, b_);\n+            return EmitFxToF8e(module_, F16, F8E4M3, operand_value, b_);\n           default:\n             return InvalidArgument(\"Unsupported conversion from %s to %s\",\n                                    PrimitiveType_Name(from_type),\n@@ -1056,19 +884,19 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n               operand_value,\n               llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n         }\n-        llvm::Function* fptrunc =\n-            codegen::intrinsics::FpTrunc::GetOrInsertDeclaration(\n-                module_, IntrinsicType::S(F16), IntrinsicType::S(F8E4M3FN));\n+        llvm::Function* fptrunc = FpTrunc::GetOrInsertDeclaration(\n+            module_, IntrinsicType::S(F16), IntrinsicType::S(F8E4M3FN));\n         return b_->CreateCall(fptrunc, {operand_value});\n       }\n       if (to_type == F8E4M3B11FNUZ) {\n-        // Cast to F16 first. Casts to F8E4M3B11FNUZ must be from F16.\n-        if (from_type != F16) {\n+        if (from_type != F16 && from_type != F32 && from_type != F64) {\n           operand_value = b_->CreateFPCast(\n               operand_value,\n               llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n+          from_type = F16;\n         }\n-        return EmitF16ToF8e4m3b11fnuz(operand_value, module_, b_);\n+        return EmitFxToF8e(module_, from_type, F8E4M3B11FNUZ, operand_value,\n+                           b_);\n       }\n       if (to_type == F4E2M1FN) {\n         // Cast to F16 first. Casts to F4E2M1FN must be from F16.\n@@ -1089,21 +917,27 @@ absl::StatusOr<llvm::Value*> ElementalIrEmitter::EmitFloatUnaryOp(\n         return EmitF32ToF8e8m0fnu(operand_value, b_);\n       }\n       if (to_type == F8E5M2FNUZ || to_type == F8E4M3FNUZ) {\n-        return EmitFloatingToF8fnuz(from_type, operand_value, to_type, b_);\n+        if (from_type != F16 && from_type != F32 && from_type != F64) {\n+          operand_value = b_->CreateFPCast(\n+              operand_value,\n+              llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n+          from_type = F16;\n+        }\n+        return EmitFxToF8e(module_, from_type, to_type, operand_value, b_);\n       }\n       if (to_type == F8E3M4) {\n         switch (from_type) {\n           case F16:\n-            return EmitFxToF8e<F16, 3>(operand_value, b_);\n+            return EmitFxToF8e(module_, F16, F8E3M4, operand_value, b_);\n           case F32:\n-            return EmitFxToF8e<F32, 3>(operand_value, b_);\n+            return EmitFxToF8e(module_, F32, F8E3M4, operand_value, b_);\n           case F64:\n-            return EmitFxToF8e<F64, 3>(operand_value, b_);\n+            return EmitFxToF8e(module_, F64, F8E3M4, operand_value, b_);\n           case BF16:\n             operand_value = b_->CreateFPCast(\n                 operand_value,\n                 llvm_ir::PrimitiveTypeToIrType(F16, module_->getContext()));\n-            return EmitFxToF8e<F16, 3>(operand_value, b_);\n+            return EmitFxToF8e(module_, F16, F8E3M4, operand_value, b_);\n           default:\n             return InvalidArgument(\"Unsupported conversion from %s to %s\",\n                                    PrimitiveType_Name(from_type),\n@@ -3509,9 +3343,8 @@ llvm_ir::ElementGenerator ElementalIrEmitter::MakeElementGenerator(\n               b_->CreateUIToFP(elem_index_linear, float_ir_type);\n           if (component_element_type == F8E4M3FNUZ ||\n               component_element_type == F8E5M2FNUZ) {\n-            TF_ASSIGN_OR_RETURN(\n-                iota_result, EmitFloatingToF8fnuz(F16, float_val,\n-                                                  component_element_type, b_));\n+            iota_result = EmitFxToF8e(module_, F16, component_element_type,\n+                                      float_val, b_);\n           } else {\n             iota_result = float_val;\n           }"
        },
        {
            "sha": "e335b9ec67037d6124eea2cce9d8551920c1fa9f",
            "filename": "third_party/xla/xla/service/float8_fnuz_ir_emitter.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 64,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -517,70 +517,6 @@ absl::StatusOr<uint64_t> GetQNaN(PrimitiveType type) {\n }\n }  // namespace\n \n-absl::StatusOr<llvm::Value*> EmitFloatingToF8fnuz(PrimitiveType input_type,\n-                                                  llvm::Value* input_value,\n-                                                  PrimitiveType output_type,\n-                                                  llvm::IRBuilderBase* b) {\n-  // Sanity check for supported types.\n-  TF_RET_CHECK(input_type == BF16 || input_type == F16 || input_type == F32 ||\n-               input_type == F64);\n-  TF_RET_CHECK(output_type == F8E4M3FNUZ || output_type == F8E5M2FNUZ);\n-\n-  llvm::IntegerType* input_int_type = b->getIntNTy(BitWidth(input_type));\n-  llvm::Value* input_uint = b->CreateBitCast(input_value, input_int_type);\n-\n-  TF_ASSIGN_OR_RETURN(\n-      llvm::Value * out_of_range_pred,\n-      IsInputOutsideOutputRange(input_type, input_uint, output_type, b));\n-  // We may now assume there won't be any further overflow issues. They will be\n-  // handled in the final select.\n-\n-  // Compute rounding bias for round-to-nearest with ties to even.\n-  TF_ASSIGN_OR_RETURN(\n-      llvm::Value * input_rounding_bias,\n-      DynamicRoundingBias(input_type, input_uint, output_type, b));\n-\n-  // Apply the rounding bias to the input. This won't carry into the sign bit.\n-  llvm::Value* input_uint_rounded =\n-      b->CreateAdd(input_uint, input_rounding_bias);\n-\n-  // The input value is broken down and in a canonical form. Appropriate\n-  // rounding has been applied, exponent is not biased, and there are no\n-  // implicit bits in the mantissa.\n-  llvm::Value* sign =\n-      ExtractSign(input_type, input_uint, /*preserve_signed_zero=*/false, b);\n-  llvm::Value* exponent = ExtractExponent(input_type, input_uint_rounded, b);\n-  llvm::Value* mantissa = ExtractMantissa(input_type, input_uint_rounded, b);\n-\n-  // The component parts of the output value.\n-  llvm::Value* output_sign = BuildOutputSign(sign, output_type, b);\n-  llvm::Value* output_exponent =\n-      BuildOutputExponent(input_type, exponent, mantissa, output_type, b);\n-  llvm::Value* output_mantissa =\n-      BuildOutputMantissa(input_type, exponent, mantissa, output_type, b);\n-\n-  // Bitwise or the output components together.\n-  llvm::Value* result = b->CreateOr(output_exponent, output_mantissa);\n-\n-  // Check for output underflow before adding a sign bit. There's no -0 in\n-  // fnuz types.\n-  llvm::Value* is_zero_pred = IsZero(input_type, result, b);\n-  output_sign = b->CreateSelect(\n-      is_zero_pred, llvm::ConstantInt::get(input_int_type, 0x0u), output_sign);\n-\n-  // Bitwise or the sign bit into the result.\n-  result = b->CreateOr(result, output_sign);\n-\n-  // Truncate down to int8.\n-  result = b->CreateTrunc(result, b->getInt8Ty());\n-\n-  // Select based on whether the value was in range.\n-  TF_ASSIGN_OR_RETURN(const uint64_t output_qnan, GetQNaN(output_type));\n-  return b->CreateSelect(out_of_range_pred,\n-                         llvm::ConstantInt::get(b->getInt8Ty(), output_qnan),\n-                         result);\n-}\n-\n absl::StatusOr<llvm::Value*> EmitF8fnuzToFloating(PrimitiveType input_type,\n                                                   llvm::Value* f8_value,\n                                                   PrimitiveType output_type,"
        },
        {
            "sha": "8c3c9314bd1137cbfbb9a0f127f1275663c93fe8",
            "filename": "third_party/xla/xla/service/float8_fnuz_ir_emitter.h",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Ffloat8_fnuz_ir_emitter.h?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -25,14 +25,6 @@ limitations under the License.\n namespace xla {\n namespace float8_fnuz_ir_emitter {\n \n-// Convert the given floating point input to the output type. input_type must\n-// be one of BF16, F16, F32, and F64. output_type must be one of F8E4M3FNUZ and\n-// F8E5M2FNUZ.\n-absl::StatusOr<llvm::Value*> EmitFloatingToF8fnuz(PrimitiveType input_type,\n-                                                  llvm::Value* input_value,\n-                                                  PrimitiveType output_type,\n-                                                  llvm::IRBuilderBase* b);\n-\n // Convert the given floating point input to the output type. input_type must\n // be one of F8E4M3FNUZ and F8E5M2FNUZ. output_type must be one of BF16, F16,\n // F32, and F64."
        },
        {
            "sha": "2d0ab8fad9131a6c12c3ff09aa938811dcbd2e5a",
            "filename": "third_party/xla/xla/service/llvm_ir/llvm_util.cc",
            "status": "modified",
            "additions": 102,
            "deletions": 1,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.cc?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/service/llvm_ir/llvm_util.h\"\n \n #include <algorithm>\n+#include <cstddef>\n #include <cstdint>\n #include <iterator>\n #include <limits>\n@@ -34,7 +35,9 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"llvm/ADT/APFloat.h\"\n #include \"llvm/ADT/ArrayRef.h\"\n+#include \"llvm/ADT/FloatingPointMode.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallPtrSet.h\"\n #include \"llvm/ADT/SmallVector.h\"\n@@ -139,7 +142,6 @@ std::optional<PrimitiveType> PrimitiveComplexTypeFromIrStructType(\n \n }  // namespace\n \n-\n llvm::CallInst* EmitCallToIntrinsic(\n     llvm::Intrinsic::ID intrinsic_id, absl::Span<llvm::Value* const> operands,\n     absl::Span<llvm::Type* const> overloaded_types, llvm::IRBuilderBase* b,\n@@ -1014,5 +1016,104 @@ absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n   return result;\n }\n \n+llvm::Value* HandleHalfwayPointsFxToF8(\n+    PrimitiveType fx_type, int f8_exponent_bits, int f8_mantissa_bits,\n+    int f8_bias, llvm::Value* fx_abs_bits, llvm::Value* f8_bits,\n+    std::optional<size_t> vector_width, llvm::IRBuilderBase* b) {\n+  using llvm::APFloat;\n+  using llvm::APInt;\n+  using llvm::Value;\n+  CHECK(fx_type == F16 || fx_type == F32 || fx_type == F64);\n+\n+  const llvm::fltSemantics* fx_semantics;\n+  llvm::Type* fx_float_type = PrimitiveTypeToIrType(fx_type, b->getContext());\n+  llvm::Type* scale_factor_type = fx_float_type;\n+\n+  if (fx_type == F16) {\n+    // Scale factor can be > 2^17, which overflows F16.\n+    fx_semantics = &llvm::APFloat::IEEEsingle();\n+    scale_factor_type = b->getFloatTy();\n+  } else if (fx_type == F32) {\n+    fx_semantics = &llvm::APFloat::IEEEsingle();\n+  } else if (fx_type == F64) {\n+    fx_semantics = &llvm::APFloat::IEEEdouble();\n+  } else {\n+    LOG(FATAL) << \"Unsupported FX type: \" << fx_type;\n+  }\n+\n+  // Get the input/output types, accounting for vectors.\n+  llvm::Type* ix_type = fx_abs_bits->getType();\n+  llvm::Type* i8_type = f8_bits->getType();\n+\n+  if (vector_width.has_value()) {\n+    auto vec_width = llvm::ElementCount::getFixed(*vector_width);\n+    fx_float_type = llvm::VectorType::get(fx_float_type, vec_width);\n+    scale_factor_type = llvm::VectorType::get(scale_factor_type, vec_width);\n+  }\n+  llvm::RoundingMode rm = llvm::RoundingMode::NearestTiesToEven;\n+\n+  auto fp_const = [&](APFloat val) {\n+    bool losesInfo;\n+    val.convert(*fx_semantics, rm, &losesInfo);\n+    return llvm::ConstantFP::get(scale_factor_type, val);\n+  };\n+\n+  const int num_subnormal_steps = 1 << f8_mantissa_bits;\n+  const int smallest_normal_exp = 1 - f8_bias;\n+  const int quantum_exponent = smallest_normal_exp - f8_mantissa_bits;\n+\n+  // Create the scaling factor constant: 2^(-quantum_exponent)\n+  // e.g., for B11 (quantum_exp = -13), this is 2^13, or 8192.0.\n+  APFloat scale_apfloat = scalbn(APFloat(1.0), -quantum_exponent, rm);\n+\n+  // Create the upper boundary constant: (num_steps - 0.5) * quantum\n+  // This is the halfway point for the *largest* subnormal step (e.g., 7.5 *\n+  // q).\n+  APFloat quantum = scalbn(APFloat(1.0), quantum_exponent, rm);\n+\n+  APFloat num_steps_apfloat(static_cast<double>(num_subnormal_steps));\n+  APFloat half_apfloat(0.5);\n+\n+  APFloat upper_bound_apfloat = num_steps_apfloat;\n+  upper_bound_apfloat.subtract(half_apfloat, rm);\n+  upper_bound_apfloat.multiply(quantum, rm);\n+\n+  Value* scale_factor = fp_const(scale_apfloat);\n+  Value* upper_bound_constant = fp_const(upper_bound_apfloat);\n+  Value* input_float = b->CreateBitCast(fx_abs_bits, fx_float_type);\n+  input_float = b->CreateFPExt(input_float, scale_factor_type);\n+\n+  // Check if the input is below the subnormal range boundary.\n+  // Anything >= 7.5q (for an M3 format) is a normal number and should\n+  // use the default 'f8_bits' value passed into this function.\n+  Value* is_subnormal_candidate =\n+      b->CreateFCmpOLT(input_float, upper_bound_constant);\n+\n+  // --- Subnormal Path ---\n+  // Apply the rounding formula: i = round_to_even(input_float * scale_factor)\n+  Value* scaled = b->CreateFMul(input_float, scale_factor);\n+\n+  // Use llvm.nearbyint, which rounds to the nearest integer using\n+  // ties-to-even.\n+  llvm::Module* module = b->GetInsertBlock()->getModule();\n+  llvm::Function* nearbyint = llvm::Intrinsic::getOrInsertDeclaration(\n+      module, llvm::Intrinsic::nearbyint, {scaled->getType()});\n+  Value* rounded = b->CreateCall(nearbyint, scaled);\n+\n+  // Convert the rounded float result to its integer bucket index.\n+  Value* int_bucket = b->CreateFPToUI(rounded, ix_type);\n+\n+  // Truncate the index (which is i32 or i64) down to our final i8 value.\n+  Value* subnormal_result = b->CreateTrunc(int_bucket, i8_type);\n+\n+  // --- Final Select ---\n+  // If it was a subnormal candidate, use our calculated result.\n+  // Otherwise, use the original 'f8_bits' value (the default normal/inf/nan).\n+  Value* final_result =\n+      b->CreateSelect(is_subnormal_candidate, subnormal_result, f8_bits);\n+\n+  return final_result;\n+}\n+\n }  // namespace llvm_ir\n }  // namespace xla"
        },
        {
            "sha": "ed79a45d7794f1a4227b08483978a08a329bf430",
            "filename": "third_party/xla/xla/service/llvm_ir/llvm_util.h",
            "status": "modified",
            "additions": 4,
            "deletions": 116,
            "changes": 120,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/833d806e7fa77c4893c55fa6a1ae1a93bf150c3b/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fllvm_ir%2Fllvm_util.h?ref=833d806e7fa77c4893c55fa6a1ae1a93bf150c3b",
            "patch": "@@ -369,122 +369,10 @@ absl::StatusOr<llvm::Value*> EmitReducePrecisionIR(\n     PrimitiveType src_ty, llvm::Value* x, int64_t dest_exponent_bits,\n     int64_t dest_mantissa_bits, bool quiet_nans, llvm::IRBuilderBase* b);\n \n-template <PrimitiveType fx_type, int f8_exponent_bits>\n-llvm::Value* HandleHalfwayPointsFxToF8(llvm::Value* fx_abs_bits,\n-                                       llvm::Value* f8_bits,\n-                                       std::optional<size_t> vector_width,\n-                                       llvm::IRBuilderBase* b) {\n-  using llvm::APFloat;\n-  using llvm::APInt;\n-  using llvm::Value;\n-  static_assert(fx_type == F16 || fx_type == F32 || fx_type == F64);\n-  static_assert(3 <= f8_exponent_bits && f8_exponent_bits <= 4);\n-\n-  const llvm::fltSemantics* fx_semantics;\n-  llvm::Type* ix_type;\n-\n-  if constexpr (fx_type == F16) {\n-    fx_semantics = &llvm::APFloat::IEEEhalf();\n-    ix_type = b->getInt16Ty();\n-  } else if constexpr (fx_type == F32) {\n-    fx_semantics = &llvm::APFloat::IEEEsingle();\n-    ix_type = b->getInt32Ty();\n-  } else if constexpr (fx_type == F64) {\n-    fx_semantics = &llvm::APFloat::IEEEdouble();\n-    ix_type = b->getInt64Ty();\n-  }\n-\n-  llvm::Type* i8_type = b->getInt8Ty();\n-\n-  if (vector_width.has_value()) {\n-    ix_type = llvm::VectorType::get(\n-        ix_type, llvm::ElementCount::getFixed(*vector_width));\n-    i8_type = llvm::VectorType::get(\n-        i8_type, llvm::ElementCount::getFixed(*vector_width));\n-  }\n-\n-  auto ix_const = [fx_semantics, ix_type](APFloat val) {\n-    bool losesInfo;\n-    val.convert(*fx_semantics, llvm::RoundingMode::NearestTiesToEven,\n-                &losesInfo);\n-    return llvm::ConstantInt::get(ix_type, val.bitcastToAPInt());\n-  };\n-\n-  auto i8_const = [i8_type](int val) {\n-    return llvm::ConstantInt::get(i8_type, val);\n-  };\n-\n-  // F16 values that are halfway between denormal F8 values. This is used to\n-  // determine how to round to denormal F8 values.\n-  const APFloat halfway_points_e4[8] = {\n-      APFloat(0x1.0p-10),  // halfway between [0/8 * 2^-6, 1/8 * 2^-6]\n-      APFloat(0x1.8p-9),   // halfway between [1/8 * 2^-6, 2/8 * 2^-6]\n-      APFloat(0x1.4p-8),   // halfway between [2/8 * 2^-6, 3/8 * 2^-6]\n-      APFloat(0x1.Cp-8),   // halfway between [3/8 * 2^-6, 4/8 * 2^-6]\n-      APFloat(0x1.2p-7),   // halfway between [4/8 * 2^-6, 5/8 * 2^-6]\n-      APFloat(0x1.6p-7),   // halfway between [5/8 * 2^-6, 6/8 * 2^-6]\n-      APFloat(0x1.Ap-7),   // halfway between [6/8 * 2^-6, 7/8 * 2^-6]\n-      APFloat(0x1.Ep-7)    // halfway between [7/8 * 2^-6, 8/8 * 2^-6]\n-  };\n-\n-  const APFloat halfway_points_e3[16] = {\n-      APFloat(0x1.0p-7),  // halfway between [0/16 * 2^-2, 1/16 * 2^-2]\n-      APFloat(0x1.8p-6),  // halfway between [1/16 * 2^-2, 2/16 * 2^-2]\n-      APFloat(0x1.4p-5),  // halfway between [2/16 * 2^-2, 3/16 * 2^-2]\n-      APFloat(0x1.Cp-5),  // halfway between [3/16 * 2^-2, 4/16 * 2^-2]\n-      APFloat(0x1.2p-4),  // halfway between [4/16 * 2^-2, 5/16 * 2^-2]\n-      APFloat(0x1.6p-4),  // halfway between [5/16 * 2^-2, 6/16 * 2^-2]\n-      APFloat(0x1.Ap-4),  // halfway between [6/16 * 2^-2, 7/16 * 2^-2]\n-      APFloat(0x1.Ep-4),  // halfway between [7/16 * 2^-2, 8/16 * 2^-2]\n-      APFloat(0x1.1p-3),  // halfway between [8/16 * 2^-2, 9/16 * 2^-2]\n-      APFloat(0x1.3p-3),  // halfway between [9/16 * 2^-2, 10/16 * 2^-2]\n-      APFloat(0x1.5p-3),  // halfway between [10/16 * 2^-2, 11/16 * 2^-2]\n-      APFloat(0x1.7p-3),  // halfway between [11/16 * 2^-2, 12/16 * 2^-2]\n-      APFloat(0x1.9p-3),  // halfway between [12/16 * 2^-2, 13/16 * 2^-2]\n-      APFloat(0x1.Bp-3),  // halfway between [13/16 * 2^-2, 14/16 * 2^-2]\n-      APFloat(0x1.Dp-3),  // halfway between [14/16 * 2^-2, 15/16 * 2^-2]\n-      APFloat(0x1.Fp-3),  // halfway between [15/16 * 2^-2, 16/16 * 2^-2]\n-  };\n-\n-  const APFloat* halfway_points;\n-  int arr_sz;\n-  if constexpr (f8_exponent_bits == 4) {\n-    halfway_points = halfway_points_e4;\n-    arr_sz = 8;\n-  } else if constexpr (f8_exponent_bits == 3) {\n-    halfway_points = halfway_points_e3;\n-    arr_sz = 16;\n-  }\n-\n-  // Handle case where output is denormal. If we're rounding to a denormal\n-  // value, ignore the current value of f8_bits and set it to the correct\n-  // denormal value. We emit the equivalent of the following:\n-  //\n-  //   if (f16_abs_bits <= halfway_points[0]) {\n-  //     f8_bits = 0;\n-  //   } else if (f16_abs_bits < halfway_points[1]) {\n-  //     f8_bits = 1;\n-  //   } else if (f16_abs_bits <= halfway_points[2]) {\n-  //   ...  // More if-else statements. The comparisons alternate between <=\n-  //   ...  // and < to handle round-to-even properly.\n-  //   } else if (f16_abs_bits < halfway_points[7])  {\n-  //     f8_bits = 7;\n-  //   }\n-  for (int i = arr_sz - 1; i >= 0; i--) {\n-    Value* comparison;\n-    llvm::Constant* half_way_point = ix_const(halfway_points[i]);\n-\n-    if (i % 2 == 0) {\n-      comparison = b->CreateICmpULE(fx_abs_bits, half_way_point);\n-    } else {\n-      comparison = b->CreateICmpULT(fx_abs_bits, half_way_point);\n-    }\n-\n-    f8_bits = b->CreateSelect(comparison, i8_const(i), f8_bits);\n-  }\n-\n-  return f8_bits;\n-}\n+llvm::Value* HandleHalfwayPointsFxToF8(\n+    PrimitiveType fx_type, int f8_exponent_bits, int f8_mantissa_bits,\n+    int f8_bias, llvm::Value* fx_abs_bits, llvm::Value* f8_bits,\n+    std::optional<size_t> vector_width, llvm::IRBuilderBase* b);\n \n }  // namespace llvm_ir\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 1289,
        "additions": 768,
        "deletions": 521
    }
}