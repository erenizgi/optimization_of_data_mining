{
    "author": "tensorflower-gardener",
    "message": "Integrate LLVM at llvm/llvm-project@4c46ae394841\n\nUpdates LLVM usage to match\n[4c46ae394841](https://github.com/llvm/llvm-project/commit/4c46ae394841)\n\nPiperOrigin-RevId: 826082725",
    "sha": "f2b36d17805e2e24ea0616bb0e325b5023d5c1c7",
    "files": [
        {
            "sha": "4117b0acfaca4c8008258a732d84281be4a192fa",
            "filename": "third_party/xla/third_party/llvm/generated.patch",
            "status": "modified",
            "additions": 575,
            "deletions": 11,
            "changes": 586,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fgenerated.patch?ref=f2b36d17805e2e24ea0616bb0e325b5023d5c1c7",
            "patch": "@@ -1,12 +1,576 @@\n Auto generated patch. Do not edit or delete it, even if empty.\n-diff -ruN --strip-trailing-cr a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n---- a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n-+++ b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n-@@ -18,7 +18,6 @@\n- #include \"mlir/IR/Operation.h\"\n- #include \"llvm/ADT/PointerUnion.h\"\n- #include \"llvm/ADT/STLExtras.h\"\n--#include \"llvm/Support/DebugLog.h\"\n- #include \"llvm/Support/raw_ostream.h\"\n- \n- namespace mlir {\n+diff -ruN --strip-trailing-cr a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n+--- a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n++++ b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n+@@ -10,8 +10,8 @@\n+ import subprocess\n+ import signal\n+ import sys\n++import threading\n+ import warnings\n+-import selectors\n+ import time\n+ from typing import (\n+     Any,\n+@@ -139,6 +139,35 @@\n+         outfile.write(\"\\n\")\n+ \n+ \n++def read_packet(\n++    f: IO[bytes], trace_file: Optional[IO[str]] = None\n++) -> Optional[ProtocolMessage]:\n++    \"\"\"Decode a JSON packet that starts with the content length and is\n++    followed by the JSON bytes from a file 'f'. Returns None on EOF.\n++    \"\"\"\n++    line = f.readline().decode(\"utf-8\")\n++    if len(line) == 0:\n++        return None  # EOF.\n++\n++    # Watch for line that starts with the prefix\n++    prefix = \"Content-Length: \"\n++    if line.startswith(prefix):\n++        # Decode length of JSON bytes\n++        length = int(line[len(prefix) :])\n++        # Skip empty line\n++        separator = f.readline().decode()\n++        if separator != \"\":\n++            Exception(\"malformed DAP content header, unexpected line: \" + separator)\n++        # Read JSON bytes\n++        json_str = f.read(length).decode()\n++        if trace_file:\n++            trace_file.write(\"from adapter:\\n%s\\n\" % (json_str))\n++        # Decode the JSON bytes into a python dictionary\n++        return json.loads(json_str)\n++\n++    raise Exception(\"unexpected malformed message from lldb-dap: \" + line)\n++\n++\n+ def packet_type_is(packet, packet_type):\n+     return \"type\" in packet and packet[\"type\"] == packet_type\n+ \n+@@ -170,8 +199,16 @@\n+         self.log_file = log_file\n+         self.send = send\n+         self.recv = recv\n+-        self.selector = selectors.DefaultSelector()\n+-        self.selector.register(recv, selectors.EVENT_READ)\n++\n++        # Packets that have been received and processed but have not yet been\n++        # requested by a test case.\n++        self._pending_packets: List[Optional[ProtocolMessage]] = []\n++        # Received packets that have not yet been processed.\n++        self._recv_packets: List[Optional[ProtocolMessage]] = []\n++        # Used as a mutex for _recv_packets and for notify when _recv_packets\n++        # changes.\n++        self._recv_condition = threading.Condition()\n++        self._recv_thread = threading.Thread(target=self._read_packet_thread)\n+ \n+         # session state\n+         self.init_commands = init_commands\n+@@ -197,6 +234,9 @@\n+         # keyed by breakpoint id\n+         self.resolved_breakpoints: dict[str, Breakpoint] = {}\n+ \n++        # trigger enqueue thread\n++        self._recv_thread.start()\n++\n+     @classmethod\n+     def encode_content(cls, s: str) -> bytes:\n+         return (\"Content-Length: %u\\r\\n\\r\\n%s\" % (len(s), s)).encode(\"utf-8\")\n+@@ -212,46 +252,17 @@\n+                 f\"seq mismatch in response {command['seq']} != {response['request_seq']}\"\n+             )\n+ \n+-    def _read_packet(\n+-        self,\n+-        timeout: float = DEFAULT_TIMEOUT,\n+-    ) -> Optional[ProtocolMessage]:\n+-        \"\"\"Decode a JSON packet that starts with the content length and is\n+-        followed by the JSON bytes from self.recv. Returns None on EOF.\n+-        \"\"\"\n+-\n+-        ready = self.selector.select(timeout)\n+-        if not ready:\n+-            warnings.warn(\n+-                \"timeout occurred waiting for a packet, check if the test has a\"\n+-                \" negative assertion and see if it can be inverted.\",\n+-                stacklevel=4,\n+-            )\n+-            return None  # timeout\n+-\n+-        line = self.recv.readline().decode(\"utf-8\")\n+-        if len(line) == 0:\n+-            return None  # EOF.\n+-\n+-        # Watch for line that starts with the prefix\n+-        prefix = \"Content-Length: \"\n+-        if line.startswith(prefix):\n+-            # Decode length of JSON bytes\n+-            length = int(line[len(prefix) :])\n+-            # Skip empty line\n+-            separator = self.recv.readline().decode()\n+-            if separator != \"\":\n+-                Exception(\"malformed DAP content header, unexpected line: \" + separator)\n+-            # Read JSON bytes\n+-            json_str = self.recv.read(length).decode()\n+-            if self.trace_file:\n+-                self.trace_file.write(\n+-                    \"%s from adapter:\\n%s\\n\" % (time.time(), json_str)\n+-                )\n+-            # Decode the JSON bytes into a python dictionary\n+-            return json.loads(json_str)\n+-\n+-        raise Exception(\"unexpected malformed message from lldb-dap: \" + line)\n++    def _read_packet_thread(self):\n++        try:\n++            while True:\n++                packet = read_packet(self.recv, trace_file=self.trace_file)\n++                # `packet` will be `None` on EOF. We want to pass it down to\n++                # handle_recv_packet anyway so the main thread can handle unexpected\n++                # termination of lldb-dap and stop waiting for new packets.\n++                if not self._handle_recv_packet(packet):\n++                    break\n++        finally:\n++            dump_dap_log(self.log_file)\n+ \n+     def get_modules(\n+         self, start_module: Optional[int] = None, module_count: Optional[int] = None\n+@@ -299,6 +310,34 @@\n+             output += self.get_output(category, clear=clear)\n+         return output\n+ \n++    def _enqueue_recv_packet(self, packet: Optional[ProtocolMessage]):\n++        with self.recv_condition:\n++            self.recv_packets.append(packet)\n++            self.recv_condition.notify()\n++\n++    def _handle_recv_packet(self, packet: Optional[ProtocolMessage]) -> bool:\n++        \"\"\"Handles an incoming packet.\n++\n++        Called by the read thread that is waiting for all incoming packets\n++        to store the incoming packet in \"self._recv_packets\" in a thread safe\n++        way. This function will then signal the \"self._recv_condition\" to\n++        indicate a new packet is available.\n++\n++        Args:\n++            packet: A new packet to store.\n++\n++        Returns:\n++            True if the caller should keep calling this function for more\n++            packets.\n++        \"\"\"\n++        with self._recv_condition:\n++            self._recv_packets.append(packet)\n++            self._recv_condition.notify()\n++            # packet is None on EOF\n++            return packet is not None and not (\n++                packet[\"type\"] == \"response\" and packet[\"command\"] == \"disconnect\"\n++            )\n++\n+     def _recv_packet(\n+         self,\n+         *,\n+@@ -322,34 +361,46 @@\n+             The first matching packet for the given predicate, if specified,\n+             otherwise None.\n+         \"\"\"\n+-        deadline = time.time() + timeout\n+-\n+-        while time.time() < deadline:\n+-            packet = self._read_packet(timeout=deadline - time.time())\n+-            if packet is None:\n+-                return None\n+-            self._process_recv_packet(packet)\n+-            if not predicate or predicate(packet):\n+-                return packet\n++        assert (\n++            threading.current_thread != self._recv_thread\n++        ), \"Must not be called from the _recv_thread\"\n++\n++        def process_until_match():\n++            self._process_recv_packets()\n++            for i, packet in enumerate(self._pending_packets):\n++                if packet is None:\n++                    # We need to return a truthy value to break out of the\n++                    # wait_for, use `EOFError` as an indicator of EOF.\n++                    return EOFError()\n++                if predicate and predicate(packet):\n++                    self._pending_packets.pop(i)\n++                    return packet\n++\n++        with self._recv_condition:\n++            packet = self._recv_condition.wait_for(process_until_match, timeout)\n++            return None if isinstance(packet, EOFError) else packet\n+ \n+-    def _process_recv_packet(self, packet) -> None:\n++    def _process_recv_packets(self) -> None:\n+         \"\"\"Process received packets, updating the session state.\"\"\"\n+-        if packet and (\"seq\" not in packet or packet[\"seq\"] == 0):\n+-            warnings.warn(\n+-                f\"received a malformed packet, expected 'seq != 0' for {packet!r}\"\n+-            )\n+-        # Handle events that may modify any stateful properties of\n+-        # the DAP session.\n+-        if packet and packet[\"type\"] == \"event\":\n+-            self._handle_event(packet)\n+-        elif packet and packet[\"type\"] == \"request\":\n+-            # Handle reverse requests and keep processing.\n+-            self._handle_reverse_request(packet)\n++        with self._recv_condition:\n++            for packet in self._recv_packets:\n++                if packet and (\"seq\" not in packet or packet[\"seq\"] == 0):\n++                    warnings.warn(\n++                        f\"received a malformed packet, expected 'seq != 0' for {packet!r}\"\n++                    )\n++                # Handle events that may modify any stateful properties of\n++                # the DAP session.\n++                if packet and packet[\"type\"] == \"event\":\n++                    self._handle_event(packet)\n++                elif packet and packet[\"type\"] == \"request\":\n++                    # Handle reverse requests and keep processing.\n++                    self._handle_reverse_request(packet)\n++                # Move the packet to the pending queue.\n++                self._pending_packets.append(packet)\n++            self._recv_packets.clear()\n+ \n+     def _handle_event(self, packet: Event) -> None:\n+         \"\"\"Handle any events that modify debug session state we track.\"\"\"\n+-        self.events.append(packet)\n+-\n+         event = packet[\"event\"]\n+         body: Optional[Dict] = packet.get(\"body\", None)\n+ \n+@@ -402,8 +453,6 @@\n+             self.invalidated_event = packet\n+         elif event == \"memory\":\n+             self.memory_event = packet\n+-        elif event == \"module\":\n+-            self.module_events.append(packet)\n+ \n+     def _handle_reverse_request(self, request: Request) -> None:\n+         if request in self.reverse_requests:\n+@@ -472,14 +521,18 @@\n+ \n+         Returns the seq number of the request.\n+         \"\"\"\n+-        packet[\"seq\"] = self.sequence\n+-        self.sequence += 1\n++        # Set the seq for requests.\n++        if packet[\"type\"] == \"request\":\n++            packet[\"seq\"] = self.sequence\n++            self.sequence += 1\n++        else:\n++            packet[\"seq\"] = 0\n+ \n+         # Encode our command dictionary as a JSON string\n+         json_str = json.dumps(packet, separators=(\",\", \":\"))\n+ \n+         if self.trace_file:\n+-            self.trace_file.write(\"%s to adapter:\\n%s\\n\" % (time.time(), json_str))\n++            self.trace_file.write(\"to adapter:\\n%s\\n\" % (json_str))\n+ \n+         length = len(json_str)\n+         if length > 0:\n+@@ -860,8 +913,6 @@\n+         if restartArguments:\n+             command_dict[\"arguments\"] = restartArguments\n+ \n+-        # Clear state, the process is about to restart...\n+-        self._process_continued(True)\n+         response = self._send_recv(command_dict)\n+         # Caller must still call wait_for_stopped.\n+         return response\n+@@ -1428,10 +1479,8 @@\n+ \n+     def terminate(self):\n+         self.send.close()\n+-        self.recv.close()\n+-        self.selector.close()\n+-        if self.log_file:\n+-            dump_dap_log(self.log_file)\n++        if self._recv_thread.is_alive():\n++            self._recv_thread.join()\n+ \n+     def request_setInstructionBreakpoints(self, memory_reference=[]):\n+         breakpoints = []\n+@@ -1528,7 +1577,6 @@\n+             stdout=subprocess.PIPE,\n+             stderr=sys.stderr,\n+             env=adapter_env,\n+-            bufsize=0,\n+         )\n+ \n+         if connection is None:\n+diff -ruN --strip-trailing-cr a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n+--- a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n++++ b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n+@@ -416,7 +416,7 @@\n+         return self.dap_server.wait_for_stopped()\n+ \n+     def continue_to_breakpoint(self, breakpoint_id: str):\n+-        self.continue_to_breakpoints([breakpoint_id])\n++        self.continue_to_breakpoints((breakpoint_id))\n+ \n+     def continue_to_breakpoints(self, breakpoint_ids):\n+         self.do_continue()\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py b/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n+--- a/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n++++ b/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n+@@ -81,20 +81,24 @@\n+                 breakpoint[\"verified\"], \"expect foo breakpoint to not be verified\"\n+             )\n+ \n++        # Flush the breakpoint events.\n++        self.dap_server.wait_for_breakpoint_events()\n++\n+         # Continue to the breakpoint\n+-        self.continue_to_breakpoint(foo_bp_id)\n+-        self.continue_to_next_stop()  # foo_bp2\n+-        self.continue_to_breakpoint(main_bp_id)\n+-        self.continue_to_exit()\n++        self.continue_to_breakpoints(dap_breakpoint_ids)\n+ \n+-        bp_events = [e for e in self.dap_server.events if e[\"event\"] == \"breakpoint\"]\n++        verified_breakpoint_ids = []\n++        unverified_breakpoint_ids = []\n++        for breakpoint_event in self.dap_server.wait_for_breakpoint_events():\n++            breakpoint = breakpoint_event[\"body\"][\"breakpoint\"]\n++            id = breakpoint[\"id\"]\n++            if breakpoint[\"verified\"]:\n++                verified_breakpoint_ids.append(id)\n++            else:\n++                unverified_breakpoint_ids.append(id)\n+ \n+-        main_bp_events = [\n+-            e for e in bp_events if e[\"body\"][\"breakpoint\"][\"id\"] == main_bp_id\n+-        ]\n+-        foo_bp_events = [\n+-            e for e in bp_events if e[\"body\"][\"breakpoint\"][\"id\"] == foo_bp_id\n+-        ]\n++        self.assertIn(main_bp_id, unverified_breakpoint_ids)\n++        self.assertIn(foo_bp_id, unverified_breakpoint_ids)\n+ \n+-        self.assertTrue(main_bp_events)\n+-        self.assertTrue(foo_bp_events)\n++        self.assertIn(main_bp_id, verified_breakpoint_ids)\n++        self.assertIn(foo_bp_id, verified_breakpoint_ids)\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py b/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n+--- a/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n++++ b/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n+@@ -156,7 +156,6 @@\n+         self.build_and_launch(\n+             program, debuggerRoot=program_parent_dir, initCommands=commands\n+         )\n+-        self.continue_to_exit()\n+         output = self.get_console()\n+         self.assertTrue(output and len(output) > 0, \"expect console output\")\n+         lines = output.splitlines()\n+@@ -172,6 +171,7 @@\n+                     % (program_parent_dir, line[len(prefix) :]),\n+                 )\n+         self.assertTrue(found, \"verified lldb-dap working directory\")\n++        self.continue_to_exit()\n+ \n+     def test_sourcePath(self):\n+         \"\"\"\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py b/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n+--- a/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n++++ b/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n+@@ -64,18 +64,19 @@\n+         self.assertEqual(program, program_module[\"path\"])\n+         self.assertIn(\"addressRange\", program_module)\n+ \n+-        self.continue_to_exit()\n+-\n+         # Collect all the module names we saw as events.\n+         module_new_names = []\n+         module_changed_names = []\n+-        for module_event in self.dap_server.module_events:\n++        module_event = self.dap_server.wait_for_event([\"module\"])\n++        while module_event is not None:\n+             reason = module_event[\"body\"][\"reason\"]\n+             if reason == \"new\":\n+                 module_new_names.append(module_event[\"body\"][\"module\"][\"name\"])\n+             elif reason == \"changed\":\n+                 module_changed_names.append(module_event[\"body\"][\"module\"][\"name\"])\n+ \n++            module_event = self.dap_server.wait_for_event([\"module\"])\n++\n+         # Make sure we got an event for every active module.\n+         self.assertNotEqual(len(module_new_names), 0)\n+         for module in active_modules:\n+@@ -85,6 +86,7 @@\n+         # symbols got added.\n+         self.assertNotEqual(len(module_changed_names), 0)\n+         self.assertIn(program_module[\"name\"], module_changed_names)\n++        self.continue_to_exit()\n+ \n+     @skipIfWindows\n+     def test_modules(self):\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py b/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n+--- a/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n++++ b/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n+@@ -1,58 +1,58 @@\n+-\"\"\"\n+-Test 'module' events for dynamically loaded libraries.\n+-\"\"\"\n+-\n++import dap_server\n+ from lldbsuite.test.decorators import *\n+ from lldbsuite.test.lldbtest import *\n++from lldbsuite.test import lldbutil\n+ import lldbdap_testcase\n++import re\n+ \n+ \n+ class TestDAP_module_event(lldbdap_testcase.DAPTestCaseBase):\n+-    def lookup_module_id(self, name):\n+-        \"\"\"Returns the identifier for the first module event starting with the given name.\"\"\"\n+-        for event in self.dap_server.module_events:\n+-            if self.get_dict_value(event, [\"body\", \"module\", \"name\"]).startswith(name):\n+-                return self.get_dict_value(event, [\"body\", \"module\", \"id\"])\n+-        self.fail(f\"No module events matching name={name}\")\n+-\n+-    def module_events(self, id):\n+-        \"\"\"Finds all module events by identifier.\"\"\"\n+-        return [\n+-            event\n+-            for event in self.dap_server.module_events\n+-            if self.get_dict_value(event, [\"body\", \"module\", \"id\"]) == id\n+-        ]\n+-\n+-    def module_reasons(self, events):\n+-        \"\"\"Returns the list of 'reason' values from the given events.\"\"\"\n+-        return [event[\"body\"][\"reason\"] for event in events]\n+-\n+     @skipIfWindows\n+     def test_module_event(self):\n+-        \"\"\"\n+-        Test that module events are fired on target load and when the list of\n+-        dynamic libraries updates while running.\n+-        \"\"\"\n+         program = self.getBuildArtifact(\"a.out\")\n+         self.build_and_launch(program)\n+-        # We can analyze the order of events after the process exits.\n+-        self.continue_to_exit()\n+ \n+-        a_out_id = self.lookup_module_id(\"a.out\")\n+-        a_out_events = self.module_events(id=a_out_id)\n++        source = \"main.cpp\"\n++        breakpoint1_line = line_number(source, \"// breakpoint 1\")\n++        breakpoint2_line = line_number(source, \"// breakpoint 2\")\n++        breakpoint3_line = line_number(source, \"// breakpoint 3\")\n+ \n+-        self.assertIn(\n+-            \"new\",\n+-            self.module_reasons(a_out_events),\n+-            \"Expected a.out to load during the debug session.\",\n++        breakpoint_ids = self.set_source_breakpoints(\n++            source, [breakpoint1_line, breakpoint2_line, breakpoint3_line]\n+         )\n++        self.continue_to_breakpoints(breakpoint_ids)\n+ \n+-        libother_id = self.lookup_module_id(\n+-            \"libother.\"  # libother.so or libother.dylib based on OS.\n+-        )\n+-        libother_events = self.module_events(id=libother_id)\n+-        self.assertEqual(\n+-            self.module_reasons(libother_events),\n+-            [\"new\", \"removed\"],\n+-            \"Expected libother to be loaded then unloaded during the debug session.\",\n+-        )\n++        # We're now stopped at breakpoint 1 before the dlopen. Flush all the module events.\n++        event = self.dap_server.wait_for_event([\"module\"])\n++        while event is not None:\n++            event = self.dap_server.wait_for_event([\"module\"])\n++\n++        # Continue to the second breakpoint, before the dlclose.\n++        self.continue_to_breakpoints(breakpoint_ids)\n++\n++        # Make sure we got a module event for libother.\n++        event = self.dap_server.wait_for_event([\"module\"])\n++        self.assertIsNotNone(event, \"didn't get a module event\")\n++        module_name = event[\"body\"][\"module\"][\"name\"]\n++        module_id = event[\"body\"][\"module\"][\"id\"]\n++        self.assertEqual(event[\"body\"][\"reason\"], \"new\")\n++        self.assertIn(\"libother\", module_name)\n++\n++        # Continue to the third breakpoint, after the dlclose.\n++        self.continue_to_breakpoints(breakpoint_ids)\n++\n++        # Make sure we got a module event for libother.\n++        event = self.dap_server.wait_for_event([\"module\"])\n++        self.assertIsNotNone(event, \"didn't get a module event\")\n++        reason = event[\"body\"][\"reason\"]\n++        self.assertEqual(reason, \"removed\")\n++        self.assertEqual(event[\"body\"][\"module\"][\"id\"], module_id)\n++\n++        # The removed module event should omit everything but the module id and name\n++        # as they are required fields.\n++        module_data = event[\"body\"][\"module\"]\n++        required_keys = [\"id\", \"name\"]\n++        self.assertListEqual(list(module_data.keys()), required_keys)\n++        self.assertEqual(module_data[\"name\"], \"\", \"expects empty name.\")\n++\n++        self.continue_to_exit()\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py b/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n+--- a/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n++++ b/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n+@@ -30,11 +30,7 @@\n+             if reason == \"entry\":\n+                 seen_stopped_event += 1\n+ \n+-        self.assertEqual(\n+-            seen_stopped_event,\n+-            1,\n+-            f\"expect only one stopped entry event in {stopped_events}\",\n+-        )\n++        self.assertEqual(seen_stopped_event, 1, \"expect only one stopped entry event.\")\n+ \n+     @skipIfAsan\n+     @skipIfWindows\n+@@ -96,13 +92,11 @@\n+         self.build_and_launch(program, console=\"integratedTerminal\", stopOnEntry=True)\n+         [bp_main] = self.set_function_breakpoints([\"main\"])\n+ \n+-        self.dap_server.request_configurationDone()\n+-        stopped_threads = list(self.dap_server.thread_stop_reasons.values())\n++        self.dap_server.request_continue()  # sends configuration done\n++        stopped_events = self.dap_server.wait_for_stopped()\n+         # We should be stopped at the entry point.\n+-        self.assertEqual(\n+-            len(stopped_threads), 1, \"Expected the main thread to be stopped on entry.\"\n+-        )\n+-        self.assertEqual(stopped_threads[0][\"reason\"], \"entry\")\n++        self.assertGreaterEqual(len(stopped_events), 0, \"expect stopped events\")\n++        self.verify_stopped_on_entry(stopped_events)\n+ \n+         # Then, if we continue, we should hit the breakpoint at main.\n+         self.dap_server.request_continue()\n+@@ -111,12 +105,8 @@\n+         # Restart and check that we still get a stopped event before reaching\n+         # main.\n+         self.dap_server.request_restart()\n+-        stopped_threads = list(self.dap_server.thread_stop_reasons.values())\n+-        # We should be stopped at the entry point.\n+-        self.assertEqual(\n+-            len(stopped_threads), 1, \"Expected the main thread to be stopped on entry.\"\n+-        )\n+-        self.assertEqual(stopped_threads[0][\"reason\"], \"entry\")\n++        stopped_events = self.dap_server.wait_for_stopped()\n++        self.verify_stopped_on_entry(stopped_events)\n+ \n+         # continue to main\n+         self.dap_server.request_continue()\n+diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py b/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n+--- a/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n++++ b/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n+@@ -32,7 +32,7 @@\n+             ],\n+         )\n+         self.set_source_breakpoints(source, [breakpoint_line])\n+-        self.do_continue()\n++        self.continue_to_next_stop()\n+ \n+         custom_event = self.dap_server.wait_for_event(\n+             filter=[\"my-custom-event-no-body\"]"
        },
        {
            "sha": "d012c7c7d6a19bc01e8123fce8cdf1c445288822",
            "filename": "third_party/xla/third_party/llvm/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fllvm%2Fworkspace.bzl?ref=f2b36d17805e2e24ea0616bb0e325b5023d5c1c7",
            "patch": "@@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n \n def repo(name):\n     \"\"\"Imports LLVM.\"\"\"\n-    LLVM_COMMIT = \"028bfa255e90581d1c08237a66c20b25096277e8\"\n-    LLVM_SHA256 = \"b1e5fbb1ed51e8e22e1ecdf0d74e7b28b1c554bb507326df2172c0c4707de0f8\"\n+    LLVM_COMMIT = \"4c46ae394841521914e0e8575e7619a1c0d1149d\"\n+    LLVM_SHA256 = \"55c824ce2e1a3afafa4e108532f4eff9f194d20d44d1c5ddc6107bb23d7c6c2a\"\n \n     tf_http_archive(\n         name = name,"
        },
        {
            "sha": "5282fbe4127ab746773b86ddbb67cbae28b83903",
            "filename": "third_party/xla/third_party/shardy/temporary.patch",
            "status": "modified",
            "additions": 593,
            "deletions": 146,
            "changes": 739,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Ftemporary.patch?ref=f2b36d17805e2e24ea0616bb0e325b5023d5c1c7",
            "patch": "@@ -1,160 +1,607 @@\n-diff --git a/docs/sdy_dialect.md b/docs/sdy_dialect.md\n-index 8051d9c..72b3aa5 100755\n---- a/docs/sdy_dialect.md\n-+++ b/docs/sdy_dialect.md\n-@@ -1101,39 +1101,36 @@ Syntax:\n- A mesh is a list of axes and an optional list of device IDs specifying the\n- device ordering.\n- \n--If the list of axes is empty\n--  - If the `device_ids` is not provided, it is an empty mesh.\n--  - If the `device_ids` is provided, it must be a single non-negative\n--    integer, we call it a **maximal-sharding mesh**.\n--\n--If the list of axes is provided\n--  - If a device ID list is specified, the product of the axis sizes should\n--    match the number of devices.\n--  - If a device ID list is not specified, the implicit device ID list is\n--    iota(product(axes)). For simplicity, we also disallow specifying a\n--    device ID list that is the same as iota(product(axes)); in this case, a\n--    device ID list shouldn't be specified.\n--  - It is not a maximal-sharding mesh even if the total size of axes is 1.\n-+If the list of axes is empty, the mesh has an implicit unnamed axis of\n-+size 1. In this case, if a device ID list is not provided, the implicit\n-+device ID list is [0]; if a device ID list is provided, it must\n-+contains a single integer of any non-negative value. We call this\n-+maximal-sharding case.\n-+\n-+For all non-maximal-sharding cases, if a device ID list is specified, the\n-+product of the axis sizes should match the number of devices. If a device ID\n-+list is not specified, the implicit device ID list is iota(product(axes)).\n-+For simplicity, we also disallow specifying a device ID list that is the\n-+same as iota(product(axes)); in this case, a device ID list shouldn't be\n-+specified.\n- \n- Here are some examples of meshes:\n- \n- - An empty mesh represents a placeholder mesh that can be replaced during\n-   propagation: <[]>\n--- A mesh without axes list and a single non-negative device ID, which is a\n--  maximal-sharding mesh: <[], device_ids=[3]>\n-+- A mesh with an unnamed axis and an explicit device ID, which is typically\n-+  used to represent maximal sharding: <[], device_ids=[3]>\n- - A mesh with two axes and implicit device IDs iota(6): <[\"a\"=2, \"b\"=3]>\n- - A mesh with two axes and explicit device IDs specifying the device\n-   ordering: <[\"a\"=3, \"b\"=2], device_ids=[0, 2, 4, 1, 3, 5]>\n- \n- **Constraints:**\n--- Elements in `device_ids` should be non-negative.\n--- If `axes` is empty, the size of `device_ids` can be 0 (empty mesh) or 1\n--  (maximal-sharding mesh).\n--- If `axes` is not empty,\n--    - Elements in `axes` must not have duplicate names.\n--    - If `device_ids` is specified, the original `device_ids` is not\n--      `iota(product(axis_sizes))` and the sorted `device_ids` is\n--      `iota(product(axis_sizes))`.\n-+- Elements in `axes` must not have duplicate names.\n-+- If `device_ids` is specified:\n-+  * The product of axis sizes must match the number of devices.\n-+  * All of its elements must be non-negative.\n-+  * `device_ids` should not be equal to `iota(product(axis_sizes))`.\n-+  * Sorted `device_ids` must be `iota(product(axis_sizes))`.\n- \n- #### Parameters:\n- \n-diff --git a/shardy/dialect/sdy/ir/attrs.td b/shardy/dialect/sdy/ir/attrs.td\n-index cde47d2..5bca49c 100644\n---- a/shardy/dialect/sdy/ir/attrs.td\n-+++ b/shardy/dialect/sdy/ir/attrs.td\n-@@ -54,39 +54,36 @@ def Sdy_Mesh : AttrDef<Sdy_Dialect, \"Mesh\"> {\n-     A mesh is a list of axes and an optional list of device IDs specifying the\n-     device ordering.\n- \n--    If the list of axes is empty\n--      - If the `device_ids` is not provided, it is an empty mesh.\n--      - If the `device_ids` is provided, it must be a single non-negative\n--        integer, we call it a **maximal-sharding mesh**.\n--\n--    If the list of axes is provided\n--      - If a device ID list is specified, the product of the axis sizes should\n--        match the number of devices.\n--      - If a device ID list is not specified, the implicit device ID list is\n--        iota(product(axes)). For simplicity, we also disallow specifying a\n--        device ID list that is the same as iota(product(axes)); in this case, a\n--        device ID list shouldn't be specified.\n--      - It is not a maximal-sharding mesh even if the total size of axes is 1.\n-+    If the list of axes is empty, the mesh has an implicit unnamed axis of\n-+    size 1. In this case, if a device ID list is not provided, the implicit\n-+    device ID list is [0]; if a device ID list is provided, it must\n-+    contains a single integer of any non-negative value. We call this\n-+    maximal-sharding case.\n-+\n-+    For all non-maximal-sharding cases, if a device ID list is specified, the\n-+    product of the axis sizes should match the number of devices. If a device ID\n-+    list is not specified, the implicit device ID list is iota(product(axes)).\n-+    For simplicity, we also disallow specifying a device ID list that is the\n-+    same as iota(product(axes)); in this case, a device ID list shouldn't be\n-+    specified.\n- \n-     Here are some examples of meshes:\n- \n-     - An empty mesh represents a placeholder mesh that can be replaced during\n-       propagation: <[]>\n--    - A mesh without axes list and a single non-negative device ID, which is a\n--      maximal-sharding mesh: <[], device_ids=[3]>\n-+    - A mesh with an unnamed axis and an explicit device ID, which is typically\n-+      used to represent maximal sharding: <[], device_ids=[3]>\n-     - A mesh with two axes and implicit device IDs iota(6): <[\"a\"=2, \"b\"=3]>\n-     - A mesh with two axes and explicit device IDs specifying the device\n-       ordering: <[\"a\"=3, \"b\"=2], device_ids=[0, 2, 4, 1, 3, 5]>\n- \n-     **Constraints:**\n--    - Elements in `device_ids` should be non-negative.\n--    - If `axes` is empty, the size of `device_ids` can be 0 (empty mesh) or 1\n--      (maximal-sharding mesh).\n--    - If `axes` is not empty,\n--        - Elements in `axes` must not have duplicate names.\n--        - If `device_ids` is specified, the original `device_ids` is not\n--          `iota(product(axis_sizes))` and the sorted `device_ids` is\n--          `iota(product(axis_sizes))`.\n-+    - Elements in `axes` must not have duplicate names.\n-+    - If `device_ids` is specified:\n-+      * The product of axis sizes must match the number of devices.\n-+      * All of its elements must be non-negative.\n-+      * `device_ids` should not be equal to `iota(product(axis_sizes))`.\n-+      * Sorted `device_ids` must be `iota(product(axis_sizes))`.\n-   }];\n-   let parameters = (ins\n-       OptionalArrayRefParameter<\"MeshAxisAttr\", \"mesh axes\">:$axes,\n diff --git a/third_party/llvm/generated.patch b/third_party/llvm/generated.patch\n-index 509398d..75d72f7 100644\n+index 75d72f7..4117b0a 100644\n --- a/third_party/llvm/generated.patch\n +++ b/third_party/llvm/generated.patch\n-@@ -1 +1,12 @@\n+@@ -1,12 +1,576 @@\n  Auto generated patch. Do not edit or delete it, even if empty.\n-+diff -ruN --strip-trailing-cr a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n-+--- a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n-++++ b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n-+@@ -18,7 +18,6 @@\n-+ #include \"mlir/IR/Operation.h\"\n-+ #include \"llvm/ADT/PointerUnion.h\"\n-+ #include \"llvm/ADT/STLExtras.h\"\n-+-#include \"llvm/Support/DebugLog.h\"\n-+ #include \"llvm/Support/raw_ostream.h\"\n-+ \n-+ namespace mlir {\n+-diff -ruN --strip-trailing-cr a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+---- a/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+-+++ b/mlir/include/mlir/Interfaces/ControlFlowInterfaces.h\n+-@@ -18,7 +18,6 @@\n+- #include \"mlir/IR/Operation.h\"\n+- #include \"llvm/ADT/PointerUnion.h\"\n+- #include \"llvm/ADT/STLExtras.h\"\n+--#include \"llvm/Support/DebugLog.h\"\n+- #include \"llvm/Support/raw_ostream.h\"\n+- \n+- namespace mlir {\n++diff -ruN --strip-trailing-cr a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n++--- a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n+++++ b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/dap_server.py\n++@@ -10,8 +10,8 @@\n++ import subprocess\n++ import signal\n++ import sys\n+++import threading\n++ import warnings\n++-import selectors\n++ import time\n++ from typing import (\n++     Any,\n++@@ -139,6 +139,35 @@\n++         outfile.write(\"\\n\")\n++ \n++ \n+++def read_packet(\n+++    f: IO[bytes], trace_file: Optional[IO[str]] = None\n+++) -> Optional[ProtocolMessage]:\n+++    \"\"\"Decode a JSON packet that starts with the content length and is\n+++    followed by the JSON bytes from a file 'f'. Returns None on EOF.\n+++    \"\"\"\n+++    line = f.readline().decode(\"utf-8\")\n+++    if len(line) == 0:\n+++        return None  # EOF.\n+++\n+++    # Watch for line that starts with the prefix\n+++    prefix = \"Content-Length: \"\n+++    if line.startswith(prefix):\n+++        # Decode length of JSON bytes\n+++        length = int(line[len(prefix) :])\n+++        # Skip empty line\n+++        separator = f.readline().decode()\n+++        if separator != \"\":\n+++            Exception(\"malformed DAP content header, unexpected line: \" + separator)\n+++        # Read JSON bytes\n+++        json_str = f.read(length).decode()\n+++        if trace_file:\n+++            trace_file.write(\"from adapter:\\n%s\\n\" % (json_str))\n+++        # Decode the JSON bytes into a python dictionary\n+++        return json.loads(json_str)\n+++\n+++    raise Exception(\"unexpected malformed message from lldb-dap: \" + line)\n+++\n+++\n++ def packet_type_is(packet, packet_type):\n++     return \"type\" in packet and packet[\"type\"] == packet_type\n++ \n++@@ -170,8 +199,16 @@\n++         self.log_file = log_file\n++         self.send = send\n++         self.recv = recv\n++-        self.selector = selectors.DefaultSelector()\n++-        self.selector.register(recv, selectors.EVENT_READ)\n+++\n+++        # Packets that have been received and processed but have not yet been\n+++        # requested by a test case.\n+++        self._pending_packets: List[Optional[ProtocolMessage]] = []\n+++        # Received packets that have not yet been processed.\n+++        self._recv_packets: List[Optional[ProtocolMessage]] = []\n+++        # Used as a mutex for _recv_packets and for notify when _recv_packets\n+++        # changes.\n+++        self._recv_condition = threading.Condition()\n+++        self._recv_thread = threading.Thread(target=self._read_packet_thread)\n++ \n++         # session state\n++         self.init_commands = init_commands\n++@@ -197,6 +234,9 @@\n++         # keyed by breakpoint id\n++         self.resolved_breakpoints: dict[str, Breakpoint] = {}\n++ \n+++        # trigger enqueue thread\n+++        self._recv_thread.start()\n+++\n++     @classmethod\n++     def encode_content(cls, s: str) -> bytes:\n++         return (\"Content-Length: %u\\r\\n\\r\\n%s\" % (len(s), s)).encode(\"utf-8\")\n++@@ -212,46 +252,17 @@\n++                 f\"seq mismatch in response {command['seq']} != {response['request_seq']}\"\n++             )\n++ \n++-    def _read_packet(\n++-        self,\n++-        timeout: float = DEFAULT_TIMEOUT,\n++-    ) -> Optional[ProtocolMessage]:\n++-        \"\"\"Decode a JSON packet that starts with the content length and is\n++-        followed by the JSON bytes from self.recv. Returns None on EOF.\n++-        \"\"\"\n++-\n++-        ready = self.selector.select(timeout)\n++-        if not ready:\n++-            warnings.warn(\n++-                \"timeout occurred waiting for a packet, check if the test has a\"\n++-                \" negative assertion and see if it can be inverted.\",\n++-                stacklevel=4,\n++-            )\n++-            return None  # timeout\n++-\n++-        line = self.recv.readline().decode(\"utf-8\")\n++-        if len(line) == 0:\n++-            return None  # EOF.\n++-\n++-        # Watch for line that starts with the prefix\n++-        prefix = \"Content-Length: \"\n++-        if line.startswith(prefix):\n++-            # Decode length of JSON bytes\n++-            length = int(line[len(prefix) :])\n++-            # Skip empty line\n++-            separator = self.recv.readline().decode()\n++-            if separator != \"\":\n++-                Exception(\"malformed DAP content header, unexpected line: \" + separator)\n++-            # Read JSON bytes\n++-            json_str = self.recv.read(length).decode()\n++-            if self.trace_file:\n++-                self.trace_file.write(\n++-                    \"%s from adapter:\\n%s\\n\" % (time.time(), json_str)\n++-                )\n++-            # Decode the JSON bytes into a python dictionary\n++-            return json.loads(json_str)\n++-\n++-        raise Exception(\"unexpected malformed message from lldb-dap: \" + line)\n+++    def _read_packet_thread(self):\n+++        try:\n+++            while True:\n+++                packet = read_packet(self.recv, trace_file=self.trace_file)\n+++                # `packet` will be `None` on EOF. We want to pass it down to\n+++                # handle_recv_packet anyway so the main thread can handle unexpected\n+++                # termination of lldb-dap and stop waiting for new packets.\n+++                if not self._handle_recv_packet(packet):\n+++                    break\n+++        finally:\n+++            dump_dap_log(self.log_file)\n++ \n++     def get_modules(\n++         self, start_module: Optional[int] = None, module_count: Optional[int] = None\n++@@ -299,6 +310,34 @@\n++             output += self.get_output(category, clear=clear)\n++         return output\n++ \n+++    def _enqueue_recv_packet(self, packet: Optional[ProtocolMessage]):\n+++        with self.recv_condition:\n+++            self.recv_packets.append(packet)\n+++            self.recv_condition.notify()\n+++\n+++    def _handle_recv_packet(self, packet: Optional[ProtocolMessage]) -> bool:\n+++        \"\"\"Handles an incoming packet.\n+++\n+++        Called by the read thread that is waiting for all incoming packets\n+++        to store the incoming packet in \"self._recv_packets\" in a thread safe\n+++        way. This function will then signal the \"self._recv_condition\" to\n+++        indicate a new packet is available.\n+++\n+++        Args:\n+++            packet: A new packet to store.\n+++\n+++        Returns:\n+++            True if the caller should keep calling this function for more\n+++            packets.\n+++        \"\"\"\n+++        with self._recv_condition:\n+++            self._recv_packets.append(packet)\n+++            self._recv_condition.notify()\n+++            # packet is None on EOF\n+++            return packet is not None and not (\n+++                packet[\"type\"] == \"response\" and packet[\"command\"] == \"disconnect\"\n+++            )\n+++\n++     def _recv_packet(\n++         self,\n++         *,\n++@@ -322,34 +361,46 @@\n++             The first matching packet for the given predicate, if specified,\n++             otherwise None.\n++         \"\"\"\n++-        deadline = time.time() + timeout\n++-\n++-        while time.time() < deadline:\n++-            packet = self._read_packet(timeout=deadline - time.time())\n++-            if packet is None:\n++-                return None\n++-            self._process_recv_packet(packet)\n++-            if not predicate or predicate(packet):\n++-                return packet\n+++        assert (\n+++            threading.current_thread != self._recv_thread\n+++        ), \"Must not be called from the _recv_thread\"\n+++\n+++        def process_until_match():\n+++            self._process_recv_packets()\n+++            for i, packet in enumerate(self._pending_packets):\n+++                if packet is None:\n+++                    # We need to return a truthy value to break out of the\n+++                    # wait_for, use `EOFError` as an indicator of EOF.\n+++                    return EOFError()\n+++                if predicate and predicate(packet):\n+++                    self._pending_packets.pop(i)\n+++                    return packet\n+++\n+++        with self._recv_condition:\n+++            packet = self._recv_condition.wait_for(process_until_match, timeout)\n+++            return None if isinstance(packet, EOFError) else packet\n++ \n++-    def _process_recv_packet(self, packet) -> None:\n+++    def _process_recv_packets(self) -> None:\n++         \"\"\"Process received packets, updating the session state.\"\"\"\n++-        if packet and (\"seq\" not in packet or packet[\"seq\"] == 0):\n++-            warnings.warn(\n++-                f\"received a malformed packet, expected 'seq != 0' for {packet!r}\"\n++-            )\n++-        # Handle events that may modify any stateful properties of\n++-        # the DAP session.\n++-        if packet and packet[\"type\"] == \"event\":\n++-            self._handle_event(packet)\n++-        elif packet and packet[\"type\"] == \"request\":\n++-            # Handle reverse requests and keep processing.\n++-            self._handle_reverse_request(packet)\n+++        with self._recv_condition:\n+++            for packet in self._recv_packets:\n+++                if packet and (\"seq\" not in packet or packet[\"seq\"] == 0):\n+++                    warnings.warn(\n+++                        f\"received a malformed packet, expected 'seq != 0' for {packet!r}\"\n+++                    )\n+++                # Handle events that may modify any stateful properties of\n+++                # the DAP session.\n+++                if packet and packet[\"type\"] == \"event\":\n+++                    self._handle_event(packet)\n+++                elif packet and packet[\"type\"] == \"request\":\n+++                    # Handle reverse requests and keep processing.\n+++                    self._handle_reverse_request(packet)\n+++                # Move the packet to the pending queue.\n+++                self._pending_packets.append(packet)\n+++            self._recv_packets.clear()\n++ \n++     def _handle_event(self, packet: Event) -> None:\n++         \"\"\"Handle any events that modify debug session state we track.\"\"\"\n++-        self.events.append(packet)\n++-\n++         event = packet[\"event\"]\n++         body: Optional[Dict] = packet.get(\"body\", None)\n++ \n++@@ -402,8 +453,6 @@\n++             self.invalidated_event = packet\n++         elif event == \"memory\":\n++             self.memory_event = packet\n++-        elif event == \"module\":\n++-            self.module_events.append(packet)\n++ \n++     def _handle_reverse_request(self, request: Request) -> None:\n++         if request in self.reverse_requests:\n++@@ -472,14 +521,18 @@\n++ \n++         Returns the seq number of the request.\n++         \"\"\"\n++-        packet[\"seq\"] = self.sequence\n++-        self.sequence += 1\n+++        # Set the seq for requests.\n+++        if packet[\"type\"] == \"request\":\n+++            packet[\"seq\"] = self.sequence\n+++            self.sequence += 1\n+++        else:\n+++            packet[\"seq\"] = 0\n++ \n++         # Encode our command dictionary as a JSON string\n++         json_str = json.dumps(packet, separators=(\",\", \":\"))\n++ \n++         if self.trace_file:\n++-            self.trace_file.write(\"%s to adapter:\\n%s\\n\" % (time.time(), json_str))\n+++            self.trace_file.write(\"to adapter:\\n%s\\n\" % (json_str))\n++ \n++         length = len(json_str)\n++         if length > 0:\n++@@ -860,8 +913,6 @@\n++         if restartArguments:\n++             command_dict[\"arguments\"] = restartArguments\n++ \n++-        # Clear state, the process is about to restart...\n++-        self._process_continued(True)\n++         response = self._send_recv(command_dict)\n++         # Caller must still call wait_for_stopped.\n++         return response\n++@@ -1428,10 +1479,8 @@\n++ \n++     def terminate(self):\n++         self.send.close()\n++-        self.recv.close()\n++-        self.selector.close()\n++-        if self.log_file:\n++-            dump_dap_log(self.log_file)\n+++        if self._recv_thread.is_alive():\n+++            self._recv_thread.join()\n++ \n++     def request_setInstructionBreakpoints(self, memory_reference=[]):\n++         breakpoints = []\n++@@ -1528,7 +1577,6 @@\n++             stdout=subprocess.PIPE,\n++             stderr=sys.stderr,\n++             env=adapter_env,\n++-            bufsize=0,\n++         )\n++ \n++         if connection is None:\n++diff -ruN --strip-trailing-cr a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n++--- a/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n+++++ b/lldb/packages/Python/lldbsuite/test/tools/lldb-dap/lldbdap_testcase.py\n++@@ -416,7 +416,7 @@\n++         return self.dap_server.wait_for_stopped()\n++ \n++     def continue_to_breakpoint(self, breakpoint_id: str):\n++-        self.continue_to_breakpoints([breakpoint_id])\n+++        self.continue_to_breakpoints((breakpoint_id))\n++ \n++     def continue_to_breakpoints(self, breakpoint_ids):\n++         self.do_continue()\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py b/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n++--- a/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n+++++ b/lldb/test/API/tools/lldb-dap/breakpoint-events/TestDAP_breakpointEvents.py\n++@@ -81,20 +81,24 @@\n++                 breakpoint[\"verified\"], \"expect foo breakpoint to not be verified\"\n++             )\n++ \n+++        # Flush the breakpoint events.\n+++        self.dap_server.wait_for_breakpoint_events()\n+++\n++         # Continue to the breakpoint\n++-        self.continue_to_breakpoint(foo_bp_id)\n++-        self.continue_to_next_stop()  # foo_bp2\n++-        self.continue_to_breakpoint(main_bp_id)\n++-        self.continue_to_exit()\n+++        self.continue_to_breakpoints(dap_breakpoint_ids)\n++ \n++-        bp_events = [e for e in self.dap_server.events if e[\"event\"] == \"breakpoint\"]\n+++        verified_breakpoint_ids = []\n+++        unverified_breakpoint_ids = []\n+++        for breakpoint_event in self.dap_server.wait_for_breakpoint_events():\n+++            breakpoint = breakpoint_event[\"body\"][\"breakpoint\"]\n+++            id = breakpoint[\"id\"]\n+++            if breakpoint[\"verified\"]:\n+++                verified_breakpoint_ids.append(id)\n+++            else:\n+++                unverified_breakpoint_ids.append(id)\n++ \n++-        main_bp_events = [\n++-            e for e in bp_events if e[\"body\"][\"breakpoint\"][\"id\"] == main_bp_id\n++-        ]\n++-        foo_bp_events = [\n++-            e for e in bp_events if e[\"body\"][\"breakpoint\"][\"id\"] == foo_bp_id\n++-        ]\n+++        self.assertIn(main_bp_id, unverified_breakpoint_ids)\n+++        self.assertIn(foo_bp_id, unverified_breakpoint_ids)\n++ \n++-        self.assertTrue(main_bp_events)\n++-        self.assertTrue(foo_bp_events)\n+++        self.assertIn(main_bp_id, verified_breakpoint_ids)\n+++        self.assertIn(foo_bp_id, verified_breakpoint_ids)\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py b/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n++--- a/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n+++++ b/lldb/test/API/tools/lldb-dap/launch/TestDAP_launch.py\n++@@ -156,7 +156,6 @@\n++         self.build_and_launch(\n++             program, debuggerRoot=program_parent_dir, initCommands=commands\n++         )\n++-        self.continue_to_exit()\n++         output = self.get_console()\n++         self.assertTrue(output and len(output) > 0, \"expect console output\")\n++         lines = output.splitlines()\n++@@ -172,6 +171,7 @@\n++                     % (program_parent_dir, line[len(prefix) :]),\n++                 )\n++         self.assertTrue(found, \"verified lldb-dap working directory\")\n+++        self.continue_to_exit()\n++ \n++     def test_sourcePath(self):\n++         \"\"\"\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py b/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n++--- a/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n+++++ b/lldb/test/API/tools/lldb-dap/module/TestDAP_module.py\n++@@ -64,18 +64,19 @@\n++         self.assertEqual(program, program_module[\"path\"])\n++         self.assertIn(\"addressRange\", program_module)\n++ \n++-        self.continue_to_exit()\n++-\n++         # Collect all the module names we saw as events.\n++         module_new_names = []\n++         module_changed_names = []\n++-        for module_event in self.dap_server.module_events:\n+++        module_event = self.dap_server.wait_for_event([\"module\"])\n+++        while module_event is not None:\n++             reason = module_event[\"body\"][\"reason\"]\n++             if reason == \"new\":\n++                 module_new_names.append(module_event[\"body\"][\"module\"][\"name\"])\n++             elif reason == \"changed\":\n++                 module_changed_names.append(module_event[\"body\"][\"module\"][\"name\"])\n++ \n+++            module_event = self.dap_server.wait_for_event([\"module\"])\n+++\n++         # Make sure we got an event for every active module.\n++         self.assertNotEqual(len(module_new_names), 0)\n++         for module in active_modules:\n++@@ -85,6 +86,7 @@\n++         # symbols got added.\n++         self.assertNotEqual(len(module_changed_names), 0)\n++         self.assertIn(program_module[\"name\"], module_changed_names)\n+++        self.continue_to_exit()\n++ \n++     @skipIfWindows\n++     def test_modules(self):\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py b/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n++--- a/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n+++++ b/lldb/test/API/tools/lldb-dap/module-event/TestDAP_module_event.py\n++@@ -1,58 +1,58 @@\n++-\"\"\"\n++-Test 'module' events for dynamically loaded libraries.\n++-\"\"\"\n++-\n+++import dap_server\n++ from lldbsuite.test.decorators import *\n++ from lldbsuite.test.lldbtest import *\n+++from lldbsuite.test import lldbutil\n++ import lldbdap_testcase\n+++import re\n++ \n++ \n++ class TestDAP_module_event(lldbdap_testcase.DAPTestCaseBase):\n++-    def lookup_module_id(self, name):\n++-        \"\"\"Returns the identifier for the first module event starting with the given name.\"\"\"\n++-        for event in self.dap_server.module_events:\n++-            if self.get_dict_value(event, [\"body\", \"module\", \"name\"]).startswith(name):\n++-                return self.get_dict_value(event, [\"body\", \"module\", \"id\"])\n++-        self.fail(f\"No module events matching name={name}\")\n++-\n++-    def module_events(self, id):\n++-        \"\"\"Finds all module events by identifier.\"\"\"\n++-        return [\n++-            event\n++-            for event in self.dap_server.module_events\n++-            if self.get_dict_value(event, [\"body\", \"module\", \"id\"]) == id\n++-        ]\n++-\n++-    def module_reasons(self, events):\n++-        \"\"\"Returns the list of 'reason' values from the given events.\"\"\"\n++-        return [event[\"body\"][\"reason\"] for event in events]\n++-\n++     @skipIfWindows\n++     def test_module_event(self):\n++-        \"\"\"\n++-        Test that module events are fired on target load and when the list of\n++-        dynamic libraries updates while running.\n++-        \"\"\"\n++         program = self.getBuildArtifact(\"a.out\")\n++         self.build_and_launch(program)\n++-        # We can analyze the order of events after the process exits.\n++-        self.continue_to_exit()\n++ \n++-        a_out_id = self.lookup_module_id(\"a.out\")\n++-        a_out_events = self.module_events(id=a_out_id)\n+++        source = \"main.cpp\"\n+++        breakpoint1_line = line_number(source, \"// breakpoint 1\")\n+++        breakpoint2_line = line_number(source, \"// breakpoint 2\")\n+++        breakpoint3_line = line_number(source, \"// breakpoint 3\")\n++ \n++-        self.assertIn(\n++-            \"new\",\n++-            self.module_reasons(a_out_events),\n++-            \"Expected a.out to load during the debug session.\",\n+++        breakpoint_ids = self.set_source_breakpoints(\n+++            source, [breakpoint1_line, breakpoint2_line, breakpoint3_line]\n++         )\n+++        self.continue_to_breakpoints(breakpoint_ids)\n++ \n++-        libother_id = self.lookup_module_id(\n++-            \"libother.\"  # libother.so or libother.dylib based on OS.\n++-        )\n++-        libother_events = self.module_events(id=libother_id)\n++-        self.assertEqual(\n++-            self.module_reasons(libother_events),\n++-            [\"new\", \"removed\"],\n++-            \"Expected libother to be loaded then unloaded during the debug session.\",\n++-        )\n+++        # We're now stopped at breakpoint 1 before the dlopen. Flush all the module events.\n+++        event = self.dap_server.wait_for_event([\"module\"])\n+++        while event is not None:\n+++            event = self.dap_server.wait_for_event([\"module\"])\n+++\n+++        # Continue to the second breakpoint, before the dlclose.\n+++        self.continue_to_breakpoints(breakpoint_ids)\n+++\n+++        # Make sure we got a module event for libother.\n+++        event = self.dap_server.wait_for_event([\"module\"])\n+++        self.assertIsNotNone(event, \"didn't get a module event\")\n+++        module_name = event[\"body\"][\"module\"][\"name\"]\n+++        module_id = event[\"body\"][\"module\"][\"id\"]\n+++        self.assertEqual(event[\"body\"][\"reason\"], \"new\")\n+++        self.assertIn(\"libother\", module_name)\n+++\n+++        # Continue to the third breakpoint, after the dlclose.\n+++        self.continue_to_breakpoints(breakpoint_ids)\n+++\n+++        # Make sure we got a module event for libother.\n+++        event = self.dap_server.wait_for_event([\"module\"])\n+++        self.assertIsNotNone(event, \"didn't get a module event\")\n+++        reason = event[\"body\"][\"reason\"]\n+++        self.assertEqual(reason, \"removed\")\n+++        self.assertEqual(event[\"body\"][\"module\"][\"id\"], module_id)\n+++\n+++        # The removed module event should omit everything but the module id and name\n+++        # as they are required fields.\n+++        module_data = event[\"body\"][\"module\"]\n+++        required_keys = [\"id\", \"name\"]\n+++        self.assertListEqual(list(module_data.keys()), required_keys)\n+++        self.assertEqual(module_data[\"name\"], \"\", \"expects empty name.\")\n+++\n+++        self.continue_to_exit()\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py b/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n++--- a/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n+++++ b/lldb/test/API/tools/lldb-dap/restart/TestDAP_restart_console.py\n++@@ -30,11 +30,7 @@\n++             if reason == \"entry\":\n++                 seen_stopped_event += 1\n++ \n++-        self.assertEqual(\n++-            seen_stopped_event,\n++-            1,\n++-            f\"expect only one stopped entry event in {stopped_events}\",\n++-        )\n+++        self.assertEqual(seen_stopped_event, 1, \"expect only one stopped entry event.\")\n++ \n++     @skipIfAsan\n++     @skipIfWindows\n++@@ -96,13 +92,11 @@\n++         self.build_and_launch(program, console=\"integratedTerminal\", stopOnEntry=True)\n++         [bp_main] = self.set_function_breakpoints([\"main\"])\n++ \n++-        self.dap_server.request_configurationDone()\n++-        stopped_threads = list(self.dap_server.thread_stop_reasons.values())\n+++        self.dap_server.request_continue()  # sends configuration done\n+++        stopped_events = self.dap_server.wait_for_stopped()\n++         # We should be stopped at the entry point.\n++-        self.assertEqual(\n++-            len(stopped_threads), 1, \"Expected the main thread to be stopped on entry.\"\n++-        )\n++-        self.assertEqual(stopped_threads[0][\"reason\"], \"entry\")\n+++        self.assertGreaterEqual(len(stopped_events), 0, \"expect stopped events\")\n+++        self.verify_stopped_on_entry(stopped_events)\n++ \n++         # Then, if we continue, we should hit the breakpoint at main.\n++         self.dap_server.request_continue()\n++@@ -111,12 +105,8 @@\n++         # Restart and check that we still get a stopped event before reaching\n++         # main.\n++         self.dap_server.request_restart()\n++-        stopped_threads = list(self.dap_server.thread_stop_reasons.values())\n++-        # We should be stopped at the entry point.\n++-        self.assertEqual(\n++-            len(stopped_threads), 1, \"Expected the main thread to be stopped on entry.\"\n++-        )\n++-        self.assertEqual(stopped_threads[0][\"reason\"], \"entry\")\n+++        stopped_events = self.dap_server.wait_for_stopped()\n+++        self.verify_stopped_on_entry(stopped_events)\n++ \n++         # continue to main\n++         self.dap_server.request_continue()\n++diff -ruN --strip-trailing-cr a/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py b/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n++--- a/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n+++++ b/lldb/test/API/tools/lldb-dap/send-event/TestDAP_sendEvent.py\n++@@ -32,7 +32,7 @@\n++             ],\n++         )\n++         self.set_source_breakpoints(source, [breakpoint_line])\n++-        self.do_continue()\n+++        self.continue_to_next_stop()\n++ \n++         custom_event = self.dap_server.wait_for_event(\n++             filter=[\"my-custom-event-no-body\"]\n diff --git a/third_party/llvm/workspace.bzl b/third_party/llvm/workspace.bzl\n-index 35aaef5..655dc54 100644\n+index 655dc54..d012c7c 100644\n --- a/third_party/llvm/workspace.bzl\n +++ b/third_party/llvm/workspace.bzl\n @@ -4,8 +4,8 @@ load(\"//third_party:repo.bzl\", \"tf_http_archive\")\n  \n  def repo(name):\n      \"\"\"Imports LLVM.\"\"\"\n--    LLVM_COMMIT = \"29c830cbf8c65fcab7f96f92c8466cbcc9924dd1\"\n--    LLVM_SHA256 = \"a717cad48a81fcc96b310e5bd953a20c8c569a08e2a95594206bd8900a1df32d\"\n-+    LLVM_COMMIT = \"028bfa255e90581d1c08237a66c20b25096277e8\"\n-+    LLVM_SHA256 = \"b1e5fbb1ed51e8e22e1ecdf0d74e7b28b1c554bb507326df2172c0c4707de0f8\"\n+-    LLVM_COMMIT = \"028bfa255e90581d1c08237a66c20b25096277e8\"\n+-    LLVM_SHA256 = \"b1e5fbb1ed51e8e22e1ecdf0d74e7b28b1c554bb507326df2172c0c4707de0f8\"\n++    LLVM_COMMIT = \"4c46ae394841521914e0e8575e7619a1c0d1149d\"\n++    LLVM_SHA256 = \"55c824ce2e1a3afafa4e108532f4eff9f194d20d44d1c5ddc6107bb23d7c6c2a\"\n  \n      tf_http_archive(\n          name = name,"
        },
        {
            "sha": "e15c9891e51fabb999d2506bc8dd4e14b61659a6",
            "filename": "third_party/xla/third_party/shardy/workspace.bzl",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f2b36d17805e2e24ea0616bb0e325b5023d5c1c7/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fshardy%2Fworkspace.bzl?ref=f2b36d17805e2e24ea0616bb0e325b5023d5c1c7",
            "patch": "@@ -3,8 +3,8 @@\n load(\"//third_party:repo.bzl\", \"tf_http_archive\", \"tf_mirror_urls\")\n \n def repo():\n-    SHARDY_COMMIT = \"87e67beaafc4acde7f684d11ed813419597e7fc4\"\n-    SHARDY_SHA256 = \"76093dba30c6b21aeee349bfc6c6a3118cc35d31c46d7f38dcabaa3ae13f562e\"\n+    SHARDY_COMMIT = \"38c7fc678b8f647a484fc2772f7e5ee1aca29c1e\"\n+    SHARDY_SHA256 = \"f0afb19e3b1b0677736b806790a519c3b272b22361a2f7c872f11ce0930bb6be\"\n \n     tf_http_archive(\n         name = \"shardy\","
        }
    ],
    "stats": {
        "total": 1333,
        "additions": 1172,
        "deletions": 161
    }
}