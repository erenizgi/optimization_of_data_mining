{
    "author": "chunnienc",
    "message": "Add reshape when fusing FC-Add and Add is changing shape of FC\n\nPiperOrigin-RevId: 797051434",
    "sha": "52fcd9ec0a16caecabd999887074245828bb6e0b",
    "files": [
        {
            "sha": "b6cfb31a961327ce7253054f44e6ef6b3095889a",
            "filename": "tensorflow/compiler/mlir/lite/tests/optimize.mlir",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52fcd9ec0a16caecabd999887074245828bb6e0b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52fcd9ec0a16caecabd999887074245828bb6e0b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Foptimize.mlir?ref=52fcd9ec0a16caecabd999887074245828bb6e0b",
            "patch": "@@ -4915,3 +4915,16 @@ func.func @BMMLHSConstnat(%arg0: tensor<1x3xf32>) -> tensor<2x3xf32> {\n   // CHECK: %1 = \"tfl.transpose\"(%0, %cst) : (tensor<3x2xf32>, tensor<2xi32>) -> tensor<2x3xf32>\n   // CHECK: return %1 : tensor<2x3xf32>\n }\n+\n+// CHECK-LABEL: @FCAddToFCWithBiasAndReshape\n+func.func public @FCAddToFCWithBiasAndReshape(%arg0: tensor<1x10xf32>) -> tensor<1x1x5xf32> {\n+  %cst = arith.constant dense<1.000000e+00> : tensor<1x1x5xf32>\n+  %cst_0 = arith.constant dense<0.000000e+00> : tensor<5x10xf32>\n+  %0 = \"tfl.no_value\"() {value} : () -> none\n+  %1 = \"tfl.fully_connected\"(%arg0, %cst_0, %0) <{asymmetric_quantize_inputs = false, fused_activation_function = \"NONE\", keep_num_dims = true, weights_format = \"DEFAULT\"}> : (tensor<1x10xf32>, tensor<5x10xf32>, none) -> tensor<1x5xf32>\n+  %2 = tfl.add(%1, %cst) <{fused_activation_function = \"NONE\"}> : (tensor<1x5xf32>, tensor<1x1x5xf32>) -> tensor<1x1x5xf32>\n+  return %2 : tensor<1x1x5xf32>\n+\n+  // CHECK: %0 = \"tfl.fully_connected\"(%arg0, %cst_0, %cst_1) <{asymmetric_quantize_inputs = false, fused_activation_function = \"NONE\", keep_num_dims = true, weights_format = \"DEFAULT\"}> : (tensor<1x10xf32>, tensor<5x10xf32>, tensor<5xf32>) -> tensor<1x5xf32>\n+  // CHECK: %1 = \"tfl.reshape\"(%0, %cst) : (tensor<1x5xf32>, tensor<3xi32>) -> tensor<1x1x5xf32>\n+}"
        },
        {
            "sha": "a072767b3f8ee81f8cdee74ac55029e84abba7bb",
            "filename": "tensorflow/compiler/mlir/lite/transforms/optimize_pass.cc",
            "status": "modified",
            "additions": 105,
            "deletions": 79,
            "changes": 184,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/52fcd9ec0a16caecabd999887074245828bb6e0b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/52fcd9ec0a16caecabd999887074245828bb6e0b/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Foptimize_pass.cc?ref=52fcd9ec0a16caecabd999887074245828bb6e0b",
            "patch": "@@ -413,7 +413,7 @@ bool CanOptimizeIdentityGatherNdOrScatterNdOp(Value params,\n \n   // Checks the value in `indices` is from 0 to n-1.\n   int cur_value = 0;\n-  for (const auto &v : indices.getValues<APInt>()) {\n+  for (const auto& v : indices.getValues<APInt>()) {\n     if (v.getSExtValue() != cur_value) return false;\n     ++cur_value;\n   }\n@@ -469,7 +469,7 @@ bool CanOptimizeIdentitySliceOp(Value input, Attribute begin, Attribute size) {\n // the element type of the returned constant to the same of the `base` argument.\n // This is used when fusing an Add or a Sub into the bias parameter of a\n // convolution.\n-Value GetBiasMultiplier(OpBuilder &builder, Value binary_op,\n+Value GetBiasMultiplier(OpBuilder& builder, Value binary_op,\n                         DenseFPElementsAttr base) {\n   Type element_type = base.getType().getElementType();\n \n@@ -527,8 +527,8 @@ TypeAttr RescaleQtype(Type input, Attribute factor) {\n // Returns `true` if reducing `axes` in `input` with `keep_dims=true` results\n // in the specified `shape` and `false` otherwise.\n static bool ShapeMatchesReduceWithKeepAxes(Value input,\n-                                           const mlir::Attribute &axes,\n-                                           const mlir::Attribute &shape) {\n+                                           const mlir::Attribute& axes,\n+                                           const mlir::Attribute& shape) {\n   RankedTensorType type =\n       mlir::dyn_cast_or_null<RankedTensorType>(input.getType());\n   if (!type) return false;\n@@ -559,7 +559,7 @@ static bool ShapeMatchesReduceWithKeepAxes(Value input,\n \n // Returns `true` if all the `axes` dimensions of `input` are 1.\n static bool AreInputDimensionsOneInAxes(Value input,\n-                                        const mlir::Attribute &axes) {\n+                                        const mlir::Attribute& axes) {\n   RankedTensorType input_type =\n       mlir::dyn_cast_or_null<RankedTensorType>(input.getType());\n   if (!input_type) return false;\n@@ -586,14 +586,14 @@ static bool AreInputDimensionsOneInAxes(Value input,\n   return true;\n }\n \n-static bool FloatValueEquals(const Attribute &attr, double value) {\n+static bool FloatValueEquals(const Attribute& attr, double value) {\n   auto fp_attr = mlir::dyn_cast_or_null<DenseFPElementsAttr>(attr);\n   if (!fp_attr) return false;\n \n   if (fp_attr.isSplat()) {\n     return fp_attr.getSplatValue<APFloat>().isExactlyValue(value);\n   }\n-  return llvm::all_of(fp_attr.getValues<APFloat>(), [value](const APFloat &f) {\n+  return llvm::all_of(fp_attr.getValues<APFloat>(), [value](const APFloat& f) {\n     return f.isExactlyValue(value);\n   });\n }\n@@ -614,7 +614,7 @@ bool IsConstantValueOf(mlir::TypedAttr value, T raw_value) {\n       return int_attr.getSplatValue<APInt>() == raw_value;\n     }\n     return llvm::all_of(int_attr.getValues<APInt>(),\n-                        [raw_value](const APInt &f) { return f == raw_value; });\n+                        [raw_value](const APInt& f) { return f == raw_value; });\n   }\n \n   return false;\n@@ -640,7 +640,7 @@ TypedAttr GetNumElementsOrOne(Type type) {\n }\n \n // Reshapes value to a given shape.\n-Value ReshapeValueDroppingLastDim(OpBuilder &builder, Value value) {\n+Value ReshapeValueDroppingLastDim(OpBuilder& builder, Value value) {\n   // This function is always guarded with\n   // HasTrivialShapeExceptSecondLastDim(), so we could cast safely here.\n   auto type = mlir::cast<ShapedType>(value.getType());\n@@ -679,8 +679,8 @@ bool HasOneUseOrUsedByOnlyBinaryOps(Value out_value) {\n     return true;\n   }\n \n-  for (auto &use : out_value.getUses()) {\n-    mlir::Operation *owner = use.getOwner();\n+  for (auto& use : out_value.getUses()) {\n+    mlir::Operation* owner = use.getOwner();\n     if (!llvm::isa<mlir::TFL::AddOp>(owner) &&\n         !llvm::isa<mlir::TFL::SubOp>(owner) &&\n         !llvm::isa<mlir::TFL::DivOp>(owner) &&\n@@ -722,7 +722,7 @@ bool IsOneHotIndexAttribute(Attribute attr) {\n   return true;\n }\n \n-Value Get1DShapeValue(OpBuilder &builder, Value value) {\n+Value Get1DShapeValue(OpBuilder& builder, Value value) {\n   auto type = mlir::cast<ShapedType>(value.getType());\n   if (!type.hasStaticShape()) {\n     return nullptr;\n@@ -749,7 +749,7 @@ Type GetEmbeddingLookupShape(Value lookup, Value value) {\n }\n \n // Creates FullyConnected op from params and returns the output.\n-mlir::Value GetFcOutput(OpBuilder *builder,\n+mlir::Value GetFcOutput(OpBuilder* builder,\n                         ::mlir::Operation::result_range result, Value input,\n                         Value filter, Value bias,\n                         StringAttr fused_activation_function,\n@@ -817,7 +817,7 @@ bool IsPermutationNCHW(Value perm) {\n   if (!matchPattern(perm, m_Constant(&perm_const))) return false;\n \n   SmallVector<int64_t, 4> axes;\n-  for (const auto &axis_int : perm_const.getValues<APInt>()) {\n+  for (const auto& axis_int : perm_const.getValues<APInt>()) {\n     axes.push_back(axis_int.getSExtValue());\n   }\n \n@@ -878,7 +878,7 @@ struct SqueezeReshapesAroundBroadcastOp\n   using OpRewritePattern<TFL::BroadcastToOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::BroadcastToOp tfl_broadcast_to_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto loc = tfl_broadcast_to_op->getLoc();\n \n     // Match the\n@@ -983,7 +983,7 @@ struct FuseAddAndStridedSlice : public OpRewritePattern<TFL::StridedSliceOp> {\n   using OpRewritePattern<TFL::StridedSliceOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::StridedSliceOp strided_slice_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // Match Add\n     mlir::TFL::AddOp add_op =\n         dyn_cast_or_null<TFL::AddOp>(strided_slice_op.getEnd().getDefiningOp());\n@@ -1071,7 +1071,7 @@ struct Convert2DUpscalingToResizeNearestNeighor\n   //\n   // Note the current pattern matching logic only handles when width == height.\n   LogicalResult matchAndRewrite(TFL::GatherNdOp gather_nd_first,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto result_value = gather_nd_first.getResult();\n     auto params_value = gather_nd_first.getParams();\n     auto indices_value = gather_nd_first.getIndices();\n@@ -1118,15 +1118,15 @@ struct Convert2DUpscalingToResizeNearestNeighor\n     if (!matchPattern(gather_nd_first.getIndices(), m_Constant(&indices)))\n       return failure();\n     int i = 0;\n-    for (const auto &axis_int : indices.getValues<APInt>()) {\n+    for (const auto& axis_int : indices.getValues<APInt>()) {\n       const int64_t axis = axis_int.getSExtValue();\n       if (axis != i / 2) return failure();\n       ++i;\n     }\n     if (!matchPattern(gather_nd_second.getIndices(), m_Constant(&indices)))\n       return failure();\n     i = 0;\n-    for (const auto &axis_int : indices.getValues<APInt>()) {\n+    for (const auto& axis_int : indices.getValues<APInt>()) {\n       const int64_t axis = axis_int.getSExtValue();\n       if (axis != i / 2) return failure();\n       ++i;\n@@ -1137,7 +1137,7 @@ struct Convert2DUpscalingToResizeNearestNeighor\n     if (!matchPattern(transpose_first.getPerm(), m_Constant(&perm)))\n       return failure();\n     SmallVector<int64_t, 4> axes;\n-    for (const auto &axis_int : perm.getValues<APInt>()) {\n+    for (const auto& axis_int : perm.getValues<APInt>()) {\n       axes.push_back(axis_int.getSExtValue());\n     }\n     if (axes != SmallVector<int64_t>({2, 1, 0, 3})) return failure();\n@@ -1146,7 +1146,7 @@ struct Convert2DUpscalingToResizeNearestNeighor\n     if (!matchPattern(transpose_second.getPerm(), m_Constant(&perm)))\n       return failure();\n     axes.clear();\n-    for (const auto &axis_int : perm.getValues<APInt>()) {\n+    for (const auto& axis_int : perm.getValues<APInt>()) {\n       axes.push_back(axis_int.getSExtValue());\n     }\n     if (axes != SmallVector<int64_t>({1, 2, 0, 3})) return failure();\n@@ -1189,7 +1189,7 @@ struct Convert2DUpscalingToResizeNearestNeighor\n // This is possible if `value` is already a 1D tensor of the correct size, or\n // if it is a constant that is either a scalar or has a shape that is\n // broadcastable to a 1D tensor of the correct size (e.g. [1, 1, C]).\n-static std::optional<Value> GetAs1DValue(PatternRewriter &rewriter, Value value,\n+static std::optional<Value> GetAs1DValue(PatternRewriter& rewriter, Value value,\n                                          int64_t num_channels) {\n   auto type = mlir::dyn_cast<RankedTensorType>(value.getType());\n   if (!type) return std::nullopt;\n@@ -1225,7 +1225,7 @@ static std::optional<Value> GetAs1DValue(PatternRewriter &rewriter, Value value,\n // If `bias` is a `NoneType`, a 1D tensor of zeros is created.\n // Otherwise, it uses `GetAs1DValue` to handle scalar constants and other\n // broadcastable shapes.\n-static std::optional<Value> GetBiasIn1D(PatternRewriter &rewriter, Value bias,\n+static std::optional<Value> GetBiasIn1D(PatternRewriter& rewriter, Value bias,\n                                         int num_channels,\n                                         Type filter_element_type) {\n   // If it's none, create a zero tensor with shape {num_channels}.\n@@ -1260,7 +1260,7 @@ static RankedTensorType GetRankedTensorType(Value value) {\n \n   // The filter may be unranked after quantization. In that case, we\n   // recursively look for the ranked tensor type.\n-  Operation *op = value.getDefiningOp();\n+  Operation* op = value.getDefiningOp();\n   while (op != nullptr && op->getNumOperands() > 0) {\n     filter_type = mlir::dyn_cast<RankedTensorType>(op->getOperand(0).getType());\n     if (filter_type) return filter_type;\n@@ -1307,7 +1307,7 @@ struct FuseFullyConnectedAndAdd : public OpRewritePattern<TFL::AddOp> {\n   using OpRewritePattern<TFL::AddOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::AddOp add_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // Match Add.\n     DenseElementsAttr added_value;\n     Value add_rhs = add_op.getRhs();\n@@ -1349,7 +1349,7 @@ struct FuseFullyConnectedAndAdd : public OpRewritePattern<TFL::AddOp> {\n     if (!fc_info) {\n       return failure();\n     }\n-    const auto &[num_channels, filter_element_type] = *fc_info;\n+    const auto& [num_channels, filter_element_type] = *fc_info;\n \n     auto bias_1d =\n         GetBiasIn1D(rewriter, bias, num_channels, filter_element_type);\n@@ -1360,24 +1360,50 @@ struct FuseFullyConnectedAndAdd : public OpRewritePattern<TFL::AddOp> {\n       return failure();\n     }\n \n+    auto fc_output_type =\n+        mlir::dyn_cast<RankedTensorType>(fc_op.getOutput()[0].getType());\n+    auto add_output_type =\n+        mlir::dyn_cast<RankedTensorType>(add_op.getOutput().getType());\n+    if (!fc_output_type || !add_output_type ||\n+        (fc_output_type.getShape() != add_output_type.getShape() &&\n+         !add_output_type.hasStaticShape())) {\n+      // The Add op changes the output shape of the FC op, and the bias has\n+      // dynamic shape. In this case we cannot create the following ReshapeOp to\n+      // ensure output shapes after rewrite match.\n+      return failure();\n+    }\n+\n     auto new_bias =\n         rewriter\n             .create<AddOp>(add_op.getLoc(), bias_1d.value(), add_rhs_1d.value(),\n                            rewriter.getStringAttr(\"NONE\"))\n             .getOutput();\n-    auto fc = rewriter.create<TFL::FullyConnectedOp>(\n-        FusedLoc::get(fc_op.getContext(), {fc_op.getLoc(), add_op.getLoc()}),\n-        add_op.getType(),\n-        /*input=*/fc_op.getInput(),\n-        /*filter=*/filter,\n-        /*bias=*/new_bias,\n-        /*fused_activation_function=*/\n-        rewriter.getStringAttr(add_op.getFusedActivationFunction()),\n-        /*weights_format=*/rewriter.getStringAttr(fc_op.getWeightsFormat()),\n-        /*keep_num_dims=*/rewriter.getBoolAttr(fc_op.getKeepNumDims()),\n-        /*asymmetric_quantize_inputs=*/\n-        fc_op.getAsymmetricQuantizeInputsAttr());\n-    rewriter.replaceOp(add_op, fc.getOutput());\n+    mlir::Value out =\n+        rewriter\n+            .create<TFL::FullyConnectedOp>(\n+                mlir::FusedLoc::get(fc_op.getContext(),\n+                                    {fc_op.getLoc(), add_op.getLoc()}),\n+                fc_output_type,\n+                /*input=*/fc_op.getInput(),\n+                /*filter=*/filter,\n+                /*bias=*/new_bias,\n+                /*fused_activation_function=*/\n+                rewriter.getStringAttr(add_op.getFusedActivationFunction()),\n+                /*weights_format=*/\n+                rewriter.getStringAttr(fc_op.getWeightsFormat()),\n+                /*keep_num_dims=*/rewriter.getBoolAttr(fc_op.getKeepNumDims()),\n+                /*asymmetric_quantize_inputs=*/\n+                fc_op.getAsymmetricQuantizeInputsAttr())\n+            .getOutput()[0];\n+\n+    if (fc_output_type.getShape() != add_output_type.getShape()) {\n+      auto target_shape = rewriter.create<arith::ConstantOp>(\n+          add_op.getLoc(), rewriter.getI32TensorAttr(llvm::SmallVector<int32_t>(\n+                               add_output_type.getShape())));\n+      out = rewriter.create<ReshapeOp>(add_op.getLoc(), add_output_type, out,\n+                                       target_shape);\n+    }\n+    rewriter.replaceOp(add_op, out);\n \n     return success();\n   }\n@@ -1395,7 +1421,7 @@ struct FuseAddAndFullyConnected\n   using OpRewritePattern<TFL::FullyConnectedOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::FullyConnectedOp fc_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // This only works with default format.\n     if (fc_op.getWeightsFormat() != \"DEFAULT\") return failure();\n \n@@ -1466,7 +1492,7 @@ struct FuseMulAndFullyConnected\n   using OpRewritePattern<TFL::FullyConnectedOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::FullyConnectedOp fc_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // This only works with default format.\n     if (fc_op.getWeightsFormat() != \"DEFAULT\") return failure();\n \n@@ -1536,13 +1562,13 @@ struct FuseMulAndFullyConnected\n };\n \n // TODO(b/136285429): Move to tablegen when variadic is supported.\n-template <typename ReluXOp, char const *Act>\n+template <typename ReluXOp, char const* Act>\n struct FuseFullyConnectedAndReluX : public OpRewritePattern<ReluXOp> {\n   using OpRewritePattern<ReluXOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(ReluXOp relu_op,\n-                                PatternRewriter &rewriter) const override {\n-    Operation *input = relu_op.getOperand().getDefiningOp();\n+                                PatternRewriter& rewriter) const override {\n+    Operation* input = relu_op.getOperand().getDefiningOp();\n     if (!isa_and_nonnull<FullyConnectedOp>(input)) return failure();\n     auto fully_connected_op = cast<FullyConnectedOp>(input);\n     if (fully_connected_op.getFusedActivationFunction() != \"NONE\")\n@@ -1582,7 +1608,7 @@ struct FuseFullyConnectedAndMul : public OpRewritePattern<TFL::MulOp> {\n   using OpRewritePattern<TFL::MulOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::MulOp mul_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // If we are broadcasting on the lhs then don't fold the multiply as it\n     // would increase the amount of compute done by the fully connected op.\n     if (mul_op.getLhs().getType() != mul_op.getType()) return failure();\n@@ -1702,7 +1728,7 @@ struct FuseAffinOpAndMulWithQDQs : public OpRewritePattern<TFL::MulOp> {\n   using OpRewritePattern<TFL::MulOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::MulOp mul_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // Mul. Required 1-D or squeezable to 1-D rhs for batch normalization.\n     DenseElementsAttr gamma_cst;\n     Value gamma = mul_op.getRhs();\n@@ -1712,7 +1738,7 @@ struct FuseAffinOpAndMulWithQDQs : public OpRewritePattern<TFL::MulOp> {\n     }\n \n     // Affine op\n-    Operation *mul_op_lhs = mul_op.getLhs().getDefiningOp();\n+    Operation* mul_op_lhs = mul_op.getLhs().getDefiningOp();\n     auto affine_op = dyn_cast_or_null<AffineOpType>(mul_op_lhs);\n     if (!affine_op) {\n       return failure();\n@@ -1849,9 +1875,9 @@ struct FuseBinaryOpToFollowingAffineOp : public OpRewritePattern<AffineOpType> {\n   using OpRewritePattern<AffineOpType>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(AffineOpType fc_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     // Binary op.\n-    Operation *binary_op = fc_op.getInput().getDefiningOp();\n+    Operation* binary_op = fc_op.getInput().getDefiningOp();\n     if (!binary_op || binary_op->getNumOperands() != 2) return failure();\n     // We only handle the cases the RHS is a scalar.\n     // TODO(fengliuai): Currently the canonicalizer pass couldn't guarantee that\n@@ -2003,7 +2029,7 @@ struct RemoveReshapeBeforeFullyConnected\n   using OpRewritePattern<TFL::FullyConnectedOp>::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::FullyConnectedOp fully_connected_op,\n-                                PatternRewriter &) const override {\n+                                PatternRewriter&) const override {\n     auto input = fully_connected_op.getInput();\n     auto input_ty = mlir::dyn_cast<ShapedType>(input.getType());\n     auto output_ty =\n@@ -2053,7 +2079,7 @@ struct RemoveReshapeAfterFullyConnected\n   using OpRewritePattern::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::ReshapeOp reshape_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto fully_connected_op = llvm::dyn_cast_or_null<TFL::FullyConnectedOp>(\n         reshape_op.getInput().getDefiningOp());\n     if (!fully_connected_op || fully_connected_op.getNumResults() != 1 ||\n@@ -2111,7 +2137,7 @@ struct FuseUnpackAndConcatToReshape\n   using OpRewritePattern::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::ConcatenationOp concat_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     if (concat_op.getFusedActivationFunction() != \"NONE\") {\n       return failure();\n     }\n@@ -2123,7 +2149,7 @@ struct FuseUnpackAndConcatToReshape\n     if (!unpack_op || unpack_op.getNumResults() != concat_op.getNumOperands()) {\n       return failure();\n     }\n-    for (const auto &index_and_value : llvm::enumerate(concat_op.getValues())) {\n+    for (const auto& index_and_value : llvm::enumerate(concat_op.getValues())) {\n       if (index_and_value.value() !=\n           unpack_op.getResult(index_and_value.index())) {\n         return failure();\n@@ -2209,7 +2235,7 @@ struct OptimizeTopK : public OpRewritePattern<TFL::TopKV2Op> {\n   }\n \n   LogicalResult matchAndRewrite(TFL::TopKV2Op op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto values = op.getValues();\n     auto indices = op.getIndices();\n     // op.getValues() and op.getIndices() cannot be used more than once.\n@@ -2277,7 +2303,7 @@ struct FuseReshapeAndTransposeAroundBatchMatmul\n   using OpRewritePattern::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::TransposeOp op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     TensorType transpose_input_type = op.getInput().getType();\n     // TODO(chhe): to support more than 3D in this pattern.\n     if (!transpose_input_type.hasStaticShape() ||\n@@ -2289,7 +2315,7 @@ struct FuseReshapeAndTransposeAroundBatchMatmul\n       return failure();\n     }\n     const SmallVector<int64_t, 3> match_perm = {1, 2, 0};\n-    for (const auto &[perm_index, match_perm_index] :\n+    for (const auto& [perm_index, match_perm_index] :\n          llvm::zip(transpose_perm.getValues<APInt>(), match_perm)) {\n       if (perm_index != match_perm_index) {\n         return failure();\n@@ -2373,7 +2399,7 @@ struct FuseTransposeReshapeIntoBatchMatmul\n   using OpRewritePattern::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::BatchMatMulOp op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto reshape_op = op.getY().getDefiningOp<ReshapeOp>();\n     if (!reshape_op || !ReshapeFirstTwoDim(reshape_op.getInput().getType(),\n                                            reshape_op.getType())) {\n@@ -2429,7 +2455,7 @@ struct FuseTransposeReshapeIntoBatchMatmul\n struct FuseLogSoftmax : public OpRewritePattern<TFL::SubOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(TFL::SubOp sub_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     if (sub_op.getFusedActivationFunction() != \"NONE\") {\n       return failure();\n     }\n@@ -2518,7 +2544,7 @@ struct FuseLogSoftmax : public OpRewritePattern<TFL::SubOp> {\n struct EliminateQDQPairs : public OpRewritePattern<TFL::QuantizeOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(TFL::QuantizeOp q_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     if (auto dq_op = dyn_cast_or_null<TFL::DequantizeOp>(\n             q_op.getInput().getDefiningOp())) {\n       if (tflite::NotFromQuantOpOrSameQuantType(dq_op.getInput(),\n@@ -2562,7 +2588,7 @@ struct UndoBroadcastFullyConnectedBiasAddWithQDQs\n   using OpRewritePattern::OpRewritePattern;\n \n   LogicalResult matchAndRewrite(TFL::AddOp add_op,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     if (!add_op->hasOneUse()) {\n       return failure();\n     }\n@@ -2635,11 +2661,11 @@ struct UndoBroadcastFullyConnectedBiasAddWithQDQs\n // (Reshape-Reshape)-FC.\n struct MoveReshapeAfterFullyConnected\n     : public OpRewritePattern<TFL::ReshapeOp> {\n-  explicit MoveReshapeAfterFullyConnected(MLIRContext *context)\n+  explicit MoveReshapeAfterFullyConnected(MLIRContext* context)\n       : OpRewritePattern<TFL::ReshapeOp>(context, /*benefit=*/0) {}\n \n   LogicalResult matchAndRewrite(TFL::ReshapeOp reshape,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto fc = llvm::dyn_cast_or_null<TFL::FullyConnectedOp>(\n         reshape.getInput().getDefiningOp());\n \n@@ -2695,11 +2721,11 @@ struct MoveReshapeAfterFullyConnected\n // layout planning.\n struct EnableFullyConnectedKeepNumDimsBeforeReshape\n     : public OpRewritePattern<TFL::ReshapeOp> {\n-  explicit EnableFullyConnectedKeepNumDimsBeforeReshape(MLIRContext *context)\n+  explicit EnableFullyConnectedKeepNumDimsBeforeReshape(MLIRContext* context)\n       : OpRewritePattern<TFL::ReshapeOp>(context, /*benefit=*/0) {}\n \n   LogicalResult matchAndRewrite(TFL::ReshapeOp reshape,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto fc = llvm::dyn_cast_or_null<TFL::FullyConnectedOp>(\n         reshape.getInput().getDefiningOp());\n \n@@ -2738,12 +2764,12 @@ struct EnableFullyConnectedKeepNumDimsBeforeReshape\n // while the push may still happen if the transpose could be fused with\n // downstream optimization phases or passe..\n struct PushTransposeThroughSqueeze : public RewritePattern {\n-  explicit PushTransposeThroughSqueeze(MLIRContext *context)\n+  explicit PushTransposeThroughSqueeze(MLIRContext* context)\n       : RewritePattern(TFL::SqueezeOp::getOperationName(), /*benefit=*/0,\n                        context) {}\n \n-  LogicalResult matchAndRewrite(mlir::Operation *op,\n-                                PatternRewriter &rewriter) const override {\n+  LogicalResult matchAndRewrite(mlir::Operation* op,\n+                                PatternRewriter& rewriter) const override {\n     TFL::SqueezeOp squeeze = cast<TFL::SqueezeOp>(op);\n     auto transpose = llvm::dyn_cast_or_null<TFL::TransposeOp>(\n         squeeze.getInput().getDefiningOp());\n@@ -2755,7 +2781,7 @@ struct PushTransposeThroughSqueeze : public RewritePattern {\n \n     llvm::SmallVector<int32_t, 4> squeeze_dims;\n     if (squeeze->hasAttr(\"squeeze_dims\")) {\n-      for (const auto &squeeze_dim : squeeze.getSqueezeDimsAttr()) {\n+      for (const auto& squeeze_dim : squeeze.getSqueezeDimsAttr()) {\n         squeeze_dims.push_back(\n             mlir::dyn_cast<IntegerAttr>(squeeze_dim).getInt());\n       }\n@@ -2773,7 +2799,7 @@ struct PushTransposeThroughSqueeze : public RewritePattern {\n       return failure();\n     }\n     llvm::SmallVector<int32_t, 4> perm;\n-    for (const auto &dim : perm_attr.getValues<APInt>()) {\n+    for (const auto& dim : perm_attr.getValues<APInt>()) {\n       perm.push_back(dim.getSExtValue());\n     }\n \n@@ -2809,7 +2835,7 @@ struct PushTransposeThroughSqueeze : public RewritePattern {\n     }\n \n     llvm::SmallVector<int32_t> new_perm;\n-    for (const auto &original_dim : filtered_perm_original_indices) {\n+    for (const auto& original_dim : filtered_perm_original_indices) {\n       new_perm.push_back(original_to_new_index_map[original_dim]);\n     }\n \n@@ -2863,14 +2889,14 @@ bool matchConstantIntPermutation(Value permValue,\n }\n \n inline DenseIntElementsAttr GetI32ElementsAttr(ArrayRef<int32_t> values,\n-                                               Builder *builder) {\n+                                               Builder* builder) {\n   RankedTensorType ty = mlir::RankedTensorType::get(\n       {static_cast<int32_t>(values.size())}, builder->getIntegerType(32));\n   return DenseIntElementsAttr::get(ty, values);\n }\n \n inline DenseIntElementsAttr GetI32ElementsAttr(ArrayRef<int64_t> values,\n-                                               Builder *builder) {\n+                                               Builder* builder) {\n   llvm::SmallVector<int32_t> new_values;\n   for (auto el : values) {\n     new_values.push_back(static_cast<int32_t>(el));\n@@ -2893,11 +2919,11 @@ inline DenseIntElementsAttr GetI32ElementsAttr(ArrayRef<int64_t> values,\n // reshapes and transposes.\n struct ReorderTransposeReshapeTranspose\n     : public OpRewritePattern<TFL::TransposeOp> {\n-  explicit ReorderTransposeReshapeTranspose(MLIRContext *context)\n+  explicit ReorderTransposeReshapeTranspose(MLIRContext* context)\n       : OpRewritePattern<TFL::TransposeOp>(context, /*benefit=*/0) {}\n \n   LogicalResult matchAndRewrite(TFL::TransposeOp outer_tpose,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     auto reshape = outer_tpose.getInput().getDefiningOp<TFL::ReshapeOp>();\n     if (!reshape) return failure();\n \n@@ -2999,11 +3025,11 @@ struct ReorderTransposeReshapeTranspose\n //   FinalOutput[B, O]   = Transpose(Intermediate[O, B], perm=[1, 0])\n struct FullyConnectedSwapOperandsWhenLHSIsConst\n     : public OpRewritePattern<TFL::FullyConnectedOp> {\n-  explicit FullyConnectedSwapOperandsWhenLHSIsConst(MLIRContext *context)\n+  explicit FullyConnectedSwapOperandsWhenLHSIsConst(MLIRContext* context)\n       : OpRewritePattern<TFL::FullyConnectedOp>(context, /*benefit=*/0) {}\n \n   LogicalResult matchAndRewrite(TFL::FullyConnectedOp fc,\n-                                PatternRewriter &rewriter) const override {\n+                                PatternRewriter& rewriter) const override {\n     if (!mlir::isa<NoneType>(fc.getBias().getType())) return failure();\n \n     auto input = fc.getInput();\n@@ -3064,16 +3090,16 @@ struct FullyConnectedSwapOperandsWhenLHSIsConst\n };\n \n // Adds canonicalization patterns to the list of patterns.\n-void AddCanonicalizationPatterns(MLIRContext *context,\n-                                 RewritePatternSet *patterns) {\n+void AddCanonicalizationPatterns(MLIRContext* context,\n+                                 RewritePatternSet* patterns) {\n   for (auto op : context->getRegisteredOperations())\n     op.getCanonicalizationPatterns(*patterns, context);\n }\n }  // namespace\n \n void OptimizePass::runOnOperation() {\n   RewritePatternSet patterns(&getContext());\n-  auto *ctx = &getContext();\n+  auto* ctx = &getContext();\n   auto func = getOperation();\n \n   // Merge reshapes into fully connected ops before we start moving them past"
        }
    ],
    "stats": {
        "total": 197,
        "additions": 118,
        "deletions": 79
    }
}