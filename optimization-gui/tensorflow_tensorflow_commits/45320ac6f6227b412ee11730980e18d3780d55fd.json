{
    "author": "tensorflower-gardener",
    "message": "Enable bf16 dots in YNNPACK by default\n\nPiperOrigin-RevId: 829013152",
    "sha": "45320ac6f6227b412ee11730980e18d3780d55fd",
    "files": [
        {
            "sha": "78ebacea4f2ef040bef5561f5cffc0b8d2e4abb0",
            "filename": "third_party/xla/xla/backends/cpu/ynn_support.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/45320ac6f6227b412ee11730980e18d3780d55fd/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/45320ac6f6227b412ee11730980e18d3780d55fd/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc?ref=45320ac6f6227b412ee11730980e18d3780d55fd",
            "patch": "@@ -159,9 +159,7 @@ absl::StatusOr<bool> IsDotSupportedByYnn(\n           // {F32, F32, F32},\n           // TODO(b/449998002): We don't have fast fp16 kernels yet.\n           // {F16, F16, F32},\n-          // TODO(b/452693819): We plan to enable this in stages, starting with\n-          // int8, and enable bf16 later.\n-          // {BF16, BF16, F32},\n+          {BF16, BF16, F32},\n           {S8, S8, S32},\n           {U8, S8, S32},\n           // TODO(b/441600372): We don't have fast int4 kernels yet. Even the"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 1,
        "deletions": 3
    }
}