{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 821380400",
    "sha": "bce088648427f369e814f28f96db4a335f20a520",
    "files": [
        {
            "sha": "0456328617e8a8fcd49ccac7da29ac05b15007c1",
            "filename": "tensorflow/compiler/tf2xla/xla_op_kernel.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bce088648427f369e814f28f96db4a335f20a520/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bce088648427f369e814f28f96db4a335f20a520/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.cc?ref=bce088648427f369e814f28f96db4a335f20a520",
            "patch": "@@ -677,7 +677,7 @@ xla::PrimitiveType XlaOpKernelContext::output_xla_type(int index) {\n   return type;\n }\n \n-void XlaOpKernelContext::SetOutput(int index, const xla::XlaOp& handle) {\n+void XlaOpKernelContext::SetOutput(int index, const xla::XlaOp handle) {\n   SetOutputExpression(\n       index,\n       XlaExpression::XlaOp(handle, context_->expected_output_dtype(index)));\n@@ -688,7 +688,7 @@ void XlaOpKernelContext::SetConstantOutput(int index, const Tensor& constant) {\n }\n \n void XlaOpKernelContext::SetTensorListOutput(int index,\n-                                             const xla::XlaOp& handle) {\n+                                             const xla::XlaOp handle) {\n   SetOutputExpression(index, XlaExpression::TensorList(handle));\n }\n \n@@ -811,7 +811,7 @@ const xla::XlaComputation* XlaOpKernelContext::GetOrCreateMul(\n \n const Tensor& XlaOpKernelContext::GetInputTensorByName(absl::string_view name) {\n   const Tensor* tensor;\n-  CHECK(context_->input(name, &tensor).ok());\n+  CHECK_OK(context_->input(name, &tensor));\n   return *tensor;\n }\n "
        },
        {
            "sha": "30de5a796d03a167b9fc1816f4d361c01143da19",
            "filename": "tensorflow/compiler/tf2xla/xla_op_kernel.h",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bce088648427f369e814f28f96db4a335f20a520/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bce088648427f369e814f28f96db4a335f20a520/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_op_kernel.h?ref=bce088648427f369e814f28f96db4a335f20a520",
            "patch": "@@ -249,7 +249,7 @@ class XlaOpKernelContext {\n   // Sets output `index` to the XlaOp `handle`.\n   // All outputs should be set using SetOutput and SetConstantOutput, not\n   // via the underlying OpKernelContext.\n-  void SetOutput(int index, const xla::XlaOp& handle);\n+  void SetOutput(int index, xla::XlaOp handle);\n \n   // Sets output `index` to compile-time constant `host_tensor`, where\n   // `host_tensor` is a tensor in host memory. It is preferable to use\n@@ -260,7 +260,7 @@ class XlaOpKernelContext {\n   void SetOutputExpression(int index, const XlaExpression& expression);\n \n   // Sets output `index` to the Tensor List `handle`.\n-  void SetTensorListOutput(int index, const xla::XlaOp& handle);\n+  void SetTensorListOutput(int index, xla::XlaOp handle);\n \n   // Status handling.\n   void SetStatus(const absl::Status& status) { context_->SetStatus(status); }\n@@ -341,27 +341,27 @@ class XlaOpKernelContext {\n   // Gets an XLA lambda to compute Max. This is cached in the\n   // XlaContext since it may be used by multiple Ops. There is a\n   // separate specialization of the computation for each DataType.\n-  const xla::XlaComputation* GetOrCreateMax(const DataType type);\n+  const xla::XlaComputation* GetOrCreateMax(DataType type);\n \n   // Gets an XLA lambda to compute Min. This is cached in the\n   // XlaContext since it may be used by multiple Ops. There is a\n   // separate specialization of the computation for each DataType.\n-  const xla::XlaComputation* GetOrCreateMin(const DataType type);\n+  const xla::XlaComputation* GetOrCreateMin(DataType type);\n \n   // Gets an XLA lambda to compute Add. This is cached in the\n   // XlaContext since it may be used by multiple Ops. There is a\n   // separate specialization of the computation for each DataType.\n-  const xla::XlaComputation* GetOrCreateAdd(const DataType type);\n+  const xla::XlaComputation* GetOrCreateAdd(DataType type);\n \n   // Gets an XLA lambda to compute LogAddExp. This is cached in the\n   // XlaContext since it may be used by multiple Ops. There is a\n   // separate specialization of the computation for each DataType.\n-  const xla::XlaComputation* GetOrCreateLogAddExp(const DataType type);\n+  const xla::XlaComputation* GetOrCreateLogAddExp(DataType type);\n \n   // Gets an XLA lambda to compute Mul. This is cached in the\n   // XlaContext since it may be used by multiple Ops. There is a\n   // separate specialization of the computation for each DataType.\n-  const xla::XlaComputation* GetOrCreateMul(const DataType type);\n+  const xla::XlaComputation* GetOrCreateMul(DataType type);\n \n   // Returns stack trace encoded as a string at a given module, or an empty\n   // string if none found."
        }
    ],
    "stats": {
        "total": 20,
        "additions": 10,
        "deletions": 10
    }
}