{
    "author": "unknown",
    "message": "[XLA:GPU] Add SdcXorChecksumKernel\n\nA kernel that calculates a XOR checksum of given device buffer, and appends it\nto a fixed-size log. Intended for use in detecting nondeterministic\ncomputations or silent data corruption.\n\nExcess entries are silently discarded.\n\nPiperOrigin-RevId: 810793263",
    "sha": "32f4a1a81c1325c5642c85d5ec495022d45714aa",
    "files": [
        {
            "sha": "be8fc6897913688ad482e8a0498463d40c773fab",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=32f4a1a81c1325c5642c85d5ec495022d45714aa",
            "patch": "@@ -458,6 +458,58 @@ xla_test(\n     ],\n )\n \n+cuda_library(\n+    name = \"sdc_xor_checksum_kernel_cuda\",\n+    srcs = [\"sdc_xor_checksum_kernel_cuda.cu.cc\"],\n+    hdrs = [\"sdc_xor_checksum_kernel_cuda.h\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":cuda_platform_id\",\n+        \":sdc_log\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:kernel_spec\",\n+        \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n+        \"//xla/tsl/platform:logging\",\n+        \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"sdc_xor_checksum_kernel_cuda_test\",\n+    srcs = [\"sdc_xor_checksum_kernel_cuda_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\"cuda-only\"],\n+    deps = [\n+        \":sdc_log\",\n+        \":sdc_xor_checksum_kernel_cuda\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:kernel_spec\",\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/stream_executor:typed_kernel_factory\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/cleanup\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"cudnn_plugin\",\n     srcs = [\"cuda_dnn.cc\"],"
        },
        {
            "sha": "86447d941b46779916290cfee52c7bc39f6c4a09",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.cu.cc",
            "status": "added",
            "additions": 209,
            "deletions": 0,
            "changes": 209,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc?ref=32f4a1a81c1325c5642c85d5ec495022d45714aa",
            "patch": "@@ -0,0 +1,209 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.h\"\n+\n+#include <algorithm>\n+#include <cstdint>\n+#include <cstdlib>\n+#include <cstring>\n+\n+#include \"absl/base/casts.h\"\n+#include \"third_party/gpus/cuda/include/cuda/atomic\"\n+#include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n+#include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n+#include \"xla/tsl/platform/logging.h\"\n+\n+namespace se = stream_executor;\n+\n+namespace {\n+\n+__device__ unsigned int ThreadIdx() {\n+  return threadIdx.z * blockDim.y * blockDim.x + threadIdx.y * blockDim.x +\n+         threadIdx.x;\n+}\n+\n+__device__ unsigned int BlockIdx() {\n+  return blockIdx.z * gridDim.y * gridDim.x + blockIdx.y * gridDim.x +\n+         blockIdx.x;\n+}\n+\n+// Based on\n+// https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf\n+template <unsigned int BLOCK_SIZE>\n+__device__ void WarpReduceXor(unsigned int tid, volatile uint32_t* data) {\n+  if (BLOCK_SIZE >= 64) data[tid] ^= data[tid + 32];\n+  if (BLOCK_SIZE >= 32) data[tid] ^= data[tid + 16];\n+  if (BLOCK_SIZE >= 16) data[tid] ^= data[tid + 8];\n+  if (BLOCK_SIZE >= 8) data[tid] ^= data[tid + 4];\n+  if (BLOCK_SIZE >= 4) data[tid] ^= data[tid + 2];\n+  if (BLOCK_SIZE >= 2) data[tid] ^= data[tid + 1];\n+}\n+\n+// Calculates a XOR of all elements of `input` and puts the result in `output`.\n+//\n+// Optimized implementation based on\n+// https://developer.download.nvidia.com/assets/cuda/files/reduction.pdf\n+// that takes advantage of `BLOCK_SIZE` threads.\n+//\n+// `BLOCK_SIZE` must be a power of 2 no larger than 1024.\n+template <unsigned int BLOCK_SIZE>\n+__device__ void ReduceXor(const uint32_t* input, uint64_t input_size,\n+                          uint32_t* output) {\n+  __shared__ uint32_t scratch[BLOCK_SIZE];\n+\n+  assert(BlockIdx() == 0);\n+  const unsigned int tid = ThreadIdx();\n+\n+  scratch[tid] = 0;\n+  for (unsigned int i = tid; i < input_size; i += BLOCK_SIZE) {\n+    scratch[tid] ^= input[i];\n+  }\n+\n+  __syncthreads();\n+\n+  if (BLOCK_SIZE >= 1024) {\n+    if (tid < 512) {\n+      scratch[tid] ^= scratch[tid + 512];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 512) {\n+    if (tid < 256) {\n+      scratch[tid] ^= scratch[tid + 256];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 256) {\n+    if (tid < 128) {\n+      scratch[tid] ^= scratch[tid + 128];\n+    }\n+    __syncthreads();\n+  }\n+  if (BLOCK_SIZE >= 128) {\n+    if (tid < 64) {\n+      scratch[tid] ^= scratch[tid + 64];\n+    }\n+    __syncthreads();\n+  }\n+  if (tid < 32) WarpReduceXor<BLOCK_SIZE>(tid, scratch);\n+  if (tid == 0) *output = scratch[0];\n+}\n+\n+// Attempts to append the checksum of the `input` buffer to the `log_entries`,\n+// using `log_header` to track available capacity and used space.\n+//\n+// The log entry is tagged with `entry_id`. The checksum is parallelized as\n+// much as block dimensions allow it.\n+//\n+// If the log does not have enough space for the new entry, the entry is\n+// discarded.\n+//\n+// `input_size` is the size of the input buffer in bytes.\n+//\n+// LIMITATIONS:\n+// - Only a single thread block is supported.\n+// - Block dimensions must be a power of 2.\n+__global__ void AppendChecksum(uint32_t entry_id, const uint8_t* input,\n+                               uint64_t input_size,\n+                               se::cuda::SdcLogHeader* log_header,\n+                               se::cuda::SdcLogEntry* log_entries) {\n+  const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n+  const uint32_t* input_u32 = reinterpret_cast<const uint32_t*>(input);\n+  const uint64_t input_u32_size = input_size / sizeof(uint32_t);\n+  uint32_t checksum = 0;\n+\n+  assert(gridDim.x == 1 && gridDim.y == 1 && gridDim.z == 1);\n+  if (BlockIdx() != 0) {\n+    return;\n+  }\n+\n+  // https://developer.nvidia.com/blog/cuda-refresher-cuda-programming-model/:\n+  // > CUDA architecture limits the numbers of threads per block (1024 threads\n+  // > per block limit).\n+  switch (block_size) {\n+    case 1024:\n+      ReduceXor<1024>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 512:\n+      ReduceXor<512>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 256:\n+      ReduceXor<256>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 128:\n+      ReduceXor<128>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 64:\n+      ReduceXor<64>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 32:\n+      ReduceXor<32>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 16:\n+      ReduceXor<16>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 8:\n+      ReduceXor<8>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 4:\n+      ReduceXor<4>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 2:\n+      ReduceXor<2>(input_u32, input_u32_size, &checksum);\n+      break;\n+    case 1:\n+      ReduceXor<1>(input_u32, input_u32_size, &checksum);\n+      break;\n+    default:\n+      // Unsupported block size.\n+      assert(false);\n+      return;\n+  }\n+\n+  if (ThreadIdx() == 0) {\n+    const size_t last_chunk_size = input_size % sizeof(uint32_t);\n+    uint32_t last_chunk = 0;\n+    memcpy(&last_chunk, input + input_u32_size * sizeof(uint32_t),\n+           last_chunk_size);\n+    checksum ^= last_chunk;\n+\n+    cuda::atomic_ref<uint32_t, cuda::thread_scope_system>\n+        checksum_log_write_idx(log_header->write_idx);\n+    const uint32_t write_idx = checksum_log_write_idx.fetch_add(1);\n+    if (write_idx < log_header->capacity) {\n+      log_entries[write_idx] = {entry_id, checksum};\n+    }\n+  }\n+}\n+\n+}  // namespace\n+\n+GPU_KERNEL_REGISTRY_REGISTER_KERNEL_STATICALLY(\n+    SdcXorChecksumKernel, se::cuda::SdcXorChecksumKernel,\n+    se::cuda::kCudaPlatformId, ([](size_t _arity) {\n+      return se::cuda::GetSdcXorChecksumKernelSpec().value();\n+    }));\n+\n+namespace stream_executor::cuda {\n+\n+absl::StatusOr<se::KernelLoaderSpec> GetSdcXorChecksumKernelSpec() {\n+  return se::KernelLoaderSpec::CreateInProcessSymbolSpec(\n+      absl::bit_cast<void*>(&AppendChecksum), \"SdcXorChecksumKernel\",\n+      /*arity=*/5);\n+}\n+\n+}  // namespace stream_executor::cuda"
        },
        {
            "sha": "a37031f4ddbf823984ee83f1437aa7d0715a2da3",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.h",
            "status": "added",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h?ref=32f4a1a81c1325c5642c85d5ec495022d45714aa",
            "patch": "@@ -0,0 +1,43 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_CUDA_SDC_XOR_CHECKSUM_KERNEL_CUDA_H_\n+#define XLA_STREAM_EXECUTOR_CUDA_SDC_XOR_CHECKSUM_KERNEL_CUDA_H_\n+\n+#include <cstdint>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n+\n+namespace stream_executor::cuda {\n+\n+// Trait for a kernel that computes the checksum of given input buffer and\n+// appends it to the SDC log.\n+//\n+// This kernel MUST execute on a single thread block.\n+struct SdcXorChecksumKernel {\n+  using KernelType =\n+      TypedKernel<uint32_t, DeviceMemory<uint8_t>, uint64_t,\n+                  DeviceMemory<SdcLogHeader>, DeviceMemory<SdcLogEntry>>;\n+};\n+\n+absl::StatusOr<KernelLoaderSpec> GetSdcXorChecksumKernelSpec();\n+\n+}  // namespace stream_executor::cuda\n+\n+#endif  // XLA_STREAM_EXECUTOR_CUDA_SDC_XOR_CHECKSUM_KERNEL_CUDA_H_"
        },
        {
            "sha": "8d25d1e20f0b690cf5a3d5089c1190ace3bac50e",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda_test.cc",
            "status": "added",
            "additions": 224,
            "deletions": 0,
            "changes": 224,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/32f4a1a81c1325c5642c85d5ec495022d45714aa/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc?ref=32f4a1a81c1325c5642c85d5ec495022d45714aa",
            "patch": "@@ -0,0 +1,224 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.h\"\n+\n+#include <array>\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+#include <vector>\n+\n+#include <gtest/gtest.h>\n+#include \"absl/cleanup/cleanup.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/stream_executor/typed_kernel_factory.h\"  // IWYU pragma: keep, required for KernelType::FactoryType::Create\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace se = stream_executor;\n+\n+namespace {\n+\n+class ChecksumKernelTest : public ::testing::Test {\n+ protected:\n+  void SetUp() override {\n+    TF_ASSERT_OK_AND_ASSIGN(platform_,\n+                            se::PlatformManager::PlatformWithName(\"CUDA\"));\n+    TF_ASSERT_OK_AND_ASSIGN(executor_, platform_->ExecutorForDevice(0));\n+    TF_ASSERT_OK_AND_ASSIGN(stream_, executor_->CreateStream(std::nullopt));\n+    allocator_ =\n+        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_->parent());\n+  }\n+\n+  template <typename T>\n+  absl::StatusOr<se::DeviceMemory<T>> CheckNotNull(\n+      se::DeviceMemory<T> device_memory, absl::string_view name) {\n+    if (device_memory.is_null()) {\n+      return absl::InternalError(\n+          absl::StrFormat(\"Device memory for %s is null\", name));\n+    }\n+    return device_memory;\n+  }\n+\n+  template <typename T>\n+  absl::Status AppendChecksumOnDevice(\n+      uint32_t entry_id, const T& input, se::cuda::SdcLog& sdc_log,\n+      stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n+    // Load kernel\n+    TF_ASSIGN_OR_RETURN(se::KernelLoaderSpec spec,\n+                        se::cuda::GetSdcXorChecksumKernelSpec());\n+    TF_ASSIGN_OR_RETURN(\n+        auto kernel,\n+        se::cuda::SdcXorChecksumKernel::KernelType::FactoryType::Create(\n+            executor_, spec));\n+\n+    // Setup device buffers\n+    TF_ASSIGN_OR_RETURN(se::DeviceMemory<uint8_t> device_input,\n+                        CheckNotNull(executor_->AllocateArray<uint8_t>(\n+                                         input.size() * sizeof(input[0])),\n+                                     \"input\"));\n+    auto cleanup_input =\n+        absl::MakeCleanup([&]() { executor_->Deallocate(&device_input); });\n+\n+    // Call kernel\n+    TF_RETURN_IF_ERROR(stream_->Memcpy(&device_input, input.data(),\n+                                       input.size() * sizeof(input[0])));\n+    TF_RETURN_IF_ERROR(\n+        kernel.Launch(dim, stream_executor::BlockDim(1, 1, 1), stream_.get(),\n+                      entry_id, device_input, device_input.ElementCount(),\n+                      sdc_log.GetDeviceHeader(), sdc_log.GetDeviceEntries()));\n+    TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n+\n+    // The result gets stored in `sdc_log`.\n+    return absl::OkStatus();\n+  }\n+\n+  se::Platform* platform_;\n+  se::StreamExecutor* executor_;\n+  std::unique_ptr<se::Stream> stream_;\n+  std::unique_ptr<se::StreamExecutorMemoryAllocator> allocator_;\n+};\n+\n+TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n+  std::vector<uint8_t> input = std::vector<uint8_t>(1024, 0x55);\n+  // Xor with the expected checksum value.\n+  // Assumes the device uses little-endian byte order.\n+  input[1000] ^= 0x78;\n+  input[1001] ^= 0x56;\n+  input[1002] ^= 0x34;\n+  input[1003] ^= 0x12;\n+  constexpr uint32_t kExpectedChecksum = 0x12345678;\n+\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/10, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+}\n+\n+TEST_F(ChecksumKernelTest,\n+       PadsMostSignifantBitsOfIncomplete32BitInputWordWithZeros) {\n+  const std::vector<uint8_t> kInput = std::vector<uint8_t>(1023, 0x55);\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/10, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, kInput, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  // Assumes the device uses little-endian byte order.\n+  EXPECT_EQ(host_log[0].checksum, 0x55000000);\n+}\n+\n+TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n+  std::vector<uint32_t> input =\n+      std::vector<uint32_t>(64 * 1024 / sizeof(uint32_t), 0x55aa55aa);\n+  // Xor with the expected checksum value.\n+  input[1000] ^= 0x12345678;\n+  constexpr uint32_t kExpectedChecksum = 0x12345678;\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/10, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log,\n+                                      se::ThreadDim(2, 4, 8)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+}\n+\n+TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n+  std::vector<uint32_t> input =\n+      std::vector<uint32_t>(64 * 1024 / sizeof(uint32_t), 0x55aa55aa);\n+  // Xor with the expected checksum value.\n+  input[1000] ^= 0x12345678;\n+  constexpr uint32_t kExpectedChecksum = 0x12345678;\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/10, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log,\n+                                      se::ThreadDim(128, 4, 2)));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 1);\n+  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+}\n+\n+TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n+  constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n+  constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n+  constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/10, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/123, kInput123, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/456, kInput456, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/789, kInput789, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 3);\n+  EXPECT_EQ(host_log[0].entry_id, 123);\n+  EXPECT_EQ(host_log[0].checksum, 0x01230123);\n+  EXPECT_EQ(host_log[1].entry_id, 456);\n+  EXPECT_EQ(host_log[1].checksum, 0x04560456);\n+  EXPECT_EQ(host_log[2].entry_id, 789);\n+  EXPECT_EQ(host_log[2].checksum, 0x07890789);\n+}\n+\n+TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n+  constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n+  constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n+  constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n+  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n+                          se::cuda::SdcLog::CreateOnDevice(\n+                              /*max_entries=*/2, *stream_, *allocator_));\n+\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/123, kInput123, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/456, kInput456, device_log));\n+  // This entry will be discarded.\n+  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/789, kInput789, device_log));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n+  ASSERT_GE(host_log.size(), 2);\n+  EXPECT_EQ(host_log[0].entry_id, 123);\n+  EXPECT_EQ(host_log[0].checksum, 0x01230123);\n+  EXPECT_EQ(host_log[1].entry_id, 456);\n+  EXPECT_EQ(host_log[1].checksum, 0x04560456);\n+}\n+\n+}  // namespace"
        }
    ],
    "stats": {
        "total": 528,
        "additions": 528,
        "deletions": 0
    }
}