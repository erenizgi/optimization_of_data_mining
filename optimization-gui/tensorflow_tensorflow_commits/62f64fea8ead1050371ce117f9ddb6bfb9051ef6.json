{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Update Expm1 & Cbrt expand ops to work with vectors.\n\nAlso cleaned up the use of fast math flags while I was here.\n\nPiperOrigin-RevId: 834181953",
    "sha": "62f64fea8ead1050371ce117f9ddb6bfb9051ef6",
    "files": [
        {
            "sha": "b14e7c172a37e391f8e93326ed06155835df2142",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/transforms/expand_float_ops.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 31,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f64fea8ead1050371ce117f9ddb6bfb9051ef6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fexpand_float_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f64fea8ead1050371ce117f9ddb6bfb9051ef6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fexpand_float_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fexpand_float_ops.cc?ref=62f64fea8ead1050371ce117f9ddb6bfb9051ef6",
            "patch": "@@ -46,6 +46,17 @@ namespace {\n \n namespace ma = ::mlir::arith;\n \n+// Get a constant value, if the type is a vector, splat the value to the vector\n+// type.\n+mlir::Value GetConst(mlir::ImplicitLocOpBuilder& b, mlir::Type type,\n+                     mlir::TypedAttr value) {\n+  if (auto vector_type = mlir::dyn_cast<mlir::VectorType>(type)) {\n+    value =\n+        mlir::SplatElementsAttr::get(mlir::cast<mlir::ShapedType>(type), value);\n+  }\n+  return mlir::arith::ConstantOp::create(b, type, value);\n+}\n+\n mlir::Value EmitBF16ToF32(mlir::Type dst_ty, mlir::Value in,\n                           mlir::ImplicitLocOpBuilder& b) {\n   auto get_type = [&](mlir::Type element_type) -> mlir::Type {\n@@ -61,13 +72,8 @@ mlir::Value EmitBF16ToF32(mlir::Type dst_ty, mlir::Value in,\n   mlir::Value i16 = ma::BitcastOp::create(b, i16_type, in);\n   mlir::Value i32 = ma::ExtUIOp::create(b, i32_type, i16);\n \n-  mlir::TypedAttr shift_attr = b.getI32IntegerAttr(16);\n-  if (auto vector_type = mlir::dyn_cast<mlir::VectorType>(in.getType())) {\n-    shift_attr = mlir::SplatElementsAttr::get(\n-        mlir::cast<mlir::ShapedType>(i32_type), shift_attr);\n-  }\n-  mlir::Value shift_const =\n-      mlir::arith::ConstantOp::create(b, i32_type, shift_attr);\n+  mlir::TypedAttr shift_value = b.getI32IntegerAttr(16);\n+  mlir::Value shift_const = GetConst(b, i32_type, shift_value);\n \n   mlir::Value i32_shl = mlir::arith::ShLIOp::create(b, i32, shift_const);\n   return ma::BitcastOp::create(b, dst_ty, i32_shl);\n@@ -101,19 +107,19 @@ class RewriteCbrtPattern : public mlir::OpRewritePattern<mlir::math::CbrtOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::math::CbrtOp op, mlir::PatternRewriter& rewriter) const override {\n     mlir::ImplicitLocOpBuilder b(op.getLoc(), rewriter);\n+    mlir::arith::FastMathFlagsAttr fastmath = op.getFastmathAttr();\n \n     mlir::Value input_abs =\n-        b.create<mlir::math::AbsFOp>(op.getOperand(), op.getFastmathAttr())\n-            .getResult();\n+        b.create<mlir::math::AbsFOp>(op.getOperand(), fastmath).getResult();\n \n-    mlir::Value one_third = b.create<mlir::arith::ConstantOp>(\n-        b.getFloatAttr(op.getType(), 1.0 / 3.0));\n-    mlir::Value cbrt_abs = b.create<mlir::math::PowFOp>(input_abs, one_third,\n-                                                        op.getFastmathAttr());\n+    mlir::TypedAttr third_attr =\n+        b.getFloatAttr(mlir::getElementTypeOrSelf(op.getType()), 1.0 / 3.0);\n+    mlir::Value third_value = GetConst(b, op.getType(), third_attr);\n+    mlir::Value cbrt_abs =\n+        b.create<mlir::math::PowFOp>(input_abs, third_value, fastmath);\n \n     mlir::Value cbrt_signed =\n-        b.create<mlir::math::CopySignOp>(cbrt_abs, op.getOperand(),\n-                                         op.getFastmathAttr())\n+        b.create<mlir::math::CopySignOp>(cbrt_abs, op.getOperand(), fastmath)\n             .getResult();\n \n     rewriter.replaceOp(op, cbrt_signed);\n@@ -133,29 +139,27 @@ class RewriteExpm1Pattern : public mlir::OpRewritePattern<mlir::math::ExpM1Op> {\n     mlir::ImplicitLocOpBuilder b(op.getLoc(), rewriter);\n \n     mlir::Type type = op.getType();\n-    mlir::Value one =\n-        b.create<mlir::arith::ConstantOp>(b.getFloatAttr(type, 1.0));\n-    mlir::Value half =\n-        b.create<mlir::arith::ConstantOp>(b.getFloatAttr(type, 0.5));\n-    mlir::Value zero =\n-        b.create<mlir::arith::ConstantOp>(b.getFloatAttr(type, 0.0));\n+    mlir::Type element_type = mlir::getElementTypeOrSelf(type);\n+    mlir::Value one = GetConst(b, type, b.getFloatAttr(element_type, 1.0));\n+    mlir::Value half = GetConst(b, type, b.getFloatAttr(element_type, 0.5));\n+    mlir::Value zero = GetConst(b, type, b.getFloatAttr(element_type, 0.0));\n     mlir::Value x = op.getOperand();\n \n-    mlir::Value exp_x = b.create<mlir::math::ExpOp>(x, op.getFastmathAttr());\n+    mlir::arith::FastMathFlagsAttr fastmath = op.getFastmathAttr();\n+\n+    mlir::Value exp_x = b.create<mlir::math::ExpOp>(x, fastmath);\n \n     mlir::Value exp_x_minus_1 =\n-        b.create<mlir::arith::SubFOp>(exp_x, one, op.getFastmathAttr());\n+        b.create<mlir::arith::SubFOp>(exp_x, one, fastmath);\n \n-    mlir::Value half_x =\n-        b.create<mlir::arith::MulFOp>(x, half, op.getFastmathAttr());\n-    mlir::Value tanh_half_x =\n-        b.create<mlir::math::TanhOp>(half_x, op.getFastmathAttr());\n+    mlir::Value half_x = b.create<mlir::arith::MulFOp>(x, half, fastmath);\n+    mlir::Value tanh_half_x = b.create<mlir::math::TanhOp>(half_x, fastmath);\n     mlir::Value exp_x_plus_1 =\n-        b.create<mlir::arith::AddFOp>(exp_x, one, op.getFastmathAttr());\n-    mlir::Value small_result = b.create<mlir::arith::MulFOp>(\n-        tanh_half_x, exp_x_plus_1, op.getFastmathAttr());\n+        b.create<mlir::arith::AddFOp>(exp_x, one, fastmath);\n+    mlir::Value small_result =\n+        b.create<mlir::arith::MulFOp>(tanh_half_x, exp_x_plus_1, fastmath);\n \n-    mlir::Value abs_x = b.create<mlir::math::AbsFOp>(x, op.getFastmathAttr());\n+    mlir::Value abs_x = b.create<mlir::math::AbsFOp>(x, fastmath);\n     mlir::Value x_is_large = b.create<mlir::arith::CmpFOp>(\n         mlir::arith::CmpFPredicate::OGT, abs_x, half);\n     mlir::Value normal_result = b.create<mlir::arith::SelectOp>("
        },
        {
            "sha": "5c2cab2fec7b4630ecc13efceb0dd81c3a645649",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/transforms/tests/expand_float_ops.mlir",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f64fea8ead1050371ce117f9ddb6bfb9051ef6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fexpand_float_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f64fea8ead1050371ce117f9ddb6bfb9051ef6/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fexpand_float_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fexpand_float_ops.mlir?ref=62f64fea8ead1050371ce117f9ddb6bfb9051ef6",
            "patch": "@@ -31,10 +31,35 @@ func.func @cbrt(%arg0: f64) -> f64 {\n \n // -----\n \n+func.func @cbrt_vector(%arg0: vector<8xf64>) -> vector<8xf64> {\n+  %ret = math.cbrt %arg0 fastmath<reassoc> : vector<8xf64>\n+  return %ret : vector<8xf64>\n+}\n+\n+// CHECK: @cbrt_vector(%[[ARG:.*]]: vector<8xf64>) -> vector<8xf64>\n+// CHECK-NOT: math.cbrt\n+// CHECK-DAG: %[[CONSTANT:.*]] = arith.constant dense<0.33333333333333331> : vector<8xf64>\n+// CHECK: %[[ABS:.*]] = math.absf %[[ARG]] fastmath<reassoc> : vector<8xf64>\n+// CHECK: %[[CBRT_ABS:.*]] = math.powf %[[ABS]], %[[CONSTANT]] fastmath<reassoc> : vector<8xf64>\n+// CHECK: %[[CBRT_SIGNED:.*]] = math.copysign %[[CBRT_ABS]], %[[ARG]] fastmath<reassoc> : vector<8xf64>\n+// CHECK: return %[[CBRT_SIGNED]]\n+\n+// -----\n+\n func.func @expm1(%arg0: f64) -> f64 {\n   %ret = math.expm1 %arg0 : f64\n   return %ret : f64\n }\n \n // CHECK-LABEL: @expm1\n // CHECK-NOT: math.expm1\n+\n+// -----\n+\n+func.func @expm1_vector(%arg0: vector<4xf64>) -> vector<4xf64> {\n+  %ret = math.expm1 %arg0 : vector<4xf64>\n+  return %ret : vector<4xf64>\n+}\n+\n+// CHECK-LABEL: @expm1_vector\n+// CHECK-NOT: math.expm1"
        }
    ],
    "stats": {
        "total": 91,
        "additions": 60,
        "deletions": 31
    }
}