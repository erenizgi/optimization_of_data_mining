{
    "author": "akuegel",
    "message": "[XLA:GPU] Run hlo lit tests on several GPU platforms.\n\nThis increases test coverage.\nAlso remove the empty test suite mlir_lit_tests. These tests have been moved to\nanother directory long ago.\n\nPiperOrigin-RevId: 820074643",
    "sha": "06ea67005be2ee707f545968372042de3c01d3d9",
    "files": [
        {
            "sha": "2d67642b096085e5a1f80aa5961fa60be1fedcb4",
            "filename": "third_party/xla/xla/lit.bzl",
            "status": "modified",
            "additions": 105,
            "deletions": 3,
            "changes": 108,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06ea67005be2ee707f545968372042de3c01d3d9/third_party%2Fxla%2Fxla%2Flit.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06ea67005be2ee707f545968372042de3c01d3d9/third_party%2Fxla%2Fxla%2Flit.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Flit.bzl?ref=06ea67005be2ee707f545968372042de3c01d3d9",
            "patch": "@@ -60,6 +60,7 @@ def lit_test_suite(\n         hermetic_cuda_data_dir = None,\n         exec_properties = {},\n         tags = [],\n+        gpu_suffix = \"\",\n         **kwargs):\n     \"\"\"Creates one lit test per source file and a test suite that bundles them.\n \n@@ -91,6 +92,8 @@ def lit_test_suite(\n       tags: string list. Tags applied to all tests and the test suite.\n       exec_properties: string_dict. Properties to pass to the test rule, e.g.\n         requirement to run on a GPU.\n+      gpu_suffix: string. A suffix derived from the gpu name that can be added\n+        to make (file) names unique.\n       **kwargs: additional keyword arguments to pass to all generated rules.\n \n     See https://llvm.org/docs/CommandGuide/lit.html for details on lit\n@@ -109,7 +112,7 @@ def lit_test_suite(\n         # It's generally good practice to prefix any generated names with the\n         # macro name, but it's also nice to have the test name just match the\n         # file name.\n-        test_name = \"%s.test\" % (test_file)\n+        test_name = \"%s.test%s\" % (test_file, gpu_suffix)\n         tests.append(test_name)\n         lit_test(\n             name = test_name,\n@@ -124,6 +127,7 @@ def lit_test_suite(\n             tags = tags + default_tags + tags_override.get(test_file, []),\n             hermetic_cuda_data_dir = hermetic_cuda_data_dir,\n             exec_properties = exec_properties,\n+            gpu_suffix = gpu_suffix,\n             **kwargs\n         )\n \n@@ -134,6 +138,101 @@ def lit_test_suite(\n         **kwargs\n     )\n \n+def lit_test_suite_for_gpus(\n+        name,\n+        srcs,\n+        cfg,\n+        tools = None,\n+        args = [],\n+        data = [],\n+        visibility = None,\n+        env = None,\n+        timeout = None,\n+        default_tags = None,\n+        tags_override = None,\n+        hermetic_cuda_data_dir = None,\n+        exec_properties = {},\n+        tags = [],\n+        gpus = [\"a6000\"],\n+        disabled_on_gpus = {},\n+        **kwargs):\n+    \"\"\"Creates one lit test suite per gpu.\n+\n+    Args:\n+      name: string. the name prefix of the generated test suite. Each test suite\n+        will get the gpu name as suffix.\n+      srcs: label_list. The files which contain the lit tests.\n+      cfg: label. The lit config file. It must list the file extension of\n+        the files in `srcs` in config.suffixes and must be in a parent directory\n+        of `srcs`.\n+      tools: label list. Tools invoked in the lit RUN lines. These binaries will\n+        be symlinked into a directory which is on the path. They must therefore\n+        have unique basenames. Note that tools that are xla_cc_binary targets\n+        will also need to have linkopts = [\"-Wl,-rpath,$$ORIGIN/../lit_lib\"],\n+        otherwise they will not work properly with hermetic cuda.\n+      args: string list. Additional arguments to pass to lit. Note that the test\n+        file, `-v`, and a `--path` argument for the directory to which `tools`\n+        are symlinked are added automatically.\n+      data: label list. Additional data dependencies of the test. Note that\n+        targets in `cfg` and `tools`, as well as their data dependencies, are\n+        added automatically.\n+      visibility: visibility of the generated test targets and test suite.\n+      env: string_dict. Environment variables available during test execution.\n+        See the common Bazel test attribute.\n+      timeout: timeout argument passed to the individual tests.\n+      default_tags: string list. Tags applied to all tests.\n+      tags_override: string_dict. Tags applied in addition to only select tests.\n+      hermetic_cuda_data_dir: string. If set, the tests will be run with a\n+        `--xla_gpu_cuda_data_dir` flag set to the hermetic CUDA data directory.\n+      tags: string list. Tags applied to all tests and the test suite.\n+      exec_properties: string_dict. Properties to pass to the test rule, e.g.\n+        requirement to run on a GPU.\n+      gpus: string list. GPU names for which a lit test suite should be\n+        generated. Supported GPU names are: p100, v100, a100_pcie, a6000, h100,\n+        b200, mi200.\n+      disabled_on_gpus: string_dict. For a gpu name (key) contains a list of\n+        test files that should be skipped.\n+      **kwargs: additional keyword arguments to pass to all generated rules.\n+\n+    See https://llvm.org/docs/CommandGuide/lit.html for details on lit\n+    \"\"\"\n+    # If there are kwargs that need to be passed to only some of the generated\n+    # rules, they should be extracted into separate named arguments.\n+\n+    for gpu in gpus:\n+        filtered_srcs = [src for src in srcs if src not in disabled_on_gpus.get(gpu, [])]\n+        gpu_args = args + [\n+            \"--param=PTX=%s\" % (\"GCN\" if gpu == \"mi200\" else \"PTX\"),\n+            \"--param=GPU=%s\" % (gpu),\n+        ]\n+        gpu_data = data + [\n+            \"//xla/tools/hlo_opt:gpu_specs/a100_pcie_80.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/a6000.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/b200.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/mi200.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/p100.txtpb\",\n+            \"//xla/tools/hlo_opt:gpu_specs/v100.txtpb\",\n+        ]\n+        lit_test_suite(\n+            \"%s_%s\" % (name, gpu),\n+            filtered_srcs,\n+            cfg,\n+            tools,\n+            gpu_args,\n+            gpu_data,\n+            visibility,\n+            env,\n+            timeout,\n+            default_tags,\n+            tags_override,\n+            hermetic_cuda_data_dir,\n+            exec_properties,\n+            tags + [\"rocm-only\"] if gpu == \"mi200\" else [\"cuda-only\"],\n+            \"_%s\" % (gpu),\n+            **kwargs\n+        )\n+\n def lit_script_with_xla_gpu_cuda_data_dir(\n         name,\n         input_file,\n@@ -163,6 +262,7 @@ def lit_test(\n         timeout = None,\n         hermetic_cuda_data_dir = None,\n         exec_properties = {},\n+        gpu_suffix = \"\",\n         **kwargs):\n     \"\"\"Runs a single test file with LLVM's lit tool.\n \n@@ -191,6 +291,8 @@ def lit_test(\n         `--xla_gpu_cuda_data_dir` flag set to the hermetic CUDA data directory.\n       exec_properties: string_dict. Properties to pass to the test rule, e.g.\n         requirement to run on a GPU.\n+      gpu_suffix: string. A suffix derived from the gpu name that can be added\n+        to make (file) names unique.\n       **kwargs: additional keyword arguments to pass to all generated rules.\n \n     See https://llvm.org/docs/CommandGuide/lit.html for details on lit\n@@ -255,8 +357,8 @@ def lit_test(\n     # copybara:comment_end\n \n     if hermetic_cuda_data_dir:\n-        output_file = \"with_xla_gpu_cuda_data_dir_{}\".format(test_file)\n-        rule_name = \"script_{}\".format(output_file)\n+        output_file = \"with_xla_gpu_cuda_data_dir%s_%s\" % (gpu_suffix, test_file)\n+        rule_name = \"script%s_%s\" % (gpu_suffix, output_file)\n         lit_script_with_xla_gpu_cuda_data_dir(\n             rule_name,\n             test_file,"
        },
        {
            "sha": "095a389ee08e9d1a805606868cd0976b4c830959",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 28,
            "deletions": 35,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/06ea67005be2ee707f545968372042de3c01d3d9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/06ea67005be2ee707f545968372042de3c01d3d9/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=06ea67005be2ee707f545968372042de3c01d3d9",
            "patch": "@@ -8,7 +8,7 @@ load(\n \n # copybara:uncomment load(\"@rules_cc//cc:cc_binary.bzl\", \"cc_binary\")\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n-load(\"//xla:lit.bzl\", \"enforce_glob\", \"lit_test_suite\")\n+load(\"//xla:lit.bzl\", \"enforce_glob\", \"lit_test_suite_for_gpus\")\n load(\n     \"//xla:xla.default.bzl\",\n     \"xla_cc_test\",\n@@ -616,7 +616,7 @@ xla_test(\n     ],\n )\n \n-lit_test_suite(\n+lit_test_suite_for_gpus(\n     name = \"hlo_lit_tests\",\n     srcs = enforce_glob(\n         [\n@@ -639,50 +639,43 @@ lit_test_suite(\n             \"*.hlo\",\n         ],\n     ),\n-    args = if_cuda_is_configured([\n-        \"--param=PTX=PTX\",\n-        \"--param=GPU=a6000\",\n-    ]) + if_rocm_is_configured([\n-        \"--param=PTX=GCN\",\n-        \"--param=GPU=mi200\",\n-    ]),\n     cfg = \"//xla:lit.cfg.py\",\n-    data = [\n-        \"//xla/tools/hlo_opt:gpu_specs/a100_pcie_80.txtpb\",\n-        \"//xla/tools/hlo_opt:gpu_specs/a6000.txtpb\",\n-        \"//xla/tools/hlo_opt:gpu_specs/h100_sxm.txtpb\",\n-        \"//xla/tools/hlo_opt:gpu_specs/mi200.txtpb\",\n-        \"//xla/tools/hlo_opt:gpu_specs/p100.txtpb\",\n-        \"//xla/tools/hlo_opt:gpu_specs/v100.txtpb\",\n-    ],\n     default_tags = tf_gpu_tests_tags(),\n+    disabled_on_gpus = {\n+        \"v100\": [\n+            \"kernel_reuse.hlo\",\n+            \"triton_naming.hlo\",\n+        ],\n+        \"p100\": [\n+            \"kernel_reuse.hlo\",\n+            \"triton_naming.hlo\",\n+        ],\n+        \"mi200\": [\n+            \"element_wise_row_vectorization.hlo\",\n+            \"scatter_bf16.hlo\",\n+            \"single_instruction.hlo\",\n+            \"reduce_unnested.hlo\",\n+            \"reduction_vectorization_sm_all.hlo\",\n+        ],\n+    },\n+    gpus = [\n+        \"a100_pcie_80\",\n+        \"a6000\",\n+        \"b200\",\n+        \"h100_sxm\",\n+        \"mi200\",\n+        \"p100\",\n+        \"v100\",\n+    ],\n     hermetic_cuda_data_dir = \"%S/../../../../../cuda_nvcc\",\n     tags = [\"no-oneapi\"],\n-    tags_override = {\n-        \"element_wise_row_vectorization.hlo\": [\"cuda-only\"],\n-        \"scatter_bf16.hlo\": [\"cuda-only\"],\n-        \"single_instruction.hlo\": [\"cuda-only\"],\n-        \"reduce_unnested.hlo\": [\"cuda-only\"],\n-        \"reduction_vectorization_sm_all.hlo\": [\"cuda-only\"],\n-    },\n     tools = [\n         \"//xla/tools:hlo-opt\",\n         \"@llvm-project//llvm:FileCheck\",\n     ],\n )\n \n # copybara:uncomment_begin(triton-opt tool doesn't build in OSS)\n-# lit_test_suite(\n-#     name = \"mlir_lit_tests\",\n-#     srcs = glob([\"*.mlir\"]),\n-#     cfg = \"//xla:lit.cfg.py\",\n-#     tools = [\n-#         \":xla-opt\",\n-#         \"@llvm-project//llvm:FileCheck\",\n-#         \"@triton//:triton-opt\",\n-#     ],\n-# )\n-#\n # cc_binary(\n #     name = \"xla-opt\",\n #     srcs = [\"xla-opt.cc\"],"
        }
    ],
    "stats": {
        "total": 171,
        "additions": 133,
        "deletions": 38
    }
}