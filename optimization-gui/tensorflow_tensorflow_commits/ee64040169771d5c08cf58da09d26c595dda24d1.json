{
    "author": "pifon2a",
    "message": "[XLA:GPU] Move constant emission logic from IrEmitterContext to IrEmitterUnnested.\n\nThe `emit_constant` method is no longer part of `IrEmitterContext`. The logic for appending global constants to the LLVM module is now a helper function within `ir_emitter_unnested.cc`, and `IrEmitterUnnested` directly adds the resulting `ConstantInfo` to the context's constants list. This simplifies `IrEmitterContext` by removing emission logic.\n\nPiperOrigin-RevId: 836517263",
    "sha": "ee64040169771d5c08cf58da09d26c595dda24d1",
    "files": [
        {
            "sha": "4cab1d826f44d5d74749440384d2ef49abce6fa2",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -457,6 +457,7 @@ cc_library(\n         \":gpu_asm_opts_util\",\n         \":gpu_constants\",\n         \":gpu_conv_runner\",\n+        \":gpu_executable\",\n         \":gpu_norm_runner\",\n         \":hlo_fusion_analysis\",\n         \":ir_emission_utils\",\n@@ -615,6 +616,8 @@ cc_library(\n         \"ir_emitter_nested.h\",\n     ],\n     deps = [\n+        \":gpu_constants\",\n+        \":gpu_executable\",\n         \":hlo_to_ir_bindings\",\n         \":ir_emission_utils\",\n         \":ir_emitter_context\",\n@@ -632,6 +635,8 @@ cc_library(\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/service/llvm_ir:loop_emitter\",\n         \"//xla/service/llvm_ir:tuple_ops\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n@@ -641,6 +646,7 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Core\",\n         \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//llvm:TargetParser\",\n         \"@local_tsl//tsl/platform:errors\",\n         \"@local_tsl//tsl/platform:fingerprint\",\n         \"@local_tsl//tsl/platform:statusor\","
        },
        {
            "sha": "76da729e5a46a1b64d5b7178b382f31f8bc69d70",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter.cc?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -156,8 +156,9 @@ absl::Status IrEmitter::HandleCall(HloInstruction* call) {\n   for (HloInstruction* operand : call->operands()) {\n     operand_addresses.push_back(GetBasePointer(*operand));\n   }\n-  return CallNestedComputation(&b_, *ir_emitter_context_, *call->to_apply(),\n-                               operand_addresses, GetBasePointer(*call));\n+  return CallNestedComputation(&b_, *ir_emitter_context_, module_,\n+                               *call->to_apply(), operand_addresses,\n+                               GetBasePointer(*call));\n }\n \n absl::Status IrEmitter::HandleCustomCall(HloInstruction*) {"
        },
        {
            "sha": "f32c6bf3a4f069e461027c5c1fd8ce636faafb6d",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_context.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 63,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.cc?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -38,69 +38,6 @@ limitations under the License.\n namespace xla {\n namespace gpu {\n \n-void IrEmitterContext::emit_constant(int64_t num_elements,\n-                                     int64_t bytes_per_element,\n-                                     absl::string_view symbol_name,\n-                                     int allocation_idx,\n-                                     DenseDataIntermediate content,\n-                                     llvm::IRBuilderBase* b) {\n-  // LLVM and PTXAS don't deal well with large constants, so we only emit very\n-  // small constants directly in LLVM IR.  Larger constants are emitted with\n-  // zero initializers in LLVM IR and are later overwritten when the PTX/CUBIN\n-  // is loaded.\n-  bool should_emit_initializer = num_elements <= 1;\n-\n-  // Ptxas has issues if the constant allocation is smaller than 64 bytes.\n-  // TODO(b/253259975): Remove when fixed ptxas version is submitted.\n-  constexpr int64_t kMinConstAllocationInBytes = 64;\n-  bool needs_padding =\n-      num_elements * bytes_per_element < kMinConstAllocationInBytes;\n-\n-  llvm::ArrayType* global_type = llvm::ArrayType::get(\n-      b->getInt8Ty(),\n-      std::max(num_elements * bytes_per_element, kMinConstAllocationInBytes));\n-\n-  GpuExecutable::ConstantInfo info;\n-  llvm::Constant* initializer = [&]() -> llvm::Constant* {\n-    if (!should_emit_initializer) {\n-      info.content = std::move(content);\n-      return llvm::ConstantAggregateZero::get(global_type);\n-    }\n-\n-    std::vector<uint8_t> padded(kMinConstAllocationInBytes, 0);\n-    absl::c_copy(content.span(), padded.begin());\n-    return llvm::ConstantDataArray::get<uint8_t>(\n-        llvm_module_constants()->getContext(),\n-        needs_padding ? llvm::ArrayRef<uint8_t>(padded)\n-                      : llvm::ArrayRef<uint8_t>(content.span().data(),\n-                                                content.span().size()));\n-  }();\n-\n-  // Explicitly set global addrspace for SPIR backend.\n-  int addrspace =\n-      llvm::Triple(llvm_module_constants()->getTargetTriple()).isSPIR() ? 1 : 0;\n-  // These globals will be looked up by name by GpuExecutable so we need to\n-  // give them an external linkage.  Not all of their uses are visible in\n-  // the LLVM IR so we can't give then a linkage that merely preserves their\n-  // names (like available_externally), we also need to ensure that they stick\n-  // around even if they're \"unused\".\n-  //\n-  // We may have to be more clever here in the future if we notice that we're\n-  // keeping around too many globals because of their linkage.\n-  llvm::GlobalVariable* global_for_const = new llvm::GlobalVariable(\n-      global_type, /*isConstant=*/should_emit_initializer,\n-      llvm::GlobalValue::ExternalLinkage,\n-      /*Initializer=*/initializer, symbol_name,\n-      /*TLMode=*/llvm::GlobalValue::NotThreadLocal,\n-      /*AddressSpace=*/addrspace,\n-      /*isExternallyInitialized=*/false);\n-  global_for_const->setAlignment(llvm::Align(kConstantBufferAlignBytes));\n-  llvm_module_constants()->insertGlobalVariable(global_for_const);\n-\n-  info.symbol_name.assign(symbol_name);\n-  info.allocation_index = allocation_idx;\n-  constants_.push_back(std::move(info));\n-}\n \n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "9f116a08c2362f53a5c9bd102f6a8aca2a6b49ec",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_context.h",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -123,12 +123,6 @@ class IrEmitterContext {\n \n   std::vector<GpuExecutable::ConstantInfo>& constants() { return constants_; }\n \n-  // Emit a constant with a given number of element, given byte size of the\n-  // element, given symbol name and content.\n-  void emit_constant(int64_t num_elements, int64_t bytes_per_element,\n-                     absl::string_view symbol_name, int allocation_idx,\n-                     DenseDataIntermediate content, llvm::IRBuilderBase* b);\n-\n   const DebugOptions& debug_options() const {\n     return hlo_module_->config().debug_options();\n   }"
        },
        {
            "sha": "656597cd301fc90d2813f6ae9d54fe25fc257c3d",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_nested.cc",
            "status": "modified",
            "additions": 78,
            "deletions": 58,
            "changes": 136,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.cc?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -14,32 +14,41 @@ limitations under the License.\n ==============================================================================*/\n #include \"xla/service/gpu/ir_emitter_nested.h\"\n \n+#include <algorithm>\n #include <cstddef>\n #include <cstdint>\n #include <iterator>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"llvm/ADT/ArrayRef.h\"\n #include \"llvm/IR/Argument.h\"\n #include \"llvm/IR/BasicBlock.h\"\n+#include \"llvm/IR/Constants.h\"\n #include \"llvm/IR/DerivedTypes.h\"\n #include \"llvm/IR/Function.h\"\n #include \"llvm/IR/GlobalValue.h\"\n+#include \"llvm/IR/GlobalVariable.h\"\n #include \"llvm/IR/IRBuilder.h\"\n #include \"llvm/IR/Instructions.h\"\n #include \"llvm/IR/LLVMContext.h\"\n #include \"llvm/Support/Casting.h\"\n+#include \"llvm/TargetParser/Triple.h\"\n #include \"xla/codegen/emitters/computation_fingerprint.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/literal.h\"\n+#include \"xla/service/gpu/gpu_constants.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/ir_emitter.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n@@ -51,6 +60,8 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"tsl/platform/errors.h\"\n #include \"tsl/platform/fingerprint.h\"\n@@ -117,8 +128,7 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n   std::string function_name = llvm_ir::SanitizeFunctionName(absl::StrCat(\n       nested_computation_.name(), \"_\", fingerprint.low64, fingerprint.high64));\n \n-  auto* function =\n-      ir_emitter_context_->llvm_module()->getFunction(function_name);\n+  auto* function = module_->getFunction(function_name);\n   if (function) return function;\n \n   TF_RETURN_IF_ERROR(EmitConstants(nested_computation_));\n@@ -143,8 +153,8 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n   {\n     const Shape& root_shape = root->shape();\n     argument_types.push_back(b_.getPtrTy());\n-    int64_t root_size = llvm_ir::ByteSizeOf(\n-        root_shape, ir_emitter_context_->llvm_module()->getDataLayout());\n+    int64_t root_size =\n+        llvm_ir::ByteSizeOf(root_shape, module_->getDataLayout());\n     argument_dereferenceable_bytes.push_back(root_size);\n   }\n \n@@ -154,7 +164,7 @@ absl::StatusOr<llvm::Function*> IrEmitterNested::CodegenNestedComputation() {\n       function_type,                       // The function type.\n       llvm::GlobalValue::InternalLinkage,  // The linkage type.\n       function_name,\n-      ir_emitter_context_->llvm_module());  // The parent LLVM module.\n+      module_);  // The parent LLVM module.\n   for (size_t arg_no = 0; arg_no < argument_dereferenceable_bytes.size();\n        ++arg_no) {\n     int64_t arg_size = argument_dereferenceable_bytes[arg_no];\n@@ -270,15 +280,14 @@ absl::Status IrEmitterNested::EmitConstants(const HloComputation& computation) {\n     std::string global_name = llvm_ir::ConstantHloToGlobalName(*instr);\n \n     auto base = static_cast<const uint8_t*>(literal.untyped_data());\n-    ir_emitter_context_->emit_constant(\n-        literal.element_count(),\n+    GpuExecutable::ConstantInfo info = AppendGlobalConstant(\n+        module_, literal.element_count(),\n         ShapeUtil::ByteSizeOfPrimitiveType(literal.shape().element_type()),\n-\n-        global_name,\n-        /*allocation_idx=*/-1,\n+        global_name, /*allocation_idx=*/-1,\n         DenseDataIntermediate::Alias(\n             absl::MakeSpan(base, base + literal.size_bytes())),\n         &b_);\n+    ir_emitter_context_->constants().push_back(std::move(info));\n   }\n   return absl::OkStatus();\n }\n@@ -303,6 +312,7 @@ llvm::Value* AddrCastToDefault(llvm::Value* arg, llvm::IRBuilderBase& b) {\n \n absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n                                    IrEmitterContext& ir_emitter_context,\n+                                   llvm::Module* llvm_module,\n                                    const HloComputation& computation,\n                                    absl::Span<llvm::Value* const> operands,\n                                    llvm::Value* output) {\n@@ -328,55 +338,65 @@ absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n   return absl::OkStatus();\n }\n \n-absl::StatusOr<std::vector<llvm::Value*>> CallNestedComputationWithScalars(\n-    llvm::IRBuilderBase* builder, IrEmitterContext& ir_emitter_context,\n-    const HloComputation& computation,\n-    absl::Span<llvm::Value* const> parameter_elements) {\n-  std::vector<llvm::Value*> parameter_buffers;\n-  for (llvm::Value* parameter_element : parameter_elements) {\n-    parameter_buffers.push_back(llvm_ir::EmitAllocaAtFunctionEntry(\n-        parameter_element->getType(), \"parameter_buffer\", builder));\n-    builder->CreateStore(parameter_element, parameter_buffers.back());\n-  }\n-\n-  return CallNestedComputationWithScalarAddrs(builder, ir_emitter_context,\n-                                              computation, parameter_buffers);\n-}\n-\n-absl::StatusOr<std::vector<llvm::Value*>> CallNestedComputationWithScalarAddrs(\n-    llvm::IRBuilderBase* builder, IrEmitterContext& ir_emitter_context,\n-    const HloComputation& computation,\n-    absl::Span<llvm::Value* const> parameter_elements_addrs) {\n-  const Shape& return_shape = computation.root_instruction()->shape();\n-  llvm::Type* return_buffer_type =\n-      llvm_ir::ShapeToIrType(return_shape, builder->getContext());\n-  llvm::Value* return_buffer = llvm_ir::EmitAllocaAtFunctionEntry(\n-      return_buffer_type, \"return_buffer\", builder);\n-\n-  std::vector<llvm::Value*> allocas_for_returned_scalars;\n-  if (!return_shape.IsTuple()) {\n-    allocas_for_returned_scalars.push_back(return_buffer);\n-  } else {\n-    allocas_for_returned_scalars =\n-        llvm_ir::EmitTupleAllocasAtFunctionEntry(return_shape, builder);\n-    llvm_ir::IrArray tuple_array(return_buffer, return_buffer_type,\n-                                 return_shape);\n-\n-    llvm_ir::EmitTuple(tuple_array, allocas_for_returned_scalars, builder);\n-  }\n-\n-  TF_RETURN_IF_ERROR(\n-      CallNestedComputation(builder, ir_emitter_context, computation,\n-                            parameter_elements_addrs, return_buffer));\n+GpuExecutable::ConstantInfo AppendGlobalConstant(\n+    llvm::Module* module, int64_t num_elements, int64_t bytes_per_element,\n+    absl::string_view symbol_name, int allocation_idx,\n+    DenseDataIntermediate content, llvm::IRBuilderBase* b) {\n+  // LLVM and PTXAS don't deal well with large constants, so we only emit very\n+  // small constants directly in LLVM IR.  Larger constants are emitted with\n+  // zero initializers in LLVM IR and are later overwritten when the PTX/CUBIN\n+  // is loaded.\n+  bool should_emit_initializer = num_elements <= 1;\n+\n+  // Ptxas has issues if the constant allocation is smaller than 64 bytes.\n+  // TODO(b/253259975): Remove when fixed ptxas version is submitted.\n+  constexpr int64_t kMinConstAllocationInBytes = 64;\n+  bool needs_padding =\n+      num_elements * bytes_per_element < kMinConstAllocationInBytes;\n+\n+  llvm::ArrayType* global_type = llvm::ArrayType::get(\n+      b->getInt8Ty(),\n+      std::max(num_elements * bytes_per_element, kMinConstAllocationInBytes));\n+\n+  GpuExecutable::ConstantInfo info;\n+  llvm::Constant* initializer = [&]() -> llvm::Constant* {\n+    if (!should_emit_initializer) {\n+      info.content = std::move(content);\n+      return llvm::ConstantAggregateZero::get(global_type);\n+    }\n \n-  std::vector<llvm::Value*> returned_scalars;\n-  returned_scalars.reserve(allocas_for_returned_scalars.size());\n-  for (llvm::Value* addr : allocas_for_returned_scalars) {\n-    auto alloca = llvm::cast<llvm::AllocaInst>(addr);\n-    returned_scalars.push_back(\n-        builder->CreateLoad(alloca->getAllocatedType(), alloca));\n-  }\n-  return returned_scalars;\n+    std::vector<uint8_t> padded(kMinConstAllocationInBytes, 0);\n+    absl::c_copy(content.span(), padded.begin());\n+    return llvm::ConstantDataArray::get<uint8_t>(\n+        module->getContext(),\n+        needs_padding ? llvm::ArrayRef<uint8_t>(padded)\n+                      : llvm::ArrayRef<uint8_t>(content.span().data(),\n+                                                content.span().size()));\n+  }();\n+\n+  // Explicitly set global addrspace for SPIR backend.\n+  int addrspace = llvm::Triple(module->getTargetTriple()).isSPIR() ? 1 : 0;\n+  // These globals will be looked up by name by GpuExecutable so we need to\n+  // give them an external linkage.  Not all of their uses are visible in\n+  // the LLVM IR so we can't give then a linkage that merely preserves their\n+  // names (like available_externally), we also need to ensure that they stick\n+  // around even if they're \"unused\".\n+  //\n+  // We may have to be more clever here in the future if we notice that we're\n+  // keeping around too many globals because of their linkage.\n+  auto* global_for_const = new llvm::GlobalVariable(\n+      global_type, /*isConstant=*/should_emit_initializer,\n+      llvm::GlobalValue::ExternalLinkage,\n+      /*Initializer=*/initializer, symbol_name,\n+      /*TLMode=*/llvm::GlobalValue::NotThreadLocal,\n+      /*AddressSpace=*/addrspace,\n+      /*isExternallyInitialized=*/false);\n+  global_for_const->setAlignment(llvm::Align(kConstantBufferAlignBytes));\n+  module->insertGlobalVariable(global_for_const);\n+\n+  info.symbol_name.assign(symbol_name);\n+  info.allocation_index = allocation_idx;\n+  return info;\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "0547a2f7bb0ef1adbc68f323ce9e0697a79f7750",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_nested.h",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_nested.h?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -16,14 +16,18 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_IR_EMITTER_NESTED_H_\n #define XLA_SERVICE_GPU_IR_EMITTER_NESTED_H_\n \n+#include <cstdint>\n #include <vector>\n \n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/IR/IRBuilder.h\"\n #include \"llvm/IR/Value.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n+#include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/ir_emitter_context.h\"\n \n namespace xla {\n@@ -45,21 +49,17 @@ namespace gpu {\n //   - a pointer to the top-level temp buffer.\n absl::Status CallNestedComputation(llvm::IRBuilderBase* builder,\n                                    IrEmitterContext& ir_emitter_context,\n+                                   llvm::Module* llvm_module,\n                                    const HloComputation& computation,\n                                    absl::Span<llvm::Value* const> operands,\n                                    llvm::Value* output);\n \n-// Like CallNestedComputation, but parameters and results are scalars.\n-absl::StatusOr<std::vector<llvm::Value*>> CallNestedComputationWithScalars(\n-    llvm::IRBuilderBase* builder, IrEmitterContext& ir_emitter_context,\n-    const HloComputation& computation,\n-    absl::Span<llvm::Value* const> parameter_elements);\n-\n-// Like CallNestedComputationWithScalars, but parameters are scalar addresses.\n-absl::StatusOr<std::vector<llvm::Value*>> CallNestedComputationWithScalarAddrs(\n-    llvm::IRBuilderBase* builder, IrEmitterContext& ir_emitter_context,\n-    const HloComputation& computation,\n-    absl::Span<llvm::Value* const> parameter_elements_addrs);\n+// Emit a constant with a given number of element, given byte size of the\n+// element, given symbol name and content.\n+GpuExecutable::ConstantInfo AppendGlobalConstant(\n+    llvm::Module* module, int64_t num_elements, int64_t bytes_per_element,\n+    absl::string_view symbol_name, int allocation_idx,\n+    DenseDataIntermediate content, llvm::IRBuilderBase* b);\n \n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "02f8cdd0277ab209d7af9846e460c4968350e3a1",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ee64040169771d5c08cf58da09d26c595dda24d1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=ee64040169771d5c08cf58da09d26c595dda24d1",
            "patch": "@@ -148,6 +148,7 @@ limitations under the License.\n #include \"xla/service/gpu/execution_stream_assignment.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/gpu_conv_runner.h\"\n+#include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/gpu_norm_runner.h\"\n #include \"xla/service/gpu/hlo_fusion_analysis.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n@@ -273,8 +274,10 @@ absl::Status IrEmitterUnnested::EmitConstant(\n   TF_ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n                       GetAllocationSliceForHlo(instr, {}));\n \n-  ir_emitter_context_->emit_constant(num_elements, element_bytes, global_name,\n-                                     slice.index(), std::move(content), &b_);\n+  GpuExecutable::ConstantInfo info = AppendGlobalConstant(\n+      ir_emitter_context_->llvm_module_constants(), num_elements, element_bytes,\n+      global_name, slice.index(), std::move(content), &b_);\n+  ir_emitter_context_->constants().push_back(std::move(info));\n   return absl::OkStatus();\n }\n \n@@ -1870,8 +1873,9 @@ absl::Status IrEmitterUnnested::EmitSort(const HloSortInstruction* sort) {\n                              : standard_num_iterations_in_sort_dim,\n         tile_size, kUnrollFactor,\n         [&](absl::Span<llvm::Value* const> operands, llvm::Value* output) {\n-          return CallNestedComputation(&b_, *ir_emitter_context_, *comparator,\n-                                       operands, output);\n+          return CallNestedComputation(&b_, *ir_emitter_context_,\n+                                       ir_emitter_context_->llvm_module(),\n+                                       *comparator, operands, output);\n         });\n   };\n   std::vector<int64_t> xor_masks;"
        }
    ],
    "stats": {
        "total": 250,
        "additions": 106,
        "deletions": 144
    }
}