{
    "author": "vwbaker",
    "message": "Add xla_gpu_experimental_enable_fusion_autotuner to XLA flag list\n\nPiperOrigin-RevId: 830848317",
    "sha": "17fa5c0e5e036ecf62b4758fdc355170228a93f9",
    "files": [
        {
            "sha": "60b40300ec906d511c4dea79c0fbb823149120e7",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17fa5c0e5e036ecf62b4758fdc355170228a93f9/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17fa5c0e5e036ecf62b4758fdc355170228a93f9/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=17fa5c0e5e036ecf62b4758fdc355170228a93f9",
            "patch": "@@ -455,6 +455,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_gpu_unsupported_use_ragged_all_to_all_one_shot_kernel(true);\n   opts.set_xla_gpu_unsupported_enable_all_reduce_decomposer(false);\n   opts.set_xla_gpu_experimental_use_autotuner_pass(false);\n+  opts.set_xla_gpu_experimental_enable_fusion_autotuner(false);\n   opts.set_xla_gpu_experimental_pack_dot_operands_along_k_dimension(true);\n   opts.set_xla_unsupported_crash_on_hlo_pass_fix_max_iterations(false);\n   opts.set_xla_hlo_pass_fix_detect_cycles(false);\n@@ -2693,6 +2694,12 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       \"Limits the thunk buffer debug instrumentation to thunks with profile \"\n       \"annotations matching one or more regexes passed as comma-separated \"\n       \"string.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_gpu_experimental_enable_fusion_autotuner\",\n+      bool_setter_for(\n+          &DebugOptions::set_xla_gpu_experimental_enable_fusion_autotuner),\n+      debug_options->xla_gpu_experimental_enable_fusion_autotuner(),\n+      \"Enable autotuning between the native & triton fusion emitters.\"));\n \n   auto setter_for_xla_gpu_detect_nan =\n       [debug_options](const std::string& value) {"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 7,
        "deletions": 0
    }
}