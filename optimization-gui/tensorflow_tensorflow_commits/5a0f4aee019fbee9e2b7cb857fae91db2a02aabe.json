{
    "author": "hsharsha",
    "message": "PR #35510: [ROCm] Initialze collectives to nullptr to force its allocation later\n\nImported from GitHub PR https://github.com/openxla/xla/pull/35510\n\nüìù Summary of Changes\nInitialize collectives pointer to nullptr\n\nüéØ Justification\n\nGpu runtime options are initialized in TF and transferred to XLA to execute thunks. Since the memory is not cleared collectives point to an uninitialized memory resulting in segfault during nccl collective initialization and operation.\n\nüöÄ Kind of Contribution\nPlease remove what does not apply: üêõ Bug Fix,\n\nCopybara import of the project:\n\n--\n2bfc6fbddbf2f9a926dd504169c56be45d2f1a0a by Harsha HS <Harsha.HavanurShamsundara@amd.com>:\n\n[ROCm] Initialze collectives to nullptr to force its allocation later\n\nMerging this change closes #35510\n\nPiperOrigin-RevId: 846266642",
    "sha": "5a0f4aee019fbee9e2b7cb857fae91db2a02aabe",
    "files": [
        {
            "sha": "b7fa471dd0551978890d843400033708e39fadd8",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable_run_options.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a0f4aee019fbee9e2b7cb857fae91db2a02aabe/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a0f4aee019fbee9e2b7cb857fae91db2a02aabe/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable_run_options.h?ref=5a0f4aee019fbee9e2b7cb857fae91db2a02aabe",
            "patch": "@@ -92,7 +92,7 @@ class GpuExecutableRunOptions {\n   bool enable_mock_collectives_ = false;\n   std::optional<DeviceIdMap> gpu_global_device_ids_;\n   CliqueIdCallback clique_id_callback_;\n-  GpuCollectives* collectives_;\n+  GpuCollectives* collectives_ = nullptr;\n   std::optional<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>\n       incarnations_;\n };"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}