{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 842584191",
    "sha": "c2dc0eef19e82b78d1894fc28a5296517bacb080",
    "files": [
        {
            "sha": "eb0a0060f8125eb01e970013f234a573b237bda7",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -40,6 +40,7 @@ xla_cc_test(\n     srcs = [\"gpu_codegen_backend_test.cc\"],\n     deps = [\n         \":gpu_codegen_backend\",\n+        \"//xla:xla_proto_cc\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n@@ -284,6 +285,7 @@ cc_library(\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n         \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/ir:hlo\",\n@@ -569,6 +571,7 @@ xla_test(\n     ],\n     deps = [\n         \":native_emitter\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n@@ -603,6 +606,7 @@ cc_library(\n         \":factory\",\n         \":fission_backend\",\n         \":triton\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/pass:hlo_pass_pipeline\",\n         \"//xla/service:compiler\",\n@@ -627,6 +631,7 @@ cc_library(\n         \":cublas\",\n         \":factory\",\n         \":triton\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/analysis:symbolic_expr\",\n         \"//xla/service:compiler\",\n@@ -659,6 +664,7 @@ xla_test(\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n+        \"//xla:xla_data_proto_cc\",\n         \"//xla/backends/autotuner:profiler\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n@@ -691,6 +697,7 @@ cc_library(\n     srcs = [\"legacy_cache.cc\"],\n     hdrs = [\"legacy_cache.h\"],\n     deps = [\n+        \"//xla:autotune_results_proto_cc\",\n         \"//xla:autotuning_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:autotuner_cache_interface\",\n@@ -715,6 +722,7 @@ cc_library(\n     hdrs = [\"fission_backend.h\"],\n     deps = [\n         \":gpu_codegen_backend\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass_pipeline\",\n@@ -744,6 +752,7 @@ xla_test(\n         \":custom_kernel\",\n         \":fission_backend\",\n         \":gpu_codegen_backend\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass_pipeline\",\n@@ -774,6 +783,7 @@ cc_library(\n         \"//xla:autotuning_proto_cc\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n+        \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n         \"//xla/hlo/ir:hlo\",\n@@ -794,7 +804,9 @@ xla_cc_test(\n     srcs = [\"legacy_cache_test.cc\"],\n     deps = [\n         \":legacy_cache\",\n+        \"//xla:autotuning_proto_cc\",\n         \"//xla:literal_util\",\n+        \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:autotuner_cache_interface\",\n         \"//xla/backends/autotuner:autotuner_cache_proto_cc\",\n         \"//xla/hlo/ir:hlo\","
        },
        {
            "sha": "f2d79b13a1741377fda307cd9b2fc6e169205c75",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/cudnn.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fcudnn.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -53,6 +53,7 @@ limitations under the License.\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "d9e9130f8f96e398f1d24a2034c67c55896fc01b",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/factory_cuda.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_cuda.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/platform/platform_object_registry.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "e327f6abdde0e0ced179e8528c0fbd44b7dcec44",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/factory_rocm.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_rocm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_rocm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffactory_rocm.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"xla/stream_executor/platform/platform_object_registry.h\"\n #include \"xla/stream_executor/rocm/rocm_platform_id.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "edc5c814af89b24c6bce6a2a18917f2e5eaf39b3",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission_backend.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend.h?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -30,6 +30,7 @@ limitations under the License.\n #include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n #include \"xla/service/compiler.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla::gpu {\n "
        },
        {
            "sha": "a9b0ecaaca050b67439bcb767c6384eea9a01ba1",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/fission_backend_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ffission_backend_test.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -44,6 +44,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "9e9ddf541aa602eeac9975af760f8a0bc43e24ea",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_codegen_backend_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend_test.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/backends/gpu/autotuner/gpu_codegen_backend.h\"\n \n #include <gtest/gtest.h>\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "5c3025ba233048d482d3fcc965b5ba79f2b85d50",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -50,6 +50,7 @@ limitations under the License.\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "18323dc1ceef2b43ea24789ebdb24bf55b489277",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/legacy_cache.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -24,6 +24,8 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/autotune_results.pb.h\"\n+#include \"xla/autotuning.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/gpu/autotuning/autotune_cache_key.h\""
        },
        {
            "sha": "13c0e93baa1313e449272b2ad769e66252c0bcfd",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/legacy_cache_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Flegacy_cache_test.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n+#include \"xla/autotuning.pb.h\"\n #include \"xla/backends/autotuner/autotuner_cache.pb.h\"\n #include \"xla/backends/autotuner/autotuner_cache_interface.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -37,6 +38,7 @@ limitations under the License.\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "636be11815a4d0ba51b4a96b676bbbed6137be26",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/miopen.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fmiopen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fmiopen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fmiopen.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/dnn.pb.h\"\n #include \"xla/xla.pb.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla {\n namespace gpu {"
        },
        {
            "sha": "bedf1bb18be8701258b76a963c5e8c817eef48fb",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/native_emitter_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c2dc0eef19e82b78d1894fc28a5296517bacb080/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fnative_emitter_test.cc?ref=c2dc0eef19e82b78d1894fc28a5296517bacb080",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla.pb.h\"\n \n namespace xla {\n namespace gpu {"
        }
    ],
    "stats": {
        "total": 25,
        "additions": 25,
        "deletions": 0
    }
}