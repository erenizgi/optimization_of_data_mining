{
    "author": "nvgrw",
    "message": "Migrate exhaustive tests\n\nPiperOrigin-RevId: 806370361",
    "sha": "4c206fe648ac6bb3db42df29ea511922c20206e8",
    "files": [
        {
            "sha": "fdc4adaddda3cedff53a4848f08454efa72e1a1a",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -4509,6 +4509,7 @@ cc_library(\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tsl/platform:env\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\","
        },
        {
            "sha": "34d68b860adc55a46d4dd4fc4abf36d74dfda53f",
            "filename": "third_party/xla/xla/service/hlo_runner.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner.cc?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -51,6 +51,7 @@ limitations under the License.\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n@@ -823,6 +824,12 @@ bool HloRunner::HasProperty(const HloRunnerPropertyTag::Type tag) const {\n   if (tag == HloRunnerPropertyTag::kCpu) {\n     return backend().platform()->Name() == \"Host\";\n   }\n+  if (tag == HloRunnerPropertyTag::kUsingGpuCuda) {\n+    const stream_executor::DeviceDescription& device_description =\n+        backend().default_stream_executor()->GetDeviceDescription();\n+    return std::holds_alternative<stream_executor::CudaComputeCapability>(\n+        device_description.gpu_compute_capability());\n+  }\n   return false;\n }\n "
        },
        {
            "sha": "b1891389f6448ab889a074602d4e075921ca33b1",
            "filename": "third_party/xla/xla/service/hlo_runner_interface.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_interface.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_interface.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_interface.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -78,6 +78,8 @@ class HloRunnerPropertyTag final {\n   static constexpr Type kUsingGpuRocm = 1;\n   // Indicates that this runner is a CPU runner.\n   static constexpr Type kCpu = 2;\n+  // Indicates that the runner is using CUDA.\n+  static constexpr Type kUsingGpuCuda = 3;\n \n  private:\n   HloRunnerPropertyTag() = default;"
        },
        {
            "sha": "046159bdebacdfb9271f7577c7bc446345548ca3",
            "filename": "third_party/xla/xla/service/hlo_runner_pjrt.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_runner_pjrt.cc?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -825,10 +825,13 @@ absl::string_view HloRunnerPjRt::Name() const { return \"HloRunnerPjRt\"; }\n \n bool HloRunnerPjRt::HasProperty(const HloRunnerPropertyTag::Type tag) const {\n   if (tag == HloRunnerPropertyTag::kUsingGpuRocm) {\n-    return pjrt_client_->platform_name() == xla::RocmName();\n+    return pjrt_client_->platform_name() == RocmName();\n   }\n   if (tag == HloRunnerPropertyTag::kCpu) {\n-    return pjrt_client_->platform_name() == xla::CpuName();\n+    return pjrt_client_->platform_name() == CpuName();\n+  }\n+  if (tag == HloRunnerPropertyTag::kUsingGpuCuda) {\n+    return pjrt_client_->platform_name() == CudaName();\n   }\n   return false;\n }"
        },
        {
            "sha": "5df049160256722b29447375b608d48b24db2155",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -3756,7 +3756,11 @@ cc_library(\n         )[0],\n     ]),\n     visibility = if_google(\n-        xla_internal([\"tests:__pkg__\"]),\n+        xla_internal([\n+            \"tests:__pkg__\",\n+        ]) + [\n+            \"//xla/tests/exhaustive:__pkg__\",\n+        ],\n         [\"//visibility:public\"],\n     ),\n     deps = ["
        },
        {
            "sha": "16eea631f7c081ac990c7e0c83c33b0f03dcc49f",
            "filename": "third_party/xla/xla/tests/exhaustive/BUILD",
            "status": "modified",
            "additions": 12,
            "deletions": 9,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2FBUILD?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -49,7 +49,6 @@ cc_library(\n     visibility = [\"//visibility:private\"],\n     deps = [\n         \"//xla:bit_cast\",\n-        \"//xla:executable_run_options\",\n         \"//xla:fp_util\",\n         \"//xla:literal\",\n         \"//xla:literal_util\",\n@@ -59,12 +58,16 @@ cc_library(\n         \"//xla/client:executable_build_options\",\n         \"//xla/hlo/builder:xla_builder\",\n         \"//xla/hlo/builder:xla_computation\",\n-        \"//xla/service:shaped_buffer\",\n-        \"//xla/stream_executor:device_description\",\n-        \"//xla/stream_executor:platform\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/tests:client_library_test_base\",\n+        \"//xla/service:hlo_module_config\",\n+        \"//xla/service:hlo_runner_interface\",\n+        \"//xla/tests:client_library_test_runner_mixin\",\n+        \"//xla/tests:hlo_pjrt_interpreter_reference_mixin\",\n+        \"//xla/tests:hlo_pjrt_test_base\",\n+        \"//xla/tests:xla_test_backend_predicates\",\n         \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n         \"//xla/tsl/util:command_line_flags\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n@@ -74,10 +77,7 @@ cc_library(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:env\",\n         \"@local_tsl//tsl/platform:path\",\n-        \"@local_tsl//tsl/platform:statusor\",\n-        \"@local_tsl//tsl/platform:test\",\n     ],\n )\n \n@@ -144,6 +144,7 @@ exhaustive_xla_test(\n         \"optonly\",\n         # This is a big test that we skip for capacity reasons in OSS testing.\n         \"no_oss\",\n+        \"test_migrated_to_hlo_runner_pjrt\",\n     ],\n     deps = [\n         \":exhaustive_op_test_utils\",\n@@ -186,6 +187,7 @@ xla_test(\n         \"optonly\",\n         # This is a big test that we skip for capacity reasons in OSS testing.\n         \"no_oss\",\n+        \"test_migrated_to_hlo_runner_pjrt\",\n     ],\n     deps = [\n         \":exhaustive_op_test_utils\",\n@@ -251,6 +253,7 @@ exhaustive_xla_test(\n         \"optonly\",\n         # This is a big test that we skip for capacity reasons in OSS testing.\n         \"no_oss\",\n+        \"test_migrated_to_hlo_runner_pjrt\",\n     ],\n     deps = [\n         \":exhaustive_binary_test_textual_hdrs\","
        },
        {
            "sha": "6c3c04b5fc60290e72e313b4d276f73adfc2b58a",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_op_test.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -40,7 +40,7 @@ class ExhaustiveOpTest : public ExhaustiveOpTestBase<T, N> {\n  public:\n   using Traits = ExhaustiveOpTestBase<T, 1>::Traits;\n \n-  ExhaustiveOpTest() : platform_(*this->client_->platform()) {}\n+  ExhaustiveOpTest() : platform_(this->test_runner()) {}\n \n   bool RelaxedDenormalSigns() const override {\n     return !platform_.IsNvidiaGpu();"
        },
        {
            "sha": "25568e62a0887e87fa15ae44c559c7d20aa82516",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_op_test_base.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 43,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.cc?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -21,15 +21,13 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <iomanip>\n-#include <iterator>\n #include <limits>\n #include <memory>\n #include <string>\n #include <type_traits>\n #include <utility>\n #include <vector>\n \n-#include \"absl/algorithm/container.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/meta/type_traits.h\"\n@@ -40,24 +38,22 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/bit_cast.h\"\n #include \"xla/client/executable_build_options.h\"\n-#include \"xla/executable_run_options.h\"\n #include \"xla/fp_util.h\"\n #include \"xla/hlo/builder/xla_builder.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n-#include \"xla/service/shaped_buffer.h\"\n-#include \"xla/shape.h\"\n+#include \"xla/service/hlo_module_config.h\"\n #include \"xla/tests/exhaustive/error_spec.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/file_system.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/command_line_flags.h\"\n #include \"xla/types.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/env.h\"\n-#include \"tsl/platform/file_system.h\"\n #include \"tsl/platform/path.h\"\n-#include \"tsl/platform/statusor.h\"\n-#include \"tsl/platform/test.h\"\n \n namespace xla {\n namespace exhaustive_op_test {\n@@ -483,40 +479,17 @@ absl::StatusOr<Literal> ExhaustiveOpTestBase<T, N>::RunComputation(\n     absl::Span<const Literal* const> input_literals) {\n   // Copy debug options from ClientLibraryTestBase.  In particular, we're\n   // interested in disabling constant folding.\n-  ExecutableBuildOptions build_opts;\n-  *build_opts.mutable_debug_options() = *mutable_debug_options();\n-\n-  std::vector<ScopedShapedBuffer> input_buffers;\n-  absl::c_transform(input_literals, std::back_inserter(input_buffers),\n-                    [&](const Literal* input_literal) {\n-                      return client_\n-                          ->LiteralToShapedBuffer(*input_literal,\n-                                                  /*device_ordinal=*/0)\n-                          .value();\n-                    });\n-  std::vector<const Shape*> input_shapes;\n-  absl::c_transform(input_buffers, std::back_inserter(input_shapes),\n-                    [&](const ScopedShapedBuffer& buffer) {\n-                      return &buffer.on_device_shape();\n-                    });\n-\n-  TF_ASSIGN_OR_RETURN(auto executables,\n-                      client_->Compile(computation, input_shapes, build_opts));\n-\n-  std::vector<const ShapedBuffer*> input_buffer_pointers;\n-  absl::c_transform(input_buffers, std::back_inserter(input_buffer_pointers),\n-                    [&](const ScopedShapedBuffer& buffer) { return &buffer; });\n-\n-  ExecutableRunOptions run_opts;\n-  run_opts.set_allocator(client_->backend().memory_allocator());\n-  run_opts.set_intra_op_thread_pool(\n-      client_->backend().eigen_intra_op_thread_pool_device());\n-  TF_ASSIGN_OR_RETURN(ScopedShapedBuffer result,\n-                      executables[0]->Run(input_buffer_pointers, run_opts));\n-\n-  TF_ASSIGN_OR_RETURN(Literal result_literal,\n-                      client_->ShapedBufferToLiteral(result));\n-  return std::move(result_literal);\n+  ExecutionOptions execution_options;\n+  *execution_options.mutable_debug_options() = *mutable_debug_options();\n+  TF_ASSIGN_OR_RETURN(\n+      HloModuleConfig config,\n+      HloModule::CreateModuleConfigFromProto(computation.proto(),\n+                                             execution_options.debug_options(),\n+                                             &execution_options));\n+  TF_ASSIGN_OR_RETURN(\n+      std::unique_ptr<HloModule> module,\n+      HloModule::CreateFromProto(computation.proto(), std::move(config)));\n+  return Execute(std::move(module), input_literals);\n }\n \n template <PrimitiveType T, size_t N>"
        },
        {
            "sha": "5a2a451b1f3d91272d5fe50eb5915b3711e085c3",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_op_test_base.h",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_op_test_base.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -25,14 +25,17 @@ limitations under the License.\n \n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/bit_cast.h\"\n-#include \"xla/executable_run_options.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n #include \"xla/literal.h\"\n-#include \"xla/tests/client_library_test_base.h\"\n+#include \"xla/tests/client_library_test_runner_mixin.h\"\n #include \"xla/tests/exhaustive/error_spec.h\"\n #include \"xla/tests/exhaustive/exhaustive_op_test_utils.h\"\n+#include \"xla/tests/hlo_pjrt_interpreter_reference_mixin.h\"\n+#include \"xla/tests/hlo_pjrt_test_base.h\"\n+#include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/command_line_flags.h\"\n #include \"xla/xla_data.pb.h\"\n \n@@ -60,7 +63,9 @@ void AddExhaustiveFlags(std::vector<tsl::Flag>& flag_list);\n // - FillInput\n // - RelaxedDenormalSigns\n template <PrimitiveType T, size_t N>\n-class ExhaustiveOpTestBase : public ClientLibraryTestBase {\n+class ExhaustiveOpTestBase\n+    : public ClientLibraryTestRunnerMixin<\n+          HloPjRtInterpreterReferenceMixin<HloPjRtTestBase>> {\n  public:\n   using Traits = ExhaustiveOpTestTraits<T, N>;\n   static constexpr PrimitiveType kT = Traits::kT;\n@@ -224,6 +229,12 @@ class ExhaustiveOpTestBase : public ClientLibraryTestBase {\n                   OutputRangeCheck check_valid_range = nullptr);\n \n  protected:\n+  absl::string_view SuiteName() const {\n+    return ::testing::UnitTest::GetInstance()\n+        ->current_test_info()\n+        ->test_suite_name();\n+  }\n+\n   // Indicates if files of the expected and actual values should be dumped.\n   bool should_dump_values_ = false;\n "
        },
        {
            "sha": "7c1f840cebde400ed976a69a21bcdb30bdee5fb8",
            "filename": "third_party/xla/xla/tests/exhaustive/platform.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 67,
            "changes": 81,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.cc?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -15,90 +15,37 @@ limitations under the License.\n \n #include \"xla/tests/exhaustive/platform.h\"\n \n-#include <memory>\n-#include <utility>\n-#include <variant>\n-\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/platform.h\"\n+#include \"xla/service/hlo_runner_interface.h\"\n \n namespace xla {\n namespace exhaustive_op_test {\n+namespace {\n \n-Platform::Value GetPlatformValue(const stream_executor::Platform& platform) {\n-  if (platform.Name() == \"Host\") {\n+Platform::Value GetPlatformValue(const HloRunnerInterface& runner) {\n+  if (runner.HasProperty(HloRunnerPropertyTag::kCpu)) {\n // We process these copts in a library instead of the final exhaustive_xla_test\n // target because we assume the final target will use the same target CPU arch\n // as this target.\n #ifdef __x86_64__\n-    return Platform::CpuValue::X86_64;\n+    return Platform::Value::kX86_64;\n #endif\n #ifdef __aarch64__\n-    return Platform::CpuValue::AARCH64;\n+    return Platform::Value::kAarch64;\n #endif\n-  } else if (platform.Name() == \"CUDA\") {\n-    auto device_descriptor_status = platform.DescriptionForDevice(0);\n-    CHECK_OK(device_descriptor_status);\n-    std::unique_ptr<stream_executor::DeviceDescription> device_descriptor =\n-        std::move(*device_descriptor_status);\n-\n-    auto cuda_compute_compatibility =\n-        device_descriptor->cuda_compute_capability();\n-    // If not available, CudaComputeCompatibility will have major version 0.\n-    if (cuda_compute_compatibility.IsAtLeast(1, 0)) {\n-      return cuda_compute_compatibility;\n-    }\n-  } else if (platform.Name() == \"ROCM\") {\n-    auto device_descriptor_status = platform.DescriptionForDevice(0);\n-    CHECK_OK(device_descriptor_status);\n-    std::unique_ptr<stream_executor::DeviceDescription> device_descriptor =\n-        std::move(*device_descriptor_status);\n-\n-    auto rocm_compute_compatibility =\n-        device_descriptor->rocm_compute_capability();\n-    // If not available, RocmComputeCompatibility will be an invalid platform\n-    // value.\n-    if (rocm_compute_compatibility.gfx_version() == \"gfx000\") {\n-      return rocm_compute_compatibility;\n-    }\n+  } else if (runner.HasProperty(HloRunnerPropertyTag::kUsingGpuCuda)) {\n+    return Platform::Value::kCuda;\n+  } else if (runner.HasProperty(HloRunnerPropertyTag::kUsingGpuRocm)) {\n+    return Platform::Value::kRocm;\n   }\n-  LOG(FATAL) << \"Unhandled stream_executor::Platform: \" << platform.Name()\n+  LOG(FATAL) << \"Unhandled platform: \" << runner.Name()\n              << \". Please add support to \" __FILE__ \".\";\n }\n+}  // namespace\n \n-bool Platform::IsNvidiaP100() const {\n-  return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-             value_) &&\n-         std::get<stream_executor::CudaComputeCapability>(value_) ==\n-             stream_executor::CudaComputeCapability::Pascal();\n-}\n-\n-bool Platform::IsNvidiaV100() const {\n-  return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-             value_) &&\n-         std::get<stream_executor::CudaComputeCapability>(value_) ==\n-             stream_executor::CudaComputeCapability::Volta();\n-}\n-\n-bool Platform::IsNvidiaA100() const {\n-  return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-             value_) &&\n-         std::get<stream_executor::CudaComputeCapability>(value_) ==\n-             stream_executor::CudaComputeCapability::Ampere();\n-}\n-\n-bool Platform::IsNvidiaH100() const {\n-  return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-             value_) &&\n-         std::get<stream_executor::CudaComputeCapability>(value_) ==\n-             stream_executor::CudaComputeCapability::Hopper();\n-}\n-\n-Platform::Platform(const stream_executor::Platform& platform)\n-    : value_(GetPlatformValue(platform)) {}\n+Platform::Platform(const HloRunnerInterface& runner)\n+    : value_(GetPlatformValue(runner)) {}\n \n }  // namespace exhaustive_op_test\n }  // namespace xla"
        },
        {
            "sha": "6a0a8aa6fc84fb21b13d0a9fadd16baf849e2903",
            "filename": "third_party/xla/xla/tests/exhaustive/platform.h",
            "status": "modified",
            "additions": 18,
            "deletions": 30,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fplatform.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -16,10 +16,8 @@ limitations under the License.\n #ifndef XLA_TESTS_EXHAUSTIVE_PLATFORM_H_\n #define XLA_TESTS_EXHAUSTIVE_PLATFORM_H_\n \n-#include <variant>\n-\n-#include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/platform.h\"\n+#include \"xla/tests/xla_test_backend_predicates.h\"\n+#include \"xla/service/hlo_runner_interface.h\"\n \n namespace xla {\n namespace exhaustive_op_test {\n@@ -28,44 +26,34 @@ namespace exhaustive_op_test {\n // with helper functions to categorically handle them.\n class Platform {\n  public:\n-  enum class CpuValue {\n-    AARCH64,\n-    X86_64,\n+  enum class Value {\n+    kAarch64,\n+    kX86_64,\n+    kCuda,\n+    kRocm,\n   };\n \n-  using Value = std::variant<CpuValue, stream_executor::CudaComputeCapability,\n-                             stream_executor::RocmComputeCapability>;\n+  explicit Platform(const HloRunnerInterface& runner);\n \n-  explicit Platform(const stream_executor::Platform& platform);\n+  bool IsCpu() const { return IsIntelCpu() || IsArmCpu(); }\n \n-  bool IsCpu() const { return std::holds_alternative<CpuValue>(value_); }\n+  bool IsIntelCpu() const { return value_ == Value::kX86_64; }\n \n-  bool IsGpu() const {\n-    return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-               value_) ||\n-           std::holds_alternative<stream_executor::RocmComputeCapability>(\n-               value_);\n-  }\n+  bool IsArmCpu() const { return value_ == Value::kAarch64; }\n \n-  bool IsNvidiaGpu() const {\n-    return std::holds_alternative<stream_executor::CudaComputeCapability>(\n-        value_);\n-  }\n+  bool IsGpu() const { return IsAmdGpu() || IsNvidiaGpu(); }\n \n-  bool IsNvidiaP100() const;\n+  bool IsAmdGpu() const { return value_ == Value::kRocm; }\n \n-  bool IsNvidiaV100() const;\n+  bool IsNvidiaGpu() const { return value_ == Value::kCuda; }\n \n-  bool IsNvidiaA100() const;\n+  bool IsNvidiaP100() const { return test::DeviceIs(test::kP100); }\n \n-  bool IsNvidiaH100() const;\n+  bool IsNvidiaV100() const { return test::DeviceIs(test::kV100); }\n \n-  bool IsAmdGpu() const {\n-    return std::holds_alternative<stream_executor::RocmComputeCapability>(\n-        value_);\n-  }\n+  bool IsNvidiaA100() const { return test::DeviceIs(test::kA100); }\n \n-  const Value& value() const { return value_; }\n+  bool IsNvidiaH100() const { return test::DeviceIs(test::kH100); }\n \n  private:\n   const Value value_;"
        },
        {
            "sha": "33278cb8956a4985dea58adb49d281f3504ddf98",
            "filename": "third_party/xla/xla/tests/exhaustive/test_op.h",
            "status": "modified",
            "additions": 9,
            "deletions": 16,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Ftest_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Ftest_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Ftest_op.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -171,22 +171,15 @@ class TestOp {\n   void Run() && {\n     typename Traits::ErrorSpecGen error_spec_gen;\n     if (test_->Platform().IsCpu()) {\n-      switch (std::get<Platform::CpuValue>(test_->Platform().value())) {\n-        case Platform::CpuValue::X86_64: {\n-          error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n-              {cpu_x86_error_spec_gen_, cpu_error_spec_gen_, error_spec_gen_});\n-          break;\n-        }\n-        case Platform::CpuValue::AARCH64: {\n-          error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n-              {cpu_arm_error_spec_gen_, cpu_error_spec_gen_, error_spec_gen_});\n-          break;\n-        }\n-        default: {\n-          error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n-              {cpu_error_spec_gen_, error_spec_gen_});\n-          break;\n-        }\n+      if (test_->Platform().IsIntelCpu()) {\n+        error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n+            {cpu_x86_error_spec_gen_, cpu_error_spec_gen_, error_spec_gen_});\n+      } else if (test_->Platform().IsArmCpu()) {\n+        error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n+            {cpu_arm_error_spec_gen_, cpu_error_spec_gen_, error_spec_gen_});\n+      } else {\n+        error_spec_gen = PickFirstErrorSpecGenPresent<Traits>(\n+            {cpu_error_spec_gen_, error_spec_gen_});\n       }\n     } else if (test_->Platform().IsGpu()) {\n       if (test_->Platform().IsNvidiaGpu()) {"
        },
        {
            "sha": "f667b3539e30b773e151aceab424efe86c7b9cd6",
            "filename": "third_party/xla/xla/tests/xla_test_backend_predicates.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fxla_test_backend_predicates.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4c206fe648ac6bb3db42df29ea511922c20206e8/third_party%2Fxla%2Fxla%2Ftests%2Fxla_test_backend_predicates.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fxla_test_backend_predicates.h?ref=4c206fe648ac6bb3db42df29ea511922c20206e8",
            "patch": "@@ -54,6 +54,8 @@ inline constexpr const absl::string_view kGpu = \"gpu\";\n inline constexpr const absl::string_view kA100 = \"a100\";\n inline constexpr const absl::string_view kH100 = \"h100\";\n inline constexpr const absl::string_view kB100 = \"b100\";\n+inline constexpr const absl::string_view kP100 = \"p100\";\n+inline constexpr const absl::string_view kV100 = \"v100\";\n \n inline constexpr const absl::string_view kInterpreter = \"interpreter\";\n "
        }
    ],
    "stats": {
        "total": 278,
        "additions": 106,
        "deletions": 172
    }
}