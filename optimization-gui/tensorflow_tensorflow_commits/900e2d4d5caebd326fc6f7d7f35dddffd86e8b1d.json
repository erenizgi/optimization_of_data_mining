{
    "author": "WillFroom",
    "message": "[XLA][XTile] Add TiledBuffer interface to insert/extract ops.\n\nPiperOrigin-RevId: 822009372",
    "sha": "900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
    "files": [
        {
            "sha": "03b4938ba06691562ac53a989e0b6c7c9fc83cf7",
            "filename": "third_party/xla/xla/codegen/xtile/ir/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2FBUILD?ref=900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
            "patch": "@@ -49,6 +49,8 @@ gentbl_cc_library(\n     compatible_with = get_compatible_with_portable(),\n     strip_include_prefix = \".\",\n     tbl_outs = {\n+        \"xtile_interface_ops.h.inc\": [\"-gen-op-interface-decls\"],\n+        \"xtile_interface_ops.cc.inc\": [\"-gen-op-interface-defs\"],\n         \"xtile_ops.h.inc\": [\"-gen-op-decls\"],\n         \"xtile_ops.cc.inc\": [\"-gen-op-defs\"],\n     },"
        },
        {
            "sha": "d0747515907fc25446487633f9c4c2428622777a",
            "filename": "third_party/xla/xla/codegen/xtile/ir/tests/ops.mlir",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fops.mlir?ref=900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
            "patch": "@@ -32,7 +32,7 @@ xtile.entry_func @too_many_tile_ids(%input: memref<1024xf32>, %id0: index, %id1:\n \n func.func @incorrect_full_shape_extract(%arg: memref<1024xf32>) -> tensor<10xf32> {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{full tile shape size: 2 does not match rank of source: 1}}\n+  // expected-error@+1 {{full tile shape size: 2 does not match rank of buffer: 1}}\n   %tile = xtile.extract %arg[%offset][10, 1][1] : memref<1024xf32> -> tensor<10xf32>\n   return %tile : tensor<10xf32>\n }\n@@ -50,7 +50,7 @@ func.func @incorrect_offset_count_extract(%arg: memref<1024xf32>) -> tensor<10xf\n \n func.func @incorrect_rank_reduction_extract(%arg: memref<16x1024xf32>) -> tensor<10xf32> {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{full tile shape: [16, 10] does not reduce to result shape: [10]}}\n+  // expected-error@+1 {{full tile shape: [16, 10] does not reduce to tile shape: [10]}}\n   %tile = xtile.extract %arg[%offset, %offset][16, 10][1, 1] : memref<16x1024xf32> -> tensor<10xf32>\n   return %tile : tensor<10xf32>\n }\n@@ -59,7 +59,7 @@ func.func @incorrect_rank_reduction_extract(%arg: memref<16x1024xf32>) -> tensor\n \n func.func @type_mismatch_extract(%arg: memref<1024xf32>) -> tensor<10xf64> {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{result element type: 'f64' does not match element type of source: 'f32'}}\n+  // expected-error@+1 {{buffer element type: 'f32' does not match element type of tile: 'f64'}}\n   %tile = xtile.extract %arg[%offset][10][1] : memref<1024xf32> -> tensor<10xf64>\n   return %tile : tensor<10xf64>\n }\n@@ -68,7 +68,7 @@ func.func @type_mismatch_extract(%arg: memref<1024xf32>) -> tensor<10xf64> {\n \n func.func @incorrect_full_shape_insert(%src: tensor<24xf32>, %dst: memref<1024xf32>) {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{full tile shape size: 2 does not match rank of destination: 1}}\n+  // expected-error@+1 {{full tile shape size: 2 does not match rank of buffer: 1}}\n   xtile.insert %src into %dst[%offset][24, 1][1] : tensor<24xf32> -> memref<1024xf32>\n   return\n }\n@@ -86,7 +86,7 @@ func.func @incorrect_offset_count_insert(%src: tensor<24xf32>, %dst: memref<1024\n \n func.func @incorrect_rank_reduction_insert(%src: tensor<24xf32>, %dst: memref<16x1024xf32>) {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{full tile shape: [16, 24] does not reduce to source shape: [24]}}\n+  // expected-error@+1 {{full tile shape: [16, 24] does not reduce to tile shape: [24]}}\n   xtile.insert %src into %dst[%offset, %offset][16, 24][1, 1] : tensor<24xf32> -> memref<16x1024xf32>\n   return\n }\n@@ -95,7 +95,7 @@ func.func @incorrect_rank_reduction_insert(%src: tensor<24xf32>, %dst: memref<16\n \n func.func @type_mismatch_insert(%src: tensor<24xf64>, %dst: memref<1024xf32>) {\n   %offset = arith.constant 0 : index\n-  // expected-error@+1 {{destination element type: 'f32' does not match element type of source: 'f64'}}\n+  // expected-error@+1 {{buffer element type: 'f32' does not match element type of tile: 'f64'}}\n   xtile.insert %src into %dst[%offset][24][1] : tensor<24xf64> -> memref<1024xf32>\n   return\n }"
        },
        {
            "sha": "aa61fdb2676727cce87711f86a3a5c2412ad7605",
            "filename": "third_party/xla/xla/codegen/xtile/ir/xtile_ops.cc",
            "status": "modified",
            "additions": 57,
            "deletions": 81,
            "changes": 138,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc?ref=900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
            "patch": "@@ -40,10 +40,55 @@ limitations under the License.\n #include \"mlir/Support/LLVM.h\"\n \n #define GET_OP_CLASSES\n+#include \"xla/codegen/xtile/ir/xtile_interface_ops.cc.inc\"\n #include \"xla/codegen/xtile/ir/xtile_ops.cc.inc\"\n \n namespace xla::xtile {\n \n+llvm::SmallDenseSet<unsigned> TiledBufferInterface::getReducedDimensions() {\n+  std::optional<llvm::SmallDenseSet<unsigned>> mask =\n+      mlir::computeRankReductionMask(getFullTileShape(),\n+                                     getTile().getType().getShape());\n+  // This should have already been verified.\n+  CHECK(mask.has_value());\n+  return *mask;\n+}\n+\n+static mlir::LogicalResult VerifyBufferOp(TiledBufferInterface op) {\n+  mlir::MemRefType buffer_type = op.getBuffer().getType();\n+  int64_t buffer_rank = buffer_type.getRank();\n+\n+  if (op.getFullTileShape().size() != buffer_rank) {\n+    return op.emitOpError()\n+           << \"full tile shape size: \" << op.getFullTileShape().size()\n+           << \" does not match rank of buffer: \" << buffer_rank;\n+  }\n+\n+  size_t offset_count = op.getOffsets().size();\n+  if (offset_count != buffer_rank) {\n+    return op.emitOpError() << \"expected \" << buffer_rank\n+                            << \" offset operands, got \" << offset_count;\n+  }\n+\n+  mlir::RankedTensorType tile_type = op.getTile().getType();\n+  if (!mlir::computeRankReductionMask(op.getFullTileShape(),\n+                                      tile_type.getShape())) {\n+    return op.emitOpError() << \"full tile shape: [\" << op.getFullTileShape()\n+                            << \"] does not reduce to tile shape: [\"\n+                            << tile_type.getShape() << \"]\";\n+  }\n+\n+  mlir::Type buffer_element_type = buffer_type.getElementType();\n+  mlir::Type tile_element_type = tile_type.getElementType();\n+  if (buffer_element_type != tile_element_type) {\n+    return op.emitOpError()\n+           << \"buffer element type: \" << buffer_element_type\n+           << \" does not match element type of tile: \" << tile_element_type;\n+  }\n+\n+  return mlir::success();\n+}\n+\n // This is lifted from the func::FuncOp builder, modified to make the tile\n // index implicit.\n void EntryFuncOp::build(mlir::OpBuilder& builder, mlir::OperationState& state,\n@@ -130,94 +175,25 @@ mlir::LogicalResult EntryFuncOp::verify() {\n   return mlir::success();\n }\n \n-llvm::SmallDenseSet<unsigned> ExtractTileOp::getReducedDimensions() {\n-  std::optional<llvm::SmallDenseSet<unsigned>> mask =\n-      mlir::computeRankReductionMask(getFullTileShape(), getType().getShape());\n-  // This should have already been verified.\n-  CHECK(mask.has_value());\n-  return *mask;\n+mlir::TypedValue<mlir::MemRefType> ExtractTileOp::getBuffer() {\n+  return getSource();\n }\n \n-// This is the function ODS expects you to implement\n-mlir::LogicalResult ExtractTileOp::verify() {\n-  mlir::MemRefType source_type = getSource().getType();\n-  int64_t source_rank = source_type.getRank();\n-  mlir::Type source_element_type = source_type.getElementType();\n-\n-  if (getFullTileShape().size() != source_rank) {\n-    return emitOpError() << \"full tile shape size: \"\n-                         << getFullTileShape().size()\n-                         << \" does not match rank of source: \" << source_rank;\n-  }\n-\n-  size_t offset_count = getOffsets().size();\n-  if (offset_count != source_rank) {\n-    return emitOpError() << \"expected \" << source_rank\n-                         << \" offset operands, got \" << offset_count;\n-  }\n-\n-  mlir::RankedTensorType result_type = getType();\n-  if (!mlir::computeRankReductionMask(getFullTileShape(),\n-                                      result_type.getShape())) {\n-    return emitOpError() << \"full tile shape: [\" << getFullTileShape()\n-                         << \"] does not reduce to result shape: [\"\n-                         << result_type.getShape() << \"]\";\n-  }\n+mlir::TypedValue<mlir::RankedTensorType> ExtractTileOp::getTile() {\n+  return getResult();\n+}\n \n-  if (result_type.getElementType() != source_element_type) {\n-    return emitOpError() << \"result element type: \"\n-                         << result_type.getElementType()\n-                         << \" does not match element type of source: \"\n-                         << source_element_type;\n-  }\n+// This is the function ODS expects you to implement\n+mlir::LogicalResult ExtractTileOp::verify() { return VerifyBufferOp(*this); }\n \n-  return mlir::success();\n+mlir::TypedValue<mlir::MemRefType> InsertTileOp::getBuffer() {\n+  return getDestination();\n }\n \n-llvm::SmallDenseSet<unsigned> InsertTileOp::getReducedDimensions() {\n-  std::optional<llvm::SmallDenseSet<unsigned>> mask =\n-      mlir::computeRankReductionMask(getFullTileShape(),\n-                                     getSource().getType().getShape());\n-  // This should have already been verified.\n-  CHECK(mask.has_value());\n-  return *mask;\n+mlir::TypedValue<mlir::RankedTensorType> InsertTileOp::getTile() {\n+  return getSource();\n }\n \n-mlir::LogicalResult InsertTileOp::verify() {\n-  mlir::MemRefType destination_type = getDestination().getType();\n-  int64_t destination_rank = destination_type.getRank();\n-\n-  if (getFullTileShape().size() != destination_rank) {\n-    return emitOpError() << \"full tile shape size: \"\n-                         << getFullTileShape().size()\n-                         << \" does not match rank of destination: \"\n-                         << destination_rank;\n-  }\n-\n-  size_t offset_count = getOffsets().size();\n-  if (offset_count != destination_rank) {\n-    return emitOpError() << \"expected \" << destination_rank\n-                         << \" offset operands, got \" << offset_count;\n-  }\n-\n-  mlir::RankedTensorType source_type = getSource().getType();\n-  if (!mlir::computeRankReductionMask(getFullTileShape(),\n-                                      source_type.getShape())) {\n-    return emitOpError() << \"full tile shape: [\" << getFullTileShape()\n-                         << \"] does not reduce to source shape: [\"\n-                         << source_type.getShape() << \"]\";\n-  }\n-\n-  mlir::Type destination_element_type = destination_type.getElementType();\n-  mlir::Type source_element_type = source_type.getElementType();\n-  if (destination_element_type != source_element_type) {\n-    return emitOpError() << \"destination element type: \"\n-                         << destination_element_type\n-                         << \" does not match element type of source: \"\n-                         << source_element_type;\n-  }\n-\n-  return mlir::success();\n-}\n+mlir::LogicalResult InsertTileOp::verify() { return VerifyBufferOp(*this); }\n \n }  // namespace xla::xtile"
        },
        {
            "sha": "abe304bdba40cca9026e3662310363f40904c82d",
            "filename": "third_party/xla/xla/codegen/xtile/ir/xtile_ops.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.h?ref=900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include <utility>\n \n #include \"llvm/ADT/DenseMap.h\"\n+#include \"llvm/ADT/DenseSet.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mlir/Bytecode/BytecodeOpInterface.h\"  // IWYU pragma: keep\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"  // IWYU pragma: keep\n@@ -37,6 +38,7 @@ limitations under the License.\n #include \"xla/hlo/analysis/indexing_map.h\"  // IWYU pragma: keep\n \n #define GET_OP_CLASSES\n+#include \"xla/codegen/xtile/ir/xtile_interface_ops.h.inc\"  // IWYU pragma: keep\n #include \"xla/codegen/xtile/ir/xtile_ops.h.inc\"  // IWYU pragma: keep\n \n #endif  // XLA_CODEGEN_XTILE_IR_XTILE_OPS_H_"
        },
        {
            "sha": "6989e80f03fbb9593afd5fe8bcf2357504685f46",
            "filename": "third_party/xla/xla/codegen/xtile/ir/xtile_ops.td",
            "status": "modified",
            "additions": 40,
            "deletions": 4,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td?ref=900e2d4d5caebd326fc6f7d7f35dddffd86e8b1d",
            "patch": "@@ -25,13 +25,47 @@ include \"mlir/IR/AttrTypeBase.td\"\n include \"mlir/IR/OpAsmInterface.td\"\n include \"mlir/IR/OpBase.td\"\n include \"mlir/IR/SymbolInterfaces.td\"\n+include \"mlir/IR/Interfaces.td\"\n include \"xla/codegen/xtile/ir/xtile_dialect.td\"\n include \"xla/codegen/xtile/ir/xtile_attrs.td\"\n \n class XTile_Op<string mnemonic, list<Trait> traits = []> :\n       Op<XTileDialect, mnemonic, traits> {\n }\n \n+def TiledBufferInterface : OpInterface<\"TiledBufferInterface\"> {\n+  let description = [{\n+\n+  }];\n+\n+  let cppNamespace = \"::xla::xtile\";\n+\n+  let extraClassDeclaration = [{\n+    // Returns the set of unit dimensions that are removed from the tile\n+    // dimensions.\n+    llvm::SmallDenseSet<unsigned> getReducedDimensions();\n+  }];\n+\n+  let extraTraitClassDeclaration = [{\n+    llvm::SmallDenseSet<unsigned> getReducedDimensions() {\n+      return static_cast<TiledBufferInterface>($_op).getReducedDimensions();\n+    }\n+  }];\n+\n+  let methods = [\n+    InterfaceMethod<\"Get the memref value of the buffer.\",\n+                    \"mlir::TypedValue<mlir::MemRefType>\", \"getBuffer\">,\n+    InterfaceMethod<\"Get the tensor value of the tile.\",\n+                    \"mlir::TypedValue<mlir::RankedTensorType>\", \"getTile\">,\n+    InterfaceMethod<\"Get the offsets into the buffer.\",\n+                    \"mlir::ValueRange\", \"getOffsets\">,\n+    InterfaceMethod<\"Get the full unreduced tile shape.\",\n+                    \"llvm::ArrayRef<int64_t>\", \"getFullTileShape\">,\n+    InterfaceMethod<\"Get the stride lengths of the buffer.\",\n+                    \"llvm::ArrayRef<int64_t>\", \"getStrides\">,\n+  ];\n+}\n+\n \n // Define your custom entry operation\n def EntryFuncOp : XTile_Op<\"entry_func\", [\n@@ -111,7 +145,7 @@ def EntryFuncReturnOp : XTile_Op<\"return\", [Pure, HasParent<\"EntryFuncOp\">,\n   let assemblyFormat = \"attr-dict\";\n }\n \n-def ExtractTileOp : XTile_Op<\"extract\"> {\n+def ExtractTileOp : XTile_Op<\"extract\", [TiledBufferInterface]> {\n   let summary = \"Extract a tile from a memref.\";\n   let description = [{\n   }];\n@@ -132,13 +166,14 @@ def ExtractTileOp : XTile_Op<\"extract\"> {\n   }];\n \n   let extraClassDeclaration = [{\n-    llvm::SmallDenseSet<unsigned> getReducedDimensions();\n+    mlir::TypedValue<mlir::MemRefType> getBuffer();\n+    mlir::TypedValue<mlir::RankedTensorType> getTile();\n   }];\n \n   let hasVerifier = 1;\n }\n \n-def InsertTileOp : XTile_Op<\"insert\"> {\n+def InsertTileOp : XTile_Op<\"insert\", [TiledBufferInterface]> {\n   let summary = \"Insert a tile into a memref.\";\n   let description = [{\n   }];\n@@ -159,7 +194,8 @@ def InsertTileOp : XTile_Op<\"insert\"> {\n   }];\n \n   let extraClassDeclaration = [{\n-    llvm::SmallDenseSet<unsigned> getReducedDimensions();\n+    mlir::TypedValue<mlir::MemRefType> getBuffer();\n+    mlir::TypedValue<mlir::RankedTensorType> getTile();\n   }];\n \n   let hasVerifier = 1;"
        }
    ],
    "stats": {
        "total": 198,
        "additions": 107,
        "deletions": 91
    }
}