{
    "author": "ezhulenev",
    "message": "[xla:cpu] Delete cpu_runtime_test that tests to-be-deleted cpu runtime matmul\n\nPiperOrigin-RevId: 829253301",
    "sha": "9e202e16188ac2c0d350cc85f91cdcdc52947b7d",
    "files": [
        {
            "sha": "ce0c61cc9b44df6a21bd405ad7ffae5228974157",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9e202e16188ac2c0d350cc85f91cdcdc52947b7d/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9e202e16188ac2c0d350cc85f91cdcdc52947b7d/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=9e202e16188ac2c0d350cc85f91cdcdc52947b7d",
            "patch": "@@ -1224,30 +1224,6 @@ cc_library(\n     ],\n )\n \n-xla_cc_test(\n-    name = \"cpu_runtime_test\",\n-    srcs = [\"cpu_runtime_test.cc\"],\n-    shard_count = 10,\n-    tags = [\"optonly\"],\n-    deps = [\n-        \":cpu_runtime\",\n-        \":runtime_custom_call_status\",\n-        \":runtime_matmul\",\n-        \":runtime_single_threaded_matmul\",\n-        \"//xla:array2d\",\n-        \"//xla:executable_run_options\",\n-        \"//xla:types\",\n-        \"//xla/client:local_client\",\n-        \"//xla/service:custom_call_status_internal\",\n-        \"//xla/tests:xla_internal_test_main\",\n-        \"@com_google_absl//absl/strings:str_format\",\n-        \"@eigen_archive//:eigen3\",\n-        \"@local_tsl//tsl/platform:env\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:test\",\n-    ],\n-)\n-\n xla_cc_test(\n     name = \"cpu_instruction_fusion_test\",\n     srcs = [\"cpu_instruction_fusion_test.cc\"],"
        },
        {
            "sha": "284cc42d9417566b29721fdb396ab5c4af1061e1",
            "filename": "third_party/xla/xla/service/cpu/cpu_runtime_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 188,
            "changes": 188,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b44bd9b7aed377f2f3dc9b661af64d0fffd3ff44/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b44bd9b7aed377f2f3dc9b661af64d0fffd3ff44/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_runtime_test.cc?ref=b44bd9b7aed377f2f3dc9b661af64d0fffd3ff44",
            "patch": "@@ -1,188 +0,0 @@\n-/* Copyright 2017 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/cpu_runtime.h\"\n-\n-#include <cstdint>\n-#include <memory>\n-#include <string>\n-#include <tuple>\n-#include <utility>\n-\n-#include \"absl/strings/str_format.h\"\n-#include \"xla/array2d.h\"\n-#include \"xla/client/local_client.h\"\n-#include \"xla/executable_run_options.h\"\n-#include \"xla/service/cpu/runtime_custom_call_status.h\"\n-#include \"xla/service/cpu/runtime_matmul.h\"\n-#include \"xla/service/cpu/runtime_single_threaded_matmul.h\"\n-#include \"xla/service/custom_call_status_internal.h\"\n-#include \"xla/types.h\"\n-#include \"tsl/platform/env.h\"\n-#include \"tsl/platform/logging.h\"\n-#include \"tsl/platform/test.h\"\n-\n-#define EIGEN_USE_THREADS\n-#include \"unsupported/Eigen/CXX11/Tensor\"\n-\n-namespace xla {\n-namespace {\n-\n-class CpuRuntimeTest : public ::testing::Test {};\n-\n-template <typename T>\n-std::unique_ptr<Array2D<float>> MaybeTransposeArray2D(const Array2D<T>& array,\n-                                                      bool transpose) {\n-  int64_t output_height = array.height();\n-  int64_t output_width = array.width();\n-  if (transpose) {\n-    std::swap(output_width, output_height);\n-  }\n-  auto output = std::make_unique<Array2D<float>>(output_height, output_width);\n-  for (int y = 0; y < array.height(); y++) {\n-    for (int x = 0; x < array.width(); x++) {\n-      if (transpose) {\n-        (*output)(x, y) = array(y, x);\n-      } else {\n-        (*output)(y, x) = array(y, x);\n-      }\n-    }\n-  }\n-  return output;\n-}\n-\n-// Verifies that matrix 'c' equals the result of matrix 'a' times matrix 'b'.\n-// Each element is compared to within a small error bound.\n-void CheckMatrixMultiply(const Array2D<float>& a, const Array2D<float>& b,\n-                         const Array2D<float>& c) {\n-  for (int i = 0; i < a.height(); ++i) {\n-    for (int j = 0; j < b.width(); ++j) {\n-      float sum = 0.0;\n-      for (int k = 0; k < a.width(); ++k) {\n-        sum += a(i, k) * b(k, j);\n-      }\n-      EXPECT_NEAR(sum, c(i, j), 0.01);\n-    }\n-  }\n-}\n-\n-std::unique_ptr<Array2D<float>> EigenMatrixMultiply(const Array2D<float>& a,\n-                                                    const Array2D<float>& b,\n-                                                    bool transpose_lhs,\n-                                                    bool transpose_rhs,\n-                                                    bool single_threaded) {\n-  CHECK_EQ(a.width(), b.height());\n-  int64_t m = a.height();\n-  int64_t n = b.width();\n-  int64_t k = a.width();\n-\n-  // The Eigen matmul runtime function expects the matrix to be in column major\n-  // order and array2d is in row-major order. Create transposes of a and b. The\n-  // 'data' buffer in the transposed array is the original array in column major\n-  // order.\n-  auto a_transpose = MaybeTransposeArray2D(a, !transpose_lhs);\n-  auto b_transpose = MaybeTransposeArray2D(b, !transpose_rhs);\n-\n-  // Since we're going to transpose c before returning it. Swap the order of the\n-  // dimension sizes to ensure the returned array is properly dimensioned.\n-  auto c_transpose = std::make_unique<Array2D<float>>(n, m);\n-  if (single_threaded) {\n-    __xla_cpu_runtime_EigenSingleThreadedMatMulF32(\n-        nullptr, c_transpose->data(), a_transpose->data(), b_transpose->data(),\n-        m, n, k, transpose_lhs, transpose_rhs);\n-  } else {\n-    tsl::thread::ThreadPool pool(tsl::Env::Default(), \"XLAEigen\", 2);\n-    Eigen::ThreadPoolDevice device(pool.AsEigenThreadPool(), pool.NumThreads());\n-    ExecutableRunOptions run_options;\n-    run_options.set_intra_op_thread_pool(&device);\n-\n-    __xla_cpu_runtime_EigenMatMulF32(&run_options, c_transpose->data(),\n-                                     a_transpose->data(), b_transpose->data(),\n-                                     m, n, k, transpose_lhs, transpose_rhs);\n-  }\n-  return MaybeTransposeArray2D(*c_transpose, true);\n-}\n-\n-struct MatMulShape {\n-  int64_t m;\n-  int64_t k;\n-  int64_t n;\n-};\n-\n-MatMulShape MatMulShapes[] = {\n-    MatMulShape{2, 2, 3},     MatMulShape{256, 512, 1024},\n-    MatMulShape{128, 128, 1}, MatMulShape{1, 128, 128},\n-    MatMulShape{1, 32, 128},  MatMulShape{1, 32, 16},\n-    MatMulShape{32, 16, 1},   MatMulShape{32, 128, 1},\n-};\n-\n-// This takes 4 parameters:\n-// * shape of the matmul\n-// * transpose_lhs\n-// * transpose_rhs\n-// * single_threaded\n-using MatMulTestParam = std::tuple<MatMulShape, bool, bool, bool>;\n-\n-class EigenMatMulTest : public CpuRuntimeTest,\n-                        public ::testing::WithParamInterface<MatMulTestParam> {\n- public:\n-  static std::string Name(\n-      const ::testing::TestParamInfo<MatMulTestParam>& info) {\n-    MatMulShape shape = std::get<0>(info.param);\n-    bool transpose_lhs = std::get<1>(info.param);\n-    bool transpose_rhs = std::get<2>(info.param);\n-    bool single_threaded = std::get<3>(info.param);\n-\n-    return absl::StrFormat(\"EigenMatMul_%d_%d_%d_%s%s%s_threaded\", shape.m,\n-                           shape.k, shape.n, transpose_lhs ? \"Tlhs_\" : \"\",\n-                           transpose_rhs ? \"Trhs_\" : \"\",\n-                           single_threaded ? \"single\" : \"multi\");\n-  }\n-};\n-\n-TEST_P(EigenMatMulTest, DoIt) {\n-  MatMulShape shape = std::get<0>(GetParam());\n-  bool transpose_lhs = std::get<1>(GetParam());\n-  bool transpose_rhs = std::get<2>(GetParam());\n-  bool single_threaded = std::get<3>(GetParam());\n-\n-  auto a = MakeLinspaceArray2D(0.0, 1.0, shape.m, shape.k);\n-  auto b = MakeLinspaceArray2D(-2.0, 2.0, shape.k, shape.n);\n-  auto c = EigenMatrixMultiply(*a, *b, transpose_lhs, transpose_rhs,\n-                               single_threaded);\n-  CheckMatrixMultiply(*a, *b, *c);\n-}\n-\n-INSTANTIATE_TEST_SUITE_P(EigenMatMulTestInstantiaion, EigenMatMulTest,\n-                         ::testing::Combine(::testing::ValuesIn(MatMulShapes),\n-                                            ::testing::Bool(),\n-                                            ::testing::Bool(),\n-                                            ::testing::Bool()),\n-                         EigenMatMulTest::Name);\n-\n-TEST_F(CpuRuntimeTest, SuccessStatus) {\n-  XlaCustomCallStatus success_status;\n-  // Success is the default state.\n-  ASSERT_TRUE(__xla_cpu_runtime_StatusIsSuccess(&success_status));\n-}\n-\n-TEST_F(CpuRuntimeTest, FailureStatus) {\n-  XlaCustomCallStatus success_status;\n-  XlaCustomCallStatusSetFailure(&success_status, \"Failed\", 6);\n-  ASSERT_FALSE(__xla_cpu_runtime_StatusIsSuccess(&success_status));\n-}\n-\n-}  // namespace\n-}  // namespace xla"
        }
    ],
    "stats": {
        "total": 212,
        "additions": 0,
        "deletions": 212
    }
}