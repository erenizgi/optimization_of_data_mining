{
    "author": "ermilovmaxim",
    "message": "override Thunk::buffer_uses where needed. Final\n\nPiperOrigin-RevId: 840457237",
    "sha": "63f5f10d673edbf52f4977f00085eb4c0a977afd",
    "files": [
        {
            "sha": "2bb478d7f742bf1e494d3f8981ae1b9577285d5d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -245,6 +245,7 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/stream_executor:device_memory\",\n@@ -499,6 +500,7 @@ cc_library(\n     deps = [\n         \":thunk\",\n         \"//xla:util\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:gpu_conv_runner\",\n         \"//xla/service/gpu:stream_executor_util\",\n@@ -546,6 +548,7 @@ cc_library(\n         \":convolution_filter_thunk_proto_cc\",\n         \":thunk\",\n         \":thunk_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:buffer_assignment_proto_cc\",\n         \"//xla/stream_executor:device_memory\",\n@@ -639,6 +642,7 @@ cc_library(\n         \"//xla/ffi:call_frame\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/ffi/api:c_api\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/stream_executor:device_memory\",\n@@ -870,6 +874,7 @@ cc_library(\n     hdrs = [\"gpublas_lt_matmul_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:matmul_utils\",\n@@ -1911,6 +1916,7 @@ cc_library(\n         \":thunk\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:gpu_norm_runner\",\n         \"//xla/service/gpu:gpu_norm_runner_proto_cc\",\n@@ -2265,6 +2271,7 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:blas\",\n         \"//xla/stream_executor:device_memory\","
        },
        {
            "sha": "2bd0501b08e365f0dca0ffcf18d74de3c14493dd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_reorder_thunk.h",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/convolution_filter_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/dnn.h\"\n \n@@ -50,6 +51,18 @@ class ConvolutionReorderThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res{\n+        BufferUse::Read(filter_input_),\n+        BufferUse::Write(filter_output_),\n+    };\n+    if (biases_.has_value()) {\n+      res.push_back(BufferUse::Read(biases_->bias_input));\n+      res.push_back(BufferUse::Write(biases_->bias_output));\n+    }\n+    return res;\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<ConvolutionReorderThunk>> FromProto(\n       ThunkInfo thunk_info, const ConvolutionReorderThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "c13653ba69c8f229749bf6ee950b5f3cf12a930b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_thunk.h",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/gpu_conv_runner.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -53,6 +54,21 @@ class ConvolutionThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    BufferUses res;\n+    res.reserve(operand_buffers_.size() + result_buffers_.size() + 1);\n+\n+    for (const BufferAllocation::Slice& slice : operand_buffers_) {\n+      res.push_back(BufferUse::Read(slice));\n+    }\n+    for (const BufferAllocation::Slice& slice : result_buffers_) {\n+      res.push_back(BufferUse::Write(slice));\n+    }\n+    res.emplace_back(scratch_buffer_, BufferUse::MemoryAccess::kWrite,\n+                     BufferUse::ContentValidity::kUndefined);\n+    return res;\n+  }\n+\n   static absl::StatusOr<std::unique_ptr<ConvolutionThunk>> FromProto(\n       ThunkInfo thunk_info, const ConvolutionThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "20164b224367e3117a1154089779cecf512687d2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cub_sort_thunk.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.cc?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"xla/ffi/call_frame.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/primitive_util.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/stream_executor/device_memory.h\"\n@@ -321,6 +322,20 @@ CubSortThunk::CubSortThunk(\n       descending_(descending),\n       batch_size_(batch_size) {}\n \n+Thunk::BufferUses CubSortThunk::buffer_uses() const {\n+  Thunk::BufferUses res;\n+  res.reserve(operands_.size() + results_.size() + 1);\n+  for (const BufferAllocation::Slice& slice : operands_) {\n+    res.push_back(BufferUse::Read(slice));\n+  }\n+  for (const BufferAllocation::Slice& slice : results_) {\n+    res.push_back(BufferUse::Write(slice));\n+  }\n+  res.emplace_back(scratch_, BufferUse::MemoryAccess::kWrite,\n+                   BufferUse::ContentValidity::kUndefined);\n+  return res;\n+}\n+\n absl::StatusOr<std::unique_ptr<CubSortThunk>> CubSortThunk::FromProto(\n     ThunkInfo thunk_info, const CubSortThunkProto& proto,\n     absl::Span<const BufferAllocation> buffer_allocations,"
        },
        {
            "sha": "cb510d7bcf6d1aca075be39bf1310f4a27f2dcc5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/cub_sort_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcub_sort_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -68,6 +68,8 @@ class CubSortThunk : public Thunk {\n     return runner_->Run(params, this);\n   }\n \n+  BufferUses buffer_uses() const override;\n+\n   static absl::StatusOr<std::unique_ptr<CubSortThunk>> FromProto(\n       ThunkInfo thunk_info, const CubSortThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations,"
        },
        {
            "sha": "642d493ec44b5c5a91c4d00f7e42bf9dd7674f7a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -45,6 +45,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/shape.h\"\n@@ -452,6 +453,30 @@ absl::Status DynamicSliceThunk::TransformAllNestedThunks(\n   return absl::OkStatus();\n }\n \n+Thunk::BufferUses DynamicSliceThunk::buffer_uses() const {\n+  Thunk::BufferUses res;\n+  res.reserve(slices_.size());\n+  for (const SliceDef& slice : slices_) {\n+    if (!slice.embedded_thunk_argument.has_value()) {\n+      continue;\n+    }\n+    res.push_back(\n+        BufferUse::Read(*slice.embedded_thunk_argument, *slice.orig_shape));\n+\n+    if (!slice.offsets.has_value()) {\n+      continue;\n+    }\n+    for (const Offset& offset : *slice.offsets) {\n+      auto* alloc_slice = std::get_if<BufferAllocation::Slice>(&offset);\n+      if (!alloc_slice) {\n+        continue;\n+      }\n+      res.push_back(BufferUse::Read(*alloc_slice));\n+    }\n+  }\n+  return res;\n+}\n+\n absl::StatusOr<OptionalDynamicSliceOffsetsProto>\n SerializeOptionalDynamicSliceOffsetsToProto(\n     const std::optional<std::vector<DynamicSliceThunk::Offset>>& offsets_item,"
        },
        {
            "sha": "68d724566b4d850144816dbefc39e4fd8c509cf8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -176,6 +176,8 @@ class DynamicSliceThunk : public Thunk {\n           absl::StatusOr<std::unique_ptr<Thunk>>(std::unique_ptr<Thunk>)>\n           fn) override;\n \n+  BufferUses buffer_uses() const override;\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n \n   // `buffer_allocations`: the actual buffer allocations; required to parse the"
        },
        {
            "sha": "5e1ff027c57ec982cf1169e39c2f1c61646f56a0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.cc?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/matmul_utils.h\"\n@@ -160,6 +161,17 @@ absl::Status CublasLtMatmulThunk::Initialize(const InitializeParams& params) {\n   return absl::OkStatus();\n }\n \n+Thunk::BufferUses CublasLtMatmulThunk::buffer_uses() const {\n+  return {\n+      BufferUse::Read(a_),       BufferUse::Read(b_),\n+      BufferUse::Read(c_),       BufferUse::Write(d_),\n+      BufferUse::Read(bias_),    BufferUse::Write(aux_),\n+      BufferUse::Read(a_scale_), BufferUse::Read(b_scale_),\n+      BufferUse::Read(c_scale_), BufferUse::Read(d_scale_),\n+      BufferUse::Write(d_amax_),\n+  };\n+}\n+\n absl::StatusOr<ThunkProto> CublasLtMatmulThunk::ToProto() const {\n   ThunkProto proto;\n   *proto.mutable_thunk_info() = thunk_info().ToProto();"
        },
        {
            "sha": "26c35ccca599021777654ab0c5b6e9432beea039",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -57,6 +57,8 @@ class CublasLtMatmulThunk : public Thunk {\n     return workspace_;\n   }\n \n+  BufferUses buffer_uses() const override;\n+\n   absl::StatusOr<ThunkProto> ToProto() const override;\n   static absl::StatusOr<std::unique_ptr<Thunk>> FromProto(\n       Thunk::ThunkInfo thunk_info, const CublasLtMatmulThunkProto& proto,"
        },
        {
            "sha": "a37b7e9760157d8ff661680a381273483224bb7d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/norm_thunk.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.cc?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -25,6 +25,7 @@ limitations under the License.\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/gpu_norm_runner.h\"\n #include \"xla/service/gpu/gpu_norm_runner.pb.h\"\n@@ -150,6 +151,35 @@ absl::Status NormThunk::Initialize(const InitializeParams& params) {\n   return lazy_runner->GetOrCreateRunner(ln_config, params.stream).status();\n }\n \n+Thunk::BufferUses NormThunk::buffer_uses() const {\n+  Thunk::BufferUses res{\n+      BufferUse::Read(x_buffer_),\n+      BufferUse::Read(scale_buffer_),\n+      BufferUse::Write(y_or_dx_buffer_),\n+  };\n+  res.emplace_back(scratch_buffer_, BufferUse::MemoryAccess::kWrite,\n+                   BufferUse::ContentValidity::kUndefined);\n+  if (bias_buffer_.has_value()) {\n+    res.push_back(BufferUse::Read(*bias_buffer_));\n+  }\n+  if (expectation_buffer_.has_value()) {\n+    res.push_back(BufferUse::Write(*expectation_buffer_));\n+  }\n+  if (norm_factor_buffer_.has_value()) {\n+    res.push_back(BufferUse::Write(*norm_factor_buffer_));\n+  }\n+  if (dy_buffer_.has_value()) {\n+    res.push_back(BufferUse::Read(*dy_buffer_));\n+  }\n+  if (dscale_buffer_.has_value()) {\n+    res.push_back(BufferUse::Write(*dscale_buffer_));\n+  }\n+  if (dbias_buffer_.has_value()) {\n+    res.push_back(BufferUse::Write(*dbias_buffer_));\n+  }\n+  return res;\n+}\n+\n absl::StatusOr<std::unique_ptr<NormThunk>> NormThunk::FromProto(\n     ThunkInfo thunk_info, const NormThunkProto& proto,\n     absl::Span<const BufferAllocation> buffer_allocations) {"
        },
        {
            "sha": "a0b392033f7fae74d217665ee1b5585b59a15f1d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/norm_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnorm_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -54,6 +54,8 @@ class NormThunk : public Thunk {\n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n   absl::Status Initialize(const InitializeParams& params) override;\n \n+  BufferUses buffer_uses() const override;\n+\n   static absl::StatusOr<std::unique_ptr<NormThunk>> FromProto(\n       ThunkInfo thunk_info, const NormThunkProto& proto,\n       absl::Span<const BufferAllocation> buffer_allocations);"
        },
        {
            "sha": "5cc145b2c214278c31e694952b2307f2c13867e5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/triangular_solve_thunk.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ftriangular_solve_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/63f5f10d673edbf52f4977f00085eb4c0a977afd/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ftriangular_solve_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ftriangular_solve_thunk.h?ref=63f5f10d673edbf52f4977f00085eb4c0a977afd",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/blas.h\"\n #include \"xla/stream_executor/device_memory.h\"\n@@ -53,6 +54,15 @@ class TriangularSolveThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  BufferUses buffer_uses() const override {\n+    return {\n+        BufferUse::Read(a_buffer_),\n+        BufferUse::Write(b_buffer_),\n+        BufferUse(temp_buffer_, BufferUse::MemoryAccess::kWrite,\n+                  BufferUse::ContentValidity::kUndefined),\n+    };\n+  };\n+\n   static absl::StatusOr<std::unique_ptr<TriangularSolveThunk>> FromProto(\n       ThunkInfo thunk_info, const TriangularSolveThunkProto& proto,\n       absl::Span<const BufferAllocation> allocations);"
        }
    ],
    "stats": {
        "total": 136,
        "additions": 136,
        "deletions": 0
    }
}