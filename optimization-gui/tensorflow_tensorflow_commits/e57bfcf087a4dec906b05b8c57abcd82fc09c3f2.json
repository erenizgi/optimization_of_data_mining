{
    "author": "basioli-k",
    "message": "[XLA][codegen] Emit stablehlo dot and addition and then lower it to triton dot.\n\nPiperOrigin-RevId: 831420465",
    "sha": "e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
    "files": [
        {
            "sha": "2c4481fe3e68bacaa737a412ba5651b103a584c8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -422,6 +422,7 @@ cc_library(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/translate/hlo_to_mhlo:attribute_importer\",\n         \"//xla/service:algorithm_util\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "11f08e27c4de193278d96967ffcc3f548532d10d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms.cc",
            "status": "modified",
            "additions": 54,
            "deletions": 284,
            "changes": 338,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.cc?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -41,6 +41,7 @@ limitations under the License.\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/translate/hlo_to_mhlo/attribute_importer.h\"\n #include \"xla/service/algorithm_util.h\"\n #include \"xla/service/llvm_ir/llvm_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -55,8 +56,6 @@ namespace triton {\n \n namespace {\n \n-namespace arith = ::mlir::arith;\n-namespace math = ::mlir::math;\n namespace ttir = ::mlir::triton;\n \n using ::mlir::ShapedType;\n@@ -65,66 +64,18 @@ using ::mlir::Value;\n \n Type ElementType(Value v) { return mlir::getElementTypeOrSelf(v); }\n \n-// Precision-relevant configuration bits for `dot`s.\n-struct PrecisionSpec {\n-  PrecisionConfig::Algorithm algorithm;\n-  // TODO(bchetioui): we hope to get rid of operand precisions eventually, they\n-  // are currently a (XLA-wide) bridge to work with ALG_UNSET.\n-  PrecisionConfig::Precision lhs_operand_precision;\n-  PrecisionConfig::Precision rhs_operand_precision;\n-  // Encodes `tt.dot`'s `inputPrecision` attribute.\n-  ttir::InputPrecision ttir_input_precision;\n-};\n-\n-using AlgorithmEmitter = absl::StatusOr<Value> (*)(EmitterLocOpBuilder,\n-                                                   const DotOperands&,\n-                                                   const PrecisionSpec&);\n-\n-// If lhs is 1.0, we will have lhs_high = 1.0 and lhs_low = 0.0.\n-// If rhs is +infinity, we will have:\n-// +infinity * 1.0 = +infinity\n-// +infinity * 0.0 = NaN\n-// We would get the wrong result if we sum these partial products. Instead, we\n-// must override any accumulated result if the last partial product is\n-// non-finite. See b/115844437.\n-Value ZeroNaNs(EmitterLocOpBuilder b, Value input) {\n-  Value positive_inf = CreateConst<float>(\n-      b, b.getF32Type(), std::numeric_limits<float>::infinity(),\n-      mlir::cast<ShapedType>(input.getType()).getShape());\n-  Value abs_input = b.create<math::AbsFOp>(input);\n-  Value is_finite = b.create<arith::CmpFOp>(arith::CmpFPredicate::OGT,\n-                                            positive_inf, abs_input);\n-  return b.create<arith::SelectOp>(is_finite, input, ZerosLike(b, input));\n-}\n-\n-absl::Status ExpectType(Value v, Type expected_type) {\n-  if (ElementType(v) != expected_type) {\n-    std::string expected_type_str, actual_type_str;\n-    {\n-      llvm::raw_string_ostream os_expected(expected_type_str);\n-      llvm::raw_string_ostream os_actual(actual_type_str);\n-      expected_type.print(os_expected);\n-      ElementType(v).print(os_actual);\n-    }\n-    return absl::FailedPreconditionError(absl::StrCat(\n-        \"Expected type \", expected_type_str, \" but got \", actual_type_str));\n-  }\n-  return absl::OkStatus();\n-}\n-\n-std::vector<Value> SplitF32(EmitterLocOpBuilder b, Value input,\n-                            int split_count) {\n-  std::vector<Value> split_inputs;\n-  split_inputs.reserve(split_count);\n-  for (int i = 0; i < split_count; ++i) {\n-    Value input_as_bf16 = Cast(b, input, b.getBF16Type());\n-    if (i != split_count - 1) {\n-      Value input_as_f32 = Cast(b, input_as_bf16, b.getF32Type());\n-      input = b.create<arith::SubFOp>(input, input_as_f32);\n-    }\n-    split_inputs.push_back(input_as_bf16);\n+mlir::stablehlo::Precision XlaPrecisionToStableHloPrecision(\n+    PrecisionConfig::Precision precision) {\n+  switch (precision) {\n+    case PrecisionConfig::DEFAULT:\n+      return mlir::stablehlo::Precision::DEFAULT;\n+    case PrecisionConfig::HIGH:\n+      return mlir::stablehlo::Precision::HIGH;\n+    case PrecisionConfig::HIGHEST:\n+      return mlir::stablehlo::Precision::HIGHEST;\n+    default:\n+      LOG(FATAL) << \"Unsupported precision: \" << precision;\n   }\n-  return split_inputs;\n }\n \n absl::StatusOr<ttir::ScaleDotElemType> GetScaleDotElemType(Type value) {\n@@ -170,129 +121,43 @@ absl::StatusOr<Value> ScaledDot(EmitterLocOpBuilder b,\n       rhs_dot_elem_type, true);\n }\n \n-Value IEEEDot(EmitterLocOpBuilder b, Value lhs, Value rhs, Value acc) {\n-  return b.create<ttir::DotOp>(lhs, rhs, acc,\n-                               /*inputPrecision=*/ttir::InputPrecision::IEEE,\n-                               /*maxNumImpreciseAcc=*/0);\n-}\n-\n-// Leverages BF16 datatype for F32 matmul computation. It follows the guidance\n-// from https://arxiv.org/pdf/1904.06376.pdf.\n-absl::StatusOr<Value> EmitBF16x9Matmul(EmitterLocOpBuilder b,\n-                                       const DotOperands& dot_operands,\n-                                       const PrecisionSpec& precision_spec) {\n-  constexpr int kNumParts = 3;\n-  constexpr int kHigh = 0;\n-  constexpr int kMid = 1;\n-  constexpr int kLow = 2;\n-\n-  Type f32 = b.getF32Type();\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n-\n-  std::vector<Value> lhs_parts = SplitF32(b, dot_operands.lhs, kNumParts);\n-  std::vector<Value> rhs_parts = SplitF32(b, dot_operands.rhs, kNumParts);\n-\n-  Value result = triton::ZerosLike(b, dot_operands.accumulator);\n-\n-  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kLow], result);\n-  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kLow], result);\n-  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kMid], result);\n-\n-  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kMid], result);\n-\n-  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kHigh], result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kLow], result);\n-\n-  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kHigh], result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kMid], result);\n-\n-  result = ZeroNaNs(b, result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kHigh], result);\n-  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n-  return result;\n-}\n-\n-// Leverages BF16 datatype for F32 matmul computation. It follows the guidance\n-// from https://arxiv.org/pdf/1904.06376.pdf.\n-absl::StatusOr<Value> EmitBF16x6Matmul(EmitterLocOpBuilder b,\n-                                       const DotOperands& dot_operands,\n-                                       const PrecisionSpec& precision_spec) {\n-  constexpr int kNumParts = 3;\n-  constexpr int kHigh = 0;\n-  constexpr int kMid = 1;\n-  constexpr int kLow = 2;\n-\n-  Type f32 = b.getF32Type();\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n-\n-  std::vector<Value> lhs_parts = SplitF32(b, dot_operands.lhs, kNumParts);\n-  std::vector<Value> rhs_parts = SplitF32(b, dot_operands.rhs, kNumParts);\n-\n-  Value result = triton::ZerosLike(b, dot_operands.accumulator);\n-\n-  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kMid], result);\n-\n-  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kHigh], result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kLow], result);\n-\n-  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kHigh], result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kMid], result);\n-\n-  result = ZeroNaNs(b, result);\n-  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kHigh], result);\n-  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n-  return result;\n-}\n-\n-// Compute F32 matmul with 3 BF16 dots. It is less accurate than\n-// EmitBF16x6Matmul.\n-absl::StatusOr<Value> EmitBF16x3Matmul(EmitterLocOpBuilder b,\n-                                       const DotOperands& dot_operands,\n-                                       const PrecisionSpec& precision_spec) {\n-  constexpr int kNumParts = 2;\n-  constexpr int kHigh = 0;\n-  constexpr int kLow = 1;\n-\n-  Type f32 = b.getF32Type();\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n-  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n-\n-  std::vector<Value> lhs_bf16 = SplitF32(b, dot_operands.lhs, kNumParts);\n-  std::vector<Value> rhs_bf16 = SplitF32(b, dot_operands.rhs, kNumParts);\n-\n-  Value result = triton::ZerosLike(b, dot_operands.accumulator);\n-  result = IEEEDot(b, lhs_bf16[kLow], rhs_bf16[kHigh], result);\n-  result = IEEEDot(b, lhs_bf16[kHigh], rhs_bf16[kLow], result);\n-  result = ZeroNaNs(b, result);\n-  result = IEEEDot(b, lhs_bf16[kHigh], rhs_bf16[kHigh], result);\n-  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n-  return result;\n-}\n+namespace {\n \n-bool IsTf32Allowed(const HloDotInstruction& dot) {\n-  auto precision_config = dot.precision_config();\n-  if (precision_config.algorithm() == PrecisionConfig::ALG_UNSET) {\n-    return tsl::tensor_float_32_execution_enabled() &&\n-           precision_config.operand_precision(0) == PrecisionConfig::DEFAULT &&\n-           precision_config.operand_precision(1) == PrecisionConfig::DEFAULT;\n-  }\n-  return algorithm_util::HasTf32InputType(precision_config.algorithm());\n+Value EmitStableHloDotAndAdd(EmitterLocOpBuilder b, Value lhs, Value rhs,\n+                             Value acc, PrecisionSpec precision_spec) {\n+  auto lhs_type = mlir::cast<ShapedType>(lhs.getType());\n+  auto rhs_type = mlir::cast<ShapedType>(rhs.getType());\n+\n+  CHECK(lhs_type.getRank() <= 2 && rhs_type.getRank() <= 2)\n+      << \"Unsupported ranks. LHS rank: \" << lhs_type.getRank()\n+      << \" RHS rank: \" << rhs_type.getRank();\n+\n+  llvm::SmallVector<int64_t> array_attr{0};\n+  auto dot_dimension_numbers = mlir::stablehlo::DotDimensionNumbersAttr::get(\n+      b.getContext(), /*lhsBatchingDimensions=*/{},\n+      /*rhsBatchingDimensions=*/{},\n+      /*lhsContractingDimensions=*/\n+      {lhs_type.getRank() - 1},\n+      /*rhsContractingDimensions=*/\n+      {0});\n+\n+  auto precision_config = mlir::stablehlo::PrecisionConfigAttr::get(\n+      b.getContext(), {precision_spec.lhs_operand_precision,\n+                       precision_spec.rhs_operand_precision});\n+  auto dot = b.create<mlir::stablehlo::DotGeneralOp>(\n+      acc.getType(), lhs, rhs, dot_dimension_numbers,\n+      /*precision_config=*/precision_config,\n+      /*algorithm=*/\n+      stablehlo::ConvertDotAlgorithm(precision_spec.algorithm, &b));\n+\n+  auto add_result =\n+      mlir::isa<mlir::IntegerType>(dot.getResult().getType().getElementType())\n+          ? b.create<mlir::arith::AddIOp>(acc, dot)\n+          : b.create<mlir::arith::AddFOp>(acc, dot);\n+  return add_result->getResult(0);\n }\n \n-ttir::InputPrecision InferDotPrecision(const HloDotInstruction& dot) {\n-  if (dot.precision_config().algorithm() ==\n-      PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3) {\n-    return ttir::InputPrecision::TF32x3;\n-  }\n-\n-  return IsTf32Allowed(dot) ? ttir::InputPrecision::TF32\n-                            : ttir::InputPrecision::IEEE;\n-}\n+}  // namespace\n \n absl::StatusOr<Type> GetAlgUnsetAccumulatorType(EmitterLocOpBuilder b,\n                                                 const HloDotInstruction& dot) {\n@@ -321,102 +186,6 @@ absl::StatusOr<Type> GetAlgUnsetAccumulatorType(EmitterLocOpBuilder b,\n                                                         : b.getF32Type();\n }\n \n-absl::StatusOr<Value> EmitDotAlgUnset(EmitterLocOpBuilder b,\n-                                      const DotOperands& dot_operands,\n-                                      const PrecisionSpec& precision_spec) {\n-  // Execute matrix multiplication of input tiles and pass the accumulator.\n-  // TODO(manany): Should be looked into once we enable Hopper workloads.\n-  // maxNumImpreciseAcc flag was introduced for Hopper to accumulate in a\n-  // lower precision than the output type. The change was introduced here:\n-  // https://github.com/openai/triton/commit/31b0c521427109a8eda609b58d756c380b21599a\n-  Value lhs = dot_operands.lhs;\n-  Value rhs = dot_operands.rhs;\n-  Value acc = dot_operands.accumulator;\n-\n-  int max_num_imprecise_acc = 0;\n-  if (ElementType(lhs).isFloat(8) || ElementType(rhs).isFloat(8)) {\n-    // For fp8 dots, disable accumulator promotion to mimick cuBLAS. It may make\n-    // sense to enable frequent accumulator promotion at higher matmul\n-    // precisions set in the config.\n-    max_num_imprecise_acc = std::numeric_limits<int>::max();\n-  }\n-\n-  return b.create<ttir::DotOp>(\n-      lhs, rhs, acc,\n-      /*inputPrecision=*/precision_spec.ttir_input_precision,\n-      /*maxNumImpreciseAcc=*/max_num_imprecise_acc);\n-}\n-\n-absl::StatusOr<Value> EmitRegularDot(EmitterLocOpBuilder b,\n-                                     const DotOperands& dot_operands,\n-                                     const PrecisionSpec& precision_spec) {\n-  Value lhs = dot_operands.lhs;\n-  Value rhs = dot_operands.rhs;\n-\n-  int max_num_imprecise_acc = 0;\n-  if (ElementType(lhs).isFloat(8) || ElementType(rhs).isFloat(8)) {\n-    // For fp8 dots, disable accumulator promotion to mimick cuBLAS. It may make\n-    // sense to enable frequent accumulator promotion at higher matmul\n-    // precisions set in the config.\n-    max_num_imprecise_acc = std::numeric_limits<int>::max();\n-  }\n-\n-  // Cast F32 inputs to BF16 if the algorithm is BF16_BF16_F32.\n-  // TODO(bchetioui): abstract this.\n-  if (precision_spec.algorithm == PrecisionConfig::ALG_DOT_BF16_BF16_F32) {\n-    if (ElementType(lhs).isF32()) {\n-      lhs = Cast(b, lhs, b.getBF16Type());\n-    }\n-\n-    if (ElementType(rhs).isF32()) {\n-      rhs = Cast(b, rhs, b.getBF16Type());\n-    }\n-  }\n-\n-  return b.create<ttir::DotOp>(\n-      dot_operands.lhs, dot_operands.rhs, dot_operands.accumulator,\n-      /*inputPrecision=*/precision_spec.ttir_input_precision,\n-      /*maxNumImpreciseAcc=*/max_num_imprecise_acc);\n-}\n-\n-// Returns an emitter for the given dot algorithm. Raises an\n-// `UnimplementedError` if the algorithm is not supported.\n-absl::StatusOr<AlgorithmEmitter> GetAlgorithmEmitter(\n-    const PrecisionConfig::Algorithm algorithm) {\n-  switch (algorithm) {\n-    case PrecisionConfig::ALG_UNSET:\n-      return EmitDotAlgUnset;\n-    case PrecisionConfig::ALG_DOT_F16_F16_F16:\n-    case PrecisionConfig::ALG_DOT_F32_F32_F32:\n-    case PrecisionConfig::ALG_DOT_F64_F64_F64:\n-    case PrecisionConfig::ALG_DOT_F16_F16_F32:\n-    case PrecisionConfig::ALG_DOT_BF16_BF16_BF16:\n-    case PrecisionConfig::ALG_DOT_BF16_BF16_F32:\n-      return EmitRegularDot;\n-    case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X3:\n-      return EmitBF16x3Matmul;\n-    case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X6:\n-      return EmitBF16x6Matmul;\n-    case PrecisionConfig::ALG_DOT_TF32_TF32_F32:\n-      // TODO(bchetioui): this should be factored out of EmitRegularDot.\n-      return EmitRegularDot;\n-    case PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3:\n-      // TODO(bchetioui): this should be factored out of EmitRegularDot.\n-      return EmitRegularDot;\n-    case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X9:\n-      return EmitBF16x9Matmul;\n-    case PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32:\n-    case PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32_FAST_ACCUM:\n-    default:\n-      break;\n-  }\n-\n-  // Couldn't find an algorithm emitter for this algorithm. Raise an error.\n-  return absl::UnimplementedError(\n-      absl::StrCat(\"This algorithm is not supported yet: \",\n-                   PrecisionConfig::Algorithm_Name(algorithm)));\n-}\n-\n // Returns the `Type` that the dot operands should be casted to if there is a\n // clear candidate. Raises an error if there are multiple allowed choices but\n // the operands do not already conform to any of them. Returns `std::nullopt` if\n@@ -490,11 +259,11 @@ absl::StatusOr<Value> EmitSingleTileDot(EmitterLocOpBuilder b,\n                                         DotOperands dot_operands) {\n   PrecisionConfig::Algorithm algorithm = dot.precision_config().algorithm();\n   PrecisionSpec precision_spec{\n-      algorithm, dot.precision_config().operand_precision(0),\n-      dot.precision_config().operand_precision(1), InferDotPrecision(dot)};\n-\n-  TF_ASSIGN_OR_RETURN(AlgorithmEmitter algorithm_emitter,\n-                      GetAlgorithmEmitter(algorithm));\n+      algorithm,\n+      XlaPrecisionToStableHloPrecision(\n+          dot.precision_config().operand_precision(0)),\n+      XlaPrecisionToStableHloPrecision(\n+          dot.precision_config().operand_precision(1))};\n \n   TF_ASSIGN_OR_RETURN(std::optional<Type> force_operands_type,\n                       GetForceOperandsType(b, dot, dot_operands));\n@@ -517,8 +286,9 @@ absl::StatusOr<Value> EmitSingleTileDot(EmitterLocOpBuilder b,\n         Cast(b, dot_operands.accumulator, force_accumulator_type);\n   }\n \n-  TF_ASSIGN_OR_RETURN(Value result,\n-                      algorithm_emitter(b, dot_operands, precision_spec));\n+  Value result =\n+      EmitStableHloDotAndAdd(b, dot_operands.lhs, dot_operands.rhs,\n+                             dot_operands.accumulator, precision_spec);\n \n   // TODO(b/393299275): once we've moved on from the legacy emitter, we should\n   // make sure that this accumulator type is equal to the one derived here."
        },
        {
            "sha": "1a55f393fdbe8ad80aa1ec92b5e7829644bd14ea",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms.h?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"mlir/IR/Types.h\"\n #include \"mlir/IR/Value.h\"\n+#include \"stablehlo/dialect/StablehloOps.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n@@ -27,6 +28,15 @@ namespace xla {\n namespace gpu {\n namespace triton {\n \n+// Precision-relevant configuration bits for `dot`s.\n+struct PrecisionSpec {\n+  PrecisionConfig::Algorithm algorithm;\n+  // TODO(bchetioui): we hope to get rid of operand precisions eventually, they\n+  // are currently a (XLA-wide) bridge to work with ALG_UNSET.\n+  mlir::stablehlo::Precision lhs_operand_precision;\n+  mlir::stablehlo::Precision rhs_operand_precision;\n+};\n+\n // Carries named `Value`s corresponding to `dot` operands. This includes an\n // accumulator.\n struct DotOperands {"
        },
        {
            "sha": "90ed34c2ee8b799c7ec697b6ba9e779e59dd7350",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 114,
            "deletions": 17,
            "changes": 131,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -3409,10 +3409,20 @@ ENTRY entry {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  // We expect that for loop instruction will be optimized away.\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fdot\", R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(this, kHloText, \"fdot\",\n+                                                    R\"(\n+CHECK:  stablehlo.dot_general\n+CHECK:  arith.addf\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK: tt.dot {{.*}} -> tensor<16x16xf32>\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"fdot\")));\n+\n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       kHloText, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n }\n@@ -3472,8 +3482,32 @@ ENTRY entry {\n \n   const bool is_tma_allowed = GetParam();\n   std::string hlo_text = absl::Substitute(kHloTextTemplate, is_tma_allowed);\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, hlo_text, \"fdot\", R\"(\n-CHECK:      xtile.entry_func @triton_fn(%[[ARG0:[A-Za-z0-9_]*]]: memref<32x123xf32>\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(this, hlo_text, \"fdot\",\n+                                                    R\"(\n+CHECK:      xtile.entry_func @xtile_dialect_fn(%[[ARG0:[A-Za-z0-9_]*]]: memref<32x123xf32>\n+CHECK-SAME:                             %[[ARG1:[A-Za-z0-9_]*]]: memref<123x512xf32>\n+CHECK-SAME:                             %[[ARG2:[A-Za-z0-9_]*]]: memref<32x512xf32>\n+CHECK-DAG:  %[[C0:.*]] = arith.constant 0 : index\n+CHECK-DAG:  %[[C4:.*]] = arith.constant 4 : index\n+CHECK-DAG:  %[[C1:.*]] = arith.constant 1 : index\n+CHECK:      {{.*}} = scf.for %{{.*}} = %[[C0]] to %[[C4]] step %[[C1]]\n+CHECK-SAME: iter_args({{.*}}) -> (tensor<16x64xf32>) {\n+CHECK-DAG:  xtile.extract %[[ARG0]]\n+CHECK-DAG:  xtile.extract %[[ARG1]]\n+CHECK-DAG:  arith.subf {{.*}} : tensor<16x32xf32>\n+CHECK-DAG:  math.absf {{.*}} : tensor<32x64xf32>\n+CHECK:      stablehlo.dot_general {{.*}} (tensor<16x32xf32>, tensor<32x64xf32>) -> tensor<16x64xf32>\n+CHECK:      arith.addf {{.*}}\n+CHECK:      scf.yield {{.*}} : tensor<16x64xf32>\n+CHECK-COUNT-1: xtile.insert\n+\n+          )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:      xtile.entry_func @xtile_dialect_fn(%[[ARG0:[A-Za-z0-9_]*]]: memref<32x123xf32>\n CHECK-SAME:                             %[[ARG1:[A-Za-z0-9_]*]]: memref<123x512xf32>\n CHECK-SAME:                             %[[ARG2:[A-Za-z0-9_]*]]: memref<32x512xf32>\n CHECK-DAG:  %[[C0:.*]] = arith.constant 0 : index\n@@ -3488,7 +3522,9 @@ CHECK-DAG:  math.absf {{.*}} : tensor<32x64xf32>\n CHECK:      tt.dot {{.*}} tensor<16x32xf32> * tensor<32x64xf32> -> tensor<16x64xf32>\n CHECK:      scf.yield {{.*}} : tensor<16x64xf32>\n CHECK-COUNT-1: xtile.insert\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"fdot\")));\n+\n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       hlo_text, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n }\n@@ -3610,7 +3646,21 @@ ENTRY entry {\n           \"num_stages\":\"1\"}}}\n })\";\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fdot\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(this, kHloText, \"fdot\", R\"(\n+  // Ensure that masking is applied only conditionally to both operands.\n+  CHECK:      %[[MASKED_OPERAND0:.*]] = scf.if\n+  CHECK:        %[[SELECT0:.*]] = arith.select\n+  CHECK-NEXT:   scf.yield %[[SELECT0]]\n+  CHECK:      %[[MASKED_OPERAND1:.*]] = scf.if\n+  CHECK:        %[[SELECT1:.*]] = arith.select\n+  CHECK-NEXT:   scf.yield %[[SELECT1]]\n+  CHECK:      stablehlo.dot_general %[[MASKED_OPERAND0]], %[[MASKED_OPERAND1]]\n+  CHECK:      arith.addf %{{.*}}\n+  )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n   // Ensure that masking is applied only conditionally to both operands.\n   CHECK:      %[[MASKED_OPERAND0:.*]] = scf.if\n   CHECK:        %[[SELECT0:.*]] = arith.select\n@@ -3619,7 +3669,8 @@ ENTRY entry {\n   CHECK:        %[[SELECT1:.*]] = arith.select\n   CHECK-NEXT:   scf.yield %[[SELECT1]]\n   CHECK:      tt.dot %[[MASKED_OPERAND0]], %[[MASKED_OPERAND1]]\n-)\"));\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"fdot\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       kHloText, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n@@ -4157,13 +4208,26 @@ TEST_P(BasicDotAlgorithmEmitterTest, BasicAlgorithmIsEmittedCorrectly) {\n                           algorithm_util::GetDotAccumulatorType(algorithm));\n   const std::string kHloText = GetDotAlgorithmHlo(in_ty, out_ty, algorithm);\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n-      this, kHloText, \"dot\",\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(\n+          this, kHloText, \"dot\",\n+          absl::Substitute(\n+              R\"(\n+  CHECK:  stablehlo.dot_general{{.*}} : (tensor<16x32x$0>, tensor<32x64x$0>) -> tensor<16x64x$1>\n+  CHECK:  arith.addf\n+  )\",\n+              primitive_util::LowercasePrimitiveTypeName(in_ty),\n+              primitive_util::LowercasePrimitiveTypeName(out_ty))));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(),\n       absl::Substitute(R\"(\n   CHECK:  tt.dot{{.*}} : tensor<16x32x$0> * tensor<32x64x$0> -> tensor<16x64x$1>\n   )\",\n                        primitive_util::LowercasePrimitiveTypeName(in_ty),\n-                       primitive_util::LowercasePrimitiveTypeName(out_ty))));\n+                       primitive_util::LowercasePrimitiveTypeName(out_ty)),\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"dot\")));\n \n   EXPECT_TRUE(\n       RunAndCompareNoHloPasses(kHloText, ErrorSpecForDotAlgorithm(algorithm)));\n@@ -4197,21 +4261,26 @@ TEST_P(MultiDotAlgorithmEmitterTest, MultiDotAlgorithmIsEmittedCorrectly) {\n       algorithm == PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3 ? F32 : BF16;\n   // Dummy value to ensure that the dot count is explicitly set.\n   int dot_count_for_algorithm = 0x1337;\n+  int stablehlo_dot_count_for_algorithm = 0x1337;\n   std::string input_precision_string = \"\";\n   switch (algorithm) {\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X3:\n       dot_count_for_algorithm = 3;\n+      stablehlo_dot_count_for_algorithm = 3;\n       break;\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X6:\n       dot_count_for_algorithm = 6;\n+      stablehlo_dot_count_for_algorithm = 6;\n       break;\n     case PrecisionConfig::ALG_DOT_BF16_BF16_F32_X9:\n       dot_count_for_algorithm = 9;\n+      stablehlo_dot_count_for_algorithm = 9;\n       break;\n     case PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3:\n       // Triton implements TF32x3 as a specific precision mode.\n       input_precision_string = \"tf32x3\";\n       dot_count_for_algorithm = 1;\n+      stablehlo_dot_count_for_algorithm = 3;\n       break;\n     default:\n       // Unreachable.\n@@ -4220,14 +4289,24 @@ TEST_P(MultiDotAlgorithmEmitterTest, MultiDotAlgorithmIsEmittedCorrectly) {\n \n   const std::string kHloText = GetDotAlgorithmHlo(in_ty, out_ty, algorithm);\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n-      this, kHloText, \"dot\",\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"dot\",\n+                                absl::Substitute(\n+                                    R\"(\n+  CHECK:  stablehlo.dot_general{{.*}} num_primitive_operations = $0, {{.*}}\n+  )\",\n+                                    stablehlo_dot_count_for_algorithm)));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(),\n       absl::Substitute(R\"(\n   CHECK-COUNT-$2:  tt.dot{{.*}}$3{{.*}} : tensor<16x32x$0> * tensor<32x64x$0> -> tensor<16x64x$1>\n   )\",\n                        primitive_util::LowercasePrimitiveTypeName(in_ty),\n                        primitive_util::LowercasePrimitiveTypeName(out_ty),\n-                       dot_count_for_algorithm, input_precision_string)));\n+                       dot_count_for_algorithm, input_precision_string),\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"dot\")));\n \n   EXPECT_TRUE(\n       RunAndCompareNoHloPasses(kHloText, ErrorSpecForDotAlgorithm(algorithm)));\n@@ -4260,14 +4339,32 @@ TEST_P(TF32DotAlgorithmEmitterTest, TF32AlgorithmsUseTF32InputPrecision) {\n       algorithm == PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3 ? \"tf32x3\"\n                                                              : \"tf32\";\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n-      this, kHloText, \"dot\",\n+  std::string num_primitive_operations_string =\n+      algorithm == PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3 ? \"3\" : \"1\";\n+\n+  // TODO(basioli): maybe algorithm string?\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(\n+          this, kHloText, \"dot\",\n+          absl::Substitute(\n+              R\"(\n+  CHECK:  stablehlo.dot_general{{.*}}, contracting_dims = [1] x [0], {{.*}} algorithm = <lhs_precision_type = tf32, rhs_precision_type = tf32, accumulation_type = f32, lhs_component_count = 1, rhs_component_count = 1, num_primitive_operations = $2, allow_imprecise_accumulation = false> : (tensor<16x32x$0>, tensor<32x64x$0>) -> tensor<16x64x$1>\n+  )\",\n+              primitive_util::LowercasePrimitiveTypeName(in_ty),\n+              primitive_util::LowercasePrimitiveTypeName(out_ty),\n+              num_primitive_operations_string)));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(),\n       absl::Substitute(R\"(\n   CHECK:  tt.dot{{.*}} inputPrecision = $2 : tensor<16x32x$0> * tensor<32x64x$0> -> tensor<16x64x$1>\n   )\",\n                        primitive_util::LowercasePrimitiveTypeName(in_ty),\n                        primitive_util::LowercasePrimitiveTypeName(out_ty),\n-                       input_precision_string)));\n+                       input_precision_string),\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second, \"dot\")));\n+\n   // No need to `RunAndCompare` here, these algorithms are already covered by\n   // other tests.\n }"
        },
        {
            "sha": "41050c7d0a472a9c01021e70fcac85ed8861e259",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 0,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -254,6 +254,61 @@ CHECK: %[[RES:.*]] = stablehlo.reshape %[[ARG:.*]] : (tensor<16xi32>) -> tensor<\n )\"));\n }\n \n+TEST_F(XTileDialectTest, HloDotIsLoweredToStableHloDot) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule t\n+\n+flhs {\n+  ROOT flhs.p0 = f32[150,160] parameter(0)\n+}\n+\n+frhs {\n+  ROOT frhs.p0 = f32[160,31] parameter(0)\n+}\n+\n+dot_fusion {\n+  fdot.p0 = f32[150,160] parameter(0)\n+  fdot.p1 = f32[160,31] parameter(1)\n+  fdot.lhs = f32[150,160] fusion(fdot.p0), kind=kCustom, calls=flhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"32\", \"8\"]}]\n+      }\n+    }\n+  }\n+  fdot.rhs = f32[160,31]{1,0} fusion(fdot.p1), kind=kCustom, calls=frhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"32\", \"8\"]}]\n+      }\n+    }\n+  }\n+\n+  ROOT dot = f32[150,31] dot(fdot.lhs, fdot.rhs), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[150, 160] parameter(0)\n+  p1 = f32[160, 31] parameter(1)\n+  ROOT custom-call = f32[150,31] fusion(p0, p1), kind=kCustom,\n+    calls=dot_fusion,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton\"}}\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHloText));\n+\n+  BlockLevelParameters block_level_parameters;\n+  block_level_parameters.output_tile_sizes = {{32, 8}};\n+\n+  TF_EXPECT_OK(CreateXTileIrAndFileCheck(\n+      this, *module->GetComputationWithName(\"dot_fusion\"),\n+      block_level_parameters,\n+      R\"(\n+CHECK: %[[RES:.*]] = stablehlo.dot_general %[[ARG0:.*]], %[[ARG1:.*]], contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<32x8xf32>, tensor<8x8xf32>) -> tensor<32x8xf32>\n+CHECK: %[[ADD_RES:.*]] = arith.addf %[[ARG2:.*]], %[[RES]] : tensor<32x8xf32>\n+)\"));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "2f61357ba2536233d8938b907024e94aef19372e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -54,21 +54,26 @@ cc_library(\n         \":passes_inc_gen\",\n         \"//xla:permutation_util\",\n         \"//xla:util\",\n+        \"//xla/backends/gpu/codegen/triton:dot_algorithms\",\n         \"//xla/backends/gpu/codegen/triton:emitter_helpers\",\n         \"//xla/backends/gpu/codegen/triton/ir:triton_xla\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/codegen/emitters/ir:xla\",\n         \"//xla/codegen/xtile/ir:xtile\",\n+        \"//xla/hlo/translate/mhlo_to_hlo:attribute_exporter\",\n+        \"//xla/service:algorithm_util\",\n         \"//xla/service/gpu:target_util\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n+        \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n@@ -92,6 +97,7 @@ cc_library(\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TensorDialect\",\n         \"@llvm-project//mlir:TransformUtils\",\n+        \"@local_tsl//tsl/platform:tensor_float_32_hdr_lib\",\n         \"@stablehlo//:stablehlo_ops\",\n         \"@triton//:TritonDialects\",\n     ],"
        },
        {
            "sha": "96f94f8ffce981d500db0acb4e2e71ecb53fbdd3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 462,
            "deletions": 1,
            "changes": 463,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -14,31 +14,47 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cstdint>\n+#include <iterator>\n+#include <limits>\n #include <memory>\n+#include <string>\n #include <utility>\n+#include <vector>\n \n #include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/Support/Casting.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/Math/IR/Math.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n #include \"mlir/IR/IRMapping.h\"\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Support/LogicalResult.h\"\n #include \"mlir/Transforms/DialectConversion.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n+#include \"xla/backends/gpu/codegen/triton/dot_algorithms.h\"\n+#include \"xla/backends/gpu/codegen/triton/emitter_helpers.h\"\n #include \"xla/codegen/emitter_loc_op_builder.h\"\n #include \"xla/codegen/xtile/ir/xtile_ops.h\"\n+#include \"xla/hlo/translate/mhlo_to_hlo/attribute_exporter.h\"\n+#include \"xla/service/algorithm_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"tsl/platform/tensor_float_32_utils.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n \n namespace mlir::triton::xla {\n@@ -327,14 +343,459 @@ class LowerReshape : public mlir::OpRewritePattern<stablehlo::ReshapeOp> {\n   }\n };\n \n+namespace {\n+\n+LogicalResult PopulateOperandPrecision(PatternRewriter& rewriter,\n+                                       stablehlo::DotGeneralOp op,\n+                                       stablehlo::Precision& lhs_precision,\n+                                       stablehlo::Precision& rhs_precision) {\n+  auto precision_config = op.getPrecisionConfig();\n+\n+  if (!precision_config.has_value()) {\n+    return rewriter.notifyMatchFailure(op->getLoc(),\n+                                       \"Dot op must have precision config.\");\n+  }\n+\n+  if (precision_config.value().size() != 2) {\n+    return rewriter.notifyMatchFailure(\n+        op->getLoc(),\n+        \"Dot op must have exactly two precisions. One for lhs and one for \"\n+        \"rhs.\");\n+  }\n+\n+  auto lhs_precision_attr =\n+      mlir::cast<stablehlo::PrecisionAttr>(precision_config.value()[0]);\n+  auto rhs_precision_attr =\n+      mlir::cast<stablehlo::PrecisionAttr>(precision_config.value()[1]);\n+\n+  lhs_precision = lhs_precision_attr.getValue();\n+  rhs_precision = rhs_precision_attr.getValue();\n+\n+  return mlir::success();\n+}\n+\n+::xla::PrecisionConfig::Precision StableHloPrecisionToXlaPrecision(\n+    stablehlo::Precision precision) {\n+  switch (precision) {\n+    case stablehlo::Precision::DEFAULT:\n+      return ::xla::PrecisionConfig::DEFAULT;\n+    case stablehlo::Precision::HIGH:\n+      return ::xla::PrecisionConfig::HIGH;\n+    case stablehlo::Precision::HIGHEST:\n+      return ::xla::PrecisionConfig::HIGHEST;\n+    default:\n+      LOG(FATAL) << \"Unsupported precision\";\n+  }\n+}\n+\n+// Triton implementations of dot algorithms.\n+\n+struct TritonPrecisionSpec {\n+  ::xla::PrecisionConfig::Algorithm algorithm;\n+  // Encodes `tt.dot`'s `inputPrecision` attribute.\n+  ttir::InputPrecision ttir_input_precision;\n+};\n+\n+mlir::Type ElementType(mlir::Value v) { return mlir::getElementTypeOrSelf(v); }\n+\n+using AlgorithmEmitter = absl::StatusOr<Value> (*)(\n+    ::xla::EmitterLocOpBuilder, const ::xla::gpu::triton::DotOperands&,\n+    const TritonPrecisionSpec&);\n+\n+absl::StatusOr<Value> EmitDotAlgUnset(\n+    ::xla::EmitterLocOpBuilder b,\n+    const ::xla::gpu::triton::DotOperands& dot_operands,\n+    const TritonPrecisionSpec& precision_spec) {\n+  // Execute matrix multiplication of input tiles and pass the accumulator.\n+  // TODO(manany): Should be looked into once we enable Hopper workloads.\n+  // maxNumImpreciseAcc flag was introduced for Hopper to accumulate in a\n+  // lower precision than the output type. The change was introduced here:\n+  // https://github.com/openai/triton/commit/31b0c521427109a8eda609b58d756c380b21599a\n+  Value lhs = dot_operands.lhs;\n+  Value rhs = dot_operands.rhs;\n+  Value acc = dot_operands.accumulator;\n+\n+  int max_num_imprecise_acc = 0;\n+  if (ElementType(lhs).isFloat(8) || ElementType(rhs).isFloat(8)) {\n+    // For fp8 dots, disable accumulator promotion to mimick cuBLAS. It may make\n+    // sense to enable frequent accumulator promotion at higher matmul\n+    // precisions set in the config.\n+    max_num_imprecise_acc = std::numeric_limits<int>::max();\n+  }\n+\n+  return b.create<ttir::DotOp>(\n+      lhs, rhs, acc,\n+      /*inputPrecision=*/precision_spec.ttir_input_precision,\n+      /*maxNumImpreciseAcc=*/max_num_imprecise_acc);\n+}\n+\n+absl::StatusOr<Value> EmitRegularDot(\n+    ::xla::EmitterLocOpBuilder b,\n+    const ::xla::gpu::triton::DotOperands& dot_operands,\n+    const TritonPrecisionSpec& precision_spec) {\n+  Value lhs = dot_operands.lhs;\n+  Value rhs = dot_operands.rhs;\n+\n+  int max_num_imprecise_acc = 0;\n+  if (ElementType(lhs).isFloat(8) || ElementType(rhs).isFloat(8)) {\n+    // For fp8 dots, disable accumulator promotion to mimick cuBLAS. It may make\n+    // sense to enable frequent accumulator promotion at higher matmul\n+    // precisions set in the config.\n+    max_num_imprecise_acc = std::numeric_limits<int>::max();\n+  }\n+\n+  // Cast F32 inputs to BF16 if the algorithm is BF16_BF16_F32.\n+  // TODO(bchetioui): abstract this.\n+  if (precision_spec.algorithm ==\n+      ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_F32) {\n+    if (ElementType(lhs).isF32()) {\n+      lhs = ::xla::gpu::triton::Cast(b, lhs, b.getBF16Type());\n+    }\n+\n+    if (ElementType(rhs).isF32()) {\n+      rhs = ::xla::gpu::triton::Cast(b, rhs, b.getBF16Type());\n+    }\n+  }\n+\n+  return b.create<ttir::DotOp>(\n+      dot_operands.lhs, dot_operands.rhs, dot_operands.accumulator,\n+      /*inputPrecision=*/precision_spec.ttir_input_precision,\n+      /*maxNumImpreciseAcc=*/max_num_imprecise_acc);\n+}\n+\n+// If lhs is 1.0, we will have lhs_high = 1.0 and lhs_low = 0.0.\n+// If rhs is +infinity, we will have:\n+// +infinity * 1.0 = +infinity\n+// +infinity * 0.0 = NaN\n+// We would get the wrong result if we sum these partial products. Instead, we\n+// must override any accumulated result if the last partial product is\n+// non-finite. See b/115844437.\n+Value ZeroNaNs(::xla::EmitterLocOpBuilder b, Value input) {\n+  Value positive_inf = ::xla::gpu::triton::CreateConst<float>(\n+      b, b.getF32Type(), std::numeric_limits<float>::infinity(),\n+      mlir::cast<ShapedType>(input.getType()).getShape());\n+  Value abs_input = b.create<math::AbsFOp>(input);\n+  Value is_finite = b.create<arith::CmpFOp>(arith::CmpFPredicate::OGT,\n+                                            positive_inf, abs_input);\n+  return b.create<arith::SelectOp>(is_finite, input,\n+                                   ::xla::gpu::triton::ZerosLike(b, input));\n+}\n+\n+absl::Status ExpectType(Value v, Type expected_type) {\n+  if (ElementType(v) != expected_type) {\n+    std::string expected_type_str, actual_type_str;\n+    {\n+      llvm::raw_string_ostream os_expected(expected_type_str);\n+      llvm::raw_string_ostream os_actual(actual_type_str);\n+      expected_type.print(os_expected);\n+      ElementType(v).print(os_actual);\n+    }\n+    return absl::FailedPreconditionError(absl::StrCat(\n+        \"Expected type \", expected_type_str, \" but got \", actual_type_str));\n+  }\n+  return absl::OkStatus();\n+}\n+\n+std::vector<Value> SplitF32(::xla::EmitterLocOpBuilder b, Value input,\n+                            int split_count) {\n+  std::vector<Value> split_inputs;\n+  split_inputs.reserve(split_count);\n+  for (int i = 0; i < split_count; ++i) {\n+    Value input_as_bf16 = ::xla::gpu::triton::Cast(b, input, b.getBF16Type());\n+    if (i != split_count - 1) {\n+      Value input_as_f32 =\n+          ::xla::gpu::triton::Cast(b, input_as_bf16, b.getF32Type());\n+      input = b.create<arith::SubFOp>(input, input_as_f32);\n+    }\n+    split_inputs.push_back(input_as_bf16);\n+  }\n+  return split_inputs;\n+}\n+\n+Value IEEEDot(::xla::EmitterLocOpBuilder b, Value lhs, Value rhs, Value acc) {\n+  return b.create<ttir::DotOp>(lhs, rhs, acc,\n+                               /*inputPrecision=*/ttir::InputPrecision::IEEE,\n+                               /*maxNumImpreciseAcc=*/0);\n+}\n+\n+// Leverages BF16 datatype for F32 matmul computation. It follows the guidance\n+// from https://arxiv.org/pdf/1904.06376.pdf.\n+absl::StatusOr<Value> EmitBF16x9Matmul(\n+    ::xla::EmitterLocOpBuilder b,\n+    const ::xla::gpu::triton::DotOperands& dot_operands,\n+    const TritonPrecisionSpec& precision_spec) {\n+  constexpr int kNumParts = 3;\n+  constexpr int kHigh = 0;\n+  constexpr int kMid = 1;\n+  constexpr int kLow = 2;\n+\n+  Type f32 = b.getF32Type();\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n+\n+  std::vector<Value> lhs_parts = SplitF32(b, dot_operands.lhs, kNumParts);\n+  std::vector<Value> rhs_parts = SplitF32(b, dot_operands.rhs, kNumParts);\n+\n+  Value result = ::xla::gpu::triton::ZerosLike(b, dot_operands.accumulator);\n+\n+  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kLow], result);\n+  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kLow], result);\n+  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kMid], result);\n+\n+  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kMid], result);\n+\n+  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kHigh], result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kLow], result);\n+\n+  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kHigh], result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kMid], result);\n+\n+  result = ZeroNaNs(b, result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kHigh], result);\n+  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n+  return result;\n+}\n+\n+// Leverages BF16 datatype for F32 matmul computation. It follows the guidance\n+// from https://arxiv.org/pdf/1904.06376.pdf.\n+absl::StatusOr<Value> EmitBF16x6Matmul(\n+    ::xla::EmitterLocOpBuilder b,\n+    const ::xla::gpu::triton::DotOperands& dot_operands,\n+    const TritonPrecisionSpec& precision_spec) {\n+  constexpr int kNumParts = 3;\n+  constexpr int kHigh = 0;\n+  constexpr int kMid = 1;\n+  constexpr int kLow = 2;\n+\n+  Type f32 = b.getF32Type();\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n+\n+  std::vector<Value> lhs_parts = SplitF32(b, dot_operands.lhs, kNumParts);\n+  std::vector<Value> rhs_parts = SplitF32(b, dot_operands.rhs, kNumParts);\n+\n+  Value result = ::xla::gpu::triton::ZerosLike(b, dot_operands.accumulator);\n+\n+  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kMid], result);\n+\n+  result = IEEEDot(b, lhs_parts[kLow], rhs_parts[kHigh], result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kLow], result);\n+\n+  result = IEEEDot(b, lhs_parts[kMid], rhs_parts[kHigh], result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kMid], result);\n+\n+  result = ZeroNaNs(b, result);\n+  result = IEEEDot(b, lhs_parts[kHigh], rhs_parts[kHigh], result);\n+  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n+  return result;\n+}\n+\n+// Compute F32 matmul with 3 BF16 dots. It is less accurate than\n+// EmitBF16x6Matmul.\n+absl::StatusOr<Value> EmitBF16x3Matmul(\n+    ::xla::EmitterLocOpBuilder b,\n+    const ::xla::gpu::triton::DotOperands& dot_operands,\n+    const TritonPrecisionSpec& precision_spec) {\n+  constexpr int kNumParts = 2;\n+  constexpr int kHigh = 0;\n+  constexpr int kLow = 1;\n+\n+  Type f32 = b.getF32Type();\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.lhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.rhs, f32));\n+  TF_RETURN_IF_ERROR(ExpectType(dot_operands.accumulator, f32));\n+\n+  std::vector<Value> lhs_bf16 = SplitF32(b, dot_operands.lhs, kNumParts);\n+  std::vector<Value> rhs_bf16 = SplitF32(b, dot_operands.rhs, kNumParts);\n+\n+  Value result = ::xla::gpu::triton::ZerosLike(b, dot_operands.accumulator);\n+  result = IEEEDot(b, lhs_bf16[kLow], rhs_bf16[kHigh], result);\n+  result = IEEEDot(b, lhs_bf16[kHigh], rhs_bf16[kLow], result);\n+  result = ZeroNaNs(b, result);\n+  result = IEEEDot(b, lhs_bf16[kHigh], rhs_bf16[kHigh], result);\n+  result = b.create<arith::AddFOp>(dot_operands.accumulator, result);\n+  return result;\n+}\n+\n+// Returns an emitter for the given dot algorithm. Raises an\n+// `UnimplementedError` if the algorithm is not supported.\n+absl::StatusOr<AlgorithmEmitter> GetAlgorithmEmitter(\n+    const ::xla::PrecisionConfig::Algorithm algorithm) {\n+  switch (algorithm) {\n+    case ::xla::PrecisionConfig::ALG_UNSET:\n+      return EmitDotAlgUnset;\n+    case ::xla::PrecisionConfig::ALG_DOT_F16_F16_F16:\n+    case ::xla::PrecisionConfig::ALG_DOT_F32_F32_F32:\n+    case ::xla::PrecisionConfig::ALG_DOT_F64_F64_F64:\n+    case ::xla::PrecisionConfig::ALG_DOT_F16_F16_F32:\n+    case ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_BF16:\n+    case ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_F32:\n+      return EmitRegularDot;\n+    case ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_F32_X3:\n+      return EmitBF16x3Matmul;\n+    case ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_F32_X6:\n+      return EmitBF16x6Matmul;\n+    case ::xla::PrecisionConfig::ALG_DOT_TF32_TF32_F32:\n+      // TODO(bchetioui): this should be factored out of EmitRegularDot.\n+      return EmitRegularDot;\n+    case ::xla::PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3:\n+      // TODO(bchetioui): this should be factored out of EmitRegularDot.\n+      return EmitRegularDot;\n+    case ::xla::PrecisionConfig::ALG_DOT_BF16_BF16_F32_X9:\n+      return EmitBF16x9Matmul;\n+    case ::xla::PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32:\n+    case ::xla::PrecisionConfig::ALG_DOT_ANY_F8_ANY_F8_F32_FAST_ACCUM:\n+    default:\n+      break;\n+  }\n+\n+  // Couldn't find an algorithm emitter for this algorithm. Raise an error.\n+  return absl::UnimplementedError(\n+      absl::StrCat(\"This algorithm is not supported yet: \",\n+                   ::xla::PrecisionConfig::Algorithm_Name(algorithm)));\n+}\n+\n+bool IsTf32Allowed(const ::xla::gpu::triton::PrecisionSpec& precision_spec) {\n+  if (precision_spec.algorithm == ::xla::PrecisionConfig::ALG_UNSET) {\n+    return tsl::tensor_float_32_execution_enabled() &&\n+           StableHloPrecisionToXlaPrecision(\n+               precision_spec.lhs_operand_precision) ==\n+               ::xla::PrecisionConfig::DEFAULT &&\n+           StableHloPrecisionToXlaPrecision(\n+               precision_spec.rhs_operand_precision) ==\n+               ::xla::PrecisionConfig::DEFAULT;\n+  }\n+  return ::xla::algorithm_util::HasTf32InputType(precision_spec.algorithm);\n+}\n+\n+ttir::InputPrecision InferDotPrecision(\n+    const ::xla::gpu::triton::PrecisionSpec& precision_spec) {\n+  if (precision_spec.algorithm ==\n+      ::xla::PrecisionConfig::ALG_DOT_TF32_TF32_F32_X3) {\n+    return ttir::InputPrecision::TF32x3;\n+  }\n+\n+  return IsTf32Allowed(precision_spec) ? ttir::InputPrecision::TF32\n+                                       : ttir::InputPrecision::IEEE;\n+}\n+\n+LogicalResult RewriteDotGeneralToTritonDot(mlir::PatternRewriter& rewriter,\n+                                           stablehlo::DotGeneralOp op,\n+                                           mlir::Operation* add_op,\n+                                           Value accumulator) {\n+  auto dot_algorithm = op.getAlgorithm();\n+\n+  auto hlo_algorithm_or_status =\n+      dot_algorithm.has_value()\n+          ? ::xla::ConvertDotAlgorithm(dot_algorithm.value())\n+          : ::xla::PrecisionConfig::ALG_UNSET;\n+\n+  if (!hlo_algorithm_or_status.ok()) {\n+    return rewriter.notifyMatchFailure(\n+        op->getLoc(),\n+        \"Dot op must have algorithm set to be converted to \"\n+        \"triton dot.\");\n+  }\n+\n+  auto hlo_algorithm = hlo_algorithm_or_status.value();\n+  auto algorithm_emitter_or_status = GetAlgorithmEmitter(hlo_algorithm);\n+\n+  if (!algorithm_emitter_or_status.ok()) {\n+    return rewriter.notifyMatchFailure(\n+        op->getLoc(),\n+        absl::StrCat(\"Algorithm emitter not found with error: \",\n+                     algorithm_emitter_or_status.status().message()));\n+  }\n+\n+  auto algorithm_emitter = algorithm_emitter_or_status.value();\n+\n+  ::xla::EmitterLocOpBuilder builder(op->getLoc(), rewriter);\n+\n+  ::xla::gpu::triton::DotOperands dot_operands{op.getLhs(), op.getRhs(),\n+                                               accumulator};\n+\n+  stablehlo::Precision lhs_precision;\n+  stablehlo::Precision rhs_precision;\n+\n+  if (mlir::failed(PopulateOperandPrecision(rewriter, op, lhs_precision,\n+                                            rhs_precision))) {\n+    return mlir::failure();\n+  }\n+\n+  ::xla::gpu::triton::PrecisionSpec precision_spec{hlo_algorithm, lhs_precision,\n+                                                   rhs_precision};\n+\n+  TritonPrecisionSpec triton_precision_spec{hlo_algorithm,\n+                                            InferDotPrecision(precision_spec)};\n+\n+  auto triton_dot_op_or_result =\n+      algorithm_emitter(builder, dot_operands, triton_precision_spec);\n+\n+  if (!triton_dot_op_or_result.ok()) {\n+    return rewriter.notifyMatchFailure(\n+        op->getLoc(), absl::StrCat(\"Algorithm emitter failed with error: \",\n+                                   triton_dot_op_or_result.status().message()));\n+  }\n+\n+  auto triton_dot_op = triton_dot_op_or_result.value();\n+\n+  rewriter.replaceAllOpUsesWith(add_op, op.getResult());\n+  rewriter.replaceOp(op, triton_dot_op);\n+\n+  return mlir::success();\n+}\n+\n+}  // namespace\n+\n+class LowerDotGeneral : public mlir::OpRewritePattern<stablehlo::DotGeneralOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+ private:\n+  mlir::LogicalResult matchAndRewrite(\n+      stablehlo::DotGeneralOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    if (std::distance(op->getUsers().begin(), op->getUsers().end()) != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(),\n+          \"Dot op must have exactly one user in order to be lowered to \"\n+          \"triton.\");\n+    }\n+\n+    mlir::Operation* add_op = dyn_cast<arith::AddFOp>(*op->getUsers().begin());\n+    if (!add_op) {\n+      add_op = dyn_cast<arith::AddIOp>(*op->getUsers().begin());\n+    }\n+\n+    if (!add_op) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(),\n+          \"Dot op must be consumed by an AddOp in order to be convertible to \"\n+          \"triton dot.\");\n+    }\n+\n+    // Accumulator is the operand of add that is not the dot operation.\n+    auto accumulator = add_op->getOperand(1) == op ? add_op->getOperand(0)\n+                                                   : add_op->getOperand(1);\n+\n+    if (mlir::failed(\n+            RewriteDotGeneralToTritonDot(rewriter, op, add_op, accumulator))) {\n+      return mlir::failure();\n+    }\n+    return mlir::success();\n+  }\n+};\n+\n class StableHLOLowerToTritonPass\n     : public impl::StableHLOLowerToTritonPassBase<StableHLOLowerToTritonPass> {\n  public:\n   void runOnOperation() override {\n     mlir::MLIRContext* mlir_context = &getContext();\n     mlir::RewritePatternSet patterns(mlir_context);\n     patterns.add<LowerTranspose, LowerIotaToMakeRange, LowerBroadcastInDim,\n-                 LowerReduce, LowerReshape>(mlir_context);\n+                 LowerReduce, LowerReshape, LowerDotGeneral>(mlir_context);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "b58315a54122d08d42c59bdef01cf0152fd8d066",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e57bfcf087a4dec906b05b8c57abcd82fc09c3f2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=e57bfcf087a4dec906b05b8c57abcd82fc09c3f2",
            "patch": "@@ -152,3 +152,31 @@ func.func @reshape_2d_to_0d_reduces(%arg0: tensor<1x1xf32>) -> tensor<f32> {\n   // CHECK: return %[[REDUCE_TENSOR]]\n   return %0 : tensor<f32>\n }\n+\n+// CHECK: func @lower_dot_add_to_triton(%[[ARG0:.*]]: tensor<2x4xf32>, %[[ARG1:.*]]: tensor<4x8xf32>, %[[ARG2:.*]]: tensor<2x8xf32>) -> tensor<2x8xf32>\n+func.func @lower_dot_add_to_triton(%arg0: tensor<2x4xf32>, %arg1: tensor<4x8xf32>, %arg2: tensor<2x8xf32>) -> tensor<2x8xf32> {\n+  // CHECK: %[[RES:.*]] = tt.dot %[[ARG0]], %[[ARG1]], %[[ARG2]], inputPrecision = tf32 : tensor<2x4xf32> * tensor<4x8xf32> -> tensor<2x8xf32>\n+  // CHECK-NOT: arith.addf\n+  %0 = stablehlo.dot_general %arg0, %arg1, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<2x4xf32>, tensor<4x8xf32>) -> tensor<2x8xf32>\n+  %1 = arith.addf %0, %arg2 : tensor<2x8xf32>\n+  // CHECK: return %[[RES]] : tensor<2x8xf32>\n+  return %1 : tensor<2x8xf32>\n+}\n+\n+// CHECK: func @lower_dot_without_add_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<2x4xf32>, %[[ARG1:.*]]: tensor<4x8xf32>, %[[ARG2:.*]]: tensor<2x8xf32>) -> tensor<2x8xf32>\n+func.func @lower_dot_without_add_falls_back_to_stablehlo(%arg0: tensor<2x4xf32>, %arg1: tensor<4x8xf32>, %arg2: tensor<2x8xf32>) -> tensor<2x8xf32> {\n+  // CHECK: %[[RES:.*]] = stablehlo.dot_general %[[ARG0]], %[[ARG1]], contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<2x4xf32>, tensor<4x8xf32>) -> tensor<2x8xf32>\n+  %0 = stablehlo.dot_general %arg0, %arg1, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<2x4xf32>, tensor<4x8xf32>) -> tensor<2x8xf32>\n+  // CHECK: return %[[RES]] : tensor<2x8xf32>\n+  return %0 : tensor<2x8xf32>\n+}\n+\n+// CHECK: func @lower_dot_f8_no_ieee_has_max_num_imprecise_acc_set_to_max(%[[ARG0:.*]]: tensor<2x4xf8E4M3FN>, %[[ARG1:.*]]: tensor<4x8xf8E4M3FN>, %[[ARG2:.*]]: tensor<2x8xf8E4M3FN>) -> tensor<2x8xf8E4M3FN>\n+func.func @lower_dot_f8_no_ieee_has_max_num_imprecise_acc_set_to_max(%arg0: tensor<2x4xf8E4M3FN>, %arg1: tensor<4x8xf8E4M3FN>, %arg2: tensor<2x8xf8E4M3FN>) -> tensor<2x8xf8E4M3FN> {\n+  // CHECK: %[[RES:.*]] = tt.dot %[[ARG0]], %[[ARG1]], %[[ARG2]], inputPrecision = tf32 {maxNumImpreciseAcc = 2147483647 : i32} : tensor<2x4xf8E4M3FN> * tensor<4x8xf8E4M3FN> -> tensor<2x8xf8E4M3FN>\n+  // CHECK-NOT: arith.addf\n+  %0 = stablehlo.dot_general %arg0, %arg1, contracting_dims = [1] x [0], precision = [DEFAULT, DEFAULT] : (tensor<2x4xf8E4M3FN>, tensor<4x8xf8E4M3FN>) -> tensor<2x8xf8E4M3FN>\n+  %1 = arith.addf %0, %arg2 : tensor<2x8xf8E4M3FN>\n+  // CHECK: return %[[RES]] : tensor<2x8xf8E4M3FN>\n+  return %1 : tensor<2x8xf8E4M3FN>\n+}"
        }
    ],
    "stats": {
        "total": 1032,
        "additions": 730,
        "deletions": 302
    }
}