{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 829394231",
    "sha": "62f00f3f0524f6d5a7da48c91f596cbb941e9276",
    "files": [
        {
            "sha": "47f6c83698edf35bc140e6a4bc1076311c9e550d",
            "filename": "tensorflow/core/util/activation_mode.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Factivation_mode.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Factivation_mode.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Factivation_mode.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -21,7 +21,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-absl::Status GetActivationModeFromString(const string& str_value,\n+absl::Status GetActivationModeFromString(const std::string& str_value,\n                                          ActivationMode* value) {\n   if (str_value == \"None\") {\n     *value = NONE;"
        },
        {
            "sha": "c01eff0c83530b2ae7e1a8e686a63f6f29ae8ab3",
            "filename": "tensorflow/core/util/activation_mode.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Factivation_mode.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Factivation_mode.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Factivation_mode.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -40,7 +40,7 @@ enum ActivationMode {\n };\n \n // Specialization to parse an attribute directly into a ActivationMode enum.\n-absl::Status GetActivationModeFromString(const string& str_value,\n+absl::Status GetActivationModeFromString(const std::string& str_value,\n                                          ActivationMode* value);\n \n inline absl::string_view ToString(ActivationMode mode) {"
        },
        {
            "sha": "3c0bd9abaaeafc4501e5987e44e30d799bc709cc",
            "filename": "tensorflow/core/util/bcast_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 14,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fbcast_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fbcast_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fbcast_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -23,13 +23,14 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-string BCast(const tensorflow::BCast::Vec& x, const tensorflow::BCast::Vec& y,\n-             const bool fewer_dims_optimization = true) {\n+std::string BCast(const tensorflow::BCast::Vec& x,\n+                  const tensorflow::BCast::Vec& y,\n+                  const bool fewer_dims_optimization = true) {\n   tensorflow::BCast b(x, y, fewer_dims_optimization);\n   if (!b.IsValid()) {\n     return \"invalid\";\n   }\n-  string ret;\n+  std::string ret;\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.x_reshape(), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.x_bcast(), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.y_reshape(), \",\"), \"]\");\n@@ -41,26 +42,26 @@ string BCast(const tensorflow::BCast::Vec& x, const tensorflow::BCast::Vec& y,\n   return ret;\n }\n \n-string BCastBatchIndices(const tensorflow::BCast::Vec& x,\n-                         const tensorflow::BCast::Vec& y,\n-                         const bool fewer_dims_optimization = true) {\n+std::string BCastBatchIndices(const tensorflow::BCast::Vec& x,\n+                              const tensorflow::BCast::Vec& y,\n+                              const bool fewer_dims_optimization = true) {\n   tensorflow::BCast b(x, y, fewer_dims_optimization,\n                       /*return_flattened_batch_indices=*/true);\n-  string ret;\n+  std::string ret;\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.x_batch_indices(), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.y_batch_indices(), \",\"), \"]\");\n   return ret;\n }\n \n-string BCastList3(const tensorflow::BCast::Vec& x,\n-                  const tensorflow::BCast::Vec& y,\n-                  const tensorflow::BCast::Vec& z,\n-                  const bool fewer_dims_optimization = true) {\n+std::string BCastList3(const tensorflow::BCast::Vec& x,\n+                       const tensorflow::BCast::Vec& y,\n+                       const tensorflow::BCast::Vec& z,\n+                       const bool fewer_dims_optimization = true) {\n   tensorflow::BCastList<3> b({x, y, z}, fewer_dims_optimization);\n   if (!b.IsValid()) {\n     return \"invalid\";\n   }\n-  string ret;\n+  std::string ret;\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.reshape(0), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.bcast(0), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.reshape(1), \",\"), \"]\");\n@@ -571,7 +572,7 @@ TEST(BCastTest, Complex_BCast_To_Each_Other) {\n   //   y = np.arange(0,21).reshape([7,1,3,1])\n   //   np.shape(x + y)\n   //   Out[.]: (11, 7, 5, 3, 2)\n-  string truth =\n+  std::string truth =\n       \"[11,1,5,1,2][1,7,1,3,1][1,7,1,3,1][11,1,5,1,2]\"\n       \"[11,7,5,3,2]\"\n       \"[11,7,5,3,2]\"\n@@ -592,7 +593,7 @@ TEST(BCastListTest, Complex_BCast_To_Each_Other) {\n   //   np.shape(x + y + z)\n   //   Out[.]: (11, 7, 5, 3, 2)\n   //\n-  string truth =\n+  std::string truth =\n       \"[11,1,1,1,2][1,7,5,3,1]\"\n       \"[1,7,1,3,1][11,1,5,1,2]\"\n       \"[1,1,5,1,1][11,7,1,3,2]\""
        },
        {
            "sha": "2bf0b27a24924df3bd39283ff0e65471c9e53761",
            "filename": "tensorflow/core/util/command_line_flags_test.cc",
            "status": "modified",
            "additions": 60,
            "deletions": 51,
            "changes": 111,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fcommand_line_flags_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fcommand_line_flags_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fcommand_line_flags_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -27,11 +27,11 @@ namespace {\n // The returned array is only valid for the lifetime of the input vector.\n // We're using const casting because we need to pass in an argv-style array of\n // char* pointers for the API, even though we know they won't be altered.\n-std::vector<char *> CharPointerVectorFromStrings(\n-    const std::vector<string> &strings) {\n+std::vector<char*> CharPointerVectorFromStrings(\n+    const std::vector<std::string>& strings) {\n   std::vector<char *> result;\n   result.reserve(strings.size());\n-  for (const string &string : strings) {\n+  for (const std::string& string : strings) {\n     result.push_back(const_cast<char *>(string.c_str()));\n   }\n   return result;\n@@ -47,23 +47,24 @@ TEST(CommandLineFlagsTest, BasicUsage) {\n   bool some_switch_set_via_hook = true;\n   bool some_switch_set_capitalized = false;\n   bool some_switch_set_by_number = false;\n-  string some_name_set_directly = \"something_a\";\n-  string some_name_set_via_hook = \"something_b\";\n+  std::string some_name_set_directly = \"something_a\";\n+  std::string some_name_set_via_hook = \"something_b\";\n   float some_float_set_directly = -23.23f;\n   float some_float_set_via_hook = -25.23f;\n-  std::vector<string> argv_strings = {\"program_name\",\n-                                      \"--some_int32_set_directly=20\",\n-                                      \"--some_int32_set_via_hook=50\",\n-                                      \"--some_int64_set_directly=214748364700\",\n-                                      \"--some_int64_set_via_hook=214748364710\",\n-                                      \"--some_switch_set_directly\",\n-                                      \"--some_switch_set_via_hook=false\",\n-                                      \"--some_switch_set_capitalized=True\",\n-                                      \"--some_switch_set_by_number=1\",\n-                                      \"--some_name_set_directly=somethingelse\",\n-                                      \"--some_name_set_via_hook=anythingelse\",\n-                                      \"--some_float_set_directly=42.0\",\n-                                      \"--some_float_set_via_hook=43.0\"};\n+  std::vector<std::string> argv_strings = {\n+      \"program_name\",\n+      \"--some_int32_set_directly=20\",\n+      \"--some_int32_set_via_hook=50\",\n+      \"--some_int64_set_directly=214748364700\",\n+      \"--some_int64_set_via_hook=214748364710\",\n+      \"--some_switch_set_directly\",\n+      \"--some_switch_set_via_hook=false\",\n+      \"--some_switch_set_capitalized=True\",\n+      \"--some_switch_set_by_number=1\",\n+      \"--some_name_set_directly=somethingelse\",\n+      \"--some_name_set_via_hook=anythingelse\",\n+      \"--some_float_set_directly=42.0\",\n+      \"--some_float_set_via_hook=43.0\"};\n   int argc = argv_strings.size();\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok = Flags::Parse(\n@@ -104,7 +105,7 @@ TEST(CommandLineFlagsTest, BasicUsage) {\n                \"some name set directly\"),\n           Flag(\n               \"some_name_set_via_hook\",\n-              [&](string value) {\n+              [&](std::string value) {\n                 some_name_set_via_hook = std::move(value);\n                 return true;\n               },\n@@ -139,7 +140,8 @@ TEST(CommandLineFlagsTest, BasicUsage) {\n TEST(CommandLineFlagsTest, BadIntValue) {\n   int some_int = 10;\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_int=notanumber\"};\n+  std::vector<std::string> argv_strings = {\"program_name\",\n+                                           \"--some_int=notanumber\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok = Flags::Parse(&argc, argv_array.data(),\n                                 {Flag(\"some_int\", &some_int, \"some int\")});\n@@ -152,7 +154,8 @@ TEST(CommandLineFlagsTest, BadIntValue) {\n TEST(CommandLineFlagsTest, BadBoolValue) {\n   bool some_switch = false;\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_switch=notabool\"};\n+  std::vector<std::string> argv_strings = {\"program_name\",\n+                                           \"--some_switch=notabool\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -166,8 +169,8 @@ TEST(CommandLineFlagsTest, BadBoolValue) {\n TEST(CommandLineFlagsTest, BadFloatValue) {\n   float some_float = -23.23f;\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\",\n-                                      \"--some_float=notanumber\"};\n+  std::vector<std::string> argv_strings = {\"program_name\",\n+                                           \"--some_float=notanumber\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -180,7 +183,7 @@ TEST(CommandLineFlagsTest, BadFloatValue) {\n \n TEST(CommandLineFlagsTest, FailedInt32Hook) {\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_int32=200\"};\n+  std::vector<std::string> argv_strings = {\"program_name\", \"--some_int32=200\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -194,7 +197,7 @@ TEST(CommandLineFlagsTest, FailedInt32Hook) {\n \n TEST(CommandLineFlagsTest, FailedInt64Hook) {\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_int64=200\"};\n+  std::vector<std::string> argv_strings = {\"program_name\", \"--some_int64=200\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -208,7 +211,8 @@ TEST(CommandLineFlagsTest, FailedInt64Hook) {\n \n TEST(CommandLineFlagsTest, FailedFloatHook) {\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_float=200.0\"};\n+  std::vector<std::string> argv_strings = {\"program_name\",\n+                                           \"--some_float=200.0\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -221,7 +225,8 @@ TEST(CommandLineFlagsTest, FailedFloatHook) {\n \n TEST(CommandLineFlagsTest, FailedBoolHook) {\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_switch=true\"};\n+  std::vector<std::string> argv_strings = {\"program_name\",\n+                                           \"--some_switch=true\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   bool parsed_ok =\n       Flags::Parse(&argc, argv_array.data(),\n@@ -234,29 +239,32 @@ TEST(CommandLineFlagsTest, FailedBoolHook) {\n \n TEST(CommandLineFlagsTest, FailedStringHook) {\n   int argc = 2;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_name=true\"};\n+  std::vector<std::string> argv_strings = {\"program_name\", \"--some_name=true\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n-  bool parsed_ok = Flags::Parse(\n-      &argc, argv_array.data(),\n-      {Flag(\"some_name\", [](string value) { return false; }, \"\", \"some name\")});\n+  bool parsed_ok =\n+      Flags::Parse(&argc, argv_array.data(),\n+                   {Flag(\n+                       \"some_name\", [](std::string value) { return false; }, \"\",\n+                       \"some name\")});\n \n   EXPECT_EQ(false, parsed_ok);\n   EXPECT_EQ(argc, 1);\n }\n \n TEST(CommandLineFlagsTest, RepeatedStringHook) {\n   int argc = 3;\n-  std::vector<string> argv_strings = {\"program_name\", \"--some_name=this\",\n-                                      \"--some_name=that\"};\n+  std::vector<std::string> argv_strings = {\"program_name\", \"--some_name=this\",\n+                                           \"--some_name=that\"};\n   std::vector<char *> argv_array = CharPointerVectorFromStrings(argv_strings);\n   int call_count = 0;\n   bool parsed_ok = Flags::Parse(&argc, argv_array.data(),\n-                                {Flag(\"some_name\",\n-                                      [&call_count](string value) {\n-                                        call_count++;\n-                                        return true;\n-                                      },\n-                                      \"\", \"some name\")});\n+                                {Flag(\n+                                    \"some_name\",\n+                                    [&call_count](std::string value) {\n+                                      call_count++;\n+                                      return true;\n+                                    },\n+                                    \"\", \"some name\")});\n \n   EXPECT_EQ(true, parsed_ok);\n   EXPECT_EQ(argc, 1);\n@@ -265,7 +273,8 @@ TEST(CommandLineFlagsTest, RepeatedStringHook) {\n \n // Return whether str==pat, but allowing any whitespace in pat\n // to match zero or more whitespace characters in str.\n-static bool MatchWithAnyWhitespace(const string &str, const string &pat) {\n+static bool MatchWithAnyWhitespace(const std::string& str,\n+                                   const std::string& pat) {\n   bool matching = true;\n   int pat_i = 0;\n   for (int str_i = 0; str_i != str.size() && matching; str_i++) {\n@@ -288,15 +297,15 @@ TEST(CommandLineFlagsTest, UsageString) {\n   int some_int = 10;\n   int64_t some_int64 = 21474836470;  // max int32 is 2147483647\n   bool some_switch = false;\n-  string some_name = \"something\";\n+  std::string some_name = \"something\";\n   // Don't test float in this case, because precision is hard to predict and\n   // match against, and we don't want a franky test.\n-  const string tool_name = \"some_tool_name\";\n-  string usage = Flags::Usage(tool_name + \"<flags>\",\n-                              {Flag(\"some_int\", &some_int, \"some int\"),\n-                               Flag(\"some_int64\", &some_int64, \"some int64\"),\n-                               Flag(\"some_switch\", &some_switch, \"some switch\"),\n-                               Flag(\"some_name\", &some_name, \"some name\")});\n+  const std::string tool_name = \"some_tool_name\";\n+  std::string usage = Flags::Usage(\n+      tool_name + \"<flags>\", {Flag(\"some_int\", &some_int, \"some int\"),\n+                              Flag(\"some_int64\", &some_int64, \"some int64\"),\n+                              Flag(\"some_switch\", &some_switch, \"some switch\"),\n+                              Flag(\"some_name\", &some_name, \"some name\")});\n   // Match the usage message, being sloppy about whitespace.\n   const char *expected_usage =\n       \" usage: some_tool_name <flags>\\n\"\n@@ -314,10 +323,10 @@ TEST(CommandLineFlagsTest, UsageString) {\n \n namespace {\n template <typename T, typename ExpectationFun>\n-void PrefixTestTempl(ExpectationFun expectation_fun, const T &value0,\n-                     const T &value1, string str0, string str1) {\n+void PrefixTestTempl(ExpectationFun expectation_fun, const T& value0,\n+                     const T& value1, std::string str0, std::string str1) {\n   int argc = 3;\n-  std::vector<string> argv_strings = {\n+  std::vector<std::string> argv_strings = {\n       \"program_name\",\n       \"--hello\" + str0,\n       \"--hello_world\" + str1,\n@@ -350,7 +359,7 @@ TEST(CommandLineFlagsTest, OneArgumentIsAPrefixOfAnother) {\n   PrefixTestTempl<bool>(expect_eq, false, true, \"=false\", \"\");\n   PrefixTestTempl<bool>(expect_eq, true, false, \"=true\", \"=false\");\n   PrefixTestTempl<bool>(expect_eq, true, false, \"\", \"=false\");\n-  PrefixTestTempl<string>(expect_eq, \"a\", \"b\", \"=a\", \"=b\");\n+  PrefixTestTempl<std::string>(expect_eq, \"a\", \"b\", \"=a\", \"=b\");\n   PrefixTestTempl<float>(expect_near, 0.1f, 0.2f, \"=0.1\", \"=0.2\");\n }\n "
        },
        {
            "sha": "5716a77059b40719b07add209e656b33526c15a7",
            "filename": "tensorflow/core/util/debug_data_dumper.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_data_dumper.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_data_dumper.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdebug_data_dumper.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -127,7 +127,7 @@ class DebugDataDumper {\n   std::optional<std::string> name_filter_;\n \n   // The groups filter.\n-  std::set<string> groups_filter_;\n+  std::set<std::string> groups_filter_;\n \n   // A flag indicating whether to dump wrapped graphs.\n   bool dump_wrapped_;"
        },
        {
            "sha": "1d98ecbe2bde67322d9b94927fd93a540c0a2781",
            "filename": "tensorflow/core/util/debug_events_writer.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 32,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -38,7 +38,8 @@ void MaybeSetDebugEventTimestamp(DebugEvent* debug_event, Env* env) {\n }\n }  // namespace\n \n-SingleDebugEventFileWriter::SingleDebugEventFileWriter(const string& file_path)\n+SingleDebugEventFileWriter::SingleDebugEventFileWriter(\n+    const std::string& file_path)\n     : env_(Env::Default()),\n       file_path_(file_path),\n       num_outstanding_events_(0),\n@@ -120,19 +121,19 @@ absl::Status SingleDebugEventFileWriter::Close() {\n   return status;\n }\n \n-const string SingleDebugEventFileWriter::FileName() { return file_path_; }\n+const std::string SingleDebugEventFileWriter::FileName() { return file_path_; }\n \n mutex DebugEventsWriter::factory_mu_(LINKER_INITIALIZED);\n \n DebugEventsWriter::~DebugEventsWriter() { Close().IgnoreError(); }\n \n // static\n DebugEventsWriter* DebugEventsWriter::GetDebugEventsWriter(\n-    const string& dump_root, const string& tfdbg_run_id,\n+    const std::string& dump_root, const std::string& tfdbg_run_id,\n     int64_t circular_buffer_size) {\n   mutex_lock l(DebugEventsWriter::factory_mu_);\n-  std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>* writer_pool =\n-      DebugEventsWriter::GetDebugEventsWriterMap();\n+  std::unordered_map<std::string, std::unique_ptr<DebugEventsWriter>>*\n+      writer_pool = DebugEventsWriter::GetDebugEventsWriterMap();\n   if (writer_pool->find(dump_root) == writer_pool->end()) {\n     std::unique_ptr<DebugEventsWriter> writer(\n         new DebugEventsWriter(dump_root, tfdbg_run_id, circular_buffer_size));\n@@ -143,10 +144,10 @@ DebugEventsWriter* DebugEventsWriter::GetDebugEventsWriter(\n \n // static\n absl::Status DebugEventsWriter::LookUpDebugEventsWriter(\n-    const string& dump_root, DebugEventsWriter** debug_events_writer) {\n+    const std::string& dump_root, DebugEventsWriter** debug_events_writer) {\n   mutex_lock l(DebugEventsWriter::factory_mu_);\n-  std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>* writer_pool =\n-      DebugEventsWriter::GetDebugEventsWriterMap();\n+  std::unordered_map<std::string, std::unique_ptr<DebugEventsWriter>>*\n+      writer_pool = DebugEventsWriter::GetDebugEventsWriterMap();\n   if (writer_pool->find(dump_root) == writer_pool->end()) {\n     return errors::FailedPrecondition(\n         \"No DebugEventsWriter has been created at dump root \", dump_root);\n@@ -182,7 +183,7 @@ absl::Status DebugEventsWriter::Init() {\n   metadata_writer_.reset();\n \n   // The metadata file should be created.\n-  string metadata_filename = GetFileNameInternal(METADATA);\n+  std::string metadata_filename = GetFileNameInternal(METADATA);\n   metadata_writer_ =\n       std::make_unique<SingleDebugEventFileWriter>(metadata_filename);\n   if (metadata_writer_ == nullptr) {\n@@ -243,7 +244,7 @@ absl::Status DebugEventsWriter::WriteExecution(Execution* execution) {\n     DebugEvent debug_event;\n     MaybeSetDebugEventTimestamp(&debug_event, env_);\n     debug_event.set_allocated_execution(execution);\n-    string serialized;\n+    std::string serialized;\n     debug_event.SerializeToString(&serialized);\n \n     mutex_lock l(execution_buffer_mu_);\n@@ -268,7 +269,7 @@ absl::Status DebugEventsWriter::WriteGraphExecutionTrace(\n     DebugEvent debug_event;\n     MaybeSetDebugEventTimestamp(&debug_event, env_);\n     debug_event.set_allocated_graph_execution_trace(graph_execution_trace);\n-    string serialized;\n+    std::string serialized;\n     debug_event.SerializeToString(&serialized);\n \n     mutex_lock l(graph_execution_trace_buffer_mu_);\n@@ -281,8 +282,8 @@ absl::Status DebugEventsWriter::WriteGraphExecutionTrace(\n }\n \n absl::Status DebugEventsWriter::WriteGraphExecutionTrace(\n-    const string& tfdbg_context_id, const string& device_name,\n-    const string& op_name, int32_t output_slot, int32_t tensor_debug_mode,\n+    const std::string& tfdbg_context_id, const std::string& device_name,\n+    const std::string& op_name, int32_t output_slot, int32_t tensor_debug_mode,\n     const Tensor& tensor_value) {\n   std::unique_ptr<GraphExecutionTrace> trace(new GraphExecutionTrace());\n   trace->set_tfdbg_context_id(tfdbg_context_id);\n@@ -301,16 +302,16 @@ absl::Status DebugEventsWriter::WriteGraphExecutionTrace(\n }\n \n void DebugEventsWriter::WriteSerializedNonExecutionDebugEvent(\n-    const string& debug_event_str, DebugEventFileType type) {\n+    const std::string& debug_event_str, DebugEventFileType type) {\n   std::unique_ptr<SingleDebugEventFileWriter>* writer = nullptr;\n   SelectWriter(type, &writer);\n   (*writer)->WriteSerializedDebugEvent(debug_event_str);\n }\n \n void DebugEventsWriter::WriteSerializedExecutionDebugEvent(\n-    const string& debug_event_str, DebugEventFileType type) {\n+    const std::string& debug_event_str, DebugEventFileType type) {\n   const std::unique_ptr<SingleDebugEventFileWriter>* writer = nullptr;\n-  std::deque<string>* buffer = nullptr;\n+  std::deque<std::string>* buffer = nullptr;\n   mutex* mu = nullptr;\n   switch (type) {\n     case EXECUTION:\n@@ -340,7 +341,7 @@ void DebugEventsWriter::WriteSerializedExecutionDebugEvent(\n   }\n }\n \n-int DebugEventsWriter::RegisterDeviceAndGetId(const string& device_name) {\n+int DebugEventsWriter::RegisterDeviceAndGetId(const std::string& device_name) {\n   mutex_lock l(device_mu_);\n   int& device_id = device_name_to_id_[device_name];\n   if (device_id == 0) {\n@@ -350,7 +351,7 @@ int DebugEventsWriter::RegisterDeviceAndGetId(const string& device_name) {\n     DebuggedDevice* debugged_device = debug_event.mutable_debugged_device();\n     debugged_device->set_device_name(device_name);\n     debugged_device->set_device_id(device_id);\n-    string serialized;\n+    std::string serialized;\n     debug_event.SerializeToString(&serialized);\n     graphs_writer_->WriteSerializedDebugEvent(serialized);\n   }\n@@ -403,7 +404,7 @@ absl::Status DebugEventsWriter::FlushExecutionFiles() {\n   return absl::OkStatus();\n }\n \n-string DebugEventsWriter::FileName(DebugEventFileType type) {\n+std::string DebugEventsWriter::FileName(DebugEventFileType type) {\n   if (file_prefix_.empty()) {\n     Init().IgnoreError();\n   }\n@@ -418,7 +419,7 @@ absl::Status DebugEventsWriter::Close() {\n     }\n   }\n \n-  std::vector<string> failed_to_close_files;\n+  std::vector<std::string> failed_to_close_files;\n \n   if (metadata_writer_ != nullptr) {\n     if (!metadata_writer_->Close().ok()) {\n@@ -472,16 +473,16 @@ absl::Status DebugEventsWriter::Close() {\n }\n \n // static\n-std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>*\n+std::unordered_map<std::string, std::unique_ptr<DebugEventsWriter>>*\n DebugEventsWriter::GetDebugEventsWriterMap() {\n-  static std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>*\n-      writer_pool =\n-          new std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>();\n+  static std::unordered_map<std::string,\n+                            std::unique_ptr<DebugEventsWriter>>* writer_pool =\n+      new std::unordered_map<std::string, std::unique_ptr<DebugEventsWriter>>();\n   return writer_pool;\n }\n \n-DebugEventsWriter::DebugEventsWriter(const string& dump_root,\n-                                     const string& tfdbg_run_id,\n+DebugEventsWriter::DebugEventsWriter(const std::string& dump_root,\n+                                     const std::string& tfdbg_run_id,\n                                      int64_t circular_buffer_size)\n     : env_(Env::Default()),\n       dump_root_(dump_root),\n@@ -499,7 +500,7 @@ DebugEventsWriter::DebugEventsWriter(const string& dump_root,\n absl::Status DebugEventsWriter::InitNonMetadataFile(DebugEventFileType type) {\n   std::unique_ptr<SingleDebugEventFileWriter>* writer = nullptr;\n   SelectWriter(type, &writer);\n-  const string filename = GetFileNameInternal(type);\n+  const std::string filename = GetFileNameInternal(type);\n   writer->reset();\n \n   *writer = std::make_unique<SingleDebugEventFileWriter>(filename);\n@@ -521,7 +522,7 @@ absl::Status DebugEventsWriter::SerializeAndWriteDebugEvent(\n   if (writer != nullptr) {\n     // Timestamp is in seconds, with double precision.\n     MaybeSetDebugEventTimestamp(debug_event, env_);\n-    string str;\n+    std::string str;\n     debug_event->AppendToString(&str);\n     (*writer)->WriteSerializedDebugEvent(str);\n     return absl::OkStatus();\n@@ -557,7 +558,7 @@ void DebugEventsWriter::SelectWriter(\n   }\n }\n \n-const string DebugEventsWriter::GetSuffix(DebugEventFileType type) {\n+const std::string DebugEventsWriter::GetSuffix(DebugEventFileType type) {\n   switch (type) {\n     case METADATA:\n       return kMetadataSuffix;\n@@ -572,13 +573,13 @@ const string DebugEventsWriter::GetSuffix(DebugEventFileType type) {\n     case GRAPH_EXECUTION_TRACES:\n       return kGraphExecutionTracesSuffix;\n     default:\n-      string suffix;\n+      std::string suffix;\n       return suffix;\n   }\n }\n \n-string DebugEventsWriter::GetFileNameInternal(DebugEventFileType type) {\n-  const string suffix = GetSuffix(type);\n+std::string DebugEventsWriter::GetFileNameInternal(DebugEventFileType type) {\n+  const std::string suffix = GetSuffix(type);\n   return absl::StrCat(file_prefix_, \".\", suffix);\n }\n "
        },
        {
            "sha": "abc7397d71dbb0d58449286c9ea25edc9ebcb7db",
            "filename": "tensorflow/core/util/debug_events_writer.h",
            "status": "modified",
            "additions": 26,
            "deletions": 24,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdebug_events_writer.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -49,7 +49,7 @@ enum DebugEventFileType {\n // TFRecord files, and hence utilizes multiple objects of this helper class.\n class SingleDebugEventFileWriter {\n  public:\n-  explicit SingleDebugEventFileWriter(const string& file_path);\n+  explicit SingleDebugEventFileWriter(const std::string& file_path);\n \n   absl::Status Init();\n \n@@ -58,11 +58,11 @@ class SingleDebugEventFileWriter {\n   absl::Status Flush();\n   absl::Status Close();\n \n-  const string FileName();\n+  const std::string FileName();\n \n  private:\n   Env* env_;\n-  const string file_path_;\n+  const std::string file_path_;\n   std::atomic_int_fast32_t num_outstanding_events_;\n \n   std::unique_ptr<WritableFile> writable_file_;\n@@ -108,15 +108,15 @@ class DebugEventsWriter {\n   //     behavior.\n   // Returns:\n   //   A pointer to a DebugEventsWriter object: a per-dump_root singleton.\n-  static DebugEventsWriter* GetDebugEventsWriter(const string& dump_root,\n-                                                 const string& tfdbg_run_id,\n-                                                 int64_t circular_buffer_size);\n+  static DebugEventsWriter* GetDebugEventsWriter(\n+      const std::string& dump_root, const std::string& tfdbg_run_id,\n+      int64_t circular_buffer_size);\n   // Look up existing events writer by dump_root.\n   // If no DebugEventsWriter has been created at the dump_root, a non-OK\n   // Status will be returned. Else an OK status will be returned, with\n   // the pointer to the existing instance provided by reference.\n   static absl::Status LookUpDebugEventsWriter(\n-      const string& dump_root, DebugEventsWriter** debug_events_writer);\n+      const std::string& dump_root, DebugEventsWriter** debug_events_writer);\n   ~DebugEventsWriter();\n \n   // Sets the debug event filenames and opens file for writing.\n@@ -168,9 +168,9 @@ class DebugEventsWriter {\n   //   tensor(s)\n   //     that this trace is concerned with. The semantics of this tensor value\n   //     depends on the value of `tensor_debug_mode`.\n-  absl::Status WriteGraphExecutionTrace(const string& tfdbg_context_id,\n-                                        const string& device_name,\n-                                        const string& op_name,\n+  absl::Status WriteGraphExecutionTrace(const std::string& tfdbg_context_id,\n+                                        const std::string& device_name,\n+                                        const std::string& op_name,\n                                         int32_t output_slot,\n                                         int32_t tensor_debug_mode,\n                                         const Tensor& tensor_value);\n@@ -180,7 +180,7 @@ class DebugEventsWriter {\n   // and GRAPHS files.\n   // NOTE: Actually used in the Python binding, to avoid overhead of\n   // serializing and parsing protos at the language interface.\n-  void WriteSerializedNonExecutionDebugEvent(const string& debug_event_str,\n+  void WriteSerializedNonExecutionDebugEvent(const std::string& debug_event_str,\n                                              DebugEventFileType type);\n \n   // Writes a serialized DebugEvent to one of the debug-events files\n@@ -189,13 +189,13 @@ class DebugEventsWriter {\n   // circular_buffer_size is configured to be >0.\n   // NOTE: Actually used in the Python binding, to avoid overhead of\n   // serializing and parsing protos at the language interface.\n-  void WriteSerializedExecutionDebugEvent(const string& debug_event_str,\n+  void WriteSerializedExecutionDebugEvent(const std::string& debug_event_str,\n                                           DebugEventFileType type);\n \n   // Given name of the device, retrieve a unique integer ID. As a side effect,\n   // if this is the first time this object encounters the device name,\n   // writes a DebuggedDevice proto to the .graphs file in the file set.\n-  int RegisterDeviceAndGetId(const string& device_name);\n+  int RegisterDeviceAndGetId(const std::string& device_name);\n \n   // EventWriter automatically flushes and closes on destruction, but\n   // this method is provided for users who want to write to disk sooner\n@@ -213,7 +213,7 @@ class DebugEventsWriter {\n   absl::Status Close();\n \n  private:\n-  static std::unordered_map<string, std::unique_ptr<DebugEventsWriter>>*\n+  static std::unordered_map<std::string, std::unique_ptr<DebugEventsWriter>>*\n \n   // Get a static map from dump-root path to DebugEventsWriter objects.\n   // This helps the per-dump-root singletone pattern.\n@@ -222,12 +222,13 @@ class DebugEventsWriter {\n   // Guards calls to the GetDebugEventsWriter() method.\n   static mutex factory_mu_;\n \n-  DebugEventsWriter(const string& dump_root, const string& tfdbg_run_id,\n+  DebugEventsWriter(const std::string& dump_root,\n+                    const std::string& tfdbg_run_id,\n                     int64_t circular_buffer_size);\n \n   // Get the path prefix. The same for all files, which differ only in the\n   // suffix.\n-  string FileName(DebugEventFileType type);\n+  std::string FileName(DebugEventFileType type);\n \n   // Initialize the TFRecord writer for non-metadata file type.\n   absl::Status InitNonMetadataFile(DebugEventFileType type);\n@@ -237,25 +238,26 @@ class DebugEventsWriter {\n \n   void SelectWriter(DebugEventFileType type,\n                     std::unique_ptr<SingleDebugEventFileWriter>** writer);\n-  const string GetSuffix(DebugEventFileType type);\n-  string GetFileNameInternal(DebugEventFileType type);\n+  const std::string GetSuffix(DebugEventFileType type);\n+  std::string GetFileNameInternal(DebugEventFileType type);\n \n   Env* env_;\n-  const string dump_root_;\n-  const string tfdbg_run_id_;\n+  const std::string dump_root_;\n+  const std::string tfdbg_run_id_;\n \n-  string file_prefix_;\n+  std::string file_prefix_;\n   bool is_initialized_ TF_GUARDED_BY(initialization_mu_);\n   mutex initialization_mu_;\n \n   const int64_t circular_buffer_size_;\n-  std::deque<string> execution_buffer_ TF_GUARDED_BY(execution_buffer_mu_);\n+  std::deque<std::string> execution_buffer_ TF_GUARDED_BY(execution_buffer_mu_);\n   mutex execution_buffer_mu_;\n-  std::deque<string> graph_execution_trace_buffer_\n+  std::deque<std::string> graph_execution_trace_buffer_\n       TF_GUARDED_BY(graph_execution_trace_buffer_mu_);\n   mutex graph_execution_trace_buffer_mu_;\n \n-  absl::flat_hash_map<string, int> device_name_to_id_ TF_GUARDED_BY(device_mu_);\n+  absl::flat_hash_map<std::string, int> device_name_to_id_\n+      TF_GUARDED_BY(device_mu_);\n   mutex device_mu_;\n \n   std::unique_ptr<SingleDebugEventFileWriter> metadata_writer_;"
        },
        {
            "sha": "2bd17cbda55a9da7c3a6360e3935837cc6de2a9a",
            "filename": "tensorflow/core/util/debug_events_writer_test.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 25,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdebug_events_writer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdebug_events_writer_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -37,21 +37,21 @@ Env* env() { return Env::Default(); }\n \n class DebugEventsWriterTest : public ::testing::Test {\n  public:\n-  static string GetDebugEventFileName(DebugEventsWriter* writer,\n-                                      DebugEventFileType type) {\n+  static std::string GetDebugEventFileName(DebugEventsWriter* writer,\n+                                           DebugEventFileType type) {\n     return writer->FileName(type);\n   }\n \n   static void ReadDebugEventProtos(DebugEventsWriter* writer,\n                                    DebugEventFileType type,\n                                    std::vector<DebugEvent>* protos) {\n     protos->clear();\n-    const string filename = writer->FileName(type);\n+    const std::string filename = writer->FileName(type);\n     std::unique_ptr<RandomAccessFile> debug_events_file;\n     TF_CHECK_OK(env()->NewRandomAccessFile(filename, &debug_events_file));\n     io::RecordReader* reader = new io::RecordReader(debug_events_file.get());\n \n-    uint64 offset = 0;\n+    uint64_t offset = 0;\n     DebugEvent actual;\n     while (ReadDebugEventProto(reader, &offset, &actual)) {\n       protos->push_back(actual);\n@@ -60,7 +60,7 @@ class DebugEventsWriterTest : public ::testing::Test {\n     delete reader;\n   }\n \n-  static bool ReadDebugEventProto(io::RecordReader* reader, uint64* offset,\n+  static bool ReadDebugEventProto(io::RecordReader* reader, uint64_t* offset,\n                                   DebugEvent* proto) {\n     tstring record;\n     absl::Status s = reader->ReadRecord(offset, &record);\n@@ -88,8 +88,8 @@ class DebugEventsWriterTest : public ::testing::Test {\n     }\n   }\n \n-  string dump_root_;\n-  string tfdbg_run_id_;\n+  std::string dump_root_;\n+  std::string tfdbg_run_id_;\n };\n \n TEST_F(DebugEventsWriterTest, GetDebugEventsWriterSameRootGivesSameObject) {\n@@ -134,7 +134,7 @@ TEST_F(DebugEventsWriterTest, ConcurrentGetDebugEventsWriterDiffDumpRoots) {\n   std::vector<DebugEventsWriter*> writers;\n   mutex mu;\n   auto fn = [this, &counter, &writers, &mu]() {\n-    const string new_dump_root =\n+    const std::string new_dump_root =\n         io::JoinPath(dump_root_, strings::Printf(\"%ld\", counter.fetch_add(1)));\n     DebugEventsWriter* writer = DebugEventsWriter::GetDebugEventsWriter(\n         new_dump_root, tfdbg_run_id_,\n@@ -159,7 +159,7 @@ TEST_F(DebugEventsWriterTest, GetDebugEventsWriterDifferentRoots) {\n   // Test the DebugEventsWriters for different directories are different.\n   DebugEventsWriter* writer_1 = DebugEventsWriter::GetDebugEventsWriter(\n       dump_root_, tfdbg_run_id_, DebugEventsWriter::kDefaultCyclicBufferSize);\n-  const string dump_root_2 = io::JoinPath(dump_root_, \"subdirectory\");\n+  const std::string dump_root_2 = io::JoinPath(dump_root_, \"subdirectory\");\n   DebugEventsWriter* writer_2 = DebugEventsWriter::GetDebugEventsWriter(\n       dump_root_2, tfdbg_run_id_, DebugEventsWriter::kDefaultCyclicBufferSize);\n   EXPECT_NE(writer_1, writer_2);\n@@ -177,7 +177,7 @@ TEST_F(DebugEventsWriterTest, GetAndInitDebugEventsWriter) {\n   EXPECT_EQ(actuals.size(), 1);\n   EXPECT_GT(actuals[0].debug_metadata().tensorflow_version().length(), 0);\n   // Check the content of the file version string.\n-  const string file_version = actuals[0].debug_metadata().file_version();\n+  const std::string file_version = actuals[0].debug_metadata().file_version();\n   EXPECT_EQ(file_version.find(DebugEventsWriter::kVersionPrefix), 0);\n   EXPECT_GT(file_version.size(), strlen(DebugEventsWriter::kVersionPrefix));\n   // Check the tfdbg run ID.\n@@ -223,7 +223,7 @@ TEST_F(DebugEventsWriterTest, ConcurrentInitCalls) {\n   EXPECT_EQ(actuals.size(), 1);\n   EXPECT_GT(actuals[0].debug_metadata().tensorflow_version().length(), 0);\n   // Check the content of the file version string.\n-  const string file_version = actuals[0].debug_metadata().file_version();\n+  const std::string file_version = actuals[0].debug_metadata().file_version();\n   EXPECT_EQ(file_version.find(DebugEventsWriter::kVersionPrefix), 0);\n   EXPECT_GT(file_version.size(), strlen(DebugEventsWriter::kVersionPrefix));\n   EXPECT_EQ(actuals[0].debug_metadata().tfdbg_run_id(), \"test_tfdbg_run_id\");\n@@ -247,7 +247,7 @@ TEST_F(DebugEventsWriterTest, InitTwiceDoesNotCreateNewMetadataFile) {\n   EXPECT_EQ(actuals[0].debug_metadata().tfdbg_run_id(), \"test_tfdbg_run_id\");\n   EXPECT_GE(actuals[0].debug_metadata().file_version().size(), 0);\n \n-  string metadata_path_1 =\n+  std::string metadata_path_1 =\n       GetDebugEventFileName(writer, DebugEventFileType::METADATA);\n   TF_ASSERT_OK(writer->Init());\n   EXPECT_EQ(GetDebugEventFileName(writer, DebugEventFileType::METADATA),\n@@ -434,7 +434,7 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteCallsToTheSameFile) {\n       new thread::ThreadPool(Env::Default(), \"test_pool\", 8);\n   std::atomic_int_fast64_t counter(0);\n   auto fn = [&writer, &counter]() {\n-    const string file_path = strings::Printf(\n+    const std::string file_path = strings::Printf(\n         \"/home/tf_programs/program_%.3ld.py\", counter.fetch_add(1));\n     SourceFile* source_file = new SourceFile();\n     source_file->set_file_path(file_path);\n@@ -451,8 +451,8 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteCallsToTheSameFile) {\n   std::vector<DebugEvent> actuals;\n   ReadDebugEventProtos(writer, DebugEventFileType::SOURCE_FILES, &actuals);\n   EXPECT_EQ(actuals.size(), kConcurrentWrites);\n-  std::vector<string> file_paths;\n-  std::vector<string> host_names;\n+  std::vector<std::string> file_paths;\n+  std::vector<std::string> host_names;\n   for (size_t i = 0; i < kConcurrentWrites; ++i) {\n     file_paths.push_back(actuals[i].source_file().file_path());\n     host_names.push_back(actuals[i].source_file().host_name());\n@@ -475,7 +475,7 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteAndFlushCallsToTheSameFile) {\n       new thread::ThreadPool(Env::Default(), \"test_pool\", 8);\n   std::atomic_int_fast64_t counter(0);\n   auto fn = [&writer, &counter]() {\n-    const string file_path = strings::Printf(\n+    const std::string file_path = strings::Printf(\n         \"/home/tf_programs/program_%.3ld.py\", counter.fetch_add(1));\n     SourceFile* source_file = new SourceFile();\n     source_file->set_file_path(file_path);\n@@ -493,8 +493,8 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteAndFlushCallsToTheSameFile) {\n   std::vector<DebugEvent> actuals;\n   ReadDebugEventProtos(writer, DebugEventFileType::SOURCE_FILES, &actuals);\n   EXPECT_EQ(actuals.size(), kConcurrentWrites);\n-  std::vector<string> file_paths;\n-  std::vector<string> host_names;\n+  std::vector<std::string> file_paths;\n+  std::vector<std::string> host_names;\n   for (size_t i = 0; i < kConcurrentWrites; ++i) {\n     file_paths.push_back(actuals[i].source_file().file_path());\n     host_names.push_back(actuals[i].source_file().host_name());\n@@ -545,8 +545,8 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteCallsToTheDifferentFiles) {\n   std::vector<DebugEvent> actuals;\n   ReadDebugEventProtos(writer, DebugEventFileType::SOURCE_FILES, &actuals);\n   EXPECT_EQ(actuals.size(), kConcurrentWrites / 3);\n-  std::vector<string> file_paths;\n-  std::vector<string> host_names;\n+  std::vector<std::string> file_paths;\n+  std::vector<std::string> host_names;\n   for (int32_t i = 0; i < kConcurrentWrites / 3; ++i) {\n     file_paths.push_back(actuals[i].source_file().file_path());\n     host_names.push_back(actuals[i].source_file().host_name());\n@@ -560,7 +560,7 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteCallsToTheDifferentFiles) {\n \n   ReadDebugEventProtos(writer, DebugEventFileType::STACK_FRAMES, &actuals);\n   EXPECT_EQ(actuals.size(), kConcurrentWrites / 3);\n-  std::vector<string> stack_frame_ids;\n+  std::vector<std::string> stack_frame_ids;\n   for (int32_t i = 0; i < kConcurrentWrites / 3; ++i) {\n     stack_frame_ids.push_back(actuals[i].stack_frame_with_id().id());\n   }\n@@ -571,8 +571,8 @@ TEST_F(DebugEventsWriterTest, ConcurrentWriteCallsToTheDifferentFiles) {\n \n   ReadDebugEventProtos(writer, DebugEventFileType::GRAPHS, &actuals);\n   EXPECT_EQ(actuals.size(), kConcurrentWrites / 3);\n-  std::vector<string> op_types;\n-  std::vector<string> op_names;\n+  std::vector<std::string> op_types;\n+  std::vector<std::string> op_names;\n   for (int32_t i = 0; i < kConcurrentWrites / 3; ++i) {\n     op_types.push_back(actuals[i].graph_op_creation().op_type());\n     op_names.push_back(actuals[i].graph_op_creation().op_name());\n@@ -809,7 +809,7 @@ TEST_F(DebugEventsWriterTest, RegisterDeviceAndGetIdTrace) {\n   int device_ids[8];\n   for (int i = 0; i < 8; ++i) {\n     thread_pool->Schedule([i, &writer, &device_ids]() {\n-      const string device_name = strings::Printf(\n+      const std::string device_name = strings::Printf(\n           \"/job:localhost/replica:0/task:0/device:GPU:%d\", i % 4);\n       device_ids[i] = writer->RegisterDeviceAndGetId(device_name);\n     });\n@@ -833,7 +833,7 @@ TEST_F(DebugEventsWriterTest, RegisterDeviceAndGetIdTrace) {\n   // are 8 threads each calling `RegisterDeviceAndGetId`.\n   EXPECT_EQ(actuals.size(), 4);\n   for (const DebugEvent& actual : actuals) {\n-    const string& device_name = actual.debugged_device().device_name();\n+    const std::string& device_name = actual.debugged_device().device_name();\n     int device_index = -1;\n     CHECK(absl::SimpleAtoi(device_name.substr(strlen(\n                                \"/job:localhost/replica:0/task:0/device:GPU:\")),"
        },
        {
            "sha": "f75670557d804df7fc8c4719d9395a45b84c273b",
            "filename": "tensorflow/core/util/dump_graph.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 32,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdump_graph.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -39,10 +39,11 @@ using strings::StrCat;\n \n struct NameCounts {\n   mutex counts_mutex;\n-  std::unordered_map<string, int> counts;\n+  std::unordered_map<std::string, int> counts;\n };\n \n-string MakeUniqueFilename(string name, const string& suffix = \".pbtxt\") {\n+std::string MakeUniqueFilename(std::string name,\n+                               const std::string& suffix = \".pbtxt\") {\n   static NameCounts& instance = *new NameCounts;\n \n   // Remove illegal characters from `name`.\n@@ -60,7 +61,7 @@ string MakeUniqueFilename(string name, const string& suffix = \".pbtxt\") {\n     count = instance.counts[name]++;\n   }\n \n-  string filename = name;\n+  std::string filename = name;\n   if (count > 0) {\n     absl::StrAppend(&filename, \"_\", count);\n   }\n@@ -78,7 +79,7 @@ struct GraphDumperConfig {\n                                const FunctionLibraryDefinition* flib_def,\n                                WritableFile*)>\n         dumper = nullptr;\n-    string suffix = \".pbtxt\";\n+    std::string suffix = \".pbtxt\";\n   } config TF_GUARDED_BY(mu);\n \n   // Returns whether a custom dumper is set.\n@@ -93,8 +94,8 @@ GraphDumperConfig& GetGraphDumperConfig() {\n   return config;\n }\n \n-string GetDumpGraphFormatLowerCase() {\n-  string fmt;\n+std::string GetDumpGraphFormatLowerCase() {\n+  std::string fmt;\n   absl::Status status =\n       tsl::ReadStringFromEnvVar(\"TF_DUMP_GRAPH_FMT\", \"TXT\", &fmt);\n   if (!status.ok()) {\n@@ -105,8 +106,8 @@ string GetDumpGraphFormatLowerCase() {\n   return fmt;\n }\n \n-string GetDumpGraphSuffix() {\n-  string fmt = GetDumpGraphFormatLowerCase();\n+std::string GetDumpGraphSuffix() {\n+  std::string fmt = GetDumpGraphFormatLowerCase();\n   if (fmt == \"txt\") {\n     return \".pbtxt\";\n   } else if (fmt == \"bin\") {\n@@ -145,11 +146,12 @@ class StderrWritableFile : public WritableFile {\n   }\n };\n \n-absl::Status CreateWritableFile(Env* env, const string& dirname,\n-                                const string& name, const string& suffix,\n-                                string* filepath,\n+absl::Status CreateWritableFile(Env* env, const std::string& dirname,\n+                                const std::string& name,\n+                                const std::string& suffix,\n+                                std::string* filepath,\n                                 std::unique_ptr<WritableFile>* file) {\n-  string dir;\n+  std::string dir;\n   if (!dirname.empty()) {\n     dir = dirname;\n   } else {\n@@ -187,8 +189,8 @@ absl::Status CreateWritableFile(Env* env, const string& dirname,\n \n absl::Status WriteProtoToUniqueFile(const tensorflow::protobuf::Message& proto,\n                                     WritableFile* file) {\n-  string s;\n-  string format = GetDumpGraphFormatLowerCase();\n+  std::string s;\n+  std::string format = GetDumpGraphFormatLowerCase();\n   if (format == \"txt\" &&\n       !::tensorflow::protobuf::TextFormat::PrintToString(proto, &s)) {\n     return absl::FailedPreconditionError(\"Unable to convert proto to text.\");\n@@ -209,7 +211,7 @@ absl::Status WriteProtoToUniqueFile(const tensorflow::protobuf::Message& proto,\n \n absl::Status WriteProtoToUniqueFile(\n     const tensorflow::protobuf::MessageLite& proto, WritableFile* file) {\n-  string s;\n+  std::string s;\n   if (!SerializeToStringDeterministic(proto, &s)) {\n     return errors::Internal(\"Failed to serialize proto to string.\");\n   }\n@@ -223,10 +225,10 @@ absl::Status WriteProtoToUniqueFile(\n \n }  // anonymous namespace\n \n-string DumpToFile(const string& name, const string& dirname,\n-                  const string& suffix, absl::string_view type_name,\n-                  std::function<absl::Status(WritableFile*)> dumper) {\n-  string filepath;\n+std::string DumpToFile(const std::string& name, const std::string& dirname,\n+                       const std::string& suffix, absl::string_view type_name,\n+                       std::function<absl::Status(WritableFile*)> dumper) {\n+  std::string filepath;\n   std::unique_ptr<WritableFile> file;\n   absl::Status status = CreateWritableFile(Env::Default(), dirname, name,\n                                            suffix, &filepath, &file);\n@@ -249,32 +251,34 @@ void SetGraphDumper(\n                                const FunctionLibraryDefinition* flib_def,\n                                WritableFile*)>\n         dumper,\n-    string suffix) {\n+    std::string suffix) {\n   GraphDumperConfig& dumper_config = GetGraphDumperConfig();\n   mutex_lock lock(dumper_config.mu);\n   dumper_config.config.dumper = dumper;\n   dumper_config.config.suffix = suffix;\n }\n \n-string DumpGraphDefToFile(const string& name, GraphDef const& graph_def,\n-                          const string& dirname) {\n+std::string DumpGraphDefToFile(const std::string& name,\n+                               GraphDef const& graph_def,\n+                               const std::string& dirname) {\n   return DumpToFile(name, dirname, GetDumpGraphSuffix(), \"Graph\",\n                     [&](WritableFile* file) {\n                       return WriteProtoToUniqueFile(graph_def, file);\n                     });\n }\n \n-string DumpCostGraphDefToFile(const string& name, CostGraphDef const& graph_def,\n-                              const string& dirname) {\n+std::string DumpCostGraphDefToFile(const std::string& name,\n+                                   CostGraphDef const& graph_def,\n+                                   const std::string& dirname) {\n   return DumpToFile(name, dirname, GetDumpGraphSuffix(), \"Graph\",\n                     [&](WritableFile* file) {\n                       return WriteProtoToUniqueFile(graph_def, file);\n                     });\n }\n \n-string DumpGraphToFile(const string& name, Graph const& graph,\n-                       const FunctionLibraryDefinition* flib_def,\n-                       const string& dirname) {\n+std::string DumpGraphToFile(const std::string& name, Graph const& graph,\n+                            const FunctionLibraryDefinition* flib_def,\n+                            const std::string& dirname) {\n   auto& dumper_config = GetGraphDumperConfig();\n   if (dumper_config.IsSet()) {\n     GraphDumperConfig::Config config;\n@@ -298,16 +302,17 @@ string DumpGraphToFile(const string& name, Graph const& graph,\n   return DumpGraphDefToFile(name, graph_def, dirname);\n }\n \n-string DumpFunctionDefToFile(const string& name, FunctionDef const& fdef,\n-                             const string& dirname) {\n+std::string DumpFunctionDefToFile(const std::string& name,\n+                                  FunctionDef const& fdef,\n+                                  const std::string& dirname) {\n   return DumpToFile(\n       name, dirname, GetDumpGraphSuffix(), \"FunctionDef\",\n       [&](WritableFile* file) { return WriteProtoToUniqueFile(fdef, file); });\n }\n \n-string DumpProtoToFile(const string& name,\n-                       tensorflow::protobuf::Message const& proto,\n-                       const string& dirname) {\n+std::string DumpProtoToFile(const std::string& name,\n+                            tensorflow::protobuf::Message const& proto,\n+                            const std::string& dirname) {\n   return DumpToFile(\n       name, dirname, GetDumpGraphSuffix(), proto.GetTypeName(),\n       [&](WritableFile* file) { return WriteProtoToUniqueFile(proto, file); });"
        },
        {
            "sha": "2a81c55a0232f2431b99a8dc8c0a14b897af4e65",
            "filename": "tensorflow/core/util/dump_graph.h",
            "status": "modified",
            "additions": 19,
            "deletions": 16,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdump_graph.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -42,29 +42,32 @@ namespace tensorflow {\n // 'name' with '.pbtxt' or '.pb'. If a graph has already been dumped by\n // this process with the same name, suffixes with \"_n.pb(txt)\", where 'n' is a\n // sequence number.\n-string DumpGraphDefToFile(const string& name, GraphDef const& graph_def,\n-                          const string& dirname = \"\");\n+std::string DumpGraphDefToFile(const std::string& name,\n+                               GraphDef const& graph_def,\n+                               const std::string& dirname = \"\");\n \n // Similar to DumpGraphDefToFile, use CostGraphDef instead of GraphDef.\n-string DumpCostGraphDefToFile(const string& name, CostGraphDef const& graph_def,\n-                              const string& dirname = \"\");\n+std::string DumpCostGraphDefToFile(const std::string& name,\n+                                   CostGraphDef const& graph_def,\n+                                   const std::string& dirname = \"\");\n \n // Similar to DumpGraphDefToFile, but builds the GraphDef to dump from a 'graph'\n // and an optional function library 'flib_def'. Returns the file name chosen.\n-string DumpGraphToFile(const string& name, Graph const& graph,\n-                       const FunctionLibraryDefinition* flib_def = nullptr,\n-                       const string& dirname = \"\");\n+std::string DumpGraphToFile(const std::string& name, Graph const& graph,\n+                            const FunctionLibraryDefinition* flib_def = nullptr,\n+                            const std::string& dirname = \"\");\n \n // Similar to DumpGraphDefToFile, but dumps a function as a FunctionDef text\n // proto. Returns the file name chosen.\n-string DumpFunctionDefToFile(const string& name, FunctionDef const& fdef,\n-                             const string& dirname = \"\");\n+std::string DumpFunctionDefToFile(const std::string& name,\n+                                  FunctionDef const& fdef,\n+                                  const std::string& dirname = \"\");\n \n // Similar to DumpGraphDefToFile, but dumps a proto of any type. Returns the\n // file name chosen.\n-string DumpProtoToFile(const string& name,\n-                       tensorflow::protobuf::Message const& proto,\n-                       const string& dirname = \"\");\n+std::string DumpProtoToFile(const std::string& name,\n+                            tensorflow::protobuf::Message const& proto,\n+                            const std::string& dirname = \"\");\n \n // Sets a custom Graph dumper. If set, this dumper will be used to dump graphs\n // instead via DumpGraphToFile. As the custom dumper may not produce protobufs,\n@@ -74,14 +77,14 @@ void SetGraphDumper(\n                                const FunctionLibraryDefinition* flib_def,\n                                WritableFile*)>\n         dumper,\n-    string suffix = \".pbtxt\");\n+    std::string suffix = \".pbtxt\");\n \n // Dump data to a file.\n // This function will create a WritableFile and pass it to the dumper.\n // The dumper callback will be responsible for writing data to the file.\n-string DumpToFile(const string& name, const string& dirname,\n-                  const string& suffix, absl::string_view type_name,\n-                  std::function<absl::Status(WritableFile*)> dumper);\n+std::string DumpToFile(const std::string& name, const std::string& dirname,\n+                       const std::string& suffix, absl::string_view type_name,\n+                       std::function<absl::Status(WritableFile*)> dumper);\n \n }  // namespace tensorflow\n "
        },
        {
            "sha": "c80f74690f0f6d3f0ab61f95f978d49384907e84",
            "filename": "tensorflow/core/util/dump_graph_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fdump_graph_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fdump_graph_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -35,15 +35,15 @@ TEST(DumpGraph, DumpGraphToFileSuccess) {\n   TF_CHECK_OK(NodeBuilder(\"A\", \"NoOp\").Finalize(&graph, &node));\n \n   setenv(\"TF_DUMP_GRAPH_PREFIX\", testing::TmpDir().c_str(), 1);\n-  string ret = DumpGraphToFile(\"graph\", graph);\n+  std::string ret = DumpGraphToFile(\"graph\", graph);\n   EXPECT_EQ(ret, io::JoinPath(testing::TmpDir(), \"graph.pbtxt\"));\n   ret = DumpGraphToFile(\"graph\", graph);\n   EXPECT_EQ(ret, io::JoinPath(testing::TmpDir(), \"graph_1.pbtxt\"));\n \n   GraphDef gdef;\n   TF_ASSERT_OK(ReadTextProto(\n       Env::Default(), io::JoinPath(testing::TmpDir(), \"graph.pbtxt\"), &gdef));\n-  string read, written;\n+  std::string read, written;\n   gdef.AppendToString(&read);\n   graph.ToGraphDefDebug().AppendToString(&written);\n   EXPECT_EQ(read, written);\n@@ -52,14 +52,14 @@ TEST(DumpGraph, DumpGraphToFileSuccess) {\n TEST(DumpGraph, DumpGraphToFileNoEnvPrefix) {\n   Graph graph(OpRegistry::Global());\n   unsetenv(\"TF_DUMP_GRAPH_PREFIX\");\n-  string ret = DumpGraphToFile(\"graph\", graph);\n+  std::string ret = DumpGraphToFile(\"graph\", graph);\n   EXPECT_TRUE(absl::StrContains(ret, \"TF_DUMP_GRAPH_PREFIX not specified\"));\n }\n \n TEST(DumpGraph, DumpFunctionDefToFileSuccess) {\n   FunctionDef fdef;\n   setenv(\"TF_DUMP_GRAPH_PREFIX\", testing::TmpDir().c_str(), 1);\n-  string ret = DumpFunctionDefToFile(\"function\", fdef);\n+  std::string ret = DumpFunctionDefToFile(\"function\", fdef);\n   EXPECT_EQ(ret, io::JoinPath(testing::TmpDir(), \"function.pbtxt\"));\n }\n \n@@ -72,16 +72,17 @@ TEST(DumpGraph, DumpProtoToFileSuccess) {\n \n   setenv(\"TF_DUMP_GRAPH_PREFIX\", testing::TmpDir().c_str(), 1);\n   setenv(\"TF_DUMP_GRAPH_FMT\", \"TXT\", 1);\n-  string expected_filepath = io::JoinPath(testing::TmpDir(), \"node_def.pbtxt\");\n-  string actual_filepath = DumpProtoToFile(\"node_def\", ndef_in);\n+  std::string expected_filepath =\n+      io::JoinPath(testing::TmpDir(), \"node_def.pbtxt\");\n+  std::string actual_filepath = DumpProtoToFile(\"node_def\", ndef_in);\n   EXPECT_EQ(expected_filepath, actual_filepath);\n \n   NodeDef ndef_out;\n   TF_ASSERT_OK(ReadTextProto(Env::Default(), expected_filepath, &ndef_out));\n   EXPECT_EQ(ndef_in.DebugString(), ndef_out.DebugString());\n \n   setenv(\"TF_DUMP_GRAPH_FMT\", \"BIN\", 1);\n-  string ret = DumpProtoToFile(\"node_def\", ndef_in);\n+  std::string ret = DumpProtoToFile(\"node_def\", ndef_in);\n   EXPECT_EQ(ret, io::JoinPath(testing::TmpDir(), \"node_def_1.pb\"));\n   TF_ASSERT_OK(ReadBinaryProto(Env::Default(), ret, &ndef_out));\n   EXPECT_EQ(ndef_out.DebugString(), ndef_in.DebugString());"
        },
        {
            "sha": "bb37622670f4d6b12bef26bcc22d9d11c968da55",
            "filename": "tensorflow/core/util/einsum_op_util.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Feinsum_op_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Feinsum_op_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Feinsum_op_util.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -28,9 +28,10 @@ limitations under the License.\n namespace tensorflow {\n \n absl::Status ValidateEinsumEquation(\n-    const string& equation, absl::InlinedVector<string, 2UL>* input_subscripts,\n-    string* output_subscript) {\n-  absl::InlinedVector<string, 2UL> inputs_and_output_subscripts =\n+    const std::string& equation,\n+    absl::InlinedVector<std::string, 2UL>* input_subscripts,\n+    std::string* output_subscript) {\n+  absl::InlinedVector<std::string, 2UL> inputs_and_output_subscripts =\n       absl::StrSplit(equation, \"->\");\n   if (inputs_and_output_subscripts.size() != 2) {\n     return errors::InvalidArgument(\n@@ -63,7 +64,7 @@ EinsumDimensionType GetDimensionType(bool is_removed, bool is_unique) {\n }\n \n // Maps the character labels to consecutive integers.\n-void MapToLabels(const string& subscript, Labels* labels,\n+void MapToLabels(const std::string& subscript, Labels* labels,\n                  absl::flat_hash_map<char, int>* label_mapping) {\n   for (int i = 0; i < subscript.size(); ++i) {\n     const char label_char = subscript[i];\n@@ -82,13 +83,13 @@ void MapToLabels(const string& subscript, Labels* labels,\n }\n \n absl::Status ParseEinsumEquation(\n-    const string& equation, OperandLabels* input_labels, Labels* output_labels,\n-    std::vector<EinsumDimensionType>* label_types,\n+    const std::string& equation, OperandLabels* input_labels,\n+    Labels* output_labels, std::vector<EinsumDimensionType>* label_types,\n     OperandLabelCounts* input_label_counts, LabelCounts* output_label_counts,\n     absl::InlinedVector<bool, 2UL>* input_has_ellipsis,\n     bool* output_has_ellipsis) {\n-  absl::InlinedVector<string, 2UL> input_str;\n-  string output_str;\n+  absl::InlinedVector<std::string, 2UL> input_str;\n+  std::string output_str;\n   TF_RETURN_IF_ERROR(ValidateEinsumEquation(equation, &input_str, &output_str));\n \n   // Temporary map from single character labels to (consecutive) integer labels."
        },
        {
            "sha": "6e45c47fea99b8800cfb7cefcd5e1260fc720056",
            "filename": "tensorflow/core/util/einsum_op_util.h",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Feinsum_op_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Feinsum_op_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Feinsum_op_util.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -53,16 +53,17 @@ enum EinsumDimensionType {\n \n // Parses and validates an einsum equation in explicit form.\n absl::Status ValidateEinsumEquation(\n-    const string& equation, absl::InlinedVector<string, 2UL>* input_subscripts,\n-    string* output_subscript);\n+    const std::string& equation,\n+    absl::InlinedVector<std::string, 2UL>* input_subscripts,\n+    std::string* output_subscript);\n \n // Parses and validates the equation and the input shapes. Single character\n // labels are integerized and we populate input and output label subscripts\n // and corresponding counts. Also create the mapping from (named) labels to\n // their EinsumDimensionType.\n absl::Status ParseEinsumEquation(\n-    const string& equation, OperandLabels* input_labels, Labels* output_labels,\n-    std::vector<EinsumDimensionType>* label_types,\n+    const std::string& equation, OperandLabels* input_labels,\n+    Labels* output_labels, std::vector<EinsumDimensionType>* label_types,\n     OperandLabelCounts* input_label_counts, LabelCounts* output_label_counts,\n     absl::InlinedVector<bool, 2UL>* input_has_ellipsis,\n     bool* output_has_ellipsis);"
        },
        {
            "sha": "c8d5a41b1fc848dcb9d85ff31c775c7c017b4e92",
            "filename": "tensorflow/core/util/equal_graph_def.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 20,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fequal_graph_def.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -33,20 +33,22 @@ limitations under the License.\n namespace tensorflow {\n \n bool EqualGraphDef(const GraphDef& actual, const GraphDef& expected,\n-                   string* diff, const EqualGraphDefOptions& options) {\n+                   std::string* diff, const EqualGraphDefOptions& options) {\n   // Intentionally do not check that versions match so that this routine can\n   // be used for less brittle golden file tests.\n   return EqualRepeatedNodeDef(actual.node(), expected.node(), diff, options);\n }\n \n-uint64 GraphDefHash(const GraphDef& gdef, const EqualGraphDefOptions& options) {\n+uint64_t GraphDefHash(const GraphDef& gdef,\n+                      const EqualGraphDefOptions& options) {\n   return RepeatedNodeDefHash(gdef.node(), options);\n }\n \n bool EqualRepeatedNodeDef(const protobuf::RepeatedPtrField<NodeDef>& actual,\n                           const protobuf::RepeatedPtrField<NodeDef>& expected,\n-                          string* diff, const EqualGraphDefOptions& options) {\n-  std::unordered_map<string, const NodeDef*> actual_index;\n+                          std::string* diff,\n+                          const EqualGraphDefOptions& options) {\n+  std::unordered_map<std::string, const NodeDef*> actual_index;\n   for (const NodeDef& node : actual) {\n     actual_index[node.name()] = &node;\n   }\n@@ -80,11 +82,11 @@ bool EqualRepeatedNodeDef(const protobuf::RepeatedPtrField<NodeDef>& actual,\n   return true;\n }\n \n-uint64 RepeatedNodeDefHash(const protobuf::RepeatedPtrField<NodeDef>& ndefs,\n-                           const EqualGraphDefOptions& options) {\n-  uint64 h = 0xDECAFCAFFE;\n+uint64_t RepeatedNodeDefHash(const protobuf::RepeatedPtrField<NodeDef>& ndefs,\n+                             const EqualGraphDefOptions& options) {\n+  uint64_t h = 0xDECAFCAFFE;\n   // Insert NodeDefs into map to deterministically sort by name\n-  std::map<string, const NodeDef*> nodes;\n+  std::map<std::string, const NodeDef*> nodes;\n   for (const NodeDef& node : ndefs) {\n     nodes[node.name()] = &node;\n   }\n@@ -97,8 +99,8 @@ uint64 RepeatedNodeDefHash(const protobuf::RepeatedPtrField<NodeDef>& ndefs,\n \n namespace {\n \n-string JoinStringField(const protobuf::RepeatedPtrField<string>& f) {\n-  string ret;\n+std::string JoinStringField(const protobuf::RepeatedPtrField<std::string>& f) {\n+  std::string ret;\n   for (int i = 0; i < f.size(); ++i) {\n     if (i > 0) absl::StrAppend(&ret, \", \");\n     absl::StrAppend(&ret, f.Get(i));\n@@ -108,8 +110,8 @@ string JoinStringField(const protobuf::RepeatedPtrField<string>& f) {\n \n }  // namespace\n \n-bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n-                  const EqualGraphDefOptions& options) {\n+bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected,\n+                  std::string* diff, const EqualGraphDefOptions& options) {\n   if (actual.name() != expected.name()) {\n     if (diff != nullptr) {\n       *diff = strings::StrCat(\"Actual node name '\", actual.name(),\n@@ -166,8 +168,8 @@ bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n     }\n   }\n \n-  std::unordered_set<string> actual_control;\n-  std::unordered_set<string> expected_control;\n+  std::unordered_set<std::string> actual_control;\n+  std::unordered_set<std::string> expected_control;\n   for (int i = first_control_input; i < actual.input_size(); ++i) {\n     actual_control.insert(actual.input(i));\n     expected_control.insert(expected.input(i));\n@@ -190,7 +192,7 @@ bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n     return false;\n   }\n \n-  std::unordered_set<string> actual_attr;\n+  std::unordered_set<std::string> actual_attr;\n   for (const auto& a : actual.attr()) {\n     if (options.ignore_internal_attrs && !a.first.empty() &&\n         a.first[0] == '_') {\n@@ -236,8 +238,8 @@ bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n   return true;\n }\n \n-uint64 NodeDefHash(const NodeDef& ndef, const EqualGraphDefOptions& options) {\n-  uint64 h = Hash64(ndef.name());\n+uint64_t NodeDefHash(const NodeDef& ndef, const EqualGraphDefOptions& options) {\n+  uint64_t h = Hash64(ndef.name());\n   h = Hash64(ndef.op().data(), ndef.op().size(), h);\n   h = Hash64(ndef.device().data(), ndef.device().size(), h);\n \n@@ -252,16 +254,16 @@ uint64 NodeDefHash(const NodeDef& ndef, const EqualGraphDefOptions& options) {\n   }\n \n   // Control inputs. Order irrelevant.\n-  std::set<string> ndef_control;\n+  std::set<std::string> ndef_control;\n   for (int i = first_control_input; i < ndef.input_size(); ++i) {\n     ndef_control.insert(ndef.input(i));\n   }\n-  for (const string& s : ndef_control) {\n+  for (const std::string& s : ndef_control) {\n     h = Hash64(s.data(), s.size(), h);\n   }\n \n   // Attributes\n-  std::map<string, AttrValue> ndef_attr;\n+  std::map<std::string, AttrValue> ndef_attr;\n   for (const auto& a : ndef.attr()) {\n     if (options.ignore_internal_attrs && !a.first.empty() &&\n         a.first[0] == '_') {"
        },
        {
            "sha": "2c720dcbfdadfd645778513a668d258362c38493",
            "filename": "tensorflow/core/util/equal_graph_def.h",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fequal_graph_def.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -37,7 +37,7 @@ struct EqualGraphDefOptions {\n // we use node names to match up nodes between the graphs, and so the naming of\n // nodes must be consistent.\n bool EqualGraphDef(const GraphDef& actual, const GraphDef& expected,\n-                   string* diff, const EqualGraphDefOptions& options = {});\n+                   std::string* diff, const EqualGraphDefOptions& options = {});\n \n // Returns a hash of `gdef` that is consistent with EqualGraphDef. In other\n // words, if two graph defs compare equal according to EqualGraphDef,\n@@ -46,16 +46,16 @@ bool EqualGraphDef(const GraphDef& actual, const GraphDef& expected,\n // Similarly to protobuf deterministic serialization, hash value is\n // guaranteed to be stable only for a given binary. In particular, one should\n // probably not persist the returned value.\n-uint64 GraphDefHash(const GraphDef& gdef,\n-                    const EqualGraphDefOptions& options = {});\n+uint64_t GraphDefHash(const GraphDef& gdef,\n+                      const EqualGraphDefOptions& options = {});\n \n // Determines if actual and expected are equal, ignoring: ordering of\n // attrs, internal attributes (if set in `options`), and control inputs.\n //\n // If the NodeDefs are different and\n // diff != nullptr, *diff is set to an explanation of the difference.\n-bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n-                  const EqualGraphDefOptions& options = {});\n+bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected,\n+                  std::string* diff, const EqualGraphDefOptions& options = {});\n \n // Returns a hash of `ndef` that is consistent with EqualNodeDef. In other\n // words, if two node defs compare equal according to EqualNodeDef, NodeDefHash\n@@ -64,15 +64,15 @@ bool EqualNodeDef(const NodeDef& actual, const NodeDef& expected, string* diff,\n // Similarly to protobuf deterministic serialization, hash value is\n // guaranteed to be stable only for a given binary. In particular, one should\n // probably not persist the returned value.\n-uint64 NodeDefHash(const NodeDef& ndef,\n-                   const EqualGraphDefOptions& options = {});\n+uint64_t NodeDefHash(const NodeDef& ndef,\n+                     const EqualGraphDefOptions& options = {});\n \n // Determines if actual and expected are equal, ignoring ordering. If they're\n // different and diff != nullptr, *diff is set to an explanation of the\n // difference.\n bool EqualRepeatedNodeDef(const protobuf::RepeatedPtrField<NodeDef>& actual,\n                           const protobuf::RepeatedPtrField<NodeDef>& expected,\n-                          string* diff,\n+                          std::string* diff,\n                           const EqualGraphDefOptions& options = {});\n \n // Returns a hash of `ndefs` that is consistent with EqualRepeatedNodeDef.\n@@ -83,8 +83,8 @@ bool EqualRepeatedNodeDef(const protobuf::RepeatedPtrField<NodeDef>& actual,\n // Similarly to protobuf deterministic serialization, hash value is\n // guaranteed to be stable only for a given binary. In particular, one should\n // probably not persist the returned value.\n-uint64 RepeatedNodeDefHash(const protobuf::RepeatedPtrField<NodeDef>& ndefs,\n-                           const EqualGraphDefOptions& options = {});\n+uint64_t RepeatedNodeDefHash(const protobuf::RepeatedPtrField<NodeDef>& ndefs,\n+                             const EqualGraphDefOptions& options = {});\n \n #define TF_EXPECT_GRAPH_EQ(expected, actual)            \\\n   do {                                                  \\"
        },
        {
            "sha": "c989b60c371751f1d516b634ebee7cf237059d49",
            "filename": "tensorflow/core/util/equal_graph_def_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fequal_graph_def_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fequal_graph_def_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -72,7 +72,7 @@ class EqualGraphDefTest : public ::testing::Test {\n \n   GraphDefBuilder e_;\n   GraphDefBuilder a_;\n-  string diff_;\n+  std::string diff_;\n };\n \n TEST_F(EqualGraphDefTest, Match) {"
        },
        {
            "sha": "4d4b16a078848b1ecd8494de1ca2287c3a2f5756",
            "filename": "tensorflow/core/util/events_writer.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fevents_writer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fevents_writer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fevents_writer.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -32,7 +32,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-EventsWriter::EventsWriter(const string& file_prefix)\n+EventsWriter::EventsWriter(const std::string& file_prefix)\n     // TODO(jeff,sanjay): Pass in env and use that here instead of Env::Default\n     : env_(Env::Default()),\n       file_prefix_(file_prefix),\n@@ -44,7 +44,7 @@ EventsWriter::~EventsWriter() {\n \n absl::Status EventsWriter::Init() { return InitWithSuffix(\"\"); }\n \n-absl::Status EventsWriter::InitWithSuffix(const string& suffix) {\n+absl::Status EventsWriter::InitWithSuffix(const std::string& suffix) {\n   file_suffix_ = suffix;\n   return InitIfNeeded();\n }\n@@ -99,7 +99,7 @@ absl::Status EventsWriter::InitIfNeeded() {\n   return absl::OkStatus();\n }\n \n-string EventsWriter::FileName() {\n+std::string EventsWriter::FileName() {\n   if (filename_.empty()) {\n     InitIfNeeded().IgnoreError();\n   }\n@@ -120,7 +120,7 @@ void EventsWriter::WriteSerializedEvent(absl::string_view event_str) {\n // NOTE(touts); This is NOT the function called by the Python code.\n // Python calls WriteSerializedEvent(), see events_writer.i.\n void EventsWriter::WriteEvent(const Event& event) {\n-  string record;\n+  std::string record;\n   event.AppendToString(&record);\n   WriteSerializedEvent(record);\n }"
        },
        {
            "sha": "f1aeb7981daab4b70dfbdbd82cbb3c9b44575e56",
            "filename": "tensorflow/core/util/events_writer_test.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 25,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fevents_writer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fevents_writer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fevents_writer_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -39,7 +39,7 @@ namespace {\n Env* env() { return Env::Default(); }\n \n void WriteSimpleValue(EventsWriter* writer, double wall_time, int64_t step,\n-                      const string& tag, float simple_value) {\n+                      const std::string& tag, float simple_value) {\n   Event event;\n   event.set_wall_time(wall_time);\n   event.set_step(step);\n@@ -54,7 +54,7 @@ void WriteFile(EventsWriter* writer) {\n   WriteSimpleValue(writer, 2345, 35, \"bar\", -42);\n }\n \n-static bool ReadEventProto(io::RecordReader* reader, uint64* offset,\n+static bool ReadEventProto(io::RecordReader* reader, uint64_t* offset,\n                            Event* proto) {\n   tstring record;\n   absl::Status s = reader->ReadRecord(offset, &record);\n@@ -64,13 +64,13 @@ static bool ReadEventProto(io::RecordReader* reader, uint64* offset,\n   return ParseProtoUnlimited(proto, record);\n }\n \n-void VerifyFile(const string& filename) {\n+void VerifyFile(const std::string& filename) {\n   TF_CHECK_OK(env()->FileExists(filename));\n   std::unique_ptr<RandomAccessFile> event_file;\n   TF_CHECK_OK(env()->NewRandomAccessFile(filename, &event_file));\n   io::RecordReader* reader = new io::RecordReader(event_file.get());\n \n-  uint64 offset = 0;\n+  uint64_t offset = 0;\n \n   Event actual;\n   CHECK(ReadEventProto(reader, &offset, &actual));\n@@ -109,101 +109,101 @@ void VerifyFile(const string& filename) {\n   delete reader;\n }\n \n-string GetDirName(const string& suffix) {\n+std::string GetDirName(const std::string& suffix) {\n   return io::JoinPath(testing::TmpDir(), suffix);\n }\n \n TEST(EventWriter, WriteFlush) {\n-  string file_prefix = GetDirName(\"/writeflush_test\");\n+  std::string file_prefix = GetDirName(\"/writeflush_test\");\n   EventsWriter writer(file_prefix);\n   WriteFile(&writer);\n   TF_EXPECT_OK(writer.Flush());\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   VerifyFile(filename);\n }\n \n TEST(EventWriter, WriteClose) {\n-  string file_prefix = GetDirName(\"/writeclose_test\");\n+  std::string file_prefix = GetDirName(\"/writeclose_test\");\n   EventsWriter writer(file_prefix);\n   WriteFile(&writer);\n   TF_EXPECT_OK(writer.Close());\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   VerifyFile(filename);\n }\n \n TEST(EventWriter, WriteDelete) {\n-  string file_prefix = GetDirName(\"/writedelete_test\");\n+  std::string file_prefix = GetDirName(\"/writedelete_test\");\n   EventsWriter* writer = new EventsWriter(file_prefix);\n   WriteFile(writer);\n-  string filename = writer->FileName();\n+  std::string filename = writer->FileName();\n   delete writer;\n   VerifyFile(filename);\n }\n \n TEST(EventWriter, FailFlush) {\n-  string file_prefix = GetDirName(\"/failflush_test\");\n+  std::string file_prefix = GetDirName(\"/failflush_test\");\n   EventsWriter writer(file_prefix);\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   WriteFile(&writer);\n   TF_EXPECT_OK(env()->FileExists(filename));\n   TF_ASSERT_OK(env()->DeleteFile(filename));\n   EXPECT_TRUE(writer.Flush().ok());\n }\n \n TEST(EventWriter, FailClose) {\n-  string file_prefix = GetDirName(\"/failclose_test\");\n+  std::string file_prefix = GetDirName(\"/failclose_test\");\n   EventsWriter writer(file_prefix);\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   WriteFile(&writer);\n   TF_EXPECT_OK(env()->FileExists(filename));\n   TF_ASSERT_OK(env()->DeleteFile(filename));\n   EXPECT_TRUE(writer.Close().ok());\n }\n \n TEST(EventWriter, InitWriteClose) {\n-  string file_prefix = GetDirName(\"/initwriteclose_test\");\n+  std::string file_prefix = GetDirName(\"/initwriteclose_test\");\n   EventsWriter writer(file_prefix);\n   TF_EXPECT_OK(writer.Init());\n-  string filename0 = writer.FileName();\n+  std::string filename0 = writer.FileName();\n   TF_EXPECT_OK(env()->FileExists(filename0));\n   WriteFile(&writer);\n   TF_EXPECT_OK(writer.Close());\n-  string filename1 = writer.FileName();\n+  std::string filename1 = writer.FileName();\n   EXPECT_EQ(filename0, filename1);\n   VerifyFile(filename1);\n }\n \n TEST(EventWriter, NameWriteClose) {\n-  string file_prefix = GetDirName(\"/namewriteclose_test\");\n+  std::string file_prefix = GetDirName(\"/namewriteclose_test\");\n   EventsWriter writer(file_prefix);\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   TF_EXPECT_OK(env()->FileExists(filename));\n   WriteFile(&writer);\n   TF_EXPECT_OK(writer.Close());\n   VerifyFile(filename);\n }\n \n TEST(EventWriter, NameClose) {\n-  string file_prefix = GetDirName(\"/nameclose_test\");\n+  std::string file_prefix = GetDirName(\"/nameclose_test\");\n   EventsWriter writer(file_prefix);\n-  string filename = writer.FileName();\n+  std::string filename = writer.FileName();\n   TF_EXPECT_OK(writer.Close());\n   TF_EXPECT_OK(env()->FileExists(filename));\n   TF_ASSERT_OK(env()->DeleteFile(filename));\n }\n \n TEST(EventWriter, FileDeletionBeforeWriting) {\n-  string file_prefix = GetDirName(\"/fdbw_test\");\n+  std::string file_prefix = GetDirName(\"/fdbw_test\");\n   EventsWriter writer(file_prefix);\n-  string filename0 = writer.FileName();\n+  std::string filename0 = writer.FileName();\n   TF_EXPECT_OK(env()->FileExists(filename0));\n   env()->SleepForMicroseconds(\n       2000000);  // To make sure timestamp part of filename will differ.\n   TF_ASSERT_OK(env()->DeleteFile(filename0));\n   TF_EXPECT_OK(writer.Init());  // Init should reopen file.\n   WriteFile(&writer);\n   TF_EXPECT_OK(writer.Flush());\n-  string filename1 = writer.FileName();\n+  std::string filename1 = writer.FileName();\n   EXPECT_NE(filename0, filename1);\n   VerifyFile(filename1);\n }"
        },
        {
            "sha": "5a41ad1982a24277f3121c94841b3ab44dd5a61b",
            "filename": "tensorflow/core/util/example_proto_fast_parsing.cc",
            "status": "modified",
            "additions": 83,
            "deletions": 79,
            "changes": 162,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -107,17 +107,17 @@ auto EnableAliasing(A* a) -> decltype(a->EnableAliasing(true), void()) {\n template <typename A>\n void EnableAliasing(A&& a) {}\n \n-uint8 PeekTag(protobuf::io::CodedInputStream* stream) {\n+uint8_t PeekTag(protobuf::io::CodedInputStream* stream) {\n   DCHECK(stream != nullptr);\n   const void* ptr;\n   int size;\n   if (!stream->GetDirectBufferPointer(&ptr, &size)) return 0;\n-  return *static_cast<const uint8*>(ptr);\n+  return *static_cast<const uint8_t*>(ptr);\n }\n \n-constexpr uint8 kVarintTag(uint32 tag) { return (tag << 3) | 0; }\n-constexpr uint8 kDelimitedTag(uint32 tag) { return (tag << 3) | 2; }\n-constexpr uint8 kFixed32Tag(uint32 tag) { return (tag << 3) | 5; }\n+constexpr uint8_t kVarintTag(uint32_t tag) { return (tag << 3) | 0; }\n+constexpr uint8_t kDelimitedTag(uint32_t tag) { return (tag << 3) | 2; }\n+constexpr uint8_t kFixed32Tag(uint32_t tag) { return (tag << 3) | 5; }\n \n namespace parsed {\n \n@@ -133,7 +133,7 @@ class Feature {\n       *dtype = DT_INVALID;\n       return absl::OkStatus();\n     }\n-    uint8 oneof_tag = static_cast<uint8>(*serialized_.data());\n+    uint8_t oneof_tag = static_cast<uint8_t>(*serialized_.data());\n     serialized_.remove_prefix(1);\n     switch (oneof_tag) {\n       case kDelimitedTag(1):\n@@ -155,15 +155,16 @@ class Feature {\n \n   bool GetNumElementsInBytesList(int* num_elements) {\n     protobuf::io::CodedInputStream stream(\n-        reinterpret_cast<const uint8*>(serialized_.data()), serialized_.size());\n+        reinterpret_cast<const uint8_t*>(serialized_.data()),\n+        serialized_.size());\n     EnableAliasing(&stream);\n-    uint32 length = 0;\n+    uint32_t length = 0;\n     if (!stream.ReadVarint32(&length)) return false;\n     auto limit = stream.PushLimit(length);\n     *num_elements = 0;\n     while (!stream.ExpectAtEnd()) {\n       if (!stream.ExpectTag(kDelimitedTag(1))) return false;\n-      uint32 bytes_length = 0;\n+      uint32_t bytes_length = 0;\n       if (!stream.ReadVarint32(&bytes_length)) return false;\n       if (!stream.Skip(bytes_length)) return false;\n       ++*num_elements;\n@@ -188,18 +189,19 @@ class Feature {\n     DCHECK(bytes_list != nullptr);\n \n     protobuf::io::CodedInputStream stream(\n-        reinterpret_cast<const uint8*>(serialized_.data()), serialized_.size());\n+        reinterpret_cast<const uint8_t*>(serialized_.data()),\n+        serialized_.size());\n \n     EnableAliasing(&stream);\n \n-    uint32 length;\n+    uint32_t length;\n     if (!stream.ReadVarint32(&length)) return false;\n     auto limit = stream.PushLimit(length);\n \n     while (!stream.ExpectAtEnd()) {\n       if (!stream.ExpectTag(kDelimitedTag(1))) return false;\n       // parse string\n-      uint32 bytes_length;\n+      uint32_t bytes_length;\n       if (!stream.ReadVarint32(&bytes_length)) return false;\n       tstring* bytes = construct_at_end(bytes_list);\n       if (bytes == nullptr) return false;\n@@ -214,22 +216,23 @@ class Feature {\n   bool ParseFloatList(Result* float_list) {\n     DCHECK(float_list != nullptr);\n     protobuf::io::CodedInputStream stream(\n-        reinterpret_cast<const uint8*>(serialized_.data()), serialized_.size());\n+        reinterpret_cast<const uint8_t*>(serialized_.data()),\n+        serialized_.size());\n     EnableAliasing(&stream);\n-    uint32 length;\n+    uint32_t length;\n     if (!stream.ReadVarint32(&length)) return false;\n     auto limit = stream.PushLimit(length);\n \n     if (!stream.ExpectAtEnd()) {\n-      uint8 peek_tag = PeekTag(&stream);\n+      uint8_t peek_tag = PeekTag(&stream);\n       if (peek_tag != kDelimitedTag(1) && peek_tag != kFixed32Tag(1)) {\n         return false;\n       }\n \n       constexpr int32_t kNumFloatBytes = 4;\n       if (peek_tag == kDelimitedTag(1)) {                       // packed\n         if (!stream.ExpectTag(kDelimitedTag(1))) return false;  // packed tag\n-        uint32 packed_length;\n+        uint32_t packed_length;\n         if (!stream.ReadVarint32(&packed_length)) return false;\n         auto packed_limit = stream.PushLimit(packed_length);\n \n@@ -245,16 +248,16 @@ class Feature {\n             sizeof(typename Result::value_type) == kNumFloatBytes) {\n           // Calculate the length of the buffer available what can be less than\n           // what we requested in resize in case of a LimitedArraySlice.\n-          const uint32 bytes_to_copy =\n-              std::min(static_cast<uint32>((float_list->size() - initial_size) *\n-                                           kNumFloatBytes),\n-                       packed_length);\n+          const uint32_t bytes_to_copy = std::min(\n+              static_cast<uint32_t>((float_list->size() - initial_size) *\n+                                    kNumFloatBytes),\n+              packed_length);\n           if (!stream.ReadRaw(float_list->data() + initial_size, bytes_to_copy))\n             return false;\n         } else {\n           int64_t index = initial_size;\n           while (!stream.ExpectAtEnd()) {\n-            uint32 buffer32;\n+            uint32_t buffer32;\n             if (!stream.ReadLittleEndian32(&buffer32)) return false;\n             if (index < float_list->size()) {\n               float_list->data()[index] = absl::bit_cast<float>(buffer32);\n@@ -274,7 +277,7 @@ class Feature {\n         int64_t index = initial_size;\n         while (!stream.ExpectAtEnd()) {\n           if (!stream.ExpectTag(kFixed32Tag(1))) return false;\n-          uint32 buffer32;\n+          uint32_t buffer32;\n           if (!stream.ReadLittleEndian32(&buffer32)) return false;\n           float_list->data()[index] = absl::bit_cast<float>(buffer32);\n           ++index;\n@@ -290,20 +293,21 @@ class Feature {\n   bool ParseInt64List(Result* int64_list) {\n     DCHECK(int64_list != nullptr);\n     protobuf::io::CodedInputStream stream(\n-        reinterpret_cast<const uint8*>(serialized_.data()), serialized_.size());\n+        reinterpret_cast<const uint8_t*>(serialized_.data()),\n+        serialized_.size());\n     EnableAliasing(&stream);\n-    uint32 length;\n+    uint32_t length;\n     if (!stream.ReadVarint32(&length)) return false;\n     auto limit = stream.PushLimit(length);\n \n     if (!stream.ExpectAtEnd()) {\n-      uint8 peek_tag = PeekTag(&stream);\n+      uint8_t peek_tag = PeekTag(&stream);\n       if (peek_tag != kDelimitedTag(1) && peek_tag != kVarintTag(1)) {\n         return false;\n       }\n       if (peek_tag == kDelimitedTag(1)) {                       // packed\n         if (!stream.ExpectTag(kDelimitedTag(1))) return false;  // packed tag\n-        uint32 packed_length;\n+        uint32_t packed_length;\n         if (!stream.ReadVarint32(&packed_length)) return false;\n         auto packed_limit = stream.PushLimit(packed_length);\n \n@@ -340,7 +344,7 @@ using Example = std::vector<FeatureMapEntry>;\n }  // namespace parsed\n \n inline bool SkipExtraneousTag(protobuf::io::CodedInputStream* stream) {\n-  uint32 data;\n+  uint32_t data;\n   protobuf_uint64 dummy;\n   switch (stream->ReadTag() & 0x7) {\n     case 0:  // varint\n@@ -368,7 +372,7 @@ bool ParseString(protobuf::io::CodedInputStream* stream,\n                  absl::string_view* result) {\n   DCHECK(stream != nullptr);\n   DCHECK(result != nullptr);\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ReadVarint32(&length)) return false;\n   if (length == 0) {\n     *result = absl::string_view(nullptr, 0);\n@@ -379,7 +383,7 @@ bool ParseString(protobuf::io::CodedInputStream* stream,\n   if (!stream->GetDirectBufferPointer(&stream_alias, &stream_size)) {\n     return false;\n   }\n-  if (static_cast<uint32>(stream_size) < length) return false;\n+  if (static_cast<uint32_t>(stream_size) < length) return false;\n   *result = absl::string_view(static_cast<const char*>(stream_alias), length);\n   stream->Skip(length);\n   return true;\n@@ -389,7 +393,7 @@ bool ParseFeatureMapEntry(protobuf::io::CodedInputStream* stream,\n                           parsed::FeatureMapEntry* feature_map_entry) {\n   DCHECK(stream != nullptr);\n   DCHECK(feature_map_entry != nullptr);\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ReadVarint32(&length)) return false;\n   auto limit = stream->PushLimit(length);\n \n@@ -422,7 +426,7 @@ bool ParseFeatures(protobuf::io::CodedInputStream* stream,\n                    parsed::Example* example) {\n   DCHECK(stream != nullptr);\n   DCHECK(example != nullptr);\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ReadVarint32(&length)) return false;\n   auto limit = stream->PushLimit(length);\n   while (!stream->ExpectAtEnd()) {\n@@ -455,14 +459,14 @@ bool ParseExample(protobuf::io::CodedInputStream* stream,\n bool ParseExample(absl::string_view serialized, parsed::Example* example) {\n   DCHECK(example != nullptr);\n   protobuf::io::CodedInputStream stream(\n-      reinterpret_cast<const uint8*>(serialized.data()), serialized.size());\n+      reinterpret_cast<const uint8_t*>(serialized.data()), serialized.size());\n   EnableAliasing(&stream);\n   return ParseExample(&stream, example);\n }\n \n }  // namespace\n \n-bool TestFastParse(const string& serialized, Example* example) {\n+bool TestFastParse(const std::string& serialized, Example* example) {\n   DCHECK(example != nullptr);\n   parsed::Example parsed_example;\n   if (!ParseExample(serialized, &parsed_example)) return false;\n@@ -473,7 +477,7 @@ bool TestFastParse(const string& serialized, Example* example) {\n     // I.e. last entry in the map overwrites all the previous ones.\n     parsed::FeatureMapEntry& name_and_feature =\n         parsed_example[parsed_example_size - i - 1];\n-    string name(name_and_feature.first);\n+    std::string name(name_and_feature.first);\n     if ((*features.mutable_feature()).count(name) > 0) continue;\n \n     auto& value = (*features.mutable_feature())[name];\n@@ -562,10 +566,10 @@ struct SparseBuffer {\n };\n \n struct SeededHasher {\n-  uint64 operator()(absl::string_view s) const {\n+  uint64_t operator()(absl::string_view s) const {\n     return Hash64(s.data(), s.size(), seed);\n   }\n-  uint64 seed{0xDECAFCAFFE};\n+  uint64_t seed{0xDECAFCAFFE};\n };\n \n void LogDenseFeatureDataLoss(absl::string_view feature_name) {\n@@ -631,7 +635,7 @@ absl::Status FastParseSerializedExample(\n     parsed::Feature& feature = name_and_feature.second;\n \n     std::pair<size_t, Type> d_and_type;\n-    uint64 h = hasher(feature_name);\n+    uint64_t h = hasher(feature_name);\n     if (!config_index.Find(h, &d_and_type)) continue;\n \n     size_t d = d_and_type.first;\n@@ -1302,7 +1306,7 @@ absl::Status FastParseExample(const Config& config,\n       size_t delta = 0;\n \n       if (indices->NumElements() > 0) {\n-        int64* ix_p = &indices->matrix<int64_t>()(offset, 0);\n+        int64_t* ix_p = &indices->matrix<int64_t>()(offset, 0);\n         size_t example_index = first_example_of_minibatch(i);\n         for (size_t example_end_index : buffer.example_end_indices) {\n           size_t feature_index = 0;\n@@ -1339,7 +1343,7 @@ absl::Status FastParseExample(const Config& config,\n     if (config.ragged[d].splits_dtype == DT_INT64) {\n       row_splits->flat<int64_t>()(0) = 0;\n     } else {\n-      row_splits->flat<int32>()(0) = 0;\n+      row_splits->flat<int32_t>()(0) = 0;\n     }\n \n     TensorShape values_shape;\n@@ -1356,13 +1360,13 @@ absl::Status FastParseExample(const Config& config,\n       // Update row_splits.  row_splits are formed by concatenating the example\n       // end_indices (adjusting each to start after the previous one ends).\n       if (config.ragged[d].splits_dtype == DT_INT64) {\n-        int64* row_splits_out = &row_splits->flat<int64_t>()(splits_offset);\n+        int64_t* row_splits_out = &row_splits->flat<int64_t>()(splits_offset);\n         int64_t start = *row_splits_out;\n         for (size_t example_end_index : buffer.example_end_indices) {\n           *++row_splits_out = start + example_end_index;\n         }\n       } else {\n-        int32* row_splits_out = &row_splits->flat<int32>()(splits_offset);\n+        int32_t* row_splits_out = &row_splits->flat<int32_t>()(splits_offset);\n         int32_t start = *row_splits_out;\n         for (size_t example_end_index : buffer.example_end_indices) {\n           *++row_splits_out = start + example_end_index;\n@@ -1561,7 +1565,7 @@ absl::Status FastParseSingleExample(const Config& config,\n     parsed::Feature& feature = name_and_feature.second;\n \n     std::pair<size_t, Type> d_and_type;\n-    uint64 h = hasher(feature_name);\n+    uint64_t h = hasher(feature_name);\n     if (!config_index.Find(h, &d_and_type)) continue;\n \n     size_t d = d_and_type.first;\n@@ -1873,7 +1877,7 @@ struct FeatureProtos {\n // Map from feature name to FeatureProtos for that feature.\n using FeatureProtosMap = absl::flat_hash_map<absl::string_view, FeatureProtos>;\n \n-string ExampleName(const absl::Span<const tstring> example_names, int n) {\n+std::string ExampleName(const absl::Span<const tstring> example_names, int n) {\n   return example_names.empty() ? \"<unknown>\" : example_names[n];\n }\n \n@@ -1882,14 +1886,14 @@ string ExampleName(const absl::Span<const tstring> example_names, int n) {\n inline int ParseBytesFeature(protobuf::io::CodedInputStream* stream,\n                              tstring* out) {\n   int num_elements = 0;\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ExpectTag(kDelimitedTag(1)) || !stream->ReadVarint32(&length)) {\n     return -1;\n   }\n   if (length > 0) {\n     auto limit = stream->PushLimit(length);\n     while (!stream->ExpectAtEnd()) {\n-      uint32 bytes_length;\n+      uint32_t bytes_length;\n       if (!stream->ExpectTag(kDelimitedTag(1)) ||\n           !stream->ReadVarint32(&bytes_length)) {\n         return -1;\n@@ -1927,22 +1931,22 @@ inline void PadInt64Feature(int num_to_pad, int64_t* out) {\n inline int ParseFloatFeature(protobuf::io::CodedInputStream* stream,\n                              float* out) {\n   int num_elements = 0;\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ExpectTag(kDelimitedTag(2)) || !stream->ReadVarint32(&length)) {\n     return -1;\n   }\n   if (length > 0) {\n     auto limit = stream->PushLimit(length);\n-    uint8 peek_tag = PeekTag(stream);\n+    uint8_t peek_tag = PeekTag(stream);\n     if (peek_tag == kDelimitedTag(1)) {  // packed\n-      uint32 packed_length;\n+      uint32_t packed_length;\n       if (!stream->ExpectTag(kDelimitedTag(1)) ||\n           !stream->ReadVarint32(&packed_length)) {\n         return -1;\n       }\n       auto packed_limit = stream->PushLimit(packed_length);\n       while (!stream->ExpectAtEnd()) {\n-        uint32 buffer32;\n+        uint32_t buffer32;\n         if (!stream->ReadLittleEndian32(&buffer32)) {\n           return -1;\n         }\n@@ -1954,7 +1958,7 @@ inline int ParseFloatFeature(protobuf::io::CodedInputStream* stream,\n       stream->PopLimit(packed_limit);\n     } else if (peek_tag == kFixed32Tag(1)) {\n       while (!stream->ExpectAtEnd()) {\n-        uint32 buffer32;\n+        uint32_t buffer32;\n         if (!stream->ExpectTag(kFixed32Tag(1)) ||\n             !stream->ReadLittleEndian32(&buffer32)) {\n           return -1;\n@@ -1978,15 +1982,15 @@ inline int ParseFloatFeature(protobuf::io::CodedInputStream* stream,\n inline int ParseInt64Feature(protobuf::io::CodedInputStream* stream,\n                              int64_t* out) {\n   int num_elements = 0;\n-  uint32 length;\n+  uint32_t length;\n   if (!stream->ExpectTag(kDelimitedTag(3)) || !stream->ReadVarint32(&length)) {\n     return -1;\n   }\n   if (length > 0) {\n     auto limit = stream->PushLimit(length);\n-    uint8 peek_tag = PeekTag(stream);\n+    uint8_t peek_tag = PeekTag(stream);\n     if (peek_tag == kDelimitedTag(1)) {  // packed\n-      uint32 packed_length;\n+      uint32_t packed_length;\n       if (!stream->ExpectTag(kDelimitedTag(1)) ||\n           !stream->ReadVarint32(&packed_length)) {\n         return -1;\n@@ -2070,7 +2074,7 @@ inline int GetFeatureLength(DataType dtype,\n }\n \n inline DataType ParseDataType(protobuf::io::CodedInputStream* stream) {\n-  uint8 peek_tag = PeekTag(stream);\n+  uint8_t peek_tag = PeekTag(stream);\n   switch (peek_tag) {\n     case kDelimitedTag(1):\n       return DT_STRING;\n@@ -2104,7 +2108,7 @@ inline bool SkipEmptyFeature(protobuf::io::CodedInputStream* stream,\n     default:\n       return false;\n   }\n-  uint32 length;\n+  uint32_t length;\n   return stream->ReadVarint32(&length) && length == 0;\n }\n \n@@ -2116,7 +2120,7 @@ absl::Status ExtractFeaturesFromSequenceExamples(\n   for (int d = 0; d < examples.size(); d++) {\n     const tstring& example = examples[d];\n     protobuf::io::CodedInputStream stream(\n-        reinterpret_cast<const uint8*>(example.data()), example.size());\n+        reinterpret_cast<const uint8_t*>(example.data()), example.size());\n     // Not clear what this does. Why not stream.EnableAliasing()?\n     EnableAliasing(&stream);\n \n@@ -2135,7 +2139,7 @@ absl::Status ExtractFeaturesFromSequenceExamples(\n             ExampleName(example_names, d));\n       }\n       if (features != nullptr) {\n-        uint32 length;\n+        uint32_t length;\n         if (!stream.ReadVarint32(&length)) {\n           return errors::InvalidArgument(\n               \"Invalid protocol message input, example id: \",\n@@ -2144,7 +2148,7 @@ absl::Status ExtractFeaturesFromSequenceExamples(\n         auto limit = stream.PushLimit(length);\n         while (!stream.ExpectAtEnd()) {\n           absl::string_view key, value;\n-          uint32 length;\n+          uint32_t length;\n           if (!stream.ExpectTag(kDelimitedTag(1)) ||\n               !stream.ReadVarint32(&length)) {\n             return errors::InvalidArgument(\n@@ -2187,7 +2191,7 @@ absl::Status GetContextFeatureLengths(\n       const auto& proto = feature.protos[d];\n       if (proto.empty()) continue;\n       protobuf::io::CodedInputStream stream(\n-          reinterpret_cast<const uint8*>(proto.data()), proto.size());\n+          reinterpret_cast<const uint8_t*>(proto.data()), proto.size());\n       EnableAliasing(&stream);\n       int num_elements = GetFeatureLength(feature.dtype, &stream);\n       if (num_elements < 0) {\n@@ -2226,10 +2230,10 @@ absl::Status GetSequenceFeatureLengths(\n       size_t num_rows = 0;\n       size_t num_elements = 0;\n       protobuf::io::CodedInputStream stream(\n-          reinterpret_cast<const uint8*>(proto.data()), proto.size());\n+          reinterpret_cast<const uint8_t*>(proto.data()), proto.size());\n       EnableAliasing(&stream);\n       while (!stream.ExpectAtEnd()) {\n-        uint32 feature_bytes;\n+        uint32_t feature_bytes;\n         if (!stream.ExpectTag(kDelimitedTag(1)) ||\n             !stream.ReadVarint32(&feature_bytes)) {\n           return errors::InvalidArgument(\"Error in sequence feature \", c.first,\n@@ -2358,7 +2362,7 @@ absl::Status ParseContextDenseFeatures(\n         num_elements += c.default_value.NumElements();\n       } else if (!feature_proto.empty()) {\n         protobuf::io::CodedInputStream stream(\n-            reinterpret_cast<const uint8*>(feature_proto.data()),\n+            reinterpret_cast<const uint8_t*>(feature_proto.data()),\n             feature_proto.size());\n         EnableAliasing(&stream);\n         num_elements += ParseFeature(dtype, &stream, &out, &out_offset);\n@@ -2408,7 +2412,7 @@ absl::Status ParseContextSparseFeatures(\n       const auto& feature_proto = feature.protos[e];\n       if (feature_proto.empty()) continue;\n       protobuf::io::CodedInputStream stream(\n-          reinterpret_cast<const uint8*>(feature_proto.data()),\n+          reinterpret_cast<const uint8_t*>(feature_proto.data()),\n           feature_proto.size());\n       EnableAliasing(&stream);\n       size_t num_added =\n@@ -2458,9 +2462,9 @@ absl::Status ParseContextRaggedFeatures(\n         Tensor(allocator, splits_dtype, splits_shape);\n     Tensor& out_values = context_result->ragged_values[t];\n     size_t out_values_offset = 0;\n-    int32* int32_splits =\n+    int32_t* int32_splits =\n         is_batch && splits_dtype == DT_INT32\n-            ? context_result->ragged_splits[t].vec<int32>().data()\n+            ? context_result->ragged_splits[t].vec<int32_t>().data()\n             : nullptr;\n     int64_t* int64_splits =\n         is_batch && splits_dtype == DT_INT64\n@@ -2478,7 +2482,7 @@ absl::Status ParseContextRaggedFeatures(\n       const auto& feature_proto = feature.protos[e];\n       if (!feature_proto.empty()) {\n         protobuf::io::CodedInputStream stream(\n-            reinterpret_cast<const uint8*>(feature_proto.data()),\n+            reinterpret_cast<const uint8_t*>(feature_proto.data()),\n             feature_proto.size());\n         EnableAliasing(&stream);\n         size_t num_added =\n@@ -2499,7 +2503,7 @@ absl::Status ParseContextRaggedFeatures(\n       int actual_splits =\n           int32_splits\n               ? int32_splits -\n-                    context_result->ragged_splits[t].vec<int32>().data()\n+                    context_result->ragged_splits[t].vec<int32_t>().data()\n               : int64_splits -\n                     context_result->ragged_splits[t].vec<int64_t>().data();\n       if (actual_splits != num_examples + 1) {\n@@ -2591,11 +2595,11 @@ absl::Status ParseSequenceDenseFeatures(\n         }\n       } else if (!feature_proto.empty()) {\n         protobuf::io::CodedInputStream stream(\n-            reinterpret_cast<const uint8*>(feature_proto.data()),\n+            reinterpret_cast<const uint8_t*>(feature_proto.data()),\n             feature_proto.size());\n         EnableAliasing(&stream);\n         while (!stream.ExpectAtEnd()) {\n-          uint32 feature_length;\n+          uint32_t feature_length;\n           if (!stream.ExpectTag(kDelimitedTag(1)) ||\n               !stream.ReadVarint32(&feature_length)) {\n             return errors::InvalidArgument(\"Error in sequence feature \",\n@@ -2716,12 +2720,12 @@ absl::Status ParseSequenceSparseFeatures(\n       const auto& feature_proto = feature.protos[e];\n       if (feature_proto.empty()) continue;\n       protobuf::io::CodedInputStream stream(\n-          reinterpret_cast<const uint8*>(feature_proto.data()),\n+          reinterpret_cast<const uint8_t*>(feature_proto.data()),\n           feature_proto.size());\n       EnableAliasing(&stream);\n       size_t num_rows = 0;\n       while (!stream.ExpectAtEnd()) {\n-        uint32 feature_length;\n+        uint32_t feature_length;\n         if (!stream.ExpectTag(kDelimitedTag(1)) ||\n             !stream.ReadVarint32(&feature_length)) {\n           // This should be unreachable -- we already scanned the feature in\n@@ -2821,17 +2825,17 @@ absl::Status ParseSequenceRaggedFeatures(\n         Tensor(allocator, splits_dtype, outer_splits_shape);\n     Tensor& out_values = sequence_result->ragged_values[t];\n     size_t out_values_offset = 0;\n-    int32* int32_inner_splits =\n+    int32_t* int32_inner_splits =\n         splits_dtype == DT_INT32\n-            ? sequence_result->ragged_splits[t].vec<int32>().data()\n+            ? sequence_result->ragged_splits[t].vec<int32_t>().data()\n             : nullptr;\n     int64_t* int64_inner_splits =\n         splits_dtype == DT_INT64\n             ? sequence_result->ragged_splits[t].vec<int64_t>().data()\n             : nullptr;\n-    int32* int32_outer_splits =\n+    int32_t* int32_outer_splits =\n         is_batch && splits_dtype == DT_INT32\n-            ? sequence_result->ragged_outer_splits[t].vec<int32>().data()\n+            ? sequence_result->ragged_outer_splits[t].vec<int32_t>().data()\n             : nullptr;\n     int64_t* int64_outer_splits =\n         is_batch && splits_dtype == DT_INT64\n@@ -2855,11 +2859,11 @@ absl::Status ParseSequenceRaggedFeatures(\n       const auto& feature_proto = feature.protos[e];\n       if (!feature_proto.empty()) {\n         protobuf::io::CodedInputStream stream(\n-            reinterpret_cast<const uint8*>(feature_proto.data()),\n+            reinterpret_cast<const uint8_t*>(feature_proto.data()),\n             feature_proto.size());\n         EnableAliasing(&stream);\n         while (!stream.ExpectAtEnd()) {\n-          uint32 feature_length;\n+          uint32_t feature_length;\n           if (!stream.ExpectTag(kDelimitedTag(1)) ||\n               !stream.ReadVarint32(&feature_length)) {\n             // This should be unreachable -- we already scanned the feature in\n@@ -2916,7 +2920,7 @@ absl::Status ParseSequenceRaggedFeatures(\n       const auto& inner_splits = sequence_result->ragged_splits[t];\n       int num_inner_splits =\n           int32_inner_splits\n-              ? int32_inner_splits - inner_splits.vec<int32>().data()\n+              ? int32_inner_splits - inner_splits.vec<int32_t>().data()\n               : int64_inner_splits - inner_splits.vec<int64_t>().data();\n       if (num_inner_splits != expected_num_rows + 1) {\n         return errors::InvalidArgument(\"Unexpected number of rows for feature \",\n@@ -2927,7 +2931,7 @@ absl::Status ParseSequenceRaggedFeatures(\n       const auto& outer_splits = sequence_result->ragged_outer_splits[t];\n       int num_outer_splits =\n           int32_outer_splits\n-              ? int32_outer_splits - outer_splits.vec<int32>().data()\n+              ? int32_outer_splits - outer_splits.vec<int32_t>().data()\n               : int64_outer_splits - outer_splits.vec<int64_t>().data();\n       if (num_outer_splits != num_examples + 1) {\n         return errors::InvalidArgument("
        },
        {
            "sha": "583a4238737807a0e6b3ad627a1858c06ab80336",
            "filename": "tensorflow/core/util/example_proto_fast_parsing.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -164,7 +164,7 @@ absl::Status FastParseSequenceExample(\n // It uses the same specialized parser as FastParseExample which is efficient.\n // But then constructs Example which is relatively slow.\n // It is exported here as a convenient API to test parser part separately.\n-bool TestFastParse(const string& serialized, Example* example);\n+bool TestFastParse(const std::string& serialized, Example* example);\n \n }  // namespace example\n }  // namespace tensorflow"
        },
        {
            "sha": "2df2732e1bc7056d2a1d0241c6301560a7a721aa",
            "filename": "tensorflow/core/util/example_proto_fast_parsing_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexample_proto_fast_parsing_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -41,8 +41,8 @@ constexpr char kSparseInt64Key[] = \"sparse_int64\";\n constexpr char kSparseFloatKey[] = \"sparse_float\";\n constexpr char kSparseStringKey[] = \"sparse_string\";\n \n-string SerializedToReadable(string serialized) {\n-  string result;\n+std::string SerializedToReadable(std::string serialized) {\n+  std::string result;\n   result += '\"';\n   for (char c : serialized)\n     absl::StrAppend(&result, \"\\\\x\", absl::Hex(c, absl::kZeroPad2));\n@@ -51,15 +51,15 @@ string SerializedToReadable(string serialized) {\n }\n \n template <class T>\n-string Serialize(const T& example) {\n-  string serialized;\n+std::string Serialize(const T& example) {\n+  std::string serialized;\n   example.SerializeToString(&serialized);\n   return serialized;\n }\n \n // Tests that serialized gets parsed identically by TestFastParse(..)\n // and the regular Example.ParseFromString(..).\n-void TestCorrectness(const string& serialized) {\n+void TestCorrectness(const std::string& serialized) {\n   Example example;\n   Example fast_example;\n   EXPECT_TRUE(example.ParseFromString(serialized));\n@@ -150,7 +150,7 @@ TEST(FastParse, DenseInt64WithContext) {\n       .mutable_int64_list()\n       ->add_value(15);\n \n-  string serialized = Serialize(example) + Serialize(context);\n+  std::string serialized = Serialize(example) + Serialize(context);\n \n   {\n     Example deserialized;\n@@ -183,10 +183,10 @@ TEST(FastParse, EmptyFeatures) {\n   TestCorrectness(Serialize(example));\n }\n \n-void TestCorrectnessJson(const string& json) {\n+void TestCorrectnessJson(const std::string& json) {\n   auto resolver = protobuf::util::NewTypeResolverForDescriptorPool(\n       \"type.googleapis.com\", protobuf::DescriptorPool::generated_pool());\n-  string serialized;\n+  std::string serialized;\n   auto s = protobuf::util::JsonToBinaryString(\n       resolver, \"type.googleapis.com/tensorflow.Example\", json, &serialized);\n   EXPECT_TRUE(s.ok()) << s;\n@@ -220,7 +220,7 @@ TEST(FastParse, SingleInt64) {\n   TestCorrectness(Serialize(example));\n }\n \n-static string ExampleWithSomeFeatures() {\n+static std::string ExampleWithSomeFeatures() {\n   Example example;\n \n   (*example.mutable_features()->mutable_feature())[\"\"];\n@@ -328,13 +328,13 @@ TEST(FastParse, StatsCollection) {\n   }\n }\n \n-string RandStr(random::SimplePhilox* rng) {\n+std::string RandStr(random::SimplePhilox* rng) {\n   static const char key_char_lookup[] =\n       \"0123456789{}~`!@#$%^&*()\"\n       \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n       \"abcdefghijklmnopqrstuvwxyz\";\n   auto len = 1 + rng->Rand32() % 200;\n-  string str;\n+  std::string str;\n   str.reserve(len);\n   while (len-- > 0) {\n     str.push_back(\n@@ -347,18 +347,18 @@ string RandStr(random::SimplePhilox* rng) {\n void Fuzz(random::SimplePhilox* rng) {\n   // Generate keys.\n   auto num_keys = 1 + rng->Rand32() % 100;\n-  std::unordered_set<string> unique_keys;\n+  std::unordered_set<std::string> unique_keys;\n   for (auto i = 0; i < num_keys; ++i) {\n     unique_keys.emplace(RandStr(rng));\n   }\n \n   // Generate serialized example.\n   Example example;\n-  string serialized_example;\n+  std::string serialized_example;\n   auto num_concats = 1 + rng->Rand32() % 4;\n   std::vector<Feature::KindCase> feat_types(\n       {Feature::kBytesList, Feature::kFloatList, Feature::kInt64List});\n-  std::vector<string> all_keys(unique_keys.begin(), unique_keys.end());\n+  std::vector<std::string> all_keys(unique_keys.begin(), unique_keys.end());\n   while (num_concats--) {\n     example.Clear();\n     auto num_active_keys = 1 + rng->Rand32() % all_keys.size();\n@@ -410,7 +410,7 @@ void Fuzz(random::SimplePhilox* rng) {\n }\n \n TEST(FastParse, FuzzTest) {\n-  const uint64 seed = 1337;\n+  const uint64_t seed = 1337;\n   random::PhiloxRandom philox(seed);\n   random::SimplePhilox rng(&philox);\n   auto num_runs = 200;"
        },
        {
            "sha": "e4bf04377822b3cb54ae1293f891e362d7c55c1a",
            "filename": "tensorflow/core/util/example_proto_helper.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 13,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -63,10 +63,10 @@ absl::Status CheckTypesMatch(const Feature& feature, const DataType& dtype,\n   return absl::OkStatus();\n }\n \n-absl::Status FeatureDenseCopy(const std::size_t out_index, const string& name,\n-                              const string& key, const DataType& dtype,\n-                              const TensorShape& shape, const Feature& feature,\n-                              Tensor* out) {\n+absl::Status FeatureDenseCopy(const std::size_t out_index,\n+                              const std::string& name, const std::string& key,\n+                              const DataType& dtype, const TensorShape& shape,\n+                              const Feature& feature, Tensor* out) {\n   const std::size_t num_elements = shape.num_elements();\n   const std::size_t offset = out_index * num_elements;\n \n@@ -109,7 +109,7 @@ absl::Status FeatureDenseCopy(const std::size_t out_index, const string& name,\n       auto out_p = out->flat<tstring>().data() + offset;\n       std::transform(values.value().data(),\n                      values.value().data() + num_elements, out_p,\n-                     [](const string* s) { return *s; });\n+                     [](const std::string* s) { return *s; });\n       return absl::OkStatus();\n     }\n     default:\n@@ -118,7 +118,7 @@ absl::Status FeatureDenseCopy(const std::size_t out_index, const string& name,\n   }\n }\n \n-Tensor FeatureSparseCopy(const std::size_t batch, const string& key,\n+Tensor FeatureSparseCopy(const std::size_t batch, const std::string& key,\n                          const DataType& dtype, const Feature& feature) {\n   switch (dtype) {\n     case DT_INT64: {\n@@ -144,7 +144,7 @@ Tensor FeatureSparseCopy(const std::size_t batch, const string& key,\n       auto out_p = out.flat<tstring>().data();\n       std::transform(values.value().data(),\n                      values.value().data() + num_elements, out_p,\n-                     [](const string* s) { return *s; });\n+                     [](const std::string* s) { return *s; });\n       return out;\n     }\n     default:\n@@ -221,7 +221,8 @@ void RowDenseCopy(const std::size_t& out_index, const DataType& dtype,\n }\n \n absl::Status SingleExampleProtoToTensors(\n-    const Example& example, const string& example_name, const int batch_index,\n+    const Example& example, const std::string& example_name,\n+    const int batch_index,\n     const std::vector<FixedLenFeature>& fixed_len_features,\n     const std::vector<VarLenFeature>& var_len_features,\n     std::vector<Tensor*>* output_dense_values_tensor,\n@@ -232,7 +233,7 @@ absl::Status SingleExampleProtoToTensors(\n   // Handle dense features.\n   for (size_t d = 0; d < fixed_len_features.size(); ++d) {\n     const FixedLenFeature& feature_config = fixed_len_features[d];\n-    const string& key = feature_config.key;\n+    const std::string& key = feature_config.key;\n     const DataType& dtype = feature_config.dtype;\n     const TensorShape& shape = feature_config.shape;\n     const Tensor& default_value = feature_config.default_value;\n@@ -274,7 +275,7 @@ absl::Status SingleExampleProtoToTensors(\n   // Handle sparse features.\n   for (size_t d = 0; d < var_len_features.size(); ++d) {\n     const VarLenFeature& feature_config = var_len_features[d];\n-    const string& key = feature_config.key;\n+    const std::string& key = feature_config.key;\n     const DataType& dtype = feature_config.dtype;\n     const auto& feature_found = feature_dict.find(key);\n \n@@ -324,7 +325,7 @@ absl::Status GetSparseTensorShapes(const VarLenFeature& var_len_feature,\n \n absl::Status BatchExampleProtoToTensors(\n     const std::vector<const Example*>& examples,\n-    const std::vector<string>& names,\n+    const std::vector<std::string>& names,\n     const std::vector<FixedLenFeature>& fixed_len_features,\n     const std::vector<VarLenFeature>& var_len_features, Allocator* allocator,\n     std::vector<Tensor>* output_dense_values_tensor,\n@@ -368,7 +369,7 @@ absl::Status BatchExampleProtoToTensors(\n \n   for (size_t b = 0; b < examples.size(); ++b) {\n     const Example& ex = *(examples[b]);\n-    const string& example_name = (has_names) ? names[b] : \"<unknown>\";\n+    const std::string& example_name = (has_names) ? names[b] : \"<unknown>\";\n     TF_RETURN_IF_ERROR(SingleExampleProtoToTensors(\n         ex, example_name, b, fixed_len_features, var_len_features,\n         &output_dense_values_tensor_ptrs, &sparse_values_tmp));\n@@ -455,7 +456,7 @@ absl::Status ParseExampleAttrs::FinishInit(int op_version) {\n     return errors::InvalidArgument(\n         \"len(ragged_keys) != len(ragged_split_types)\");\n   }\n-  if (num_dense > std::numeric_limits<int32>::max()) {\n+  if (num_dense > std::numeric_limits<int32_t>::max()) {\n     return errors::InvalidArgument(\"num_dense_ too large\");\n   }\n   for (const DataType& type : dense_types) {"
        },
        {
            "sha": "2b2dda892523a8a25e0b2e9533f3e4ef35799289",
            "filename": "tensorflow/core/util/example_proto_helper.h",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexample_proto_helper.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -40,20 +40,20 @@ namespace tensorflow {\n \n // \"Dense\" feature configuration.\n struct FixedLenFeature {\n-  string key;\n+  std::string key;\n   DataType dtype;\n   TensorShape shape;\n   Tensor default_value;\n-  string values_output_tensor_name;\n+  std::string values_output_tensor_name;\n };\n \n // \"Sparse\" feature configuration.\n struct VarLenFeature {\n-  string key;\n+  std::string key;\n   DataType dtype;\n-  string values_output_tensor_name;\n-  string indices_output_tensor_name;\n-  string shapes_output_tensor_name;\n+  std::string values_output_tensor_name;\n+  std::string indices_output_tensor_name;\n+  std::string shapes_output_tensor_name;\n };\n \n // Given a single tensorflow::Example, with an optional example name\n@@ -77,7 +77,7 @@ struct VarLenFeature {\n // CopyIntoSparseTensor can be used to copy from the temporary vector\n // into the final allocated tensors.\n absl::Status SingleExampleProtoToTensors(\n-    const Example& example, const string& name, int batch_index,\n+    const Example& example, const std::string& name, int batch_index,\n     const std::vector<FixedLenFeature>& fixed_len_features,\n     const std::vector<VarLenFeature>& var_len_features,\n     std::vector<Tensor*>* output_dense_values_tensor,\n@@ -111,7 +111,7 @@ absl::Status GetSparseTensorShapes(const VarLenFeature& var_len_feature,\n // allocated using a provided Allocator within this method.\n absl::Status BatchExampleProtoToTensors(\n     const std::vector<const Example*>& examples,\n-    const std::vector<string>& names,\n+    const std::vector<std::string>& names,\n     const std::vector<FixedLenFeature>& fixed_len_features,\n     const std::vector<VarLenFeature>& var_len_features, Allocator* allocator,\n     std::vector<Tensor>* output_dense_values_tensor,\n@@ -130,8 +130,8 @@ absl::Status CheckTypesMatch(const Feature& feature, const DataType& dtype,\n \n // For a single Example, copy a dense feature value into an output\n // dense value tensor Out at the provided out_index offset.\n-absl::Status FeatureDenseCopy(std::size_t out_index, const string& name,\n-                              const string& key, const DataType& dtype,\n+absl::Status FeatureDenseCopy(std::size_t out_index, const std::string& name,\n+                              const std::string& key, const DataType& dtype,\n                               const TensorShape& shape, const Feature& feature,\n                               Tensor* out);\n \n@@ -142,7 +142,7 @@ void RowDenseCopy(const std::size_t& out_index, const DataType& dtype,\n \n // For a single Example, and given sparse feature return a temporary output\n // Tensor suitable for being collected in the temporary sparse value vector.\n-Tensor FeatureSparseCopy(std::size_t batch, const string& key,\n+Tensor FeatureSparseCopy(std::size_t batch, const std::string& key,\n                          const DataType& dtype, const Feature& feature);\n \n // Copy a temporary Tensor into the final sparse indices and values\n@@ -251,10 +251,10 @@ struct ParseSequenceExampleAttrs {\n   absl::Status Init(ContextType* ctx, int op_version = 1) {\n     switch (op_version) {\n       case 1: {\n-        std::vector<string> missing_empty_vector;\n+        std::vector<std::string> missing_empty_vector;\n         TF_RETURN_IF_ERROR(ctx->GetAttr(\n             \"feature_list_dense_missing_assumed_empty\", &missing_empty_vector));\n-        for (const string& feature : missing_empty_vector) {\n+        for (const std::string& feature : missing_empty_vector) {\n           feature_list_dense_missing_assumed_empty.insert(feature);\n         }\n       }\n@@ -300,7 +300,7 @@ struct ParseSequenceExampleAttrs {\n     return FinishInit(op_version);\n   }\n \n-  std::unordered_set<string> feature_list_dense_missing_assumed_empty;\n+  std::unordered_set<std::string> feature_list_dense_missing_assumed_empty;\n   int64_t num_context_sparse;\n   int64_t num_context_dense;\n   int64_t num_context_ragged;"
        },
        {
            "sha": "6ee738641a11f5d4474c7cf2d591e25dd4251d15",
            "filename": "tensorflow/core/util/exec_on_stall.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexec_on_stall.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fexec_on_stall.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fexec_on_stall.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -82,7 +82,7 @@ class ExecuteOnStall {\n   Env* env_;\n   std::function<void()> f_;\n   int64_t deadline_;\n-  int32 poll_microseconds_;\n+  int32_t poll_microseconds_;\n };\n \n }  // namespace tensorflow"
        },
        {
            "sha": "81b8254559548a8989314a62f98d03612ef1a472",
            "filename": "tensorflow/core/util/fake_clock_env.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Ffake_clock_env.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Ffake_clock_env.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Ffake_clock_env.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -28,7 +28,7 @@ void FakeClockEnv::AdvanceByMicroseconds(int64_t micros) {\n   }\n }\n \n-uint64 FakeClockEnv::NowMicros() const {\n+uint64_t FakeClockEnv::NowMicros() const {\n   {\n     mutex_lock l(mu_);\n     return current_time_;"
        },
        {
            "sha": "7d1e9305dd5b9262d9e1df7fb5496a4c337cf147",
            "filename": "tensorflow/core/util/fake_clock_env.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Ffake_clock_env.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Ffake_clock_env.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Ffake_clock_env.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -43,11 +43,11 @@ class FakeClockEnv : public EnvWrapper {\n   void AdvanceByMicroseconds(int64_t micros);\n \n   // Returns the current time of FakeClockEnv in microseconds.\n-  uint64 NowMicros() const override;\n+  uint64_t NowMicros() const override;\n \n  private:\n   mutable mutex mu_;\n-  uint64 current_time_ TF_GUARDED_BY(mu_) = 0;\n+  uint64_t current_time_ TF_GUARDED_BY(mu_) = 0;\n \n   FakeClockEnv(const FakeClockEnv&) = delete;\n   void operator=(const FakeClockEnv&) = delete;"
        },
        {
            "sha": "63691f0b3c05b2972b628d83c0ef2791140295cb",
            "filename": "tensorflow/core/util/image_resizer_state.h",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fimage_resizer_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fimage_resizer_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fimage_resizer_state.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -100,12 +100,12 @@ struct ImageResizerState {\n     OP_REQUIRES(\n         context,\n         FastBoundsCheck(input_shape.dim_size(1),\n-                        std::numeric_limits<int32>::max()) &&\n+                        std::numeric_limits<int32_t>::max()) &&\n             FastBoundsCheck(input_shape.dim_size(2),\n-                            std::numeric_limits<int32>::max()),\n+                            std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\"input sizes must be between 0 and max int32\"));\n-    in_height = static_cast<int32>(input_shape.dim_size(1));\n-    in_width = static_cast<int32>(input_shape.dim_size(2));\n+    in_height = static_cast<int32_t>(input_shape.dim_size(1));\n+    in_width = static_cast<int32_t>(input_shape.dim_size(2));\n \n     // Verify the output tensor's shape.\n     const Tensor& shape_t = context->input(1);\n@@ -117,7 +117,7 @@ struct ImageResizerState {\n                                         shape_t.shape().DebugString()));\n \n     // Verify and assign `out_height` and `out_width`.\n-    auto Svec = shape_t.vec<int32>();\n+    auto Svec = shape_t.vec<int32_t>();\n     out_height = internal::SubtleMustCopy(Svec(0));\n     out_width = internal::SubtleMustCopy(Svec(1));\n     OP_REQUIRES(context, out_height > 0 && out_width > 0,\n@@ -222,8 +222,9 @@ struct ImageResizerGradientState {\n \n     OP_REQUIRES(\n         context,\n-        FastBoundsCheck(original_height, std::numeric_limits<int32>::max()) &&\n-            FastBoundsCheck(original_width, std::numeric_limits<int32>::max()),\n+        FastBoundsCheck(original_height, std::numeric_limits<int32_t>::max()) &&\n+            FastBoundsCheck(original_width,\n+                            std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\n             \"original sizes must be between 0 and max int32\"));\n "
        },
        {
            "sha": "1f9762e1fdbbb0049b41f6c79dfa964b563f2a78",
            "filename": "tensorflow/core/util/matmul_bcast_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmatmul_bcast_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmatmul_bcast_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmatmul_bcast_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -22,11 +22,11 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-string MatMulBCastToStr(const MatMulBCast& b) {\n+std::string MatMulBCastToStr(const MatMulBCast& b) {\n   if (!b.IsValid()) {\n     return \"invalid\";\n   }\n-  string ret;\n+  std::string ret;\n   absl::StrAppend(&ret, \"[\",\n                   absl::StrJoin(b.output_batch_shape().dim_sizes(), \",\"), \"]\");\n   absl::StrAppend(&ret, \"[\", absl::StrJoin(b.x_batch_indices(), \",\"), \"]\");"
        },
        {
            "sha": "34b512435e73ed567e795cba840adfb338ae737d",
            "filename": "tensorflow/core/util/memmapped_file_system.cc",
            "status": "modified",
            "additions": 49,
            "deletions": 47,
            "changes": 96,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -28,10 +28,10 @@ namespace tensorflow {\n \n namespace {\n \n-uint64 DecodeUint64LittleEndian(const uint8* buffer) {\n-  uint64 result = 0;\n-  for (int i = 0; i < static_cast<int>(sizeof(uint64)); ++i) {\n-    result |= static_cast<uint64>(buffer[i]) << (8 * i);\n+uint64_t DecodeUint64LittleEndian(const uint8_t* buffer) {\n+  uint64_t result = 0;\n+  for (int i = 0; i < static_cast<int>(sizeof(uint64_t)); ++i) {\n+    result |= static_cast<uint64_t>(buffer[i]) << (8 * i);\n   }\n   return result;\n }\n@@ -42,21 +42,21 @@ namespace {\n \n class ReadOnlyMemoryRegionFromMemmapped : public ReadOnlyMemoryRegion {\n  public:\n-  ReadOnlyMemoryRegionFromMemmapped(const void* data, uint64 length)\n+  ReadOnlyMemoryRegionFromMemmapped(const void* data, uint64_t length)\n       : data_(data), length_(length) {}\n   ~ReadOnlyMemoryRegionFromMemmapped() override = default;\n   const void* data() override { return data_; }\n-  uint64 length() override { return length_; }\n+  uint64_t length() override { return length_; }\n \n  private:\n   const void* const data_;\n-  const uint64 length_;\n+  const uint64_t length_;\n   // intentionally copyable\n };\n \n class RandomAccessFileFromMemmapped : public RandomAccessFile {\n  public:\n-  RandomAccessFileFromMemmapped(const void* data, uint64 length)\n+  RandomAccessFileFromMemmapped(const void* data, uint64_t length)\n       : data_(data), length_(length) {}\n \n   ~RandomAccessFileFromMemmapped() override = default;\n@@ -66,14 +66,14 @@ class RandomAccessFileFromMemmapped : public RandomAccessFile {\n         \"RandomAccessFileFromMemmapped does not support Name()\");\n   }\n \n-  absl::Status Read(uint64 offset, size_t to_read, absl::string_view* result,\n+  absl::Status Read(uint64_t offset, size_t to_read, absl::string_view* result,\n                     char* scratch) const override {\n     if (offset >= length_) {\n       *result = absl::string_view(scratch, 0);\n       return absl::Status(absl::StatusCode::kOutOfRange, \"Read after file end\");\n     }\n-    const uint64 region_left =\n-        std::min(length_ - offset, static_cast<uint64>(to_read));\n+    const uint64_t region_left =\n+        std::min(length_ - offset, static_cast<uint64_t>(to_read));\n     *result = absl::string_view(reinterpret_cast<const char*>(data_) + offset,\n                                 region_left);\n     return (region_left == to_read)\n@@ -84,15 +84,15 @@ class RandomAccessFileFromMemmapped : public RandomAccessFile {\n \n  private:\n   const void* const data_;\n-  const uint64 length_;\n+  const uint64_t length_;\n   // intentionally copyable\n };\n \n }  // namespace\n \n MemmappedFileSystem::MemmappedFileSystem() = default;\n \n-absl::Status MemmappedFileSystem::FileExists(const string& fname,\n+absl::Status MemmappedFileSystem::FileExists(const std::string& fname,\n                                              TransactionToken* token) {\n   if (!mapped_memory_) {\n     return errors::FailedPrecondition(\"MemmappedEnv is not initialized\");\n@@ -105,7 +105,7 @@ absl::Status MemmappedFileSystem::FileExists(const string& fname,\n }\n \n absl::Status MemmappedFileSystem::NewRandomAccessFile(\n-    const string& filename, TransactionToken* token,\n+    const std::string& filename, TransactionToken* token,\n     std::unique_ptr<RandomAccessFile>* result) {\n   if (!mapped_memory_) {\n     return errors::FailedPrecondition(\"MemmappedEnv is not initialized\");\n@@ -121,7 +121,7 @@ absl::Status MemmappedFileSystem::NewRandomAccessFile(\n }\n \n absl::Status MemmappedFileSystem::NewReadOnlyMemoryRegionFromFile(\n-    const string& filename, TransactionToken* token,\n+    const std::string& filename, TransactionToken* token,\n     std::unique_ptr<ReadOnlyMemoryRegion>* result) {\n   if (!mapped_memory_) {\n     return errors::FailedPrecondition(\"MemmappedEnv is not initialized\");\n@@ -136,9 +136,9 @@ absl::Status MemmappedFileSystem::NewReadOnlyMemoryRegionFromFile(\n   return absl::OkStatus();\n }\n \n-absl::Status MemmappedFileSystem::GetFileSize(const string& filename,\n+absl::Status MemmappedFileSystem::GetFileSize(const std::string& filename,\n                                               TransactionToken* token,\n-                                              uint64* size) {\n+                                              uint64_t* size) {\n   if (!mapped_memory_) {\n     return errors::FailedPrecondition(\"MemmappedEnv is not initialized\");\n   }\n@@ -150,10 +150,10 @@ absl::Status MemmappedFileSystem::GetFileSize(const string& filename,\n   return absl::OkStatus();\n }\n \n-absl::Status MemmappedFileSystem::Stat(const string& fname,\n+absl::Status MemmappedFileSystem::Stat(const std::string& fname,\n                                        TransactionToken* token,\n                                        FileStatistics* stat) {\n-  uint64 size;\n+  uint64_t size;\n   auto status = GetFileSize(fname, token, &size);\n   if (status.ok()) {\n     stat->length = size;\n@@ -162,85 +162,85 @@ absl::Status MemmappedFileSystem::Stat(const string& fname,\n }\n \n absl::Status MemmappedFileSystem::NewWritableFile(\n-    const string& filename, TransactionToken* token,\n+    const std::string& filename, TransactionToken* token,\n     std::unique_ptr<WritableFile>* wf) {\n   return errors::Unimplemented(\"memmapped format doesn't support writing\");\n }\n \n absl::Status MemmappedFileSystem::NewAppendableFile(\n-    const string& filename, TransactionToken* token,\n+    const std::string& filename, TransactionToken* token,\n     std::unique_ptr<WritableFile>* result) {\n   return errors::Unimplemented(\"memmapped format doesn't support writing\");\n }\n \n-absl::Status MemmappedFileSystem::GetChildren(const string& filename,\n-                                              TransactionToken* token,\n-                                              std::vector<string>* strings) {\n+absl::Status MemmappedFileSystem::GetChildren(\n+    const std::string& filename, TransactionToken* token,\n+    std::vector<std::string>* strings) {\n   return errors::Unimplemented(\"memmapped format doesn't support GetChildren\");\n }\n \n absl::Status MemmappedFileSystem::GetMatchingPaths(\n-    const string& pattern, TransactionToken* token,\n-    std::vector<string>* results) {\n+    const std::string& pattern, TransactionToken* token,\n+    std::vector<std::string>* results) {\n   return errors::Unimplemented(\n       \"memmapped format doesn't support GetMatchingPaths\");\n }\n \n-absl::Status MemmappedFileSystem::DeleteFile(const string& filename,\n+absl::Status MemmappedFileSystem::DeleteFile(const std::string& filename,\n                                              TransactionToken* token) {\n   return errors::Unimplemented(\"memmapped format doesn't support DeleteFile\");\n }\n \n-absl::Status MemmappedFileSystem::CreateDir(const string& dirname,\n+absl::Status MemmappedFileSystem::CreateDir(const std::string& dirname,\n                                             TransactionToken* token) {\n   return errors::Unimplemented(\"memmapped format doesn't support CreateDir\");\n }\n \n-absl::Status MemmappedFileSystem::DeleteDir(const string& dirname,\n+absl::Status MemmappedFileSystem::DeleteDir(const std::string& dirname,\n                                             TransactionToken* token) {\n   return errors::Unimplemented(\"memmapped format doesn't support DeleteDir\");\n }\n \n-absl::Status MemmappedFileSystem::RenameFile(const string& filename_from,\n-                                             const string& filename_to,\n+absl::Status MemmappedFileSystem::RenameFile(const std::string& filename_from,\n+                                             const std::string& filename_to,\n                                              TransactionToken* token) {\n   return errors::Unimplemented(\"memmapped format doesn't support RenameFile\");\n }\n \n-const void* MemmappedFileSystem::GetMemoryWithOffset(uint64 offset) const {\n-  return reinterpret_cast<const uint8*>(mapped_memory_->data()) + offset;\n+const void* MemmappedFileSystem::GetMemoryWithOffset(uint64_t offset) const {\n+  return reinterpret_cast<const uint8_t*>(mapped_memory_->data()) + offset;\n }\n \n constexpr const char MemmappedFileSystem::kMemmappedPackagePrefix[];\n constexpr const char MemmappedFileSystem::kMemmappedPackageDefaultGraphDef[];\n \n-absl::Status MemmappedFileSystem::InitializeFromFile(Env* env,\n-                                                     const string& filename) {\n+absl::Status MemmappedFileSystem::InitializeFromFile(\n+    Env* env, const std::string& filename) {\n   TF_RETURN_IF_ERROR(\n       env->NewReadOnlyMemoryRegionFromFile(filename, &mapped_memory_));\n   directory_.clear();\n-  if (mapped_memory_->length() <= sizeof(uint64)) {\n+  if (mapped_memory_->length() <= sizeof(uint64_t)) {\n     return errors::DataLoss(\"Corrupted memmapped model file: \", filename,\n                             \" Invalid package size\");\n   }\n   const auto memory_start =\n-      reinterpret_cast<const uint8*>(mapped_memory_->data());\n-  const uint64 directory_offset = DecodeUint64LittleEndian(\n-      memory_start + mapped_memory_->length() - sizeof(uint64));\n-  if (directory_offset > mapped_memory_->length() - sizeof(uint64)) {\n+      reinterpret_cast<const uint8_t*>(mapped_memory_->data());\n+  const uint64_t directory_offset = DecodeUint64LittleEndian(\n+      memory_start + mapped_memory_->length() - sizeof(uint64_t));\n+  if (directory_offset > mapped_memory_->length() - sizeof(uint64_t)) {\n     return errors::DataLoss(\"Corrupted memmapped model file: \", filename,\n                             \" Invalid directory offset\");\n   }\n   MemmappedFileSystemDirectory proto_directory;\n   if (!ParseProtoUnlimited(\n           &proto_directory, memory_start + directory_offset,\n-          mapped_memory_->length() - directory_offset - sizeof(uint64))) {\n+          mapped_memory_->length() - directory_offset - sizeof(uint64_t))) {\n     return errors::DataLoss(\"Corrupted memmapped model file: \", filename,\n                             \" Can't parse its internal directory\");\n   }\n \n   // Iterating in reverse order to get lengths of elements;\n-  uint64 prev_element_offset = directory_offset;\n+  uint64_t prev_element_offset = directory_offset;\n   for (auto element_iter = proto_directory.element().rbegin();\n        element_iter != proto_directory.element().rend(); ++element_iter) {\n     // Check that the element offset is in the right range.\n@@ -262,7 +262,8 @@ absl::Status MemmappedFileSystem::InitializeFromFile(Env* env,\n   return absl::OkStatus();\n }\n \n-bool MemmappedFileSystem::IsMemmappedPackageFilename(const string& filename) {\n+bool MemmappedFileSystem::IsMemmappedPackageFilename(\n+    const std::string& filename) {\n   return absl::StartsWith(filename, kMemmappedPackagePrefix);\n }\n \n@@ -274,7 +275,7 @@ bool IsValidRegionChar(char c) {\n }  // namespace\n \n bool MemmappedFileSystem::IsWellFormedMemmappedPackageFilename(\n-    const string& filename) {\n+    const std::string& filename) {\n   if (!IsMemmappedPackageFilename(filename)) {\n     return false;\n   }\n@@ -290,7 +291,7 @@ bool MemmappedFileSystem::IsWellFormedMemmappedPackageFilename(\n \n MemmappedEnv::MemmappedEnv(Env* env) : EnvWrapper(env) {}\n \n-absl::Status MemmappedEnv::GetFileSystemForFile(const string& fname,\n+absl::Status MemmappedEnv::GetFileSystemForFile(const std::string& fname,\n                                                 FileSystem** result) {\n   if (MemmappedFileSystem::IsMemmappedPackageFilename(fname)) {\n     if (!memmapped_file_system_) {\n@@ -304,15 +305,16 @@ absl::Status MemmappedEnv::GetFileSystemForFile(const string& fname,\n }\n \n absl::Status MemmappedEnv::GetRegisteredFileSystemSchemes(\n-    std::vector<string>* schemes) {\n+    std::vector<std::string>* schemes) {\n   const auto status = EnvWrapper::GetRegisteredFileSystemSchemes(schemes);\n   if (status.ok()) {\n     schemes->emplace_back(MemmappedFileSystem::kMemmappedPackagePrefix);\n   }\n   return status;\n }\n \n-absl::Status MemmappedEnv::InitializeFromFile(const string& package_filename) {\n+absl::Status MemmappedEnv::InitializeFromFile(\n+    const std::string& package_filename) {\n   std::unique_ptr<MemmappedFileSystem> file_system_ptr(new MemmappedFileSystem);\n   const auto status =\n       file_system_ptr->InitializeFromFile(target(), package_filename);"
        },
        {
            "sha": "69f3b62949fd67f93855c0e1a6b460181769537a",
            "filename": "tensorflow/core/util/memmapped_file_system.h",
            "status": "modified",
            "additions": 32,
            "deletions": 27,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -64,58 +64,63 @@ class MemmappedFileSystem : public FileSystem {\n \n   TF_USE_FILESYSTEM_METHODS_WITH_NO_TRANSACTION_SUPPORT;\n \n-  absl::Status FileExists(const string& fname,\n+  absl::Status FileExists(const std::string& fname,\n                           TransactionToken* token) override;\n   absl::Status NewRandomAccessFile(\n-      const string& filename, TransactionToken* token,\n+      const std::string& filename, TransactionToken* token,\n       std::unique_ptr<RandomAccessFile>* result) override;\n   absl::Status NewReadOnlyMemoryRegionFromFile(\n-      const string& filename, TransactionToken* token,\n+      const std::string& filename, TransactionToken* token,\n       std::unique_ptr<ReadOnlyMemoryRegion>* result) override;\n \n   // All these functions return Unimplemented error, the memmapped storage is\n   // read only.\n-  absl::Status NewWritableFile(const string& fname, TransactionToken* token,\n+  absl::Status NewWritableFile(const std::string& fname,\n+                               TransactionToken* token,\n                                std::unique_ptr<WritableFile>* result) override;\n   absl::Status NewAppendableFile(\n-      const string& fname, TransactionToken* token,\n+      const std::string& fname, TransactionToken* token,\n       std::unique_ptr<WritableFile>* result) override;\n-  absl::Status GetChildren(const string& dir, TransactionToken* token,\n-                           std::vector<string>* r) override;\n-  absl::Status GetMatchingPaths(const string& pattern, TransactionToken* token,\n-                                std::vector<string>* results) override;\n-  absl::Status DeleteFile(const string& f, TransactionToken* token) override;\n-  absl::Status CreateDir(const string& d, TransactionToken* token) override;\n-  absl::Status DeleteDir(const string& d, TransactionToken* token) override;\n-  absl::Status RenameFile(const string& s, const string& t,\n+  absl::Status GetChildren(const std::string& dir, TransactionToken* token,\n+                           std::vector<std::string>* r) override;\n+  absl::Status GetMatchingPaths(const std::string& pattern,\n+                                TransactionToken* token,\n+                                std::vector<std::string>* results) override;\n+  absl::Status DeleteFile(const std::string& f,\n+                          TransactionToken* token) override;\n+  absl::Status CreateDir(const std::string& d,\n+                         TransactionToken* token) override;\n+  absl::Status DeleteDir(const std::string& d,\n+                         TransactionToken* token) override;\n+  absl::Status RenameFile(const std::string& s, const std::string& t,\n                           TransactionToken* token) override;\n \n   // These functions are implemented.\n-  absl::Status GetFileSize(const string& f, TransactionToken* token,\n-                           uint64* s) override;\n+  absl::Status GetFileSize(const std::string& f, TransactionToken* token,\n+                           uint64_t* s) override;\n   // Currently just returns size.\n-  absl::Status Stat(const string& fname, TransactionToken* token,\n+  absl::Status Stat(const std::string& fname, TransactionToken* token,\n                     FileStatistics* stat) override;\n \n   // Initializes filesystem from a file in memmapped format.\n-  absl::Status InitializeFromFile(Env* env, const string& filename);\n+  absl::Status InitializeFromFile(Env* env, const std::string& filename);\n \n   // Checks if the filename has a correct prefix.\n-  static bool IsMemmappedPackageFilename(const string& filename);\n+  static bool IsMemmappedPackageFilename(const std::string& filename);\n \n-  static bool IsWellFormedMemmappedPackageFilename(const string& filename);\n+  static bool IsWellFormedMemmappedPackageFilename(const std::string& filename);\n \n  private:\n   struct FileRegion {\n-    FileRegion(uint64 o, uint64 l) : offset(o), length(l) {}\n+    FileRegion(uint64_t o, uint64_t l) : offset(o), length(l) {}\n \n-    uint64 offset;  // Offset from the beginning of the file.\n-    uint64 length;  // Length of the region.\n+    uint64_t offset;  // Offset from the beginning of the file.\n+    uint64_t length;  // Length of the region.\n   };\n \n-  using DirectoryType = std::unordered_map<string, FileRegion>;\n+  using DirectoryType = std::unordered_map<std::string, FileRegion>;\n \n-  const void* GetMemoryWithOffset(uint64 offset) const;\n+  const void* GetMemoryWithOffset(uint64_t offset) const;\n \n   std::unique_ptr<ReadOnlyMemoryRegion> mapped_memory_;\n   DirectoryType directory_;\n@@ -128,11 +133,11 @@ class MemmappedEnv : public EnvWrapper {\n  public:\n   explicit MemmappedEnv(Env* env);\n   ~MemmappedEnv() override = default;\n-  absl::Status GetFileSystemForFile(const string& fname,\n+  absl::Status GetFileSystemForFile(const std::string& fname,\n                                     FileSystem** result) override;\n   absl::Status GetRegisteredFileSystemSchemes(\n-      std::vector<string>* schemes) override;\n-  absl::Status InitializeFromFile(const string& filename);\n+      std::vector<std::string>* schemes) override;\n+  absl::Status InitializeFromFile(const std::string& filename);\n \n  protected:\n   std::unique_ptr<MemmappedFileSystem> memmapped_file_system_;"
        },
        {
            "sha": "ea54a143771906a2fb5abf85026da5721aca976c",
            "filename": "tensorflow/core/util/memmapped_file_system_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -38,7 +38,7 @@ constexpr char kTensor2FileName[] = \"memmapped_package://t2\";\n constexpr char kProtoFileName[] = \"memmapped_package://b\";\n constexpr int kTestGraphDefVersion = 666;\n \n-absl::Status CreateMemmappedFileSystemFile(const string& filename,\n+absl::Status CreateMemmappedFileSystemFile(const std::string& filename,\n                                            bool corrupted,\n                                            Tensor* test_tensor) {\n   Env* env = Env::Default();\n@@ -72,8 +72,8 @@ absl::Status CreateMemmappedFileSystemFile(const string& filename,\n TEST(MemmappedFileSystemTest, SimpleTest) {\n   const TensorShape test_tensor_shape = {10, 200};\n   Tensor test_tensor(DT_FLOAT, test_tensor_shape);\n-  const string dir = testing::TmpDir();\n-  const string filename = io::JoinPath(dir, \"memmapped_env_test\");\n+  const std::string dir = testing::TmpDir();\n+  const std::string filename = io::JoinPath(dir, \"memmapped_env_test\");\n   TF_ASSERT_OK(CreateMemmappedFileSystemFile(filename, false, &test_tensor));\n \n   // Check that we can memmap the created file.\n@@ -96,7 +96,7 @@ TEST(MemmappedFileSystemTest, SimpleTest) {\n             absl::string_view(static_cast<const char*>(memory_region->data()),\n                               test_tensor.TotalBytes()));\n   // Check that GetFileSize works.\n-  uint64 file_size = 0;\n+  uint64_t file_size = 0;\n   TF_ASSERT_OK(memmapped_env.GetFileSize(kTensor2FileName, &file_size));\n   EXPECT_EQ(test_tensor.TotalBytes(), file_size);\n \n@@ -134,8 +134,9 @@ TEST(MemmappedFileSystemTest, Corrupted) {\n   // Create a corrupted file (it is not closed it properly).\n   const TensorShape test_tensor_shape = {100, 200};\n   Tensor test_tensor(DT_FLOAT, test_tensor_shape);\n-  const string dir = testing::TmpDir();\n-  const string filename = io::JoinPath(dir, \"memmapped_env_corrupted_test\");\n+  const std::string dir = testing::TmpDir();\n+  const std::string filename =\n+      io::JoinPath(dir, \"memmapped_env_corrupted_test\");\n   TF_ASSERT_OK(CreateMemmappedFileSystemFile(filename, true, &test_tensor));\n   MemmappedFileSystem memmapped_env;\n   ASSERT_NE(memmapped_env.InitializeFromFile(Env::Default(), filename),\n@@ -144,8 +145,8 @@ TEST(MemmappedFileSystemTest, Corrupted) {\n \n TEST(MemmappedFileSystemTest, ProxyToDefault) {\n   MemmappedEnv memmapped_env(Env::Default());\n-  const string dir = testing::TmpDir();\n-  const string filename = io::JoinPath(dir, \"test_file\");\n+  const std::string dir = testing::TmpDir();\n+  const std::string filename = io::JoinPath(dir, \"test_file\");\n   // Check that we can create write and read ordinary file.\n   std::unique_ptr<WritableFile> writable_file_temp;\n   TF_ASSERT_OK(memmapped_env.NewAppendableFile(filename, &writable_file_temp));\n@@ -156,10 +157,10 @@ TEST(MemmappedFileSystemTest, ProxyToDefault) {\n   };\n   std::unique_ptr<WritableFile, decltype(adh)> writable_file(\n       writable_file_temp.release(), adh);\n-  const string test_string = \"bla-bla-bla\";\n+  const std::string test_string = \"bla-bla-bla\";\n   TF_ASSERT_OK(writable_file->Append(test_string));\n   TF_ASSERT_OK(writable_file->Close());\n-  uint64 file_length = 0;\n+  uint64_t file_length = 0;\n   TF_EXPECT_OK(memmapped_env.GetFileSize(filename, &file_length));\n   EXPECT_EQ(test_string.length(), file_length);\n   FileStatistics stat;"
        },
        {
            "sha": "37a84f08c9b9681a7efaadd56a61f31e5103e238",
            "filename": "tensorflow/core/util/memmapped_file_system_writer.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -19,16 +19,16 @@ limitations under the License.\n namespace tensorflow {\n \n absl::Status MemmappedFileSystemWriter::InitializeToFile(\n-    Env* env, const string& filename) {\n+    Env* env, const std::string& filename) {\n   auto status = env->NewWritableFile(filename, &output_file_);\n   if (status.ok()) {\n     output_file_offset_ = 0;\n   }\n   return status;\n }\n \n-absl::Status MemmappedFileSystemWriter::SaveTensor(const Tensor& tensor,\n-                                                   const string& element_name) {\n+absl::Status MemmappedFileSystemWriter::SaveTensor(\n+    const Tensor& tensor, const std::string& element_name) {\n   if (!output_file_) {\n     return errors::FailedPrecondition(\n         \"MemmappedEnvWritter: saving tensor into not opened file\");\n@@ -56,7 +56,7 @@ absl::Status MemmappedFileSystemWriter::SaveTensor(const Tensor& tensor,\n }\n \n absl::Status MemmappedFileSystemWriter::SaveProtobuf(\n-    const protobuf::MessageLite& message, const string& element_name) {\n+    const protobuf::MessageLite& message, const std::string& element_name) {\n   if (!output_file_) {\n     return errors::FailedPrecondition(\n         \"MemmappedEnvWritter: saving protobuf into not opened file\");\n@@ -69,7 +69,7 @@ absl::Status MemmappedFileSystemWriter::SaveProtobuf(\n         MemmappedFileSystem::kMemmappedPackagePrefix,\n         \" and include [A-Za-z0-9_.]\");\n   }\n-  const string encoded = message.SerializeAsString();\n+  const std::string encoded = message.SerializeAsString();\n   AddToDirectoryElement(element_name, encoded.size());\n   const auto res = output_file_->Append(encoded);\n   if (res.ok()) {\n@@ -80,11 +80,11 @@ absl::Status MemmappedFileSystemWriter::SaveProtobuf(\n \n namespace {\n \n-absl::string_view EncodeUint64LittleEndian(uint64 val, char* output_buffer) {\n-  for (unsigned int i = 0; i < sizeof(uint64); ++i) {\n+absl::string_view EncodeUint64LittleEndian(uint64_t val, char* output_buffer) {\n+  for (unsigned int i = 0; i < sizeof(uint64_t); ++i) {\n     output_buffer[i] = (val >> i * 8);\n   }\n-  return {output_buffer, sizeof(uint64)};\n+  return {output_buffer, sizeof(uint64_t)};\n }\n \n }  // namespace\n@@ -94,11 +94,11 @@ absl::Status MemmappedFileSystemWriter::FlushAndClose() {\n     return errors::FailedPrecondition(\n         \"MemmappedEnvWritter: flushing into not opened file\");\n   }\n-  const string dir = directory_.SerializeAsString();\n+  const std::string dir = directory_.SerializeAsString();\n   TF_RETURN_IF_ERROR(output_file_->Append(dir));\n \n   // Write the directory offset.\n-  char buffer[sizeof(uint64)];\n+  char buffer[sizeof(uint64_t)];\n   TF_RETURN_IF_ERROR(output_file_->Append(\n       EncodeUint64LittleEndian(output_file_offset_, buffer)));\n \n@@ -109,13 +109,13 @@ absl::Status MemmappedFileSystemWriter::FlushAndClose() {\n   return absl::OkStatus();\n }\n \n-absl::Status MemmappedFileSystemWriter::AdjustAlignment(uint64 alignment) {\n-  const uint64 alignment_rest = output_file_offset_ % alignment;\n-  const uint64 to_write_for_alignment =\n+absl::Status MemmappedFileSystemWriter::AdjustAlignment(uint64_t alignment) {\n+  const uint64_t alignment_rest = output_file_offset_ % alignment;\n+  const uint64_t to_write_for_alignment =\n       (alignment_rest == 0) ? 0 : alignment - (output_file_offset_ % alignment);\n-  static constexpr uint64 kFillerBufferSize = 16;\n+  static constexpr uint64_t kFillerBufferSize = 16;\n   const char kFillerBuffer[kFillerBufferSize] = {};\n-  for (uint64 rest = to_write_for_alignment; rest > 0;) {\n+  for (uint64_t rest = to_write_for_alignment; rest > 0;) {\n     absl::string_view sp(kFillerBuffer, std::min(rest, kFillerBufferSize));\n     TF_RETURN_IF_ERROR(output_file_->Append(sp));\n     rest -= sp.size();\n@@ -124,8 +124,8 @@ absl::Status MemmappedFileSystemWriter::AdjustAlignment(uint64 alignment) {\n   return absl::OkStatus();\n }\n \n-void MemmappedFileSystemWriter::AddToDirectoryElement(const string& name,\n-                                                      uint64 length) {\n+void MemmappedFileSystemWriter::AddToDirectoryElement(const std::string& name,\n+                                                      uint64_t length) {\n   MemmappedFileSystemDirectoryElement* new_directory_element =\n       directory_.add_element();\n   new_directory_element->set_offset(output_file_offset_);"
        },
        {
            "sha": "0a61e648c58c3887b112af7dccdb21280304bcdb",
            "filename": "tensorflow/core/util/memmapped_file_system_writer.h",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmemmapped_file_system_writer.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -31,19 +31,20 @@ class MemmappedFileSystemWriter {\n  public:\n   MemmappedFileSystemWriter() = default;\n   ~MemmappedFileSystemWriter() = default;\n-  absl::Status InitializeToFile(Env* env, const string& filename);\n-  absl::Status SaveTensor(const Tensor& tensor, const string& element_name);\n+  absl::Status InitializeToFile(Env* env, const std::string& filename);\n+  absl::Status SaveTensor(const Tensor& tensor,\n+                          const std::string& element_name);\n   absl::Status SaveProtobuf(const protobuf::MessageLite& message,\n-                            const string& element_name);\n+                            const std::string& element_name);\n   // Writes out the directory of regions and closes the output file.\n   absl::Status FlushAndClose();\n \n  private:\n-  absl::Status AdjustAlignment(uint64 alignment);\n-  void AddToDirectoryElement(const string& element_name, uint64 length);\n+  absl::Status AdjustAlignment(uint64_t alignment);\n+  void AddToDirectoryElement(const std::string& element_name, uint64_t length);\n   MemmappedFileSystemDirectory directory_;\n   // The current offset in the file, to support alignment.\n-  uint64 output_file_offset_ = 0;\n+  uint64_t output_file_offset_ = 0;\n   std::unique_ptr<WritableFile> output_file_;\n   MemmappedFileSystemWriter(const MemmappedFileSystemWriter&) = delete;\n   void operator=(const MemmappedFileSystemWriter&) = delete;"
        },
        {
            "sha": "3b628d42eb2d84215949ab1ffbe425a6ffc17444",
            "filename": "tensorflow/core/util/mirror_pad_mode.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -24,7 +24,7 @@ namespace tensorflow {\n \n absl::Status GetNodeAttr(const NodeDef& node_def, absl::string_view attr_name,\n                          MirrorPadMode* value) {\n-  string str_value;\n+  std::string str_value;\n   TF_RETURN_IF_ERROR(GetNodeAttr(node_def, attr_name, &str_value));\n   if (str_value == \"REFLECT\") {\n     *value = MirrorPadMode::REFLECT;\n@@ -36,6 +36,8 @@ absl::Status GetNodeAttr(const NodeDef& node_def, absl::string_view attr_name,\n   return absl::OkStatus();\n }\n \n-string GetMirrorPadModeAttrString() { return \"mode: {'REFLECT', 'SYMMETRIC'}\"; }\n+std::string GetMirrorPadModeAttrString() {\n+  return \"mode: {'REFLECT', 'SYMMETRIC'}\";\n+}\n \n }  // end namespace tensorflow"
        },
        {
            "sha": "a90a2b131a8ab171bd84fc0b4e78e74f37c2317f",
            "filename": "tensorflow/core/util/mirror_pad_mode.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fmirror_pad_mode.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -39,7 +39,7 @@ enum class MirrorPadMode {\n \n // Return the string containing the list of valid padding modes, that can be\n // used as an Attr() in REGISTER_OP.\n-string GetMirrorPadModeAttrString();\n+std::string GetMirrorPadModeAttrString();\n \n // Forward declaration to avoid including core/framework/graph.proto.\n class NodeDef;"
        },
        {
            "sha": "eb37d294b5b5379b415e013b36e055eb60f077d2",
            "filename": "tensorflow/core/util/overflow.h",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Foverflow.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Foverflow.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Foverflow.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -32,9 +32,9 @@ inline int64_t MultiplyWithoutOverflow(int64_t x, int64_t y) {\n   // Multiply in uint64 rather than int64 since signed overflow is undefined.\n   // Negative values will wrap around to large unsigned values in the casts\n   // (see section 4.7 [conv.integral] of the C++14 standard).\n-  const uint64 ux = x;\n-  const uint64 uy = y;\n-  const uint64 uxy = ux * uy;\n+  const uint64_t ux = x;\n+  const uint64_t uy = y;\n+  const uint64_t uxy = ux * uy;\n \n   // Check if we overflow uint64, using a cheap check if both inputs are small\n   if (TF_PREDICT_FALSE((ux | uy) >> 32 != 0)) {\n@@ -54,9 +54,9 @@ inline int64_t AddWithoutOverflow(int64_t x, int64_t y) {\n   // Add in uint64 rather than int64 since signed overflow is undefined.\n   // Negative values will wrap around to large unsigned values in the casts\n   // (see section 4.7 [conv.integral] of the C++14 standard).\n-  const uint64 ux = x;\n-  const uint64 uy = y;\n-  const uint64 uxy = ux + uy;\n+  const uint64_t ux = x;\n+  const uint64_t uy = y;\n+  const uint64_t uxy = ux + uy;\n \n   // Cast back to signed. A negative value signals an overflow.\n   return static_cast<int64_t>(uxy);"
        },
        {
            "sha": "6ec5b99bfc38d4e0f577dce59549efaee6642132",
            "filename": "tensorflow/core/util/padding.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpadding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpadding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fpadding.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -69,13 +69,13 @@ absl::Status CheckValidPadding(Padding padding_type,\n   return absl::OkStatus();\n }\n \n-string GetPaddingAttrString() { return \"padding: {'SAME', 'VALID'}\"; }\n+std::string GetPaddingAttrString() { return \"padding: {'SAME', 'VALID'}\"; }\n \n-string GetPaddingAttrStringWithExplicit() {\n+std::string GetPaddingAttrStringWithExplicit() {\n   return \"padding: {'SAME', 'VALID', 'EXPLICIT'}\";\n }\n \n-string GetExplicitPaddingsAttrString() {\n+std::string GetExplicitPaddingsAttrString() {\n   return \"explicit_paddings: list(int) = []\";\n }\n "
        },
        {
            "sha": "594de0fbc954142242f3176d09a3ff2019dc4935",
            "filename": "tensorflow/core/util/presized_cuckoo_map.h",
            "status": "modified",
            "additions": 26,
            "deletions": 26,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map.h?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -50,15 +50,15 @@ template <class value>\n class PresizedCuckooMap {\n  public:\n   // The key type is fixed as a pre-hashed key for this specialized use.\n-  typedef uint64 key_type;\n+  typedef uint64_t key_type;\n \n-  explicit PresizedCuckooMap(uint64 num_entries) { Clear(num_entries); }\n+  explicit PresizedCuckooMap(uint64_t num_entries) { Clear(num_entries); }\n \n-  void Clear(uint64 num_entries) {\n+  void Clear(uint64_t num_entries) {\n     cpq_.reset(new CuckooPathQueue());\n     double n(num_entries);\n     n /= kLoadFactor;\n-    num_buckets_ = (static_cast<uint64>(n) / kSlotsPerBucket);\n+    num_buckets_ = (static_cast<uint64_t>(n) / kSlotsPerBucket);\n     // Very small cuckoo tables don't work, because the probability\n     // of having same-bucket hashes is large.  We compromise for those\n     // uses by having a larger static starting size.\n@@ -74,12 +74,12 @@ class PresizedCuckooMap {\n   // Returns false if k is already in table or if the table\n   // is full; true otherwise.\n   bool InsertUnique(const key_type k, const value& v) {\n-    uint64 tk = key_transform(k);\n-    uint64 b1 = fast_map_to_buckets(tk);\n-    uint64 b2 = fast_map_to_buckets(h2(tk));\n+    uint64_t tk = key_transform(k);\n+    uint64_t b1 = fast_map_to_buckets(tk);\n+    uint64_t b2 = fast_map_to_buckets(h2(tk));\n \n     // Merged find and duplicate checking.\n-    uint64 target_bucket = 0;\n+    uint64_t target_bucket = 0;\n     int target_slot = kNoSpace;\n \n     for (auto bucket : {b1, b2}) {\n@@ -104,14 +104,14 @@ class PresizedCuckooMap {\n \n   // Returns true if found.  Sets *out = value.\n   bool Find(const key_type k, value* out) const {\n-    uint64 tk = key_transform(k);\n+    uint64_t tk = key_transform(k);\n     return FindInBucket(k, fast_map_to_buckets(tk), out) ||\n            FindInBucket(k, fast_map_to_buckets(h2(tk)), out);\n   }\n \n   // Prefetch memory associated with the key k into cache.\n   void PrefetchKey(const key_type k) const {\n-    const uint64 tk = key_transform(k);\n+    const uint64_t tk = key_transform(k);\n     absl::PrefetchToLocalCache(&buckets_[fast_map_to_buckets(tk)].keys);\n     absl::PrefetchToLocalCache(&buckets_[fast_map_to_buckets(h2(tk))].keys);\n   }\n@@ -138,7 +138,7 @@ class PresizedCuckooMap {\n   // around the full point.  For (2,4) a max BFS path len of 5 results in ~682\n   // nodes to visit, calculated below, and is a good value.\n \n-  static constexpr uint8 kMaxBFSPathLen = 5;\n+  static constexpr uint8_t kMaxBFSPathLen = 5;\n \n   // Constants for BFS cuckoo path search:\n   // The visited list must be maintained for all but the last level of search\n@@ -151,7 +151,7 @@ class PresizedCuckooMap {\n   static constexpr int kVisitedListSize = 170;\n \n   static constexpr int kNoSpace = -1;  // SpaceAvailable return\n-  static constexpr uint64 kUnusedSlot = ~(0ULL);\n+  static constexpr uint64_t kUnusedSlot = ~(0ULL);\n \n   // Buckets are organized with key_types clustered for access speed\n   // and for compactness while remaining aligned.\n@@ -164,7 +164,7 @@ class PresizedCuckooMap {\n   // the number of cache lines dirtied during search.\n \n   struct CuckooPathEntry {\n-    uint64 bucket;\n+    uint64_t bucket;\n     int depth;\n     int parent;       // To index in the visited array.\n     int parent_slot;  // Which slot in our parent did we come from?  -1 == root.\n@@ -208,35 +208,35 @@ class PresizedCuckooMap {\n   // collisions, OR must ensure that their keys are always in\n   // the range 0 - (uint64max - 1).  This transforms 'not found flag'\n   // keys into something else.\n-  inline uint64 key_transform(const key_type k) const {\n+  inline uint64_t key_transform(const key_type k) const {\n     return k + (k == kUnusedSlot);\n   }\n \n   // h2 performs a very quick mix of h to generate the second bucket hash.\n   // Assumes there is plenty of remaining entropy in the initial h.\n-  inline uint64 h2(uint64 h) const {\n-    const uint64 m = 0xc6a4a7935bd1e995;\n+  inline uint64_t h2(uint64_t h) const {\n+    const uint64_t m = 0xc6a4a7935bd1e995;\n     return m * ((h >> 32) | (h << 32));\n   }\n \n   // alt_bucket identifies the \"other\" bucket for key k, where\n   // other is \"the one that isn't bucket b\"\n-  inline uint64 alt_bucket(key_type k, uint64 b) const {\n+  inline uint64_t alt_bucket(key_type k, uint64_t b) const {\n     if (fast_map_to_buckets(k) != b) {\n       return fast_map_to_buckets(k);\n     }\n     return fast_map_to_buckets(h2(k));\n   }\n \n-  inline void InsertInternal(key_type k, const value& v, uint64 b, int slot) {\n+  inline void InsertInternal(key_type k, const value& v, uint64_t b, int slot) {\n     Bucket* bptr = &buckets_[b];\n     bptr->keys[slot] = k;\n     bptr->values[slot] = v;\n   }\n \n   // For the associative cuckoo table, check all of the slots in\n   // the bucket to see if the key is present.\n-  bool FindInBucket(key_type k, uint64 b, value* out) const {\n+  bool FindInBucket(key_type k, uint64_t b, value* out) const {\n     const Bucket& bref = buckets_[b];\n     for (int i = 0; i < kSlotsPerBucket; i++) {\n       if (bref.keys[i] == k) {\n@@ -249,7 +249,7 @@ class PresizedCuckooMap {\n \n   //  returns either kNoSpace or the index of an\n   //  available slot (0 <= slot < kSlotsPerBucket)\n-  inline int SpaceAvailable(uint64 bucket) const {\n+  inline int SpaceAvailable(uint64_t bucket) const {\n     const Bucket& bref = buckets_[bucket];\n     for (int i = 0; i < kSlotsPerBucket; i++) {\n       if (bref.keys[i] == kUnusedSlot) {\n@@ -259,15 +259,15 @@ class PresizedCuckooMap {\n     return kNoSpace;\n   }\n \n-  inline void CopyItem(uint64 src_bucket, int src_slot, uint64 dst_bucket,\n+  inline void CopyItem(uint64_t src_bucket, int src_slot, uint64_t dst_bucket,\n                        int dst_slot) {\n     Bucket& src_ref = buckets_[src_bucket];\n     Bucket& dst_ref = buckets_[dst_bucket];\n     dst_ref.keys[dst_slot] = src_ref.keys[src_slot];\n     dst_ref.values[dst_slot] = src_ref.values[src_slot];\n   }\n \n-  bool CuckooInsert(key_type k, const value& v, uint64 b1, uint64 b2) {\n+  bool CuckooInsert(key_type k, const value& v, uint64_t b1, uint64_t b2) {\n     int visited_end = 0;\n     cpq_->reset();\n \n@@ -299,10 +299,10 @@ class PresizedCuckooMap {\n           const Bucket& bref = buckets_[e.bucket];\n           for (int i = 0; i < kSlotsPerBucket; i++) {\n             int slot = (start_slot + i) % kSlotsPerBucket;\n-            uint64 next_bucket = alt_bucket(bref.keys[slot], e.bucket);\n+            uint64_t next_bucket = alt_bucket(bref.keys[slot], e.bucket);\n             // Optimization:  Avoid single-step cycles (from e, don't\n             // add a child node that is actually e's parent).\n-            uint64 e_parent_bucket = visited_[e.parent].bucket;\n+            uint64_t e_parent_bucket = visited_[e.parent].bucket;\n             if (next_bucket != e_parent_bucket) {\n               cpq_->push_back({next_bucket, e.depth + 1, parent_index, slot});\n             }\n@@ -315,7 +315,7 @@ class PresizedCuckooMap {\n     return false;\n   }\n \n-  inline uint64 fast_map_to_buckets(uint64 x) const {\n+  inline uint64_t fast_map_to_buckets(uint64_t x) const {\n     // Map x (uniform in 2^64) to the range [0, num_buckets_ -1]\n     // using Lemire's alternative to modulo reduction:\n     // http://lemire.me/blog/2016/06/27/a-fast-alternative-to-the-modulo-reduction/\n@@ -324,7 +324,7 @@ class PresizedCuckooMap {\n   }\n \n   // Set upon initialization: num_entries / kLoadFactor / kSlotsPerBucket.\n-  uint64 num_buckets_;\n+  uint64_t num_buckets_;\n   std::vector<Bucket> buckets_;\n \n   std::unique_ptr<CuckooPathQueue> cpq_;"
        },
        {
            "sha": "ad46c36cd7d25805cf990b0f6bf74b3b8b26422f",
            "filename": "tensorflow/core/util/presized_cuckoo_map_test.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 32,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/62f00f3f0524f6d5a7da48c91f596cbb941e9276/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Futil%2Fpresized_cuckoo_map_test.cc?ref=62f00f3f0524f6d5a7da48c91f596cbb941e9276",
            "patch": "@@ -45,17 +45,17 @@ TEST(PresizedCuckooMapTest, Prefetch) {\n TEST(PresizedCuckooMapTest, TooManyItems) {\n   static constexpr int kTableSize = 1000;\n   PresizedCuckooMap<int> pscm(kTableSize);\n-  for (uint64 i = 0; i < kTableSize; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(int64_t)));\n+  for (uint64_t i = 0; i < kTableSize; i++) {\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(int64_t)));\n     ASSERT_TRUE(pscm.InsertUnique(key, i));\n   }\n   // Try to over-fill the table.  A few of these\n   // inserts will succeed, but should start failing.\n-  uint64 failed_at = 0;\n-  for (uint64 i = kTableSize; i < (2 * kTableSize); i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(int64_t)));\n+  uint64_t failed_at = 0;\n+  for (uint64_t i = kTableSize; i < (2 * kTableSize); i++) {\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(int64_t)));\n     if (!pscm.InsertUnique(key, i)) {\n       failed_at = i;\n       break;\n@@ -66,10 +66,10 @@ TEST(PresizedCuckooMapTest, TooManyItems) {\n \n   // Requirement 2:  Table must preserve all items inserted prior\n   // to the failure.\n-  for (uint64 i = 0; i < failed_at; i++) {\n+  for (uint64_t i = 0; i < failed_at; i++) {\n     int out;\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(int64_t)));\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(int64_t)));\n     EXPECT_TRUE(pscm.Find(key, &out));\n     EXPECT_EQ(out, i);\n   }\n@@ -78,7 +78,7 @@ TEST(PresizedCuckooMapTest, TooManyItems) {\n TEST(PresizedCuckooMapTest, ZeroSizeMap) {\n   PresizedCuckooMap<int> pscm(0);\n   int out;\n-  for (uint64 i = 0; i < 100; i++) {\n+  for (uint64_t i = 0; i < 100; i++) {\n     EXPECT_FALSE(pscm.Find(i, &out));\n   }\n }\n@@ -102,13 +102,13 @@ TEST(PresizedCuckooMapTest, RepeatedClear) {\n void RunFill(int64_t table_size) {\n   PresizedCuckooMap<int> pscm(table_size);\n   for (int64_t i = 0; i < table_size; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(int64_t)));\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(int64_t)));\n     EXPECT_TRUE(pscm.InsertUnique(key, i));\n   }\n   for (int64_t i = 0; i < table_size; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(int64_t)));\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(int64_t)));\n     int out;\n     EXPECT_TRUE(pscm.Find(key, &out));\n     EXPECT_EQ(out, i);\n@@ -125,37 +125,37 @@ TEST(PresizedCuckooMapTest, Duplicates) {\n   static constexpr int kSmallTableSize = 1000;\n   PresizedCuckooMap<int> pscm(kSmallTableSize);\n \n-  for (uint64 i = 0; i < kSmallTableSize; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(uint64)));\n+  for (uint64_t i = 0; i < kSmallTableSize; i++) {\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(uint64_t)));\n     EXPECT_TRUE(pscm.InsertUnique(key, i));\n   }\n \n-  for (uint64 i = 0; i < kSmallTableSize; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(uint64)));\n+  for (uint64_t i = 0; i < kSmallTableSize; i++) {\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(uint64_t)));\n     EXPECT_FALSE(pscm.InsertUnique(key, i));\n   }\n }\n \n-static void CalculateKeys(uint64 num, std::vector<uint64> *dst) {\n+static void CalculateKeys(uint64_t num, std::vector<uint64_t>* dst) {\n   dst->resize(num);\n-  for (uint64 i = 0; i < num; i++) {\n-    uint64 key =\n-        Fingerprint64(string(reinterpret_cast<char *>(&i), sizeof(uint64)));\n+  for (uint64_t i = 0; i < num; i++) {\n+    uint64_t key = Fingerprint64(\n+        std::string(reinterpret_cast<char*>(&i), sizeof(uint64_t)));\n     dst->at(i) = key;\n   }\n }\n \n void BM_CuckooFill(::testing::benchmark::State &state) {\n   const int arg = state.range(0);\n \n-  uint64 table_size = arg;\n-  std::vector<uint64> calculated_keys;\n+  uint64_t table_size = arg;\n+  std::vector<uint64_t> calculated_keys;\n   CalculateKeys(table_size, &calculated_keys);\n   for (auto s : state) {\n     PresizedCuckooMap<int> pscm(table_size);\n-    for (uint64 i = 0; i < table_size; i++) {\n+    for (uint64_t i = 0; i < table_size; i++) {\n       pscm.InsertUnique(calculated_keys[i], i);\n     }\n   }\n@@ -166,18 +166,18 @@ BENCHMARK(BM_CuckooFill)->Arg(1000)->Arg(10000000);\n void BM_CuckooRead(::testing::benchmark::State &state) {\n   const int arg = state.range(0);\n \n-  uint64 table_size = arg;\n-  std::vector<uint64> calculated_keys;\n+  uint64_t table_size = arg;\n+  std::vector<uint64_t> calculated_keys;\n   CalculateKeys(table_size, &calculated_keys);\n   PresizedCuckooMap<int> pscm(table_size);\n-  for (uint64 i = 0; i < table_size; i++) {\n+  for (uint64_t i = 0; i < table_size; i++) {\n     pscm.InsertUnique(calculated_keys[i], i);\n   }\n \n   int i = 0;\n   for (auto s : state) {\n     // Avoid using '%', which is expensive.\n-    uint64 key_index = i;\n+    uint64_t key_index = i;\n     ++i;\n     if (i == table_size) i = 0;\n "
        }
    ],
    "stats": {
        "total": 1219,
        "additions": 631,
        "deletions": 588
    }
}