{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add functions to allocate memory with VMM API.\n\nPiperOrigin-RevId: 819074758",
    "sha": "d0564fd22323a8170b3e1267a73a28febd123723",
    "files": [
        {
            "sha": "79ee89c8ae297cb639678aea263dec3d33c906ed",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=d0564fd22323a8170b3e1267a73a28febd123723",
            "patch": "@@ -1156,6 +1156,7 @@ cc_library(\n         \":cuda_version_parser\",\n         \":cudnn_api_wrappers\",\n         \":tma_util\",\n+        \"//xla:util\",\n         \"//xla/backends/gpu/collectives:gpu_collectives\",\n         \"//xla/core/collectives\",\n         \"//xla/core/collectives:collectives_registry\",\n@@ -1192,6 +1193,7 @@ cc_library(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:logging\",\n         \"//xla/tsl/platform:macros\",\n+        \"//xla/tsl/platform:status\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base\",\n@@ -1240,6 +1242,7 @@ xla_test(\n         \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "5a7fa373be07cacacdb4b4d028a68e89ade19dc1",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 161,
            "deletions": 1,
            "changes": 162,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=d0564fd22323a8170b3e1267a73a28febd123723",
            "patch": "@@ -92,8 +92,10 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/macros.h\"\n+#include \"xla/tsl/platform/status.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n+#include \"xla/util.h\"\n #include \"tsl/platform/casts.h\"\n #include \"tsl/platform/fingerprint.h\"\n #include \"tsl/platform/numa.h\"\n@@ -623,6 +625,42 @@ absl::StatusOr<std::unique_ptr<MemoryAllocation>> AllocateHostMemory(\n       });\n }\n \n+absl::StatusOr<bool> IsVmmSupported(CUdevice device) {\n+  int deviceSupportsVmm = 0;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuDeviceGetAttribute(\n+      &deviceSupportsVmm,\n+      CU_DEVICE_ATTRIBUTE_VIRTUAL_MEMORY_MANAGEMENT_SUPPORTED, device)));\n+  return deviceSupportsVmm;\n+}\n+\n+absl::StatusOr<bool> IsRdmaSupported(CUdevice device) {\n+  int rdma_supported = 0;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuDeviceGetAttribute(\n+      &rdma_supported,\n+      CU_DEVICE_ATTRIBUTE_GPU_DIRECT_RDMA_WITH_CUDA_VMM_SUPPORTED, device)));\n+  return rdma_supported;\n+}\n+\n+CUmemAllocationProp GetVmmAllocationProperties(CUdevice device,\n+                                               bool is_rdma_supported) {\n+  CUmemAllocationProp properties = {};\n+  properties.type = CU_MEM_ALLOCATION_TYPE_PINNED;\n+  properties.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n+  properties.requestedHandleTypes =\n+      static_cast<CUmemAllocationHandleType>(CU_MEM_HANDLE_TYPE_NONE);\n+  properties.location.id = device;\n+  properties.allocFlags.gpuDirectRDMACapable = is_rdma_supported ? 1 : 0;\n+  return properties;\n+}\n+\n+CUmemAccessDesc GetVmmAccessDescriptor(int device) {\n+  CUmemAccessDesc descriptor = {};\n+  descriptor.location.type = CU_MEM_LOCATION_TYPE_DEVICE;\n+  descriptor.location.id = device;\n+  descriptor.flags = CU_MEM_ACCESS_FLAGS_PROT_READWRITE;\n+  return descriptor;\n+}\n+\n }  // namespace\n \n // Given const GPU memory, returns a libcuda device pointer datatype, suitable\n@@ -666,6 +704,107 @@ absl::StatusOr<xla::gpu::GpuCollectives*> GetGpuCollectives(\n   return tsl::down_cast<xla::gpu::GpuCollectives*>(collectives);\n }\n \n+CudaExecutor::VmmMemoryHandle::~VmmMemoryHandle() { TF_CHECK_OK(Release()); }\n+\n+absl::Status CudaExecutor::VmmMemoryHandle::Release() {\n+  if (handle_ != 0) {\n+    TF_RETURN_IF_ERROR(cuda::ToStatus(\n+        cuMemRelease(static_cast<CUmemGenericAllocationHandle>(handle_))));\n+    handle_ = 0;\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+CudaExecutor::VmmMemoryHandle::VmmMemoryHandle(VmmMemoryHandle&& other) {\n+  handle_ = other.handle_;\n+  other.handle_ = 0;\n+}\n+\n+CudaExecutor::VmmMemoryHandle& CudaExecutor::VmmMemoryHandle::operator=(\n+    VmmMemoryHandle&& other) {\n+  if (this != &other) {\n+    TF_CHECK_OK(Release());\n+    handle_ = other.handle_;\n+    other.handle_ = 0;\n+  }\n+  return *this;\n+}\n+\n+absl::StatusOr<CudaExecutor::VmmMemoryHandle>\n+CudaExecutor::RetainVmmMemoryHandle(void* ptr) {\n+  if (!is_vmm_supported_) {\n+    return absl::InternalError(\"VMM is not supported on this device.\");\n+  }\n+\n+  CUmemGenericAllocationHandle handle;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemRetainAllocationHandle(&handle, ptr)));\n+\n+  return CudaExecutor::VmmMemoryHandle(static_cast<uint64_t>(handle));\n+}\n+\n+absl::StatusOr<void*> CudaExecutor::VmmAllocateMemory(uint64_t bytes) {\n+  if (!is_vmm_supported_) {\n+    return absl::InternalError(\"VMM is not supported on this device.\");\n+  }\n+\n+  std::unique_ptr<ActivateContext> activation = Activate();\n+\n+  CUmemAllocationProp properties =\n+      GetVmmAllocationProperties(device_, is_rdma_supported_);\n+  size_t granularity = 0;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemGetAllocationGranularity(\n+      &granularity, &properties, CU_MEM_ALLOC_GRANULARITY_RECOMMENDED)));\n+\n+  uint64_t padded_size = xla::RoundUpTo<uint64_t>(bytes, granularity);\n+  CUmemGenericAllocationHandle handle;\n+\n+  // Create physical memory allocation.\n+  TF_RETURN_IF_ERROR(\n+      cuda::ToStatus(cuMemCreate(&handle, padded_size, &properties, 0)));\n+\n+  // Reserve and map virtual address space.\n+  CUdeviceptr ptr;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(\n+      cuMemAddressReserve(&ptr, padded_size, granularity, 0, 0)));\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemMap(ptr, padded_size, 0, handle, 0)));\n+\n+  int device_count = 0;\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cudaGetDeviceCount(&device_count)));\n+  for (int peer = 0; peer < device_count; peer++) {\n+    if (peer == device_ordinal() || CanEnablePeerAccess(peer, device_)) {\n+      CUmemAccessDesc accessDesc = GetVmmAccessDescriptor(peer);\n+      TF_RETURN_IF_ERROR(\n+          cuda::ToStatus(cuMemSetAccess(ptr, padded_size, &accessDesc, 1)));\n+    }\n+  }\n+\n+  return reinterpret_cast<void*>(ptr);\n+}\n+\n+absl::Status CudaExecutor::VmmDeallocateMemory(void* ptr) {\n+  if (!is_vmm_supported_) {\n+    return absl::InternalError(\"VMM is not supported on this device.\");\n+  }\n+\n+  std::unique_ptr<ActivateContext> activation = Activate();\n+\n+  CUmemGenericAllocationHandle handle = 0;\n+  {\n+    TF_ASSIGN_OR_RETURN(VmmMemoryHandle scoped_handle,\n+                        RetainVmmMemoryHandle(ptr));\n+    handle = static_cast<CUmemGenericAllocationHandle>(scoped_handle.handle());\n+  }\n+  size_t size = 0;\n+  CUdeviceptr device_ptr = reinterpret_cast<CUdeviceptr>(ptr);\n+  TF_RETURN_IF_ERROR(\n+      cuda::ToStatus(cuMemGetAddressRange(nullptr, &size, device_ptr)));\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemUnmap(device_ptr, size)));\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemRelease(handle)));\n+  TF_RETURN_IF_ERROR(cuda::ToStatus(cuMemAddressFree(device_ptr, size)));\n+  return absl::OkStatus();\n+}\n+\n absl::StatusOr<void*> CollectiveMemoryAllocate(StreamExecutor* executor,\n                                                uint64_t bytes) {\n   if (bytes == 0) return nullptr;\n@@ -755,6 +894,8 @@ CudaExecutor::CreateMemoryAllocator(MemoryType type) {\n \n absl::Status CudaExecutor::Init() {\n   TF_ASSIGN_OR_RETURN(device_, GetDevice(device_ordinal()));\n+  TF_ASSIGN_OR_RETURN(is_vmm_supported_, IsVmmSupported(device_));\n+  TF_ASSIGN_OR_RETURN(is_rdma_supported_, IsRdmaSupported(device_));\n   TF_ASSIGN_OR_RETURN(CudaContext * context,\n                       CudaContext::Create(device_ordinal(), device_));\n   cuda_context_ = context;\n@@ -1078,6 +1219,20 @@ DeviceMemoryBase CudaExecutor::Allocate(uint64_t size, int64_t memory_space) {\n     return DeviceMemoryBase(result.value(), size);\n   }\n \n+  if (memory_space == static_cast<int64_t>(MemoryType::kP2P) &&\n+      is_vmm_supported_) {\n+    auto device_buf_base = VmmAllocateMemory(size);\n+\n+    if (device_buf_base.ok()) {\n+      return DeviceMemoryBase(device_buf_base.value(), size);\n+    }\n+\n+    LOG(ERROR) << \"Failed to allocate memory with VMM: \"\n+               << device_buf_base.status();\n+\n+    return DeviceMemoryBase(nullptr, 0);\n+  }\n+\n   CHECK(memory_space == static_cast<int64_t>(MemoryType::kDevice) ||\n         memory_space == static_cast<int64_t>(MemoryType::kP2P));\n \n@@ -1105,7 +1260,12 @@ void CudaExecutor::Deallocate(DeviceMemoryBase* mem) {\n   if (memory_space == MemoryType::kHost) {\n     HostDeallocate(cuda_context_, numa_node_, mem->opaque(), mem->size());\n   } else {\n-    DeviceDeallocate(cuda_context_, mem->opaque());\n+    // Memory space is always kDevice here, so the only way to check if the\n+    // memory was allocated with VMM API is to try to retain the handle with VMM\n+    // API (which VmmDeallocateMemory does).\n+    if (!VmmDeallocateMemory(mem->opaque()).ok()) {\n+      DeviceDeallocate(cuda_context_, mem->opaque());\n+    }\n   }\n }\n "
        },
        {
            "sha": "51d23c77872044db60096412b1f3eac604cc478f",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.h",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h?ref=d0564fd22323a8170b3e1267a73a28febd123723",
            "patch": "@@ -137,7 +137,31 @@ class CudaExecutor : public GpuExecutor {\n   absl::StatusOr<std::unique_ptr<MemoryAllocator>> CreateMemoryAllocator(\n       MemoryType type) override;\n \n+  // RAII wrapper for a VMM memory handle.\n+  class VmmMemoryHandle {\n+   public:\n+    explicit VmmMemoryHandle(uint64_t handle) : handle_(handle) {}\n+    ~VmmMemoryHandle();\n+    VmmMemoryHandle(const VmmMemoryHandle&) = delete;\n+    VmmMemoryHandle& operator=(const VmmMemoryHandle&) = delete;\n+    VmmMemoryHandle(VmmMemoryHandle&&);\n+    VmmMemoryHandle& operator=(VmmMemoryHandle&&);\n+\n+    uint64_t handle() const { return handle_; }\n+\n+   private:\n+    absl::Status Release();\n+    uint64_t handle_;\n+  };\n+\n+  // Returns a handle to the given memory if it was allocated with VMM API.\n+  absl::StatusOr<VmmMemoryHandle> RetainVmmMemoryHandle(void* ptr);\n+\n  private:\n+  absl::Status VmmDeallocateMemory(void* ptr);\n+\n+  absl::StatusOr<void*> VmmAllocateMemory(uint64_t bytes);\n+\n   // Loads a module in cubin format.\n   absl::StatusOr<ModuleHandle> LoadModuleFromCuBin(const char* cubin)\n       ABSL_EXCLUSIVE_LOCKS_REQUIRED(in_memory_modules_mu_);\n@@ -152,6 +176,10 @@ class CudaExecutor : public GpuExecutor {\n   // Returns true if a delay kernel is supported.\n   absl::StatusOr<bool> DelayKernelIsSupported();\n \n+  bool is_vmm_supported_ = false;\n+\n+  bool is_rdma_supported_ = false;\n+\n   // Guards the in-memory-module mapping.\n   absl::Mutex in_memory_modules_mu_;\n "
        },
        {
            "sha": "36b2f20ac42612e93c7ee609c70945c3f8bec560",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor_test.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 1,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d0564fd22323a8170b3e1267a73a28febd123723/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor_test.cc?ref=d0564fd22323a8170b3e1267a73a28febd123723",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/cuda/cuda_platform.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n@@ -208,8 +209,47 @@ TEST(CudaExecutorTest, GetPointerMemorySpaceWorksWithDeviceMemory) {\n   DeviceMemoryBase allocation = executor->Allocate(256);\n   EXPECT_NE(allocation.opaque(), nullptr);\n   EXPECT_THAT(executor->GetPointerMemorySpace(allocation.opaque()),\n-              IsOkAndHolds(MemoryType::kDevice));\n+              absl_testing::IsOkAndHolds(MemoryType::kDevice));\n }\n \n+TEST(CudaExecutorTest, AllocateMemoryWithVmmApi) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"CUDA\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  auto cuda_executor = dynamic_cast<CudaExecutor*>(executor);\n+  ASSERT_NE(cuda_executor, nullptr);\n+  DeviceMemoryBase ptr =\n+      cuda_executor->Allocate(1024, static_cast<int>(MemoryType::kP2P));\n+\n+  EXPECT_NE(ptr.opaque(), nullptr);\n+  EXPECT_EQ(ptr.size(), 1024);\n+  EXPECT_THAT(executor->GetPointerMemorySpace(ptr.opaque()),\n+              absl_testing::IsOkAndHolds(MemoryType::kDevice));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(CudaExecutor::VmmMemoryHandle handle,\n+                          cuda_executor->RetainVmmMemoryHandle(ptr.opaque()));\n+  EXPECT_NE(handle.handle(), 0);\n+}\n+\n+TEST(CudaExecutorTest,\n+     RetainVmmMemoryHandleForTheMemoryAllocatedWithoutVmmApi) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"CUDA\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  auto cuda_executor = dynamic_cast<CudaExecutor*>(executor);\n+  ASSERT_NE(cuda_executor, nullptr);\n+  DeviceMemoryBase ptr =\n+      cuda_executor->Allocate(1024, static_cast<int>(MemoryType::kDevice));\n+\n+  EXPECT_NE(ptr.opaque(), nullptr);\n+  EXPECT_EQ(ptr.size(), 1024);\n+\n+  EXPECT_THAT(cuda_executor->RetainVmmMemoryHandle(ptr.opaque()),\n+              absl_testing::StatusIs(absl::StatusCode::kInternal));\n+}\n }  // namespace\n }  // namespace stream_executor::gpu"
        }
    ],
    "stats": {
        "total": 235,
        "additions": 233,
        "deletions": 2
    }
}