{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 828849265",
    "sha": "d5622324857e7744863ae9daf6e5d52d1e0a2477",
    "files": [
        {
            "sha": "fbd6a9c0d46d5e7d73f3e3a6f7832956d772e2b1",
            "filename": "tensorflow/core/tpu/kernels/xla/host_compute_ops.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d5622324857e7744863ae9daf6e5d52d1e0a2477/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Fhost_compute_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d5622324857e7744863ae9daf6e5d52d1e0a2477/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Fhost_compute_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Fhost_compute_ops.cc?ref=d5622324857e7744863ae9daf6e5d52d1e0a2477",
            "patch": "@@ -180,7 +180,7 @@ class HostComputeOp : public XlaOpKernel {\n     // Send values to the host.\n     std::vector<xla::XlaOp> send_to_host_tokens;\n     for (int i = 0; i < input_handles.size(); ++i) {\n-      const string channel_name = GetDeviceToHostChannelName(send_key_, i);\n+      const std::string channel_name = GetDeviceToHostChannelName(send_key_, i);\n       xla::Shape xla_shape;\n       OP_REQUIRES_OK(ctx, TensorShapeToXLAShape(input_dtypes_[i],\n                                                 input_shapes[i], &xla_shape));\n@@ -242,7 +242,7 @@ class HostComputeOp : public XlaOpKernel {\n     // Copy results to the device.\n     std::vector<xla::XlaOp> recv_from_host_tokens;\n     for (int i = 0; i < output_shapes->size(); ++i) {\n-      const string channel_name = GetHostToDeviceChannelName(recv_key_, i);\n+      const std::string channel_name = GetHostToDeviceChannelName(recv_key_, i);\n       // Specify frontend attributes.\n       xla::FrontendAttributes attrs;\n       (*attrs.mutable_map())[xla::kXlaHostTransferRendezvousNameAttr] =\n@@ -403,21 +403,21 @@ class HostComputeOp : public XlaOpKernel {\n \n   DataTypeVector input_dtypes_;\n   DataTypeVector output_dtypes_;\n-  std::vector<string> ancestors_;\n+  std::vector<std::string> ancestors_;\n   std::vector<TensorShape> static_output_shapes_;\n   std::vector<xla::Shape> static_xla_output_shapes_;\n-  string original_node_name_;\n+  std::string original_node_name_;\n   // If static_xla_output_shapes_.size() == 1 then xla_output_shape_ is the\n   // unique output shape, otherwise it is a tuple of all the xla_output_shapes_.\n   xla::Shape static_xla_output_shape_;\n-  string send_key_;\n-  string recv_key_;\n+  std::string send_key_;\n+  std::string recv_key_;\n   // If shape inference is performed at runtime, the graph needed to perform\n   // shape inference is stored in this function.\n   std::unique_ptr<FunctionBody> shape_inference_graph_function_;\n   int64_t cost_estimate_;\n   int64_t tpu_core_;\n-  std::vector<string> token_input_nodes_;\n+  std::vector<std::string> token_input_nodes_;\n \n   HostComputeOp(const HostComputeOp&) = delete;\n   void operator=(const HostComputeOp&) = delete;\n@@ -470,9 +470,9 @@ class SendToHostOp : public XlaOpKernel {\n \n  private:\n   DataType input_dtype_;\n-  string key_;\n-  std::vector<string> token_input_nodes_;\n-  string original_node_name_;\n+  std::string key_;\n+  std::vector<std::string> token_input_nodes_;\n+  std::string original_node_name_;\n   SendToHostOp(const SendToHostOp&) = delete;\n   void operator=(const SendToHostOp&) = delete;\n };\n@@ -529,9 +529,9 @@ class RecvFromHostOp : public XlaOpKernel {\n  private:\n   DataType output_dtype_;\n   TensorShape output_shape_;\n-  string key_;\n-  std::vector<string> token_input_nodes_;\n-  string original_node_name_;\n+  std::string key_;\n+  std::vector<std::string> token_input_nodes_;\n+  std::string original_node_name_;\n   RecvFromHostOp(const RecvFromHostOp&) = delete;\n   void operator=(const RecvFromHostOp&) = delete;\n };"
        },
        {
            "sha": "d9f89b172a815de3a9b4a896271d6f75fd7f3112",
            "filename": "tensorflow/core/tpu/kernels/xla/outfeed_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d5622324857e7744863ae9daf6e5d52d1e0a2477/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Foutfeed_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d5622324857e7744863ae9daf6e5d52d1e0a2477/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Foutfeed_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Ftpu%2Fkernels%2Fxla%2Foutfeed_ops.cc?ref=d5622324857e7744863ae9daf6e5d52d1e0a2477",
            "patch": "@@ -45,7 +45,7 @@ class OutfeedEnqueueOp : public XlaOpKernel {\n     OP_REQUIRES_OK(\n         ctx, TensorShapeToXLAShape(dtype_, ctx->InputShape(0), &xla_shape));\n     // Outfeed configuration is only needed for embedding outfeed.\n-    const string outfeed_config;\n+    const std::string outfeed_config;\n     xla::Outfeed(ctx->Input(0), xla_shape, outfeed_config);\n   }\n \n@@ -83,7 +83,7 @@ class OutfeedEnqueueTupleOp : public XlaOpKernel {\n     auto b = ctx->builder();\n     auto tuple = xla::Tuple(b, handles);\n     // Outfeed configuration is only needed for embedding outfeed.\n-    const string outfeed_config;\n+    const std::string outfeed_config;\n     xla::Outfeed(tuple, tuple_shape, outfeed_config);\n   }\n "
        }
    ],
    "stats": {
        "total": 30,
        "additions": 15,
        "deletions": 15
    }
}