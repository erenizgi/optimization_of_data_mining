{
    "author": "chsigg",
    "message": "Remove deprecated non-hermetic CUDA and NCCL repo rules.\n\nThis change removes the `cuda_configure` and `nccl_configure` repository rules and their associated template files. These rules have been deprecated in favor of the hermetic versions. Utility functions like `find_cuda_config` are retained as they are used by TensorRT configuration scripts.\n\nPiperOrigin-RevId: 814599272",
    "sha": "997e65e64e6addf5a8b5fe89415ccefd78f153d4",
    "files": [
        {
            "sha": "aa0d5818798fd9d928e8eb47ad7566c8f85d9bbb",
            "filename": "third_party/xla/docs/build_from_source.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fdocs%2Fbuild_from_source.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fdocs%2Fbuild_from_source.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fbuild_from_source.md?ref=997e65e64e6addf5a8b5fe89415ccefd78f153d4",
            "patch": "@@ -114,7 +114,7 @@ bazel build \\\n ```\n \n For more details regarding\n-[hermetic CUDA you can check out this document.](hermetic_cuda.md)\n+[hermetic CUDA you can check out this document.](https://github.com/google-ml-infra/rules_ml_toolchain/blob/main/gpu)\n \n ### Build XLA with CUDA/cuDNN Support Using the JAX CI/Release Container\n "
        },
        {
            "sha": "4d9c75d3b2fee0e5c722911aa91e0526de6a5075",
            "filename": "third_party/xla/docs/hermetic_cuda.md",
            "status": "removed",
            "additions": 0,
            "deletions": 58,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fdocs%2Fhermetic_cuda.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fdocs%2Fhermetic_cuda.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Fhermetic_cuda.md?ref=22fa876f4ee784e5a37401607be26c2feba354a4",
            "patch": "@@ -1,58 +0,0 @@\n-# Hermetic CUDA, CUDNN, NCCL and NVSHMEM overview\n-\n-The overview and usage examples are given in [rules_ml_toolchain project](https://github.com/google-ml-infra/rules_ml_toolchain/blob/main/third_party/gpus/hermetic_toolkits.md).\n-\n-## DEPRECATED: Non-hermetic CUDA/CUDNN usage\n-Though non-hermetic CUDA/CUDNN usage is deprecated, it might be used for\n-some experiments currently unsupported officially (for example, building wheels\n-on Windows with CUDA).\n-\n-Here are the steps to use non-hermetic CUDA installed locally in Google ML\n-projects:\n-\n-1. Delete calls to hermetic CUDA repository rules from the `WORKSPACE`\n-   file of the project dependent on XLA.\n-\n-2. Add the calls to non-hermetic CUDA repository rules to the bottom of the\n-   `WORKSPACE` file.\n-\n-   For XLA and JAX:\n-   ```\n-   load(\"@local_xla//third_party/gpus:cuda_configure.bzl\", \"cuda_configure\")\n-   cuda_configure(name = \"local_config_cuda\")\n-   load(\"@local_xla//third_party/nccl:nccl_configure.bzl\", \"nccl_configure\")\n-   nccl_configure(name = \"local_config_nccl\")\n-   ```\n-\n-   For Tensorflow:\n-   ```\n-   load(\"@local_xla//third_party/gpus:cuda_configure.bzl\", \"cuda_configure\")\n-   cuda_configure(name = \"local_config_cuda\")\n-   load(\"@local_xla//third_party/nccl:nccl_configure.bzl\", \"nccl_configure\")\n-   nccl_configure(name = \"local_config_nccl\")\n-   ```\n-\n-3. Set the following environment variables directly in your shell or in\n-   `.bazelrc` file as shown below:\n-   ```\n-   build:cuda --action_env=TF_CUDA_VERSION=<locally installed cuda version>\n-   build:cuda --action_env=TF_CUDNN_VERSION=<locally installed cudnn version>\n-   build:cuda --action_env=TF_CUDA_COMPUTE_CAPABILITIES=<CUDA compute capabilities>\n-   build:cuda --action_env=LD_LIBRARY_PATH=<CUDA/CUDNN libraries folder locations divided by “:” sign>\n-   build:cuda --action_env=CUDA_TOOLKIT_PATH=<preinstalled CUDA folder location>\n-   build:cuda --action_env=TF_CUDA_PATHS=<preinstalled CUDA/CUDNN folder locations divided by “,” sign>\n-   build:cuda --action_env=NCCL_INSTALL_PATH=<preinstalled NCCL library folder location>\n-   ```\n-\n-   Note that `TF_CUDA_VERSION` and `TF_CUDNN_VERSION` should consist of major and\n-   minor versions only (e.g. `12.3` for CUDA and `9.1` for CUDNN).\n-\n-4. Now you can run `bazel` command to use locally installed CUDA and CUDNN.\n-\n-   For XLA, no changes in the command options are needed.\n-\n-   For JAX, use `--override_repository=tsl=<tsl_path>` flag in the Bazel command\n-   options.\n-\n-   For Tensorflow, use `--override_repository=local_tsl=<tsl_path>` flag in the\n-   Bazel command options."
        },
        {
            "sha": "2e383e9cc4cf3a0ee7cdee6131a603c94ce6684d",
            "filename": "third_party/xla/opensource_only.files",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fopensource_only.files",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fopensource_only.files",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fopensource_only.files?ref=997e65e64e6addf5a8b5fe89415ccefd78f153d4",
            "patch": "@@ -79,8 +79,6 @@ xla/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_rocm.tpl:\n xla/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_sycl.tpl:\n xla/third_party/gpus/crosstool/sycl_cc_toolchain_config.bzl.tpl:\n xla/third_party/gpus/crosstool/windows/msvc_wrapper_for_nvcc.py.tpl:\n-xla/third_party/gpus/cuda/BUILD.tpl:\n-xla/third_party/gpus/cuda/BUILD.windows.tpl:\n xla/third_party/gpus/cuda/LICENSE:\n xla/third_party/gpus/cuda/build_defs.bzl.tpl:\n xla/third_party/gpus/cuda/cuda_config.h.tpl:\n@@ -138,8 +136,6 @@ xla/third_party/nccl/build_defs.bzl.tpl:\n xla/third_party/nccl/generated_names.bzl.tpl:\n xla/third_party/nccl/hermetic/cuda_nccl.BUILD.tpl:\n xla/third_party/nccl/hermetic/nccl_configure.bzl:\n-xla/third_party/nccl/nccl_configure.bzl:\n-xla/third_party/nccl/system.BUILD.tpl:\n xla/third_party/nvshmem/hermetic/nvidia_nvshmem.BUILD.tpl:\n xla/third_party/nvshmem/hermetic/nvshmem_json_init_repository.bzl:\n xla/third_party/nvshmem/hermetic/nvshmem_redist_init_repository.bzl:"
        },
        {
            "sha": "6fa0d1e3bdd6e22d9f1b29441d06ccde66f854a5",
            "filename": "third_party/xla/third_party/gpus/cuda/BUILD.tpl",
            "status": "removed",
            "additions": 0,
            "deletions": 320,
            "changes": 320,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.tpl?ref=22fa876f4ee784e5a37401607be26c2feba354a4",
            "patch": "@@ -1,320 +0,0 @@\n-# NB: DEPRECATED! This file is a part of the deprecated `cuda_configure` rule.\n-# Please use `hermetic/cuda_configure` instead.\n-\n-load(\":build_defs.bzl\", \"cuda_header_library\")\n-load(\"@bazel_skylib//:bzl_library.bzl\", \"bzl_library\")\n-load(\"@bazel_skylib//lib:selects.bzl\", \"selects\")\n-load(\"@bazel_skylib//rules:common_settings.bzl\", \"bool_flag\", \"bool_setting\")\n-\n-licenses([\"restricted\"])  # MPL2, portions GPL v3, LGPL v3, BSD-like\n-\n-package(default_visibility = [\"//visibility:public\"])\n-\n-# Config setting whether TensorFlow is built with CUDA support using clang.\n-#\n-# TODO(b/174244321), DEPRECATED: this target will be removed when all users\n-# have been converted to :is_cuda_enabled (most) or :is_cuda_compiler_clang.\n-selects.config_setting_group(\n-    name = \"using_clang\",\n-    match_all = [\n-        \"@local_config_cuda//:is_cuda_enabled\",\n-        \"@local_config_cuda//:is_cuda_compiler_clang\",\n-    ],\n-)\n-\n-# Config setting whether TensorFlow is built with CUDA support using nvcc.\n-#\n-# TODO(b/174244321), DEPRECATED: this target will be removed when all users\n-# have been converted to :is_cuda_enabled (most) or :is_cuda_compiler_nvcc.\n-selects.config_setting_group(\n-    name = \"using_nvcc\",\n-    match_all = [\n-        \"@local_config_cuda//:is_cuda_enabled\",\n-        \"@local_config_cuda//:is_cuda_compiler_nvcc\",\n-    ],\n-)\n-\n-# Equivalent to using_clang && -c opt.\n-selects.config_setting_group(\n-    name = \"using_clang_opt\",\n-    match_all = [\n-        \":using_clang\",\n-        \":_opt\",\n-    ],\n-)\n-\n-config_setting(\n-    name = \"_opt\",\n-    values = {\"compilation_mode\": \"opt\"},\n-)\n-\n-# Provides CUDA headers for '#include \"third_party/gpus/cuda/include/cuda.h\"'\n-# All clients including TensorFlow should use these directives.\n-cuda_header_library(\n-    name = \"cuda_headers\",\n-    hdrs = [\n-        \"cuda/cuda_config.h\",\n-        \":cuda-include\",\n-    ],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\n-        \".\",  # required to include cuda/cuda/cuda_config.h as cuda/config.h\n-        \"cuda/include\",\n-    ],\n-)\n-\n-# See comment on identically named target in hermetic/BUILD.tpl. This is here\n-# to keep users who have still not migrated from hermetic cuda from being\n-# broken.\n-alias(\n-  name = \"implicit_cuda_headers_dependency\",\n-  actual = \":cuda_headers\",\n-)\n-\n-cc_library(\n-    name = \"cudart_static\",\n-    srcs = [\"cuda/lib/%{cudart_static_lib}\"],\n-    linkopts = [\n-        \"-ldl\",\n-        \"-lpthread\",\n-        %{cudart_static_linkopt}\n-    ],\n-)\n-\n-cc_library(\n-    name = \"cuda_driver\",\n-    srcs = [\"cuda/lib/%{cuda_driver_lib}\"],\n-)\n-\n-cc_library(\n-    name = \"cudart\",\n-    srcs = [\"cuda/lib/%{cudart_lib}\"],\n-    data = [\"cuda/lib/%{cudart_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cuda_header_library(\n-    name = \"cublas_headers\",\n-    hdrs = [\":cublas-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cublas/include\"],\n-    strip_include_prefix = \"cublas/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cusolver_headers\",\n-    hdrs = [\":cusolver-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cusolver/include\"],\n-    strip_include_prefix = \"cusolver/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cufft_headers\",\n-    hdrs = [\":cufft-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cufft/include\"],\n-    strip_include_prefix = \"cufft/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cusparse_headers\",\n-    hdrs = [\":cusparse-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cusparse/include\"],\n-    strip_include_prefix = \"cusparse/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"curand_headers\",\n-    hdrs = [\":curand-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"curand/include\"],\n-    strip_include_prefix = \"curand/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_library(\n-    name = \"cublas\",\n-    srcs = [\"cuda/lib/%{cublas_lib}\"],\n-    data = [\"cuda/lib/%{cublas_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"cublasLt\",\n-    srcs = [\"cuda/lib/%{cublasLt_lib}\"],\n-    data = [\"cuda/lib/%{cublasLt_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"cusolver\",\n-    srcs = [\"cuda/lib/%{cusolver_lib}\"],\n-    data = [\"cuda/lib/%{cusolver_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"cudnn\",\n-    srcs = [\"cuda/lib/%{cudnn_lib}\"],\n-    data = [\"cuda/lib/%{cudnn_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"cudnn_header\",\n-    hdrs = [\":cudnn-include\"],\n-    include_prefix = \"third_party/gpus/cudnn\",\n-    strip_include_prefix = \"cudnn/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_library(\n-    name = \"cufft\",\n-    srcs = [\"cuda/lib/%{cufft_lib}\"],\n-    data = [\"cuda/lib/%{cufft_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"curand\",\n-    srcs = [\"cuda/lib/%{curand_lib}\"],\n-    data = [\"cuda/lib/%{curand_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"cuda\",\n-    deps = [\n-        \":cublas\",\n-        \":cublasLt\",\n-        \":cuda_headers\",\n-        \":cudart\",\n-        \":cudnn\",\n-        \":cufft\",\n-        \":curand\",\n-    ],\n-)\n-\n-alias(\n-    name = \"cub_headers\",\n-    actual = \"%{cub_actual}\",\n-)\n-\n-cuda_header_library(\n-    name = \"cupti_headers\",\n-    hdrs = [\":cuda-extras\"],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\"cuda/extras/CUPTI/include/\"],\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"nvml_headers\",\n-    hdrs = [\":nvml\"],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\"cuda/nvml/include/\"],\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_library(\n-    name = \"cupti_dsos\",\n-    data = [\"cuda/lib/%{cupti_lib}\"],\n-)\n-\n-cc_library(\n-    name = \"cusparse\",\n-    srcs = [\"cuda/lib/%{cusparse_lib}\"],\n-    data = [\"cuda/lib/%{cusparse_lib}\"],\n-    linkstatic = 1,\n-)\n-\n-cc_library(\n-    name = \"libdevice_root\",\n-    data = [\":cuda-nvvm\"],\n-)\n-\n-bzl_library(\n-    name = \"build_defs_bzl\",\n-    srcs = [\"build_defs.bzl\"],\n-    deps = [\n-        \"@bazel_skylib//lib:selects\",\n-    ],\n-)\n-\n-py_library(\n-    name = \"cuda_config_py\",\n-    srcs = [\"cuda/cuda_config.py\"],\n-)\n-\n-# Build setting that is always true (i.e. it can not be changed on the\n-# command line). It is used to create the config settings below that are\n-# always or never satisfied.\n-bool_setting(\n-    name = \"true_setting\",\n-    visibility = [\"//visibility:private\"],\n-    build_setting_default = True,\n-)\n-\n-# Config settings whether TensorFlow is built with CUDA.\n-# These configs are never satisfied.\n-config_setting(\n-    name = \"cuda_tools\",\n-    flag_values = {\":true_setting\": \"False\"},\n-)\n-\n-# Flags indicating if we should include CUDA libs.\n-bool_flag(\n-    name = \"include_cuda_libs\",\n-    build_setting_default = False,\n-)\n-\n-config_setting(\n-    name = \"cuda_libs\",\n-    flag_values = {\":true_setting\": \"False\"},\n-)\n-\n-bool_flag(\n-    name = \"override_include_cuda_libs\",\n-    build_setting_default = False,\n-)\n-\n-config_setting(\n-    name = \"overrided_cuda_libs\",\n-    flag_values = {\":true_setting\": \"False\"},\n-)\n-\n-selects.config_setting_group(\n-    name = \"any_cuda_libs\",\n-    match_any = [\n-        \":cuda_libs\",\n-        \":overrided_cuda_libs\"\n-    ],\n-)\n-\n-selects.config_setting_group(\n-    name = \"cuda_tools_and_libs\",\n-    match_all = [\n-        \":any_cuda_libs\",\n-        \":cuda_tools\"\n-    ],\n-)\n-\n-%{copy_rules}\n-\n-cc_library(\n-    # This is not yet fully supported, but we need the rule\n-    # to make bazel query happy.\n-    name = \"nvptxcompiler\",\n-)\n-\n-cc_library(\n-    # This is not yet fully supported, but we need the rule\n-    # to make bazel query happy.\n-    name = \"nvjitlink\",\n-)"
        },
        {
            "sha": "6b25c8398a71442966223babba7455f31f16e847",
            "filename": "third_party/xla/third_party/gpus/cuda/BUILD.windows.tpl",
            "status": "removed",
            "additions": 0,
            "deletions": 242,
            "changes": 242,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.windows.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.windows.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda%2FBUILD.windows.tpl?ref=22fa876f4ee784e5a37401607be26c2feba354a4",
            "patch": "@@ -1,242 +0,0 @@\n-# NB: DEPRECATED! This file is a part of the deprecated `cuda_configure` rule.\n-# Hermetic CUDA repository rule doesn't support Windows.\n-# Please use `hermetic/cuda_configure`.\n-\n-load(\":build_defs.bzl\", \"cuda_header_library\")\n-load(\"@bazel_skylib//:bzl_library.bzl\", \"bzl_library\")\n-load(\"@bazel_skylib//lib:selects.bzl\", \"selects\")\n-\n-licenses([\"restricted\"])  # MPL2, portions GPL v3, LGPL v3, BSD-like\n-\n-package(default_visibility = [\"//visibility:public\"])\n-\n-# Config setting whether TensorFlow is built with CUDA support using clang.\n-#\n-# TODO(b/174244321), DEPRECATED: this target will be removed when all users\n-# have been converted to :is_cuda_enabled (most) or :is_cuda_compiler_clang.\n-selects.config_setting_group(\n-    name = \"using_clang\",\n-    match_all = [\n-        \"@local_config_cuda//:is_cuda_enabled\",\n-        \"@local_config_cuda//:is_cuda_compiler_clang\",\n-    ],\n-)\n-\n-# Config setting whether TensorFlow is built with CUDA support using nvcc.\n-#\n-# TODO(b/174244321), DEPRECATED: this target will be removed when all users\n-# have been converted to :is_cuda_enabled (most) or :is_cuda_compiler_nvcc.\n-selects.config_setting_group(\n-    name = \"using_nvcc\",\n-    match_all = [\n-        \"@local_config_cuda//:is_cuda_enabled\",\n-        \"@local_config_cuda//:is_cuda_compiler_nvcc\",\n-    ],\n-)\n-\n-# Equivalent to using_clang && -c opt.\n-selects.config_setting_group(\n-    name = \"using_clang_opt\",\n-    match_all = [\n-        \":using_clang\",\n-        \":_opt\",\n-    ],\n-)\n-\n-config_setting(\n-    name = \"_opt\",\n-    values = {\"compilation_mode\": \"opt\"},\n-)\n-\n-# Provides CUDA headers for '#include \"third_party/gpus/cuda/include/cuda.h\"'\n-# All clients including TensorFlow should use these directives.\n-cuda_header_library(\n-    name = \"cuda_headers\",\n-    hdrs = [\n-        \"cuda/cuda_config.h\",\n-        \":cuda-include\",\n-    ],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\n-        \".\",  # required to include cuda/cuda/cuda_config.h as cuda/config.h\n-        \"cuda/include\",\n-    ],\n-)\n-\n-cc_import(\n-    name = \"cudart_static\",\n-    # /WHOLEARCHIVE:cudart_static.lib will cause a\n-    # \"Internal error during CImplib::EmitThunk\" error.\n-    # Treat this library as interface library to avoid being whole archived when\n-    # linking a DLL that depends on this.\n-    # TODO(pcloudy): Remove this rule after b/111278841 is resolved.\n-    interface_library = \"cuda/lib/%{cudart_static_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cuda_driver\",\n-    interface_library = \"cuda/lib/%{cuda_driver_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cudart\",\n-    interface_library = \"cuda/lib/%{cudart_lib}\",\n-    system_provided = 1,\n-)\n-\n-cuda_header_library(\n-    name = \"cublas_headers\",\n-    hdrs = [\":cublas-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cublas/include\"],\n-    strip_include_prefix = \"cublas/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cusolver_headers\",\n-    hdrs = [\":cusolver-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cusolver/include\"],\n-    strip_include_prefix = \"cusolver/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cufft_headers\",\n-    hdrs = [\":cufft-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cufft/include\"],\n-    strip_include_prefix = \"cufft/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"cusparse_headers\",\n-    hdrs = [\":cusparse-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"cusparse/include\"],\n-    strip_include_prefix = \"cusparse/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"curand_headers\",\n-    hdrs = [\":curand-include\"],\n-    include_prefix = \"third_party/gpus/cuda/include\",\n-    includes = [\"curand/include\"],\n-    strip_include_prefix = \"curand/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_import(\n-    name = \"cublas\",\n-    interface_library = \"cuda/lib/%{cublas_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cublasLt\",\n-    interface_library = \"cuda/lib/%{cublasLt_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cusolver\",\n-    interface_library = \"cuda/lib/%{cusolver_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cudnn\",\n-    interface_library = \"cuda/lib/%{cudnn_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_library(\n-    name = \"cudnn_header\",\n-    hdrs = [\":cudnn-include\"],\n-    include_prefix = \"third_party/gpus/cudnn\",\n-    strip_include_prefix = \"cudnn/include\",\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_import(\n-    name = \"cufft\",\n-    interface_library = \"cuda/lib/%{cufft_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"curand\",\n-    interface_library = \"cuda/lib/%{curand_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_library(\n-    name = \"cuda\",\n-    deps = [\n-        \":cublas\",\n-        \":cublasLt\",\n-        \":cuda_headers\",\n-        \":cudart\",\n-        \":cudnn\",\n-        \":cufft\",\n-        \":curand\",\n-    ],\n-)\n-\n-alias(\n-    name = \"cub_headers\",\n-    actual = \"%{cub_actual}\",\n-)\n-\n-cuda_header_library(\n-    name = \"cupti_headers\",\n-    hdrs = [\":cuda-extras\"],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\"cuda/extras/CUPTI/include/\"],\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cuda_header_library(\n-    name = \"nvml_headers\",\n-    hdrs = [\":nvml\"],\n-    include_prefix = \"third_party/gpus\",\n-    includes = [\"cuda/nvml/include/\"],\n-    deps = [\":cuda_headers\"],\n-)\n-\n-cc_import(\n-    name = \"cupti_dsos\",\n-    interface_library = \"cuda/lib/%{cupti_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_import(\n-    name = \"cusparse\",\n-    interface_library = \"cuda/lib/%{cusparse_lib}\",\n-    system_provided = 1,\n-)\n-\n-cc_library(\n-    name = \"libdevice_root\",\n-    data = [\":cuda-nvvm\"],\n-)\n-\n-bzl_library(\n-    name = \"build_defs_bzl\",\n-    srcs = [\"build_defs.bzl\"],\n-    deps = [\n-        \"@bazel_skylib//lib:selects\",\n-    ],\n-)\n-\n-py_library(\n-    name = \"cuda_config_py\",\n-    srcs = [\"cuda/cuda_config.py\"],\n-)\n-\n-%{copy_rules}"
        },
        {
            "sha": "7ff3c8d0151034a80d409f0f00adf713cff43612",
            "filename": "third_party/xla/third_party/gpus/cuda_configure.bzl",
            "status": "modified",
            "additions": 0,
            "deletions": 1268,
            "changes": 1268,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda_configure.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/997e65e64e6addf5a8b5fe89415ccefd78f153d4/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda_configure.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fgpus%2Fcuda_configure.bzl?ref=997e65e64e6addf5a8b5fe89415ccefd78f153d4",
            "patch": "@@ -30,340 +30,25 @@ NB: DEPRECATED! Use `hermetic/cuda_configure` rule instead.\n     environment variable is used by GCC compiler.\n \"\"\"\n \n-load(\n-    \"@bazel_tools//tools/cpp:lib_cc_configure.bzl\",\n-    \"escape_string\",\n-    \"get_env_var\",\n-)\n-load(\n-    \"@bazel_tools//tools/cpp:windows_cc_configure.bzl\",\n-    \"find_msvc_tool\",\n-    \"find_vc_path\",\n-    \"setup_vc_env_vars\",\n-)\n-load(\"//third_party/clang_toolchain:download_clang.bzl\", \"download_clang\")\n load(\n     \"//third_party/remote_config:common.bzl\",\n-    \"config_repo_label\",\n     \"err_out\",\n     \"execute\",\n-    \"get_bash_bin\",\n-    \"get_cpu_value\",\n     \"get_host_environ\",\n     \"get_python_bin\",\n-    \"is_windows\",\n-    \"raw_exec\",\n     \"read_dir\",\n-    \"realpath\",\n-    \"which\",\n-)\n-load(\n-    \":compiler_common_tools.bzl\",\n-    \"get_cxx_inc_directories\",\n-    \"to_list_of_strings\",\n )\n \n-_GCC_HOST_COMPILER_PATH = \"GCC_HOST_COMPILER_PATH\"\n-_GCC_HOST_COMPILER_PREFIX = \"GCC_HOST_COMPILER_PREFIX\"\n-_CLANG_CUDA_COMPILER_PATH = \"CLANG_CUDA_COMPILER_PATH\"\n-_TF_SYSROOT = \"TF_SYSROOT\"\n-_CUDA_TOOLKIT_PATH = \"CUDA_TOOLKIT_PATH\"\n-_TF_CUDA_VERSION = \"TF_CUDA_VERSION\"\n-_TF_CUDNN_VERSION = \"TF_CUDNN_VERSION\"\n-_CUDNN_INSTALL_PATH = \"CUDNN_INSTALL_PATH\"\n-_TF_CUDA_COMPUTE_CAPABILITIES = \"TF_CUDA_COMPUTE_CAPABILITIES\"\n-_TF_CUDA_CONFIG_REPO = \"TF_CUDA_CONFIG_REPO\"\n-_TF_DOWNLOAD_CLANG = \"TF_DOWNLOAD_CLANG\"\n-_PYTHON_BIN_PATH = \"PYTHON_BIN_PATH\"\n-_TMPDIR = \"TMPDIR\"\n-\n-def verify_build_defines(params):\n-    \"\"\"Verify all variables that crosstool/BUILD.tpl expects are substituted.\n-\n-    Args:\n-      params: dict of variables that will be passed to the BUILD.tpl template.\n-    \"\"\"\n-    missing = []\n-    for param in [\n-        \"cxx_builtin_include_directories\",\n-        \"extra_no_canonical_prefixes_flags\",\n-        \"host_compiler_path\",\n-        \"host_compiler_prefix\",\n-        \"host_compiler_warnings\",\n-        \"linker_bin_path\",\n-        \"compiler_deps\",\n-        \"msvc_cl_path\",\n-        \"msvc_env_include\",\n-        \"msvc_env_lib\",\n-        \"msvc_env_path\",\n-        \"msvc_env_tmp\",\n-        \"msvc_lib_path\",\n-        \"msvc_link_path\",\n-        \"msvc_ml_path\",\n-        \"unfiltered_compile_flags\",\n-        \"win_compiler_deps\",\n-    ]:\n-        if (\"%{\" + param + \"}\") not in params:\n-            missing.append(param)\n-\n-    if missing:\n-        auto_configure_fail(\n-            \"BUILD.tpl template is missing these variables: \" +\n-            str(missing) +\n-            \".\\nWe only got: \" +\n-            str(params) +\n-            \".\",\n-        )\n-\n-def _get_nvcc_tmp_dir_for_windows(repository_ctx):\n-    \"\"\"Return the Windows tmp directory for nvcc to generate intermediate source files.\"\"\"\n-    escaped_tmp_dir = escape_string(\n-        get_env_var(repository_ctx, \"TMP\", \"C:\\\\Windows\\\\Temp\").replace(\n-            \"\\\\\",\n-            \"\\\\\\\\\",\n-        ),\n-    )\n-    return escaped_tmp_dir + \"\\\\\\\\nvcc_inter_files_tmp_dir\"\n-\n-def _get_msvc_compiler(repository_ctx):\n-    vc_path = find_vc_path(repository_ctx)\n-    return find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\n-\n-def _get_win_cuda_defines(repository_ctx):\n-    \"\"\"Return CROSSTOOL defines for Windows\"\"\"\n-\n-    # If we are not on Windows, return fake vaules for Windows specific fields.\n-    # This ensures the CROSSTOOL file parser is happy.\n-    if not is_windows(repository_ctx):\n-        return {\n-            \"%{msvc_env_tmp}\": \"msvc_not_used\",\n-            \"%{msvc_env_path}\": \"msvc_not_used\",\n-            \"%{msvc_env_include}\": \"msvc_not_used\",\n-            \"%{msvc_env_lib}\": \"msvc_not_used\",\n-            \"%{msvc_cl_path}\": \"msvc_not_used\",\n-            \"%{msvc_ml_path}\": \"msvc_not_used\",\n-            \"%{msvc_link_path}\": \"msvc_not_used\",\n-            \"%{msvc_lib_path}\": \"msvc_not_used\",\n-        }\n-\n-    vc_path = find_vc_path(repository_ctx)\n-    if not vc_path:\n-        auto_configure_fail(\n-            \"Visual C++ build tools not found on your machine.\" +\n-            \"Please check your installation following https://docs.bazel.build/versions/master/windows.html#using\",\n-        )\n-        return {}\n-\n-    env = setup_vc_env_vars(repository_ctx, vc_path)\n-    escaped_paths = escape_string(env[\"PATH\"])\n-    escaped_include_paths = escape_string(env[\"INCLUDE\"])\n-    escaped_lib_paths = escape_string(env[\"LIB\"])\n-    escaped_tmp_dir = escape_string(\n-        get_env_var(repository_ctx, \"TMP\", \"C:\\\\Windows\\\\Temp\").replace(\n-            \"\\\\\",\n-            \"\\\\\\\\\",\n-        ),\n-    )\n-\n-    msvc_cl_path = \"windows/msvc_wrapper_for_nvcc.bat\"\n-    msvc_ml_path = find_msvc_tool(repository_ctx, vc_path, \"ml64.exe\").replace(\n-        \"\\\\\",\n-        \"/\",\n-    )\n-    msvc_link_path = find_msvc_tool(repository_ctx, vc_path, \"link.exe\").replace(\n-        \"\\\\\",\n-        \"/\",\n-    )\n-    msvc_lib_path = find_msvc_tool(repository_ctx, vc_path, \"lib.exe\").replace(\n-        \"\\\\\",\n-        \"/\",\n-    )\n-\n-    # nvcc will generate some temporary source files under %{nvcc_tmp_dir}\n-    # The generated files are guaranteed to have unique name, so they can share\n-    # the same tmp directory\n-    escaped_cxx_include_directories = [\n-        _get_nvcc_tmp_dir_for_windows(repository_ctx),\n-        \"C:\\\\\\\\botcode\\\\\\\\w\",\n-    ]\n-    for path in escaped_include_paths.split(\";\"):\n-        if path:\n-            escaped_cxx_include_directories.append(path)\n-\n-    return {\n-        \"%{msvc_env_tmp}\": escaped_tmp_dir,\n-        \"%{msvc_env_path}\": escaped_paths,\n-        \"%{msvc_env_include}\": escaped_include_paths,\n-        \"%{msvc_env_lib}\": escaped_lib_paths,\n-        \"%{msvc_cl_path}\": msvc_cl_path,\n-        \"%{msvc_ml_path}\": msvc_ml_path,\n-        \"%{msvc_link_path}\": msvc_link_path,\n-        \"%{msvc_lib_path}\": msvc_lib_path,\n-        \"%{cxx_builtin_include_directories}\": to_list_of_strings(\n-            escaped_cxx_include_directories,\n-        ),\n-    }\n-\n-# TODO(dzc): Once these functions have been factored out of Bazel's\n-# cc_configure.bzl, load them from @bazel_tools instead.\n-# BEGIN cc_configure common functions.\n-def find_cc(repository_ctx, use_cuda_clang):\n-    \"\"\"Find the C++ compiler.\"\"\"\n-    if is_windows(repository_ctx):\n-        return _get_msvc_compiler(repository_ctx)\n-\n-    if use_cuda_clang:\n-        target_cc_name = \"clang\"\n-        cc_path_envvar = _CLANG_CUDA_COMPILER_PATH\n-        if _flag_enabled(repository_ctx, _TF_DOWNLOAD_CLANG):\n-            return \"extra_tools/bin/clang\"\n-    else:\n-        target_cc_name = \"gcc\"\n-        cc_path_envvar = _GCC_HOST_COMPILER_PATH\n-    cc_name = target_cc_name\n-\n-    cc_name_from_env = get_host_environ(repository_ctx, cc_path_envvar)\n-    if cc_name_from_env:\n-        cc_name = cc_name_from_env\n-    if cc_name.startswith(\"/\"):\n-        # Absolute path, maybe we should make this supported by our which function.\n-        return cc_name\n-    cc = which(repository_ctx, cc_name)\n-    if cc == None:\n-        fail((\"Cannot find {}, either correct your path or set the {}\" +\n-              \" environment variable\").format(target_cc_name, cc_path_envvar))\n-    return cc\n-\n def auto_configure_fail(msg):\n     \"\"\"Output failure message when cuda configuration fails.\"\"\"\n     red = \"\\033[0;31m\"\n     no_color = \"\\033[0m\"\n     fail(\"\\n%sCuda Configuration Error:%s %s\\n\" % (red, no_color, msg))\n \n-# END cc_configure common functions (see TODO above).\n-\n-def _cuda_include_path(repository_ctx, cuda_config):\n-    \"\"\"Generates the Starlark string with cuda include directories.\n-\n-      Args:\n-        repository_ctx: The repository context.\n-        cc: The path to the gcc host compiler.\n-\n-      Returns:\n-        A list of the gcc host compiler include directories.\n-      \"\"\"\n-    nvcc_path = repository_ctx.path(\"%s/bin/nvcc%s\" % (\n-        cuda_config.cuda_toolkit_path,\n-        \".exe\" if cuda_config.cpu_value == \"Windows\" else \"\",\n-    ))\n-\n-    # The expected exit code of this command is non-zero. Bazel remote execution\n-    # only caches commands with zero exit code. So force a zero exit code.\n-    cmd = \"%s -v /dev/null -o /dev/null ; [ $? -eq 1 ]\" % str(nvcc_path)\n-    result = raw_exec(repository_ctx, [get_bash_bin(repository_ctx), \"-c\", cmd])\n-    target_dir = \"\"\n-    for one_line in err_out(result).splitlines():\n-        if one_line.startswith(\"#$ _TARGET_DIR_=\"):\n-            target_dir = (\n-                cuda_config.cuda_toolkit_path + \"/\" + one_line.replace(\n-                    \"#$ _TARGET_DIR_=\",\n-                    \"\",\n-                ) + \"/include\"\n-            )\n-    inc_entries = []\n-    if target_dir != \"\":\n-        inc_entries.append(realpath(repository_ctx, target_dir))\n-    inc_entries.append(realpath(repository_ctx, cuda_config.cuda_toolkit_path + \"/include\"))\n-    return inc_entries\n-\n def enable_cuda(repository_ctx):\n     \"\"\"Returns whether to build with CUDA support.\"\"\"\n     return int(get_host_environ(repository_ctx, \"TF_NEED_CUDA\", False))\n \n-def matches_version(environ_version, detected_version):\n-    \"\"\"Checks whether the user-specified version matches the detected version.\n-\n-      This function performs a weak matching so that if the user specifies only\n-      the\n-      major or major and minor versions, the versions are still considered\n-      matching\n-      if the version parts match. To illustrate:\n-\n-          environ_version  detected_version  result\n-          -----------------------------------------\n-          5.1.3            5.1.3             True\n-          5.1              5.1.3             True\n-          5                5.1               True\n-          5.1.3            5.1               False\n-          5.2.3            5.1.3             False\n-\n-      Args:\n-        environ_version: The version specified by the user via environment\n-          variables.\n-        detected_version: The version autodetected from the CUDA installation on\n-          the system.\n-      Returns: True if user-specified version matches detected version and False\n-        otherwise.\n-    \"\"\"\n-    environ_version_parts = environ_version.split(\".\")\n-    detected_version_parts = detected_version.split(\".\")\n-    if len(detected_version_parts) < len(environ_version_parts):\n-        return False\n-    for i, part in enumerate(detected_version_parts):\n-        if i >= len(environ_version_parts):\n-            break\n-        if part != environ_version_parts[i]:\n-            return False\n-    return True\n-\n-_NVCC_VERSION_PREFIX = \"Cuda compilation tools, release \"\n-\n-_DEFINE_CUDNN_MAJOR = \"#define CUDNN_MAJOR\"\n-\n-def compute_capabilities(repository_ctx):\n-    \"\"\"Returns a list of strings representing cuda compute capabilities.\n-\n-    Args:\n-      repository_ctx: the repo rule's context.\n-    Returns: list of cuda architectures to compile for. 'compute_xy' refers to\n-      both PTX and SASS, 'sm_xy' refers to SASS only.\n-    \"\"\"\n-    capabilities = get_host_environ(\n-        repository_ctx,\n-        _TF_CUDA_COMPUTE_CAPABILITIES,\n-        \"compute_35,compute_52\",\n-    ).split(\",\")\n-\n-    # Map old 'x.y' capabilities to 'compute_xy'.\n-    if len(capabilities) > 0 and all([len(x.split(\".\")) == 2 for x in capabilities]):\n-        # If all capabilities are in 'x.y' format, only include PTX for the\n-        # highest capability.\n-        cc_list = sorted([x.replace(\".\", \"\") for x in capabilities])\n-        capabilities = [\"sm_%s\" % x for x in cc_list[:-1]] + [\"compute_%s\" % cc_list[-1]]\n-    for i, capability in enumerate(capabilities):\n-        parts = capability.split(\".\")\n-        if len(parts) != 2:\n-            continue\n-        capabilities[i] = \"compute_%s%s\" % (parts[0], parts[1])\n-\n-    # Make list unique\n-    capabilities = dict(zip(capabilities, capabilities)).keys()\n-\n-    # Validate capabilities.\n-    for capability in capabilities:\n-        if not capability.startswith((\"compute_\", \"sm_\")):\n-            auto_configure_fail(\"Invalid compute capability: %s\" % capability)\n-        for prefix in [\"compute_\", \"sm_\"]:\n-            if not capability.startswith(prefix):\n-                continue\n-            if len(capability) == len(prefix) + 2 and capability[-2:].isdigit():\n-                continue\n-            if len(capability) == len(prefix) + 3 and capability.endswith(\"90a\"):\n-                continue\n-            auto_configure_fail(\"Invalid compute capability: %s\" % capability)\n-\n-    return capabilities\n-\n def lib_name(base_name, cpu_value, version = None, static = False):\n     \"\"\"Constructs the platform-specific name of a library.\n \n@@ -390,147 +75,6 @@ def lib_name(base_name, cpu_value, version = None, static = False):\n     else:\n         auto_configure_fail(\"Invalid cpu_value: %s\" % cpu_value)\n \n-def _lib_path(lib, cpu_value, basedir, version, static):\n-    file_name = lib_name(lib, cpu_value, version, static)\n-    return \"%s/%s\" % (basedir, file_name)\n-\n-def _should_check_soname(version, static):\n-    return version and not static\n-\n-def _check_cuda_lib_params(lib, cpu_value, basedir, version, static = False):\n-    return (\n-        _lib_path(lib, cpu_value, basedir, version, static),\n-        _should_check_soname(version, static),\n-    )\n-\n-def _check_cuda_libs(repository_ctx, script_path, libs):\n-    python_bin = get_python_bin(repository_ctx)\n-    contents = repository_ctx.read(script_path).splitlines()\n-\n-    cmd = \"from os import linesep;\"\n-    cmd += \"f = open('script.py', 'w');\"\n-    for line in contents:\n-        cmd += \"f.write('%s' + linesep);\" % line\n-    cmd += \"f.close();\"\n-    cmd += \"from os import system;\"\n-    args = \" \".join([\"\\\"\" + path + \"\\\" \" + str(check) for path, check in libs])\n-    cmd += \"system('%s script.py %s');\" % (python_bin, args)\n-\n-    all_paths = [path for path, _ in libs]\n-    checked_paths = execute(repository_ctx, [python_bin, \"-c\", cmd]).stdout.splitlines()\n-\n-    # Filter out empty lines from splitting on '\\r\\n' on Windows\n-    checked_paths = [path for path in checked_paths if len(path) > 0]\n-    if all_paths != checked_paths:\n-        auto_configure_fail(\"Error with installed CUDA libs. Expected '%s'. Actual '%s'.\" % (all_paths, checked_paths))\n-\n-def _find_libs(repository_ctx, check_cuda_libs_script, cuda_config):\n-    \"\"\"Returns the CUDA and cuDNN libraries on the system.\n-\n-      Also, verifies that the script actually exist.\n-\n-      Args:\n-        repository_ctx: The repository context.\n-        check_cuda_libs_script: The path to a script verifying that the cuda\n-          libraries exist on the system.\n-        cuda_config: The CUDA config as returned by _get_cuda_config\n-\n-      Returns:\n-        Map of library names to structs of filename and path.\n-      \"\"\"\n-    cpu_value = cuda_config.cpu_value\n-    stub_dir = \"\" if is_windows(repository_ctx) else \"/stubs\"\n-\n-    check_cuda_libs_params = {\n-        \"cuda\": _check_cuda_lib_params(\n-            \"cuda\",\n-            cpu_value,\n-            cuda_config.config[\"cuda_library_dir\"] + stub_dir,\n-            version = None,\n-            static = False,\n-        ),\n-        \"cudart\": _check_cuda_lib_params(\n-            \"cudart\",\n-            cpu_value,\n-            cuda_config.config[\"cuda_library_dir\"],\n-            cuda_config.cudart_version,\n-            static = False,\n-        ),\n-        \"cudart_static\": _check_cuda_lib_params(\n-            \"cudart_static\",\n-            cpu_value,\n-            cuda_config.config[\"cuda_library_dir\"],\n-            cuda_config.cudart_version,\n-            static = True,\n-        ),\n-        \"cublas\": _check_cuda_lib_params(\n-            \"cublas\",\n-            cpu_value,\n-            cuda_config.config[\"cublas_library_dir\"],\n-            cuda_config.cublas_version,\n-            static = False,\n-        ),\n-        \"cublasLt\": _check_cuda_lib_params(\n-            \"cublasLt\",\n-            cpu_value,\n-            cuda_config.config[\"cublas_library_dir\"],\n-            cuda_config.cublas_version,\n-            static = False,\n-        ),\n-        \"cusolver\": _check_cuda_lib_params(\n-            \"cusolver\",\n-            cpu_value,\n-            cuda_config.config[\"cusolver_library_dir\"],\n-            cuda_config.cusolver_version,\n-            static = False,\n-        ),\n-        \"curand\": _check_cuda_lib_params(\n-            \"curand\",\n-            cpu_value,\n-            cuda_config.config[\"curand_library_dir\"],\n-            cuda_config.curand_version,\n-            static = False,\n-        ),\n-        \"cufft\": _check_cuda_lib_params(\n-            \"cufft\",\n-            cpu_value,\n-            cuda_config.config[\"cufft_library_dir\"],\n-            cuda_config.cufft_version,\n-            static = False,\n-        ),\n-        \"cudnn\": _check_cuda_lib_params(\n-            \"cudnn\",\n-            cpu_value,\n-            cuda_config.config[\"cudnn_library_dir\"],\n-            cuda_config.cudnn_version,\n-            static = False,\n-        ),\n-        \"cupti\": _check_cuda_lib_params(\n-            \"cupti\",\n-            cpu_value,\n-            cuda_config.config[\"cupti_library_dir\"],\n-            cuda_config.cupti_version,\n-            static = False,\n-        ),\n-        \"cusparse\": _check_cuda_lib_params(\n-            \"cusparse\",\n-            cpu_value,\n-            cuda_config.config[\"cusparse_library_dir\"],\n-            cuda_config.cusparse_version,\n-            static = False,\n-        ),\n-    }\n-\n-    # Verify that the libs actually exist at their locations.\n-    _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())\n-\n-    paths = {filename: v[0] for (filename, v) in check_cuda_libs_params.items()}\n-    return paths\n-\n-def _cudart_static_linkopt(cpu_value):\n-    \"\"\"Returns additional platform-specific linkopts for cudart.\"\"\"\n-    return \"\" if cpu_value == \"Darwin\" else \"\\\"-lrt\\\",\"\n-\n # TODO(csigg): Only call once instead of from here, tensorrt_configure.bzl,\n # and nccl_configure.bzl.\n def find_cuda_config(repository_ctx, cuda_libraries):\n@@ -543,232 +87,6 @@ def find_cuda_config(repository_ctx, cuda_libraries):\n     # Parse the dict from stdout.\n     return dict([tuple(x.split(\": \")) for x in exec_result.stdout.splitlines()])\n \n-def _get_cuda_config(repository_ctx):\n-    \"\"\"Detects and returns information about the CUDA installation on the system.\n-\n-      Args:\n-        repository_ctx: The repository context.\n-\n-      Returns:\n-        A struct containing the following fields:\n-          cuda_toolkit_path: The CUDA toolkit installation directory.\n-          cudnn_install_basedir: The cuDNN installation directory.\n-          cuda_version: The version of CUDA on the system.\n-          cudart_version: The CUDA runtime version on the system.\n-          cudnn_version: The version of cuDNN on the system.\n-          compute_capabilities: A list of the system's CUDA compute capabilities.\n-          cpu_value: The name of the host operating system.\n-      \"\"\"\n-    config = find_cuda_config(repository_ctx, [\"cuda\", \"cudnn\"])\n-    cpu_value = get_cpu_value(repository_ctx)\n-    toolkit_path = config[\"cuda_toolkit_path\"]\n-\n-    is_windows = cpu_value == \"Windows\"\n-    cuda_version = config[\"cuda_version\"].split(\".\")\n-    cuda_major = cuda_version[0]\n-    cuda_minor = cuda_version[1]\n-\n-    cuda_version = (\"64_%s%s\" if is_windows else \"%s.%s\") % (cuda_major, cuda_minor)\n-    cudnn_version = (\"64_%s\" if is_windows else \"%s\") % config[\"cudnn_version\"]\n-\n-    if int(cuda_major) >= 11:\n-        # The libcudart soname in CUDA 11.x is versioned as 11.0 for backward compatability.\n-        if int(cuda_major) == 11:\n-            cudart_version = \"64_110\" if is_windows else \"11.0\"\n-            cupti_version = cuda_version\n-        else:\n-            cudart_version = (\"64_%s\" if is_windows else \"%s\") % cuda_major\n-            cupti_version = cudart_version\n-        cublas_version = (\"64_%s\" if is_windows else \"%s\") % config[\"cublas_version\"].split(\".\")[0]\n-        cusolver_version = (\"64_%s\" if is_windows else \"%s\") % config[\"cusolver_version\"].split(\".\")[0]\n-        curand_version = (\"64_%s\" if is_windows else \"%s\") % config[\"curand_version\"].split(\".\")[0]\n-        cufft_version = (\"64_%s\" if is_windows else \"%s\") % config[\"cufft_version\"].split(\".\")[0]\n-        cusparse_version = (\"64_%s\" if is_windows else \"%s\") % config[\"cusparse_version\"].split(\".\")[0]\n-    elif (int(cuda_major), int(cuda_minor)) >= (10, 1):\n-        # cuda_lib_version is for libraries like cuBLAS, cuFFT, cuSOLVER, etc.\n-        # It changed from 'x.y' to just 'x' in CUDA 10.1.\n-        cuda_lib_version = (\"64_%s\" if is_windows else \"%s\") % cuda_major\n-        cudart_version = cuda_version\n-        cupti_version = cuda_version\n-        cublas_version = cuda_lib_version\n-        cusolver_version = cuda_lib_version\n-        curand_version = cuda_lib_version\n-        cufft_version = cuda_lib_version\n-        cusparse_version = cuda_lib_version\n-    else:\n-        cudart_version = cuda_version\n-        cupti_version = cuda_version\n-        cublas_version = cuda_version\n-        cusolver_version = cuda_version\n-        curand_version = cuda_version\n-        cufft_version = cuda_version\n-        cusparse_version = cuda_version\n-\n-    return struct(\n-        cuda_toolkit_path = toolkit_path,\n-        cuda_version = cuda_version,\n-        cupti_version = cupti_version,\n-        cuda_version_major = cuda_major,\n-        cudart_version = cudart_version,\n-        cublas_version = cublas_version,\n-        cusolver_version = cusolver_version,\n-        curand_version = curand_version,\n-        cufft_version = cufft_version,\n-        cusparse_version = cusparse_version,\n-        cudnn_version = cudnn_version,\n-        compute_capabilities = compute_capabilities(repository_ctx),\n-        cpu_value = cpu_value,\n-        config = config,\n-    )\n-\n-def _tpl(repository_ctx, tpl, substitutions = {}, out = None):\n-    if not out:\n-        out = tpl.replace(\":\", \"/\")\n-    repository_ctx.template(\n-        out,\n-        Label(\"//third_party/gpus/%s.tpl\" % tpl),\n-        substitutions,\n-    )\n-\n-def _file(repository_ctx, label):\n-    repository_ctx.template(\n-        label.replace(\":\", \"/\"),\n-        Label(\"//third_party/gpus/%s.tpl\" % label),\n-        {},\n-    )\n-\n-_DUMMY_CROSSTOOL_BZL_FILE = \"\"\"\n-def error_gpu_disabled():\n-  fail(\"ERROR: Building with --config=cuda but TensorFlow is not configured \" +\n-       \"to build with GPU support. Please re-run ./configure and enter 'Y' \" +\n-       \"at the prompt to build with GPU support.\")\n-\n-  native.genrule(\n-      name = \"error_gen_crosstool\",\n-      outs = [\"CROSSTOOL\"],\n-      cmd = \"echo 'Should not be run.' && exit 1\",\n-  )\n-\n-  native.filegroup(\n-      name = \"crosstool\",\n-      srcs = [\":CROSSTOOL\"],\n-      output_licenses = [\"unencumbered\"],\n-  )\n-\"\"\"\n-\n-_DUMMY_CROSSTOOL_BUILD_FILE = \"\"\"\n-load(\"//crosstool:error_gpu_disabled.bzl\", \"error_gpu_disabled\")\n-\n-error_gpu_disabled()\n-\"\"\"\n-\n-def _create_dummy_repository(repository_ctx):\n-    cpu_value = get_cpu_value(repository_ctx)\n-\n-    # Set up BUILD file for cuda/.\n-    _tpl(\n-        repository_ctx,\n-        \"cuda:build_defs.bzl\",\n-        {\n-            \"%{cuda_is_configured}\": \"False\",\n-            \"%{cuda_extra_copts}\": \"[]\",\n-            \"%{cuda_gpu_architectures}\": \"[]\",\n-            \"%{cuda_version}\": \"0.0\",\n-        },\n-    )\n-    _tpl(\n-        repository_ctx,\n-        \"cuda:BUILD\",\n-        {\n-            \"%{cuda_driver_lib}\": lib_name(\"cuda\", cpu_value),\n-            \"%{cudart_static_lib}\": lib_name(\n-                \"cudart_static\",\n-                cpu_value,\n-                static = True,\n-            ),\n-            \"%{cudart_static_linkopt}\": _cudart_static_linkopt(cpu_value),\n-            \"%{cudart_lib}\": lib_name(\"cudart\", cpu_value),\n-            \"%{cublas_lib}\": lib_name(\"cublas\", cpu_value),\n-            \"%{cublasLt_lib}\": lib_name(\"cublasLt\", cpu_value),\n-            \"%{cusolver_lib}\": lib_name(\"cusolver\", cpu_value),\n-            \"%{cudnn_lib}\": lib_name(\"cudnn\", cpu_value),\n-            \"%{cufft_lib}\": lib_name(\"cufft\", cpu_value),\n-            \"%{curand_lib}\": lib_name(\"curand\", cpu_value),\n-            \"%{cupti_lib}\": lib_name(\"cupti\", cpu_value),\n-            \"%{cusparse_lib}\": lib_name(\"cusparse\", cpu_value),\n-            \"%{cub_actual}\": \":cuda_headers\",\n-            \"%{copy_rules}\": \"\"\"\n-filegroup(name=\"cuda-include\")\n-filegroup(name=\"cublas-include\")\n-filegroup(name=\"cusolver-include\")\n-filegroup(name=\"cufft-include\")\n-filegroup(name=\"cusparse-include\")\n-filegroup(name=\"curand-include\")\n-filegroup(name=\"cudnn-include\")\n-\"\"\",\n-        },\n-    )\n-\n-    # Create dummy files for the CUDA toolkit since they are still required by\n-    # tensorflow/compiler/xla/tsl/platform/default/build_config:cuda.\n-    repository_ctx.file(\"cuda/cuda/include/cuda.h\")\n-    repository_ctx.file(\"cuda/cuda/include/cublas.h\")\n-    repository_ctx.file(\"cuda/cuda/include/cudnn.h\")\n-    repository_ctx.file(\"cuda/cuda/extras/CUPTI/include/cupti.h\")\n-    repository_ctx.file(\"cuda/cuda/nvml/include/nvml.h\")\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cuda\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cudart\", cpu_value))\n-    repository_ctx.file(\n-        \"cuda/cuda/lib/%s\" % lib_name(\"cudart_static\", cpu_value),\n-    )\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cublas\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cublasLt\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cusolver\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cudnn\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"curand\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cufft\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cupti\", cpu_value))\n-    repository_ctx.file(\"cuda/cuda/lib/%s\" % lib_name(\"cusparse\", cpu_value))\n-\n-    # Set up cuda_config.h, which is used by\n-    # tensorflow/compiler/xla/stream_executor/dso_loader.cc.\n-    _tpl(\n-        repository_ctx,\n-        \"cuda:cuda_config.h\",\n-        {\n-            \"%{cuda_version}\": \"\",\n-            \"%{cudart_version}\": \"\",\n-            \"%{cupti_version}\": \"\",\n-            \"%{cublas_version}\": \"\",\n-            \"%{cusolver_version}\": \"\",\n-            \"%{curand_version}\": \"\",\n-            \"%{cufft_version}\": \"\",\n-            \"%{cusparse_version}\": \"\",\n-            \"%{cudnn_version}\": \"\",\n-            \"%{cuda_toolkit_path}\": \"\",\n-            \"%{cuda_compute_capabilities}\": \"\",\n-        },\n-        \"cuda/cuda/cuda_config.h\",\n-    )\n-\n-    # Set up cuda_config.py, which is used by gen_build_info to provide\n-    # static build environment info to the API\n-    _tpl(\n-        repository_ctx,\n-        \"cuda:cuda_config.py\",\n-        _py_tmpl_dict({}),\n-        \"cuda/cuda/cuda_config.py\",\n-    )\n-\n-    # If cuda_configure is not configured to build with GPU support, and the user\n-    # attempts to build with --config=cuda, add a dummy build rule to intercept\n-    # this and fail with an actionable error message.\n-    repository_ctx.file(\n-        \"crosstool/error_gpu_disabled.bzl\",\n-        _DUMMY_CROSSTOOL_BZL_FILE,\n-    )\n-    repository_ctx.file(\"crosstool/BUILD\", _DUMMY_CROSSTOOL_BUILD_FILE)\n-\n def _norm_path(path):\n     \"\"\"Returns a path with '/' and remove the trailing slash.\"\"\"\n     path = path.replace(\"\\\\\", \"/\")\n@@ -821,589 +139,3 @@ def make_copy_dir_rule(repository_ctx, name, src_dir, out_dir, exceptions = None\n     ],\n     cmd = \\\"\"\"cp -rLf \"%s/.\" \"%s/\" %s\\\"\"\",\n )\"\"\" % (name, \"\\n\".join(outs), src_dir, out_dir, post_cmd)\n-\n-def _flag_enabled(repository_ctx, flag_name):\n-    return get_host_environ(repository_ctx, flag_name) == \"1\"\n-\n-def _use_cuda_clang(repository_ctx):\n-    # Returns the flag if we need to use clang both for C++ and Cuda.\n-    return _flag_enabled(repository_ctx, \"TF_CUDA_CLANG\")\n-\n-def _use_nvcc_and_clang(repository_ctx):\n-    # Returns the flag if we need to use clang for C++ and NVCC for Cuda.\n-    return _flag_enabled(repository_ctx, \"TF_NVCC_CLANG\")\n-\n-def _tf_sysroot(repository_ctx):\n-    return get_host_environ(repository_ctx, _TF_SYSROOT, \"\")\n-\n-def _compute_cuda_extra_copts(repository_ctx, compute_capabilities):\n-    copts = [\"--no-cuda-include-ptx=all\"] if _use_cuda_clang(repository_ctx) else []\n-    for capability in compute_capabilities:\n-        if capability.startswith(\"compute_\"):\n-            capability = capability.replace(\"compute_\", \"sm_\")\n-            copts.append(\"--cuda-include-ptx=%s\" % capability)\n-        copts.append(\"--cuda-gpu-arch=%s\" % capability)\n-\n-    return str(copts)\n-\n-def _tpl_path(repository_ctx, filename):\n-    return repository_ctx.path(Label(\"//third_party/gpus/%s.tpl\" % filename))\n-\n-def _basename(repository_ctx, path_str):\n-    \"\"\"Returns the basename of a path of type string.\n-\n-    This method is different from path.basename in that it also works if\n-    the host platform is different from the execution platform\n-    i.e. linux -> windows.\n-    \"\"\"\n-\n-    num_chars = len(path_str)\n-    is_win = is_windows(repository_ctx)\n-    for i in range(num_chars):\n-        r_i = num_chars - 1 - i\n-        if (is_win and path_str[r_i] == \"\\\\\") or path_str[r_i] == \"/\":\n-            return path_str[r_i + 1:]\n-    return path_str\n-\n-def _create_local_cuda_repository(repository_ctx):\n-    \"\"\"Creates the repository containing files set up to build with CUDA.\"\"\"\n-\n-    # Resolve all labels before doing any real work. Resolving causes the\n-    # function to be restarted with all previous state being lost. This\n-    # can easily lead to a O(n^2) runtime in the number of labels.\n-    # See https://github.com/tensorflow/tensorflow/commit/62bd3534525a036f07d9851b3199d68212904778\n-    tpl_paths = {filename: _tpl_path(repository_ctx, filename) for filename in [\n-        \"cuda:build_defs.bzl\",\n-        \"crosstool:clang/bin/crosstool_wrapper_driver_is_not_gcc\",\n-        \"crosstool:windows/msvc_wrapper_for_nvcc.py\",\n-        \"crosstool:BUILD\",\n-        \"crosstool:cc_toolchain_config.bzl\",\n-        \"cuda:cuda_config.h\",\n-        \"cuda:cuda_config.py\",\n-    ]}\n-    tpl_paths[\"cuda:BUILD\"] = _tpl_path(repository_ctx, \"cuda:BUILD.windows\" if is_windows(repository_ctx) else \"cuda:BUILD\")\n-\n-    cuda_config = _get_cuda_config(repository_ctx)\n-\n-    cuda_include_path = cuda_config.config[\"cuda_include_dir\"]\n-    cublas_include_path = cuda_config.config[\"cublas_include_dir\"]\n-    cudnn_header_dir = cuda_config.config[\"cudnn_include_dir\"]\n-    cupti_header_dir = cuda_config.config[\"cupti_include_dir\"]\n-    nvvm_libdevice_dir = cuda_config.config[\"nvvm_library_dir\"]\n-    nvml_header_dir = cuda_config.config[\"nvml_header_dir\"]\n-\n-    # Create genrule to copy files from the installed CUDA toolkit into execroot.\n-    copy_rules = [\n-        make_copy_dir_rule(\n-            repository_ctx,\n-            name = \"cuda-include\",\n-            src_dir = cuda_include_path,\n-            out_dir = \"cuda/include\",\n-        ),\n-        make_copy_dir_rule(\n-            repository_ctx,\n-            name = \"cuda-nvvm\",\n-            src_dir = nvvm_libdevice_dir,\n-            out_dir = \"cuda/nvvm/libdevice\",\n-        ),\n-        make_copy_dir_rule(\n-            repository_ctx,\n-            name = \"cuda-extras\",\n-            src_dir = cupti_header_dir,\n-            out_dir = \"cuda/extras/CUPTI/include\",\n-        ),\n-        make_copy_dir_rule(\n-            repository_ctx,\n-            name = \"nvml\",\n-            src_dir = nvml_header_dir,\n-            out_dir = \"cuda/nvml/include\",\n-        ),\n-    ]\n-\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cublas-include\",\n-        srcs = [\n-            cublas_include_path + \"/cublas.h\",\n-            cublas_include_path + \"/cublas_v2.h\",\n-            cublas_include_path + \"/cublas_api.h\",\n-            cublas_include_path + \"/cublasLt.h\",\n-        ],\n-        outs = [\n-            \"cublas/include/cublas.h\",\n-            \"cublas/include/cublas_v2.h\",\n-            \"cublas/include/cublas_api.h\",\n-            \"cublas/include/cublasLt.h\",\n-        ],\n-    ))\n-\n-    cusolver_include_path = cuda_config.config[\"cusolver_include_dir\"]\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cusolver-include\",\n-        srcs = [\n-            cusolver_include_path + \"/cusolver_common.h\",\n-            cusolver_include_path + \"/cusolverDn.h\",\n-        ],\n-        outs = [\n-            \"cusolver/include/cusolver_common.h\",\n-            \"cusolver/include/cusolverDn.h\",\n-        ],\n-    ))\n-\n-    cufft_include_path = cuda_config.config[\"cufft_include_dir\"]\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cufft-include\",\n-        srcs = [\n-            cufft_include_path + \"/cufft.h\",\n-        ],\n-        outs = [\n-            \"cufft/include/cufft.h\",\n-        ],\n-    ))\n-\n-    cusparse_include_path = cuda_config.config[\"cusparse_include_dir\"]\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cusparse-include\",\n-        srcs = [\n-            cusparse_include_path + \"/cusparse.h\",\n-        ],\n-        outs = [\n-            \"cusparse/include/cusparse.h\",\n-        ],\n-    ))\n-\n-    curand_include_path = cuda_config.config[\"curand_include_dir\"]\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"curand-include\",\n-        srcs = [\n-            curand_include_path + \"/curand.h\",\n-        ],\n-        outs = [\n-            \"curand/include/curand.h\",\n-        ],\n-    ))\n-\n-    check_cuda_libs_script = repository_ctx.path(Label(\"@local_xla//third_party/gpus:check_cuda_libs.py\"))\n-    cuda_libs = _find_libs(repository_ctx, check_cuda_libs_script, cuda_config)\n-    cuda_lib_srcs = []\n-    cuda_lib_outs = []\n-    for path in cuda_libs.values():\n-        cuda_lib_srcs.append(path)\n-        cuda_lib_outs.append(\"cuda/lib/\" + _basename(repository_ctx, path))\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cuda-lib\",\n-        srcs = cuda_lib_srcs,\n-        outs = cuda_lib_outs,\n-    ))\n-\n-    # copy files mentioned in third_party/nccl/build_defs.bzl.tpl\n-    file_ext = \".exe\" if is_windows(repository_ctx) else \"\"\n-    bin_files = (\n-        [\"crt/link.stub\"] +\n-        [f + file_ext for f in [\"bin2c\", \"fatbinary\", \"nvlink\", \"nvprune\"]]\n-    )\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cuda-bin\",\n-        srcs = [cuda_config.cuda_toolkit_path + \"/bin/\" + f for f in bin_files],\n-        outs = [\"cuda/bin/\" + f for f in bin_files],\n-    ))\n-\n-    # Select the headers based on the cuDNN version (strip '64_' for Windows).\n-    cudnn_headers = [\"cudnn.h\"]\n-    if cuda_config.cudnn_version.rsplit(\"_\", 1)[-1] >= \"9\":\n-        cudnn_headers += [\n-            \"cudnn_adv.h\",\n-            \"cudnn_backend.h\",\n-            \"cudnn_cnn.h\",\n-            \"cudnn_graph.h\",\n-            \"cudnn_ops.h\",\n-            \"cudnn_version.h\",\n-        ]\n-    elif cuda_config.cudnn_version.rsplit(\"_\", 1)[-1] >= \"8\":\n-        cudnn_headers += [\n-            \"cudnn_backend.h\",\n-            \"cudnn_adv_infer.h\",\n-            \"cudnn_adv_train.h\",\n-            \"cudnn_cnn_infer.h\",\n-            \"cudnn_cnn_train.h\",\n-            \"cudnn_ops_infer.h\",\n-            \"cudnn_ops_train.h\",\n-            \"cudnn_version.h\",\n-        ]\n-\n-    cudnn_srcs = []\n-    cudnn_outs = []\n-    for header in cudnn_headers:\n-        cudnn_srcs.append(cudnn_header_dir + \"/\" + header)\n-        cudnn_outs.append(\"cudnn/include/\" + header)\n-\n-    copy_rules.append(make_copy_files_rule(\n-        repository_ctx,\n-        name = \"cudnn-include\",\n-        srcs = cudnn_srcs,\n-        outs = cudnn_outs,\n-    ))\n-\n-    # Set up BUILD file for cuda/\n-    repository_ctx.template(\n-        \"cuda/build_defs.bzl\",\n-        tpl_paths[\"cuda:build_defs.bzl\"],\n-        {\n-            \"%{cuda_is_configured}\": \"True\",\n-            \"%{cuda_extra_copts}\": _compute_cuda_extra_copts(\n-                repository_ctx,\n-                cuda_config.compute_capabilities,\n-            ),\n-            \"%{cuda_gpu_architectures}\": str(cuda_config.compute_capabilities),\n-            \"%{cuda_version}\": cuda_config.cuda_version,\n-        },\n-    )\n-\n-    repository_ctx.template(\n-        \"cuda/BUILD\",\n-        tpl_paths[\"cuda:BUILD\"],\n-        {\n-            \"%{cuda_driver_lib}\": _basename(repository_ctx, cuda_libs[\"cuda\"]),\n-            \"%{cudart_static_lib}\": _basename(repository_ctx, cuda_libs[\"cudart_static\"]),\n-            \"%{cudart_static_linkopt}\": _cudart_static_linkopt(cuda_config.cpu_value),\n-            \"%{cudart_lib}\": _basename(repository_ctx, cuda_libs[\"cudart\"]),\n-            \"%{cublas_lib}\": _basename(repository_ctx, cuda_libs[\"cublas\"]),\n-            \"%{cublasLt_lib}\": _basename(repository_ctx, cuda_libs[\"cublasLt\"]),\n-            \"%{cusolver_lib}\": _basename(repository_ctx, cuda_libs[\"cusolver\"]),\n-            \"%{cudnn_lib}\": _basename(repository_ctx, cuda_libs[\"cudnn\"]),\n-            \"%{cufft_lib}\": _basename(repository_ctx, cuda_libs[\"cufft\"]),\n-            \"%{curand_lib}\": _basename(repository_ctx, cuda_libs[\"curand\"]),\n-            \"%{cupti_lib}\": _basename(repository_ctx, cuda_libs[\"cupti\"]),\n-            \"%{cusparse_lib}\": _basename(repository_ctx, cuda_libs[\"cusparse\"]),\n-            \"%{cub_actual}\": \":cuda_headers\",\n-            \"%{copy_rules}\": \"\\n\".join(copy_rules),\n-        },\n-    )\n-\n-    is_cuda_clang = _use_cuda_clang(repository_ctx)\n-    is_nvcc_and_clang = _use_nvcc_and_clang(repository_ctx)\n-    tf_sysroot = _tf_sysroot(repository_ctx)\n-\n-    should_download_clang = is_cuda_clang and _flag_enabled(\n-        repository_ctx,\n-        _TF_DOWNLOAD_CLANG,\n-    )\n-    if should_download_clang:\n-        download_clang(repository_ctx, \"crosstool/extra_tools\")\n-\n-    # Set up crosstool/\n-    cc = find_cc(repository_ctx, is_cuda_clang)\n-    cc_fullpath = cc if not should_download_clang else \"crosstool/\" + cc\n-\n-    host_compiler_includes = get_cxx_inc_directories(\n-        repository_ctx,\n-        cc_fullpath,\n-        tf_sysroot,\n-    )\n-    cuda_defines = {}\n-    cuda_defines[\"%{builtin_sysroot}\"] = tf_sysroot\n-    cuda_defines[\"%{cuda_toolkit_path}\"] = \"\"\n-    cuda_defines[\"%{compiler}\"] = \"unknown\"\n-    if is_cuda_clang:\n-        cuda_defines[\"%{cuda_toolkit_path}\"] = cuda_config.config[\"cuda_toolkit_path\"]\n-        cuda_defines[\"%{compiler}\"] = \"clang\"\n-\n-    host_compiler_prefix = get_host_environ(repository_ctx, _GCC_HOST_COMPILER_PREFIX)\n-    if not host_compiler_prefix:\n-        host_compiler_prefix = \"/usr/bin\"\n-\n-    cuda_defines[\"%{host_compiler_prefix}\"] = host_compiler_prefix\n-\n-    # Bazel sets '-B/usr/bin' flag to workaround build errors on RHEL (see\n-    # https://github.com/bazelbuild/bazel/issues/760).\n-    # However, this stops our custom clang toolchain from picking the provided\n-    # LLD linker, so we're only adding '-B/usr/bin' when using non-downloaded\n-    # toolchain.\n-    # TODO: when bazel stops adding '-B/usr/bin' by default, remove this\n-    #       flag from the CROSSTOOL completely (see\n-    #       https://github.com/bazelbuild/bazel/issues/5634)\n-    if should_download_clang:\n-        cuda_defines[\"%{linker_bin_path}\"] = \"\"\n-    else:\n-        cuda_defines[\"%{linker_bin_path}\"] = host_compiler_prefix\n-\n-    cuda_defines[\"%{extra_no_canonical_prefixes_flags}\"] = \"\"\n-    cuda_defines[\"%{unfiltered_compile_flags}\"] = \"\"\n-    cuda_defines[\"%{cuda_nvcc_files}\"] = \"[]\"\n-    if is_cuda_clang and not is_nvcc_and_clang:\n-        cuda_defines[\"%{host_compiler_path}\"] = str(cc)\n-        cuda_defines[\"%{host_compiler_warnings}\"] = \"\"\"\n-        # Some parts of the codebase set -Werror and hit this warning, so\n-        # switch it off for now.\n-        \"-Wno-invalid-partial-specialization\"\n-    \"\"\"\n-        cuda_defines[\"%{cxx_builtin_include_directories}\"] = to_list_of_strings(host_compiler_includes)\n-        cuda_defines[\"%{compiler_deps}\"] = \":empty\"\n-        cuda_defines[\"%{win_compiler_deps}\"] = \":empty\"\n-        repository_ctx.file(\n-            \"crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\",\n-            \"\",\n-        )\n-        repository_ctx.file(\"crosstool/windows/msvc_wrapper_for_nvcc.py\", \"\")\n-    else:\n-        cuda_defines[\"%{host_compiler_path}\"] = \"clang/bin/crosstool_wrapper_driver_is_not_gcc\"\n-        cuda_defines[\"%{host_compiler_warnings}\"] = \"\"\n-\n-        # nvcc has the system include paths built in and will automatically\n-        # search them; we cannot work around that, so we add the relevant cuda\n-        # system paths to the allowed compiler specific include paths.\n-        cuda_defines[\"%{cxx_builtin_include_directories}\"] = to_list_of_strings(\n-            host_compiler_includes + _cuda_include_path(\n-                repository_ctx,\n-                cuda_config,\n-            ) + [cupti_header_dir, cudnn_header_dir, nvml_header_dir],\n-        )\n-\n-        # For gcc, do not canonicalize system header paths; some versions of gcc\n-        # pick the shortest possible path for system includes when creating the\n-        # .d file - given that includes that are prefixed with \"../\" multiple\n-        # time quickly grow longer than the root of the tree, this can lead to\n-        # bazel's header check failing.\n-        if not is_cuda_clang:\n-            cuda_defines[\"%{extra_no_canonical_prefixes_flags}\"] = \"\\\"-fno-canonical-system-headers\\\"\"\n-\n-        file_ext = \".exe\" if is_windows(repository_ctx) else \"\"\n-        nvcc_path = \"%s/nvcc%s\" % (cuda_config.config[\"cuda_binary_dir\"], file_ext)\n-        cuda_defines[\"%{compiler_deps}\"] = \":crosstool_wrapper_driver_is_not_gcc\"\n-        cuda_defines[\"%{win_compiler_deps}\"] = \":windows_msvc_wrapper_files\"\n-\n-        wrapper_defines = {\n-            \"%{cpu_compiler}\": str(cc),\n-            \"%{cuda_version}\": cuda_config.cuda_version,\n-            \"%{nvcc_path}\": nvcc_path,\n-            \"%{host_compiler_path}\": str(cc),\n-            \"%{use_clang_compiler}\": str(is_nvcc_and_clang),\n-            \"%{nvcc_tmp_dir}\": _get_nvcc_tmp_dir_for_windows(repository_ctx),\n-            \"%{tmpdir}\": get_host_environ(\n-                repository_ctx,\n-                _TMPDIR,\n-                \"\",\n-            ),\n-        }\n-        repository_ctx.template(\n-            \"crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\",\n-            tpl_paths[\"crosstool:clang/bin/crosstool_wrapper_driver_is_not_gcc\"],\n-            wrapper_defines,\n-        )\n-        repository_ctx.file(\n-            \"crosstool/windows/msvc_wrapper_for_nvcc.bat\",\n-            content = \"@echo OFF\\n{} -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py %*\".format(\n-                get_python_bin(repository_ctx),\n-            ),\n-        )\n-        repository_ctx.template(\n-            \"crosstool/windows/msvc_wrapper_for_nvcc.py\",\n-            tpl_paths[\"crosstool:windows/msvc_wrapper_for_nvcc.py\"],\n-            wrapper_defines,\n-        )\n-\n-    cuda_defines.update(_get_win_cuda_defines(repository_ctx))\n-\n-    verify_build_defines(cuda_defines)\n-\n-    # Only expand template variables in the BUILD file\n-    repository_ctx.template(\n-        \"crosstool/BUILD\",\n-        tpl_paths[\"crosstool:BUILD\"],\n-        cuda_defines,\n-    )\n-\n-    # No templating of cc_toolchain_config - use attributes and templatize the\n-    # BUILD file.\n-    repository_ctx.template(\n-        \"crosstool/cc_toolchain_config.bzl\",\n-        tpl_paths[\"crosstool:cc_toolchain_config.bzl\"],\n-        {},\n-    )\n-\n-    # Set up cuda_config.h, which is used by\n-    # tensorflow/compiler/xla/stream_executor/dso_loader.cc.\n-    repository_ctx.template(\n-        \"cuda/cuda/cuda_config.h\",\n-        tpl_paths[\"cuda:cuda_config.h\"],\n-        {\n-            \"%{cuda_version}\": cuda_config.cuda_version,\n-            \"%{cudart_version}\": cuda_config.cudart_version,\n-            \"%{cupti_version}\": cuda_config.cupti_version,\n-            \"%{cublas_version}\": cuda_config.cublas_version,\n-            \"%{cusolver_version}\": cuda_config.cusolver_version,\n-            \"%{curand_version}\": cuda_config.curand_version,\n-            \"%{cufft_version}\": cuda_config.cufft_version,\n-            \"%{cusparse_version}\": cuda_config.cusparse_version,\n-            \"%{cudnn_version}\": cuda_config.cudnn_version,\n-            \"%{cuda_toolkit_path}\": cuda_config.cuda_toolkit_path,\n-            \"%{cuda_compute_capabilities}\": \", \".join([\n-                cc.split(\"_\")[1]\n-                for cc in cuda_config.compute_capabilities\n-            ]),\n-        },\n-    )\n-\n-    # Set up cuda_config.py, which is used by gen_build_info to provide\n-    # static build environment info to the API\n-    repository_ctx.template(\n-        \"cuda/cuda/cuda_config.py\",\n-        tpl_paths[\"cuda:cuda_config.py\"],\n-        _py_tmpl_dict({\n-            \"cuda_version\": cuda_config.cuda_version,\n-            \"cudnn_version\": cuda_config.cudnn_version,\n-            \"cuda_compute_capabilities\": cuda_config.compute_capabilities,\n-            \"cpu_compiler\": str(cc),\n-        }),\n-    )\n-\n-def _py_tmpl_dict(d):\n-    return {\"%{cuda_config}\": str(d)}\n-\n-def _create_remote_cuda_repository(repository_ctx, remote_config_repo):\n-    \"\"\"Creates pointers to a remotely configured repo set up to build with CUDA.\"\"\"\n-    _tpl(\n-        repository_ctx,\n-        \"cuda:build_defs.bzl\",\n-        {\n-            \"%{cuda_is_configured}\": \"True\",\n-            \"%{cuda_extra_copts}\": _compute_cuda_extra_copts(\n-                repository_ctx,\n-                compute_capabilities(repository_ctx),\n-            ),\n-            \"%{cuda_version}\": get_host_environ(repository_ctx, _TF_CUDA_VERSION),\n-        },\n-    )\n-    repository_ctx.template(\n-        \"cuda/BUILD\",\n-        config_repo_label(remote_config_repo, \"cuda:BUILD\"),\n-        {},\n-    )\n-    repository_ctx.template(\n-        \"cuda/build_defs.bzl\",\n-        config_repo_label(remote_config_repo, \"cuda:build_defs.bzl\"),\n-        {},\n-    )\n-    repository_ctx.template(\n-        \"cuda/cuda/cuda_config.h\",\n-        config_repo_label(remote_config_repo, \"cuda:cuda/cuda_config.h\"),\n-        {},\n-    )\n-    repository_ctx.template(\n-        \"cuda/cuda/cuda_config.py\",\n-        config_repo_label(remote_config_repo, \"cuda:cuda/cuda_config.py\"),\n-        _py_tmpl_dict({}),\n-    )\n-\n-    repository_ctx.template(\n-        \"crosstool/BUILD\",\n-        config_repo_label(remote_config_repo, \"crosstool:BUILD\"),\n-        {},\n-    )\n-\n-    repository_ctx.template(\n-        \"crosstool/cc_toolchain_config.bzl\",\n-        config_repo_label(remote_config_repo, \"crosstool:cc_toolchain_config.bzl\"),\n-        {},\n-    )\n-\n-    repository_ctx.template(\n-        \"crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\",\n-        config_repo_label(remote_config_repo, \"crosstool:clang/bin/crosstool_wrapper_driver_is_not_gcc\"),\n-        {},\n-    )\n-\n-def _cuda_autoconf_impl(repository_ctx):\n-    \"\"\"Implementation of the cuda_autoconf repository rule.\"\"\"\n-    build_file = Label(\"//third_party/gpus:local_config_cuda.BUILD\")\n-\n-    if not enable_cuda(repository_ctx):\n-        _create_dummy_repository(repository_ctx)\n-    elif get_host_environ(repository_ctx, _TF_CUDA_CONFIG_REPO) != None:\n-        has_cuda_version = get_host_environ(repository_ctx, _TF_CUDA_VERSION) != None\n-        has_cudnn_version = get_host_environ(repository_ctx, _TF_CUDNN_VERSION) != None\n-        if not has_cuda_version or not has_cudnn_version:\n-            auto_configure_fail(\"%s and %s must also be set if %s is specified\" %\n-                                (_TF_CUDA_VERSION, _TF_CUDNN_VERSION, _TF_CUDA_CONFIG_REPO))\n-        _create_remote_cuda_repository(\n-            repository_ctx,\n-            get_host_environ(repository_ctx, _TF_CUDA_CONFIG_REPO),\n-        )\n-    else:\n-        _create_local_cuda_repository(repository_ctx)\n-\n-    repository_ctx.symlink(build_file, \"BUILD\")\n-\n-# For @bazel_tools//tools/cpp:windows_cc_configure.bzl\n-_MSVC_ENVVARS = [\n-    \"BAZEL_VC\",\n-    \"BAZEL_VC_FULL_VERSION\",\n-    \"BAZEL_VS\",\n-    \"BAZEL_WINSDK_FULL_VERSION\",\n-    \"VS90COMNTOOLS\",\n-    \"VS100COMNTOOLS\",\n-    \"VS110COMNTOOLS\",\n-    \"VS120COMNTOOLS\",\n-    \"VS140COMNTOOLS\",\n-    \"VS150COMNTOOLS\",\n-    \"VS160COMNTOOLS\",\n-]\n-\n-_ENVIRONS = [\n-    _GCC_HOST_COMPILER_PATH,\n-    _GCC_HOST_COMPILER_PREFIX,\n-    _CLANG_CUDA_COMPILER_PATH,\n-    \"TF_NEED_CUDA\",\n-    \"TF_CUDA_CLANG\",\n-    \"TF_NVCC_CLANG\",\n-    _TF_DOWNLOAD_CLANG,\n-    _CUDA_TOOLKIT_PATH,\n-    _CUDNN_INSTALL_PATH,\n-    _TF_CUDA_VERSION,\n-    _TF_CUDNN_VERSION,\n-    _TF_CUDA_COMPUTE_CAPABILITIES,\n-    \"NVVMIR_LIBRARY_DIR\",\n-    _PYTHON_BIN_PATH,\n-    \"TMP\",\n-    _TMPDIR,\n-    \"TF_CUDA_PATHS\",\n-] + _MSVC_ENVVARS\n-\n-remote_cuda_configure = repository_rule(\n-    implementation = _create_local_cuda_repository,\n-    environ = _ENVIRONS,\n-    remotable = True,\n-    attrs = {\n-        \"environ\": attr.string_dict(),\n-        \"_find_cuda_config\": attr.label(\n-            default = Label(\"//third_party/gpus:find_cuda_config.py\"),\n-        ),\n-    },\n-)\n-\n-cuda_configure = repository_rule(\n-    implementation = _cuda_autoconf_impl,\n-    environ = _ENVIRONS + [_TF_CUDA_CONFIG_REPO],\n-    attrs = {\n-        \"_find_cuda_config\": attr.label(\n-            default = Label(\"//third_party/gpus:find_cuda_config.py\"),\n-        ),\n-    },\n-)\n-\"\"\"Detects and configures the local CUDA toolchain.\n-\n-Add the following to your WORKSPACE FILE:\n-\n-```python\n-cuda_configure(name = \"local_config_cuda\")\n-```\n-\n-Args:\n-  name: A unique name for this workspace rule.\n-\"\"\""
        },
        {
            "sha": "00f0b2b84ccf56b4098a874ba5df4cb8e8f19a97",
            "filename": "third_party/xla/third_party/nccl/nccl_configure.bzl",
            "status": "removed",
            "additions": 0,
            "deletions": 221,
            "changes": 221,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fnccl%2Fnccl_configure.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fnccl%2Fnccl_configure.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fnccl%2Fnccl_configure.bzl?ref=22fa876f4ee784e5a37401607be26c2feba354a4",
            "patch": "@@ -1,221 +0,0 @@\n-\"\"\"Repository rule for NCCL configuration.\n-\n-NB: DEPRECATED! Use `hermetic/nccl_configure` rule instead.\n-\n-`nccl_configure` depends on the following environment variables:\n-\n-  * `TF_NCCL_VERSION`: Installed NCCL version or empty to build from source.\n-  * `NCCL_INSTALL_PATH` (deprecated): The installation path of the NCCL library.\n-  * `NCCL_HDR_PATH` (deprecated): The installation path of the NCCL header \n-    files.\n-  * `TF_CUDA_PATHS`: The base paths to look for CUDA and cuDNN. Default is\n-    `/usr/local/cuda,usr/`.\n-  * `TF_NCCL_USE_STUB`: \"1\" if a NCCL stub that loads NCCL dynamically should\n-    be used, \"0\" if NCCL should be linked in statically.\n-\n-\"\"\"\n-\n-load(\n-    \"//third_party/gpus:cuda_configure.bzl\",\n-    \"enable_cuda\",\n-    \"find_cuda_config\",\n-)\n-load(\n-    \"//third_party/remote_config:common.bzl\",\n-    \"config_repo_label\",\n-    \"get_cpu_value\",\n-    \"get_host_environ\",\n-)\n-\n-_CUDA_TOOLKIT_PATH = \"CUDA_TOOLKIT_PATH\"\n-_NCCL_HDR_PATH = \"NCCL_HDR_PATH\"\n-_NCCL_INSTALL_PATH = \"NCCL_INSTALL_PATH\"\n-_TF_CUDA_COMPUTE_CAPABILITIES = \"TF_CUDA_COMPUTE_CAPABILITIES\"\n-_TF_NCCL_VERSION = \"TF_NCCL_VERSION\"\n-_TF_NEED_CUDA = \"TF_NEED_CUDA\"\n-_TF_CUDA_PATHS = \"TF_CUDA_PATHS\"\n-_TF_NCCL_USE_STUB = \"TF_NCCL_USE_STUB\"\n-\n-_DEFINE_NCCL_MAJOR = \"#define NCCL_MAJOR\"\n-_DEFINE_NCCL_MINOR = \"#define NCCL_MINOR\"\n-_DEFINE_NCCL_PATCH = \"#define NCCL_PATCH\"\n-\n-_NCCL_DUMMY_BUILD_CONTENT = \"\"\"\n-filegroup(\n-  name = \"LICENSE\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-cc_library(\n-  name = \"nccl\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-cc_library(\n-  name = \"nccl_config\",\n-  hdrs = [\"nccl_config.h\"],\n-  include_prefix = \"third_party/nccl\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\"\"\"\n-\n-_NCCL_ARCHIVE_BUILD_CONTENT = \"\"\"\n-filegroup(\n-  name = \"LICENSE\",\n-  data = [\"@nccl_archive//:LICENSE.txt\"],\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-alias(\n-  name = \"nccl\",\n-  actual = \"@nccl_archive//:nccl\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-alias(\n-  name = \"nccl_config\",\n-  actual = \"@nccl_archive//:nccl_config\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\"\"\"\n-\n-_NCCL_ARCHIVE_STUB_BUILD_CONTENT = \"\"\"\n-filegroup(\n-  name = \"LICENSE\",\n-  data = [\"@nccl_archive//:LICENSE.txt\"],\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-alias(\n-  name = \"nccl\",\n-  actual = \"@nccl_archive//:nccl_via_stub\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-alias(\n-  name = \"nccl_headers\",\n-  actual = \"@nccl_archive//:nccl_headers\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\n-alias(\n-  name = \"nccl_config\",\n-  actual = \"@nccl_archive//:nccl_config\",\n-  visibility = [\"//visibility:public\"],\n-)\n-\"\"\"\n-\n-def _label(file):\n-    return Label(\"//third_party/nccl:{}\".format(file))\n-\n-def _create_local_nccl_repository(repository_ctx):\n-    nccl_version = get_host_environ(repository_ctx, _TF_NCCL_VERSION, \"\")\n-    if nccl_version:\n-        nccl_version = nccl_version.split(\".\")[0]\n-\n-    cuda_config = find_cuda_config(repository_ctx, [\"cuda\"])\n-    cuda_version = cuda_config[\"cuda_version\"].split(\".\")\n-\n-    if nccl_version == \"\":\n-        # Alias to open source build from @nccl_archive.\n-        if get_host_environ(repository_ctx, _TF_NCCL_USE_STUB, \"0\") == \"0\":\n-            repository_ctx.file(\"BUILD\", _NCCL_ARCHIVE_BUILD_CONTENT)\n-        else:\n-            repository_ctx.file(\"BUILD\", _NCCL_ARCHIVE_STUB_BUILD_CONTENT)\n-\n-        repository_ctx.template(\"generated_names.bzl\", _label(\"generated_names.bzl.tpl\"), {})\n-        repository_ctx.template(\n-            \"build_defs.bzl\",\n-            _label(\"build_defs.bzl.tpl\"),\n-            {\n-                \"%{cuda_version}\": \"(%s, %s)\" % tuple(cuda_version),\n-                \"%{nvlink_label}\": \"@local_config_cuda//cuda:cuda/bin/nvlink\",\n-                \"%{fatbinary_label}\": \"@local_config_cuda//cuda:cuda/bin/fatbinary\",\n-                \"%{bin2c_label}\": \"@local_config_cuda//cuda:cuda/bin/bin2c\",\n-                \"%{link_stub_label}\": \"@local_config_cuda//cuda:cuda/bin/crt/link.stub\",\n-                \"%{nvprune_label}\": \"@local_config_cuda//cuda:cuda/bin/nvprune\",\n-            },\n-        )\n-    else:\n-        # Create target for locally installed NCCL.\n-        config = find_cuda_config(repository_ctx, [\"nccl\"])\n-        config_wrap = {\n-            \"%{nccl_version}\": config[\"nccl_version\"],\n-            \"%{nccl_header_dir}\": config[\"nccl_include_dir\"],\n-            \"%{nccl_library_dir}\": config[\"nccl_library_dir\"],\n-        }\n-        repository_ctx.template(\"BUILD\", _label(\"system.BUILD.tpl\"), config_wrap)\n-        repository_ctx.template(\"generated_names.bzl\", _label(\"generated_names.bzl.tpl\"), {})\n-\n-def _create_remote_nccl_repository(repository_ctx, remote_config_repo):\n-    repository_ctx.template(\n-        \"BUILD\",\n-        config_repo_label(remote_config_repo, \":BUILD\"),\n-        {},\n-    )\n-    nccl_version = get_host_environ(repository_ctx, _TF_NCCL_VERSION, \"\")\n-    if nccl_version == \"\":\n-        repository_ctx.template(\n-            \"generated_names.bzl\",\n-            config_repo_label(remote_config_repo, \":generated_names.bzl\"),\n-            {},\n-        )\n-        repository_ctx.template(\n-            \"build_defs.bzl\",\n-            config_repo_label(remote_config_repo, \":build_defs.bzl\"),\n-            {},\n-        )\n-\n-def _nccl_autoconf_impl(repository_ctx):\n-    if (not enable_cuda(repository_ctx) or\n-        get_cpu_value(repository_ctx) not in (\"Linux\", \"FreeBSD\")):\n-        # Add a dummy build file to make bazel query happy.\n-        repository_ctx.file(\"BUILD\", _NCCL_DUMMY_BUILD_CONTENT)\n-        repository_ctx.file(\"nccl_config.h\", \"#define TF_NCCL_VERSION \\\"\\\"\")\n-    elif get_host_environ(repository_ctx, \"TF_NCCL_CONFIG_REPO\") != None:\n-        _create_remote_nccl_repository(repository_ctx, get_host_environ(repository_ctx, \"TF_NCCL_CONFIG_REPO\"))\n-    else:\n-        _create_local_nccl_repository(repository_ctx)\n-\n-_ENVIRONS = [\n-    _CUDA_TOOLKIT_PATH,\n-    _NCCL_HDR_PATH,\n-    _NCCL_INSTALL_PATH,\n-    _TF_NCCL_VERSION,\n-    _TF_CUDA_COMPUTE_CAPABILITIES,\n-    _TF_NEED_CUDA,\n-    _TF_CUDA_PATHS,\n-]\n-\n-remote_nccl_configure = repository_rule(\n-    implementation = _create_local_nccl_repository,\n-    environ = _ENVIRONS,\n-    remotable = True,\n-    attrs = {\n-        \"environ\": attr.string_dict(),\n-        \"_find_cuda_config\": attr.label(\n-            default = Label(\"//third_party/gpus:find_cuda_config.py\"),\n-        ),\n-    },\n-)\n-\n-nccl_configure = repository_rule(\n-    implementation = _nccl_autoconf_impl,\n-    environ = _ENVIRONS,\n-    attrs = {\n-        \"_find_cuda_config\": attr.label(\n-            default = Label(\"//third_party/gpus:find_cuda_config.py\"),\n-        ),\n-    },\n-)\n-\"\"\"Detects and configures the NCCL configuration.\n-\n-Add the following to your WORKSPACE FILE:\n-\n-```python\n-nccl_configure(name = \"local_config_nccl\")\n-```\n-\n-Args:\n-  name: A unique name for this workspace rule.\n-\"\"\""
        },
        {
            "sha": "8a0827fb9e12f358d1cf9d8c09bdd47b63a40881",
            "filename": "third_party/xla/third_party/nccl/system.BUILD.tpl",
            "status": "removed",
            "additions": 0,
            "deletions": 62,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fnccl%2Fsystem.BUILD.tpl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/22fa876f4ee784e5a37401607be26c2feba354a4/third_party%2Fxla%2Fthird_party%2Fnccl%2Fsystem.BUILD.tpl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fthird_party%2Fnccl%2Fsystem.BUILD.tpl?ref=22fa876f4ee784e5a37401607be26c2feba354a4",
            "patch": "@@ -1,62 +0,0 @@\n-load(\"@bazel_skylib//rules:write_file.bzl\", \"write_file\")\n-load(\n-    \"@local_xla//xla/tsl/platform/default:cuda_build_defs.bzl\",\n-    \"cuda_rpath_flags\"\n-)\n-\n-filegroup(\n-    name = \"LICENSE\",\n-    visibility = [\"//visibility:public\"],\n-)\n-\n-cc_library(\n-    name = \"nccl\",\n-    srcs = [\"libnccl.so.%{nccl_version}\"],\n-    hdrs = [\"nccl.h\"],\n-    include_prefix = \"third_party/nccl\",\n-    visibility = [\"//visibility:public\"],\n-    deps = [\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-    ],\n-    linkopts = cuda_rpath_flags(\"nvidia/nccl/lib\"),\n-)\n-\n-cc_library(\n-    name = \"nccl_headers\",\n-    hdrs = [\"nccl.h\"],\n-    include_prefix = \"third_party/nccl\",\n-    visibility = [\"//visibility:public\"],\n-    deps = [\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-    ],\n-)\n-\n-genrule(\n-    name = \"nccl-files\",\n-    outs = [\n-        \"libnccl.so.%{nccl_version}\",\n-        \"nccl.h\",\n-    ],\n-    cmd = \"\"\"\n-cp \"%{nccl_header_dir}/nccl.h\" \"$(@D)/nccl.h\" &&\n-cp \"%{nccl_library_dir}/libnccl.so.%{nccl_version}\" \\\n-  \"$(@D)/libnccl.so.%{nccl_version}\"\n-\"\"\",\n-)\n-\n-# This additional header allows us to determine the configured NCCL version\n-# without including the rest of NCCL.\n-write_file(\n-    name = \"nccl_config_header\",\n-    out = \"nccl_config.h\",\n-    content = [\n-        \"#define TF_NCCL_VERSION \\\"%{nccl_version}\\\"\"\n-    ]\n-)\n-\n-cc_library(\n-    name = \"nccl_config\",\n-    hdrs = [\"nccl_config.h\"],\n-    include_prefix = \"third_party/nccl\",\n-    visibility = [\"//visibility:public\"],\n-)"
        }
    ],
    "stats": {
        "total": 2177,
        "additions": 1,
        "deletions": 2176
    }
}