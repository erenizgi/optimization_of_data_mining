{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Add pass to make integer division / remainder safe.\n\nPiperOrigin-RevId: 837453532",
    "sha": "f1b20454202645ec17e272dc26d3b1699e1e45b4",
    "files": [
        {
            "sha": "8eaddc18832745b6341b6df813c5e03d6975e053",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -358,6 +358,8 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm, bool fast_min_max) {\n   pm.addPass(mlir::createConvertComplexToStandardPass());\n   pm.addPass(mlir::memref::createExpandStridedMetadataPass());\n \n+  pm.addPass(emitters::CreateSafeIntegerArithmeticPass());\n+\n   AddGenericLoweringPasses(pm, fast_min_max);\n }\n "
        },
        {
            "sha": "3ecfe8738f8cdf5346156a67237083a4f0d2fe27",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -468,7 +468,11 @@ absl::StatusOr<Value> EmitElementwise(EmitterLocOpBuilder& b,\n     case HloOpcode::kDivide:\n       if (is_integer) {\n         // Unsigned not supported yet.\n-        return ma::DivSIOp::create(b, inputs[0], inputs[1]);\n+        auto div = ma::DivSIOp::create(b, inputs[0], inputs[1]);\n+        // Attr signifies that this op should be re-written to guard against\n+        // undefined behavior.\n+        div->setAttr(\"xla.guard_ub\", b.getUnitAttr());\n+        return div;\n       }\n       return ma::DivFOp::create(b, inputs[0], inputs[1]);\n     case HloOpcode::kCompare:\n@@ -516,7 +520,11 @@ absl::StatusOr<Value> EmitElementwise(EmitterLocOpBuilder& b,\n       return mm::PowFOp::create(b, inputs[0], inputs[1]);\n     case HloOpcode::kRemainder:\n       if (is_integer) {\n-        return ma::RemSIOp::create(b, inputs[0], inputs[1]);\n+        auto rem = ma::RemSIOp::create(b, inputs[0], inputs[1]);\n+        // Attr signifies that this op should be re-written to guard against\n+        // undefined behavior.\n+        rem->setAttr(\"xla.guard_ub\", b.getUnitAttr());\n+        return rem;\n       }\n       return ma::RemFOp::create(b, inputs[0], inputs[1]);\n     case HloOpcode::kRsqrt:"
        },
        {
            "sha": "429feecc9eb9826cefba74c98ccbfd30bbd58681",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2FBUILD?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -54,6 +54,7 @@ cc_library(\n         \"lower_xla_to_scf.cc\",\n         \"merge_pointers_to_same_slice.cc\",\n         \"propagate_slice_indices.cc\",\n+        \"safe_integer_arithmetic.cc\",\n         \"unswitch_loops.cc\",\n         \"vectorize_loads_stores.cc\",\n     ],"
        },
        {
            "sha": "74a5ab5fe2f89748da979241a96664bd6a7e7da5",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.h?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -59,6 +59,7 @@ std::unique_ptr<mlir::Pass> CreateVectorizeLoadsAndStoresPass(\n     const std::string& gpu_device_info = \"\");\n std::unique_ptr<mlir::Pass> CreateVectorizeLoadsAndStoresPass(\n     const stream_executor::DeviceDescription& device_description);\n+std::unique_ptr<mlir::Pass> CreateSafeIntegerArithmeticPass();\n \n #define GEN_PASS_REGISTRATION\n #include \"xla/codegen/emitters/transforms/passes.h.inc\""
        },
        {
            "sha": "0b7afb432042f6c53edd7682c9a7d3834cecf92a",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/passes.td",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fpasses.td?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -332,4 +332,14 @@ def VectorizeLoadsAndStoresPass :\n   let constructor = \"CreateVectorizeLoadsAndStoresPass()\";\n }\n \n+def SafeIntegerArithmeticPass : Pass<\"xla-safe-integer-arithmetic\"> {\n+  let summary = \"Make integer arithmetics safe.\";\n+\n+  let description = [{\n+    This pass converts integer division and remainder to ones that do not cause\n+    undefined behavior. It only converts operations that are marked with the\n+    attribute \"xla.guard_ub\".\n+  }];\n+}\n+\n #endif  // XLA_CODEGEN_EMITTERS_TRANSFORMS_PASSES_TD_"
        },
        {
            "sha": "63199d564c10dafd8ecb65fdf851032d6d09d08b",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/safe_integer_arithmetic.cc",
            "status": "added",
            "additions": 134,
            "deletions": 0,
            "changes": 134,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fsafe_integer_arithmetic.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fsafe_integer_arithmetic.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Fsafe_integer_arithmetic.cc?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -0,0 +1,134 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cassert>\n+#include <memory>\n+#include <utility>\n+\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"  // IWYU pragma: keep\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributeInterfaces.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/codegen/emitters/transforms/passes.h\"\n+#include \"xla/mlir_hlo/mhlo/transforms/map_mhlo_to_scalar_op.h\"\n+\n+namespace xla::emitters {\n+\n+#define GEN_PASS_DEF_SAFEINTEGERARITHMETICPASS\n+#include \"xla/codegen/emitters/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+inline mlir::Value GetConstantOrSplat(mlir::ImplicitLocOpBuilder& builder,\n+                                      mlir::Type type, mlir::TypedAttr value) {\n+  if (auto vector_type = mlir::dyn_cast<mlir::VectorType>(type)) {\n+    value = mlir::SplatElementsAttr::get(vector_type, value);\n+  }\n+  return mlir::arith::ConstantOp::create(builder, type, value);\n+}\n+\n+inline mlir::Value GetConstantOrSplat(mlir::ImplicitLocOpBuilder& builder,\n+                                      mlir::Type type, mlir::APInt value) {\n+  return GetConstantOrSplat(\n+      builder, type,\n+      builder.getIntegerAttr(mlir::getElementTypeOrSelf(type), value));\n+}\n+\n+template <typename OpT, bool is_unsigned>\n+mlir::LogicalResult RewriteToSafeDiv(OpT op, mlir::PatternRewriter& rewriter) {\n+  if (!op->hasAttr(\"xla.guard_ub\")) {\n+    return rewriter.notifyMatchFailure(op, \"already safe\");\n+  }\n+\n+  mlir::ImplicitLocOpBuilder builder(op.getLoc(), rewriter);\n+  mlir::Type element_type = mlir::getElementTypeOrSelf(op.getType());\n+  auto int_type = mlir::cast<mlir::IntegerType>(element_type);\n+  mlir::Value minusOne = GetConstantOrSplat(\n+      builder, op.getType(), mlir::APInt::getAllOnes(int_type.getWidth()));\n+  mlir::Value smin =\n+      GetConstantOrSplat(builder, op.getType(),\n+                         mlir::APInt::getSignedMinValue(int_type.getWidth()));\n+  mlir::Value safe_div = mlir::mhlo::impl::makeSafeIntDiv<mlir::arith::DivUIOp,\n+                                                          mlir::arith::DivSIOp>(\n+      builder, is_unsigned, op.getLhs(), op.getRhs(),\n+      /*returnedOnZero=*/minusOne,\n+      /*returnedOnSignedOverflow=*/smin);\n+\n+  rewriter.replaceOp(op, safe_div);\n+  return mlir::success();\n+}\n+\n+template <typename OpT, bool is_unsigned>\n+mlir::LogicalResult RewriteToSafeRem(OpT op, mlir::PatternRewriter& rewriter) {\n+  if (!op->hasAttr(\"xla.guard_ub\")) {\n+    return rewriter.notifyMatchFailure(op, \"already safe\");\n+  }\n+\n+  mlir::ImplicitLocOpBuilder builder(op.getLoc(), rewriter);\n+  mlir::Type element_type = mlir::getElementTypeOrSelf(op.getType());\n+  auto int_type = mlir::cast<mlir::IntegerType>(element_type);\n+  auto zero = GetConstantOrSplat(builder, op.getType(),\n+                                 mlir::APInt::getZero(int_type.getWidth()));\n+  mlir::Value safe_div = mlir::mhlo::impl::makeSafeIntDiv<mlir::arith::RemUIOp,\n+                                                          mlir::arith::RemSIOp>(\n+      builder, is_unsigned, op.getLhs(), op.getRhs(),\n+      /*returnedOnZero=*/op.getLhs(),\n+      /*returnedOnSignedOverflow=*/zero);\n+\n+  rewriter.replaceOp(op, safe_div);\n+  return mlir::success();\n+}\n+\n+class SafeIntegerArithmeticPass\n+    : public impl::SafeIntegerArithmeticPassBase<SafeIntegerArithmeticPass> {\n+ public:\n+  using SafeIntegerArithmeticPassBase::SafeIntegerArithmeticPassBase;\n+\n+  void runOnOperation() override {\n+    mlir::MLIRContext* context = &getContext();\n+    mlir::RewritePatternSet patterns(context);\n+\n+    patterns.add(RewriteToSafeDiv<mlir::arith::DivUIOp, /*is_unsigned=*/true>);\n+    patterns.add(RewriteToSafeDiv<mlir::arith::DivSIOp, /*is_unsigned=*/false>);\n+\n+    patterns.add(RewriteToSafeRem<mlir::arith::RemUIOp, /*is_unsigned=*/true>);\n+    patterns.add(RewriteToSafeRem<mlir::arith::RemSIOp, /*is_unsigned=*/false>);\n+\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      signalPassFailure();\n+      return;\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateSafeIntegerArithmeticPass() {\n+  return std::make_unique<SafeIntegerArithmeticPass>();\n+}\n+\n+}  // namespace xla::emitters"
        },
        {
            "sha": "798e8c7de7e11ceaca6689b402035735539bbb8a",
            "filename": "third_party/xla/xla/codegen/emitters/transforms/tests/safe_integer_arithmetic.mlir",
            "status": "added",
            "additions": 178,
            "deletions": 0,
            "changes": 178,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fsafe_integer_arithmetic.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fsafe_integer_arithmetic.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fsafe_integer_arithmetic.mlir?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -0,0 +1,178 @@\n+// RUN: emitters_opt %s -xla-safe-integer-arithmetic --split-input-file  \\\n+// RUN: | FileCheck %s\n+\n+func.func @unmarked_signed_div_is_not_changed(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK: %[[RESULT:.*]] = arith.divsi %arg0, %arg1 : i32\n+  %0 = arith.divsi %arg0, %arg1 : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @unmarked_unsigned_div_is_not_changed(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK: %[[RESULT:.*]] = arith.divui %arg0, %arg1 : i32\n+  %0 = arith.divui %arg0, %arg1 : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @unmarked_signed_rem_is_not_changed(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK: %[[RESULT:.*]] = arith.remsi %arg0, %arg1 : i32\n+  %0 = arith.remsi %arg0, %arg1 : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @unmarked_unsigned_rem_is_not_changed(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK: %[[RESULT:.*]] = arith.remui %arg0, %arg1 : i32\n+  %0 = arith.remui %arg0, %arg1 : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @signed_div(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant -1 : i32\n+  // CHECK-DAG: %[[CMIN:.*]] = arith.constant -2147483648 : i32\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant 0 : i32\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant 1 : i32\n+  // CHECK:     %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : i32\n+  // CHECK:     %[[LHS_MIN:.*]] = arith.cmpi eq, %arg0, %[[CMIN]] : i32\n+  // CHECK:     %[[RHS_MINUS1:.*]] = arith.cmpi eq, %arg1, %[[C_1]] : i32\n+  // CHECK:     %[[OVERFLOW:.*]] = arith.andi %[[LHS_MIN]], %[[RHS_MINUS1]] : i1\n+  // CHECK:     %[[IS_UB:.*]] = arith.ori %[[RHS_ZERO]], %[[OVERFLOW]] : i1\n+  // CHECK:     %[[BOUNDED_RHS:.*]] = arith.select %[[IS_UB]], %[[C1]], %arg1 : i32\n+  // CHECK:     %[[DIV:.*]] = arith.divsi %arg0, %[[BOUNDED_RHS]] : i32\n+  // CHECK:     %[[OVERFLOW_RESULT:.*]] = arith.select %[[OVERFLOW]], %[[CMIN]], %[[DIV]] : i32\n+  // CHECK:     %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %[[C_1]], %[[OVERFLOW_RESULT]] : i32\n+  %0 = arith.divsi %arg0, %arg1 {xla.guard_ub} : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @signed_div_vector(%arg0: vector<8xi32>, %arg1: vector<8xi32>) -> vector<8xi32> {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant dense<-1> : vector<8xi32>\n+  // CHECK-DAG: %[[CMIN:.*]] = arith.constant dense<-2147483648> : vector<8xi32>\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant dense<0> : vector<8xi32>\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant dense<1> : vector<8xi32>\n+  // CHECK:     %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : vector<8xi32>\n+  // CHECK:     %[[LHS_MIN:.*]] = arith.cmpi eq, %arg0, %[[CMIN]] : vector<8xi32>\n+  // CHECK:     %[[RHS_MINUS1:.*]] = arith.cmpi eq, %arg1, %[[C_1]] : vector<8xi32>\n+  // CHECK:     %[[OVERFLOW:.*]] = arith.andi %[[LHS_MIN]], %[[RHS_MINUS1]] : vector<8xi1>\n+  // CHECK:     %[[IS_UB:.*]] = arith.ori %[[RHS_ZERO]], %[[OVERFLOW]] : vector<8xi1>\n+  // CHECK:     %[[BOUNDED_RHS:.*]] = arith.select %[[IS_UB]], %[[C1]], %arg1 : vector<8xi1>, vector<8xi32>\n+  // CHECK:     %[[DIV:.*]] = arith.divsi %arg0, %[[BOUNDED_RHS]] : vector<8xi32>\n+  // CHECK:     %[[OVERFLOW_RESULT:.*]] = arith.select %[[OVERFLOW]], %[[CMIN]], %[[DIV]] : vector<8xi1>, vector<8xi32>\n+  // CHECK:     %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %[[C_1]], %[[OVERFLOW_RESULT]] : vector<8xi1>, vector<8xi32>\n+  %0 = arith.divsi %arg0, %arg1 {xla.guard_ub} : vector<8xi32>\n+  // CHECK: return %[[RESULT]] : vector<8xi32>\n+  func.return %0 : vector<8xi32>\n+}\n+\n+// -----\n+\n+func.func @unsigned_div(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant -1 : i32\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant 0 : i32\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant 1 : i32\n+  // CHECK: %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : i32\n+  // CHECK: %[[BOUNDED_RHS:.*]] = arith.select %[[RHS_ZERO]], %[[C1]], %arg1 : i32\n+  // CHECK: %[[DIV:.*]] = arith.divui %arg0, %[[BOUNDED_RHS]] : i32\n+  // CHECK: %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %[[C_1]], %[[DIV]] : i32\n+  %0 = arith.divui %arg0, %arg1 {xla.guard_ub} : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @unsigned_div_vector(%arg0: vector<4xi32>, %arg1: vector<4xi32>) -> vector<4xi32> {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant dense<-1> : vector<4xi32>\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant dense<0> : vector<4xi32>\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant dense<1> : vector<4xi32>\n+  // CHECK: %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : vector<4xi32>\n+  // CHECK: %[[BOUNDED_RHS:.*]] = arith.select %[[RHS_ZERO]], %[[C1]], %arg1 :  vector<4xi1>, vector<4xi32>\n+  // CHECK: %[[DIV:.*]] = arith.divui %arg0, %[[BOUNDED_RHS]] : vector<4xi32>\n+  // CHECK: %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %[[C_1]], %[[DIV]] :  vector<4xi1>, vector<4xi32>\n+  %0 = arith.divui %arg0, %arg1 {xla.guard_ub} : vector<4xi32>\n+  // CHECK: return %[[RESULT]] : vector<4xi32>\n+  func.return %0 : vector<4xi32>\n+}\n+\n+// -----\n+\n+func.func @signed_rem(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant -1 : i32\n+  // CHECK-DAG: %[[CMIN:.*]] = arith.constant -2147483648 : i32\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant 0 : i32\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant 1 : i32\n+  // CHECK:     %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : i32\n+  // CHECK:     %[[LHS_MIN:.*]] = arith.cmpi eq, %arg0, %[[CMIN]] : i32\n+  // CHECK:     %[[RHS_MINUS1:.*]] = arith.cmpi eq, %arg1, %[[C_1]] : i32\n+  // CHECK:     %[[OVERFLOW:.*]] = arith.andi %[[LHS_MIN]], %[[RHS_MINUS1]] : i1\n+  // CHECK:     %[[IS_UB:.*]] = arith.ori %[[RHS_ZERO]], %[[OVERFLOW]] : i1\n+  // CHECK:     %[[BOUNDED_RHS:.*]] = arith.select %[[IS_UB]], %[[C1]], %arg1 : i32\n+  // CHECK:     %[[REM:.*]] = arith.remsi %arg0, %[[BOUNDED_RHS]] : i32\n+  // CHECK:     %[[OVERFLOW_RESULT:.*]] = arith.select %[[OVERFLOW]], %[[C0]], %[[REM]] : i32\n+  // CHECK:     %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %arg0, %[[OVERFLOW_RESULT]] : i32\n+  %0 = arith.remsi %arg0, %arg1 {xla.guard_ub} : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @signed_rem_vector(%arg0: vector<2xi32>, %arg1: vector<2xi32>) -> vector<2xi32> {\n+  // CHECK-DAG: %[[C_1:.*]] = arith.constant dense<-1> : vector<2xi32>\n+  // CHECK-DAG: %[[CMIN:.*]] = arith.constant dense<-2147483648> : vector<2xi32>\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant dense<0> : vector<2xi32>\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant dense<1> : vector<2xi32>\n+  // CHECK:     %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : vector<2xi32>\n+  // CHECK:     %[[LHS_MIN:.*]] = arith.cmpi eq, %arg0, %[[CMIN]] : vector<2xi32>\n+  // CHECK:     %[[RHS_MINUS1:.*]] = arith.cmpi eq, %arg1, %[[C_1]] : vector<2xi32>\n+  // CHECK:     %[[OVERFLOW:.*]] = arith.andi %[[LHS_MIN]], %[[RHS_MINUS1]] : vector<2xi1>\n+  // CHECK:     %[[IS_UB:.*]] = arith.ori %[[RHS_ZERO]], %[[OVERFLOW]] : vector<2xi1>\n+  // CHECK:     %[[BOUNDED_RHS:.*]] = arith.select %[[IS_UB]], %[[C1]], %arg1 : vector<2xi1>, vector<2xi32>\n+  // CHECK:     %[[REM:.*]] = arith.remsi %arg0, %[[BOUNDED_RHS]] : vector<2xi32>\n+  // CHECK:     %[[OVERFLOW_RESULT:.*]] = arith.select %[[OVERFLOW]], %[[C0]], %[[REM]] : vector<2xi1>, vector<2xi32>\n+  // CHECK:     %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %arg0, %[[OVERFLOW_RESULT]] : vector<2xi1>, vector<2xi32>\n+  %0 = arith.remsi %arg0, %arg1 {xla.guard_ub} : vector<2xi32>\n+  // CHECK: return %[[RESULT]] : vector<2xi32>\n+  func.return %0 : vector<2xi32>\n+}\n+\n+// -----\n+\n+func.func @unsigned_rem(%arg0: i32, %arg1: i32) -> i32 {\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant 0 : i32\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant 1 : i32\n+  // CHECK: %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : i32\n+  // CHECK: %[[BOUNDED_RHS:.*]] = arith.select %[[RHS_ZERO]], %[[C1]], %arg1 : i32\n+  // CHECK: %[[REM:.*]] = arith.remui %arg0, %[[BOUNDED_RHS]] : i32\n+  // CHECK: %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %arg0, %[[REM]] : i32\n+  %0 = arith.remui %arg0, %arg1 {xla.guard_ub} : i32\n+  // CHECK: return %[[RESULT]] : i32\n+  func.return %0 : i32\n+}\n+\n+// -----\n+\n+func.func @unsigned_rem_vectors(%arg0: vector<16xi32>, %arg1: vector<16xi32>) -> vector<16xi32> {\n+  // CHECK-DAG: %[[C0:.*]] = arith.constant dense<0> : vector<16xi32>\n+  // CHECK-DAG: %[[C1:.*]] = arith.constant dense<1> : vector<16xi32>\n+  // CHECK: %[[RHS_ZERO:.*]] = arith.cmpi eq, %arg1, %[[C0]] : vector<16xi32>\n+  // CHECK: %[[BOUNDED_RHS:.*]] = arith.select %[[RHS_ZERO]], %[[C1]], %arg1 : vector<16xi1>, vector<16xi32>\n+  // CHECK: %[[REM:.*]] = arith.remui %arg0, %[[BOUNDED_RHS]] : vector<16xi32>\n+  // CHECK: %[[RESULT:.*]] = arith.select %[[RHS_ZERO]], %arg0, %[[REM]] : vector<16xi1>, vector<16xi32>\n+  %0 = arith.remui %arg0, %arg1 {xla.guard_ub} : vector<16xi32>\n+  // CHECK: return %[[RESULT]] : vector<16xi32>\n+  func.return %0 : vector<16xi32>\n+}"
        },
        {
            "sha": "f24c9f3781f925ff95860ba2601fe3777bc719f0",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/map_mhlo_to_scalar_op.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmap_mhlo_to_scalar_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1b20454202645ec17e272dc26d3b1699e1e45b4/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmap_mhlo_to_scalar_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmap_mhlo_to_scalar_op.h?ref=f1b20454202645ec17e272dc26d3b1699e1e45b4",
            "patch": "@@ -893,7 +893,7 @@ inline Value mapMhloOpToStdScalarOp<mhlo::ClampOp>(\n }\n \n template <typename U, typename S>\n-inline Value makeSafeIntDiv(ImplicitLocOpBuilder& lb, Type originalType,\n+inline Value makeSafeIntDiv(ImplicitLocOpBuilder& lb, bool isUnsigned,\n                             Value lhs, Value rhs, Value returnedOnZero,\n                             Value returnedOnSignedOverflow) {\n   Type type = lhs.getType();\n@@ -908,7 +908,7 @@ inline Value makeSafeIntDiv(ImplicitLocOpBuilder& lb, Type originalType,\n       lb.create<arith::CmpIOp>(arith::CmpIPredicate::eq, rhs, zero);\n \n   // For unsigned just set the divisor to 1 when it would be 0.\n-  if (originalType.isUnsignedInteger()) {\n+  if (isUnsigned) {\n     Value safeRhs = lb.create<arith::SelectOp>(rhsIsZero, one, rhs);\n     Value safeDiv = lb.create<U>(lhs, safeRhs);\n     return lb.create<arith::SelectOp>(rhsIsZero, returnedOnZero, safeDiv);\n@@ -956,7 +956,7 @@ inline Value mapMhloOpToStdScalarOp<mhlo::DivOp>(\n   Value minusOne = makeConstant(APInt::getAllOnes(elementType.getWidth()));\n   Value smin = makeConstant(APInt::getSignedMinValue(elementType.getWidth()));\n   return makeSafeIntDiv<arith::DivUIOp, arith::DivSIOp>(\n-      lb, originalType, adaptor.getLhs(), adaptor.getRhs(),\n+      lb, originalType.isUnsignedInteger(), adaptor.getLhs(), adaptor.getRhs(),\n       /*returnedOnZero=*/minusOne,\n       /*returnedOnSignedOverflow=*/smin);\n }\n@@ -980,7 +980,7 @@ inline Value mapMhloOpToStdScalarOp<mhlo::RemOp>(\n   Type type = adaptor.getLhs().getType();\n   Value zero = lb.create<arith::ConstantOp>(lb.getZeroAttr(type));\n   return makeSafeIntDiv<arith::RemUIOp, arith::RemSIOp>(\n-      lb, originalType, adaptor.getLhs(), adaptor.getRhs(),\n+      lb, originalType.isUnsignedInteger(), adaptor.getLhs(), adaptor.getRhs(),\n       /*returnedOnZero=*/adaptor.getLhs(),\n       /*returnedOnSignedOverflow=*/zero);\n }"
        }
    ],
    "stats": {
        "total": 346,
        "additions": 340,
        "deletions": 6
    }
}