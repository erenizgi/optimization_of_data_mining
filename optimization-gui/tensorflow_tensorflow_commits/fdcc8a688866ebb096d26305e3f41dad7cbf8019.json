{
    "author": "tensorflower-gardener",
    "message": "Replace RBE Docker container image: use Docker image without pre-installed CUDA packages.\n\nEnable CUDA forward-compatibility mode in all RBE jobs by default.\n\nForward compatibility mode in hermetic CUDA allows the linker to use the user-mode driver from Bazel cache, so there is no need to install UMD in the RBE Docker image.\n\nUMD on RBE machines is rarely updated, thus RBE jobs need forward compatibility mode to enable the most recent CUDA features usage in the tests.\n\nThe non-RBE job runners are updated more often, hence we can update the drivers on those machines and not rely on forward compatibility mode.\n\nPiperOrigin-RevId: 810595379",
    "sha": "fdcc8a688866ebb096d26305e3f41dad7cbf8019",
    "files": [
        {
            "sha": "2d88beaa52d2bd01a1861df363b8b33d5114c8dc",
            "filename": ".bazelrc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/.bazelrc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/.bazelrc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/.bazelrc?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -169,6 +169,7 @@ build --repo_env USE_HERMETIC_CC_TOOLCHAIN=1\n # TODO: Migrate for https://github.com/bazelbuild/bazel/issues/7260\n build:clang_local --noincompatible_enable_cc_toolchain_resolution\n build:clang_local --noincompatible_enable_android_toolchain_resolution\n+build:clang_local --@rules_ml_toolchain//common:enable_hermetic_cc=False\n build:clang_local --repo_env USE_HERMETIC_CC_TOOLCHAIN=0\n \n # Print a stacktrace when a test is killed\n@@ -665,6 +666,9 @@ build:rbe_linux_cuda --config=cuda_clang_official\n build:rbe_linux_cuda --config=rbe_linux_cpu\n # For Remote build execution -- GPU configuration\n build:rbe_linux_cuda --repo_env=REMOTE_GPU_TESTING=1\n+# Enable forward compatibility for CUDA builds because RBE docker image doesn't\n+# have latest CUDA drivers installed.\n+build:rbe_linux_cuda --@cuda_driver//:enable_forward_compatibility=true\n \n build:rbe_linux_cuda_nvcc --config=rbe_linux_cuda\n build:rbe_linux_cuda_nvcc --config=cuda_nvcc"
        },
        {
            "sha": "c9de6694a753803a8844562f6f44d58ef480ad8f",
            "filename": "WORKSPACE",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/WORKSPACE",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/WORKSPACE",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/WORKSPACE?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -102,6 +102,10 @@ register_toolchains(\"@rules_ml_toolchain//cc:linux_x86_64_linux_x86_64\")\n \n register_toolchains(\"@rules_ml_toolchain//cc:linux_x86_64_linux_x86_64_cuda\")\n \n+register_toolchains(\"@rules_ml_toolchain//cc:linux_aarch64_linux_aarch64\")\n+\n+register_toolchains(\"@rules_ml_toolchain//cc:linux_aarch64_linux_aarch64_cuda\")\n+\n load(\n     \"@rules_ml_toolchain//third_party/gpus/cuda/hermetic:cuda_json_init_repository.bzl\",\n     \"cuda_json_init_repository\","
        },
        {
            "sha": "fbf723bb44ade9ed25dc438dbaa913e8c8f73593",
            "filename": "tensorflow/tools/toolchains/remote_config/configs.bzl",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -47,10 +47,11 @@ def initialize_rbe_configs():\n         python_bin_path = \"C:/Python37/python.exe\",\n     )\n \n-    # The `ml-build-rbe` image is identical to the `ml-build` image except for the base image.\n     # The `ml-build`'s base image is a standard `ubuntu22.04` image.\n-    # The `ml-build-rbe`'s base image is `nvidia/cuda:12.3.2-base-ubuntu22.04` which has nvidia driver installed.\n-    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-rbe@sha256:468a498a1f1f49daa257dcf8ee2f653c8c54e7621da511ce3ab7c14fcbd92d6f\")\n+    # Note that in order to use this image with RBE GPU builds, you need to have hermetic CUDA\n+    # toolchain integrated into your project, and pass\n+    # `--@cuda_driver//:enable_forward_compatibility=true` to Bazel command.\n+    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build@sha256:ea67e8453d8b09c2ba48853da5e79efef4b65804b4a48dfae4b4da89ffd38405\")\n \n     # TF-Version-Specific SIG Build RBE Configs. The crosstool generated from these\n     # configs are python-version-independent because they only care about the"
        },
        {
            "sha": "17242556683f93ad7d14ec9f6101eb28655ca015",
            "filename": "tensorflow/workspace0.bzl",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/tensorflow%2Fworkspace0.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/tensorflow%2Fworkspace0.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fworkspace0.bzl?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -140,10 +140,10 @@ def workspace():\n     # Details: https://github.com/google-ml-infra/rules_ml_toolchain\n     http_archive(\n         name = \"rules_ml_toolchain\",\n-        sha256 = \"59d7eb36a02cbe3c2e2fa67fda5e8f1ab7e274bc4773bbd207c51fe199e11c19\",\n-        strip_prefix = \"rules_ml_toolchain-ffd9e3d7b84e43c2686c803cb08ce790ffd58baa\",\n+        sha256 = \"77ad040f826af31ce3142e3b8bcf6c61972b4f95c84185676fa1af325fbf52c6\",\n+        strip_prefix = \"rules_ml_toolchain-a912c87727405e2145b168e5b62a5d5ae7232cb2\",\n         urls = [\n-            \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/ffd9e3d7b84e43c2686c803cb08ce790ffd58baa.tar.gz\",\n+            \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/a912c87727405e2145b168e5b62a5d5ae7232cb2.tar.gz\",\n         ],\n     )\n "
        },
        {
            "sha": "e54ff01be85d74c8f54abb963b65cd6009e01a5f",
            "filename": "third_party/xla/.github/workflows/benchmarks/build_binaries.sh",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fbuild_binaries.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fbuild_binaries.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2F.github%2Fworkflows%2Fbenchmarks%2Fbuild_binaries.sh?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -85,13 +85,13 @@ case \"$HARDWARE_CATEGORY\" in\n     device_type_flag_value=\"host\"\n     ;;\n   GPU_L4)\n-    BUILD_TYPE=\"XLA_LINUX_X86_GPU_L4_16_VCPU_PRESUBMIT_GITHUB_ACTIONS\" # Or _48_VCPU if that's the more common\n+    BUILD_TYPE=\"XLA_LINUX_X86_GPU_L4_16_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\" # Or _48_VCPU if that's the more common\n     runner_binary_path=\"./$BAZEL_BIN_DIR/xla/tools/multihost_hlo_runner/hlo_runner_main_gpu\"\n     stats_binary_path=\"./$BAZEL_BIN_DIR/xla/tools/compute_xspace_stats_main_gpu\"\n     device_type_flag_value=\"gpu\"\n     ;;\n   GPU_B200)\n-    BUILD_TYPE=\"XLA_LINUX_X86_GPU_A4_224_VCPU_PRESUBMIT_GITHUB_ACTIONS\"\n+    BUILD_TYPE=\"XLA_LINUX_X86_GPU_A4_224_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\"\n     runner_binary_path=\"./$BAZEL_BIN_DIR/xla/tools/multihost_hlo_runner/hlo_runner_main_gpu\"\n     stats_binary_path=\"./$BAZEL_BIN_DIR/xla/tools/compute_xspace_stats_main_gpu\"\n     device_type_flag_value=\"gpu\""
        },
        {
            "sha": "bd737f2542e654f7c6bfa539b75693c5f406bd98",
            "filename": "third_party/xla/WORKSPACE",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2FWORKSPACE",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2FWORKSPACE",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2FWORKSPACE?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -9,10 +9,10 @@ load(\"@bazel_tools//tools/build_defs/repo:http.bzl\", \"http_archive\")\n # Details: https://github.com/google-ml-infra/rules_ml_toolchain\n http_archive(\n     name = \"rules_ml_toolchain\",\n-    sha256 = \"1a855dd94eebedae69d1804e8837ad70b8018358a0a03eea0bec71d7dc2b096a\",\n-    strip_prefix = \"rules_ml_toolchain-d321763a84c900bc29b4f5459a4f81fad19b2356\",\n+    sha256 = \"77ad040f826af31ce3142e3b8bcf6c61972b4f95c84185676fa1af325fbf52c6\",\n+    strip_prefix = \"rules_ml_toolchain-a912c87727405e2145b168e5b62a5d5ae7232cb2\",\n     urls = [\n-        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/d321763a84c900bc29b4f5459a4f81fad19b2356.tar.gz\",\n+        \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/a912c87727405e2145b168e5b62a5d5ae7232cb2.tar.gz\",\n     ],\n )\n "
        },
        {
            "sha": "c34fa4b52175793b4c0880bf9ceb2e68721c073b",
            "filename": "third_party/xla/build_tools/ci/build.py",
            "status": "modified",
            "additions": 105,
            "deletions": 0,
            "changes": 105,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -117,6 +117,9 @@ class BuildType(enum.Enum):\n   XLA_LINUX_X86_GPU_L4_16_VCPU_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n   XLA_LINUX_X86_GPU_L4_48_VCPU_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n   XLA_LINUX_X86_GPU_A4_224_VCPU_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n+  XLA_LINUX_X86_GPU_L4_16_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n+  XLA_LINUX_X86_GPU_L4_48_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n+  XLA_LINUX_X86_GPU_A4_224_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS = enum.auto()\n \n   XLA_MACOS_X86_CPU_KOKORO = enum.auto()\n   XLA_MACOS_ARM64_CPU_KOKORO = enum.auto()\n@@ -429,6 +432,39 @@ def nvidia_gpu_build_with_compute_capability(\n     subcommand=\"build\",\n )\n \n+Build(\n+    type_=BuildType.XLA_LINUX_X86_GPU_L4_16_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS,\n+    repo=\"openxla/xla\",\n+    target_patterns=_XLA_GPU_PRESUBMIT_BENCHMARKS_DEFAULT_TARGET_PATTERNS,\n+    configs=(\"warnings\", \"rbe_linux_cuda_nvcc\"),\n+    test_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    )\n+    + _tag_filters_for_compute_capability(compute_capability=75),\n+    build_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    ),\n+    options={\n+        \"run_under\": \"//build_tools/ci:parallel_gpu_execute\",\n+        \"//xla/tsl:ci_build\": True,\n+        \"@local_config_cuda//cuda:include_cuda_libs\": False,\n+        **_DEFAULT_BAZEL_OPTIONS,\n+    },\n+    repo_env={\n+        \"TF_CUDA_COMPUTE_CAPABILITIES\": \"7.5\",\n+    },\n+    extra_setup_commands=([\"nvidia-smi\"],),\n+    subcommand=\"build\",\n+)\n+\n Build(\n     type_=BuildType.XLA_LINUX_X86_GPU_L4_48_VCPU_PRESUBMIT_GITHUB_ACTIONS,\n     repo=\"openxla/xla\",\n@@ -461,6 +497,39 @@ def nvidia_gpu_build_with_compute_capability(\n     subcommand=\"build\",\n )\n \n+Build(\n+    type_=BuildType.XLA_LINUX_X86_GPU_L4_48_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS,\n+    repo=\"openxla/xla\",\n+    configs=(\"warnings\", \"rbe_linux_cuda_nvcc\"),\n+    target_patterns=_XLA_GPU_PRESUBMIT_BENCHMARKS_DEFAULT_TARGET_PATTERNS,\n+    test_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    )\n+    + _tag_filters_for_compute_capability(compute_capability=75),\n+    build_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    ),\n+    options={\n+        \"run_under\": \"//build_tools/ci:parallel_gpu_execute\",\n+        \"//xla/tsl:ci_build\": True,\n+        \"@local_config_cuda//cuda:include_cuda_libs\": False,\n+        **_DEFAULT_BAZEL_OPTIONS,\n+    },\n+    repo_env={\n+        \"TF_CUDA_COMPUTE_CAPABILITIES\": \"7.5\",\n+    },\n+    extra_setup_commands=([\"nvidia-smi\"],),\n+    subcommand=\"build\",\n+)\n+\n Build(\n     type_=BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_PRESUBMIT_GITHUB_ACTIONS,\n     repo=\"openxla/xla\",\n@@ -496,6 +565,42 @@ def nvidia_gpu_build_with_compute_capability(\n     subcommand=\"build\",\n )\n \n+Build(\n+    type_=BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS,\n+    repo=\"openxla/xla\",\n+    configs=(),\n+    target_patterns=_XLA_GPU_PRESUBMIT_BENCHMARKS_DEFAULT_TARGET_PATTERNS,\n+    test_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    )\n+    + _tag_filters_for_compute_capability(compute_capability=100),\n+    build_tag_filters=(\n+        \"-no_oss\",\n+        \"requires-gpu-nvidia\",\n+        \"gpu\",\n+        \"-rocm-only\",\n+        \"-oneapi-only\",\n+    ),\n+    options={\n+        \"run_under\": \"//build_tools/ci:parallel_gpu_execute\",\n+        # Use User Mode and Kernel Mode Drivers pre-installed on the system.\n+        \"//xla/tsl:ci_build\": True,\n+        \"@local_config_cuda//cuda:include_cuda_libs\": False,\n+        **_DEFAULT_BAZEL_OPTIONS,\n+    },\n+    repo_env={\n+        \"TF_CUDA_COMPUTE_CAPABILITIES\": \"10\",\n+        \"HERMETIC_CUDA_VERSION\": \"12.8.0\",\n+        \"HERMETIC_CUDNN_VERSION\": \"9.8.0\",\n+    },\n+    extra_setup_commands=([\"nvidia-smi\"],),\n+    subcommand=\"build\",\n+)\n+\n macos_tag_filter = (\n     \"-no_oss\",\n     \"-gpu\","
        },
        {
            "sha": "508892fe7c8689a1ee7f691fef34146b3cec1120",
            "filename": "third_party/xla/build_tools/ci/golden_commands.txt",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -44,18 +44,36 @@ parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_fi\n bazel test --build_tag_filters=-no_oss,-gpu,-requires-gpu-nvidia,-requires-gpu-amd,-requires-gpu-intel --test_tag_filters=-no_oss,-gpu,-requires-gpu-nvidia,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=nonccl --config=rbe_linux_cpu --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build -- //xla/... //build_tools/... @local_tsl//tsl/...\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_CPU_GITHUB_ACTIONS\n+# BEGIN BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n+nvidia-smi\n+parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm100-only,requires-gpu-sm60,requires-gpu-sm70,requires-gpu-sm80,requires-gpu-sm90,requires-gpu-sm100,-requires-gpu-amd,-requires-gpu-intel --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=10 --repo_env=HERMETIC_CUDA_VERSION=12.8.0 --repo_env=HERMETIC_CUDNN_VERSION=9.8.0 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm100-only,requires-gpu-sm60,requires-gpu-sm70,requires-gpu-sm80,requires-gpu-sm90,requires-gpu-sm100,-requires-gpu-amd,-requires-gpu-intel --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=10 --repo_env=HERMETIC_CUDA_VERSION=12.8.0 --repo_env=HERMETIC_CUDNN_VERSION=9.8.0 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel analyze-profile profile.json.gz\n+# END BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_PRESUBMIT_GITHUB_ACTIONS\n nvidia-smi\n parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm100-only,requires-gpu-sm60,requires-gpu-sm70,requires-gpu-sm80,requires-gpu-sm90,requires-gpu-sm100,-requires-gpu-amd,-requires-gpu-intel --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=10 --repo_env=HERMETIC_CUDA_VERSION=12.8.0 --repo_env=HERMETIC_CUDNN_VERSION=9.8.0 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm100-only,requires-gpu-sm60,requires-gpu-sm70,requires-gpu-sm80,requires-gpu-sm90,requires-gpu-sm100,-requires-gpu-amd,-requires-gpu-intel --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=10 --repo_env=HERMETIC_CUDA_VERSION=12.8.0 --repo_env=HERMETIC_CUDNN_VERSION=9.8.0 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_A4_224_VCPU_PRESUBMIT_GITHUB_ACTIONS\n+# BEGIN BuildType.XLA_LINUX_X86_GPU_L4_16_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n+nvidia-smi\n+parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel analyze-profile profile.json.gz\n+# END BuildType.XLA_LINUX_X86_GPU_L4_16_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_LINUX_X86_GPU_L4_16_VCPU_PRESUBMIT_GITHUB_ACTIONS\n nvidia-smi\n parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_L4_16_VCPU_PRESUBMIT_GITHUB_ACTIONS\n+# BEGIN BuildType.XLA_LINUX_X86_GPU_L4_48_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n+nvidia-smi\n+parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --@local_config_cuda//cuda:include_cuda_libs=False --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu\n+bazel analyze-profile profile.json.gz\n+# END BuildType.XLA_LINUX_X86_GPU_L4_48_VCPU_BENCHMARK_PRESUBMIT_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_LINUX_X86_GPU_L4_48_VCPU_PRESUBMIT_GITHUB_ACTIONS\n nvidia-smi\n parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only --test_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneapi-only,requires-gpu-sm75-only,requires-gpu-sm60,requires-gpu-sm70,-requires-gpu-sm80,-requires-gpu-sm80-only,-requires-gpu-sm90,-requires-gpu-sm90-only,-requires-gpu-sm100,-requires-gpu-sm100-only,-requires-gpu-amd,-requires-gpu-intel --config=warnings --config=rbe_linux_cuda_nvcc --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=7.5 --run_under=//build_tools/ci:parallel_gpu_execute --//xla/tsl:ci_build --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --nobuild -- //xla/tools/multihost_hlo_runner:hlo_runner_main_gpu //xla/tools:compute_xspace_stats_main_gpu"
        },
        {
            "sha": "a81d70cb4139f77f53fe2bd7ba69d7da13d59949",
            "filename": "third_party/xla/tensorflow.bazelrc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Ftensorflow.bazelrc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Ftensorflow.bazelrc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Ftensorflow.bazelrc?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -545,6 +545,9 @@ build:rbe_linux_cuda --config=rbe_linux_cpu\n build:rbe_linux_cuda --repo_env=TF_SYSROOT=\n # For Remote build execution -- GPU configuration\n build:rbe_linux_cuda --repo_env=REMOTE_GPU_TESTING=1\n+# Enable forward compatibility for CUDA builds because RBE docker image doesn't\n+# have latest CUDA drivers installed.\n+build:rbe_linux_cuda --@cuda_driver//:enable_forward_compatibility=true\n \n build:rbe_linux_cuda_nvcc --config=rbe_linux_cuda\n build:rbe_linux_cuda_nvcc --config=cuda_nvcc"
        },
        {
            "sha": "4c689ece55a5366704a7a09b91fe33605a6478ae",
            "filename": "third_party/xla/tools/toolchains/remote_config/configs.bzl",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Ftools%2Ftoolchains%2Fremote_config%2Fconfigs.bzl?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -47,10 +47,11 @@ def initialize_rbe_configs():\n         python_bin_path = \"C:/Python37/python.exe\",\n     )\n \n-    # The `ml-build-rbe` image is identical to the `ml-build` image except for the base image.\n     # The `ml-build`'s base image is a standard `ubuntu22.04` image.\n-    # The `ml-build-rbe`'s base image is `nvidia/cuda:12.3.2-base-ubuntu22.04` which has nvidia driver installed.\n-    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-rbe@sha256:468a498a1f1f49daa257dcf8ee2f653c8c54e7621da511ce3ab7c14fcbd92d6f\")\n+    # Note that in order to use this image with RBE GPU builds, you need to have hermetic CUDA\n+    # toolchain integrated into your project, and pass\n+    # `--@cuda_driver//:enable_forward_compatibility=true` to Bazel command.\n+    ml_build_rbe_config(\"docker://us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build@sha256:ea67e8453d8b09c2ba48853da5e79efef4b65804b4a48dfae4b4da89ffd38405\")\n \n     # TF-Version-Specific SIG Build RBE Configs. The crosstool generated from these\n     # configs are python-version-independent because they only care about the"
        },
        {
            "sha": "e4e05b24a79bbdaf753731e7285427a292f2bb98",
            "filename": "third_party/xla/workspace0.bzl",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fworkspace0.bzl",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fdcc8a688866ebb096d26305e3f41dad7cbf8019/third_party%2Fxla%2Fworkspace0.bzl",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fworkspace0.bzl?ref=fdcc8a688866ebb096d26305e3f41dad7cbf8019",
            "patch": "@@ -140,10 +140,10 @@ def workspace():\n     if \"rules_ml_toolchain\" not in native.existing_rules():\n         http_archive(\n             name = \"rules_ml_toolchain\",\n-            sha256 = \"1a855dd94eebedae69d1804e8837ad70b8018358a0a03eea0bec71d7dc2b096a\",\n-            strip_prefix = \"rules_ml_toolchain-d321763a84c900bc29b4f5459a4f81fad19b2356\",\n+            sha256 = \"77ad040f826af31ce3142e3b8bcf6c61972b4f95c84185676fa1af325fbf52c6\",\n+            strip_prefix = \"rules_ml_toolchain-a912c87727405e2145b168e5b62a5d5ae7232cb2\",\n             urls = [\n-                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/d321763a84c900bc29b4f5459a4f81fad19b2356.tar.gz\",\n+                \"https://github.com/google-ml-infra/rules_ml_toolchain/archive/a912c87727405e2145b168e5b62a5d5ae7232cb2.tar.gz\",\n             ],\n         )\n "
        }
    ],
    "stats": {
        "total": 170,
        "additions": 153,
        "deletions": 17
    }
}