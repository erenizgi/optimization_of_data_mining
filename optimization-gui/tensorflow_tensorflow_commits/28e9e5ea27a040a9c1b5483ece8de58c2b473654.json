{
    "author": "subhankarshah",
    "message": "[XLA:MSA] Allow block prefetching for custom call prefetches that have aliased uses.\n* Extend alternate memory chunk reservations for aliased uses.\n* Add pinned allocations in alternate memory for aliased uses.\n* Mark all aliased allocations as colocated.\n\nPin all values aliased with the prefetched source value to default memory.\n\nPiperOrigin-RevId: 825801181",
    "sha": "28e9e5ea27a040a9c1b5483ece8de58c2b473654",
    "files": [
        {
            "sha": "0eedc0fd47f8bf3a5b0c05c262dc9c4cd988bbe2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 151,
            "deletions": 8,
            "changes": 159,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=28e9e5ea27a040a9c1b5483ece8de58c2b473654",
            "patch": "@@ -2245,9 +2245,11 @@ absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches() {\n   // 2. Update the operands in alternate memory map.\n   // 3. Add the copy done and copy start values to the finalized values set.\n   // 4. Add a repack allocation block to the repack allocation blocks list.\n-  // 5. Serve the uses of the original value from the pinned allocation in the\n+  // 5. If the prefetch done value is aliased with values other than the\n+  //    prefetch start value, allocate the aliased values.\n+  // 6. Serve the uses of the original value from the pinned allocation in the\n   //    default memory.\n-  // 6. Clear the pending chunks after the loop.\n+  // 7. Clear the pending chunks after the loop.\n   for (const HloValue* prefetch_done_value : block_prefetched_values) {\n     UseInterval use_interval = value_to_use_intervals.at(prefetch_done_value);\n     int64_t first_use_time = use_interval.first_use_time;\n@@ -2357,23 +2359,164 @@ absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches() {\n         allocations_->back().get()));\n     repack_allocation_blocks_.back().next_colocated =\n         &(repack_allocation_blocks_.back());\n+    const HloBuffer& buffer =\n+        alias_analysis_.GetBufferContainingValue(*prefetch_done_value);\n+\n+    // 5. If the prefetch done value is aliased with values other than the\n+    //    prefetch start value, allocate the aliased values.\n+    if (buffer.values().size() > 2) {\n+      ColocateAndFinalizeValuesAliasedToExistingBlockPrefetches(\n+          prefetch_done_value, buffer, chunk_candidate, buffer_size,\n+          &repack_allocation_blocks_.back(), instruction_schedule,\n+          value_to_use_intervals,\n+          prefetch_done_value_to_prefetch_start_instruction,\n+          prefetch_end_times);\n+    }\n   }\n \n-  // 5. Serve the uses of the original value from the pinned allocation in the\n+  // 6. Serve the uses of the original value from the pinned allocation in the\n   //    default memory.\n   for (auto [_, original_value] : prefetch_done_value_to_original_value) {\n-    Allocation* allocation = value_to_pinned_allocation[original_value];\n-    for (const HloUse& use : original_value->GetUses()) {\n-      allocation->AddUse(use);\n+    // Finalize all values aliased to the original value.\n+    // Note: We do not need to add pinned allocations for the aliased values,\n+    // just finalizing them is sufficient to ensure that they will be served\n+    // from default memory.\n+    const HloBuffer& buffer =\n+        alias_analysis_.GetBufferContainingValue(*original_value);\n+    for (const HloValue* aliased_value : buffer.values()) {\n+      if (finalized_values_.contains(aliased_value)) {\n+        continue;\n+      }\n+      // If a pinned allocation already exists for the aliased value, add the\n+      // uses of the original value to the pinned allocation.\n+      auto it = value_to_pinned_allocation.find(aliased_value);\n+      if (it != value_to_pinned_allocation.end()) {\n+        Allocation* allocation = it->second;\n+        for (const HloUse& use : original_value->GetUses()) {\n+          allocation->AddUse(use);\n+        }\n+      }\n+      finalized_values_.insert(aliased_value);\n     }\n-    finalized_values_.insert(original_value);\n   }\n \n-  // 6. Clear the pending chunks.\n+  // 7. Clear the pending chunks.\n   ClearPendingChunks();\n   return absl::OkStatus();\n }\n \n+void MsaAlgorithm::ColocateAndFinalizeValuesAliasedToExistingBlockPrefetches(\n+    const HloValue* prefetch_done_value, const HloBuffer& buffer,\n+    const Chunk& chunk_candidate, int64_t buffer_size,\n+    AllocationBlock* first_colocated_repack_allocation,\n+    const absl::flat_hash_map<const HloInstruction*, int64_t>&\n+        instruction_schedule,\n+    const absl::flat_hash_map<const HloValue*, UseInterval>&\n+        value_to_use_intervals,\n+    absl::flat_hash_map<const HloValue*, HloInstruction*>&\n+        prefetch_done_value_to_prefetch_start_instruction,\n+    std::vector<int64_t>& prefetch_end_times) {\n+  VLOG(1) << \"HloBuffer for block prefetched value: \"\n+          << prefetch_done_value->ToShortString()\n+          << \" aliases with: \" << (buffer.values().size() - 1)\n+          << \" other values\";\n+\n+  std::vector<const HloValue*> colocated_values;\n+  for (const HloValue* aliased_value : buffer.values()) {\n+    colocated_values.push_back(aliased_value);\n+  }\n+  absl::c_sort(colocated_values, [&](const HloValue* a, const HloValue* b) {\n+    return instruction_schedule.at(a->defining_instruction()) <\n+           instruction_schedule.at(b->defining_instruction());\n+  });\n+\n+  // After sorting by schedule time, the first two values in the colocated\n+  // values list should be the prefetch start and prefetch done values, followed\n+  // by their uses which might be aliased.\n+  CHECK_EQ(\n+      colocated_values[0]->instruction(),\n+      prefetch_done_value_to_prefetch_start_instruction[prefetch_done_value]);\n+  CHECK_EQ(colocated_values[1], prefetch_done_value);\n+\n+  int64_t prev_last_use_time =\n+      value_to_use_intervals.at(prefetch_done_value).last_use_time;\n+\n+  std::vector<AllocationBlock*> colocations;\n+  colocations.push_back(first_colocated_repack_allocation);\n+\n+  int64_t maybe_sliced_value_definition_time =\n+      instruction_schedule.at(prefetch_done_value->defining_instruction());\n+\n+  // For each of the colocated values that follow the block prefetched value,\n+  // extend the chunk candidate to the right and add a pinned allocation in\n+  // the alternate memory. We start from index 2, since the first two values\n+  // in the colocated values list are the prefetch start and prefetch done\n+  // values.\n+  for (int i = 2; i < colocated_values.size(); ++i) {\n+    const HloValue* aliased_value = colocated_values[i];\n+    CHECK(!finalized_values_.contains(aliased_value));\n+    int64_t aliased_value_definition_time =\n+        instruction_schedule.at(aliased_value->defining_instruction());\n+    CHECK_LT(maybe_sliced_value_definition_time, aliased_value_definition_time);\n+    // The last use time of the previous value in the colocated values list\n+    // should be the definition time of the current value in the colocated\n+    // values list. This is because only the last use of a value can be\n+    // aliased.\n+    CHECK_EQ(prev_last_use_time, aliased_value_definition_time);\n+    int64_t aliased_value_last_use_time = std::numeric_limits<int64_t>::min();\n+    for (const HloUse& use : aliased_value->GetUses()) {\n+      aliased_value_last_use_time =\n+          std::max(aliased_value_last_use_time,\n+                   instruction_schedule.at(use.instruction));\n+    }\n+    prev_last_use_time = aliased_value_last_use_time;\n+\n+    MsaBufferInterval aliased_interval = MsaBufferInterval{\n+        /*buffer=*/aliased_value,\n+        /*size=*/buffer_size,\n+        /*start=*/aliased_value_definition_time +\n+            1,  // We need to add 1 because a chunk is already reserved till\n+                // the prev_last_use_time which is equal to the\n+                // aliased_value_definition_time.\n+        /*end=*/aliased_value_last_use_time,\n+        /*colocations=*/{},\n+        /*need_allocation=*/true};\n+    Chunk aliased_chunk_candidate = FindChunkCandidate(\n+        aliased_interval, /*preferred_offset=*/chunk_candidate.offset);\n+    // The aliased chunk candidate should be the same as the chunk candidate,\n+    // since they are colocated and aliased. We are in principle extending the\n+    // same chunk candidate to the right and we should always be able to do\n+    // that because we are processing the values from left to right and we\n+    // have checked that the prefetched value is only aliased to the right.\n+    CHECK_EQ(aliased_chunk_candidate, chunk_candidate);\n+    allocations_->push_back(std::make_unique<PinnedAllocation>(\n+        aliased_value->defining_position(), MemorySpace::kAlternate,\n+        aliased_chunk_candidate, aliased_value_definition_time,\n+        aliased_value_last_use_time));\n+    AddToPendingChunks(aliased_interval, aliased_chunk_candidate);\n+    for (const HloUse& use : aliased_value->GetUses()) {\n+      allocations_->back()->AddUse(use);\n+      operands_in_alternate_memory_map_[use.instruction].insert(\n+          std::make_pair(use.operand_number, use.operand_index));\n+    }\n+    auto const sorted_position =\n+        std::lower_bound(prefetch_end_times.begin(), prefetch_end_times.end(),\n+                         aliased_value_last_use_time);\n+    prefetch_end_times.insert(sorted_position, aliased_value_last_use_time);\n+    finalized_values_.insert(aliased_value);\n+    repack_allocation_blocks_.push_back(MakeRepackAllocationBlock(\n+        aliased_value_definition_time, aliased_value_last_use_time,\n+        aliased_chunk_candidate.size, aliased_chunk_candidate.offset,\n+        allocations_->back().get()));\n+    repack_allocation_blocks_.back().next_colocated =\n+        &(repack_allocation_blocks_.back());\n+    colocations.push_back(&repack_allocation_blocks_.back());\n+  }\n+\n+  // Mark repack allocation blocks as colocated.\n+  MarkRepackAllocationBlocksColocated(colocations);\n+}\n+\n absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n   if (!options_.hlo_position_to_custom_call_prefetch_details.empty() ||\n       options_.reserved_bytes_for_block_prefetches <= 0) {"
        },
        {
            "sha": "e6ae2d6101eea9886e2637556074f978dd302945",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=28e9e5ea27a040a9c1b5483ece8de58c2b473654",
            "patch": "@@ -385,6 +385,20 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n           value_to_use_intervals,\n       std::vector<int64_t>& prefetch_end_times);\n \n+  // Creates colocated allocations for values aliased to existing block\n+  // prefetches and finalizes them.\n+  void ColocateAndFinalizeValuesAliasedToExistingBlockPrefetches(\n+      const HloValue* prefetch_done_value, const HloBuffer& buffer,\n+      const Chunk& chunk_candidate, int64_t buffer_size,\n+      AllocationBlock* first_colocated_repack_allocation,\n+      const absl::flat_hash_map<const HloInstruction*, int64_t>&\n+          instruction_schedule,\n+      const absl::flat_hash_map<const HloValue*, UseInterval>&\n+          value_to_use_intervals,\n+      absl::flat_hash_map<const HloValue*, HloInstruction*>&\n+          prefetch_done_value_to_prefetch_start_instruction,\n+      std::vector<int64_t>& prefetch_end_times);\n+\n   // Returns the maximum amount of scoped memory that is reserved at any time in\n   // the program.\n   int64_t MaxScopedMemoryOffset();"
        },
        {
            "sha": "5730a254836fa2e506bf694f814c6ce335dc8ad2",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 265,
            "deletions": 0,
            "changes": 265,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/28e9e5ea27a040a9c1b5483ece8de58c2b473654/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=28e9e5ea27a040a9c1b5483ece8de58c2b473654",
            "patch": "@@ -15806,6 +15806,271 @@ ENTRY entry {\n       /*operand_memory_space=*/kDefaultMemorySpace);\n }\n \n+TEST_F(MemorySpaceAssignmentTest,\n+       TestScheduleCustomCallPrefetchesWithAliasing) {\n+  // params p0, p1, p2 have sliced and non-sliced custom call prefetches.\n+  // slice_done_1 and prefetch_done_0 have multiple uses.\n+  // p0, p1 and p2 have uses apart from the custom call prefetches.\n+  // custom_call17 output aliases with prefetch_done_0, extending the live range\n+  // of prefetch_done_0 by sharing the buffer with one additional hlo value.\n+  // custom_call15 output aliases with slice_done_5 and custom_call21\n+  // output aliases with custom_call17, extending the live range of\n+  // slice_done_5, by sharing the buffer with two additional hlo values.\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = f32[4,3]{1,0} parameter(0)\n+  p1 = f32[4,3]{1,0} parameter(1)\n+  p2 = f32[4,3]{1,0} parameter(2)\n+\n+  prefetch_start0 = (f32[4,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  prefetch_start0_gte_0 = f32[4,3]{1,0} get-tuple-element(prefetch_start0), index=0\n+  prefetch_start0_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(prefetch_start0), index=1\n+  prefetch_done_0 = f32[4,3]{1,0} custom-call(p0, prefetch_start0_gte_0, prefetch_start0_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+\n+  slice_start_0 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  slice_start_0_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_0), index=0\n+  slice_start_0_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_0), index=1\n+  slice_done_0 = f32[2,3]{1,0} custom-call(p0, slice_start_0_gte_0, slice_start_0_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_1 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p1), custom_call_target=\"tpu_custom_call\"\n+  slice_start_1_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_1), index=0\n+  slice_start_1_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_1), index=1\n+  slice_done_1 = f32[2,3]{1,0} custom-call(p1, slice_start_1_gte_0, slice_start_1_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_2 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p2), custom_call_target=\"tpu_custom_call\"\n+  slice_start_2_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_2), index=0\n+  slice_start_2_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_2), index=1\n+  slice_done_2 = f32[2,3]{1,0} custom-call(p2, slice_start_2_gte_0, slice_start_2_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_3 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p0), custom_call_target=\"tpu_custom_call\"\n+  slice_start_3_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_3), index=0\n+  slice_start_3_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_3), index=1\n+  slice_done_3 = f32[2,3]{1,0} custom-call(p0, slice_start_3_gte_0, slice_start_3_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_4 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p1), custom_call_target=\"tpu_custom_call\"\n+  slice_start_4_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_4), index=0\n+  slice_start_4_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_4), index=1\n+  slice_done_4 = f32[2,3]{1,0} custom-call(p1, slice_start_4_gte_0, slice_start_4_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  slice_start_5 = (f32[2,3]{1,0}, s32[]{:T(128)S(2)}) custom-call(p2), custom_call_target=\"tpu_custom_call\"\n+  slice_start_5_gte_0 = f32[2,3]{1,0} get-tuple-element(slice_start_5), index=0\n+  slice_start_5_gte_1 = s32[]{:T(128)S(2)} get-tuple-element(slice_start_5), index=1\n+  slice_done_5 = f32[2,3]{1,0} custom-call(p2, slice_start_5_gte_0, slice_start_5_gte_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  negate0 = f32[2,3]{1,0} negate(slice_done_0)\n+  negate1 = f32[2,3]{1,0} negate(negate0)\n+  negate2 = f32[2,3]{1,0} negate(negate1)\n+  add3 = f32[2,3]{1,0} add(slice_done_1, negate2)\n+  negate4 = f32[2,3]{1,0} negate(add3)\n+  negate5 = f32[2,3]{1,0} negate(negate4)\n+  add6 = f32[2,3]{1,0} add(slice_done_2, negate5)\n+  negate7 = f32[2,3]{1,0} negate(add6)\n+  negate8 = f32[2,3]{1,0} negate(negate7)\n+  add9 = f32[2,3]{1,0} add(slice_done_3, negate8)\n+  negate10 = f32[2,3]{1,0} negate(add9)\n+  add11 = f32[2,3]{1,0} add(slice_done_1, negate10)\n+  add12 = f32[2,3]{1,0} add(slice_done_4, add11)\n+  negate13 = f32[2,3]{1,0} negate(add12)\n+  negate14 = f32[2,3]{1,0} negate(negate13)\n+  custom_call15 = f32[2,3]{1,0} custom-call(slice_done_5, negate14), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate16 = f32[4,3]{1,0} negate(prefetch_done_0)\n+  custom_call17 = f32[4,3]{1,0} custom-call(prefetch_done_0, negate16), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  add18 = f32[4,3]{1,0} add(p0, custom_call17)\n+  add19 = f32[4,3]{1,0} add(p1, add18)\n+  add20 = f32[4,3]{1,0} add(p2, custom_call17)\n+  custom_call21 = f32[4,3]{1,0} custom-call(add19, custom_call17), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+  add22 = f32[4,3]{1,0} add(add20, custom_call21)\n+  add23 = f32[2,3]{1,0} add(negate14, custom_call15)\n+  ROOT tuple = (f32[4,3]{1,0}, f32[2,3]{1,0}) tuple(add22, add23)\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 96;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 96;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+  memory_space_options.verify = true;\n+\n+  std::vector<CustomCallPrefetchInfo> custom_call_prefetch_instructions = {\n+      {\"p0\", \"prefetch_start0\", \"prefetch_done_0\"},\n+      {\"p0\", \"slice_start_0\", \"slice_done_0\"},\n+      {\"p0\", \"slice_start_3\", \"slice_done_3\"},\n+      {\"p1\", \"slice_start_1\", \"slice_done_1\"},\n+      {\"p1\", \"slice_start_4\", \"slice_done_4\"},\n+      {\"p2\", \"slice_start_2\", \"slice_done_2\"},\n+      {\"p2\", \"slice_start_5\", \"slice_done_5\"}};\n+\n+  memory_space_options.hlo_position_to_custom_call_prefetch_details =\n+      GetCustomCallPrefetchDetailsMap(/*module=*/module.get(),\n+                                      /*custom_call_prefetch_instructions=*/\n+                                      custom_call_prefetch_instructions);\n+\n+  XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n+\n+  // Check that all uses of custom call prefetches are in alternate memory\n+  // space.\n+  std::vector<std::string> prefetched_uses = {\n+      \"negate0\", \"add3\",          \"add6\",     \"add9\",         \"add11\",\n+      \"add12\",   \"custom_call15\", \"negate16\", \"custom_call17\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetched_uses,\n+      /*operand_index=*/0,\n+      /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  // Check that all aliased uses of custom call prefetches are in alternate\n+  // memory space.\n+  std::vector<std::string> aliased_uses = {\"add18\", \"add20\", \"custom_call21\",\n+                                           \"add22\", \"add23\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/aliased_uses,\n+      /*operand_index=*/1,\n+      /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  // Check that all direct uses of parameters are in default memory space.\n+  std::vector<std::string> direct_uses = {\"add18\", \"add19\", \"add20\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/direct_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kParameter,\n+      /*operand_memory_space=*/kDefaultMemorySpace);\n+}\n+\n+TEST_F(MemorySpaceAssignmentTest, TestCustomCallPrefetchSourceAliasing) {\n+  // The block prefetched value (custom_call1) is aliased to the left and to the\n+  // right, we test that all aliased values are in default memory space.\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  param0 = f32[2,1,3]{2,1,0} parameter(0), sharding={replicated}\n+\n+  custom_call0 = f32[2,1,3]{2,1,0} custom-call(param0), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate0 = f32[2,1,3]{2,1,0} negate(custom_call0)\n+  negate1 = f32[2,1,3]{2,1,0} negate(negate0)\n+  custom_call1 = f32[2,1,3]{2,1,0} custom-call(custom_call0, negate1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate2 = f32[2,1,3]{2,1,0} negate(custom_call1)\n+  negate3 = f32[2,1,3]{2,1,0} negate(negate2)\n+\n+  prefetch_start_param0 = (f32[2,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(custom_call1), custom_call_target=\"tpu_custom_call\"\n+  gte_param0_0 = f32[2,1,3]{2,1,0:S(1)} get-tuple-element(prefetch_start_param0), index=0\n+  gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(prefetch_start_param0), index=1\n+  prefetch_done_param0 = f32[2,1,3]{2,1,0:S(1)} custom-call(custom_call1, gte_param0_0, gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  first_slice_prefetch_start_param0 = (f32[1,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(custom_call1), custom_call_target=\"tpu_custom_call\"\n+  first_slice_gte_param0_0 = f32[1,1,3]{2,1,0:S(1)} get-tuple-element(first_slice_prefetch_start_param0), index=0\n+  first_slice_gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(first_slice_prefetch_start_param0), index=1\n+  first_slice_prefetch_done_param0 = f32[1,1,3]{2,1,0:S(1)} custom-call(custom_call1, first_slice_gte_param0_0, first_slice_gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  second_slice_prefetch_start_param0 = (f32[1,1,3]{2,1,0:S(1)}, s32[]{:T(128)S(2)}) custom-call(custom_call1), custom_call_target=\"tpu_custom_call\"\n+  second_slice_gte_param0_0 = f32[1,1,3]{2,1,0:S(1)} get-tuple-element(second_slice_prefetch_start_param0), index=0\n+  second_slice_gte_param0_1 = s32[]{:T(128)S(2)} get-tuple-element(second_slice_prefetch_start_param0), index=1\n+  second_slice_prefetch_done_param0 = f32[1,1,3]{2,1,0:S(1)} custom-call(custom_call1, second_slice_gte_param0_0, second_slice_gte_param0_1), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (1, {})}\n+\n+  negate_param0 = f32[2,1,3]{2,1,0} negate(prefetch_done_param0)\n+  add_param0 = f32[2,1,3]{2,1,0} add(prefetch_done_param0, negate_param0)\n+  negate_param0_first_slice = f32[1,1,3]{2,1,0} negate(first_slice_prefetch_done_param0)\n+  add_param0_first_slice = f32[1,1,3]{2,1,0} add(first_slice_prefetch_done_param0, negate_param0_first_slice)\n+  negate_param0_second_slice = f32[1,1,3]{2,1,0} negate(second_slice_prefetch_done_param0)\n+  add_param0_second_slice = f32[1,1,3]{2,1,0} add(second_slice_prefetch_done_param0, negate_param0_second_slice)\n+\n+  custom_call2 = f32[2,1,3]{2,1,0} custom-call(custom_call1, negate3), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate4 = f32[2,1,3]{2,1,0} negate(custom_call2)\n+  negate5 = f32[2,1,3]{2,1,0} negate(negate4)\n+  custom_call3 = f32[2,1,3]{2,1,0} custom-call(custom_call2, negate5), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  add0 = f32[2,1,3]{2,1,0} add(custom_call3, add_param0)\n+  negate6 = f32[2,1,3]{2,1,0} negate(add0)\n+\n+  ROOT tuple = (f32[2,1,3]{2,1,0}, f32[1,1,3]{2,1,0}, f32[1,1,3]{2,1,0}) tuple(negate6, add_param0_first_slice, add_param0_second_slice)\n+})\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 1000;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 1000;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+\n+  std::vector<CustomCallPrefetchInfo> custom_call_prefetch_instructions = {\n+      {\"custom_call1\", \"prefetch_start_param0\", \"prefetch_done_param0\"},\n+      {\"custom_call1\", \"first_slice_prefetch_start_param0\",\n+       \"first_slice_prefetch_done_param0\"},\n+      {\"custom_call1\", \"second_slice_prefetch_start_param0\",\n+       \"second_slice_prefetch_done_param0\"}};\n+\n+  memory_space_options.hlo_position_to_custom_call_prefetch_details =\n+      GetCustomCallPrefetchDetailsMap(/*module=*/module.get(),\n+                                      /*custom_call_prefetch_instructions=*/\n+                                      custom_call_prefetch_instructions);\n+\n+  const std::string text_proto = R\"pb(\n+    overrides {\n+      hlo_position_matcher {\n+        instruction_name_regex: \"param0|custom_call0|custom_call1|custom_call2|custom_call3\"\n+      }\n+      override_options { assign_first: true }\n+    })pb\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto msa_sort_order_overrides,\n+                          ParseTextProto<MsaSortOrderOverrides>(text_proto));\n+  memory_space_options.msa_sort_order_overrides =\n+      std::move(msa_sort_order_overrides);\n+\n+  XLA_VLOG_LINES(1, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_VLOG_LINES(1, \"After MSA: \\n\" + module->ToString());\n+\n+  std::vector<std::string> prefetch_uses = {\n+      \"add_param0\",\n+      \"add_param0_first_slice\",\n+      \"add_param0_second_slice\",\n+      \"negate_param0\",\n+      \"negate_param0_first_slice\",\n+      \"negate_param0_second_slice\",\n+  };\n+\n+  // Check that all uses of custom call prefetches are in alternate memory\n+  // space.\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetch_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  std::vector<std::string> default_memory_space_uses = {\n+      \"negate0\",\n+      \"custom_call1\",\n+      \"negate2\",\n+      \"prefetch_start_param0\",\n+      \"prefetch_done_param0\",\n+      \"first_slice_prefetch_start_param0\",\n+      \"first_slice_prefetch_done_param0\",\n+      \"second_slice_prefetch_start_param0\",\n+      \"second_slice_prefetch_done_param0\",\n+      \"custom_call2\",\n+      \"negate4\",\n+      \"custom_call3\",\n+      \"add0\"};\n+\n+  // Check that all the uses of the hlo values that alias with the prefetched\n+  // hlo value (custom_call1) are in default memory space even though they are\n+  // higher in the sort order.\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/default_memory_space_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kDefaultMemorySpace);\n+}\n+\n TEST_F(SlicedPrefetchTest, TestMultiplePinnedAllocationsBug) {\n   // When block prefetching, finalize the original value if a sliced value is\n   // prefetched successfully and the original value is not, if not finalized it"
        }
    ],
    "stats": {
        "total": 438,
        "additions": 430,
        "deletions": 8
    }
}