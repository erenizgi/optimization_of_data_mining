{
    "author": "tensorflower-gardener",
    "message": "[XLA:Original Value] Use `TupleTree` instead of `ShapeTree` in `OriginalValue`.\n\nThis change decouples `OriginalValue` from a specific `Shape`, allowing it to represent original values without being constrained by a fixed shape structure. The `OriginalValueProto` is updated to remove the shape field, and related code is adjusted accordingly.\n\nAlso, this cl removes OriginalValuePointer and adds some generic utils for using shared_ptr as map keys and use those instead.\n\nPiperOrigin-RevId: 798633988",
    "sha": "186baec876e82884b92d8afbd5e68bc711a7a3a9",
    "files": [
        {
            "sha": "f83403746d13fa86ca8896c2dd96b55ded3948fd",
            "filename": "third_party/xla/xla/hlo/ir/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -77,12 +77,14 @@ cc_library(\n         \"//xla:side_effect_util\",\n         \"//xla:sort_json\",\n         \"//xla:status_macros\",\n+        \"//xla:tuple_tree\",\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:window_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/hlo/parser:hlo_lexer\",\n+        \"//xla/hlo/utils:pointer_utils\",\n         \"//xla/service:compilation_environments\",\n         \"//xla/service:computation_layout\",\n         \"//xla/service:computation_placer_hdr\",\n@@ -397,3 +399,18 @@ xla_cc_test(\n         \"@com_google_googletest//:gtest\",\n     ],\n )\n+\n+xla_cc_test(\n+    name = \"hlo_original_value_test\",\n+    srcs = [\"hlo_original_value_test.cc\"],\n+    deps = [\n+        \":hlo\",\n+        \"//xla:shape_util\",\n+        \"//xla:tuple_tree\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/hash:hash_testing\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "4324a2934fc7acfa45ed0e8d0670247395be44e9",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -1503,8 +1503,10 @@ void AddEntryToOriginalValueRecoveryTable(\n     std::shared_ptr<OriginalValue> old_original_value,\n     std::shared_ptr<OriginalValue> new_original_value,\n     std::unique_ptr<HloModule> recovery_module) {\n-  original_value_recovery_table[*old_original_value->leaf_begin()->second] = {\n-      *new_original_value->leaf_begin()->second, std::move(recovery_module)};\n+  original_value_recovery_table\n+      [*old_original_value->original_arrays().begin()->second] = {\n+          *new_original_value->original_arrays().begin()->second,\n+          std::move(recovery_module)};\n }\n }  // namespace\n "
        },
        {
            "sha": "0229042175c29d3b852e22372c5a42d86bc94dcf",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.cc",
            "status": "modified",
            "additions": 60,
            "deletions": 53,
            "changes": 113,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -19,17 +19,23 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <utility>\n #include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n+#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/utils/pointer_utils.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -56,76 +62,76 @@ OriginalArray OriginalArray::FromProto(\n           ShapeIndex(original_array_proto.shape_index())};\n }\n \n-std::string OriginalValueToString(const OriginalValue& original_value,\n-                                  const Shape& shape,\n-                                  std::vector<int64_t>& shape_index) {\n-  std::string result;\n-  if (shape.IsTuple()) {\n-    if (shape.tuple_shapes().empty()) {\n-      return \"()\";\n-    }\n-    shape_index.push_back(0);\n-    absl::StrAppend(&result, \"(\",\n-                    OriginalValueToString(original_value, shape.tuple_shapes(0),\n-                                          shape_index));\n-    shape_index.pop_back();\n-    for (int64_t i = 1; i < shape.tuple_shapes().size(); ++i) {\n-      shape_index.push_back(i);\n-      absl::StrAppend(&result, \", \",\n-                      OriginalValueToString(\n-                          original_value, shape.tuple_shapes(i), shape_index));\n-      shape_index.pop_back();\n+namespace {\n+using Node = TupleTree<std::optional<OriginalArray>>::Node;\n+\n+std::string NodeToString(const Node& node) {\n+  if (node.IsLeaf()) {\n+    const std::optional<OriginalArray>& leaf_val = node.value();\n+    if (leaf_val.has_value()) {\n+      return absl::StrCat(\"{\", leaf_val->ToString(), \"}\");\n     }\n-    absl::StrAppend(&result, \")\");\n-    return result;\n+    return \"{}\";\n   }\n \n-  const auto& leaf = original_value.element(shape_index);\n-  if (leaf.has_value()) {\n-    absl::StrAppend(&result, \"{\", leaf->ToString(), \"}\");\n-  } else {\n-    absl::StrAppend(&result, \"{}\");\n+  if (node.children().empty()) {\n+    return \"()\";\n   }\n-  return result;\n+\n+  std::vector<std::string> children_str;\n+  for (const auto& child : node.children()) {\n+    children_str.push_back(NodeToString(child));\n+  }\n+\n+  return absl::StrCat(\"(\", absl::StrJoin(children_str, \", \"), \")\");\n }\n+}  // namespace\n \n std::string OriginalValue::ToString() const {\n-  std::vector<int64_t> shape_index;\n-  return OriginalValueToString(*this, shape(), shape_index);\n+  auto node_or = tree_.ToNode();\n+  CHECK_OK(node_or.status());\n+  return NodeToString(*node_or);\n }\n \n OriginalValueProto OriginalValue::ToProto() const {\n   OriginalValueProto original_value_proto;\n-  *original_value_proto.mutable_shape() = shape().ToProto();\n-  for (const auto& leaf : leaves()) {\n-    OriginalValueNodeProto* original_value_node_proto =\n-        original_value_proto.add_leaves();\n-    for (const auto& index : leaf.first) {\n-      original_value_node_proto->add_shape_index(index);\n+  tree_.ForEachElement([&original_value_proto](\n+                           const ShapeIndex& index,\n+                           const std::optional<OriginalArray>& value) {\n+    OriginalValueElementProto* original_value_node_proto =\n+        original_value_proto.add_elements();\n+    for (const auto& i : index) {\n+      original_value_node_proto->add_shape_index(i);\n     }\n-    *original_value_node_proto->mutable_original_array() =\n-        leaf.second->ToProto();\n-  }\n+    if (value.has_value()) {\n+      *original_value_node_proto->mutable_original_array() = value->ToProto();\n+    }\n+  });\n   return original_value_proto;\n }\n \n std::shared_ptr<OriginalValue> OriginalValue::FromProto(\n     const xla::OriginalValueProto& original_value_proto) {\n-  xla::Shape original_value_shape(\n-      Shape::FromProto(original_value_proto.shape()).value_or(Shape()));\n-  auto original_value = std::make_shared<OriginalValue>(original_value_shape);\n-\n-  for (const auto& leaf : original_value_proto.leaves()) {\n-    *original_value->mutable_element(ShapeIndex(leaf.shape_index())) =\n-        OriginalArray::FromProto(leaf.original_array());\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> nodes;\n+  for (const auto& leaf : original_value_proto.elements()) {\n+    ShapeIndex index(leaf.shape_index());\n+    if (leaf.has_original_array()) {\n+      nodes.emplace_back(index,\n+                         OriginalArray::FromProto(leaf.original_array()));\n+    } else {\n+      // This case should not happen based on ToProto, but handling defensively.\n+      nodes.emplace_back(index, std::nullopt);\n+    }\n   }\n-  return original_value;\n+  return std::make_shared<OriginalValue>(\n+      TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(nodes)));\n }\n \n std::shared_ptr<OriginalValue> OriginalValue::CreateFromInstruction(\n     const HloInstruction* instruction, absl::string_view prefix) {\n   std::shared_ptr<OriginalValue> original_value =\n-      std::make_shared<OriginalValue>(instruction->shape());\n+      std::make_shared<OriginalValue>(\n+          TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n \n   if (instruction->opcode() == HloOpcode::kGetTupleElement) {\n     const auto* tuple = instruction->operand(0);\n@@ -148,7 +154,7 @@ std::shared_ptr<OriginalValue> OriginalValue::CreateFromInstruction(\n                                       {operand_number});\n     }\n   } else {\n-    for (auto& leaf : original_value->leaves()) {\n+    for (auto& leaf : original_value->mutable_original_arrays()) {\n       leaf.second = {absl::StrCat(prefix, instruction->name()), leaf.first};\n     }\n   }\n@@ -178,23 +184,24 @@ void CopyOriginalValue(const HloInstruction* src_instruction,\n   }\n \n   std::shared_ptr<OriginalValue> original_value_clone =\n-      std::make_shared<OriginalValue>(original_value->shape());\n+      std::make_shared<OriginalValue>();\n   original_value_clone->CopySubtreeFrom(*original_value, {}, {});\n   dest_instruction->set_original_value(original_value_clone);\n }\n \n void DeduplicateOriginalValues(HloModule* module) {\n-  absl::flat_hash_set<OriginalValuePointer> unique_original_values;\n+  absl::flat_hash_set<std::shared_ptr<OriginalValue>,\n+                      PointeeHash<OriginalValue>, PointeeEqual<OriginalValue>>\n+      unique_original_values;\n   for (HloComputation* computation : module->computations()) {\n     for (HloInstruction* instruction : computation->instructions()) {\n       if (std::shared_ptr<OriginalValue> original_value =\n               instruction->original_value()) {\n-        OriginalValuePointer original_value_ptr(original_value);\n-        auto p = unique_original_values.insert(original_value_ptr);\n+        auto p = unique_original_values.insert(original_value);\n         if (!p.second) {\n           // Reassign the pointer with the existing identical object and release\n           // the duplicate.\n-          instruction->set_original_value(p.first->original_value);\n+          instruction->set_original_value(*p.first);\n         }\n       }\n     }"
        },
        {
            "sha": "35359b60aadae0460c1f477b918f14461797a58f",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.h",
            "status": "modified",
            "additions": 47,
            "deletions": 51,
            "changes": 98,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -16,12 +16,16 @@ limitations under the License.\n #ifndef XLA_HLO_IR_HLO_ORIGINAL_VALUE_H_\n #define XLA_HLO_IR_HLO_ORIGINAL_VALUE_H_\n \n+#include <algorithm>\n+#include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n \n-#include \"xla/shape_tree.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tuple_tree.h\"\n+#include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla {\n@@ -56,71 +60,63 @@ struct OriginalArray {\n \n // The information of an HLO value produced by an instruction in an unoptimized\n // HLO module.\n-class OriginalValue : public ShapeTree<std::optional<OriginalArray>> {\n+class OriginalValue {\n  public:\n-  explicit OriginalValue(Shape shape) : ShapeTree(std::move(shape)) {}\n+  OriginalValue() = default;\n+  explicit OriginalValue(\n+      TupleTree<std::optional<OriginalArray>>::Node&& root_node)\n+      : tree_(std::move(root_node)) {}\n+  explicit OriginalValue(TupleTree<std::optional<OriginalArray>>&& tree)\n+      : tree_(std::move(tree)) {}\n   std::string ToString() const;\n   OriginalValueProto ToProto() const;\n   static std::shared_ptr<OriginalValue> FromProto(\n       const xla::OriginalValueProto& original_value_proto);\n   static std::shared_ptr<OriginalValue> CreateFromInstruction(\n       const HloInstruction* instruction, absl::string_view prefix = \"\");\n-};\n \n-struct OriginalValuePointer {\n-  OriginalValuePointer() = default;\n-  explicit OriginalValuePointer(\n-      std::shared_ptr<xla::OriginalValue> original_value) {\n-    this->original_value = std::move(original_value);\n+  const std::optional<OriginalArray>& original_array(\n+      ShapeIndexView index) const {\n+    return tree_.element(index);\n+  }\n+  std::optional<OriginalArray>* mutable_original_array(ShapeIndexView index) {\n+    return tree_.mutable_element(index);\n   }\n \n-  friend bool operator==(const OriginalValuePointer& lhs,\n-                         const OriginalValuePointer& rhs) {\n-    // Returns if any original value is empty.\n-    if (!lhs.original_value || !rhs.original_value) {\n-      return !lhs.original_value == !rhs.original_value;\n-    }\n-    // Returns if the original values have different shapes.\n-    if (!xla::ShapeUtil::Compatible(lhs.original_value->shape(),\n-                                    rhs.original_value->shape())) {\n-      return false;\n-    }\n-    // Compares nodes.\n-    for (auto& leaf : lhs.original_value->leaves()) {\n-      xla::ShapeIndex index = leaf.first;\n-      std::optional<const xla::OriginalArray> lhs_original_array = leaf.second;\n-      std::optional<const xla::OriginalArray> rhs_original_array =\n-          rhs.original_value->element(index);\n-      if (!lhs_original_array.has_value() || !rhs_original_array.has_value() ||\n-          *lhs_original_array != *rhs_original_array) {\n-        return false;\n-      }\n-    }\n-    return true;\n+  // Returns a const iterator over the pairs of ShapeIndex and\n+  // std::optional<OriginalArray>.\n+  auto original_arrays() const { return tree_.leaves(); }\n+  // Returns a non-const iterator over the pairs of ShapeIndex and\n+  // std::optional<OriginalArray>.\n+  auto mutable_original_arrays() { return tree_.leaves(); }\n+\n+  void CopySubtreeFrom(const OriginalValue& other, const ShapeIndex& src_index,\n+                       const ShapeIndex& dst_index) {\n+    tree_.CopySubtreeFrom(other.tree_, src_index, dst_index);\n+  }\n+\n+  bool operator==(const OriginalValue& other) const {\n+    auto this_original_arrays = original_arrays();\n+    auto other_original_arrays = other.original_arrays();\n+    return std::equal(this_original_arrays.begin(), this_original_arrays.end(),\n+                      other_original_arrays.begin(),\n+                      other_original_arrays.end());\n+  }\n+\n+  bool operator!=(const OriginalValue& other) const {\n+    return !(*this == other);\n   }\n \n   template <typename H>\n-  friend H AbslHashValue(H h, const OriginalValuePointer& value) {\n-    // Ignore layout information, which is added to shapes during the HLO\n-    // transformation.\n-    h = xla::Shape::template Hash<H, false /*kIsLayoutSensitive*/>(\n-        std::move(h), value.original_value->shape());\n-    value.original_value->ForEachElement(\n-        [&h, &value](const xla::ShapeIndex& shape_index,\n-                     const std::optional<xla::OriginalArray>& original_array) {\n-          if (!value.original_value->IsLeaf(shape_index)) {\n-            return;\n-          }\n-          if (!original_array) {\n-            return;\n-          }\n-          h = H::combine(std::move(h), original_array->instruction_name,\n-                         original_array->shape_index);\n-        });\n-    return std::move(h);\n+  friend H AbslHashValue(H h, const OriginalValue& value) {\n+    for (const auto& leaf : value.original_arrays()) {\n+      h = H::combine(std::move(h), leaf.first, leaf.second);\n+    }\n+    return h;\n   }\n \n-  std::shared_ptr<xla::OriginalValue> original_value = nullptr;\n+ private:\n+  TupleTree<std::optional<OriginalArray>> tree_;\n };\n \n // Copies the original value of the source to the destination instruction. This"
        },
        {
            "sha": "47854f989027fcb25fa7c8c6b14edd092bce0ccb",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value_test.cc",
            "status": "added",
            "additions": 329,
            "deletions": 0,
            "changes": 329,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -0,0 +1,329 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n+\n+#include <memory>\n+#include <optional>\n+#include <utility>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/hash/hash_testing.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tuple_tree.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+namespace {\n+\n+using ::testing::ElementsAre;\n+using ::testing::Eq;\n+using ::testing::Optional;\n+using Node = TupleTree<std::optional<OriginalArray>>::Node;\n+\n+TEST(OriginalArrayTest, ToString) {\n+  OriginalArray array1{\"inst1\", {}};\n+  EXPECT_EQ(array1.ToString(), \"\\\"inst1\\\"\");\n+\n+  OriginalArray array2{\"inst2\", {1, 2}};\n+  EXPECT_EQ(array2.ToString(), \"\\\"inst2\\\" {1,2}\");\n+}\n+\n+TEST(OriginalArrayTest, ProtoSerde) {\n+  OriginalArray array1{\"inst1\", {}};\n+  OriginalArrayProto proto1 = array1.ToProto();\n+  EXPECT_EQ(proto1.instruction_name(), \"inst1\");\n+  EXPECT_TRUE(proto1.shape_index().empty());\n+  OriginalArray array1_from_proto = OriginalArray::FromProto(proto1);\n+  EXPECT_EQ(array1_from_proto, array1);\n+\n+  OriginalArray array2{\"inst2\", {1, 2}};\n+  OriginalArrayProto proto2 = array2.ToProto();\n+  EXPECT_EQ(proto2.instruction_name(), \"inst2\");\n+  EXPECT_THAT(proto2.shape_index(), ElementsAre(1, 2));\n+  OriginalArray array2_from_proto = OriginalArray::FromProto(proto2);\n+  EXPECT_EQ(array2_from_proto, array2);\n+}\n+\n+TEST(OriginalArrayTest, EqualityAndHashing) {\n+  OriginalArray array1{\"inst1\", {}};\n+  OriginalArray array2{\"inst1\", {}};\n+  OriginalArray array3{\"inst2\", {}};\n+  OriginalArray array4{\"inst1\", {1}};\n+  OriginalArray array5{\"inst1\", {1}};\n+\n+  EXPECT_EQ(array1, array2);\n+  EXPECT_NE(array1, array3);\n+  EXPECT_NE(array1, array4);\n+  EXPECT_EQ(array4, array5);\n+\n+  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n+      array1,\n+      array2,\n+      array3,\n+      array4,\n+      array5,\n+  }));\n+}\n+\n+TEST(OriginalValueTest, ToStringScalar) {\n+  OriginalValue value(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  EXPECT_EQ(value.ToString(), \"{\\\"inst1\\\"}\");\n+}\n+\n+TEST(OriginalValueTest, ToStringTuple) {\n+  OriginalValue value(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                   Node::Leaf(OriginalArray{\"inst2\", {2}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"inst3\", {3}}),\n+                                Node::Leaf(std::nullopt)})}));\n+  EXPECT_EQ(value.ToString(),\n+            \"({\\\"inst1\\\" {1}}, {\\\"inst2\\\" {2}}, ({\\\"inst3\\\" {3}}, {}))\");\n+}\n+\n+TEST(OriginalValueTest, ProtoSerde) {\n+  OriginalValue value(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                   Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  OriginalValueProto proto = value.ToProto();\n+  std::shared_ptr<OriginalValue> value_from_proto =\n+      OriginalValue::FromProto(proto);\n+  EXPECT_EQ(*value_from_proto, value);\n+\n+  // Test with nullopt\n+  OriginalValue value_with_null(Node::Tuple(\n+      {Node::Leaf(OriginalArray{\"inst1\", {1}}), Node::Leaf(std::nullopt)}));\n+  OriginalValueProto proto_with_null = value_with_null.ToProto();\n+  std::shared_ptr<OriginalValue> value_with_null_from_proto =\n+      OriginalValue::FromProto(proto_with_null);\n+  EXPECT_EQ(value_with_null_from_proto->ToString(), value_with_null.ToString());\n+  EXPECT_EQ(*value_with_null_from_proto, value_with_null);\n+}\n+\n+TEST(OriginalValueTest, ElementAccess) {\n+  OriginalValue value(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                   Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  EXPECT_THAT(value.original_array({0}),\n+              Optional(Eq(OriginalArray{\"inst1\", {1}})));\n+  EXPECT_THAT(value.original_array({1}),\n+              Optional(Eq(OriginalArray{\"inst2\", {2}})));\n+\n+  *value.mutable_original_array({1}) = OriginalArray{\"inst3\", {3}};\n+  EXPECT_THAT(value.original_array({1}),\n+              Optional(Eq(OriginalArray{\"inst3\", {3}})));\n+}\n+\n+TEST(OriginalValueTest, Elements) {\n+  OriginalValue value(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"inst2\", {2}})}),\n+                   Node::Leaf(OriginalArray{\"inst3\", {3}})}));\n+\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> elements;\n+  for (const auto& element : value.mutable_original_arrays()) {\n+    elements.push_back(element);\n+  }\n+\n+  EXPECT_EQ(elements.size(), 3);\n+  EXPECT_EQ(elements[0].first, ShapeIndex({0}));\n+  EXPECT_THAT(elements[0].second, Optional(Eq(OriginalArray{\"inst1\", {1}})));\n+  EXPECT_EQ(elements[1].first, ShapeIndex({1, 0}));\n+  EXPECT_THAT(elements[1].second, Optional(Eq(OriginalArray{\"inst2\", {2}})));\n+  EXPECT_EQ(elements[2].first, ShapeIndex({2}));\n+  EXPECT_THAT(elements[2].second, Optional(Eq(OriginalArray{\"inst3\", {3}})));\n+}\n+\n+TEST(OriginalValueTest, CopySubtreeFrom) {\n+  OriginalValue src(\n+      Node::Tuple({Node::Leaf(OriginalArray{\"src1\", {1}}),\n+                   Node::Tuple({Node::Leaf(OriginalArray{\"src2\", {2}}),\n+                                Node::Leaf(OriginalArray{\"src3\", {3}})})}));\n+\n+  OriginalValue dst;\n+  dst.CopySubtreeFrom(src, {1}, {});\n+  EXPECT_EQ(dst.ToString(), \"({\\\"src2\\\" {2}}, {\\\"src3\\\" {3}})\");\n+\n+  dst.CopySubtreeFrom(src, {0}, {});\n+  EXPECT_EQ(dst.ToString(), \"{\\\"src1\\\" {1}}\");\n+}\n+\n+TEST(OriginalValueTest, EqualityAndHashing) {\n+  OriginalValue value1(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  OriginalValue value2(Node::Leaf(OriginalArray{\"inst1\", {}}));\n+  OriginalValue value3(Node::Leaf(OriginalArray{\"inst2\", {}}));\n+  OriginalValue value4(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                    Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+  OriginalValue value5(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                    Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+\n+  EXPECT_EQ(value1, value2);\n+  EXPECT_NE(value1, value3);\n+  EXPECT_NE(value1, value4);\n+  EXPECT_EQ(value4, value5);\n+\n+  EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n+      value1,\n+      value2,\n+      value3,\n+      value4,\n+      value5,\n+  }));\n+}\n+\n+using OriginalValueHloTest = HloHardwareIndependentTestBase;\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstruction) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  ROOT tuple = (f32[], f32[]) tuple(p0, p1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* p1 = module->entry_computation()->parameter_instruction(1);\n+  HloInstruction* tuple = module->entry_computation()->root_instruction();\n+\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0, \"prefix_\"));\n+  p1->set_original_value(OriginalValue::CreateFromInstruction(p1, \"prefix_\"));\n+  tuple->set_original_value(OriginalValue::CreateFromInstruction(tuple));\n+\n+  EXPECT_EQ(p0->original_value()->ToString(), \"{\\\"prefix_p0\\\"}\");\n+  EXPECT_EQ(p1->original_value()->ToString(), \"{\\\"prefix_p1\\\"}\");\n+  EXPECT_EQ(tuple->original_value()->ToString(),\n+            \"({\\\"prefix_p0\\\"}, {\\\"prefix_p1\\\"})\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstructionGTE) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  tuple = (f32[], f32[]) tuple(p0, p1)\n+  ROOT gte = f32[] get-tuple-element(tuple), index=1\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* p1 = module->entry_computation()->parameter_instruction(1);\n+  HloInstruction* tuple = FindInstruction(module.get(), \"tuple\");\n+  HloInstruction* gte = module->entry_computation()->root_instruction();\n+\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+  p1->set_original_value(OriginalValue::CreateFromInstruction(p1));\n+  tuple->set_original_value(OriginalValue::CreateFromInstruction(tuple));\n+  gte->set_original_value(OriginalValue::CreateFromInstruction(gte));\n+\n+  EXPECT_EQ(gte->original_value()->ToString(), \"{\\\"p1\\\"}\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CreateFromInstructionTuple) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+ ROOT p0 = (f32[], f32[]) parameter(0)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+\n+  EXPECT_EQ(p0->original_value()->ToString(), \"({\\\"p0\\\" {0}}, {\\\"p0\\\" {1}})\");\n+}\n+\n+TEST_F(OriginalValueHloTest, CopyOriginalValue) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  ROOT p0 = f32[] parameter(0)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+\n+  std::unique_ptr<HloInstruction> clone = p0->Clone();\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/false);\n+  EXPECT_EQ(p0->original_value(), clone->original_value());\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/true);\n+  EXPECT_NE(p0->original_value(), clone->original_value());\n+  EXPECT_EQ(*p0->original_value(), *clone->original_value());\n+}\n+\n+TEST_F(OriginalValueHloTest, DeduplicateOriginalValues) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  n0 = f32[] negate(p0)\n+  n1 = f32[] negate(p1)\n+  ROOT add = f32[] add(n0, n1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n+  HloInstruction* p1 = FindInstruction(module.get(), \"p1\");\n+  HloInstruction* n0 = FindInstruction(module.get(), \"n0\");\n+  HloInstruction* n1 = FindInstruction(module.get(), \"n1\");\n+\n+  auto value1 =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instA\", {}}));\n+  auto value2 =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instB\", {}}));\n+  auto value1_dup =\n+      std::make_shared<OriginalValue>(Node::Leaf(OriginalArray{\"instA\", {}}));\n+\n+  p0->set_original_value(value1);\n+  p1->set_original_value(value2);\n+  n0->set_original_value(value1_dup);\n+  n1->set_original_value(value2);  // Intentional same shared_ptr\n+\n+  EXPECT_NE(p0->original_value(),\n+            n0->original_value());  // Different shared_ptr\n+  EXPECT_EQ(*p0->original_value(), *n0->original_value());  // Same value\n+  EXPECT_EQ(p1->original_value(), n1->original_value());    // Same shared_ptr\n+\n+  DeduplicateOriginalValues(module.get());\n+\n+  EXPECT_EQ(p0->original_value(),\n+            n0->original_value());  // Should be same shared_ptr now\n+  EXPECT_EQ(p1->original_value(), n1->original_value());\n+  EXPECT_NE(p0->original_value(), p1->original_value());\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        },
        {
            "sha": "4b534ff3fe1de22cf478d9db56bbb7717349e838",
            "filename": "third_party/xla/xla/hlo/parser/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2FBUILD?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -33,6 +33,7 @@ cc_library(\n         \"//xla:literal_util\",\n         \"//xla:shape_layout\",\n         \"//xla:shape_util\",\n+        \"//xla:tuple_tree\",\n         \"//xla:types\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -77,15 +78,13 @@ xla_cc_test(\n         \"//xla:window_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/builder:xla_builder\",\n-        \"//xla/hlo/ir:collective_op_group_mode\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:pattern_matcher_gmock\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:pattern_matcher\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:status_matchers\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test\",\n         \"//xla/tsl/platform:test_main\","
        },
        {
            "sha": "ff8a5adfb735c30c327394f29fbbe6d41446cdb7",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -80,6 +80,7 @@ limitations under the License.\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/status.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/types.h\"\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -270,8 +271,7 @@ class HloParserImpl : public HloParser {\n   absl::StatusOr<std::vector<Shape>> ParseShapeListOnly();\n   absl::StatusOr<Layout> ParseLayoutOnly();\n   absl::StatusOr<HloSharding> ParseShardingOnly();\n-  absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValueOnly(\n-      Shape shape);\n+  absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValueOnly();\n   absl::StatusOr<FrontendAttributes> ParseFrontendAttributesOnly();\n   absl::StatusOr<StatisticsViz> ParseStatisticsVizOnly();\n   absl::StatusOr<std::vector<bool>> ParseParameterReplicationOnly();\n@@ -592,7 +592,9 @@ class HloParserImpl : public HloParser {\n                   uint64_t lexer_skip_mask = kNoneMask);\n   bool ParseUnsignedIntegerType(PrimitiveType* primitive_type);\n   bool ParseOriginalArray(OriginalArray& original_array);\n-  bool ParseOriginalValue(std::shared_ptr<OriginalValue>& original_value);\n+  bool ParseOriginalValueArrays(\n+      std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n+          original_value_arrays);\n   bool ParseOriginalValueRecoveryTable(\n       OriginalValueRecoveryTable& original_value_recovery_table);\n   bool ParseCollectiveOpGroupMode(CollectiveOpGroupMode* result);\n@@ -5237,16 +5239,12 @@ bool HloParserImpl::ParseAttributeHelper(\n         return true;\n       }\n       case AttrTy::kOriginalValue: {\n-        // By the time this attribute is added, the instruction shape should\n-        // have been inferred.\n-        if (!shape) {\n-          return TokenError(\"expects instruction shape\");\n-        }\n-        std::shared_ptr<OriginalValue> result =\n-            std::make_shared<OriginalValue>(*shape);\n-        if (!ParseOriginalValue(result)) {\n+        std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n+        if (!ParseOriginalValueArrays(arrays)) {\n           return false;\n         }\n+        auto result = std::make_shared<OriginalValue>(\n+            TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n         static_cast<optional<std::shared_ptr<OriginalValue>>*>(attr_out_ptr)\n             ->emplace(std::move(result));\n         return true;\n@@ -6627,8 +6625,9 @@ bool HloParserImpl::ParseOriginalArray(OriginalArray& original_array) {\n }\n \n // original_value ::= '{' '('* original_array [','] ')'* | original_value '}'\n-bool HloParserImpl::ParseOriginalValue(\n-    std::shared_ptr<OriginalValue>& original_value) {\n+bool HloParserImpl::ParseOriginalValueArrays(\n+    std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n+        original_value_arrays) {\n   VLOG(kDebugLevel) << \"ParseOriginalValue\";\n \n   if (!ParseToken(TokKind::kLbrace, \"Expects '{'\")) {\n@@ -6651,13 +6650,15 @@ bool HloParserImpl::ParseOriginalValue(\n       if (!ParseOriginalArray(original_array)) {\n         return false;\n       }\n-      if (!original_array.instruction_name.empty()) {\n-        *original_value->mutable_element(leaf_shape_index) = original_array;\n-      } else {\n+      if (original_array.instruction_name.empty()) {\n         // The original value is not expected to have any leaf without values.\n         // However we should not fail the execution here. This should\n         // be done in HloVerifier instead.\n         LOG(WARNING) << \"Found an empty leaf node in an original value\";\n+        original_value_arrays.emplace_back(leaf_shape_index, std::nullopt);\n+      } else {\n+        original_value_arrays.emplace_back(leaf_shape_index,\n+                                           std::move(original_array));\n       }\n     } else {\n       return false;\n@@ -7319,13 +7320,14 @@ absl::StatusOr<HloSharding> HloParserImpl::ParseShardingOnly() {\n }\n \n absl::StatusOr<std::shared_ptr<OriginalValue>>\n-HloParserImpl::ParseOriginalValueOnly(Shape shape) {\n+HloParserImpl::ParseOriginalValueOnly() {\n   lexer_.Lex();\n-  std::shared_ptr<OriginalValue> original_value =\n-      std::make_shared<OriginalValue>(shape);\n-  if (!ParseOriginalValue(original_value)) {\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n+  if (!ParseOriginalValueArrays(arrays)) {\n     return InvalidArgument(\"Syntax error:\\n%s\", GetError());\n   }\n+  auto original_value = std::make_shared<OriginalValue>(\n+      TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n   if (lexer_.GetKind() != TokKind::kEof) {\n     return InvalidArgument(\"Syntax error:\\nExtra content after original value\");\n   }\n@@ -7526,9 +7528,9 @@ absl::StatusOr<HloSharding> ParseSharding(absl::string_view str) {\n }\n \n absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValue(\n-    absl::string_view str, const Shape& shape) {\n+    absl::string_view str) {\n   HloParserImpl parser(str);\n-  return parser.ParseOriginalValueOnly(shape);\n+  return parser.ParseOriginalValueOnly();\n }\n \n absl::StatusOr<FrontendAttributes> ParseFrontendAttributes("
        },
        {
            "sha": "9e53d4da4bc0918de95fc8efbb77a93d48a91c68",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.h?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -83,10 +83,9 @@ absl::StatusOr<std::unique_ptr<HloModule>> ParseAndReturnUnverifiedModule(\n // \"{replicated}\".\n absl::StatusOr<HloSharding> ParseSharding(absl::string_view str);\n \n-// Parses original value from str. The shape is used to initialize the original\n-// value.\n+// Parses original value from str.\n absl::StatusOr<std::shared_ptr<OriginalValue>> ParseOriginalValue(\n-    absl::string_view str, const Shape& shape);\n+    absl::string_view str);\n \n // Parses frontend attributes from str. str is supposed to contain the body of\n // the frontend attributes , i.e. just the rhs of the"
        },
        {
            "sha": "8c73736af3ae8dda01cf53b20211b2b29e9f6f22",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -53,7 +53,6 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/status_matchers.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n@@ -5646,9 +5645,11 @@ ENTRY %test {\n \n \n )\";\n-  EXPECT_THAT(ParseAndReturnUnverifiedModule(hlo_string).status(),\n-              absl_testing::StatusIs(tsl::error::INVALID_ARGUMENT,\n-                                     HasSubstr(\"expects instruction shape\")));\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnUnverifiedModule(hlo_string));\n+\n+  ExpectHasSubstr(module->ToString(HloPrintOptions::ShortParsable()),\n+                  \"origin={{\\\"v\\\"}}\");\n }\n \n TEST_F(HloParserTest, EmptyLeafInOriginalValue) {"
        },
        {
            "sha": "3789f45457801e983a92a18590312af79d1ece9b",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/attribute_exporter.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -355,11 +355,10 @@ std::optional<xla::OpSharding> ConvertSharding(llvm::StringRef sharding) {\n }\n \n std::optional<xla::OriginalValueProto> ConvertOriginalValue(\n-    llvm::StringRef original_value, const xla::Shape& shape) {\n+    llvm::StringRef original_value) {\n   absl::StatusOr<std::shared_ptr<xla::OriginalValue>> hlo_original_value =\n       xla::ParseOriginalValue(\n-          absl::string_view(original_value.data(), original_value.size()),\n-          shape);\n+          absl::string_view(original_value.data(), original_value.size()));\n   if (!hlo_original_value.ok()) {\n     return std::nullopt;\n   }"
        },
        {
            "sha": "deefdd4e71397d9d1236e8e3d5ef8e12eb0e28b7",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/attribute_exporter.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fattribute_exporter.h?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -99,7 +99,7 @@ std::optional<xla::OpSharding> ExtractShardyResultShardingFromFrontendAttrs(\n // Returns an OriginalValueProto that represents a value in the unoptimized HLO\n // graph.\n std::optional<xla::OriginalValueProto> ConvertOriginalValue(\n-    llvm::StringRef original_value, const xla::Shape& shape);\n+    llvm::StringRef original_value);\n \n std::optional<xla::HloInputOutputAliasProto> ConvertInputOutputAlias(\n     llvm::ArrayRef<mlir::Attribute> aliasing);"
        },
        {
            "sha": "b3f3c0ff538cde5b3909172e56c1b9ac93c46a50",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -6450,12 +6450,7 @@ std::optional<xla::OriginalValueProto> CreateOriginalValueFromOp(\n   if (!original_value_attr) {\n     return std::nullopt;\n   }\n-  mlir::FailureOr<xla::Shape> shape_or = ExtractXlaShape(op);\n-  if (failed(shape_or)) {\n-    return std::nullopt;\n-  }\n-  return xla::ConvertOriginalValue(original_value_attr.getValue(),\n-                                   shape_or.value());\n+  return xla::ConvertOriginalValue(original_value_attr.getValue());\n }\n \n }  // namespace mlir"
        },
        {
            "sha": "4a3069676807526b9a069875671f01de209a3c75",
            "filename": "third_party/xla/xla/hlo/utils/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2FBUILD?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -280,6 +280,12 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"pointer_utils\",\n+    hdrs = [\"pointer_utils.h\"],\n+    deps = [\"@com_google_absl//absl/hash\"],\n+)\n+\n xla_cc_test(\n     name = \"hlo_traversal_test\",\n     srcs = [\"hlo_traversal_test.cc\"],"
        },
        {
            "sha": "d18998c8c947b5d417efa906fd6eba124889e5d9",
            "filename": "third_party/xla/xla/hlo/utils/pointer_utils.h",
            "status": "added",
            "additions": 53,
            "deletions": 0,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fpointer_utils.h?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -0,0 +1,53 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_UTILS_POINTER_UTILS_H_\n+#define XLA_HLO_UTILS_POINTER_UTILS_H_\n+\n+#include <cstddef>\n+#include <memory>\n+\n+#include \"absl/hash/hash.h\"\n+\n+namespace xla {\n+// Hash functor for std::shared_ptr<T>, hashing the value of the pointee.\n+template <typename T>\n+struct PointeeHash {\n+  size_t operator()(const std::shared_ptr<T>& value) const {\n+    if (!value) {\n+      return absl::Hash<int>()(0);  // Hash for nullptr\n+    }\n+    return absl::Hash<T>()(*value);\n+  }\n+};\n+\n+// Equality functor for std::shared_ptr<T>, comparing the values of the\n+// pointees.\n+template <typename T>\n+struct PointeeEqual {\n+  bool operator()(const std::shared_ptr<T>& lhs,\n+                  const std::shared_ptr<T>& rhs) const {\n+    if (!lhs && !rhs) {\n+      return true;\n+    }\n+    if (!lhs || !rhs) {\n+      return false;\n+    }\n+    return *lhs == *rhs;\n+  }\n+};\n+}  // namespace xla\n+\n+#endif  // XLA_HLO_UTILS_POINTER_UTILS_H_"
        },
        {
            "sha": "5935b1d7474299aff6bd982908e476384bbd2b66",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -3451,6 +3451,7 @@ xla_cc_test(\n         \"//xla:debug_options_flags\",\n         \"//xla:literal_util\",\n         \"//xla:shape_util\",\n+        \"//xla:tuple_tree\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/hlo/analysis:alias_info\","
        },
        {
            "sha": "bb19d96b3999ee26f6627a413a3ab9ae6c999d97",
            "filename": "third_party/xla/xla/service/call_inliner.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -118,14 +118,15 @@ class SubcomputationInsertionVisitor : public DfsHloVisitorWithDefault {\n     new_hlo_pointer->CopyOriginalValue(hlo, /*clone=*/true);\n     if (std::shared_ptr<OriginalValue> original_value =\n             new_hlo_pointer->original_value()) {\n-      for (auto& leaf : original_value->leaves()) {\n-        std::optional<OriginalArray>& original_array = leaf.second;\n+      for (auto& pair : original_value->mutable_original_arrays()) {\n+        std::optional<OriginalArray>& original_array = pair.second;\n         if (original_array.has_value()) {\n           std::string call_instruction_name;\n           if (std::shared_ptr<OriginalValue> call_original_value =\n                   call_->original_value()) {\n-            call_instruction_name =\n-                call_original_value->leaf_begin()->second->instruction_name;\n+            call_instruction_name = call_original_value->original_arrays()\n+                                        .begin()\n+                                        ->second->instruction_name;\n           }\n           original_array->instruction_name = absl::StrCat(\n               call_instruction_name, \"/\", original_array->instruction_name);"
        },
        {
            "sha": "3efc292b4695040f079bf11a8391bb9526be2fc0",
            "filename": "third_party/xla/xla/service/hlo_module_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_module_test.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/comparison_util.h\"\n #include \"xla/debug_options_flags.h\"\n@@ -37,6 +38,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_original_value.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/hlo/testlib/test.h\"\n #include \"xla/hlo/testlib/verified_hlo_module.h\"\n@@ -52,6 +54,7 @@ limitations under the License.\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/lib/strings/proto_serialization.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/casts.h\"\n@@ -971,10 +974,9 @@ TEST_F(HloModuleTest, PrintOriginalValue) {\n   std::vector<float> values(16, 42.0);\n   auto instruction =\n       HloInstruction::CreateConstant(LiteralUtil::CreateR0<float>(42.0f));\n-  auto original_value = std::make_shared<OriginalValue>(instruction->shape());\n-  for (auto& leaf : original_value->leaves()) {\n-    leaf.second = {std::string(instruction->name()), leaf.first};\n-  }\n+  auto original_value =\n+      std::make_shared<OriginalValue>(TupleTree<std::optional<OriginalArray>>(\n+          OriginalArray{std::string(instruction->name()), {}}));\n   instruction->set_original_value(original_value);\n   builder.AddInstruction(std::move(instruction));\n   module->AddEntryComputation(builder.Build());"
        },
        {
            "sha": "e19c4989e80c1f70bb12315da753f8f4c91c2ba5",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -2751,8 +2751,8 @@ absl::Status VerifyOriginalValue(const HloModule& module) {\n       if (auto original_value = instruction->original_value()) {\n         // An original value is expected to have intermediate nodes that are\n         // always nullopt and leaves with actual values.\n-        for (const auto& leaf : original_value->leaves()) {\n-          if (!leaf.second.has_value()) {\n+        for (const auto& pair : original_value->original_arrays()) {\n+          if (!pair.second.has_value()) {\n             return Internal(\n                 \"Leaf nodes in an original value is expected to contain values.\"\n                 \" Instruction: %s.\","
        },
        {
            "sha": "37499625b9e1e4c125cf013a454bf28dfc1e5457",
            "filename": "third_party/xla/xla/xla_data.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/186baec876e82884b92d8afbd5e68bc711a7a3a9/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla_data.proto?ref=186baec876e82884b92d8afbd5e68bc711a7a3a9",
            "patch": "@@ -1193,14 +1193,13 @@ message OriginalArrayProto {\n   repeated int64 shape_index = 2;\n }\n \n-message OriginalValueNodeProto {\n+message OriginalValueElementProto {\n   repeated int64 shape_index = 1;\n   OriginalArrayProto original_array = 2;\n }\n \n message OriginalValueProto {\n-  ShapeProto shape = 1;\n-  repeated OriginalValueNodeProto leaves = 2;\n+  repeated OriginalValueElementProto elements = 1;\n }\n \n message GemmPerfTableEntry {"
        }
    ],
    "stats": {
        "total": 728,
        "additions": 568,
        "deletions": 160
    }
}