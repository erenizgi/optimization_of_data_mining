{
    "author": "amd-songpiao",
    "message": "PR #35026: [ROCm] fixed TritonFusionNumericsVerifierTest.VerifyThatDisablingTritonIsFast on rocm\n\nImported from GitHub PR https://github.com/openxla/xla/pull/35026\n\nThe original warp size 32 leads to the following error message: \"INTERNAL: Failed to launch ROCm kernel: triton_softmax with block dimensions: 2048x1x1: HIP_ERROR_InvalidValue\".\n\n32 warps × 64 threads/wavefront = 2048 threads (exceeds 1024 limit)\n\nFor comparison on NVIDIA:\n32 warps × 32 threads/warp = 1024 threads (within limit)\n\nThis test should be a general test for all the platforms.\n\n@xla-rotation could you review my PR, please?\nCopybara import of the project:\n\n--\n26edce6666fd55e7ad965aa677d7721140c60739 by Songlin Piao <Songlin.Piao@amd.com>:\n\nadapt the num_warps so that the hlo could be compiled on both amd and nvidia\n\nMerging this change closes #35026\n\nPiperOrigin-RevId: 843141066",
    "sha": "4fb9488700235410453bf977977f35d31ba7b38b",
    "files": [
        {
            "sha": "c0492c26cdac1c6f5fbfa099c6258a9a1293fd87",
            "filename": "third_party/xla/xla/service/gpu/transforms/triton_fusion_numerics_verifier_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4fb9488700235410453bf977977f35d31ba7b38b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4fb9488700235410453bf977977f35d31ba7b38b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc?ref=4fb9488700235410453bf977977f35d31ba7b38b",
            "patch": "@@ -517,7 +517,7 @@ ENTRY main {\n       \"kind\":\"__triton\",\n       \"block_level_fusion_config\":{\n         \"output_tiles\":[{\"sizes\":[\"1\",\"1\",\"1\",\"16384\"]}],\n-        \"num_warps\":\"32\",\n+        \"num_warps\":\"16\",\n         \"num_ctas\":\"1\",\n         \"num_stages\":\"1\"}}}\n }"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}