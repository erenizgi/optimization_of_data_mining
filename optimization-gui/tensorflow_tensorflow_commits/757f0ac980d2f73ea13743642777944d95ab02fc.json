{
    "author": "beckerhe",
    "message": "Add proto serialization for GpuComputeCapability\n\nPiperOrigin-RevId: 825657032",
    "sha": "757f0ac980d2f73ea13743642777944d95ab02fc",
    "files": [
        {
            "sha": "b61a76c155b6f9dcbf7929baeb53c57e37602273",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=757f0ac980d2f73ea13743642777944d95ab02fc",
            "patch": "@@ -68,6 +68,7 @@ cc_library(\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n     ],\n )\n@@ -924,6 +925,9 @@ xla_cc_test(\n     deps = [\n         \":device_description\",\n         \":semantic_version\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/rocm:rocm_compute_capability\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "9264fb048dd642783f85b5f38c6f3deeb0c22982",
            "filename": "third_party/xla/xla/stream_executor/device_description.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 1,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.cc?ref=757f0ac980d2f73ea13743642777944d95ab02fc",
            "patch": "@@ -17,13 +17,14 @@ limitations under the License.\n \n #include <cstdint>\n #include <string>\n-#include <variant>\n \n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.pb.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/stream_executor/rocm/rocm_compute_capability.h\"\n #include \"xla/tsl/lib/math/math_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n@@ -150,4 +151,33 @@ void CalculateDimensionality(const DeviceDescription &device_description,\n   }\n }\n \n+GpuComputeCapabilityProto GpuComputeCapability::ToProto() const {\n+  GpuComputeCapabilityProto proto;\n+  if (IsCuda()) {\n+    *proto.mutable_cuda_compute_capability() =\n+        cuda_compute_capability()->ToProto();\n+  } else {\n+    *proto.mutable_rocm_compute_capability() =\n+        rocm_compute_capability()->ToProto();\n+  }\n+  return proto;\n+}\n+\n+absl::StatusOr<GpuComputeCapability> GpuComputeCapability::FromProto(\n+    const GpuComputeCapabilityProto& proto) {\n+  if (proto.has_cuda_compute_capability()) {\n+    TF_ASSIGN_OR_RETURN(\n+        CudaComputeCapability cuda_compute_capability,\n+        CudaComputeCapability::FromProto(proto.cuda_compute_capability()));\n+    return GpuComputeCapability(cuda_compute_capability);\n+  }\n+\n+  if (proto.has_rocm_compute_capability()) {\n+    return GpuComputeCapability(\n+        RocmComputeCapability::FromProto(proto.rocm_compute_capability()));\n+  }\n+\n+  return absl::InvalidArgumentError(\n+      \"The serialized GpuComputeCapability has no compute capability set.\");\n+}\n }  // namespace stream_executor"
        },
        {
            "sha": "521e2d2bd50b73d3d9da1e01cc15ee49bee6ceae",
            "filename": "third_party/xla/xla/stream_executor/device_description.h",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.h?ref=757f0ac980d2f73ea13743642777944d95ab02fc",
            "patch": "@@ -78,6 +78,21 @@ class GpuComputeCapability {\n     return rocm_compute_capability()->ToString();\n   }\n \n+  GpuComputeCapabilityProto ToProto() const;\n+\n+  static absl::StatusOr<GpuComputeCapability> FromProto(\n+      const GpuComputeCapabilityProto& proto);\n+\n+  friend bool operator==(const GpuComputeCapability& lhs,\n+                         const GpuComputeCapability& rhs) {\n+    return lhs.compute_capability_ == rhs.compute_capability_;\n+  }\n+\n+  friend bool operator!=(const GpuComputeCapability& lhs,\n+                         const GpuComputeCapability& rhs) {\n+    return !(lhs == rhs);\n+  }\n+\n  private:\n   std::variant<CudaComputeCapability, RocmComputeCapability>\n       compute_capability_;"
        },
        {
            "sha": "54e7db38cfd2d7873cfc58448c08565e5632778f",
            "filename": "third_party/xla/xla/stream_executor/device_description.proto",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description.proto?ref=757f0ac980d2f73ea13743642777944d95ab02fc",
            "patch": "@@ -24,6 +24,13 @@ message RocmComputeCapabilityProto {\n   string gcn_arch_name = 1;\n }\n \n+message GpuComputeCapabilityProto {\n+  oneof compute_capability {\n+    CudaComputeCapabilityProto cuda_compute_capability = 1;\n+    RocmComputeCapabilityProto rocm_compute_capability = 2;\n+  }\n+}\n+\n message GpuDeviceInfoProto {\n   int32 threads_per_block_limit = 1;\n   int32 threads_per_warp = 2;"
        },
        {
            "sha": "8f6684abaaa6b4aa22f4863a9e205908e2e195a1",
            "filename": "third_party/xla/xla/stream_executor/device_description_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/757f0ac980d2f73ea13743642777944d95ab02fc/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fdevice_description_test.cc?ref=757f0ac980d2f73ea13743642777944d95ab02fc",
            "patch": "@@ -16,11 +16,16 @@ limitations under the License.\n \n #include <string>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/rocm/rocm_compute_capability.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n \n namespace stream_executor {\n namespace {\n+using absl_testing::IsOkAndHolds;\n \n TEST(DeviceDescription, DefaultConstruction) {\n   DeviceDescription desc;\n@@ -116,5 +121,16 @@ TEST(RocmComputeCapability, Accessors) {\n   EXPECT_TRUE(RocmComputeCapability{\"gfx1103\"}.has_hipblaslt());\n }\n \n+TEST(GpuComputeCapability, ProtoConversion) {\n+  EXPECT_THAT(\n+      GpuComputeCapability::FromProto(\n+          GpuComputeCapability(CudaComputeCapability::Volta()).ToProto()),\n+      IsOkAndHolds(GpuComputeCapability(CudaComputeCapability::Volta())));\n+  EXPECT_THAT(\n+      GpuComputeCapability::FromProto(\n+          GpuComputeCapability(RocmComputeCapability(\"gfx900\")).ToProto()),\n+      IsOkAndHolds(GpuComputeCapability(RocmComputeCapability(\"gfx900\"))));\n+}\n+\n }  // namespace\n }  // namespace stream_executor"
        }
    ],
    "stats": {
        "total": 74,
        "additions": 73,
        "deletions": 1
    }
}