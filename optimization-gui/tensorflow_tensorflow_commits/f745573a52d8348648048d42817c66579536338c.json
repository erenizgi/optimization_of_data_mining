{
    "author": "WillFroom",
    "message": "[XLA:CPU/GPU][XTile] Fix not instruction for non-pred types.\n\nPiperOrigin-RevId: 841696951",
    "sha": "f745573a52d8348648048d42817c66579536338c",
    "files": [
        {
            "sha": "ce2212b64621e9fa5536ef6971f6ab3220060d9f",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=f745573a52d8348648048d42817c66579536338c",
            "patch": "@@ -132,6 +132,7 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:ArithDialect\",\n+        \"@llvm-project//mlir:ArithUtils\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:MathDialect\",\n         \"@llvm-project//mlir:Support\","
        },
        {
            "sha": "f73c72bcf7873a940cd38b3e0e302140a93f20a5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 1,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=f745573a52d8348648048d42817c66579536338c",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"llvm/Support/Casting.h\"\n #include \"llvm/Support/MathExtras.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Arith/Utils/Utils.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n #include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Builders.h\"\n@@ -156,6 +157,17 @@ absl::StatusOr<TensorValue> EmitNestedFusion(\n \n   return EmitScope(b, to_emit, region_values);\n }\n+\n+// Get a constant with all high bits of the same type as provided.\n+mlir::Value OnesLike(mlir::ImplicitLocOpBuilder& b, mlir::Type type) {\n+  mlir::Type element_type = mlir::getElementTypeOrSelf(type);\n+  CHECK(element_type.isInteger()) << \"OnesLike only supports integer types.\";\n+\n+  int64_t width = element_type.getIntOrFloatBitWidth();\n+  mlir::APInt all_ones = mlir::APInt::getAllOnes(width);\n+  return mlir::createScalarOrSplatConstant(b, b.getLoc(), type, all_ones);\n+}\n+\n }  // namespace\n \n SmallVector<int64_t> GetPaddedTileSizes(ArrayRef<int64_t> tile_sizes) {\n@@ -425,7 +437,7 @@ absl::StatusOr<Value> EmitElementwise(mlir::ImplicitLocOpBuilder& b,\n     case HloOpcode::kFloor:\n       return mm::FloorOp::create(b, inputs[0]);\n     case HloOpcode::kNot:\n-      return ma::XOrIOp::create(b, inputs[0], OnesLike(b, inputs[0]));\n+      return ma::XOrIOp::create(b, inputs[0], OnesLike(b, inputs[0].getType()));\n     case HloOpcode::kNegate:\n       // NegFOp is not supported by Triton.\n       return Subtract(b, {ZerosLike(b, inputs[0]), inputs[0]});"
        },
        {
            "sha": "5d1dfee338123fe4652d6f983e77b352a8f45955",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.h",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h?ref=f745573a52d8348648048d42817c66579536338c",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n #include \"mlir/IR/Types.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/IR/ValueRange.h\"\n@@ -197,10 +198,6 @@ inline mlir::Value ZerosLike(mlir::ImplicitLocOpBuilder& b, mlir::Value x) {\n   return ConstLike(b, x, 0);\n }\n \n-inline mlir::Value OnesLike(mlir::ImplicitLocOpBuilder& b, mlir::Value x) {\n-  return ConstLike(b, x, 1);\n-}\n-\n bool IsFp8Type(mlir::Type t);\n \n // Triton type conversions."
        },
        {
            "sha": "99112cd3bf51b33414f8dda36a210d8f196d20b7",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f745573a52d8348648048d42817c66579536338c/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=f745573a52d8348648048d42817c66579536338c",
            "patch": "@@ -420,6 +420,32 @@ CHECK: arith.divsi {{.*}} : i32\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n+TEST_F(TritonEmitterTest, BitwiseNotIsEmittedCorrectly) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+fused_not {\n+  param_0 = s32[100] parameter(0)\n+  ROOT not = s32[100] not(param_0)\n+}\n+\n+ENTRY main {\n+  p0 = s32[100] parameter(0)\n+  ROOT not = s32[100] fusion(p0), kind=kCustom, calls=fused_not,\n+    backend_config={\"fusion_backend_config\":{\n+      \"kind\":\"__triton\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"1\",\"output_tiles\":[{\"sizes\":[100]}],\n+        \"num_ctas\":1,\"num_stages\":1,\"is_tma_allowed\":false}}}\n+}\n+)\";\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fused_not\", R\"(\n+CHECK: arith.constant dense<-1>\n+CHECK: arith.xori\n+)\"));\n+  EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n+}\n+\n TEST_F(TritonEmitterTest, ReductionOnMinormostAxisIsEmittedCorrectly) {\n   constexpr absl::string_view kHloText = R\"(\n HloModule m"
        }
    ],
    "stats": {
        "total": 46,
        "additions": 41,
        "deletions": 5
    }
}