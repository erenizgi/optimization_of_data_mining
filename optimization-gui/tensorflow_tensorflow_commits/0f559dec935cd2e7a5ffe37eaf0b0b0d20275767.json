{
    "author": "ezhulenev",
    "message": "[xla:cpu] Move buffer allocation info encoding to tf2xla\n\nPiperOrigin-RevId: 825732652",
    "sha": "0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
    "files": [
        {
            "sha": "ffb340b3da3f415ac8b91413854ac635b3db3f97",
            "filename": "tensorflow/compiler/aot/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2FBUILD?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -96,6 +96,7 @@ cc_library(\n         \":thunk_proto_execution_deserializer\",\n         \"//tensorflow/compiler/tf2xla\",\n         \"//tensorflow/compiler/tf2xla:allocator\",\n+        \"//tensorflow/compiler/tf2xla:encoded_buffer_allocation_info\",\n         \"//tensorflow/compiler/tf2xla:mlir_tf2xla\",  # fixdeps: keep\n         \"//tensorflow/compiler/tf2xla:tf2xla_proto_cc\",\n         \"//tensorflow/compiler/tf2xla:tf2xla_util\","
        },
        {
            "sha": "21c286cafa7aef0b6dec1c0212e50e0f0878b9de",
            "filename": "tensorflow/compiler/aot/codegen.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -42,6 +42,7 @@ limitations under the License.\n #include \"tensorflow/compiler/aot/embedded_protocol_buffers.h\"\n #include \"tensorflow/compiler/aot/thunk_proto_execution_deserializer.h\"\n #include \"tensorflow/compiler/tf2xla/allocator.h\"\n+#include \"tensorflow/compiler/tf2xla/encoded_buffer_allocation_info.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla_util.h\"\n #include \"xla/backends/cpu/buffer_allocation_info.h\""
        },
        {
            "sha": "6cb8c8b29f01144f76bcd98df4d7e8f5d680ff6b",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -138,6 +138,25 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"encoded_buffer_allocation_info\",\n+    hdrs = [\"encoded_buffer_allocation_info.h\"],\n+    visibility = [\":friends\"],\n+    deps = [\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n+    ],\n+)\n+\n+tf_cc_test(\n+    name = \"encoded_buffer_allocation_info_test\",\n+    srcs = [\"encoded_buffer_allocation_info_test.cc\"],\n+    deps = [\n+        \":encoded_buffer_allocation_info\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n+    ],\n+)\n+\n cc_library(\n     name = \"tf2xla\",\n     srcs = [\"tf2xla.cc\"],\n@@ -218,6 +237,7 @@ filegroup(\n     name = \"xla_compiled_cpu_runtime_hdrs\",\n     srcs = [\n         \"allocator.h\",\n+        \"encoded_buffer_allocation_info.h\",\n         \"xla_compiled_cpu_function.h\",\n         \"//tensorflow/core/kernels:xla_cpu_runtime_hdrs\",\n         \"//tensorflow/core/platform:xla_cpu_runtime_srcs\",\n@@ -437,6 +457,7 @@ cc_library(\n         \":allocator\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/types:span\",\n+        \":encoded_buffer_allocation_info\",\n         \"@local_xla//xla/service:custom_call_status_internal\",\n         \"@local_xla//xla/backends/cpu/runtime:rng_state_lib\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n@@ -502,6 +523,7 @@ cc_library(\n     hdrs = [\"xla_jit_compiled_cpu_function.h\"],\n     visibility = [\"//visibility:public\"],\n     deps = [\n+        \":encoded_buffer_allocation_info\",\n         \":tf2xla\",\n         \":tf2xla_proto_cc\",\n         \":xla_compiled_cpu_function\","
        },
        {
            "sha": "5981751259967a4f5208bce668d16fb06ded1f9f",
            "filename": "tensorflow/compiler/tf2xla/encoded_buffer_allocation_info.h",
            "status": "added",
            "additions": 99,
            "deletions": 0,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info.h?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -0,0 +1,99 @@\n+/* Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef TENSORFLOW_COMPILER_TF2XLA_ENCODED_BUFFER_ALLOCATION_INFO_H_\n+#define TENSORFLOW_COMPILER_TF2XLA_ENCODED_BUFFER_ALLOCATION_INFO_H_\n+\n+#include <cstdint>\n+\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+\n+namespace xla {\n+namespace cpu {\n+\n+// Encoded version of `BufferAllocationInfo`, which can be used to reconstruct\n+// the `BufferAllocationInfo` later. It's used in the AOT compiler, to\n+// represent buffer allocation info as a lightweight struct.\n+struct EncodedBufferAllocationInfo {\n+  EncodedBufferAllocationInfo(uint64_t packed_kind_and_size,\n+                              uint32_t entry_param_number,\n+                              uint32_t result_number)\n+      : packed_kind_and_size(packed_kind_and_size),\n+        entry_param_number(entry_param_number),\n+        result_number(result_number) {}\n+\n+  // Encodes BufferAllocationInfo into the struct that can be used to\n+  // reconstruct the BufferAllocationInfo later using the constructor. We need\n+  // this because we use BufferAllocationInfo in places where using protocol\n+  // buffers would negatively impact binary size.\n+  explicit EncodedBufferAllocationInfo(\n+      const BufferAllocationInfo& buffer_info) {\n+    packed_kind_and_size = Pack(buffer_info.kind(), buffer_info.size());\n+    entry_param_number = buffer_info.is_entry_parameter()\n+                             ? buffer_info.entry_parameter_number()\n+                             : -1;\n+    result_number = buffer_info.is_result() ? buffer_info.result_number() : -1;\n+  }\n+\n+  explicit operator BufferAllocationInfo() const {\n+    auto kind = UnpackKind(packed_kind_and_size);\n+    auto size = UnpackSize(packed_kind_and_size);\n+    int32_t entry_param_number = static_cast<int32_t>(this->entry_param_number);\n+    int32_t result_number = static_cast<int32_t>(this->result_number);\n+\n+    switch (kind) {\n+      case BufferAllocationInfo::Kind::kConstant:\n+        return BufferAllocationInfo::Constant(size);\n+      case BufferAllocationInfo::Kind::kTemp:\n+        return BufferAllocationInfo::Temp(size);\n+      case BufferAllocationInfo::Kind::kParameter:\n+        if (entry_param_number >= 0 && result_number >= 0) {\n+          return BufferAllocationInfo::InOutParameter(size, entry_param_number,\n+                                                      result_number);\n+        }\n+        if (entry_param_number >= 0) {\n+          return BufferAllocationInfo::EntryParameter(size, entry_param_number);\n+        }\n+        return BufferAllocationInfo::Result(size, result_number);\n+      case BufferAllocationInfo::Kind::kThreadLocal:\n+        return BufferAllocationInfo::ThreadLocal(size);\n+    }\n+  }\n+\n+  static uint64_t Pack(BufferAllocationInfo::Kind kind, uint64_t size) {\n+    return (static_cast<uint64_t>(size) << 2) | static_cast<uint64_t>(kind);\n+  }\n+\n+  static constexpr BufferAllocationInfo::Kind UnpackKind(uint64_t packed) {\n+    return static_cast<BufferAllocationInfo::Kind>((packed << 62) >> 62);\n+  }\n+\n+  static constexpr uint64_t UnpackSize(uint64_t packed) { return packed >> 2; }\n+\n+  uint64_t packed_kind_and_size = 0;\n+  uint32_t entry_param_number = -1;\n+  uint32_t result_number = -1;\n+};\n+}  // namespace cpu\n+\n+// TODO(ezhulenev): This is a temporary hack to keep `tfcompile` code working.\n+namespace cpu_function_runtime {\n+using BufferInfo = ::xla::cpu::BufferAllocationInfo;\n+using EncodedBufferInfo = ::xla::cpu::EncodedBufferAllocationInfo;\n+}  // namespace cpu_function_runtime\n+\n+}  // namespace xla\n+\n+#endif  // TENSORFLOW_COMPILER_TF2XLA_ENCODED_BUFFER_ALLOCATION_INFO_H_"
        },
        {
            "sha": "c9fc52100abb338eb44f5879012b95d9ea745c19",
            "filename": "tensorflow/compiler/tf2xla/encoded_buffer_allocation_info_test.cc",
            "status": "renamed",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fencoded_buffer_allocation_info_test.cc?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -1,4 +1,4 @@\n-/* Copyright 2025 The OpenXLA Authors.\n+/* Copyright 2025 The TensorFlow Authors. All Rights Reserved.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n you may not use this file except in compliance with the License.\n@@ -13,14 +13,15 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"tensorflow/compiler/tf2xla/encoded_buffer_allocation_info.h\"\n \n #include <gtest/gtest.h>\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n \n namespace xla::cpu {\n namespace {\n \n-TEST(BufferAllocationInfoTest, RoundTrip) {\n+TEST(EncodedBufferAllocationInfoTest, RoundTrip) {\n   auto round_trip = [](const BufferAllocationInfo& buffer_info) {\n     EncodedBufferAllocationInfo encoded(buffer_info);\n     BufferAllocationInfo round_trip(encoded);",
            "previous_filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info_test.cc"
        },
        {
            "sha": "fc7b67df70efc59678267dab211fa8f1974392bd",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"tensorflow/compiler/tf2xla/encoded_buffer_allocation_info.h\"\n #include \"xla/backends/cpu/alignment.h\"\n #include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/backends/cpu/runtime/rng_state_lib.h\""
        },
        {
            "sha": "5599318e3a9a0263283151c3d2d78c4ce1bf0e9f",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n+#include \"tensorflow/compiler/tf2xla/encoded_buffer_allocation_info.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/xla_compiled_cpu_function_thunks.h\"\n #include \"xla/backends/cpu/buffer_allocation_info.h\""
        },
        {
            "sha": "23bd0d7c282adc03d35a2852d5050a155b294816",
            "filename": "third_party/xla/xla/backends/cpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 9,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -60,15 +60,6 @@ cc_library(\n     ],\n )\n \n-xla_cc_test(\n-    name = \"buffer_allocation_info_test\",\n-    srcs = [\"buffer_allocation_info_test.cc\"],\n-    deps = [\n-        \":buffer_allocation_info\",\n-        \"@com_google_googletest//:gtest_main\",\n-    ],\n-)\n-\n onednn_graph_cc_library(\n     name = \"onednn_emitter\",\n     srcs = [\"onednn_emitter.cc\"],"
        },
        {
            "sha": "d71811569a3eb56482152f90313d3539c0a33115",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info.h",
            "status": "modified",
            "additions": 2,
            "deletions": 75,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0f559dec935cd2e7a5ffe37eaf0b0b0d20275767/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h?ref=0f559dec935cd2e7a5ffe37eaf0b0b0d20275767",
            "patch": "@@ -19,8 +19,7 @@ limitations under the License.\n #include <cassert>\n #include <cstdint>\n \n-namespace xla {\n-namespace cpu {\n+namespace xla::cpu {\n \n // `BufferAllocationInfo` stores information about buffer allocations required\n // by an XLA:CPU executable at run time. It corresponds to a `BufferAllocation`\n@@ -117,78 +116,6 @@ class BufferAllocationInfo {\n   int32_t result_number_ = -1;\n };\n \n-// Encoded version of `BufferAllocationInfo`, which can be used to reconstruct\n-// the `BufferAllocationInfo` later. It's used in the AOT compiler, to\n-// represent buffer allocation info as a lightweight struct.\n-struct EncodedBufferAllocationInfo {\n-  EncodedBufferAllocationInfo(uint64_t packed_kind_and_size,\n-                              uint32_t entry_param_number,\n-                              uint32_t result_number)\n-      : packed_kind_and_size(packed_kind_and_size),\n-        entry_param_number(entry_param_number),\n-        result_number(result_number) {}\n-\n-  // Encodes BufferAllocationInfo into the struct that can be used to\n-  // reconstruct the BufferAllocationInfo later using the constructor. We need\n-  // this because we use BufferAllocationInfo in places where using protocol\n-  // buffers would negatively impact binary size.\n-  explicit EncodedBufferAllocationInfo(\n-      const BufferAllocationInfo& buffer_info) {\n-    packed_kind_and_size = Pack(buffer_info.kind(), buffer_info.size());\n-    entry_param_number = buffer_info.is_entry_parameter()\n-                             ? buffer_info.entry_parameter_number()\n-                             : -1;\n-    result_number = buffer_info.is_result() ? buffer_info.result_number() : -1;\n-  }\n-\n-  explicit operator BufferAllocationInfo() const {\n-    auto kind = UnpackKind(packed_kind_and_size);\n-    auto size = UnpackSize(packed_kind_and_size);\n-    int32_t entry_param_number = static_cast<int32_t>(this->entry_param_number);\n-    int32_t result_number = static_cast<int32_t>(this->result_number);\n-\n-    switch (kind) {\n-      case BufferAllocationInfo::Kind::kConstant:\n-        return BufferAllocationInfo::Constant(size);\n-      case BufferAllocationInfo::Kind::kTemp:\n-        return BufferAllocationInfo::Temp(size);\n-      case BufferAllocationInfo::Kind::kParameter:\n-        if (entry_param_number >= 0 && result_number >= 0) {\n-          return BufferAllocationInfo::InOutParameter(size, entry_param_number,\n-                                                      result_number);\n-        }\n-        if (entry_param_number >= 0) {\n-          return BufferAllocationInfo::EntryParameter(size, entry_param_number);\n-        }\n-        return BufferAllocationInfo::Result(size, result_number);\n-      case BufferAllocationInfo::Kind::kThreadLocal:\n-        return BufferAllocationInfo::ThreadLocal(size);\n-    }\n-  }\n-\n-  static uint64_t Pack(BufferAllocationInfo::Kind kind, uint64_t size) {\n-    return (static_cast<uint64_t>(size) << 2) | static_cast<uint64_t>(kind);\n-  }\n-\n-  static constexpr BufferAllocationInfo::Kind UnpackKind(uint64_t packed) {\n-    return static_cast<BufferAllocationInfo::Kind>((packed << 62) >> 62);\n-  }\n-\n-  static constexpr uint64_t UnpackSize(uint64_t packed) { return packed >> 2; }\n-\n-  uint64_t packed_kind_and_size = 0;\n-  uint32_t entry_param_number = -1;\n-  uint32_t result_number = -1;\n-};\n-\n-}  // namespace cpu\n-\n-// TODO(ezhulenev): This is a temporary hack to keep `tfcompile` code working.\n-namespace cpu_function_runtime {\n-using BufferInfo = ::xla::cpu::BufferAllocationInfo;\n-using EncodedBufferInfo = ::xla::cpu::EncodedBufferAllocationInfo;\n-}  // namespace cpu_function_runtime\n-\n-}  // namespace xla\n+}  // namespace xla::cpu\n \n #endif  // XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_H_"
        }
    ],
    "stats": {
        "total": 218,
        "additions": 131,
        "deletions": 87
    }
}