{
    "author": "vwbaker",
    "message": "[xla:gpu] Fix our convert integer to pred in our Triton emitter\n\n`arith.trunci` for i1 will simply take the last bit, but HLO expects convert to i1 to be value != 0. Emit this conversion a a compare not equal to 0 instead. This is already done correctly for floats.\n\nPiperOrigin-RevId: 824716165",
    "sha": "d299463d26ff38c2018387dad5d6e0411c715ca5",
    "files": [
        {
            "sha": "c4bff9fac9dd214a60d804e28716a3c4746657b0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=d299463d26ff38c2018387dad5d6e0411c715ca5",
            "patch": "@@ -236,6 +236,11 @@ Value Cast(EmitterLocOpBuilder& b, Value value, Type dst_element_ty) {\n       }\n       return b.create<ma::ExtSIOp>(dst_ty, value);\n     }\n+    // int => bool is always value != 0.\n+    if (dst_element_ty.isInteger(1)) {\n+      return b.create<ma::CmpIOp>(ma::CmpIPredicate::ne, value,\n+                                  ZerosLike(b, value));\n+    }\n     return b.create<ma::TruncIOp>(dst_ty, value);\n   }\n   // int => float"
        },
        {
            "sha": "504873169da57af79775de8e33af3cf03d35c7e8",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=d299463d26ff38c2018387dad5d6e0411c715ca5",
            "patch": "@@ -259,8 +259,8 @@ ENTRY e {\n                                  module_and_metadata.block_level_parameters,\n                                  R\"(\n CHECK: %[[LOAD:.*]] = xtile.extract {{.*}} -> tensor<16x16xi8>\n-CHECK: %[[TRUNCI:.*]] = arith.trunci %[[LOAD]] : tensor<16x16xi8> to tensor<16x16xi1>\n-CHECK: %{{.*}} = arith.andi %[[TRUNCI]], %{{.*}} : tensor<16x16xi1>\n+CHECK: %[[CMPI:.*]] = arith.cmpi ne, %[[LOAD]], {{.*}} : tensor<16x16xi8>\n+CHECK: %{{.*}} = arith.andi %[[CMPI]], %{{.*}} : tensor<16x16xi1>\n )\"));\n }\n "
        },
        {
            "sha": "cdd54ead2ad20812b3cbe779d64008a02a42ab32",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_test.cc?ref=d299463d26ff38c2018387dad5d6e0411c715ca5",
            "patch": "@@ -468,9 +468,10 @@ ENTRY e {\n )\";\n   TF_EXPECT_OK(CreateTritonIrAndFileCheckForDot(this, kHloText,\n                                                 \"triton_gemm_computation\", R\"(\n+CHECK: %[[CST:.*]] = arith.constant dense<0>\n CHECK: %[[LOAD:.*]] = tt.load %{{.*}} {{.*}} : !tt.ptr<tensor<16x16xi8>>\n-CHECK: %[[TRUNCI:.*]] = arith.trunci %[[LOAD]] : tensor<16x16xi8> to tensor<16x16xi1>\n-CHECK: %{{.*}} = arith.andi %[[TRUNCI]], %{{.*}} : tensor<16x16xi1>\n+CHECK: %[[CMPI:.*]] = arith.cmpi ne, %[[LOAD]], %[[CST]] : tensor<16x16xi8>\n+CHECK: %{{.*}} = arith.andi %[[CMPI]], %{{.*}} : tensor<16x16xi1>\n )\"));\n }\n "
        },
        {
            "sha": "6e0212843c49f00b152dab9ef43965aae5d0ddd4",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 1,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d299463d26ff38c2018387dad5d6e0411c715ca5/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=d299463d26ff38c2018387dad5d6e0411c715ca5",
            "patch": "@@ -231,6 +231,32 @@ ENTRY entry {\n       hlo_text, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n }\n \n+TEST_F(TritonEmitterTest, ConvertIntegerToPredIsEmittedCorrectly) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule m\n+\n+fused_convert {\n+  p0 = s32[3,2,2]{2,1,0} parameter(0)\n+  ROOT convert0 = pred[3,2,2]{2,1,0} convert(p0)\n+}\n+\n+ENTRY %main {\n+  p0 = s32[3,2,2]{2,1,0} parameter(0)\n+  ROOT input_convert_fusion = pred[3,2,2]{2,1,0} fusion(p0), kind=kCustom,\n+    calls=fused_convert,\n+    backend_config={\"fusion_backend_config\":{\n+      \"kind\":\"__triton\",\"block_level_fusion_config\":{\n+        \"num_warps\":\"1\",\"output_tiles\":[{\"sizes\":[\"1\",\"2\",\"2\"]}],\"num_ctas\":1,\n+        \"num_stages\":1,\"is_tma_allowed\":false}}}\n+}\n+)\";\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fused_convert\", R\"(\n+CHECK: %[[CST:.*]] = arith.constant dense<0>\n+CHECK: arith.cmpi ne, %{{.*}}, %[[CST]]\n+)\"));\n+  EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n+}\n+\n TEST_F(TritonEmitterTest, PredicateAddIsEmittedCorrectly) {\n   constexpr absl::string_view kHloText = R\"(\n HloModule m\n@@ -2503,7 +2529,7 @@ ENTRY main {\n   TF_EXPECT_OK(\n       CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n CHECK:      %[[I8_PARAM:.*]] = xtile.extract {{.*}} -> tensor<4xi8>\n-CHECK:      arith.trunci %[[I8_PARAM]] : tensor<4xi8> to tensor<4xi1>\n+CHECK:      arith.cmpi ne, %[[I8_PARAM]], {{.*}} : tensor<4xi8>\n )\"));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));"
        }
    ],
    "stats": {
        "total": 42,
        "additions": 37,
        "deletions": 5
    }
}