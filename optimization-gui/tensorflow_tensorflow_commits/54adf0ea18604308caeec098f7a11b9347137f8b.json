{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Create 0D elemental ops and convert them to scalars as a later pass.\n\nNot emitting 0D tensors from the tiled emitter is a triton specific requirement, the additional to/from tensors scattered around make lowering more complex for other backends (such as CPU) so this is the first step to pushing the logic down the stack.\n\nPiperOrigin-RevId: 827929019",
    "sha": "54adf0ea18604308caeec098f7a11b9347137f8b",
    "files": [
        {
            "sha": "5b7fcae407f93a5e4f6731ffc07dcf290ba60806",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -454,7 +454,7 @@ absl::StatusOr<Value> EmitElementwise(EmitterLocOpBuilder& b,\n       if (is_integer) {\n         // XLA add semantics for predicates is equal to bitwise OR, while Arith\n         // defines it differently. Replace add with or in this case.\n-        if (inputs[0].getType().isInteger(1)) {\n+        if (getElementTypeOrSelf(inputs[0]).isInteger(1)) {\n           return b.create<ma::OrIOp>(inputs[0], inputs[1]);\n         }\n         return b.create<ma::AddIOp>(inputs[0], inputs[1]);"
        },
        {
            "sha": "07c11f5b37946dcce5ff206a707d6f4a590ad3a5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 50,
            "deletions": 35,
            "changes": 85,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -184,6 +184,31 @@ using ::xla::gpu::triton::TritonType;\n \n namespace {\n \n+using TensorValue = mlir::TypedValue<mlir::RankedTensorType>;\n+// Create either a non-0D tensor or a scalar.\n+// If the passed value is a tensor with rank 0, it is wrapped in a ToScalarOp\n+// to extract the scalar and in all other cases, the value is returned as is.\n+ScalarOrTensor MakeScalarOrTensor(EmitterLocOpBuilder& b, mlir::Value value) {\n+  if (auto tensor_value = mlir::dyn_cast<TensorValue>(value);\n+      tensor_value && tensor_value.getType().getRank() == 0) {\n+    // Triton does not support 0-D tensors so we must extract the scalar value.\n+    // TODO(csigg): This should be handled in the extract/insert rewrite.\n+    return ScalarOrTensor(b.createOrFold<xtile::ToScalarOp>(tensor_value));\n+  }\n+\n+  return ScalarOrTensor(value);\n+}\n+\n+// Create a tensor from the passed value.\n+// If the passed value is a scalar, it is wrapped in a ToTensorOp to create a\n+// 0D-Tensor else it is returned as is.\n+TensorValue MakeTensor(EmitterLocOpBuilder& b, mlir::Value value) {\n+  if (auto tensor = mlir::dyn_cast<TensorValue>(value)) {\n+    return tensor;\n+  }\n+  return mlir::cast<TensorValue>(b.createOrFold<xtile::ToTensorOp>(value));\n+}\n+\n Value MakeIndex(EmitterLocOpBuilder& b, int64_t value) {\n   return b.create<arith::ConstantIndexOp>(value);\n }\n@@ -304,8 +329,6 @@ absl::StatusOr<TileInfo> TileInfo::Construct(\n                   minor_to_major_layout, storage_type);\n }\n \n-using TensorValue = mlir::TypedValue<mlir::RankedTensorType>;\n-\n // Same as HLO BroadcastInDims. The sorted indices in `dims` specify the mapping\n // of the input dimensions to the output dimensions.\n ScalarOrTensor BroadcastInDims(EmitterLocOpBuilder b, ScalarOrTensor value,\n@@ -317,8 +340,7 @@ ScalarOrTensor BroadcastInDims(EmitterLocOpBuilder b, ScalarOrTensor value,\n \n   if (value.IsScalar()) {\n     CHECK(dims.empty()) << \"scalar broadcast must have empty dims\";\n-    broadcast_in_dim_input =\n-        b.create<xtile::ToTensorOp>(value.UnwrapScalar()).getResult();\n+    broadcast_in_dim_input = MakeTensor(b, value.UnwrapScalar());\n   } else {\n     broadcast_in_dim_input = value.UnwrapTensor();\n   }\n@@ -350,13 +372,7 @@ ScalarOrTensor EmitParameterExtract(EmitterLocOpBuilder b,\n       tensor_type, arg, tile_info.offsets(), tile_info.padded_tile_sizes(),\n       tile_info.tile_strides());\n \n-  if (tensor_type.getRank() == 0) {\n-    // Triton does not support 0-D tensors so we must extract the scalar value.\n-    // TODO(csigg): This should be handled in the extract/insert rewrite.\n-    return ScalarOrTensor(b.create<xtile::ToScalarOp>(extracted_tensor));\n-  }\n-\n-  return ScalarOrTensor(extracted_tensor);\n+  return MakeScalarOrTensor(b, extracted_tensor);\n }\n \n absl::StatusOr<ScalarOrTensor> EmitScope(\n@@ -409,8 +425,8 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n                                                      neutral.UnwrapUnsafe()));\n   }\n \n-  Value init_value = b.create<xtile::ToTensorOp>(\n-      values[tiled_hlo_reduce.operand(1)].UnwrapScalar());\n+  Value init_value =\n+      MakeTensor(b, values[tiled_hlo_reduce.operand(1)].UnwrapScalar());\n \n   stablehlo::ReduceOp reduction = b.create<stablehlo::ReduceOp>(\n       input.UnwrapTensor(), init_value, reduction_dimension);\n@@ -442,8 +458,7 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n \n         // Emit from tensor op so that the reducer can be lowered to triton, as\n         // the triton reducer can only work with scalars.\n-        auto extracted_argument =\n-            ScalarOrTensor(b.create<xtile::ToScalarOp>(argument));\n+        auto extracted_argument = MakeScalarOrTensor(b, argument);\n         TF_RET_CHECK(region_values.insert({instr, extracted_argument}).second);\n       } else {\n         to_emit.push_back(instr);\n@@ -457,17 +472,12 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n                                   region_values));\n     // Emit from_elements op so that the reducer can be lowered to triton, as\n     // the triton reducer can only work with scalars.\n-    auto result_as_scalar = b.create<xtile::ToTensorOp>(result.UnwrapUnsafe());\n+    auto result_as_scalar = MakeTensor(b, result.UnwrapUnsafe());\n     b.create<stablehlo::ReturnOp>(SmallVector<Value>({result_as_scalar}));\n     b.setInsertionPointAfter(reduction);\n   }\n \n-  auto result = reduction.getResult(0);\n-  if (mlir::cast<ShapedType>(result.getType()).getRank() == 0) {\n-    result = b.create<xtile::ToScalarOp>(result);\n-  }\n-\n-  return ScalarOrTensor(result);\n+  return MakeScalarOrTensor(b, reduction.getResult(0));\n }\n \n // Emit code corresponding to a fusion instruction somehow nested within the\n@@ -1516,11 +1526,11 @@ absl::StatusOr<ScalarOrTensor> EmitTiledHloInstruction(\n     operands.reserve(hlo->operands().size());\n \n     for (const TiledHloInstruction* operand : tiled_hlo.operands()) {\n-      operands.push_back(values[operand].UnwrapUnsafe());\n+      operands.push_back(MakeTensor(b, values[operand].UnwrapUnsafe()));\n     }\n     TF_ASSIGN_OR_RETURN(Value result,\n                         EmitElementwise(b, device_info, *hlo, operands));\n-    return ScalarOrTensor(result);\n+    return MakeScalarOrTensor(b, result);\n   }\n \n   if (hlo->opcode() == HloOpcode::kReshape) {\n@@ -1635,11 +1645,11 @@ absl::StatusOr<ScalarOrTensor> EmitScope(\n       std::vector<Value> operands;\n       operands.reserve(hlo->operands().size());\n       for (const HloInstruction* operand : hlo->operands()) {\n-        operands.push_back(values[operand].UnwrapUnsafe());\n+        operands.push_back(MakeTensor(b, values[operand].UnwrapUnsafe()));\n       }\n       TF_ASSIGN_OR_RETURN(Value elementwise_result,\n                           EmitElementwise(b, device_info, *hlo, operands));\n-      result = ScalarOrTensor(elementwise_result);\n+      result = MakeScalarOrTensor(b, elementwise_result);\n     } else if (hlo->opcode() == HloOpcode::kTuple) {\n       TF_RET_CHECK(hlo->IsRoot()) << hlo->ToString();\n     } else if (hlo->opcode() == HloOpcode::kBitcast ||\n@@ -1842,14 +1852,8 @@ absl::Status EmitGeneric(mlir::OpBuilder builder,\n           ScalarOrTensor(Cast(b, result.UnwrapUnsafe(), result_storage_type));\n     }\n \n-    mlir::Value input_tensor;\n-    if (result.IsScalar()) {\n-      // TODO(csigg): Handle this in extract/insert rewrite.\n-      mlir::Value scalar_value = result.UnwrapScalar();\n-      input_tensor = b.create<xtile::ToTensorOp>(scalar_value);\n-    } else {\n-      input_tensor = result.UnwrapTensor();\n-    }\n+    // TODO(csigg): Handle this in extract/insert rewrite.\n+    mlir::Value input_tensor = MakeTensor(b, result.UnwrapUnsafe());\n \n     TF_ASSIGN_OR_RETURN(\n         auto tile_info,\n@@ -2312,11 +2316,22 @@ absl::Status LowerXTileToTriton(mlir::ModuleOp xtile_dialect_module,\n                                 mlir::MLIRContext& mlir_context,\n                                 const HloFusionInstruction& fusion,\n                                 const se::DeviceDescription& device_info) {\n-  {  // Convert xTile ops to Triton ops.\n+  {\n+    auto backend_config =\n+        fusion.backend_config<GpuBackendConfig>()->fusion_backend_config();\n+    absl::string_view fusion_kind = backend_config.kind();\n+\n+    // Convert xTile ops to Triton ops.\n     mlir::PassManager pm(&mlir_context);\n     // Disable verifier because the Triton code may be invalid due to the\n     // unsupported types.\n     pm.enableVerifier(/*enabled=*/false);\n+    // The legacy emitter supports 0D tensors so we would get inconsistent\n+    // results if we try to rewrite them.\n+    if (fusion_kind != kTritonGemmFusionKind) {\n+      pm.addPass(\n+          mlir::triton::xla::CreateTritonXLAConvert0DTensorToScalarPass());\n+    }\n     pm.addPass(mlir::triton::xla::CreateTensorLowerToTritonPass());\n     pm.addPass(mlir::triton::xla::CreateStableHLOLowerToTritonPass());\n "
        },
        {
            "sha": "5b415122b9b1304d5eda714a4fe92a017b3b7404",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 27,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -392,12 +392,9 @@ ENTRY entry_computation {\n       CreateXTileIrAndFileCheck(this, kHloText, \"fused_reduce\", R\"(\n CHECK: stablehlo.reduce\n CHECK: reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)\n-CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG0]] : tensor<f32>\n-CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG1]] : tensor<f32>\n-CHECK:   %[[ADD:.*]] = arith.addf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n+CHECK:   %[[ADD:.*]] = arith.addf %[[ARG0]], %[[ARG1]] : tensor<f32>\n CHECK:   %[[MIN:.*]] = arith.minimumf %[[ADD]]\n-CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[MIN]] : f32\n-CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n+CHECK:   stablehlo.return %[[MIN]] : tensor<f32>\n )\"));\n \n   TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n@@ -1033,11 +1030,8 @@ CHECK:  %[[CMPI:.*]] = arith.cmpi slt, %[[BROADCAST]]\n CHECK:  %[[SELECT:.*]] = arith.select %[[CMPI]], %[[LOAD]], %{{.*}}\n CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%[[SELECT]] init: %{{.*}}) across dimensions = [0] : (tensor<8x4xf32>, tensor<f32>) -> tensor<4xf32>\n CHECK:   reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)  {\n-CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG0]] : tensor<f32>\n-CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG1]] : tensor<f32>\n-CHECK:   %[[MAX:.*]] = arith.maximumf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n-CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[MAX]] : f32\n-CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n+CHECK:   %[[MAX:.*]] = arith.maximumf %[[ARG0]], %[[ARG1]] : tensor<f32>\n+CHECK:   stablehlo.return %[[MAX]] : tensor<f32>\n CHECK: }\n           )\"));\n \n@@ -1102,11 +1096,8 @@ CHECK-NEXT:       xtile.extract %[[P0]]\n CHECK-SAME:       [%[[PID]], %[[EXTRACT_IDX_0]]] [1, 128] [1, 1]\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG2:[^:]*]]: tensor<f32>, %[[ARG3:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG2_SCALAR:.*]] = xtile.to_scalar %[[ARG2]] : tensor<f32>\n-CHECK-NEXT:           %[[ARG3_SCALAR:.*]] = xtile.to_scalar %[[ARG3]] : tensor<f32>\n-CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG2_SCALAR]], %[[ARG3_SCALAR]] : f32\n-CHECK-NEXT:           %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ADD]] : f32\n-CHECK-NEXT:           stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n+CHECK:              %[[ADD:.*]] = arith.addf %[[ARG2]], %[[ARG3]] : tensor<f32>\n+CHECK:              stablehlo.return %[[ADD]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            arith.mulf\n CHECK-SAME:       tensor<1x128xf32>\n@@ -1186,11 +1177,8 @@ CHECK-DAG:        %[[EXTRACT_IDX_1:.*]] = xla.apply_indexing #indexing_map(%[[TI\n CHECK-DAG:        xtile.extract %[[P1]][%[[EXTRACT_IDX_1]]] [128] [1] : {{.*}} -> tensor<128xf32>\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG3:[^:]*]]: tensor<f32>, %[[ARG4:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG3_SCALAR:.*]] = xtile.to_scalar %[[ARG3]] : tensor<f32>\n-CHECK-NEXT:           %[[ARG4_SCALAR:.*]] = xtile.to_scalar %[[ARG4]] : tensor<f32>\n-CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG3_SCALAR]], %[[ARG4_SCALAR]] : f32\n-CHECK-NEXT:           %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ADD]] : f32\n-CHECK-NEXT:           stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n+CHECK:              %[[ADD:.*]] = arith.addf %[[ARG3]], %[[ARG4]] : tensor<f32>\n+CHECK:              stablehlo.return %[[ADD]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            arith.mulf\n CHECK-DAG:        xtile.insert {{.*}} into %[[P2]]\n@@ -1278,11 +1266,8 @@ CHECK-DAG:        %[[COL_INDEX_COPY:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n CHECK:            xtile.extract %[[P2]][%[[ROW_INDEX_COPY]], %[[COL_INDEX_COPY]]] [1, 1] [1, 1] : {{.*}} -> tensor<1x1xf32>\n CHECK:            stablehlo.reduce\n CHECK-NEXT:       reducer(%[[ARG4:[^:]*]]: tensor<f32>, %[[ARG5:[^:]*]]: tensor<f32>)  {\n-CHECK-NEXT:           %[[ARG4_SCALAR:.*]] = xtile.to_scalar %[[ARG4]] : tensor<f32>\n-CHECK-NEXT:           %[[ARG5_SCALAR:.*]] = xtile.to_scalar %[[ARG5]] : tensor<f32>\n-CHECK-NEXT:           %[[MAX:.*]] = arith.maximumf %[[ARG4_SCALAR]], %[[ARG5_SCALAR]] : f32\n-CHECK-NEXT:           %[[TO_TENSOR_MAX:.*]] = xtile.to_tensor %[[MAX]] : f32\n-CHECK-NEXT:           stablehlo.return %[[TO_TENSOR_MAX]] : tensor<f32>\n+CHECK:              %[[MAX:.*]] = arith.maximumf %[[ARG4]], %[[ARG5]] : tensor<f32>\n+CHECK:              stablehlo.return %[[MAX]] : tensor<f32>\n CHECK-NEXT:       }\n CHECK:            xtile.insert {{.*}} into %[[P3]]{{.*}}\n )\"));\n@@ -2636,8 +2621,8 @@ ENTRY main {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n-CHECK:       %[[RES_TO_TENSOR:.*]] = xtile.to_tensor %[[ARG:.*]] : f32\n-CHECK:       stablehlo.broadcast_in_dim %[[RES_TO_TENSOR]], dims = []\n+CHECK:       %[[EXTRACTED_VALUE:.*]] = xtile.extract\n+CHECK:       stablehlo.broadcast_in_dim %[[EXTRACTED_VALUE]], dims = []\n           )\"));\n \n   TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck("
        },
        {
            "sha": "3f5d942decfb3fd628a0bcfb1d7d1a462b76c2ba",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -179,8 +179,7 @@ ENTRY e {\n       this, *module->GetComputationWithName(\"broadcast_in_dim_fusion\"),\n       block_level_parameters,\n       R\"(\n-CHECK: %[[TO_TENSOR:.*]] = xtile.to_tensor %[[ARG:.*]] : f32\n-CHECK: %[[RES:.*]] = stablehlo.broadcast_in_dim %[[TO_TENSOR]], dims = [] : (tensor<f32>) -> tensor<16x32x8xf32>\n+CHECK: %[[RES:.*]] = stablehlo.broadcast_in_dim %[[ARG:.*]], dims = [] : (tensor<f32>) -> tensor<16x32x8xf32>\n )\"));\n }\n \n@@ -220,11 +219,8 @@ CHECK: %[[REDUCE_INPUT:.*]] = arith.select {{.*}}\n CHECK: %[[INIT_VALUE_TO_TENSOR:.*]] = xtile.to_tensor %{{.*}} : f32\n CHECK: %[[RES:.*]] = stablehlo.reduce(%[[REDUCE_INPUT]] init: %[[INIT_VALUE_TO_TENSOR]]) across dimensions = [0] : (tensor<256x16xf32>, tensor<f32>) -> tensor<16xf32>\n CHECK: reducer(%[[ARG_0:.*]]: tensor<f32>, %[[ARG_1:.*]]: tensor<f32>)  {\n-CHECK:   %[[SCALAR_0:.*]] = xtile.to_scalar %[[ARG_0]] : tensor<f32>\n-CHECK:   %[[SCALAR_1:.*]] = xtile.to_scalar %[[ARG_1]] : tensor<f32>\n-CHECK:   %[[SUM:.*]] = arith.addf %[[SCALAR_0]], %[[SCALAR_1]] : f32\n-CHECK:   %[[TO_TENSOR:.*]] = xtile.to_tensor %[[SUM]] : f32\n-CHECK:   stablehlo.return %[[TO_TENSOR]] : tensor<f32>\n+CHECK:   %[[SUM:.*]] = arith.addf %[[ARG_0]], %[[ARG_1]] : tensor<f32>\n+CHECK:   stablehlo.return %[[SUM]] : tensor<f32>\n CHECK: }\n )\"));\n }"
        },
        {
            "sha": "94d389bd79bc5afc877761884f1b60e8766b7279",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -37,6 +37,7 @@ cc_library(\n         \"round_f32_to_tf32_for_tf32_dot_pass.cc\",\n         \"stablehlo_lower_to_triton.cc\",\n         \"tensor_lower_to_triton.cc\",\n+        \"triton_xla_convert_tensor_to_scalar_pass.cc\",\n         \"triton_xla_convert_unsupported_types.cc\",\n         \"triton_xla_extract_insert_to_triton_pass.cc\",\n         \"triton_xla_fold_transpose_pass.cc\","
        },
        {
            "sha": "3a2f6a3ebc180d958eac857fd82a1d9d697b7bc2",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -52,6 +52,7 @@ std::unique_ptr<mlir::Pass> CreateStableHLOLowerToTritonPass();\n std::unique_ptr<mlir::Pass> CreateTensorLowerToTritonPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLAMathToLibdevicePass(\n     absl::string_view libdevice_path, absl::string_view triple);\n+std::unique_ptr<mlir::Pass> CreateTritonXLAConvert0DTensorToScalarPass();\n \n // Returns true if the `op` contains an operation in it's regions that satisfies\n // the `fn`."
        },
        {
            "sha": "c7a2855cecfc4ee7ba03f1e48467d75124b34db3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -243,4 +243,12 @@ def TritonXLAMathToLibdevicePass\n   ];\n }\n \n+def TritonXLAConvert0DTensorToScalarPass\n+    : Pass<\"triton-xla-convert-0d-tensor-to-scalar\", \"mlir::ModuleOp\"> {\n+  let summary = \"Lowers 0D tensors to scalars.\";\n+  let dependentDialects = [\n+    \"::xla::xtile::XTileDialect\",\n+  ];\n+}\n+\n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_PASSES_TD_"
        },
        {
            "sha": "b873d063ed992225151940c17442a9f49c4a34db",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_convert_tensor_to_scalar_pass.mlir",
            "status": "added",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_tensor_to_scalar_pass.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_tensor_to_scalar_pass.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_tensor_to_scalar_pass.mlir?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -0,0 +1,29 @@\n+// RUN: xla-opt %s -split-input-file -triton-xla-convert-0d-tensor-to-scalar \\\n+// RUN: | FileCheck %s\n+\n+func.func @addf(%arg0: tensor<f32>) -> tensor<f32> {\n+  // CHECK: arith.addf {{.*}} : f32\n+  %0 = arith.addf %arg0, %arg0 : tensor<f32>\n+  return %0 : tensor<f32>\n+}\n+\n+// -----\n+\n+func.func @addf() -> tensor<f32> {\n+  // CHECK: arith.constant 1.000000e+00 : f32\n+  %0 = arith.constant dense<1.0> : tensor<f32>\n+  return %0 : tensor<f32>\n+}\n+\n+// -----\n+\n+func.func @addf(%arg0: tensor<f32>) -> tensor<f32> {\n+  // CHECK: tt.extern_elementwise {{.*}}{libname = \"dev\", libpath = \"/path\",\n+  // CHECK-SAME: pure = true, symbol = \"sym\"} : (f32) -> f32\n+  %0 = tt.extern_elementwise %arg0\n+    {libname = \"dev\",\n+     libpath = \"/path\",\n+     pure = true,\n+     symbol = \"sym\"} : (tensor<f32>) -> tensor<f32> \n+  return %0 : tensor<f32>\n+}"
        },
        {
            "sha": "988ee1e284daee8060ca1292d32b8723553bbb77",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_convert_tensor_to_scalar_pass.cc",
            "status": "added",
            "additions": 153,
            "deletions": 0,
            "changes": 153,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/54adf0ea18604308caeec098f7a11b9347137f8b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc?ref=54adf0ea18604308caeec098f7a11b9347137f8b",
            "patch": "@@ -0,0 +1,153 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <memory>\n+#include <optional>\n+#include <utility>\n+\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributeInterfaces.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Location.h\"\n+#include \"mlir/IR/OpDefinition.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Types.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n+\n+namespace mlir::triton::xla {\n+\n+#define GEN_PASS_DEF_TRITONXLACONVERT0DTENSORTOSCALARPASS\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+struct ElementwiseConverter\n+    : public mlir::OpTraitConversionPattern<mlir::OpTrait::Elementwise> {\n+ public:\n+  using OpTraitConversionPattern::OpTraitConversionPattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::Operation* op, mlir::ArrayRef<mlir::Value> operands,\n+      mlir::ConversionPatternRewriter& rewriter) const override {\n+    llvm::SmallVector<mlir::Type> new_result_types;\n+    if (mlir::failed(getTypeConverter()->convertTypes(op->getResultTypes(),\n+                                                      new_result_types))) {\n+      return rewriter.notifyMatchFailure(op, \"failed to convert type\");\n+    }\n+\n+    mlir::Operation* new_op = Operation::create(\n+        op->getLoc(), op->getName(), new_result_types, operands, op->getAttrs(),\n+        op->getPropertiesStorage(), op->getSuccessors(), op->getNumRegions());\n+    rewriter.replaceOp(op, rewriter.insert(new_op));\n+    return mlir::success();\n+  }\n+};\n+\n+struct ConstantConversionPattern\n+    : public mlir::OpConversionPattern<mlir::arith::ConstantOp> {\n+  using OpConversionPattern<mlir::arith::ConstantOp>::OpConversionPattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::arith::ConstantOp op, OpAdaptor adaptor,\n+      mlir::ConversionPatternRewriter& rewriter) const override {\n+    auto dense_attr =\n+        mlir::dyn_cast<mlir::DenseElementsAttr>(op.getValueAttr());\n+    if (!dense_attr) {\n+      return rewriter.notifyMatchFailure(op, \"expected a DenseElementsAttr\");\n+    }\n+\n+    if (dense_attr.size() != 1) {\n+      return rewriter.notifyMatchFailure(op, \"expected a single element\");\n+    }\n+\n+    auto scalar_attr = dense_attr.getValues<mlir::TypedAttr>()[0];\n+    rewriter.replaceOpWithNewOp<mlir::arith::ConstantOp>(op, scalar_attr);\n+\n+    return mlir::success();\n+  }\n+};\n+\n+struct TritonXLAConvert0DTensorToScalarPass\n+    : public impl::TritonXLAConvert0DTensorToScalarPassBase<\n+          TritonXLAConvert0DTensorToScalarPass> {\n+  void runOnOperation() override {\n+    mlir::TypeConverter type_converter;\n+    type_converter.addConversion([](mlir::Type type) { return type; });\n+\n+    type_converter.addConversion([](mlir::RankedTensorType type) -> mlir::Type {\n+      if (type.getRank() == 0) {\n+        return type.getElementType();\n+      }\n+      return type;\n+    });\n+\n+    type_converter.addSourceMaterialization(\n+        [](mlir::OpBuilder& builder, mlir::Type result_type,\n+           mlir::ValueRange inputs, mlir::Location loc) -> mlir::Value {\n+          if (inputs.size() != 1) {\n+            return nullptr;\n+          }\n+          return ::xla::xtile::ToTensorOp::create(builder, loc, inputs.front());\n+        });\n+\n+    type_converter.addTargetMaterialization(\n+        [](mlir::OpBuilder& builder, mlir::Type result_type,\n+           mlir::ValueRange inputs, mlir::Location loc) -> mlir::Value {\n+          if (inputs.size() != 1) {\n+            return nullptr;\n+          }\n+          return ::xla::xtile::ToScalarOp::create(builder, loc, inputs.front());\n+        });\n+\n+    mlir::ConversionTarget target(getContext());\n+\n+    target.markUnknownOpDynamicallyLegal(\n+        [&](mlir::Operation* op) -> std::optional<bool> {\n+          if (op->hasTrait<mlir::OpTrait::Elementwise>()) {\n+            return type_converter.isLegal(op);\n+          }\n+          return std::nullopt;\n+        });\n+\n+    target.addDynamicallyLegalOp<mlir::arith::ConstantOp>(\n+        [&](mlir::arith::ConstantOp op) {\n+          return type_converter.isLegal(op.getOperation());\n+        });\n+\n+    mlir::RewritePatternSet patterns(&getContext());\n+\n+    patterns.add<ElementwiseConverter, ConstantConversionPattern>(\n+        type_converter, &getContext());\n+\n+    if (mlir::failed(mlir::applyPartialConversion(getOperation(), target,\n+                                                  std::move(patterns)))) {\n+      signalPassFailure();\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateTritonXLAConvert0DTensorToScalarPass() {\n+  return std::make_unique<TritonXLAConvert0DTensorToScalarPass>();\n+}\n+\n+}  // namespace mlir::triton::xla"
        }
    ],
    "stats": {
        "total": 328,
        "additions": 258,
        "deletions": 70
    }
}