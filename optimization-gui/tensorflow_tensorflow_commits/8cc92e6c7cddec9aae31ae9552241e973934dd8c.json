{
    "author": "junwhanahn",
    "message": "Improve `IfrtMergeReshardsPass` to allow for more efficient merging\n\nThe current implementation can only handle copy operations whose source operations are the same, but there can be many parallel copies that have the same source and destination devices but with arguments produced by different ops. See the added test for an example.\n\nThis CL improves the algorithm (and as a result simplifies the implementation as well) to allow for merging such parallel copies. The intuition is that the existing grouping based on the first reshard user op is actually sufficient to prevent any circular dependency after merging because reshard X that (transitively) depends on reshard Y can never have the same first reshard user op by definition. Thus, we can simply iterate over all reshard ops in the function and merge them based on the same keys that we are using today.\n\nThe algorithm now runs iteratively until fixpoint because merging some reshard ops changes the \"first reshard user op\", which may create more merging opportunities. The added test fails without this loop.\n\nThis is particularly useful when arguments are progressively broadcast over multiple pipeline stage submeshes because argument broadcast and across-stage transfers for intermediates will be completely batchable as long as their broadcast order is the same.\n\nPiperOrigin-RevId: 840342080",
    "sha": "8cc92e6c7cddec9aae31ae9552241e973934dd8c",
    "files": [
        {
            "sha": "49499f85d8ae736bdc2f78ecb12128eec59bd02d",
            "filename": "third_party/xla/xla/python/ifrt/ir/tests/ifrt_merge_reshards.mlir",
            "status": "modified",
            "additions": 34,
            "deletions": 4,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8cc92e6c7cddec9aae31ae9552241e973934dd8c/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftests%2Fifrt_merge_reshards.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8cc92e6c7cddec9aae31ae9552241e973934dd8c/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftests%2Fifrt_merge_reshards.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftests%2Fifrt_merge_reshards.mlir?ref=8cc92e6c7cddec9aae31ae9552241e973934dd8c",
            "patch": "@@ -3,6 +3,8 @@\n #sharding = #ifrt.sharding_param<2 to [0] on 2>\n !array0 = !ifrt.array<tensor<2xi32>, #sharding, [0,1]>\n !array1 = !ifrt.array<tensor<2xi32>, #sharding, [2,3]>\n+!array2 = !ifrt.array<tensor<2xi32>, #sharding, [4,5]>\n+!array3 = !ifrt.array<tensor<2xi32>, #sharding, [6,7]>\n \n // CHECK-LABEL: @merge_reshards_of_call_results\n func.func @merge_reshards_of_call_results(%arg0: !array0, %arg1: !array0)\n@@ -29,16 +31,19 @@ func.func @merge_reshards_of_func_args(%arg0: !array0, %arg1: !array0)\n \n // CHECK-LABEL: @merge_reshards_for_same_devices_only\n func.func @merge_reshards_for_same_devices_only(\n-    %arg0: !array0, %arg1: !array0, %arg2: !array0, %arg3: !array0)\n-  -> (!array1, !array1, !array0, !array0) attributes {ifrt.function} {\n+    %arg0: !array0, %arg1: !array0, %arg2: !array0, %arg3: !array0, %arg4: !array1, %arg5: !array1)\n+  -> (!array1, !array1, !array0, !array0, !array1, !array1) attributes {ifrt.function} {\n // CHECK-NEXT: %[[MERGED1:.*]]:2, %{{.*}} = ifrt.Reshard(%arg0, %arg1)\n // CHECK-NEXT: %[[MERGED2:.*]]:2, %{{.*}} = ifrt.Reshard(%arg2, %arg3)\n-// CHECK-NEXT: return %[[MERGED1]]#0, %[[MERGED1]]#1, %[[MERGED2]]#0, %[[MERGED2]]#1\n+// CHECK-NEXT: %[[MERGED3:.*]]:2, %{{.*}} = ifrt.Reshard(%arg4, %arg5)\n+// CHECK-NEXT: return %[[MERGED1]]#0, %[[MERGED1]]#1, %[[MERGED2]]#0, %[[MERGED2]]#1, %[[MERGED3]]#0, %[[MERGED3]]#1\n   %1, %ctrl_1 = ifrt.Reshard(%arg0) : (!array0) -> !array1\n   %2, %ctrl_2 = ifrt.Reshard(%arg1) : (!array0) -> !array1\n   %3, %ctrl_3 = ifrt.Reshard(%arg2) : (!array0) -> !array0\n   %4, %ctrl_4 = ifrt.Reshard(%arg3) : (!array0) -> !array0\n-  return %1, %2, %3, %4 : !array1, !array1, !array0, !array0\n+  %5, %ctrl_5 = ifrt.Reshard(%arg4) : (!array1) -> !array1\n+  %6, %ctrl_6 = ifrt.Reshard(%arg5) : (!array1) -> !array1\n+  return %1, %2, %3, %4, %5, %6 : !array1, !array1, !array0, !array0, !array1, !array1\n }\n \n // CHECK-LABEL: @merge_reshards_for_same_donated_only\n@@ -71,6 +76,31 @@ func.func @dont_merge_if_any_control_dependencies(\n   return %1, %2 : !array1, !array1\n }\n \n+// CHECK-LABEL: @merge_reshards_interleaved_with_calls\n+func.func @merge_reshards_interleaved_with_calls(\n+    %arg0: !array0, %arg1: !array0)\n+  -> (!array0, !array1, !array2, !array3) attributes {ifrt.function} {\n+  // CHECK-NEXT: %[[CALL0:.*]]:2, %{{.*}} = ifrt.Call\n+  // CHECK-NEXT: %[[R0:.*]]:2, %{{.*}} = ifrt.Reshard(%arg0, %[[CALL0]]#0)\n+  // CHECK-NEXT: %[[CALL1:.*]]:2, %{{.*}} = ifrt.Call @identity(%[[R0]]#1, %[[R0]]#0)\n+  // CHECK-NEXT: %[[R1:.*]]:2, %{{.*}} = ifrt.Reshard(%[[R0]]#0, %[[CALL1]]#0)\n+  // CHECK-NEXT: %[[CALL2:.*]]:2, %{{.*}} = ifrt.Call @identity(%[[R1]]#1, %[[R1]]#0)\n+  // CHECK-NEXT: %[[R2:.*]]:2, %{{.*}} = ifrt.Reshard(%[[R1]]#0, %[[CALL2]]#0)\n+  // CHECK-NEXT: %[[CALL3:.*]]:2, %{{.*}} = ifrt.Call @identity(%[[R2]]#1, %[[R2]]#0)\n+  // CHECK-NEXT: return %[[CALL0]]#1, %[[CALL1]]#1, %[[CALL2]]#1, %[[CALL3]]#1\n+  %0, %ctrl_0 = ifrt.Reshard(%arg0) : (!array0) -> !array1\n+  %1, %ctrl_1 = ifrt.Reshard(%0) : (!array1) -> !array2\n+  %2, %ctrl_2 = ifrt.Reshard(%1) : (!array2) -> !array3\n+  %3:2, %ctrl_3 = ifrt.Call @identity(%arg0, %arg0) on devices [0,1] : (!array0, !array0) -> (!array0, !array0)\n+  %4, %ctrl_4 = ifrt.Reshard(%3#0) : (!array0) -> !array1\n+  %5:2, %ctrl_5 = ifrt.Call @identity(%4, %0) on devices [2,3] : (!array1, !array1) -> (!array1, !array1)\n+  %6, %ctrl_6 = ifrt.Reshard(%5#0) : (!array1) -> !array2\n+  %7:2, %ctrl_7 = ifrt.Call @identity(%6, %1) on devices [4,5] : (!array2, !array2) -> (!array2, !array2)\n+  %8, %ctrl_8 = ifrt.Reshard(%7#0) : (!array2) -> !array3\n+  %9:2, %ctrl_9 = ifrt.Call @identity(%8, %2) on devices [6,7] : (!array3, !array3) -> (!array3, !array3)\n+  func.return %3#1, %5#1, %7#1, %9#1 : !array0, !array1, !array2, !array3\n+}\n+\n func.func private @identity(%arg0: tensor<2xi32>, %arg1: tensor<2xi32>)\n   -> (tensor<2xi32>, tensor<2xi32>) {\n   return %arg0, %arg1 : tensor<2xi32>, tensor<2xi32>"
        },
        {
            "sha": "803cc7a5ddee8f1e28a959c4db595b20cc595211",
            "filename": "third_party/xla/xla/python/ifrt/ir/transforms/ifrt_merge_reshards_pass.cc",
            "status": "modified",
            "additions": 68,
            "deletions": 102,
            "changes": 170,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8cc92e6c7cddec9aae31ae9552241e973934dd8c/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftransforms%2Fifrt_merge_reshards_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8cc92e6c7cddec9aae31ae9552241e973934dd8c/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftransforms%2Fifrt_merge_reshards_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Ftransforms%2Fifrt_merge_reshards_pass.cc?ref=8cc92e6c7cddec9aae31ae9552241e973934dd8c",
            "patch": "@@ -48,68 +48,71 @@ class IfrtMergeReshardsPass\n   void runOnOperation() override;\n };\n \n-// Merges reshards on `source_values` which flow into the same\n-// destination. We merge only if the reshard:\n+// Merges reshards in `func_op`. We merge only if the reshard:\n+//\n // - has only one input and output. I.e. it isn't already merged.\n // - has no input control dependencies.\n+// - has the same source and destination devices.\n // - has the same `donation` setting.\n-//\n-// `source_values` are expected to be of type IfrtArrayType on the same devices,\n-// and be OpResults from the same ops, or BlockArgs in the same block.\n-//\n-// We defer erasing the op until the end of the pass, to avoid invalidating the\n-// iterator.\n-void MergeReshardsIgnoringControlDependencies(\n-    mlir::ValueRange source_values, std::vector<mlir::Operation*>& ops_to_erase,\n-    mlir::RewriterBase& rewriter) {\n+bool MergeReshardsIgnoringControlDependencies(mlir::func::FuncOp func_op) {\n+  mlir::IRRewriter rewriter(func_op->getContext());\n+\n   // We group reshards by {first_user, devices, donated, src_memory_kind,\n   // dst_memory_kind}. We need to group by:\n-  // - first_user because we need to pick some destination.\n-  // - devices as well, because certain users can have multiple devices, e.g.\n-  // func.return.\n+  //\n+  // - first_user because we need to pick some destination. Also, reshard ops\n+  //   with the same first user are always safe to merge without violating\n+  //   dominance order because if one of reshard X's arguments is transitively\n+  //   produced by reshard Y, reshard Y's first user will be either reshard X or\n+  //   any operation before reshard X.\n+  //\n+  // - src and dst devices because some reshards will be lowered to copies and\n+  //   IFRT CopyArrays requires src and dst devices to match.\n+  //\n   // - donated because the donation is all-or-nothing.\n+  //\n   // - src and dst memory kind because we can't merge reshards that change\n-  // memory kind.\n-  llvm::DenseMap<std::tuple<mlir::Operation*, IfrtDevicesAttr, mlir::Attribute,\n-                            mlir::StringAttr, mlir::StringAttr>,\n-                 llvm::SmallVector<ReshardOp>>\n-      user_device_donate_tuple_to_reshards;\n-\n-  // Group reshards by their first user.\n-  for (mlir::Value value : source_values) {\n-    CHECK(mlir::isa<IfrtArrayType>(value.getType()));\n-\n-    for (mlir::Operation* user : value.getUsers()) {\n-      auto reshard_op = mlir::dyn_cast<ReshardOp>(user);\n-      if (!reshard_op || reshard_op.getOutputs().size() != 1 ||\n-          reshard_op->use_empty() || !reshard_op.getControlInputs().empty()) {\n-        continue;\n-      }\n-\n-      // This could potentially be very expensive as `isBeforeInBlock` is\n-      // average O(1) but worst case O(n).\n-      mlir::Operation* first_reshard_user = *llvm::min_element(\n-          reshard_op->getUsers(), [](mlir::Operation* a, mlir::Operation* b) {\n-            return a->isBeforeInBlock(b);\n-          });\n-\n-      auto output_type =\n-          mlir::cast<IfrtArrayType>(reshard_op.getOutputs().front().getType());\n-      user_device_donate_tuple_to_reshards\n-          [{first_reshard_user, output_type.getDevicesAttr(),\n-            // We can't hash by the bool itself, and `donated` is a optional\n-            // attr, so false can be represented by nullptr or BoolAttr(false).\n-            // So we explicitly convert to BoolAttr.\n-            rewriter.getBoolAttr(reshard_op.getDonated()),\n-            mlir::cast<IfrtArrayType>(reshard_op.getInputs().front().getType())\n-                .getMemoryKindAttr(),\n-            output_type.getMemoryKindAttr()}]\n-              .push_back(reshard_op);\n+  //   memory kind.\n+  using Key = std::tuple<mlir::Operation*, IfrtDevicesAttr, IfrtDevicesAttr,\n+                         mlir::Attribute, mlir::StringAttr, mlir::StringAttr>;\n+  llvm::DenseMap<Key, llvm::SmallVector<ReshardOp>> reshard_groups;\n+\n+  func_op.walk([&](ReshardOp reshard_op) {\n+    if (reshard_op.getOutputs().size() != 1 || reshard_op->use_empty() ||\n+        !reshard_op.getControlInputs().empty()) {\n+      return;\n     }\n-  }\n+\n+    // This could potentially be very expensive as `isBeforeInBlock` is\n+    // average O(1) but worst case O(n).\n+    mlir::Operation* first_reshard_user = *llvm::min_element(\n+        reshard_op->getUsers(), [](mlir::Operation* a, mlir::Operation* b) {\n+          return a->isBeforeInBlock(b);\n+        });\n+\n+    auto input_type =\n+        mlir::cast<IfrtArrayType>(reshard_op.getInputs().front().getType());\n+    auto output_type =\n+        mlir::cast<IfrtArrayType>(reshard_op.getOutputs().front().getType());\n+\n+    const Key key = std::make_tuple(\n+        first_reshard_user, input_type.getDevicesAttr(),\n+        output_type.getDevicesAttr(),\n+        // We can't hash by the bool itself, and `donated` is a optional\n+        // attr, so false can be represented by nullptr or BoolAttr(false).\n+        // So we explicitly convert to BoolAttr.\n+        rewriter.getBoolAttr(reshard_op.getDonated()),\n+        input_type.getMemoryKindAttr(), output_type.getMemoryKindAttr());\n+    reshard_groups[key].push_back(reshard_op);\n+  });\n \n   // Rewrite each group of reshards.\n-  for (auto& [_, reshards] : user_device_donate_tuple_to_reshards) {\n+  bool rewritten = false;\n+  for (auto& [_, reshards] : reshard_groups) {\n+    if (reshards.size() <= 1) {\n+      continue;\n+    }\n+\n     // Create a new reshard op that takes all the inputs of the reshards.\n     llvm::SmallVector<mlir::Value> inputs;\n     llvm::SmallVector<mlir::Type> output_types;\n@@ -126,9 +129,10 @@ void MergeReshardsIgnoringControlDependencies(\n       locs.push_back(reshard.getLoc());\n     }\n \n-    // Insert the new reshard op just before one of the reshards, to\n-    // minimize reordering reshards.\n-    rewriter.setInsertionPoint(reshards.front());\n+    // Insert the new reshard op just before the last reshard in the block order\n+    // in order to minimize reordering reshards while not violating dominance\n+    // order after the merge.\n+    rewriter.setInsertionPoint(reshards.back());\n     auto merged_reshard =\n         rewriter.create<ReshardOp>(rewriter.getFusedLoc(locs),\n                                    /*outputs=*/output_types,\n@@ -144,69 +148,31 @@ void MergeReshardsIgnoringControlDependencies(\n                                   merged_reshard.getOutputs()[index]);\n       rewriter.replaceAllUsesWith(reshard.getControlOutput(),\n                                   merged_reshard.getControlOutput());\n-      ops_to_erase.push_back(reshard);\n+      rewriter.eraseOp(reshard);\n     }\n-  }\n-}\n \n-template <typename T>\n-bool MergeReshardsIgnoringControlDependencies(\n-    mlir::Operation* op, std::vector<mlir::Operation*>& ops_to_erase,\n-    mlir::RewriterBase& rewriter) {\n-  if (auto casted = mlir::dyn_cast<T>(op)) {\n-    MergeReshardsIgnoringControlDependencies(casted.getOutputs(), ops_to_erase,\n-                                             rewriter);\n-    return true;\n+    rewritten = true;\n   }\n-  return false;\n-}\n \n-template <typename First, typename Second, typename... Rest>\n-bool MergeReshardsIgnoringControlDependencies(\n-    mlir::Operation* op, std::vector<mlir::Operation*>& ops_to_erase,\n-    mlir::RewriterBase& rewriter) {\n-  return MergeReshardsIgnoringControlDependencies<First>(op, ops_to_erase,\n-                                                         rewriter) ||\n-         MergeReshardsIgnoringControlDependencies<Second, Rest...>(\n-             op, ops_to_erase, rewriter);\n+  return rewritten;\n }\n \n void IfrtMergeReshardsPass::runOnOperation() {\n   mlir::func::FuncOp func_op = getOperation();\n-  mlir::IRRewriter rewriter(func_op->getContext());\n-  std::vector<mlir::Operation*> ops_to_erase;\n-\n   // We only need to run this pass on IFRT functions.\n   if (!func_op->hasAttr(kIfrtFunctionAttrName) &&\n       !func_op->hasAttr(kIfrtReshardFunctionAttrName)) {\n     return;\n   }\n \n-  // Handle func block args.\n-  {\n-    llvm::DenseMap<IfrtDevicesAttr, llvm::SmallVector<mlir::Value>>\n-        devices_to_args;\n-    for (mlir::Value arg : func_op.getArguments()) {\n-      if (auto array_type = mlir::dyn_cast<IfrtArrayType>(arg.getType())) {\n-        devices_to_args[array_type.getDevicesAttr()].push_back(arg);\n-      }\n-    }\n-\n-    for (auto& [_, args] : devices_to_args) {\n-      MergeReshardsIgnoringControlDependencies(args, ops_to_erase, rewriter);\n+  // Run transformation until fixpoint since merging reshard ops may create more\n+  // opportunities for further merges. This loop runs at most O(num_reshard_ops)\n+  // times even in the worst case.\n+  while (true) {\n+    if (!MergeReshardsIgnoringControlDependencies(func_op)) {\n+      break;\n     }\n   }\n-\n-  // Handle ops in the IFRT function body.\n-  func_op.getFunctionBody().walk([&](mlir::Operation* op) {\n-    MergeReshardsIgnoringControlDependencies<\n-        CallOp, CallLoadedExecutableOp, ReshardOp, CopyArraysOp, RemapArraysOp>(\n-        op, ops_to_erase, rewriter);\n-  });\n-\n-  for (mlir::Operation* op : ops_to_erase) {\n-    rewriter.eraseOp(op);\n-  }\n }\n \n }  // namespace"
        }
    ],
    "stats": {
        "total": 208,
        "additions": 102,
        "deletions": 106
    }
}