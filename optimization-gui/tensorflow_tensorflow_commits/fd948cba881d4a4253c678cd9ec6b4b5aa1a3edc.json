{
    "author": "ezhulenev",
    "message": "[xla:cpu] Migrate tf2xla to BufferAllocationInfo\n\nReverts f2ed04aff6c4112a98ac50695a2a8f7bdfb8a71e\n\nPiperOrigin-RevId: 821660240",
    "sha": "fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
    "files": [
        {
            "sha": "ddcf94fbc07951b8aaf69a668c9b5a85b82f2c7c",
            "filename": "tensorflow/compiler/aot/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2FBUILD?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -119,20 +119,20 @@ cc_library(\n         \"@com_google_absl//absl/types:span\",\n         \"@llvm-project//llvm:Support\",\n         \"@llvm-project//llvm:Target\",\n-        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:debug_options_flags\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:status_macros\",\n         \"@local_xla//xla:util\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info_util\",\n         \"@local_xla//xla/backends/cpu/codegen:symbol_name_util\",\n         \"@local_xla//xla/backends/cpu/runtime:thunk_proto_cc\",\n         \"@local_xla//xla/backends/cpu/runtime:thunk_proto_serdes\",\n         \"@local_xla//xla/client:client_library\",\n         \"@local_xla//xla/client:compile_only_client\",\n         \"@local_xla//xla/hlo/builder:xla_computation\",\n         \"@local_xla//xla/service:compiler\",\n-        \"@local_xla//xla/service/cpu:buffer_info_util\",\n         \"@local_xla//xla/service/cpu:cpu_aot_compilation_result\",\n         \"@local_xla//xla/service/cpu:cpu_compiler\",\n         \"@local_xla//xla/service/cpu:cpu_executable\",\n@@ -155,7 +155,6 @@ tf_cc_test(\n         \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/strings\",\n         \"@llvm-project//llvm:Support\",  # fixdeps: keep\n-        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla/service/cpu:cpu_aot_compilation_result\",\n     ] + if_llvm_x86_available(["
        },
        {
            "sha": "f4969b93353e428535e100893f090046c5f6e407",
            "filename": "tensorflow/compiler/aot/codegen.cc",
            "status": "modified",
            "additions": 65,
            "deletions": 63,
            "changes": 128,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -44,11 +44,11 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/allocator.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla_util.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info_util.h\"\n #include \"xla/backends/cpu/runtime/thunk.pb.h\"\n #include \"xla/backends/cpu/runtime/thunk_proto_serdes.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/debug_options_flags.h\"\n-#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/shape.h\"\n@@ -65,7 +65,7 @@ namespace tfcompile {\n \n namespace {\n \n-using BufferInfo = xla::cpu_function_runtime::BufferInfo;\n+using xla::cpu::BufferAllocationInfo;\n \n bool IsAlpha(char c) {\n   return (c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z');\n@@ -117,33 +117,36 @@ absl::Status XLATypeToCpp(xla::PrimitiveType type, string* str) {\n }\n \n // Returns the sum of the size of each buffer in `buffer_infos`.\n-size_t TotalBufferBytes(const std::vector<BufferInfo>& buffer_infos) {\n-  return std::accumulate(buffer_infos.begin(), buffer_infos.end(), size_t{0},\n-                         [](size_t size, const BufferInfo& buffer_info) {\n-                           return size + buffer_info.size();\n-                         });\n+size_t TotalBufferBytes(absl::Span<const BufferAllocationInfo> buffer_infos) {\n+  return std::accumulate(\n+      buffer_infos.begin(), buffer_infos.end(), size_t{0},\n+      [](size_t size, const BufferAllocationInfo& buffer_info) {\n+        return size + buffer_info.size();\n+      });\n }\n \n-// Returns a vector of BufferInfo instances in `buffer_infos` that are entry\n-// parameter buffers.\n-std::vector<BufferInfo> ExtractEntryParamBufferInfos(\n-    const std::vector<BufferInfo>& buffer_infos) {\n-  std::vector<BufferInfo> result;\n+// Returns a vector of BufferAllocationInfo instances in `buffer_infos` that are\n+// entry parameter buffers.\n+std::vector<BufferAllocationInfo> ExtractEntryParamBufferAllocationInfos(\n+    absl::Span<const BufferAllocationInfo> buffer_infos) {\n+  std::vector<BufferAllocationInfo> result;\n   std::copy_if(buffer_infos.begin(), buffer_infos.end(),\n-               std::back_inserter(result), [](const BufferInfo& buffer_info) {\n+               std::back_inserter(result),\n+               [](const BufferAllocationInfo& buffer_info) {\n                  return buffer_info.is_entry_parameter();\n                });\n   return result;\n }\n \n-// Returns a vector of BufferInfo instances in `buffer_infos` that are temp\n-// buffers.\n-std::vector<BufferInfo> ExtractTempBufferInfos(\n-    const std::vector<BufferInfo>& buffer_infos) {\n-  std::vector<BufferInfo> result;\n+// Returns a vector of BufferAllocationInfo instances in `buffer_infos` that are\n+// temp buffers.\n+std::vector<BufferAllocationInfo> ExtractTempBufferAllocationInfos(\n+    absl::Span<const BufferAllocationInfo> buffer_infos) {\n+  std::vector<BufferAllocationInfo> result;\n   std::copy_if(buffer_infos.begin(), buffer_infos.end(),\n-               std::back_inserter(result), [](const BufferInfo& buffer_info) {\n-                 return buffer_info.is_temp_buffer();\n+               std::back_inserter(result),\n+               [](const BufferAllocationInfo& buffer_info) {\n+                 return buffer_info.is_temp();\n                });\n   return result;\n }\n@@ -471,25 +474,24 @@ absl::Status ValidateFeedFetchCppNames(const tf2xla::Config& config) {\n }\n \n // Returns a list of C++ expressions that, when executed, will construct the\n-// BufferInfo instances in `buffer_infos`.\n-std::vector<string> BufferInfosToCppExpression(\n-    const std::vector<BufferInfo>& buffer_infos) {\n-  std::vector<string> buffer_infos_as_strings;\n-  std::transform(buffer_infos.begin(), buffer_infos.end(),\n-                 std::back_inserter(buffer_infos_as_strings),\n-                 [](const BufferInfo& buffer_info) {\n-                   xla::cpu_function_runtime::EncodedBufferInfo encoded =\n-                       buffer_info.Encode();\n-                   auto param_to_str = [](uint32_t param) -> std::string {\n-                     return param == ~0U ? \"~0U\" : absl::StrCat(param, \"U\");\n-                   };\n-                   return absl::StrCat(\n-                       \"::xla::cpu_function_runtime::BufferInfo(\"\n-                       \"::xla::cpu_function_runtime::EncodedBufferInfo{\",\n-                       encoded.packed_kind_and_size, \"ULL, \",\n-                       param_to_str(encoded.entry_param_number), \", \",\n-                       param_to_str(encoded.result_param_number), \"})\");\n-                 });\n+// BufferAllocationInfo instances in `buffer_infos`.\n+std::vector<std::string> BufferAllocationInfosToCppExpression(\n+    absl::Span<const BufferAllocationInfo> buffer_infos) {\n+  std::vector<std::string> buffer_infos_as_strings;\n+  absl::c_transform(\n+      buffer_infos, std::back_inserter(buffer_infos_as_strings),\n+      [](const BufferAllocationInfo& buffer_info) {\n+        xla::cpu::EncodedBufferAllocationInfo encoded(buffer_info);\n+        auto param_to_str = [](int32_t param) -> std::string {\n+          return param == -1 ? \"~0U\" : absl::StrCat(param, \"U\");\n+        };\n+        return absl::StrCat(\n+            \"static_cast<::xla::cpu::BufferAllocationInfo>(\"\n+            \"::xla::cpu::EncodedBufferAllocationInfo{\",\n+            encoded.packed_kind_and_size, \"ULL, \",\n+            param_to_str(encoded.entry_param_number), \", \",\n+            param_to_str(encoded.result_number), \"})\");\n+      });\n   return buffer_infos_as_strings;\n }\n \n@@ -659,8 +661,8 @@ absl::Status ExtendRewrites(\n       const std::string function_declarations_from_obj_files,\n       GenFunctionDeclarations(absl::MakeSpan(entry_point_symbols)));\n \n-  const int64_t buffer_infos_size = aot_thunks->buffer_infos().size();\n-  const std::optional<size_t> temp_allocation_index =\n+  int64_t buffer_infos_size = aot_thunks->buffer_allocation_infos().size();\n+  std::optional<size_t> temp_allocation_index =\n       aot_thunks->temp_allocation_index();\n   if (temp_allocation_index.has_value() &&\n       (*temp_allocation_index < 0 ||\n@@ -838,21 +840,21 @@ absl::Status GenerateHeader(\n   TF_RETURN_IF_ERROR(ValidateConfig(config));\n   TF_RETURN_IF_ERROR(ValidateFeedFetchCppNames(config));\n \n-  const std::vector<BufferInfo>& buffer_infos =\n-      compile_result.aot->buffer_infos();\n+  absl::Span<const BufferAllocationInfo> buffer_infos =\n+      compile_result.aot->buffer_allocation_infos();\n \n   const std::vector<int32> arg_index_table =\n-      ::xla::cpu::CreateArgIndexTableFromBufferInfos(buffer_infos);\n+      ::xla::cpu::CreateArgIndexTable(buffer_infos);\n   const std::vector<int32> result_index_table =\n-      ::xla::cpu::CreateResultIndexTableFromBufferInfos(buffer_infos);\n+      ::xla::cpu::CreateResultIndexTable(buffer_infos);\n   std::vector<string> buffer_infos_as_strings =\n-      BufferInfosToCppExpression(buffer_infos);\n+      BufferAllocationInfosToCppExpression(buffer_infos);\n \n   // Compute sizes and generate methods.\n-  std::vector<BufferInfo> buffer_infos_for_args =\n-      ExtractEntryParamBufferInfos(buffer_infos);\n-  std::vector<BufferInfo> buffer_infos_for_temps =\n-      ExtractTempBufferInfos(buffer_infos);\n+  std::vector<BufferAllocationInfo> buffer_infos_for_args =\n+      ExtractEntryParamBufferAllocationInfos(buffer_infos);\n+  std::vector<BufferAllocationInfo> buffer_infos_for_temps =\n+      ExtractTempBufferAllocationInfos(buffer_infos);\n   const xla::ProgramShapeProto& ps = compile_result.program_shape;\n   string methods_arg, methods_result, methods_variable;\n   TF_RETURN_IF_ERROR(GenArgMethods(config, ps, compile_result, &methods_arg));\n@@ -868,13 +870,13 @@ absl::Status GenerateHeader(\n       CheckEqual(ps.result().tuple_shapes_size(), result_index_table.size(),\n                  \"Result number mismatch, proto vs. result_index_table\"));\n   TF_ASSIGN_OR_RETURN(auto program_shape, xla::ProgramShape::FromProto(ps));\n-  const size_t arg_bytes_aligned = tensorflow::AlignedBufferBytes(\n-      buffer_infos_for_args.data(), buffer_infos_for_args.size(),\n-      /*allocate_entry_params=*/true);\n+  const size_t arg_bytes_aligned =\n+      tensorflow::AlignedBufferBytes(buffer_infos_for_args,\n+                                     /*allocate_entry_params=*/true);\n   const size_t arg_bytes_total = TotalBufferBytes(buffer_infos_for_args);\n-  const size_t temp_bytes_aligned = tensorflow::AlignedBufferBytes(\n-      buffer_infos_for_temps.data(), buffer_infos_for_temps.size(),\n-      /*allocate_entry_params=*/true);\n+  const size_t temp_bytes_aligned =\n+      tensorflow::AlignedBufferBytes(buffer_infos_for_temps,\n+                                     /*allocate_entry_params=*/true);\n   const size_t temp_bytes_total = TotalBufferBytes(buffer_infos_for_temps);\n \n   // Create rewrite strings for namespace start and end.\n@@ -980,7 +982,7 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n \n   // Byte size of each argument buffer. There are kNumArgs entries.\n   static const ::int64_t ArgSize(::tensorflow::int32 index) {\n-    return BufferInfos()[ArgIndexToBufferIndex()[index]].size();\n+    return BufferAllocationInfos()[ArgIndexToBufferIndex()[index]].size();\n   }\n \n   // Returns static data used to create an XlaCompiledCpuFunction.\n@@ -989,7 +991,7 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n       XlaCompiledCpuFunction::StaticData* data =\n         new XlaCompiledCpuFunction::StaticData;\n       set_static_data_function_library_symbol_map(data, FunctionLibrarySymbolMap());\n-      set_static_data_buffer_infos(data, BufferInfos());\n+      set_static_data_buffer_infos(data, BufferAllocationInfos());\n       set_static_data_num_buffers(data, kNumBuffers);\n       set_static_data_result_index_table(data, ResultIndexToBufferIndex());\n       set_static_data_num_results(data, kNumResults);\n@@ -1081,12 +1083,12 @@ class {{CLASS}} final : public tensorflow::{{COMPUTATION_CLASS_BASE}} {\n   // Number of buffers for the compiled computation.\n   static constexpr size_t kNumBuffers = {{NUM_BUFFERS}};\n \n-  static const ::xla::cpu_function_runtime::BufferInfo* BufferInfos() {\n-    static const ::xla::cpu_function_runtime::BufferInfo\n-      kBufferInfos[kNumBuffers] = {\n+  static const ::xla::cpu::BufferAllocationInfo* BufferAllocationInfos() {\n+    static const ::xla::cpu::BufferAllocationInfo\n+      kBufferAllocationInfos[kNumBuffers] = {\n {{BUFFER_INFOS_AS_STRING}}\n       };\n-    return kBufferInfos;\n+    return kBufferAllocationInfos;\n   }\n \n   static const ::tensorflow::int32* ResultIndexToBufferIndex() {"
        },
        {
            "sha": "a4f18482db7f325afc189cd09577533c7b862000",
            "filename": "tensorflow/compiler/aot/codegen_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Faot%2Fcodegen_test.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -24,7 +24,6 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"llvm/Support/TargetSelect.h\"\n #include \"tensorflow/compiler/aot/compile.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/shape_util.h\"\n #include \"tensorflow/core/framework/tensor_shape.pb.h\"\n@@ -40,7 +39,7 @@ namespace tensorflow {\n namespace tfcompile {\n namespace {\n \n-using ::xla::cpu_function_runtime::BufferInfo;\n+using ::xla::cpu::BufferAllocationInfo;\n \n void ExpectErrorContains(const absl::Status& status, absl::string_view str) {\n   EXPECT_NE(absl::OkStatus(), status);"
        },
        {
            "sha": "254a1e85c3519249f033294a31643636dc6fcc17",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -406,8 +406,9 @@ cc_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \"@com_google_absl//absl/base:dynamic_annotations\",\n-        \"@local_xla//xla:cpu_function_runtime\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n     ],\n )\n \n@@ -419,8 +420,8 @@ tf_cc_test(\n         \"//tensorflow/core:framework\",\n         \"//tensorflow/core:test\",\n         \"//tensorflow/core:test_main\",\n-        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n     ],\n )\n \n@@ -431,14 +432,15 @@ cc_library(\n     compatible_with = get_compatible_with_portable(),\n     visibility = [\"//visibility:public\"],\n     deps = [\n+        # Keep dependencies to a minimum here; this library is used in every AOT\n+        # binary produced by tfcompile.\n         \":allocator\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/types:span\",\n         \"@local_xla//xla/service:custom_call_status_internal\",\n-        # Keep dependencies to a minimum here; this library is used in every AOT\n-        # binary produced by tfcompile.\n         \"@local_xla//xla/backends/cpu/runtime:rng_state_lib\",\n         \"@local_xla//xla/backends/cpu:alignment\",\n-        \"@local_xla//xla:cpu_function_runtime\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n         \"@local_xla//xla:executable_run_options\",\n         \"//tensorflow/core/platform:types\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -513,7 +515,6 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:casts\",\n-        \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n         \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n@@ -530,7 +531,6 @@ cc_library(\n     ] + if_libtpu(\n         if_false = [\n             \"@local_xla//xla/service:cpu_plugin\",\n-            \"@local_xla//xla/service/cpu:buffer_info_util\",\n             \"@local_xla//xla/service/cpu:cpu_executable\",\n         ],\n         if_true = [],"
        },
        {
            "sha": "08db8bb0261bc6eac1b0ba20afc0c51069f77c53",
            "filename": "tensorflow/compiler/tf2xla/allocator.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 12,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -20,8 +20,9 @@ limitations under the License.\n #include <cstdlib>\n \n #include \"absl/base/dynamic_annotations.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/cpu/alignment.h\"\n-#include \"xla/cpu_function_runtime.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n \n namespace tensorflow {\n \n@@ -64,26 +65,26 @@ size_t align_to(size_t n, size_t align) {\n }  // namespace\n \n size_t AlignedBufferBytes(\n-    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n+    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n     bool allocate_entry_params) {\n   size_t total = 0;\n-  for (size_t i = 0; i < n; ++i) {\n+  for (size_t i = 0; i < buffers.size(); ++i) {\n     bool should_allocate =\n-        buffer_infos[i].is_temp_buffer() ||\n-        (buffer_infos[i].is_entry_parameter() && allocate_entry_params);\n+        buffers[i].is_temp() || buffers[i].is_result() ||\n+        (buffers[i].is_entry_parameter() && allocate_entry_params);\n \n     if (should_allocate) {\n-      total += align_to(buffer_infos[i].size(), xla::cpu::Align());\n+      total += align_to(buffers[i].size(), xla::cpu::Align());\n     }\n   }\n   return total;\n }\n \n void* MallocContiguousBuffers(\n-    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n+    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n     bool allocate_entry_params, void** bufs, bool annotate_initialized) {\n   const size_t total =\n-      tensorflow::AlignedBufferBytes(buffer_infos, n, allocate_entry_params);\n+      tensorflow::AlignedBufferBytes(buffers, allocate_entry_params);\n   void* contiguous = nullptr;\n   if (total > 0) {\n     contiguous = aligned_malloc(total, xla::cpu::Align());\n@@ -94,13 +95,13 @@ void* MallocContiguousBuffers(\n     }\n   }\n   uintptr_t pos = reinterpret_cast<uintptr_t>(contiguous);\n-  for (size_t i = 0; i < n; ++i) {\n+  for (size_t i = 0; i < buffers.size(); ++i) {\n     bool should_allocate =\n-        buffer_infos[i].is_temp_buffer() ||\n-        (buffer_infos[i].is_entry_parameter() && allocate_entry_params);\n+        buffers[i].is_temp() || buffers[i].is_result() ||\n+        (buffers[i].is_entry_parameter() && allocate_entry_params);\n     if (should_allocate) {\n       bufs[i] = reinterpret_cast<void*>(pos);\n-      pos += align_to(buffer_infos[i].size(), xla::cpu::Align());\n+      pos += align_to(buffers[i].size(), xla::cpu::Align());\n     } else {\n       bufs[i] = nullptr;\n     }"
        },
        {
            "sha": "b9d181ff60ba062c26f241bfe0eec23973af106e",
            "filename": "tensorflow/compiler/tf2xla/allocator.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -18,7 +18,8 @@ limitations under the License.\n \n #include <cstddef>\n \n-#include \"xla/cpu_function_runtime.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n \n namespace tensorflow {\n \n@@ -27,7 +28,7 @@ namespace tensorflow {\n // allocate_entry_params is false, entry parameters.  There are `n` entries in\n // `buffer_infos`.  Each buffer is aligned to Align() byte boundaries.\n size_t AlignedBufferBytes(\n-    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n+    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n     bool allocate_entry_params);\n \n // MallocContiguousBuffers allocates buffers for use by the entry point\n@@ -43,7 +44,7 @@ size_t AlignedBufferBytes(\n // the head of the allocated contiguous block, which should be passed to\n // FreeContiguous when the buffers are no longer in use.\n void* MallocContiguousBuffers(\n-    const xla::cpu_function_runtime::BufferInfo* buffer_infos, size_t n,\n+    absl::Span<const xla::cpu::BufferAllocationInfo> buffers,\n     bool allocate_entry_params, void** bufs, bool annotate_initialized);\n \n // FreeContiguous frees the contiguous block of memory allocated by"
        },
        {
            "sha": "d5b9158c1fcb3f5ea1806f2651ba9a869ae21dd6",
            "filename": "tensorflow/compiler/tf2xla/allocator_test.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 18,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fallocator_test.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -22,14 +22,14 @@ limitations under the License.\n #include <vector>\n \n #include \"xla/backends/cpu/alignment.h\"\n-#include \"xla/cpu_function_runtime.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"tensorflow/core/framework/allocator.h\"\n #include \"tensorflow/core/platform/test.h\"\n \n namespace tensorflow {\n namespace {\n \n-using ::xla::cpu_function_runtime::BufferInfo;\n+using ::xla::cpu::BufferAllocationInfo;\n \n TEST(AllocatorTest, AlignmentValue) {\n   // We've chosen 64 byte alignment for the tfcompile runtime to mimic the\n@@ -41,33 +41,36 @@ TEST(AllocatorTest, AlignmentValue) {\n   EXPECT_LE(xla::cpu::MinAlign(), Allocator::kAllocatorAlignment);\n }\n \n-std::vector<BufferInfo> SizesToBufferInfos(const intptr_t* sizes, size_t n) {\n-  std::vector<BufferInfo> buffer_infos;\n-  std::transform(sizes, sizes + n, std::back_inserter(buffer_infos),\n-                 [&](intptr_t size) {\n-                   if (size == -1) {\n-                     // Use a dummy on-stack buffer allocation to indicate the\n-                     // the current slot does not need an allocation.\n-                     int64_t on_stack_buffer_size = 4;\n-                     return BufferInfo::MakeOnStackBuffer(on_stack_buffer_size);\n-                   }\n-                   return BufferInfo::MakeTempBuffer(size);\n-                 });\n+std::vector<BufferAllocationInfo> SizesToBufferAllocationInfos(\n+    const intptr_t* sizes, size_t n) {\n+  std::vector<BufferAllocationInfo> buffer_infos;\n+  std::transform(\n+      sizes, sizes + n, std::back_inserter(buffer_infos), [&](intptr_t size) {\n+        if (size == -1) {\n+          // Use a dummy on-stack buffer allocation to indicate the\n+          // the current slot does not need an allocation.\n+          int64_t on_stack_buffer_size = 4;\n+          return BufferAllocationInfo::ThreadLocal(on_stack_buffer_size);\n+        }\n+        return BufferAllocationInfo::Temp(size);\n+      });\n   return buffer_infos;\n }\n \n // Simple wrappers to make writing tests more ergonomic.\n \n size_t AlignedBufferBytesFromSizes(const intptr_t* sizes, size_t n) {\n-  std::vector<BufferInfo> buffer_infos = SizesToBufferInfos(sizes, n);\n-  return tensorflow::AlignedBufferBytes(buffer_infos.data(), n,\n+  std::vector<BufferAllocationInfo> buffer_infos =\n+      SizesToBufferAllocationInfos(sizes, n);\n+  return tensorflow::AlignedBufferBytes(buffer_infos,\n                                         /*allocate_entry_params=*/false);\n }\n \n void* MallocContiguousBuffersFromSizes(const intptr_t* sizes, size_t n,\n                                        void** bufs, bool annotate_initialized) {\n-  std::vector<BufferInfo> buffer_infos = SizesToBufferInfos(sizes, n);\n-  return tensorflow::MallocContiguousBuffers(buffer_infos.data(), n,\n+  std::vector<BufferAllocationInfo> buffer_infos =\n+      SizesToBufferAllocationInfos(sizes, n);\n+  return tensorflow::MallocContiguousBuffers(buffer_infos,\n                                              /*allocate_entry_params=*/false,\n                                              bufs, annotate_initialized);\n }"
        },
        {
            "sha": "7ca32b83f158af07c6ca495d710e77886aefb90f",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -25,9 +25,9 @@ limitations under the License.\n \n #include \"absl/log/check.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n #include \"tensorflow/compiler/tf2xla/allocator.h\"\n #include \"xla/backends/cpu/runtime/rng_state_lib.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"tensorflow/core/platform/types.h\"\n \n namespace tensorflow {\n@@ -72,7 +72,7 @@ XlaCompiledCpuFunction::XlaCompiledCpuFunction(const StaticData& static_data,\n       alloc_mode == AllocMode::ARGS_VARIABLES_RESULTS_PROFILES_AND_TEMPS;\n   // Allocate arg and temp buffers.\n   alloc_buffer_table_ = tensorflow::MallocContiguousBuffers(\n-      static_data.buffer_infos_, static_data.num_buffers_,\n+      absl::MakeConstSpan(static_data.buffer_infos_, static_data.num_buffers_),\n       /*allocate_entry_params=*/allocate_entry_params, buffer_table_,\n       /*annotate_initialized=*/true);\n   // If Hlo profiling is enabled the generated code expects an appropriately"
        },
        {
            "sha": "3d5bff87b3570f5f12d4adb5cba53d1f6e8a650d",
            "filename": "tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h",
            "status": "modified",
            "additions": 6,
            "deletions": 8,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_compiled_cpu_function.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -29,8 +29,8 @@ limitations under the License.\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/cpu/alignment.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/backends/cpu/runtime/rng_state_lib.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/executable_run_options.h\"\n #include \"xla/service/custom_call_status_internal.h\"\n #include \"tensorflow/core/platform/types.h\"\n@@ -123,7 +123,7 @@ class XlaCompiledCpuFunction {\n     // End serialized thunk execution specific\n \n     // Contains information about the buffers used by the XLA computation.\n-    const xla::cpu_function_runtime::BufferInfo* buffer_infos_ = nullptr;\n+    const xla::cpu::BufferAllocationInfo* buffer_infos_ = nullptr;\n     int32_t num_buffers_ = 0;\n \n     // Result parameter i is described by\n@@ -251,9 +251,7 @@ class XlaCompiledCpuFunction {\n   // called for each positional argument, in order to set the argument buffers.\n   //\n   // Allocated memory must be aligned to the size specified by\n-  // xla::cpu_function_runtime::MinAlign(). If possible, use the functions in\n-  // tensorflow/compiler/tf2xla/cpu_function_runtime.h to ensure correct\n-  // alignment.\n+  // xla::cpu::MinAlign().\n   //\n   // Aliasing of argument and result buffers is not allowed, and results in\n   // undefined behavior.\n@@ -362,7 +360,7 @@ class XlaCompiledCpuFunction {\n     return temp_allocation_index_;\n   }\n \n-  const xla::cpu_function_runtime::BufferInfo* buffer_infos() const {\n+  const xla::cpu::BufferAllocationInfo* buffer_infos() const {\n     return buffer_infos_;\n   }\n \n@@ -415,7 +413,7 @@ class XlaCompiledCpuFunction {\n \n   static void set_static_data_buffer_infos(\n       StaticData* static_data,\n-      const xla::cpu_function_runtime::BufferInfo* buffer_infos) {\n+      const xla::cpu::BufferAllocationInfo* buffer_infos) {\n     static_data->buffer_infos_ = buffer_infos;\n   }\n \n@@ -531,7 +529,7 @@ class XlaCompiledCpuFunction {\n   void** const buffer_table_;\n \n   // Describes the buffers used by the XLA computation.\n-  const xla::cpu_function_runtime::BufferInfo* const buffer_infos_;\n+  const xla::cpu::BufferAllocationInfo* const buffer_infos_;\n   const int32 num_buffers_;\n \n   // Indices of expanded result tuple."
        },
        {
            "sha": "48e562ce5c78107d7cff12b3e710007dd87afe4d",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 9,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -32,9 +32,7 @@ limitations under the License.\n #include \"xla/client/client_library.h\"\n #include \"xla/client/executable_build_options.h\"\n #include \"xla/client/local_client.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/hlo/builder/xla_computation.h\"\n-#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/platform_util.h\"\n@@ -64,10 +62,10 @@ absl::StatusOr<size_t> ComputeResultIndex(\n \n // Returns the number of results.\n int CountResults(\n-    absl::Span<const xla::cpu_function_runtime::BufferInfo> buffer_infos) {\n+    absl::Span<const xla::cpu::BufferAllocationInfo> buffer_infos) {\n   int num_results = 0;\n   for (const auto& info : buffer_infos) {\n-    if (info.is_result_parameter()) {\n+    if (info.is_result()) {\n       ++num_results;\n     }\n   }\n@@ -152,18 +150,18 @@ XlaJitCompiledCpuFunction::Compile(\n       cpu_executable->buffer_assignment();\n \n   // Compute buffer infos and the result index, needed to run the raw function.\n-  std::vector<xla::cpu_function_runtime::BufferInfo> buffer_infos =\n-      xla::cpu::CreateBufferInfosFromBufferAssignment(cpu_executable->module(),\n-                                                      buffer_assignment);\n+  std::vector<xla::cpu::BufferAllocationInfo> buffer_infos =\n+      xla::cpu::CreateBufferAllocationInfos(cpu_executable->module(),\n+                                            buffer_assignment);\n \n   std::vector<xla::cpu::BufferAllocationInfo> buffer_allocation_infos =\n       xla::cpu::CreateBufferAllocationInfos(cpu_executable->module(),\n                                             buffer_assignment);\n \n   std::vector<int32> arg_index_table =\n-      xla::cpu::CreateArgIndexTableFromBufferInfos(buffer_infos);\n+      xla::cpu::CreateArgIndexTable(buffer_infos);\n   std::vector<int32> result_index_table =\n-      xla::cpu::CreateResultIndexTableFromBufferInfos(buffer_infos);\n+      xla::cpu::CreateResultIndexTable(buffer_infos);\n   TF_ASSIGN_OR_RETURN(size_t result_index,\n                       ComputeResultIndex(buffer_assignment));\n   const int num_results = CountResults(buffer_infos);"
        },
        {
            "sha": "0678c3be6c67f6c901fb939930b14304fc44eca8",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -24,8 +24,8 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/xla_compiled_cpu_function_thunks.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/client/local_client.h\"\n-#include \"xla/cpu_function_runtime.h\"\n #include \"xla/service/cpu/executable.pb.h\"\n #include \"tensorflow/core/framework/graph.pb.h\"\n #include \"tensorflow/core/platform/types.h\"\n@@ -82,7 +82,7 @@ class XlaJitCompiledCpuFunction {\n   XlaCompiledCpuFunction::StaticData static_data_;\n \n   // The backing array for buffer infos.\n-  std::vector<xla::cpu_function_runtime::BufferInfo> buffer_infos_;\n+  std::vector<xla::cpu::BufferAllocationInfo> buffer_infos_;\n \n   // The backing array for the arg index table.\n   std::vector<int32> arg_index_table_;"
        },
        {
            "sha": "67ff1417c86b2abd6359f922ec0dce65151cdea0",
            "filename": "third_party/xla/xla/backends/cpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -41,12 +41,6 @@ cc_library(\n     name = \"buffer_allocation_info\",\n     hdrs = [\"buffer_allocation_info.h\"],\n     visibility = internal_visibility([\":friends\"]),\n-    deps = [\n-        \"//xla:xla_data_proto_cc\",\n-        \"@com_google_absl//absl/log:check\",\n-        \"@com_google_absl//absl/strings:str_format\",\n-        \"@com_google_absl//absl/strings:string_view\",\n-    ],\n )\n \n cc_library("
        },
        {
            "sha": "1a12333ed1c29c172b4c38422168dfcde15adef0",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info.h",
            "status": "modified",
            "additions": 83,
            "deletions": 87,
            "changes": 170,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -16,13 +16,11 @@ limitations under the License.\n #ifndef XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_H_\n #define XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_H_\n \n+#include <cassert>\n #include <cstdint>\n \n-#include \"absl/log/check.h\"\n-#include \"absl/strings/str_format.h\"\n-#include \"absl/strings/string_view.h\"\n-\n-namespace xla::cpu {\n+namespace xla {\n+namespace cpu {\n \n // `BufferAllocationInfo` stores information about buffer allocations required\n // by an XLA:CPU executable at run time. It corresponds to a `BufferAllocation`\n@@ -34,36 +32,28 @@ namespace xla::cpu {\n // don't want to bring in these dependencies, e.g. in AOT compilation.\n class BufferAllocationInfo {\n  public:\n-  // Encoded version of `BufferAllocationInfo`, which can be used to reconstruct\n-  // the `BufferAllocationInfo` later. It's used in the AOT compiler, to\n-  // represent buffer allocation info as a lightweight struct.\n-  struct Encoded {\n-    uint64_t packed_kind_and_size = 0;\n-    uint32_t entry_param_number = -1;\n-    uint32_t result_number = -1;\n+  // If buffer allocation is an in-out parameter, we use `kParameter` kind and\n+  // set both entry parameter and result numbers.\n+  enum class Kind : uint64_t {\n+    kConstant = 0,\n+    kTemp = 1,\n+    kParameter = 2,\n+    kThreadLocal = 3\n   };\n \n-  // Creates a BufferAllocationInfo from a serialized encoding generated by\n-  // `Encode`.\n-  explicit constexpr BufferAllocationInfo(const Encoded& encoded)\n-      : kind_(UnpackKind(encoded.packed_kind_and_size)),\n-        size_(UnpackSize(encoded.packed_kind_and_size)),\n-        entry_param_number_(encoded.entry_param_number),\n-        result_number_(encoded.result_number) {}\n-\n   bool is_constant() const { return kind_ == Kind::kConstant; }\n \n   bool is_entry_parameter() const { return entry_param_number_ >= 0; }\n \n   int32_t entry_parameter_number() const {\n-    DCHECK(is_entry_parameter());\n+    assert(is_entry_parameter());  // WARNING: do not replace with DCHECK\n     return entry_param_number_;\n   }\n \n   bool is_result() const { return result_number_ >= 0; }\n \n   int32_t result_number() const {\n-    DCHECK(is_result());\n+    assert(is_result());  // WARNING: do not replace with DCHECK\n     return result_number_;\n   }\n \n@@ -75,22 +65,9 @@ class BufferAllocationInfo {\n   // These buffers are never allocated by the runtime.\n   bool is_thread_local() const { return kind_ == Kind::kThreadLocal; }\n \n-  // Returns the size for this buffer.\n+  Kind kind() const { return kind_; }\n   uint64_t size() const { return size_; }\n \n-  // Encodes this BufferAllocationInfo into the struct that can be used\n-  // to reconstruct the BufferAllocationInfo later using the constructor. We\n-  // need this because we use BufferAllocationInfo in places where using\n-  // protocol buffers would negatively impact binary size.\n-  Encoded Encode() const {\n-    static_assert(sizeof(*this) == 16);\n-    return Encoded{\n-        Pack(kind_, size_),\n-        static_cast<uint32_t>(entry_param_number_),\n-        static_cast<uint32_t>(result_number_),\n-    };\n-  }\n-\n   bool operator==(const BufferAllocationInfo& buffer_info) const {\n     return kind_ == buffer_info.kind_ && size_ == buffer_info.size_ &&\n            entry_param_number_ == buffer_info.entry_param_number_ &&\n@@ -118,40 +95,14 @@ class BufferAllocationInfo {\n   }\n \n   static BufferAllocationInfo Result(uint64_t size, int32_t result_number) {\n-    return BufferAllocationInfo(Kind::kResult, size, -1, result_number);\n+    return BufferAllocationInfo(Kind::kParameter, size, -1, result_number);\n   }\n \n   static BufferAllocationInfo ThreadLocal(uint64_t size) {\n     return BufferAllocationInfo(Kind::kThreadLocal, size);\n   }\n \n-  template <typename Sink>\n-  friend void AbslStringify(Sink& sink, const BufferAllocationInfo& info) {\n-    absl::Format(\n-        &sink, \"BufferAllocationInfo(%s, size=%d%s%s)\", ToString(info.kind_),\n-        info.size_,\n-        info.entry_param_number_ >= 0\n-            ? absl::StrFormat(\", entry_param=%d\", info.entry_param_number_)\n-            : \"\",\n-        info.result_number_ >= 0\n-            ? absl::StrFormat(\", result=%d\", info.result_number_)\n-            : \"\");\n-  }\n-\n  private:\n-  template <typename Sink>\n-  friend void AbslStringify(Sink& sink, const BufferAllocationInfo& info);\n-\n-  // If buffer allocation is an in-out parameter, we use `kParameter` kind and\n-  // set both entry parameter and result numbers.\n-  enum class Kind : uint64_t {\n-    kConstant,\n-    kTemp,\n-    kParameter,\n-    kResult,\n-    kThreadLocal\n-  };\n-\n   BufferAllocationInfo(Kind kind, uint64_t size,\n                        int32_t entry_param_number = -1,\n                        int32_t result_number = -1)\n@@ -160,39 +111,84 @@ class BufferAllocationInfo {\n         entry_param_number_(entry_param_number),\n         result_number_(result_number) {}\n \n-  static uint64_t Pack(Kind kind, uint64_t size) {\n-    return (static_cast<uint64_t>(size) << 4) | static_cast<uint64_t>(kind);\n-  }\n+  Kind kind_;\n+  uint64_t size_;\n+  int32_t entry_param_number_ = -1;\n+  int32_t result_number_ = -1;\n+};\n \n-  static inline constexpr Kind UnpackKind(uint64_t packed) {\n-    return static_cast<Kind>((packed << 60) >> 60);\n+// Encoded version of `BufferAllocationInfo`, which can be used to reconstruct\n+// the `BufferAllocationInfo` later. It's used in the AOT compiler, to\n+// represent buffer allocation info as a lightweight struct.\n+struct EncodedBufferAllocationInfo {\n+  EncodedBufferAllocationInfo(uint64_t packed_kind_and_size,\n+                              uint32_t entry_param_number,\n+                              uint32_t result_number)\n+      : packed_kind_and_size(packed_kind_and_size),\n+        entry_param_number(entry_param_number),\n+        result_number(result_number) {}\n+\n+  // Encodes BufferAllocationInfo into the struct that can be used to\n+  // reconstruct the BufferAllocationInfo later using the constructor. We need\n+  // this because we use BufferAllocationInfo in places where using protocol\n+  // buffers would negatively impact binary size.\n+  explicit EncodedBufferAllocationInfo(\n+      const BufferAllocationInfo& buffer_info) {\n+    packed_kind_and_size = Pack(buffer_info.kind(), buffer_info.size());\n+    entry_param_number = buffer_info.is_entry_parameter()\n+                             ? buffer_info.entry_parameter_number()\n+                             : -1;\n+    result_number = buffer_info.is_result() ? buffer_info.result_number() : -1;\n   }\n \n-  static inline constexpr uint64_t UnpackSize(uint64_t packed) {\n-    return packed >> 4;\n-  }\n+  explicit operator BufferAllocationInfo() const {\n+    auto kind = UnpackKind(packed_kind_and_size);\n+    auto size = UnpackSize(packed_kind_and_size);\n+    int32_t entry_param_number = static_cast<int32_t>(this->entry_param_number);\n+    int32_t result_number = static_cast<int32_t>(this->result_number);\n \n-  static absl::string_view ToString(Kind kind) {\n     switch (kind) {\n-      case Kind::kConstant:\n-        return \"constant\";\n-      case Kind::kTemp:\n-        return \"temp\";\n-      case Kind::kParameter:\n-        return \"parameter\";\n-      case Kind::kResult:\n-        return \"result\";\n-      case Kind::kThreadLocal:\n-        return \"thread-local\";\n+      case BufferAllocationInfo::Kind::kConstant:\n+        return BufferAllocationInfo::Constant(size);\n+      case BufferAllocationInfo::Kind::kTemp:\n+        return BufferAllocationInfo::Temp(size);\n+      case BufferAllocationInfo::Kind::kParameter:\n+        if (entry_param_number >= 0 && result_number >= 0) {\n+          return BufferAllocationInfo::InOutParameter(size, entry_param_number,\n+                                                      result_number);\n+        }\n+        if (entry_param_number >= 0) {\n+          return BufferAllocationInfo::EntryParameter(size, entry_param_number);\n+        }\n+        return BufferAllocationInfo::Result(size, result_number);\n+      case BufferAllocationInfo::Kind::kThreadLocal:\n+        return BufferAllocationInfo::ThreadLocal(size);\n     }\n   }\n \n-  Kind kind_ : 4;\n-  uint64_t size_ : 60;\n-  int32_t entry_param_number_ = -1;\n-  int32_t result_number_ = -1;\n+  static uint64_t Pack(BufferAllocationInfo::Kind kind, uint64_t size) {\n+    return (static_cast<uint64_t>(size) << 2) | static_cast<uint64_t>(kind);\n+  }\n+\n+  static constexpr BufferAllocationInfo::Kind UnpackKind(uint64_t packed) {\n+    return static_cast<BufferAllocationInfo::Kind>((packed << 62) >> 62);\n+  }\n+\n+  static constexpr uint64_t UnpackSize(uint64_t packed) { return packed >> 2; }\n+\n+  uint64_t packed_kind_and_size = 0;\n+  uint32_t entry_param_number = -1;\n+  uint32_t result_number = -1;\n };\n \n-}  // namespace xla::cpu\n+}  // namespace cpu\n+\n+// TODO(ezhulenev): This is a temporary hack to keep `tfcompile` code working.\n+namespace cpu_function_runtime {\n+using BufferInfo = ::xla::cpu::BufferAllocationInfo;\n+using EncodedBufferInfo = ::xla::cpu::EncodedBufferAllocationInfo;\n+}  // namespace cpu_function_runtime\n+\n+}  // namespace xla\n \n #endif  // XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_H_"
        },
        {
            "sha": "3848bb6c4db313953fa3a0622f6ba56f802849c1",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_test.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -22,7 +22,8 @@ namespace {\n \n TEST(BufferAllocationInfoTest, RoundTrip) {\n   auto round_trip = [](const BufferAllocationInfo& buffer_info) {\n-    BufferAllocationInfo round_trip(buffer_info.Encode());\n+    EncodedBufferAllocationInfo encoded(buffer_info);\n+    BufferAllocationInfo round_trip(encoded);\n     ASSERT_EQ(round_trip, buffer_info);\n   };\n "
        },
        {
            "sha": "94f276cf4e8d3c5773eb5972a1220b775a81829f",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info_util.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -21,7 +21,6 @@ limitations under the License.\n \n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/log/check.h\"\n-#include \"absl/log/log.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -90,11 +89,6 @@ std::vector<BufferAllocationInfo> CreateBufferAllocationInfos(\n     }\n   }\n \n-  VLOG(3) << \"Created \" << allocations.size() << \" buffer allocation infos: \";\n-  for (const BufferAllocationInfo& allocation : allocations) {\n-    VLOG(3) << \"  \" << allocation;\n-  }\n-\n   return allocations;\n }\n "
        },
        {
            "sha": "b35ad602969736f9a53ac9cf0f14d96a3692d832",
            "filename": "third_party/xla/xla/cpu_function_runtime.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcpu_function_runtime.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -22,7 +22,7 @@ limitations under the License.\n #include <cstdlib>\n \n namespace xla {\n-namespace cpu_function_runtime {\n+namespace cpu_function_runtime_deprecated {\n \n struct EncodedBufferInfo {\n   uint64_t packed_kind_and_size = 0;\n@@ -174,7 +174,7 @@ class BufferInfo {\n   int32_t result_param_number_ = -1;\n };\n \n-}  // namespace cpu_function_runtime\n+}  // namespace cpu_function_runtime_deprecated\n }  // namespace xla\n \n #endif  // XLA_CPU_FUNCTION_RUNTIME_H_"
        },
        {
            "sha": "b1e885813c6efafeb60395292314c41dee96cc0e",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -171,25 +171,12 @@ cc_library(\n     alwayslink = True,  # Contains per-platform transfer manager registration\n )\n \n-cc_library(\n-    name = \"buffer_info_util\",\n-    srcs = [\"buffer_info_util.cc\"],\n-    hdrs = [\"buffer_info_util.h\"],\n-    deps = [\n-        \"//xla:cpu_function_runtime\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/service:buffer_assignment\",\n-        \"@com_google_absl//absl/types:span\",\n-    ],\n-)\n-\n cc_library(\n     name = \"cpu_compiler_pure\",\n     srcs = [\"cpu_compiler.cc\"],\n     hdrs = [\"cpu_compiler.h\"],\n     copts = tsl_copts(),\n     deps = [\n-        \":buffer_info_util\",\n         \":conv_canonicalization\",\n         \":cpu_aot_compilation_result\",\n         \":cpu_aot_loader\",\n@@ -428,7 +415,6 @@ cc_library(\n     srcs = [\"cpu_aot_compilation_result.cc\"],\n     hdrs = [\"cpu_aot_compilation_result.h\"],\n     deps = [\n-        \":buffer_info_util\",\n         \":cpu_executable\",\n         \":executable_proto_cc\",\n         \"//xla:cpu_function_runtime\","
        },
        {
            "sha": "cbcbdfa853eb7e385fbab792cd66a54cbc65c0fa",
            "filename": "third_party/xla/xla/service/cpu/buffer_info_util.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 101,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a6eef2333cad21113fea35454a9140e6bf00de2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a6eef2333cad21113fea35454a9140e6bf00de2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.cc?ref=3a6eef2333cad21113fea35454a9140e6bf00de2",
            "patch": "@@ -1,101 +0,0 @@\n-/* Copyright 2018 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/cpu/buffer_info_util.h\"\n-\n-#include <cassert>\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/types/span.h\"\n-#include \"xla/cpu_function_runtime.h\"\n-\n-namespace xla {\n-namespace cpu {\n-\n-using BufferInfo = cpu_function_runtime::BufferInfo;\n-\n-std::vector<BufferInfo> CreateBufferInfosFromBufferAssignment(\n-    const HloModule& module, const BufferAssignment& buffer_assignment) {\n-  std::vector<BufferInfo> buffer_infos;\n-  for (const BufferAllocation& allocation : buffer_assignment.Allocations()) {\n-    if (allocation.is_thread_local()) {\n-      buffer_infos.push_back(BufferInfo::MakeOnStackBuffer(allocation.size()));\n-    } else if (allocation.is_constant()) {\n-      buffer_infos.push_back(BufferInfo::MakeConstant(allocation.size()));\n-    } else if (allocation.is_entry_computation_parameter()) {\n-      buffer_infos.push_back(BufferInfo::MakeEntryParameter(\n-          /*size=*/allocation.size(),\n-          /*param_number=*/allocation.parameter_number()));\n-    } else {\n-      buffer_infos.push_back(BufferInfo::MakeTempBuffer(allocation.size()));\n-    }\n-  }\n-\n-  // Fill in the result parameters' indices, expanding all tuples.\n-  auto root_instr = module.entry_computation()->root_instruction();\n-  auto output_allocation = buffer_assignment.GetUniqueTopLevelOutputSlice();\n-  if (output_allocation->allocation()->is_tuple()) {\n-    int out_index = 0;\n-    ShapeUtil::ForEachSubshape(\n-        root_instr->shape(),\n-        [&](const Shape& subshape, const ShapeIndex& index) {\n-          if (subshape.IsTuple()) {\n-            return;\n-          }\n-          int64_t result_index =\n-              buffer_assignment.GetUniqueSlice(root_instr, index)->index();\n-          assert(result_index < buffer_infos.size());\n-          buffer_infos[result_index].set_result_parameter_number(out_index++);\n-        });\n-  }\n-\n-  return buffer_infos;\n-}\n-\n-std::vector<int32_t> CreateArgIndexTableFromBufferInfos(\n-    absl::Span<const BufferInfo> buffer_infos) {\n-  std::vector<int32_t> ret;\n-  for (int64_t i = 0; i < buffer_infos.size(); i++) {\n-    if (!buffer_infos[i].is_entry_parameter()) {\n-      continue;\n-    }\n-    uint64_t param_index = buffer_infos[i].entry_parameter_number();\n-    if (param_index >= ret.size()) {\n-      ret.resize(param_index + 1);\n-    }\n-    ret[param_index] = i;\n-  }\n-  return ret;\n-}\n-\n-std::vector<int32_t> CreateResultIndexTableFromBufferInfos(\n-    absl::Span<const BufferInfo> buffer_infos) {\n-  std::vector<int32_t> ret;\n-  for (int64_t i = 0; i < buffer_infos.size(); i++) {\n-    if (!buffer_infos[i].is_result_parameter()) {\n-      continue;\n-    }\n-    uint64_t result_index = buffer_infos[i].result_parameter_number();\n-    if (result_index >= ret.size()) {\n-      ret.resize(result_index + 1);\n-    }\n-    ret[result_index] = i;\n-  }\n-  return ret;\n-}\n-\n-}  // namespace cpu\n-}  // namespace xla"
        },
        {
            "sha": "c21ea2f8459a1b71b7a86fd8a65e2416af802768",
            "filename": "third_party/xla/xla/service/cpu/buffer_info_util.h",
            "status": "removed",
            "additions": 0,
            "deletions": 48,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3a6eef2333cad21113fea35454a9140e6bf00de2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3a6eef2333cad21113fea35454a9140e6bf00de2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbuffer_info_util.h?ref=3a6eef2333cad21113fea35454a9140e6bf00de2",
            "patch": "@@ -1,48 +0,0 @@\n-/* Copyright 2018 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_\n-#define XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_\n-\n-#include <cstdint>\n-#include <vector>\n-\n-#include \"absl/types/span.h\"\n-#include \"xla/cpu_function_runtime.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/service/buffer_assignment.h\"\n-\n-namespace xla {\n-namespace cpu {\n-// Creates and returns a list of BufferInfo instances containing relevant\n-// information from `buffer_assignment`.\n-std::vector<cpu_function_runtime::BufferInfo>\n-CreateBufferInfosFromBufferAssignment(\n-    const HloModule& module, const BufferAssignment& buffer_assignment);\n-\n-// Creates and returns a table containing the mapping from entry computation\n-// parameters to buffer allocation indices.\n-//\n-// If this function returns V then entry parameter i has buffer allocation index\n-// V[i].\n-std::vector<int32_t> CreateArgIndexTableFromBufferInfos(\n-    absl::Span<const cpu_function_runtime::BufferInfo> buffer_infos);\n-\n-std::vector<int32_t> CreateResultIndexTableFromBufferInfos(\n-    absl::Span<const cpu_function_runtime::BufferInfo> buffer_infos);\n-}  // namespace cpu\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_CPU_BUFFER_INFO_UTIL_H_"
        },
        {
            "sha": "0894f3243783fe8524a5789889ea24367a20f5af",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 10,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -43,7 +43,6 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/compiler.h\"\n-#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/cpu_executable.h\"\n #include \"xla/service/cpu/executable.pb.h\"\n #include \"xla/service/executable.h\"\n@@ -57,7 +56,6 @@ limitations under the License.\n #include \"xla/util.h\"\n \n namespace xla::cpu {\n-using BufferInfo = cpu_function_runtime::BufferInfo;\n \n CpuAotCompilationOptions::CpuAotCompilationOptions(\n     std::string triple, std::string cpu_name, std::string features,\n@@ -88,14 +86,10 @@ CpuAotCompilationResult::Create(\n   TF_ASSIGN_OR_RETURN(ThunkSequenceProto thunk_proto,\n                       thunk_sequence_serdes.ToProto(thunks));\n \n-  std::vector<cpu_function_runtime::BufferInfo> buffer_infos;\n   std::vector<cpu::BufferAllocationInfo> buffer_allocation_infos;\n   std::optional<size_t> temp_allocation_index;\n \n   if (buffer_assignment) {\n-    buffer_infos =\n-        CreateBufferInfosFromBufferAssignment(*hlo_module, *buffer_assignment);\n-\n     buffer_allocation_infos =\n         CreateBufferAllocationInfos(*hlo_module, *buffer_assignment);\n \n@@ -114,21 +108,19 @@ CpuAotCompilationResult::Create(\n   return absl::WrapUnique(new CpuAotCompilationResult(\n       hlo_module, buffer_assignment, function_name, std::move(obj_files),\n       std::move(symbols), thunk_proto, std::move(temp_allocation_index),\n-      std::move(buffer_infos), std::move(buffer_allocation_infos),\n-      std::move(function_library), std::move(hlo_profile_printer_data)));\n+      std::move(buffer_allocation_infos), std::move(function_library),\n+      std::move(hlo_profile_printer_data)));\n }\n \n CpuAotCompilationResult::CpuAotCompilationResult(\n     const HloModule* hlo_module, const BufferAssignment* buffer_assignment,\n     absl::string_view function_name, std::vector<ObjFileProto> obj_files,\n     std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n     std::optional<size_t> temp_allocation_index,\n-    std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n     std::vector<BufferAllocationInfo> buffer_allocation_infos,\n     std::unique_ptr<FunctionLibrary> function_library,\n     std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data)\n     : temp_allocation_index_(temp_allocation_index),\n-      buffer_infos_(std::move(buffer_infos)),\n       buffer_allocation_infos_(std::move(buffer_allocation_infos)),\n       function_library_(std::move(function_library)),\n       hlo_profile_printer_data_(std::move(hlo_profile_printer_data)) {"
        },
        {
            "sha": "4c5329c98ebc79e914fd1dc80e5406c7b794d0d5",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -148,10 +148,6 @@ class CpuAotCompilationResult : public AotCompilationResult {\n     return temp_allocation_index_;\n   }\n \n-  const std::vector<cpu_function_runtime::BufferInfo>& buffer_infos() const {\n-    return buffer_infos_;\n-  }\n-\n   absl::Span<const BufferAllocationInfo> buffer_allocation_infos() const {\n     return buffer_allocation_infos_;\n   }\n@@ -188,7 +184,6 @@ class CpuAotCompilationResult : public AotCompilationResult {\n       absl::string_view function_name, std::vector<ObjFileProto> obj_files,\n       std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n       std::optional<size_t> temp_allocation_index,\n-      std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n       std::vector<BufferAllocationInfo> buffer_allocation_infos,\n       std::unique_ptr<FunctionLibrary> function_library,\n       std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data);\n@@ -203,7 +198,6 @@ class CpuAotCompilationResult : public AotCompilationResult {\n   CompilationResultProto proto_;\n   std::unique_ptr<HloModule> module_;\n   std::optional<size_t> temp_allocation_index_;\n-  std::vector<cpu_function_runtime::BufferInfo> buffer_infos_;\n   std::vector<BufferAllocationInfo> buffer_allocation_infos_;\n \n   std::unique_ptr<FunctionLibrary> function_library_;"
        },
        {
            "sha": "14871c762fc4dc58f0fe427366fac62af27ff0ce",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=fd948cba881d4a4253c678cd9ec6b4b5aa1a3edc",
            "patch": "@@ -172,7 +172,6 @@ limitations under the License.\n #include \"xla/service/conditional_simplifier.h\"\n #include \"xla/service/conditional_to_select.h\"\n #include \"xla/service/copy_insertion.h\"\n-#include \"xla/service/cpu/buffer_info_util.h\"\n #include \"xla/service/cpu/conv_canonicalization.h\"\n #include \"xla/service/cpu/cpu_aot_compilation_result.h\"\n #include \"xla/service/cpu/cpu_aot_loader.h\""
        }
    ],
    "stats": {
        "total": 630,
        "additions": 219,
        "deletions": 411
    }
}