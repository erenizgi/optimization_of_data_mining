{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 847189518",
    "sha": "818e61079e341f265462be2e8634b02141ef84a9",
    "files": [
        {
            "sha": "1d252f549d380357c8c2471296a314a885df263c",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_debug_allocator_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 11,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_debug_allocator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_debug_allocator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_debug_allocator_test.cc?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -57,7 +57,8 @@ TEST(GPUDebugAllocatorTest, OverwriteDetection_None) {\n     memset(&cpu_array[0], 0, cpu_array.size() * sizeof(int64_t));\n     int64_t* gpu_array =\n         TypedAllocator::Allocate<int64_t>(&a, cpu_array.size(), {});\n-    se::DeviceMemory<int64_t> gpu_array_ptr{se::DeviceMemoryBase{gpu_array}};\n+    stream_executor::DeviceAddress<int64_t> gpu_array_ptr{\n+        stream_executor::DeviceAddressBase{gpu_array}};\n     TF_CHECK_OK(stream_exec->SynchronousMemcpyH2D(\n         &cpu_array[0], s * sizeof(int64_t), &gpu_array_ptr));\n     EXPECT_TRUE(a.CheckHeader(gpu_array));\n@@ -85,14 +86,14 @@ TEST(GPUDebugAllocatorTest, OverwriteDetection_Header) {\n           int64_t* gpu_array =\n               TypedAllocator::Allocate<int64_t>(&a, cpu_array.size(), {});\n \n-          se::DeviceMemory<int64_t> gpu_array_ptr{\n-              se::DeviceMemoryBase{gpu_array}};\n+          stream_executor::DeviceAddress<int64_t> gpu_array_ptr{\n+              stream_executor::DeviceAddressBase{gpu_array}};\n           TF_CHECK_OK(stream_exec->SynchronousMemcpyH2D(\n               &cpu_array[0], cpu_array.size() * sizeof(int64_t),\n               &gpu_array_ptr));\n \n-          se::DeviceMemory<int64_t> gpu_hdr_ptr{\n-              se::DeviceMemoryBase{gpu_array - 1}};\n+          stream_executor::DeviceAddress<int64_t> gpu_hdr_ptr{\n+              stream_executor::DeviceAddressBase{gpu_array - 1}};\n           // Clobber first word of the header.\n           float pi = 3.1417;\n           TF_CHECK_OK(stream_exec->SynchronousMemcpyH2D(&pi, sizeof(float),\n@@ -122,15 +123,15 @@ TEST(GPUDebugAllocatorTest, OverwriteDetection_Footer) {\n           int64_t* gpu_array =\n               TypedAllocator::Allocate<int64_t>(&a, cpu_array.size(), {});\n \n-          se::DeviceMemory<int64_t> gpu_array_ptr{\n-              se::DeviceMemoryBase{gpu_array}};\n+          stream_executor::DeviceAddress<int64_t> gpu_array_ptr{\n+              stream_executor::DeviceAddressBase{gpu_array}};\n           TF_CHECK_OK(stream_exec->SynchronousMemcpyH2D(\n               &cpu_array[0], cpu_array.size() * sizeof(int64_t),\n               &gpu_array_ptr));\n \n           // Clobber word of the footer.\n-          se::DeviceMemory<int64_t> gpu_ftr_ptr{\n-              se::DeviceMemoryBase{gpu_array + s}};\n+          stream_executor::DeviceAddress<int64_t> gpu_ftr_ptr{\n+              stream_executor::DeviceAddressBase{gpu_array + s}};\n           float pi = 3.1417;\n           TF_CHECK_OK(stream_exec->SynchronousMemcpyH2D(&pi, sizeof(float),\n                                                         &gpu_ftr_ptr));\n@@ -156,7 +157,8 @@ TEST(GPUDebugAllocatorTest, ResetToNan) {\n \n   // Allocate 1024 floats\n   float* gpu_array = TypedAllocator::Allocate<float>(&a, cpu_array.size(), {});\n-  se::DeviceMemory<float> gpu_array_ptr{se::DeviceMemoryBase{gpu_array}};\n+  stream_executor::DeviceAddress<float> gpu_array_ptr{\n+      stream_executor::DeviceAddressBase{gpu_array}};\n   TF_CHECK_OK(stream_exec->SynchronousMemcpyD2H(\n       gpu_array_ptr, cpu_array.size() * sizeof(float), &cpu_array[0]));\n   for (float f : cpu_array) {\n@@ -200,7 +202,8 @@ TEST(GPUDebugAllocatorTest, ResetToNanWithHeaderFooter) {\n \n   // Allocate 1024 floats\n   float* gpu_array = TypedAllocator::Allocate<float>(&a, cpu_array.size(), {});\n-  se::DeviceMemory<float> gpu_array_ptr{se::DeviceMemoryBase{gpu_array}};\n+  stream_executor::DeviceAddress<float> gpu_array_ptr{\n+      stream_executor::DeviceAddressBase{gpu_array}};\n   TF_CHECK_OK(stream_exec->SynchronousMemcpyD2H(\n       gpu_array_ptr, cpu_array.size() * sizeof(float), &cpu_array[0]));\n   for (float f : cpu_array) {"
        },
        {
            "sha": "441715bd2d22cb531caff27b2fc98b633db1353f",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_device.h",
            "status": "modified",
            "additions": 56,
            "deletions": 55,
            "changes": 111,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device.h?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -105,28 +105,28 @@ class BaseGPUDevice : public LocalDevice {\n #endif\n     se::Stream* host_to_device = nullptr;\n     se::Stream* device_to_host = nullptr;\n-    gtl::InlinedVector<se::Stream*, 4> device_to_device;\n+    absl::InlinedVector<stream_executor::Stream*, 4UL> device_to_device;\n     int priority = 0;\n   };\n \n   // Initialize the device and return the status of initialization.\n #ifdef TF_GPU_USE_PJRT\n-  Status Init(const SessionOptions& options,\n-              xla::LocalDeviceState* xla_local_device_state);\n+  absl::Status Init(const SessionOptions& options,\n+                    xla::LocalDeviceState* xla_local_device_state);\n #else\n-  Status Init(const SessionOptions& options);\n+  absl::Status Init(const SessionOptions& options);\n #endif  // TF_GPU_USE_PJRT\n \n   void Compute(OpKernel* op_kernel, OpKernelContext* context) override;\n \n-  Status Sync() override;\n+  absl::Status Sync() override;\n \n   void ComputeAsync(AsyncOpKernel* op_kernel, OpKernelContext* context,\n                     AsyncOpKernel::DoneCallback done) override;\n \n-  Status MakeTensorFromProto(const TensorProto& tensor_proto,\n-                             AllocatorAttributes alloc_attrs,\n-                             Tensor* tensor) override;\n+  absl::Status MakeTensorFromProto(const TensorProto& tensor_proto,\n+                                   AllocatorAttributes alloc_attrs,\n+                                   Tensor* tensor) override;\n \n   void CopyTensorInSameDevice(const Tensor* input_tensor, Tensor* output_tensor,\n                               const DeviceContext* device_context,\n@@ -135,9 +135,9 @@ class BaseGPUDevice : public LocalDevice {\n   // The caller owns the returned device.\n   PerOpGpuDevice* MakeGpuDevice() override;\n \n-  Status ReinitializeGpuDevice(OpKernelContext* context, PerOpGpuDevice* device,\n-                               DeviceContext* dc,\n-                               Allocator* allocator) override;\n+  absl::Status ReinitializeGpuDevice(OpKernelContext* context,\n+                                     PerOpGpuDevice* device, DeviceContext* dc,\n+                                     Allocator* allocator) override;\n \n   // Returns the platform GPU id of this device within the native driver system;\n   // e.g., for CUDA and ROCm this is the ordinal of the GPU within the system.\n@@ -164,7 +164,7 @@ class BaseGPUDevice : public LocalDevice {\n \n   // If returned value is > 0 then GPU Memory chunks freed before this count\n   // are guaranteed not to be in use by any kernel pending on this device.\n-  uint64 SafeAllocFrontier(uint64 old_value) override;\n+  uint64_t SafeAllocFrontier(uint64_t old_value) override;\n \n   // Returns the number of kernels that have been queued for execution on\n   // the compute stream and are not yet known to have completed.\n@@ -216,13 +216,13 @@ class BaseGPUDevice : public LocalDevice {\n   EventMgr* em_ = nullptr;\n   std::unique_ptr<thread::ThreadPool> thread_pool_;\n   std::unique_ptr<GPUKernelTracker> kernel_tracker_;\n-  int32 pending_cap_ = 0;\n+  int32_t pending_cap_ = 0;\n   bool timestamped_allocator_ = false;\n   NodeFileWriter* node_file_writer_ = nullptr;  // not owned\n   const GPUOptions::Experimental::StreamMergeOptions stream_merge_options_;\n \n   // Initialize scratch buffers used by Eigen.\n-  Status InitScratchBuffers();\n+  absl::Status InitScratchBuffers();\n \n   void ReinitializeDevice(OpKernelContext* context, PerOpGpuDevice* device,\n                           int stream_id, Allocator* allocator);\n@@ -235,9 +235,9 @@ class BaseGPUDevice : public LocalDevice {\n   // allocate memory or if the tensor \"from\" is not DMA-copyable.\n   // If there is no error prior to enqueueing the copy, an OK status\n   // is returned.\n-  Status MaybeCopyTensorToGPU(const AllocatorAttributes& alloc_attrs,\n-                              const Tensor& from, Tensor* to,\n-                              StatusCallback done);\n+  absl::Status MaybeCopyTensorToGPU(const AllocatorAttributes& alloc_attrs,\n+                                    const Tensor& from, Tensor* to,\n+                                    StatusCallback done);\n \n   Tensor CopyGpuTensorToHostDebugOnly(const Tensor& gpu_tensor);\n   void LogInputs(OpKernel* op_kernel, OpKernelContext* context);\n@@ -293,25 +293,25 @@ class GPUKernelTracker {\n   // Determine whether a GPU kernel should have a recording event queued\n   // immediately afterwards.  If so, advance the counter and return the new\n   // counter value after enqueuing.\n-  uint64 MaybeQueue(OpKernelContext* ctx);\n+  uint64_t MaybeQueue(OpKernelContext* ctx);\n \n   // Record that a GPU kernel has just been enqueued on the compute stream.\n   // Inserts the supplied counter value in a new PendingKernel record appended\n   // to the end of the ring buffer then returns that same count.\n   // Caller is responsible for ensuring that RecordTerminate() is eventually\n   // called with the same counter value.\n-  void RecordQueued(uint64 queued_count, int weight)\n+  void RecordQueued(uint64_t queued_count, int weight)\n       TF_EXCLUSIVE_LOCKS_REQUIRED(mu_);\n \n   // Takes a count value returned by RecordQueued and finds the corresponding\n   // PendingKernel record in the ring buffer.  Marks the kernel as completed and\n   // advances the completion frontier accordingly.\n-  void RecordTerminated(uint64 queued_count);\n+  void RecordTerminated(uint64_t queued_count);\n \n   // Returns the largest timing count such that all kernels queued no\n   // later than that count are known to have terminated.\n-  inline uint64 LastTerminatedCount(uint64 old_value) {\n-    uint64 new_value = last_terminated_count_.load(std::memory_order_relaxed);\n+  inline uint64_t LastTerminatedCount(uint64_t old_value) {\n+    uint64_t new_value = last_terminated_count_.load(std::memory_order_relaxed);\n     if (new_value == old_value) {\n       MaybeQueueProgressEvent();\n     }\n@@ -344,22 +344,22 @@ class GPUKernelTracker {\n   std::unique_ptr<SharedCounter> owned_counter_;\n   Allocator* allocator_ = nullptr;\n   EventMgr* em_ = nullptr;\n-  std::atomic<uint64> last_terminated_count_ = {1};\n+  std::atomic<uint64_t> last_terminated_count_ = {1};\n \n   void MaybeQueueProgressEvent();\n \n   // Records when a kernel was queued for execution.  Kernel launches are\n   // identified by a unique count value from a per-GPU device timing counter.\n   struct PendingKernel {\n-    uint64 queued_count;\n+    uint64_t queued_count;\n     int weight;\n     bool terminated;\n     PendingKernel(const PendingKernel& pk) = default;\n     PendingKernel() : queued_count(0), weight(0), terminated(false) {}\n   };\n   mutex mu_;\n-  int32 mem_since_last_ TF_GUARDED_BY(mu_);\n-  int32 ops_since_last_ TF_GUARDED_BY(mu_);\n+  int32_t mem_since_last_ TF_GUARDED_BY(mu_);\n+  int32_t ops_since_last_ TF_GUARDED_BY(mu_);\n   // Ring buffer of PendingKernel records.\n   std::vector<PendingKernel> pending_kernels_ TF_GUARDED_BY(mu_);\n   // Next unused slot in pending_kernels_.\n@@ -376,12 +376,13 @@ class GPUKernelTracker {\n \n class BaseGPUDeviceFactory : public DeviceFactory {\n  public:\n-  Status ListPhysicalDevices(std::vector<string>* devices) override;\n-  Status CreateDevices(const SessionOptions& options,\n-                       const std::string& name_prefix,\n-                       std::vector<std::unique_ptr<Device>>* devices) override;\n-  Status GetDeviceDetails(int device_index,\n-                          std::unordered_map<string, string>* details) override;\n+  absl::Status ListPhysicalDevices(std::vector<std::string>* devices) override;\n+  absl::Status CreateDevices(\n+      const SessionOptions& options, const std::string& name_prefix,\n+      std::vector<std::unique_ptr<Device>>* devices) override;\n+  absl::Status GetDeviceDetails(\n+      int device_index,\n+      std::unordered_map<std::string, std::string>* details) override;\n \n   struct InterconnectMap {\n     // Name of interconnect technology, if known.\n@@ -390,7 +391,7 @@ class BaseGPUDeviceFactory : public DeviceFactory {\n     // Where architecture-specific subclassing is not done that won't\n     // always be possible.  The minimum expectation is that\n     // faster links should have a higher value than slower links.\n-    int32 strength;\n+    int32_t strength;\n     static const int kSameDeviceStrength;\n     static const int kStreamExecutorStrength;\n     std::set<std::pair<tsl::PlatformDeviceId, tsl::PlatformDeviceId>>\n@@ -400,7 +401,7 @@ class BaseGPUDeviceFactory : public DeviceFactory {\n  protected:\n   // Populates *maps with interconnect maps for all local direct access\n   // pathways between GPUs.\n-  virtual Status GetInterconnectMaps(\n+  virtual absl::Status GetInterconnectMaps(\n       const std::vector<tsl::PlatformDeviceId>& visible_gpu_order,\n       se::Platform* gpu_manager, std::vector<InterconnectMap>* maps);\n \n@@ -413,7 +414,7 @@ class BaseGPUDeviceFactory : public DeviceFactory {\n       LocalityMap;\n   // Populates *localities with the DeviceLocality descriptor for\n   // every TfDeviceId.\n-  virtual Status GetDeviceLocalities(\n+  virtual absl::Status GetDeviceLocalities(\n       int num_tf_gpus, const std::vector<InterconnectMap>& interconnects,\n       LocalityMap* localities);\n \n@@ -422,45 +423,45 @@ class BaseGPUDeviceFactory : public DeviceFactory {\n   // 'devices' vector. The 'gpu_allocator' is created by the caller and usually\n   // preallocates a set amount of GPU memory.\n #ifdef TF_GPU_USE_PJRT\n-  Status CreateGPUDevice(const SessionOptions& options,\n-                         const std::string& name_prefix,\n-                         tsl::TfDeviceId tf_device_id,\n-                         const DeviceLocality& dev_locality,\n-                         xla::LocalDeviceState* xla_local_device_state,\n-                         Allocator* gpu_allocator,\n-                         std::vector<std::unique_ptr<Device>>* devices);\n+  absl::Status CreateGPUDevice(const SessionOptions& options,\n+                               const std::string& name_prefix,\n+                               tsl::TfDeviceId tf_device_id,\n+                               const DeviceLocality& dev_locality,\n+                               xla::LocalDeviceState* xla_local_device_state,\n+                               Allocator* gpu_allocator,\n+                               std::vector<std::unique_ptr<Device>>* devices);\n #else\n-  Status CreateGPUDevice(const SessionOptions& options,\n-                         const std::string& name_prefix,\n-                         tsl::TfDeviceId tf_device_id,\n-                         const DeviceLocality& dev_locality,\n-                         Allocator* gpu_allocator,\n-                         std::vector<std::unique_ptr<Device>>* devices);\n+  absl::Status CreateGPUDevice(const SessionOptions& options,\n+                               const std::string& name_prefix,\n+                               tsl::TfDeviceId tf_device_id,\n+                               const DeviceLocality& dev_locality,\n+                               Allocator* gpu_allocator,\n+                               std::vector<std::unique_ptr<Device>>* devices);\n #endif  // TF_GPU_USE_PJRT\n \n   virtual std::unique_ptr<BaseGPUDevice> CreateGPUDevice(\n-      const SessionOptions& options, const string& name, Bytes memory_limit,\n-      const DeviceLocality& dev_locality, tsl::TfDeviceId tf_device_id,\n-      const string& physical_device_desc, Allocator* gpu_allocator,\n-      Allocator* cpu_allocator) = 0;\n+      const SessionOptions& options, const std::string& name,\n+      Bytes memory_limit, const DeviceLocality& dev_locality,\n+      tsl::TfDeviceId tf_device_id, const std::string& physical_device_desc,\n+      Allocator* gpu_allocator, Allocator* cpu_allocator) = 0;\n \n-  Status EnablePeerAccess(\n+  absl::Status EnablePeerAccess(\n       const std::vector<tsl::PlatformDeviceId>& visible_gpu_order);\n \n   // Returns into 'ids' the list of valid platform GPU ids, in the order that\n   // they should map to TF GPU ids \"/device:GPU:0\", \"/device:GPU:1\", etc,\n   // based upon 'visible_gpu_order' which was generated by parsing\n   // GPUOptions::visible_device_list which is a comma-separated list of CUDA or\n   // ROCm GPU ids.\n-  Status GetValidDeviceIds(\n+  absl::Status GetValidDeviceIds(\n       const std::vector<tsl::PlatformDeviceId>& visible_gpu_order,\n       std::vector<tsl::PlatformDeviceId>* ids);\n \n   // Cache the valid device IDs if not already cached. Cached IDs are stored in\n   // field cached_device_ids_. Passes {0, 1, ..., num_devices-1} to\n   // GetValidDeviceIds, so this should only be used in functions where all\n   // devices should be treated as visible, like ListPhysicalDevices.\n-  Status CacheDeviceIds();\n+  absl::Status CacheDeviceIds();\n \n   // visible_gpu_initialized_[platform_device_id] is true if visible GPU\n   // platform_device_id has been initialized by the process."
        },
        {
            "sha": "2848cf5d16d91d4b7ee9106232e0ff7a4ccbe7d0",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_device_factory.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 14,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_factory.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_factory.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_factory.cc?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -28,10 +28,11 @@ namespace tensorflow {\n \n class GPUDevice : public BaseGPUDevice {\n  public:\n-  GPUDevice(const SessionOptions& options, const string& name,\n+  GPUDevice(const SessionOptions& options, const std::string& name,\n             Bytes memory_limit, const DeviceLocality& locality,\n-            tsl::TfDeviceId tf_device_id, const string& physical_device_desc,\n-            Allocator* gpu_allocator, Allocator* cpu_allocator)\n+            tsl::TfDeviceId tf_device_id,\n+            const std::string& physical_device_desc, Allocator* gpu_allocator,\n+            Allocator* cpu_allocator)\n       : BaseGPUDevice(options, name, memory_limit, locality, tf_device_id,\n                       physical_device_desc, gpu_allocator, cpu_allocator,\n                       false /* sync every op */),\n@@ -64,10 +65,10 @@ class GPUDevice : public BaseGPUDevice {\n class GPUDeviceFactory : public BaseGPUDeviceFactory {\n  private:\n   std::unique_ptr<BaseGPUDevice> CreateGPUDevice(\n-      const SessionOptions& options, const string& name, Bytes memory_limit,\n-      const DeviceLocality& locality, tsl::TfDeviceId tf_device_id,\n-      const string& physical_device_desc, Allocator* gpu_allocator,\n-      Allocator* cpu_allocator) override {\n+      const SessionOptions& options, const std::string& name,\n+      Bytes memory_limit, const DeviceLocality& locality,\n+      tsl::TfDeviceId tf_device_id, const std::string& physical_device_desc,\n+      Allocator* gpu_allocator, Allocator* cpu_allocator) override {\n     return absl::make_unique<GPUDevice>(options, name, memory_limit, locality,\n                                         tf_device_id, physical_device_desc,\n                                         gpu_allocator, cpu_allocator);\n@@ -82,7 +83,7 @@ REGISTER_LOCAL_DEVICE_FACTORY(\"GPU\", GPUDeviceFactory, 210);\n // -----------------------------------------------------------------------------\n class GPUCompatibleCPUDevice : public ThreadPoolDevice {\n  public:\n-  GPUCompatibleCPUDevice(const SessionOptions& options, const string& name,\n+  GPUCompatibleCPUDevice(const SessionOptions& options, const std::string& name,\n                          Bytes memory_limit, const DeviceLocality& locality,\n                          Allocator* allocator)\n       : ThreadPoolDevice(options, name, memory_limit, locality, allocator),\n@@ -114,14 +115,15 @@ class GPUCompatibleCPUDevice : public ThreadPoolDevice {\n // The associated factory.\n class GPUCompatibleCPUDeviceFactory : public DeviceFactory {\n  public:\n-  Status ListPhysicalDevices(std::vector<string>* devices) override {\n+  absl::Status ListPhysicalDevices(std::vector<std::string>* devices) override {\n     devices->push_back(\"/physical_device:CPU:0\");\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n-  Status CreateDevices(const SessionOptions& options, const string& name_prefix,\n-                       std::vector<std::unique_ptr<Device>>* devices) override {\n+  absl::Status CreateDevices(\n+      const SessionOptions& options, const std::string& name_prefix,\n+      std::vector<std::unique_ptr<Device>>* devices) override {\n     int n = 1;\n     auto iter = options.config.device_count().find(\"CPU\");\n     if (iter != options.config.device_count().end()) {\n@@ -131,7 +133,7 @@ class GPUCompatibleCPUDeviceFactory : public DeviceFactory {\n                              ? port::NUMANumNodes()\n                              : 1;\n     for (int i = 0; i < n; i++) {\n-      string name = strings::StrCat(name_prefix, \"/device:CPU:\", i);\n+      std::string name = absl::StrCat(name_prefix, \"/device:CPU:\", i);\n       int numa_node = i % num_numa_nodes;\n       DeviceLocality locality;\n       locality.set_numa_node(numa_node);\n@@ -140,7 +142,7 @@ class GPUCompatibleCPUDeviceFactory : public DeviceFactory {\n           ProcessState::singleton()->GetCPUAllocator(numa_node)));\n     }\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n };\n REGISTER_LOCAL_DEVICE_FACTORY(\"CPU\", GPUCompatibleCPUDeviceFactory, 70);"
        },
        {
            "sha": "f191c8f32b082fe444228b06d76984d4b714c1be",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_device_test.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 24,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_device_test.cc?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -76,7 +76,7 @@ bool IsRocm() {\n       .IsRocm();\n }\n \n-void ExpectErrorMessageSubstr(const Status& s, StringPiece substr) {\n+void ExpectErrorMessageSubstr(const absl::Status& s, absl::string_view substr) {\n   EXPECT_TRUE(absl::StrContains(s.ToString(), substr))\n       << s << \", expected substring \" << substr;\n }\n@@ -92,12 +92,12 @@ class GPUDeviceTest : public ::testing::Test {\n \n  protected:\n   static SessionOptions MakeSessionOptions(\n-      const string& visible_device_list = \"\",\n+      const std::string& visible_device_list = \"\",\n       double per_process_gpu_memory_fraction = 0, int gpu_device_count = 1,\n       const std::vector<std::vector<float>>& memory_limit_mb = {},\n-      const std::vector<std::vector<int32>>& priority = {},\n-      const std::vector<std::vector<int32>>& device_ordinal = {},\n-      const int32 num_virtual_devices = 0,\n+      const std::vector<std::vector<int32_t>>& priority = {},\n+      const std::vector<std::vector<int32_t>>& device_ordinal = {},\n+      const int32_t num_virtual_devices = 0,\n       const bool use_cuda_malloc_async = false) {\n     SessionOptions options;\n     ConfigProto* config = &options.config;\n@@ -178,7 +178,7 @@ TEST_F(GPUDeviceTest, CudaMallocAsync) {\n   SessionOptions opts = MakeSessionOptions(\"0\", 0, 1, {}, {}, {}, 0,\n                                            /*use_cuda_malloc_async=*/true);\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status;\n+  absl::Status status;\n   int number_instantiated =\n       se::GpuCudaMallocAsyncAllocator::GetInstantiatedCountTestOnly();\n   {  // The new scope is to trigger the destruction of the object.\n@@ -209,7 +209,7 @@ TEST_F(GPUDeviceTest, CudaMallocAsyncPreallocate) {\n                                            /*use_cuda_malloc_async=*/true);\n   setenv(\"TF_CUDA_MALLOC_ASYNC_SUPPORTED_PREALLOC\", \"2048\", 1);\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status;\n+  absl::Status status;\n \n   int number_instantiated =\n       se::GpuCudaMallocAsyncAllocator::GetInstantiatedCountTestOnly();\n@@ -240,7 +240,7 @@ TEST_F(GPUDeviceTest, CudaMallocAsyncPreallocate) {\n TEST_F(GPUDeviceTest, FailedToParseVisibleDeviceList) {\n   SessionOptions opts = MakeSessionOptions(\"0,abc\");\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n   ExpectErrorMessageSubstr(status, \"Could not parse entry\");\n@@ -249,7 +249,7 @@ TEST_F(GPUDeviceTest, FailedToParseVisibleDeviceList) {\n TEST_F(GPUDeviceTest, InvalidGpuId) {\n   SessionOptions opts = MakeSessionOptions(\"100\");\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n   ExpectErrorMessageSubstr(status,\n@@ -259,7 +259,7 @@ TEST_F(GPUDeviceTest, InvalidGpuId) {\n TEST_F(GPUDeviceTest, DuplicateEntryInVisibleDeviceList) {\n   SessionOptions opts = MakeSessionOptions(\"0,0\");\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n   ExpectErrorMessageSubstr(status,\n@@ -269,7 +269,7 @@ TEST_F(GPUDeviceTest, DuplicateEntryInVisibleDeviceList) {\n TEST_F(GPUDeviceTest, VirtualDeviceConfigConflictsWithMemoryFractionSettings) {\n   SessionOptions opts = MakeSessionOptions(\"0\", 0.1, 1, {{}});\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n   ExpectErrorMessageSubstr(\n@@ -281,7 +281,7 @@ TEST_F(GPUDeviceTest, GpuDeviceCountTooSmall) {\n   // (empty) VirtualDevices messages.\n   SessionOptions opts = MakeSessionOptions(\"0\", 0, 0, {{}});\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::UNKNOWN);\n   ExpectErrorMessageSubstr(status,\n@@ -293,7 +293,7 @@ TEST_F(GPUDeviceTest, NotEnoughGpuInVisibleDeviceList) {\n   // messages.\n   SessionOptions opts = MakeSessionOptions(\"0\", 0, 8, {{}, {}});\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::UNKNOWN);\n   ExpectErrorMessageSubstr(status,\n@@ -307,7 +307,7 @@ TEST_F(GPUDeviceTest, VirtualDeviceConfigConflictsWithVisibleDeviceList) {\n   // messages.\n   SessionOptions opts = MakeSessionOptions(\"0,1\", 0, 8, {{}});\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n   ExpectErrorMessageSubstr(\n@@ -376,7 +376,7 @@ TEST_F(GPUDeviceTest, SingleVirtualDeviceWithInvalidPriority) {\n         MakeSessionOptions(\"0\", 0, 1, {{123, 456}}, {{-9999, 0}});\n #endif\n     std::vector<std::unique_ptr<Device>> devices;\n-    Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+    absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n         opts, kDeviceNamePrefix, &devices);\n     EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n #if TENSORFLOW_USE_ROCM\n@@ -399,7 +399,7 @@ TEST_F(GPUDeviceTest, SingleVirtualDeviceWithInvalidPriority) {\n     SessionOptions opts = MakeSessionOptions(\"0\", 0, 1, {{123, 456}}, {{0, 1}});\n #endif\n     std::vector<std::unique_ptr<Device>> devices;\n-    Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+    absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n         opts, kDeviceNamePrefix, &devices);\n     EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n #if TENSORFLOW_USE_ROCM\n@@ -457,7 +457,7 @@ TEST_F(GPUDeviceTest, MultipleVirtualDevicesWithPriority) {\n     // 0 is a valid priority value for both AMD and NVidia GPUs\n     SessionOptions opts = MakeSessionOptions(\"0\", 0, 1, {{123, 456}}, {{0}});\n     std::vector<std::unique_ptr<Device>> devices;\n-    Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+    absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n         opts, kDeviceNamePrefix, &devices);\n     EXPECT_EQ(status.code(), error::INVALID_ARGUMENT);\n     ExpectErrorMessageSubstr(\n@@ -546,7 +546,7 @@ TEST_F(GPUDeviceTest, UnifiedMemoryUnavailableOnPrePascalGpus) {\n       ->mutable_experimental()\n       ->set_use_unified_memory(true);\n   std::vector<std::unique_ptr<Device>> devices;\n-  Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n+  absl::Status status = DeviceFactory::GetFactory(\"GPU\")->CreateDevices(\n       opts, kDeviceNamePrefix, &devices);\n   EXPECT_EQ(status.code(), error::INTERNAL);\n   ExpectErrorMessageSubstr(status, \"does not support oversubscription.\");\n@@ -611,7 +611,7 @@ TEST_F(GPUDeviceTest, CopyTensorInSameDevice) {\n   CopyCPUToGPU(&cpu_tensor, &input_tensor, device, device_context);\n   absl::Notification note;\n   device->CopyTensorInSameDevice(&input_tensor, &output_tensor, device_context,\n-                                 [&note](const Status& s) {\n+                                 [&note](const absl::Status& s) {\n                                    TF_ASSERT_OK(s);\n                                    note.Notify();\n                                  });\n@@ -629,11 +629,11 @@ TEST_F(GPUDeviceTest, CopyTensorInSameDevice) {\n \n TEST_F(GPUDeviceTest, DeviceDetails) {\n   DeviceFactory* factory = DeviceFactory::GetFactory(\"GPU\");\n-  std::vector<string> devices;\n+  std::vector<std::string> devices;\n   TF_ASSERT_OK(factory->ListPhysicalDevices(&devices));\n   EXPECT_GE(devices.size(), 1);\n   for (int i = 0; i < devices.size(); i++) {\n-    std::unordered_map<string, string> details;\n+    std::unordered_map<std::string, std::string> details;\n     TF_ASSERT_OK(factory->GetDeviceDetails(i, &details));\n     EXPECT_NE(details[\"device_name\"], \"\");\n #if TENSORFLOW_USE_ROCM\n@@ -669,7 +669,7 @@ class GPUKernelTrackerTest : public ::testing::Test {\n                                                nullptr));\n   }\n \n-  void RecordQueued(uint64 v) {\n+  void RecordQueued(uint64_t v) {\n     mutex_lock l(kernel_tracker_->mu_);\n     kernel_tracker_->RecordQueued(v, 1);\n   }\n@@ -686,7 +686,7 @@ TEST_F(GPUKernelTrackerTest, CappingOnly) {\n \n   std::deque<int64_t> queued_counts;\n   for (int i = 0; i < 32; ++i) {\n-    uint64 queued_count = timing_counter_->next();\n+    uint64_t queued_count = timing_counter_->next();\n     queued_counts.push_back(queued_count);\n     RecordQueued(queued_count);\n   }\n@@ -708,7 +708,7 @@ TEST_F(GPUKernelTrackerTest, CappingOnly) {\n   // to introduce gaps between last_completed_ and first_available_.\n   int64_t lower_bound = timing_counter_->get();\n   for (int i = 0; i < 1111; ++i) {\n-    uint64 queued_count = timing_counter_->next();\n+    uint64_t queued_count = timing_counter_->next();\n     queued_counts.push_back(queued_count);\n     RecordQueued(queued_count);\n     int64_t upper_bound = timing_counter_->get();"
        },
        {
            "sha": "15fd92a873bea09509869555293bd881f79821dc",
            "filename": "tensorflow/core/common_runtime/gpu/gpu_process_state.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_process_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_process_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fgpu_process_state.cc?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -122,11 +122,11 @@ static std::unique_ptr<SubAllocator> CreateSubAllocator(\n                              options.experimental().use_unified_memory());\n   if (use_unified_memory) {\n     auto unified_memory_allocator =\n-        executor->CreateMemoryAllocator(stream_executor::MemoryType::kUnified)\n+        executor->CreateMemoryAllocator(stream_executor::MemorySpace::kUnified)\n             .value();\n     return std::make_unique<se::StreamExecutorAllocator>(\n         std::move(unified_memory_allocator),\n-        stream_executor::MemoryType::kUnified, platform_device_id.value(),\n+        stream_executor::MemorySpace::kUnified, platform_device_id.value(),\n         alloc_visitors);\n   } else {\n     return std::make_unique<se::DeviceMemAllocator>(\n@@ -140,7 +140,7 @@ Allocator* GPUProcessState::GetGPUAllocator(\n   CHECK(process_state_);\n #if (defined(GOOGLE_CUDA) && GOOGLE_CUDA) || \\\n     (defined(TENSORFLOW_USE_ROCM) && TENSORFLOW_USE_ROCM)\n-  const string& allocator_type = options.allocator_type();\n+  const std::string& allocator_type = options.allocator_type();\n   mutex_lock lock(mu_);\n   tsl::CheckValidTfDeviceId(\n       DEVICE_GPU, se::GPUMachineManager()->VisibleDeviceCount(), tf_device_id);\n@@ -172,7 +172,7 @@ Allocator* GPUProcessState::GetGPUAllocator(\n \n     auto gpu_bfc_allocator = std::make_unique<GPUBFCAllocator>(\n         std::move(sub_allocator), total_bytes,\n-        strings::StrCat(\"GPU_\", tf_device_id.value(), \"_bfc\"), [&] {\n+        absl::StrCat(\"GPU_\", tf_device_id.value(), \"_bfc\"), [&] {\n           GPUBFCAllocator::Options o;\n           o.allow_growth = options.allow_growth();\n           o.allow_retry_on_failure =\n@@ -366,9 +366,9 @@ Allocator* GPUProcessState::GetGpuHostAllocator(const GPUOptions& options,\n       gpu_host_free_visitors_.push_back({});\n     }\n     auto host_memory_allocator =\n-        se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+        se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n     SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-        std::move(host_memory_allocator), stream_executor::MemoryType::kHost,\n+        std::move(host_memory_allocator), stream_executor::MemorySpace::kHost,\n         numa_node, gpu_host_alloc_visitors_[numa_node],\n         gpu_host_free_visitors_[numa_node]);\n "
        },
        {
            "sha": "954658e1111a4c9a0a1f73bdabc02f51164461f2",
            "filename": "tensorflow/core/common_runtime/gpu/pool_allocator_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fpool_allocator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/818e61079e341f265462be2e8634b02141ef84a9/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fpool_allocator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fgpu%2Fpool_allocator_test.cc?ref=818e61079e341f265462be2e8634b02141ef84a9",
            "patch": "@@ -30,9 +30,9 @@ TEST(PoolAllocatorTest, ZeroSizeBuffers) {\n       se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n   se::StreamExecutor* se = platform->ExecutorForDevice(/*ordinal=*/0).value();\n   auto host_memory_allocator =\n-      se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+      se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n   SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-      std::move(host_memory_allocator), stream_executor::MemoryType::kHost, 0);\n+      std::move(host_memory_allocator), stream_executor::MemorySpace::kHost, 0);\n   PoolAllocator pool(2 /*pool_size_limit*/, false /*auto_resize*/,\n                      sub_allocator, new NoopRounder, \"pool\");\n \n@@ -49,9 +49,9 @@ TEST(PoolAllocatorTest, ZeroSizePool) {\n       se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n   se::StreamExecutor* se = platform->ExecutorForDevice(/*ordinal=*/0).value();\n   auto host_memory_allocator =\n-      se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+      se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n   SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-      std::move(host_memory_allocator), stream_executor::MemoryType::kHost, 0);\n+      std::move(host_memory_allocator), stream_executor::MemorySpace::kHost, 0);\n   PoolAllocator pool(0 /*pool_size_limit*/, false /*auto_resize*/,\n                      sub_allocator, new NoopRounder, \"pool\");\n \n@@ -83,9 +83,9 @@ TEST(PoolAllocatorTest, Alignment) {\n       se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n   se::StreamExecutor* se = platform->ExecutorForDevice(/*ordinal=*/0).value();\n   auto host_memory_allocator =\n-      se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+      se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n   SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-      std::move(host_memory_allocator), stream_executor::MemoryType::kHost, 0);\n+      std::move(host_memory_allocator), stream_executor::MemorySpace::kHost, 0);\n   PoolAllocator pool(0 /*pool_size_limit*/, false /*auto_resize*/,\n                      sub_allocator, new NoopRounder, \"pool\");\n   for (int i = 0; i < 16; ++i) {\n@@ -145,9 +145,9 @@ TEST(PoolAllocatorTest, CudaHostAllocator) {\n       se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n   se::StreamExecutor* se = platform->ExecutorForDevice(/*ordinal=*/0).value();\n   auto host_memory_allocator =\n-      se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+      se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n   SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-      std::move(host_memory_allocator), stream_executor::MemoryType::kHost, 0,\n+      std::move(host_memory_allocator), stream_executor::MemorySpace::kHost, 0,\n       {alloc_visitor}, {free_visitor});\n   PoolAllocator pool(2 /*pool_size_limit*/, false /*auto_resize*/,\n                      sub_allocator, new NoopRounder, \"pool\");\n@@ -250,9 +250,9 @@ TEST(PoolAllocatorTest, Name) {\n       se::PlatformManager::PlatformWithName(se::GpuPlatformName()).value();\n   se::StreamExecutor* se = platform->ExecutorForDevice(/*ordinal=*/0).value();\n   auto host_memory_allocator =\n-      se->CreateMemoryAllocator(stream_executor::MemoryType::kHost).value();\n+      se->CreateMemoryAllocator(stream_executor::MemorySpace::kHost).value();\n   SubAllocator* sub_allocator = new se::StreamExecutorAllocator(\n-      std::move(host_memory_allocator), stream_executor::MemoryType::kHost, 0);\n+      std::move(host_memory_allocator), stream_executor::MemorySpace::kHost, 0);\n   PoolAllocator pool(2 /*pool_size_limit*/, false /*auto_resize*/,\n                      sub_allocator, new NoopRounder, \"pool\");\n   EXPECT_EQ(\"pool\", pool.Name());"
        }
    ],
    "stats": {
        "total": 246,
        "additions": 126,
        "deletions": 120
    }
}