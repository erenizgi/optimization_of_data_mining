{
    "author": "loislo",
    "message": "[XLA:GPU] Specialize buffer debug float check thunk.\n\nThis change introduces a custom `BufferDebugFloatCheckEntry` for float checking, allowing for more specific data to be logged (e.g., `nan_count`). The metadata store is updated with a batch lookup function to efficiently retrieve metadata for multiple entries. The custom call targets are also renamed to better reflect their purpose.\n\nPiperOrigin-RevId: 830820450",
    "sha": "b97df3e433a0a2e668b83eea7e969f82cf2529f6",
    "files": [
        {
            "sha": "949a6ae1fcea67671b55c8db1ea7274c169cf50a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -48,6 +48,18 @@ BufferDebugLogEntryMetadataStore::GetEntryMetadata(\n   return GetEntryMetadataLocked(entry_id);\n }\n \n+std::vector<std::optional<BufferDebugLogEntryMetadataStore::Metadata>>\n+BufferDebugLogEntryMetadataStore::GetEntryMetadataBatch(\n+    absl::Span<const BufferDebugLogEntryId> entry_ids) {\n+  absl::MutexLock lock{mutex_};\n+  std::vector<std::optional<Metadata>> result;\n+  result.reserve(entry_ids.size());\n+  for (BufferDebugLogEntryId entry_id : entry_ids) {\n+    result.push_back(GetEntryMetadataLocked(entry_id));\n+  }\n+  return result;\n+}\n+\n std::optional<BufferDebugLogEntryMetadataStore::Metadata>\n BufferDebugLogEntryMetadataStore::GetEntryMetadataLocked(\n     BufferDebugLogEntryId entry_id) {"
        },
        {
            "sha": "d15f9970eeb87bd30beb062e38844780105ed73e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_entry_metadata_store.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_entry_metadata_store.h?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -80,6 +80,12 @@ class BufferDebugLogEntryMetadataStore {\n   std::optional<Metadata> GetEntryMetadata(BufferDebugLogEntryId entry_id)\n       ABSL_LOCKS_EXCLUDED(mutex_);\n \n+  // Returns the metadata for the entries with `entry_ids` previously\n+  // returned by `AssignId`, or `std::nullopt` if the ID is invalid.\n+  std::vector<std::optional<Metadata>> GetEntryMetadataBatch(\n+      absl::Span<const BufferDebugLogEntryId> entry_ids)\n+      ABSL_LOCKS_EXCLUDED(mutex_);\n+\n   // Converts a list of `entries` with IDs assigned by this store to a\n   // `BufferDebugLogProto` with additional metadata.\n   BufferDebugLogProto EntriesToProto("
        },
        {
            "sha": "9c660b0282e6145f821b86b5d37a3bce2b5d7b96",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_structs.h",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -54,6 +54,35 @@ static_assert(sizeof(BufferDebugLogEntry) == sizeof(uint32_t) * 2);\n static_assert(offsetof(BufferDebugLogEntry, entry_id) == 0);\n static_assert(offsetof(BufferDebugLogEntry, value) == sizeof(uint32_t));\n \n+struct BufferDebugFloatCheckEntry {\n+  // An ID that uniquely identifies a log entry within a HLO module execution.\n+  BufferDebugLogEntryId entry_id;\n+  uint32_t nan_count;\n+\n+  template <typename Sink>\n+  friend void AbslStringify(Sink& sink,\n+                            const BufferDebugFloatCheckEntry& entry) {\n+    absl::Format(&sink, \"{entry_id: %v, nan_count: %u}\", entry.entry_id.value(),\n+                 entry.nan_count);\n+  }\n+\n+  bool operator==(const BufferDebugFloatCheckEntry& other) const {\n+    return std::tie(entry_id, nan_count) ==\n+           std::tie(other.entry_id, other.nan_count);\n+  }\n+\n+  bool operator!=(const BufferDebugFloatCheckEntry& other) const {\n+    return !(*this == other);\n+  }\n+};\n+\n+// The struct layout must match on both host and device.\n+static_assert(_Alignof(BufferDebugFloatCheckEntry) == _Alignof(uint32_t));\n+static_assert(sizeof(BufferDebugFloatCheckEntry) == sizeof(uint32_t) * 2);\n+static_assert(offsetof(BufferDebugFloatCheckEntry, entry_id) == 0);\n+static_assert(offsetof(BufferDebugFloatCheckEntry, nan_count) ==\n+              sizeof(uint32_t));\n+\n struct BufferDebugLogHeader {\n   // The first entry in `BufferDebugLogEntry` following the header that has not\n   // been written to. May be bigger than `capacity` if the log was truncated."
        },
        {
            "sha": "460b4faf0cf9c3e3a3c6eef10a7e4e06c92da051",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_float_check_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_float_check_thunk.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -131,15 +131,15 @@ absl::Status BuffersDebugFloatCheckThunk::ExecuteOnStream(\n       TF_RETURN_IF_ERROR(kernels->f32.Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           f32_buffer, f32_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n+          buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n     } else if (buffer_type == PrimitiveType::BF16) {\n       VLOG(1) << \"BF16 buffer detected with id: \" << entry_id\n               << \" and size: \" << device_buffer.size();\n       se::DeviceMemory<Eigen::bfloat16> bf16_buffer(device_buffer);\n       TF_RETURN_IF_ERROR(kernels->bf16.Launch(\n           thread_dim, se::BlockDim(1, 1, 1), params.stream, entry_id,\n           bf16_buffer, bf16_buffer.size(), buffer_debug_log.GetDeviceHeader(),\n-          buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n+          buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n     } else {\n       VLOG(1) << \"Unsupported primitive type for float checking: \"\n               << PrimitiveType_Name(buffer_type);"
        },
        {
            "sha": "982ae9705ab2b8adfbdfc237537acf12b040d8b4",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_float_check.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 21,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_float_check.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <cstddef>\n #include <cstring>\n #include <memory>\n+#include <optional>\n #include <string>\n #include <utility>\n #include <vector>\n@@ -46,7 +47,6 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n-#include \"xla/service/dump.h\"\n #include \"xla/shape.h\"\n #include \"xla/stream_executor/gpu/buffer_debug_log.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -57,7 +57,8 @@ namespace xla::gpu {\n \n namespace se = stream_executor;\n \n-// With BufferDebugLogEntry size of 8 bytes, this is enough to hold ~8K entries.\n+// With BufferDebugFloatCheckEntry size of 8 bytes, this is enough to hold ~8K\n+// entries.\n constexpr size_t kLogSizeBytes = 64 * 1024;\n \n namespace {\n@@ -144,28 +145,39 @@ absl::Status BufferDebugFloatCheck(\n   VLOG(1) << \"HLO module ptr: \" << hlo_module;\n   VLOG(1) << \"HLO module name: \" << hlo_module->name();\n   CHECK(hlo_module != nullptr);\n-  const DebugOptions& debug_options = hlo_module->config().debug_options();\n \n   se::gpu::BufferDebugLog buffer_debug_log =\n       se::gpu::BufferDebugLog::FromDeviceMemoryUnchecked(\n           log_buffer.device_memory());\n   TF_ASSIGN_OR_RETURN(\n-      std::vector<BufferDebugLogEntry> log_entries,\n-      buffer_debug_log.ReadFromDevice<BufferDebugLogEntry>(*stream));\n-  BufferDebugLogProto buffer_debug_log_proto =\n-      metadata_store->EntriesToProto(log_entries);\n-\n-  VLOG(1) << \"read \" << buffer_debug_log_proto.entries_size() << \" entries\";\n-  DumpPerExecutionProtobufToFile(*hlo_module, buffer_debug_log_proto,\n-                                 debug_options, \"buffer_debug_log\", nullptr);\n+      std::vector<BufferDebugFloatCheckEntry> entries,\n+      buffer_debug_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream));\n+\n+  std::vector<BufferDebugLogEntryId> entry_ids;\n+  entry_ids.reserve(entries.size());\n+  for (const auto& entry : entries) {\n+    entry_ids.push_back(entry.entry_id);\n+  }\n+\n+  VLOG(1) << \"read \" << entries.size() << \" entries\";\n+  auto entries_metadata = metadata_store->GetEntryMetadataBatch(entry_ids);\n   int non_zero_float_check_modules_count = 0;\n-  for (const auto& entry : buffer_debug_log_proto.entries()) {\n-    if (entry.check_type() ==\n+  CHECK_EQ(entries.size(), entries_metadata.size());\n+\n+  for (int i = 0; i < entries.size(); ++i) {\n+    const auto& entry = entries[i];\n+    const auto& metadata = entries_metadata[i];\n+    if (!metadata.has_value()) {\n+      LOG(WARNING) << \"Entry ID \" << entry.entry_id\n+                   << \" for float check not found in metadata\";\n+      continue;\n+    }\n+    if (metadata->check_type ==\n             BufferDebugLogEntryProto::CHECK_TYPE_FLOAT_CHECKS &&\n-        entry.checksum() > 0) {\n+        entry.nan_count > 0) {\n       LOG(ERROR) << \"Found entry with non zero float check count \"\n-                 << entry.checksum() << \" for thunk \" << entry.thunk_id()\n-                 << \" and execution \" << entry.execution_id()\n+                 << entry.nan_count << \" for thunk \" << entry.entry_id\n+                 << \" and execution \" << metadata->execution_id\n                  << \" for module: \\n\"\n                  << hlo_module->ToString();\n       non_zero_float_check_modules_count++;\n@@ -183,7 +195,8 @@ absl::Status BufferDebugFloatCheck(\n XLA_FFI_DEFINE_HANDLER_SYMBOL(\n     kBufferDebugFloatCheckLogInitHandler,\n     [](se::Stream* absl_nonnull stream, xla::ffi::Buffer<U8> log_buffer) {\n-      return se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(\n+      return se::gpu::BufferDebugLog::CreateOnDevice<\n+                 xla::gpu::BufferDebugFloatCheckEntry>(\n                  *stream, log_buffer.device_memory())\n           .status();\n     },\n@@ -200,12 +213,13 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CreateDebugInitThunk(\n   XLA_FFI_Handler_Bundle buffer_debug_init_bundle{};\n   buffer_debug_init_bundle.execute = kBufferDebugFloatCheckLogInitHandler;\n   return CustomCallThunk::Create(\n-      Thunk::ThunkInfo(), \"xla_gpu_buffer_debug_log_init\",\n+      Thunk::ThunkInfo(), \"xla_gpu_buffer_debug_float_check_init\",\n       buffer_debug_init_bundle, /*operands=*/{shaped_log_slice},\n       /*results=*/{}, /*attributes=*/{}, hlo_module->entry_computation());\n }\n \n-absl::StatusOr<std::unique_ptr<CustomCallThunk>> CreateBufferDebugDumpThunk(\n+absl::StatusOr<std::unique_ptr<CustomCallThunk>>\n+CreateBufferDebugFloatCheckThunk(\n     std::shared_ptr<BufferDebugLogEntryMetadataStore> metadata_store,\n     BufferAllocation::Slice log_slice,\n     const HloModule* absl_nonnull hlo_module) {\n@@ -222,7 +236,7 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CreateBufferDebugDumpThunk(\n           .Arg<xla::ffi::Buffer<U8>>()\n           .To(absl::bind_front(BufferDebugFloatCheck, metadata_store));\n   return CustomCallThunk::Create(\n-      Thunk::ThunkInfo(), \"xla_gpu_buffer_debug_log_dump\",\n+      Thunk::ThunkInfo(), \"xla_gpu_buffer_debug_float_check\",\n       std::move(float_check_bundle),\n       /*operands=*/{shaped_log_slice},\n       /*results=*/{}, /*attributes=*/{}, hlo_module->entry_computation());\n@@ -246,7 +260,7 @@ absl::Status RunFloatCheckPassInternal(SequentialThunk* root_thunk,\n \n   TF_ASSIGN_OR_RETURN(\n       auto buffer_debug_dump_thunk,\n-      CreateBufferDebugDumpThunk(metadata_store, log_slice, hlo_module));\n+      CreateBufferDebugFloatCheckThunk(metadata_store, log_slice, hlo_module));\n \n   ThunkFilter thunk_filter = CreateThunkFilter(debug_options);\n   root_thunk->TransformAllNestedThunks([&](std::unique_ptr<Thunk> thunk) {"
        },
        {
            "sha": "03273b16dfcf8846a8a45fa1fb86e27cc76536db",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -501,12 +501,12 @@ TEST_F(ThunkBufferDebugPassTest, InsertsBuffersDebugFloatCheckThunks) {\n   const CustomCallThunk& buffer_debug_init_thunk =\n       static_cast<const CustomCallThunk&>(*new_thunks[0]);\n   EXPECT_EQ(buffer_debug_init_thunk.target_name(),\n-            \"xla_gpu_buffer_debug_log_init\");\n+            \"xla_gpu_buffer_debug_float_check_init\");\n \n   const CustomCallThunk& buffer_debug_dump_thunk =\n       static_cast<const CustomCallThunk&>(*new_thunks[2]);\n   EXPECT_EQ(buffer_debug_dump_thunk.target_name(),\n-            \"xla_gpu_buffer_debug_log_dump\");\n+            \"xla_gpu_buffer_debug_float_check\");\n \n   const std::vector<std::unique_ptr<Thunk>>& sub_thunks =\n       static_cast<const SequentialThunk&>(*new_thunks[1]).thunks();"
        },
        {
            "sha": "be040ab8bce65ed9569178ff80dd7e4f6dd26a80",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda.cu.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda.cu.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -108,8 +108,9 @@ __device__ void ReduceSum(const T* input, uint64_t input_size,\n   if (tid == 0) *output = scratch[0];\n }\n \n-// Attempts to append the NaN count of the `input` buffer to the `log_entries`,\n-// using `log_header` to track available capacity and used space.\n+// Attempts to append the NaN count of the `input` buffer to the\n+// `float_check_entries`, using `log_header` to track available capacity and\n+// used space.\n //\n // The log entry is tagged with `entry_id`. The NaN count is parallelized as\n // much as block dimensions allow it.\n@@ -123,10 +124,10 @@ __device__ void ReduceSum(const T* input, uint64_t input_size,\n // - Only a single thread block is supported.\n // - Block dimensions must be a power of 2.\n template <typename T>\n-__global__ void AppendFloatCheck(xla::gpu::BufferDebugLogEntryId entry_id,\n-                                 const T* input, uint64_t input_size_in_bytes,\n-                                 xla::gpu::BufferDebugLogHeader* log_header,\n-                                 xla::gpu::BufferDebugLogEntry* log_entries) {\n+__global__ void AppendFloatCheck(\n+    xla::gpu::BufferDebugLogEntryId entry_id, const T* input,\n+    uint64_t input_size_in_bytes, xla::gpu::BufferDebugLogHeader* log_header,\n+    xla::gpu::BufferDebugFloatCheckEntry* float_check_entries) {\n   const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n   const uint64_t input_size = input_size_in_bytes / sizeof(T);\n   uint32_t nan_count = 0;\n@@ -185,7 +186,8 @@ __global__ void AppendFloatCheck(xla::gpu::BufferDebugLogEntryId entry_id,\n #if __CUDA_ARCH__ >= 600\n     const uint32_t write_idx = nan_count_log_write_idx.fetch_add(1);\n     if (nan_count_log_write_idx.load() < log_header->capacity) {\n-      log_entries[write_idx] = {entry_id, nan_count};\n+      float_check_entries[write_idx] =\n+          xla::gpu::BufferDebugFloatCheckEntry{entry_id, nan_count};\n     }\n #else\n     // Our toolchains generate a fetch_add PTX instructions with system scope,"
        },
        {
            "sha": "f224a8b1487963782789273faf1bd42b8dfcd701",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_float_check_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 15,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_float_check_kernel_cuda_test.cc?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -49,7 +49,7 @@ namespace se = stream_executor;\n namespace stream_executor::cuda {\n namespace {\n \n-using xla::gpu::BufferDebugLogEntry;\n+using xla::gpu::BufferDebugFloatCheckEntry;\n using xla::gpu::BufferDebugLogEntryId;\n using xla::gpu::ThunkId;\n \n@@ -106,7 +106,7 @@ class FloatCheckKernelTest : public ::testing::Test {\n         dim, stream_executor::BlockDim(1, 1, 1), stream_.get(), entry_id,\n         device_input, device_input.ElementCount() * sizeof(T),\n         buffer_debug_log.GetDeviceHeader(),\n-        buffer_debug_log.GetDeviceEntries<BufferDebugLogEntry>()));\n+        buffer_debug_log.GetDeviceEntries<BufferDebugFloatCheckEntry>()));\n     TF_RETURN_IF_ERROR(stream_->BlockHostUntilDone());\n \n     // The result gets stored in `buffer_debug_log`.\n@@ -125,16 +125,17 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForF32) {\n                               2.0f, std::numeric_limits<float>::quiet_NaN()};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n-                                                                   mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+          *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{123}, input, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+      auto host_log,\n+      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].value, 2);\n+  EXPECT_EQ(host_log[0].nan_count, 2);\n }\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n@@ -146,16 +147,17 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsForBf16) {\n       xla::bfloat16(std::numeric_limits<float>::quiet_NaN())};\n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n-                                                                   mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+          *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckBf16Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+      auto host_log,\n+      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].value, 2);\n+  EXPECT_EQ(host_log[0].nan_count, 2);\n }\n \n TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n@@ -167,19 +169,20 @@ TEST_F(FloatCheckKernelTest, ChecksFloatsInParallel) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       se::gpu::BufferDebugLog device_log,\n-      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugLogEntry>(*stream_,\n-                                                                   mem));\n+      se::gpu::BufferDebugLog::CreateOnDevice<BufferDebugFloatCheckEntry>(\n+          *stream_, mem));\n \n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n   TF_EXPECT_OK(AppendFloatCheckOnDevice<gpu::BufferDebugFloatCheckF32Kernel>(\n       BufferDebugLogEntryId{0}, input, device_log, se::ThreadDim(2, 4, 8)));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      auto host_log, device_log.ReadFromDevice<BufferDebugLogEntry>(*stream_));\n+      auto host_log,\n+      device_log.ReadFromDevice<BufferDebugFloatCheckEntry>(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n-  EXPECT_EQ(host_log[0].value, 3);\n-  EXPECT_EQ(host_log[1].value, 3);\n+  EXPECT_EQ(host_log[0].nan_count, 3);\n+  EXPECT_EQ(host_log[1].nan_count, 3);\n }\n \n }  // namespace"
        },
        {
            "sha": "6c2d84c9613262b18fc067bc802f8506ef478ad8",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_float_check_kernel.h",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_float_check_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b97df3e433a0a2e668b83eea7e969f82cf2529f6/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_float_check_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_float_check_kernel.h?ref=b97df3e433a0a2e668b83eea7e969f82cf2529f6",
            "patch": "@@ -33,14 +33,15 @@ struct BufferDebugFloatCheckF32Kernel {\n   using KernelType =\n       TypedKernel<xla::gpu::BufferDebugLogEntryId, DeviceMemory<float>,\n                   uint64_t, DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n-                  DeviceMemory<xla::gpu::BufferDebugLogEntry>>;\n+                  DeviceMemory<xla::gpu::BufferDebugFloatCheckEntry>>;\n };\n \n struct BufferDebugFloatCheckBf16Kernel {\n-  using KernelType = TypedKernel<xla::gpu::BufferDebugLogEntryId,\n-                                 DeviceMemory<Eigen::bfloat16>, uint64_t,\n-                                 DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n-                                 DeviceMemory<xla::gpu::BufferDebugLogEntry>>;\n+  using KernelType =\n+      TypedKernel<xla::gpu::BufferDebugLogEntryId,\n+                  DeviceMemory<Eigen::bfloat16>, uint64_t,\n+                  DeviceMemory<xla::gpu::BufferDebugLogHeader>,\n+                  DeviceMemory<xla::gpu::BufferDebugFloatCheckEntry>>;\n };\n \n }  // namespace stream_executor::gpu"
        }
    ],
    "stats": {
        "total": 171,
        "additions": 119,
        "deletions": 52
    }
}