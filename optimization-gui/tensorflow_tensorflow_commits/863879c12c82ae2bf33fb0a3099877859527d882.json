{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 848076929",
    "sha": "863879c12c82ae2bf33fb0a3099877859527d882",
    "files": [
        {
            "sha": "ef440aa870dfe309fe943a50b532cea287719849",
            "filename": "tensorflow/core/kernels/sparse/add_op.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 13,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fadd_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fadd_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fadd_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -281,17 +281,18 @@ struct CSRSparseMatrixAdd<GPUDevice, T>\n         beta_(beta),\n         initialized_(false) {}\n \n-  Status Initialize() {\n+  absl::Status Initialize() {\n     TF_RETURN_IF_ERROR(cuda_sparse_.Initialize());\n     TF_RETURN_IF_ERROR(descrA_.Initialize());\n     TF_RETURN_IF_ERROR(descrB_.Initialize());\n     TF_RETURN_IF_ERROR(descrC_.Initialize());\n     initialized_ = true;\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n-  Status GetWorkspaceSize(const ConstCSRComponent<T>& a,\n-                          const ConstCSRComponent<T>& b, size_t* bufferSize) {\n+  absl::Status GetWorkspaceSize(const ConstCSRComponent<T>& a,\n+                                const ConstCSRComponent<T>& b,\n+                                size_t* bufferSize) {\n     DCHECK(initialized_);\n \n     const int m = a.row_ptr.size() - 1;\n@@ -313,13 +314,13 @@ struct CSRSparseMatrixAdd<GPUDevice, T>\n         b.row_ptr.data(), b.col_ind.data(), descrC_.descr(), null_T, null_int,\n         null_int, bufferSize));\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n-  Status GetOutputStructure(const ConstCSRComponent<T>& a,\n-                            const ConstCSRComponent<T>& b,\n-                            TTypes<int32>::UnalignedVec c_row_ptr,\n-                            int* output_nnz, void* workspace) {\n+  absl::Status GetOutputStructure(const ConstCSRComponent<T>& a,\n+                                  const ConstCSRComponent<T>& b,\n+                                  TTypes<int32_t>::UnalignedVec c_row_ptr,\n+                                  int* output_nnz, void* workspace) {\n     DCHECK(initialized_);\n \n     const int m = a.row_ptr.size() - 1;\n@@ -343,11 +344,12 @@ struct CSRSparseMatrixAdd<GPUDevice, T>\n       return errors::Internal(\n           \"CSRAdd: CsrgeamNnz returned nnzTotalDevHostPtr < 0: \", *output_nnz);\n     }\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n-  Status Compute(const ConstCSRComponent<T>& a, const ConstCSRComponent<T>& b,\n-                 CSRComponent<T>* c, void* workspace) {\n+  absl::Status Compute(const ConstCSRComponent<T>& a,\n+                       const ConstCSRComponent<T>& b, CSRComponent<T>* c,\n+                       void* workspace) {\n     DCHECK(initialized_);\n \n     const int m = a.row_ptr.size() - 1;\n@@ -368,7 +370,7 @@ struct CSRSparseMatrixAdd<GPUDevice, T>\n         b.row_ptr.data(), b.col_ind.data(), descrC_.descr(), c->values.data(),\n         c->row_ptr.data(), c->col_ind.data(), workspace));\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n  private:"
        },
        {
            "sha": "311469571aaf9f267c78b9f800408c07fd7b5072",
            "filename": "tensorflow/core/kernels/sparse/csr_sparse_matrix_to_dense_op.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_dense_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_dense_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_dense_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -237,20 +237,20 @@ REGISTER_GPU(complex128)\n namespace functor {\n template <>\n struct COOSparseMatrixToSparseTensor<GPUDevice> {\n-  Status operator()(OpKernelContext* ctx,\n-                    TTypes<int64_t>::ConstVec host_dense_shape,\n-                    TTypes<int>::ConstVec host_batch_ptrs,\n-                    TTypes<int>::Vec coo_row_ind,\n-                    TTypes<int>::ConstVec coo_col_ind,\n-                    TTypes<int64_t>::Matrix indices);\n+  absl::Status operator()(OpKernelContext* ctx,\n+                          TTypes<int64_t>::ConstVec host_dense_shape,\n+                          TTypes<int>::ConstVec host_batch_ptrs,\n+                          TTypes<int>::Vec coo_row_ind,\n+                          TTypes<int>::ConstVec coo_col_ind,\n+                          TTypes<int64_t>::Matrix indices);\n };\n extern template struct COOSparseMatrixToSparseTensor<GPUDevice>;\n \n template <>\n struct CSRSparseMatrixToCOOSparseMatrix<GPUDevice> {\n-  Status operator()(OpKernelContext* c,\n-                    TTypes<const int>::UnalignedVec csr_row_ptr,\n-                    TTypes<int>::UnalignedVec coo_row_ind);\n+  absl::Status operator()(OpKernelContext* c,\n+                          TTypes<const int>::UnalignedVec csr_row_ptr,\n+                          TTypes<int>::UnalignedVec coo_row_ind);\n };\n extern template struct CSRSparseMatrixToCOOSparseMatrix<GPUDevice>;\n "
        },
        {
            "sha": "07448230f398fbf72843a33e30bf6f61d3c1e1c6",
            "filename": "tensorflow/core/kernels/sparse/csr_sparse_matrix_to_sparse_tensor_op.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_sparse_tensor_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_sparse_tensor_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fcsr_sparse_matrix_to_sparse_tensor_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -222,20 +222,20 @@ REGISTER_GPU(complex128)\n namespace functor {\n template <>\n struct COOSparseMatrixToSparseTensor<GPUDevice> {\n-  Status operator()(OpKernelContext* ctx,\n-                    TTypes<int64_t>::ConstVec host_dense_shape,\n-                    TTypes<int>::ConstVec host_batch_ptrs,\n-                    TTypes<int>::Vec coo_row_ind,\n-                    TTypes<int>::ConstVec coo_col_ind,\n-                    TTypes<int64_t>::Matrix indices);\n+  absl::Status operator()(OpKernelContext* ctx,\n+                          TTypes<int64_t>::ConstVec host_dense_shape,\n+                          TTypes<int>::ConstVec host_batch_ptrs,\n+                          TTypes<int>::Vec coo_row_ind,\n+                          TTypes<int>::ConstVec coo_col_ind,\n+                          TTypes<int64_t>::Matrix indices);\n };\n extern template struct COOSparseMatrixToSparseTensor<GPUDevice>;\n \n template <>\n struct CSRSparseMatrixToCOOSparseMatrix<GPUDevice> {\n-  Status operator()(OpKernelContext* c,\n-                    TTypes<const int>::UnalignedVec csr_row_ptr,\n-                    TTypes<int>::UnalignedVec coo_row_ind);\n+  absl::Status operator()(OpKernelContext* c,\n+                          TTypes<const int>::UnalignedVec csr_row_ptr,\n+                          TTypes<int>::UnalignedVec coo_row_ind);\n };\n extern template struct CSRSparseMatrixToCOOSparseMatrix<GPUDevice>;\n "
        },
        {
            "sha": "eda72f21e674f9c8a5deefc94548ac6c68cada8b",
            "filename": "tensorflow/core/kernels/sparse/dense_to_csr_sparse_matrix_op.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 20,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fdense_to_csr_sparse_matrix_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fdense_to_csr_sparse_matrix_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fdense_to_csr_sparse_matrix_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -174,7 +174,7 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n     const int64_t rows = dense_tensor_shape.dim_size((rank == 2) ? 0 : 1);\n     const int64_t cols = dense_tensor_shape.dim_size((rank == 2) ? 1 : 2);\n \n-    ScratchSpace<int32> nnz_per_batch_host(c, batch_size, /*on_host*/ true);\n+    ScratchSpace<int32_t> nnz_per_batch_host(c, batch_size, /*on_host*/ true);\n \n     Tensor nnz_per_batch_device_t;\n     if (rank == 2) {\n@@ -185,7 +185,7 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n                            c->allocate_temp(DT_INT32, TensorShape({batch_size}),\n                                             &nnz_per_batch_device_t),\n                            done);\n-      auto nnz_per_batch_device = nnz_per_batch_device_t.vec<int32>();\n+      auto nnz_per_batch_device = nnz_per_batch_device_t.vec<int32_t>();\n \n       functor::CalculateNNZPerBatchMatrixFromIndices<Device>\n           calculate_nnz_from_indices;\n@@ -194,14 +194,14 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n           c, calculate_nnz_from_indices(c, indices, nnz_per_batch_device),\n           done);\n \n-      stream_executor::DeviceMemoryBase nnz_per_batch_device_ptr(\n+      stream_executor::DeviceAddressBase nnz_per_batch_device_ptr(\n           static_cast<void*>(nnz_per_batch_device.data()));\n \n       OP_REQUIRES_OK_ASYNC(\n           c,\n           stream->Memcpy(nnz_per_batch_host.mutable_data() /*host_dst*/,\n                          nnz_per_batch_device_ptr /*gpu_src*/,\n-                         batch_size * sizeof(int32) /*size*/),\n+                         batch_size * sizeof(int32_t) /*size*/),\n           done);\n     }\n \n@@ -216,7 +216,7 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n       // tensor by the time we get here; we can unreference it.\n       nnz_per_batch_device_ref.Unref();\n \n-      auto nnz_per_batch = nnz_per_batch_host.tensor().vec<int32>();\n+      auto nnz_per_batch = nnz_per_batch_host.tensor().vec<int32_t>();\n \n       {\n         // Ensure that within the callback, the proper GPU settings are\n@@ -227,7 +227,7 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n         // Extract out the values.\n         Tensor temp_values_t;\n         OP_REQUIRES_OK_ASYNC(c,\n-                             (functor::DoGatherNd<Device, T, int64>(\n+                             (functor::DoGatherNd<Device, T, int64_t>(\n                                  c, params_t, indices_t, &temp_values_t)),\n                              done);\n         const Tensor& values_t = const_cast<const Tensor&>(temp_values_t);\n@@ -249,7 +249,7 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n \n         Tensor batch_ptr_t(cpu_allocator(), DT_INT32,\n                            TensorShape({batch_size + 1}));\n-        auto batch_ptr = batch_ptr_t.vec<int32>();\n+        auto batch_ptr = batch_ptr_t.vec<int32_t>();\n         auto indices = indices_t.matrix<int64_t>();\n \n         batch_ptr(0) = 0;\n@@ -286,9 +286,9 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n                              &csr_row_ptr_t),\n             done);\n \n-        auto coo_row_ind = coo_row_ind_t.vec<int32>();\n-        auto coo_col_ind = coo_col_ind_t.vec<int32>();\n-        auto csr_row_ptr = csr_row_ptr_t.vec<int32>();\n+        auto coo_row_ind = coo_row_ind_t.vec<int32_t>();\n+        auto coo_col_ind = coo_col_ind_t.vec<int32_t>();\n+        auto csr_row_ptr = csr_row_ptr_t.vec<int32_t>();\n \n         // Convert SparseTensor rep to coo row ind, coo col ind.\n         if (total_nnz > 0) {\n@@ -302,8 +302,8 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n         // a bug if you have empty coo rows.\n         // TODO(ebrevdo): File bug w/ nvidia so coo2csr can handle\n         // zero-element input coo rows.\n-        functor::SetZeroFunctor<Device, int32> set_zero;\n-        set_zero(d, csr_row_ptr_t.flat<int32>());\n+        functor::SetZeroFunctor<Device, int32_t> set_zero;\n+        set_zero(d, csr_row_ptr_t.flat<int32_t>());\n \n         functor::COOSparseMatrixToCSRSparseMatrix<Device> coo_to_csr;\n         for (int i = 0; i < batch_size; ++i) {\n@@ -313,9 +313,9 @@ class DenseToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n             // handled by the SetZero above.\n           } else {\n             // Convert coo to csr.\n-            auto coo_row_ind_i =\n-                TTypes<int32>::UnalignedVec(&coo_row_ind(batch_ptr(i)), nnz_i);\n-            auto csr_row_ptr_i = TTypes<int32>::UnalignedVec(\n+            auto coo_row_ind_i = TTypes<int32_t>::UnalignedVec(\n+                &coo_row_ind(batch_ptr(i)), nnz_i);\n+            auto csr_row_ptr_i = TTypes<int32_t>::UnalignedVec(\n                 &csr_row_ptr((rows + 1) * i), rows + 1);\n             OP_REQUIRES_OK_ASYNC(\n                 c, coo_to_csr(c, rows, cols, coo_row_ind_i, csr_row_ptr_i),\n@@ -368,9 +368,9 @@ REGISTER_GPU(GPU, complex128)\n namespace functor {\n \n template <>\n-Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n+absl::Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n     OpKernelContext* c, TTypes<int64_t>::ConstMatrix indices,\n-    TTypes<int32>::Vec nnz_per_batch);\n+    TTypes<int32_t>::Vec nnz_per_batch);\n extern template struct CalculateNNZPerBatchMatrixFromIndices<GPUDevice>;\n \n template <>\n@@ -384,9 +384,9 @@ extern template struct SparseTensorToCOOSparseMatrix<GPUDevice>;\n \n template <>\n struct COOSparseMatrixToCSRSparseMatrix<GPUDevice> {\n-  Status operator()(OpKernelContext* c, const int rows, const int cols,\n-                    TTypes<int>::UnalignedVec coo_row_ind,\n-                    TTypes<int>::UnalignedVec csr_row_ptr) {\n+  absl::Status operator()(OpKernelContext* c, const int rows, const int cols,\n+                          TTypes<int>::UnalignedVec coo_row_ind,\n+                          TTypes<int>::UnalignedVec csr_row_ptr) {\n     GpuSparse cuda_sparse(c);\n     TF_RETURN_IF_ERROR(cuda_sparse.Initialize());\n     return cuda_sparse.Coo2csr(coo_row_ind.data(),"
        },
        {
            "sha": "be11f9d81065a6e92025de5ddf99058ad447523d",
            "filename": "tensorflow/core/kernels/sparse/sparse_mat_mul_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_mat_mul_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_mat_mul_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_mat_mul_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -506,7 +506,7 @@ class CSRSparseMatMulGPUOp : public OpKernel {\n                      DT_INT8, TensorShape({static_cast<int64_t>(bufferSize1)}),\n                      &buffer1_t));\n       }\n-      void* buffer1 = buffer1_t.flat<int8>().data();\n+      void* buffer1 = buffer1_t.flat<int8_t>().data();\n \n       // Do workEstimation using buffer1.\n       // buffer1 implicitly captured in gemmDesc for use in the compute call.\n@@ -525,7 +525,7 @@ class CSRSparseMatMulGPUOp : public OpKernel {\n                      DT_INT8, TensorShape({static_cast<int64_t>(bufferSize2)}),\n                      &buffer2_t));\n       }\n-      void* buffer2 = buffer2_t.flat<int8>().data();\n+      void* buffer2 = buffer2_t.flat<int8_t>().data();\n \n       // Compute the gemm.\n       // Note that buffer1 is implicitly consumed here and buffer2 is implicitly\n@@ -552,7 +552,7 @@ class CSRSparseMatMulGPUOp : public OpKernel {\n       // Copy product to final c_row_ptr and intermediate column and values\n       // tensors.\n       void* row_ptr = &c_row_ptr(i * (rows + 1));\n-      void* col_ptr = colidx_tmp.flat<int32>().data();\n+      void* col_ptr = colidx_tmp.flat<int32_t>().data();\n       void* val_ptr = values_tmp.flat<T>().data();\n       cusparseStatus_t cusp_status =\n           cusparseCsrSetPointers(matC.get(), row_ptr, col_ptr, val_ptr);"
        },
        {
            "sha": "d25a86056b574b590cccccc02419ce0e4f1cd957",
            "filename": "tensorflow/core/kernels/sparse/sparse_matrix_components_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_matrix_components_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_matrix_components_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_matrix_components_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -137,7 +137,7 @@ namespace functor {\n       const Eigen::DSizes<Eigen::DenseIndex, 1>& sizes);        \\\n   extern template struct Slice<GPUDevice, T, 1>;\n \n-DECLARE_GPU_SPEC(int32);\n+DECLARE_GPU_SPEC(int32_t);\n DECLARE_GPU_SPEC(float);\n DECLARE_GPU_SPEC(double);\n DECLARE_GPU_SPEC(complex64);"
        },
        {
            "sha": "7d7bba8601da6465e06672bbc5c5dcb7057f41c0",
            "filename": "tensorflow/core/kernels/sparse/sparse_tensor_to_csr_sparse_matrix_op.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 20,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_tensor_to_csr_sparse_matrix_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_tensor_to_csr_sparse_matrix_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_tensor_to_csr_sparse_matrix_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -166,7 +166,7 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n     const int64_t rows = dense_shape((rank == 2) ? 0 : 1);\n     const int64_t cols = dense_shape((rank == 2) ? 1 : 2);\n \n-    static constexpr int64_t kInt32Max = std::numeric_limits<int32>::max();\n+    static constexpr int64_t kInt32Max = std::numeric_limits<int32_t>::max();\n     OP_REQUIRES_ASYNC(\n         c, batch_size < kInt32Max,\n         errors::InvalidArgument(\"dense_shape batch_size must be < Int32Max,\"\n@@ -187,7 +187,7 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n                                 (rows + 1) * batch_size),\n         done);\n \n-    ScratchSpace<int32> nnz_per_batch_host(c, batch_size, /*on_host*/ true);\n+    ScratchSpace<int32_t> nnz_per_batch_host(c, batch_size, /*on_host*/ true);\n \n     Tensor nnz_per_batch_device_t;\n     if (rank == 2) {\n@@ -198,7 +198,7 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n                            c->allocate_temp(DT_INT32, TensorShape({batch_size}),\n                                             &nnz_per_batch_device_t),\n                            done);\n-      auto nnz_per_batch_device = nnz_per_batch_device_t.vec<int32>();\n+      auto nnz_per_batch_device = nnz_per_batch_device_t.vec<int32_t>();\n \n       functor::CalculateNNZPerBatchMatrixFromIndices<Device>\n           calculate_nnz_from_indices;\n@@ -207,14 +207,14 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n           c, calculate_nnz_from_indices(c, indices, nnz_per_batch_device),\n           done);\n \n-      stream_executor::DeviceMemoryBase nnz_per_batch_device_ptr(\n+      stream_executor::DeviceAddressBase nnz_per_batch_device_ptr(\n           static_cast<void*>(nnz_per_batch_device.data()));\n \n       OP_REQUIRES_OK_ASYNC(\n           c,\n           stream->Memcpy(nnz_per_batch_host.mutable_data() /*host_dst*/,\n                          nnz_per_batch_device_ptr /*gpu_src*/,\n-                         batch_size * sizeof(int32) /*size*/),\n+                         batch_size * sizeof(int32_t) /*size*/),\n           done);\n     }\n \n@@ -227,7 +227,7 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n       // tensor by the time we get here; we can unreference it.\n       nnz_per_batch_device_ref.Unref();\n \n-      auto nnz_per_batch = nnz_per_batch_host.tensor().vec<int32>();\n+      auto nnz_per_batch = nnz_per_batch_host.tensor().vec<int32_t>();\n \n       // Ensure that within the callback, the proper GPU settings are\n       // configured.\n@@ -237,7 +237,7 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n         Tensor batch_ptr_t(cpu_allocator(), DT_INT32,\n                            TensorShape({batch_size + 1}));\n \n-        auto batch_ptr = batch_ptr_t.vec<int32>();\n+        auto batch_ptr = batch_ptr_t.vec<int32_t>();\n         auto indices = indices_t.matrix<int64_t>();\n \n         batch_ptr(0) = 0;\n@@ -274,9 +274,9 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n                              &csr_row_ptr_t),\n             done);\n \n-        auto coo_row_ind = coo_row_ind_t.vec<int32>();\n-        auto coo_col_ind = coo_col_ind_t.vec<int32>();\n-        auto csr_row_ptr = csr_row_ptr_t.vec<int32>();\n+        auto coo_row_ind = coo_row_ind_t.vec<int32_t>();\n+        auto coo_col_ind = coo_col_ind_t.vec<int32_t>();\n+        auto csr_row_ptr = csr_row_ptr_t.vec<int32_t>();\n \n         // Convert SparseTensor rep to coo row ind, coo col ind.\n         if (total_nnz > 0) {\n@@ -290,8 +290,8 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n         // a bug if you have empty coo rows.\n         // TODO(ebrevdo): File bug w/ nvidia so coo2csr can handle\n         // zero-element input coo rows.\n-        functor::SetZeroFunctor<Device, int32> set_zero;\n-        set_zero(d, csr_row_ptr_t.flat<int32>());\n+        functor::SetZeroFunctor<Device, int32_t> set_zero;\n+        set_zero(d, csr_row_ptr_t.flat<int32_t>());\n \n         functor::COOSparseMatrixToCSRSparseMatrix<Device> coo_to_csr;\n         for (int i = 0; i < batch_size; ++i) {\n@@ -301,9 +301,9 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n             // handled by the SetZero above.\n           } else {\n             // Convert coo to csr.\n-            auto coo_row_ind_i =\n-                TTypes<int32>::UnalignedVec(&coo_row_ind(batch_ptr(i)), nnz_i);\n-            auto csr_row_ptr_i = TTypes<int32>::UnalignedVec(\n+            auto coo_row_ind_i = TTypes<int32_t>::UnalignedVec(\n+                &coo_row_ind(batch_ptr(i)), nnz_i);\n+            auto csr_row_ptr_i = TTypes<int32_t>::UnalignedVec(\n                 &csr_row_ptr((rows + 1) * i), rows + 1);\n             OP_REQUIRES_OK_ASYNC(\n                 c, coo_to_csr(c, rows, cols, coo_row_ind_i, csr_row_ptr_i),\n@@ -345,9 +345,9 @@ class SparseTensorToCSRSparseMatrixGPUOp : public AsyncOpKernel {\n namespace functor {\n \n template <>\n-Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n+absl::Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n     OpKernelContext* c, TTypes<int64_t>::ConstMatrix indices,\n-    TTypes<int32>::Vec nnz_per_batch);\n+    TTypes<int32_t>::Vec nnz_per_batch);\n extern template struct CalculateNNZPerBatchMatrixFromIndices<GPUDevice>;\n \n template <>\n@@ -361,9 +361,9 @@ extern template struct SparseTensorToCOOSparseMatrix<GPUDevice>;\n \n template <>\n struct COOSparseMatrixToCSRSparseMatrix<GPUDevice> {\n-  Status operator()(OpKernelContext* c, const int rows, const int cols,\n-                    TTypes<int>::UnalignedVec coo_row_ind,\n-                    TTypes<int>::UnalignedVec csr_row_ptr) {\n+  absl::Status operator()(OpKernelContext* c, const int rows, const int cols,\n+                          TTypes<int>::UnalignedVec coo_row_ind,\n+                          TTypes<int>::UnalignedVec csr_row_ptr) {\n     GpuSparse cuda_sparse(c);\n     TF_RETURN_IF_ERROR(cuda_sparse.Initialize());\n     return cuda_sparse.Coo2csr(coo_row_ind.data(),"
        },
        {
            "sha": "234b00e57495939edb434fe321feac30633f8ddf",
            "filename": "tensorflow/core/kernels/sparse/transpose_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Ftranspose_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/863879c12c82ae2bf33fb0a3099877859527d882/tensorflow%2Fcore%2Fkernels%2Fsparse%2Ftranspose_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Ftranspose_op.cc?ref=863879c12c82ae2bf33fb0a3099877859527d882",
            "patch": "@@ -255,8 +255,8 @@ struct CSRSparseMatrixTransposeComponent<CPUDevice, T> {\n \n template <typename T>\n struct CSRSparseMatrixTransposeComponent<GPUDevice, T> {\n-  Status operator()(OpKernelContext* ctx, const ConstCSRComponent<T>& x,\n-                    CSRComponent<T>* y) {\n+  absl::Status operator()(OpKernelContext* ctx, const ConstCSRComponent<T>& x,\n+                          CSRComponent<T>* y) {\n     TF_RETURN_IF_ERROR(ValidateTransposeInputs(x, *y));\n     GpuSparse cuda_sparse(ctx);\n     TF_RETURN_IF_ERROR(cuda_sparse.Initialize());\n@@ -277,7 +277,7 @@ struct CSRSparseMatrixTransposeComponent<GPUDevice, T> {\n         x.col_ind.data() /*csrColInd*/, y->values.data() /*cscVal*/,\n         y->col_ind.data() /*cscRowInd*/, y->row_ptr.data() /*cscColPtr*/,\n         copyValues);\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n };\n #endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM"
        }
    ],
    "stats": {
        "total": 158,
        "additions": 80,
        "deletions": 78
    }
}