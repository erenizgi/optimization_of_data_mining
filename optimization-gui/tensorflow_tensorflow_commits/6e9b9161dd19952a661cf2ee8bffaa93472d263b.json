{
    "author": "shawnwang18",
    "message": "PR #34735: [XLA:GPU] enable dynamic slice fusion default lowered to cuda graph\n\nImported from GitHub PR https://github.com/openxla/xla/pull/34735\n\nüìù Summary of Changes\nAdded DebugOptions::DYNAMIC_SLICE_FUSION to the list of enabled GPU command buffers in the default debug options.\n\nüöÄ Kind of Contribution\n‚ö°Ô∏è Performance Improvement\n\nüß™ Unit Tests:\nchange the default setting, unittest has already been added.\nCopybara import of the project:\n\n--\n12db9b02864a72046775dbd3684ec60beff0c791 by Shawn Wang <shawnw@nvidia.com>:\n\nenable dynamic slice fusion default lowered to cuda graph\n\nfix unittest\n\nfix\n\nfix\n\nMerging this change closes #34735\n\nPiperOrigin-RevId: 843733907",
    "sha": "6e9b9161dd19952a661cf2ee8bffaa93472d263b",
    "files": [
        {
            "sha": "8c4cbe8e9941d202e0fa021e582fb03a5401317d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/BUILD",
            "status": "modified",
            "additions": 10,
            "deletions": 1,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD?ref=6e9b9161dd19952a661cf2ee8bffaa93472d263b",
            "patch": "@@ -1,6 +1,7 @@\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n+load(\"//xla/tsl:tsl.bzl\", \"if_google\")\n \n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n@@ -185,6 +186,15 @@ cc_library(\n xla_test(\n     name = \"dynamic_slice_fusion_test\",\n     srcs = [\"dynamic_slice_fusion_test.cc\"],\n+    # TODO(b/46791573): Remove heap_check= once the bug is fixed.\n+    backend_args = if_google(\n+        {\n+            \"b200\": [\"--heap_check=\"],\n+            \"a100\": [\"--heap_check=\"],\n+            \"h100\": [\"--heap_check=\"],\n+        },\n+        {},\n+    ),\n     backend_tags = {\n         \"gpu\": [\n             \"multi_gpu\",\n@@ -224,7 +234,6 @@ xla_test(\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "d99cd48be0455a2daa5ca7dc6bfd79635447ce1b",
            "filename": "third_party/xla/xla/backends/gpu/codegen/dynamic_slice_fusion_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc?ref=6e9b9161dd19952a661cf2ee8bffaa93472d263b",
            "patch": "@@ -48,7 +48,6 @@ limitations under the License.\n #include \"xla/service/platform_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -3412,8 +3411,10 @@ TEST_F(DynamicSliceFusionTest,\n       ROOT while = (s32[], s32[32,32], s32[32,32]) while(tuple), body=body, condition=condition\n     }\n   )\";\n+  HloModuleConfig config = GetModuleConfigWithoutCommandBuffer();\n+  config.mutable_debug_options().set_xla_gpu_enable_dynamic_slice_fusion(true);\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> fused_module,\n-                          ParseAndReturnVerifiedModule(hlo_fused));\n+                          ParseAndReturnVerifiedModule(hlo_fused, config));\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<OpaqueExecutable> wrapped_exec,\n                           CreateExecutable(fused_module->Clone(), false));\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Executable> exec,"
        },
        {
            "sha": "5487a31836ecb3444d9d10f3558a88636455f540",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=6e9b9161dd19952a661cf2ee8bffaa93472d263b",
            "patch": "@@ -243,6 +243,7 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLASLT);\n   opts.add_xla_gpu_enable_command_buffer(DebugOptions::CUSTOM_CALL);\n   opts.add_xla_gpu_enable_command_buffer(DebugOptions::CUDNN);\n+  opts.add_xla_gpu_enable_command_buffer(DebugOptions::DYNAMIC_SLICE_FUSION);\n   opts.set_xla_gpu_graph_min_graph_size(5);\n   opts.set_xla_gpu_command_buffer_scheduling_mode(DebugOptions::LHS);\n   opts.set_xla_gpu_command_buffer_unroll_loops(false);"
        },
        {
            "sha": "1fea535da5e44b87ca833563db5e9e6e5547fb7d",
            "filename": "third_party/xla/xla/debug_options_parsers_test.cc",
            "status": "modified",
            "additions": 23,
            "deletions": 18,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6e9b9161dd19952a661cf2ee8bffaa93472d263b/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc?ref=6e9b9161dd19952a661cf2ee8bffaa93472d263b",
            "patch": "@@ -391,13 +391,14 @@ TEST(ParseRepeatedEnumModifiersTest, Invalid) {\n TEST(ParseRepeatedEnumFlagsTest, CommandBufferCmdType) {\n   DebugOptions debug_options = DefaultDebugOptionsIgnoringFlags();\n \n-  // Check that the default setting has 5 types.\n+  // Check that the default setting has 6 types.\n   const auto& enabled_types = debug_options.xla_gpu_enable_command_buffer();\n-  ASSERT_EQ(enabled_types.size(), 5);\n-  ASSERT_THAT(enabled_types,\n-              ElementsAre(DebugOptions::FUSION, DebugOptions::CUBLAS,\n-                          DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n-                          DebugOptions::CUDNN));\n+  ASSERT_EQ(enabled_types.size(), 6);\n+  ASSERT_THAT(\n+      enabled_types,\n+      ElementsAre(DebugOptions::FUSION, DebugOptions::CUBLAS,\n+                  DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n+                  DebugOptions::CUDNN, DebugOptions::DYNAMIC_SLICE_FUSION));\n \n   // Initialize the flag objects.\n   std::vector<tsl::Flag> flag_objects;\n@@ -406,26 +407,30 @@ TEST(ParseRepeatedEnumFlagsTest, CommandBufferCmdType) {\n   // Removing options from the existing setting.\n   SetXlaFlagsEnvVar(\"--xla_gpu_enable_command_buffer=-fusion,-cublas\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n-  EXPECT_EQ(enabled_types.size(), 3);\n-  EXPECT_THAT(enabled_types,\n-              ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n-                          DebugOptions::CUDNN));\n+  EXPECT_EQ(enabled_types.size(), 4);\n+  EXPECT_THAT(\n+      enabled_types,\n+      ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n+                  DebugOptions::CUDNN, DebugOptions::DYNAMIC_SLICE_FUSION));\n \n   // Removing an option that isn't there and adding a duplicate.\n   SetXlaFlagsEnvVar(\"--xla_gpu_enable_command_buffer=+cublaslt,-fusion\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n-  EXPECT_EQ(enabled_types.size(), 3);\n-  EXPECT_THAT(enabled_types,\n-              ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n-                          DebugOptions::CUDNN));\n+  EXPECT_EQ(enabled_types.size(), 4);\n+  EXPECT_THAT(\n+      enabled_types,\n+      ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n+                  DebugOptions::CUDNN, DebugOptions::DYNAMIC_SLICE_FUSION));\n \n   // Adding an option.\n   SetXlaFlagsEnvVar(\"--xla_gpu_enable_command_buffer=+cublas\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n-  EXPECT_EQ(enabled_types.size(), 4);\n-  EXPECT_THAT(enabled_types,\n-              ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n-                          DebugOptions::CUDNN, DebugOptions::CUBLAS));\n+  EXPECT_EQ(enabled_types.size(), 5);\n+  EXPECT_THAT(\n+      enabled_types,\n+      ElementsAre(DebugOptions::CUBLASLT, DebugOptions::CUSTOM_CALL,\n+                  DebugOptions::CUDNN, DebugOptions::DYNAMIC_SLICE_FUSION,\n+                  DebugOptions::CUBLAS));\n \n   // Overwriting the default setting.\n   SetXlaFlagsEnvVar(\"--xla_gpu_enable_command_buffer=custom_call,fusion\");"
        }
    ],
    "stats": {
        "total": 58,
        "additions": 37,
        "deletions": 21
    }
}