{
    "author": "ezhulenev",
    "message": "[xla:cpu] Construct BufferAllocationInfo from BufferAssignment\n\nThis is no-op change, preparing for migration from cpu_function_runtime::BufferInfo to new BufferAllocationInfo type.\n\nPiperOrigin-RevId: 819827983",
    "sha": "503198fb6bf9452d65218548a7baf2e75aa58b87",
    "files": [
        {
            "sha": "cc6f5f8c66ae1aaede7ed9e8d0656c1068f5b4e9",
            "filename": "tensorflow/compiler/tf2xla/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2FBUILD?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -516,6 +516,8 @@ cc_library(\n         \"@local_xla//xla:cpu_function_runtime\",\n         \"@local_xla//xla:shape_util\",\n         \"@local_xla//xla:xla_data_proto_cc\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info\",\n+        \"@local_xla//xla/backends/cpu:buffer_allocation_info_util\",\n         \"@local_xla//xla/backends/cpu/codegen:compiled_function_library\",\n         \"@local_xla//xla/client:client_library\",\n         \"@local_xla//xla/client:executable_build_options\","
        },
        {
            "sha": "8be6dafa6ca8c139a624022303365b72c789e9c1",
            "filename": "tensorflow/compiler/tf2xla/xla_jit_compiled_cpu_function.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Ftf2xla%2Fxla_jit_compiled_cpu_function.cc?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -26,6 +26,8 @@ limitations under the License.\n #include \"tensorflow/compiler/tf2xla/tf2xla.h\"\n #include \"tensorflow/compiler/tf2xla/tf2xla.pb.h\"\n #include \"tensorflow/compiler/tf2xla/xla_compiled_cpu_function.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info_util.h\"\n #include \"xla/backends/cpu/codegen/compiled_function_library.h\"\n #include \"xla/client/client_library.h\"\n #include \"xla/client/executable_build_options.h\"\n@@ -153,6 +155,11 @@ XlaJitCompiledCpuFunction::Compile(\n   std::vector<xla::cpu_function_runtime::BufferInfo> buffer_infos =\n       xla::cpu::CreateBufferInfosFromBufferAssignment(cpu_executable->module(),\n                                                       buffer_assignment);\n+\n+  std::vector<xla::cpu::BufferAllocationInfo> buffer_allocation_infos =\n+      xla::cpu::CreateBufferAllocationInfos(cpu_executable->module(),\n+                                            buffer_assignment);\n+\n   std::vector<int32> arg_index_table =\n       xla::cpu::CreateArgIndexTableFromBufferInfos(buffer_infos);\n   std::vector<int32> result_index_table ="
        },
        {
            "sha": "4daf263f90c7420dfaa26b534af956f39ded843d",
            "filename": "third_party/xla/xla/backends/cpu/BUILD",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -41,6 +41,25 @@ cc_library(\n     deps = [\n         \"//xla:xla_data_proto_cc\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"buffer_allocation_info_util\",\n+    srcs = [\"buffer_allocation_info_util.cc\"],\n+    hdrs = [\"buffer_allocation_info_util.h\"],\n+    visibility = internal_visibility([\":friends\"]),\n+    deps = [\n+        \":buffer_allocation_info\",\n+        \"//xla:shape_util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:buffer_assignment\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/types:span\",\n     ],\n )\n "
        },
        {
            "sha": "ca4893c753c91408e863f84961e169f508e0574e",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info.h",
            "status": "modified",
            "additions": 59,
            "deletions": 24,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info.h?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -19,6 +19,8 @@ limitations under the License.\n #include <cstdint>\n \n #include \"absl/log/check.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/strings/string_view.h\"\n \n namespace xla::cpu {\n \n@@ -38,7 +40,7 @@ class BufferAllocationInfo {\n   struct Encoded {\n     uint64_t packed_kind_and_size = 0;\n     uint32_t entry_param_number = -1;\n-    uint32_t result_param_number = -1;\n+    uint32_t result_number = -1;\n   };\n \n   // Creates a BufferAllocationInfo from a serialized encoding generated by\n@@ -47,26 +49,22 @@ class BufferAllocationInfo {\n       : kind_(UnpackKind(encoded.packed_kind_and_size)),\n         size_(UnpackSize(encoded.packed_kind_and_size)),\n         entry_param_number_(encoded.entry_param_number),\n-        result_param_number_(encoded.result_param_number) {}\n+        result_number_(encoded.result_number) {}\n \n   bool is_constant() const { return kind_ == Kind::kConstant; }\n \n-  bool is_entry_parameter() const {\n-    return kind_ == Kind::kParameter && entry_param_number_ >= 0;\n-  }\n+  bool is_entry_parameter() const { return entry_param_number_ >= 0; }\n \n   int32_t entry_parameter_number() const {\n     DCHECK(is_entry_parameter());\n     return entry_param_number_;\n   }\n \n-  bool is_result_parameter() const {\n-    return kind_ == Kind::kParameter && result_param_number_ >= 0;\n-  }\n+  bool is_result() const { return result_number_ >= 0; }\n \n-  int32_t result_parameter_number() const {\n-    DCHECK(is_result_parameter());\n-    return result_param_number_;\n+  int32_t result_number() const {\n+    DCHECK(is_result());\n+    return result_number_;\n   }\n \n   // Returns true if this buffer is temporary scratch space required by the XLA\n@@ -89,14 +87,14 @@ class BufferAllocationInfo {\n     return Encoded{\n         Pack(kind_, size_),\n         static_cast<uint32_t>(entry_param_number_),\n-        static_cast<uint32_t>(result_param_number_),\n+        static_cast<uint32_t>(result_number_),\n     };\n   }\n \n   bool operator==(const BufferAllocationInfo& buffer_info) const {\n     return kind_ == buffer_info.kind_ && size_ == buffer_info.size_ &&\n            entry_param_number_ == buffer_info.entry_param_number_ &&\n-           result_param_number_ == buffer_info.result_param_number_;\n+           result_number_ == buffer_info.result_number_;\n   }\n \n   static BufferAllocationInfo Temp(uint64_t size) {\n@@ -112,32 +110,54 @@ class BufferAllocationInfo {\n     return BufferAllocationInfo(Kind::kParameter, size, entry_param_number);\n   }\n \n-  static BufferAllocationInfo ResultParameter(uint64_t size,\n-                                              int32_t result_param_number) {\n-    return BufferAllocationInfo(Kind::kParameter, size,\n-                                /*entry_param_number=*/-1, result_param_number);\n-  }\n-\n   static BufferAllocationInfo InOutParameter(uint64_t size,\n                                              int32_t entry_param_number,\n-                                             int32_t result_param_number) {\n+                                             int32_t result_number) {\n     return BufferAllocationInfo(Kind::kParameter, size, entry_param_number);\n   }\n \n+  static BufferAllocationInfo Result(uint64_t size, int32_t result_number) {\n+    return BufferAllocationInfo(Kind::kResult, size, -1, result_number);\n+  }\n+\n   static BufferAllocationInfo ThreadLocal(uint64_t size) {\n     return BufferAllocationInfo(Kind::kThreadLocal, size);\n   }\n \n+  template <typename Sink>\n+  friend void AbslStringify(Sink& sink, const BufferAllocationInfo& info) {\n+    absl::Format(\n+        &sink, \"BufferAllocationInfo(%s, size=%d%s%s)\", ToString(info.kind_),\n+        info.size_,\n+        info.entry_param_number_ >= 0\n+            ? absl::StrFormat(\", entry_param=%d\", info.entry_param_number_)\n+            : \"\",\n+        info.result_number_ >= 0\n+            ? absl::StrFormat(\", result=%d\", info.result_number_)\n+            : \"\");\n+  }\n+\n  private:\n-  enum class Kind : uint64_t { kConstant, kTemp, kParameter, kThreadLocal };\n+  template <typename Sink>\n+  friend void AbslStringify(Sink& sink, const BufferAllocationInfo& info);\n+\n+  // If buffer allocation is an in-out parameter, we use `kParameter` kind and\n+  // set both entry parameter and result numbers.\n+  enum class Kind : uint64_t {\n+    kConstant,\n+    kTemp,\n+    kParameter,\n+    kResult,\n+    kThreadLocal\n+  };\n \n   BufferAllocationInfo(Kind kind, uint64_t size,\n                        int32_t entry_param_number = -1,\n-                       int32_t result_param_number = -1)\n+                       int32_t result_number = -1)\n       : kind_(kind),\n         size_(size),\n         entry_param_number_(entry_param_number),\n-        result_param_number_(result_param_number) {}\n+        result_number_(result_number) {}\n \n   static uint64_t Pack(Kind kind, uint64_t size) {\n     return (static_cast<uint64_t>(size) << 2) | static_cast<uint64_t>(kind);\n@@ -151,10 +171,25 @@ class BufferAllocationInfo {\n     return packed >> 2;\n   }\n \n+  static absl::string_view ToString(Kind kind) {\n+    switch (kind) {\n+      case Kind::kConstant:\n+        return \"constant\";\n+      case Kind::kTemp:\n+        return \"temp\";\n+      case Kind::kParameter:\n+        return \"parameter\";\n+      case Kind::kResult:\n+        return \"result\";\n+      case Kind::kThreadLocal:\n+        return \"thread-local\";\n+    }\n+  }\n+\n   Kind kind_ : 2;\n   uint64_t size_ : 62;\n   int32_t entry_param_number_ = -1;\n-  int32_t result_param_number_ = -1;\n+  int32_t result_number_ = -1;\n };\n \n }  // namespace xla::cpu"
        },
        {
            "sha": "e6d9cfea617367c146d5e8aa731f8c648c6576c3",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info_util.cc",
            "status": "added",
            "additions": 131,
            "deletions": 0,
            "changes": 131,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.cc?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -0,0 +1,131 @@\n+/* Copyright 2018 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/cpu/buffer_allocation_info_util.h\"\n+\n+#include <cassert>\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+\n+namespace xla::cpu {\n+\n+std::vector<BufferAllocationInfo> CreateBufferAllocationInfos(\n+    const HloModule& module, const BufferAssignment& buffer_assignment) {\n+  std::vector<BufferAllocationInfo> allocations;\n+\n+  // A mapping from a buffer allocation index to the result parameter number.\n+  absl::flat_hash_map<BufferAllocation::Index, int64_t> result_allocations;\n+  const HloInstruction* root = module.entry_computation()->root_instruction();\n+  ShapeUtil::ForEachLeafShape(\n+      root->shape(), [&](const Shape& subshape, const ShapeIndex& index) {\n+        BufferAllocation::Index allocation_index =\n+            buffer_assignment.GetUniqueSlice(root, index)->index();\n+        int64_t result_index = result_allocations.size();\n+        result_allocations[allocation_index] = result_index;\n+      });\n+\n+  for (const BufferAllocation& allocation : buffer_assignment.Allocations()) {\n+    // Check that the allocations index is contiguous in [0, num_allocations).\n+    DCHECK_EQ(allocation.index(), allocations.size());\n+\n+    if (allocation.is_thread_local()) {\n+      allocations.push_back(\n+          BufferAllocationInfo::ThreadLocal(allocation.size()));\n+\n+    } else if (allocation.is_constant()) {\n+      allocations.push_back(BufferAllocationInfo::Constant(allocation.size()));\n+\n+    } else if (allocation.is_entry_computation_parameter() &&\n+               allocation.maybe_live_out()) {\n+      // Entry computation parameter that is aliased with one of the results.\n+      allocations.push_back(BufferAllocationInfo::InOutParameter(\n+          allocation.size(), allocation.parameter_number(),\n+          result_allocations.at(allocation.index())));\n+\n+    } else if (allocation.is_entry_computation_parameter()) {\n+      // A read-only entry computation parameter.\n+      allocations.push_back(BufferAllocationInfo::EntryParameter(\n+          allocation.size(), allocation.parameter_number()));\n+\n+    } else if (allocation.maybe_live_out() &&\n+               result_allocations.contains(allocation.index())) {\n+      // This is a result buffer that corresponds to a flatten result index.\n+      allocations.push_back(BufferAllocationInfo::Result(\n+          allocation.size(), result_allocations[allocation.index()]));\n+\n+    } else if (allocation.maybe_live_out()) {\n+      // This is a result buffer that holds the tuple. It doesn't correspond to\n+      // a flatten result index, and it's never used by XLA:CPU at run time, but\n+      // we still record it as we want to know about all allocations.\n+      allocations.push_back(\n+          BufferAllocationInfo::Result(allocation.size(), -1));\n+\n+    } else {\n+      // A temporary allocation that holds intermediate buffers.\n+      DCHECK(allocation.IsPreallocatedTempBuffer());\n+      allocations.push_back(BufferAllocationInfo::Temp(allocation.size()));\n+    }\n+  }\n+\n+  VLOG(3) << \"Created \" << allocations.size() << \" buffer allocation infos: \";\n+  for (const BufferAllocationInfo& allocation : allocations) {\n+    VLOG(3) << \"  \" << allocation;\n+  }\n+\n+  return allocations;\n+}\n+\n+std::vector<int32_t> CreateArgIndexTable(\n+    absl::Span<const BufferAllocationInfo> allocations) {\n+  std::vector<int32_t> ret;\n+  for (int64_t i = 0; i < allocations.size(); i++) {\n+    if (allocations[i].is_entry_parameter()) {\n+      int32_t parameter_number = allocations[i].entry_parameter_number();\n+      if (parameter_number >= ret.size()) {\n+        ret.resize(parameter_number + 1);\n+      }\n+      ret[parameter_number] = i;\n+    }\n+  }\n+  return ret;\n+}\n+\n+std::vector<int32_t> CreateResultIndexTable(\n+    absl::Span<const BufferAllocationInfo> allocations) {\n+  std::vector<int32_t> ret;\n+  for (int64_t i = 0; i < allocations.size(); i++) {\n+    if (allocations[i].is_result()) {\n+      int32_t result_number = allocations[i].result_number();\n+      if (result_number >= ret.size()) {\n+        ret.resize(result_number + 1);\n+      }\n+      ret[result_number] = i;\n+    }\n+  }\n+  return ret;\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "cf5fcbbb0604d3f384d827a796792bcb373d8359",
            "filename": "third_party/xla/xla/backends/cpu/buffer_allocation_info_util.h",
            "status": "added",
            "additions": 47,
            "deletions": 0,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbuffer_allocation_info_util.h?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -0,0 +1,47 @@\n+/* Copyright 2018 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_UTIL_H_\n+#define XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_UTIL_H_\n+\n+#include <cstdint>\n+#include <vector>\n+\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+\n+namespace xla::cpu {\n+\n+// Creates and returns a list of `BufferAllocationInfo` instances containing\n+// relevant information from `buffer_assignment`.\n+std::vector<BufferAllocationInfo> CreateBufferAllocationInfos(\n+    const HloModule& module, const BufferAssignment& buffer_assignment);\n+\n+// Creates and returns a table containing the mapping from entry computation\n+// parameters to buffer allocation indices:\n+//\n+//   vector[parameter_number] == allocation.index()\n+//   vector[result_number]    == allocation.index()\n+//\n+std::vector<int32_t> CreateArgIndexTable(\n+    absl::Span<const BufferAllocationInfo> allocations);\n+std::vector<int32_t> CreateResultIndexTable(\n+    absl::Span<const BufferAllocationInfo> allocations);\n+\n+}  // namespace xla::cpu\n+\n+#endif  // XLA_BACKENDS_CPU_BUFFER_ALLOCATION_INFO_UTIL_H_"
        },
        {
            "sha": "dd43f97694618625b337a5011b55c7e850f137c9",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -432,6 +432,8 @@ cc_library(\n         \":executable_proto_cc\",\n         \"//xla:cpu_function_runtime\",\n         \"//xla:util\",\n+        \"//xla/backends/cpu:buffer_allocation_info\",\n+        \"//xla/backends/cpu:buffer_allocation_info_util\",\n         \"//xla/backends/cpu:constant_allocation\",\n         \"//xla/backends/cpu/runtime:function_library\",\n         \"//xla/backends/cpu/runtime:thunk\","
        },
        {
            "sha": "4364bb10510abfeea4d42076fe13bd72100f3791",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 3,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.cc?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -29,6 +29,8 @@ limitations under the License.\n #include \"absl/memory/memory.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info_util.h\"\n #include \"xla/backends/cpu/constant_allocation.h\"\n #include \"xla/backends/cpu/runtime/function_library.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n@@ -87,12 +89,16 @@ CpuAotCompilationResult::Create(\n                       thunk_sequence_serdes.ToProto(thunks));\n \n   std::vector<cpu_function_runtime::BufferInfo> buffer_infos;\n+  std::vector<cpu::BufferAllocationInfo> buffer_allocation_infos;\n   std::optional<size_t> temp_allocation_index;\n \n   if (buffer_assignment) {\n     buffer_infos =\n         CreateBufferInfosFromBufferAssignment(*hlo_module, *buffer_assignment);\n \n+    buffer_allocation_infos =\n+        CreateBufferAllocationInfos(*hlo_module, *buffer_assignment);\n+\n     // Find temp allocation index if it exists\n     for (const BufferAllocation& allocation :\n          buffer_assignment->Allocations()) {\n@@ -108,8 +114,8 @@ CpuAotCompilationResult::Create(\n   return absl::WrapUnique(new CpuAotCompilationResult(\n       hlo_module, buffer_assignment, function_name, std::move(obj_files),\n       std::move(symbols), thunk_proto, std::move(temp_allocation_index),\n-      std::move(buffer_infos), std::move(function_library),\n-      std::move(hlo_profile_printer_data)));\n+      std::move(buffer_infos), std::move(buffer_allocation_infos),\n+      std::move(function_library), std::move(hlo_profile_printer_data)));\n }\n \n CpuAotCompilationResult::CpuAotCompilationResult(\n@@ -118,17 +124,19 @@ CpuAotCompilationResult::CpuAotCompilationResult(\n     std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n     std::optional<size_t> temp_allocation_index,\n     std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n+    std::vector<BufferAllocationInfo> buffer_allocation_infos,\n     std::unique_ptr<FunctionLibrary> function_library,\n     std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data)\n     : temp_allocation_index_(temp_allocation_index),\n       buffer_infos_(std::move(buffer_infos)),\n+      buffer_allocation_infos_(std::move(buffer_allocation_infos)),\n       function_library_(std::move(function_library)),\n       hlo_profile_printer_data_(std::move(hlo_profile_printer_data)) {\n   *proto_.mutable_hlo_module()->mutable_hlo_module() = hlo_module->ToProto();\n   *proto_.mutable_hlo_module()->mutable_config() =\n       hlo_module->config().ToProto();\n   *proto_.mutable_buffer_assignment() = buffer_assignment->ToProto();\n-  proto_.set_entry_function_name(std::string(function_name));\n+  proto_.set_entry_function_name(function_name);\n   for (ObjFileProto& obj_file : obj_files) {\n     *proto_.add_object_files() = std::move(obj_file);\n   }"
        },
        {
            "sha": "16320df6f6fa74da1f682d86e21500c0eb49318a",
            "filename": "third_party/xla/xla/service/cpu/cpu_aot_compilation_result.h",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/503198fb6bf9452d65218548a7baf2e75aa58b87/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_aot_compilation_result.h?ref=503198fb6bf9452d65218548a7baf2e75aa58b87",
            "patch": "@@ -17,7 +17,6 @@ limitations under the License.\n #define XLA_SERVICE_CPU_CPU_AOT_COMPILATION_RESULT_H_\n \n #include <cstddef>\n-#include <cstdint>\n #include <memory>\n #include <optional>\n #include <string>\n@@ -26,6 +25,7 @@ limitations under the License.\n \n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/cpu/buffer_allocation_info.h\"\n #include \"xla/backends/cpu/runtime/function_library.h\"\n #include \"xla/backends/cpu/runtime/thunk.h\"\n #include \"xla/backends/cpu/runtime/thunk.pb.h\"\n@@ -152,6 +152,10 @@ class CpuAotCompilationResult : public AotCompilationResult {\n     return buffer_infos_;\n   }\n \n+  absl::Span<const BufferAllocationInfo> buffer_allocation_infos() const {\n+    return buffer_allocation_infos_;\n+  }\n+\n   const HloProfilePrinterData* hlo_profile_printer_data() const {\n     return hlo_profile_printer_data_.get();\n   }\n@@ -185,6 +189,7 @@ class CpuAotCompilationResult : public AotCompilationResult {\n       std::vector<SymbolProto> symbols, const ThunkSequenceProto& thunks,\n       std::optional<size_t> temp_allocation_index,\n       std::vector<cpu_function_runtime::BufferInfo> buffer_infos,\n+      std::vector<BufferAllocationInfo> buffer_allocation_infos,\n       std::unique_ptr<FunctionLibrary> function_library,\n       std::unique_ptr<HloProfilePrinterData> hlo_profile_printer_data);\n \n@@ -199,6 +204,7 @@ class CpuAotCompilationResult : public AotCompilationResult {\n   std::unique_ptr<HloModule> module_;\n   std::optional<size_t> temp_allocation_index_;\n   std::vector<cpu_function_runtime::BufferInfo> buffer_infos_;\n+  std::vector<BufferAllocationInfo> buffer_allocation_infos_;\n \n   std::unique_ptr<FunctionLibrary> function_library_;\n "
        }
    ],
    "stats": {
        "total": 313,
        "additions": 285,
        "deletions": 28
    }
}