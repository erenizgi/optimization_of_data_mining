{
    "author": "rao-ashish",
    "message": "PR #33284: PjRt API changes for improved cross host transfers\n\nImported from GitHub PR https://github.com/openxla/xla/pull/33284\n\nüìù Summary of Changes\nThis PR adds methods `CrossHostSendBuffers` and `CrossHostReceiveBuffers` to PjRt clients as a new cross-host data transfer API. This new API enables optimizations when running on GPUs such as communicator caching and aggregating transfers with NCCL group calls. The new API evolved from discussions with @emilyfertig (for eg see discussion in #32074 , #32076 , #32295 ).\n\nüéØ Justification\nThe current implementation of cross-process device-puts on GPUs does not cache communicators for reuse across multiple transfers between the same sets of devices, and does not aggregate transfers of multiple arrays together with NCCL group calls. This PR adds cross-host transfer methods `CrossHostSendBuffers` and `CrossHostReceiveBuffers` that now have information about the global device IDs involved in the data transfer so that communicators can be cached. Further, since these methods operate on multiple arrays, transfers can be aggregated with NCCL group calls.\n\nüöÄ Kind of Contribution\n‚ö°Ô∏è Performance Improvement\n\nüìä Benchmark (for Performance Improvements)\nThis PR only makes API changes necessary for future performance improvements such as communicator caching, so no benchmarks were ran for this PR. Follow-up PRs implementing performance improvements will include benchmarks.\n\nüß™ Unit Tests:\nUnit tests for the new API have been added inside `se_gpu_pjrt_client_test.cc`.\n\nüß™ Execution Tests:\nWhen building XLA with the code in this PR along with [a patch for `pjrt_ifrt/pjrt_client.cc`](https://gist.github.com/rao-ashish/ba5cd773906c8e428147bb80a3568912) so that it uses the new API, I verified that [these 4 correctness checks](https://gist.github.com/rao-ashish/24ac0df0cb18243c649ac535964b31b8) pass. The IFRT changes will be included in a follow-up PR once other PjRt clients have implemented the new API.\nCopybara import of the project:\n\n--\n7e0eb7e5dd0a32f32df966ca83c5efda920a92de by Ashish Rao <asrao@nvidia.com>:\n\nPjRt API changes for improved cross host transfers\n\nMerging this change closes #33284\n\nPiperOrigin-RevId: 828560118",
    "sha": "dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
    "files": [
        {
            "sha": "809d0abc46d7b0cad0330755d12440b72bca5988",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -307,6 +307,7 @@ cc_library(\n         \"//xla/service:computation_placer_hdr\",\n         \"//xla/service:hlo_cost_analysis\",\n         \"//xla/tsl/framework:allocator\",\n+        \"//xla/tsl/lib/gtl:int_type\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/protobuf:coordination_service_proto_cc\","
        },
        {
            "sha": "bd289db2cb68c882a60b14c7ee3d09bed340b8c7",
            "filename": "third_party/xla/xla/pjrt/c_api_client/pjrt_c_api_client.cc",
            "status": "modified",
            "additions": 149,
            "deletions": 27,
            "changes": 176,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.cc?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -989,24 +989,15 @@ PJRT_Transfers_CrossHostRecvNotifierInfo CppCrossHostRecvNotifierToC(\n       }};\n }\n \n-absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n-PjRtCApiClient::MakeCrossHostReceiveBuffers(\n-    absl::Span<const Shape> shapes, PjRtDevice* device,\n-    PjRtCrossHostRecvNotifier notifier) {\n-  const PJRT_Api* c_api = pjrt_c_api();\n-  PJRT_CrossHostTransfers_Extension* extension =\n-      FindExtension<PJRT_CrossHostTransfers_Extension>(\n-          PJRT_Extension_Type::PJRT_Extension_Type_CrossHostTransfers);\n-  if (extension == nullptr) {\n-    return absl::UnimplementedError(\n-        \"MakeCrossHostReceiveBuffers is not implemented in this PJRT plugin.\");\n-  }\n-  PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers_Args args;\n-  args.struct_size =\n-      PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers_Args_STRUCT_SIZE;\n-  args.extension_start = nullptr;\n-  args.client = c_client_.get();\n-  args.num_shapes = shapes.size();\n+// Helper struct and method used to serialize shapes past the C API boundary.\n+struct ShapesInfo {\n+  std::vector<size_t> shape_num_dims;\n+  std::vector<PJRT_Buffer_MemoryLayout*> layout_list;\n+  std::vector<const int64_t*> num_dims;\n+  std::vector<PJRT_Buffer_Type> element_type_list;\n+};\n+\n+ShapesInfo MakeShapesInfo(absl::Span<const Shape> shapes) {\n   std::vector<size_t> shape_num_dims;\n   shape_num_dims.reserve(shapes.size());\n   std::vector<PJRT_Buffer_MemoryLayout*> layout_list;\n@@ -1015,6 +1006,7 @@ PjRtCApiClient::MakeCrossHostReceiveBuffers(\n   num_dims.reserve(shapes.size());\n   std::vector<PJRT_Buffer_Type> element_type_list;\n   element_type_list.reserve(shapes.size());\n+\n   for (int i = 0; i < shapes.size(); ++i) {\n     shape_num_dims.push_back(shapes[i].dimensions().size());\n \n@@ -1031,10 +1023,51 @@ PjRtCApiClient::MakeCrossHostReceiveBuffers(\n     //   layout_list.push_back(&(c_layout_data.c_layout));\n     layout_list.push_back(nullptr);\n   }\n-  args.shape_num_dims = shape_num_dims.data();\n-  args.num_dims = num_dims.data();\n-  args.element_types = element_type_list.data();\n-  args.layouts = layout_list.data();\n+\n+  return ShapesInfo{\n+      /*shape_num_dims=*/std::move(shape_num_dims),\n+      /*layout_list=*/std::move(layout_list),\n+      /*num_dims=*/std::move(num_dims),\n+      /*element_type_list=*/std::move(element_type_list),\n+  };\n+}\n+\n+// Helper method to convert a list of PJRT_Buffer* to a list of PjRtBuffer*.\n+std::vector<std::unique_ptr<PjRtBuffer>> MakePjRtBuffersFromPJRT_Buffers(\n+    PjRtCApiClient* client, PJRT_Buffer** c_buffers, size_t num_buffers) {\n+  std::vector<std::unique_ptr<PjRtBuffer>> buffers;\n+  buffers.reserve(num_buffers);\n+  for (int i = 0; i < num_buffers; ++i) {\n+    buffers.emplace_back(\n+        std::make_unique<PjRtCApiBuffer>(client, c_buffers[i]));\n+  }\n+  return buffers;\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+PjRtCApiClient::MakeCrossHostReceiveBuffers(\n+    absl::Span<const Shape> shapes, PjRtDevice* device,\n+    PjRtCrossHostRecvNotifier notifier) {\n+  const PJRT_Api* c_api = pjrt_c_api();\n+  PJRT_CrossHostTransfers_Extension* extension =\n+      FindExtension<PJRT_CrossHostTransfers_Extension>(\n+          PJRT_Extension_Type::PJRT_Extension_Type_CrossHostTransfers);\n+  if (extension == nullptr) {\n+    return absl::UnimplementedError(\n+        \"MakeCrossHostReceiveBuffers is not implemented in this PJRT plugin.\");\n+  }\n+  PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers_Args args;\n+  args.struct_size =\n+      PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers_Args_STRUCT_SIZE;\n+  args.extension_start = nullptr;\n+  args.client = c_client_.get();\n+\n+  ShapesInfo shapes_info = MakeShapesInfo(shapes);\n+  args.num_shapes = shapes.size();\n+  args.shape_num_dims = shapes_info.shape_num_dims.data();\n+  args.num_dims = shapes_info.num_dims.data();\n+  args.element_types = shapes_info.element_type_list.data();\n+  args.layouts = shapes_info.layout_list.data();\n \n   args.notifier = CppCrossHostRecvNotifierToC(c_api, std::move(notifier));\n   args.device = tensorflow::down_cast<PjRtCApiDevice*>(device)->c_device();\n@@ -1044,13 +1077,102 @@ PjRtCApiClient::MakeCrossHostReceiveBuffers(\n   RETURN_STATUS_IF_PJRT_ERROR(\n       extension->PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers(&args),\n       c_api);\n-  std::vector<std::unique_ptr<PjRtBuffer>> buffers;\n-  buffers.reserve(args.num_buffers);\n+\n+  return MakePjRtBuffersFromPJRT_Buffers(this, args.buffers,\n+                                         temp_buffers.size());\n+}\n+\n+absl::StatusOr<std::vector<Future<>>> PjRtCApiClient::CrossHostSendBuffers(\n+    absl::Span<PjRtBuffer* const> buffers,\n+    absl::Span<const PjRtGlobalDeviceId> dst_global_device_ids,\n+    std::vector<CrossHostTransferKey> transfer_keys) {\n+  // Get C API extension.\n+  const PJRT_Api* c_api = pjrt_c_api();\n+  PJRT_CrossHostTransfers_Extension* extension =\n+      FindExtension<PJRT_CrossHostTransfers_Extension>(\n+          PJRT_Extension_Type::PJRT_Extension_Type_CrossHostTransfers);\n+  if (extension == nullptr) {\n+    return absl::UnimplementedError(\n+        \"CrossHostSendBuffers is not implemented in this PJRT plugin.\");\n+  }\n+\n+  // Form inputs.\n+  PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args args;\n+  args.struct_size =\n+      PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args_STRUCT_SIZE;\n+  args.extension_start = nullptr;\n+  args.client = c_client_.get();\n+  args.num_buffers = buffers.size();\n+\n+  std::vector<PJRT_Buffer*> c_buffers;\n+  c_buffers.reserve(buffers.size());\n+  for (PjRtBuffer* buffer : buffers) {\n+    c_buffers.push_back(\n+        tensorflow::down_cast<const PjRtCApiBuffer*>(buffer)->c_buffer());\n+  }\n+\n+  args.buffers = c_buffers.data();\n+  args.dst_global_device_ids = dst_global_device_ids.data();\n+  args.transfer_keys = transfer_keys.data();\n+\n+  auto send_events = std::vector<PJRT_Event*>(args.num_buffers);\n+  args.send_events = send_events.data();\n+\n+  RETURN_STATUS_IF_PJRT_ERROR(\n+      extension->PJRT_Transfers_PJRT_Client_CrossHostSendBuffers(&args), c_api);\n+\n+  std::vector<Future<>> send_futures;\n+  send_futures.reserve(args.num_buffers);\n   for (int i = 0; i < args.num_buffers; ++i) {\n-    buffers.emplace_back(std::unique_ptr<PjRtBuffer>(\n-        std::make_unique<PjRtCApiBuffer>(this, args.buffers[i])));\n+    send_futures.push_back(\n+        pjrt::ConvertCEventToCppFuture(args.send_events[i], c_api));\n   }\n-  return buffers;\n+\n+  return send_futures;\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+PjRtCApiClient::CrossHostReceiveBuffers(\n+    xla::PjRtDevice* device, absl::Span<const xla::Shape> shapes,\n+    absl::Span<const PjRtGlobalDeviceId> src_global_device_ids,\n+    std::vector<CrossHostTransferKey> transfer_keys) {\n+  // Get C API extension.\n+  const PJRT_Api* c_api = pjrt_c_api();\n+  PJRT_CrossHostTransfers_Extension* extension =\n+      FindExtension<PJRT_CrossHostTransfers_Extension>(\n+          PJRT_Extension_Type::PJRT_Extension_Type_CrossHostTransfers);\n+  if (extension == nullptr) {\n+    return absl::UnimplementedError(\n+        \"CrossHostReceiveBuffers is not implemented in this PJRT plugin.\");\n+  }\n+\n+  // Form inputs.\n+  PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args args;\n+  args.struct_size =\n+      PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args_STRUCT_SIZE;\n+  args.extension_start = nullptr;\n+  args.client = c_client_.get();\n+\n+  ShapesInfo shapes_info = MakeShapesInfo(shapes);\n+  args.num_shapes = shapes.size();\n+  args.shape_num_dims = shapes_info.shape_num_dims.data();\n+  args.num_dims = shapes_info.num_dims.data();\n+  args.element_types = shapes_info.element_type_list.data();\n+  args.layouts = shapes_info.layout_list.data();\n+\n+  args.device = tensorflow::down_cast<PjRtCApiDevice*>(device)->c_device();\n+  args.src_global_device_ids = src_global_device_ids.data();\n+  args.transfer_keys = transfer_keys.data();\n+\n+  std::vector<PJRT_Buffer*> temp_buffers(shapes.size());\n+  args.buffers = temp_buffers.data();\n+\n+  RETURN_STATUS_IF_PJRT_ERROR(\n+      extension->PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers(&args),\n+      c_api);\n+\n+  return MakePjRtBuffersFromPJRT_Buffers(this, args.buffers,\n+                                         temp_buffers.size());\n }\n \n class PjRtCApiAsyncHostToDeviceTransferManager"
        },
        {
            "sha": "fde0de94a06b4c0dbe66468d55678b9344d33991",
            "filename": "third_party/xla/xla/pjrt/c_api_client/pjrt_c_api_client.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc_api_client%2Fpjrt_c_api_client.h?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -376,6 +376,17 @@ class PjRtCApiClient : public PjRtClient {\n                               PjRtDevice* device,\n                               PjRtCrossHostRecvNotifier notifier) override;\n \n+  absl::StatusOr<std::vector<Future<>>> CrossHostSendBuffers(\n+      absl::Span<PjRtBuffer* const> buffers,\n+      absl::Span<const PjRtGlobalDeviceId> dst_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) override;\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+  CrossHostReceiveBuffers(\n+      xla::PjRtDevice* device, absl::Span<const xla::Shape> shapes,\n+      absl::Span<const PjRtGlobalDeviceId> src_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) override;\n+\n   absl::Status DmaMap(void* data, size_t size) override;\n \n   absl::Status DmaUnmap(void* data) override;"
        },
        {
            "sha": "a67b4073cb960db9b65d34bc7f626732e8b451c2",
            "filename": "third_party/xla/xla/pjrt/extensions/cross_host_transfers/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2FBUILD?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -13,6 +13,7 @@ cc_library(\n         \"//xla:future\",\n         \"//xla:shape_util\",\n         \"//xla/pjrt:pjrt_client\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt/c:pjrt_c_api_hdrs\",\n         \"//xla/pjrt/c:pjrt_c_api_helpers\",\n         \"//xla/pjrt/c:pjrt_c_api_wrapper_impl\","
        },
        {
            "sha": "fb66794f488880ffbbd82fe1f3726631c673dd5b",
            "filename": "third_party/xla/xla/pjrt/extensions/cross_host_transfers/pjrt_c_api_cross_host_transfers_extension.cc",
            "status": "modified",
            "additions": 76,
            "deletions": 1,
            "changes": 77,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.cc?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -29,10 +29,80 @@ limitations under the License.\n #include \"xla/pjrt/c/pjrt_c_api_helpers.h\"\n #include \"xla/pjrt/c/pjrt_c_api_wrapper_impl.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/shape.h\"\n \n namespace pjrt {\n \n+PJRT_Error* PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers(\n+    PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args* args) {\n+  PJRT_RETURN_IF_ERROR(ActualStructSizeIsGreaterOrEqual(\n+      \"PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args\",\n+      PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args_STRUCT_SIZE,\n+      args->struct_size));\n+\n+  std::vector<xla::Shape> shapes;\n+  shapes.reserve(args->num_shapes);\n+  for (int i = 0; i < args->num_shapes; ++i) {\n+    PJRT_ASSIGN_OR_RETURN(\n+        xla::Shape shape,\n+        pjrt::BuildXlaShapeFromC(args->element_types[i], args->num_dims[i],\n+                                 args->shape_num_dims[i], args->layouts[i]));\n+    shapes.push_back(std::move(shape));\n+  }\n+\n+  std::vector<xla::PjRtGlobalDeviceId> src_global_device_ids;\n+  src_global_device_ids.reserve(args->num_shapes);\n+\n+  std::vector<xla::CrossHostTransferKey> transfer_keys;\n+  transfer_keys.reserve(args->num_shapes);\n+\n+  for (int i = 0; i < args->num_shapes; ++i) {\n+    src_global_device_ids.push_back(args->src_global_device_ids[i]);\n+    transfer_keys.push_back(args->transfer_keys[i]);\n+  }\n+\n+  PJRT_ASSIGN_OR_RETURN(std::vector<std::unique_ptr<xla::PjRtBuffer>> buffers,\n+                        args->client->client->CrossHostReceiveBuffers(\n+                            args->device->device, shapes, src_global_device_ids,\n+                            std::move(transfer_keys)));\n+\n+  for (int i = 0; i < buffers.size(); ++i) {\n+    args->buffers[i] = new PJRT_Buffer{std::move(buffers[i]), args->client};\n+  }\n+  return nullptr;\n+}\n+\n+PJRT_Error* PJRT_Transfers_PJRT_Client_CrossHostSendBuffers(\n+    PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args* args) {\n+  std::vector<xla::PjRtBuffer*> buffers;\n+  buffers.reserve(args->num_buffers);\n+  for (int i = 0; i < args->num_buffers; ++i) {\n+    buffers.push_back(args->buffers[i]->buffer.get());\n+  }\n+\n+  std::vector<xla::PjRtGlobalDeviceId> dst_global_device_ids;\n+  dst_global_device_ids.reserve(args->num_buffers);\n+\n+  std::vector<xla::CrossHostTransferKey> transfer_keys;\n+  transfer_keys.reserve(args->num_buffers);\n+\n+  for (int i = 0; i < args->num_buffers; ++i) {\n+    dst_global_device_ids.push_back(args->dst_global_device_ids[i]);\n+    transfer_keys.push_back(args->transfer_keys[i]);\n+  }\n+\n+  PJRT_ASSIGN_OR_RETURN(\n+      std::vector<tsl::Future<>> send_futures,\n+      args->client->client->CrossHostSendBuffers(buffers, dst_global_device_ids,\n+                                                 std::move(transfer_keys)));\n+\n+  for (int i = 0; i < buffers.size(); ++i) {\n+    args->send_events[i] = new PJRT_Event{std::move(send_futures[i])};\n+  }\n+  return nullptr;\n+}\n+\n namespace {\n static xla::PjRtCrossHostRecvNotifier CCrossHostRecvNotifierToCpp(\n     const PJRT_Transfers_CrossHostRecvNotifierInfo& c_notifier) {\n@@ -110,7 +180,12 @@ PJRT_CrossHostTransfers_Extension CreateCrossHostTransfersExtension(\n       /*PJRT_CrossHostTransfers_PJRT_Client_MakeCrossHostReceiveBuffers=*/\n       PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers,\n       /*PJRT_CrossHostTransfers_PJRT_Buffer_CopyToRemoteDevice=*/\n-      PJRT_Transfers_PJRT_Buffer_CopyToRemoteDevice};\n+      PJRT_Transfers_PJRT_Buffer_CopyToRemoteDevice,\n+      /*PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers=*/\n+      PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers,\n+      /*PJRT_Transfers_PJRT_Client_CrossHostSendBuffers=*/\n+      PJRT_Transfers_PJRT_Client_CrossHostSendBuffers,\n+  };\n }\n \n }  // namespace pjrt"
        },
        {
            "sha": "6c59660cf532bd9550984da91da173bbede8cb31",
            "filename": "third_party/xla/xla/pjrt/extensions/cross_host_transfers/pjrt_c_api_cross_host_transfers_extension.h",
            "status": "modified",
            "additions": 58,
            "deletions": 3,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fextensions%2Fcross_host_transfers%2Fpjrt_c_api_cross_host_transfers_extension.h?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -30,10 +30,58 @@ extern \"C\" {\n // are supported with the PjRtClient::MakeCrossHostReceiveBuffers() and\n // PjRtBuffer::CopyToRemoteDevice() APIs.\n \n-#define PJRT_API_CROSS_HOST_TRANSFERS_EXTENSION_VERSION 1\n+// Version 2 adds an alternate API for cross-host transfers:\n+// CrossHostSendBuffers and CrossHostReceiveBuffers. These methods allow PjRt\n+// clients to implement various optimizations for cross-host transfers.\n+\n+#define PJRT_API_CROSS_HOST_TRANSFERS_EXTENSION_VERSION 2\n \n // ---------------------------------- Methods ----------------------------------\n \n+// Structs and methods prefixed with\n+// PJRT_Transfers_PJRT_Client_CrossHost{Send,Receive}Buffers correspond to the\n+// second cross-host transfers API.\n+struct PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args {\n+  size_t struct_size;\n+  PJRT_Extension_Base* extension_start;\n+  PJRT_Client* client;\n+  size_t num_buffers;\n+  PJRT_Buffer** buffers;\n+  const xla::PjRtGlobalDeviceId*\n+      dst_global_device_ids;                       // Has size num_buffers.\n+  const xla::CrossHostTransferKey* transfer_keys;  // Has size num_buffers.\n+  PJRT_Event** send_events;  // Output; has size num_buffers.\n+};\n+\n+PJRT_DEFINE_STRUCT_TRAITS(PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args,\n+                          send_events);\n+\n+typedef PJRT_Error* PJRT_Transfers_PJRT_Client_CrossHostSendBuffers(\n+    PJRT_Transfers_PJRT_Client_CrossHostSendBuffers_Args* args);\n+\n+struct PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args {\n+  size_t struct_size;\n+  PJRT_Extension_Base* extension_start;\n+  PJRT_Client* client;\n+  size_t num_shapes;\n+  size_t* shape_num_dims;\n+  const int64_t** num_dims;\n+  PJRT_Buffer_Type* element_types;\n+  PJRT_Buffer_MemoryLayout** layouts;\n+  PJRT_Device* device;\n+  const xla::PjRtGlobalDeviceId* src_global_device_ids;  // Has size num_shapes.\n+  const xla::CrossHostTransferKey* transfer_keys;        // Has size num_shapes.\n+  PJRT_Buffer** buffers;  // Output; has size num_shapes.\n+};\n+\n+PJRT_DEFINE_STRUCT_TRAITS(\n+    PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args, buffers);\n+\n+typedef PJRT_Error* PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers(\n+    PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers_Args* args);\n+\n+// The structs and methods below correspond to the original cross-host transfers\n+// API.\n typedef void (*PJRT_Transfers_CrossHostRecvNotifier)(\n     PJRT_Error* error, const char** serialized_descriptors,\n     size_t* descriptors_sizes, size_t num_descriptors, void* user_arg);\n@@ -79,15 +127,22 @@ typedef void PJRT_Buffer_CopyToRemoteDevice(\n \n // --------------------------- Extension entrypoint ----------------------------\n \n+// NOLINTBEGIN: Non-lowercase struct member names follow the convention of the\n+// PJRT C API.\n typedef struct PJRT_CrossHostTransfers_Extension {\n   PJRT_Extension_Base base;\n-\n   PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers*\n       PJRT_Transfers_PJRT_Client_MakeCrossHostReceiveBuffers;\n   PJRT_Buffer_CopyToRemoteDevice* PJRT_Transfers_PJRT_Buffer_CopyToRemoteDevice;\n+  PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers*\n+      PJRT_Transfers_PJRT_Client_CrossHostReceiveBuffers;\n+  PJRT_Transfers_PJRT_Client_CrossHostSendBuffers*\n+      PJRT_Transfers_PJRT_Client_CrossHostSendBuffers;\n } PJRT_CrossHostTransfers_Extension;\n+// NOLINTEND\n+\n PJRT_DEFINE_STRUCT_TRAITS(PJRT_CrossHostTransfers_Extension,\n-                          PJRT_Transfers_PJRT_Buffer_CopyToRemoteDevice);\n+                          PJRT_Transfers_PJRT_Client_CrossHostSendBuffers);\n \n #ifdef __cplusplus\n }"
        },
        {
            "sha": "aaf2460c5f8be606eacbcce0e46f73e350d665b1",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -230,6 +230,7 @@ xla_test(\n         \"//xla/pjrt:local_device_state\",\n         \"//xla/pjrt:mlir_to_hlo\",\n         \"//xla/pjrt:pjrt_client\",\n+        \"//xla/pjrt:pjrt_common\",\n         \"//xla/pjrt:pjrt_compiler\",\n         \"//xla/pjrt:pjrt_device_description\",\n         \"//xla/pjrt:pjrt_executable\","
        },
        {
            "sha": "a6b1ab670b75f4f8bf966e814093d500daabae4e",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 342,
            "deletions": 72,
            "changes": 414,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -61,6 +61,8 @@ limitations under the License.\n #include \"xla/layout.h\"\n #include \"xla/literal.h\"\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n+#include \"xla/pjrt/common_pjrt_client.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/distributed/client.h\"\n #include \"xla/pjrt/distributed/in_memory_key_value_store.h\"\n@@ -353,6 +355,330 @@ absl::Status StreamExecutorGpuClient::UpdateCompileOptionsInternal(\n   return absl::OkStatus();\n }\n \n+std::string CrossHostTransferName(PjRtGlobalDeviceId src_global_device_id,\n+                                  PjRtGlobalDeviceId dst_global_device_id,\n+                                  RunId transfer_run_id) {\n+  return absl::StrCat(\"cross_host_transfer-\", src_global_device_id.value(),\n+                      \"_to_\", dst_global_device_id.value(), \"-run_\",\n+                      transfer_run_id.ToInt());\n+}\n+\n+absl::StatusOr<std::unique_ptr<Communicator>> CreateTransferCommunicator(\n+    LocalDeviceState* local_device, gpu::GpuCollectives* gpu_collectives,\n+    CliqueId clique_id, bool is_sender) {\n+  VLOG(3) << \"Creating a new communicator for cross host transfer, is_sender = \"\n+          << is_sender;\n+\n+  // Create the communicator.\n+  //\n+  // TODO(mwhittaker): The way we are constructing GpuCliqueKeys is a\n+  // big hack. This code doesn't know the GlobalDeviceId of the sending\n+  // process. Instead, we use two arbitrary GlobalDeviceIds. This\n+  // works because NcclCommunicators don't actually use the\n+  // GlobalDeviceIds. Instead, they just need to the know the number\n+  // of devices (2 in this case).\n+  gpu::GpuCliqueKey clique_key(\n+      /*devices=*/{GlobalDeviceId(0), GlobalDeviceId(1)},\n+      /*num_local_participants=*/1);\n+  CliqueIds clique_ids(clique_id);\n+  gpu::GpuCollectives::Device collectives_device(local_device->executor());\n+  std::vector<Collectives::DeviceRank> ranks = {\n+      Collectives::DeviceRank(&collectives_device, RankId(is_sender ? 1 : 0))};\n+  gpu::GpuCollectives::Config config;\n+\n+  TF_ASSIGN_OR_RETURN(std::vector<std::unique_ptr<Communicator>> communicators,\n+                      gpu_collectives->CreateCommunicators(\n+                          clique_key, clique_ids, ranks, config));\n+  CHECK_EQ(communicators.size(), 1);\n+\n+  return std::move(communicators[0]);\n+}\n+\n+absl::StatusOr<std::vector<Future<>>>\n+StreamExecutorGpuClient::CrossHostSendBuffers(\n+    absl::Span<PjRtBuffer* const> buffers,\n+    absl::Span<const PjRtGlobalDeviceId> dst_global_device_ids,\n+    std::vector<CrossHostTransferKey> transfer_keys) {\n+  // Validate arguments.\n+  if (dst_global_device_ids.size() != buffers.size() ||\n+      transfer_keys.size() != buffers.size()) {\n+    return InvalidArgument(\n+        \"CrossHostSendBuffers: buffers, \"\n+        \"dst_global_device_ids, and transfer_keys \"\n+        \"must have the same length, but got %d, %d, and %d.\",\n+        buffers.size(), dst_global_device_ids.size(), transfer_keys.size());\n+  }\n+\n+  // Perform sends.\n+  std::vector<Future<>> out_futures;\n+  out_futures.reserve(buffers.size());\n+  for (int i = 0; i < buffers.size(); ++i) {\n+    TF_ASSIGN_OR_RETURN(\n+        Future<> curr_future,\n+        CrossHostSendBuffer(buffers[i], dst_global_device_ids[i],\n+                            transfer_keys[i]));\n+    out_futures.push_back(std::move(curr_future));\n+  }\n+  return out_futures;\n+}\n+\n+// Helpers used inside CrossHostSendBuffer to acquire a hold on a send buffer\n+// and get its raw buffer and definition events. This is used to ensure that the\n+// buffer is not deleted while the send is in progress.\n+struct HeldSendBuffer {\n+  tsl::RCReference<CommonPjRtRawBuffer> raw_buffer;\n+  std::vector<tsl::RCReference<tsl::AsyncValue>> definition_events;\n+};\n+\n+absl::StatusOr<HeldSendBuffer> AcquireHeldSendBuffer(\n+    tsl::RCReference<PjRtDeviceEvent> usage_event,\n+    CommonPjRtBufferImpl* buffer_impl, const char* caller_name) {\n+  tsl::RCReference<CommonPjRtRawBuffer> raw_buffer;\n+  std::vector<tsl::RCReference<tsl::AsyncValue>> definition_events;\n+\n+  TF_RETURN_IF_ERROR(buffer_impl->AcquireScopedRawBuffer(\n+      [&](tsl::RCReference<CommonPjRtRawBuffer> buf_raw_buffer,\n+          std::vector<tsl::RCReference<tsl::AsyncValue>>\n+              buf_definition_events) mutable\n+          -> absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>> {\n+        raw_buffer = std::move(buf_raw_buffer);\n+        usage_event->AndThen([raw_buffer]() {});\n+        definition_events = std::move(buf_definition_events);\n+        return usage_event;\n+      },\n+      caller_name));\n+\n+  return HeldSendBuffer{std::move(raw_buffer), std::move(definition_events)};\n+}\n+\n+absl::StatusOr<Future<>> StreamExecutorGpuClient::CrossHostSendBuffer(\n+    PjRtBuffer* buffer, PjRtGlobalDeviceId dst_global_device_id,\n+    CrossHostTransferKey transfer_key) {\n+  // Get the default GpuCollectives instance.\n+  TF_ASSIGN_OR_RETURN(Collectives * collectives,\n+                      CollectivesRegistry::Default(\"gpu\"));\n+  gpu::GpuCollectives* gpu_collectives =\n+      tsl::down_cast<gpu::GpuCollectives*>(collectives);\n+\n+  // Get the local device and its id.\n+  PjRtStreamExecutorDevice* pjrt_se_device =\n+      tensorflow::down_cast<PjRtStreamExecutorDevice*>(buffer->device());\n+  TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n+                      pjrt_se_device->GetLocalDeviceState());\n+  PjRtGlobalDeviceId src_global_device_id = pjrt_se_device->global_device_id();\n+\n+  // Get the name of the transfer.\n+  std::string cross_host_transfer_name = CrossHostTransferName(\n+      src_global_device_id, dst_global_device_id, RunId(transfer_key.value()));\n+\n+  // Get the buffer's shape.\n+  TF_ASSIGN_OR_RETURN(Shape shape, buffer->HostShape());\n+\n+  auto [promise, future] = Future<>::MakePromise();\n+\n+  // Create an event to track when the send is done.\n+  auto usage_event = tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(\n+      BufferSequencingEvent::Create(this->thread_pool()));\n+\n+  // Acquire a hold on the buffer and get some metadata.\n+  TF_ASSIGN_OR_RETURN(\n+      HeldSendBuffer held_send_buffer,\n+      AcquireHeldSendBuffer(\n+          usage_event, tensorflow::down_cast<CommonPjRtBufferImpl*>(buffer),\n+          \"CrossHostSendBuffer\"));\n+\n+  auto send = [this, gpu_collectives, promise = std::move(promise),\n+               usage_event = std::move(usage_event),\n+               held_send_buffer = std::move(held_send_buffer), local_device,\n+               cross_host_transfer_name, shape]() mutable {\n+    se::Stream* stream = local_device->GetDeviceToDeviceStream();\n+\n+    auto f = [&]() -> absl::Status {\n+      // Wait until the buffer we want to send is fully materialized.\n+      for (const auto& event : held_send_buffer.definition_events) {\n+        tsl::BlockUntilReady(event.get());\n+        if (auto* status = event->GetErrorIfPresent()) {\n+          return *status;\n+        }\n+      }\n+\n+      // Get the clique ID from the KV store.\n+      TF_ASSIGN_OR_RETURN(std::string descriptor,\n+                          kv_store_->Get(cross_host_transfer_name,\n+                                         cross_host_transfer_timeout_));\n+      CliqueId clique_id(descriptor);\n+\n+      // Create a communicator.\n+      TF_ASSIGN_OR_RETURN(\n+          std::unique_ptr<Communicator> communicator,\n+          CreateTransferCommunicator(local_device, gpu_collectives, clique_id,\n+                                     /*is_sender=*/true));\n+\n+      // Send data to the receiver.\n+      auto mem = tensorflow::down_cast<PjRtStreamExecutorRawBuffer*>(\n+                     held_send_buffer.raw_buffer.get())\n+                     ->device_buffer();\n+\n+      Future<> send_future = communicator->Send(\n+          mem->mem(), shape.element_type(), ShapeUtil::ElementsIn(shape),\n+          RankId(0), gpu::GpuCollectives::On(*stream));\n+      TF_RETURN_IF_ERROR(send_future.Await());\n+\n+      // Mark send as done.\n+      TF_RETURN_IF_ERROR(\n+          AllocateAndRecordEvent(usage_event->event(), local_device, stream));\n+\n+      return absl::OkStatus();\n+    };\n+\n+    absl::Status s = f();\n+    if (!s.ok()) {\n+      SetEventAsError(usage_event->event(), s);\n+    }\n+    promise.Set(s);\n+  };\n+\n+  local_device->execute_thread()->Schedule(std::move(send));\n+  return future;\n+}\n+\n+absl::StatusOr<StreamExecutorGpuClient::PrepareReceiveBufferResult>\n+StreamExecutorGpuClient::PrepareReceiveBuffer(PjRtDevice* device, Shape shape) {\n+  TF_ASSIGN_OR_RETURN(auto* memory_space, device->default_memory_space());\n+  TF_ASSIGN_OR_RETURN(\n+      Shape on_device_shape,\n+      MakeDefaultShapeForMemorySpace(\n+          memory_space, shape, shape.has_layout() ? &shape.layout() : nullptr));\n+  TF_ASSIGN_OR_RETURN(size_t on_device_bytes_count,\n+                      GetOnDeviceBytesCount(memory_space, on_device_shape));\n+\n+  // Allocate an uninitialized buffer. The buffer will be populated with data\n+  // received from the sending process.\n+  TF_ASSIGN_OR_RETURN(tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n+                      AllocateRawBuffer(memory_space, on_device_bytes_count,\n+                                        /*retry_on_oom=*/true,\n+                                        /*allocate_after=*/{}));\n+  TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n+                      tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n+                          ->GetLocalDeviceState());\n+\n+  se::Stream* stream = local_device->GetDeviceToDeviceStream();\n+\n+  BufferSequencingEventRef definition_event =\n+      BufferSequencingEvent::Create(this->thread_pool());\n+  TF_ASSIGN_OR_RETURN(\n+      auto buffer,\n+      DefineBuffer(\n+          on_device_shape, raw_buffer,\n+          {tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(definition_event)},\n+          /*raw_buffer_is_mutable=*/true));\n+\n+  return PrepareReceiveBufferResult{std::move(buffer), std::move(raw_buffer),\n+                                    local_device, stream,\n+                                    std::move(definition_event)};\n+}\n+\n+absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+StreamExecutorGpuClient::CrossHostReceiveBuffers(\n+    xla::PjRtDevice* device, absl::Span<const xla::Shape> shapes,\n+    absl::Span<const PjRtGlobalDeviceId> src_global_device_ids,\n+    std::vector<CrossHostTransferKey> transfer_keys) {\n+  // Validate arguments.\n+  if (shapes.empty()) {\n+    return InvalidArgument(\"shapes parameter empty in CrossHostReceiveBuffers\");\n+  }\n+  if (src_global_device_ids.size() != shapes.size() ||\n+      transfer_keys.size() != shapes.size()) {\n+    return InvalidArgument(\n+        \"CrossHostReceiveBuffers: shapes, src_global_device_ids, and \"\n+        \"transfer_keys must have the same length, but got %d, %d, and %d.\",\n+        shapes.size(), src_global_device_ids.size(), transfer_keys.size());\n+  }\n+\n+  // Perform receives.\n+  std::vector<std::unique_ptr<PjRtBuffer>> receive_buffers;\n+  receive_buffers.reserve(shapes.size());\n+  for (int i = 0; i < shapes.size(); ++i) {\n+    TF_ASSIGN_OR_RETURN(\n+        std::unique_ptr<PjRtBuffer> receive_buffer,\n+        CrossHostReceiveBuffer(shapes[i], device, src_global_device_ids[i],\n+                               transfer_keys[i]));\n+    receive_buffers.push_back(std::move(receive_buffer));\n+  }\n+  return receive_buffers;\n+}\n+\n+absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n+StreamExecutorGpuClient::CrossHostReceiveBuffer(\n+    xla::Shape shape, xla::PjRtDevice* device,\n+    PjRtGlobalDeviceId src_global_device_id,\n+    CrossHostTransferKey transfer_key) {\n+  // Get the default GpuCollectives instance.\n+  TF_ASSIGN_OR_RETURN(Collectives * collectives,\n+                      CollectivesRegistry::Default(\"gpu\"));\n+  gpu::GpuCollectives* gpu_collectives =\n+      tsl::down_cast<gpu::GpuCollectives*>(collectives);\n+\n+  // Get the name of the transfer.\n+  PjRtGlobalDeviceId dst_global_device_id = device->global_device_id();\n+  std::string cross_host_transfer_name = CrossHostTransferName(\n+      src_global_device_id, dst_global_device_id, RunId(transfer_key.value()));\n+\n+  TF_ASSIGN_OR_RETURN(\n+      StreamExecutorGpuClient::PrepareReceiveBufferResult receive_prep_result,\n+      PrepareReceiveBuffer(device, shape));\n+\n+  auto recv = [this, gpu_collectives, cross_host_transfer_name,\n+               local_device = receive_prep_result.local_device,\n+               definition_event = receive_prep_result.definition_event,\n+               stream = receive_prep_result.stream,\n+               raw_buffer = std::move(receive_prep_result.raw_buffer), shape,\n+               dtype = receive_prep_result.buffer->element_type()]() mutable {\n+    WaitForAllocation(stream, *raw_buffer);\n+    auto f = [&]() -> absl::Status {\n+      auto mem =\n+          tensorflow::down_cast<PjRtStreamExecutorRawBuffer*>(raw_buffer.get())\n+              ->device_buffer();\n+\n+      // Construct the clique ID and set the descriptor in the KV store.\n+      TF_ASSIGN_OR_RETURN(CliqueId clique_id,\n+                          gpu_collectives->CreateUniqueCliqueId());\n+      std::string descriptor = clique_id.ToString();\n+      TF_RETURN_IF_ERROR(kv_store_->Set(cross_host_transfer_name, descriptor));\n+\n+      // Create a communicator.\n+      TF_ASSIGN_OR_RETURN(\n+          std::unique_ptr<Communicator> communicator,\n+          CreateTransferCommunicator(local_device, gpu_collectives, clique_id,\n+                                     /*is_sender=*/false));\n+\n+      // Receive data from the sender.\n+      Future<> recv_future = communicator->Recv(\n+          mem->mem(), shape.element_type(), ShapeUtil::ElementsIn(shape),\n+          RankId(1), gpu::GpuCollectives::On(*stream));\n+      TF_RETURN_IF_ERROR(recv_future.Await());\n+\n+      // Keep mem alive until the Recv has finished executing. Note that\n+      // recv_event is fulfilled when the receive is enqueued, but not\n+      // necessarily executed.\n+      definition_event.AndThen([mem]() {});\n+\n+      // Set definition event.\n+      TF_RETURN_IF_ERROR(\n+          AllocateAndRecordEvent(definition_event, local_device, stream));\n+\n+      return absl::OkStatus();\n+    };\n+\n+    if (absl::Status s = f(); !s.ok()) {\n+      SetEventAsError(definition_event, s);\n+    }\n+  };\n+  receive_prep_result.local_device->execute_thread()->Schedule(std::move(recv));\n+\n+  return std::move(receive_prep_result.buffer);\n+}\n+\n void StreamExecutorGpuClient::ScheduleRemoteSend(\n     PjRtMemorySpace* memory_space,\n     tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n@@ -385,8 +711,7 @@ void StreamExecutorGpuClient::ScheduleRemoteSend(\n       [this, gpu_collectives = std::move(gpu_collectives),\n        on_done = std::move(on_done),\n        definition_events = std::move(definition_events),\n-       memory_space = memory_space, raw_buffer = std::move(raw_buffer),\n-       usage_event = usage_event](\n+       raw_buffer = std::move(raw_buffer), usage_event = usage_event](\n           absl::StatusOr<std::string> serialized_descriptor) mutable {\n         if (!serialized_descriptor.ok()) {\n           on_done(serialized_descriptor.status(),\n@@ -419,29 +744,10 @@ void StreamExecutorGpuClient::ScheduleRemoteSend(\n                 CliqueId clique_id(serialized_descriptor);\n \n                 // Create a communicator.\n-                //\n-                // TODO(mwhittaker): The way we are constructing GpuCliqueKeys\n-                // is a big hack. This code doesn't know the GlobalDeviceId of\n-                // the sending process. Instead, we use two arbitrary\n-                // GlobalDeviceIds. This works because NcclCommunicators don't\n-                // actually use the GlobalDeviceIds.  Instead, they just need to\n-                // the know the number of devices (2 in this case).\n-                gpu::GpuCliqueKey clique_key(\n-                    /*devices=*/{GlobalDeviceId(0), GlobalDeviceId(1)},\n-                    /*num_local_participants=*/1);\n-                CliqueIds clique_ids(clique_id);\n-                gpu::GpuCollectives::Device collectives_device(\n-                    local_device->executor());\n-                std::vector<Collectives::DeviceRank> ranks = {\n-                    Collectives::DeviceRank(&collectives_device, RankId(1))};\n-                gpu::GpuCollectives::Config config;\n                 TF_ASSIGN_OR_RETURN(\n-                    std::vector<std::unique_ptr<Communicator>> communicators,\n-                    gpu_collectives->CreateCommunicators(clique_key, clique_ids,\n-                                                         ranks, config));\n-                CHECK_EQ(communicators.size(), 1);\n-                std::unique_ptr<Communicator> communicator =\n-                    std::move(communicators[0]);\n+                    std::unique_ptr<Communicator> communicator,\n+                    CreateTransferCommunicator(local_device, gpu_collectives,\n+                                               clique_id, /*is_sender=*/true));\n \n                 // Send data to the receiver.\n                 Future<> send_future = communicator->Send(\n@@ -491,37 +797,17 @@ StreamExecutorGpuClient::MakeCrossHostReceiveBuffers(\n     return absl::InternalError(\"Failed to get GPU collectives\");\n   }\n \n-  TF_ASSIGN_OR_RETURN(auto* memory_space, device->default_memory_space());\n-  TF_ASSIGN_OR_RETURN(\n-      Shape on_device_shape,\n-      MakeDefaultShapeForMemorySpace(\n-          memory_space, shape, shape.has_layout() ? &shape.layout() : nullptr));\n-  TF_ASSIGN_OR_RETURN(size_t on_device_bytes_count,\n-                      GetOnDeviceBytesCount(memory_space, on_device_shape));\n-  TF_ASSIGN_OR_RETURN(tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n-                      AllocateRawBuffer(memory_space, on_device_bytes_count,\n-                                        /*retry_on_oom=*/true,\n-                                        /*allocate_after=*/{}));\n-\n-  // Allocate an uninitialized buffer. The buffer will be populated with data\n-  // received from the sending process.\n-  TF_ASSIGN_OR_RETURN(LocalDeviceState * local_device,\n-                      tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n-                          ->GetLocalDeviceState());\n-  se::Stream* stream = local_device->GetDeviceToDeviceStream();\n-  BufferSequencingEventRef definition_event =\n-      BufferSequencingEvent::Create(this->thread_pool());\n   TF_ASSIGN_OR_RETURN(\n-      auto buffer,\n-      DefineBuffer(\n-          on_device_shape, raw_buffer,\n-          {tsl::MakeRef<PjRtStreamExecutorDeviceEvent>(definition_event)},\n-          /*raw_buffer_is_mutable=*/true));\n+      StreamExecutorGpuClient::PrepareReceiveBufferResult receive_prep_result,\n+      PrepareReceiveBuffer(device, shape));\n \n   auto recv = [this, gpu_collectives, notifier = std::move(notifier),\n-               local_device, definition_event, stream,\n-               raw_buffer = std::move(raw_buffer), shape = shapes[0],\n-               dtype = buffer->element_type()]() mutable {\n+               local_device = receive_prep_result.local_device,\n+               definition_event = receive_prep_result.definition_event,\n+               stream = receive_prep_result.stream,\n+               raw_buffer = std::move(receive_prep_result.raw_buffer),\n+               shape = shapes[0],\n+               dtype = receive_prep_result.buffer->element_type()]() mutable {\n     WaitForAllocation(stream, *raw_buffer);\n     auto f = [&]() -> absl::Status {\n       // Create a CliqueId.\n@@ -542,26 +828,10 @@ StreamExecutorGpuClient::MakeCrossHostReceiveBuffers(\n       });\n \n       // Create a communicator.\n-      //\n-      // TODO(mwhittaker): The way we are constructing GpuCliqueKeys is a big\n-      // hack. This code doesn't know the GlobalDeviceId of the sending process.\n-      // Instead, we use two arbitrary GlobalDeviceIds. This works because\n-      // NcclCommunicators don't actually use the GlobalDeviceIds. Instead, they\n-      // just need to the know the number of devices (2 in this case).\n-      gpu::GpuCliqueKey clique_key(\n-          /*devices=*/{GlobalDeviceId(0), GlobalDeviceId(1)},\n-          /*num_local_participants=*/1);\n-      CliqueIds clique_ids(clique_id);\n-      gpu::GpuCollectives::Device collectives_device(local_device->executor());\n-      std::vector<Collectives::DeviceRank> ranks = {\n-          Collectives::DeviceRank(&collectives_device, RankId(0))};\n-      gpu::GpuCollectives::Config config;\n       TF_ASSIGN_OR_RETURN(\n-          std::vector<std::unique_ptr<Communicator>> communicators,\n-          gpu_collectives->CreateCommunicators(clique_key, clique_ids, ranks,\n-                                               config));\n-      CHECK_EQ(communicators.size(), 1);\n-      std::unique_ptr<Communicator> communicator = std::move(communicators[0]);\n+          std::unique_ptr<Communicator> communicator,\n+          CreateTransferCommunicator(local_device, gpu_collectives, clique_id,\n+                                     /*is_sender=*/false));\n \n       // Receive data from the sender.\n       Future<> recv_future = communicator->Recv(\n@@ -588,7 +858,7 @@ StreamExecutorGpuClient::MakeCrossHostReceiveBuffers(\n   thread_pool()->Schedule(recv);\n \n   std::vector<std::unique_ptr<PjRtBuffer>> buffers;\n-  buffers.push_back(std::move(buffer));\n+  buffers.push_back(std::move(receive_prep_result.buffer));\n   return buffers;\n }\n "
        },
        {
            "sha": "383d40cf0d817563b5005293c228431962caa25e",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.h",
            "status": "modified",
            "additions": 38,
            "deletions": 0,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.h?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -140,6 +140,21 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n       std::optional<absl::Span<const std::optional<Layout>>> device_layouts,\n       PjRtMemorySpace* memory_space) override;\n \n+  // CrossHostSendBuffers and CrossHostReceiveBuffers are part of the new\n+  // cross-host transfers API.\n+  absl::StatusOr<std::vector<Future<>>> CrossHostSendBuffers(\n+      absl::Span<PjRtBuffer* const> buffers,\n+      absl::Span<const PjRtGlobalDeviceId> dst_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) override;\n+\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+  CrossHostReceiveBuffers(\n+      xla::PjRtDevice* device, absl::Span<const xla::Shape> shapes,\n+      absl::Span<const PjRtGlobalDeviceId> src_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) override;\n+\n+  // ScheduleRemoteSend and MakeCrossHostReceiveBuffers are methods implemented\n+  // to support the legacy cross-host transfers API.\n   void ScheduleRemoteSend(\n       PjRtMemorySpace* memory_space,\n       tsl::RCReference<CommonPjRtRawBuffer> raw_buffer,\n@@ -186,6 +201,29 @@ class StreamExecutorGpuClient : public xla::PjRtStreamExecutorClient {\n   const bool abort_collectives_on_failure_ = false;\n   std::optional<xla::StreamExecutorGpuTopologyDescription> topology_;\n   std::shared_ptr<KeyValueStoreInterface> kv_store_;\n+\n+  // Helpers for cross host transfers.\n+  absl::Duration cross_host_transfer_timeout_ = absl::Minutes(3);\n+\n+  absl::StatusOr<Future<>> CrossHostSendBuffer(\n+      PjRtBuffer* buffer, PjRtGlobalDeviceId dst_global_device_id,\n+      CrossHostTransferKey transfer_key);\n+\n+  struct PrepareReceiveBufferResult {\n+    std::unique_ptr<PjRtBuffer> buffer;\n+    tsl::RCReference<CommonPjRtRawBuffer> raw_buffer;\n+    LocalDeviceState* local_device;\n+    se::Stream* stream;\n+    BufferSequencingEventRef definition_event;\n+  };\n+\n+  absl::StatusOr<PrepareReceiveBufferResult> PrepareReceiveBuffer(\n+      PjRtDevice* device, Shape shape);\n+\n+  absl::StatusOr<std::unique_ptr<PjRtBuffer>> CrossHostReceiveBuffer(\n+      xla::Shape shape, xla::PjRtDevice* device,\n+      PjRtGlobalDeviceId src_global_device_ids,\n+      CrossHostTransferKey transfer_keys);\n };\n \n std::vector<std::unique_ptr<PjRtStreamExecutorDevice>> BuildLocalDevices("
        },
        {
            "sha": "7306b63e10ba8005ff848b0ed84ed75a4b383ec5",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 331,
            "deletions": 4,
            "changes": 335,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -73,6 +73,7 @@ limitations under the License.\n #include \"xla/pjrt/local_device_state.h\"\n #include \"xla/pjrt/mlir_to_hlo.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/pjrt_compiler.h\"\n #include \"xla/pjrt/pjrt_device_description.h\"\n #include \"xla/pjrt/pjrt_executable.h\"\n@@ -2914,6 +2915,283 @@ TEST(StreamExecutorGpuClientTest, LinkedEventPromise) {\n   ASSERT_EQ(literal, *new_literal);\n }\n \n+TEST(StreamExecutorGpuClientTest, FailedCrossHostSendArgsSizeMismatch) {\n+  // Create the client.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<PjRtClient> client,\n+                          GetStreamExecutorGpuClient(DefaultOptions()));\n+\n+  // Create a buffer to try to send.\n+  std::vector<int32_t> data(256);\n+  std::iota(data.begin(), data.end(), 1);\n+\n+  Shape shape = ShapeUtil::MakeShape(S32, {256});\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<PjRtBuffer> buffer,\n+      client->BufferFromHostBuffer(\n+          data.data(), shape.element_type(), shape.dimensions(),\n+          /*byte_strides=*/std::nullopt,\n+          PjRtClient::HostBufferSemantics::kImmutableOnlyDuringCall, nullptr,\n+          *client->addressable_devices()[0]->default_memory_space(),\n+          /*device_layout=*/nullptr));\n+\n+  // Try to send some data, giving an extra dst_global_device_id.\n+  EXPECT_THAT(\n+      client->CrossHostSendBuffers(\n+          {buffer.get()}, {PjRtGlobalDeviceId(1), PjRtGlobalDeviceId(2)},\n+          {CrossHostTransferKey(0)}),\n+      absl_testing::StatusIs(\n+          absl::StatusCode::kInvalidArgument,\n+          ::testing::StrEq(\"CrossHostSendBuffers: buffers, \"\n+                           \"dst_global_device_ids, and transfer_keys \"\n+                           \"must have the same length, but got 1, 2, and 1.\")));\n+\n+  // Try to send some data, giving and extra transfer key.\n+  EXPECT_THAT(\n+      client->CrossHostSendBuffers(\n+          {buffer.get()}, {PjRtGlobalDeviceId(1)},\n+          {CrossHostTransferKey(0), CrossHostTransferKey(1)}),\n+      absl_testing::StatusIs(\n+          absl::StatusCode::kInvalidArgument,\n+          ::testing::StrEq(\"CrossHostSendBuffers: buffers, \"\n+                           \"dst_global_device_ids, and transfer_keys \"\n+                           \"must have the same length, but got 1, 1, and 2.\")));\n+}\n+\n+TEST(StreamExecutorGpuClientTest, FailedCrossHostReceiveArgsSizeMismatch) {\n+  // Create the client.\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<PjRtClient> client,\n+                          GetStreamExecutorGpuClient(DefaultOptions()));\n+\n+  // Create shapes to receive.\n+  std::vector<Shape> shapes = {ShapeUtil::MakeShape(S32, {256})};\n+\n+  // Check InvalidArgument status when we don't give enough\n+  // src_global_device_ids.\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+      mismatch_status_or_1 = client->CrossHostReceiveBuffers(\n+          /*device=*/client->addressable_devices()[0],\n+          /*shapes=*/shapes,\n+          /*src_global_device_ids=*/{},\n+          /*transfer_keys=*/{CrossHostTransferKey(0)});\n+  EXPECT_THAT(\n+      mismatch_status_or_1.status(),\n+      absl_testing::StatusIs(\n+          absl::StatusCode::kInvalidArgument,\n+          ::testing::StrEq(\n+              \"CrossHostReceiveBuffers: shapes, src_global_device_ids, and \"\n+              \"transfer_keys must have the same length, but got 1, 0, and \"\n+              \"1.\")));\n+\n+  // Check InvalidArgument status when we give too many\n+  // transfer_keys.\n+  absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+      mismatch_status_or_2 = client->CrossHostReceiveBuffers(\n+          /*device=*/client->addressable_devices()[0],\n+          /*shapes=*/shapes,\n+          /*src_global_device_ids=*/{PjRtGlobalDeviceId(0)},\n+          /*transfer_keys=*/{CrossHostTransferKey(0), CrossHostTransferKey(1)});\n+  EXPECT_THAT(\n+      mismatch_status_or_2.status(),\n+      absl_testing::StatusIs(\n+          absl::StatusCode::kInvalidArgument,\n+          ::testing::StrEq(\n+              \"CrossHostReceiveBuffers: shapes, src_global_device_ids, and \"\n+              \"transfer_keys must have the same length, but got 1, 1, and \"\n+              \"2.\")));\n+}\n+\n+static std::string SuccessfulCrossHostTransferTestName(\n+    const ::testing::TestParamInfo<int>& info) {\n+  return absl::StrFormat(\"num_arrays_%d\", info.param);\n+}\n+\n+class SuccessfulCrossHostTransferTest : public ::testing::TestWithParam<int> {};\n+\n+TEST_P(SuccessfulCrossHostTransferTest, SuccessfulCrossHostTransfer) {\n+  int num_arrays = GetParam();\n+\n+  tsl::SubProcess sender;\n+  tsl::SubProcess receiver;\n+\n+  std::vector<std::string> sender_argv;\n+  sender_argv.push_back(\"successful_cross_host_transfer_test\");\n+  sender_argv.push_back(\"--test_to_run=SuccessfulCrossHostTransferHelper\");\n+  sender_argv.push_back(\"--cross_host_test_role=sender\");\n+  sender_argv.push_back(absl::StrFormat(\"--num_arrays=%d\", num_arrays));\n+\n+  std::vector<std::string> receiver_argv;\n+  receiver_argv.push_back(\"successful_cross_host_transfer_test\");\n+  receiver_argv.push_back(\"--test_to_run=SuccessfulCrossHostTransferHelper\");\n+  receiver_argv.push_back(\"--cross_host_test_role=receiver\");\n+  receiver_argv.push_back(absl::StrFormat(\"--num_arrays=%d\", num_arrays));\n+\n+  sender.SetProgram(\"/proc/self/exe\", sender_argv);\n+  sender.SetChannelAction(tsl::CHAN_STDOUT, tsl::ACTION_PIPE);\n+  sender.SetChannelAction(tsl::CHAN_STDERR, tsl::ACTION_PIPE);\n+\n+  receiver.SetProgram(\"/proc/self/exe\", receiver_argv);\n+  receiver.SetChannelAction(tsl::CHAN_STDOUT, tsl::ACTION_PIPE);\n+  receiver.SetChannelAction(tsl::CHAN_STDERR, tsl::ACTION_PIPE);\n+\n+  ASSERT_TRUE(sender.Start());\n+  ASSERT_TRUE(receiver.Start());\n+\n+  std::string sender_stdout, sender_stderr;\n+  std::string receiver_stdout, receiver_stderr;\n+\n+  int sender_status =\n+      sender.Communicate(nullptr, &sender_stdout, &sender_stderr);\n+  int receiver_status =\n+      receiver.Communicate(nullptr, &receiver_stdout, &receiver_stderr);\n+\n+  EXPECT_EQ(sender_status, 0) << \"sender stdout:\\n\"\n+                              << sender_stdout << \"\\nsender stderr:\\n\"\n+                              << sender_stderr;\n+  EXPECT_EQ(receiver_status, 0) << \"receiver stdout:\\n\"\n+                                << receiver_stdout << \"\\nreceiver stderr:\\n\"\n+                                << receiver_stderr;\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(SuccessfulCrossHostTransfer,\n+                         SuccessfulCrossHostTransferTest,\n+                         ::testing::ValuesIn({1, 2, 3}),\n+                         SuccessfulCrossHostTransferTestName);\n+\n+absl::Status SuccessfulCrossHostTransferTestBody(bool is_sender,\n+                                                 int num_arrays) {\n+  std::string log_prefix = is_sender ? \"sender\" : \"receiver\";\n+\n+  // Sender creates a coordination service on so both processes can find each\n+  // other via the distributed runtime (port chosen arbitrarily).\n+  std::unique_ptr<xla::DistributedRuntimeService> service;\n+  if (is_sender) {\n+    LOG(INFO) << log_prefix << \": creating coordination service\";\n+    TF_ASSIGN_OR_RETURN(\n+        service, xla::GetDistributedRuntimeService(\n+                     \"127.0.0.1:12347\",\n+                     xla::CoordinationServiceImpl::Options{/*num_nodes=*/2}));\n+    LOG(INFO) << log_prefix << \": created service\";\n+  }\n+\n+  // Connect to the coordination service.\n+  int32_t node_id = is_sender ? 0 : 1;\n+  xla::DistributedRuntimeClient::Options distributed_options;\n+  distributed_options.node_id = node_id;\n+  distributed_options.init_timeout = absl::Seconds(120);\n+  auto distributed_client =\n+      GetDistributedRuntimeClient(\"127.0.0.1:12347\", distributed_options);\n+\n+  LOG(INFO) << log_prefix << \": connecting distributed client\";\n+  TF_QCHECK_OK(distributed_client->Connect());\n+  LOG(INFO) << log_prefix << \": distributed client connected\";\n+\n+  // Create the GPU client.\n+  GpuClientOptions options = DefaultOptions();\n+  options.node_id = node_id;\n+  options.num_nodes = 2;\n+  options.kv_store =\n+      GetDistributedKeyValueStore(distributed_client, /*key_prefix=*/\"cross:\");\n+  options.allowed_devices = {node_id};\n+\n+  LOG(INFO) << log_prefix << \": creating PjRtClient\";\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<PjRtClient> client,\n+                      GetStreamExecutorGpuClient(options));\n+  LOG(INFO) << log_prefix << \": PjRtClient created\";\n+\n+  // Sender logic.\n+  if (is_sender) {\n+    LOG(INFO) << log_prefix << \": creating buffers\";\n+    std::vector<int32_t> data(256);\n+    std::iota(data.begin(), data.end(), 1);\n+    Shape shape = ShapeUtil::MakeShape(S32, {256});\n+\n+    // Create the data to send.\n+    std::vector<std::unique_ptr<PjRtBuffer>> buffers;\n+    for (int i = 0; i < num_arrays; ++i) {\n+      TF_ASSIGN_OR_RETURN(\n+          std::unique_ptr<PjRtBuffer> buffer,\n+          client->BufferFromHostBuffer(\n+              data.data(), shape.element_type(), shape.dimensions(),\n+              /*byte_strides=*/std::nullopt,\n+              PjRtClient::HostBufferSemantics::kImmutableOnlyDuringCall,\n+              nullptr,\n+              *client->addressable_devices()[0]->default_memory_space(),\n+              /*device_layout=*/nullptr));\n+      TF_RETURN_IF_ERROR(buffer->GetReadyFuture().Await());\n+      buffers.push_back(std::move(buffer));\n+    }\n+\n+    // Send some data.\n+    LOG(INFO) << log_prefix << \": issuing CrossHostSendBuffers\";\n+\n+    std::vector<PjRtBuffer*> raw_buffers;\n+    std::vector<PjRtGlobalDeviceId> dst_device_ids;\n+    std::vector<CrossHostTransferKey> transfer_keys;\n+    for (int i = 0; i < buffers.size(); ++i) {\n+      raw_buffers.push_back(buffers[i].get());\n+      dst_device_ids.push_back(PjRtGlobalDeviceId(1));\n+      transfer_keys.push_back(CrossHostTransferKey(i));\n+    };\n+\n+    TF_ASSIGN_OR_RETURN(\n+        std::vector<Future<>> send_futures,\n+        client->CrossHostSendBuffers(raw_buffers, dst_device_ids,\n+                                     std::move(transfer_keys)));\n+\n+    EXPECT_EQ(send_futures.size(), num_arrays);\n+    for (int i = 0; i < num_arrays; ++i) {\n+      LOG(INFO) << log_prefix << \": waiting for send \" << i << \" to complete\";\n+      TF_RETURN_IF_ERROR(send_futures[i].Await());\n+      LOG(INFO) << log_prefix << \": send \" << i << \" completed\";\n+    }\n+  } else {\n+    // Receiver logic.\n+    // Expected data to receive.\n+    std::vector<int32_t> expected_data(256);\n+    std::iota(expected_data.begin(), expected_data.end(), 1);\n+    auto expected_literal = LiteralUtil::CreateR1<int32_t>(expected_data);\n+\n+    // Receive some data.\n+    std::vector<Shape> shapes;\n+    std::vector<PjRtGlobalDeviceId> src_device_ids;\n+    std::vector<CrossHostTransferKey> transfer_keys;\n+    for (int i = 0; i < num_arrays; ++i) {\n+      shapes.push_back(ShapeUtil::MakeShape(S32, {256}));\n+      src_device_ids.push_back(PjRtGlobalDeviceId(0));\n+      transfer_keys.push_back(CrossHostTransferKey(i));\n+    }\n+\n+    LOG(INFO) << log_prefix << \": calling CrossHostReceiveBuffers\";\n+    TF_ASSIGN_OR_RETURN(\n+        std::vector<std::unique_ptr<PjRtBuffer>> receive_buffers,\n+        client->CrossHostReceiveBuffers(client->addressable_devices()[0],\n+                                        shapes, src_device_ids,\n+                                        std::move(transfer_keys)));\n+    LOG(INFO) << log_prefix\n+              << \": CrossHostReceiveBuffers returned, waiting for ready\";\n+\n+    // Verify we received the expected data.\n+    EXPECT_EQ(receive_buffers.size(), num_arrays);\n+\n+    for (int i = 0; i < num_arrays; ++i) {\n+      LOG(INFO) << log_prefix << \": waiting for receive \" << i\n+                << \" to complete\";\n+      TF_RETURN_IF_ERROR(receive_buffers[i]->GetReadyFuture().Await());\n+      LOG(INFO) << log_prefix << \": receive \" << i << \" completed\";\n+\n+      TF_ASSIGN_OR_RETURN(std::shared_ptr<xla::Literal> recv_literal,\n+                          receive_buffers[i]->ToLiteralSync());\n+\n+      EXPECT_TRUE(LiteralTestUtil::Equal(expected_literal, *recv_literal));\n+      LOG(INFO) << log_prefix << \": verification of receive \" << i\n+                << \" complete\";\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n struct ShardedAutotuningTestInfo {\n   bool use_xla_computation;\n   int num_active_nodes;\n@@ -2952,6 +3230,7 @@ TEST_P(ShardedAutotuningTest, ShardedAutotuningWorks) {\n       std::vector<std::string> argv;\n       argv.reserve(6);\n       argv.push_back(\"sharded_autotuning_test\");\n+      argv.push_back(\"--test_to_run=ShardedAutotuningWorksHelper\");\n       argv.push_back(absl::StrFormat(\"--node_id=%d\", node_id));\n       argv.push_back(absl::StrFormat(\"--use_xla_computation=%d\",\n                                      param.use_xla_computation));\n@@ -3106,13 +3385,30 @@ INSTANTIATE_TEST_SUITE_P(\n }  // namespace xla\n \n int main(int argc, char* argv[]) {\n-  // Save name of binary so that it may invoke itself.\n+  // Populated by a command line flag. Will be either\n+  // 'ShardedAutotuningWorksHelper', 'SuccessfulCrossHostTransferHelper', or\n+  // empty. If empty, all tests are run. Otherwise, the test body for\n+  // 'ShardedAutotuningWorks' or 'SuccessfulCrossHostTransfer' will be run.\n+  std::string test_to_run;\n+\n+  // Variables used by ShardedAutotuningWorks.\n   int node_id = -1;\n   int num_active_nodes = -1;\n   int num_nodes_using_cache = -1;\n   std::string cache_dir;\n   bool use_xla_computation = false;\n+\n+  // Variables used by SuccessfulCrossHostTransfer.\n+  std::string cross_host_test_role;\n+  int num_arrays = -1;\n+\n   std::vector<tsl::Flag> flag_list = {\n+      tsl::Flag(\"test_to_run\", &test_to_run,\n+                \"Which test(s) to execute. Allowed values: '' (runs \"\n+                \"all tests), 'ShardedAutotuningWorksHelper' or \"\n+                \"'SuccessfulCrossHostTransferHelper'.\"),\n+\n+      // Flags for ShardedAutotuningWorks.\n       tsl::Flag(\"node_id\", &node_id,\n                 \"Node ID for ShardedAutotuningWorks test.\"),\n       tsl::Flag(\"num_active_nodes\", &num_active_nodes,\n@@ -3123,12 +3419,25 @@ int main(int argc, char* argv[]) {\n                 \"Test parameter for ShardedAutotuningWorks.\"),\n       tsl::Flag(\"use_xla_computation\", &use_xla_computation,\n                 \"Test parameter for ShardedAutotuningWorks.\"),\n-  };\n+\n+      // Flags for SuccessfulCrossHostTransfer.\n+      tsl::Flag(\"cross_host_test_role\", &cross_host_test_role,\n+                \"Test parameter for SuccessfulCrossHostTransfer; either \"\n+                \"'sender' or 'receiver'.\"),\n+      tsl::Flag(\"num_arrays\", &num_arrays,\n+                \"Test parameter for SuccessfulCrossHostTransfer; number of \"\n+                \"arrays to transfer.\")};\n+\n   xla::AppendDebugOptionsFlags(&flag_list);\n   std::string usage = tsl::Flags::Usage(argv[0], flag_list);\n   tsl::Flags::Parse(&argc, argv, flag_list);\n+\n   testing::InitGoogleTest(&argc, argv);\n-  if (node_id >= 0) {\n+  if (test_to_run.empty()) {\n+    return RUN_ALL_TESTS();\n+  }\n+\n+  if (test_to_run == \"ShardedAutotuningWorksHelper\") {\n     absl::Status result = xla::ShardedAutotuningWorksTestBody(\n         node_id, num_active_nodes, num_nodes_using_cache, cache_dir,\n         use_xla_computation);\n@@ -3137,5 +3446,23 @@ int main(int argc, char* argv[]) {\n     }\n     return result.raw_code();\n   }\n-  return RUN_ALL_TESTS();\n+  if (test_to_run == \"SuccessfulCrossHostTransferHelper\") {\n+    absl::Status s;\n+    if (cross_host_test_role == \"sender\") {\n+      s = xla::SuccessfulCrossHostTransferTestBody(/*is_sender=*/true,\n+                                                   num_arrays);\n+    } else if (cross_host_test_role == \"receiver\") {\n+      s = xla::SuccessfulCrossHostTransferTestBody(/*is_sender=*/false,\n+                                                   num_arrays);\n+    } else {\n+      LOG(ERROR) << \"cross_host_test_role must be 'sender' or 'receiver'.\";\n+      return 1;\n+    }\n+    if (!s.ok()) {\n+      LOG(ERROR) << s;\n+    }\n+    return s.raw_code();\n+  }\n+  LOG(ERROR) << \"Unrecognized multiprocess test name \" << test_to_run << \".\";\n+  return 1;\n }"
        },
        {
            "sha": "51c553f7840e017ac9559a7f2b2ac33d2991073f",
            "filename": "third_party/xla/xla/pjrt/pjrt_client.h",
            "status": "modified",
            "additions": 55,
            "deletions": 20,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dbd803eed66a2f926fc0ff453bff7ce03d17b7ea/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_client.h?ref=dbd803eed66a2f926fc0ff453bff7ce03d17b7ea",
            "patch": "@@ -59,6 +59,7 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/framework/allocator.h\"\n+#include \"xla/tsl/lib/gtl/int_type.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/protobuf/coordination_service.pb.h\"\n@@ -443,14 +444,18 @@ struct PjRtPluginAttributes {\n   absl::flat_hash_map<std::string, PjRtValueType> attributes;\n };\n \n+// Each cross-host transfer in the second transfers API is associated with a\n+// unique CrossHostTransferKey.\n+TSL_LIB_GTL_DEFINE_INT_TYPE(CrossHostTransferKey, int64_t);\n+\n // Encapsulates the state of Python session with XLA.\n //\n // It is the responsibility of the client of this API to keep the PjRtClient\n // alive as long as any of the other runtime objects are alive.\n //\n // A note on the semantics of cross-device copies.\n //\n-// There are two mechanisms to transfer a buffer from one device to another.\n+// There are three mechanisms to transfer a buffer from one device to another.\n // When both devices are on the same host (more specifically, the user program\n // ends up with pointers to both the source and destination buffers in the same\n // address space), the caller can use:\n@@ -460,18 +465,25 @@ struct PjRtPluginAttributes {\n // made via native device networking (as opposed to the user program fetching\n // the buffer and sending it using its own networking code), the caller can\n // use:\n+//   DstHost: dst_client->CrossHostReceiveBuffers(...)\n+//   SrcHost: src_client->CrossHostSendBuffers(...)\n+//\n+// The caller can also use the original cross-host transfers API:\n //   DstHost: dst_client->MakeCrossHostReceiveBuffers(...)\n //   DstHost: [...]\n //   DstHost: gets callback containing PjRtCrossHostRecvDescriptors\n //   DstHost: sends cross-host recv serialized descriptors to SrcHost\n //   SrcHost: src_buffer->CopyToRemoteDevice(serialized_descriptors)\n //\n+// See subclass documentation for platform-specific tradeoffs between the\n+// two cross-host transfer methods.\n+//\n // Note that in the cross-host case, the dst_client may call\n-// MakeCrossHostReceiveBuffers before the action that produces src_buffer has\n+// (Make)CrossHostReceiveBuffers before the action that produces src_buffer has\n // been enqueued at SrcHost.\n //\n // On some platforms, device-to-device transfers consume scarce hardware\n-// resources. If dst_client->MakeCrossHostReceiveBuffers immediately claimed\n+// resources. If dst_client->(Make)CrossHostReceiveBuffers immediately claimed\n // those resources, then there would be a risk of system-wide deadlock, if the\n // resources claimed by the recv prevented other transfers that are necessary\n // to generate src_buffer from acquiring enough resources to proceed.\n@@ -965,16 +977,16 @@ class PjRtClient {\n   virtual absl::StatusOr<std::uintptr_t> UnsafeBufferPointer(\n       PjRtBuffer* buffer);\n \n-  // Returns a vector of PjRtBuffers that can be used to receive\n-  // cross host transfers using `client` on `device'. Asynchronously calls\n-  // `notifier` once receive descriptors are ready to be communicated to the\n-  // sender. `shapes` must be the exact shapes, with identical layouts,\n-  // corresponding to the buffers that will be sent. When resources for the\n-  // transfer are available, notifier will be called with a vector of\n-  // PjRtCrossHostRecvDescriptors structs, one for each shape in `shapes`. Each\n-  // struct contains an opaque string that should be transmitted to the sending\n-  // host and used in a call to CopyToRemoteDevice. None of the recv buffers\n-  // will become ready until *all* of the sends have completed.\n+  // Part of original cross-host transfers API. Returns a vector of PjRtBuffers\n+  // that can be used to receive cross host transfers using `client` on\n+  // `device'. Asynchronously calls `notifier` once receive descriptors are\n+  // ready to be communicated to the sender. `shapes` must be the exact shapes,\n+  // with identical layouts, corresponding to the buffers that will be sent.\n+  // When resources for the transfer are available, notifier will be called with\n+  // a vector of PjRtCrossHostRecvDescriptors structs, one for each shape in\n+  // `shapes`. Each struct contains an opaque string that should be transmitted\n+  // to the sending host and used in a call to CopyToRemoteDevice. None of the\n+  // recv buffers will become ready until *all* of the sends have completed.\n   //\n   // If MakeCrossHostReceiveBuffers returns an error, then `notifier` will not\n   // be called. Otherwise `notifier` will be called exactly once. In the case\n@@ -1012,6 +1024,28 @@ class PjRtClient {\n         \"DmaUnmap not supported on platform %s\", platform_name()));\n   }\n \n+  // CrossHostSendBuffers and CrossHostReceiveBuffers are part of the second\n+  // cross-host transfers API.\n+\n+  // Send buffers to remote devices specified by dst_global_device_ids.\n+  virtual absl::StatusOr<std::vector<Future<>>> CrossHostSendBuffers(\n+      absl::Span<PjRtBuffer* const> buffers,\n+      absl::Span<const PjRtGlobalDeviceId> dst_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) {\n+    return absl::InternalError(\n+        \"Cross-host data transfers are not supported by this client.\");\n+  }\n+\n+  // Places buffers from a cross-host send onto device.\n+  virtual absl::StatusOr<std::vector<std::unique_ptr<PjRtBuffer>>>\n+  CrossHostReceiveBuffers(\n+      xla::PjRtDevice* device, absl::Span<const xla::Shape> shapes,\n+      absl::Span<const PjRtGlobalDeviceId> src_global_device_ids,\n+      std::vector<CrossHostTransferKey> transfer_keys) {\n+    return absl::UnimplementedError(\n+        \"Cross-host data transfers are not supported.\");\n+  }\n+\n  private:\n   std::unique_ptr<PjRtHostMemoryForDeviceManager>\n       host_memory_for_device_manager_;\n@@ -1225,13 +1259,14 @@ class PjRtBuffer {\n   virtual absl::StatusOr<std::unique_ptr<PjRtBuffer>> CopyToMemorySpace(\n       PjRtMemorySpace* dst_memory_space) = 0;\n \n-  // Prepares to send a copy of the buffer to a remote device. The destination\n-  // device is encoded in `serialized_descriptor`, which must be fulfilled by\n-  // the result of call to MakeCrossHostReceiveBuffers on the remote host's\n-  // destination device. MakeCrossHostReceiveBuffers takes an array of shapes to\n-  // construct the destination buffers, and a callback supplies an array\n-  // containing both the destination buffers, and a serialized descriptor for\n-  // each buffer. For each destination buffer there should be a matching call to\n+  // Part of original cross-host transfers API. Prepares to send a copy of the\n+  // buffer to a remote device. The destination device is encoded in\n+  // `serialized_descriptor`, which must be fulfilled by the result of call to\n+  // MakeCrossHostReceiveBuffers on the remote host's destination device.\n+  // MakeCrossHostReceiveBuffers takes an array of shapes to construct the\n+  // destination buffers, and a callback supplies an array containing both the\n+  // destination buffers, and a serialized descriptor for each buffer. For each\n+  // destination buffer there should be a matching call to\n   // src->CopyToRemoteDevice on a remote host for a src buffer of the\n   // corresponding shape. If `serialized_descriptor` is fulfilled with a non-Ok\n   // status, then the transfer is canceled, otherwise it must be the string"
        }
    ],
    "stats": {
        "total": 1190,
        "additions": 1063,
        "deletions": 127
    }
}