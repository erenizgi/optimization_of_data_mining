{
    "author": "shawnwang18",
    "message": "PR #28740: [XLA:GPU] Lowering dynamic update slice thunk into command buffer if it depends on loop iteration.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/28740\n\nThis is PR tries to lower DynamicSliceThunk into command buffer, even if it depends on the loop iteration.\n\nThe command buffer implementation will also use the same approach (HloEvaluator to get new allocation during runtime) as DynamicSLiceThunk to get the sliced allocations, and for each iteration, CommandBuffer will use HloEvalutor to get the new addresses, and doing graph update with the new address.\n\nThe major changes to custom.cc file is to resolve the issue that when a module has been parsed by command buffer scheduler, it rewrites the module into nested calls, which breaks the while loop analysis pattern, and module extraction pattern, so the fix is trying to introduced a cloned inline module, and perform the loop analysis and module extraction from the inlined module.\n\nCopybara import of the project:\n\n--\n2fe7c75a9fcbc9ade65f5a275aba3a2bc996ba07 by Shawn Wang <shawnw@nvidia.com>:\n\nadd debug information for command_buffer_conversion_pass\n\n--\n88183dd7dc53c2bdc80f3a664a99b50e275311b2 by Shawn Wang <shawnw@nvidia.com>:\n\nLower dynamic update slice thunk into command buffer when its offset\nvalue depends on loop iteraiton.\n\n--\n3cf46be90b3be2185f0b5106ea9eeaa45b088601 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\n45b31f69f9299a13bac24a966625190c9e90c91e by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\nce3af2b9b131c9902b45d6d9934424d861656d32 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\na7fc4ab02b5d7dec6d337fcc57bbfd38a3b205ed by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\n73784aa6530244559c1530b2f922cf81c6d43822 by Shawn Wang <shawnw@nvidia.com>:\n\nchange to gemm command for test\n\n--\n64b1cf454fc360bcc3255f29bd27c01799537e07 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\n0a3d7a1b6c142a3c9aa2b299d902520ed7f91515 by Shawn Wang <shawnw@nvidia.com>:\n\nclang format\n\n--\n3105ce82fa3751d73d41b0564402e108328ea147 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\n--\n85ce21672052c4bbfd50db54248dbe1ae2494230 by Shawn Wang <shawnw@nvidia.com>:\n\nfix\n\nMerging this change closes #28740\n\nPiperOrigin-RevId: 817644265",
    "sha": "12bb0a674b79bfed14c83839f155dd91b5a74c79",
    "files": [
        {
            "sha": "4caf58490096bbdeedbcb2cfcd7c961377c77737",
            "filename": "third_party/xla/xla/backends/gpu/codegen/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -152,6 +152,7 @@ cc_library(\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:call_graph\",\n+        \"//xla/service:call_inliner\",\n         \"//xla/service:custom_call_status\",\n         \"//xla/service:custom_call_target_registry\",\n         \"//xla/service:hlo_proto_cc\","
        },
        {
            "sha": "9b502af45a03916b9f976fa9fad6307e706821a2",
            "filename": "third_party/xla/xla/backends/gpu/codegen/custom.cc",
            "status": "modified",
            "additions": 73,
            "deletions": 28,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -62,6 +62,7 @@ limitations under the License.\n #include \"xla/literal_util.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/call_graph.h\"\n+#include \"xla/service/call_inliner.h\"\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_target_registry.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n@@ -307,7 +308,7 @@ absl::Status CollectSliceInfo(\n     std::vector<std::unique_ptr<HloModule>>& extracted_offset_modules,\n     unsigned arg_idx, bool can_compute_indvar_on_host,\n     std::optional<const HloInstruction*> while_op,\n-    std::optional<int64_t> indvar_idx) {\n+    std::optional<int64_t> indvar_idx, InlinedModule* inlined_module) {\n   if (!IsDynamicSliceOrDynamicUpdateSlice(slice_instrs[arg_idx])) {\n     return absl::OkStatus();\n   }\n@@ -317,18 +318,33 @@ absl::Status CollectSliceInfo(\n       fusion_instr.parent()->GetUniqueCaller(HloOpcode::kAsyncStart);\n \n   std::vector<DynamicSliceThunk::Offset> arg_offsets;\n+\n+  bool can_compute_offset_on_host =\n+      indvar_idx != std::nullopt && can_compute_indvar_on_host;\n+\n   for (auto idx_op : arg_slice_instr->index_operands()) {\n     const auto* param = Cast<HloParameterInstruction>(idx_op);\n     const HloInstruction* offset_value =\n         async_caller.has_value()\n             ? (*async_caller)->operand(param->parameter_number())\n             : fusion_instr.operand(param->parameter_number());\n \n+    const HloInstruction* inlined_offset_value;\n+    if (can_compute_offset_on_host) {\n+      inlined_offset_value =\n+          async_caller.has_value()\n+              ? inlined_module->get_inlined_inst(async_caller.value())\n+                    ->operand(param->parameter_number())\n+              : inlined_module->get_inlined_inst(&fusion_instr)\n+                    ->operand(param->parameter_number());\n+    }\n+\n     VLOG(2) << \"Offset value:\" << offset_value->ToString();\n \n     // Try to evaluate the offset value, maybe it is simple arithmetic.\n     absl::StatusOr<Literal> offset_literal = HloEvaluator().Evaluate(\n-        /*instruction=*/offset_value,\n+        /*instruction=*/can_compute_offset_on_host ? inlined_offset_value\n+                                                   : offset_value,\n         /*precomputed_analyses=*/{},\n         /*recursively_evaluate_nonconstant_operands=*/true);\n \n@@ -343,9 +359,9 @@ absl::Status CollectSliceInfo(\n             absl::StrCat(\"Unsupported constant offset shape: \",\n                          offset_literal->shape().ToString()));\n       }\n-    } else if (indvar_idx != std::nullopt && can_compute_indvar_on_host) {\n+    } else if (can_compute_offset_on_host) {\n       std::unique_ptr<HloModule> offset_module =\n-          ExtractOffsetModule(offset_value, indvar_idx.value());\n+          ExtractOffsetModule(inlined_offset_value, indvar_idx.value());\n       CHECK(offset_module != nullptr) << \"Failed to extract slice module\";\n       extracted_offset_modules.push_back(std::move(offset_module));\n       arg_offsets.emplace_back() = extracted_offset_modules.back().get();\n@@ -545,13 +561,22 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n       GetParentWhileOp(fusion, call_graph);\n   std::unique_ptr<HloModule> init_module, update_module;\n   std::optional<int64_t> indvar_idx;\n+  InlinedModule* inlined_module = nullptr;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetWhileOp is not expected to return nullptr.\";\n-    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    TF_ASSIGN_OR_RETURN(inlined_module,\n+                        ir_emitter_context.get_inlined_module());\n+    auto inlined_while_op = inlined_module->get_inlined_inst(*while_op);\n+    CHECK(inlined_while_op != nullptr)\n+        << \"While loop is not found in the inlined module.\";\n+    indvar_idx = GetLoopInductionVarTupleIdx(inlined_while_op);\n     if (indvar_idx != std::nullopt) {\n-      init_module = ExtractWhileInitModule(*while_op, indvar_idx.value());\n-      update_module = ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+      VLOG(3) << \"Found loop index variable: \" << indvar_idx.value();\n+      init_module =\n+          ExtractWhileInitModule(inlined_while_op, indvar_idx.value());\n+      update_module =\n+          ExtractWhileUpdateModule(inlined_while_op, indvar_idx.value());\n     }\n   }\n   bool can_compute_indvar_on_host =\n@@ -567,7 +592,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n       buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n       offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n       extracted_offset_modules, arg_idx++, can_compute_indvar_on_host, while_op,\n-      indvar_idx));\n+      indvar_idx, inlined_module));\n \n   TF_ASSIGN_OR_RETURN(\n       BufferAllocation::Slice rhs_slice,\n@@ -578,7 +603,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n       buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n       offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n       extracted_offset_modules, arg_idx++, can_compute_indvar_on_host, while_op,\n-      indvar_idx));\n+      indvar_idx, inlined_module));\n \n   BufferAllocation::Slice output;\n   std::optional<BufferAllocation::Slice> workspace = std::nullopt;\n@@ -597,7 +622,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n         extracted_offset_modules, arg_idx, can_compute_indvar_on_host, while_op,\n-        indvar_idx));\n+        indvar_idx, inlined_module));\n   } else {\n     TF_ASSIGN_OR_RETURN(\n         output,\n@@ -608,7 +633,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n         extracted_offset_modules, arg_idx++, can_compute_indvar_on_host,\n-        while_op, indvar_idx));\n+        while_op, indvar_idx, inlined_module));\n \n     // TODO(vuson): If we want to support slices of workspace, we'd need to\n     // start `HloFindIf` with `get-tuple-element` with the right index.\n@@ -619,7 +644,7 @@ absl::StatusOr<FusionEmissionResult> EmitGemm(\n         buffer_assignment, fusion, absl::Span<HloInstruction*>(slice_instrs),\n         offset_buffer_indices, orig_shapes, sliced_shapes, offset_byte_sizes,\n         extracted_offset_modules, arg_idx, can_compute_indvar_on_host, while_op,\n-        indvar_idx));\n+        indvar_idx, inlined_module));\n     fake_allocations[arg_idx] = std::make_unique<BufferAllocation>(\n         /*index=*/arg_idx, workspace->size(), /*color=*/0);\n     slice_workspace_fake = BufferAllocation::Slice(\n@@ -759,13 +784,22 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n       GetParentWhileOp(fusion, call_graph);\n   std::unique_ptr<HloModule> init_module, update_module;\n   std::optional<int64_t> indvar_idx = std::nullopt;\n+  InlinedModule* inlined_module = nullptr;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetWhileOp is not expected to return nullptr.\";\n-    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    TF_ASSIGN_OR_RETURN(inlined_module,\n+                        ir_emitter_context.get_inlined_module());\n+    auto inlined_while_op = inlined_module->get_inlined_inst(*while_op);\n+    CHECK(inlined_while_op != nullptr)\n+        << \"While loop is not found in the inlined module.\";\n+    indvar_idx = GetLoopInductionVarTupleIdx(inlined_while_op);\n     if (indvar_idx != std::nullopt) {\n-      init_module = ExtractWhileInitModule(*while_op, indvar_idx.value());\n-      update_module = ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+      VLOG(3) << \"Found loop index variable: \" << indvar_idx.value();\n+      init_module =\n+          ExtractWhileInitModule(inlined_while_op, indvar_idx.value());\n+      update_module =\n+          ExtractWhileUpdateModule(inlined_while_op, indvar_idx.value());\n     }\n   }\n   bool can_compute_indvar_on_host =\n@@ -793,7 +827,8 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n               buffer_assignment, fusion,\n               absl::Span<HloInstruction*>(slice_instrs), offsets, orig_shapes,\n               sliced_shapes, offset_byte_sizes, extracted_offset_modules,\n-              arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx));\n+              arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx,\n+              inlined_module));\n \n           operands.push_back(CustomCallThunk::Slice{slice, subshape});\n           arguments.push_back(slice);\n@@ -820,7 +855,8 @@ absl::StatusOr<FusionEmissionResult> EmitCustomCall(\n             buffer_assignment, fusion,\n             absl::Span<HloInstruction*>(slice_instrs), offsets, orig_shapes,\n             sliced_shapes, offset_byte_sizes, extracted_offset_modules,\n-            arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx));\n+            arg_idx++, can_compute_indvar_on_host, while_op, indvar_idx,\n+            inlined_module));\n \n         results.push_back(CustomCallThunk::Slice{slice, subshape});\n         arguments.push_back(slice);\n@@ -1059,24 +1095,27 @@ absl::StatusOr<SliceDataForCollectives>\n CollectSliceArgumentMetadataForCollectives(\n     const HloInstType* instr, const BufferAssignment& buffer_assignment,\n     const HloFusionAdaptor& adaptor, const HloFusionInstruction& fusion_instr,\n-    const CallGraph& call_graph) {\n+    const CallGraph& call_graph, InlinedModule* inlined_module) {\n   int num_args =\n       instr->operand_count() +\n       (instr->shape().IsTuple() ? instr->shape().tuple_shapes_size() : 1);\n   SliceDataForCollectives slice_data(num_args);\n   std::optional<HloInstruction*> while_op =\n       GetParentWhileOp(fusion_instr, call_graph);\n-\n   std::optional<int64_t> indvar_idx = std::nullopt;\n   if (while_op != std::nullopt) {\n     CHECK(while_op.value() != nullptr)\n         << \"GetParentWhileOp is not expected to return nullptr.\";\n-    indvar_idx = GetLoopInductionVarTupleIdx(*while_op);\n+    auto inlined_while_op = inlined_module->get_inlined_inst(*while_op);\n+    CHECK(inlined_while_op != nullptr)\n+        << \"While loop is not found in the inlined module.\";\n+    indvar_idx = GetLoopInductionVarTupleIdx(inlined_while_op);\n     if (indvar_idx != std::nullopt) {\n+      VLOG(3) << \"Found loop index variable: \" << indvar_idx.value();\n       slice_data.init_module =\n-          ExtractWhileInitModule(*while_op, indvar_idx.value());\n+          ExtractWhileInitModule(inlined_while_op, indvar_idx.value());\n       slice_data.update_module =\n-          ExtractWhileUpdateModule(*while_op, indvar_idx.value());\n+          ExtractWhileUpdateModule(inlined_while_op, indvar_idx.value());\n     }\n   }\n   slice_data.can_compute_indvar_on_host = (slice_data.init_module != nullptr &&\n@@ -1096,7 +1135,8 @@ CollectSliceArgumentMetadataForCollectives(\n         /*offsets=*/slice_data.offset_buffer_indices, slice_data.orig_shapes,\n         slice_data.sliced_shapes, slice_data.offset_byte_sizes,\n         slice_data.extracted_offset_modules, arg_idx,\n-        slice_data.can_compute_indvar_on_host, while_op, indvar_idx));\n+        slice_data.can_compute_indvar_on_host, while_op, indvar_idx,\n+        inlined_module));\n     arg_idx++;\n   }\n \n@@ -1122,7 +1162,8 @@ CollectSliceArgumentMetadataForCollectives(\n         /*offsets=*/slice_data.offset_buffer_indices, slice_data.orig_shapes,\n         slice_data.sliced_shapes, slice_data.offset_byte_sizes,\n         slice_data.extracted_offset_modules, arg_idx,\n-        slice_data.can_compute_indvar_on_host, while_op, indvar_idx));\n+        slice_data.can_compute_indvar_on_host, while_op, indvar_idx,\n+        inlined_module));\n     arg_idx++;\n   }\n \n@@ -1205,10 +1246,13 @@ absl::StatusOr<FusionEmissionResult> EmitCollective(\n   const BufferAssignment& buffer_assignment =\n       ir_emitter_context.buffer_assignment();\n \n-  TF_ASSIGN_OR_RETURN(\n-      auto slice_data,\n-      CollectSliceArgumentMetadataForCollectives(\n-          instr, buffer_assignment, adaptor, fusion_instr, call_graph));\n+  TF_ASSIGN_OR_RETURN(InlinedModule * inlined_module,\n+                      ir_emitter_context.get_inlined_module());\n+\n+  TF_ASSIGN_OR_RETURN(auto slice_data,\n+                      CollectSliceArgumentMetadataForCollectives(\n+                          instr, buffer_assignment, adaptor, fusion_instr,\n+                          call_graph, inlined_module));\n \n   int64_t replica_count = instr->GetModule()->config().replica_count();\n   int64_t partition_count = instr->GetModule()->config().num_partitions();\n@@ -1383,6 +1427,7 @@ absl::StatusOr<FusionEmissionResult> DynamicSliceFusion::Emit(\n                    /*visit=*/[](HloInstructionAdaptor node) -> bool {\n                      return node.opcode() == HloOpcode::kReduceScatter;\n                    });\n+\n   if (maybe_collective != std::nullopt) {\n     const HloReduceScatterInstruction* rs =\n         Cast<const HloReduceScatterInstruction>("
        },
        {
            "sha": "de824f3c23daaacde193be42364819c07132c90c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/dynamic_slice_fusion_test.cc",
            "status": "modified",
            "additions": 82,
            "deletions": 0,
            "changes": 82,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fdynamic_slice_fusion_test.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -83,6 +83,28 @@ class DynamicSliceFusionTest : public HloTestBase {\n     return config;\n   }\n \n+  HloModuleConfig GetModuleConfigWithCommandBuffer() {\n+    DebugOptions debug_options = GetDebugOptionsForTest();\n+    debug_options.set_xla_gpu_enable_cublaslt(false);\n+    debug_options.set_xla_gpu_gemm_rewrite_size_threshold(0);\n+    debug_options.set_xla_gpu_enable_dynamic_slice_fusion(true);\n+    debug_options.set_xla_gpu_triton_gemm_any(false);\n+    debug_options.set_xla_gpu_enable_cublaslt(false);\n+    debug_options.set_xla_gpu_cublas_fallback(true);\n+    debug_options.set_xla_gpu_graph_min_graph_size(1);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLAS);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUBLASLT);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUSTOM_CALL);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::CUDNN);\n+    debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n+    debug_options.add_xla_gpu_enable_command_buffer(\n+        DebugOptions::DYNAMIC_SLICE_FUSION);\n+    HloModuleConfig config;\n+    config.set_debug_options(debug_options);\n+    return config;\n+  }\n+\n   HloModuleConfig GetModuleConfigWithDeterministicOps() {\n     DebugOptions debug_options = GetDebugOptionsForTest();\n     debug_options.set_xla_gpu_exclude_nondeterministic_ops(true);\n@@ -3389,6 +3411,66 @@ TEST_F(DynamicSliceFusionTest,\n       /*run_hlo_passes=*/false, /*use_threads=*/true, std::nullopt));\n }\n \n+TEST_F(DynamicSliceFusionTest,\n+       OffsetAsFunctionOfInductionVariableShouldUseOffsetModulesWithCmdBuffer) {\n+  const char* hlo = R\"(\n+  HloModule test\n+\n+  %Body {\n+    param = (f32[1,8,8]{2,1,0}, f32[1,8,8]{2,1,0}, f32[4,8,8]{2,1,0}, u32[]) parameter(0)\n+    p0 = get-tuple-element(param), index=0\n+    p1 = get-tuple-element(param), index=1\n+    p2 = get-tuple-element(param), index=2\n+    loop_iter = get-tuple-element(param), index=3\n+\n+    bitcast.41 = f32[8,8]{1,0} reshape(p0)\n+    bitcast.42 = f32[8,8]{1,0} reshape(p1)\n+    dot.1 = f32[8,8]{1,0} dot(bitcast.41, bitcast.42), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+    bitcast.43 = f32[1,8,8]{2,1,0} reshape(dot.1)\n+    c0 = u32[] constant(0)\n+    c_trip_count = u32[] constant(11)\n+    compare = pred[] compare(loop_iter, c0), direction=LT\n+    add = u32[] add(loop_iter, c_trip_count)\n+    offset = u32[] select(compare, add, loop_iter)\n+    dus = f32[4,8,8]{2,1,0} dynamic-update-slice(p2, bitcast.43, offset, c0, c0)\n+    c1 = u32[] constant(1)\n+    add2 = u32[] add(loop_iter, c1)\n+    ROOT tuple = tuple(p0, p1, dus, u32[] add2)\n+  }\n+\n+  %Cond {\n+    %param.1 = (f32[1,8,8]{2,1,0}, f32[1,8,8]{2,1,0}, f32[4,8,8]{2,1,0}, u32[]) parameter(0)\n+    %i.1 = u32[] get-tuple-element(%param.1), index=3\n+    %trip_count = u32[] constant(11)\n+    ROOT %done = pred[] compare(u32[] %i.1, u32[] %trip_count), direction=LT\n+  }\n+\n+  ENTRY %test {\n+    %p0.1 = f32[1,8,8]{2,1,0} parameter(0)\n+    %p1.1 = f32[1,8,8]{2,1,0} parameter(1)\n+    %p2.1 = f32[4,8,8]{2,1,0} parameter(2)\n+    %c0.1 = u32[] constant(0)\n+    %initial_tuple = tuple(%p0.1, %p1.1, %p2.1, u32[] %c0.1)\n+    ROOT %while = while(%initial_tuple), condition=%Cond, body=%Body, backend_config={\"known_trip_count\":{\"n\":\"11\"}}\n+  })\";\n+\n+  // Run the same HLO with and without command buffer and compare results.\n+  HloModuleConfig with_cmd_buffer = GetModuleConfigWithCommandBuffer();\n+  HloModuleConfig without_cmd_buffer = GetModuleConfigWithoutCommandBuffer();\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> cmd_buffer_module,\n+                          ParseAndReturnVerifiedModule(hlo));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> no_cmd_buffer_module,\n+                          ParseAndReturnVerifiedModule(hlo));\n+\n+  ErrorSpec error_spec(1e-5, 1e-5);\n+  EXPECT_TRUE(\n+      RunAndCompareTwoModules(hlo, hlo, GetModuleConfigWithCommandBuffer(),\n+                              GetModuleConfigWithoutCommandBuffer(), error_spec,\n+                              /*run_hlo_passes=*/true));\n+}\n+\n TEST_F(DynamicSliceFusionTest, MultipleOffsetsAsFunctionOfInductionVariable) {\n   const char* hlo_fused = R\"(\n     HloModule test, replica_count=2"
        },
        {
            "sha": "49873d997a8033e89663df8a5374c913d5d85cde",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -72,6 +72,7 @@ cc_library(\n         \":while_thunk\",\n         \"//xla:debug_options_flags\",\n         \"//xla:executable_run_options\",\n+        \"//xla:literal_util\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n         \"//xla:types\",\n@@ -81,6 +82,7 @@ cc_library(\n         \"//xla/ffi:call_frame\",\n         \"//xla/ffi:ffi_api\",\n         \"//xla/ffi/api:c_api\",\n+        \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:buffer_use\",\n         \"//xla/runtime:execution_graph\",\n@@ -227,7 +229,6 @@ cc_library(\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n-        \"//xla/service:hlo_proto_cc\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/stream_executor:device_memory\",\n@@ -243,6 +244,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n@@ -2680,6 +2682,7 @@ cc_library(\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform\","
        },
        {
            "sha": "8a0af36d3558bae2f9d6e105b05cdc9687ae6018",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 96,
            "deletions": 16,
            "changes": 112,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -62,6 +62,8 @@ limitations under the License.\n #include \"xla/executable_run_options.h\"\n #include \"xla/ffi/call_frame.h\"\n #include \"xla/ffi/ffi_api.h\"\n+#include \"xla/hlo/evaluator/hlo_evaluator.h\"\n+#include \"xla/literal_util.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/runtime/execution_graph.h\"\n #include \"xla/runtime/resource_use.h\"\n@@ -97,6 +99,23 @@ limitations under the License.\n \n namespace xla::gpu {\n \n+namespace {\n+// Indvar is a thread-local map that stores the induction variable for each\n+// dynamic slice thunk. The same thunk object in the memory is shared by\n+// multiple replicas of the same computation. So, each replica should have its\n+// own tracking of the induction variable (threadlocal). With threadlocal, we\n+// cannot embed this inside the dynamic slice thunk object, and so we have a\n+// static map. There could be multiple dynamic slice thunks in the same module,\n+// and so we need a map to store the induction variable for each thunk. The\n+// usage of threadlocal in this context is similar to `LoopCounters` in\n+// while_thunk.cc (b/343294327).\n+Literal& Indvar(DynamicSliceFusionCmd* cmd) {\n+  static thread_local absl::flat_hash_map<DynamicSliceFusionCmd*, Literal>\n+      indvar_map;\n+  return indvar_map[cmd];\n+}\n+}  // namespace\n+\n using MemoryAccess = BufferUse::MemoryAccess;\n \n std::string CommandBufferCmdString(CommandBufferCmdType type) {\n@@ -1582,7 +1601,8 @@ CommandBufferCmd::BufferUseVector WhileCmd::buffers() const {\n GemmCmd::GemmCmd(GemmConfig config, const BufferAllocation::Slice& lhs_buffer,\n                  const BufferAllocation::Slice& rhs_buffer,\n                  const BufferAllocation::Slice& output_buffer,\n-                 const BufferAllocation::Slice& workspace, bool deterministic)\n+                 std::optional<BufferAllocation::Slice> workspace,\n+                 bool deterministic)\n     : TracedCommandBufferCmd(CommandBufferCmdType::kGemmCmd),\n       config_(std::move(config)),\n       lhs_buffer_(lhs_buffer),\n@@ -1609,14 +1629,18 @@ absl::StatusOr<const se::CommandBuffer::Command*> GemmCmd::Record(\n       execute_params.buffer_allocations->GetDeviceAddress(rhs_buffer_);\n   se::DeviceMemoryBase out =\n       execute_params.buffer_allocations->GetDeviceAddress(output_buffer_);\n-  se::DeviceMemoryBase workspace =\n-      execute_params.buffer_allocations->GetDeviceAddress(workspace_);\n+\n+  se::DeviceMemoryBase workspace(/*opaque=*/nullptr, /*size=*/0);\n+  if (workspace_.has_value()) {\n+    workspace =\n+        execute_params.buffer_allocations->GetDeviceAddress(workspace_.value());\n+  }\n \n   VLOG(5) << \"GemmCmd: deterministic=\" << deterministic_;\n   VLOG(5) << \"  Lhs: \" << lhs_buffer_ << \" (\" << lhs.opaque() << \")\";\n   VLOG(5) << \"  Lhs: \" << rhs_buffer_ << \" (\" << rhs.opaque() << \")\";\n   VLOG(5) << \"  Out: \" << output_buffer_ << \" (\" << out.opaque() << \")\";\n-  VLOG(5) << \"  Workspace: \" << workspace_ << \" (\" << workspace.opaque() << \")\";\n+  VLOG(5) << \"  Workspace: \" << workspace.opaque();\n \n   return RecordTracedCommand(execute_params, record_params,\n                              std::move(record_action), command_buffer,\n@@ -1627,8 +1651,13 @@ absl::StatusOr<const se::CommandBuffer::Command*> GemmCmd::Record(\n }\n \n CommandBufferCmd::BufferUseVector GemmCmd::buffers() const {\n+  if (workspace_.has_value()) {\n+    return {BufferUse::Read(lhs_buffer_), BufferUse::Read(rhs_buffer_),\n+            BufferUse::Write(output_buffer_),\n+            BufferUse::Write(workspace_.value())};\n+  }\n   return {BufferUse::Read(lhs_buffer_), BufferUse::Read(rhs_buffer_),\n-          BufferUse::Write(output_buffer_), BufferUse::Write(workspace_)};\n+          BufferUse::Write(output_buffer_)};\n }\n \n //===----------------------------------------------------------------------===//\n@@ -2339,10 +2368,15 @@ DynamicSliceFusionCmd::DynamicSliceFusionCmd(\n     std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>> offsets,\n     std::vector<std::optional<Shape>> orig_shapes,\n     std::vector<std::optional<Shape>> sliced_shapes,\n-    std::vector<std::optional<uint64_t>> offset_byte_sizes)\n+    std::vector<std::optional<uint64_t>> offset_byte_sizes,\n+    std::optional<\n+        const DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata*>\n+        offset_as_function_of_indvar_metadata)\n     : CommandBufferCmd(CommandBufferCmdType::kDynamicSliceFusionCmd),\n       embedded_commands_(std::move(embedded_commands)),\n-      fake_allocations_(std::move(fake_allocations)) {\n+      fake_allocations_(std::move(fake_allocations)),\n+      offset_as_function_of_indvar_metadata_(\n+          std::move(offset_as_function_of_indvar_metadata)) {\n   // Zip all arguments together to create a list of SliceDef.\n   for (auto [arg, offset, orig_shape, sliced_shape, offset_byte_size] :\n        llvm::zip_equal(arguments, offsets, orig_shapes, sliced_shapes,\n@@ -2409,22 +2443,36 @@ absl::Status DynamicSliceFusionCmd::Prepare(\n     const Thunk::PrepareParams& params,\n     Thunk::ResourceRequestsInterface& resource_requests) {\n   for (DynamicSliceThunk::SliceDef& slice : slices_) {\n+    VLOG(3) << \"DynamicSliceFusionCmd: slice: \" << slice.ToString();\n     if (slice.offsets.has_value()) {\n       TF_RET_CHECK(slice.embedded_thunk_argument.has_value());\n       TF_RET_CHECK(slice.orig_shape.has_value());\n       TF_RET_CHECK(slice.sliced_shape.has_value());\n       TF_RET_CHECK(slice.offset_byte_size.has_value());\n-\n       TF_RET_CHECK(slice.orig_shape->IsArray());\n       TF_RET_CHECK(slice.sliced_shape->IsArray());\n-\n       TF_RET_CHECK(slice.offsets->size() ==\n                    slice.orig_shape->dimensions().size());\n       TF_RET_CHECK(slice.sliced_shape->dimensions().size() ==\n                    slice.orig_shape->dimensions().size());\n     }\n   }\n   TF_RETURN_IF_ERROR(embedded_commands_.Prepare(params, resource_requests));\n+  if (offset_as_function_of_indvar_metadata_ != std::nullopt) {\n+    Indvar(this) =\n+        HloEvaluator()\n+            .Evaluate(\n+                *offset_as_function_of_indvar_metadata_.value()->indvar_init,\n+                {})\n+            .value();\n+    VLOG(3) << \"Indvar init module: \"\n+            << offset_as_function_of_indvar_metadata_.value()\n+                   ->indvar_init->ToString();\n+    VLOG(3) << \"Indvar update module: \"\n+            << offset_as_function_of_indvar_metadata_.value()\n+                   ->indvar_update->ToString();\n+    VLOG(3) << \"Indvar value initialized to :\" << Indvar(this).ToString();\n+  }\n   return absl::OkStatus();\n }\n \n@@ -2489,6 +2537,19 @@ absl::StatusOr<const se::CommandBuffer::Command*> DynamicSliceFusionCmd::Record(\n                 << \"]: constant offset = \" << *const_offset;\n         offset_value(argument_idx, offset_idx) = *const_offset;\n \n+      } else if (HloModule** offset_module = std::get_if<HloModule*>(&offset)) {\n+        TF_ASSIGN_OR_RETURN(\n+            Literal offset,\n+            HloEvaluator().Evaluate(**offset_module, {&Indvar(this)}));\n+        auto offset_int = LiteralUtil::LiteralAsScalarInt64(offset);\n+        if (offset_int.has_value()) {\n+          offset_value(argument_idx, offset_idx) = *offset_int;\n+        } else {\n+          return absl::InternalError(\n+              absl::StrFormat(\"Unhandled type returned from offset module: %s\",\n+                              offset.shape().ToString()));\n+        }\n+        VLOG(2) << \"Offset value = \" << offset_value(argument_idx, offset_idx);\n       } else {\n         // Transfer slice offset value from device to host.\n         auto alloc_slice = std::get<BufferAllocation::Slice>(offset);\n@@ -2539,7 +2600,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> DynamicSliceFusionCmd::Record(\n       new_offset += start * stride;\n     }\n \n-    VLOG(2) << \"Create sliced argument \" << argument_idx << \" of shape \"\n+    VLOG(3) << \"Create sliced argument \" << argument_idx << \" of shape \"\n             << slice.sliced_shape->ToString()\n             << \" by slicing argument of shape \" << slice.orig_shape->ToString()\n             << \" at offset \" << new_offset << \" with \" << new_size;\n@@ -2553,6 +2614,9 @@ absl::StatusOr<const se::CommandBuffer::Command*> DynamicSliceFusionCmd::Record(\n                                       orig_allocations.device_ordinal(),\n                                       orig_allocations.memory_allocator());\n \n+  VLOG(3) << \"DynamicSliceFusionCmd: new slice_allocations: \"\n+          << slice_allocations.ToString();\n+\n   Thunk::ExecuteParams new_params =\n       Thunk::ExecuteParams::CloneWithNewAllocations(execute_params,\n                                                     slice_allocations);\n@@ -2562,13 +2626,29 @@ absl::StatusOr<const se::CommandBuffer::Command*> DynamicSliceFusionCmd::Record(\n   // manager relies on command buffer pointer as an identity for command\n   // buffers, and it means that command buffer commands sequence should not\n   // create ephemeral command buffers at run time.\n-  auto nested_command_buffer =\n-      execute_params.stream->parent()\n-          ->CreateCommandBuffer(se::CommandBuffer::Mode::kNested)\n-          .value();\n-  TF_RETURN_IF_ERROR(embedded_commands_.Record(new_params, record_params,\n+  TF_ASSIGN_OR_RETURN(auto nested_command_buffer,\n+                      execute_params.stream->parent()->CreateCommandBuffer(\n+                          se::CommandBuffer::Mode::kNested));\n+\n+  StateManager state;\n+  RecordParams nested_record_params = {state, std::nullopt, false};\n+  TF_RETURN_IF_ERROR(embedded_commands_.Record(new_params, nested_record_params,\n                                                CommandBufferCmd::RecordCreate{},\n-                                               nested_command_buffer.get()));\n+                                               nested_command_buffer.get(),\n+                                               /*finalize=*/true));\n+\n+  // For command buffer instantiation ran by CommandBufferThunk::Initialize, we\n+  // must not step the Indvar, because it is not a real run.\n+  if (offset_as_function_of_indvar_metadata_ != std::nullopt &&\n+      command_buffer->state() == se::CommandBuffer::State::kUpdate) {\n+    Indvar(this) =\n+        HloEvaluator()\n+            .Evaluate(\n+                *offset_as_function_of_indvar_metadata_.value()->indvar_update,\n+                {&Indvar(this)})\n+            .value();\n+    VLOG(2) << \"Update Indvar = \" << Indvar(this).ToString();\n+  }\n \n   return Handle(\n       std::move(record_action),"
        },
        {
            "sha": "fae591555e3e09df87bb10eea12ec7d3dcdf231e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.h",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -902,7 +902,7 @@ class GemmCmd : public TracedCommandBufferCmd {\n   GemmCmd(GemmConfig config, const BufferAllocation::Slice& lhs_buffer,\n           const BufferAllocation::Slice& rhs_buffer,\n           const BufferAllocation::Slice& output_buffer,\n-          const BufferAllocation::Slice& workspace, bool deterministic);\n+          std::optional<BufferAllocation::Slice> workspace, bool deterministic);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -921,7 +921,7 @@ class GemmCmd : public TracedCommandBufferCmd {\n   const BufferAllocation::Slice lhs_buffer_;\n   const BufferAllocation::Slice rhs_buffer_;\n   const BufferAllocation::Slice output_buffer_;\n-  const BufferAllocation::Slice workspace_;\n+  std::optional<BufferAllocation::Slice> workspace_;\n   // Whether to run deterministically.\n   const bool deterministic_;\n };\n@@ -1218,7 +1218,10 @@ class DynamicSliceFusionCmd : public CommandBufferCmd {\n           offsets,\n       std::vector<std::optional<Shape>> orig_shapes,\n       std::vector<std::optional<Shape>> sliced_shapes,\n-      std::vector<std::optional<uint64_t>> offset_byte_sizes);\n+      std::vector<std::optional<uint64_t>> offset_byte_sizes,\n+      std::optional<\n+          const DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata*>\n+          offset_as_function_of_indvar_metadata = std::nullopt);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -1234,6 +1237,8 @@ class DynamicSliceFusionCmd : public CommandBufferCmd {\n \n   BufferUseVector buffers() const override;\n \n+  bool force_update() override { return true; }\n+\n   bool requires_initialization() override;\n \n   bool support_loop_unroll() override { return false; }\n@@ -1261,6 +1266,13 @@ class DynamicSliceFusionCmd : public CommandBufferCmd {\n   // command sequences.\n   absl::flat_hash_map<int64_t, std::optional<BufferAllocation::Slice>>\n       embeded_to_origin_slice_map_;\n+\n+  // This structure holds the metadata for offset computations on host. It\n+  // stores a single induction variable initialization module, its update module\n+  // and the offsets that are a function of the induction variable.\n+  std::optional<\n+      const DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata*>\n+      offset_as_function_of_indvar_metadata_;\n };\n \n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "8cb463184fb1846eb7c5ecfd61ecae6df9cf9303",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_emitter.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 8,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -122,13 +122,9 @@ static absl::StatusOr<Command> Convert(\n }\n \n static absl::StatusOr<Command> Convert(const GemmThunk& thunk) {\n-  if (!thunk.workspace().has_value()) {\n-    return absl::InternalError(\n-        \"Gemm thunk does not contain a workspace buffer\");\n-  }\n-  return std::make_unique<GemmCmd>(\n-      thunk.config(), thunk.lhs_buffer(), thunk.rhs_buffer(),\n-      thunk.output_buffer(), thunk.workspace().value(), thunk.deterministic());\n+  return std::make_unique<GemmCmd>(thunk.config(), thunk.lhs_buffer(),\n+                                   thunk.rhs_buffer(), thunk.output_buffer(),\n+                                   thunk.workspace(), thunk.deterministic());\n }\n \n static absl::StatusOr<Command> Convert(const CublasLtMatmulThunk& thunk) {\n@@ -202,7 +198,8 @@ static absl::StatusOr<Command> Convert(\n   return std::make_unique<DynamicSliceFusionCmd>(\n       std::move(embedded_cmds), thunk.get_arguments(),\n       std::move(fake_allocations), thunk.get_offsets(), thunk.get_orig_shapes(),\n-      thunk.get_sliced_shapes(), thunk.get_offset_byte_sizes());\n+      thunk.get_sliced_shapes(), thunk.get_offset_byte_sizes(),\n+      thunk.get_offset_function());\n }\n \n static absl::StatusOr<Command> Convert(const PartitionIdThunk& thunk) {"
        },
        {
            "sha": "c1381c37290d333eb2a11fc30c8bccb2e3efd857",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 2,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd_emitter.h\"\n@@ -58,6 +59,17 @@ namespace gpu {\n \n using CommandBufferConfig = CommandBufferConversionPass::CommandBufferConfig;\n \n+std::string CommandBufferConversionPass::CommandBufferConfig::ToString() const {\n+  std::vector<std::string> cmd_names;\n+  cmd_names.reserve(enabled_commands.size());\n+  for (auto cmd : enabled_commands) {\n+    cmd_names.push_back(DebugOptions::CommandBufferCmdType_Name(cmd));\n+  }\n+  std::string out;\n+  out += \"enabled_commands: [\" + absl::StrJoin(cmd_names, \", \") + \"]\";\n+  return out;\n+}\n+\n namespace {\n \n CommandBufferConfig GetCommandBufferConfig(\n@@ -127,6 +139,7 @@ std::optional<DebugOptions::CommandBufferCmdType> GetCommandBufferCmdType(\n         return DebugOptions::FUSION;\n       } else {\n         // Only copy within the same device can be converted to command buffers.\n+        VLOG(2) << \"Unsupported thunk kind: \" << Thunk::KindToString(kind);\n         return std::nullopt;\n       }\n     case Thunk::kKernel:\n@@ -155,7 +168,10 @@ std::optional<DebugOptions::CommandBufferCmdType> GetCommandBufferCmdType(\n       return DebugOptions::CUSTOM_CALL;\n     case Thunk::kCublasLtMatmul:\n       return DebugOptions::CUBLASLT;\n+    case Thunk::kDynamicSlice:\n+      return DebugOptions::DYNAMIC_SLICE_FUSION;\n     default:\n+      VLOG(2) << \"Unsupported thunk kind: \" << Thunk::KindToString(kind);\n       return std::nullopt;\n   }\n }\n@@ -214,7 +230,14 @@ bool IsConvertible(const Thunk& thunk, const CommandBufferConfig& config) {\n   }\n \n   auto cmd_type = GetCommandBufferCmdType(thunk);\n-  if (!cmd_type.has_value() || !config.enabled_commands.contains(*cmd_type)) {\n+  if (!cmd_type.has_value()) {\n+    return false;  // Thunk kind is not supported for command buffer conversion.\n+  }\n+\n+  if (!config.enabled_commands.contains(*cmd_type)) {\n+    VLOG(2) << \"Thunk kind \" << Thunk::KindToString(thunk.kind())\n+            << \" lowering is not enabled by the user for type \"\n+            << DebugOptions::CommandBufferCmdType_Name(*cmd_type);\n     return false;  // Thunk kind is not supported for command buffer conversion.\n   }\n \n@@ -360,6 +383,13 @@ absl::Status FlushCommandBuffer(\n   // them to the new thunks sequence as is.\n   if (current_command_buffer_thunks.size() <\n       std::max(1, debug_options.xla_gpu_graph_min_graph_size())) {\n+    if (VLOG_IS_ON(2)) {\n+      for (const auto& thunk : current_command_buffer_thunks) {\n+        VLOG(2) << \"Thunk kind \" << Thunk::KindToString(thunk->kind())\n+                << \" is not lowered to command buffer because command size is \"\n+                   \"less than the min graph size\";\n+      }\n+    }\n     new_thunks.insert(\n         new_thunks.end(),\n         std::make_move_iterator(current_command_buffer_thunks.begin()),\n@@ -392,7 +422,8 @@ absl::StatusOr<bool> CommandBufferConversionPass::Run(\n \n   CommandBufferConfig config =\n       GetCommandBufferConfig(debug_options, device_info);\n-\n+  VLOG(1) << \"Module \" << module_name_\n+          << \" CommandBufferConfig: \" << config.ToString();\n   TF_ASSIGN_OR_RETURN(\n       CommandBufferCmdExecutor::SynchronizationMode synchronization_mode,\n       GetSynchronizationMode("
        },
        {
            "sha": "9defc515b1f07eff451e24feb4639a26b7399d68",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass.h",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -32,7 +32,8 @@ namespace gpu {\n // Converts compatible sequences of Thunks into CommandBufferThunks.\n class CommandBufferConversionPass : public ThunkPassInterface {\n  public:\n-  CommandBufferConversionPass() = default;\n+  CommandBufferConversionPass(absl::string_view module_name = \"\")\n+      : module_name_(module_name) {}\n \n   absl::string_view name() const override {\n     return \"command-buffer-conversion\";\n@@ -47,7 +48,11 @@ class CommandBufferConversionPass : public ThunkPassInterface {\n     // remove that flag and enable all supported commands by default.\n     absl::flat_hash_set<DebugOptions::CommandBufferCmdType> enabled_commands;\n     const se::DeviceDescription& device_description;\n+    std::string ToString() const;\n   };\n+\n+ private:\n+  std::string module_name_;\n };\n \n }  // namespace gpu"
        },
        {
            "sha": "2f5a9584fa7e7bfb30419042e93b5b8ec3232f42",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass_test.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -242,7 +242,7 @@ TEST(CommandBufferConversionPassTest, ConvertsToCommandBufferThunk) {\n \n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   // CopyThunk should be converted to a CommandBufferThunk, because it is\n   // supported in command buffers. The expected transformation is:\n@@ -264,7 +264,7 @@ TEST(CommandBufferConversionPassTest, ConvertsToCommandBufferThunk) {\n }\n \n TEST(CommandBufferConversionPassTest, PartiallyConvertsToCommandBufferThunk) {\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   std::vector<std::unique_ptr<Thunk>> thunks;\n \n@@ -334,7 +334,7 @@ TEST(CommandBufferConversionPassTest, ConvertsAsyncPairToCommandBuffer) {\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n   FakeErrorAllocator allocator;\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass(\"test\");\n   ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n               IsOkAndHolds(true));\n \n@@ -378,7 +378,7 @@ TEST(CommandBufferConversionPassTest,\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n   FakeErrorAllocator allocator;\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass(\"test\");\n   // Expected no transformation, because there is a non-convertible thunk in\n   // between the asyncs.\n   ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n@@ -407,7 +407,7 @@ TEST(CommandBufferConversionPassTest, ConvertCrossedAsyncs) {\n   ASSERT_EQ(root_thunk->thunks().size(), 4);\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n   DebugOptions debug_options;\n   debug_options.clear_xla_gpu_enable_command_buffer();\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n@@ -450,7 +450,7 @@ TEST(CommandBufferConversionPassTest, ConvertNestedAsyncs) {\n   ASSERT_EQ(root_thunk->thunks().size(), 5);\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n   DebugOptions debug_options;\n   debug_options.clear_xla_gpu_enable_command_buffer();\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n@@ -500,7 +500,7 @@ TEST(CommandBufferConversionPassTest, DontConvertAsyncsIfUnpairedStart) {\n   ASSERT_EQ(root_thunk->thunks().size(), 5);\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n   DebugOptions debug_options;\n   debug_options.clear_xla_gpu_enable_command_buffer();\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n@@ -563,7 +563,7 @@ TEST(CommandBufferConversionPassTest, ConvertsAsyncPairsMixedWithOtherThunks) {\n \n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n   FakeErrorAllocator allocator;\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass(\"test\");\n   ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n               IsOkAndHolds(true));\n \n@@ -601,7 +601,7 @@ TEST(CommandBufferConversionPassTest, DontConvertIfNotMinGraphSize) {\n \n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   // The size of the sequence is less than the min graph size, so it should not\n   // be converted to a command buffer.\n@@ -611,7 +611,7 @@ TEST(CommandBufferConversionPassTest, DontConvertIfNotMinGraphSize) {\n }\n \n TEST(CommandBufferConversionPassTest, ConvertWhileThunk) {\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   std::vector<std::unique_ptr<Thunk>> thunks;\n \n@@ -669,7 +669,7 @@ TEST(CommandBufferConversionPassTest,\n   // Check that if a branch of a conditional thunk is not convertible, the\n   // conditional thunk is not convertible either, but the branches are attempted\n   // to be converted independently.\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass(\"test\");\n \n   std::vector<std::unique_ptr<Thunk>> thunks;\n \n@@ -720,7 +720,7 @@ TEST(CommandBufferConversionPassTest,\n }\n \n TEST(CommandBufferConversionPassTest, ConvertWhileThunkWithAsyncPair) {\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   std::vector<std::unique_ptr<Thunk>> thunks;\n \n@@ -796,7 +796,7 @@ TEST(CommandBufferConversionPassTest, ConvertsCuDnnThunkToCommandBufferThunk) {\n \n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   // The expected transformation is: SequentialThunk(CuDnnThunk) ->\n   // SequentialThunk(CommandBufferThunk(CuDnnThunk))\n@@ -812,7 +812,7 @@ TEST(CommandBufferConversionPassTest, ConvertsCuDnnThunkToCommandBufferThunk) {\n   EXPECT_THAT(thunks_in_command_buffer, ThunkKindsAre(Thunk::kCuDnn));\n }\n TEST(CommandBufferConversionPassTest, ConvertTheBodyOfWhileThunk) {\n-  CommandBufferConversionPass pass;\n+  CommandBufferConversionPass pass{\"test\"};\n \n   std::vector<std::unique_ptr<Thunk>> thunks;\n "
        },
        {
            "sha": "7b01e3ac7c1cb6f7648a7b794cb9e756b8c2d3a9",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.cc",
            "status": "modified",
            "additions": 72,
            "deletions": 3,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -29,7 +29,9 @@ limitations under the License.\n #include \"absl/functional/function_ref.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/ADT/STLExtras.h\"\n@@ -111,6 +113,65 @@ DynamicSliceThunk::OffsetAsFunctionOfIndvarModulesMetadata::FromProto(\n       std::move(extracted_offset_modules));\n }\n \n+std::string DynamicSliceThunk::SliceDef::ToString() const {\n+  std::string result = \"SliceDef{\";\n+\n+  // embedded_thunk_argument\n+  if (embedded_thunk_argument.has_value()) {\n+    result += \"embedded_thunk_argument:\" + embedded_thunk_argument->ToString();\n+  } else {\n+    result += \"embedded_thunk_argument:null\";\n+  }\n+\n+  // offsets\n+  if (offsets.has_value()) {\n+    result += \", offsets:[\";\n+    result +=\n+        absl::StrJoin(*offsets, \", \", [](std::string* out, const auto& offset) {\n+          std::visit(\n+              [out](const auto& value) {\n+                using T = std::decay_t<decltype(value)>;\n+                if constexpr (std::is_same_v<T, int64_t>) {\n+                  absl::StrAppend(out, value);\n+                } else if constexpr (std::is_same_v<T,\n+                                                    BufferAllocation::Slice>) {\n+                  absl::StrAppend(out, value.ToString());\n+                } else if constexpr (std::is_same_v<T, HloModule*>) {\n+                  absl::StrAppend(out, \"HloModule*:\", value->ToString());\n+                }\n+              },\n+              offset);\n+        });\n+    result += \"]\";\n+  } else {\n+    result += \", offsets:null\";\n+  }\n+\n+  // orig_shape\n+  if (orig_shape.has_value()) {\n+    result += \", orig_shape:\" + orig_shape->ToString();\n+  } else {\n+    result += \", orig_shape:null\";\n+  }\n+\n+  // sliced_shape\n+  if (sliced_shape.has_value()) {\n+    result += \", sliced_shape:\" + sliced_shape->ToString();\n+  } else {\n+    result += \", sliced_shape:null\";\n+  }\n+\n+  // offset_byte_size\n+  if (offset_byte_size.has_value()) {\n+    result += \", offset_byte_size:\" + absl::StrCat(*offset_byte_size);\n+  } else {\n+    result += \", offset_byte_size:null\";\n+  }\n+\n+  result += \"}\";\n+  return result;\n+}\n+\n DynamicSliceThunk::DynamicSliceThunk(\n     ThunkInfo thunk_info, std::unique_ptr<ThunkSequence> embedded_thunk,\n     std::vector<std::optional<BufferAllocation::Slice>> arguments,\n@@ -159,6 +220,7 @@ DynamicSliceThunk::DynamicSliceThunk(\n absl::Status DynamicSliceThunk::Prepare(\n     const PrepareParams& params, ResourceRequestsInterface& resource_requests) {\n   for (SliceDef& slice : slices_) {\n+    VLOG(2) << \"DynamicSliceThunk: slice: \" << slice.ToString();\n     if (slice.offsets.has_value()) {\n       TF_RET_CHECK(slice.embedded_thunk_argument.has_value());\n       TF_RET_CHECK(slice.orig_shape.has_value());\n@@ -184,7 +246,12 @@ absl::Status DynamicSliceThunk::Prepare(\n                 /*module=*/*offset_as_function_of_indvar_metadata_->indvar_init,\n                 /*arg_literals=*/{})\n             .value();\n-    VLOG(2) << \"Indvar = \" << Indvar(this).ToString();\n+    VLOG(2) << \"Indvar init module: \"\n+            << offset_as_function_of_indvar_metadata_->indvar_init->ToString();\n+    VLOG(2)\n+        << \"Indvar update module: \"\n+        << offset_as_function_of_indvar_metadata_->indvar_update->ToString();\n+    VLOG(2) << \"Indvar initialized to \" << Indvar(this).ToString();\n   }\n   return absl::OkStatus();\n }\n@@ -276,7 +343,6 @@ absl::Status DynamicSliceThunk::ExecuteOnStream(const ExecuteParams& params) {\n                               offset.shape().ToString()));\n         }\n         VLOG(2) << \"Offset value = \" << offset_value(argument_idx, offset_idx);\n-\n       } else {\n         // Transfer slice offset value from device to host.\n         auto alloc_slice = std::get<BufferAllocation::Slice>(offset);\n@@ -341,6 +407,9 @@ absl::Status DynamicSliceThunk::ExecuteOnStream(const ExecuteParams& params) {\n                                       orig_allocations.device_ordinal(),\n                                       orig_allocations.memory_allocator());\n \n+  VLOG(2) << \"DynamicSliceThunk: slice_allocations: \"\n+          << slice_allocations.ToString();\n+\n   Thunk::ExecuteParams new_params =\n       Thunk::ExecuteParams::CloneWithNewAllocations(params, slice_allocations);\n \n@@ -353,7 +422,7 @@ absl::Status DynamicSliceThunk::ExecuteOnStream(const ExecuteParams& params) {\n             .Evaluate(*offset_as_function_of_indvar_metadata_->indvar_update,\n                       {&Indvar(this)})\n             .value();\n-    VLOG(2) << \"Indvar = \" << Indvar(this).ToString();\n+    VLOG(2) << \"Update Indvar = \" << Indvar(this).ToString();\n   }\n \n   return absl::OkStatus();"
        },
        {
            "sha": "776dcc7c15d4b8b6ab94be64f8e4278ec1bed6ab",
            "filename": "third_party/xla/xla/backends/gpu/runtime/dynamic_slice_thunk.h",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fdynamic_slice_thunk.h?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -136,6 +136,7 @@ class DynamicSliceThunk : public Thunk {\n     std::optional<Shape> orig_shape;\n     std::optional<Shape> sliced_shape;\n     std::optional<uint64_t> offset_byte_size;\n+    std::string ToString() const;\n   };\n \n   const SequentialThunk* get_embedded_thunk() const {\n@@ -185,6 +186,15 @@ class DynamicSliceThunk : public Thunk {\n       absl::Span<const BufferAllocation> buffer_allocations,\n       absl::Span<const BufferAllocation> fake_allocations);\n \n+  std::optional<const OffsetAsFunctionOfIndvarModulesMetadata*>\n+  get_offset_function() const {\n+    if (offset_as_function_of_indvar_metadata_.has_value()) {\n+      return &offset_as_function_of_indvar_metadata_.value();\n+    } else {\n+      return std::nullopt;\n+    }\n+  }\n+\n  private:\n   std::unique_ptr<SequentialThunk> embedded_thunk_;\n   std::vector<std::optional<BufferAllocation::Slice>> arguments_;"
        },
        {
            "sha": "923576c12c7d4a3c6b7c08321e90c0ee7ab508ac",
            "filename": "third_party/xla/xla/hlo/analysis/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2FBUILD?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -155,6 +155,7 @@ cc_library(\n         \"//xla/hlo/evaluator:hlo_evaluator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_query\",\n+        \"//xla/service:call_inliner\",\n         \"//xla/service:collective_ops_utils\",\n         \"//xla/service:constant_value\",\n         \"//xla/service:hlo_module_config\","
        },
        {
            "sha": "60346bf5f8e9c4a166af10ca556c372916ea912c",
            "filename": "third_party/xla/xla/service/call_inliner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -527,7 +527,7 @@ const HloInstruction* InlinedModule::get_inlined_inst(\n   return nullptr;\n }\n \n-absl::StatusOr<InlinedModule> GetInlinedModule(HloModule* module) {\n+absl::StatusOr<InlinedModule> GetInlinedModule(const HloModule* module) {\n   auto [cloned_module, clone_context] =\n       module->CloneWithContext(\"inline\", module->config());\n   CallInliner::InlinedInstructionMap clone_inlined_map;"
        },
        {
            "sha": "54b41c9f37b51897576b579b0f506632f45538e1",
            "filename": "third_party/xla/xla/service/call_inliner.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.h?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -116,7 +116,7 @@ struct InlinedModule {\n // Given a module, this function first clones the module, then inlines the\n // module, and returns the inlined module, clone context and inlined map in\n // InlinedModule struct.\n-absl::StatusOr<InlinedModule> GetInlinedModule(HloModule* module);\n+absl::StatusOr<InlinedModule> GetInlinedModule(const HloModule* module);\n \n }  // namespace xla\n "
        },
        {
            "sha": "02f0796739464a968ec7b875360ac1a062ce87f6",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -401,6 +401,7 @@ cc_library(\n         \"//xla/backends/gpu/runtime:thunk_id\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:call_inliner\",\n         \"//xla/service:name_uniquer\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\","
        },
        {
            "sha": "5b7be1214521c3500dba138765e674f3cdf8e7c1",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -179,7 +179,8 @@ static absl::Status RunThunkPasses(const DebugOptions& debug_options,\n     pipeline.AddPass(std::make_unique<ThunkChecksumTracingPass>());\n   }\n   if (debug_options.xla_gpu_experimental_enable_command_buffer_on_thunks()) {\n-    pipeline.AddPass(std::make_unique<CommandBufferConversionPass>());\n+    pipeline.AddPass(std::make_unique<CommandBufferConversionPass>(\n+        hlo_module ? hlo_module->name() : \"Anonymous\"));\n   }\n   TF_ASSIGN_OR_RETURN(bool changed, pipeline.Run(root_thunk, debug_options,\n                                                  device_info, allocator));"
        },
        {
            "sha": "eb1362a5ee04250c1c963a9e48248f1bb860cc01",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_context.h",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12bb0a674b79bfed14c83839f155dd91b5a74c79/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_context.h?ref=12bb0a674b79bfed14c83839f155dd91b5a74c79",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/call_inliner.h\"\n #include \"xla/service/gpu/execution_stream_assignment.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n@@ -117,6 +118,16 @@ class IrEmitterContext {\n   }\n   NameUniquer* name_uniquer() { return &name_uniquer_; }\n \n+  absl::StatusOr<InlinedModule*> get_inlined_module() {\n+    if (inlined_module_ == nullptr) {\n+      TF_ASSIGN_OR_RETURN(InlinedModule inlined_module,\n+                          GetInlinedModule(hlo_module_));\n+      inlined_module_ =\n+          std::make_unique<InlinedModule>(std::move(inlined_module));\n+    }\n+    return inlined_module_.get();\n+  }\n+\n   std::vector<GpuExecutable::ConstantInfo>& constants() { return constants_; }\n \n   // Emit a constant with a given number of element, given byte size of the\n@@ -155,6 +166,7 @@ class IrEmitterContext {\n   NameUniquer name_uniquer_;\n   std::vector<GpuExecutable::ConstantInfo> constants_;\n   KernelReuseCache kernel_cache_;\n+  std::unique_ptr<InlinedModule> inlined_module_;\n \n   CollectivesAsyncEvents collectives_async_events_;\n   InstructionToHostExecuteAsyncEvents instruction_to_host_execute_async_events_;"
        }
    ],
    "stats": {
        "total": 508,
        "additions": 429,
        "deletions": 79
    }
}