{
    "author": "metaflow",
    "message": "[XLA:GPU] call AdjustDebugOptionsForAutotuning from autotuner util\n\nthat removes most of the code duplication and call to the gpu backend in\ncompile.\n\nPiperOrigin-RevId: 837848792",
    "sha": "ad73a1d1ce1bbcaff3f2722058359fa28093503b",
    "files": [
        {
            "sha": "d9798ea65c2860e12ccdc9b984b1a5221e1c2793",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_codegen_backend.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad73a1d1ce1bbcaff3f2722058359fa28093503b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad73a1d1ce1bbcaff3f2722058359fa28093503b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_codegen_backend.h?ref=ad73a1d1ce1bbcaff3f2722058359fa28093503b",
            "patch": "@@ -96,6 +96,7 @@ class GpuCodegenBackend : public CodegenBackend {\n   static void AdjustDebugOptionsForAutotuning(\n       DebugOptions& debug_options, bool force_allow_register_spills) {\n     debug_options.set_xla_enable_dumping(false);\n+    debug_options.set_xla_gpu_dump_llvmir(false);\n     // Avoid using another thread pool.\n     debug_options.set_xla_gpu_force_compilation_parallelism(1);\n     debug_options.set_xla_gpu_enable_llvm_module_compilation_parallelism(false);\n@@ -114,6 +115,10 @@ class GpuCodegenBackend : public CodegenBackend {\n               .xla_gpu_filter_kernels_spilling_registers_on_autotuning() &&\n           !force_allow_register_spills);\n     }\n+    // Avoid dumping compilation steps.\n+    debug_options.set_xla_gpu_dump_autotune_results_to(\"\");\n+    debug_options.set_xla_gpu_load_autotune_results_from(\"\");\n+    debug_options.set_xla_gpu_dump_autotune_logs_to(\"\");\n   }\n \n  private:"
        },
        {
            "sha": "86b2d3982f1a6414e7270095e7b280fec8b47557",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_compile_util.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 18,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad73a1d1ce1bbcaff3f2722058359fa28093503b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_compile_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad73a1d1ce1bbcaff3f2722058359fa28093503b/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_compile_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_compile_util.cc?ref=ad73a1d1ce1bbcaff3f2722058359fa28093503b",
            "patch": "@@ -80,21 +80,9 @@ AutotunerCompileUtil::AutotunerCompileUtil(std::unique_ptr<Compiler> compiler,\n       stream_(stream),\n       allocator_(allocator),\n       opts_(opts) {\n-  // Avoid dumping compilation steps.\n-  opts_.set_xla_enable_dumping(false);\n-  opts_.set_xla_gpu_dump_autotune_results_to(\"\");\n-  opts_.set_xla_gpu_load_autotune_results_from(\"\");\n-  opts_.set_xla_gpu_dump_llvmir(false);\n-  opts_.set_xla_gpu_dump_autotune_logs_to(\"\");\n-  // Avoid using another thread pool.\n-  opts_.set_xla_gpu_force_compilation_parallelism(1);\n-  opts_.set_xla_gpu_enable_llvm_module_compilation_parallelism(false);\n-  // Avoid using GPU graphs as we don't want to measure graph construction time.\n-  opts_.clear_xla_gpu_enable_command_buffer();\n-  // Avoid using async dot as we don't want to measure event overheads.\n-  opts_.set_xla_gpu_async_dot(false);\n-  opts_.set_xla_embed_ir_in_executable(false);\n-  opts_.set_xla_gpu_kernel_cache_file(\"\");\n+  GpuCodegenBackend::AdjustDebugOptionsForAutotuning(\n+      opts_,\n+      /*force_allow_register_spills=*/false);\n }\n \n absl::StatusOr<AutotunerCompileUtil::ProfilingOutput>\n@@ -138,9 +126,6 @@ absl::StatusOr<std::unique_ptr<Executable>> AutotunerCompileUtil::Compile(\n   if (!new_hlo_module.status().ok()) {\n     return new_hlo_module.status();\n   }\n-  GpuCodegenBackend::AdjustDebugOptionsForAutotuning(\n-      new_hlo_module->get()->mutable_config().mutable_debug_options(),\n-      /*force_allow_register_spills=*/false);\n   absl::StatusOr<std::unique_ptr<Executable>> out = compiler_->RunBackend(\n       std::move(*new_hlo_module), &stream_executor_,\n       Compiler::CompileOptions{&allocator_, /*thread_pool=*/nullptr,"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 8,
        "deletions": 18
    }
}