{
    "author": "tensorflower-gardener",
    "message": "[XLA:Original Value] Improve HLO original value recovery table API\n\nThis CL refactors the `OriginalValueRecoveryTable` API to be more flexible and expressive, particularly for handling tuple-shaped instructions and complex value recovery scenarios during HLO transformations.\n\nThe key changes include:\n\n* Replaced `AddRecoveryModule` and `BuildAndAddRecoveryModule` with the more powerful `AddRecoveryComputation` and `BuildAndAddRecoveryComputation` methods.\n* The new API uses a callback function to generate recovery computations. This allows HLO passes to define recovery logic inline, making transformations more self-contained and easier to understand.\n* The callback can return three distinct states:\n  1. A recovery `HloModule` for complex transformations.\n  2. nullptr to indicate the original value is preserved identically, allowing for direct propagation.\n  3. `std::nullopt` to explicitly drop an original value that cannot be recovered.\n* The implementation now correctly handles tuple-shaped instructions by iterating through all sub-elements.\n* The placeholder naming scheme for new original values has been made more robust, changing from a prefix (`_ovplaceholder_`) to a unique, delimited suffix (`__ovp<index>`). This change is necessary because the previous scheme can cause conflicting placeholder names if different instructions happen to have the same name across optimization passes.\n* `VerifyOriginalValue` is changed to just check the tuple structure follows from the shape. Empty leaf is now tolerated because it seems to be totally expected to happen.\n\nAll existing call sites in the Algebraic Simplifier, TPU-specific simplifiers, and the SPMD Partitioner have been migrated to this new, more expressive API.\n\nPiperOrigin-RevId: 804545260",
    "sha": "1e141de119b3e4ec803e5b66a6104ab571294d7b",
    "files": [
        {
            "sha": "dc40f4078562b86d991e2b18f6c253263f6002f6",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 110,
            "deletions": 57,
            "changes": 167,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -35,7 +35,10 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/strings/cord.h\"\n #include \"absl/strings/escaping.h\"\n+#include \"absl/strings/match.h\"\n+#include \"absl/strings/numbers.h\"\n #include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_split.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n@@ -70,6 +73,7 @@ limitations under the License.\n #include \"xla/tsl/platform/logging.h\"\n #include \"xla/tsl/platform/status.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tuple_tree.h\"\n #include \"xla/util.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n@@ -1411,7 +1415,8 @@ struct OriginalArrayComparator {\n // testing and debugging.\n inline absl::btree_map<OriginalArray, std::pair<OriginalArray, HloModule*>,\n                        OriginalArrayComparator>\n-GetOrderedHashMap(const OriginalValueRecoveryTable& unordered_table) {\n+GetOrderedHashMap(\n+    const HloModule::OriginalValueRecoveryTable::Table& unordered_table) {\n   absl::btree_map<OriginalArray, std::pair<OriginalArray, HloModule*>,\n                   OriginalArrayComparator>\n       ordered_table;\n@@ -1425,7 +1430,7 @@ GetOrderedHashMap(const OriginalValueRecoveryTable& unordered_table) {\n std::string HloModule::OriginalValueRecoveryTable::ToString(\n     HloPrintOptions options) const {\n   std::string result;\n-  for (const auto& p : GetOrderedHashMap(*this)) {\n+  for (const auto& p : GetOrderedHashMap(table_)) {\n     const auto& replaced_original_array = p.first;\n     const auto& replacing_original_array = p.second.first;\n     HloModule* recovery_module = p.second.second;\n@@ -1455,7 +1460,7 @@ std::string HloModule::OriginalValueRecoveryTable::ToString(\n OriginalValueRecoveryTableProto HloModule::OriginalValueRecoveryTable::ToProto()\n     const {\n   OriginalValueRecoveryTableProto original_value_recovery_table_proto;\n-  for (const auto& p : GetOrderedHashMap(*this)) {\n+  for (const auto& p : GetOrderedHashMap(table_)) {\n     const auto& replaced_original_array = p.first;\n     const auto& replacing_original_array = p.second.first;\n     HloModule* recovery_module = p.second.second;\n@@ -1491,79 +1496,127 @@ HloModule::OriginalValueRecoveryTable::FromProto(\n       TF_ASSIGN_OR_RETURN(recovery_module,\n                           HloModule::CreateFromProto(proto, config));\n     }\n-    original_value_recovery_table[replaced_original_array] =\n+    original_value_recovery_table.table_[replaced_original_array] =\n         std::make_pair(replacing_original_array, std::move(recovery_module));\n   }\n   return original_value_recovery_table;\n }\n \n namespace {\n-void AddEntryToOriginalValueRecoveryTable(\n-    OriginalValueRecoveryTable& original_value_recovery_table,\n-    std::shared_ptr<OriginalValue> old_original_value,\n-    std::shared_ptr<OriginalValue> new_original_value,\n-    std::unique_ptr<HloModule> recovery_module) {\n-  original_value_recovery_table\n-      [*old_original_value->original_arrays().begin()->second] = {\n-          *new_original_value->original_arrays().begin()->second,\n-          std::move(recovery_module)};\n+std::string GetOriginalValuePlaceholderInstructionName(\n+    absl::string_view original_value_instruction_name) {\n+  std::string base_name = std::string(original_value_instruction_name);\n+  int64_t placeholder_index = 0;\n+  if (absl::StrContains(original_value_instruction_name,\n+                        kOriginalValuePlaceholderDelimiter)) {\n+    // split by the delimiter and update the base and index\n+    std::vector<std::string> parts = absl::StrSplit(\n+        original_value_instruction_name, kOriginalValuePlaceholderDelimiter);\n+    CHECK_EQ(parts.size(), 2)\n+        << \"Original value instruction name does not have the expected format: \"\n+        << original_value_instruction_name;\n+    base_name = parts[0];\n+    CHECK(absl::SimpleAtoi(parts[1], &placeholder_index))\n+        << \"Invalid placeholder index in original value name: \"\n+        << original_value_instruction_name;\n+    ++placeholder_index;\n+  }\n+  return absl::StrCat(base_name, kOriginalValuePlaceholderDelimiter,\n+                      placeholder_index);\n }\n }  // namespace\n \n-void HloModule::OriginalValueRecoveryTable::AddRecoveryModule(\n+void HloModule::OriginalValueRecoveryTable::AddRecoveryComputation(\n     const HloInstruction* replaced_inst, HloInstruction* replacing_inst,\n-    std::unique_ptr<HloModule> recovery_module) {\n-  const std::shared_ptr<OriginalValue>& replaced_original_value =\n+    std::function<std::optional<std::unique_ptr<HloModule>>(\n+        const ShapeIndex& index, const OriginalArray& replaced_original_array,\n+        const xla::Shape& replaced_array_shape,\n+        const xla::Shape& replacing_array_shape)>&&\n+        build_recovery_computation) {\n+  CHECK(ShapeUtil::EqualStructure(replaced_inst->shape(),\n+                                  replacing_inst->shape()));\n+  std::shared_ptr<OriginalValue> replaced_original_value =\n       replaced_inst->original_value();\n   if (!replaced_original_value) {\n     return;\n   }\n-  std::shared_ptr<OriginalValue> replacing_original_value =\n-      replacing_inst->original_value();\n-\n-  // Creates a placeholder original value for the replacing instruction if it\n-  // doesn't have one.\n-  if (!replacing_original_value) {\n-    replacing_original_value = OriginalValue::CreateFromInstruction(\n-        replacing_inst, /*prefix=*/kOriginalValuePlaceholderPrefix);\n-    if (!replacing_original_value) {\n-      return;\n+  if (replacing_inst->original_value() == nullptr) {\n+    replacing_inst->set_original_value(std::make_shared<OriginalValue>(\n+        TupleTree<std::optional<OriginalArray>>(replacing_inst->shape())));\n+  }\n+  for (const auto& [shape_index, replaced_original_array] :\n+       replaced_original_value->original_arrays()) {\n+    if (!replaced_original_array || table_.contains(*replaced_original_array)) {\n+      // If the replaced array is already tracked by the recovery table, we can\n+      // ignore it since it is already handled by another path.\n+      continue;\n+    }\n+    // If build_recovery_computation is not provided, we can just propagate the\n+    // replaced original array.\n+    std::optional<std::unique_ptr<HloModule>> recovery_computation(nullptr);\n+    if (build_recovery_computation) {\n+      recovery_computation = build_recovery_computation(\n+          shape_index, *replaced_original_array,\n+          ShapeUtil::GetSubshape(replaced_inst->shape(), shape_index),\n+          ShapeUtil::GetSubshape(replacing_inst->shape(), shape_index));\n+    }\n+    if (!recovery_computation) {\n+      continue;\n     }\n+    std::optional<OriginalArray>* replacing_original_array =\n+        replacing_inst->original_value()->mutable_original_array(shape_index);\n+    if (recovery_computation->get() == nullptr &&\n+        !replacing_original_array->has_value()) {\n+      // If the recovery computation is the identity computation and the\n+      // replacing original array is not set, we can just propagate the replaced\n+      // original array without setting any recovery computation.\n+      replacing_original_array->emplace(*replaced_original_array);\n+      continue;\n+    }\n+    if (!*replacing_original_array) {\n+      replacing_original_array->emplace(\n+          OriginalArray{GetOriginalValuePlaceholderInstructionName(\n+                            replaced_original_array->instruction_name),\n+                        shape_index});\n+    }\n+    table_.emplace(*replaced_original_array,\n+                   std::make_pair(**replacing_original_array,\n+                                  std::move(*recovery_computation)));\n   }\n-\n-  AddEntryToOriginalValueRecoveryTable(*this, replaced_original_value,\n-                                       replacing_original_value,\n-                                       std::move(recovery_module));\n }\n \n-void HloModule::OriginalValueRecoveryTable::BuildAndAddRecoveryModule(\n+void HloModule::OriginalValueRecoveryTable::BuildAndAddRecoveryComputation(\n     const HloInstruction* replaced_inst, HloInstruction* replacing_inst,\n-    const std::function<HloInstruction*(\n-        xla::HloComputation::Builder& builder, const xla::Shape& input_shape,\n-        const xla::Shape& output_shape)>& build_entry_computation) {\n-  const std::shared_ptr<OriginalValue>& replaced_original_value =\n-      replaced_inst->original_value();\n-  if (!replaced_original_value) {\n-    return;\n-  }\n-  std::shared_ptr<OriginalValue> replacing_original_value =\n-      replacing_inst->original_value();\n-\n-  if (build_entry_computation) {\n-    xla::HloComputation::Builder builder(\"recovery_computation\");\n-    xla::HloModuleConfig config;\n-    auto recovery_module =\n-        std::make_unique<xla::HloModule>(\"recovery_module\", config);\n-    recovery_module->AddEntryComputation(builder.Build(build_entry_computation(\n-        builder, replacing_inst->shape(), replaced_inst->shape())));\n-\n-    return AddRecoveryModule(replaced_inst, replacing_inst,\n-                             std::move(recovery_module));\n-  }\n-\n-  AddEntryToOriginalValueRecoveryTable(*this, replaced_original_value,\n-                                       replacing_original_value,\n-                                       /*recovery_module=*/nullptr);\n+    std::function<std::optional<HloInstruction*>(\n+        xla::HloComputation::Builder& builder, const ShapeIndex& index,\n+        const OriginalArray& replaced_original_array,\n+        const xla::Shape& replaced_array_shape,\n+        const xla::Shape& replacing_array_shape)>&&\n+        build_recovery_computation) {\n+  AddRecoveryComputation(\n+      replaced_inst, replacing_inst,\n+      [build_recovery_computation](const ShapeIndex& index,\n+                                   const OriginalArray& replaced_original_array,\n+                                   const xla::Shape& replaced_array_shape,\n+                                   const xla::Shape& replacing_array_shape)\n+          -> std::optional<std::unique_ptr<HloModule>> {\n+        xla::HloComputation::Builder builder(\"recovery_computation\");\n+        xla::HloModuleConfig config;\n+        auto recovery_module =\n+            std::make_unique<xla::HloModule>(\"recovery_module\", config);\n+        std::optional<HloInstruction*> root_instruction =\n+            build_recovery_computation(builder, index, replaced_original_array,\n+                                       replaced_array_shape,\n+                                       replacing_array_shape);\n+        if (!root_instruction) {\n+          return std::nullopt;\n+        }\n+        if (*root_instruction == nullptr) {\n+          return nullptr;\n+        }\n+        recovery_module->AddEntryComputation(builder.Build(*root_instruction));\n+        return recovery_module;\n+      });\n }\n \n /* static */ std::atomic<int> HloModule::next_unique_module_id_(0);"
        },
        {
            "sha": "3e57fd0afdfcdb1843451789fff4bb7fff96f657",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.h",
            "status": "modified",
            "additions": 96,
            "deletions": 30,
            "changes": 126,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.h?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -61,8 +61,7 @@ limitations under the License.\n \n namespace xla {\n \n-inline constexpr absl::string_view kOriginalValuePlaceholderPrefix =\n-    \"_ovplaceholder_\";\n+inline constexpr absl::string_view kOriginalValuePlaceholderDelimiter = \"__ovp\";\n \n using LayoutCanonicalizationCallback =\n     std::function<absl::StatusOr<std::pair<std::vector<Shape>, Shape>>(\n@@ -869,11 +868,12 @@ class HloModule {\n       topological_sort_;\n \n  public:\n-  class OriginalValueRecoveryTable\n-      : public absl::flat_hash_map<\n-            OriginalArray,\n-            std::pair<OriginalArray, std::unique_ptr<HloModule>>> {\n+  class OriginalValueRecoveryTable {\n    public:\n+    using Table = absl::flat_hash_map<\n+        OriginalArray, std::pair<OriginalArray, std::unique_ptr<HloModule>>>;\n+    using iterator = Table::iterator;\n+    using const_iterator = Table::const_iterator;\n     std::string ToString(HloPrintOptions options = HloPrintOptions()) const;\n \n     OriginalValueRecoveryTableProto ToProto() const;\n@@ -882,26 +882,94 @@ class HloModule {\n         const xla::OriginalValueRecoveryTableProto&\n             original_value_recovery_table);\n \n-    // Adds an entry to the original value recovery table. Each entry contains a\n-    // recovery computation that can be used to recover the original array in\n-    // the old original value from the original array in the new original value.\n-\n-    // Adds an entry to the original value recovery table. Tries to\n-    // create a placeholder original value for the replacing instruction if it\n-    // doesn't have one.\n-    void AddRecoveryModule(const HloInstruction* replaced_inst,\n-                           HloInstruction* replacing_inst,\n-                           std::unique_ptr<HloModule> recovery_module);\n-\n-    // Creates a recovery module using the computation built from\n-    // build_recovery_computation as the entry computation, and adds an entry to\n-    // the original value recovery table using the recovery module.\n-    void BuildAndAddRecoveryModule(\n+    // Populates the original value recovery table for a transformation that\n+    // replaces `replaced_inst` with `replacing_inst`.\n+    //\n+    // This method facilitates tracking of \"original values\" across HLO passes.\n+    // When an instruction is replaced, this method helps establish the link\n+    // between the original values of the old instruction and the new one.\n+    //\n+    // It iterates through each `OriginalArray` associated with the\n+    // `replaced_inst`. For each, it invokes the `build_recovery_computation`\n+    // callback to determine how to recover the original value. The callback can\n+    // either provide a recovery computation (as an `HloModule`), indicate that\n+    // the original value can be directly propagated, or indicate that it cannot\n+    // be recovered. If the callback is not provided, the original value is\n+    // propagated by default. This is the same as if the callback always\n+    // returns `nullptr` (see below).\n+    //\n+    // Precondition: `replaced_inst` and `replacing_inst` must have shapes with\n+    // identical tuple structures.\n+    //\n+    // The `build_recovery_computation` callback has the following signature:\n+    // `std::optional<std::unique_ptr<HloModule>>(\n+    //     const ShapeIndex& index,\n+    //     const OriginalArray& replaced_original_array,\n+    //     const xla::Shape& replaced_array_shape,\n+    //     const xla::Shape& replacing_array_shape)`\n+    //\n+    // It is called for each `OriginalArray` in `replaced_inst` and should\n+    // return one of the following:\n+    //\n+    //  - A valid `std::unique_ptr<HloModule>`: This HLO module represents the\n+    //    recovery computation. Its entry computation must take one parameter\n+    //    (the value corresponding to the `OriginalArray` in `replacing_inst`)\n+    //    and return the recovered value (which should match the value of the\n+    //    `OriginalArray` in `replaced_inst`). An entry will be added to the\n+    //    recovery table.\n+    //\n+    //  - `nullptr` (as a `std::unique_ptr<HloModule>`): This indicates that the\n+    //    original value is preserved identically.\n+    //    - If `replacing_inst` does not have an `OriginalArray` at this\n+    //      `ShapeIndex`, the `OriginalArray` from `replaced_inst` is directly\n+    //      propagated to it. No entry is added to the recovery table.\n+    //    - If `replacing_inst` already has an `OriginalArray`, an entry is\n+    //      added to the table mapping the old `OriginalArray` to the new one\n+    //      with a `nullptr` recovery module, signifying they are equivalent.\n+    //\n+    //  - `std::nullopt`: This indicates that the original value cannot be\n+    //    recovered and should be dropped.\n+    //\n+    // This method will create `OriginalValue` and placeholder `OriginalArray`s\n+    // for `replacing_inst` if they don't already exist and a recovery is\n+    // established.\n+    void AddRecoveryComputation(\n         const HloInstruction* replaced_inst, HloInstruction* replacing_inst,\n-        const std::function<HloInstruction*(\n-            xla::HloComputation::Builder& builder,\n-            const xla::Shape& input_shape, const xla::Shape& output_shape)>&\n-            build_entry_computation);\n+        std::function<std::optional<std::unique_ptr<HloModule>>(\n+            const ShapeIndex& index,\n+            const OriginalArray& replaced_original_array,\n+            const xla::Shape& replaced_array_shape,\n+            const xla::Shape& replacing_array_shape)>&&\n+            build_recovery_computation = nullptr);\n+\n+    // Similar to `AddRecoveryComputation`, but the callback is provided an\n+    // HLO module builder so that caller can directly build the recovery\n+    // computation with less boilerplate.\n+    void BuildAndAddRecoveryComputation(\n+        const HloInstruction* replaced_inst, HloInstruction* replacing_inst,\n+        std::function<std::optional<HloInstruction*>(\n+            xla::HloComputation::Builder& builder, const ShapeIndex& index,\n+            const OriginalArray& replaced_original_array,\n+            const xla::Shape& replaced_array_shape,\n+            const xla::Shape& replacing_array_shape)>&&\n+            build_recovery_computation);\n+\n+    bool empty() const { return table_.empty(); }\n+\n+    void emplace(const OriginalArray& replaced_original_array,\n+                 std::pair<OriginalArray, std::unique_ptr<HloModule>>&&\n+                     recovery_computation) {\n+      table_.emplace(replaced_original_array, std::move(recovery_computation));\n+    }\n+\n+    iterator begin() { return table_.begin(); }\n+    iterator end() { return table_.end(); }\n+    const_iterator begin() const { return table_.begin(); }\n+    const_iterator end() const { return table_.end(); }\n+\n+   private:\n+    friend class HloModule;\n+    Table table_;\n   };\n \n   const OriginalValueRecoveryTable& original_value_recovery_table() const {\n@@ -912,11 +980,9 @@ class HloModule {\n   }\n \n   void set_original_value_recovery_table(\n-      OriginalValueRecoveryTable& original_value_recovery_table) {\n-    for (auto& p : original_value_recovery_table) {\n-      original_value_recovery_table_[p.first] =\n-          std::make_pair(p.second.first, std::move(p.second.second));\n-    }\n+      OriginalValueRecoveryTable&& original_value_recovery_table) {\n+    original_value_recovery_table_.table_ =\n+        std::move(original_value_recovery_table.table_);\n   }\n \n  private:"
        },
        {
            "sha": "29e3d0b2267d05c725314aec26eecf5d8b5c8d02",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -1213,7 +1213,8 @@ bool HloParserImpl::ParseHloModule(HloModule* module,\n     module->buffer_donor_config() = buffer_donor_config;\n   }\n   if (original_value_recovery_table) {\n-    module->set_original_value_recovery_table(*original_value_recovery_table);\n+    module->set_original_value_recovery_table(\n+        std::move(*original_value_recovery_table));\n   }\n   DeduplicateOriginalValues(module);\n \n@@ -6709,8 +6710,9 @@ bool HloParserImpl::ParseOriginalValueRecoveryTable(\n       }\n       recovery_module = std::move(status_or_recovery_module.value());\n     }\n-    original_value_recovery_table[replaced_original_array] =\n-        std::make_pair(replacing_original_array, std::move(recovery_module));\n+    original_value_recovery_table.emplace(\n+        replaced_original_array,\n+        std::make_pair(replacing_original_array, std::move(recovery_module)));\n   }\n \n   lexer_.Lex();"
        },
        {
            "sha": "dfb1ee7ea0a0cd76ed2e87a7b87792ef582b210e",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/algebraic_simplifier.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 17,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Falgebraic_simplifier.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -50,6 +50,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction_utils.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/hlo/utils/hlo_sharding_util.h\"\n #include \"xla/layout.h\"\n #include \"xla/layout_util.h\"\n@@ -5240,23 +5241,20 @@ absl::Status AlgebraicSimplifierVisitor::HandleBroadcast(\n         dims.erase(dims.begin() + inserted_index);\n       }\n \n-      HloInstruction* replaced_inst = operand;\n-      if (replaced_inst->original_value()) {\n-        HloInstruction* replacing_inst = operand->mutable_operand(0);\n-        auto build_entry_computation = [](xla::HloComputation::Builder& builder,\n-                                          const xla::Shape& input_shape,\n-                                          const xla::Shape& output_shape) {\n-          xla::HloInstruction* param = builder.AddInstruction(\n-              xla::HloInstruction::CreateParameter(0, input_shape, \"p\"));\n-          return builder.AddInstruction(\n-              xla::HloInstruction::CreateReshape(output_shape, param));\n-        };\n-        HloModule* module = broadcast->parent()->parent();\n-        module->mutable_original_value_recovery_table()\n-            .BuildAndAddRecoveryModule(replaced_inst, replacing_inst,\n-                                       build_entry_computation);\n-      }\n-\n+      HloModule* module = broadcast->parent()->parent();\n+      module->mutable_original_value_recovery_table()\n+          .BuildAndAddRecoveryComputation(\n+              operand, operand->mutable_operand(0),\n+              [](xla::HloComputation::Builder& builder, const ShapeIndex& index,\n+                 const OriginalArray& replaced_original_array,\n+                 const xla::Shape& replaced_shape,\n+                 const xla::Shape& replacing_shape) {\n+                xla::HloInstruction* param =\n+                    builder.AddInstruction(xla::HloInstruction::CreateParameter(\n+                        0, replacing_shape, \"p\"));\n+                return builder.AddInstruction(\n+                    xla::HloInstruction::CreateReshape(replaced_shape, param));\n+              });\n       return ReplaceWithNewInstruction(\n           broadcast,\n           HloInstruction::CreateBroadcast(broadcast->shape(),"
        },
        {
            "sha": "ee32594cc10472f458bfe8ed8dcaf1d0eeeca28e",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 52,
            "deletions": 12,
            "changes": 64,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -44,7 +44,6 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/comparison_util.h\"\n-#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_input_output_alias_config.h\"\n@@ -2896,20 +2895,61 @@ absl::Status VerifyLayoutConstrainedAllReduce(const HloModule& module) {\n   return absl::OkStatus();\n }\n \n-// Verifies that leaf nodes in an original value contain values.\n+namespace {\n+std::string FormatShapeIndexValidationError(\n+    absl::string_view instruction_name,\n+    const absl::flat_hash_set<ShapeIndex>& shape_leaf_indices,\n+    const absl::flat_hash_set<ShapeIndex>& ov_leaf_indices) {\n+  std::vector<ShapeIndex> shape_only;\n+  std::vector<ShapeIndex> ov_only;\n+  for (const auto& idx : shape_leaf_indices) {\n+    if (!ov_leaf_indices.contains(idx)) {\n+      shape_only.push_back(idx);\n+    }\n+  }\n+  for (const auto& idx : ov_leaf_indices) {\n+    if (!shape_leaf_indices.contains(idx)) {\n+      ov_only.push_back(idx);\n+    }\n+  }\n+  std::sort(shape_only.begin(), shape_only.end());\n+  std::sort(ov_only.begin(), ov_only.end());\n+  auto shape_index_formatter = [](std::string* out, const ShapeIndex& i) {\n+    absl::StrAppend(out, i.ToString());\n+  };\n+  return absl::StrFormat(\n+      \"Mismatched tuple structure in original_value for \"\n+      \"instruction %s. Leaf indices in shape and original_value \"\n+      \"do not match.\\nIn shape only: {%s}\\nIn original_value only: {%s}\",\n+      instruction_name, absl::StrJoin(shape_only, \", \", shape_index_formatter),\n+      absl::StrJoin(ov_only, \", \", shape_index_formatter));\n+}\n+\n+}  // namespace\n+\n+// Verifies that the original value has the same tuple structure as the\n+// instruction shape.\n absl::Status VerifyOriginalValue(const HloModule& module) {\n   for (const HloComputation* computation : module.computations()) {\n     for (const HloInstruction* instruction : computation->instructions()) {\n-      if (auto original_value = instruction->original_value()) {\n-        // An original value is expected to have intermediate nodes that are\n-        // always nullopt and leaves with actual values.\n-        for (const auto& pair : original_value->original_arrays()) {\n-          if (!pair.second.has_value()) {\n-            return Internal(\n-                \"Leaf nodes in an original value is expected to contain values.\"\n-                \" Instruction: %s.\",\n-                instruction->ToString());\n-          }\n+      if (instruction->original_value()) {\n+        const auto& shape = instruction->shape();\n+        const auto& original_value = instruction->original_value();\n+        absl::flat_hash_set<ShapeIndex> shape_leaf_indices;\n+        ShapeUtil::ForEachLeafShape(\n+            shape, [&](const Shape& /*subshape*/, const ShapeIndex& index) {\n+              shape_leaf_indices.insert(index);\n+            });\n+\n+        absl::flat_hash_set<ShapeIndex> ov_leaf_indices;\n+        for (const auto& [index, value] : original_value->original_arrays()) {\n+          ov_leaf_indices.insert(index);\n+        }\n+\n+        if (shape_leaf_indices != ov_leaf_indices) {\n+          return Internal(\"%s\", FormatShapeIndexValidationError(\n+                                    instruction->name(), shape_leaf_indices,\n+                                    ov_leaf_indices));\n         }\n       }\n     }"
        },
        {
            "sha": "afad4ff712873fd5a454f0117e0537b26985604f",
            "filename": "third_party/xla/xla/service/hlo_verifier_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier_test.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -3690,12 +3690,27 @@ HloModule module\n ENTRY %entry_computation {\n   ROOT op = ((f32[], f32[3]{0}), f32[2,3]) parameter(0),  origin={(({}, {\"v2\"}), {\"v3\"})}\n }\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnUnverifiedModule(hlo_string));\n+\n+  auto status = verifier().Run(module.get()).status();\n+  EXPECT_TRUE(status.ok());\n+}\n+\n+TEST_F(HloVerifierTest, MismatchedTupleInOriginalValue) {\n+  const std::string hlo_string = R\"(\n+HloModule module\n+ENTRY %entry_computation {\n+  ROOT op = f32[] parameter(0),  origin={(({}, {\"v2\"}), {\"v3\"})}\n+}\n )\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnUnverifiedModule(hlo_string));\n \n   auto status = verifier().Run(module.get()).status();\n   EXPECT_FALSE(status.ok());\n+  EXPECT_THAT(status.message(), HasSubstr(\"Mismatched tuple structure\"));\n }\n \n TEST_F(HloVerifierTest, RaggedAllToAllWithRank1OffsetsSizes) {"
        },
        {
            "sha": "3b9ae8ec39cb341466f0bc7809ae57c55c2498a9",
            "filename": "third_party/xla/xla/service/propagate_original_value_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 7,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -150,8 +150,24 @@ ENTRY %ReshapeAndBroadcastMerged (param0: f32[5]) -> f32[1,2,3,5,1] {\n   RunAndFilecheckHloRewrite(hlo_string, AlgebraicSimplifier(options));\n }\n \n-TEST_F(OriginalValueRecoveryTableTest, FailedToGetPlaceholderOriginalValue) {\n+TEST_F(OriginalValueRecoveryTableTest,\n+       NullOriginalValueOnTupleGetTupleElementIsNotContagious) {\n   constexpr absl::string_view hlo_string = R\"(\n+// CHECK:      HloModule test, entry_computation_layout={((f32[5]{0}, f32[5]{0}))->f32[1,2,3,5,1]{4,3,2,1,0}}, origin_recovery_table={\n+// CHECK-NEXT:   {\"reshape\"} : {\"reshape__ovp0\"},\n+// CHECK-NEXT:   \"\n+// CHECK-NEXT:     ENTRY %recovery_computation (p: f32[5]) -> f32[1,5,1] {\n+// CHECK-NEXT:       %p = f32[5]{0} parameter(0)\n+// CHECK-NEXT:       ROOT %reshape = f32[1,5,1]{2,1,0} reshape(%p)\n+// CHECK-NEXT:     }\n+// CHECK-NEXT:   \"\n+// CHECK-NEXT: }\n+// CHECK:      ENTRY %main (param: (f32[5], f32[5])) -> f32[1,2,3,5,1] {\n+// CHECK-NEXT:   %param = (f32[5]{0}, f32[5]{0}) parameter(0)\n+// CHECK-NEXT:   %get-tuple-element = f32[5]{0} get-tuple-element(%param), index=1, origin={{[{]}}{\"reshape__ovp0\"}}\n+// CHECK-NEXT:   ROOT %broadcast = f32[1,2,3,5,1]{4,3,2,1,0} broadcast(%get-tuple-element), dimensions={3}\n+// CHECK-NEXT: }\n+  \n HloModule test\n \n ENTRY %main (param0: (f32[5]{0}, f32[5]{0})) -> f32[1,2,3,5,1] {\n@@ -164,12 +180,7 @@ ENTRY %main (param0: (f32[5]{0}, f32[5]{0})) -> f32[1,2,3,5,1] {\n   )\";\n \n   AlgebraicSimplifierOptions options;\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(hlo_string));\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed,\n-                          AlgebraicSimplifier(options).Run(module.get()));\n-  EXPECT_TRUE(changed);\n-  EXPECT_TRUE(module->original_value_recovery_table().empty());\n+  RunAndFilecheckHloRewrite(hlo_string, AlgebraicSimplifier(options));\n }\n \n }  // namespace"
        },
        {
            "sha": "f7dae65d69769ce651e1d7265bff65a9083f173b",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 29,
            "changes": 70,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1e141de119b3e4ec803e5b66a6104ab571294d7b/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=1e141de119b3e4ec803e5b66a6104ab571294d7b",
            "patch": "@@ -48,6 +48,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/hlo/ir/hlo_sharding.h\"\n #include \"xla/hlo/ir/tile_assignment.h\"\n #include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n@@ -6163,37 +6164,48 @@ absl::StatusOr<bool> SpmdPartitioner::PreprocessCallSites(\n void SpmdPartitioningVisitor::SetPartitionedHlo(\n     const HloInstruction* hlo, PartitionedHlo&& partitioned_hlo) {\n   CHECK_EQ(partitioned_instructions_.count(hlo), 0);\n-  if (hlo->original_value() && !partitioned_hlo.sharding().IsReplicated()) {\n-    SpmdBuilder builder(\"recovery_computation\", nullptr);\n-    auto* param = builder.AddInstruction(xla::HloInstruction::CreateParameter(\n-        0, partitioned_hlo.hlo()->shape(), \"param\"));\n-    param->set_sharding(partitioned_hlo.sharding());\n-    xla::HloModuleConfig config;\n-    auto recovery_module =\n-        std::make_unique<HloModule>(\"recovery_module\", config);\n-    PartitionedHlo::ReshardCache reshard_cache;\n-    int64_t next_channel_id = hlo_query::NextChannelId(*recovery_module);\n-\n-    xla::spmd::PartitionedHlo::PartitioningState partitioning_state =\n-        partitioned_hlo.state();\n-    partitioning_state.b = &builder;\n-    partitioning_state.module = recovery_module.get();\n-    partitioning_state.partition_id =\n-        partitioning_state.collective_ops_creator.create_partition_id(&builder);\n-    partitioning_state.next_channel_id = &next_channel_id;\n-    partitioning_state.reshard_cache = &reshard_cache;\n-\n-    PartitionedHlo param_partitioned_hlo(param, partitioned_hlo.base_shape(),\n-                                         partitioning_state);\n-    // Creates computation to recover the partitioned value.\n-    param_partitioned_hlo.Replicate();\n-    recovery_module->AddEntryComputation(builder.Build());\n-\n+  if (!partitioned_hlo.sharding().IsReplicated()) {\n     // Adds recovery computation to the original value recovery table.\n     auto* module = const_cast<HloModule*>(hlo->parent()->parent());\n-    module->mutable_original_value_recovery_table().AddRecoveryModule(\n-        /*replaced_inst=*/hlo, /*replacing_inst=*/partitioned_hlo.hlo(),\n-        std::move(recovery_module));\n+    module->mutable_original_value_recovery_table().AddRecoveryComputation(\n+        hlo, partitioned_hlo.hlo(),\n+        [&](const ShapeIndex& index,\n+            const OriginalArray& replaced_original_array,\n+            const xla::Shape& replaced_array_shape,\n+            const xla::Shape& replacing_array_shape) {\n+          SpmdBuilder builder(\"recovery_computation\", nullptr);\n+          auto* param =\n+              builder.AddInstruction(xla::HloInstruction::CreateParameter(\n+                  0, replacing_array_shape, \"param\"));\n+          if (partitioned_hlo.sharding().IsTuple()) {\n+            param->set_sharding(\n+                partitioned_hlo.sharding().GetSubSharding(hlo->shape(), index));\n+          } else {\n+            param->set_sharding(partitioned_hlo.sharding());\n+          }\n+          xla::HloModuleConfig config;\n+          auto recovery_module =\n+              std::make_unique<HloModule>(\"recovery_module\", config);\n+          PartitionedHlo::ReshardCache reshard_cache;\n+          int64_t next_channel_id = hlo_query::NextChannelId(*recovery_module);\n+\n+          xla::spmd::PartitionedHlo::PartitioningState partitioning_state =\n+              partitioned_hlo.state();\n+          partitioning_state.b = &builder;\n+          partitioning_state.module = recovery_module.get();\n+          partitioning_state.partition_id =\n+              partitioning_state.collective_ops_creator.create_partition_id(\n+                  &builder);\n+          partitioning_state.next_channel_id = &next_channel_id;\n+          partitioning_state.reshard_cache = &reshard_cache;\n+\n+          PartitionedHlo param_partitioned_hlo(param, replaced_array_shape,\n+                                               partitioning_state);\n+          // Creates computation to recover the partitioned value.\n+          param_partitioned_hlo.Replicate();\n+          recovery_module->AddEntryComputation(builder.Build());\n+          return recovery_module;\n+        });\n   }\n \n   partitioned_instructions_.emplace(hlo, partitioned_hlo);"
        }
    ],
    "stats": {
        "total": 507,
        "additions": 352,
        "deletions": 155
    }
}