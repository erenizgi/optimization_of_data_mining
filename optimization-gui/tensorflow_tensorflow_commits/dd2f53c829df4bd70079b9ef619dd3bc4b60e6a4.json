{
    "author": "metaflow",
    "message": "[XLA:GPU] move hoisting of bitcasts to a separate pass\n\nPiperOrigin-RevId: 843628242",
    "sha": "dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
    "files": [
        {
            "sha": "c626469d5be7b34c013ac079ad1650b62c354356",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -427,7 +427,6 @@ cc_library(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n         \"//xla/backends/autotuner:codegen_backend\",\n-        \"//xla/backends/gpu/codegen/triton:tma_utils\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/transforms/simplifiers:float_normalization\",\n         \"//xla/hlo/utils:hlo_query\",\n@@ -442,12 +441,12 @@ cc_library(\n         \"//xla/service/gpu/autotuning:dot_search_space\",\n         \"//xla/service/gpu/autotuning:triton_configs\",\n         \"//xla/service/gpu/transforms:fusion_wrapper\",\n+        \"//xla/service/gpu/transforms:hoist_fused_bitcasts\",\n         \"//xla/service/gpu/transforms:nest_gemm_fusion\",\n         \"//xla/service/gpu/transforms:priority_fusion\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/stream_executor/gpu:tma_metadata\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "71a113e2e4631dca56b76cfe6487638871608214",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/triton.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Ftriton.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -25,7 +25,6 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"xla/autotuning.pb.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n-#include \"xla/backends/gpu/codegen/triton/tma_utils.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n@@ -42,12 +41,12 @@ limitations under the License.\n #include \"xla/service/gpu/matmul_utils.h\"\n #include \"xla/service/gpu/split_k_gemm_rewriter.h\"\n #include \"xla/service/gpu/transforms/fusion_wrapper.h\"\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n #include \"xla/service/gpu/transforms/nest_gemm_fusion.h\"\n #include \"xla/service/gpu/transforms/priority_fusion.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n-#include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n@@ -221,7 +220,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonBackend::RunHloPasses(\n   // into fusions.\n   FusionWrapper fusion_wrapper(gpu_device_info);\n   TF_RETURN_IF_ERROR(fusion_wrapper.Run(hlo_module.get()).status());\n-\n+  TF_RETURN_IF_ERROR(HoistFusedBitcasts().Run(hlo_module.get()).status());\n   NestGemmFusion nest_gemm_fusion(gpu_device_info, mlir_context_);\n   TF_RETURN_IF_ERROR(nest_gemm_fusion.Run(hlo_module.get()).status());\n   return hlo_module;"
        },
        {
            "sha": "faefcc8e14163fb4dad581fa13435ba47fa23d0e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -551,7 +551,6 @@ xla_test(\n         \"no_mac\",\n     ],\n     deps = [\n-        \":fusion_emitter\",\n         \":test_utils\",\n         \":xtile_compiler\",\n         \"//xla:autotuning_proto_cc\",\n@@ -569,6 +568,7 @@ xla_test(\n         \"//xla/service/gpu:target_constants\",\n         \"//xla/service/gpu/model:block_level_parameters\",\n         \"//xla/service/gpu/tests:gpu_codegen_test\",\n+        \"//xla/service/gpu/transforms:hoist_fused_bitcasts\",\n         \"//xla/service/gpu/transforms:nest_gemm_fusion\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\","
        },
        {
            "sha": "52e8470478101026bc360cf92541fbc1db096f6a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/triton_gemm_fusion_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftriton_gemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftriton_gemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftriton_gemm_fusion_test.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -32,7 +32,6 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"xla/autotuning.pb.h\"\n-#include \"xla/backends/gpu/codegen/triton/fusion_emitter.h\"\n #include \"xla/backends/gpu/codegen/triton/test_utils.h\"\n #include \"xla/backends/gpu/codegen/triton/xtile_compiler.h\"\n #include \"xla/error_spec.h\"\n@@ -50,6 +49,7 @@ limitations under the License.\n #include \"xla/service/gpu/model/block_level_parameters.h\"\n #include \"xla/service/gpu/target_constants.h\"\n #include \"xla/service/gpu/tests/gpu_codegen_test.h\"\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n #include \"xla/service/gpu/transforms/nest_gemm_fusion.h\"\n #include \"xla/service/pattern_matcher.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n@@ -112,6 +112,7 @@ class TritonTest : public GpuCodegenTest {\n   GetModuleAndNestedFusionMetadata(absl::string_view hlo_text) {\n     TF_ASSIGN_OR_RETURN(std::unique_ptr<VerifiedHloModule> module,\n                         ParseAndReturnVerifiedModule(hlo_text));\n+    TF_RETURN_IF_ERROR(HoistFusedBitcasts().Run(module.get()).status());\n     TF_ASSIGN_OR_RETURN(\n         bool fusion_was_nested,\n         NestGemmFusion(device_desc(), &mlir_context_).Run(module.get()));"
        },
        {
            "sha": "be400454a9386ceb127c6c8e8e08d06fe8d7b617",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -1781,6 +1781,7 @@ cc_library(\n         \"//xla/service/gpu/transforms:gemm_fusion_swap_operands\",\n         \"//xla/service/gpu/transforms:gemm_rewriter\",\n         \"//xla/service/gpu/transforms:gemv_rewriter\",\n+        \"//xla/service/gpu/transforms:hoist_fused_bitcasts\",\n         \"//xla/service/gpu/transforms:layout_assignment\",\n         \"//xla/service/gpu/transforms:move_copy_to_users\",\n         \"//xla/service/gpu/transforms:nest_gemm_fusion\","
        },
        {
            "sha": "544ac7a01b382bc7d39248259180933322fa4ceb",
            "filename": "third_party/xla/xla/service/gpu/autotuning/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2FBUILD?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -185,6 +185,7 @@ cc_library(\n         \"//xla/service/gpu/transforms:dot_algorithm_rewriter\",\n         \"//xla/service/gpu/transforms:fusion_wrapper\",\n         \"//xla/service/gpu/transforms:gemm_rewriter\",\n+        \"//xla/service/gpu/transforms:hoist_fused_bitcasts\",\n         \"//xla/service/gpu/transforms:nest_gemm_fusion\",\n         \"//xla/service/gpu/transforms:priority_fusion\",\n         \"//xla/service/gpu/transforms:scaled_dot_rewriter\","
        },
        {
            "sha": "5828cb9d6b34876de3a8d2573043e78f7f976794",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -92,6 +92,7 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/dot_algorithm_rewriter.h\"\n #include \"xla/service/gpu/transforms/fusion_wrapper.h\"\n #include \"xla/service/gpu/transforms/gemm_rewriter.h\"\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n #include \"xla/service/gpu/transforms/nest_gemm_fusion.h\"\n #include \"xla/service/gpu/transforms/priority_fusion.h\"\n #include \"xla/service/gpu/transforms/scaled_dot_rewriter.h\"\n@@ -106,7 +107,6 @@ limitations under the License.\n #include \"xla/stream_executor/device_address_allocator.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/gpu/redzone_allocator.h\"\n-#include \"xla/stream_executor/gpu/tma_metadata.h\"\n #include \"xla/stream_executor/integrations/tf_allocator_adapter.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/stream_executor/stream.h\"\n@@ -351,6 +351,8 @@ absl::StatusOr<std::unique_ptr<HloModule>> TritonGemmAutotuneExtractor(\n     TF_RETURN_IF_ERROR(fusion_wrapper.Run(new_module.get()).status());\n   }\n \n+  HoistFusedBitcasts hoist_fused_bitcasts;\n+  TF_RETURN_IF_ERROR(hoist_fused_bitcasts.Run(new_module.get()).status());\n   NestGemmFusion nest_gemm_fusion(gpu_device_info, mlir_context);\n   TF_RETURN_IF_ERROR(nest_gemm_fusion.Run(new_module.get()).status());\n   return new_module;"
        },
        {
            "sha": "e5b83fb8f3b13f94184bef815247dc1da9398637",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -239,6 +239,7 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/gemm_fusion_swap_operands.h\"\n #include \"xla/service/gpu/transforms/gemm_rewriter.h\"\n #include \"xla/service/gpu/transforms/gemv_rewriter.h\"\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n #include \"xla/service/gpu/transforms/layout_assignment.h\"\n #include \"xla/service/gpu/transforms/move_copy_to_users.h\"\n #include \"xla/service/gpu/transforms/nest_gemm_fusion.h\"\n@@ -1757,8 +1758,9 @@ absl::Status GpuCompiler::OptimizeHloPostLayoutAssignment(\n   // normalized again.\n   add_float_normalization(pipeline);\n \n-  // Match the location of this pass in `gemm_fusion_autotuner.cc` to make sure\n-  // that there is no discrepancy.\n+  // GemmFusionAutotuner runs hoist-fused-bitcasts and nest-gemm-fusion,\n+  // matching its behavior here.\n+  pipeline.AddPass<HoistFusedBitcasts>();\n   pipeline.AddPass<NestGemmFusion>(gpu_target_config.device_description,\n                                    &mlir_context_);\n "
        },
        {
            "sha": "a12b23b02ee29aa7945da1acd5a3e9ec4faf5c67",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -1812,10 +1812,14 @@ TEST_F(PassOrderTest, GemmRewriterRunsAfterDotNormalizer) {\n   VerifyNotRunInBetween(pass_range, /*pass_regex=*/\"algsimp\");\n }\n \n-TEST_F(PassOrderTest, NestGemmFusionRunsAfterGemmFusionAutotuner) {\n+TEST_F(PassOrderTest, HoistFusedBitcastsRunsAfterGemmFusionAutotuner) {\n+  VerifyPassOrder(\"gemm-fusion-autotuner\", \"hoist-fused-bitcasts\");\n+}\n+\n+TEST_F(PassOrderTest, NestGemmFusionRunsAfterHoistFusedBitcasts) {\n   // NestGemmFusion expect to see __triton_gemm custom call with a backend\n   // config created by gemm_fusion_autotuner.\n-  VerifyPassOrder(\"gemm-fusion-autotuner\", \"nest_gemm_fusion\");\n+  VerifyPassOrder(\"hoist-fused-bitcasts\", \"nest_gemm_fusion\");\n }\n \n TEST_F(PassOrderTest, TransposeDimensionGrouperRunsBeforeGemmRewriter) {"
        },
        {
            "sha": "6b98ddb81a56eb8058d6a2a5711891aeebc1c454",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 62,
            "deletions": 0,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -1843,6 +1843,68 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"hoist_fused_bitcasts\",\n+    srcs = [\"hoist_fused_bitcasts.cc\"],\n+    hdrs = [\"hoist_fused_bitcasts.h\"],\n+    deps = [\n+        \"//xla:shape_util\",\n+        \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla:xla_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/hlo/utils:hlo_query\",\n+        \"//xla/service:call_graph\",\n+        \"//xla/service:matmul_indexing_utils\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:matmul_utils\",\n+        \"//xla/service/gpu/model:block_level_parameters\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@llvm-project//llvm:Support\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"hoist_fused_bitcasts_test\",\n+    srcs = [\"hoist_fused_bitcasts_test.cc\"],\n+    tags = [\n+        \"nomsan\",\n+    ],\n+    deps = [\n+        \":hoist_fused_bitcasts\",\n+        \"//xla:xla_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:filecheck\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:pattern_matcher_gmock\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n+        \"//xla/service:pattern_matcher\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/service/gpu:gpu_device_info_for_tests\",\n+        \"//xla/stream_executor:device_description\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@llvm-project//mlir:IR\",\n+    ],\n+)\n+\n cc_library(\n     name = \"nest_gemm_fusion\",\n     srcs = [\"nest_gemm_fusion.cc\"],"
        },
        {
            "sha": "fbc791ee7ad58c0aeeddb1b2c652144fb8e28efb",
            "filename": "third_party/xla/xla/service/gpu/transforms/hoist_fused_bitcasts.cc",
            "status": "added",
            "additions": 961,
            "deletions": 0,
            "changes": 961,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -0,0 +1,961 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <deque>\n+#include <memory>\n+#include <optional>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_join.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"llvm/ADT/SetVector.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"llvm/ADT/iterator_range.h\"\n+#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/utils/hlo_query.h\"\n+#include \"xla/layout.h\"\n+#include \"xla/service/call_graph.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/matmul_utils.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n+#include \"xla/xla.pb.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+// Extracts the TritonGemmConfig from the given fusion's backend config.\n+absl::StatusOr<TritonGemmConfig> GetTritonGemmConfig(\n+    const HloFusionInstruction& fusion) {\n+  TF_ASSIGN_OR_RETURN(auto gpu_config,\n+                      fusion.backend_config<GpuBackendConfig>());\n+  const FusionBackendConfig& backend_config =\n+      gpu_config.fusion_backend_config();\n+  if (!backend_config.has_triton_gemm_config()) {\n+    return absl::InternalError(\n+        \"The fusion's backend config doesn't have a triton_gemm_config.\");\n+  }\n+  return TritonGemmConfig::FromProto(backend_config.triton_gemm_config());\n+}\n+\n+using HloInstructionSetVector =\n+    llvm::SetVector<HloInstruction*, std::vector<HloInstruction*>,\n+                    HloInstructionSet>;\n+\n+// Returns the set of instructions that are reachable from 'instruction' using\n+// the given accessor.\n+template <typename T>\n+HloInstructionSetVector GetTransitiveInstructionSet(\n+    const HloInstruction* instruction, T (HloInstruction::*get)() const) {\n+  std::deque<HloInstruction*> worklist;\n+  auto append = [&](const auto& instructions) {\n+    worklist.insert(worklist.end(), instructions.begin(), instructions.end());\n+  };\n+  append((instruction->*get)());\n+  HloInstructionSetVector result;\n+  while (!worklist.empty()) {\n+    HloInstruction* front = worklist.front();\n+    worklist.pop_front();\n+    if (result.insert(front)) {\n+      append((front->*get)());\n+    }\n+  }\n+  return result;\n+}\n+\n+// Returns the set of producers reachable from 'instruction' in use-before-def\n+// order.\n+HloInstructionSetVector GetProducerSet(const HloInstruction* instruction) {\n+  return GetTransitiveInstructionSet(instruction, &HloInstruction::operands);\n+}\n+// Returns the set of consumers reachable from 'instruction' in def-before-use\n+// order.\n+HloInstructionSetVector GetConsumerSet(const HloInstruction* instruction) {\n+  return GetTransitiveInstructionSet(instruction, &HloInstruction::users);\n+}\n+\n+// Verifies that the set of instructions is closed under the given accessor,\n+// i.e. that the set of instructions reachable through the given accessor are\n+// either in the set itself or the root.\n+template <typename T>\n+absl::Status VerifyIsClosedInstructionSet(\n+    const HloInstructionSetVector& instructions, const HloInstruction* root,\n+    T (HloInstruction::*get)() const) {\n+  for (HloInstruction* instruction : instructions) {\n+    for (HloInstruction* reachable : (instruction->*get)()) {\n+      if (reachable != root && instructions.count(reachable) == 0) {\n+        return absl::FailedPreconditionError(\n+            absl::StrCat(\"Instruction \", reachable->ToString(),\n+                         \" is reachable from \", instruction->ToString(),\n+                         \", which is not in the recursive set of, or \",\n+                         root->ToString(), \" itself.\"));\n+      }\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+absl::Status VerifyIsClosedProducerSet(\n+    const HloInstructionSetVector& instructions, const HloInstruction* root) {\n+  return VerifyIsClosedInstructionSet(instructions, root,\n+                                      &HloInstruction::users);\n+}\n+\n+// Copies the element type and size from `source` to `destination`.\n+void CopyElementType(const Shape& source, Shape* destination) {\n+  destination->set_element_type(source.element_type());\n+  destination->mutable_layout()->set_element_size_in_bits(\n+      source.layout().element_size_in_bits());\n+}\n+\n+llvm::SmallVector<int64_t> GetInversePermutation(\n+    absl::Span<const int64_t> permutation) {\n+  llvm::SmallVector<int64_t> result(permutation.size());\n+  for (int64_t i = 0; i < permutation.size(); ++i) {\n+    result[permutation[i]] = i;\n+  }\n+  return result;\n+}\n+\n+// Applies the backward-mapping 'permutation' to 'values'.\n+llvm::SmallVector<int64_t> ApplyPermutation(\n+    absl::Span<const int64_t> values, absl::Span<const int64_t> permutation) {\n+  llvm::SmallVector<int64_t> result;\n+  result.reserve(permutation.size());\n+  for (int64_t index : permutation) {\n+    result.push_back(values[index]);\n+  }\n+  return result;\n+}\n+\n+// Returns the dimensions of 'shape' in minor-to-major order.\n+llvm::SmallVector<int64_t> GetPhysicalDimensions(const Shape& shape) {\n+  return ApplyPermutation(shape.dimensions(), shape.layout().minor_to_major());\n+}\n+\n+// Parameters to rewrite a bitcast(broadcast/transpose) as\n+// broadcast/transpose(bitcast) and vice versa.\n+struct BitcastParams {\n+  Shape new_shape;                      // The bitcast output shape.\n+  llvm::SmallVector<int64_t> new_dims;  // The dims of the broadcast/transpose.\n+};\n+\n+// Returns parameters to rewrite a broadcast + bitcast as bitcast + broadcast.\n+//\n+// Example:\n+//\n+// broadcast = broadcast(operand)\n+// result = result_shape bitcast(broadcast)\n+//\n+// to\n+//\n+// bitcast = new_shape bitcast(operand)\n+// result = broadcast(bitcast), dimensions={new_dims}.\n+//\n+// Assumes that:\n+// - broadcast does not transpose dimensions (checked by hlo_verifier);\n+// - bitcast does not mix operand and broadcast dimensions (checks);\n+absl::StatusOr<BitcastParams> CalculateBitcastOfBroadcast(\n+    const HloBroadcastInstruction* broadcast, const Shape& result_shape) {\n+  const Shape& broadcast_shape = broadcast->shape();\n+\n+  // Maps broadcast dimension index to whether it's an operand dimension.\n+  llvm::SmallVector<bool> is_operand_dim(broadcast_shape.dimensions().size());\n+  for (const int64_t index : broadcast->dimensions()) {\n+    is_operand_dim[index] = true;\n+  }\n+\n+  // Dimensions of the new broadcast.\n+  llvm::SmallVector<int64_t> new_dims;\n+  llvm::SmallVector<int64_t> broadcast_physical_dims =\n+      GetPhysicalDimensions(broadcast_shape);\n+  auto factors = CommonFactors(GetPhysicalDimensions(result_shape),\n+                               broadcast_physical_dims);\n+  for (int64_t i = 1; i < factors.size(); ++i) {\n+    auto [result_from, broadcast_from] = factors[i - 1];\n+    auto [result_to, broadcast_to] = factors[i];\n+\n+    bool all_operands = true, any_operands = false;\n+    for (int64_t j = broadcast_from; j < broadcast_to; ++j) {\n+      if (broadcast_physical_dims[j] == 1) {\n+        // If dimension size is 1 then we can ignore it: it's either immediately\n+        // dropped by old reshape or it's coming from the operand and then the\n+        // new reshape will handle it.\n+        continue;\n+      }\n+      bool value = is_operand_dim[broadcast_shape.layout().minor_to_major(j)];\n+      all_operands &= value;\n+      any_operands |= value;\n+    }\n+    if (!any_operands) {\n+      continue;  // All dimensions in this group are broadcast dimensions.\n+    }\n+    if (!all_operands) {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"Cannot hoist bitcast across \", broadcast->ToString(),\n+                       \" as it mixes operand and broadcast dimensions.\"));\n+    }\n+\n+    for (int64_t j = result_from; j < result_to; ++j) {\n+      new_dims.push_back(result_shape.layout().minor_to_major(j));\n+    }\n+  }\n+  absl::c_sort(new_dims);  // Sort into logical order.\n+\n+  BitcastParams result;\n+  CopyElementType(result_shape, &result.new_shape);\n+  for (int64_t index : new_dims) {\n+    result.new_shape.add_dimensions(result_shape.dimensions(index));\n+  }\n+  auto* new_layout =\n+      result.new_shape.mutable_layout()->mutable_minor_to_major();\n+  new_layout->reserve(new_dims.size());\n+  for (int64_t index : result_shape.layout().minor_to_major()) {\n+    if (auto it = absl::c_lower_bound(new_dims, index);\n+        it != new_dims.end() && *it == index) {\n+      new_layout->push_back(it - new_dims.begin());\n+    }\n+  }\n+  result.new_dims = std::move(new_dims);\n+\n+  VLOG(3) << \"CalculateBitcastOfBroadcast:\";\n+  VLOG(3) << \"  broadcast = \" << broadcast_shape.ToString(true) << \" broadcast(\"\n+          << broadcast->operand(0)->shape().ToString(true)\n+          << \" operand), dimensions=\"\n+          << absl::StrJoin(broadcast->dimensions(), \",\");\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n+          << broadcast_shape.ToString(true) << \" broadcast)\";\n+  VLOG(3) << \"--------------------------------\";\n+  VLOG(3) << \"  bitcast   = \" << result.new_shape.ToString(true) << \" bitcast(\"\n+          << broadcast->operand(0)->shape().ToString(true) << \" operand)\";\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" broadcast(\"\n+          << result.new_shape.ToString(true)\n+          << \" bitcast), dimensions=\" << absl::StrJoin(result.new_dims, \",\");\n+\n+  return result;\n+}\n+\n+// Returns parameters to rewrite a bitcast + broadcast as broadcast + bitcast.\n+//\n+// Example:\n+//\n+// bitcast = bitcast(operand_shape operand)\n+// result = broadcast(bitcast)\n+//\n+// to\n+//\n+// broadcast = new_shape broadcast(operand), dimensions={new_dims}.\n+// result = bitcast(broadcast)\n+//\n+// Assumes that:\n+// - broadcast does not transpose dimensions (checked by hlo_verifier);\n+// - bitcast does not mix operand and broadcast dimensions (checks);\n+absl::StatusOr<BitcastParams> CalculateBroadcastOfBitcast(\n+    const HloBroadcastInstruction* broadcast, const Shape& operand_shape) {\n+  const Shape& bitcast_shape = broadcast->operand(0)->shape();\n+  const Shape& result_shape = broadcast->shape();\n+\n+  // Maps logical result dimension index to a range of physical operand\n+  // dimensions, or nullopt if the dimension is broadcasted.\n+  llvm::SmallVector<std::optional<std::pair<int64_t, int64_t>>>\n+      result_to_operand_range(result_shape.dimensions().size());\n+  auto result_inv_layout =\n+      GetInversePermutation(result_shape.layout().minor_to_major());\n+  auto factors = CommonFactors(GetPhysicalDimensions(bitcast_shape),\n+                               GetPhysicalDimensions(operand_shape));\n+  for (int64_t i = 1; i < factors.size(); ++i) {\n+    auto [bitcast_from, operand_from] = factors[i - 1];\n+    auto [bitcast_to, operand_to] = factors[i];\n+\n+    llvm::SmallVector<int64_t> indices;\n+    indices.reserve(bitcast_to - bitcast_from);\n+    for (int64_t j = bitcast_from; j < bitcast_to; ++j) {\n+      int64_t index =\n+          broadcast->dimensions()[bitcast_shape.layout().minor_to_major(j)];\n+\n+      // Store the entire operand dimension range in the minor-most dimension\n+      // index and an empty range in all others.\n+      result_to_operand_range[index].emplace(operand_from, operand_to);\n+      operand_from = operand_to;\n+\n+      // Check that the physical result indices form a contiguous range.\n+      indices.push_back(result_inv_layout[index]);\n+    };\n+\n+    if (indices.back() - indices.front() >= bitcast_to - bitcast_from ||\n+        !absl::c_is_sorted(indices)) {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"Cannot hoist bitcast across \", broadcast->ToString(),\n+                       \" because result dimensions are not contiguous.\"));\n+    }\n+  }\n+\n+  BitcastParams result;\n+  CopyElementType(operand_shape, &result.new_shape);\n+  result.new_dims.resize(operand_shape.dimensions().size());\n+  auto* new_layout =\n+      result.new_shape.mutable_layout()->mutable_minor_to_major();\n+  int64_t new_rank = operand_shape.dimensions().size() +\n+                     result_shape.dimensions().size() -\n+                     bitcast_shape.dimensions().size();\n+  new_layout->reserve(new_rank);\n+  llvm::SmallVector<int64_t> new_shape_dims(new_rank);\n+\n+  // We are free to insert the broadcast dimensions in any order. Insert them\n+  // at the end of the the logical dimension order.\n+  int64_t broadcast_index = operand_shape.dimensions().size();\n+\n+  // Iterate through the logical result dimension indices in physical order.\n+  for (int64_t result_index : result_shape.layout().minor_to_major()) {\n+    if (auto range = result_to_operand_range[result_index]) {\n+      // This result dimension corresponds to a group of operand dimensions.\n+      // Iterate through the range of physical operand dimension indices.\n+      for (int64_t i = range->first; i < range->second; ++i) {\n+        int64_t operand_index = operand_shape.layout().minor_to_major(i);\n+        int64_t new_index = operand_index;\n+        new_shape_dims[new_index] = operand_shape.dimensions(operand_index);\n+        new_layout->push_back(new_index);\n+        result.new_dims[operand_index] = new_index;\n+      }\n+    } else {\n+      // This is a new dimension introduced by the original broadcast.\n+      int64_t new_index = broadcast_index++;\n+      new_shape_dims[new_index] = result_shape.dimensions(result_index);\n+      new_layout->push_back(new_index);\n+    }\n+  }\n+  absl::c_sort(result.new_dims);  // Sort into logical order.\n+  for (int64_t dimension : new_shape_dims) {\n+    result.new_shape.add_dimensions(dimension);\n+  }\n+\n+  VLOG(3) << \"CalculateBroadcastOfBitcast:\";\n+  VLOG(3) << \"  bitcast   = \" << bitcast_shape.ToString(true) << \" bitcast(\"\n+          << operand_shape.ToString(true) << \" operand)\";\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" broadcast(\"\n+          << bitcast_shape.ToString(true) << \" bitcast), dimensions=\"\n+          << absl::StrJoin(broadcast->dimensions(), \",\");\n+  VLOG(3) << \"--------------------------------\";\n+  VLOG(3) << \"  broadcast = \" << result.new_shape.ToString(true)\n+          << \" broadcast(\" << operand_shape.ToString(true)\n+          << \" operand), dimensions=\" << absl::StrJoin(result.new_dims, \",\");\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n+          << result.new_shape.ToString(true) << \" broadcast)\";\n+\n+  return result;\n+}\n+\n+// Implements CalculateBitcastOfTranspose(), except that result.new_dims is\n+// the inverse permutation, mapping the input dimensions to the output\n+// dimensions.\n+absl::StatusOr<BitcastParams> CalculateBitcastOfTransposeImpl(\n+    const HloTransposeInstruction* transpose, const Shape& result_shape,\n+    const Shape& transpose_shape, const Shape& operand_shape,\n+    absl::Span<const int64_t> transpose_dims) {\n+  if (transpose->shape().layout() != transpose->operand(0)->shape().layout()) {\n+    return absl::InternalError(\n+        absl::StrCat(\"Expected input and output layouts to be the same for \",\n+                     transpose->ToString()));\n+  }\n+\n+  // Maps physical operand dimension index to a range of physical result\n+  // dimensions.\n+  llvm::SmallVector<std::pair<int64_t, int64_t>> operand_to_result_range(\n+      operand_shape.dimensions().size());\n+  // Maps logical operand dimension index to the physical dimension index.\n+  llvm::SmallVector<int64_t> operand_inv_layout =\n+      GetInversePermutation(operand_shape.layout().minor_to_major());\n+\n+  const absl::InlinedVector<std::pair<int64_t, int64_t>, 8> factors =\n+      ::xla::gpu::detail::CommonFactorsMergingTrivialRanges(\n+          GetPhysicalDimensions(result_shape),\n+          GetPhysicalDimensions(transpose_shape));\n+  for (int64_t i = 1; i < factors.size(); ++i) {\n+    auto [result_from, transpose_from] = factors[i - 1];\n+    auto [result_to, transpose_to] = factors[i];\n+\n+    llvm::SmallVector<int64_t> indices;\n+    indices.reserve(transpose_to - transpose_from);\n+    for (int64_t j = transpose_from; j < transpose_to; ++j) {\n+      int64_t index = operand_inv_layout\n+          [transpose_dims[transpose_shape.layout().minor_to_major(j)]];\n+\n+      // Store the entire result dimension range in the minor-most dimension\n+      // index and an empty range in all others.\n+      operand_to_result_range[index] = {result_from, result_to};\n+      result_from = result_to;\n+\n+      // Check that the physical operand indices form a contiguous range.\n+      indices.push_back(index);\n+    };\n+\n+    if (indices.empty()) {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"Cannot hoist bitcast across \", transpose->ToString(),\n+                       \" because size-1 dims in bitcasts are not yet supported \"\n+                       \"(b/466065483).\"));\n+    }\n+    if (indices.back() - indices.front() >= transpose_to - transpose_from ||\n+        !absl::c_is_sorted(indices)) {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"Cannot hoist bitcast across \", transpose->ToString(),\n+                       \" because result dimensions are not contiguous.\"));\n+    }\n+  }\n+\n+  BitcastParams result;\n+  CopyElementType(result_shape, &result.new_shape);\n+  // Just like the old transpose, the new transpose does not change the\n+  // layout.\n+  *result.new_shape.mutable_layout() = result_shape.layout();\n+  result.new_dims.resize(result_shape.dimensions().size());\n+  llvm::SmallVector<int64_t> new_shape_dims(result_shape.dimensions().size());\n+  // Iterate through the physical operand and new_shape dimension indices.\n+  for (int64_t i = 0, j = 0; i < operand_shape.dimensions().size(); ++i) {\n+    auto range = operand_to_result_range[i];\n+    // Iterate through corresponding range of physical result dimension\n+    // indices.\n+    for (int64_t k = range.first; k < range.second; ++k) {\n+      int64_t new_index = result_shape.layout().minor_to_major(j++);\n+      int64_t result_index = result_shape.layout().minor_to_major(k);\n+      new_shape_dims[new_index] = result_shape.dimensions(result_index);\n+      result.new_dims[new_index] = result_index;\n+    }\n+  }\n+  for (int64_t dimension : new_shape_dims) {\n+    result.new_shape.add_dimensions(dimension);\n+  }\n+\n+  VLOG(3) << \"CalculateBitcastOfTransposeImpl:\";\n+  VLOG(3) << \"  transpose = \" << transpose_shape.ToString(true) << \" transpose(\"\n+          << operand_shape.ToString(true)\n+          << \" operand), dimensions=\" << absl::StrJoin(transpose_dims, \",\");\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n+          << transpose_shape.ToString(true) << \" transpose)\";\n+  VLOG(3) << \"--------------------------------\";\n+  VLOG(3) << \"  bitcast   = \" << result.new_shape.ToString(true) << \" bitcast(\"\n+          << operand_shape.ToString(true) << \" operand)\";\n+  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" transpose(\"\n+          << result.new_shape.ToString(true) << \" bitcast), dimensions=\"\n+          << absl::StrJoin(GetInversePermutation(result.new_dims), \",\");\n+\n+  return result;\n+}\n+\n+// Returns parameters to rewrite a transpose + bitcast as bitcast + transpose.\n+//\n+// Example:\n+//\n+// transpose = transpose(operand)\n+// result = result_shape bitcast(transpose)\n+//\n+// to\n+//\n+// bitcast = new_shape bitcast(operand)\n+// result = transpose(bitcast), dimensions={new_dims}.\n+//\n+// Assumes that:\n+// - bitcast only mixes contiguous dimensions (checks);\n+// - transpose does not change layout (checks);\n+absl::StatusOr<BitcastParams> CalculateBitcastOfTranspose(\n+    const HloTransposeInstruction* transpose, const Shape& result_shape) {\n+  TF_ASSIGN_OR_RETURN(\n+      BitcastParams result,\n+      CalculateBitcastOfTransposeImpl(\n+          transpose, result_shape, transpose->shape(),\n+          transpose->operand(0)->shape(), transpose->dimensions()));\n+  result.new_dims = GetInversePermutation(result.new_dims);\n+  return result;\n+}\n+\n+// Returns parameters to rewrite a bitcast + transpose as transpose + bitcast.\n+//\n+// Example:\n+//\n+// bitcast = bitcast(operand_shape operand)\n+// result = transpose(bitcast)\n+//\n+// to\n+//\n+// transpose = new_shape transpose(operand), dimensions={new_dims}.\n+// result = bitcast(transpose)\n+//\n+// Assumes that:\n+// - bitcast only mixes contiguous dimensions (checks);\n+// - transpose does not change layout (checks);\n+absl::StatusOr<BitcastParams> CalculateTransposeOfBitcast(\n+    const HloTransposeInstruction* transpose, const Shape& operand_shape) {\n+  return CalculateBitcastOfTransposeImpl(\n+      transpose, operand_shape, transpose->operand(0)->shape(),\n+      transpose->shape(), GetInversePermutation(transpose->dimensions()));\n+}\n+\n+// Simulates a rewrite of all producers of a given bitcast/reshape, moving the\n+// instruction outside of the computation. Returns the new shapes of affected\n+// instructions in order of traversal from consumers to producers.\n+absl::StatusOr<std::vector<std::pair<HloInstruction*, Shape>>>\n+PlanHoistBitcastUpwardsToCallers(const HloInstruction* bitcast) {\n+  // Check that all producers only affect the bitcast. If there are any\n+  // other consumers: refuse the hoisting.\n+  // It is possible to support more cases by sinking the bitcast from such\n+  // producers downward.\n+  HloInstructionSetVector producers = GetProducerSet(bitcast);\n+  TF_RETURN_IF_ERROR(VerifyIsClosedProducerSet(producers, bitcast));\n+  if (bitcast->shape().element_type() !=\n+      bitcast->operand(0)->shape().element_type()) {\n+    return absl::UnimplementedError(\n+        absl::StrCat(\"Hoisting bitcast with type conversion is not supported: \",\n+                     bitcast->ToString()));\n+  }\n+\n+  HloInstructionMap<Shape> result_shapes;\n+  auto set_result_shape =\n+      [&](const absl::Span<HloInstruction* const> instructions,\n+          const Shape& shape) -> absl::Status {\n+    for (HloInstruction* instruction : instructions) {\n+      // Only update the dimensions keeping the type intact.\n+      Shape new_shape(shape);\n+      CopyElementType(instruction->shape(), &new_shape);\n+      CHECK_EQ(ShapeUtil::ArrayDataSize(new_shape),\n+               ShapeUtil::ArrayDataSize(instruction->shape()))\n+          << \" instruction \" << instruction->ToString()\n+          << \" updating result shape from \"\n+          << ShapeUtil::HumanStringWithLayout(instruction->shape()) << \" to \"\n+          << ShapeUtil::HumanStringWithLayout(new_shape)\n+          << \" with different data size\";\n+      auto it = result_shapes.find(instruction);\n+      if (it == result_shapes.end()) {\n+        VLOG(2) << \"updating the result shape of \" << instruction->ToString()\n+                << \" to \" << ShapeUtil::HumanStringWithLayout(new_shape);\n+        result_shapes.emplace(instruction, new_shape);\n+      } else if (it->second != new_shape) {\n+        return absl::FailedPreconditionError(absl::StrCat(\n+            \"Conflicting shape assignment for \", instruction->ToString(),\n+            \" got \", ShapeUtil::HumanStringWithLayout(it->second), \" and \",\n+            ShapeUtil::HumanStringWithLayout(shape)));\n+      }\n+    }\n+    return absl::OkStatus();\n+  };\n+  TF_RETURN_IF_ERROR(set_result_shape(bitcast->operands(), bitcast->shape()));\n+\n+  std::vector<std::pair<HloInstruction*, Shape>> result;\n+  // We want to visit instructions in order from consumers to producers: we\n+  // hoist the bitcast upwards and having a valid HLO at every rewrite step\n+  // helps a lot. A simple DFS or BFS over operands will not work in non-tree\n+  // situations when there are multiple consumers of the same producer. Instead\n+  // of writing a custom traversal we can simply walk the post-order (producers\n+  // before consumers) list backward and only update the instructions affected.\n+  // TODO(b/393299275): use MakeInstructionPostOrderFrom(bitcast) - that should\n+  // be slightly more efficient.\n+  auto def_before_use = bitcast->parent()->MakeInstructionPostOrder();\n+  for (HloInstruction* instruction :\n+       llvm::make_range(def_before_use.rbegin(), def_before_use.rend())) {\n+    auto it = result_shapes.find(instruction);\n+    if (it == result_shapes.end()) {\n+      continue;  // Not affected.\n+    }\n+    Shape& result_shape = it->second;\n+    if (instruction->shape() == result_shape) {\n+      continue;  // No change.\n+    }\n+    result.emplace_back(instruction, result_shape);\n+    switch (instruction->opcode()) {\n+      case HloOpcode::kParameter:\n+      case HloOpcode::kConstant:\n+        // No operands.\n+        break;\n+      case HloOpcode::kReshape:  // Reshape is a bitcast.\n+      case HloOpcode::kBitcast:\n+        // Other bitcast will be hoisted separately so we don't need to\n+        // update its operand.\n+        break;\n+      case HloOpcode::kBroadcast: {\n+        TF_ASSIGN_OR_RETURN(\n+            BitcastParams params,\n+            CalculateBitcastOfBroadcast(\n+                Cast<HloBroadcastInstruction>(instruction), result_shape));\n+        TF_RETURN_IF_ERROR(\n+            set_result_shape(instruction->operands(), params.new_shape));\n+        break;\n+      }\n+      case HloOpcode::kTranspose: {\n+        TF_ASSIGN_OR_RETURN(\n+            BitcastParams params,\n+            CalculateBitcastOfTranspose(\n+                Cast<HloTransposeInstruction>(instruction), result_shape));\n+        TF_RETURN_IF_ERROR(\n+            set_result_shape(instruction->operands(), params.new_shape));\n+        break;\n+      }\n+      default:\n+        if (!instruction->IsElementwise()) {\n+          return absl::FailedPreconditionError(absl::StrCat(\n+              \"Cannot hoist bitcast past \", instruction->ToString()));\n+        }\n+        TF_RETURN_IF_ERROR(\n+            set_result_shape(instruction->operands(), result_shape));\n+        break;\n+    }\n+  }\n+  return result;\n+}\n+\n+// Returns the shape of the root instruction after hoisting all bitcasts.\n+//\n+// For example, given:\n+//\n+// dot = dot_shape dot\n+// bitcast = bitcast(dot)\n+// ROOT root = transpose(bitcast)\n+//\n+// Returns root_shape for:\n+//\n+// dot = dot_shape dot\n+// ROOT root = roots_shape transpose(dot)\n+//\n+absl::StatusOr<Shape> ComputeRootShapeAfterHoistingBitcasts(\n+    const HloInstruction* dot) {\n+  if (dot->IsRoot()) {\n+    return dot->shape();\n+  }\n+\n+  HloInstructionMap<Shape> operand_shapes;\n+  auto set_operand_shape =\n+      [&](const absl::Span<HloInstruction* const> instructions,\n+          const Shape& shape) -> absl::Status {\n+    for (HloInstruction* instruction : instructions) {\n+      // Only update the dimensions keeping the type intact.\n+      Shape new_shape(shape);\n+      const HloInstruction* operand = instruction->operand(0);\n+      CopyElementType(operand->shape(), &new_shape);\n+      CHECK_EQ(ShapeUtil::ArrayDataSize(new_shape),\n+               ShapeUtil::ArrayDataSize(operand->shape()))\n+          << \" instruction \" << instruction->ToString()\n+          << \" updating operand shape from \"\n+          << ShapeUtil::HumanStringWithLayout(operand->shape()) << \" to \"\n+          << ShapeUtil::HumanStringWithLayout(new_shape)\n+          << \" with different data size\";\n+      auto it = operand_shapes.find(instruction);\n+      if (it == operand_shapes.end()) {\n+        VLOG(2) << \"updating the operand shape of \"\n+                << instruction->ToString(\n+                       HloPrintOptions().set_print_operand_shape(true))\n+                << \" to \" << ShapeUtil::HumanStringWithLayout(new_shape);\n+        operand_shapes.emplace(instruction, new_shape);\n+      } else if (it->second != new_shape) {\n+        return absl::FailedPreconditionError(absl::StrCat(\n+            \"Conflicting shape assignment for \", instruction->ToString(),\n+            \" got \", ShapeUtil::HumanStringWithLayout(it->second), \" and \",\n+            ShapeUtil::HumanStringWithLayout(shape)));\n+      }\n+    }\n+    return absl::OkStatus();\n+  };\n+  TF_RETURN_IF_ERROR(set_operand_shape(dot->users(), dot->shape()));\n+\n+  for (HloInstruction* instruction : GetConsumerSet(dot)) {\n+    auto it = operand_shapes.find(instruction);\n+    if (it == operand_shapes.end()) {\n+      continue;  // Not affected.\n+    }\n+    Shape& operand_shape = it->second;\n+    TF_ASSIGN_OR_RETURN(Shape result_shape, [&]() -> absl::StatusOr<Shape> {\n+      switch (instruction->opcode()) {\n+        case HloOpcode::kBroadcast: {\n+          TF_ASSIGN_OR_RETURN(\n+              BitcastParams params,\n+              CalculateBroadcastOfBitcast(\n+                  Cast<HloBroadcastInstruction>(instruction), operand_shape));\n+          return params.new_shape;\n+        }\n+        case HloOpcode::kTranspose: {\n+          TF_ASSIGN_OR_RETURN(\n+              BitcastParams params,\n+              CalculateTransposeOfBitcast(\n+                  Cast<HloTransposeInstruction>(instruction), operand_shape));\n+          return params.new_shape;\n+        }\n+        default:\n+          if (!instruction->IsElementwise()) {\n+            return absl::FailedPreconditionError(absl::StrCat(\n+                \"Cannot hoist bitcast past \", instruction->ToString()));\n+          }\n+          [[fallthrough]];\n+        case HloOpcode::kReshape:  // Reshape is a bitcast.\n+        case HloOpcode::kBitcast:\n+          return operand_shape;\n+      }\n+    }());\n+    if (instruction->IsRoot()) {\n+      CopyElementType(instruction->shape(), &result_shape);\n+      return result_shape;\n+    }\n+    TF_RETURN_IF_ERROR(set_operand_shape(instruction->users(), result_shape));\n+  }\n+  return absl::InternalError(\"No root found\");\n+}\n+\n+// Hoists the given 'bitcast' upwards out of its computation, to the parent of\n+// each caller.\n+absl::Status HoistBitcastUpwardsToCallers(HloInstruction* bitcast,\n+                                          absl::Span<HloInstruction*> callers) {\n+  TF_ASSIGN_OR_RETURN(auto rewrite_plan,\n+                      PlanHoistBitcastUpwardsToCallers(bitcast));\n+  for (auto [instruction, result_shape] : rewrite_plan) {\n+    VLOG(2) << absl::StrCat(\"rewriting result shape of \",\n+                            instruction->ToString(), \" to \",\n+                            ShapeUtil::HumanStringWithLayout(result_shape));\n+    switch (instruction->opcode()) {\n+      case HloOpcode::kParameter: {\n+        // Create a new bitcast in callers.\n+        int64_t number = instruction->parameter_number();\n+        for (HloInstruction* caller : callers) {\n+          // Create a more generic `bitcast` even if the caller has a\n+          // `reshape`.\n+          HloInstruction* new_bitcast =\n+              caller->AddInstruction(HloInstruction::CreateBitcast(\n+                  result_shape, caller->mutable_operand(number)));\n+          TF_RETURN_IF_ERROR(\n+              caller->ReplaceOperandWithDifferentShape(number, new_bitcast));\n+        }\n+        break;\n+      }\n+      case HloOpcode::kBroadcast: {\n+        auto* broadcast = Cast<HloBroadcastInstruction>(instruction);\n+        auto params = CalculateBitcastOfBroadcast(broadcast, result_shape);\n+        // Must be OK, already succeeded in PlanHoistBitcasUpwardsToCallers.\n+        QCHECK_OK(params);\n+        broadcast->mutable_dimensions()->assign(params->new_dims.begin(),\n+                                                params->new_dims.end());\n+        break;\n+      }\n+      case HloOpcode::kTranspose: {\n+        auto* transpose = Cast<HloTransposeInstruction>(instruction);\n+        auto params = CalculateBitcastOfTranspose(transpose, result_shape);\n+        // Must be OK, already succeeded in PlanHoistBitcastUpwardsToCallers.\n+        QCHECK_OK(params);\n+        transpose->mutable_dimensions()->assign(params->new_dims.begin(),\n+                                                params->new_dims.end());\n+        break;\n+      }\n+      default:\n+        break;\n+    }\n+    *instruction->mutable_shape() = result_shape;\n+  }\n+  TF_RETURN_IF_ERROR(bitcast->ReplaceAllUsesWith(bitcast->mutable_operand(0)));\n+  TF_RETURN_IF_ERROR(bitcast->parent()->RemoveInstruction(bitcast));\n+  return absl::OkStatus();\n+}\n+\n+// Inserts a bitcast at the root if the root shape is different from the dot\n+// shape. The bitcast is chosen so that it cancels out bitcasts and reshapes\n+// along the way up to the dot. Updates the callers of the dot to expect the new\n+// root shape.\n+absl::Status MaybeInsertRootBitcast(HloInstruction* dot,\n+                                    absl::Span<HloInstruction*> callers) {\n+  TF_ASSIGN_OR_RETURN(Shape root_shape,\n+                      ComputeRootShapeAfterHoistingBitcasts(dot));\n+\n+  HloComputation* computation = dot->parent();\n+  HloInstruction* root = computation->root_instruction();\n+  if (root->shape() == root_shape) {\n+    return absl::OkStatus();\n+  }\n+\n+  // Insert a new bitcast at the root.\n+  computation->set_root_instruction(\n+      root->AddInstruction(HloInstruction::CreateBitcast(root_shape, root)));\n+\n+  // Insert new bitcast for each caller's result.\n+  for (HloInstruction* caller : callers) {\n+    HloInstruction* new_bitcast = caller->AddInstruction(\n+        HloInstruction::CreateBitcast(caller->shape(), caller));\n+    TF_RETURN_IF_ERROR(caller->ReplaceAllUsesWith(new_bitcast));\n+    *caller->mutable_shape() = root_shape;\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+// Try hoisting bitcasts and reshapes in the computation away from 'dot' to the\n+// callers of the computation. Some bitcasts or reshapes may remain in the\n+// computation, because they cannot be hoisted across all ops, e.g. across some\n+// transposes and broadcasts. This is not reported as an error.\n+absl::Status TryHoistBitcastsInComputationToCallers(HloInstruction* dot,\n+                                                    CallGraph* call_graph) {\n+  VLOG(2) << \"Before hoisting bitcasts: \" << dot->parent()->ToString();\n+\n+  auto callers = call_graph->GetComputationCallers(dot->parent());\n+  if (auto status = MaybeInsertRootBitcast(dot, absl::MakeSpan(callers));\n+      !status.ok()) {\n+    VLOG(2) << \"Failed to insert root bitcast: \" << status;\n+  }\n+  VLOG(2) << \"After inserting root bitcast: \" << dot->parent()->ToString();\n+\n+  auto def_before_use = dot->parent()->MakeInstructionPostOrder();\n+  for (HloInstruction* instruction :\n+       llvm::make_range(def_before_use.rbegin(), def_before_use.rend())) {\n+    if (!HloPredicateIsOp<HloOpcode::kBitcast, HloOpcode::kReshape>(\n+            instruction)) {\n+      continue;\n+    }\n+    VLOG(2) << \"Hoisting bitcast upwards \" << instruction->ToString();\n+    auto status =\n+        HoistBitcastUpwardsToCallers(instruction, absl::MakeSpan(callers));\n+    if (!status.ok()) {\n+      VLOG(2) << \"Failed to hoist \" << instruction->ToString()\n+              << \" upwards: \" << status;\n+    }\n+  }\n+\n+  VLOG(2) << \"After hoisting bitcasts: \" << dot->parent()->ToString();\n+  return absl::OkStatus();\n+}\n+\n+class HoistFusedBitcastsVisitor : public DfsHloRewriteVisitor {\n+ public:\n+  explicit HoistFusedBitcastsVisitor(CallGraph* call_graph)\n+      : call_graph_(call_graph) {}\n+\n+ private:\n+  absl::Status RewriteFusion(HloFusionInstruction* fusion,\n+                             CallGraph* call_graph) {\n+    HloComputation* computation = fusion->called_computation();\n+    HloInstruction* instr =\n+        hlo_query::GetFirstInstructionWithOpcode(*computation, HloOpcode::kDot);\n+    if (instr == nullptr) {\n+      instr = hlo_query::GetFirstInstructionWithOpcode(*computation,\n+                                                       HloOpcode::kScaledDot);\n+      if (instr == nullptr) {\n+        return absl::InternalError(absl::StrCat(\"Computation of fusion \",\n+                                                fusion->ToString(),\n+                                                \" has no dot instruction\"));\n+      }\n+    }\n+\n+    TF_RETURN_IF_ERROR(\n+        TryHoistBitcastsInComputationToCallers(instr, call_graph));\n+    // TODO(b/446827313): don't mark as changed if no changes were made.\n+    MarkAsChanged();\n+    return absl::OkStatus();\n+  }\n+\n+  absl::Status HandleFusion(HloInstruction* instruction) override {\n+    HloFusionInstruction* fusion = Cast<HloFusionInstruction>(instruction);\n+\n+    // Check if we target this fusion.\n+    absl::StatusOr<TritonGemmConfig> config = GetTritonGemmConfig(*fusion);\n+    if (!config.ok()) {\n+      VLOG(2) << \"Skipping fusion as it does not have a TritonGemmConfig\";\n+      return absl::OkStatus();\n+    }\n+    HloComputation* computation = fusion->called_computation();\n+    HloInstruction* instr =\n+        hlo_query::GetFirstInstructionWithOpcode(*computation, HloOpcode::kDot);\n+    if (instr == nullptr) {\n+      instr = hlo_query::GetFirstInstructionWithOpcode(*computation,\n+                                                       HloOpcode::kScaledDot);\n+      if (instr == nullptr) {\n+        VLOG(2) << \"Skipping fusion as it has no dot instruction\";\n+        return absl::OkStatus();\n+      }\n+    }\n+    return RewriteFusion(fusion, call_graph_);\n+  }\n+\n+ private:\n+  CallGraph* call_graph_;\n+};\n+\n+}  // namespace\n+\n+absl::StatusOr<bool> HoistFusedBitcasts::RunOnModule(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  bool changed = false;\n+  auto call_graph = CallGraph::Build(module, execution_threads);\n+  for (HloComputation* computation :\n+       module->MakeNonfusionComputations(execution_threads)) {\n+    HoistFusedBitcastsVisitor visitor(call_graph.get());\n+    TF_RETURN_IF_ERROR(computation->Accept(&visitor));\n+    changed |= visitor.changed();\n+  }\n+  return changed;\n+}\n+\n+absl::StatusOr<bool> HoistFusedBitcasts::RunImpl(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  return RunOnModule(module, execution_threads);\n+}\n+\n+namespace detail {\n+\n+absl::InlinedVector<std::pair<int64_t, int64_t>, 8>\n+CommonFactorsMergingTrivialRanges(absl::Span<const int64_t> a,\n+                                  absl::Span<const int64_t> b) {\n+  // CommonFactors does what we need but it also creates empty groups with\n+  // product of 1, e.g. `[1] -> []` or `[] -> [1]`. We remove the bounds of\n+  // such ranges to merge them with neighbors. There are many different ways\n+  // to do this, here we continously append ranges to the start of the next\n+  // group unless it is the very last range.\n+  absl::InlinedVector<std::pair<int64_t, int64_t>, 8> bounds =\n+      CommonFactors(a, b);\n+  for (size_t i = 0; i + 1 < bounds.size() && bounds.size() > 2;) {\n+    auto [a_start, b_start] = bounds[i];\n+    auto [a_end, b_end] = bounds[i + 1];\n+    if (a_start != a_end && b_start != b_end) {\n+      i++;\n+      continue;\n+    }\n+    if (i + 2 == bounds.size()) {\n+      // Very last range - append it to the previous one.\n+      bounds.erase(bounds.begin() + i);\n+    } else {\n+      bounds.erase(bounds.begin() + i + 1);\n+    }\n+  }\n+  return bounds;\n+}\n+\n+}  // namespace detail\n+}  // namespace xla::gpu"
        },
        {
            "sha": "01d1fb3c367cd9ff9efbb762c891030a7352f420",
            "filename": "third_party/xla/xla/service/gpu/transforms/hoist_fused_bitcasts.h",
            "status": "added",
            "additions": 66,
            "deletions": 0,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts.h?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -0,0 +1,66 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_TRANSFORMS_HOIST_FUSED_BITCASTS_H_\n+#define XLA_SERVICE_GPU_TRANSFORMS_HOIST_FUSED_BITCASTS_H_\n+\n+#include <cstdint>\n+#include <utility>\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+\n+namespace xla::gpu {\n+\n+// Hoist bitcasts and reshapes in the computation out of \"__triton_gemm\" fusions\n+// with a dot instruction.\n+class HoistFusedBitcasts : public HloModulePass {\n+ public:\n+  absl::string_view name() const override { return \"hoist-fused-bitcasts\"; }\n+\n+ protected:\n+  absl::StatusOr<bool> RunImpl(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+\n+ private:\n+  absl::StatusOr<bool> RunOnModule(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads);\n+};\n+\n+namespace detail {\n+\n+// Returns the start indices of consecutive non-overlapping subsequences of `a`\n+// and `b` with the same product (see `CommonFactors` from `util.h`) grouping\n+// ranges having product of 1 with neighbors.\n+//\n+// For example, if a=[2, 5, 1, 3] and b=[1, 10, 3, 1], the result will be\n+// {{0, 0}, {2, 2}, {4, 4}}, grouping [2,5] with [1,10] and [1,3] with [3,1].\n+absl::InlinedVector<std::pair<int64_t, int64_t>, 8>\n+CommonFactorsMergingTrivialRanges(absl::Span<const int64_t> a,\n+                                  absl::Span<const int64_t> b);\n+\n+}  // namespace detail\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_SERVICE_GPU_TRANSFORMS_HOIST_FUSED_BITCASTS_H_"
        },
        {
            "sha": "e14c6bba099ca5b9467df086af632371ee454e0b",
            "filename": "third_party/xla/xla/service/gpu/transforms/hoist_fused_bitcasts_test.cc",
            "status": "added",
            "additions": 1314,
            "deletions": 0,
            "changes": 1314,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fhoist_fused_bitcasts_test.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -0,0 +1,1314 @@\n+/* Copyright 2024 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/transforms/hoist_fused_bitcasts.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/str_join.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/strings/substitute.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/testlib/filecheck.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/gpu/gpu_device_info_for_tests.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/device_description.h\"\n+#include \"xla/xla.pb.h\"\n+\n+using ::absl_testing::IsOkAndHolds;\n+\n+namespace xla {\n+\n+namespace gpu {\n+namespace {\n+\n+// Wraps a matcher for a fusion instruction's output tile sizes.\n+// Proto matchers would be nice, but b/229726259 is P2.\n+MATCHER_P(OutputTileSizesIs, matcher, \"\") {\n+  auto backend_config = arg.template backend_config<GpuBackendConfig>();\n+  if (!backend_config.ok()) {\n+    *result_listener << \"failed to get backend config: \"\n+                     << backend_config.status();\n+    return false;\n+  }\n+  FusionBackendConfig fusion_backend_config =\n+      backend_config->fusion_backend_config();\n+  if (!fusion_backend_config.has_block_level_fusion_config()) {\n+    *result_listener << \"has no block level fusion config\";\n+    return false;\n+  }\n+  if (fusion_backend_config.kind() != \"__triton_nested_gemm_fusion\") {\n+    *result_listener << \"fusion kind is not __triton_nested_gemm_fusion\";\n+    return false;\n+  }\n+  auto output_tile_sizes =\n+      fusion_backend_config.block_level_fusion_config().output_tiles(0).sizes();\n+  return ExplainMatchResult(matcher, output_tile_sizes, result_listener);\n+}\n+\n+class HoistFusedBitcastsReshapeTest\n+    : public HloHardwareIndependentTestBase,\n+      public ::testing::WithParamInterface<HloOpcode> {\n+ protected:\n+  const se::DeviceDescription device_description_{\n+      TestGpuDeviceInfo::RTXA6000DeviceInfo(\n+          se::GpuComputeCapability{se::CudaComputeCapability::Ampere()})};\n+  mlir::MLIRContext mlir_context_;\n+\n+  std::unique_ptr<VerifiedHloModule> RunHoistFusedBitcasts(\n+      absl::string_view hlo, const bool expect_change = true) {\n+    std::unique_ptr<VerifiedHloModule> module =\n+        ParseAndReturnVerifiedModule(hlo).value();\n+    EXPECT_THAT(HoistFusedBitcasts().Run(module.get()),\n+                IsOkAndHolds(expect_change));\n+    EXPECT_OK(verifier().Run(module.get()).status());\n+    return module;\n+  }\n+};\n+\n+// Tests hoisting of bitcasts which would otherwise trigger unsatisfiable\n+// constraints during symbolic tile analysis.\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedOutOfGemmFusions) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  lhs = f32[21] parameter(0)\n+  bitcast = f32[3,7]{0,1} $0(lhs)\n+  rhs = f32[7,11] parameter(1)\n+  ROOT dot = f32[3,11] dot(bitcast, rhs),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY entry {\n+  p0 = f32[21] parameter(0)\n+  p1 = f32[7,11] parameter(1)\n+  ROOT fusion = f32[3,11] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+}\n+)\";\n+\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: dot {\n+CHECK-NEXT: [[lhs:[^ ]+]] = f32[3,7]{0,1} parameter(0)\n+CHECK-NEXT: [[rhs:[^ ]+]] = f32[7,11]{1,0} parameter(1)\n+CHECK-NEXT: ROOT {{.*}} = f32[3,11]{1,0} dot([[lhs]], [[rhs]]), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+CHECK-NEXT: }\n+CHECK: ENTRY\n+CHECK: bitcast\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsCanBeHoistedPastOtherBitcasts) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  lhs = f32[3,7] parameter(0)\n+  bitcast0 = f32[21] $0(lhs)\n+  bitcast1 = f32[3,7] $0(bitcast0)\n+  rhs = f32[7,11] parameter(1)\n+  ROOT dot = f32[3,11] dot(bitcast1, rhs),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY entry {\n+  p0 = f32[3, 7] parameter(0)\n+  p1 = f32[7,11] parameter(1)\n+  ROOT fusion = f32[3,11] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+}\n+)\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsCanBeHoistedPastElementwiseEpilogues) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  lhs = f32[3,7] parameter(0)\n+  rhs = f32[7,11] parameter(1)\n+  dot = f32[3,11] dot(lhs, rhs),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  bitcast = f32[33] $0(dot)\n+  ROOT add = f32[33] add(bitcast, bitcast)\n+}\n+\n+ENTRY entry {\n+  p0 = f32[3, 7] parameter(0)\n+  p1 = f32[7,11] parameter(1)\n+  ROOT fusion = f32[33] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsCanBeHoistedPastConvertEpilogues) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  lhs = f32[3,7] parameter(0)\n+  rhs = f32[7,11] parameter(1)\n+  dot = f32[3,11] dot(lhs, rhs),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  bitcast = f32[33] $0(dot)\n+  ROOT convert = f16[33] convert(bitcast)\n+}\n+\n+ENTRY entry {\n+  p0 = f32[3, 7] parameter(0)\n+  p1 = f32[7,11] parameter(1)\n+  ROOT fusion = f16[33] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: f16[3,11]{1,0} convert(\n+CHECK: f16[3,11]{1,0} fusion(\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+// We cannot hoist bitcasts past transposes, but we don't need to hoist\n+// because the bitcast is not rank-expanding and symbolic tile analysis\n+// works fine.\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsCannotBeHoistedPastTransposes) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = f32[72,36,2] parameter(0)\n+  transpose0 = f32[72,2,36] transpose(p0), dimensions={0,2,1}\n+  bitcast0 = f32[144,36] $0(transpose0)\n+  p1 = f32[36,3] parameter(1)\n+  dot = f32[144,3] dot(bitcast0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  bitcast1 = f32[144,3] $0(dot)\n+  ROOT transpose1 = f32[3,144] transpose(bitcast1), dimensions={1,0}\n+}\n+\n+ENTRY entry {\n+  p0 = f32[72,36,2] parameter(0)\n+  p1 = f32[36,3] parameter(1)\n+  ROOT fusion = f32[3,144] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n+          \"block_m\":\"128\",\"block_n\":\"16\",\"block_k\":\"32\",\n+          \"split_k\":\"1\",\"num_stages\":\"4\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsKeepElementSizeInBits) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  lhs = s8[21]{0:E(4)} parameter(0)\n+  c1 = s8[21] convert(lhs)\n+  c2 = f32[21] convert(c1)\n+  b0 = f32[3,7] $0(c2)\n+  rhs = f32[7,11] parameter(1)\n+  dot = f32[3,11] dot(b0, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  b1 = f32[33] $0(dot)\n+  ROOT c = s8[33]{0:E(4)} convert(b1)\n+}\n+\n+ENTRY entry {\n+  p0 = s8[21]{0:E(4)} parameter(0)\n+  p1 = f32[7,11] parameter(1)\n+  ROOT fusion = s8[33]{0:E(4)} fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+  CHECK: ENTRY\n+  CHECK: {{.*}} = s8[3,7]{1,0:E(4)} bitcast({{.*}})\n+  CHECK: [[fusion:[^ ]+]] = s8[3,11]{1,0:E(4)} fusion({{.*}})\n+  CHECK: ROOT {{.*}} = s8[33]{0:E(4)} bitcast([[fusion]])\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       TritonFusionEmitterDeviceLegacyTestSample1) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = f16[1,16,17,3] parameter(0)\n+  bitcast0 = f16[16,51] $0(f16[1,16,17,3] p0)\n+  p1 = s8[16,17,3] parameter(1)\n+  bitcast1 = s8[16,51] $0(s8[16,17,3] p1)\n+  convert = f16[16,51] convert(s8[16,51] bitcast1)\n+  bitcast2 = f16[51,16]{0,1} $0(f16[16,51] convert)\n+  dot = f16[16,16] dot(bitcast0, bitcast2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  ROOT bitcast3 = f16[1,16,16] $0(f16[16,16] dot)\n+}\n+\n+ENTRY entry {\n+  p0 = f16[1,16,17,3] parameter(0)\n+  p1 = s8[16,17,3] parameter(1)\n+  ROOT fusion = f16[1,16,16] fusion(f16[1,16,17,3] p0, s8[16,17,3] p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n+          \"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"32\",\n+          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       TritonFusionEmitterDeviceLegacyTestSample2) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = pred[3,122,96,12] parameter(0)\n+  transpose = pred[3,96,12,122] transpose(p0), dimensions={0,2,3,1}\n+  bitcast0 = pred[3456,122] $0(transpose)\n+  convert0 = f16[3456,122] convert(bitcast0)\n+  p1 = pred[1,5,122] parameter(1)\n+  bitcast1 = pred[5,122] $0(p1)\n+  convert1 = f16[5,122] convert(bitcast1)\n+  bitcast2 = f16[122,5]{0,1} $0(convert1)\n+  dot.1 = f16[3456,5] dot(convert0, bitcast2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+  ROOT bitcast3 = f16[3,96,12,1,5] $0(dot.1)\n+}\n+\n+ENTRY entry_computation {\n+  p0 = pred[3,122,96,12] parameter(0)\n+  p1 = pred[1,5,122] parameter(1)\n+  ROOT gemm_fusion_dot = f16[3,96,12,1,5] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n+          \"block_m\":\"4\",\"block_n\":\"16\",\"block_k\":\"128\",\n+          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  // Note: block sizes were 16,16,32, but that now fails to satisfy constraints.\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       TritonFusionEmitterDeviceLegacyTestSample3) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = f32[1,40] parameter(0)\n+  bitcast0 = f32[40] $0(p0)\n+  bitcast1 = f32[40,1] $0(bitcast0)\n+  p1 = f32[1,40,250000] parameter(1)\n+  bitcast2 = f32[40,250000] $0(p1)\n+  dot = f32[1,250000] dot(bitcast1, bitcast2), lhs_contracting_dims={0}, rhs_contracting_dims={0}\n+  bitcast3 = f32[250000] $0(dot)\n+  ROOT bitcast4 = f32[1,250000] $0(bitcast3)\n+}\n+\n+ENTRY entry_computation {\n+  p0 = f32[1,40] parameter(0)\n+  p1 = f32[1,40,250000] parameter(1)\n+  ROOT gemm_fusion_dot.2 = f32[1,250000] fusion(p0, p1),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n+          \"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"32\",\n+          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+})\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedPastCompare) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = s32[11,24,128]{2,1,0} parameter(0)\n+  p1 = s32[11,24,128]{2,1,0} parameter(1)\n+  eq = pred[11,24,128]{2,1,0} compare(p0, p1), direction=EQ\n+  eq_reshape = pred[264,128]{1,0} $0(eq)\n+  eq_f32 = f32[264,128]{1,0} convert(eq_reshape)\n+  p2 = f32[128,8]{1,0} parameter(2)\n+  ROOT result = f32[264,8]{1,0} dot(eq_f32, p2),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = s32[11,24, 128]{2,1,0} parameter(0)\n+  p1 = s32[11,24,128]{2,1,0} parameter(1)\n+  p2 = f32[128,8]{1,0} parameter(2)\n+  ROOT result = f32[264,8] fusion(p0, p1, p2), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\n+      \"block_m\":32,\"block_n\":16,\"block_k\":128,\n+      \"split_k\":1,\"num_stages\":1,\"num_warps\":4, \"num_ctas\":1}}}}\n+)\";\n+  RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedUpThroughBroadcasts) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[11,1,24,1] parameter(0)\n+  p0_broadcast = f32[11,1,24,1,128] broadcast(p0), dimensions={0,1,2,3}\n+  p0_reshape = f32[264,128] $0(p0_broadcast)\n+\n+  p1 = f32[128,8]{1,0} parameter(1)\n+  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[11,1,24,1] parameter(0)\n+  p1 = f32[128,8] parameter(1)\n+  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+// Broadcast fusion:\n+CHECK: {{.*}} {\n+CHECK-NEXT: [[dot_p0:[^ ]+]] = f32[264]{0} parameter(0)\n+CHECK-NEXT: {{.*}} = f32[264,128]{1,0} broadcast([[dot_p0]]), dimensions={0}\n+CHECK: ENTRY {{.*}} {\n+CHECK: [[entry_p0:[^ ]+]] = f32[11,1,24,1]{3,2,1,0} parameter(0)\n+CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsAreHoistedUpThroughBroadcastsWithTrivialDimensions) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[11,24,1] parameter(0)\n+  p0_broadcast = f32[11,1,24,1,128] broadcast(p0), dimensions={0,2,3}\n+  p0_reshape = f32[264,128] $0(p0_broadcast)\n+  p1 = f32[128,8]{1,0} parameter(1)\n+  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[11,24,1] parameter(0)\n+  p1 = f32[128,8] parameter(1)\n+  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+// Broadcast fusion:\n+CHECK: {{.*}} {\n+CHECK-NEXT: [[dot_p0:[^ ]+]] = f32[264]{0} parameter(0)\n+CHECK-NEXT: {{.*}} = f32[264,128]{1,0} broadcast([[dot_p0]]), dimensions={0}\n+CHECK: ENTRY {{.*}} {\n+CHECK: [[entry_p0:[^ ]+]] = f32[11,24,1]{{.*}} parameter(0)\n+CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastOfOperandAndBroadcastDimsIsNotHoistedUp) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[3,4] parameter(0)\n+  p1 = f32[64,7]{1,0} parameter(1)\n+  broadcast = f32[3,4,16] broadcast(p0), dimensions={0,1}\n+  // Bitcast mixes operand and broadcasted dimensions and cannot be hoisted.\n+  reshape = f32[3,64] $0(broadcast)\n+  ROOT dot = f32[3,7]{1,0} dot(reshape, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,4] parameter(0)\n+  p1 = f32[64,7] parameter(1)\n+  ROOT result = f32[3,7] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  // Cos should not be rewritten as we cannot hoist bitcast.\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK:      f32[3,4,16]{2,1,0} broadcast\n+CHECK-NEXT: f32[3,64]{1,0} $0\n+)\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastOfOperandAndBroadcastDimsIsNotHoistedDown) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7]{1,0} parameter(1)\n+  dot = f32[6,5]{1,0} dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  // Bitcast mixes operand and broadcasted dimensions and cannot be hoisted.\n+  reshape = f32[2,3,5] $0(dot)\n+  ROOT broadcast = f32[2,4,3,5] broadcast(reshape), dimensions={0,2,3}\n+}\n+\n+ENTRY e {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[2,4,3,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  // Cos should not be rewritten as we cannot hoist bitcast.\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK:      f32[2,3,5]{2,1,0} $0\n+CHECK-NEXT: f32[2,4,3,5]{3,2,1,0} broadcast\n+)\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsAreHoistedUpThroughBroadcastDiamonds) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[3,5] parameter(0)\n+  b0 = f32[3,5,77,1] broadcast(p0), dimensions={0,1}\n+  b1 = f32[3,5,1] broadcast(p0), dimensions={0,1}\n+  b2 = f32[3,5,77,1] broadcast(b1), dimensions={0,1,3}\n+  sum = add(b0, b2)\n+  sum_reshape = f32[15,77] $0(sum)\n+  p1 = f32[77,8]{1,0} parameter(1)\n+  ROOT result = f32[15,8] dot(sum_reshape, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,5] parameter(0)\n+  p1 = f32[77,8] parameter(1)\n+  ROOT result = f32[15,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: [[p0:[^ ]+]] = f32[15]{0} parameter(0)\n+CHECK-DAG: {{.*}} = f32[15,77]{1,0} broadcast([[p0]]), dimensions={0}\n+CHECK-DAG: [[br:[^ ]+]] = f32[15]{0} broadcast([[p0]]), dimensions={0}\n+CHECK-DAG: {{.*}} = f32[15,77]{1,0} broadcast([[br]]), dimensions={0}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedOverBroadcasts) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[11,1,24,1] parameter(0)\n+  p0_broadcast = f32[11,1,24,1,128,1] broadcast(p0), dimensions={0,1,2,5}\n+  p0_reshape = f32[264,128] $0(p0_broadcast)\n+\n+  p1 = f32[128,8]{1,0} parameter(1)\n+  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[11,1,24,1] parameter(0)\n+  p1 = f32[128,8] parameter(1)\n+  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           R\"(\n+// Broadcast fusion:\n+CHECK: {{.*}} {\n+CHECK-NEXT: [[dot_p0:[^ ]+]] = f32[264]{0} parameter(0)\n+CHECK-NEXT: {{.*}} = f32[264,128]{1,0} broadcast([[dot_p0]]), dimensions={0}\n+CHECK: ENTRY {{.*}} {\n+CHECK: [[entry_p0:[^ ]+]] = f32[11,1,24,1]{3,2,1,0} parameter(0)\n+CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n+)\"),\n+\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsLayoutIsPreserved) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+gemm_dot {\n+  p0 = pred[3,122,96,12] parameter(0)\n+  bitcast0 = pred[3,122,1152] $0(p0)\n+  transpose0 = pred[3,1152,122] transpose(bitcast0), dimensions={0,2,1}\n+  bitcast2 = pred[3456,122] $0(transpose0)\n+  convert0 = f16[3456,122] convert(bitcast2)\n+  p1 = pred[1,5,122] parameter(1)\n+  bitcast3 = pred[5,122] $0(p1)\n+  convert1 = f16[5,122] convert(bitcast3)\n+  bitcast4 = f16[122,5]{0,1} $0(convert1)\n+  dot0 = f16[3456,5]{1,0} dot(convert0, bitcast4), lhs_contracting_dims={1},\n+    rhs_contracting_dims={0}\n+  ROOT bitcast5 = f16[3,96,12,1,5] $0(dot0)\n+}\n+\n+ENTRY e {\n+  p0 = pred[3,122,96,12] parameter(0)\n+  p1 = pred[1,5,122] parameter(1)\n+  ROOT fusion = f16[3,96,12,1,5] fusion(p0, p1), kind=kCustom, calls=gemm_dot,\n+    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n+}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK: {{.*}} {\n+CHECK: [[re:[^ ]+]] = pred[3456,122]{1,0} $0({{.*}})\n+CHECK: {{.*}} = f16[3456,122]{1,0} convert([[re]])\n+CHECK-NOT: $0\n+CHECK: {{.*}} = f16[122,5]{0,1} convert({{.*}})\n+CHECK-NEXT: }\n+CHECK: ENTRY {{.*}} {\n+CHECK: {{.*}} = pred[122,5]{0,1} bitcast({{.*}})\n+)\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       CheckDimensionsOfBroadcastAfterBitcastIsHoisted) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = bf16[1,8] parameter(0)\n+  broadcast0 = bf16[1,8,8] broadcast(p0), dimensions={0,2}\n+  lhs = bf16[1,2,4,8] $0(broadcast0)\n+\n+  p1 = bf16[1,8] parameter(1)\n+  broadcast1 = bf16[1,8,8] broadcast(p1), dimensions={0,2}\n+  rhs = bf16[1,2,4,8] $0(broadcast1)\n+\n+  ROOT dot = bf16[2,1,4,4] dot(lhs, rhs),\n+    lhs_contracting_dims={3}, lhs_batch_dims={1,0},\n+    rhs_contracting_dims={3}, rhs_batch_dims={1,0}\n+}\n+\n+ENTRY entry {\n+  p0 = bf16[1,8] parameter(0)\n+  ROOT fusion = bf16[2,1,4,4] fusion(p0, p0), kind=kCustom, calls=dot,\n+    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n+})\";\n+\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: bf16[1,2,4,8]{{.*}} broadcast({{.*}}), dimensions={3}\n+CHECK: bf16[1,2,4,8]{{.*}} broadcast({{.*}}), dimensions={3}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedUpThroughTransposes) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[7,6] parameter(0)\n+  transpose = f32[6,7] transpose(p0), dimensions={1,0}\n+  bitcast = f32[2,3,7] $0(transpose)\n+  p1 = f32[2,5,7] parameter(1)\n+  ROOT result = f32[2,3,5] dot(bitcast, p1),\n+    lhs_contracting_dims={2}, lhs_batch_dims={0},\n+    rhs_contracting_dims={2}, rhs_batch_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[7,6] parameter(0)\n+  p1 = f32[2,5,7] parameter(1)\n+  ROOT result = f32[2,3,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: {{.*}} {\n+CHECK-NEXT: [[p0:[^ ]*]] = f32[7,2,3]{2,1,0} parameter(0)\n+CHECK-NEXT: {{.*}} = f32[2,3,7]{2,1,0} transpose([[p0]]), dimensions={1,2,0}\n+CHECK ENTRY\n+CHECK f32[7,2,3]{2,1,0} bitcast\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsWithSize1DimensionsAreHoistedUpThroughTransposes) {\n+  const HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[7,6] parameter(0)\n+  transpose = f32[6,7] transpose(p0), dimensions={1,0}\n+  bitcast = f32[1,6,7] $0(transpose)\n+  p1 = f32[1,5,7] parameter(1)\n+  ROOT result = f32[1,6,5] dot(bitcast, p1),\n+    lhs_contracting_dims={2}, lhs_batch_dims={0},\n+    rhs_contracting_dims={2}, rhs_batch_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[7,6] parameter(0)\n+  p1 = f32[1,5,7] parameter(1)\n+  ROOT result = f32[1,6,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: {{.*}} {\n+CHECK-NEXT: [[p0:[^ ]+]] = f32[7,1,6]{2,1,0} parameter(0)\n+CHECK-NEXT: {{.*}} = f32[1,6,7]{2,1,0} transpose([[p0]]), dimensions={1,2,0}\n+CHECK-NOT: bitcast\n+CHECK: }\n+CHECK ENTRY {{.*}} {\n+CHECK: bitcast\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       RankReducingBitcastsAreNotHoistedUpThroughTransposes) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[2,7,3] parameter(0)\n+  transpose = f32[3,2,7] transpose(p0), dimensions={2,0,1}\n+  $0 = f32[6,7] $0(transpose)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT dot = f32[6,5] dot($0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+}\n+\n+ENTRY e {\n+  p0 = f32[2,7,3] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[6,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK:      transpose\n+CHECK-SAME: f32[3,2,7]{2,1,0} transpose\n+CHECK-SAME: dimensions={2,0,1}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       RankReducingBitcastsAreNotHoistedDownThroughTransposes) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  dot = f32[6,5] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  $0 = f32[2,3,5] $0(dot)\n+  ROOT transpose = f32[2,5,3] transpose($0), dimensions={0,2,1}\n+}\n+\n+ENTRY e {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[2,5,3] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK:      f32[2,3,5]{2,1,0} $0\n+CHECK-NEXT: f32[2,5,3]{2,1,0} transpose\n+)\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       HoistingBitcastDoesNotIntroduceArtificialDimension) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+gemm_dot {\n+  p0 = f16[3,122,1152] parameter(0)\n+  transpose = f16[3,1152,122] transpose(p0), dimensions={0,2,1}\n+  bitcast0 = f16[3,96,12,122] $0(transpose)\n+  bitcast1 = f16[3456,122] $0(bitcast0)\n+  p1 = f16[122,5] parameter(1)\n+  ROOT dot = f16[3456,5]{1,0} dot(bitcast1, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY e {\n+  p0 = f16[3,122,1152] parameter(0)\n+  p1 = f16[122,5] parameter(1)\n+  ROOT fusion = f16[3456,5] fusion(p0, p1), kind=kCustom, calls=gemm_dot,\n+    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n+}\n+          )\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  // Checks that transpose is on rank 3 tensor from hoisting bitcast1, not rank\n+  // 4 tensor from hoisting bitcast0 first and then failing to hoist bitcast1.\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK:      transpose\n+CHECK-SAME: f16[3,1152,122]{2,1,0} transpose\n+CHECK-SAME: dimensions={0,2,1}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedDownThroughTransposes) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[2,3,7] parameter(0)\n+  p1 = f32[2,5,7] parameter(1)\n+  dot = f32[2,3,5] dot(p0, p1),\n+    lhs_contracting_dims={2}, lhs_batch_dims={0},\n+    rhs_contracting_dims={2}, rhs_batch_dims={0}\n+  bitcast = f32[6,5] $0(dot)\n+  ROOT transpose = f32[5,6] transpose(bitcast), dimensions={1,0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[2,3,7] parameter(0)\n+  p1 = f32[2,5,7] parameter(1)\n+  ROOT result = f32[5,6] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK:      ROOT transpose\n+CHECK-SAME: f32[5,2,3]{2,1,0} transpose\n+CHECK-SAME: dimensions={2,0,1}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastsAreHoistedDownThroughBroadcasts) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  dot = f32[3,5] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  bitcast = f32[15] $0(dot)\n+  ROOT broadcast = f32[2,15,6] broadcast(bitcast), dimensions={1}\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[2,15,6] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK:      ROOT broadcast\n+CHECK-SAME: f32[3,5,6,2]{2,1,0,3} broadcast\n+CHECK-SAME: dimensions={0,1}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+// TODO(b/467306121): handle the case when we need to sink the reshape through\n+// broadcast.\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       DISABLED_BitcastsAreHoistedDownThroughBroadcastsWithTrivialDimensions) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[6,7] parameter(1)\n+  dot = f32[3,6] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  bitcast = f32[3,2,3] $0(dot)\n+  ROOT broadcast = f32[3,2,1,3,7] broadcast(bitcast), dimensions={0,1,3}\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[6,7] parameter(1)\n+  ROOT result = f32[3,2,1,3,7] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK:      ROOT broadcast\n+CHECK-SAME: f32[3,5,6,2]{2,1,0,3} broadcast\n+CHECK-SAME: dimensions={0,1}\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsAreHoistedDownThroughBroadcastsWithNonDefaultLayout) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  dot = f32[6,5] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  bitcast = f32[2,3,5]{2,1,0} $0(dot)\n+  ROOT broadcast = f32[2,3,5]{2,0,1} broadcast(bitcast), dimensions={0,1,2}\n+}\n+\n+ENTRY e {\n+  p0 = f32[6,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[2,3,5]{2,0,1} fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK:      f32[2,3,5]{2,1,0} $0(dot)\n+CHECK-NEXT: f32[2,3,5]{2,0,1} broadcast\n+)\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, BitcastRootsAreHoistedDown) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  dot = f32[3,5] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  ROOT bitcast = f32[15] $0(dot)\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  ROOT result = f32[15] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: ROOT dot\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastAreHoistedDownThroughBinaryElementwiseOps) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+triton_dot {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  p2 = f32[15] parameter(2)\n+  dot = f32[3,5] dot(p0, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  $0 = f32[15] $0(dot)\n+  ROOT add = f32[15] add($0, p2)\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,7] parameter(0)\n+  p1 = f32[5,7] parameter(1)\n+  p2 = f32[15] parameter(2)\n+  ROOT result = f32[15] fusion(p0, p1, p2), kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: ROOT add = f32[3,5]{1,0} add\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsWithNonDefaultLayoutAreHoistedOutThroughBroadcast) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[7,2]{0,1} parameter(0)\n+  broadcast.1 = f32[15,7,2]{1,0,2} broadcast(p0), dimensions={1,2}\n+  $0.1 = f32[2,7,15]{1,2,0} $0(broadcast.1)\n+  p1 = f32[2,15,15]{2,1,0} parameter(1)\n+  dot = f32[2,7,15]{2,1,0} dot($0.1, p1),\n+    lhs_batch_dims={0}, lhs_contracting_dims={2},\n+    rhs_batch_dims={0}, rhs_contracting_dims={2}\n+  $0.2 = f32[15,14]{0,1} $0(dot)\n+  ROOT broadcast.2 = f32[15,11,14]{0,2,1} broadcast($0.2), dimensions={0,2}\n+}\n+\n+ENTRY e {\n+  p0 = f32[7,2]{0,1} parameter(0)\n+  p1 = f32[2,15,15]{2,1,0} parameter(1)\n+  ROOT result = f32[15,11,14]{0,2,1} fusion(p0, p1),\n+    kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+CHECK: f32[2,7,15]{1,2,0} broadcast({{.*}}), dimensions={0,1}\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+CHECK: f32[2,7,15,11]{2,1,0,3} broadcast({{.*}}), dimensions={0,1,2}\n+CHECK: ENTRY\n+CHECK: f32[7,2]{0,1} parameter(0)\n+CHECK: f32[2,7]{1,0} bitcast(p0\n+CHECK: result = f32[2,7,15,11]{2,1,0,3} fusion\n+CHECK: ROOT {{.*}} = f32[15,11,14]{0,2,1} bitcast(result)\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       BitcastsWithNonDefaultLayoutAreHoistedOutThroughTranspose) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[2,3,7]{0,2,1} parameter(0)\n+  $0.1 = f32[7,3,2]{2,0,1} $0(p0)\n+  transpose.1 = f32[3,2,7]{2,0,1} transpose($0.1), dimensions={1,2,0}\n+  p1 = f32[3,5,7]{2,1,0} parameter(1)\n+  dot = f32[3,2,5]{2,1,0} dot(transpose.1, p1),\n+    lhs_batch_dims={0}, lhs_contracting_dims={2},\n+    rhs_batch_dims={0}, rhs_contracting_dims={2}\n+  $0.2 = f32[5,3,2]{0,2,1} $0(dot)\n+  ROOT transpose.2 = f32[2,3,5]{0,2,1} transpose($0.2), dimensions={2,1,0}\n+}\n+\n+ENTRY e {\n+  p0 = f32[2,3,7]{0,2,1} parameter(0)\n+  p1 = f32[3,5,7]{2,1,0} parameter(1)\n+  ROOT result = f32[2,3,5]{0,2,1} fusion(p0, p1),\n+    kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+CHECK: f32[3,2,7]{2,0,1} transpose({{.*}}), dimensions={1,2,0}\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+CHECK: f32[3,5,2]{2,1,0} transpose({{.*}}), dimensions={0,2,1}\n+CHECK: ENTRY\n+CHECK: f32[2,3,7]{0,2,1} parameter(0)\n+CHECK: f32[7,3,2]{2,0,1} bitcast(p0\n+CHECK: result = f32[3,5,2]{2,1,0} fusion\n+CHECK: ROOT {{.*}} = f32[2,3,5]{0,2,1} bitcast(result)\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+TEST_P(HoistFusedBitcastsReshapeTest, MultipleBitcastsAreHoistedOut) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[3,3]{1,0} parameter(0)\n+  $0.1 = f32[3,3]{1,0} $0(p0)\n+  $0.2 = f32[3,3]{1,0} $0($0.1)\n+  p1 = f32[3,3]{1,0} parameter(1)\n+  dot = f32[3,3]{1,0} dot($0.2, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  $0.3 = f32[3,3]{1,0} $0(dot)\n+  ROOT $0.4 = f32[3,3]{0,1} $0($0.3)\n+}\n+\n+ENTRY e {\n+  p0 = f32[3,3]{1,0} parameter(0)\n+  ROOT result = f32[3,3]{0,1} fusion(p0, p0),\n+    kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+CHECK: ENTRY\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n+// TODO(b/393299275): this test was not written correctly and now fails.\n+TEST_P(HoistFusedBitcastsReshapeTest,\n+       DISABLED_BitcastsAreNotHoistedOutThroughLayoutChangingTranspose) {\n+  HloOpcode opcode = GetParam();\n+  absl::string_view hlo = R\"(\n+HloModule t\n+\n+triton_dot {\n+  p0 = f32[7,2]{1,0} parameter(0)\n+  $0.1 = f32[2,7]{0,1} $0(p0)\n+  transpose.1 = f32[2,7]{1,0} transpose($0.1), dimensions={0,1}\n+  p1 = f32[5,7]{1,0} parameter(1)\n+  dot = f32[2,5]{1,0} dot(transpose.1, p1),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n+  $0.2 = f32[5,2]{0,1} $0(dot)\n+  ROOT transpose.2 = f32[5,2]{1,0} transpose($0.2), dimensions={0,1}\n+}\n+\n+ENTRY e {\n+  p0 = f32[7,2]{1,0} parameter(0)\n+  p1 = f32[5,7]{1,0} parameter(1)\n+  ROOT result = f32[5,2]{1,0} fusion(p0, p1),\n+    kind=kCustom, calls=triton_dot,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n+    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n+    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module =\n+      RunHoistFusedBitcasts(absl::Substitute(hlo, HloOpcodeString(opcode)));\n+  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n+                           absl::Substitute(R\"(\n+CHECK: $0.1 = f32[2,7]{0,1} $0\n+CHECK: $0.2 = f32[5,2]{0,1} $0\n+CHECK: ENTRY\n+CHECK-NOT: bitcast\n+CHECK-NOT: reshape\n+        )\",\n+                                            HloOpcodeString(opcode))),\n+              IsOkAndHolds(true));\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(HoistFusedBitcastsReshapeTestSuite,\n+                         HoistFusedBitcastsReshapeTest,\n+                         ::testing::ValuesIn({HloOpcode::kReshape,\n+                                              HloOpcode::kBitcast}),\n+                         [](const ::testing::TestParamInfo<HloOpcode>& info) {\n+                           return std::string(HloOpcodeString(info.param));\n+                         });\n+\n+struct CommonFactorsTestCase {\n+  std::vector<int64_t> from, to;\n+  absl::InlinedVector<std::pair<int64_t, int64_t>, 8> expected;\n+};\n+\n+class CommonFactorsMergingTrivialRangesTest\n+    : public ::testing::TestWithParam<CommonFactorsTestCase> {};\n+\n+TEST_P(CommonFactorsMergingTrivialRangesTest, Example) {\n+  const CommonFactorsTestCase& test_case = GetParam();\n+  EXPECT_EQ(test_case.expected, detail::CommonFactorsMergingTrivialRanges(\n+                                    test_case.from, test_case.to));\n+}\n+\n+INSTANTIATE_TEST_SUITE_P(\n+    CommonFactorsMergingTrivialRangesTestSuite,\n+    CommonFactorsMergingTrivialRangesTest,\n+    ::testing::Values(\n+        CommonFactorsTestCase{{1}, {}, {{0, 0}, {1, 0}}},\n+        CommonFactorsTestCase{{}, {1}, {{0, 0}, {0, 1}}},\n+        CommonFactorsTestCase{{}, {}, {{0, 0}}},\n+        CommonFactorsTestCase{{1, 2, 0}, {2, 0, 3}, {{0, 0}, {3, 3}}},\n+        CommonFactorsTestCase{{2, 3, 0}, {1, 0, 1000}, {{0, 0}, {3, 3}}},\n+        CommonFactorsTestCase{{1, 1, 1}, {1, 1}, {{0, 0}, {1, 1}, {3, 2}}},\n+        CommonFactorsTestCase{{1, 1, 3}, {3, 1, 1}, {{0, 0}, {3, 3}}},\n+        CommonFactorsTestCase{{2, 6}, {4, 3}, {{0, 0}, {2, 2}}},\n+        CommonFactorsTestCase{{1, 2, 6}, {4, 1, 3, 1}, {{0, 0}, {3, 4}}},\n+        CommonFactorsTestCase{{2, 3, 4, 5}, {6, 20}, {{0, 0}, {2, 1}, {4, 2}}},\n+        CommonFactorsTestCase{\n+            {2, 3, 4, 5, 6}, {6, 20, 6}, {{0, 0}, {2, 1}, {4, 2}, {5, 3}}},\n+        CommonFactorsTestCase{{2, 2, 2, 2}, {4, 4}, {{0, 0}, {2, 1}, {4, 2}}},\n+        CommonFactorsTestCase{\n+            {2, 5, 1, 3}, {1, 10, 3, 1}, {{0, 0}, {2, 2}, {4, 4}}}),\n+    [](const ::testing::TestParamInfo<CommonFactorsTestCase>& info) {\n+      return absl::StrCat(absl::StrJoin(info.param.from, \"_\"), \"_to_\",\n+                          absl::StrJoin(info.param.to, \"_\"));\n+    });\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "8a8069c5a04c5b4aca8da2e40f9f24e6fed1919a",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 814,
            "changes": 814,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -15,11 +15,8 @@ limitations under the License.\n \n #include \"xla/service/gpu/transforms/nest_gemm_fusion.h\"\n \n-#include <cstddef>\n #include <cstdint>\n-#include <deque>\n #include <memory>\n-#include <optional>\n #include <utility>\n #include <variant>\n #include <vector>\n@@ -36,9 +33,7 @@ limitations under the License.\n #include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"llvm/ADT/SetVector.h\"\n #include \"llvm/ADT/SmallVector.h\"\n-#include \"llvm/ADT/iterator_range.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"xla/backends/gpu/codegen/triton/support.h\"\n #include \"xla/codegen/tiling/symbolic_tile.h\"\n@@ -51,10 +46,8 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/hlo/ir/hlo_print_options.h\"\n #include \"xla/hlo/transforms/simplifiers/hlo_dce.h\"\n #include \"xla/hlo/utils/hlo_query.h\"\n-#include \"xla/layout.h\"\n #include \"xla/service/call_graph.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n@@ -64,7 +57,6 @@ limitations under the License.\n #include \"xla/service/instruction_fusion.h\"\n #include \"xla/service/matmul_indexing_utils.h\"\n #include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tools/hlo_decomposer.h\"\n #include \"xla/tsl/platform/errors.h\"\n@@ -338,783 +330,6 @@ absl::Status MakeNestedFusionFromGemmFusion(\n   return absl::OkStatus();\n }\n \n-using HloInstructionSetVector =\n-    llvm::SetVector<HloInstruction*, std::vector<HloInstruction*>,\n-                    HloInstructionSet>;\n-\n-// Returns the set of instructions that are reachable from 'instruction' using\n-// the given accessor.\n-template <typename T>\n-HloInstructionSetVector GetTransitiveInstructionSet(\n-    const HloInstruction* instruction, T (HloInstruction::*get)() const) {\n-  std::deque<HloInstruction*> worklist;\n-  auto append = [&](const auto& instructions) {\n-    worklist.insert(worklist.end(), instructions.begin(), instructions.end());\n-  };\n-  append((instruction->*get)());\n-  HloInstructionSetVector result;\n-  while (!worklist.empty()) {\n-    HloInstruction* front = worklist.front();\n-    worklist.pop_front();\n-    if (result.insert(front)) {\n-      append((front->*get)());\n-    }\n-  }\n-  return result;\n-}\n-\n-// Returns the set of producers reachable from 'instruction' in use-before-def\n-// order.\n-HloInstructionSetVector GetProducerSet(const HloInstruction* instruction) {\n-  return GetTransitiveInstructionSet(instruction, &HloInstruction::operands);\n-}\n-// Returns the set of consumers reachable from 'instruction' in def-before-use\n-// order.\n-HloInstructionSetVector GetConsumerSet(const HloInstruction* instruction) {\n-  return GetTransitiveInstructionSet(instruction, &HloInstruction::users);\n-}\n-\n-// Verifies that the set of instructions is closed under the given accessor,\n-// i.e. that the set of instructions reachable through the given accessor are\n-// either in the set itself or the root.\n-template <typename T>\n-absl::Status VerifyIsClosedInstructionSet(\n-    const HloInstructionSetVector& instructions, const HloInstruction* root,\n-    T (HloInstruction::*get)() const) {\n-  for (HloInstruction* instruction : instructions) {\n-    for (HloInstruction* reachable : (instruction->*get)()) {\n-      if (reachable != root && instructions.count(reachable) == 0) {\n-        return absl::FailedPreconditionError(\n-            absl::StrCat(\"Instruction \", reachable->ToString(),\n-                         \" is reachable from \", instruction->ToString(),\n-                         \", which is not in the recursive set of, or \",\n-                         root->ToString(), \" itself.\"));\n-      }\n-    }\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-absl::Status VerifyIsClosedProducerSet(\n-    const HloInstructionSetVector& instructions, const HloInstruction* root) {\n-  return VerifyIsClosedInstructionSet(instructions, root,\n-                                      &HloInstruction::users);\n-}\n-\n-// Copies the element type and size from `source` to `destination`.\n-void CopyElementType(const Shape& source, Shape* destination) {\n-  destination->set_element_type(source.element_type());\n-  destination->mutable_layout()->set_element_size_in_bits(\n-      source.layout().element_size_in_bits());\n-}\n-\n-llvm::SmallVector<int64_t> GetInversePermutation(\n-    absl::Span<const int64_t> permutation) {\n-  llvm::SmallVector<int64_t> result(permutation.size());\n-  for (int64_t i = 0; i < permutation.size(); ++i) {\n-    result[permutation[i]] = i;\n-  }\n-  return result;\n-}\n-\n-// Applies the backward-mapping 'permutation' to 'values'.\n-llvm::SmallVector<int64_t> ApplyPermutation(\n-    absl::Span<const int64_t> values, absl::Span<const int64_t> permutation) {\n-  llvm::SmallVector<int64_t> result;\n-  result.reserve(permutation.size());\n-  for (int64_t index : permutation) {\n-    result.push_back(values[index]);\n-  }\n-  return result;\n-}\n-\n-// Returns the dimensions of 'shape' in minor-to-major order.\n-llvm::SmallVector<int64_t> GetPhysicalDimensions(const Shape& shape) {\n-  return ApplyPermutation(shape.dimensions(), shape.layout().minor_to_major());\n-}\n-\n-// Parameters to rewrite a bitcast(broadcast/transpose) as\n-// broadcast/transpose(bitcast) and vice versa.\n-struct BitcastParams {\n-  Shape new_shape;                      // The bitcast output shape.\n-  llvm::SmallVector<int64_t> new_dims;  // The dims of the broadcast/transpose.\n-};\n-\n-// Returns parameters to rewrite a broadcast + bitcast as bitcast + broadcast.\n-//\n-// Example:\n-//\n-// broadcast = broadcast(operand)\n-// result = result_shape bitcast(broadcast)\n-//\n-// to\n-//\n-// bitcast = new_shape bitcast(operand)\n-// result = broadcast(bitcast), dimensions={new_dims}.\n-//\n-// Assumes that:\n-// - broadcast does not transpose dimensions (checked by hlo_verifier);\n-// - bitcast does not mix operand and broadcast dimensions (checks);\n-absl::StatusOr<BitcastParams> CalculateBitcastOfBroadcast(\n-    const HloBroadcastInstruction* broadcast, const Shape& result_shape) {\n-  const Shape& broadcast_shape = broadcast->shape();\n-\n-  // Maps broadcast dimension index to whether it's an operand dimension.\n-  llvm::SmallVector<bool> is_operand_dim(broadcast_shape.dimensions().size());\n-  for (const int64_t index : broadcast->dimensions()) {\n-    is_operand_dim[index] = true;\n-  }\n-\n-  // Dimensions of the new broadcast.\n-  llvm::SmallVector<int64_t> new_dims;\n-  llvm::SmallVector<int64_t> broadcast_physical_dims =\n-      GetPhysicalDimensions(broadcast_shape);\n-  auto factors = CommonFactors(GetPhysicalDimensions(result_shape),\n-                               broadcast_physical_dims);\n-  for (int64_t i = 1; i < factors.size(); ++i) {\n-    auto [result_from, broadcast_from] = factors[i - 1];\n-    auto [result_to, broadcast_to] = factors[i];\n-\n-    bool all_operands = true, any_operands = false;\n-    for (int64_t j = broadcast_from; j < broadcast_to; ++j) {\n-      if (broadcast_physical_dims[j] == 1) {\n-        // If dimension size is 1 then we can ignore it: it's either immediately\n-        // dropped by old reshape or it's coming from the operand and then the\n-        // new reshape will handle it.\n-        continue;\n-      }\n-      bool value = is_operand_dim[broadcast_shape.layout().minor_to_major(j)];\n-      all_operands &= value;\n-      any_operands |= value;\n-    }\n-    if (!any_operands) {\n-      continue;  // All dimensions in this group are broadcast dimensions.\n-    }\n-    if (!all_operands) {\n-      return absl::InvalidArgumentError(\n-          absl::StrCat(\"Cannot hoist bitcast across \", broadcast->ToString(),\n-                       \" as it mixes operand and broadcast dimensions.\"));\n-    }\n-\n-    for (int64_t j = result_from; j < result_to; ++j) {\n-      new_dims.push_back(result_shape.layout().minor_to_major(j));\n-    }\n-  }\n-  absl::c_sort(new_dims);  // Sort into logical order.\n-\n-  BitcastParams result;\n-  CopyElementType(result_shape, &result.new_shape);\n-  for (int64_t index : new_dims) {\n-    result.new_shape.add_dimensions(result_shape.dimensions(index));\n-  }\n-  auto* new_layout =\n-      result.new_shape.mutable_layout()->mutable_minor_to_major();\n-  new_layout->reserve(new_dims.size());\n-  for (int64_t index : result_shape.layout().minor_to_major()) {\n-    if (auto it = absl::c_lower_bound(new_dims, index);\n-        it != new_dims.end() && *it == index) {\n-      new_layout->push_back(it - new_dims.begin());\n-    }\n-  }\n-  result.new_dims = std::move(new_dims);\n-\n-  VLOG(3) << \"CalculateBitcastOfBroadcast:\";\n-  VLOG(3) << \"  broadcast = \" << broadcast_shape.ToString(true) << \" broadcast(\"\n-          << broadcast->operand(0)->shape().ToString(true)\n-          << \" operand), dimensions=\"\n-          << absl::StrJoin(broadcast->dimensions(), \",\");\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n-          << broadcast_shape.ToString(true) << \" broadcast)\";\n-  VLOG(3) << \"--------------------------------\";\n-  VLOG(3) << \"  bitcast   = \" << result.new_shape.ToString(true) << \" bitcast(\"\n-          << broadcast->operand(0)->shape().ToString(true) << \" operand)\";\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" broadcast(\"\n-          << result.new_shape.ToString(true)\n-          << \" bitcast), dimensions=\" << absl::StrJoin(result.new_dims, \",\");\n-\n-  return result;\n-}\n-\n-// Returns parameters to rewrite a bitcast + broadcast as broadcast + bitcast.\n-//\n-// Example:\n-//\n-// bitcast = bitcast(operand_shape operand)\n-// result = broadcast(bitcast)\n-//\n-// to\n-//\n-// broadcast = new_shape broadcast(operand), dimensions={new_dims}.\n-// result = bitcast(broadcast)\n-//\n-// Assumes that:\n-// - broadcast does not transpose dimensions (checked by hlo_verifier);\n-// - bitcast does not mix operand and broadcast dimensions (checks);\n-absl::StatusOr<BitcastParams> CalculateBroadcastOfBitcast(\n-    const HloBroadcastInstruction* broadcast, const Shape& operand_shape) {\n-  const Shape& bitcast_shape = broadcast->operand(0)->shape();\n-  const Shape& result_shape = broadcast->shape();\n-\n-  // Maps logical result dimension index to a range of physical operand\n-  // dimensions, or nullopt if the dimension is broadcasted.\n-  llvm::SmallVector<std::optional<std::pair<int64_t, int64_t>>>\n-      result_to_operand_range(result_shape.dimensions().size());\n-  auto result_inv_layout =\n-      GetInversePermutation(result_shape.layout().minor_to_major());\n-  auto factors = CommonFactors(GetPhysicalDimensions(bitcast_shape),\n-                               GetPhysicalDimensions(operand_shape));\n-  for (int64_t i = 1; i < factors.size(); ++i) {\n-    auto [bitcast_from, operand_from] = factors[i - 1];\n-    auto [bitcast_to, operand_to] = factors[i];\n-\n-    llvm::SmallVector<int64_t> indices;\n-    indices.reserve(bitcast_to - bitcast_from);\n-    for (int64_t j = bitcast_from; j < bitcast_to; ++j) {\n-      int64_t index =\n-          broadcast->dimensions()[bitcast_shape.layout().minor_to_major(j)];\n-\n-      // Store the entire operand dimension range in the minor-most dimension\n-      // index and an empty range in all others.\n-      result_to_operand_range[index].emplace(operand_from, operand_to);\n-      operand_from = operand_to;\n-\n-      // Check that the physical result indices form a contiguous range.\n-      indices.push_back(result_inv_layout[index]);\n-    };\n-\n-    if (indices.back() - indices.front() >= bitcast_to - bitcast_from ||\n-        !absl::c_is_sorted(indices)) {\n-      return absl::InvalidArgumentError(\n-          absl::StrCat(\"Cannot hoist bitcast across \", broadcast->ToString(),\n-                       \" because result dimensions are not contiguous.\"));\n-    }\n-  }\n-\n-  BitcastParams result;\n-  CopyElementType(operand_shape, &result.new_shape);\n-  result.new_dims.resize(operand_shape.dimensions().size());\n-  auto* new_layout =\n-      result.new_shape.mutable_layout()->mutable_minor_to_major();\n-  int64_t new_rank = operand_shape.dimensions().size() +\n-                     result_shape.dimensions().size() -\n-                     bitcast_shape.dimensions().size();\n-  new_layout->reserve(new_rank);\n-  llvm::SmallVector<int64_t> new_shape_dims(new_rank);\n-\n-  // We are free to insert the broadcast dimensions in any order. Insert them\n-  // at the end of the the logical dimension order.\n-  int64_t broadcast_index = operand_shape.dimensions().size();\n-\n-  // Iterate through the logical result dimension indices in physical order.\n-  for (int64_t result_index : result_shape.layout().minor_to_major()) {\n-    if (auto range = result_to_operand_range[result_index]) {\n-      // This result dimension corresponds to a group of operand dimensions.\n-      // Iterate through the range of physical operand dimension indices.\n-      for (int64_t i = range->first; i < range->second; ++i) {\n-        int64_t operand_index = operand_shape.layout().minor_to_major(i);\n-        int64_t new_index = operand_index;\n-        new_shape_dims[new_index] = operand_shape.dimensions(operand_index);\n-        new_layout->push_back(new_index);\n-        result.new_dims[operand_index] = new_index;\n-      }\n-    } else {\n-      // This is a new dimension introduced by the original broadcast.\n-      int64_t new_index = broadcast_index++;\n-      new_shape_dims[new_index] = result_shape.dimensions(result_index);\n-      new_layout->push_back(new_index);\n-    }\n-  }\n-  absl::c_sort(result.new_dims);  // Sort into logical order.\n-  for (int64_t dimension : new_shape_dims) {\n-    result.new_shape.add_dimensions(dimension);\n-  }\n-\n-  VLOG(3) << \"CalculateBroadcastOfBitcast:\";\n-  VLOG(3) << \"  bitcast   = \" << bitcast_shape.ToString(true) << \" bitcast(\"\n-          << operand_shape.ToString(true) << \" operand)\";\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" broadcast(\"\n-          << bitcast_shape.ToString(true) << \" bitcast), dimensions=\"\n-          << absl::StrJoin(broadcast->dimensions(), \",\");\n-  VLOG(3) << \"--------------------------------\";\n-  VLOG(3) << \"  broadcast = \" << result.new_shape.ToString(true)\n-          << \" broadcast(\" << operand_shape.ToString(true)\n-          << \" operand), dimensions=\" << absl::StrJoin(result.new_dims, \",\");\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n-          << result.new_shape.ToString(true) << \" broadcast)\";\n-\n-  return result;\n-}\n-\n-// Implements CalculateBitcastOfTranspose(), except that result.new_dims is\n-// the inverse permutation, mapping the input dimensions to the output\n-// dimensions.\n-absl::StatusOr<BitcastParams> CalculateBitcastOfTransposeImpl(\n-    const HloTransposeInstruction* transpose, const Shape& result_shape,\n-    const Shape& transpose_shape, const Shape& operand_shape,\n-    absl::Span<const int64_t> transpose_dims) {\n-  if (transpose->shape().layout() != transpose->operand(0)->shape().layout()) {\n-    return absl::InternalError(\n-        absl::StrCat(\"Expected input and output layouts to be the same for \",\n-                     transpose->ToString()));\n-  }\n-\n-  // Maps physical operand dimension index to a range of physical result\n-  // dimensions.\n-  llvm::SmallVector<std::pair<int64_t, int64_t>> operand_to_result_range(\n-      operand_shape.dimensions().size());\n-  // Maps logical operand dimension index to the physical dimension index.\n-  llvm::SmallVector<int64_t> operand_inv_layout =\n-      GetInversePermutation(operand_shape.layout().minor_to_major());\n-\n-  const absl::InlinedVector<std::pair<int64_t, int64_t>, 8> factors =\n-      ::xla::gpu::detail::CommonFactorsMergingTrivialRanges(\n-          GetPhysicalDimensions(result_shape),\n-          GetPhysicalDimensions(transpose_shape));\n-  for (int64_t i = 1; i < factors.size(); ++i) {\n-    auto [result_from, transpose_from] = factors[i - 1];\n-    auto [result_to, transpose_to] = factors[i];\n-\n-    llvm::SmallVector<int64_t> indices;\n-    indices.reserve(transpose_to - transpose_from);\n-    for (int64_t j = transpose_from; j < transpose_to; ++j) {\n-      int64_t index = operand_inv_layout\n-          [transpose_dims[transpose_shape.layout().minor_to_major(j)]];\n-\n-      // Store the entire result dimension range in the minor-most dimension\n-      // index and an empty range in all others.\n-      operand_to_result_range[index] = {result_from, result_to};\n-      result_from = result_to;\n-\n-      // Check that the physical operand indices form a contiguous range.\n-      indices.push_back(index);\n-    };\n-\n-    if (indices.empty()) {\n-      return absl::InvalidArgumentError(\n-          absl::StrCat(\"Cannot hoist bitcast across \", transpose->ToString(),\n-                       \" because size-1 dims in bitcasts are not yet supported \"\n-                       \"(b/466065483).\"));\n-    }\n-    if (indices.back() - indices.front() >= transpose_to - transpose_from ||\n-        !absl::c_is_sorted(indices)) {\n-      return absl::InvalidArgumentError(\n-          absl::StrCat(\"Cannot hoist bitcast across \", transpose->ToString(),\n-                       \" because result dimensions are not contiguous.\"));\n-    }\n-  }\n-\n-  BitcastParams result;\n-  CopyElementType(result_shape, &result.new_shape);\n-  // Just like the old transpose, the new transpose does not change the\n-  // layout.\n-  *result.new_shape.mutable_layout() = result_shape.layout();\n-  result.new_dims.resize(result_shape.dimensions().size());\n-  llvm::SmallVector<int64_t> new_shape_dims(result_shape.dimensions().size());\n-  // Iterate through the physical operand and new_shape dimension indices.\n-  for (int64_t i = 0, j = 0; i < operand_shape.dimensions().size(); ++i) {\n-    auto range = operand_to_result_range[i];\n-    // Iterate through corresponding range of physical result dimension\n-    // indices.\n-    for (int64_t k = range.first; k < range.second; ++k) {\n-      int64_t new_index = result_shape.layout().minor_to_major(j++);\n-      int64_t result_index = result_shape.layout().minor_to_major(k);\n-      new_shape_dims[new_index] = result_shape.dimensions(result_index);\n-      result.new_dims[new_index] = result_index;\n-    }\n-  }\n-  for (int64_t dimension : new_shape_dims) {\n-    result.new_shape.add_dimensions(dimension);\n-  }\n-\n-  VLOG(3) << \"CalculateBitcastOfTransposeImpl:\";\n-  VLOG(3) << \"  transpose = \" << transpose_shape.ToString(true) << \" transpose(\"\n-          << operand_shape.ToString(true)\n-          << \" operand), dimensions=\" << absl::StrJoin(transpose_dims, \",\");\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" bitcast(\"\n-          << transpose_shape.ToString(true) << \" transpose)\";\n-  VLOG(3) << \"--------------------------------\";\n-  VLOG(3) << \"  bitcast   = \" << result.new_shape.ToString(true) << \" bitcast(\"\n-          << operand_shape.ToString(true) << \" operand)\";\n-  VLOG(3) << \"  result    = \" << result_shape.ToString(true) << \" transpose(\"\n-          << result.new_shape.ToString(true) << \" bitcast), dimensions=\"\n-          << absl::StrJoin(GetInversePermutation(result.new_dims), \",\");\n-\n-  return result;\n-}\n-\n-// Returns parameters to rewrite a transpose + bitcast as bitcast + transpose.\n-//\n-// Example:\n-//\n-// transpose = transpose(operand)\n-// result = result_shape bitcast(transpose)\n-//\n-// to\n-//\n-// bitcast = new_shape bitcast(operand)\n-// result = transpose(bitcast), dimensions={new_dims}.\n-//\n-// Assumes that:\n-// - bitcast only mixes contiguous dimensions (checks);\n-// - transpose does not change layout (checks);\n-absl::StatusOr<BitcastParams> CalculateBitcastOfTranspose(\n-    const HloTransposeInstruction* transpose, const Shape& result_shape) {\n-  TF_ASSIGN_OR_RETURN(\n-      BitcastParams result,\n-      CalculateBitcastOfTransposeImpl(\n-          transpose, result_shape, transpose->shape(),\n-          transpose->operand(0)->shape(), transpose->dimensions()));\n-  result.new_dims = GetInversePermutation(result.new_dims);\n-  return result;\n-}\n-\n-// Returns parameters to rewrite a bitcast + transpose as transpose + bitcast.\n-//\n-// Example:\n-//\n-// bitcast = bitcast(operand_shape operand)\n-// result = transpose(bitcast)\n-//\n-// to\n-//\n-// transpose = new_shape transpose(operand), dimensions={new_dims}.\n-// result = bitcast(transpose)\n-//\n-// Assumes that:\n-// - bitcast only mixes contiguous dimensions (checks);\n-// - transpose does not change layout (checks);\n-absl::StatusOr<BitcastParams> CalculateTransposeOfBitcast(\n-    const HloTransposeInstruction* transpose, const Shape& operand_shape) {\n-  return CalculateBitcastOfTransposeImpl(\n-      transpose, operand_shape, transpose->operand(0)->shape(),\n-      transpose->shape(), GetInversePermutation(transpose->dimensions()));\n-}\n-\n-// Simulates a rewrite of all producers of a given bitcast/reshape, moving the\n-// instruction outside of the computation. Returns the new shapes of affected\n-// instructions in order of traversal from consumers to producers.\n-absl::StatusOr<std::vector<std::pair<HloInstruction*, Shape>>>\n-PlanHoistBitcastUpwardsToCallers(const HloInstruction* bitcast) {\n-  // Check that all producers only affect the bitcast. If there are any\n-  // other consumers: refuse the hoisting.\n-  // It is possible to support more cases by sinking the bitcast from such\n-  // producers downward.\n-  HloInstructionSetVector producers = GetProducerSet(bitcast);\n-  TF_RETURN_IF_ERROR(VerifyIsClosedProducerSet(producers, bitcast));\n-  if (bitcast->shape().element_type() !=\n-      bitcast->operand(0)->shape().element_type()) {\n-    return absl::UnimplementedError(\n-        absl::StrCat(\"Hoisting bitcast with type conversion is not supported: \",\n-                     bitcast->ToString()));\n-  }\n-\n-  HloInstructionMap<Shape> result_shapes;\n-  auto set_result_shape =\n-      [&](const absl::Span<HloInstruction* const> instructions,\n-          const Shape& shape) -> absl::Status {\n-    for (HloInstruction* instruction : instructions) {\n-      // Only update the dimensions keeping the type intact.\n-      Shape new_shape(shape);\n-      CopyElementType(instruction->shape(), &new_shape);\n-      CHECK_EQ(ShapeUtil::ArrayDataSize(new_shape),\n-               ShapeUtil::ArrayDataSize(instruction->shape()))\n-          << \" instruction \" << instruction->ToString()\n-          << \" updating result shape from \"\n-          << ShapeUtil::HumanStringWithLayout(instruction->shape()) << \" to \"\n-          << ShapeUtil::HumanStringWithLayout(new_shape)\n-          << \" with different data size\";\n-      auto it = result_shapes.find(instruction);\n-      if (it == result_shapes.end()) {\n-        VLOG(2) << \"updating the result shape of \" << instruction->ToString()\n-                << \" to \" << ShapeUtil::HumanStringWithLayout(new_shape);\n-        result_shapes.emplace(instruction, new_shape);\n-      } else if (it->second != new_shape) {\n-        return absl::FailedPreconditionError(absl::StrCat(\n-            \"Conflicting shape assignment for \", instruction->ToString(),\n-            \" got \", ShapeUtil::HumanStringWithLayout(it->second), \" and \",\n-            ShapeUtil::HumanStringWithLayout(shape)));\n-      }\n-    }\n-    return absl::OkStatus();\n-  };\n-  TF_RETURN_IF_ERROR(set_result_shape(bitcast->operands(), bitcast->shape()));\n-\n-  std::vector<std::pair<HloInstruction*, Shape>> result;\n-  // We want to visit instructions in order from consumers to producers: we\n-  // hoist the bitcast upwards and having a valid HLO at every rewrite step\n-  // helps a lot. A simple DFS or BFS over operands will not work in non-tree\n-  // situations when there are multiple consumers of the same producer. Instead\n-  // of writing a custom traversal we can simply walk the post-order (producers\n-  // before consumers) list backward and only update the instructions affected.\n-  // TODO(b/393299275): use MakeInstructionPostOrderFrom(bitcast) - that should\n-  // be slightly more efficient.\n-  auto def_before_use = bitcast->parent()->MakeInstructionPostOrder();\n-  for (HloInstruction* instruction :\n-       llvm::make_range(def_before_use.rbegin(), def_before_use.rend())) {\n-    auto it = result_shapes.find(instruction);\n-    if (it == result_shapes.end()) {\n-      continue;  // Not affected.\n-    }\n-    Shape& result_shape = it->second;\n-    if (instruction->shape() == result_shape) {\n-      continue;  // No change.\n-    }\n-    result.emplace_back(instruction, result_shape);\n-    switch (instruction->opcode()) {\n-      case HloOpcode::kParameter:\n-      case HloOpcode::kConstant:\n-        // No operands.\n-        break;\n-      case HloOpcode::kReshape:  // Reshape is a bitcast.\n-      case HloOpcode::kBitcast:\n-        // Other bitcast will be hoisted separately so we don't need to\n-        // update its operand.\n-        break;\n-      case HloOpcode::kBroadcast: {\n-        TF_ASSIGN_OR_RETURN(\n-            BitcastParams params,\n-            CalculateBitcastOfBroadcast(\n-                Cast<HloBroadcastInstruction>(instruction), result_shape));\n-        TF_RETURN_IF_ERROR(\n-            set_result_shape(instruction->operands(), params.new_shape));\n-        break;\n-      }\n-      case HloOpcode::kTranspose: {\n-        TF_ASSIGN_OR_RETURN(\n-            BitcastParams params,\n-            CalculateBitcastOfTranspose(\n-                Cast<HloTransposeInstruction>(instruction), result_shape));\n-        TF_RETURN_IF_ERROR(\n-            set_result_shape(instruction->operands(), params.new_shape));\n-        break;\n-      }\n-      default:\n-        if (!instruction->IsElementwise()) {\n-          return absl::FailedPreconditionError(absl::StrCat(\n-              \"Cannot hoist bitcast past \", instruction->ToString()));\n-        }\n-        TF_RETURN_IF_ERROR(\n-            set_result_shape(instruction->operands(), result_shape));\n-        break;\n-    }\n-  }\n-  return result;\n-}\n-\n-// Returns the shape of the root instruction after hoisting all bitcasts.\n-//\n-// For example, given:\n-//\n-// dot = dot_shape dot\n-// bitcast = bitcast(dot)\n-// ROOT root = transpose(bitcast)\n-//\n-// Returns root_shape for:\n-//\n-// dot = dot_shape dot\n-// ROOT root = roots_shape transpose(dot)\n-//\n-absl::StatusOr<Shape> ComputeRootShapeAfterHoistingBitcasts(\n-    const HloInstruction* dot) {\n-  if (dot->IsRoot()) {\n-    return dot->shape();\n-  }\n-\n-  HloInstructionMap<Shape> operand_shapes;\n-  auto set_operand_shape =\n-      [&](const absl::Span<HloInstruction* const> instructions,\n-          const Shape& shape) -> absl::Status {\n-    for (HloInstruction* instruction : instructions) {\n-      // Only update the dimensions keeping the type intact.\n-      Shape new_shape(shape);\n-      const HloInstruction* operand = instruction->operand(0);\n-      CopyElementType(operand->shape(), &new_shape);\n-      CHECK_EQ(ShapeUtil::ArrayDataSize(new_shape),\n-               ShapeUtil::ArrayDataSize(operand->shape()))\n-          << \" instruction \" << instruction->ToString()\n-          << \" updating operand shape from \"\n-          << ShapeUtil::HumanStringWithLayout(operand->shape()) << \" to \"\n-          << ShapeUtil::HumanStringWithLayout(new_shape)\n-          << \" with different data size\";\n-      auto it = operand_shapes.find(instruction);\n-      if (it == operand_shapes.end()) {\n-        VLOG(2) << \"updating the operand shape of \"\n-                << instruction->ToString(\n-                       HloPrintOptions().set_print_operand_shape(true))\n-                << \" to \" << ShapeUtil::HumanStringWithLayout(new_shape);\n-        operand_shapes.emplace(instruction, new_shape);\n-      } else if (it->second != new_shape) {\n-        return absl::FailedPreconditionError(absl::StrCat(\n-            \"Conflicting shape assignment for \", instruction->ToString(),\n-            \" got \", ShapeUtil::HumanStringWithLayout(it->second), \" and \",\n-            ShapeUtil::HumanStringWithLayout(shape)));\n-      }\n-    }\n-    return absl::OkStatus();\n-  };\n-  TF_RETURN_IF_ERROR(set_operand_shape(dot->users(), dot->shape()));\n-\n-  for (HloInstruction* instruction : GetConsumerSet(dot)) {\n-    auto it = operand_shapes.find(instruction);\n-    if (it == operand_shapes.end()) {\n-      continue;  // Not affected.\n-    }\n-    Shape& operand_shape = it->second;\n-    TF_ASSIGN_OR_RETURN(Shape result_shape, [&]() -> absl::StatusOr<Shape> {\n-      switch (instruction->opcode()) {\n-        case HloOpcode::kBroadcast: {\n-          TF_ASSIGN_OR_RETURN(\n-              BitcastParams params,\n-              CalculateBroadcastOfBitcast(\n-                  Cast<HloBroadcastInstruction>(instruction), operand_shape));\n-          return params.new_shape;\n-        }\n-        case HloOpcode::kTranspose: {\n-          TF_ASSIGN_OR_RETURN(\n-              BitcastParams params,\n-              CalculateTransposeOfBitcast(\n-                  Cast<HloTransposeInstruction>(instruction), operand_shape));\n-          return params.new_shape;\n-        }\n-        default:\n-          if (!instruction->IsElementwise()) {\n-            return absl::FailedPreconditionError(absl::StrCat(\n-                \"Cannot hoist bitcast past \", instruction->ToString()));\n-          }\n-          [[fallthrough]];\n-        case HloOpcode::kReshape:  // Reshape is a bitcast.\n-        case HloOpcode::kBitcast:\n-          return operand_shape;\n-      }\n-    }());\n-    if (instruction->IsRoot()) {\n-      CopyElementType(instruction->shape(), &result_shape);\n-      return result_shape;\n-    }\n-    TF_RETURN_IF_ERROR(set_operand_shape(instruction->users(), result_shape));\n-  }\n-  return absl::InternalError(\"No root found\");\n-}\n-\n-// Hoists the given 'bitcast' upwards out of its computation, to the parent of\n-// each caller.\n-absl::Status HoistBitcastUpwardsToCallers(HloInstruction* bitcast,\n-                                          absl::Span<HloInstruction*> callers) {\n-  TF_ASSIGN_OR_RETURN(auto rewrite_plan,\n-                      PlanHoistBitcastUpwardsToCallers(bitcast));\n-  for (auto [instruction, result_shape] : rewrite_plan) {\n-    VLOG(2) << absl::StrCat(\"rewriting result shape of \",\n-                            instruction->ToString(), \" to \",\n-                            ShapeUtil::HumanStringWithLayout(result_shape));\n-    switch (instruction->opcode()) {\n-      case HloOpcode::kParameter: {\n-        // Create a new bitcast in callers.\n-        int64_t number = instruction->parameter_number();\n-        for (HloInstruction* caller : callers) {\n-          // Create a more generic `bitcast` even if the caller has a\n-          // `reshape`.\n-          HloInstruction* new_bitcast =\n-              caller->AddInstruction(HloInstruction::CreateBitcast(\n-                  result_shape, caller->mutable_operand(number)));\n-          TF_RETURN_IF_ERROR(\n-              caller->ReplaceOperandWithDifferentShape(number, new_bitcast));\n-        }\n-        break;\n-      }\n-      case HloOpcode::kBroadcast: {\n-        auto* broadcast = Cast<HloBroadcastInstruction>(instruction);\n-        auto params = CalculateBitcastOfBroadcast(broadcast, result_shape);\n-        // Must be OK, already succeeded in PlanHoistBitcasUpwardsToCallers.\n-        QCHECK_OK(params);\n-        broadcast->mutable_dimensions()->assign(params->new_dims.begin(),\n-                                                params->new_dims.end());\n-        break;\n-      }\n-      case HloOpcode::kTranspose: {\n-        auto* transpose = Cast<HloTransposeInstruction>(instruction);\n-        auto params = CalculateBitcastOfTranspose(transpose, result_shape);\n-        // Must be OK, already succeeded in PlanHoistBitcastUpwardsToCallers.\n-        QCHECK_OK(params);\n-        transpose->mutable_dimensions()->assign(params->new_dims.begin(),\n-                                                params->new_dims.end());\n-        break;\n-      }\n-      default:\n-        break;\n-    }\n-    *instruction->mutable_shape() = result_shape;\n-  }\n-  TF_RETURN_IF_ERROR(bitcast->ReplaceAllUsesWith(bitcast->mutable_operand(0)));\n-  TF_RETURN_IF_ERROR(bitcast->parent()->RemoveInstruction(bitcast));\n-  return absl::OkStatus();\n-}\n-\n-// Inserts a bitcast at the root if the root shape is different from the dot\n-// shape. The bitcast is chosen so that it cancels out bitcasts and reshapes\n-// along the way up to the dot. Updates the callers of the dot to expect the new\n-// root shape.\n-absl::Status MaybeInsertRootBitcast(HloInstruction* dot,\n-                                    absl::Span<HloInstruction*> callers) {\n-  TF_ASSIGN_OR_RETURN(Shape root_shape,\n-                      ComputeRootShapeAfterHoistingBitcasts(dot));\n-\n-  HloComputation* computation = dot->parent();\n-  HloInstruction* root = computation->root_instruction();\n-  if (root->shape() == root_shape) {\n-    return absl::OkStatus();\n-  }\n-\n-  // Insert a new bitcast at the root.\n-  computation->set_root_instruction(\n-      root->AddInstruction(HloInstruction::CreateBitcast(root_shape, root)));\n-\n-  // Insert new bitcast for each caller's result.\n-  for (HloInstruction* caller : callers) {\n-    HloInstruction* new_bitcast = caller->AddInstruction(\n-        HloInstruction::CreateBitcast(caller->shape(), caller));\n-    TF_RETURN_IF_ERROR(caller->ReplaceAllUsesWith(new_bitcast));\n-    *caller->mutable_shape() = root_shape;\n-  }\n-\n-  return absl::OkStatus();\n-}\n-\n-// Try hoisting bitcasts and reshapes in the computation away from 'dot' to the\n-// callers of the computation. Some bitcasts or reshapes may remain in the\n-// computation, because they cannot be hoisted across all ops, e.g. across some\n-// transposes and broadcasts. This is not reported as an error.\n-absl::Status TryHoistBitcastsInComputationToCallers(HloInstruction* dot,\n-                                                    CallGraph* call_graph) {\n-  VLOG(2) << \"Before hoisting bitcasts: \" << dot->parent()->ToString();\n-\n-  auto callers = call_graph->GetComputationCallers(dot->parent());\n-  if (auto status = MaybeInsertRootBitcast(dot, absl::MakeSpan(callers));\n-      !status.ok()) {\n-    VLOG(2) << \"Failed to insert root bitcast: \" << status;\n-  }\n-  VLOG(2) << \"After inserting root bitcast: \" << dot->parent()->ToString();\n-\n-  auto def_before_use = dot->parent()->MakeInstructionPostOrder();\n-  for (HloInstruction* instruction :\n-       llvm::make_range(def_before_use.rbegin(), def_before_use.rend())) {\n-    if (!HloPredicateIsOp<HloOpcode::kBitcast, HloOpcode::kReshape>(\n-            instruction)) {\n-      continue;\n-    }\n-    VLOG(2) << \"Hoisting bitcast upwards \" << instruction->ToString();\n-    auto status =\n-        HoistBitcastUpwardsToCallers(instruction, absl::MakeSpan(callers));\n-    if (!status.ok()) {\n-      VLOG(2) << \"Failed to hoist \" << instruction->ToString()\n-              << \" upwards: \" << status;\n-    }\n-  }\n-\n-  VLOG(2) << \"After hoisting bitcasts: \" << dot->parent()->ToString();\n-  return absl::OkStatus();\n-}\n-\n class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n  public:\n   explicit NestGemmFusionVisitor(\n@@ -1171,8 +386,6 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n       }\n     }\n \n-    TF_RETURN_IF_ERROR(\n-        TryHoistBitcastsInComputationToCallers(instr, call_graph));\n     TF_RETURN_IF_ERROR(MakeNestedFusionFromGemmFusion(\n         fusion, instr, mlir_context_, device_description_));\n \n@@ -1359,32 +572,5 @@ absl::StatusOr<BlockLevelParameters> FindBlockLevelParameters(\n       \"Couldn't find output tile sizes that satisfy \", tiled_dot.ToString()));\n }\n \n-absl::InlinedVector<std::pair<int64_t, int64_t>, 8>\n-CommonFactorsMergingTrivialRanges(absl::Span<const int64_t> a,\n-                                  absl::Span<const int64_t> b) {\n-  // CommonFactors does what we need but it also creates empty groups with\n-  // product of 1, e.g. `[1] -> []` or `[] -> [1]`. We remove the bounds of\n-  // such ranges to merge them with neighbors. There are many different ways\n-  // to do this, here we continously append ranges to the start of the next\n-  // group unless it is the very last range.\n-  absl::InlinedVector<std::pair<int64_t, int64_t>, 8> bounds =\n-      CommonFactors(a, b);\n-  for (size_t i = 0; i + 1 < bounds.size() && bounds.size() > 2;) {\n-    auto [a_start, b_start] = bounds[i];\n-    auto [a_end, b_end] = bounds[i + 1];\n-    if (a_start != a_end && b_start != b_end) {\n-      i++;\n-      continue;\n-    }\n-    if (i + 2 == bounds.size()) {\n-      // Very last range - append it to the previous one.\n-      bounds.erase(bounds.begin() + i);\n-    } else {\n-      bounds.erase(bounds.begin() + i + 1);\n-    }\n-  }\n-  return bounds;\n-}\n-\n }  // namespace detail\n }  // namespace xla::gpu"
        },
        {
            "sha": "720dd8b116bdb054f0fe4a5538606af1ec4f5710",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.h",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.h?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -16,14 +16,9 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_TRANSFORMS_NEST_GEMM_FUSION_H_\n #define XLA_SERVICE_GPU_TRANSFORMS_NEST_GEMM_FUSION_H_\n \n-#include <cstdint>\n-#include <utility>\n-\n #include \"absl/container/flat_hash_set.h\"\n-#include \"absl/container/inlined_vector.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n@@ -86,16 +81,6 @@ absl::StatusOr<BlockLevelParameters> FindBlockLevelParameters(\n     mlir::MLIRContext* mlir_context,\n     const se::DeviceDescription& device_description);\n \n-// Returns the start indices of consecutive non-overlapping subsequences of `a`\n-// and `b` with the same product (see `CommonFactors` from `util.h`) grouping\n-// ranges having product of 1 with neighbors.\n-//\n-// For example, if a=[2, 5, 1, 3] and b=[1, 10, 3, 1], the result will be\n-// {{0, 0}, {2, 2}, {4, 4}}, grouping [2,5] with [1,10] and [1,3] with [3,1].\n-absl::InlinedVector<std::pair<int64_t, int64_t>, 8>\n-CommonFactorsMergingTrivialRanges(absl::Span<const int64_t> a,\n-                                  absl::Span<const int64_t> b);\n-\n }  // namespace detail\n \n }  // namespace xla::gpu"
        },
        {
            "sha": "da4c0d8adc6eb1848258e8f3e837aeceadc73400",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion_test.cc",
            "status": "modified",
            "additions": 41,
            "deletions": 1277,
            "changes": 1318,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc?ref=dd2f53c829df4bd70079b9ef619dd3bc4b60e6a4",
            "patch": "@@ -85,7 +85,7 @@ class NestGemmFusionTest : public HloHardwareIndependentTestBase {\n           se::GpuComputeCapability{se::CudaComputeCapability::Ampere()})};\n   mlir::MLIRContext mlir_context_;\n \n-  std::unique_ptr<VerifiedHloModule> ParseAndRunNestGemmFusion(\n+  std::unique_ptr<VerifiedHloModule> RunNestGemmFusion(\n       absl::string_view hlo, const bool expect_change = true) {\n     std::unique_ptr<VerifiedHloModule> module =\n         ParseAndReturnVerifiedModule(hlo).value();\n@@ -120,7 +120,7 @@ ENTRY entry {\n     }\n })\";\n \n-  std::unique_ptr<VerifiedHloModule> module = ParseAndRunNestGemmFusion(hlo);\n+  std::unique_ptr<VerifiedHloModule> module = RunNestGemmFusion(hlo);\n   const HloInstruction* fusion = nullptr;\n   ASSERT_THAT(module->entry_computation()->root_instruction(),\n               GmockMatch(match::Fusion(&fusion)));\n@@ -174,7 +174,7 @@ ENTRY e {\n                          \"split_k\":1,\"num_stages\":1,\"num_warps\":2,\n                          \"num_ctas\":1}}}\n })\";\n-  std::unique_ptr<VerifiedHloModule> module = ParseAndRunNestGemmFusion(hlo);\n+  std::unique_ptr<VerifiedHloModule> module = RunNestGemmFusion(hlo);\n   HloComputation* fusion_computation = module->entry_computation()\n                                            ->root_instruction()\n                                            ->fused_instructions_computation();\n@@ -187,6 +187,43 @@ ENTRY e {\n               GmockMatch(match::Concatenate(match::Fusion(), match::Fusion())));\n }\n \n+TEST_F(NestGemmFusionTest, CreatesTwoNestedFusionsFromSameParameter) {\n+  absl::string_view hlo = R\"(\n+dot {\n+  p0 = f32[32] parameter(0)\n+  lhs = f32[4,8] reshape(p0)\n+  rhs = f32[8,4] reshape(p0)\n+  ROOT dot = f32[4,4] dot(lhs, rhs),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY entry {\n+  p0 = f32[32] parameter(0)\n+  ROOT fusion = f32[4,4] fusion(p0),\n+    kind=kCustom, calls=dot, backend_config={\n+      \"fusion_backend_config\": {\n+        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n+          \"block_m\":\"4\", \"block_n\":\"4\", \"block_k\":\"8\",\n+          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n+        }\n+      }\n+    }\n+}\n+)\";\n+  std::unique_ptr<VerifiedHloModule> module = RunNestGemmFusion(hlo);\n+  EXPECT_THAT(\n+      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n+CHECK: {{.*}} {\n+CHECK-NEXT: {{.*}} f32[32]{0} parameter(0)\n+CHECK-NEXT: ROOT {{.*}} reshape\n+CHECK-NEXT: }\n+CHECK: {{.*}} {\n+CHECK-NEXT: {{.*}} f32[32]{0} parameter(0)\n+CHECK-NEXT: ROOT {{.*}} reshape\n+)\"),\n+      IsOkAndHolds(true));\n+}\n+\n // TODO(b/393299275): update test to use a unsupported operation.\n TEST_F(NestGemmFusionTest, DISABLED_UnsupportedComputationsAreNotChanged) {\n   // Fusions other than kTritonNestedGemmFusionKind are not supported.\n@@ -234,7 +271,7 @@ ENTRY e {\n   ROOT result = (f32[128,128], f32[8192,512]) tuple(r1, r2)\n }\n )\";\n-  std::unique_ptr<VerifiedHloModule> module = ParseAndRunNestGemmFusion(hlo);\n+  std::unique_ptr<VerifiedHloModule> module = RunNestGemmFusion(hlo);\n   HloInstruction* root = module->entry_computation()->root_instruction();\n   EXPECT_EQ(root->opcode(), HloOpcode::kTuple);\n   EXPECT_EQ(root->operand(0)->opcode(), HloOpcode::kFusion);\n@@ -251,1279 +288,6 @@ ENTRY e {\n             \"__triton_nested_gemm_fusion\");\n }\n \n-class NestGemmFusionReshapeTest\n-    : public NestGemmFusionTest,\n-      public ::testing::WithParamInterface<HloOpcode> {};\n-\n-// Tests hoisting of bitcasts which would otherwise trigger unsatisfiable\n-// constraints during symbolic tile analysis.\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedOutOfGemmFusions) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  lhs = f32[21] parameter(0)\n-  bitcast = f32[3,7]{0,1} $0(lhs)\n-  rhs = f32[7,11] parameter(1)\n-  ROOT dot = f32[3,11] dot(bitcast, rhs),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY entry {\n-  p0 = f32[21] parameter(0)\n-  p1 = f32[7,11] parameter(1)\n-  ROOT fusion = f32[3,11] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-}\n-)\";\n-\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-\n-  const HloInstruction* fusion = nullptr;\n-  ASSERT_THAT(module->entry_computation()->root_instruction(),\n-              GmockMatch(match::Fusion(&fusion)));\n-  EXPECT_THAT(fusion->operand(0), GmockMatch(match::Bitcast()));\n-  EXPECT_THAT(*fusion, OutputTileSizesIs(ElementsAre(32, 64)));\n-\n-  const HloInstruction* lhs = nullptr;\n-  const HloInstruction* rhs = nullptr;\n-  EXPECT_THAT(fusion->fused_expression_root(),\n-              GmockMatch(match::Dot(match::Fusion(&lhs), match::Fusion(&rhs))));\n-  EXPECT_THAT(*lhs, OutputTileSizesIs(ElementsAre(32, 16)));\n-  EXPECT_THAT(*rhs, OutputTileSizesIs(ElementsAre(16, 64)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, SupportsTwoBitcastsFromSameParameter) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = f32[32] parameter(0)\n-  lhs = f32[4,8] $0(p0)\n-  rhs = f32[8,4] $0(p0)\n-  ROOT dot = f32[4,4] dot(lhs, rhs),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY entry {\n-  p0 = f32[32] parameter(0)\n-  ROOT fusion = f32[4,4] fusion(p0),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"4\", \"block_n\":\"4\", \"block_k\":\"8\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-}\n-)\";\n-\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-\n-  const HloInstruction* fusion = nullptr;\n-  ASSERT_THAT(module->entry_computation()->root_instruction(),\n-              GmockMatch(match::Fusion(&fusion)));\n-  EXPECT_THAT(*fusion, OutputTileSizesIs(ElementsAre(4, 4)));\n-\n-  const HloInstruction* lhs = nullptr;\n-  const HloInstruction* rhs = nullptr;\n-  EXPECT_THAT(fusion->fused_expression_root(),\n-              GmockMatch(match::Dot(match::Fusion(&lhs), match::Fusion(&rhs))));\n-  EXPECT_THAT(*lhs, OutputTileSizesIs(ElementsAre(4, 8)));\n-  EXPECT_THAT(*rhs, OutputTileSizesIs(ElementsAre(8, 4)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsCanBeHoistedPastOtherBitcasts) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  lhs = f32[3,7] parameter(0)\n-  bitcast0 = f32[21] $0(lhs)\n-  bitcast1 = f32[3,7] $0(bitcast0)\n-  rhs = f32[7,11] parameter(1)\n-  ROOT dot = f32[3,11] dot(bitcast1, rhs),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY entry {\n-  p0 = f32[3, 7] parameter(0)\n-  p1 = f32[7,11] parameter(1)\n-  ROOT fusion = f32[3,11] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-}\n-)\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsCanBeHoistedPastElementwiseEpilogues) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  lhs = f32[3,7] parameter(0)\n-  rhs = f32[7,11] parameter(1)\n-  dot = f32[3,11] dot(lhs, rhs),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  bitcast = f32[33] $0(dot)\n-  ROOT add = f32[33] add(bitcast, bitcast)\n-}\n-\n-ENTRY entry {\n-  p0 = f32[3, 7] parameter(0)\n-  p1 = f32[7,11] parameter(1)\n-  ROOT fusion = f32[33] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsCanBeHoistedPastConvertEpilogues) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  lhs = f32[3,7] parameter(0)\n-  rhs = f32[7,11] parameter(1)\n-  dot = f32[3,11] dot(lhs, rhs),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  bitcast = f32[33] $0(dot)\n-  ROOT convert = f16[33] convert(bitcast)\n-}\n-\n-ENTRY entry {\n-  p0 = f32[3, 7] parameter(0)\n-  p1 = f32[7,11] parameter(1)\n-  ROOT fusion = f16[33] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK: f16[3,11]{1,0} convert(\n-CHECK: f16[3,11]{1,0} fusion(\n-)\"),\n-      IsOkAndHolds(true));\n-\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-}\n-\n-// We cannot hoist bitcasts past transposes, but we don't need to hoist\n-// because the bitcast is not rank-expanding and symbolic tile analysis\n-// works fine.\n-TEST_P(NestGemmFusionReshapeTest, BitcastsCannotBeHoistedPastTransposes) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = f32[72,36,2] parameter(0)\n-  transpose0 = f32[72,2,36] transpose(p0), dimensions={0,2,1}\n-  bitcast0 = f32[144,36] $0(transpose0)\n-  p1 = f32[36,3] parameter(1)\n-  dot = f32[144,3] dot(bitcast0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  bitcast1 = f32[144,3] $0(dot)\n-  ROOT transpose1 = f32[3,144] transpose(bitcast1), dimensions={1,0}\n-}\n-\n-ENTRY entry {\n-  p0 = f32[72,36,2] parameter(0)\n-  p1 = f32[36,3] parameter(1)\n-  ROOT fusion = f32[3,144] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\":{\n-        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n-          \"block_m\":\"128\",\"block_n\":\"16\",\"block_k\":\"32\",\n-          \"split_k\":\"1\",\"num_stages\":\"4\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsKeepElementSizeInBits) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  lhs = s8[21]{0:E(4)} parameter(0)\n-  c1 = s8[21] convert(lhs)\n-  c2 = f32[21] convert(c1)\n-  b0 = f32[3,7] $0(c2)\n-  rhs = f32[7,11] parameter(1)\n-  dot = f32[3,11] dot(b0, rhs), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  b1 = f32[33] $0(dot)\n-  ROOT c = s8[33]{0:E(4)} convert(b1)\n-}\n-\n-ENTRY entry {\n-  p0 = s8[21]{0:E(4)} parameter(0)\n-  p1 = f32[7,11] parameter(1)\n-  ROOT fusion = s8[33]{0:E(4)} fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\": {\n-        \"kind\":\"__triton_gemm\",  \"triton_gemm_config\": {\n-          \"block_m\":\"32\", \"block_n\":\"64\", \"block_k\":\"16\",\n-          \"split_k\":\"1\", \"num_stages\":\"1\", \"num_warps\":\"1\", \"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-  CHECK: ENTRY\n-  CHECK: {{.*}} = s8[3,7]{1,0:E(4)} bitcast({{.*}})\n-  CHECK: [[fusion:[^ ]+]] = s8[3,11]{1,0:E(4)} fusion({{.*}})\n-  CHECK: ROOT {{.*}} = s8[33]{0:E(4)} bitcast([[fusion]])\n-)\"),\n-      IsOkAndHolds(true));\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, TritonFusionEmitterDeviceLegacyTestSample1) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = f16[1,16,17,3] parameter(0)\n-  bitcast0 = f16[16,51] $0(f16[1,16,17,3] p0)\n-  p1 = s8[16,17,3] parameter(1)\n-  bitcast1 = s8[16,51] $0(s8[16,17,3] p1)\n-  convert = f16[16,51] convert(s8[16,51] bitcast1)\n-  bitcast2 = f16[51,16]{0,1} $0(f16[16,51] convert)\n-  dot = f16[16,16] dot(bitcast0, bitcast2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  ROOT bitcast3 = f16[1,16,16] $0(f16[16,16] dot)\n-}\n-\n-ENTRY entry {\n-  p0 = f16[1,16,17,3] parameter(0)\n-  p1 = s8[16,17,3] parameter(1)\n-  ROOT fusion = f16[1,16,16] fusion(f16[1,16,17,3] p0, s8[16,17,3] p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\":{\n-        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n-          \"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"32\",\n-          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, TritonFusionEmitterDeviceLegacyTestSample2) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = pred[3,122,96,12] parameter(0)\n-  transpose = pred[3,96,12,122] transpose(p0), dimensions={0,2,3,1}\n-  bitcast0 = pred[3456,122] $0(transpose)\n-  convert0 = f16[3456,122] convert(bitcast0)\n-  p1 = pred[1,5,122] parameter(1)\n-  bitcast1 = pred[5,122] $0(p1)\n-  convert1 = f16[5,122] convert(bitcast1)\n-  bitcast2 = f16[122,5]{0,1} $0(convert1)\n-  dot.1 = f16[3456,5] dot(convert0, bitcast2), lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-  ROOT bitcast3 = f16[3,96,12,1,5] $0(dot.1)\n-}\n-\n-ENTRY entry_computation {\n-  p0 = pred[3,122,96,12] parameter(0)\n-  p1 = pred[1,5,122] parameter(1)\n-  ROOT gemm_fusion_dot = f16[3,96,12,1,5] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\":{\n-        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n-          \"block_m\":\"4\",\"block_n\":\"16\",\"block_k\":\"128\",\n-          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  // Note: block sizes were 16,16,32, but that now fails to satisfy constraints.\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, TritonFusionEmitterDeviceLegacyTestSample3) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = f32[1,40] parameter(0)\n-  bitcast0 = f32[40] $0(p0)\n-  bitcast1 = f32[40,1] $0(bitcast0)\n-  p1 = f32[1,40,250000] parameter(1)\n-  bitcast2 = f32[40,250000] $0(p1)\n-  dot = f32[1,250000] dot(bitcast1, bitcast2), lhs_contracting_dims={0}, rhs_contracting_dims={0}\n-  bitcast3 = f32[250000] $0(dot)\n-  ROOT bitcast4 = f32[1,250000] $0(bitcast3)\n-}\n-\n-ENTRY entry_computation {\n-  p0 = f32[1,40] parameter(0)\n-  p1 = f32[1,40,250000] parameter(1)\n-  ROOT gemm_fusion_dot.2 = f32[1,250000] fusion(p0, p1),\n-    kind=kCustom, calls=dot, backend_config={\n-      \"fusion_backend_config\":{\n-        \"kind\":\"__triton_gemm\",\"triton_gemm_config\":{\n-          \"block_m\":\"16\",\"block_n\":\"16\",\"block_k\":\"32\",\n-          \"split_k\":\"1\",\"num_stages\":\"1\",\"num_warps\":\"4\",\"num_ctas\":\"1\"\n-        }\n-      }\n-    }\n-})\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedPastCompare) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = s32[11,24,128]{2,1,0} parameter(0)\n-  p1 = s32[11,24,128]{2,1,0} parameter(1)\n-  eq = pred[11,24,128]{2,1,0} compare(p0, p1), direction=EQ\n-  eq_reshape = pred[264,128]{1,0} $0(eq)\n-  eq_f32 = f32[264,128]{1,0} convert(eq_reshape)\n-  p2 = f32[128,8]{1,0} parameter(2)\n-  ROOT result = f32[264,8]{1,0} dot(eq_f32, p2),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = s32[11,24, 128]{2,1,0} parameter(0)\n-  p1 = s32[11,24,128]{2,1,0} parameter(1)\n-  p2 = f32[128,8]{1,0} parameter(2)\n-  ROOT result = f32[264,8] fusion(p0, p1, p2), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\n-      \"block_m\":32,\"block_n\":16,\"block_k\":128,\n-      \"split_k\":1,\"num_stages\":1,\"num_warps\":4, \"num_ctas\":1}}}}\n-)\";\n-  ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedUpThroughBroadcasts) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[11,1,24,1] parameter(0)\n-  p0_broadcast = f32[11,1,24,1,128] broadcast(p0), dimensions={0,1,2,3}\n-  p0_reshape = f32[264,128] $0(p0_broadcast)\n-\n-  p1 = f32[128,8]{1,0} parameter(1)\n-  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[11,1,24,1] parameter(0)\n-  p1 = f32[128,8] parameter(1)\n-  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-// Broadcast fusion:\n-CHECK: {{.*}} {\n-CHECK-NEXT: [[broadcast_p0:[^ ]+]] = f32[264]{0} parameter(0)\n-CHECK-NEXT: ROOT {{.*}} = f32[264,128]{1,0} broadcast([[broadcast_p0]]), dimensions={0}\n-CHECK-NEXT: }\n-CHECK: ENTRY {{.*}} {\n-CHECK: [[entry_p0:[^ ]+]] = f32[11,1,24,1]{3,2,1,0} parameter(0)\n-CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsAreHoistedUpThroughBroadcastsWithTrivialDimensions) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[11,24,1] parameter(0)\n-  p0_broadcast = f32[11,1,24,1,128] broadcast(p0), dimensions={0,2,3}\n-  p0_reshape = f32[264,128] $0(p0_broadcast)\n-  p1 = f32[128,8]{1,0} parameter(1)\n-  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[11,24,1] parameter(0)\n-  p1 = f32[128,8] parameter(1)\n-  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(\n-                              absl::Substitute(hlo, HloOpcodeString(opcode))));\n-  ASSERT_THAT(\n-      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n-      IsOkAndHolds(true));\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-// Broadcast fusion:\n-CHECK: {{.*}} {\n-CHECK-NEXT: [[broadcast_p0:[^ ]+]] = f32[264]{0} parameter(0)\n-CHECK-NEXT: ROOT {{.*}} = f32[264,128]{1,0} broadcast([[broadcast_p0]]), dimensions={0}\n-CHECK-NEXT: }\n-CHECK: ENTRY {{.*}} {\n-CHECK: [[entry_p0:[^ ]+]] = f32[11,24,1]{{.*}} parameter(0)\n-CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastOfOperandAndBroadcastDimsIsNotHoistedUp) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[3,4] parameter(0)\n-  p1 = f32[64,7]{1,0} parameter(1)\n-  broadcast = f32[3,4,16] broadcast(p0), dimensions={0,1}\n-  // Bitcast mixes operand and broadcasted dimensions and cannot be hoisted.\n-  reshape = f32[3,64] $0(broadcast)\n-  ROOT dot = f32[3,7]{1,0} dot(reshape, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,4] parameter(0)\n-  p1 = f32[64,7] parameter(1)\n-  ROOT result = f32[3,7] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  // Cos should not be rewritten as we cannot hoist bitcast.\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK:      f32[3,4,16]{2,1,0} broadcast\n-CHECK-NEXT: f32[3,64]{1,0} $0\n-)\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastOfOperandAndBroadcastDimsIsNotHoistedDown) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7]{1,0} parameter(1)\n-  dot = f32[6,5]{1,0} dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  // Bitcast mixes operand and broadcasted dimensions and cannot be hoisted.\n-  reshape = f32[2,3,5] $0(dot)\n-  ROOT broadcast = f32[2,4,3,5] broadcast(reshape), dimensions={0,2,3}\n-}\n-\n-ENTRY e {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[2,4,3,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  // Cos should not be rewritten as we cannot hoist bitcast.\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK:      f32[2,3,5]{2,1,0} $0\n-CHECK-NEXT: f32[2,4,3,5]{3,2,1,0} broadcast\n-)\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsAreHoistedUpThroughBroadcastDiamonds) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[3,5] parameter(0)\n-  b0 = f32[3,5,77,1] broadcast(p0), dimensions={0,1}\n-  b1 = f32[3,5,1] broadcast(p0), dimensions={0,1}\n-  b2 = f32[3,5,77,1] broadcast(b1), dimensions={0,1,3}\n-  sum = add(b0, b2)\n-  sum_reshape = f32[15,77] $0(sum)\n-  p1 = f32[77,8]{1,0} parameter(1)\n-  ROOT result = f32[15,8] dot(sum_reshape, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,5] parameter(0)\n-  p1 = f32[77,8] parameter(1)\n-  ROOT result = f32[15,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK: [[p0:[^ ]+]] = f32[15]{0} parameter(0)\n-CHECK-DAG: {{.*}} = f32[15,77]{1,0} broadcast([[p0]]), dimensions={0}\n-CHECK-DAG: [[br:[^ ]+]] = f32[15]{0} broadcast([[p0]]), dimensions={0}\n-CHECK-DAG: {{.*}} = f32[15,77]{1,0} broadcast([[br]]), dimensions={0}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedOverBroadcasts) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[11,1,24,1] parameter(0)\n-  p0_broadcast = f32[11,1,24,1,128,1] broadcast(p0), dimensions={0,1,2,5}\n-  p0_reshape = f32[264,128] $0(p0_broadcast)\n-\n-  p1 = f32[128,8]{1,0} parameter(1)\n-  ROOT result = f32[264,8]{1,0} dot(p0_reshape, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[11,1,24,1] parameter(0)\n-  p1 = f32[128,8] parameter(1)\n-  ROOT result = f32[264,8] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           R\"(\n-// Broadcast fusion:\n-CHECK: {{.*}} {\n-CHECK-NEXT: [[broadcast_p0:[^ ]+]] = f32[264]{0} parameter(0)\n-CHECK-NEXT: ROOT {{.*}} = f32[264,128]{1,0} broadcast([[broadcast_p0]]), dimensions={0}\n-CHECK-NEXT: }\n-CHECK: ENTRY {{.*}} {\n-CHECK: [[entry_p0:[^ ]+]] = f32[11,1,24,1]{3,2,1,0} parameter(0)\n-CHECK: {{.*}} = f32[264]{0} bitcast([[entry_p0]])\n-)\"),\n-\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsLayoutIsPreserved) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-gemm_dot {\n-  p0 = pred[3,122,96,12] parameter(0)\n-  bitcast0 = pred[3,122,1152] $0(p0)\n-  transpose0 = pred[3,1152,122] transpose(bitcast0), dimensions={0,2,1}\n-  bitcast2 = pred[3456,122] $0(transpose0)\n-  convert0 = f16[3456,122] convert(bitcast2)\n-  p1 = pred[1,5,122] parameter(1)\n-  bitcast3 = pred[5,122] $0(p1)\n-  convert1 = f16[5,122] convert(bitcast3)\n-  bitcast4 = f16[122,5]{0,1} $0(convert1)\n-  dot0 = f16[3456,5]{1,0} dot(convert0, bitcast4), lhs_contracting_dims={1},\n-    rhs_contracting_dims={0}\n-  ROOT bitcast5 = f16[3,96,12,1,5] $0(dot0)\n-}\n-\n-ENTRY e {\n-  p0 = pred[3,122,96,12] parameter(0)\n-  p1 = pred[1,5,122] parameter(1)\n-  ROOT fusion = f16[3,96,12,1,5] fusion(p0, p1), kind=kCustom, calls=gemm_dot,\n-    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n-}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK: {{.*}} {\n-CHECK: transpose\n-CHECK: [[bitcast_or_reshape:[^ ]+]] = pred[3456,122]{1,0} $0({{.*}})\n-CHECK: ROOT {{.*}} = f16[3456,122]{1,0} convert([[bitcast_or_reshape]])\n-CHECK-NEXT: }\n-CHECK: {{.*}} {\n-CHECK-NOT: $0\n-CHECK: ROOT {{.*}} = f16[122,5]{0,1} convert({{.*}})\n-CHECK-NEXT: }\n-CHECK: ENTRY {{.*}} {\n-CHECK: {{.*}} = pred[122,5]{0,1} bitcast({{.*}})\n-)\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       CheckDimensionsOfBroadcastAfterBitcastIsHoisted) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-dot {\n-  p0 = bf16[1,8] parameter(0)\n-  broadcast0 = bf16[1,8,8] broadcast(p0), dimensions={0,2}\n-  lhs = bf16[1,2,4,8] $0(broadcast0)\n-\n-  p1 = bf16[1,8] parameter(1)\n-  broadcast1 = bf16[1,8,8] broadcast(p1), dimensions={0,2}\n-  rhs = bf16[1,2,4,8] $0(broadcast1)\n-\n-  ROOT dot = bf16[2,1,4,4] dot(lhs, rhs),\n-    lhs_contracting_dims={3}, lhs_batch_dims={1,0},\n-    rhs_contracting_dims={3}, rhs_batch_dims={1,0}\n-}\n-\n-ENTRY entry {\n-  p0 = bf16[1,8] parameter(0)\n-  ROOT fusion = bf16[2,1,4,4] fusion(p0, p0), kind=kCustom, calls=dot,\n-    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n-})\";\n-\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK: bf16[1,2,4,8]{{.*}} broadcast({{.*}}), dimensions={3}\n-CHECK: bf16[1,2,4,8]{{.*}} broadcast({{.*}}), dimensions={3}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedUpThroughTransposes) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[7,6] parameter(0)\n-  transpose = f32[6,7] transpose(p0), dimensions={1,0}\n-  bitcast = f32[2,3,7] $0(transpose)\n-  p1 = f32[2,5,7] parameter(1)\n-  ROOT result = f32[2,3,5] dot(bitcast, p1),\n-    lhs_contracting_dims={2}, lhs_batch_dims={0},\n-    rhs_contracting_dims={2}, rhs_batch_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[7,6] parameter(0)\n-  p1 = f32[2,5,7] parameter(1)\n-  ROOT result = f32[2,3,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      ROOT transpose\n-CHECK-SAME: f32[2,3,7]{2,1,0} transpose\n-CHECK-SAME: dimensions={1,2,0}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsWithSize1DimensionsAreHoistedUpThroughTransposes) {\n-  const HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[7,6] parameter(0)\n-  transpose = f32[6,7] transpose(p0), dimensions={1,0}\n-  bitcast = f32[1,6,7] $0(transpose)\n-  p1 = f32[1,5,7] parameter(1)\n-  ROOT result = f32[1,6,5] dot(bitcast, p1),\n-    lhs_contracting_dims={2}, lhs_batch_dims={0},\n-    rhs_contracting_dims={2}, rhs_batch_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[7,6] parameter(0)\n-  p1 = f32[1,5,7] parameter(1)\n-  ROOT result = f32[1,6,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      ROOT transpose\n-CHECK-SAME: f32[1,6,7]{2,1,0} transpose\n-CHECK-SAME: dimensions={1,2,0}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       RankReducingBitcastsAreNotHoistedUpThroughTransposes) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[2,7,3] parameter(0)\n-  transpose = f32[3,2,7] transpose(p0), dimensions={2,0,1}\n-  $0 = f32[6,7] $0(transpose)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT dot = f32[6,5] dot($0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-}\n-\n-ENTRY e {\n-  p0 = f32[2,7,3] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[6,5] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      transpose\n-CHECK-SAME: f32[3,2,7]{2,1,0} transpose\n-CHECK-SAME: dimensions={2,0,1}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       RankReducingBitcastsAreNotHoistedDownThroughTransposes) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  dot = f32[6,5] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  $0 = f32[2,3,5] $0(dot)\n-  ROOT transpose = f32[2,5,3] transpose($0), dimensions={0,2,1}\n-}\n-\n-ENTRY e {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[2,5,3] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK:      f32[2,3,5]{2,1,0} $0\n-CHECK-NEXT: f32[2,5,3]{2,1,0} transpose\n-)\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       HoistingBitcastDoesNotIntroduceArtificialDimension) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-gemm_dot {\n-  p0 = f16[3,122,1152] parameter(0)\n-  transpose = f16[3,1152,122] transpose(p0), dimensions={0,2,1}\n-  bitcast0 = f16[3,96,12,122] $0(transpose)\n-  bitcast1 = f16[3456,122] $0(bitcast0)\n-  p1 = f16[122,5] parameter(1)\n-  ROOT dot = f16[3456,5]{1,0} dot(bitcast1, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n-}\n-\n-ENTRY e {\n-  p0 = f16[3,122,1152] parameter(0)\n-  p1 = f16[122,5] parameter(1)\n-  ROOT fusion = f16[3456,5] fusion(p0, p1), kind=kCustom, calls=gemm_dot,\n-    backend_config={\"fusion_backend_config\":{kind:\"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":32,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}\n-}\n-          )\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  // Checks that transpose is on rank 3 tensor from hoisting bitcast1, not rank\n-  // 4 tensor from hoisting bitcast0 first and then failing to hoist bitcast1.\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      transpose\n-CHECK-SAME: f16[3,1152,122]{2,1,0} transpose\n-CHECK-SAME: dimensions={0,2,1}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedDownThroughTransposes) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[2,3,7] parameter(0)\n-  p1 = f32[2,5,7] parameter(1)\n-  dot = f32[2,3,5] dot(p0, p1),\n-    lhs_contracting_dims={2}, lhs_batch_dims={0},\n-    rhs_contracting_dims={2}, rhs_batch_dims={0}\n-  bitcast = f32[6,5] $0(dot)\n-  ROOT transpose = f32[5,6] transpose(bitcast), dimensions={1,0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[2,3,7] parameter(0)\n-  p1 = f32[2,5,7] parameter(1)\n-  ROOT result = f32[5,6] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      ROOT transpose\n-CHECK-SAME: f32[5,2,3]{2,1,0} transpose\n-CHECK-SAME: dimensions={2,0,1}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastsAreHoistedDownThroughBroadcasts) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  dot = f32[3,5] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  bitcast = f32[15] $0(dot)\n-  ROOT broadcast = f32[2,15,6] broadcast(bitcast), dimensions={1}\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[2,15,6] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      ROOT broadcast\n-CHECK-SAME: f32[3,5,6,2]{2,1,0,3} broadcast\n-CHECK-SAME: dimensions={0,1}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-// TODO(b/467306121): handle the case when we need to sink the reshape through\n-// broadcast.\n-TEST_P(NestGemmFusionReshapeTest,\n-       DISABLED_BitcastsAreHoistedDownThroughBroadcastsWithTrivialDimensions) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[6,7] parameter(1)\n-  dot = f32[3,6] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  bitcast = f32[3,2,3] $0(dot)\n-  ROOT broadcast = f32[3,2,1,3,7] broadcast(bitcast), dimensions={0,1,3}\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[6,7] parameter(1)\n-  ROOT result = f32[3,2,1,3,7] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(\n-                              absl::Substitute(hlo, HloOpcodeString(opcode))));\n-  ASSERT_THAT(\n-      NestGemmFusion(device_description_, &mlir_context_).Run(module.get()),\n-      IsOkAndHolds(true));\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK:      ROOT broadcast\n-CHECK-SAME: f32[3,5,6,2]{2,1,0,3} broadcast\n-CHECK-SAME: dimensions={0,1}\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsAreHoistedDownThroughBroadcastsWithNonDefaultLayout) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  dot = f32[6,5] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  bitcast = f32[2,3,5]{2,1,0} $0(dot)\n-  ROOT broadcast = f32[2,3,5]{2,0,1} broadcast(bitcast), dimensions={0,1,2}\n-}\n-\n-ENTRY e {\n-  p0 = f32[6,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[2,3,5]{2,0,1} fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK:      f32[2,3,5]{2,1,0} $0(dot)\n-CHECK-NEXT: f32[2,3,5]{2,0,1} broadcast\n-)\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, BitcastRootsAreHoistedDown) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  dot = f32[3,5] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  ROOT bitcast = f32[15] $0(dot)\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  ROOT result = f32[15] fusion(p0, p1), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK: ROOT dot\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastAreHoistedDownThroughBinaryElementwiseOps) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-triton_dot {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  p2 = f32[15] parameter(2)\n-  dot = f32[3,5] dot(p0, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  $0 = f32[15] $0(dot)\n-  ROOT add = f32[15] add($0, p2)\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,7] parameter(0)\n-  p1 = f32[5,7] parameter(1)\n-  p2 = f32[15] parameter(2)\n-  ROOT result = f32[15] fusion(p0, p1, p2), kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":16,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":1,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK: ROOT add = f32[3,5]{1,0} add\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsWithNonDefaultLayoutAreHoistedOutThroughBroadcast) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[7,2]{0,1} parameter(0)\n-  broadcast.1 = f32[15,7,2]{1,0,2} broadcast(p0), dimensions={1,2}\n-  $0.1 = f32[2,7,15]{1,2,0} $0(broadcast.1)\n-  p1 = f32[2,15,15]{2,1,0} parameter(1)\n-  dot = f32[2,7,15]{2,1,0} dot($0.1, p1),\n-    lhs_batch_dims={0}, lhs_contracting_dims={2},\n-    rhs_batch_dims={0}, rhs_contracting_dims={2}\n-  $0.2 = f32[15,14]{0,1} $0(dot)\n-  ROOT broadcast.2 = f32[15,11,14]{0,2,1} broadcast($0.2), dimensions={0,2}\n-}\n-\n-ENTRY e {\n-  p0 = f32[7,2]{0,1} parameter(0)\n-  p1 = f32[2,15,15]{2,1,0} parameter(1)\n-  ROOT result = f32[15,11,14]{0,2,1} fusion(p0, p1),\n-    kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-CHECK: f32[2,7,15]{1,2,0} broadcast({{.*}}), dimensions={0,1}\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-CHECK: f32[2,7,15,11]{2,1,0,3} broadcast({{.*}}), dimensions={0,1,2}\n-CHECK: ENTRY\n-CHECK: f32[7,2]{0,1} parameter(0)\n-CHECK: f32[2,7]{1,0} bitcast(p0\n-CHECK: result = f32[2,7,15,11]{2,1,0,3} fusion\n-CHECK: ROOT {{.*}} = f32[15,11,14]{0,2,1} bitcast(result)\n-)\"),\n-      IsOkAndHolds(true));\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest,\n-       BitcastsWithNonDefaultLayoutAreHoistedOutThroughTranspose) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[2,3,7]{0,2,1} parameter(0)\n-  $0.1 = f32[7,3,2]{2,0,1} $0(p0)\n-  transpose.1 = f32[3,2,7]{2,0,1} transpose($0.1), dimensions={1,2,0}\n-  p1 = f32[3,5,7]{2,1,0} parameter(1)\n-  dot = f32[3,2,5]{2,1,0} dot(transpose.1, p1),\n-    lhs_batch_dims={0}, lhs_contracting_dims={2},\n-    rhs_batch_dims={0}, rhs_contracting_dims={2}\n-  $0.2 = f32[5,3,2]{0,2,1} $0(dot)\n-  ROOT transpose.2 = f32[2,3,5]{0,2,1} transpose($0.2), dimensions={2,1,0}\n-}\n-\n-ENTRY e {\n-  p0 = f32[2,3,7]{0,2,1} parameter(0)\n-  p1 = f32[3,5,7]{2,1,0} parameter(1)\n-  ROOT result = f32[2,3,5]{0,2,1} fusion(p0, p1),\n-    kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-CHECK: f32[3,2,7]{2,0,1} transpose({{.*}}), dimensions={1,2,0}\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-CHECK: f32[3,5,2]{2,1,0} transpose({{.*}}), dimensions={0,2,1}\n-CHECK: ENTRY\n-CHECK: f32[2,3,7]{0,2,1} parameter(0)\n-CHECK: f32[7,3,2]{2,0,1} bitcast(p0\n-CHECK: result = f32[3,5,2]{2,1,0} fusion\n-CHECK: ROOT {{.*}} = f32[2,3,5]{0,2,1} bitcast(result)\n-)\"),\n-      IsOkAndHolds(true));\n-  ASSERT_OK(verifier().Run(module.get()).status());\n-}\n-\n-TEST_P(NestGemmFusionReshapeTest, MultipleBitcastsAreHoistedOut) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[3,3]{1,0} parameter(0)\n-  $0.1 = f32[3,3]{1,0} $0(p0)\n-  $0.2 = f32[3,3]{1,0} $0($0.1)\n-  p1 = f32[3,3]{1,0} parameter(1)\n-  dot = f32[3,3]{1,0} dot($0.2, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  $0.3 = f32[3,3]{1,0} $0(dot)\n-  ROOT $0.4 = f32[3,3]{0,1} $0($0.3)\n-}\n-\n-ENTRY e {\n-  p0 = f32[3,3]{1,0} parameter(0)\n-  ROOT result = f32[3,3]{0,1} fusion(p0, p0),\n-    kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(\n-      RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()), R\"(\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-CHECK: ENTRY\n-)\"),\n-      IsOkAndHolds(true));\n-}\n-\n-// TODO(b/393299275): this test was not written correctly and now fails.\n-TEST_P(NestGemmFusionReshapeTest,\n-       DISABLED_BitcastsAreNotHoistedOutThroughLayoutChangingTranspose) {\n-  HloOpcode opcode = GetParam();\n-  absl::string_view hlo = R\"(\n-HloModule t\n-\n-triton_dot {\n-  p0 = f32[7,2]{1,0} parameter(0)\n-  $0.1 = f32[2,7]{0,1} $0(p0)\n-  transpose.1 = f32[2,7]{1,0} transpose($0.1), dimensions={0,1}\n-  p1 = f32[5,7]{1,0} parameter(1)\n-  dot = f32[2,5]{1,0} dot(transpose.1, p1),\n-    lhs_contracting_dims={1}, rhs_contracting_dims={1}\n-  $0.2 = f32[5,2]{0,1} $0(dot)\n-  ROOT transpose.2 = f32[5,2]{1,0} transpose($0.2), dimensions={0,1}\n-}\n-\n-ENTRY e {\n-  p0 = f32[7,2]{1,0} parameter(0)\n-  p1 = f32[5,7]{1,0} parameter(1)\n-  ROOT result = f32[5,2]{1,0} fusion(p0, p1),\n-    kind=kCustom, calls=triton_dot,\n-    backend_config={\"fusion_backend_config\": {kind: \"__triton_gemm\",\n-    triton_gemm_config: {\"block_m\":32,\"block_n\":16,\"block_k\":8,\n-    \"split_k\":1,\"num_stages\":1,\"num_warps\":4,\"num_ctas\":1}}}}\n-)\";\n-  std::unique_ptr<VerifiedHloModule> module =\n-      ParseAndRunNestGemmFusion(absl::Substitute(hlo, HloOpcodeString(opcode)));\n-  EXPECT_THAT(RunFileCheck(module->ToString(HloPrintOptions::ShortParsable()),\n-                           absl::Substitute(R\"(\n-CHECK: $0.1 = f32[2,7]{0,1} $0\n-CHECK: $0.2 = f32[5,2]{0,1} $0\n-CHECK: ENTRY\n-CHECK-NOT: bitcast\n-CHECK-NOT: reshape\n-        )\",\n-                                            HloOpcodeString(opcode))),\n-              IsOkAndHolds(true));\n-}\n-\n-INSTANTIATE_TEST_SUITE_P(NestGemmFusionReshapeTestSuite,\n-                         NestGemmFusionReshapeTest,\n-                         ::testing::ValuesIn({HloOpcode::kReshape,\n-                                              HloOpcode::kBitcast}),\n-                         [](const ::testing::TestParamInfo<HloOpcode>& info) {\n-                           return std::string(HloOpcodeString(info.param));\n-                         });\n-\n-struct CommonFactorsTestCase {\n-  std::vector<int64_t> from, to;\n-  absl::InlinedVector<std::pair<int64_t, int64_t>, 8> expected;\n-};\n-\n-class CommonFactorsMergingTrivialRangesTest\n-    : public ::testing::TestWithParam<CommonFactorsTestCase> {};\n-\n-TEST_P(CommonFactorsMergingTrivialRangesTest, Example) {\n-  const CommonFactorsTestCase& test_case = GetParam();\n-  EXPECT_EQ(test_case.expected, detail::CommonFactorsMergingTrivialRanges(\n-                                    test_case.from, test_case.to));\n-}\n-\n-INSTANTIATE_TEST_SUITE_P(\n-    CommonFactorsMergingTrivialRangesTestSuite,\n-    CommonFactorsMergingTrivialRangesTest,\n-    ::testing::Values(\n-        CommonFactorsTestCase{{1}, {}, {{0, 0}, {1, 0}}},\n-        CommonFactorsTestCase{{}, {1}, {{0, 0}, {0, 1}}},\n-        CommonFactorsTestCase{{}, {}, {{0, 0}}},\n-        CommonFactorsTestCase{{1, 2, 0}, {2, 0, 3}, {{0, 0}, {3, 3}}},\n-        CommonFactorsTestCase{{2, 3, 0}, {1, 0, 1000}, {{0, 0}, {3, 3}}},\n-        CommonFactorsTestCase{{1, 1, 1}, {1, 1}, {{0, 0}, {1, 1}, {3, 2}}},\n-        CommonFactorsTestCase{{1, 1, 3}, {3, 1, 1}, {{0, 0}, {3, 3}}},\n-        CommonFactorsTestCase{{2, 6}, {4, 3}, {{0, 0}, {2, 2}}},\n-        CommonFactorsTestCase{{1, 2, 6}, {4, 1, 3, 1}, {{0, 0}, {3, 4}}},\n-        CommonFactorsTestCase{{2, 3, 4, 5}, {6, 20}, {{0, 0}, {2, 1}, {4, 2}}},\n-        CommonFactorsTestCase{\n-            {2, 3, 4, 5, 6}, {6, 20, 6}, {{0, 0}, {2, 1}, {4, 2}, {5, 3}}},\n-        CommonFactorsTestCase{{2, 2, 2, 2}, {4, 4}, {{0, 0}, {2, 1}, {4, 2}}},\n-        CommonFactorsTestCase{\n-            {2, 5, 1, 3}, {1, 10, 3, 1}, {{0, 0}, {2, 2}, {4, 4}}}),\n-    [](const ::testing::TestParamInfo<CommonFactorsTestCase>& info) {\n-      return absl::StrCat(absl::StrJoin(info.param.from, \"_\"), \"_to_\",\n-                          absl::StrJoin(info.param.to, \"_\"));\n-    });\n-\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 4583,
        "additions": 2465,
        "deletions": 2118
    }
}