{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Remove TF_ prefix from RETURN_IF_ERROR and ASSIGN_OR_RETURN macros.\n\nPiperOrigin-RevId: 847716343",
    "sha": "2f90852c17800308bc406ac1ea7de4cf9e78fd01",
    "files": [
        {
            "sha": "de324ce85f41f56402b8913819ed6e285c546c00",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2f90852c17800308bc406ac1ea7de4cf9e78fd01/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2f90852c17800308bc406ac1ea7de4cf9e78fd01/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=2f90852c17800308bc406ac1ea7de4cf9e78fd01",
            "patch": "@@ -1521,6 +1521,7 @@ cc_library(\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status_macros\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\","
        },
        {
            "sha": "39b735c1381572a5bf856a3e3e16298818f62003",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 46,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2f90852c17800308bc406ac1ea7de4cf9e78fd01/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2f90852c17800308bc406ac1ea7de4cf9e78fd01/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=2f90852c17800308bc406ac1ea7de4cf9e78fd01",
            "patch": "@@ -59,6 +59,7 @@ limitations under the License.\n #include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"tsl/platform/casts.h\"\n+#include \"xla/tsl/platform/status_macros.h\"\n \n namespace xla {\n namespace gpu {\n@@ -91,9 +92,9 @@ absl::Status LoadRaggedTensorMetadata(\n     se::Stream& stream, absl::Span<DeviceBufferPair const> buffers,\n     absl::Span<int64_t* const> ragged_metadata_allocs) {\n   for (int64_t i = 0; i < kNumRaggedMetadataOperands; ++i) {\n-    TF_RETURN_IF_ERROR(stream.Memcpy(ragged_metadata_allocs[i],\n-                                     buffers[i + 2].source_buffer,\n-                                     buffers[i + 2].source_buffer.size()));\n+    RETURN_IF_ERROR(stream.Memcpy(ragged_metadata_allocs[i],\n+                                  buffers[i + 2].source_buffer,\n+                                  buffers[i + 2].source_buffer.size()));\n   }\n \n   // Wait for the copies to complete.\n@@ -111,7 +112,7 @@ absl::Status RunAllToAllOnIndexBuffer(\n     const se::DeviceAddressBase& source_buffer, int64_t num_updates_per_replica,\n     const se::DeviceAddressBase& destination_buffer, PrimitiveType element_type,\n     se::Stream& stream, Communicator& comm) {\n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n+  ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n   auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(&comm);\n   Future<> future = gpu_comm->GroupExecute(\n@@ -125,18 +126,18 @@ absl::Status RunAllToAllOnIndexBuffer(\n           se::DeviceAddressBase recv_slice =\n               GpuCollectives::Slice(destination_buffer, element_type, offset,\n                                     /*count=*/num_updates_per_replica);\n-          TF_RETURN_IF_ERROR(comm->LaunchSend(send_slice, element_type,\n-                                              /*count=*/num_updates_per_replica,\n-                                              RankId(peer),\n-                                              GpuCollectives::On(stream)));\n-          TF_RETURN_IF_ERROR(comm->LaunchRecv(recv_slice, element_type,\n-                                              /*count=*/num_updates_per_replica,\n-                                              RankId(peer),\n-                                              GpuCollectives::On(stream)));\n+          RETURN_IF_ERROR(comm->LaunchSend(send_slice, element_type,\n+                                           /*count=*/num_updates_per_replica,\n+                                           RankId(peer),\n+                                           GpuCollectives::On(stream)));\n+          RETURN_IF_ERROR(comm->LaunchRecv(recv_slice, element_type,\n+                                           /*count=*/num_updates_per_replica,\n+                                           RankId(peer),\n+                                           GpuCollectives::On(stream)));\n         }\n         return absl::OkStatus();\n       });\n-  TF_RETURN_IF_ERROR(future.Await());\n+  RETURN_IF_ERROR(future.Await());\n   return stream.BlockHostUntilDone();\n }\n \n@@ -149,7 +150,7 @@ absl::Status RunRaggedAllToAll(\n   int device_ordinal = stream.parent()->device_ordinal();\n   XLA_VLOG_DEVICE(3, device_ordinal)\n       << \"Performing ragged-all-to-all from device ordinal: \" << device_ordinal;\n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n+  ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n   std::vector<DeviceBufferPair> buffers = original_buffers;\n \n@@ -161,13 +162,13 @@ absl::Status RunRaggedAllToAll(\n   // local output buffer. To get the correct offsets we perform an AllToAll on\n   // the output_offsets buffer.\n   DeviceBufferPair& output_offsets_buffer_pair = buffers[4];\n-  TF_RETURN_IF_ERROR(RunAllToAllOnIndexBuffer(\n+  RETURN_IF_ERROR(RunAllToAllOnIndexBuffer(\n       output_offsets_buffer_pair.source_buffer, num_updates_per_replica,\n       output_offsets_device_buffer, output_offsets_buffer_pair.element_type,\n       stream, comm));\n   output_offsets_buffer_pair.source_buffer = output_offsets_device_buffer;\n \n-  TF_RETURN_IF_ERROR(\n+  RETURN_IF_ERROR(\n       LoadRaggedTensorMetadata(stream, buffers, ragged_metadata_allocs));\n \n   const int64_t* input_offsets = ragged_metadata_allocs[0];\n@@ -198,12 +199,12 @@ absl::Status RunRaggedAllToAll(\n                 output_offsets[idx] * ragged_row_element_size,\n                 recv_sizes[idx] * ragged_row_element_size);\n \n-            TF_RETURN_IF_ERROR(\n+            RETURN_IF_ERROR(\n                 comm->LaunchSend(send_slice, element_type,\n                                  send_sizes[idx] * ragged_row_element_size,\n                                  RankId(peer), GpuCollectives::On(stream)));\n \n-            TF_RETURN_IF_ERROR(\n+            RETURN_IF_ERROR(\n                 comm->LaunchRecv(recv_slice, element_type,\n                                  recv_sizes[idx] * ragged_row_element_size,\n                                  RankId(peer), GpuCollectives::On(stream)));\n@@ -246,7 +247,7 @@ RendezvousBeforeKernelStart(absl::string_view name,\n   // Record that this device has started the memcpy ragged-all-to-all. We do\n   // this before the rendezvous to make sure that RecordEvent is called before\n   // WaitFor on another stream.\n-  TF_RETURN_IF_ERROR(stream.RecordEvent(start_event));\n+  RETURN_IF_ERROR(stream.RecordEvent(start_event));\n \n   auto rendezvous_fn = [](absl::Span<const RendezvousValue* const> values) {\n     std::vector<RendezvousValue> values_copy;\n@@ -262,7 +263,7 @@ RendezvousBeforeKernelStart(absl::string_view name,\n   std::string start_rendezvous_key =\n       absl::StrFormat(\"start %s ragged-all-to-all for rank %d, clique %s\", name,\n                       rank.value(), clique_key.ToString());\n-  TF_ASSIGN_OR_RETURN(\n+  ASSIGN_OR_RETURN(\n       std::shared_ptr<std::vector<RendezvousValue>> rendezvous_values,\n       Rendezvous<std::vector<RendezvousValue>>(\n           /*name=*/\n@@ -273,7 +274,7 @@ RendezvousBeforeKernelStart(absl::string_view name,\n   // Wait for all devices to reach the start event. This indicates that all\n   // output buffers are ready for transfer.\n   for (auto& value : *rendezvous_values) {\n-    TF_RETURN_IF_ERROR(stream.WaitFor(value.start_event));\n+    RETURN_IF_ERROR(stream.WaitFor(value.start_event));\n   }\n \n   return rendezvous_values;\n@@ -286,21 +287,21 @@ absl::Status RendezvousAfterKernelFinish(\n     int64_t num_ranks, se::Stream& stream, se::Event* end_event,\n     const std::shared_ptr<std::vector<RendezvousValue>>& rendezvous_values) {\n   // Record that this device has finished the memcpy ragged-all-to-all.\n-  TF_RETURN_IF_ERROR(stream.RecordEvent(end_event));\n+  RETURN_IF_ERROR(stream.RecordEvent(end_event));\n \n   // Do another rendezvous to make sure that we call RecordEvent for end_event\n   // before WaitFor on another stream.\n   std::string finish_rendezvous_key =\n       absl::StrFormat(\"finish %s ragged-all-to-all for rank %d, clique %s\",\n                       name, rank.value(), clique_key.ToString());\n-  TF_RETURN_IF_ERROR(Rendezvous(/*name=*/finish_rendezvous_key,\n-                                /*key=*/clique_key,\n-                                /*num_threads=*/num_ranks));\n+  RETURN_IF_ERROR(Rendezvous(/*name=*/finish_rendezvous_key,\n+                             /*key=*/clique_key,\n+                             /*num_threads=*/num_ranks));\n \n   // Wait for all devices to reach the end event. This indicates that all\n   // updates from other devices have arrived.\n   for (auto& value : *rendezvous_values) {\n-    TF_RETURN_IF_ERROR(stream.WaitFor(value.end_event));\n+    RETURN_IF_ERROR(stream.WaitFor(value.end_event));\n   }\n \n   return absl::OkStatus();\n@@ -324,7 +325,7 @@ absl::Status RaggedAllToAllStartThunk::RunOneShotRaggedAllToAll(\n   se::DeviceAddressBase input_buffer = buffers[0].source_buffer;\n   se::DeviceAddressBase output_buffer = buffers[1].destination_buffer;\n \n-  TF_ASSIGN_OR_RETURN(\n+  ASSIGN_OR_RETURN(\n       std::shared_ptr<std::vector<RendezvousValue>> rendezvous_values,\n       RendezvousBeforeKernelStart(\n           /*name=*/\"one-shot\", clique_key, rank, num_ranks, output_buffer,\n@@ -337,7 +338,7 @@ absl::Status RaggedAllToAllStartThunk::RunOneShotRaggedAllToAll(\n     output_ptrs.push_back(value.output_buffer);\n   }\n \n-  TF_RETURN_IF_ERROR(RunRaggedAllToAllKernel(\n+  RETURN_IF_ERROR(RunRaggedAllToAllKernel(\n       &stream, element_type, input_buffer, output_ptrs,\n       buffers[2].source_buffer, buffers[3].source_buffer,\n       buffers[4].source_buffer, num_ranks, num_updates_per_replica,\n@@ -370,7 +371,7 @@ RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n   auto status = [&instr]() -> absl::Status {\n     for (HloInstruction* operand : instr->operands()) {\n       Shape shape = operand->shape();\n-      TF_RETURN_IF_ERROR(IsValidOperand(shape, Thunk::kRaggedAllToAll));\n+      RETURN_IF_ERROR(IsValidOperand(shape, Thunk::kRaggedAllToAll));\n     }\n \n     if (!ShapeUtil::IsEffectivelyMostMajorDimension(instr->shape(), 0)) {\n@@ -399,7 +400,7 @@ RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n \n absl::Status RaggedAllToAllStartThunk::Initialize(\n     const InitializeParams& params) {\n-  TF_RETURN_IF_ERROR(CollectiveThunk::Initialize(params));\n+  RETURN_IF_ERROR(CollectiveThunk::Initialize(params));\n   device_count_ = params.local_device_count;\n \n   se::StreamExecutor* executor = params.executor;\n@@ -414,7 +415,7 @@ absl::Status RaggedAllToAllStartThunk::Initialize(\n     }\n   }\n \n-  TF_ASSIGN_OR_RETURN(\n+  ASSIGN_OR_RETURN(\n       const GpuCliqueKey clique_key,\n       GetCollectiveGpuCliqueKey(*params.collective_params, config_.config));\n   const std::optional<RankId> rank =\n@@ -426,9 +427,9 @@ absl::Status RaggedAllToAllStartThunk::Initialize(\n   // Allocate temp buffers in the host memory to load the sizes and offsets of\n   // ragged tensors from device memory.\n   for (int64_t i = 0; i < kNumRaggedMetadataOperands; ++i) {\n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<se::MemoryAllocation> alloc,\n-                        executor->HostMemoryAllocate(config_.num_total_updates *\n-                                                     sizeof(int64_t)));\n+    ASSIGN_OR_RETURN(std::unique_ptr<se::MemoryAllocation> alloc,\n+                     executor->HostMemoryAllocate(config_.num_total_updates *\n+                                                  sizeof(int64_t)));\n     state->host_buffer_allocs.push_back(std::move(alloc));\n   }\n \n@@ -441,8 +442,8 @@ absl::Status RaggedAllToAllStartThunk::Initialize(\n   }\n \n   if (is_local()) {\n-    TF_ASSIGN_OR_RETURN(state->start_event, executor->CreateEvent());\n-    TF_ASSIGN_OR_RETURN(state->end_event, executor->CreateEvent());\n+    ASSIGN_OR_RETURN(state->start_event, executor->CreateEvent());\n+    ASSIGN_OR_RETURN(state->end_event, executor->CreateEvent());\n   }\n \n   {\n@@ -470,16 +471,14 @@ bool RaggedAllToAllStartThunk::is_local() const {\n absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n     const ExecuteParams& params, const GpuCliqueKey& clique_key,\n     se::Stream& stream, Communicator& comm) {\n-  TF_ASSIGN_OR_RETURN(\n-      std::vector<DeviceBufferPair> device_buffers,\n-      ConvertToDeviceBuffers(params, buffers_,\n-                             config_.config.operand_element_type));\n+  ASSIGN_OR_RETURN(std::vector<DeviceBufferPair> device_buffers,\n+                   ConvertToDeviceBuffers(params, buffers_,\n+                                          config_.config.operand_element_type));\n \n-  TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n+  ASSIGN_OR_RETURN(int32_t num_ranks, comm.NumRanks());\n \n-  TF_ASSIGN_OR_RETURN(\n-      bool peer_access_enabled,\n-      params.collective_cliques->peer_access_enabled(clique_key));\n+  ASSIGN_OR_RETURN(bool peer_access_enabled,\n+                   params.collective_cliques->peer_access_enabled(clique_key));\n \n   StreamState* state = nullptr;\n   {\n@@ -493,7 +492,7 @@ absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n                                       device_buffers[0].element_type);\n \n   if (should_use_one_shot_kernel) {\n-    TF_RETURN_IF_ERROR(\n+    RETURN_IF_ERROR(\n         RunOneShotRaggedAllToAll(clique_key, stream, *state, device_buffers));\n     return false;\n   }\n@@ -507,7 +506,7 @@ absl::StatusOr<bool> RaggedAllToAllStartThunk::RunCollective(\n         reinterpret_cast<int64_t*>(state->host_buffer_allocs[i]->opaque()));\n   }\n \n-  TF_RETURN_IF_ERROR(\n+  RETURN_IF_ERROR(\n       RunRaggedAllToAll(config_.num_row_elements, config_.num_total_updates,\n                         device_buffers, stream, comm, ragged_metadata_allocs,\n                         state->output_offsets_device_buffer.memory(),"
        }
    ],
    "stats": {
        "total": 92,
        "additions": 46,
        "deletions": 46
    }
}