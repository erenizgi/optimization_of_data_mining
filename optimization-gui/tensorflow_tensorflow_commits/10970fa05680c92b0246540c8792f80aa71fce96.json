{
    "author": "sohaibiftikhar",
    "message": "[XLA:GPU]: Remove redundant cast from triton function lowering.\n\nWe are adding some llvm casts that are not needed when both the source\nand destination is the same.\n\nIn addition it makes the assumption that everything is a !tt.ptr<> which won't\nbe true when we emit collectives.\n\nPiperOrigin-RevId: 827929212",
    "sha": "10970fa05680c92b0246540c8792f80aa71fce96",
    "files": [
        {
            "sha": "87535c60c0365a420d46d099e73b5fdcc295805a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_extract_insert_to_triton_pass.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 19,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/10970fa05680c92b0246540c8792f80aa71fce96/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/10970fa05680c92b0246540c8792f80aa71fce96/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc?ref=10970fa05680c92b0246540c8792f80aa71fce96",
            "patch": "@@ -42,6 +42,7 @@ limitations under the License.\n #include \"mlir/IR/AffineMap.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/MLIRContext.h\"\n@@ -289,26 +290,22 @@ class RewriteFuncOp : public mlir::OpRewritePattern<func::FuncOp> {\n       auto element_type =\n           mlir::cast<PointerType>(operand_type).getPointeeType();\n \n-      mlir::UnrealizedConversionCastOp cast_to_orig_type;\n-      if (auto attr = op.getArgAttr(index, \"tt.tma_descriptor\")) {\n-        auto tma_descriptor = mlir::cast<TmaDescriptorAttr>(attr);\n-        auto layout = tma_descriptor.getLayout();\n-        auto block_shape = tma_descriptor.getTileShape();\n-        SmallVector<int64_t> ordered_block_shape =\n-            GetMajorToMinorOrder(block_shape, layout);\n-\n-        operand_type = TensorDescType::get(\n-            builder.getContext(),\n-            RankedTensorType::get(ordered_block_shape, element_type));\n-        // !tt.tensordesc<tensor<block_shape x element_type>> -> !tt.ptr<>\n-        cast_to_orig_type = builder.create<mlir::UnrealizedConversionCastOp>(\n-            operand_type, func_arg);\n-      } else {\n-        // !tt.ptr<> -> !tt.ptr<>\n-        cast_to_orig_type = builder.create<mlir::UnrealizedConversionCastOp>(\n-            operand_type, func_arg);\n-        operand_type = GetTensorPtrType(element_type);\n+      auto attr = op.getArgAttr(index, \"tt.tma_descriptor\");\n+      if (!attr) {\n+        continue;\n       }\n+      auto tma_descriptor = mlir::cast<TmaDescriptorAttr>(attr);\n+      auto layout = tma_descriptor.getLayout();\n+      auto block_shape = tma_descriptor.getTileShape();\n+      SmallVector<int64_t> ordered_block_shape =\n+          GetMajorToMinorOrder(block_shape, layout);\n+\n+      operand_type = TensorDescType::get(\n+          builder.getContext(),\n+          RankedTensorType::get(ordered_block_shape, element_type));\n+      // !tt.tensordesc<tensor<block_shape x element_type>> -> !tt.ptr<>\n+      auto cast_to_orig_type = builder.create<mlir::UnrealizedConversionCastOp>(\n+          operand_type, func_arg);\n       func_arg.replaceAllUsesExcept(cast_to_orig_type.getResult(0),\n                                     cast_to_orig_type);\n     }"
        }
    ],
    "stats": {
        "total": 35,
        "additions": 16,
        "deletions": 19
    }
}