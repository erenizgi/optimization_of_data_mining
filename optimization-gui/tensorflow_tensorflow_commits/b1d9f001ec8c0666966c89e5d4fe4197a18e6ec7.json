{
    "author": "basioli-k",
    "message": "[XLA][host offloading] Open source `FindAndWrapOffloadedComputations` offloader  util.\n\nPiperOrigin-RevId: 797672627",
    "sha": "b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7",
    "files": [
        {
            "sha": "7fd1e3397d06c8456c2b7cfa99e58e8e56b77b30",
            "filename": "third_party/xla/xla/hlo/transforms/BUILD",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2FBUILD?ref=b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7",
            "patch": "@@ -2,6 +2,7 @@\n #   Implementation of XLAâ€™s HLO transformations.\n \n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n+load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_libtpu_portable\")\n load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n \n package(\n@@ -501,3 +502,26 @@ xla_cc_test(\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )\n+\n+cc_library(\n+    name = \"offloaded_instruction_wrapper\",\n+    srcs = [\"offloaded_instruction_wrapper.cc\"],\n+    hdrs = [\"offloaded_instruction_wrapper.h\"],\n+    compatible_with = get_compatible_with_libtpu_portable(),\n+    deps = [\n+        \"//xla:side_effect_util\",\n+        \"//xla:util\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/transforms/simplifiers:hlo_dce\",\n+        \"//xla/tsl/platform:errors\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/functional:function_ref\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@local_tsl//tsl/platform:casts\",\n+        \"@local_tsl//tsl/platform:errors\",\n+    ],\n+)"
        },
        {
            "sha": "b5fecabd6923ba4f9eb26deed2a563fb98ba1b2a",
            "filename": "third_party/xla/xla/hlo/transforms/offloaded_instruction_wrapper.cc",
            "status": "added",
            "additions": 219,
            "deletions": 0,
            "changes": 219,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.cc?ref=b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7",
            "patch": "@@ -0,0 +1,219 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/offloaded_instruction_wrapper.h\"\n+\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/functional/function_ref.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/transforms/simplifiers/hlo_dce.h\"\n+#include \"xla/side_effect_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/util.h\"\n+#include \"tsl/platform/casts.h\"\n+\n+namespace xla::offloader_util {\n+\n+namespace {\n+\n+absl::Status ClearComputeTypeFrontendAttribute(HloInstruction* instr) {\n+  FrontendAttributes copy_of_frontend_attributes = instr->frontend_attributes();\n+  copy_of_frontend_attributes.mutable_map()->erase(kXlaComputeTypeAttr);\n+  instr->set_frontend_attributes(copy_of_frontend_attributes);\n+  return absl::OkStatus();\n+}\n+\n+}  // namespace\n+\n+absl::Status RecursivelyClearComputeTypeFrontendAttribute(\n+    HloComputation* computation) {\n+  for (HloInstruction* instruction : computation->instructions()) {\n+    TF_RETURN_IF_ERROR(ClearComputeTypeFrontendAttribute(instruction));\n+    for (HloComputation* called_computation :\n+         instruction->called_computations()) {\n+      TF_RETURN_IF_ERROR(\n+          RecursivelyClearComputeTypeFrontendAttribute(called_computation));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<std::vector<std::pair<HloInstruction*, HloCallInstruction*>>>\n+FindAndWrapOffloadedComputations(\n+    HloComputation& computation,\n+    absl::FunctionRef<bool(const HloInstruction*)> should_offload,\n+    absl::FunctionRef<bool(const HloInstruction&, const HloInstruction&)>\n+        should_fuse,\n+    absl::FunctionRef<absl::Status(HloInstruction*)>\n+        clear_backend_config_device_type,\n+    absl::string_view new_call_name_prefix) {\n+  // If a constant is used on TC and offloaded, clear offload annotations and\n+  // only materialize it on TC. This simplifies the dependency chain.\n+  for (HloInstruction* instr : computation.instructions()) {\n+    if (instr->IsConstant() && should_offload(instr)) {\n+      TF_RETURN_IF_ERROR(clear_backend_config_device_type(instr));\n+    }\n+  }\n+\n+  std::vector<std::pair<HloInstruction*, HloCallInstruction*>>\n+      offloaded_instructions_and_calls;\n+  // On each iteration of the outer loop, try to create one offloaded\n+  // computation out of a connected set of offloaded instructions.\n+  while (true) {\n+    HloInstruction* offloaded_instr = nullptr;\n+    HloCallInstruction* offloaded_call_instr = nullptr;\n+    // Stores all the ancestor instructions of offloaded_call_instr which were\n+    // not added to the current offloaded computation.\n+    absl::flat_hash_set<HloInstruction*> unmerged_ancestors;\n+    std::vector<HloInstruction*> post_order =\n+        computation.MakeInstructionPostOrder();\n+    for (auto it = post_order.rbegin(); it != post_order.rend(); ++it) {\n+      HloInstruction* instr = *it;\n+      // The current instruction is not an offload instruction.\n+      if (!should_offload(instr)) {\n+        if (absl::c_any_of(instr->users(), [&](const HloInstruction* user) {\n+              return user == offloaded_call_instr ||\n+                     unmerged_ancestors.contains(user);\n+            })) {\n+          unmerged_ancestors.insert(instr);\n+        }\n+        continue;\n+      }\n+\n+      VLOG(2) << \"Offloading instruction: \" << instr->ToString();\n+\n+      // The current instruction is the root of a new offloaded computation.\n+      if (offloaded_call_instr == nullptr) {\n+        VLOG(2) << instr->name()\n+                << \" is the root of a new offloaded computation\";\n+\n+        HloInstruction* call_instr;\n+        if (instr->opcode() == HloOpcode::kCall) {\n+          call_instr = instr;\n+        } else {\n+          call_instr = computation.CreateCallInstruction({instr});\n+          call_instr->SetAndSanitizeName(new_call_name_prefix);\n+          call_instr->UniquifyName(computation.parent());\n+          call_instr->set_frontend_attributes(instr->frontend_attributes());\n+        }\n+        offloaded_call_instr = tsl::down_cast<HloCallInstruction*>(call_instr);\n+        CHECK_NE(offloaded_call_instr, nullptr);\n+        TF_RETURN_IF_ERROR(\n+            clear_backend_config_device_type(offloaded_call_instr));\n+        TF_RETURN_IF_ERROR(\n+            ClearComputeTypeFrontendAttribute(offloaded_call_instr));\n+        offloaded_instr = instr;\n+        continue;\n+      }\n+\n+      // If the current instruction is indirectly connected to the current\n+      // offloaded computation, it must go in a separate offload computation.\n+      if (absl::c_any_of(instr->users(), [&](const HloInstruction* user) {\n+            return unmerged_ancestors.contains(user);\n+          })) {\n+        VLOG(2) << instr->name()\n+                << \" is indirectly connected to the current offloaded \"\n+                   \"computation, it must go in a separate offload computation\";\n+\n+        unmerged_ancestors.insert(instr);\n+        continue;\n+      }\n+\n+      // The current instruction is directly connected to the current offloaded\n+      // computation.\n+      if (offloaded_call_instr->IsUserOf(instr)) {\n+        VLOG(2)\n+            << instr->name()\n+            << \" is directly connected to the current offloaded computation\";\n+        if (should_fuse(*offloaded_call_instr, *instr)) {\n+          bool instr_escapes_offloaded_computation =\n+              absl::c_any_of(instr->users(), [&](const HloInstruction* user) {\n+                return user != offloaded_call_instr && !should_offload(user);\n+              });\n+\n+          VLOG(3) << instr->name() << \" fusing into existing computation\";\n+          VLOG(6) << \"instr_escapes_offloaded_computation: \"\n+                  << instr_escapes_offloaded_computation;\n+\n+          offloaded_call_instr->AppendInstructionIntoCalledComputation(\n+              instr, /*add_output=*/instr_escapes_offloaded_computation);\n+          offloaded_instr = instr;\n+        } else {\n+          unmerged_ancestors.insert(instr);\n+        }\n+        continue;\n+      }\n+\n+      if (should_fuse(*offloaded_call_instr, *instr)) {\n+        VLOG(2) << instr->ToString()\n+                << \" current instruction is disconnected from the current \"\n+                   \"offload computation\";\n+        // If the current instruction is disconnected from the current offload\n+        // computation, include it anyway.\n+        offloaded_call_instr->AppendInstructionIntoCalledComputation(\n+            instr, /*add_output=*/true);\n+        offloaded_instr = instr;\n+      } else {\n+        unmerged_ancestors.insert(instr);\n+      }\n+    }\n+\n+    // If there are no offload instructions left in the computation, stop\n+    // looking.\n+    if (offloaded_call_instr == nullptr) {\n+      break;\n+    }\n+    offloaded_instructions_and_calls.push_back(\n+        std::pair(offloaded_instr, offloaded_call_instr));\n+\n+    for (HloInstruction* instr : computation.instructions()) {\n+      // If an offloaded instruction is a custom call marked with side effects.\n+      // Remove the annotation so it can be properly removed from the\n+      // original computation during DCE.\n+      if (instr->opcode() == HloOpcode::kCustomCall && should_offload(instr)) {\n+        static_cast<HloCustomCallInstruction*>(instr)\n+            ->set_custom_call_has_side_effect(false);\n+      }\n+      // If an offloaded instruction is a Sharding custom call or has control\n+      // dependencies (such as those around elided copies), remove it\n+      // explicitly since it won't be removed by HloDCE.\n+      if (instr->IsDead() && (instr->IsCustomCall(\"Sharding\") ||\n+                              (instr->HasControlDependencies() &&\n+                               !instr->HasSuccessorControlDependencies()))) {\n+        TF_RETURN_IF_ERROR(instr->SafelyDropAllControlDependencies());\n+        TF_RETURN_IF_ERROR(computation.RemoveInstruction(instr));\n+      }\n+    }\n+\n+    // DCE any offloaded instructions that have no remaining un-wrapped uses.\n+    TF_RETURN_IF_ERROR(HloDCE().Run(computation.parent()).status());\n+\n+    VLOG(6) << \"After offloading computation after DCE:\";\n+    XLA_VLOG_LINES(6, computation.parent()->ToString());\n+  }\n+  return offloaded_instructions_and_calls;\n+}\n+\n+}  // namespace xla::offloader_util"
        },
        {
            "sha": "3f6ca399d1d3a28574f986d66a8cce766b11774d",
            "filename": "third_party/xla/xla/hlo/transforms/offloaded_instruction_wrapper.h",
            "status": "added",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Foffloaded_instruction_wrapper.h?ref=b1d9f001ec8c0666966c89e5d4fe4197a18e6ec7",
            "patch": "@@ -0,0 +1,52 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_TRANSFORMS_OFFLOADED_INSTRUCTION_WRAPPER_H_\n+#define XLA_HLO_TRANSFORMS_OFFLOADED_INSTRUCTION_WRAPPER_H_\n+\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/functional/function_ref.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n+\n+namespace xla::offloader_util {\n+\n+absl::Status RecursivelyClearComputeTypeFrontendAttribute(\n+    HloComputation* computation);\n+\n+// Attempts to create computations islands out of a connected set of\n+// instructions that satisfy `should_offload`.\n+// Returns a vector of pairs, where the first element is the offloaded\n+// instruction and the second element is its replacement, namely the call to the\n+// newly created computation that contains the offloaded instruction.\n+absl::StatusOr<std::vector<std::pair<HloInstruction*, HloCallInstruction*>>>\n+FindAndWrapOffloadedComputations(\n+    HloComputation& computation,\n+    absl::FunctionRef<bool(const HloInstruction*)> should_offload,\n+    absl::FunctionRef<bool(const HloInstruction&, const HloInstruction&)>\n+        should_fuse,\n+    absl::FunctionRef<absl::Status(HloInstruction*)>\n+        clear_backend_config_device_type,\n+    absl::string_view new_call_name_prefix);\n+\n+}  // namespace xla::offloader_util\n+\n+#endif  // XLA_HLO_TRANSFORMS_OFFLOADED_INSTRUCTION_WRAPPER_H_"
        }
    ],
    "stats": {
        "total": 295,
        "additions": 295,
        "deletions": 0
    }
}