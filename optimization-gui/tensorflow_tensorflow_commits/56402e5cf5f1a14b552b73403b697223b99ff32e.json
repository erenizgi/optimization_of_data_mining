{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Remove xtile.to_tensor/scalar.\n\nThese ops were implemented as a quick stop gap to enable less test churn as they had symmetric folding but the tensor equivalent have more well defined semantics, obvious lowering patterns and will generally just make CPU lowering simpler.\n\nPiperOrigin-RevId: 830399434",
    "sha": "56402e5cf5f1a14b552b73403b697223b99ff32e",
    "files": [
        {
            "sha": "54dce50a3300f354d1eb17865375975934c891d5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 23,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -185,16 +185,6 @@ namespace {\n \n using TensorValue = mlir::TypedValue<mlir::RankedTensorType>;\n \n-// Create a tensor from the passed value.\n-// If the passed value is a scalar, it is wrapped in a ToTensorOp to create a\n-// 0D-Tensor else it is returned as is.\n-TensorValue MakeTensor(EmitterLocOpBuilder& b, mlir::Value value) {\n-  if (auto tensor = mlir::dyn_cast<TensorValue>(value)) {\n-    return tensor;\n-  }\n-  return mlir::cast<TensorValue>(b.createOrFold<xtile::ToTensorOp>(value));\n-}\n-\n Value MakeIndex(EmitterLocOpBuilder& b, int64_t value) {\n   return b.create<arith::ConstantIndexOp>(value);\n }\n@@ -330,7 +320,12 @@ TensorValue BroadcastInDims(EmitterLocOpBuilder b, TensorValue value,\n \n TensorValue Splat(EmitterLocOpBuilder b, Value value,\n                   ArrayRef<int64_t> output_shape) {\n-  return BroadcastInDims(b, MakeTensor(b, value), output_shape, /*dims=*/{});\n+  auto tensor_value = mlir::dyn_cast<TensorValue>(value);\n+  if (!tensor_value) {\n+    tensor_value = b.create<mlir::tensor::FromElementsOp>(\n+        mlir::RankedTensorType::get({}, value.getType()), value);\n+  }\n+  return BroadcastInDims(b, tensor_value, output_shape, /*dims=*/{});\n }\n \n TensorValue Iota(EmitterLocOpBuilder b, int32_t limit) {\n@@ -561,7 +556,7 @@ SmallVector<Value> GetRuntimeValues(\n       mlir::OpBuilder builder(value.getContext());\n       builder.setInsertionPointAfterValue(value);\n       runtime_values.push_back(\n-          xtile::ToScalarOp::create(builder, value.getLoc(), value));\n+          mlir::tensor::ExtractOp::create(builder, value.getLoc(), value));\n     }\n   }\n   return runtime_values;\n@@ -662,9 +657,9 @@ absl::StatusOr<TensorValue> EmitTiledBitcast(\n   if (ShapeUtil::Equal(trt->transpose1_shape, trt->reshape_shape)) {\n     normalized_reshape = normalized_input;\n   } else {\n-    TF_ASSIGN_OR_RETURN(normalized_reshape,\n-                        EmitTiledReshape(b, reshape_tile_sizes,\n-                                         MakeTensor(b, normalized_input)));\n+    TF_ASSIGN_OR_RETURN(\n+        normalized_reshape,\n+        EmitTiledReshape(b, reshape_tile_sizes, normalized_input));\n   }\n \n   // The final transpose simply uses the tile sizes computed for the original\n@@ -919,7 +914,7 @@ absl::StatusOr<TensorValue> EmitDot(\n   // and the dot's output type does not match its expectations.\n   TF_ASSIGN_OR_RETURN(Type accumulator_type,\n                       triton::GetDotAccumulatorType(b, dot));\n-  Value accumulator =\n+  TensorValue accumulator =\n       CreateConst(b, accumulator_type, 0.0f, padded_tile_sizes_no_unit_dims);\n \n   TF_ASSIGN_OR_RETURN(int64_t loop_iteration_count,\n@@ -1012,12 +1007,13 @@ absl::StatusOr<TensorValue> EmitDot(\n     result = Cast(b, result, dot_output_type);\n   }\n \n+  auto tensor_result = mlir::cast<TensorValue>(result);\n+\n   if (padded_tile_sizes.size() != padded_tile_sizes_no_unit_dims.size()) {\n-    TF_ASSIGN_OR_RETURN(\n-        result, EmitTiledReshape(b, padded_tile_sizes, MakeTensor(b, result)));\n+    return EmitTiledReshape(b, padded_tile_sizes, tensor_result);\n   }\n \n-  return MakeTensor(b, result);\n+  return tensor_result;\n }\n \n absl::StatusOr<TensorValue> EmitScaledDot(\n@@ -1054,7 +1050,7 @@ absl::StatusOr<TensorValue> EmitScaledDot(\n   }\n \n   Type accumulator_type = b.getF32Type();\n-  Value accumulator =\n+  TensorValue accumulator =\n       CreateConst(b, accumulator_type, 0.0f, padded_tile_sizes_no_unit_dims);\n \n   TF_ASSIGN_OR_RETURN(int64_t loop_iteration_count,\n@@ -1165,12 +1161,13 @@ absl::StatusOr<TensorValue> EmitScaledDot(\n     result = Cast(b, result, dot_output_type);\n   }\n \n+  auto tensor_result = mlir::cast<TensorValue>(result);\n+\n   if (padded_tile_sizes.size() != padded_tile_sizes_no_unit_dims.size()) {\n-    TF_ASSIGN_OR_RETURN(\n-        result, EmitTiledReshape(b, padded_tile_sizes, MakeTensor(b, result)));\n+    return EmitTiledReshape(b, padded_tile_sizes, tensor_result);\n   }\n \n-  return MakeTensor(b, result);\n+  return tensor_result;\n }\n \n absl::StatusOr<TensorValue> EmitConcatenate("
        },
        {
            "sha": "894c7761c93155fd8c58fdf6d6ec9e4e35dcf90d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -510,8 +510,8 @@ CHECK:  xtile.insert %[[ABS]]\n CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n CHECK:  %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 0 : i32}>\n-CHECK: %[[SCALAR_TENSOR:.*]] = xtile.to_tensor %[[REDUCE]] : f32\n-CHECK: xtile.insert %[[SCALAR_TENSOR]] into %arg1\n+CHECK: %[[REDUCE_TENSOR:.*]] = tensor.from_elements %[[REDUCE]] : tensor<f32>\n+CHECK: xtile.insert %[[REDUCE_TENSOR]] into %arg1\n CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<512xf32>\n )\",\n       GetFusionInstruction(*xtile_module_and_hlo_module.second,\n@@ -2039,8 +2039,8 @@ ENTRY main {\n // CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n // CHECK: %[[C17:.*]] = arith.constant 17 : i32\n // CHECK: %[[THRESHOLD:.*]] = arith.subi %[[C17]], %[[TILE_OFFSET_I32]]\n-// CHECK: %[[TO_TENSOR_THRESHOLD:.*]] = xtile.to_tensor %[[THRESHOLD]]\n-// CHECK: %[[THRESHOLD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[TO_TENSOR_THRESHOLD]], dims = []\n+// CHECK: %[[THRESHOLD_TENSOR:.*]] = tensor.from_elements %[[THRESHOLD]]\n+// CHECK: %[[THRESHOLD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[THRESHOLD_TENSOR]], dims = []\n // CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]\n // CHECK: %[[PAD_SPLAT:.*]] = stablehlo.broadcast_in_dim %[[PAD_VALUE]], dims = []\n // CHECK: %[[SELECT:.*]] = arith.select %[[MASK]], %[[EXTRACT]], %[[PAD_SPLAT]]"
        },
        {
            "sha": "76a223fea3d0d7cf574dbb026a92a4f59dd0fb4d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -62,7 +62,6 @@ cc_library(\n         \"//xla/codegen/xtile/ir:xtile\",\n         \"//xla/service/gpu:target_util\",\n         \"//xla/service/llvm_ir:llvm_util\",\n-        \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"@com_google_absl//absl/algorithm:container\","
        },
        {
            "sha": "c73a5f953bc4d0e5812c2f32f608a543a864679d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 11,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -21,7 +21,9 @@ limitations under the License.\n #include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/Support/Casting.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/Diagnostics.h\"\n@@ -116,8 +118,8 @@ class LowerBroadcastInDim\n     if (input_shape.empty()) {\n       auto broadcast_dim_input = op.getOperand();\n \n-      auto extracted = ::xla::xtile::ToScalarOp::create(rewriter, op.getLoc(),\n-                                                        broadcast_dim_input);\n+      auto extracted = mlir::tensor::ExtractOp::create(rewriter, op.getLoc(),\n+                                                       broadcast_dim_input);\n \n       rewriter.replaceOpWithNewOp<ttir::SplatOp>(op, op.getResult().getType(),\n                                                  extracted);\n@@ -191,8 +193,8 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n     for (auto [old_arg, new_arg] :\n          llvm::zip(old_block.getArguments(),\n                    triton_reduce_region_block.getArguments())) {\n-      auto to_tensor_op =\n-          ::xla::xtile::ToTensorOp::create(rewriter, op.getLoc(), new_arg);\n+      auto to_tensor_op = mlir::tensor::FromElementsOp::create(\n+          rewriter, op.getLoc(), old_arg.getType(), new_arg);\n       mapping.map(old_arg, to_tensor_op);\n     }\n \n@@ -202,7 +204,7 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n \n     SmallVector<Value> return_operands;\n     for (Value operand : old_block.getTerminator()->getOperands()) {\n-      return_operands.push_back(::xla::xtile::ToScalarOp::create(\n+      return_operands.push_back(mlir::tensor::ExtractOp::create(\n           rewriter, op->getLoc(), mapping.lookup(operand)));\n     }\n     ttir::ReduceReturnOp::create(rewriter, op.getLoc(), return_operands);\n@@ -216,8 +218,8 @@ class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n       if (mlir::isa<mlir::ShapedType>(triton_result.getType())) {\n         new_results.push_back(triton_result);\n       } else {\n-        new_results.push_back(::xla::xtile::ToTensorOp::create(\n-            rewriter, op.getLoc(), triton_result));\n+        new_results.push_back(mlir::tensor::FromElementsOp::create(\n+            rewriter, op.getLoc(), op.getType(0), triton_result));\n       }\n     }\n \n@@ -260,8 +262,8 @@ class LowerReshape : public mlir::OpRewritePattern<stablehlo::ReshapeOp> {\n     }\n \n     if (input_is_0d) {\n-      auto to_scalar = ::xla::xtile::ToScalarOp::create(rewriter, op->getLoc(),\n-                                                        op.getOperand());\n+      auto to_scalar = mlir::tensor::ExtractOp::create(rewriter, op->getLoc(),\n+                                                       op.getOperand());\n       rewriter.replaceOpWithNewOp<ttir::SplatOp>(op, op.getType(), to_scalar);\n       return mlir::success();\n     }\n@@ -318,8 +320,8 @@ class LowerReshape : public mlir::OpRewritePattern<stablehlo::ReshapeOp> {\n     ttir::ReduceReturnOp::create(rewriter, result.getLoc(), {result});\n \n     rewriter.setInsertionPointAfter(reduction);\n-    rewriter.replaceOpWithNewOp<::xla::xtile::ToTensorOp>(\n-        op, reduction.getResult());\n+    rewriter.replaceOpWithNewOp<mlir::tensor::FromElementsOp>(\n+        op, op.getType(), reduction.getResult());\n \n     return mlir::success();\n   }"
        },
        {
            "sha": "d367ca8b1ea5e433179ae99ef300f1754d80ac5f",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tensor_lower_to_triton.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftensor_lower_to_triton.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -47,7 +47,7 @@ class LowerBitcast : public mlir::OpRewritePattern<tensor::BitcastOp> {\n       tensor::BitcastOp op, mlir::PatternRewriter& rewriter) const override {\n     mlir::Value source = op.getSource();\n     if (op.getSource().getType().getRank() == 0) {\n-      source = ::xla::xtile::ToScalarOp::create(rewriter, op.getLoc(), source);\n+      source = mlir::tensor::ExtractOp::create(rewriter, op.getLoc(), source);\n     }\n \n     mlir::TensorType tensor_result_type = op.getResult().getType();\n@@ -60,7 +60,8 @@ class LowerBitcast : public mlir::OpRewritePattern<tensor::BitcastOp> {\n \n     mlir::Value result = bitcast.getResult();\n     if (is_0d_result) {\n-      result = ::xla::xtile::ToTensorOp::create(rewriter, op.getLoc(), result);\n+      result = mlir::tensor::FromElementsOp::create(rewriter, op.getLoc(),\n+                                                    tensor_result_type, result);\n     }\n \n     rewriter.replaceOp(op, result);"
        },
        {
            "sha": "fd91132cd75952a6bc8fd06011dda5dbe379bb9d",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 24,
            "deletions": 36,
            "changes": 60,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -46,9 +46,9 @@ func.func @lower_broadcast_in_dim(%arg0: tensor<2x4xf32>) -> tensor<8x2x4x16xf32\n \n // CHECK: func @lower_broadcast_in_dim_on_0d_tensor_produced_by_to_tensor_to_splat(%[[ARG0:.*]]: f32) -> tensor<4x2xf32>\n func.func @lower_broadcast_in_dim_on_0d_tensor_produced_by_to_tensor_to_splat(%arg0: f32) -> tensor<4x2xf32> {\n-  // CHECK-NOT: xtile.to_tensor\n+  // CHECK-NOT: tensor.from_elements\n   // CHECK: %[[RES:.*]] = tt.splat %[[ARG0]] : f32 -> tensor<4x2xf32>\n-  %to_tensor = xtile.to_tensor %arg0 : f32\n+  %to_tensor = tensor.from_elements %arg0 : tensor<f32>\n   %0 = stablehlo.broadcast_in_dim %to_tensor, dims = [] : (tensor<f32>) -> tensor<4x2xf32>\n   // CHECK: return %[[RES]] : tensor<4x2xf32>\n   return %0 : tensor<4x2xf32>\n@@ -61,13 +61,13 @@ func.func @reduce(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n   %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n   //CHECK: ^bb0(%[[ARG1:.*]]: f32, %[[ARG2:.*]]: f32):\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n-    // CHECK: tt.reduce.return %[[RES]] : f32\n-    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n-    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n-    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = xtile.to_tensor %2 : f32\n-    stablehlo.return %3 : tensor<f32>\n+    // CHECK: %[[ARG1_CAST:.*]] = tensor.from_elements %[[ARG1]] : tensor<f32>\n+    // CHECK: %[[ARG2_CAST:.*]] = tensor.from_elements %[[ARG2]] : tensor<f32>\n+    // CHECK: %[[RES:.*]] = arith.addf %[[ARG1_CAST]], %[[ARG2_CAST]] : tensor<f32>\n+    // CHECK: %[[RES_CAST:.*]] = tensor.extract %[[RES]][] : tensor<f32>\n+    // CHECK: tt.reduce.return %[[RES_CAST]] : f32\n+    %add = arith.addf %arg1, %arg2 : tensor<f32>\n+    stablehlo.return %add : tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n   return %1 : tensor<8xf32>\n }\n@@ -79,17 +79,14 @@ func.func @reduce_to_scalar_followed_by_extract(%arg0: tensor<16xf32>) -> f32 {\n   %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n   //CHECK: ^bb0(%[[ARG1:.*]]: f32, %[[ARG2:.*]]: f32):\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n-    // CHECK: tt.reduce.return %[[RES]] : f32\n-    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n-    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n-    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = xtile.to_tensor %2 : f32\n-    stablehlo.return %3 : tensor<f32>\n+    // CHECK: %[[RES:.*]] = arith.addf {{.*}} : tensor<f32>\n+    // CHECK: tt.reduce.return {{.*}} : f32\n+    %add = arith.addf %arg1, %arg2 : tensor<f32>\n+    stablehlo.return %add : tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n-  // CHECK-NOT: xtile.to_tensor\n-  // CHECK-NOT: xtile.to_scalar\n-  %extract = xtile.to_scalar %1 : tensor<f32>\n+  // CHECK-NOT: tensor.from_elements\n+  // CHECK-NOT: tensor.extract\n+  %extract = tensor.extract %1[] : tensor<f32>\n   // CHECK: return %[[REDUCE_RESULT:.*]] : f32\n   return %extract : f32\n }\n@@ -100,11 +97,8 @@ func.func @reduce_over_multiple_dimensions_falls_back_to_stablehlo(%arg0: tensor\n   // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) across dimensions = [0, 1] : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n   %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n   ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n-    %extracted_arg1 = xtile.to_scalar %arg1 : tensor<f32>\n-    %extracted_arg2 = xtile.to_scalar %arg2 : tensor<f32>\n-    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n-    %3 = xtile.to_tensor %2 : f32\n-    stablehlo.return %3 : tensor<f32>\n+    %add = arith.addf %arg1, %arg2 : tensor<f32>\n+    stablehlo.return %add : tensor<f32>\n   }) {dimensions = array<i64: 0, 1>} : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n   // CHECK: return %[[RES]] : tensor<4xf32>\n   return %1 : tensor<4xf32>\n@@ -116,15 +110,9 @@ func.func @reduce_with_multiple_inputs(%arg0: tensor<16x8xf32>, %arg1: tensor<16\n   // CHECK: %[[REDUCE_RESULT:.*]] = \"tt.reduce\"(%[[ARG0]], %[[ARG1]]) <{axis = 0 : i32}> ({\n   %1, %2 = \"stablehlo.reduce\"(%arg0, %arg1, %0, %0) ({\n   ^bb0(%arg0_reducer: tensor<f32>, %arg1_reducer: tensor<f32>, %arg2_reducer: tensor<f32>, %arg3_reducer: tensor<f32>):\n-    %extracted_arg0 = xtile.to_scalar %arg0_reducer : tensor<f32>\n-    %extracted_arg1 = xtile.to_scalar %arg1_reducer : tensor<f32>\n-    %2 = arith.addf %extracted_arg0, %extracted_arg1 : f32\n-    %3 = xtile.to_tensor %2 : f32\n-    %extracted_arg2 = xtile.to_scalar %arg2_reducer : tensor<f32>\n-    %extracted_arg3 = xtile.to_scalar %arg3_reducer : tensor<f32>\n-    %4 = arith.addf %extracted_arg2, %extracted_arg3 : f32\n-    %5 = xtile.to_tensor %4 : f32\n-    stablehlo.return %3, %5 : tensor<f32>, tensor<f32>\n+    %add0 = arith.addf %arg0_reducer, %arg1_reducer : tensor<f32>\n+    %add1 = arith.addf %arg2_reducer, %arg3_reducer : tensor<f32>\n+    stablehlo.return %add0, %add1 : tensor<f32>, tensor<f32>\n   }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<16x8xf32>, tensor<f32>, tensor<f32>) -> (tensor<8xf32>, tensor<8xf32>)\n   return %1 : tensor<8xf32>\n }\n@@ -144,7 +132,7 @@ func.func @reshape_0d_to_0d_folds(%arg0: tensor<f32>) -> tensor<f32> {\n \n // CHECK-LABEL: @reshape_0d_to_2d_splats(%arg0: tensor<f32>)\n func.func @reshape_0d_to_2d_splats(%arg0: tensor<f32>) -> tensor<1x1xf32> {\n-  // CHECK: %[[SCALAR:.*]] = xtile.to_scalar %arg0 : tensor<f32>\n+  // CHECK: %[[SCALAR:.*]] = tensor.extract %arg0[] : tensor<f32>\n   // CHECK: %[[SPLAT:.*]] = tt.splat %[[SCALAR]] : f32 -> tensor<1x1xf32>\n   %0 = stablehlo.reshape %arg0 : (tensor<f32>) -> tensor<1x1xf32>\n   // CHECK: return %[[SPLAT]]\n@@ -159,8 +147,8 @@ func.func @reshape_2d_to_0d_reduces(%arg0: tensor<1x1xf32>) -> tensor<f32> {\n   // CHECK:    %[[ADD:.*]] = arith.addf %arg1, %arg2 : f32\n   // CHECK:    tt.reduce.return %[[ADD]] : f32\n   // CHECK:  }) : (tensor<1xf32>) -> f32\n-  // CHECK:  %[[TO_TENSOR:.*]] = xtile.to_tensor %[[REDUCE]] : f32\n+  // CHECK:  %[[REDUCE_TENSOR:.*]] = tensor.from_elements %[[REDUCE]] : tensor<f32>\n   %0 = stablehlo.reshape %arg0 : (tensor<1x1xf32>) -> tensor<f32>\n-  // CHECK: return %[[TO_TENSOR]]\n+  // CHECK: return %[[REDUCE_TENSOR]]\n   return %0 : tensor<f32>\n }"
        },
        {
            "sha": "76412bc44997c8f2a3621b25616b2bdcc0c14c5c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/tensor_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftensor_to_triton_lowering.mlir?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -14,9 +14,9 @@ func.func @lower_bitcast(%arg0: tensor<2x4x8xf32>) -> tensor<2x4x8xi32> {\n \n // CHECK: func @lower_bitcast_0d(%[[ARG:.*]]: tensor<f32>) -> tensor<i32>\n func.func @lower_bitcast_0d(%arg0: tensor<f32>) -> tensor<i32> {\n-  // CHECK: %[[SCALAR_ARG:.*]] = xtile.to_scalar %[[ARG]] : tensor<f32>\n+  // CHECK: %[[SCALAR_ARG:.*]] = tensor.extract %[[ARG]][] : tensor<f32>\n   // CHECK: %[[RES:.*]] = tt.bitcast %[[SCALAR_ARG]] : f32 -> i32\n-  // CHECK: %[[TENSOR_RES:.*]] = xtile.to_tensor %[[RES]] : i32\n+  // CHECK: %[[TENSOR_RES:.*]] = tensor.from_elements %[[RES]] : tensor<i32>\n   %0 = tensor.bitcast %arg0 : tensor<f32> to tensor<i32>\n   // CHECK: return %[[TENSOR_RES]] : tensor<i32>\n   return %0 : tensor<i32>"
        },
        {
            "sha": "eefd68ef4d18e6b414c3a0581f1ebb8374d32217",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_convert_tensor_to_scalar_pass.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_tensor_to_scalar_pass.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <utility>\n \n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n@@ -105,7 +106,8 @@ struct TritonXLAConvert0DTensorToScalarPass\n           if (inputs.size() != 1) {\n             return nullptr;\n           }\n-          return ::xla::xtile::ToTensorOp::create(builder, loc, inputs.front());\n+          return mlir::tensor::FromElementsOp::create(builder, loc, result_type,\n+                                                      inputs.front());\n         });\n \n     type_converter.addTargetMaterialization(\n@@ -114,7 +116,7 @@ struct TritonXLAConvert0DTensorToScalarPass\n           if (inputs.size() != 1) {\n             return nullptr;\n           }\n-          return ::xla::xtile::ToScalarOp::create(builder, loc, inputs.front());\n+          return mlir::tensor::ExtractOp::create(builder, loc, inputs.front());\n         });\n \n     mlir::ConversionTarget target(getContext());"
        },
        {
            "sha": "db583e0bd767d85ed83c5e26d6e0beb52cb9a1b5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_xtile_pass.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n@@ -220,13 +221,13 @@ class XTileExtractToTriton\n     mlir::Value memref_to_ptr =\n         CreateMemrefToPtr(rewriter, extract_op.getSource());\n \n-    if (extract_op.getType().getRank() == 0) {\n+    if (result_type.getRank() == 0) {\n       mlir::Value scalar_value = rewriter.create<ttir::LoadOp>(\n           extract_op->getLoc(), memref_to_ptr, ttir::CacheModifier::NONE,\n           ttir::EvictionPolicy::NORMAL, /*isVolatile=*/false);\n \n-      rewriter.replaceOpWithNewOp<::xla::xtile::ToTensorOp>(extract_op,\n-                                                            scalar_value);\n+      rewriter.replaceOpWithNewOp<mlir::tensor::FromElementsOp>(\n+          extract_op, result_type, scalar_value);\n       return mlir::success();\n     }\n \n@@ -263,7 +264,7 @@ class XTileInsertToTriton\n         CreateMemrefToPtr(rewriter, insert_op.getDestination());\n \n     if (insert_op.getSource().getType().getRank() == 0) {\n-      mlir::Value scalar_value = ::xla::xtile::ToScalarOp::create(\n+      mlir::Value scalar_value = mlir::tensor::ExtractOp::create(\n           rewriter, insert_op.getLoc(), insert_op.getSource());\n \n       rewriter.replaceOpWithNewOp<ttir::StoreOp>("
        },
        {
            "sha": "714bdbf033fc51d6d4c3b43447b44d0287621faa",
            "filename": "third_party/xla/xla/codegen/xtile/ir/tests/to_from_tensor.mlir",
            "status": "removed",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/088b21c29e0fdc058835145776cd27d8adb12686/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fto_from_tensor.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/088b21c29e0fdc058835145776cd27d8adb12686/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fto_from_tensor.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Ftests%2Fto_from_tensor.mlir?ref=088b21c29e0fdc058835145776cd27d8adb12686",
            "patch": "@@ -1,17 +0,0 @@\n-// RUN: emitters_opt %s  -canonicalize | FileCheck %s\n-\n-// CHECK-LABEL: @to_scalar_roundtrip\n-func.func @to_scalar_roundtrip(%arg0: tensor<i32>) -> tensor<i32> {\n-  %0 = xtile.to_scalar %arg0 : tensor<i32>\n-  %1 = xtile.to_tensor %0 : i32\n-  // CHECK: return %arg0 : tensor<i32>\n-  return %1 : tensor<i32>\n-}\n-\n-// CHECK-LABEL: @to_tensor_roundtrip\n-func.func @to_tensor_roundtrip(%arg0: i32) -> i32 {\n-  %0 = xtile.to_tensor %arg0 : i32\n-  %1 = xtile.to_scalar %0 : tensor<i32>\n-  // CHECK: return %arg0 : i32\n-  return %1 : i32\n-}"
        },
        {
            "sha": "af712066db5ece40fc4ce4af57eabefbd2a81d44",
            "filename": "third_party/xla/xla/codegen/xtile/ir/xtile_ops.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 54,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.cc?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -198,58 +198,4 @@ mlir::TypedValue<mlir::RankedTensorType> InsertTileOp::getTile() {\n \n mlir::LogicalResult InsertTileOp::verify() { return VerifyBufferOp(*this); }\n \n-mlir::LogicalResult ToScalarOp::inferReturnTypes(\n-    mlir::MLIRContext* context, ::std::optional<mlir::Location> location,\n-    mlir::ValueRange operands, mlir::DictionaryAttr attributes,\n-    mlir::OpaqueProperties properties, mlir::RegionRange regions,\n-    ::llvm::SmallVectorImpl<mlir::Type>& inferredReturnTypes) {\n-  if (operands.size() != 1) {\n-    return mlir::failure();\n-  }\n-\n-  auto tensor_type =\n-      mlir::dyn_cast<mlir::RankedTensorType>(operands[0].getType());\n-  if (!tensor_type) {\n-    return mlir::failure();\n-  }\n-\n-  if (tensor_type.getRank() != 0) {\n-    return mlir::failure();\n-  }\n-\n-  inferredReturnTypes.push_back(tensor_type.getElementType());\n-  return mlir::success();\n-}\n-\n-mlir::OpFoldResult ToScalarOp::fold(FoldAdaptor adaptor) {\n-  if (auto to_tensor = getOperand().getDefiningOp<ToTensorOp>()) {\n-    // to_scalar(to_tensor(x)) -> x\n-    return to_tensor.getOperand();\n-  }\n-\n-  return {};\n-}\n-\n-mlir::LogicalResult ToTensorOp::inferReturnTypes(\n-    mlir::MLIRContext* context, ::std::optional<mlir::Location> location,\n-    mlir::ValueRange operands, mlir::DictionaryAttr attributes,\n-    mlir::OpaqueProperties properties, mlir::RegionRange regions,\n-    ::llvm::SmallVectorImpl<mlir::Type>& inferredReturnTypes) {\n-  if (operands.size() != 1) {\n-    return mlir::failure();\n-  }\n-  inferredReturnTypes.push_back(\n-      mlir::RankedTensorType::get({}, operands[0].getType()));\n-  return mlir::success();\n-}\n-\n-mlir::OpFoldResult ToTensorOp::fold(FoldAdaptor adaptor) {\n-  if (auto to_scalar = getOperand().getDefiningOp<ToScalarOp>()) {\n-    // to_tensor(to_scalar(x)) -> x\n-    return to_scalar.getOperand();\n-  }\n-\n-  return {};\n-}\n-\n }  // namespace xla::xtile"
        },
        {
            "sha": "617eb535cb77876718b53153f655aaf208be1d3e",
            "filename": "third_party/xla/xla/codegen/xtile/ir/xtile_ops.td",
            "status": "modified",
            "additions": 0,
            "deletions": 21,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56402e5cf5f1a14b552b73403b697223b99ff32e/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fcodegen%2Fxtile%2Fir%2Fxtile_ops.td?ref=56402e5cf5f1a14b552b73403b697223b99ff32e",
            "patch": "@@ -212,27 +212,6 @@ def InsertTileOp : XTile_Op<\"insert\", [TiledBufferInterface]> {\n   let hasVerifier = 1;\n }\n \n-// TODO(willfroom): Revisit if/where these are needed after the migration of the\n-// triton emitter to support 0D tensors is complete.\n-def ToScalarOp : XTile_Op<\"to_scalar\", [Pure, DeclareOpInterfaceMethods<InferTypeOpInterface>]> {\n-  let summary = \"Converts a 0D tensor to a scalar\";\n-  let arguments = (ins 0DTensorOf<[AnyType]>:$input);\n-  let results = (outs AnyType:$output);\n-\n-  let assemblyFormat = \"$input `:` type($input) attr-dict\";\n-\n-  let hasFolder = 1;\n-}\n-\n-def ToTensorOp : XTile_Op<\"to_tensor\", [Pure, DeclareOpInterfaceMethods<InferTypeOpInterface>]> {\n-  let summary = \"Converts a scalar to a 0D tensor\";\n-  let arguments = (ins AnyType:$input);\n-  let results = (outs 0DTensorOf<[AnyType]>:$output);\n-\n-  let assemblyFormat = \"$input `:` type($input) attr-dict\";\n-\n-  let hasFolder = 1;\n-}\n \n #endif // XLA_CODEGEN_XTILE_IR_XTILE_OPS\n "
        }
    ],
    "stats": {
        "total": 252,
        "additions": 75,
        "deletions": 177
    }
}