{
    "author": "unknown",
    "message": "[XLA:GPU] CustomCallThunk: enable use of lambdas with captures\n\nAdd CustomCallThunk::OwnedHandlerBundle, a bag of `unique_ptr<ffi::Ffi>` that\nenable using lambdas with captures in CustomCallThunk. Lambda captures must\noutlive the created thunk.\n\nThe functionality is similar to what is possible with \"old-style\" callbacks,\nbut doesn't depend on them, and adds support for other handlers available via\nXLA_FFI_Handler_Bundle.\n\nPiperOrigin-RevId: 826043689",
    "sha": "a0921d99976c5945c79951e4664313bcadff019f",
    "files": [
        {
            "sha": "ce08225d763c3ab0fc2743c3efd85f03b579aa23",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=a0921d99976c5945c79951e4664313bcadff019f",
            "patch": "@@ -701,6 +701,7 @@ cc_library(\n         \"//xla:executable_run_options\",\n         \"//xla:shape_util\",\n         \"//xla:util\",\n+        \"//xla/ffi\",\n         \"//xla/ffi:attribute_map\",\n         \"//xla/ffi:call_frame\",\n         \"//xla/ffi:execution_context\",\n@@ -720,6 +721,7 @@ cc_library(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n@@ -748,6 +750,7 @@ xla_test(\n         \"//xla/service:executable\",\n         \"//xla/service:platform_util\",\n         \"//xla/service/gpu:buffer_allocations\",\n+        \"//xla/service/gpu:resource_requests\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n         \"//xla/stream_executor:stream\","
        },
        {
            "sha": "facad7c0e5575b97f6362db8d74bc2eee105b454",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk.cc",
            "status": "modified",
            "additions": 156,
            "deletions": 40,
            "changes": 196,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.cc?ref=a0921d99976c5945c79951e4664313bcadff019f",
            "patch": "@@ -22,11 +22,12 @@ limitations under the License.\n #include <optional>\n #include <string>\n #include <utility>\n+#include <variant>\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/nullability.h\"\n #include \"absl/container/inlined_vector.h\"\n-#include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n@@ -41,9 +42,11 @@ limitations under the License.\n #include \"xla/ffi/attribute_map.h\"\n #include \"xla/ffi/call_frame.h\"\n #include \"xla/ffi/execution_state.h\"\n+#include \"xla/ffi/ffi.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/primitive_util.h\"\n+#include \"xla/runtime/object_pool.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_status_internal.h\"\n@@ -250,6 +253,44 @@ absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::Create(\n       std::move(attributes), std::move(execution_state), called_computation));\n }\n \n+absl::StatusOr<std::unique_ptr<CustomCallThunk>> CustomCallThunk::Create(\n+    ThunkInfo thunk_info, std::string target_name, OwnedHandlerBundle bundle,\n+    std::vector<std::optional<ShapedSlice>> operands,\n+    std::vector<std::optional<ShapedSlice>> results,\n+    xla::ffi::AttributesMap attributes,\n+    const HloComputation* called_computation) {\n+  if (!bundle.execute) {\n+    return absl::InvalidArgumentError(\n+        \"Execute handler is required for a CustomCallThunk\");\n+  }\n+\n+  auto execution_state = std::make_unique<ffi::ExecutionState>();\n+  // Initialize FFI handler state if it has an instantiate callback.\n+  if (bundle.instantiate) {\n+    // At FFI handler instantiation time, we don't have any arguments or\n+    // results or access to the underlying device (stream, etc.)\n+    CallFrameBuilder builder(/*num_args=*/0, /*num_rets=*/0);\n+\n+    CallFrameBuilder::AttributesBuilder attrs;\n+    attrs.Append(attributes);\n+\n+    builder.AddAttributes(attrs.Build());\n+    CallFrame call_frame = builder.Build();\n+\n+    CallOptions options;\n+    options.execution_state = execution_state.get();\n+    TF_RETURN_IF_ERROR(Call(*bundle.instantiate, call_frame, options,\n+                            xla::ffi::ExecutionStage::kInstantiate));\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(CallFrame call_frame,\n+                      BuildCallFramePrototype(operands, results, attributes));\n+  return absl::WrapUnique(new CustomCallThunk(\n+      thunk_info, std::move(target_name), std::move(bundle),\n+      std::move(operands), std::move(results), std::move(call_frame),\n+      std::move(attributes), std::move(execution_state), called_computation));\n+}\n+\n CustomCallThunk::CustomCallThunk(\n     ThunkInfo thunk_info, std::string target_name,\n     std::vector<std::optional<ShapedSlice>> operands,\n@@ -266,7 +307,7 @@ CustomCallThunk::CustomCallThunk(\n \n CustomCallThunk::CustomCallThunk(\n     ThunkInfo thunk_info, std::string target_name,\n-    XLA_FFI_Handler_Bundle bundle,\n+    std::variant<XLA_FFI_Handler_Bundle, OwnedHandlerBundle> bundle,\n     std::vector<std::optional<ShapedSlice>> operands,\n     std::vector<std::optional<ShapedSlice>> results, CallFrame call_frame,\n     ffi::AttributesMap attributes,\n@@ -317,18 +358,9 @@ absl::Status CustomCallThunk::ExecuteCustomCall(const ExecuteParams& params) {\n   return absl::OkStatus();\n }\n \n-absl::Status CustomCallThunk::ExecuteFfiHandler(\n-    RunId run_id, XLA_FFI_Handler* handler, XLA_FFI_ExecutionStage stage,\n-    se::Stream* stream, const ffi::ExecutionContext* execution_context,\n-    const BufferAllocations* buffer_allocations) {\n-  if (handler == nullptr) {\n-    return absl::InternalError(\"FFI execute handler is not set\");\n-  }\n-  if (stage != XLA_FFI_ExecutionStage_PREPARE &&\n-      !(buffer_allocations && stream)) {\n-    return absl::InternalError(\"buffer allocations and stream are required\");\n-  }\n-\n+absl::StatusOr<ObjectPool<CallFrame>::BorrowedObject>\n+CustomCallThunk::BuildCallFrame(\n+    const BufferAllocations* absl_nullable buffer_allocations) {\n   auto device_memory = [&](BufferAllocation::Slice slice) {\n     return buffer_allocations ? buffer_allocations->GetDeviceAddress(slice)\n                               : se::DeviceMemoryBase{};\n@@ -360,58 +392,142 @@ absl::Status CustomCallThunk::ExecuteFfiHandler(\n   // device memory addresses.\n   TF_ASSIGN_OR_RETURN(auto call_frame, call_frames_->GetOrCreate());\n   TF_RETURN_IF_ERROR(call_frame->UpdateWithBuffers(arguments, results));\n+  return call_frame;\n+}\n \n+CallOptions CustomCallThunk::BuildCallOptions(\n+    RunId run_id, se::Stream* absl_nullable stream,\n+    const BufferAllocations* absl_nullable buffer_allocations,\n+    const ffi::ExecutionContext* absl_nonnull execution_context) {\n   int32_t device_ordinal = -1;\n   se::DeviceMemoryAllocator* allocator = nullptr;\n-  if (stage != XLA_FFI_ExecutionStage_PREPARE) {\n+  if (buffer_allocations != nullptr) {\n     device_ordinal = buffer_allocations->device_ordinal();\n     allocator = buffer_allocations->memory_allocator();\n   }\n \n-  CallOptions options = {run_id,\n-                         device_ordinal,\n-                         CallOptions::GpuOptions{stream, allocator},\n-                         called_computation_,\n-                         execution_context,\n-                         execution_state_.get()};\n+  return CallOptions{run_id,\n+                     device_ordinal,\n+                     CallOptions::GpuOptions{stream, allocator},\n+                     called_computation_,\n+                     execution_context,\n+                     execution_state_.get()};\n+}\n+\n+absl::Status CustomCallThunk::ExecuteFfiHandler(\n+    RunId run_id, XLA_FFI_Handler* handler, XLA_FFI_ExecutionStage stage,\n+    se::Stream* stream, const ffi::ExecutionContext* execution_context,\n+    const BufferAllocations* buffer_allocations) {\n+  if (handler == nullptr) {\n+    return absl::InternalError(\"FFI execute handler is not set\");\n+  }\n+  if (stage != XLA_FFI_ExecutionStage_PREPARE &&\n+      !(buffer_allocations && stream)) {\n+    return absl::InternalError(\"buffer allocations and stream are required\");\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(auto call_frame, BuildCallFrame(buffer_allocations));\n+  CallOptions options =\n+      BuildCallOptions(run_id, stream, buffer_allocations, execution_context);\n+  return Call(handler, *call_frame, options, stage);\n+}\n+\n+absl::Status CustomCallThunk::ExecuteFfiHandler(\n+    RunId run_id, xla::ffi::Ffi& handler, xla::ffi::ExecutionStage stage,\n+    se::Stream* stream, const ffi::ExecutionContext* execution_context,\n+    const BufferAllocations* buffer_allocations) {\n+  if (stage != xla::ffi::ExecutionStage::kPrepare &&\n+      !(buffer_allocations && stream)) {\n+    return absl::InternalError(\"buffer allocations and stream are required\");\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(auto call_frame, BuildCallFrame(buffer_allocations));\n+  CallOptions options =\n+      BuildCallOptions(run_id, stream, buffer_allocations, execution_context);\n   return Call(handler, *call_frame, options, stage);\n }\n \n absl::Status CustomCallThunk::Prepare(\n     const PrepareParams& params, ResourceRequestsInterface& resource_requests) {\n-  if (!bundle_ || !bundle_->prepare) {\n-    return absl::OkStatus();\n+  if (bundle_.has_value()) {\n+    const RunId run_id =\n+        params.collective_params ? params.collective_params->run_id : RunId{-1};\n+\n+    if (const auto* c_bundle =\n+            std::get_if<XLA_FFI_Handler_Bundle>(&bundle_.value());\n+        c_bundle && c_bundle->prepare) {\n+      return ExecuteFfiHandler(run_id, c_bundle->prepare,\n+                               XLA_FFI_ExecutionStage_PREPARE,\n+                               /*stream=*/nullptr,\n+                               /*execution_context=*/nullptr,\n+                               /*buffer_allocations=*/nullptr);\n+    }\n+    if (const auto* owned_bundle =\n+            std::get_if<OwnedHandlerBundle>(&bundle_.value());\n+        owned_bundle && owned_bundle->prepare) {\n+      return ExecuteFfiHandler(run_id, *owned_bundle->prepare,\n+                               xla::ffi::ExecutionStage::kPrepare,\n+                               /*stream=*/nullptr,\n+                               /*execution_context=*/nullptr,\n+                               /*buffer_allocations=*/nullptr);\n+    }\n   }\n \n-  return ExecuteFfiHandler(\n-      params.collective_params ? params.collective_params->run_id : RunId{-1},\n-      bundle_->prepare, XLA_FFI_ExecutionStage_PREPARE,\n-      /*stream=*/nullptr,\n-      /*execution_context=*/nullptr,\n-      /*buffer_allocations=*/nullptr);\n+  return absl::OkStatus();\n }\n \n absl::Status CustomCallThunk::Initialize(const InitializeParams& params) {\n-  if (!bundle_ || !bundle_->initialize) {\n-    return absl::OkStatus();\n+  if (bundle_.has_value()) {\n+    const RunId run_id =\n+        params.collective_params ? params.collective_params->run_id : RunId{-1};\n+\n+    if (const auto* c_bundle =\n+            std::get_if<XLA_FFI_Handler_Bundle>(&bundle_.value());\n+        c_bundle && c_bundle->initialize) {\n+      return ExecuteFfiHandler(run_id, *c_bundle->initialize,\n+                               XLA_FFI_ExecutionStage_INITIALIZE, params.stream,\n+                               params.ffi_execution_context,\n+                               params.buffer_allocations);\n+    }\n+    if (const auto* owned_bundle =\n+            std::get_if<OwnedHandlerBundle>(&bundle_.value());\n+        owned_bundle && owned_bundle->initialize) {\n+      return ExecuteFfiHandler(run_id, *owned_bundle->initialize,\n+                               xla::ffi::ExecutionStage::kInitialize,\n+                               params.stream, params.ffi_execution_context,\n+                               params.buffer_allocations);\n+    }\n   }\n-\n-  return ExecuteFfiHandler(\n-      params.collective_params ? params.collective_params->run_id : RunId{-1},\n-      bundle_->initialize, XLA_FFI_ExecutionStage_INITIALIZE, params.stream,\n-      params.ffi_execution_context, params.buffer_allocations);\n+  return absl::OkStatus();\n }\n \n absl::Status CustomCallThunk::ExecuteOnStream(const ExecuteParams& params) {\n   TF_ASSIGN_OR_RETURN(\n       se::Stream * stream,\n       GetStreamForExecution(Thunk::execution_stream_id(), params));\n+\n   if (bundle_.has_value()) {\n-    return ExecuteFfiHandler(\n-        params.collective_params ? params.collective_params->run_id : RunId{-1},\n-        bundle_->execute, XLA_FFI_ExecutionStage_EXECUTE, stream,\n-        params.ffi_execution_context, params.buffer_allocations);\n+    const RunId run_id =\n+        params.collective_params ? params.collective_params->run_id : RunId{-1};\n+    if (const auto* c_bundle =\n+            std::get_if<XLA_FFI_Handler_Bundle>(&bundle_.value());\n+        c_bundle) {\n+      return ExecuteFfiHandler(\n+          run_id, c_bundle->execute, XLA_FFI_ExecutionStage_EXECUTE, stream,\n+          params.ffi_execution_context, params.buffer_allocations);\n+    }\n+    if (const auto* owned_bundle =\n+            std::get_if<OwnedHandlerBundle>(&bundle_.value());\n+        owned_bundle) {\n+      if (!owned_bundle->execute) {\n+        return absl::InternalError(\"FFI execute handler is not set\");\n+      }\n+      return ExecuteFfiHandler(\n+          run_id, *owned_bundle->execute, xla::ffi::ExecutionStage::kExecute,\n+          stream, params.ffi_execution_context, params.buffer_allocations);\n+    }\n   }\n+\n   return ExecuteCustomCall(params);\n }\n "
        },
        {
            "sha": "ce8ca0d0ee405816c4665308ed49afac91472b75",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk.h",
            "status": "modified",
            "additions": 57,
            "deletions": 9,
            "changes": 66,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk.h?ref=a0921d99976c5945c79951e4664313bcadff019f",
            "patch": "@@ -21,8 +21,10 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n+#include <variant>\n #include <vector>\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n@@ -33,6 +35,8 @@ limitations under the License.\n #include \"xla/ffi/call_frame.h\"\n #include \"xla/ffi/execution_context.h\"\n #include \"xla/ffi/execution_state.h\"\n+#include \"xla/ffi/ffi.h\"\n+#include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/runtime/object_pool.h\"\n #include \"xla/service/custom_call_status.h\"\n@@ -56,6 +60,17 @@ namespace gpu {\n // compiler is allowed to create.\n class CustomCallThunk : public Thunk {\n  public:\n+  // An owning equivalent of XLA_FFI_Handler_Bundle that allows using lambdas\n+  // with captures.\n+  //\n+  // The members can be initialized with xla::ffi::Ffi::Bind().To(...).\n+  struct OwnedHandlerBundle {\n+    std::unique_ptr<xla::ffi::Ffi> initialize;\n+    std::unique_ptr<xla::ffi::Ffi> instantiate;\n+    std::unique_ptr<xla::ffi::Ffi> prepare;\n+    std::unique_ptr<xla::ffi::Ffi> execute;\n+  };\n+\n   using CustomCallTarget =\n       std::function<void(stream_executor::Stream*, void**, const char*, size_t,\n                          XlaCustomCallStatus*)>;\n@@ -98,14 +113,31 @@ class CustomCallThunk : public Thunk {\n       xla::ffi::AttributesMap attributes,\n       const HloComputation* called_computation);\n \n+  // Creates a custom call thunk from a bundle of handlers created with\n+  // xla::ffi::Bind(). Any pointer or reference lambda captures must be valid\n+  // for the lifetime of the thunk.\n+  static absl::StatusOr<std::unique_ptr<CustomCallThunk>> Create(\n+      ThunkInfo thunk_info, std::string target_name, OwnedHandlerBundle bundle,\n+      std::vector<std::optional<ShapedSlice>> operands,\n+      std::vector<std::optional<ShapedSlice>> results,\n+      xla::ffi::AttributesMap attributes,\n+      const HloComputation* called_computation);\n+\n   absl::Status Prepare(const PrepareParams& params,\n                        ResourceRequestsInterface& resource_requests) override;\n   absl::Status Initialize(const InitializeParams& params) override;\n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n   const std::string& target_name() const { return target_name_; }\n   CustomCallTarget call_target() const { return call_target_; }\n-  std::optional<XLA_FFI_Handler_Bundle> bundle() const { return bundle_; }\n+  std::optional<XLA_FFI_Handler_Bundle> bundle() const {\n+    if (!bundle_.has_value()) {\n+      return std::nullopt;\n+    }\n+    const XLA_FFI_Handler_Bundle* c_bundle =\n+        std::get_if<XLA_FFI_Handler_Bundle>(&bundle_.value());\n+    return c_bundle ? std::make_optional(*c_bundle) : std::nullopt;\n+  }\n   std::optional<ffi::CallFrame> call_frame() const {\n     return call_frame_ ? std::make_optional(call_frame_->Copy()) : std::nullopt;\n   }\n@@ -126,22 +158,37 @@ class CustomCallThunk : public Thunk {\n                   std::string opaque, CustomCallTarget call_target,\n                   const std::optional<CustomCallApiVersion>& api_version);\n \n-  CustomCallThunk(ThunkInfo thunk_info, std::string target_name,\n-                  XLA_FFI_Handler_Bundle bundle,\n-                  std::vector<std::optional<ShapedSlice>> operands,\n-                  std::vector<std::optional<ShapedSlice>> results,\n-                  ffi::CallFrame call_frame, xla::ffi::AttributesMap attributes,\n-                  std::unique_ptr<ffi::ExecutionState> execution_state,\n-                  const HloComputation* called_computation);\n+  CustomCallThunk(\n+      ThunkInfo thunk_info, std::string target_name,\n+      std::variant<XLA_FFI_Handler_Bundle, OwnedHandlerBundle> bundle,\n+      std::vector<std::optional<ShapedSlice>> operands,\n+      std::vector<std::optional<ShapedSlice>> results,\n+      ffi::CallFrame call_frame, xla::ffi::AttributesMap attributes,\n+      std::unique_ptr<ffi::ExecutionState> execution_state,\n+      const HloComputation* called_computation);\n \n   absl::Status ExecuteCustomCall(const ExecuteParams& params);\n \n+  absl::StatusOr<ObjectPool<xla::ffi::CallFrame>::BorrowedObject>\n+  BuildCallFrame(const BufferAllocations* absl_nullable buffer_allocations);\n+\n+  xla::ffi::CallOptions BuildCallOptions(\n+      RunId run_id, se::Stream* absl_nullable stream,\n+      const BufferAllocations* absl_nullable buffer_allocations,\n+      const ffi::ExecutionContext* absl_nonnull execution_context);\n+\n   absl::Status ExecuteFfiHandler(RunId run_id, XLA_FFI_Handler* handler,\n                                  XLA_FFI_ExecutionStage stage,\n                                  se::Stream* stream,\n                                  const ffi::ExecutionContext* execution_context,\n                                  const BufferAllocations* buffer_allocations);\n \n+  absl::Status ExecuteFfiHandler(RunId run_id, xla::ffi::Ffi& handler,\n+                                 xla::ffi::ExecutionStage stage,\n+                                 se::Stream* stream,\n+                                 const ffi::ExecutionContext* execution_context,\n+                                 const BufferAllocations* buffer_allocations);\n+\n   // API version of the custom call. If not set, it means the custom call thunk\n   // was initialized from a non-registered function pointer and can't be\n   // serialized to a proto.\n@@ -159,7 +206,8 @@ class CustomCallThunk : public Thunk {\n   // XLA FFI provides a right type safe mechanism for registering external\n   // functions with XLA runtime. It's under construction, and still misses\n   // a lot of features. Long term it will replace legacy custom calls.\n-  std::optional<XLA_FFI_Handler_Bundle> bundle_;\n+  std::optional<std::variant<XLA_FFI_Handler_Bundle, OwnedHandlerBundle>>\n+      bundle_;\n   std::optional<xla::ffi::AttributesMap> attributes_;\n \n   // Reference call frame pre-initialized at construction time."
        },
        {
            "sha": "d29f0b889d47b5899281577ae528aabaff864314",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_call_thunk_test.cc",
            "status": "modified",
            "additions": 122,
            "deletions": 0,
            "changes": 122,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a0921d99976c5945c79951e4664313bcadff019f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_call_thunk_test.cc?ref=a0921d99976c5945c79951e4664313bcadff019f",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n #include <cstddef>\n #include <memory>\n #include <string>\n+#include <utility>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n@@ -34,6 +35,7 @@ limitations under the License.\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_target_registry.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n+#include \"xla/service/gpu/resource_requests.h\"\n #include \"xla/service/platform_util.h\"\n #include \"xla/service/service_executable_run_options.h\"\n #include \"xla/stream_executor/platform.h\"\n@@ -44,6 +46,7 @@ limitations under the License.\n \n namespace xla::gpu {\n namespace {\n+using absl_testing::IsOk;\n using absl_testing::StatusIs;\n using ::testing::HasSubstr;\n \n@@ -198,5 +201,124 @@ TEST(CustomCallThunkTest, ResolvesLegacyCustomCall) {\n                        HasSubstr(\"Legacy Custom call was executed!\")));\n }\n \n+TEST(CustomCallThunkTest, CustomCallWithOwnedHandlers) {\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor, GpuExecutor());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+  int instantiate_calls = 0;\n+  int prepare_calls = 0;\n+  int initialize_calls = 0;\n+  int execute_calls = 0;\n+  CustomCallThunk::OwnedHandlerBundle bundle;\n+  bundle.instantiate =\n+      ffi::Ffi::Bind<ffi::ExecutionStage::kInstantiate>().To([&]() {\n+        ++instantiate_calls;\n+        return absl::OkStatus();\n+      });\n+  bundle.prepare = ffi::Ffi::Bind<ffi::ExecutionStage::kPrepare>().To([&]() {\n+    ++prepare_calls;\n+    return absl::OkStatus();\n+  });\n+  bundle.initialize =\n+      ffi::Ffi::Bind<ffi::ExecutionStage::kInitialize>().To([&]() {\n+        ++initialize_calls;\n+        return absl::OkStatus();\n+      });\n+  bundle.execute = ffi::Ffi::Bind<ffi::ExecutionStage::kExecute>().To([&]() {\n+    ++execute_calls;\n+    return absl::OkStatus();\n+  });\n+  se::StreamExecutorMemoryAllocator allocator(executor);\n+  Thunk::PrepareParams prepare_params = Thunk::PrepareParams{};\n+  ResourceRequests resource_requests;\n+  BufferAllocations buffer_allocations({}, 0, &allocator);\n+  Thunk::InitializeParams initialize_params;\n+  initialize_params.stream = stream.get();\n+  initialize_params.buffer_allocations = &buffer_allocations;\n+  Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n+      ServiceExecutableRunOptions(), BufferAllocations({}, 0, &allocator),\n+      stream.get(), stream.get(), nullptr, nullptr);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> thunk,\n+      CustomCallThunk::Create(Thunk::ThunkInfo(), \"target_name\",\n+                              std::move(bundle),\n+                              /*operands=*/{},\n+                              /*results=*/{}, /*attributes=*/{},\n+                              /*called_computation=*/nullptr));\n+  EXPECT_EQ(instantiate_calls, 1);\n+  EXPECT_EQ(prepare_calls, 0);\n+  EXPECT_EQ(initialize_calls, 0);\n+  EXPECT_EQ(execute_calls, 0);\n+\n+  EXPECT_THAT(thunk->Prepare(prepare_params, resource_requests), IsOk());\n+  EXPECT_EQ(instantiate_calls, 1);\n+  EXPECT_EQ(prepare_calls, 1);\n+  EXPECT_EQ(initialize_calls, 0);\n+  EXPECT_EQ(execute_calls, 0);\n+\n+  EXPECT_THAT(thunk->Initialize(initialize_params), IsOk());\n+  EXPECT_EQ(instantiate_calls, 1);\n+  EXPECT_EQ(prepare_calls, 1);\n+  EXPECT_EQ(initialize_calls, 1);\n+  EXPECT_EQ(execute_calls, 0);\n+\n+  EXPECT_THAT(thunk->ExecuteOnStream(execute_params), IsOk());\n+  EXPECT_EQ(initialize_calls, 1);\n+  EXPECT_EQ(instantiate_calls, 1);\n+  EXPECT_EQ(prepare_calls, 1);\n+  EXPECT_EQ(execute_calls, 1);\n+}\n+\n+TEST(CustomCallThunkTest, CustomCallWithOwnedHandlersWithoutOptionalOnes) {\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor, GpuExecutor());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+  int execute_calls = 0;\n+  CustomCallThunk::OwnedHandlerBundle bundle;\n+  bundle.execute = ffi::Ffi::Bind().To([&]() {\n+    ++execute_calls;\n+    return absl::OkStatus();\n+  });\n+  se::StreamExecutorMemoryAllocator allocator(executor);\n+  Thunk::PrepareParams prepare_params = Thunk::PrepareParams{};\n+  ResourceRequests resource_requests;\n+  Thunk::InitializeParams initialize_params = Thunk::InitializeParams{};\n+  Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n+      ServiceExecutableRunOptions(), BufferAllocations({}, 0, &allocator),\n+      stream.get(), stream.get(), nullptr, nullptr);\n+\n+  // Optional handlers are null and shouldn't be invoked.\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<CustomCallThunk> thunk,\n+      CustomCallThunk::Create(Thunk::ThunkInfo(), \"target_name\",\n+                              std::move(bundle),\n+                              /*operands=*/{},\n+                              /*results=*/{}, /*attributes=*/{},\n+                              /*called_computation=*/nullptr));\n+  EXPECT_THAT(thunk->Prepare(prepare_params, resource_requests), IsOk());\n+  EXPECT_THAT(thunk->Initialize(initialize_params), IsOk());\n+  EXPECT_THAT(thunk->ExecuteOnStream(execute_params), IsOk());\n+  EXPECT_EQ(execute_calls, 1);\n+}\n+\n+TEST(CustomCallThunkTest, CustomCallWithOwnedHandlersWithoutExecute) {\n+  TF_ASSERT_OK_AND_ASSIGN(se::StreamExecutor * executor, GpuExecutor());\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<se::Stream> stream,\n+                          executor->CreateStream());\n+  CustomCallThunk::OwnedHandlerBundle bundle;  // all handlers null\n+  se::StreamExecutorMemoryAllocator allocator(executor);\n+  Thunk::ExecuteParams execute_params = Thunk::ExecuteParams::Create(\n+      ServiceExecutableRunOptions(), BufferAllocations({}, 0, &allocator),\n+      stream.get(), stream.get(), nullptr, nullptr);\n+\n+  EXPECT_THAT(CustomCallThunk::Create(Thunk::ThunkInfo(), \"target_name\",\n+                                      std::move(bundle),\n+                                      /*operands=*/{},\n+                                      /*results=*/{}, /*attributes=*/{},\n+                                      /*called_computation=*/nullptr),\n+              StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 387,
        "additions": 338,
        "deletions": 49
    }
}