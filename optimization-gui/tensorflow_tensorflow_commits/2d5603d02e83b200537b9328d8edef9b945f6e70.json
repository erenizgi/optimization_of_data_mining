{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 847189107",
    "sha": "2d5603d02e83b200537b9328d8edef9b945f6e70",
    "files": [
        {
            "sha": "3c1c79a5f02d6b978a1e5bb22f0b8309ae56f861",
            "filename": "tensorflow/core/kernels/sparse/kernels_gpu.cu.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 33,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fkernels_gpu.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fkernels_gpu.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fkernels_gpu.cu.cc?ref=2d5603d02e83b200537b9328d8edef9b945f6e70",
            "patch": "@@ -37,22 +37,22 @@ namespace functor {\n \n namespace {\n struct StridedDataReader {\n-  StridedDataReader(const int64* begin, int stride)\n+  StridedDataReader(const int64_t* begin, int stride)\n       : begin_(begin), stride_(stride) {}\n \n   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE int operator()(int idx) const {\n     return static_cast<int>(ldg(begin_ + idx * stride_));\n   }\n \n-  const int64* begin_;\n+  const int64_t* begin_;\n   const int stride_;\n };\n }  // namespace\n \n template <>\n-Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n+absl::Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n     OpKernelContext* c, TTypes<int64_t>::ConstMatrix indices,\n-    TTypes<int32>::Vec nnz_per_batch) {\n+    TTypes<int32_t>::Vec nnz_per_batch) {\n   const auto& cu_stream = GetGpuStream(c);\n \n   const int total_nnz = indices.dimension(0);\n@@ -96,9 +96,9 @@ Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n   TF_RETURN_IF_ERROR(c->allocate_temp(\n       DT_INT8, TensorShape({static_cast<int64_t>(temp_storage_bytes)}),\n       &temp_storage));\n-  DCHECK_NE(temp_storage.flat<int8>().data(), nullptr);\n+  DCHECK_NE(temp_storage.flat<int8_t>().data(), nullptr);\n   auto second_success = gpuprim::DeviceHistogram::HistogramEven(\n-      /*d_temp_storage*/ temp_storage.flat<int8>().data(),\n+      /*d_temp_storage*/ temp_storage.flat<int8_t>().data(),\n       /*temp_storage_bytes&*/ temp_storage_bytes,\n       /*d_samples*/ indices_first_column,\n       /*d_histogram*/ nnz_per_batch.data(),\n@@ -116,13 +116,13 @@ Status CalculateNNZPerBatchMatrixFromIndices<GPUDevice>::operator()(\n         temp_storage_bytes, \", status: \", GpuGetErrorString(second_success));\n   }\n \n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n // TODO(ebrevdo): Write a custom batch-friendly impl of this to update\n // the SparseTensor indices directly.\n template <>\n-Status CSRSparseMatrixToCOOSparseMatrix<GPUDevice>::operator()(\n+absl::Status CSRSparseMatrixToCOOSparseMatrix<GPUDevice>::operator()(\n     OpKernelContext* c, TTypes<const int>::UnalignedVec csr_row_ptr,\n     TTypes<int>::UnalignedVec coo_row_ind) {\n   GpuSparse gpu_sparse(c);\n@@ -133,7 +133,7 @@ Status CSRSparseMatrixToCOOSparseMatrix<GPUDevice>::operator()(\n }\n \n template <int stride>\n-__global__ void SparseTensorToCOOMatrixKernel(const int64* indices,\n+__global__ void SparseTensorToCOOMatrixKernel(const int64_t* indices,\n                                               int* coo_rows_out,\n                                               int* coo_cols_out, int size) {\n   const int offset = (stride == 3) ? 1 : 0;\n@@ -168,7 +168,8 @@ void SparseTensorToCOOSparseMatrix<GPUDevice>::operator()(\n \n __global__ void COOMatrixToSparseTensorKernel2D(const int* coo_rows,\n                                                 const int* coo_cols,\n-                                                int64* indices_out, int size) {\n+                                                int64_t* indices_out,\n+                                                int size) {\n   GPU_1D_KERNEL_LOOP(i, size) {\n     indices_out[i * 2] = static_cast<int64_t>(ldg(coo_rows + i));\n     indices_out[i * 2 + 1] = static_cast<int64_t>(ldg(coo_cols + i));\n@@ -191,7 +192,7 @@ __device__ inline int BinarySearchRange(int* range, int n, int x) {\n }\n \n __global__ void COOMatrixToSparseTensorKernel3D(\n-    const int* coo_rows, const int* coo_cols, int64* indices_out,\n+    const int* coo_rows, const int* coo_cols, int64_t* indices_out,\n     GpuDeviceArrayStruct<int> batch_ptr_s, const int batch_size,\n     const int size) {\n   // Step 1: access the batch ptrs and copy to shared memory.\n@@ -214,7 +215,7 @@ __global__ void COOMatrixToSparseTensorKernel3D(\n }\n \n template <>\n-Status COOSparseMatrixToSparseTensor<GPUDevice>::operator()(\n+absl::Status COOSparseMatrixToSparseTensor<GPUDevice>::operator()(\n     OpKernelContext* c, TTypes<int64_t>::ConstVec host_dense_shape,\n     TTypes<int>::ConstVec host_batch_ptr, TTypes<int>::Vec coo_row_ind,\n     TTypes<int>::ConstVec coo_col_ind, TTypes<int64_t>::Matrix indices) {\n@@ -234,7 +235,7 @@ Status COOSparseMatrixToSparseTensor<GPUDevice>::operator()(\n                                 config.block_count, config.thread_per_block, 0,\n                                 d.stream(), coo_row_ind.data(),\n                                 coo_col_ind.data(), indices.data(), size));\n-    return OkStatus();\n+    return absl::OkStatus();\n   } else {\n     const int batch_size = host_dense_shape(0);\n     GpuDeviceArrayOnHost<int> batch_ptr_copy(c, host_batch_ptr.size());\n@@ -251,7 +252,7 @@ Status COOSparseMatrixToSparseTensor<GPUDevice>::operator()(\n                         config.thread_per_block, shared_memory_size, d.stream(),\n                         coo_row_ind.data(), coo_col_ind.data(), indices.data(),\n                         batch_ptr_copy.data(), batch_size, size));\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n }\n \n@@ -281,10 +282,10 @@ __global__ void CSRSparseMatrixBatchMulVecKernel3D(\n }\n \n template <typename T>\n-Status CSRSparseMatrixBatchMulVecImpl(OpKernelContext* ctx,\n-                                      const CSRSparseMatrix& a,\n-                                      typename TTypes<T>::ConstFlat b,\n-                                      CSRSparseMatrix* c) {\n+absl::Status CSRSparseMatrixBatchMulVecImpl(OpKernelContext* ctx,\n+                                            const CSRSparseMatrix& a,\n+                                            typename TTypes<T>::ConstFlat b,\n+                                            CSRSparseMatrix* c) {\n   DCHECK_EQ(a.dims(), 3);\n   const int total_nnz = a.total_nnz();\n   Tensor c_values_t;\n@@ -321,7 +322,7 @@ Status CSRSparseMatrixBatchMulVecImpl(OpKernelContext* ctx,\n       config.thread_per_block, shared_memory_size, d.stream(), a_values.data(),\n       b.data(), c_values.data(), batch_ptr_copy.data(), batch_size, total_nnz));\n \n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n #define DEFINE_SPARSE_MUL_VEC_GPU(T)                                        \\\n@@ -416,12 +417,12 @@ __global__ void CSRSparseMatrixSoftmaxKernel3D(\n }\n \n template <typename T>\n-Status CSRSparseMatrixSoftmaxGPUImpl(OpKernelContext* ctx,\n-                                     const CSRSparseMatrix& logits,\n-                                     typename TTypes<T>::Vec softmax_values) {\n+absl::Status CSRSparseMatrixSoftmaxGPUImpl(\n+    OpKernelContext* ctx, const CSRSparseMatrix& logits,\n+    typename TTypes<T>::Vec softmax_values) {\n   auto host_dense_shape = logits.dense_shape().vec<int64_t>();\n-  auto host_batch_ptr = logits.batch_pointers().vec<int32>();\n-  auto row_ptr = logits.row_pointers().vec<int32>();\n+  auto host_batch_ptr = logits.batch_pointers().vec<int32_t>();\n+  auto row_ptr = logits.row_pointers().vec<int32_t>();\n   auto logits_values = logits.values().vec<T>();\n \n   const int ndims = host_dense_shape.size();\n@@ -459,7 +460,7 @@ Status CSRSparseMatrixSoftmaxGPUImpl(OpKernelContext* ctx,\n                                 logits_values.data(), softmax_values.data()));\n   }\n \n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n #define DEFINE_SOFTMAX_GPU(T)                                             \\\n@@ -604,18 +605,19 @@ __global__ void CSRSparseMatrixSoftmaxGradKernel3D(\n }\n \n template <typename T>\n-Status CSRSparseMatrixSoftmaxGradGPUImpl(\n+absl::Status CSRSparseMatrixSoftmaxGradGPUImpl(\n     OpKernelContext* ctx, const CSRSparseMatrix& softmax,\n     const CSRSparseMatrix& grad_softmax,\n     typename TTypes<T>::Vec gradient_values) {\n   auto host_dense_shape = softmax.dense_shape().vec<int64_t>();\n-  auto softmax_host_batch_ptr = softmax.batch_pointers().vec<int32>();\n-  auto softmax_row_ptr = softmax.row_pointers().vec<int32>();\n-  auto softmax_col_ind = softmax.col_indices().vec<int32>();\n+  auto softmax_host_batch_ptr = softmax.batch_pointers().vec<int32_t>();\n+  auto softmax_row_ptr = softmax.row_pointers().vec<int32_t>();\n+  auto softmax_col_ind = softmax.col_indices().vec<int32_t>();\n   auto softmax_values = softmax.values().vec<T>();\n-  auto grad_softmax_host_batch_ptr = grad_softmax.batch_pointers().vec<int32>();\n-  auto grad_softmax_row_ptr = grad_softmax.row_pointers().vec<int32>();\n-  auto grad_softmax_col_ind = grad_softmax.col_indices().vec<int32>();\n+  auto grad_softmax_host_batch_ptr =\n+      grad_softmax.batch_pointers().vec<int32_t>();\n+  auto grad_softmax_row_ptr = grad_softmax.row_pointers().vec<int32_t>();\n+  auto grad_softmax_col_ind = grad_softmax.col_indices().vec<int32_t>();\n   auto grad_softmax_values = grad_softmax.values().vec<T>();\n \n   const int ndims = host_dense_shape.size();\n@@ -666,7 +668,7 @@ Status CSRSparseMatrixSoftmaxGradGPUImpl(\n         grad_softmax_values.data(), gradient_values.data()));\n   }\n \n-  return OkStatus();\n+  return absl::OkStatus();\n }\n \n #define DEFINE_SOFTMAX_GRAD_GPU(T)                                          \\"
        },
        {
            "sha": "5c9bfd8a805a5402432c7a27f1876bcbc022e5fe",
            "filename": "tensorflow/core/kernels/sparse/mat_mul_op.h",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmat_mul_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmat_mul_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmat_mul_op.h?ref=2d5603d02e83b200537b9328d8edef9b945f6e70",
            "patch": "@@ -276,7 +276,7 @@ class CSRMatMulCPUOp : public CSRMatMulOp<CPUDevice, T> {\n   Eigen::Ref<const SparseMatrix> GetSparseMatrixRef(\n       const CSRSparseMatrix& csr_matrix, const int batch_index,\n       const int64_t row_begin, const int64_t num_shard_rows,\n-      std::vector<int32>* row_ptrs) {\n+      std::vector<int32_t>* row_ptrs) {\n     // Compute the row pointers of the sparse sub-matrix.\n     row_ptrs->resize(num_shard_rows + 1);\n     const int64_t row_offset =\n@@ -325,7 +325,7 @@ class CSRMatMulCPUOp : public CSRMatMulOp<CPUDevice, T> {\n \n                 // Define an Eigen::SparseMatrix over the row range:\n                 // [row_begin, row_end) of the CSR SparseMatrix A.\n-                std::vector<int32> row_ptrs;\n+                std::vector<int32_t> row_ptrs;\n                 auto sparse_matrix = GetSparseMatrixRef(\n                     lhs, batch_idx, row_begin, num_shard_rows, &row_ptrs);\n \n@@ -396,7 +396,7 @@ class CSRMatMulCPUOp : public CSRMatMulOp<CPUDevice, T> {\n \n                 // Define a new sparse sub-matrix from the row range\n                 // [row_begin, row_end) of the sparse matrix A.\n-                std::vector<int32> row_ptrs;\n+                std::vector<int32_t> row_ptrs;\n                 auto sparse_matrix = GetSparseMatrixRef(\n                     lhs, batch_idx, row_begin, num_shard_rows, &row_ptrs);\n \n@@ -773,9 +773,9 @@ class CSRSparseMatrixMatMul<GPUDevice, T> {\n   explicit CSRSparseMatrixMatMul(const bool transpose_output)\n       : transpose_output_(transpose_output) {}\n \n-  Status Compute(OpKernelContext* ctx, const ConstCSRComponent<T>& a,\n-                 typename TTypes<T>::UnalignedConstMatrix b,\n-                 typename TTypes<T>::UnalignedMatrix c) {\n+  absl::Status Compute(OpKernelContext* ctx, const ConstCSRComponent<T>& a,\n+                       typename TTypes<T>::UnalignedConstMatrix b,\n+                       typename TTypes<T>::UnalignedMatrix c) {\n     GpuSparse cuda_sparse(ctx);\n     TF_RETURN_IF_ERROR(cuda_sparse.Initialize());\n     {\n@@ -859,11 +859,11 @@ class CSRSparseMatrixMatMul<GPUDevice, T> {\n       Tensor buffer;\n       TF_RETURN_IF_ERROR(ctx->allocate_temp(\n           DT_INT8, TensorShape({static_cast<int64_t>(bufferSize)}), &buffer));\n-      DCHECK(buffer.flat<int8>().data() != nullptr);\n+      DCHECK(buffer.flat<int8_t>().data() != nullptr);\n \n       TF_RETURN_IF_ERROR(cuda_sparse.SpMM(transA, transB, &alpha, matA, matB,\n                                           &beta, matC, algo,\n-                                          buffer.flat<int8>().data()));\n+                                          buffer.flat<int8_t>().data()));\n \n       TF_RETURN_IF_GPUSPARSE_ERROR(cusparseDestroyDnMat(matB));\n       TF_RETURN_IF_GPUSPARSE_ERROR(cusparseDestroyDnMat(matC));\n@@ -940,7 +940,7 @@ class CSRSparseMatrixMatMul<GPUDevice, T> {\n #endif  // GOOGLE_CUDA && CUDA_VERSION >= 10020\n     }\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n  private:\n@@ -954,8 +954,8 @@ class CSRSparseMatrixMatVec<GPUDevice, T> {\n       : transA_(TransposeAndConjugateToGpuSparseOp(transpose_a, conjugate_a,\n                                                    &status_)) {}\n \n-  Status Compute(OpKernelContext* ctx, const ConstCSRComponent<T>& a,\n-                 const T* x, T* y) {\n+  absl::Status Compute(OpKernelContext* ctx, const ConstCSRComponent<T>& a,\n+                       const T* x, T* y) {\n     TF_RETURN_IF_ERROR(status_);\n     GpuSparse cuda_sparse(ctx);\n     TF_RETURN_IF_ERROR(cuda_sparse.Initialize());\n@@ -1001,11 +1001,11 @@ class CSRSparseMatrixMatVec<GPUDevice, T> {\n #endif\n     }\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n \n  private:\n-  Status status_;\n+  absl::Status status_;\n   const gpusparseOperation_t transA_;\n };\n "
        },
        {
            "sha": "1a68bcc34e91435e846f937f14731e628c5e9945",
            "filename": "tensorflow/core/kernels/sparse/mul_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmul_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/2d5603d02e83b200537b9328d8edef9b945f6e70/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmul_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsparse%2Fmul_op.cc?ref=2d5603d02e83b200537b9328d8edef9b945f6e70",
            "patch": "@@ -125,8 +125,8 @@ class CSRSparseMatrixMulScalar<GPUDevice, T> {\n  public:\n   explicit CSRSparseMatrixMulScalar() {}\n \n-  Status Compute(OpKernelContext* ctx, const CSRSparseMatrix& a,\n-                 typename TTypes<T>::ConstScalar b, CSRSparseMatrix* c) {\n+  absl::Status Compute(OpKernelContext* ctx, const CSRSparseMatrix& a,\n+                       typename TTypes<T>::ConstScalar b, CSRSparseMatrix* c) {\n     const int total_nnz = a.total_nnz();\n     Tensor c_values_t;\n     TF_RETURN_IF_ERROR(ctx->allocate_temp(\n@@ -146,7 +146,7 @@ class CSRSparseMatrixMulScalar<GPUDevice, T> {\n     functor::BinaryFunctor<GPUDevice, functor::mul<T>, 1>().Right(\n         d, c_values, a_values, b, error_ptr);\n \n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n };\n "
        }
    ],
    "stats": {
        "total": 100,
        "additions": 51,
        "deletions": 49
    }
}