{
    "author": "ermilovmaxim",
    "message": "[XLA:GPU] Enable chlo.sinh -> kSinh HloInstruction lowering.\n\nPiperOrigin-RevId: 815903539",
    "sha": "adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
    "files": [
        {
            "sha": "a1cd81f8fe0b481c15cfe5dc85a7af7e646b49a5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/optimize_loops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Foptimize_loops.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -54,6 +54,7 @@ bool IsExpensiveToUnroll(mlir::Operation* op) {\n       mlir::math::AcosOp,\n       mlir::math::AcoshOp,\n       mlir::math::AtanhOp,\n+      mlir::math::SinhOp,\n       mlir::scf::ForOp\n       // go/keep-sorted end\n       // clang-format on"
        },
        {
            "sha": "00d273723e088c1c1c3360976a80bcbf1ceec429",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -1399,7 +1399,11 @@ XlaOp Cosh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n // +/-89.4159851, due to rounding error when computing x +/- log(1/2).  The\n // correct answer of 3.40281961e+38 (0x7f7fffec) is very close to max-float, so\n // we deem this acceptable.\n-XlaOp Sinh(XlaOp x) {\n+XlaOp Sinh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n+           bool expand) {\n+  if (!expand) {\n+    return x.builder()->UnaryOp(HloOpcode::kSinh, x, result_accuracy);\n+  }\n   XlaBuilder* b = x.builder();\n   auto do_it = [&](XlaOp x) -> absl::StatusOr<XlaOp> {\n     TF_ASSIGN_OR_RETURN(auto shape, b->GetShape(x));"
        },
        {
            "sha": "ccb6b77d7e14c79c69e4413533c931dc22d17872",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -115,7 +115,9 @@ XlaOp Cosh(XlaOp x,\n            bool expand = true);\n \n // Computes the hyperbolic sine of 'x'.\n-XlaOp Sinh(XlaOp x);\n+XlaOp Sinh(XlaOp x,\n+           const std::optional<ResultAccuracy>& result_accuracy = std::nullopt,\n+           bool expand = true);\n \n // Applies a complex conjugation operation if 'a' is complex and 'conjugate'\n // is true, otherwise returns its argument."
        },
        {
            "sha": "34b870dd360ead9530ad009b7406df116665a6f9",
            "filename": "third_party/xla/xla/hlo/builder/xla_builder.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -1772,6 +1772,9 @@ class XlaBuilder {\n                     bool expand);\n   friend XlaOp Sin(XlaOp operand,\n                    const std::optional<ResultAccuracy>& result_accuracy);\n+  friend XlaOp Sinh(XlaOp x,\n+                    const std::optional<ResultAccuracy>& result_accuracy,\n+                    bool expand);\n   friend XlaOp Tan(XlaOp operand,\n                    const std::optional<ResultAccuracy>& result_accuracy);\n   friend XlaOp Tanh(XlaOp operand,"
        },
        {
            "sha": "0a869930c7ce25bba92d1feba5a866e3f715466e",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -2759,6 +2759,7 @@ std::unique_ptr<HloInstruction> HloInstruction::CloneWithNewOperands(\n     case HloOpcode::kLogistic:\n     case HloOpcode::kSign:\n     case HloOpcode::kSin:\n+    case HloOpcode::kSinh:\n     case HloOpcode::kSqrt:\n     case HloOpcode::kCbrt:\n     case HloOpcode::kTan:"
        },
        {
            "sha": "69435b320056958e403e81e40f009180af706719",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/gen_hlo_op_writer.td",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -257,6 +257,7 @@ defvar CustomHloConverterOps = [\n   MHLO_SendOp,\n   MHLO_SetDimensionSizeOp,\n   MHLO_SineOp,\n+  MHLO_SinhOp,\n   MHLO_SortOp,\n   MHLO_StochasticConvertOp,\n   MHLO_SubtractOp,"
        },
        {
            "sha": "a3d1e4ab533c5a797f59d9e7cd40a9b9e4dccea5",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -5246,6 +5246,17 @@ LogicalResult ExportXlaOp(CoshOp op, OpLoweringContext ctx) {\n   return success();\n }\n \n+LogicalResult ExportXlaOp(SinhOp op, OpLoweringContext ctx) {\n+  auto& value_map = *ctx.values;\n+  xla::XlaOp operand;\n+  if (failed(GetXlaOp(op.getOperand(), value_map, &operand, op))) {\n+    return failure();\n+  }\n+  value_map[op] =\n+      xla::Sinh(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n+  return success();\n+}\n+\n LogicalResult ExportXlaOp(AcoshOp op, OpLoweringContext ctx) {\n   return ExportElementwiseXlaOp<AcoshOp, xla::Acosh>(op, ctx);\n }"
        },
        {
            "sha": "19b645f6f2a195883b1011a63797bfd1bbe19faa",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -19,6 +19,7 @@ lit_test_suite(\n             \"case.mlir\",\n             \"composite.mlir\",\n             \"cosh.mlir\",\n+            \"sinh.mlir\",\n             \"dynamic.mlir\",\n             \"export-with-layouts.mlir\",\n             \"export.mlir\","
        },
        {
            "sha": "3e4c3aa639703962cd4f8c68360c9e02bf5fd7cc",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/sinh.mlir",
            "status": "added",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fsinh.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fsinh.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fsinh.mlir?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -0,0 +1,9 @@\n+// RUN: xla-translate -mlir-hlo-to-hlo-text %s | FileCheck %s\n+\n+module {\n+  func.func @main(%arg0: tensor<4xf32>) -> tensor<4xf32> {\n+    // CHECK: f32[4] sinh\n+    %0 = \"mhlo.sinh\"(%arg0) : (tensor<4xf32>) -> tensor<4xf32>\n+    func.return %0 : tensor<4xf32>\n+  }\n+}"
        },
        {
            "sha": "a52ae636a60c4f94b3baaf90ec71c877a58854d8",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 2,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -52,12 +52,14 @@ namespace {\n ChloLegalizeToHighLevelMhloPassOptions FromPassOptions(bool enableAcosh,\n                                                        bool enableAcos,\n                                                        bool enableAtanh,\n-                                                       bool enableCosh) {\n+                                                       bool enableCosh,\n+                                                       bool enableSinh) {\n   ChloLegalizeToHighLevelMhloPassOptions options;\n   options.enable_acosh_ = enableAcosh;\n   options.enable_acos_ = enableAcos;\n   options.enable_atanh_ = enableAtanh;\n   options.enable_cosh_ = enableCosh;\n+  options.enable_sinh_ = enableSinh;\n   return options;\n }\n \n@@ -77,6 +79,10 @@ static bool qualifiesForDirectMhloLoweringCosh(chlo::CoshOp op) {\n   return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n+static bool qualifiesForDirectMhloLoweringSinh(chlo::SinhOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+}\n+\n struct ChloLegalizeToHighLevelMhloPass\n     : public impl::ChloLegalizeToHighLevelMhloPassBase<\n           ChloLegalizeToHighLevelMhloPass> {\n@@ -94,7 +100,7 @@ struct ChloLegalizeToHighLevelMhloPass\n     chlo::populateChloToHighLevelMhloOpPatterns(\n         &context, &conversionPatterns,\n         FromPassOptions(enable_acosh_, enable_acos_, enable_atanh_,\n-                        enable_cosh_));\n+                        enable_cosh_, enable_sinh_));\n \n     // Consider the mhlo dialect legal for tests. Also add helper dialects\n     // that are needed by the patterns.\n@@ -121,6 +127,11 @@ struct ChloLegalizeToHighLevelMhloPass\n         return !qualifiesForDirectMhloLoweringCosh(op);\n       });\n     }\n+    if (enable_sinh_) {\n+      conversionTarget.addDynamicallyLegalOp<chlo::SinhOp>([](chlo::SinhOp op) {\n+        return !qualifiesForDirectMhloLoweringSinh(op);\n+      });\n+    }\n     conversionTarget\n         .addIllegalOp<chlo::TopKOp, chlo::ErfOp, chlo::RaggedDotOp>();\n \n@@ -254,6 +265,15 @@ LogicalResult convertCoshChloToMhlo(chlo::CoshOp op,\n   return success();\n }\n \n+LogicalResult convertSinhChloToMhlo(chlo::SinhOp op,\n+                                    PatternRewriter& rewriter) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringSinh(op)) {\n+    return failure();\n+  }\n+  rewriter.replaceOpWithNewOp<mhlo::SinhOp>(op, op->getOperands());\n+  return success();\n+}\n+\n }  // namespace\n \n ChloLegalizeToHighLevelMhloPassOptions getDefaultChloToHighLevelMhloOptions() {\n@@ -266,6 +286,7 @@ ChloLegalizeToHighLevelMhloPassOptions getGpuChloToHighLevelMhloOptions() {\n   opts.enable_acos_ = true;\n   opts.enable_atanh_ = true;\n   opts.enable_cosh_ = true;\n+  opts.enable_sinh_ = true;\n   return opts;\n }\n \n@@ -292,6 +313,9 @@ void populateChloToHighLevelMhloOpPatterns(\n   if (options.enable_cosh_) {\n     patterns->add(mhlo::convertCoshChloToMhlo, kBenefit);\n   }\n+  if (options.enable_sinh_) {\n+    patterns->add(mhlo::convertSinhChloToMhlo, kBenefit);\n+  }\n   patterns->add(mhlo::convertRaggedDotChloToMhlo, kBenefit);\n   populateWithGenerated(*patterns);\n }"
        },
        {
            "sha": "5e79bc76e999ed17d7d5991764af876631b3eede",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 4,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -130,6 +130,11 @@ std::optional<int64_t> getPublicFeaturesNotInStablehlo(HloOpTy hloOp) {\n     // Version 1: Initial version for CoshOp.\n     return 1;\n   }\n+  // StableHLO doesn't support Sinh yet.\n+  if constexpr (std::is_same<HloOpTy, mhlo::SinhOp>::value) {\n+    // Version 1: Initial version for CoshOp.\n+    return 1;\n+  }\n   return std::nullopt;\n }\n \n@@ -463,6 +468,7 @@ LogicalResult convertAttributes(ConversionPatternRewriter& rewriter,\n                   !std::is_same<HloOpTy, mhlo::AcoshOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::AtanhOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::CoshOp>::value &&\n+                  !std::is_same<HloOpTy, mhlo::SinhOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::ErfOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::TopKOp>::value) {\n       if (!stablehloAttr) {\n@@ -756,10 +762,10 @@ void populateHloToStablehloPatterns(RewritePatternSet* patterns,\n       patterns, converter, context, allowExperimentalFeatures,\n       allowXlaFeatures);\n \n-  populateHloToStablehloCustomCallPatterns<mhlo::AcosOp, mhlo::AcoshOp,\n-                                           mhlo::AtanhOp, mhlo::CoshOp,\n-                                           mhlo::ErfOp, mhlo::TopKOp>(\n-      patterns, converter, context, allowExperimentalFeatures);\n+  populateHloToStablehloCustomCallPatterns<\n+      mhlo::AcosOp, mhlo::AcoshOp, mhlo::AtanhOp, mhlo::CoshOp, mhlo::SinhOp,\n+      mhlo::ErfOp, mhlo::TopKOp>(patterns, converter, context,\n+                                 allowExperimentalFeatures);\n }\n \n }  // namespace stablehlo"
        },
        {
            "sha": "5d6c4c5d74d5cc096d40b9f6eb5ed8a7d1e5ec06",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -30,7 +30,9 @@ def ChloLegalizeToHighLevelMhloPass : Pass<\"chlo-legalize-to-high-level-mhlo\", \"\n     Option<\"enable_atanh_\", \"enable-atanh\", \"bool\", /*default=*/\"false\",\n            \"Enable chlo.atanh to mhlo.atanh lowering.\">,\n     Option<\"enable_cosh_\", \"enable-cosh\", \"bool\", /*default=*/\"false\",\n-           \"Enable chlo.cosh to mhlo.cosh lowering.\">\n+           \"Enable chlo.cosh to mhlo.cosh lowering.\">,\n+    Option<\"enable_sinh_\", \"enable-sinh\", \"bool\", /*default=*/\"false\",\n+           \"Enable chlo.sinh to mhlo.sinh lowering.\">\n   ];\n   let dependentDialects = [\"mhlo::MhloDialect\"];\n }"
        },
        {
            "sha": "949da90ed67a352a929dd54f60fb099baad80f81",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_preserve_high_level_ops.cpp",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -266,6 +266,15 @@ struct CoshOpToCustomCallPattern : public OpRewritePattern<chlo::CoshOp> {\n   }\n };\n \n+struct SinhOpToCustomCallPattern : public OpRewritePattern<chlo::SinhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::SinhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOperationInCustomCall(rewriter, op, \"mhlo.sinh\",\n+                                         /*version=*/1);\n+  }\n+};\n+\n ///////\n // CHLO to CompositeOp Patterns\n ///////\n@@ -341,6 +350,14 @@ struct CoshOpToCompositePattern : public OpRewritePattern<chlo::CoshOp> {\n   }\n };\n \n+struct SinhOpToCompositePattern : public OpRewritePattern<chlo::SinhOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::SinhOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOpInComposite(op, /*version=*/1, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloPreserveHighLevelOpsPass\n@@ -368,6 +385,7 @@ struct ChloPreserveHighLevelOpsPass\n         AcoshOpToCustomCallPattern,\n         AtanhOpToCustomCallPattern,\n         CoshOpToCustomCallPattern,\n+        SinhOpToCustomCallPattern,\n         ErfOpToCustomCallPattern,\n         RaggedDotOpToCustomCallPattern,\n         TopKOpToCustomCallPattern>(ctx);\n@@ -377,6 +395,7 @@ struct ChloPreserveHighLevelOpsPass\n         AcoshOpToCompositePattern,\n         AtanhOpToCompositePattern,\n         CoshOpToCompositePattern,\n+        SinhOpToCompositePattern,\n         ErfOpToCompositePattern,\n         RaggedDotOpToCompositePattern,\n         TopKOpToCompositePattern>(ctx);"
        },
        {
            "sha": "fead6dec92b83085e142e714892be4f142c34fb3",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_recompose_ops.cpp",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -312,6 +312,22 @@ struct CoshOpRecomposePattern\n   }\n };\n \n+struct SinhOpRecomposePattern\n+    : public OpRewritePattern<stablehlo::CompositeOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n+                                PatternRewriter& rewriter) const override {\n+    if (op.getName() != \"chlo.sinh\") {\n+      return rewriter.notifyMatchFailure(op, \"not a chlo.sinh\");\n+    }\n+    if (op.getVersion() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"unsupported version for chlo.cosh composite\");\n+    }\n+    return recomposeChloOpFromCompositeOp<chlo::SinhOp>(op, rewriter);\n+  }\n+};\n+\n struct ErfOpRecomposePattern : public OpRewritePattern<stablehlo::CompositeOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n@@ -441,6 +457,16 @@ struct CoshOpCustomCallRecomposePattern\n   }\n };\n \n+struct SinhOpCustomCallRecomposePattern\n+    : public OpRewritePattern<stablehlo::CustomCallOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CustomCallOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return recomposeChloOpFromCustomCall<chlo::SinhOp>(\n+        op, {\"mhlo.sinh\", \"chlo.sinh\"}, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloRecomposeOpsPass\n@@ -465,6 +491,7 @@ struct ChloRecomposeOpsPass\n       AcoshOpCustomCallRecomposePattern,\n       AtanhOpCustomCallRecomposePattern,\n       CoshOpCustomCallRecomposePattern,\n+      SinhOpCustomCallRecomposePattern,\n       ErfOpCustomCallRecomposePattern,\n       RaggedDotOpCustomCallRecomposePattern,\n       TanOpCustomCallRecomposePattern,\n@@ -476,6 +503,7 @@ struct ChloRecomposeOpsPass\n       AcoshOpRecomposePattern,\n       AtanhOpRecomposePattern,\n       CoshOpRecomposePattern,\n+      SinhOpRecomposePattern,\n       ErfOpRecomposePattern,\n       RaggedDotOpRecomposePattern,\n       TopKOpRecomposePattern>(ctx);"
        },
        {
            "sha": "885d8e8b144e1effcf7eb66be34cfb9360277106",
            "filename": "third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -1,5 +1,5 @@\n // RUN: mlir-hlo-opt --chlo-legalize-to-hlo --split-input-file -verify-diagnostics %s | FileCheck %s --dump-input-context=20\n-// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh enable-cosh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n+// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh enable-cosh enable-sinh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n \n // CHECK-LABEL: func.func @asin_bf16(\n // CHECK-SAME:    %[[TMP_arg0:.*]]: tensor<bf16>\n@@ -2640,6 +2640,7 @@ func.func @sinh_f32(%x : tensor<f32>) -> tensor<f32> {\n   %1 = chlo.sinh %x : tensor<f32> -> tensor<f32>\n   func.return %1 : tensor<f32>\n }\n+// CHECK-HIGH-LEVEL: mhlo.sinh\n \n // -----\n \n@@ -2652,6 +2653,7 @@ func.func @sinh_f16(%x : tensor<f16>) -> tensor<f16> {\n   %1 = chlo.sinh %x : tensor<f16> -> tensor<f16>\n   func.return %1 : tensor<f16>\n }\n+// CHECK-HIGH-LEVEL: mhlo.sinh\n \n // -----\n \n@@ -2669,6 +2671,7 @@ func.func @sinh_complex(%x : tensor<2xcomplex<f32>>) -> tensor<2xcomplex<f32>> {\n   %1 = chlo.sinh %x : tensor<2xcomplex<f32>> -> tensor<2xcomplex<f32>>\n   func.return %1 : tensor<2xcomplex<f32>>\n }\n+// CHECK-HIGH-LEVEL-NOT: mhlo.sinh\n \n // -----\n "
        },
        {
            "sha": "8e33b9d34361b633d8e2ff4a4eaf983b2ea78cc3",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_preserve_high_level_ops.mlir",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -113,6 +113,16 @@ func.func @cosh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n \n // -----\n \n+// CHECK-LABEL: func @sinh_preserve\n+func.func @sinh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-CC: stablehlo.custom_call @mhlo.sinh(%arg0) {mhlo.attributes = {}, mhlo.version = 1 : i64} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  // CHECK: stablehlo.composite \"chlo.sinh\" %arg0 {decomposition = @chlo.sinh.impl, version = 1 : i32}\n+  %0 = chlo.sinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @tan_no_preserve\n func.func @tan_no_preserve(%arg0: tensor<16xf32>) -> tensor<?xf32> {\n   // CHECK: chlo.tan"
        },
        {
            "sha": "e8c6136148914ac5e2068f18ed95c683edc9b94a",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_recompose_ops.mlir",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -78,6 +78,21 @@ func.func private @chlo.cosh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20\n \n // -----\n \n+// CHECK-LABEL: func @sinh_recompose_composite\n+func.func @sinh_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-NEXT: chlo.sinh\n+  // CHECK-NOT: stablehlo.composite\n+  %0 = stablehlo.composite \"chlo.sinh\" %arg0 {decomposition = @chlo.sinh.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+// CHECK-NOT: @chlo.sinh.impl\n+func.func private @chlo.sinh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  %0 = chlo.sinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_composite\n func.func @ragged_dot_recompose_composite(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>\n@@ -181,6 +196,20 @@ func.func @cosh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16\n \n // -----\n \n+// CHECK-LABEL: @sinh_recompose_cc\n+func.func @sinh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK: %0 = chlo.sinh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  %0 = \"stablehlo.custom_call\"(%arg0) {\n+    backend_config = \"\",\n+    call_target_name = \"mhlo.sinh\",\n+    mhlo.attributes = {},\n+    mhlo.version = 1 : i64\n+  } : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  func.return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_cc\n func.func @ragged_dot_recompose_cc(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>"
        },
        {
            "sha": "0e5a08622bb12be1e889cf7b45cd9a4ce6d6da85",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_ops.inc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adf2e981a3121ba09ebd51fb19d0b518f723d9ea/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc?ref=adf2e981a3121ba09ebd51fb19d0b518f723d9ea",
            "patch": "@@ -209,7 +209,8 @@ DEFINE_UNARY_TEST_OP(AsinOp, { return Asin; }, { return std::asin; });\n DEFINE_UNARY_TEST_OP(AtanOp, { return Atan; }, { return std::atan; });\n DEFINE_UNARY_TEST_OP(\n     CoshOp, { return [](XlaOp x) { return Cosh(x); }; }, { return std::cosh; });\n-DEFINE_UNARY_TEST_OP(SinhOp, { return Sinh; }, { return std::sinh; });\n+DEFINE_UNARY_TEST_OP(\n+    SinhOp, { return [](XlaOp x) { return Sinh(x); }; }, { return std::sinh; });\n DEFINE_UNARY_TEST_OP(\n     TanhOp, { return [](XlaOp x) { return Tanh(x); }; }, { return std::tanh; });\n DEFINE_UNARY_TEST_OP("
        }
    ],
    "stats": {
        "total": 177,
        "additions": 166,
        "deletions": 11
    }
}