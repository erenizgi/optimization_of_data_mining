{
    "author": "mdfaijul",
    "message": "PR #30714: [XLA:GPU][oneAPI] Stub for IntelGpuCompiler\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30714\n\nThis is a stub for IntelGpuCompiler. Each feature would extend its implementations in the future PRs.\n\nCopybara import of the project:\n\n--\n9cc4709998294557c29454746ad9b09e5f3a14a4 by mdfaijul <md.faijul.amin@intel.com>:\n\nStub for IntelGpuCompiler\n\n--\n2c21e97d5890523ea05eb6c2fb2ce40f6824f9dd by mdfaijul <md.faijul.amin@intel.com>:\n\nRemove wrong comment.\n\n--\n4e808564cf42a316fd30b8fe8159618bf1f1066a by mdfaijul <md.faijul.amin@intel.com>:\n\nFix license headers.\n\nMerging this change closes #30714\n\nPiperOrigin-RevId: 803426563",
    "sha": "17abf11533badf237b4c34899172c78602265bc6",
    "files": [
        {
            "sha": "af40ce5521bfa875712d68388003392f7a4be405",
            "filename": "third_party/xla/build_tools/ci/build.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -52,7 +52,10 @@\n     \"//build_tools/...\",\n     \"@local_tsl//tsl/...\",\n )\n-_XLA_ONEAPI_TARGET_PATTERNS = (\"//xla/stream_executor/sycl/...\",)\n+_XLA_ONEAPI_TARGET_PATTERNS = (\n+    \"//xla/stream_executor/sycl/...\",\n+    \"//xla/service/gpu/...\",\n+)\n _XLA_CPU_PRESUBMIT_BENCHMARKS_DEFAULT_TARGET_PATTERNS = (\n     \"//xla/tools/multihost_hlo_runner:hlo_runner_main\",\n     \"//xla/tools:compute_xspace_stats_main\","
        },
        {
            "sha": "ae305ed6b551ce114eebf1e48ffb808317b329a8",
            "filename": "third_party/xla/build_tools/ci/golden_commands.txt",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -65,8 +65,8 @@ bazel test --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneap\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_L4_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_LINUX_X86_GPU_ONEAPI_GITHUB_ACTIONS\n-parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build --nobuild -- //xla/stream_executor/sycl/...\n-bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build -- //xla/stream_executor/sycl/...\n+parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build --nobuild -- //xla/stream_executor/sycl/... //xla/service/gpu/...\n+bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build -- //xla/stream_executor/sycl/... //xla/service/gpu/...\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_ONEAPI_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_MACOS_ARM64_CPU_KOKORO"
        },
        {
            "sha": "3566acb499cc640a07d2755fc7cd49106f079603",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 50,
            "deletions": 0,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -172,6 +172,7 @@ xla_test(\n     srcs = [\"custom_call_test.cc\"],\n     backends = [\"gpu\"],\n     local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]),\n+    tags = [\"no-oneapi\"],  # TODO(intel-tf): Remove it when macro substitutions for SYCL are available in xla/stream_executor/sycl/*.\n     deps = [\n         \"//xla:debug_options_flags\",\n         \"//xla:shape_util\",\n@@ -3141,3 +3142,52 @@ cc_library(\n         \"@local_tsl//tsl/profiler/lib:traceme_encode\",\n     ],\n )\n+\n+cc_library(\n+    name = \"intel_gpu_compiler\",\n+    srcs = [\n+        \"intel_gpu_compiler_registration.cc\",\n+    ],\n+    tags = [\n+        \"gpu\",\n+        \"oneapi-only\",\n+    ],\n+    deps = [\n+        \":intel_gpu_compiler_impl\",\n+        \"//xla/service:compiler\",\n+        \"//xla/stream_executor/sycl:sycl_platform_id\",\n+    ],\n+    alwayslink = True,  # Contains compiler registration\n+)\n+\n+cc_library(\n+    name = \"intel_gpu_compiler_impl\",\n+    srcs = [\n+        \"intel_gpu_compiler.cc\",\n+    ],\n+    hdrs = [\n+        \"intel_gpu_compiler.h\",\n+    ],\n+    tags = [\n+        \"gpu\",\n+        \"oneapi-only\",\n+    ],\n+    deps = [\n+        \":gpu_compiler\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"intel_gpu_compiler_test\",\n+    srcs = [\"intel_gpu_compiler_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\n+        \"gpu\",\n+        \"oneapi-only\",\n+    ],\n+    deps = [\n+        \":intel_gpu_compiler\",\n+        \"//xla/tests:hlo_test_base\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)"
        },
        {
            "sha": "1666428c06765dc3cebc4af66bfa8e2404855741",
            "filename": "third_party/xla/xla/service/gpu/intel_gpu_compiler.cc",
            "status": "added",
            "additions": 52,
            "deletions": 0,
            "changes": 52,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.cc?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -0,0 +1,52 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/intel_gpu_compiler.h\"\n+\n+#include \"xla/service/gpu/target_constants.h\"\n+#include \"xla/stream_executor/sycl/sycl_platform_id.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+IntelGpuCompiler::IntelGpuCompiler()\n+    : GpuCompiler(stream_executor::sycl::kSyclPlatformId, spir::TargetTriple(),\n+                  spir::DataLayout()) {}\n+\n+absl::Status IntelGpuCompiler::OptimizeHloConvolutionCanonicalization(\n+    HloModule* hlo_module, se::GpuComputeCapability gpu_version,\n+    se::dnn::VersionInfo dnn_version,\n+    const se::SemanticVersion& toolkit_version) {\n+  // Note: this is a stub.\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<GpuCompiler::BackendCompileResult>\n+IntelGpuCompiler::CompileTargetBinary(\n+    const HloModuleConfig& module_config, llvm::Module* llvm_module,\n+    const stream_executor::DeviceDescription& device_description,\n+    bool relocatable, const HloModule* debug_module,\n+    const CompileOptions& options, std::optional<int> shard_number) {\n+  // Note: this is a stub.\n+  return BackendCompileResult{};\n+}\n+\n+std::vector<std::string> IntelGpuCompiler::GetLLVMCommandLineOptions(\n+    const DebugOptions& debug_options) const {\n+  return {};\n+}\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "11bc3eefc8184035ce0547acae7a1c2904f4f5e3",
            "filename": "third_party/xla/xla/service/gpu/intel_gpu_compiler.h",
            "status": "added",
            "additions": 59,
            "deletions": 0,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler.h?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -0,0 +1,59 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_GPU_INTEL_GPU_COMPILER_H_\n+#define XLA_SERVICE_GPU_INTEL_GPU_COMPILER_H_\n+\n+#include <string>\n+#include <vector>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"llvm/IR/Module.h\"\n+#include \"xla/hlo/analysis/hlo_dataflow_analysis.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/service/gpu/gpu_compiler.h\"\n+#include \"xla/stream_executor/semantic_version.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+class IntelGpuCompiler : public GpuCompiler {\n+ public:\n+  IntelGpuCompiler();\n+\n+  absl::Status OptimizeHloConvolutionCanonicalization(\n+      HloModule* hlo_module, se::GpuComputeCapability gpu_version,\n+      se::dnn::VersionInfo dnn_version,\n+      const se::SemanticVersion& toolkit_version) override;\n+\n+  absl::StatusOr<BackendCompileResult> CompileTargetBinary(\n+      const HloModuleConfig& module_config, llvm::Module* llvm_module,\n+      const stream_executor::DeviceDescription& device_description,\n+      bool relocatable, const HloModule* debug_module,\n+      const CompileOptions& options, std::optional<int> shard_number) override;\n+\n+  std::vector<std::string> GetLLVMCommandLineOptions(\n+      const DebugOptions& debug_options) const override;\n+\n+ private:\n+  IntelGpuCompiler(const IntelGpuCompiler&) = delete;\n+  IntelGpuCompiler& operator=(const IntelGpuCompiler&) = delete;\n+};\n+\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_GPU_INTEL_GPU_COMPILER_H_"
        },
        {
            "sha": "b765599237cc4675170de561fc9cc3a72cef0961",
            "filename": "third_party/xla/xla/service/gpu/intel_gpu_compiler_registration.cc",
            "status": "added",
            "additions": 25,
            "deletions": 0,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_registration.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_registration.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_registration.cc?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -0,0 +1,25 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/intel_gpu_compiler.h\"\n+#include \"xla/stream_executor/sycl/sycl_platform_id.h\"\n+\n+static bool InitCompilerModule() {\n+  xla::Compiler::RegisterCompilerFactory(\n+      stream_executor::sycl::kSyclPlatformId,\n+      []() { return std::make_unique<xla::gpu::IntelGpuCompiler>(); });\n+  return true;\n+}\n+static bool compiler_module_initialized = InitCompilerModule();"
        },
        {
            "sha": "809121f35fe2695c851e0569f2ab366e86b27b50",
            "filename": "third_party/xla/xla/service/gpu/intel_gpu_compiler_test.cc",
            "status": "added",
            "additions": 33,
            "deletions": 0,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fintel_gpu_compiler_test.cc?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -0,0 +1,33 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <gtest/gtest.h>\n+#include \"xla/stream_executor/sycl/sycl_platform_id.h\"\n+#include \"xla/tests/hlo_test_base.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+class IntelGpuCompilerTest : public HloTestBase {};\n+\n+TEST_F(IntelGpuCompilerTest, CheckCompiler) {\n+  auto compiler = backend().compiler();\n+  EXPECT_EQ(compiler->PlatformId(), stream_executor::sycl::kSyclPlatformId);\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "7d87370ec462f57708d5792f8460ff0aa6281575",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/17abf11533badf237b4c34899172c78602265bc6/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=17abf11533badf237b4c34899172c78602265bc6",
            "patch": "@@ -78,6 +78,7 @@ xla_test(\n     backends = [\"gpu\"],\n     local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]),\n     tags = [\n+        \"no-oneapi\",  # TODO(intel-tf): Enable this test for SYCL when IntelGpuCompiler is implemented.\n         \"notsan\",\n         \"test_migrated_to_hlo_runner_pjrt\",\n     ],  # TODO(b/345034145): Fix tsan error."
        }
    ],
    "stats": {
        "total": 229,
        "additions": 226,
        "deletions": 3
    }
}