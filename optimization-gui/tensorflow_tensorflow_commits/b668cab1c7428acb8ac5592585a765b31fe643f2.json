{
    "author": "basioli-k",
    "message": "[XLA:CPU] Remove legacy JIT compilation path.\n\nPiperOrigin-RevId: 797289242",
    "sha": "b668cab1c7428acb8ac5592585a765b31fe643f2",
    "files": [
        {
            "sha": "aa3b61e86e16446bc0e45af669bbe9ccd55ddfd7",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/hlo_benchmark_runner.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -169,12 +169,7 @@ absl::Status RunHloBenchmark(benchmark::State& state,\n     compile_options.executable_build_options.mutable_debug_options()\n         ->add_xla_disable_hlo_passes(\"cpu-parallel-task-assigner\");\n   }\n-  // TODO(intel-tf): Remove this if-block once oneDNN custom calls are enabled\n-  // with thunk runtime\n-  if (!benchmark_options.use_thunk_runtime) {\n-    compile_options.executable_build_options.mutable_debug_options()\n-        ->set_xla_cpu_use_thunk_runtime(false);\n-  }\n+\n   std::unique_ptr<PjRtLoadedExecutable> executable;\n   if (benchmark_options.aot_options) {\n     auto* cpu_client = tsl::down_cast<PjRtCpuClient*>(client.get());"
        },
        {
            "sha": "cb13c47fa0b4fe145d2b97b2447b13e9ba17a589",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 189,
            "deletions": 260,
            "changes": 449,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -1491,7 +1491,6 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n       JitCompiler::Create(std::move(jit_compiler_options),\n                           std::move(ir_compiler), GetCompilationTaskRunner()));\n \n-  HloComputation* entry_computation = module->entry_computation();\n   absl::flat_hash_map<const HloInstruction*, int64_t>\n       instruction_to_profile_idx;\n   absl::flat_hash_map<const HloComputation*, int64_t>\n@@ -1555,306 +1554,236 @@ CpuCompiler::CompileCpuExecutable(std::unique_ptr<HloModule> module) {\n #endif\n   );\n \n-  // If we use Thunk runtime then instead of emitting LLVM function for the\n-  // entry computation we emit a sequence of thunks that implement the\n-  // computation as a sequence of interpreted commands.\n-  if (module->config().debug_options().xla_cpu_use_thunk_runtime()) {\n-    // The thunk runtime manages large constants, therefore we only emit\n-    // small ones.\n-    TF_RETURN_IF_ERROR(nested_ir_emitter.EmitSmallConstantGlobals());\n-\n-    // IR emitter is responsible for building LLVM module with host kernels for\n-    // corresponding HLO instructions (fusions, elemental instructions, etc.).\n-    IrEmitter2 ir_emitter2(*module, llvm_module.get(), &nested_ir_emitter);\n-\n-    // Thunk emitter is responsible for building a Thunk sequence that will\n-    // resolved kernels in the compiled LLVM module and execute them together\n-    // with Thunks implemented as library calls (e.g. oneDNN or Eigen).\n-    ThunkEmitter thunk_emitter(ir_emitter2, *GetCompilationThreadPool(),\n-                               *assignment, target_machine_features, *module);\n-    TF_ASSIGN_OR_RETURN(ThunkSequence thunks,\n-                        thunk_emitter.EmitEntryComputation(*module));\n-\n-    TF_ASSIGN_OR_RETURN(std::vector<ThunkEmitter::EmittedKernel> kernels,\n-                        thunk_emitter.ConsumeKernels());\n-\n-    std::string ir_module_string;\n-    if (embed_ir_in_executable) {\n-      std::string emitter2_ir = llvm_ir::DumpToString(llvm_module.get());\n+  // The thunk runtime manages large constants, therefore we only emit\n+  // small ones.\n+  TF_RETURN_IF_ERROR(nested_ir_emitter.EmitSmallConstantGlobals());\n \n-      auto thunk_kernel_fmt = [](std::string* out,\n-                                 const ThunkEmitter::EmittedKernel& kernel) {\n-        absl::StrAppend(\n-            out, llvm_ir::DumpToString(kernel.module.getModuleUnlocked()));\n-      };\n-      std::string thunks_ir = absl::StrJoin(kernels, \"\\n\", thunk_kernel_fmt);\n+  // IR emitter is responsible for building LLVM module with host kernels for\n+  // corresponding HLO instructions (fusions, elemental instructions, etc.).\n+  IrEmitter2 ir_emitter2(*module, llvm_module.get(), &nested_ir_emitter);\n \n-      ir_module_string = absl::StrCat(emitter2_ir, \"\\n\", thunks_ir);\n-    }\n+  // Thunk emitter is responsible for building a Thunk sequence that will\n+  // resolved kernels in the compiled LLVM module and execute them together\n+  // with Thunks implemented as library calls (e.g. oneDNN or Eigen).\n+  ThunkEmitter thunk_emitter(ir_emitter2, *GetCompilationThreadPool(),\n+                             *assignment, target_machine_features, *module);\n+  TF_ASSIGN_OR_RETURN(ThunkSequence thunks,\n+                      thunk_emitter.EmitEntryComputation(*module));\n \n-    TF_RETURN_IF_ERROR(VerifyLlvmModule(*llvm_module));\n-    for (const auto& [name, module] : kernels) {\n-      TF_RETURN_IF_ERROR(VerifyLlvmModule(*module.getModuleUnlocked()));\n-    }\n+  TF_ASSIGN_OR_RETURN(std::vector<ThunkEmitter::EmittedKernel> kernels,\n+                      thunk_emitter.ConsumeKernels());\n \n-    // Some kernels have to be compiled separately because they have\n-    // extra backend options.\n-    int num_extra_functions = 0;\n-    using BackendOptions = llvm::StringRef;\n-    using Kernel = llvm::StringRef;\n-    absl::flat_hash_map<BackendOptions, absl::flat_hash_set<Kernel>>\n-        backend_extra_options_to_kernels;\n-    for (const auto& k : ir_emitter2.kernels()) {\n-      if (k.backend_extra_options.empty()) continue;\n-      auto [_, inserted] =\n-          backend_extra_options_to_kernels[k.backend_extra_options].insert(\n-              k.name);\n-      CHECK(inserted) << \"Kernel \" << k.name << \" is not unique\";\n-      num_extra_functions++;\n-    }\n-    const int num_extra_parts = backend_extra_options_to_kernels.size();\n-    // We assign one dylib to each set of kernels that have the same extra\n-    // backend options. We do this because we work under the assumption that\n-    // very few kernels will set extra options, and if they do, the options are\n-    // likely to be identical.\n-    if (num_extra_parts >= parallel_codegen_split_count) {\n-      return Internal(\n-          \"Too many extra compilation parts due to non-default options (%d). \"\n-          \"Consider reducing this number or increasing \"\n-          \"parallel_codegen_split_count (%d)\",\n-          num_extra_parts, parallel_codegen_split_count);\n-    }\n+  std::string ir_module_string;\n+  if (embed_ir_in_executable) {\n+    std::string emitter2_ir = llvm_ir::DumpToString(llvm_module.get());\n \n-    // We define the number of module parts based on the total number of\n-    // compiled functions (kernels and comparators) that are called from thunks,\n-    // and the maximum number of parts that we want to split the module into.\n-    size_t num_compiled_functions = ir_emitter2.kernels().size() +\n-                                    ir_emitter2.comparators().size() +\n-                                    kernels.size();\n-    size_t num_default_parts =\n-        std::min(num_compiled_functions - num_extra_functions,\n-                 parallel_codegen_split_count - num_extra_parts);\n-\n-    // JIT compile the LLVM IR module to in-memory machine code. We split the\n-    // module into `num_jit_dylibs` parts to allow parallel compilation. In\n-    // practice, all of the kernel functions are independent and don't call each\n-    // other, so we can compile each individual part in parallel. We split\n-    // module preserving locals, which should guarantee that all thread local\n-    // computations end up in the same module with the corresponding kernel.\n-\n-    // Collect all compiled symbols grouped by LLVM module part, so that we can\n-    // issue compile tasks in parallel without any interference.\n-    std::vector<CompiledSymbolsPart> compiled_parts;\n-\n-    VLOG(2) << \"Compile LLVM module with \" << ir_emitter2.kernels().size()\n-            << \" kernels and \" << ir_emitter2.comparators().size()\n-            << \" comparators\";\n-\n-    int dylib_index = 0;\n-    auto add_jit_module = [&](std::unique_ptr<llvm::Module> llvm_module_part) {\n-      // Collect symbols that are compiled in this LLVM module part.\n-      RemoveUnusedSymbols(*llvm_module_part);\n-      compiled_parts.push_back(\n-          CollectCompiledSymbolsPart(ir_emitter2, *llvm_module_part));\n-\n-      std::string dump = llvm_ir::DumpToString(llvm_module_part.get());\n-      VLOG(5) << \"Adding compilation module:\\n\" << dump;\n-\n-      // Clone LLVM module part into its own thread safe context.\n-      auto tsm =\n-          CloneAsThreadSafeModule(dylib_index, std::move(llvm_module_part));\n-      TF_CHECK_OK(jit_compiler.AddModule(std::move(tsm), dylib_index++));\n+    auto thunk_kernel_fmt = [](std::string* out,\n+                               const ThunkEmitter::EmittedKernel& kernel) {\n+      absl::StrAppend(out,\n+                      llvm_ir::DumpToString(kernel.module.getModuleUnlocked()));\n     };\n+    std::string thunks_ir = absl::StrJoin(kernels, \"\\n\", thunk_kernel_fmt);\n \n-    // If there are extra parts, compile them first, since we must\n-    // remove the affected kernels from the LLVM module.\n-    if (num_extra_parts > 0) {\n-      TraceMe trace([&] {\n-        return TraceMeEncode(\"CompileExtraKernels\",\n-                             {{\"num_extra_parts\", num_extra_parts}});\n-      });\n-      for (const auto& [backend_extra_options, kernels] :\n-           backend_extra_options_to_kernels) {\n-        TF_ASSIGN_OR_RETURN(\n-            std::unique_ptr<llvm::Module> new_module,\n-            ExtractKernelsFromModule(llvm_module.get(), kernels));\n-        AddXlaBackendExtraOptionsAsModuleFlag(new_module.get(),\n-                                              backend_extra_options);\n-        add_jit_module(std::move(new_module));\n-      }\n-    }\n-\n-    if (HasLargeConstants(*llvm_module)) {\n-      VLOG(3) << \"Skip parallel compilation due to large constants\";\n-      num_default_parts = 1;\n-    }\n-\n-    if (num_default_parts > 1) {\n-      VLOG(3) << \"Split LLVM module into \" << num_default_parts\n-              << \" parts before codegen to enable parallel compilation\"\n-              << \" (max split count: \" << parallel_codegen_split_count << \")\";\n-\n-      TraceMe trace([&] {\n-        return TraceMeEncode(\"SplitModule\",\n-                             {{\"num_default_parts\", num_default_parts}});\n-      });\n+    ir_module_string = absl::StrCat(emitter2_ir, \"\\n\", thunks_ir);\n+  }\n \n-      llvm::SplitModule(*llvm_module, num_default_parts, add_jit_module,\n-                        /*PreserveLocals=*/true, /*RoundRobin=*/true);\n-      // Free resources used by the original LLVM module.\n-      llvm_module.reset();\n-      llvm_context.reset();\n+  TF_RETURN_IF_ERROR(VerifyLlvmModule(*llvm_module));\n+  for (const auto& [name, module] : kernels) {\n+    TF_RETURN_IF_ERROR(VerifyLlvmModule(*module.getModuleUnlocked()));\n+  }\n \n-    } else {\n-      VLOG(3) << \"Compile LLVM module without splitting (max split count: \"\n-              << parallel_codegen_split_count << \")\";\n-      compiled_parts.push_back(\n-          CollectCompiledSymbolsPart(ir_emitter2, *llvm_module));\n-      TF_CHECK_OK(jit_compiler.AddModule(llvm::orc::ThreadSafeModule(\n-          std::move(llvm_module), std::move(llvm_context))));\n+  // Some kernels have to be compiled separately because they have\n+  // extra backend options.\n+  int num_extra_functions = 0;\n+  using BackendOptions = llvm::StringRef;\n+  using Kernel = llvm::StringRef;\n+  absl::flat_hash_map<BackendOptions, absl::flat_hash_set<Kernel>>\n+      backend_extra_options_to_kernels;\n+  for (const auto& k : ir_emitter2.kernels()) {\n+    if (k.backend_extra_options.empty()) {\n+      continue;\n     }\n+    auto [_, inserted] =\n+        backend_extra_options_to_kernels[k.backend_extra_options].insert(\n+            k.name);\n+    CHECK(inserted) << \"Kernel \" << k.name << \" is not unique\";\n+    num_extra_functions++;\n+  }\n+  const int num_extra_parts = backend_extra_options_to_kernels.size();\n+  // We assign one dylib to each set of kernels that have the same extra\n+  // backend options. We do this because we work under the assumption that\n+  // very few kernels will set extra options, and if they do, the options are\n+  // likely to be identical.\n+  if (num_extra_parts >= parallel_codegen_split_count) {\n+    return Internal(\n+        \"Too many extra compilation parts due to non-default options (%d). \"\n+        \"Consider reducing this number or increasing \"\n+        \"parallel_codegen_split_count (%d)\",\n+        num_extra_parts, parallel_codegen_split_count);\n+  }\n+\n+  // We define the number of module parts based on the total number of\n+  // compiled functions (kernels and comparators) that are called from thunks,\n+  // and the maximum number of parts that we want to split the module into.\n+  size_t num_compiled_functions = ir_emitter2.kernels().size() +\n+                                  ir_emitter2.comparators().size() +\n+                                  kernels.size();\n+  size_t num_default_parts =\n+      std::min(num_compiled_functions - num_extra_functions,\n+               parallel_codegen_split_count - num_extra_parts);\n+\n+  // JIT compile the LLVM IR module to in-memory machine code. We split the\n+  // module into `num_jit_dylibs` parts to allow parallel compilation. In\n+  // practice, all of the kernel functions are independent and don't call each\n+  // other, so we can compile each individual part in parallel. We split\n+  // module preserving locals, which should guarantee that all thread local\n+  // computations end up in the same module with the corresponding kernel.\n+\n+  // Collect all compiled symbols grouped by LLVM module part, so that we can\n+  // issue compile tasks in parallel without any interference.\n+  std::vector<CompiledSymbolsPart> compiled_parts;\n \n-    // Collect compiled symbols from all LLVM module parts.\n-    std::vector<FunctionLibrary::Symbol> compiled_symbols;\n-\n-    absl::flat_hash_map<FunctionLibrary::TypeId, SymbolProto::FunctionTypeId>\n-        symbol_type_id_to_function_type_id;\n+  VLOG(2) << \"Compile LLVM module with \" << ir_emitter2.kernels().size()\n+          << \" kernels and \" << ir_emitter2.comparators().size()\n+          << \" comparators\";\n \n-    VLOG(3) << \"Adding \" << kernels.size() << \" kernels to the JIT compiler\";\n-    // Make sure we use all the \"default\" modules for maximum parallelism.\n-    int num_default_so_far = dylib_index - num_extra_parts;\n-    int kernel_dylib_index =\n-        num_default_so_far < num_default_parts ? num_default_so_far : 0;\n-    for (auto& [name, module] : kernels) {\n-      compiled_symbols.push_back(\n-          FunctionLibrary::Sym<FunctionLibrary::Kernel>(name));\n-      symbol_type_id_to_function_type_id.emplace(\n-          compiled_symbols.back().type_id, SymbolProto::KERNEL);\n-      TF_CHECK_OK(jit_compiler.AddModule(std::move(module),\n-                                         num_extra_parts + kernel_dylib_index));\n-      // Simply roundrobin the default kernel dylibs\n-      kernel_dylib_index = (kernel_dylib_index + 1) % num_default_parts;\n-    }\n+  int dylib_index = 0;\n+  auto add_jit_module = [&](std::unique_ptr<llvm::Module> llvm_module_part) {\n+    // Collect symbols that are compiled in this LLVM module part.\n+    RemoveUnusedSymbols(*llvm_module_part);\n+    compiled_parts.push_back(\n+        CollectCompiledSymbolsPart(ir_emitter2, *llvm_module_part));\n \n-    for (const CompiledSymbolsPart& part : compiled_parts) {\n-      for (const IrEmitter2::KernelInfo& kernel : part.kernels) {\n-        compiled_symbols.push_back(\n-            FunctionLibrary::Sym<FunctionLibrary::Kernel>(kernel.name));\n-        symbol_type_id_to_function_type_id.emplace(\n-            compiled_symbols.back().type_id, SymbolProto::KERNEL);\n-      }\n-      for (const IrEmitter2::ComparatorInfo& comparator : part.comparators) {\n-        compiled_symbols.push_back(\n-            FunctionLibrary::Sym<FunctionLibrary::Comparator>(comparator.name));\n-        symbol_type_id_to_function_type_id.emplace(\n-            compiled_symbols.back().type_id, SymbolProto::COMPARATOR);\n-      }\n-    }\n+    std::string dump = llvm_ir::DumpToString(llvm_module_part.get());\n+    VLOG(5) << \"Adding compilation module:\\n\" << dump;\n \n-    VLOG(3) << \"Collected \" << compiled_symbols.size() << \" compiled symbols\";\n+    // Clone LLVM module part into its own thread safe context.\n+    auto tsm =\n+        CloneAsThreadSafeModule(dylib_index, std::move(llvm_module_part));\n+    TF_CHECK_OK(jit_compiler.AddModule(std::move(tsm), dylib_index++));\n+  };\n \n-    TraceMe trace_codegen([&] {\n-      return TraceMeEncode(\n-          \"Codegen\", {{\"num_default_parts\", num_default_parts},\n-                      {\"num_extra_parts\", num_extra_parts},\n-                      {\"num_compiled_functions\", num_compiled_functions}});\n+  // If there are extra parts, compile them first, since we must\n+  // remove the affected kernels from the LLVM module.\n+  if (num_extra_parts > 0) {\n+    TraceMe trace([&] {\n+      return TraceMeEncode(\"CompileExtraKernels\",\n+                           {{\"num_extra_parts\", num_extra_parts}});\n     });\n+    for (const auto& [backend_extra_options, kernels] :\n+         backend_extra_options_to_kernels) {\n+      TF_ASSIGN_OR_RETURN(std::unique_ptr<llvm::Module> new_module,\n+                          ExtractKernelsFromModule(llvm_module.get(), kernels));\n+      AddXlaBackendExtraOptionsAsModuleFlag(new_module.get(),\n+                                            backend_extra_options);\n+      add_jit_module(std::move(new_module));\n+    }\n+  }\n \n-    TF_ASSIGN_OR_RETURN(std::unique_ptr<FunctionLibrary> function_library,\n-                        std::move(jit_compiler).Compile(compiled_symbols));\n+  if (HasLargeConstants(*llvm_module)) {\n+    VLOG(3) << \"Skip parallel compilation due to large constants\";\n+    num_default_parts = 1;\n+  }\n \n-    // Create constant allocations from the buffer assignment.\n-    TF_ASSIGN_OR_RETURN(std::vector<ConstantAllocation> constants,\n-                        CreateConstantAllocations(*assignment));\n+  if (num_default_parts > 1) {\n+    VLOG(3) << \"Split LLVM module into \" << num_default_parts\n+            << \" parts before codegen to enable parallel compilation\"\n+            << \" (max split count: \" << parallel_codegen_split_count << \")\";\n \n-    TF_ASSIGN_OR_RETURN(\n-        auto cpu_executable,\n-        CpuExecutable::Create(std::move(function_library),\n-                              std::move(assignment), std::move(module),\n-                              std::move(thunks), std::move(constants),\n-                              std::move(hlo_profile_printer_data),\n-                              std::move(hlo_profile_index_map)));\n+    TraceMe trace([&] {\n+      return TraceMeEncode(\"SplitModule\",\n+                           {{\"num_default_parts\", num_default_parts}});\n+    });\n \n-    // Save object files to be able to export them to AOT compilation\n-    // result.\n-    cpu_executable->set_obj_files(std::move(obj_files));\n+    llvm::SplitModule(*llvm_module, num_default_parts, add_jit_module,\n+                      /*PreserveLocals=*/true, /*RoundRobin=*/true);\n+    // Free resources used by the original LLVM module.\n+    llvm_module.reset();\n+    llvm_context.reset();\n \n-    // Save compiled symbols to be able to export them to AOT compilation\n-    // result.\n-    cpu_executable->set_compiled_symbols(std::move(compiled_symbols));\n+  } else {\n+    VLOG(3) << \"Compile LLVM module without splitting (max split count: \"\n+            << parallel_codegen_split_count << \")\";\n+    compiled_parts.push_back(\n+        CollectCompiledSymbolsPart(ir_emitter2, *llvm_module));\n+    TF_CHECK_OK(jit_compiler.AddModule(llvm::orc::ThreadSafeModule(\n+        std::move(llvm_module), std::move(llvm_context))));\n+  }\n \n-    // Save mapping between symbol type id and function type id to be able to\n-    // export them to AOT compilation result.\n-    cpu_executable->set_symbol_type_id_to_function_type_id(\n-        symbol_type_id_to_function_type_id);\n+  // Collect compiled symbols from all LLVM module parts.\n+  std::vector<FunctionLibrary::Symbol> compiled_symbols;\n \n-    if (embed_ir_in_executable) {\n-      cpu_executable->set_ir_module_string(ir_module_string);\n-    }\n+  absl::flat_hash_map<FunctionLibrary::TypeId, SymbolProto::FunctionTypeId>\n+      symbol_type_id_to_function_type_id;\n \n-    return with_hlo_proto(std::move(cpu_executable));\n+  VLOG(3) << \"Adding \" << kernels.size() << \" kernels to the JIT compiler\";\n+  // Make sure we use all the \"default\" modules for maximum parallelism.\n+  int num_default_so_far = dylib_index - num_extra_parts;\n+  int kernel_dylib_index =\n+      num_default_so_far < num_default_parts ? num_default_so_far : 0;\n+  for (auto& [name, module] : kernels) {\n+    compiled_symbols.push_back(\n+        FunctionLibrary::Sym<FunctionLibrary::Kernel>(name));\n+    symbol_type_id_to_function_type_id.emplace(compiled_symbols.back().type_id,\n+                                               SymbolProto::KERNEL);\n+    TF_CHECK_OK(jit_compiler.AddModule(std::move(module),\n+                                       num_extra_parts + kernel_dylib_index));\n+    // Simply roundrobin the default kernel dylibs\n+    kernel_dylib_index = (kernel_dylib_index + 1) % num_default_parts;\n   }\n \n-  TF_RETURN_IF_ERROR(nested_ir_emitter.EmitAllConstantGlobals());\n-\n-  // Each computation is a single function.  Emit all embedded computations\n-  // before the entry computation. The order of computations returned from\n-  // SubcomputationEmissionOrder guarantees that a called computation occurs\n-  // before a caller computation.\n-  for (ComputationToEmit subcomputation :\n-       SubcomputationEmissionOrder(entry_computation)) {\n-    if (subcomputation.computation->IsFusionComputation()) {\n-      continue;\n+  for (const CompiledSymbolsPart& part : compiled_parts) {\n+    for (const IrEmitter2::KernelInfo& kernel : part.kernels) {\n+      compiled_symbols.push_back(\n+          FunctionLibrary::Sym<FunctionLibrary::Kernel>(kernel.name));\n+      symbol_type_id_to_function_type_id.emplace(\n+          compiled_symbols.back().type_id, SymbolProto::KERNEL);\n+    }\n+    for (const IrEmitter2::ComparatorInfo& comparator : part.comparators) {\n+      compiled_symbols.push_back(\n+          FunctionLibrary::Sym<FunctionLibrary::Comparator>(comparator.name));\n+      symbol_type_id_to_function_type_id.emplace(\n+          compiled_symbols.back().type_id, SymbolProto::COMPARATOR);\n     }\n-    TF_RETURN_IF_ERROR(\n-        nested_ir_emitter\n-            .EmitComputation(\n-                subcomputation.computation, subcomputation.computation->name(),\n-                /*is_top_level_computation=*/false,\n-                schedule.sequence(subcomputation.computation).instructions(),\n-                subcomputation.allow_reassociation)\n-            .status());\n-  }\n-  absl::string_view function_name_prefix = entry_computation->name().empty()\n-                                               ? \"__compute\"\n-                                               : entry_computation->name();\n-  TF_ASSIGN_OR_RETURN(llvm::Function * entry_function,\n-                      nested_ir_emitter.EmitComputation(\n-                          entry_computation, function_name_prefix,\n-                          /*is_top_level_computation=*/true,\n-                          schedule.sequence(entry_computation).instructions(),\n-                          /*allow_reassociation=*/false));\n-\n-  std::string ir_module_string;\n-  if (embed_ir_in_executable) {\n-    ir_module_string = llvm_ir::DumpToString(llvm_module.get());\n   }\n \n-  TF_RETURN_IF_ERROR(VerifyLlvmModule(*llvm_module));\n+  VLOG(3) << \"Collected \" << compiled_symbols.size() << \" compiled symbols\";\n \n-  // Save entry function name before destroying LLVM module.\n-  std::string entry_function_name = entry_function->getName().str();\n+  TraceMe trace_codegen([&] {\n+    return TraceMeEncode(\"Codegen\",\n+                         {{\"num_default_parts\", num_default_parts},\n+                          {\"num_extra_parts\", num_extra_parts},\n+                          {\"num_compiled_functions\", num_compiled_functions}});\n+  });\n \n-  // JIT compile the LLVM IR module to in-memory machine code.\n-  llvm::orc::ThreadSafeModule thread_safe_module(std::move(llvm_module),\n-                                                 std::move(llvm_context));\n-  TF_RETURN_IF_ERROR(jit_compiler.AddModule(std::move(thread_safe_module)));\n+  TF_ASSIGN_OR_RETURN(std::unique_ptr<FunctionLibrary> function_library,\n+                      std::move(jit_compiler).Compile(compiled_symbols));\n \n-  using ComputeFn = std::remove_pointer_t<CpuExecutable::ComputeFunctionType>;\n-  TF_ASSIGN_OR_RETURN(\n-      std::unique_ptr<FunctionLibrary> function_library,\n-      std::move(jit_compiler)\n-          .Compile({FunctionLibrary::Sym<ComputeFn>(entry_function_name)}));\n+  // Create constant allocations from the buffer assignment.\n+  TF_ASSIGN_OR_RETURN(std::vector<ConstantAllocation> constants,\n+                      CreateConstantAllocations(*assignment));\n \n   TF_ASSIGN_OR_RETURN(\n       auto cpu_executable,\n       CpuExecutable::Create(std::move(function_library), std::move(assignment),\n-                            std::move(module), entry_function_name,\n+                            std::move(module), std::move(thunks),\n+                            std::move(constants),\n                             std::move(hlo_profile_printer_data),\n                             std::move(hlo_profile_index_map)));\n \n+  // Save object files to be able to export them to AOT compilation\n+  // result.\n   cpu_executable->set_obj_files(std::move(obj_files));\n \n+  // Save compiled symbols to be able to export them to AOT compilation\n+  // result.\n+  cpu_executable->set_compiled_symbols(std::move(compiled_symbols));\n+\n+  // Save mapping between symbol type id and function type id to be able to\n+  // export them to AOT compilation result.\n+  cpu_executable->set_symbol_type_id_to_function_type_id(\n+      symbol_type_id_to_function_type_id);\n+\n   if (embed_ir_in_executable) {\n     cpu_executable->set_ir_module_string(ir_module_string);\n   }"
        },
        {
            "sha": "e59ab4571bedafc479ac4df3ae5d6805586efc62",
            "filename": "third_party/xla/xla/service/cpu/tests/BUILD",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -313,6 +313,11 @@ xla_cc_test(\n     name = \"onednn_convolution_test\",\n     srcs = [\"onednn_convolution_test.cc\"],\n     copts = tsl_copts(),\n+    tags = [\n+        # TODO: reenable once onednn is supported by the thunk runtime.\n+        \"no_oss\",\n+        \"notap\",\n+    ],\n     deps = [\n         \"//xla:literal\",\n         \"//xla:shape_util\",\n@@ -354,6 +359,11 @@ xla_cc_test(\n     name = \"onednn_layer_norm_test\",\n     srcs = [\"onednn_layer_norm_test.cc\"],\n     copts = tsl_copts(),\n+    tags = [\n+        # TODO: reenable once onednn is supported by the thunk runtime.\n+        \"no_oss\",\n+        \"notap\",\n+    ],\n     deps = [\n         \"//xla/hlo/testlib:test\",\n         \"//xla/service:cpu_plugin\",\n@@ -368,6 +378,11 @@ xla_cc_test(\n     srcs = [\"onednn_softmax_test.cc\"],\n     copts = tsl_copts(),\n     shard_count = if_graph_api(4, 1),\n+    tags = [\n+        # TODO: reenable once onednn is supported by the thunk runtime.\n+        \"no_oss\",\n+        \"notap\",\n+    ],\n     deps = [\n         \"//xla:literal\",\n         \"//xla:shape_util\","
        },
        {
            "sha": "997724a03f56a9b6fdb7d5b881370889fd51dca3",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_convolution_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_convolution_test.cc?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -37,7 +37,6 @@ class ConvolutionTest : public HloTestBase,\n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_cpu_use_thunk_runtime(false);\n     return debug_options;\n   }\n "
        },
        {
            "sha": "57cbe8b3f9475ffa66e3f5de99b8c5449572adf2",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_layer_norm_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_layer_norm_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_layer_norm_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_layer_norm_test.cc?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -26,7 +26,6 @@ class LayerNormTest : public HloTestBase {\n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_cpu_use_thunk_runtime(false);\n     return debug_options;\n   }\n "
        },
        {
            "sha": "15386c85d42cf56b73b7113a3d31b2efb2cf9554",
            "filename": "third_party/xla/xla/service/cpu/tests/onednn_softmax_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_softmax_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b668cab1c7428acb8ac5592585a765b31fe643f2/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_softmax_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fonednn_softmax_test.cc?ref=b668cab1c7428acb8ac5592585a765b31fe643f2",
            "patch": "@@ -49,7 +49,6 @@ class OneDnnSoftmaxTest\n  protected:\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = HloTestBase::GetDebugOptionsForTest();\n-    debug_options.set_xla_cpu_use_thunk_runtime(false);\n     return debug_options;\n   }\n "
        }
    ],
    "stats": {
        "total": 474,
        "additions": 205,
        "deletions": 269
    }
}