{
    "author": "kenfranko",
    "message": "Reverts 2d4dd837737e8cfb7864a91dc04a7f94aba562b3\n\nPiperOrigin-RevId: 822637158",
    "sha": "85c99b1ecb953424a031f172820efacfe73f9613",
    "files": [
        {
            "sha": "d1aebe6ac976778ebe3784ebc90f8b15c72fe1e5",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=85c99b1ecb953424a031f172820efacfe73f9613",
            "patch": "@@ -325,10 +325,6 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   // default value of the command line flag in `MakeDebugOptionsFlags`.\n   opts.add_xla_gpu_unsupported_generic_triton_emitter_features(\n       DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM);\n-  opts.add_xla_gpu_unsupported_generic_triton_emitter_features(\n-      DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_GEMM_SHAPES);\n-  opts.add_xla_gpu_unsupported_generic_triton_emitter_features(\n-      DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_OPS_IN_GEMM_FUSION);\n   opts.set_xla_gpu_unsupported_enable_triton_multi_output_fusion(true);\n   opts.set_xla_gpu_enable_cudnn_int8x32_convolution_reordering(true);\n   opts.set_xla_gpu_triton_gemm_any(true);"
        },
        {
            "sha": "5dd25afa5387ab7481c1cd27634a0549029a242d",
            "filename": "third_party/xla/xla/debug_options_parsers_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 12,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_parsers_test.cc?ref=85c99b1ecb953424a031f172820efacfe73f9613",
            "patch": "@@ -390,37 +390,35 @@ TEST(ParseRepeatedEnumFlagsTest, GenericTritonEmitterFeatures) {\n   const auto& enabled_features =\n       debug_options.xla_gpu_unsupported_generic_triton_emitter_features();\n \n-  // Check default setting.\n+  // Check that the default setting is empty.\n   ASSERT_THAT(\n       enabled_features,\n-      testing::UnorderedElementsAre(\n-          DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM,\n-          DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_GEMM_SHAPES,\n-          DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_OPS_IN_GEMM_FUSION));\n+      ElementsAre(DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM));\n \n   // Initialize the flag objects.\n   std::vector<tsl::Flag> flag_objects;\n   MakeDebugOptionsFlags(&flag_objects, &debug_options);\n \n   // Adding options.\n   SetXlaFlagsEnvVar(\n-      \"--xla_gpu_unsupported_generic_triton_emitter_features=\"\n-      \"-allow_all_gemm_shapes\");\n+      \"--xla_gpu_unsupported_generic_triton_emitter_features=+allow_all_gemm_\"\n+      \"shapes\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n+  EXPECT_EQ(enabled_features.size(), 2);\n   EXPECT_THAT(\n       enabled_features,\n-      testing::UnorderedElementsAre(\n-          DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM,\n-          DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_OPS_IN_GEMM_FUSION));\n+      ElementsAre(DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM,\n+                  DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_GEMM_SHAPES));\n \n   // Overwriting options.\n   SetXlaFlagsEnvVar(\n       \"--xla_gpu_unsupported_generic_triton_emitter_features=disable_legacy_\"\n       \"gemm,allow_all_ops_in_gemm_fusion\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n+  EXPECT_EQ(enabled_features.size(), 2);\n   EXPECT_THAT(\n       enabled_features,\n-      testing::UnorderedElementsAre(\n+      ElementsAre(\n           DebugOptions::GENERIC_TRITON_EMITTER_DISABLE_LEGACY_GEMM,\n           DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_OPS_IN_GEMM_FUSION));\n \n@@ -429,9 +427,10 @@ TEST(ParseRepeatedEnumFlagsTest, GenericTritonEmitterFeatures) {\n       \"--xla_gpu_unsupported_generic_triton_emitter_features=-disable_legacy_\"\n       \"gemm,-unspecified,+enable_nested_gemm,+allow_all_ops_in_gemm_fusion\");\n   ParseFlagsFromEnvAndDieIfUnknown(\"XLA_FLAGS\", flag_objects);\n+  EXPECT_EQ(enabled_features.size(), 2);\n   EXPECT_THAT(\n       enabled_features,\n-      testing::UnorderedElementsAre(\n+      ElementsAre(\n           DebugOptions::GENERIC_TRITON_EMITTER_ALLOW_ALL_OPS_IN_GEMM_FUSION,\n           DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM));\n }"
        },
        {
            "sha": "4f4c5f947c2966703242db5484f0d1026ca7bf60",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=85c99b1ecb953424a031f172820efacfe73f9613",
            "patch": "@@ -1068,7 +1068,8 @@ GemmFusionAutotunerImpl::CompileAll(AutotunerCompileUtil& compile_util,\n       if (code == absl::StatusCode::kInternal ||\n           code == absl::StatusCode::kFailedPrecondition ||\n           code == absl::StatusCode::kUnimplemented ||\n-          code == absl::StatusCode::kInvalidArgument) {\n+          (debug_options_.xla_gpu_exhaustive_tiling_search() &&\n+           code == absl::StatusCode::kInvalidArgument)) {\n         VLOG(5) << \"Compilation failed with status \" << executable_or.status()\n                 << \" that is ignored\";\n         return nullptr;"
        },
        {
            "sha": "c592b558fdf340de7d2e2471a402ff1ce5382cf1",
            "filename": "third_party/xla/xla/service/gpu/determinism_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fdeterminism_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fdeterminism_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fdeterminism_test.cc?ref=85c99b1ecb953424a031f172820efacfe73f9613",
            "patch": "@@ -50,6 +50,10 @@ class DeterminismTest : public GpuCodegenTest {\n  public:\n   DeterminismTest() : debug_options_(HloTestBase::GetDebugOptionsForTest()) {\n     debug_options_.set_xla_gpu_exclude_nondeterministic_ops(true);\n+    // TODO(b/393299275): remove when the flag is enabled by default.\n+    debug_options_.clear_xla_gpu_unsupported_generic_triton_emitter_features();\n+    debug_options_.add_xla_gpu_unsupported_generic_triton_emitter_features(\n+        DebugOptions::GENERIC_TRITON_EMITTER_ENABLE_NESTED_GEMM);\n   }\n \n   se::CudaComputeCapability get_cuda_cc() const {"
        },
        {
            "sha": "439e55c7473e268e9ad8e56dd9837b1a68984ea6",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/85c99b1ecb953424a031f172820efacfe73f9613/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion_test.cc?ref=85c99b1ecb953424a031f172820efacfe73f9613",
            "patch": "@@ -192,8 +192,7 @@ ENTRY e {\n               GmockMatch(match::Concatenate(match::Fusion(), match::Fusion())));\n }\n \n-// TODO(b/393299275): update test to use a unsupported operation.\n-TEST_F(NestGemmFusionTest, DISABLED_UnsupportedComputationsAreNotChanged) {\n+TEST_F(NestGemmFusionTest, UnsupportedComputationsAreNotChanged) {\n   // Fusions other than kTritonNestedGemmFusionKind are not supported.\n   // In this case pass should only change the supported fusions.\n   absl::string_view hlo = R\"("
        }
    ],
    "stats": {
        "total": 37,
        "additions": 18,
        "deletions": 19
    }
}