{
    "author": "subhankarshah",
    "message": "Cleanup: Remove `types` and `_types` modules from `xla/python/tools` because it is dead code\n\nPiperOrigin-RevId: 825262464",
    "sha": "a7654beb5c4146750b0a5964540bef3eba2f09bb",
    "files": [
        {
            "sha": "db2cb0f2a71de918cb61842b4bd77ee6dd6748d8",
            "filename": "third_party/xla/xla/python/tools/BUILD",
            "status": "removed",
            "additions": 0,
            "deletions": 92,
            "changes": 92,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2FBUILD?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a",
            "patch": "@@ -1,92 +0,0 @@\n-load(\"//xla:py_strict.bzl\", \"py_strict_test\")\n-\n-# NOTE: We can't use `pytype_pybind_extension` nor `pytype_strict_contrib_test`\n-# because the OSS versions of these files do not include ports of those rules.\n-# We must instead use `tsl_pybind_extension` and `py_strict_test`.\n-load(\"//xla:pytype.bzl\", \"pytype_strict_library\")\n-load(\"//xla/tsl:tsl.default.bzl\", \"tsl_pybind_extension\")\n-\n-package(\n-    # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n-    licenses = [\"notice\"],\n-)\n-\n-exports_files([\n-    \"__init__.py\",\n-    \"types.py\",\n-    \"_types.pyi\",\n-])\n-\n-# NOTE: This wrapper library is necessary in order to capture the Python\n-# dependencies of our extension (namely `ml_dtypes`).  Although the\n-# underlying `pybind_extension` rule has a `py_deps` argument for capturing\n-# such dependencies directly, the `tsl_pybind_extension` rule doesn't expose\n-# that `py_deps` argument for us to use.\n-#\n-# NOTE: On the OSS side, the `pytype_strict_library` rule is changed into\n-# the non-typed rule, which in turn causes an error about the `pytype_srcs`\n-# field.  The \"..:xla_client\" target gets around this by adding a custom\n-# copybara rule; but in lieu of adding yet another custom rule to maintain,\n-# we just use the generic copybara mechanism for commenting the field out\n-# on the OSS side.\n-# TODO(wrengr,phawkins): Once cl/619904840 lands, we can remove the\n-# pragma and the preceding commentary.\n-pytype_strict_library(\n-    name = \"types\",\n-    srcs = [\"types.py\"],\n-    # copybara:uncomment pytype_srcs = [\"_types.pyi\"],\n-    # Cannot build this on OSS because the \":xla_data_proto_py_pb2\"\n-    # dependency isn't part of the public API.\n-    tags = [\"no_oss\"],\n-    # TODO(dsuo): Should this be public given note above?\n-    visibility = [\"//visibility:public\"],\n-    deps = [\n-        \":_types\",  # buildcleaner: keep\n-        \"//third_party/py/numpy\",\n-        \"//xla:xla_data_proto_py\",\n-        \"@ml_dtypes_py//ml_dtypes\",\n-    ],\n-)\n-\n-# NOTE: Copybara detects the `tsl_pybind_extension` rule and automatically\n-# injects the @com_google_protobuf//:protobuf_python python dependency\n-# required by \"@pybind11_protobuf//pybind11_protobuf:native_proto_caster\".\n-tsl_pybind_extension(\n-    name = \"_types\",\n-    srcs = [\"_types.cc\"],\n-    pytype_deps = [\"//third_party/py/numpy\"],\n-    pytype_srcs = [\"_types.pyi\"],\n-    # Users should depend on \":types\" instead.\n-    visibility = [\"//visibility:private\"],\n-    deps = [\n-        \"//xla:literal\",\n-        \"//xla:xla_data_proto_cc\",\n-        \"//xla/pjrt:status_casters\",\n-        \"//xla/python:logging\",\n-        \"//xla/python:nb_numpy\",\n-        \"//xla/python:types\",\n-        \"//xla/tsl/python/lib/core:numpy\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@nanobind\",\n-        \"@pybind11\",\n-        \"@pybind11_abseil//pybind11_abseil:import_status_module\",\n-        \"@pybind11_protobuf//pybind11_protobuf:native_proto_caster\",\n-    ],\n-)\n-\n-py_strict_test(\n-    name = \"types_test\",\n-    size = \"small\",\n-    srcs = [\"types_test.py\"],\n-    # Cannot build this on OSS because the \":xla_data_proto_py_pb2\"\n-    # dependency isn't part of the public API.\n-    tags = [\"no_oss\"],\n-    deps = [\n-        \":types\",\n-        \"@absl_py//absl/testing:absltest\",\n-        \"@absl_py//absl/testing:parameterized\",\n-        # copybara:uncomment \"//third_party/py/google/protobuf:use_fast_cpp_protos\",\n-        \"//third_party/py/numpy\",\n-        \"//xla:xla_data_proto_py\",\n-    ],\n-)"
        },
        {
            "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391",
            "filename": "third_party/xla/xla/python/tools/__init__.py",
            "status": "removed",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F__init__.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F__init__.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F__init__.py?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a"
        },
        {
            "sha": "fb44e3c64ef2e255a52018f66ec9f3252584a7c7",
            "filename": "third_party/xla/xla/python/tools/_types.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 161,
            "changes": 161,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.cc?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a",
            "patch": "@@ -1,161 +0,0 @@\n-/* Copyright 2024 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"absl/strings/str_cat.h\"\n-#include \"nanobind/nanobind.h\"\n-#include \"nanobind/stl/shared_ptr.h\"  // IWYU pragma: keep\n-#include \"pybind11/detail/common.h\"\n-#include \"pybind11/numpy.h\"\n-#include \"pybind11/pybind11.h\"\n-#include \"pybind11/pytypes.h\"\n-// The \"pybind11_abseil/status_casters.h\" header says\n-// it's deprecated and that we should import the other headers directly.\n-#include \"pybind11_abseil/import_status_module.h\"\n-#include \"pybind11_protobuf/native_proto_caster.h\"\n-#include \"xla/literal.h\"\n-#include \"xla/pjrt/status_casters.h\"\n-#include \"xla/python/logging.h\"\n-#include \"xla/python/nb_numpy.h\"\n-#include \"xla/python/types.h\"\n-#include \"xla/xla_data.pb.h\"\n-// NOTE: The tsl-numpy header forbids importing the actual NumPy arrayobject.h\n-// header before tsl-numpy (whereas, importing pybind11-numpy before tsl-numpy\n-// is fine); however, tsl-numpy does reexport NumPy's arrayobject.h header.\n-// Since one of the TF headers above already includes tsl-numpy, therefore\n-// we must include it down here rather than including actual NumPy directly.\n-#include \"xla/tsl/python/lib/core/numpy.h\"\n-\n-namespace py = ::pybind11;\n-namespace nb = ::nanobind;\n-\n-namespace {\n-py::object MakeNdarray(const xla::LiteralProto& proto) {\n-  auto m_lit = xla::Literal::CreateFromProto(proto);\n-  if (!m_lit.ok()) {\n-    // NOTE: The OSS version of XLA is still using an old version of\n-    // Abseil (LTS branch, Aug 2023, Patch 1) which does not have the\n-    // `AbslStringify` interface for implicitly converting `absl::Status`\n-    // into the `absl::AlphaNum` required by `absl::StrCat`.  Therefore we\n-    // inline the latest definition of the `AbslStringify` overload.\n-    throw py::value_error(absl::StrCat(\n-        \"Cannot `xla::Literal::CreateFromProto`: \",\n-        m_lit.status().ToString(absl::StatusToStringMode::kWithEverything)));\n-  }\n-\n-  // Move (not copy) the literal onto the heap, for sharing with Python.\n-  auto lit = std::make_shared<xla::Literal>(std::move(m_lit).value());\n-\n-  auto nbobj = xla::ValueOrThrow(xla::LiteralToPython(std::move(lit)));\n-  return py::reinterpret_steal<py::object>(nbobj.release().ptr());\n-}\n-\n-// Partial reversion of cl/617156835, until we can get the proto-casters\n-// (and hence the extension) switched over to nanobind.\n-// TODO(wrengr): Or can we mix `{py,nb}::module_::def` calls??\n-xla::PrimitiveType DtypeToEtype(const py::dtype& py_d) {\n-  auto nb_d = nb::borrow<xla::nb_dtype>(py_d.ptr());\n-  return xla::ValueOrThrow(xla::DtypeToPrimitiveType(nb_d));\n-}\n-\n-py::dtype EtypeToDtype(xla::PrimitiveType p) {\n-  auto nb_d = xla::ValueOrThrow(xla::PrimitiveTypeToNbDtype(p));\n-  return py::reinterpret_steal<py::dtype>(nb_d.release().ptr());\n-}\n-}  // namespace\n-\n-// NOTE: It seems insurmountable to get \"native_proto_caster.h\" to work\n-// with nanobind modules; therefore, we define our extension as a pybind11\n-// module so that we can use `pybind11::module_::def`.\n-PYBIND11_MODULE(_types, py_m) {\n-  // Initialize ABSL logging because code within XLA uses it.\n-  // (As per `xla::Init` in \"xla.cc\"; though we don't need it ourselves.)\n-#ifndef PLATFORM_GOOGLE\n-  xla::InitializeAbslLogging();\n-#endif  // PLATFORM_GOOGLE\n-\n-  // Normally this would happen at the start of NB_MODULE, but since\n-  // this is a pybind11 module we have to do this ourselves.\n-  // (As per `xla::Init` in \"xla.cc\".)\n-  nb::detail::init(NB_DOMAIN_STR);\n-\n-  // Import implicit conversions from Python protobuf objects to C++\n-  // protobuf objects.\n-  pybind11_protobuf::ImportNativeProtoCasters();\n-\n-  // Import dependencies for converting `absl::StatusOr` to Python exceptions.\n-  // This also brings into scope pybind11 casters for doing conversions\n-  // implicitly; however, towards the goal of converting everything to\n-  // nanobind, we call `xla::ValueOrThrow` to make make the conversions\n-  // explicit (since `nb::detail::type_caster` disallows raising exceptions,\n-  // and therefore nanobind cannot do this implicitly).\n-  py::google::ImportStatusModule();\n-\n-  // Import the 'ml_dtypes' module; which is implicitly required by\n-  // `xla::LiteralToPython`.\n-  // NOTE: If the `tsl_pybind_extension` build rule allowed us to specify\n-  // this as a py_dep, then importing the module here would mean that\n-  // client Python code need not import the hidden dependency themselves.\n-  // However, since `tsl_pybind_extension` does not allow specifying py_deps,\n-  // if client rules do not themselves declare the dependency then this will\n-  // generate a `ModuleNotFoundError` / `ImportError` exception.  Hence why\n-  // we define the \"types.py\" wrapper library to encapsulate the dependency.\n-  py::module_::import(\"ml_dtypes\");\n-\n-  // Ensure that tsl-numpy initializes datastructures of the actual-NumPy\n-  // implementation, and does whatever else tsl-numpy needs.  This is\n-  // also necessary for using the `xla::nb_dtype` type.\n-  tsl::ImportNumpy();\n-\n-  // Declare that C++ can `nb::cast` from `std::shared_ptr<xla::Literal>`\n-  // to `nb::object`; which is implicitly required by `xla::LiteralToPython`.\n-  // (FWIW: This also enables using `nb::type<xla::Literal>()` to get\n-  // the Python-type-object associated with the C++ class.)\n-  //\n-  // NOTE: This does *not* mean that C++ can `py::cast` from `xla::Literal`\n-  // to `py::object`.  It's unclear whether we can simultaneously provide\n-  // both nanobind and pybind11 bindings (if we wanted the latter).\n-  nb::module_ nb_m = nb::cast<nb::module_>(nb::borrow(py_m.ptr()));\n-  nb::class_<xla::Literal>(nb_m, \"Literal\")\n-      .def(\"__repr__\", &xla::Literal::ToString);\n-\n-  // We do not define `py_m.doc()` here, since it wouldn't be inherited\n-  // by the \"types.py\" wrapper library.  See there for the python docstring.\n-\n-  // LINT.IfChange\n-  py_m.def(\"make_ndarray\", &MakeNdarray, py::arg(\"proto\").none(false),\n-           py::pos_only(), R\"pbdoc(\n-    Converts `tensorflow.compiler.xla.xla_data_pb2.LiteralProto`\n-    into an `xla::Literal` and then converts that literal into a tree\n-    of tuples with leaves being `numpy.ndarray` views of array-shaped\n-    sub-literals.\n-  )pbdoc\");\n-\n-  // This method name is based on `xla_client.dtype_to_etype`.\n-  // NOTE: `xla_client` uses a Python class wrapping the protobuf-enum,\n-  // rather than using the protobuf-enum directly.  See the module docstring\n-  // in \"types.py\" for more explanation on why.\n-  py_m.def(\"dtype_to_etype\", &DtypeToEtype, py::arg(\"dtype\").none(false),\n-           py::pos_only(), R\"pbdoc(\n-    Converts `numpy.dtype` into\n-    `tensorflow.compiler.xla.xla_data_pb2.PrimitiveType`.\n-  )pbdoc\");\n-\n-  py_m.def(\"etype_to_dtype\", &EtypeToDtype, py::arg(\"ptype\").none(false),\n-           py::pos_only(), R\"pbdoc(\n-    Converts `tensorflow.compiler.xla.xla_data_pb2.PrimitiveType` into\n-    `numpy.dtype`.\n-  )pbdoc\");\n-  // LINT.ThenChange(_types.pyi)\n-}"
        },
        {
            "sha": "f355656f05b6748de087c821de28bc711f195bb5",
            "filename": "third_party/xla/xla/python/tools/_types.pyi",
            "status": "removed",
            "additions": 0,
            "deletions": 25,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.pyi",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.pyi",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2F_types.pyi?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a",
            "patch": "@@ -1,25 +0,0 @@\n-# Copyright 2024 The OpenXLA Authors.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\n-from typing import Union\n-import numpy as np\n-from xla import xla_data_pb2\n-\n-# LINT.IfChange\n-NdarrayTree = Union[np.ndarray, tuple['NdarrayTree', ...]]\n-def make_ndarray(proto: xla_data_pb2.LiteralProto, /) -> NdarrayTree: ...\n-def dtype_to_etype(dtype: np.dtype, /) -> xla_data_pb2.PrimitiveType: ...\n-def etype_to_dtype(ptype: xla_data_pb2.PrimitiveType, /) -> np.dtype: ...\n-# LINT.ThenChange(types.py, _types.cc)"
        },
        {
            "sha": "189758f1e749c836751d33e8f43e1b3f52737b40",
            "filename": "third_party/xla/xla/python/tools/types.py",
            "status": "removed",
            "additions": 0,
            "deletions": 53,
            "changes": 53,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes.py?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a",
            "patch": "@@ -1,53 +0,0 @@\n-# Copyright 2024 The OpenXLA Authors.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\"\"\"tensorflow.compiler.xla.python.tools.types.\n-\n-This module provides Python bindings for various functions in\n-'tensorflow/compiler/xla/python/types.h'.  It is primarily intended\n-to assist internal users in debugging things; and is not considered\n-part of the public API for OpenXLA.\n-\n-NOTE: This module *does* depend on Python protocol buffers; so beware!\n-The XLA Python bindings are currently packaged both as part of jaxlib and\n-as part of TensorFlow.  Therefore, since we use protocol buffers here,\n-importing both jaxlib and TensorFlow may fail with duplicate protocol\n-buffer message definitions.\n-\"\"\"\n-\n-from typing import Union\n-# NOTE: `ml_dtypes` is implicitly required by `xla::LiteralToPython`.\n-# The entire goal of this wrapper library is to capture this dependency,\n-# so that client code need not be aware of it.\n-import ml_dtypes  # pylint: disable=unused-import\n-import numpy\n-# NOTE: These protos are not part of TensorFlow's public API, therefore\n-# we cannot abide by [g-direct-tensorflow-import].\n-# pylint: disable=g-direct-tensorflow-import,unused-import\n-from local_xla.xla import xla_data_pb2\n-# pylint: enable=g-direct-tensorflow-import,unused-import\n-\n-# NOTE: `import <name> as <name>` is required for names to be exported.\n-# See PEP 484 & <https://github.com/google/jax/issues/7570>\n-# pylint: disable=g-importing-member,useless-import-alias,unused-import,g-multiple-import\n-# LINT.IfChange\n-from ._types import (\n-    make_ndarray as make_ndarray,\n-    dtype_to_etype as dtype_to_etype,\n-    etype_to_dtype as etype_to_dtype,\n-)\n-# TODO(wrengr): We can't import the `NdarrayTree` defined in the pyi file.\n-# So re-defining it here for now.\n-NdarrayTree = Union[numpy.ndarray, tuple['NdarrayTree', ...]]\n-# LINT.ThenChange(_types.pyi)"
        },
        {
            "sha": "a6cdb1d0f76b13f7042cd50b22d037d6157fc72c",
            "filename": "third_party/xla/xla/python/tools/types_test.py",
            "status": "removed",
            "additions": 0,
            "deletions": 181,
            "changes": 181,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5f9bd8099bce0fdcaf53fda2f252314554c827a/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftools%2Ftypes_test.py?ref=f5f9bd8099bce0fdcaf53fda2f252314554c827a",
            "patch": "@@ -1,181 +0,0 @@\n-# Copyright 2024 The OpenXLA Authors.\n-#\n-# Licensed under the Apache License, Version 2.0 (the \"License\");\n-# you may not use this file except in compliance with the License.\n-# You may obtain a copy of the License at\n-#\n-#     http://www.apache.org/licenses/LICENSE-2.0\n-#\n-# Unless required by applicable law or agreed to in writing, software\n-# distributed under the License is distributed on an \"AS IS\" BASIS,\n-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-# See the License for the specific language governing permissions and\n-# limitations under the License.\n-# ==============================================================================\n-\n-import itertools\n-import math\n-import re\n-from typing import List, NamedTuple\n-\n-from absl.testing import absltest\n-from absl.testing import parameterized\n-import numpy as np\n-\n-# NOTE: These protos are not part of the public API, therefore we cannot\n-# abide by [g-direct-tensorflow-import].\n-# pylint: disable=g-direct-tensorflow-import\n-from local_xla.xla import xla_data_pb2\n-from xla.python.tools import types\n-# pylint: enable=g-direct-tensorflow-import\n-\n-\n-class MakeNdarrayInvalidTest(absltest.TestCase):\n-  \"\"\"Tests for invalid/unsupported arguments to `make_ndarray`.\"\"\"\n-\n-  def setUp(self):\n-    super().setUp()\n-    self.assert_cannot_create_from_proto = self.assertRaisesRegex(\n-        ValueError, re.escape('Cannot `xla::Literal::CreateFromProto`')\n-    )\n-\n-  # NOTE: The `Literal(const Shape&, bool, ArrayValueState)` ctor does\n-  # a CHECK forbidding `element_size_in_bits` from being specified;\n-  # so we can't test anything about custom sizes here.\n-\n-  def testMissingLayout(self):\n-    # NOTE: `CreateFromProto` requires explicit `shape.layout.minor_to_major`.\n-    # Though in principle it could use a default ctor instead, like we\n-    # do in `make_named_parameter` below`.\n-    pb = xla_data_pb2.LiteralProto(\n-        shape=xla_data_pb2.ShapeProto(\n-            element_type=xla_data_pb2.PrimitiveType.F64,\n-            dimensions=[1, 2, 3],\n-        )\n-    )\n-    with self.assert_cannot_create_from_proto:\n-      types.make_ndarray(pb)\n-\n-  def testMissingMinorToMajor(self):\n-    # NOTE: `CreateFromProto` requires explicit `shape.layout.minor_to_major`.\n-    # Though in principle it could use a default ctor instead, like we\n-    # do in `make_named_parameter` below`.\n-    pb = xla_data_pb2.LiteralProto(\n-        shape=xla_data_pb2.ShapeProto(\n-            element_type=xla_data_pb2.PrimitiveType.F64,\n-            dimensions=[1, 2, 3],\n-            layout=xla_data_pb2.LayoutProto(),\n-        )\n-    )\n-    with self.assert_cannot_create_from_proto:\n-      types.make_ndarray(pb)\n-\n-  def testInvalidPrimitiveType(self):\n-    # NOTE: The `is_dynamic_dimension` field isn't required by\n-    # `CreateFromProto`; however, the `Shape(const ShapeProto&)` ctor\n-    # will log warnings if we leave it unspecified.\n-    pb = xla_data_pb2.LiteralProto(\n-        shape=xla_data_pb2.ShapeProto(\n-            element_type=xla_data_pb2.PrimitiveType.PRIMITIVE_TYPE_INVALID,\n-            dimensions=[1, 2, 3],\n-            is_dynamic_dimension=[False, False, False],\n-            layout=xla_data_pb2.LayoutProto(\n-                minor_to_major=[0, 1, 2],\n-            ),\n-        )\n-    )\n-    with self.assert_cannot_create_from_proto:\n-      types.make_ndarray(pb)\n-\n-  def testHasDimLevelTypes(self):\n-    # NOTE: `CreateFromProto` forbids `dim_level_types` (even if all-dense).\n-    pb = xla_data_pb2.LiteralProto(\n-        shape=xla_data_pb2.ShapeProto(\n-            element_type=xla_data_pb2.PrimitiveType.F64,\n-            dimensions=[1, 2, 3],\n-            is_dynamic_dimension=[False, False, False],\n-            layout=xla_data_pb2.LayoutProto(\n-                dim_level_types=[\n-                    xla_data_pb2.DimLevelType.DIM_DENSE,\n-                    xla_data_pb2.DimLevelType.DIM_DENSE,\n-                    xla_data_pb2.DimLevelType.DIM_DENSE,\n-                ],\n-                minor_to_major=[0, 1, 2],\n-            ),\n-        )\n-    )\n-    with self.assert_cannot_create_from_proto:\n-      types.make_ndarray(pb)\n-\n-\n-class MakeNdarrayValidTestParameter(NamedTuple):\n-  testcase_name: str\n-  proto: xla_data_pb2.LiteralProto\n-  arr: np.ndarray\n-\n-\n-def make_named_parameter(\n-    testcase_name: str,\n-    dimensions: List[int],\n-    data: List[float],\n-) -> MakeNdarrayValidTestParameter:\n-  \"\"\"Helper function to construct parameters for `MakeNdarrayValidTest`.\"\"\"\n-  assert math.prod(dimensions) == len(data)\n-  nd = len(dimensions)\n-  proto = xla_data_pb2.LiteralProto(\n-      shape=xla_data_pb2.ShapeProto(\n-          element_type=xla_data_pb2.PrimitiveType.F64,\n-          dimensions=dimensions,\n-          is_dynamic_dimension=itertools.repeat(False, nd),\n-          layout=xla_data_pb2.LayoutProto(\n-              minor_to_major=range(nd),\n-          ),\n-      ),\n-      f64s=data,\n-  )\n-  arr = types.make_ndarray(proto)\n-  return MakeNdarrayValidTestParameter(testcase_name, proto, arr)\n-\n-\n-@parameterized.named_parameters(\n-    make_named_parameter('A', [2, 3], [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]),\n-    make_named_parameter('B', [1, 2, 3], [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]),\n-    make_named_parameter('C', [2, 3], [5.0, 4.0, 3.0, 2.0, 1.0, 0.0]),\n-    make_named_parameter('D', [3, 2], [5.0, 4.0, 3.0, 2.0, 1.0, 0.0]),\n-)\n-class MakeNdarrayValidTest(parameterized.TestCase):\n-  \"\"\"Correctness tests for valid arguments to `make_ndarray`.\"\"\"\n-\n-  def testHasCorrectDtype(self, proto, arr):\n-    \"\"\"Test that the result has the right dtype.\"\"\"\n-    e = proto.shape.element_type\n-    d = arr.dtype\n-    with self.subTest(msg='etype_to_dtype'):\n-      self.assertEqual(types.etype_to_dtype(e), d)\n-    with self.subTest(msg='dtype_to_etype'):\n-      self.assertEqual(e, types.dtype_to_etype(d))\n-\n-  def testHasCorrectRank(self, proto, arr):\n-    \"\"\"Test that the result has the right rank.\"\"\"\n-    self.assertLen(proto.shape.dimensions, arr.ndim)\n-\n-  def testHasCorrectShape(self, proto, arr):\n-    \"\"\"Test that the result has the same/right shape.\"\"\"\n-    self.assertTupleEqual(tuple(proto.shape.dimensions), arr.shape)\n-\n-  def testHasCorrectData(self, proto, arr):\n-    \"\"\"Test that the result has the same/right data.\"\"\"\n-    # TODO(wrengr): Figure out a way to abstract away the name of the\n-    # proto field containing the data; so that we can test multiple types.\n-    self.assertSequenceAlmostEqual(proto.f64s, list(np.nditer(arr)))\n-\n-  # TODO(wrengr): Add tests for:\n-  # * dynamic dimension sizes.\n-  # * non-trivial `minor_to_major`.\n-  # * problematic types {PRED,F16,C64,C128} are all handled correctly.\n-  # * BF16 is handled correctly.\n-  # * tuples are handled correctly\n-\n-\n-if __name__ == '__main__':\n-  absltest.main()"
        }
    ],
    "stats": {
        "total": 512,
        "additions": 0,
        "deletions": 512
    }
}