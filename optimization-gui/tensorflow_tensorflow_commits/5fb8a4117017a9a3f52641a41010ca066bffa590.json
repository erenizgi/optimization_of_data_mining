{
    "author": "metaflow",
    "message": "[XLA:GPU] inline multiple nested fusions in triton fusion numerics verifier\n\nwe have cases when there are multiple level of nested fusions\n\nPiperOrigin-RevId: 807411709",
    "sha": "5fb8a4117017a9a3f52641a41010ca066bffa590",
    "files": [
        {
            "sha": "a8f83004785e6535babc3db5afafb8a402631f38",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=5fb8a4117017a9a3f52641a41010ca066bffa590",
            "patch": "@@ -2969,9 +2969,13 @@ cc_library(\n         \"//xla/backends/gpu/runtime:buffer_comparator\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/hlo/pass:hlo_pass_pipeline\",\n+        \"//xla/hlo/transforms/simplifiers:hlo_dce\",\n+        \"//xla/service:call_inliner\",\n         \"//xla/service:dump\",\n         \"//xla/service:executable\",\n         \"//xla/service:hlo_cost_analysis\",\n+        \"//xla/service:hlo_cse\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:shaped_buffer\",\n         \"//xla/service/gpu:backend_configs_cc\","
        },
        {
            "sha": "827f90486ee4eda29768b5ce5001aadccfb0ddd0",
            "filename": "third_party/xla/xla/service/gpu/transforms/triton_fusion_numerics_verifier.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 11,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier.cc?ref=5fb8a4117017a9a3f52641a41010ca066bffa590",
            "patch": "@@ -26,12 +26,16 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/buffer_comparator.h\"\n+#include \"xla/hlo/ir/dfs_hlo_visitor_with_default.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_print_options.h\"\n+#include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n+#include \"xla/hlo/transforms/simplifiers/hlo_dce.h\"\n+#include \"xla/service/call_inliner.h\"\n #include \"xla/service/dump.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/autotuning/autotuner_compile_util.h\"\n@@ -45,6 +49,7 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/priority_fusion.h\"\n #include \"xla/service/gpu/transforms/tree_reduction_rewriter.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n+#include \"xla/service/hlo_cse.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/shaped_buffer.h\"\n #include \"xla/shape.h\"\n@@ -82,6 +87,37 @@ absl::StatusOr<const HloFusionInstruction*> AsTritonFusion(\n   return nullptr;\n }\n \n+class FusionToCallVisitor : public DfsHloRewriteVisitor {\n+ public:\n+  absl::Status HandleFusion(HloInstruction* hlo) override {\n+    auto* fusion = Cast<HloFusionInstruction>(hlo);\n+\n+    std::unique_ptr<HloInstruction> new_call =\n+        HloInstruction::CreateCall(fusion->shape(), fusion->operands(),\n+                                   fusion->fused_instructions_computation());\n+    return ReplaceWithNewInstruction(fusion, std::move(new_call));\n+  }\n+};\n+\n+absl::Status InlineModuleFusions(HloModule* hlo_module) {\n+  // HLO module for the triton emitter might contain multiple nested fusions.\n+  // Other emitters might not support them, thus we need to inline all fusions.\n+  while (true) {\n+    FusionToCallVisitor visitor;\n+    TF_RETURN_IF_ERROR(hlo_module->entry_computation()->Accept(&visitor));\n+    if (!visitor.changed()) {\n+      return absl::OkStatus();\n+    }\n+    HloPassPipeline pipeline(\"inline-fusions\");\n+    pipeline.AddPass<CallInliner>();\n+    pipeline.AddPass<HloCSE>(/*is_layout_sensitive=*/false);\n+    pipeline.AddPass<HloDCE>();\n+    TF_RETURN_IF_ERROR(pipeline.Run(hlo_module).status());\n+    VLOG(2) << \"After inline call: \" << hlo_module->ToString();\n+  }\n+  return absl::OkStatus();\n+}\n+\n // Extracts the fusion computation and re-runs the fusion pass in order to make\n // sure that the fusions are suitable for the MLIR emitters and will be\n // reasonably fast. Without this the generated code can be extremely slow (e.g.\n@@ -92,17 +128,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> NewHloModuleFromFusionComputation(\n   std::unique_ptr<HloModule> new_module =\n       ExtractComputationIntoNewModule(*fusion.fused_instructions_computation());\n   new_module->mutable_config().set_debug_options(debug_opts);\n-  // Make sure that nested fusions do not trigger the generic triton emitter. We\n-  // can do that by clearing the backend config and setting the fusion kind to\n-  // loop.\n-  for (HloComputation* computation : new_module->computations()) {\n-    for (HloInstruction* instruction : computation->instructions()) {\n-      if (instruction->opcode() == HloOpcode::kFusion) {\n-        instruction->clear_backend_config();\n-        instruction->set_fusion_kind(HloInstruction::FusionKind::kLoop);\n-      }\n-    }\n-  }\n+  TF_RETURN_IF_ERROR(InlineModuleFusions(new_module.get()));\n   TreeReductionRewriter tree_reduction_rewriter(gpu_device_info);\n   TF_RETURN_IF_ERROR(tree_reduction_rewriter.Run(new_module.get()).status());\n   TF_RETURN_IF_ERROR(DotAlgorithmRewriter().Run(new_module.get()).status());"
        },
        {
            "sha": "b652f5556e0b43fafcdc60b20f2a6680abb608c6",
            "filename": "third_party/xla/xla/service/gpu/transforms/triton_fusion_numerics_verifier_test.cc",
            "status": "modified",
            "additions": 90,
            "deletions": 0,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5fb8a4117017a9a3f52641a41010ca066bffa590/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftriton_fusion_numerics_verifier_test.cc?ref=5fb8a4117017a9a3f52641a41010ca066bffa590",
            "patch": "@@ -221,6 +221,96 @@ ENTRY main{\n   TF_EXPECT_OK(verifier.Run(module.get(), /*execution_threads=*/{}));\n }\n \n+TEST_P(TritonFusionNumericsVerifierTest, VerifyMultipleNestedFusionNumerics) {\n+  constexpr absl::string_view kMultiOutputFusionHloText = R\"(\n+HloModule m\n+lhs_computation (p0: bf16[128,512]) -> bf16[128,512] {\n+  ROOT p0 = bf16[128,512]{1,0} parameter(0)\n+}\n+\n+rhs_computation (p0: bf16[256,512]) -> bf16[256,512] {\n+  ROOT p0 = bf16[256,512]{1,0} parameter(0)\n+}\n+\n+concat_computation (p0: bf16[128,512], p1: bf16[256,512]) -> bf16[384,512] {\n+  p0 = bf16[128,512]{1,0} parameter(0)\n+  lhs_f = bf16[128,512]{1,0} fusion(p0), kind=kCustom, calls=lhs_computation, backend_config={\n+    \"operation_queue_id\":\"0\",\n+    \"wait_on_operation_queues\":[],\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\"}}\n+  p1 = bf16[256,512]{1,0} parameter(1)\n+  rhs_f = bf16[256,512]{1,0} fusion(p1), kind=kCustom, calls=rhs_computation, backend_config={\n+    \"operation_queue_id\":\"0\",\n+    \"wait_on_operation_queues\":[],\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\"}}\n+  ROOT concat = bf16[384,512]{1,0} concatenate(lhs_f, rhs_f), dimensions={0}\n+}\n+\n+dot_rhs_computation (p0: bf16[512,512]) -> bf16[512,512] {\n+  ROOT p0 = bf16[512,512]{1,0} parameter(0)\n+}\n+\n+gemm_computation (p0: bf16[128,512], p1: bf16[256,512], p2: bf16[512,512]) -> bf16[384,512] {\n+  p0 = bf16[128,512]{1,0} parameter(0)\n+  p1 = bf16[256,512]{1,0} parameter(1)\n+  concat_f = bf16[384,512]{1,0} fusion(p0, p1), kind=kCustom,\n+    calls=concat_computation, backend_config={\n+    \"operation_queue_id\":\"0\",\n+    \"wait_on_operation_queues\":[],\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"8\",\n+        \"output_tiles\":[{\"sizes\":[\"128\",\"64\"]}],\n+        \"num_ctas\":1,\n+        \"num_stages\":4,\n+        \"is_tma_allowed\":false}}}\n+  p2 = bf16[512,512]{1,0} parameter(2)\n+  dot_rhs_f = bf16[512,512]{1,0} fusion(p2), kind=kCustom,\n+    calls=dot_rhs_computation, backend_config={\n+    \"operation_queue_id\":\"0\",\n+    \"wait_on_operation_queues\":[],\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"8\",\n+        \"output_tiles\":[{\"sizes\":[\"64\",\"256\"]}],\n+        \"num_ctas\":1,\n+        \"num_stages\":4,\n+        \"is_tma_allowed\":false}}}\n+  ROOT dot = bf16[384,512]{1,0} dot(concat_f, dot_rhs_f),\n+    lhs_contracting_dims={1}, rhs_contracting_dims={0}\n+}\n+\n+ENTRY main (p0: bf16[128,512], p1: bf16[256,512], p2: bf16[512,512]) -> bf16[384,512] {\n+  p0 = bf16[128,512]{1,0} parameter(0)\n+  p1 = bf16[256,512]{1,0} parameter(1)\n+  p2 = bf16[512,512]{1,0} parameter(2)\n+  ROOT gemm_f = bf16[384,512]{1,0} fusion(p0, p1, p2),\n+    kind=kCustom, calls=gemm_computation, backend_config={\n+    \"operation_queue_id\":\"0\",\n+    \"wait_on_operation_queues\":[],\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\",\n+      \"block_level_fusion_config\":{\n+        \"num_warps\":\"8\",\n+        \"output_tiles\":[{\"sizes\":[\"128\",\"256\"]}],\n+        \"num_ctas\":1,\n+        \"num_stages\":4,\n+        \"is_tma_allowed\":false}}}\n+}\n+)\";\n+  auto module = Module(kMultiOutputFusionHloText,\n+                       primitive_util::LowercasePrimitiveTypeName(GetParam()));\n+\n+  EXPECT_NE(TritonFusion(*module), nullptr);\n+  auto verifier =\n+      TritonFusionNumericsVerifier(CreateDeviceOrDevicelessConfig());\n+  TF_EXPECT_OK(verifier.Run(module.get(), /*execution_threads=*/{}));\n+}\n+\n TEST_F(TritonFusionNumericsVerifierTest, CheckMismatch) {\n   // This test intentionally compares two different Triton modules to each\n   // other. This is to test that the verifier functions correctly catch and"
        }
    ],
    "stats": {
        "total": 142,
        "additions": 131,
        "deletions": 11
    }
}