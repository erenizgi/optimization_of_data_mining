{
    "author": "derdrdirk",
    "message": "[Autotuner] Log autotuner config in readable json format. When debugging the autotuner we often want to know the values of the AutotuneConfig.\n\nPiperOrigin-RevId: 847683182",
    "sha": "f5b102299e277dfea97cee3cfc630278bcd8daa1",
    "files": [
        {
            "sha": "2f950b590aa8ef0593fc54537c42438046638c35",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=f5b102299e277dfea97cee3cfc630278bcd8daa1",
            "patch": "@@ -499,6 +499,7 @@ absl::StatusOr<std::vector<Autotuner::ConfigResult>> Autotuner::ProfileAll(\n \n   std::optional<ScopedShapedBuffer> reference_output;\n   if (autotune_config_.check_buffers) {\n+    VLOG(2) << \"Checking buffers\";\n     reference_output = GetReferenceOutput(candidates, *input_buffers);\n     if (!reference_output.has_value()) {\n       LOG(WARNING) << \"No reference output found even though buffer checking \"\n@@ -605,6 +606,8 @@ std::optional<ScopedShapedBuffer> Autotuner::GetReferenceOutput(\n       continue;\n     }\n     if (profile_result.value().output_buffer.has_value()) {\n+      VLOG(2) << \"Found reference output for config: \"\n+              << candidate.config.ToString();\n       return std::move(profile_result.value().output_buffer.value());\n     }\n   }\n@@ -732,4 +735,28 @@ std::string Autotuner::Config::ToString() const {\n                          UnpackedAnyShortDebugString(*backend_config));\n }\n \n+std::string AutotuneConfig::ToString() const {\n+  return absl::StrFormat(\n+      \"{\\n\"\n+      \"  \\\"check_buffers\\\": %s,\\n\"\n+      \"  \\\"relative_tolerance\\\": %f,\\n\"\n+      \"  \\\"crash_on_check_failure\\\": %s,\\n\"\n+      \"  \\\"optimize_scratch_bytes\\\": %s,\\n\"\n+      \"  \\\"scratch_bytes_window_size_us\\\": %d,\\n\"\n+      \"  \\\"expect_all_instructions_in_cache\\\": %s,\\n\"\n+      \"  \\\"dump_logs_to\\\": \\\"%s\\\",\\n\"\n+      \"  \\\"exclude_cublas_config\\\": %s,\\n\"\n+      \"  \\\"select_first_config\\\": %s,\\n\"\n+      \"  \\\"use_default_config\\\": %s,\\n\"\n+      \"  \\\"dump_hlos\\\": %s\\n\"\n+      \"}\",\n+      check_buffers ? \"true\" : \"false\", relative_tolerance,\n+      crash_on_check_failure ? \"true\" : \"false\",\n+      optimize_scratch_bytes ? \"true\" : \"false\", scratch_bytes_window_size_us,\n+      expect_all_instructions_in_cache ? \"true\" : \"false\", dump_logs_to,\n+      exclude_cublas_config ? \"true\" : \"false\",\n+      select_first_config ? \"true\" : \"false\",\n+      use_default_config ? \"true\" : \"false\", dump_hlos ? \"true\" : \"false\");\n+}\n+\n }  // namespace xla"
        },
        {
            "sha": "bec84c70609d33a5961596e87af77e7f17c8fa5a",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=f5b102299e277dfea97cee3cfc630278bcd8daa1",
            "patch": "@@ -87,6 +87,8 @@ struct AutotuneConfig {\n   // If true, dump the autotuned instructions to the modules's xla_dump_to or\n   // to stdout if not set.\n   bool dump_hlos = false;\n+\n+  std::string ToString() const;\n };\n \n class Autotuner {"
        },
        {
            "sha": "1ea8b49cff2ddfa0067fa474da869a27746f23f2",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner_test.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner_test.cc?ref=f5b102299e277dfea97cee3cfc630278bcd8daa1",
            "patch": "@@ -986,5 +986,36 @@ TEST_F(AutotunerTest, DumpHlos) {\n           MatchesRegex(\".*\\\\.test_module\\\\.autotuner_1\\\\.add\\\\.before\\\\.txt\")));\n }\n \n+TEST(AutotuneConfigTest, ToString) {\n+  AutotuneConfig config;\n+  config.check_buffers = true;\n+  config.relative_tolerance = 1e-4;\n+  config.crash_on_check_failure = false;\n+  config.optimize_scratch_bytes = true;\n+  config.scratch_bytes_window_size_us = 10;\n+  config.expect_all_instructions_in_cache = false;\n+  config.dump_logs_to = \"/tmp/log\";\n+  config.exclude_cublas_config = true;\n+  config.select_first_config = false;\n+  config.use_default_config = true;\n+  config.dump_hlos = false;\n+\n+  std::string expected =\n+      \"{\\n\"\n+      \"  \\\"check_buffers\\\": true,\\n\"\n+      \"  \\\"relative_tolerance\\\": 0.000100,\\n\"\n+      \"  \\\"crash_on_check_failure\\\": false,\\n\"\n+      \"  \\\"optimize_scratch_bytes\\\": true,\\n\"\n+      \"  \\\"scratch_bytes_window_size_us\\\": 10,\\n\"\n+      \"  \\\"expect_all_instructions_in_cache\\\": false,\\n\"\n+      \"  \\\"dump_logs_to\\\": \\\"/tmp/log\\\",\\n\"\n+      \"  \\\"exclude_cublas_config\\\": true,\\n\"\n+      \"  \\\"select_first_config\\\": false,\\n\"\n+      \"  \\\"use_default_config\\\": true,\\n\"\n+      \"  \\\"dump_hlos\\\": false\\n\"\n+      \"}\";\n+  EXPECT_EQ(config.ToString(), expected);\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "630899b170c5d228209d468fa3ac338f8daba4fa",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f5b102299e277dfea97cee3cfc630278bcd8daa1/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=f5b102299e277dfea97cee3cfc630278bcd8daa1",
            "patch": "@@ -103,6 +103,7 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n   bool is_deviceless = stream_executor == nullptr;\n   AutotuneConfig autotune_config =\n       GetAutotuneConfig(debug_options, is_deviceless, optimize_scratch_bytes);\n+  VLOG(1) << \"Autotune config: \" << autotune_config.ToString();\n \n   if (!is_deviceless) {\n     profiler = GpuProfiler::Create("
        }
    ],
    "stats": {
        "total": 61,
        "additions": 61,
        "deletions": 0
    }
}