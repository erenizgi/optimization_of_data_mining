{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add device number to logs.\n\nPiperOrigin-RevId: 802913529",
    "sha": "5ea9704359f7388fd849c74e74fd0c18afb78909",
    "files": [
        {
            "sha": "e973e97f5a50273f2940a86d8122a7a5c4dce55c",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 129,
            "deletions": 86,
            "changes": 215,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5ea9704359f7388fd849c74e74fd0c18afb78909/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5ea9704359f7388fd849c74e74fd0c18afb78909/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=5ea9704359f7388fd849c74e74fd0c18afb78909",
            "patch": "@@ -167,29 +167,33 @@ absl::StatusOr<CUmodule> LoadPtx(Context* context, const char* ptx_contents) {\n         CHECK_LE(info_log_buffer_bytes, kLogBufferBytesLimit);\n \n         if (!status.ok()) {\n-          LOG(ERROR) << \"failed to load PTX text as a module: \" << status;\n+          LOG(ERROR) << \"[\" << context->device_ordinal()\n+                     << \"] failed to load PTX text as a module: \" << status;\n           // As a precaution for null termination of the API-provided value,\n           // ensure that at least the last byte is null.\n           error_log_buffer[error_log_buffer_bytes ? error_log_buffer_bytes - 1\n                                                   : 0] = '\\0';\n-          LOG(ERROR) << \"error log buffer (\" << error_log_buffer_bytes\n+          LOG(ERROR) << \"[\" << context->device_ordinal()\n+                     << \"] error log buffer (\" << error_log_buffer_bytes\n                      << \" bytes): \" << error_log_buffer.data();\n           if (absl::StrContains(error_log_buffer.data(),\n                                 \"Register allocation failed\")) {\n-            returned_status = absl::ResourceExhaustedError(\n-                absl::StrFormat(\"Failed to load PTX text as a module (register \"\n-                                \"allocation failed): %s\",\n-                                status.ToString()));\n+            returned_status = absl::ResourceExhaustedError(absl::StrFormat(\n+                \"[%d] Failed to load PTX text as a module (register \"\n+                \"allocation failed): %s\",\n+                context->device_ordinal(), status.ToString()));\n           } else {\n             returned_status = status;\n           }\n           notification.Notify();\n           return;\n         }\n \n-        VLOG(3) << \"PTX compilation info log (\" << info_log_buffer_bytes\n+        VLOG(3) << \"[\" << context->device_ordinal()\n+                << \"] PTX compilation info log (\" << info_log_buffer_bytes\n                 << \" bytes): \" << info_log_buffer.data();\n-        VLOG(3) << \"PTX compilation error log (\" << error_log_buffer_bytes\n+        VLOG(3) << \"[\" << context->device_ordinal()\n+                << \"] PTX compilation error log (\" << error_log_buffer_bytes\n                 << \" bytes): \" << error_log_buffer.data();\n         CHECK(module != nullptr);\n         notification.Notify();\n@@ -205,9 +209,11 @@ absl::StatusOr<CUmodule> LoadPtx(Context* context, const char* ptx_contents) {\n absl::StatusOr<CUmodule> LoadCubin(Context* context, const char* cubin_bytes) {\n   ScopedActivateContext activation(context);\n   CUmodule module;\n-  TF_RETURN_IF_ERROR(cuda::ToStatus(\n-      cuModuleLoadFatBinary(&module, cubin_bytes),\n-      \"Failed to load in-memory CUBIN (compiled for a different GPU?).\"));\n+  TF_RETURN_IF_ERROR(\n+      cuda::ToStatus(cuModuleLoadFatBinary(&module, cubin_bytes),\n+                     absl::StrFormat(\"[%d] Failed to load in-memory CUBIN \"\n+                                     \"(compiled for a different GPU?).\",\n+                                     context->device_ordinal())));\n   return module;\n }\n \n@@ -220,15 +226,17 @@ absl::StatusOr<CUfunction> GetModuleFunction(Context* context, CUmodule module,\n   CHECK(module != nullptr && kernel_name != nullptr);\n   cudaError_t cuda_error = cudaPeekAtLastError();\n   if (cuda_error != cudaSuccess) {\n-    return absl::InternalError(\n-        absl::StrCat(\"There was an error before calling cuModuleGetFunction (\",\n-                     cuda_error, \"): \", cudaGetErrorName(cuda_error), \" : \",\n-                     cudaGetErrorString(cuda_error)));\n+    return absl::InternalError(absl::StrCat(\n+        \"[\", context->device_ordinal(),\n+        \"] There was an error before calling cuModuleGetFunction (\", cuda_error,\n+        \"): \", cudaGetErrorName(cuda_error), \" : \",\n+        cudaGetErrorString(cuda_error)));\n   }\n   CUfunction function;\n   TF_RETURN_IF_ERROR(\n       cuda::ToStatus(cuModuleGetFunction(&function, module, kernel_name),\n-                     \"Failed to get module function\"));\n+                     absl::StrFormat(\"[%d] Failed to get module function\",\n+                                     context->device_ordinal())));\n   return function;\n }\n \n@@ -520,8 +528,8 @@ void* DeviceAllocate(Context* context, uint64_t bytes) {\n     return nullptr;\n   }\n   void* ptr = reinterpret_cast<void*>(result);\n-  VLOG(2) << \"allocated \" << ptr << \" for context \" << context << \" of \"\n-          << bytes << \" bytes\";\n+  VLOG(2) << \"[\" << context->device_ordinal() << \"] allocated \" << ptr\n+          << \" for context \" << context << \" of \" << bytes << \" bytes\";\n   return ptr;\n }\n \n@@ -532,10 +540,12 @@ void DeviceDeallocate(Context* context, void* location) {\n   CUdeviceptr pointer = absl::bit_cast<CUdeviceptr>(location);\n   auto status = cuda::ToStatus(cuMemFree(pointer));\n   if (!status.ok()) {\n-    LOG(ERROR) << \"failed to free device memory at \" << location\n+    LOG(ERROR) << \"[\" << context->device_ordinal()\n+               << \"] failed to free device memory at \" << location\n                << \"; result: \" << status;\n   } else {\n-    VLOG(2) << \"deallocated \" << location << \" for context \" << context;\n+    VLOG(2) << \"[\" << context->device_ordinal() << \"] deallocated \" << location\n+            << \" for context \" << context;\n   }\n }\n \n@@ -549,16 +559,17 @@ absl::StatusOr<void*> HostAllocate(Context* context, int numa_node,\n     auto* buffer =\n         tsl::port::NUMAMalloc(numa_node, size, /* minimum_alignment=*/256);\n     if (buffer == nullptr && size > 0) {\n-      return absl::InternalError(absl::StrFormat(\n-          \"Failed to allocate host memory of size %d pinned to NUMA node %d\",\n-          size, numa_node));\n+      return absl::InternalError(\n+          absl::StrFormat(\"[%d] Failed to allocate host memory of size %d \"\n+                          \"pinned to NUMA node %d\",\n+                          context->device_ordinal(), size, numa_node));\n     }\n     if (size > 0 && !HostRegister(context, buffer, size)) {\n       tsl::port::NUMAFree(buffer, size);\n-      return absl::InternalError(\n-          absl::StrFormat(\"Failed to register host memory of size %d pinned to \"\n-                          \"NUMA node %d with the GPU driver\",\n-                          size, numa_node));\n+      return absl::InternalError(absl::StrFormat(\n+          \"[%d] Failed to register host memory of size %d pinned to \"\n+          \"NUMA node %d with the GPU driver\",\n+          context->device_ordinal(), size, numa_node));\n     }\n     return buffer;\n   } else {\n@@ -570,7 +581,8 @@ absl::StatusOr<void*> HostAllocate(Context* context, int numa_node,\n         cuMemHostAlloc(&buffer, size, CU_MEMHOSTALLOC_PORTABLE)));\n     if (!buffer && size > 0) {\n       return absl::InternalError(absl::StrFormat(\n-          \"Failed to allocate pinned host memory of size %d\", size));\n+          \"[%d] Failed to allocate pinned host memory of size %d\",\n+          context->device_ordinal(), size));\n     }\n     return buffer;\n   }\n@@ -588,7 +600,8 @@ void HostDeallocate(Context* context, int numa_node, void* location,\n     ScopedActivateContext activation(context);\n     auto status = cuda::ToStatus(cuMemFreeHost(location));\n     if (!status.ok()) {\n-      LOG(ERROR) << \"error deallocating host memory at \" << location << \": \"\n+      LOG(ERROR) << \"[\" << context->device_ordinal()\n+                 << \"] error deallocating host memory at \" << location << \": \"\n                  << status;\n     }\n   }\n@@ -598,12 +611,14 @@ void HostDeallocate(Context* context, int numa_node, void* location,\n absl::StatusOr<std::unique_ptr<MemoryAllocation>> AllocateHostMemory(\n     CudaContext* cuda_context, int numa_node, uint64_t size) {\n   TF_ASSIGN_OR_RETURN(void* ptr, HostAllocate(cuda_context, numa_node, size));\n-  VLOG(2) << \"allocated \" << ptr << \" for context \" << cuda_context << \" of \"\n-          << size << \" bytes of host memory\";\n+  VLOG(2) << \"[\" << cuda_context->device_ordinal() << \"] allocated \" << ptr\n+          << \" for context \" << cuda_context << \" of \" << size\n+          << \" bytes of host memory\";\n   return std::make_unique<GenericMemoryAllocation>(\n       ptr, size, [cuda_context, numa_node](void* location, uint64_t size) {\n         HostDeallocate(cuda_context, numa_node, location, size);\n-        VLOG(2) << \"deallocated collective memory at \" << location\n+        VLOG(2) << \"[\" << cuda_context->device_ordinal()\n+                << \"] deallocated collective memory at \" << location\n                 << \" for context \" << cuda_context;\n       });\n }\n@@ -683,18 +698,21 @@ CudaExecutor::CreateMemoryAllocator(MemoryType type) {\n           TF_RETURN_IF_ERROR(cuda::ToStatus(\n               cuMemAllocManaged(&result, size, CU_MEM_ATTACH_GLOBAL)));\n           void* ptr = reinterpret_cast<void*>(result);\n-          VLOG(2) << \"allocated \" << ptr << \" for context \" << cuda_context_\n-                  << \" of \" << size << \" bytes in unified memory\";\n+          VLOG(2) << \"[\" << device_ordinal() << \"] allocated \" << ptr\n+                  << \" for context \" << cuda_context_ << \" of \" << size\n+                  << \" bytes in unified memory\";\n           return std::make_unique<GenericMemoryAllocation>(\n               ptr, size, [this](void* location, uint64_t size) {\n                 std::unique_ptr<ActivateContext> activation = Activate();\n                 CUdeviceptr pointer = absl::bit_cast<CUdeviceptr>(location);\n                 auto status = cuda::ToStatus(cuMemFree(pointer));\n                 if (!status.ok()) {\n-                  LOG(ERROR) << \"failed to free unified memory at \" << location\n-                             << \"; result: \" << status;\n+                  LOG(ERROR) << \"[\" << device_ordinal()\n+                             << \"] failed to free unified memory at \"\n+                             << location << \"; result: \" << status;\n                 } else {\n-                  VLOG(2) << \"deallocated unified memory at \" << location\n+                  VLOG(2) << \"[\" << device_ordinal()\n+                          << \"] deallocated unified memory at \" << location\n                           << \" for context \" << cuda_context_;\n                 }\n               });\n@@ -704,16 +722,19 @@ CudaExecutor::CreateMemoryAllocator(MemoryType type) {\n         [this](uint64_t size)\n             -> absl::StatusOr<std::unique_ptr<MemoryAllocation>> {\n           TF_ASSIGN_OR_RETURN(void* ptr, CollectiveMemoryAllocate(this, size));\n-          VLOG(2) << \"allocated \" << ptr << \" for context \" << cuda_context_\n-                  << \" of \" << size << \" bytes of collective memory\";\n+          VLOG(2) << \"[\" << device_ordinal() << \"] allocated \" << ptr\n+                  << \" for context \" << cuda_context_ << \" of \" << size\n+                  << \" bytes of collective memory\";\n           return std::make_unique<GenericMemoryAllocation>(\n               ptr, size, [this](void* location, uint64_t size) {\n                 auto status = CollectiveMemoryDeallocate(this, location);\n                 if (!status.ok()) {\n-                  LOG(ERROR) << \"failed to free collective memory at \"\n+                  LOG(ERROR) << \"[\" << device_ordinal()\n+                             << \"] failed to free collective memory at \"\n                              << location << \"; result: \" << status;\n                 } else {\n-                  VLOG(2) << \"deallocated collective memory at \" << location\n+                  VLOG(2) << \"[\" << device_ordinal()\n+                          << \"] deallocated collective memory at \" << location\n                           << \" for context \" << cuda_context_;\n                 }\n               });\n@@ -736,8 +757,7 @@ absl::Status CudaExecutor::Init() {\n   numa_node_ = ReadNumaNode(GetPCIBusID(device_), device_ordinal())\n                    .value_or(tsl::port::kNUMANoAffinity);\n   if (numa_node_ == tsl::port::kNUMANoAffinity) {\n-    VLOG(2) << \"Could not determine NUMA node of device ordinal \"\n-            << device_ordinal();\n+    VLOG(2) << \"[\" << device_ordinal() << \"] Could not determine NUMA node\";\n   }\n   return absl::OkStatus();\n }\n@@ -762,11 +782,12 @@ absl::StatusOr<ModuleHandle> CudaExecutor::LoadModuleFromCuBin(\n   if (module == nullptr) {\n     TF_ASSIGN_OR_RETURN(module, LoadCubin(cuda_context_, cubin));\n     module_refcount = 1;\n-    VLOG(3) << \"Loaded CUBIN \" << static_cast<const void*>(cubin)\n-            << \" as module \" << module;\n+    VLOG(3) << \"[\" << device_ordinal() << \"] Loaded CUBIN \"\n+            << static_cast<const void*>(cubin) << \" as module \" << module;\n   } else {\n     ++module_refcount;\n-    VLOG(3) << \"CUBIN \" << static_cast<const void*>(cubin)\n+    VLOG(3) << \"[\" << device_ordinal() << \"] CUBIN \"\n+            << static_cast<const void*>(cubin)\n             << \" is already loaded as module \" << module;\n   }\n   gpu_binary_to_module_[module_handle] = {module, module_refcount};\n@@ -781,13 +802,14 @@ absl::StatusOr<ModuleHandle> CudaExecutor::LoadModuleFromPtx(const char* ptx) {\n \n   if (module == nullptr) {\n     TF_ASSIGN_OR_RETURN(module, LoadPtx(cuda_context_, ptx));\n-    VLOG(3) << \"Loaded PTX \" << static_cast<const void*>(ptx) << \" as module \"\n-            << module;\n+    VLOG(3) << \"[\" << device_ordinal() << \"] Loaded PTX \"\n+            << static_cast<const void*>(ptx) << \" as module \" << module;\n     module_refcount = 1;\n   } else {\n     ++module_refcount;\n-    VLOG(3) << \"PTX \" << static_cast<const void*>(ptx)\n-            << \" is already loaded as module \" << module;\n+    VLOG(3) << \"[\" << device_ordinal() << \"] PTX \"\n+            << static_cast<const void*>(ptx) << \" is already loaded as module \"\n+            << module;\n   }\n   gpu_binary_to_module_[module_handle] = {module, module_refcount};\n   return module_handle;\n@@ -806,7 +828,8 @@ absl::StatusOr<std::unique_ptr<Kernel>> CudaExecutor::LoadKernel(\n     kernel_to_gpu_binary_[cuda_kernel.get()] = module_handle;\n \n     CUmodule module = gpu_binary_to_module_.at(module_handle).first;\n-    VLOG(2) << \"getting function \" << kernel_name << \" from module \" << module;\n+    VLOG(2) << \"[\" << device_ordinal() << \"] getting function \" << kernel_name\n+            << \" from module \" << module;\n     TF_ASSIGN_OR_RETURN(\n         CUfunction function,\n         GetModuleFunction(cuda_context_, module, kernel_name.c_str()));\n@@ -815,15 +838,17 @@ absl::StatusOr<std::unique_ptr<Kernel>> CudaExecutor::LoadKernel(\n   } else if (spec.has_cuda_ptx_in_memory()) {\n     const char* ptx = spec.cuda_ptx_in_memory()->ptx.data();\n     if (ptx == nullptr) {\n-      LOG(FATAL) << \"Loader spec has no ptx for kernel \" << kernel_name;\n+      LOG(FATAL) << \"[\" << device_ordinal()\n+                 << \"] Loader spec has no ptx for kernel \" << kernel_name;\n     }\n \n     absl::MutexLock lock{&in_memory_modules_mu_};\n     TF_ASSIGN_OR_RETURN(ModuleHandle module_handle, LoadModuleFromPtx(ptx));\n     kernel_to_gpu_binary_[cuda_kernel.get()] = module_handle;\n \n     CUmodule module = gpu_binary_to_module_.at(module_handle).first;\n-    VLOG(2) << \"getting function \" << kernel_name << \" from module \" << module;\n+    VLOG(2) << \"[\" << device_ordinal() << \"] getting function \" << kernel_name\n+            << \" from module \" << module;\n     TF_ASSIGN_OR_RETURN(\n         CUfunction function,\n         GetModuleFunction(cuda_context_, module, kernel_name.c_str()));\n@@ -832,17 +857,20 @@ absl::StatusOr<std::unique_ptr<Kernel>> CudaExecutor::LoadKernel(\n   } else if (spec.has_in_process_symbol()) {\n     void* symbol = spec.in_process_symbol()->symbol;\n \n-    VLOG(2) << \"Resolve CUDA kernel \" << kernel_name\n-            << \" from symbol pointer: \" << symbol;\n+    VLOG(2) << \"[\" << device_ordinal() << \"] Resolve CUDA kernel \"\n+            << kernel_name << \" from symbol pointer: \" << symbol;\n     cudaFunction_t func;\n-    TF_RETURN_IF_ERROR(cuda::ToStatus(cudaGetFuncBySymbol(&func, symbol),\n-                                      \"Failed call to cudaGetFuncBySymbol\"));\n+    TF_RETURN_IF_ERROR(cuda::ToStatus(\n+        cudaGetFuncBySymbol(&func, symbol),\n+        absl::StrFormat(\"[%d] Failed call to cudaGetFuncBySymbol\",\n+                        device_ordinal())));\n     cuda_kernel->set_gpu_function(func);\n \n   } else {\n     return absl::InternalError(\"No method of loading CUDA kernel provided\");\n   }\n-  VLOG(3) << \"LoadKernel on kernel : \" << kernel_name;\n+  VLOG(3) << \"[\" << device_ordinal()\n+          << \"] LoadKernel on kernel : \" << kernel_name;\n \n   {\n     // Keep track of loaded kernels.\n@@ -880,22 +908,25 @@ CudaExecutor::CreateEventBasedTimer(Stream* stream, bool use_delay_kernel) {\n bool CudaExecutor::UnloadGpuBinary(ModuleHandle gpu_binary) {\n   auto module_it = gpu_binary_to_module_.find(gpu_binary);\n   if (gpu_binary_to_module_.end() == module_it) {\n-    VLOG(3) << \"No loaded CUDA module for \" << gpu_binary;\n+    VLOG(3) << \"[\" << device_ordinal() << \"] No loaded CUDA module for \"\n+            << gpu_binary;\n     return false;\n   }\n   auto& module = module_it->second.first;\n   auto& refcount = module_it->second.second;\n-  VLOG(3) << \"Found CUDA module \" << module << \" with refcount \" << refcount;\n+  VLOG(3) << \"[\" << device_ordinal() << \"] Found CUDA module \" << module\n+          << \" with refcount \" << refcount;\n   if (--refcount == 0) {\n-    VLOG(3) << \"Unloading CUDA module \" << module;\n+    VLOG(3) << \"[\" << device_ordinal() << \"] Unloading CUDA module \" << module;\n     UnloadCudaModule(cuda_context_, module);\n     gpu_binary_to_module_.erase(module_it);\n   }\n   return true;\n }\n \n void CudaExecutor::UnloadKernel(const Kernel* kernel) {\n-  VLOG(3) << \"Unloading kernel \" << kernel << \" : \" << kernel->name();\n+  VLOG(3) << \"[\" << device_ordinal() << \"] Unloading kernel \" << kernel << \" : \"\n+          << kernel->name();\n \n   absl::MutexLock lock{&in_memory_modules_mu_};\n   loaded_kernels_.erase(kernel);\n@@ -904,12 +935,12 @@ void CudaExecutor::UnloadKernel(const Kernel* kernel) {\n   if (kernel_to_gpu_binary_.end() == gpu_binary_it) {\n     // We might never see kernel being explicitly loaded if it was resolved from\n     // in process symbol pointer (CUDA C++ device function pointer).\n-    VLOG(3) << \"Kernel \" << kernel << \" : \" << kernel->name()\n-            << \" has never been loaded.\";\n+    VLOG(3) << \"[\" << device_ordinal() << \"] Kernel \" << kernel << \" : \"\n+            << kernel->name() << \" has never been loaded.\";\n     return;\n   }\n-  VLOG(3) << \"Kernel \" << kernel << \" : \" << kernel->name()\n-          << \" has loaded GPU code \" << gpu_binary_it->second;\n+  VLOG(3) << \"[\" << device_ordinal() << \"] Kernel \" << kernel << \" : \"\n+          << kernel->name() << \" has loaded GPU code \" << gpu_binary_it->second;\n   UnloadGpuBinary(gpu_binary_it->second);\n   kernel_to_gpu_binary_.erase(gpu_binary_it);\n }\n@@ -1014,7 +1045,8 @@ CudaExecutor::CreateOrShareConstant(Stream* stream,\n }\n \n DeviceMemoryBase CudaExecutor::Allocate(uint64_t size, int64_t memory_space) {\n-  VLOG(1) << \"CudaExecutor::Allocate size: \" << size\n+  VLOG(1) << \"[\" << device_ordinal()\n+          << \"] CudaExecutor::Allocate size: \" << size\n           << \" memory_space: \" << memory_space;\n \n   if (memory_space == static_cast<int64_t>(MemoryType::kCollective)) {\n@@ -1023,21 +1055,25 @@ DeviceMemoryBase CudaExecutor::Allocate(uint64_t size, int64_t memory_space) {\n       LOG(ERROR) << \"Failed to allocate collective memory: \" << result.status();\n       return DeviceMemoryBase(nullptr, 0);\n     }\n-    VLOG(1) << \"CudaExecutor::Allocate returns \" << result.value();\n+    VLOG(1) << \"[\" << device_ordinal() << \"] CudaExecutor::Allocate returns \"\n+            << result.value();\n     return DeviceMemoryBase(result.value(), size);\n   } else if (memory_space ==\n              static_cast<int64_t>(stream_executor::MemoryType::kHost)) {\n     auto result = HostAllocate(cuda_context_, numa_node_, size);\n     if (!result.ok()) {\n-      LOG(ERROR) << \"Failed to allocate host memory: \" << result.status();\n+      LOG(ERROR) << \"[\" << device_ordinal()\n+                 << \"] Failed to allocate host memory: \" << result.status();\n       return DeviceMemoryBase(nullptr, 0);\n     }\n-    VLOG(1) << \"CudaExecutor::Allocate returns \" << result.value();\n+    VLOG(1) << \"[\" << device_ordinal() << \"] CudaExecutor::Allocate returns \"\n+            << result.value();\n     return DeviceMemoryBase(result.value(), size);\n   }\n   CHECK_EQ(memory_space, 0);\n   auto device_buf_base = DeviceAllocate(cuda_context_, size);\n-  VLOG(1) << \"CudaExecutor::Allocate returns \" << device_buf_base;\n+  VLOG(1) << \"[\" << device_ordinal() << \"] CudaExecutor::Allocate returns \"\n+          << device_buf_base;\n   return DeviceMemoryBase(device_buf_base, size);\n }\n \n@@ -1047,7 +1083,8 @@ CudaExecutor::HostMemoryAllocate(uint64_t size) {\n }\n \n void CudaExecutor::Deallocate(DeviceMemoryBase* mem) {\n-  VLOG(1) << \"CudaExecutor::Deallocate mem: \" << mem->opaque();\n+  VLOG(1) << \"[\" << device_ordinal()\n+          << \"] CudaExecutor::Deallocate mem: \" << mem->opaque();\n \n   auto status_or_memory_space = GetPointerMemorySpace(mem->opaque());\n   if (!status_or_memory_space.ok()) {\n@@ -1067,13 +1104,15 @@ bool CudaExecutor::SynchronizeAllActivity() {\n }\n \n bool CudaExecutor::HostMemoryRegister(void* location, uint64_t size) {\n-  VLOG(1) << \"Called StreamExecutor::HostMemoryRegister(data=\" << location\n+  VLOG(1) << \"[\" << device_ordinal()\n+          << \"] Called StreamExecutor::HostMemoryRegister(data=\" << location\n           << \")\";\n   return HostRegister(cuda_context_, location, size);\n }\n \n bool CudaExecutor::HostMemoryUnregister(void* location) {\n-  VLOG(1) << \"Called StreamExecutor::HostUnregister(data=\" << location << \")\";\n+  VLOG(1) << \"[\" << device_ordinal()\n+          << \"] Called StreamExecutor::HostUnregister(data=\" << location << \")\";\n   return HostUnregister(cuda_context_, location);\n }\n \n@@ -1095,13 +1134,15 @@ absl::Status CudaExecutor::SynchronousMemcpy(DeviceMemoryBase* gpu_dst,\n                                              const void* host_src,\n                                              uint64_t size) {\n   std::unique_ptr<ActivateContext> activation = Activate();\n-  TF_RETURN_IF_ERROR(cuda::ToStatus(\n-      cuMemcpyHtoD(AsCudaDevicePtr(gpu_dst), host_src, size),\n-      absl::StrFormat(\n-          \"failed to synchronous memcpy from host to device: GPU dst: %llx;\"\n-          \" host src: %p; size: %u=0x%x\",\n-          AsCudaDevicePtr(gpu_dst), host_src, size, size)));\n-  VLOG(2) << \"successfully enqueued sync memcpy h2d of \" << size << \" bytes\";\n+  TF_RETURN_IF_ERROR(\n+      cuda::ToStatus(cuMemcpyHtoD(AsCudaDevicePtr(gpu_dst), host_src, size),\n+                     absl::StrFormat(\"[%d] failed to synchronous memcpy from \"\n+                                     \"host to device: GPU dst: %llx;\"\n+                                     \" host src: %p; size: %u=0x%x\",\n+                                     device_ordinal(), AsCudaDevicePtr(gpu_dst),\n+                                     host_src, size, size)));\n+  VLOG(2) << \"[\" << device_ordinal()\n+          << \"] successfully enqueued sync memcpy h2d of \" << size << \" bytes\";\n   return absl::OkStatus();\n }\n \n@@ -1111,11 +1152,12 @@ absl::Status CudaExecutor::SynchronousMemcpy(void* host_dst,\n   std::unique_ptr<ActivateContext> activation = Activate();\n   TF_RETURN_IF_ERROR(cuda::ToStatus(\n       cuMemcpyDtoH(host_dst, AsCudaDevicePtr(gpu_src), size),\n-      absl::StrFormat(\"failed to synchronous memcpy from device to host \"\n+      absl::StrFormat(\"[%d] failed to synchronous memcpy from device to host \"\n                       \"host dst: %p; GPU src: %llx; size: %u=0x%x\",\n-                      host_dst, AsCudaDevicePtr(gpu_src), size, size)));\n-  VLOG(2) << \"successfully sync memcpy'd d2h of \" << size << \" bytes to \"\n-          << host_dst;\n+                      device_ordinal(), host_dst, AsCudaDevicePtr(gpu_src),\n+                      size, size)));\n+  VLOG(2) << \"[\" << device_ordinal() << \"] successfully sync memcpy'd d2h of \"\n+          << size << \" bytes to \" << host_dst;\n   return absl::OkStatus();\n }\n \n@@ -1272,7 +1314,8 @@ absl::StatusOr<std::unique_ptr<Stream>> CudaExecutor::CreateStream(\n \n absl::StatusOr<std::unique_ptr<CommandBuffer>>\n CudaExecutor::CreateCommandBuffer(CommandBuffer::Mode mode) {\n-  VLOG(2) << \"Create CUDA command buffer (CUDA graph)\";\n+  VLOG(2) << \"[\" << device_ordinal()\n+          << \"] Create CUDA command buffer (CUDA graph)\";\n   return CudaCommandBuffer::Create(mode, this, cuda_context_);\n }\n "
        }
    ],
    "stats": {
        "total": 215,
        "additions": 129,
        "deletions": 86
    }
}