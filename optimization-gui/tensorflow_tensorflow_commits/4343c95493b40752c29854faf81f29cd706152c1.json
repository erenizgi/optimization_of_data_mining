{
    "author": "Tongfei-Guo",
    "message": "[XLA:SPMD] Fix on entry input/output layout changing check.\n\nPiperOrigin-RevId: 834762307",
    "sha": "4343c95493b40752c29854faf81f29cd706152c1",
    "files": [
        {
            "sha": "dedd077eeb73c89bb5a6dcd92918260b8c507014",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 37,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4343c95493b40752c29854faf81f29cd706152c1/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4343c95493b40752c29854faf81f29cd706152c1/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=4343c95493b40752c29854faf81f29cd706152c1",
            "patch": "@@ -5609,16 +5609,28 @@ absl::StatusOr<bool> SpmdPartitioner::RunImpl(\n   // parameters preserve their signatures.\n   auto new_program_shape = module->entry_computation()->ComputeProgramShape();\n   if (!options_.allow_module_signature_change) {\n-    TF_RET_CHECK(Shape::Equal().MinorToMajorOnlyInLayout()(\n-        program_shape.result(), new_program_shape.result()))\n-        << \"Result shape changed for the entry computation\";\n-    TF_RET_CHECK(program_shape.parameters_size() ==\n-                 new_program_shape.parameters_size())\n-        << \"Parameter count changed for the entry computation\";\n+    if (!Shape::Equal()(program_shape.result(), new_program_shape.result())) {\n+      return absl::InvalidArgumentError(\n+          \"Result shape changed for the entry computation from: \" +\n+          program_shape.result().ToString() +\n+          \" to: \" + new_program_shape.result().ToString());\n+    }\n+    if (program_shape.parameters_size() !=\n+        new_program_shape.parameters_size()) {\n+      return absl::InvalidArgumentError(\n+          \"Parameter count changed for the entry computation from: \" +\n+          std::to_string(program_shape.parameters_size()) +\n+          \" to: \" + std::to_string(new_program_shape.parameters_size()));\n+    }\n     for (int64_t i = 0; i < program_shape.parameters_size(); ++i) {\n-      TF_RET_CHECK(Shape::Equal().MinorToMajorOnlyInLayout()(\n-          program_shape.parameters(i), new_program_shape.parameters(i)))\n-          << \"Parameter shape changed for the entry computation\";\n+      if (!Shape::Equal()(program_shape.parameters(i),\n+                          new_program_shape.parameters(i))) {\n+        return absl::InvalidArgumentError(\n+            \"Parameter shape changed for the entry computation parameter \" +\n+            std::to_string(i) +\n+            \" from: \" + program_shape.parameters(i).ToString() +\n+            \" to: \" + new_program_shape.parameters(i).ToString());\n+      }\n     }\n   } else {\n     // Fix up some bad tiling in entry computation layout.\n@@ -5711,34 +5723,6 @@ absl::Status SpmdPartitioner::PreprocessSharding(\n     }\n   }\n \n-  // Entry computation's parameter and root sharding must be either all\n-  // replicated or all on a single device.\n-  if (!options_.allow_module_signature_change) {\n-    const HloComputation* entry = module->entry_computation();\n-    TF_RET_CHECK(entry->root_instruction()->has_sharding());\n-    const HloSharding& root_sharding = entry->root_instruction()->sharding();\n-    if (!root_sharding.UniqueDevice().has_value()) {\n-      if (root_sharding.IsTuple()) {\n-        TF_RET_CHECK(absl::c_all_of(root_sharding.tuple_elements(),\n-                                    [](const HloSharding& s) {\n-                                      return s.IsReplicated() || s.IsManual();\n-                                    }))\n-            << \"Unsupported entry root sharding: \" << root_sharding.ToString();\n-\n-      } else {\n-        TF_RET_CHECK(root_sharding.IsReplicated() || root_sharding.IsManual())\n-            << \"Unsupported entry root sharding: \" << root_sharding.ToString();\n-      }\n-    }\n-\n-    for (const HloInstruction* param : entry->parameter_instructions()) {\n-      TF_RET_CHECK(param->has_sharding());\n-      TF_RET_CHECK(param->sharding().IsReplicated() ||\n-                   param->sharding().UniqueDevice().has_value())\n-          << \"Unsupported entry parameter sharding:\"\n-          << param->sharding().ToString();\n-    }\n-  }\n   return absl::OkStatus();\n }\n "
        }
    ],
    "stats": {
        "total": 58,
        "additions": 21,
        "deletions": 37
    }
}