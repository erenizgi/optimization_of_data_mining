{
    "author": "tensorflower-gardener",
    "message": "Map CudaGraph Node in traceviewer could show per-node framework namescope by rewrite their annotation to the value during its corresponing creation.\n\nPiperOrigin-RevId: 832016962",
    "sha": "7bbde49af9d139d18d1898e83066cb4bf2d02e96",
    "files": [
        {
            "sha": "13debc127f8755d6f1407eb4ff2c549c8cf840b3",
            "filename": "third_party/xla/xla/backends/profiler/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -168,6 +168,7 @@ cuda_library(\n         \"@com_google_googletest//:gtest_for_library\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n         \"@local_config_cuda//cuda:cuda_runtime\",\n+        \"@local_tsl//tsl/profiler/lib:scoped_annotation\",\n     ],\n )\n "
        },
        {
            "sha": "2e1642fa65bbbef5779e0cb837f6d5e76bc2c5cb",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cuda_test.cu.cc",
            "status": "modified",
            "additions": 55,
            "deletions": 29,
            "changes": 84,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcuda_test.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcuda_test.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcuda_test.cu.cc?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -24,11 +24,14 @@ limitations under the License.\n #include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"\n #include \"third_party/gpus/cuda/include/driver_types.h\"\n #include \"xla/backends/profiler/gpu/cuda_test.h\"\n+#include \"tsl/profiler/lib/scoped_annotation.h\"\n \n namespace xla {\n namespace profiler {\n namespace test {\n \n+using tsl::profiler::ScopedAnnotation;\n+\n namespace {\n \n // Simple printf kernel.\n@@ -38,9 +41,9 @@ __global__ void simple_print() { printf(\"hello, world!\\n\"); }\n __global__ void empty() {}\n \n // Simple kernel accesses memory.\n-__global__ void access(int *addr) { *addr = *addr * 2; }\n+__global__ void access(int* addr) { *addr = *addr * 2; }\n \n-unsigned *g_device_copy;\n+unsigned* g_device_copy;\n \n unsigned *gpu0_buf, *gpu1_buf;\n \n@@ -58,13 +61,13 @@ void EmptyKernel(int iters) {\n   }\n }\n \n-void AccessKernel(int *addr) { access<<<1, 1>>>(addr); }\n+void AccessKernel(int* addr) { access<<<1, 1>>>(addr); }\n \n void Synchronize() { cudaDeviceSynchronize(); }\n \n void UnifiedMemoryHtoDAndDtoH() {\n-  int *addr = nullptr;\n-  cudaMallocManaged(reinterpret_cast<void **>(&addr), sizeof(int));\n+  int* addr = nullptr;\n+  cudaMallocManaged(reinterpret_cast<void**>(&addr), sizeof(int));\n   // The page is now in host memory.\n   *addr = 1;\n   // The kernel wants to access the page. HtoD transfer happens.\n@@ -77,21 +80,21 @@ void UnifiedMemoryHtoDAndDtoH() {\n \n void MemCopyH2D() {\n   unsigned host_val = 0x12345678;\n-  cudaMalloc(reinterpret_cast<void **>(&g_device_copy), sizeof(unsigned));\n+  cudaMalloc(reinterpret_cast<void**>(&g_device_copy), sizeof(unsigned));\n   cudaMemcpy(g_device_copy, &host_val, sizeof(unsigned),\n              cudaMemcpyHostToDevice);\n }\n \n void MemCopyH2D_Async() {\n   unsigned host_val = 0x12345678;\n-  cudaMalloc(reinterpret_cast<void **>(&g_device_copy), sizeof(unsigned));\n+  cudaMalloc(reinterpret_cast<void**>(&g_device_copy), sizeof(unsigned));\n   cudaMemcpyAsync(g_device_copy, &host_val, sizeof(unsigned),\n                   cudaMemcpyHostToDevice);\n }\n \n void MemCopyD2H() {\n   unsigned host_val = 0;\n-  cudaMalloc(reinterpret_cast<void **>(&g_device_copy), sizeof(unsigned));\n+  cudaMalloc(reinterpret_cast<void**>(&g_device_copy), sizeof(unsigned));\n   cudaMemcpy(&host_val, g_device_copy, sizeof(unsigned),\n              cudaMemcpyDeviceToHost);\n }\n@@ -101,10 +104,10 @@ namespace {\n // Helper function to set up memory buffers on two devices.\n void P2PMemcpyHelper() {\n   cudaSetDevice(0);\n-  cudaMalloc(reinterpret_cast<void **>(&gpu0_buf), sizeof(unsigned));\n+  cudaMalloc(reinterpret_cast<void**>(&gpu0_buf), sizeof(unsigned));\n   cudaDeviceEnablePeerAccess(/*peerDevice=*/1, /*flags=*/0);\n   cudaSetDevice(1);\n-  cudaMalloc(reinterpret_cast<void **>(&gpu1_buf), sizeof(unsigned));\n+  cudaMalloc(reinterpret_cast<void**>(&gpu1_buf), sizeof(unsigned));\n   cudaDeviceEnablePeerAccess(/*peerDevice=*/0, /*flags=*/0);\n }\n \n@@ -131,12 +134,12 @@ void MemCopyP2PExplicit() {\n \n // The test about cuda graph is based on Nvidia's CUPTI sample code\n // under extras/CUPTI/samples/cuda_graphs_trace/ dir of CUDA distribution.\n-__global__ void VecAdd(const int *a, const int *b, int *c, int n) {\n+__global__ void VecAdd(const int* a, const int* b, int* c, int n) {\n   int i = blockDim.x * blockIdx.x + threadIdx.x;\n   if (i < n) c[i] = a[i] + b[i];\n }\n \n-__global__ void VecSub(const int *a, const int *b, int *c, int n) {\n+__global__ void VecSub(const int* a, const int* b, int* c, int n) {\n   int i = blockDim.x * blockIdx.x + threadIdx.x;\n   if (i < n) c[i] = a[i] - b[i];\n }\n@@ -162,9 +165,12 @@ void CudaGraphCreateAndExecute() {\n \n   // Allocates vectors in device memory.\n   int *d_a, *d_b, *d_c;\n-  cudaMalloc((void **)&d_a, kNumBytes);\n-  cudaMalloc((void **)&d_b, kNumBytes);\n-  cudaMalloc((void **)&d_c, kNumBytes);\n+  cudaMalloc((void**)&d_a, kNumBytes);\n+  cudaMalloc((void**)&d_b, kNumBytes);\n+  cudaMalloc((void**)&d_c, kNumBytes);\n+\n+  ScopedAnnotation module_annotation(\n+      \"XlaModule:#hlo_module=my_module,program_id=1#\");\n \n   cudaGraphCreate(&graph, 0);\n \n@@ -175,41 +181,61 @@ void CudaGraphCreateAndExecute() {\n   memcpy_params.extent.width = kNumBytes;\n   memcpy_params.extent.height = 1;\n   memcpy_params.extent.depth = 1;\n-  cudaGraphAddMemcpyNode(&nodes[0], graph, nullptr, 0, &memcpy_params);\n+  {\n+    ScopedAnnotation memcpy_1_annotation(\n+        \"Thunk:#name=my_module/prep,hlo_op=memcpy.1#\");\n+    cudaGraphAddMemcpyNode(&nodes[0], graph, nullptr, 0, &memcpy_params);\n+  }\n \n   memcpy_params.srcPtr.ptr = vec_b.data();\n   memcpy_params.dstPtr.ptr = d_b;\n-  cudaGraphAddMemcpyNode(&nodes[1], graph, nullptr, 0, &memcpy_params);\n+  {\n+    ScopedAnnotation memcpy_2_annotation(\n+        \"Thunk:#name=my_module/prep,hlo_op=memcpy.2#\");\n+    cudaGraphAddMemcpyNode(&nodes[1], graph, nullptr, 0, &memcpy_params);\n+  }\n \n   // Init kernel params.\n   int num = kNumElements;\n-  void *kernelArgs[] = {(void *)&d_a, (void *)&d_b, (void *)&d_c, (void *)&num};\n+  void* kernelArgs[] = {(void*)&d_a, (void*)&d_b, (void*)&d_c, (void*)&num};\n   blocks_per_grid = (kNumElements + kThreadsPerBlock - 1) / kThreadsPerBlock;\n-  kernel_params.func = (void *)VecAdd;\n+  kernel_params.func = (void*)VecAdd;\n   kernel_params.gridDim = dim3(blocks_per_grid, 1, 1);\n   kernel_params.blockDim = dim3(kThreadsPerBlock, 1, 1);\n   kernel_params.sharedMemBytes = 0;\n-  kernel_params.kernelParams = (void **)kernelArgs;\n+  kernel_params.kernelParams = (void**)kernelArgs;\n   kernel_params.extra = nullptr;\n+  {\n+    ScopedAnnotation add_1_annotation(\n+        \"Thunk:#name=my_module/body,hlo_op=add.1#\");\n+    cudaGraphAddKernelNode(&nodes[2], graph, &nodes[0], 2, &kernel_params);\n+  }\n \n-  cudaGraphAddKernelNode(&nodes[2], graph, &nodes[0], 2, &kernel_params);\n-\n-  kernel_params.func = (void *)VecSub;\n-  cudaGraphAddKernelNode(&nodes[3], graph, &nodes[2], 1, &kernel_params);\n-\n+  kernel_params.func = (void*)VecSub;\n+  {\n+    ScopedAnnotation sub_1_annotation(\n+        \"Thunk:#name=my_module/body,hlo_op=sub.1#\");\n+    cudaGraphAddKernelNode(&nodes[3], graph, &nodes[2], 1, &kernel_params);\n+  }\n   memcpy_params.kind = cudaMemcpyDeviceToHost;\n   memcpy_params.srcPtr.ptr = d_c;\n   memcpy_params.dstPtr.ptr = vec_c.data();\n   memcpy_params.extent.width = kNumBytes;\n   memcpy_params.extent.height = 1;\n   memcpy_params.extent.depth = 1;\n-  cudaGraphAddMemcpyNode(&nodes[4], graph, &nodes[3], 1, &memcpy_params);\n-\n+  {\n+    ScopedAnnotation memcpy_3_annotation(\n+        \"Thunk:#name=my_module/post,hlo_op=memcpy.3#\");\n+    cudaGraphAddMemcpyNode(&nodes[4], graph, &nodes[3], 1, &memcpy_params);\n+  }\n   cudaGraphClone(&cloned_graph, graph);\n \n-  cudaGraphInstantiate(&graph_exec, cloned_graph, nullptr, nullptr, 0);\n+  cudaGraphInstantiate(&graph_exec, graph, nullptr, nullptr, 0);\n \n-  cudaGraphLaunch(graph_exec, stream);\n+  {\n+    ScopedAnnotation module_annotation(\"Thunk:#name=my_module,hlo_op=call.1#\");\n+    cudaGraphLaunch(graph_exec, stream);\n+  }\n \n   cudaStreamSynchronize(stream);\n "
        },
        {
            "sha": "d6a7de323334f5a74191aea974e3d47384c87b72",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 16,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -155,8 +155,12 @@ const char *getActivityUnifiedMemoryKindString(\n template <typename CuptiActivity>\n void SetEventGraphId(CuptiTracerEvent &event,\n                      const CuptiActivity *cupti_activity) {\n+  // In current implementation, CuptiActivityKernelTy, CuptiActivityMemcpyTy,\n+  // CuptiActivityMemcpyP2PTy and CuptiActivityMemsetTy all have graphNodeId\n+  // when they have graphId.\n   if constexpr (CuptiActivityHasGraphId<CuptiActivity>::value) {\n     event.graph_id = cupti_activity->graphId;\n+    event.graph_node_id = cupti_activity->graphNodeId;\n   }\n }\n \n@@ -658,23 +662,27 @@ absl::string_view StringDeduper::Dedup(absl::string_view str,\n   return absl::string_view();\n }\n \n-void AnnotationMap::Add(uint32_t device_id, uint32_t correlation_id,\n-                        const absl::string_view annotation,\n-                        const absl::string_view nvtx_range,\n-                        int64_t scope_range_id) {\n-  if (annotation.empty() && nvtx_range.empty()) return;\n-  VLOG(3) << \"Add annotation: device_id: \" << device_id\n-          << \" correlation_id: \" << correlation_id\n-          << \" annotation: \" << annotation;\n-  if (device_id >= per_device_map_.size()) return;\n-  auto &per_device_map = per_device_map_[device_id];\n-  if (per_device_map.annotation_deduper.Size() < max_size_) {\n-    AnnotationInfo info;\n-    info.annotation = per_device_map.annotation_deduper.Dedup(annotation);\n-    info.nvtx_range = per_device_map.nvtx_range_deduper.Dedup(nvtx_range);\n-    info.scope_range_id = scope_range_id;\n-    per_device_map.correlation_map.emplace(correlation_id, info);\n+absl::string_view AnnotationMap::Add(uint32_t device_id,\n+                                     uint32_t correlation_id,\n+                                     const absl::string_view annotation,\n+                                     const absl::string_view nvtx_range,\n+                                     int64_t scope_range_id) {\n+  if ((!annotation.empty() || !nvtx_range.empty()) &&\n+      device_id < per_device_map_.size()) {\n+    VLOG(3) << \"Add annotation: device_id: \" << device_id\n+            << \" correlation_id: \" << correlation_id\n+            << \" annotation: \" << annotation;\n+    auto& per_device_map = per_device_map_[device_id];\n+    if (per_device_map.annotation_deduper.Size() < max_size_) {\n+      AnnotationInfo info;\n+      info.annotation = per_device_map.annotation_deduper.Dedup(annotation);\n+      info.nvtx_range = per_device_map.nvtx_range_deduper.Dedup(nvtx_range);\n+      info.scope_range_id = scope_range_id;\n+      per_device_map.correlation_map.emplace(correlation_id, info);\n+      return info.annotation;\n+    }\n   }\n+  return \"\";\n }\n \n AnnotationMap::AnnotationInfo AnnotationMap::LookUp("
        },
        {
            "sha": "da5a03f6cc17491286fb332eadf3ffb9f5f70fd3",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.h",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -280,9 +280,14 @@ class AnnotationMap {\n   explicit AnnotationMap(uint64_t max_size, uint32_t num_gpus)\n       : max_size_(max_size), per_device_map_(num_gpus) {}\n \n-  void Add(uint32_t device_id, uint32_t correlation_id,\n-           absl::string_view annotation, absl::string_view nvtx_range,\n-           int64_t scope_range_id = 0);\n+  // Returns a string_view of the dedupped annotation string. The string_view is\n+  // valid as long as the AnnotationMap is alive. If the annotation is dropped\n+  // due to size limit or any other reason, an empty string_view will be\n+  // returned.\n+  absl::string_view Add(uint32_t device_id, uint32_t correlation_id,\n+                        absl::string_view annotation,\n+                        absl::string_view nvtx_range,\n+                        int64_t scope_range_id = 0);\n \n   AnnotationInfo LookUp(uint32_t device_id, uint32_t correlation_id) const\n       ABSL_ATTRIBUTE_LIFETIME_BOUND;"
        },
        {
            "sha": "9ee5ca44ccffcdb95ed988eda58835cd1ef57f59",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_collector.cc",
            "status": "modified",
            "additions": 42,
            "deletions": 76,
            "changes": 118,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -414,60 +414,6 @@ class PerDeviceCollector {\n \n  public:\n   PerDeviceCollector() = default;\n-  void SetCudaGraphIdMap(\n-      absl::flat_hash_map<uint32_t, uint32_t>& cuda_graph_id_map) {\n-    per_device_cuda_graph_id_map_.insert(cuda_graph_id_map.begin(),\n-                                         cuda_graph_id_map.end());\n-  }\n-\n-  void SetCudaGraphNodeIdMap(\n-      absl::flat_hash_map<uint32_t, absl::flat_hash_map<uint64_t, uint64_t>>&\n-          cuda_graph_node_id_map) {\n-    for (const auto& [graph_id, node_map] : cuda_graph_node_id_map) {\n-      per_device_cuda_graph_node_id_map_[graph_id].insert(node_map.begin(),\n-                                                          node_map.end());\n-    }\n-  }\n-\n-  void AddGraphIdMapsToPlane(XPlaneBuilder* device_plane) {\n-    // Create a new line for graph metadata\n-    XLineBuilder line =\n-        device_plane->GetOrCreateLine(StatType::kGraphMetadataLineId);\n-    line.SetName(GetStatTypeStr(StatType::kGraphMetadataLineId));\n-    line.SetTimestampNs(0);\n-\n-    // Add the graph id map to the device plane\n-    for (const auto& [graph_id, orig_graph_id] :\n-         per_device_cuda_graph_id_map_) {\n-      XEventBuilder event =\n-          line.AddEvent(*device_plane->GetOrCreateEventMetadata(\n-              GetStatTypeStr(StatType::kCudaGraphMapId)));\n-      event.AddStatValue(*device_plane->GetOrCreateStatMetadata(\n-                             GetStatTypeStr(StatType::kCudaGraphId)),\n-                         graph_id);\n-      event.AddStatValue(*device_plane->GetOrCreateStatMetadata(\n-                             GetStatTypeStr(StatType::kCudaGraphOrigId)),\n-                         orig_graph_id);\n-    }\n-    // Add the node id map to the device plane\n-    for (const auto& [graph_id, node_map] :\n-         per_device_cuda_graph_node_id_map_) {\n-      for (const auto& [node_id, orig_node_id] : node_map) {\n-        XEventBuilder event =\n-            line.AddEvent(*device_plane->GetOrCreateEventMetadata(\n-                GetStatTypeStr(StatType::kCudaGraphNodeMapId)));\n-        event.AddStatValue(*device_plane->GetOrCreateStatMetadata(\n-                               GetStatTypeStr(StatType::kCudaGraphId)),\n-                           graph_id);\n-        event.AddStatValue(*device_plane->GetOrCreateStatMetadata(\n-                               GetStatTypeStr(StatType::kCudaGraphNodeId)),\n-                           node_id);\n-        event.AddStatValue(*device_plane->GetOrCreateStatMetadata(\n-                               GetStatTypeStr(StatType::kCudaGraphOrigNodeId)),\n-                           orig_node_id);\n-      }\n-    }\n-  }\n \n   void AddEvent(CuptiTracerEvent&& event) {\n     absl::MutexLock l(m_);\n@@ -635,9 +581,6 @@ class PerDeviceCollector {\n   std::vector<CuptiTracerEvent> events_ TF_GUARDED_BY(m_);\n   cudaOccDeviceProp device_properties_;\n   absl::flat_hash_map<DeviceOccupancyParams, OccupancyStats> occupancy_cache_;\n-  absl::flat_hash_map<uint32_t, uint32_t> per_device_cuda_graph_id_map_;\n-  absl::flat_hash_map<uint32_t, absl::flat_hash_map<uint64_t, uint64_t>>\n-      per_device_cuda_graph_node_id_map_;\n };\n \n // Using two iterator of the CuptiTracerEvent queue to mark the current and\n@@ -752,17 +695,26 @@ void CuptiTraceCollector::OnTracerCollectedCallbackData(\n     auto event_in_queue = min_heap.top();\n     min_heap.pop();\n     auto& event = event_in_queue.Event();\n+    absl::string_view deduped_annotation{};\n     if (event.type == CuptiTracerEventType::Generic &&\n         event.generic_info.cbid ==\n             CUPTI_DRIVER_TRACE_CBID_cuLaunchCooperativeKernelMultiDevice) {\n       for (uint32_t device = 0; device < options_.num_gpus; ++device) {\n-        annotation_map_.Add(device, event.correlation_id, event.annotation,\n-                            event.nvtx_range, event.scope_range_id);\n+        deduped_annotation =\n+            annotation_map_.Add(device, event.correlation_id, event.annotation,\n+                                event.nvtx_range, event.scope_range_id);\n       }\n     } else {\n-      annotation_map_.Add(event.device_id, event.correlation_id,\n-                          event.annotation, event.nvtx_range,\n-                          event.scope_range_id);\n+      deduped_annotation = annotation_map_.Add(\n+          event.device_id, event.correlation_id, event.annotation,\n+          event.nvtx_range, event.scope_range_id);\n+    }\n+    if (event.type == CuptiTracerEventType::CudaGraph && event.graph_id != 0 &&\n+        event.graph_node_id != 0) {\n+      if (!deduped_annotation.empty()) {\n+        graph_node_annotations_.insert(\n+            {{event.graph_id, event.graph_node_id}, deduped_annotation});\n+      }\n     }\n     // Clear the annotation and nvtx_range of the Callback API events, as they\n     // are now in the combined AnnotationMap which will be used by the\n@@ -840,20 +792,39 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n       // followed AddEvent() processing.\n       if (!AddNvtxMarker(event)) return;\n     }\n+\n+    // If this is a CudaGraphNodeMap event, we need to record the mapping from\n+    // graph_id/graph_node_id to orig_graph_id/orig_graph_node_id.\n     if (event.type == CuptiTracerEventType::CudaGraphNodeMap) {\n+      cuda_graph_id_map_[event.graph_id] = event.cuda_graph_info.orig_graph_id;\n       cuda_graph_node_id_map_[event.graph_id][event.graph_node_id] =\n           event.cuda_graph_info.orig_graph_node_id;\n-      cuda_graph_id_map_[event.graph_id] = event.cuda_graph_info.orig_graph_id;\n+      return;\n     }\n-    if (event.type != CuptiTracerEventType::CudaGraphNodeMap) {\n-      per_device_collector_[event.device_id].AddEvent(std::move(event));\n+\n+    // For activity events with graph_id and graph_node_id, we need to rewrite\n+    // the annotation to reflect the detail framework information which are got\n+    // during the callback for cuda graph creation and nodes insertion.\n+    if (event.source == CuptiTracerEventSource::Activity &&\n+        (event.graph_id != 0 && event.graph_node_id != 0)) {\n+      // We need to rewrite the annotation of this inner node event in cuda\n+      // graph device plane.\n+      auto orig_graph_id_it = cuda_graph_id_map_.find(event.graph_id);\n+      if (orig_graph_id_it != cuda_graph_id_map_.end()) {\n+        uint32_t orig_graph_id = orig_graph_id_it->second;\n+        const auto& node_id_2_orig = cuda_graph_node_id_map_[event.graph_id];\n+        auto orig_node_id_it = node_id_2_orig.find(event.graph_node_id);\n+        if (orig_node_id_it != node_id_2_orig.end()) {\n+          uint64_t orig_node_id = orig_node_id_it->second;\n+          auto annotation_it =\n+              graph_node_annotations_.find({orig_graph_id, orig_node_id});\n+          if (annotation_it != graph_node_annotations_.end()) {\n+            event.annotation = annotation_it->second;\n+          }\n+        }\n+      }\n     }\n-    per_device_collector_[event.device_id].SetCudaGraphIdMap(\n-        cuda_graph_id_map_);\n-    per_device_collector_[event.device_id].SetCudaGraphNodeIdMap(\n-        cuda_graph_node_id_map_);\n-    cuda_graph_node_id_map_.clear();\n-    cuda_graph_id_map_.clear();\n+    per_device_collector_[event.device_id].AddEvent(std::move(event));\n   }\n   void OnEventsDropped(const std::string& reason,\n                        uint32_t num_events) override {\n@@ -903,11 +874,6 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n           device_ordinal, &device_plane);\n       num_events += per_device_collector_[device_ordinal].Flush(\n           start_gpu_ns_, end_gpu_ns, &device_plane, &host_plane, &nvtx_plane);\n-      if (options_.dump_graph_nope_mapping) {\n-        // Add the graph id maps to the device plane\n-        per_device_collector_[device_ordinal].AddGraphIdMapsToPlane(\n-            &device_plane);\n-      }\n       NormalizeTimeStamps(&device_plane, start_walltime_ns_);\n     }\n     NormalizeTimeStamps(&host_plane, start_walltime_ns_);"
        },
        {
            "sha": "8255d12cadeafd58d10d3260f9916e21e211b669",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_collector.h",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.h?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -24,6 +24,8 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/strings/string_view.h\"\n #include \"xla/backends/profiler/gpu/cupti_buffer_events.h\"\n #include \"xla/tsl/profiler/utils/xplane_builder.h\"\n #include \"tsl/profiler/protobuf/xplane.pb.h\"\n@@ -42,8 +44,6 @@ struct CuptiTracerCollectorOptions {\n   uint64_t max_annotation_strings = 1024 * 1024;\n   // Number of GPUs involved.\n   uint32_t num_gpus;\n-  // Whether to dump the graph nope mapping.\n-  bool dump_graph_nope_mapping = false;\n };\n // This struct will be used to store the PM Sampling data.\n // Same as CUDA 12.6.2 extras/CUPTI/samples/pm_sampling/pm_sampling.h\n@@ -132,6 +132,9 @@ class CuptiTraceCollector {\n   CuptiTracerCollectorOptions options_;\n   // map of child_scope_id -> parent_scope_id\n   ScopeRangeIdTree scope_range_id_tree_;\n+  // <graph_id, graph_node_id> to annotation string during creation of the node.\n+  absl::flat_hash_map<std::pair<uint32_t, uint64_t>, absl::string_view>\n+      graph_node_annotations_ = {};\n \n  private:\n   AnnotationMap annotation_map_;"
        },
        {
            "sha": "e52688c55855c3273e39402f9c5fc56a9eca1e53",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 2,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -619,11 +619,11 @@ void SetCuMemHostUnregisterEventUponApiExit(\n struct GraphResourceCreationInfo {\n   uint32_t graph_id = 0;\n   uint32_t orig_graph_id = 0;\n-  absl::flat_hash_map<uint64_t, uint64_t> node_id_map;\n+  absl::flat_hash_map<uint64_t, uint64_t> node_id_map = {};\n };\n \n static GraphResourceCreationInfo& GetGraphResourceCreationInfo() {\n-  static thread_local GraphResourceCreationInfo per_thread_graph_info;\n+  static thread_local GraphResourceCreationInfo per_thread_graph_info{};\n   return per_thread_graph_info;\n }\n \n@@ -1257,7 +1257,16 @@ CuptiTracer::CreateDefaultCallbackIds() {\n       CUPTI_DRIVER_TRACE_CBID_cuGraphInstantiateWithFlags,\n       CUPTI_DRIVER_TRACE_CBID_cuGraphInstantiateWithParams,\n       CUPTI_DRIVER_TRACE_CBID_cuGraphInstantiateWithParams_ptsz,\n+      // Following add-node to cuda graph events are needed to trace as they are\n+      // used to create graph nodes for different Hlo operations in XLA.\n       CUPTI_DRIVER_TRACE_CBID_cuGraphAddMemcpyNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddKernelNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddMemsetNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddEmptyNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddChildGraphNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddKernelNode_v2,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddNode,\n+      CUPTI_DRIVER_TRACE_CBID_cuGraphAddNode_v2,\n #endif  // CUDA_VERSION >= 12080\n   };\n }"
        },
        {
            "sha": "05d1738a92c2e74a6378d83bb808b856d123fff9",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_tracer_options_utils.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbde49af9d139d18d1898e83066cb4bf2d02e96/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer_options_utils.cc?ref=7bbde49af9d139d18d1898e83066cb4bf2d02e96",
            "patch": "@@ -70,10 +70,6 @@ absl::Status UpdateCuptiTracerOptionsFromProfilerOptions(\n                           collector_options.max_annotation_strings = value;\n                         }));\n \n-  TF_RETURN_IF_ERROR(SetValue<bool>(\n-      profile_options, \"gpu_dump_graph_node_mapping\", input_keys,\n-      [&](bool value) { collector_options.dump_graph_nope_mapping = value; }));\n-\n   TF_RETURN_IF_ERROR(SetValue<int64_t>(\n       profile_options, \"gpu_num_chips_to_profile_per_task\", input_keys,\n       [&](int64_t value) {"
        }
    ],
    "stats": {
        "total": 278,
        "additions": 146,
        "deletions": 132
    }
}