{
    "author": "chsigg",
    "message": "Increment XLA GPU autotune cache version to 15.\n\nThis change invalidates the autotune cache, which is necessary because enabling the generic emitter (cl/823475406) affected autotuning results.\n\nPiperOrigin-RevId: 823818338",
    "sha": "c50123703dba0462e63db96b894de2956d8f4bdc",
    "files": [
        {
            "sha": "bfbf6137552d6d6f2a703333fa6559f8e6fa341f",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotune_cache_key.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c50123703dba0462e63db96b894de2956d8f4bdc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c50123703dba0462e63db96b894de2956d8f4bdc/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotune_cache_key.h?ref=c50123703dba0462e63db96b894de2956d8f4bdc",
            "patch": "@@ -32,7 +32,7 @@ class AutotuneCacheKey {\n   // Tie a version to the cache key in order to invalidate the cache when\n   // necessary. This should be incremented on triton upgrades or any other\n   // changes that may affect the autotuning results.\n-  static constexpr int kCurrentVersion = 14;\n+  static constexpr int kCurrentVersion = 15;\n \n   AutotuneCacheKey(const se::DeviceDescription& device_description,\n                    const HloInstruction& instruction,"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}