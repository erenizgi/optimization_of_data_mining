{
    "author": "pschuh",
    "message": "Fix tests that become flaky when you insert delays after buffer creation for robustness testing.\n\nI believe it has to do with BufferFromHostBuffer results need to be blocked on\nbefore destroying because they don't provide on_done callbacks. An alternative\nfix could be to make shared_ptrs to the host data and capture that in the\non_done callback.\n\nPiperOrigin-RevId: 828196740",
    "sha": "f3076689e5c0453e914aa9caef58a1727658f0e6",
    "files": [
        {
            "sha": "07cbfb7ba3276f477ec2da43fb142878a08d1590",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_nvshmem_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3076689e5c0453e914aa9caef58a1727658f0e6/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_nvshmem_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3076689e5c0453e914aa9caef58a1727658f0e6/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_nvshmem_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_nvshmem_test.cc?ref=f3076689e5c0453e914aa9caef58a1727658f0e6",
            "patch": "@@ -155,6 +155,7 @@ TEST(StreamExecutorGpuClientTest, NvshmemMemoryTest) {\n       std::vector<std::vector<std::unique_ptr<PjRtBuffer>>> result,\n       executable->Execute({{input.get()}}, ExecuteOptions()));\n   std::vector<std::unique_ptr<xla::PjRtBuffer>>& result_buffers = result[0];\n+  TF_ASSERT_OK(result_buffers[0]->GetReadyFuture().Await());\n   EXPECT_EQ(result_buffers[0]->memory_space()->kind(), \"device\");\n   Shape result_shape = result_buffers[0]->on_device_shape();\n   int64_t memory_space = result_shape.layout().memory_space();"
        },
        {
            "sha": "6b88a490d140706dd8e7b838b6d92b713945c9fa",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f3076689e5c0453e914aa9caef58a1727658f0e6/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f3076689e5c0453e914aa9caef58a1727658f0e6/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client_test.cc?ref=f3076689e5c0453e914aa9caef58a1727658f0e6",
            "patch": "@@ -1783,6 +1783,7 @@ TEST(StreamExecutorGpuClientTest, ExecutePinnedHostOutputTest) {\n \n   std::vector<std::unique_ptr<xla::PjRtBuffer>>& result_buffers = result[0];\n   EXPECT_EQ(result_buffers[0]->memory_space()->kind(), \"pinned_host\");\n+  TF_ASSERT_OK(result_buffers[0]->GetReadyFuture().Await());\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       auto memory_stats, executable->GetExecutable()->GetCompiledMemoryStats());\n@@ -1818,6 +1819,7 @@ TEST(StreamExecutorGpuClientTest, ExecutePinnedHostOutputTupleTest) {\n       auto result, executable->Execute({{input.get()}}, execute_options));\n \n   std::vector<std::unique_ptr<xla::PjRtBuffer>>& result_buffers = result[0];\n+  TF_ASSERT_OK(result_buffers[0]->GetReadyFuture().Await());\n   EXPECT_EQ(result_buffers.size(), 2);\n   EXPECT_EQ(result_buffers[0]->memory_space()->kind(), \"device\");\n   EXPECT_EQ(result_buffers[1]->memory_space()->kind(), \"pinned_host\");\n@@ -2061,6 +2063,7 @@ TEST(StreamExecutorGpuClientTest,\n       auto result, executable->Execute({{input.get()}}, ExecuteOptions()));\n   std::vector<std::unique_ptr<xla::PjRtBuffer>>& result_buffers = result[0];\n   EXPECT_EQ(result_buffers[0]->memory_space()->kind(), \"device\");\n+  TF_ASSERT_OK(result_buffers[0]->GetReadyFuture().Await());\n   Shape result_shape = result_buffers[0]->on_device_shape();\n   auto memory_space = result_shape.layout().memory_space();\n   EXPECT_EQ(memory_space, 1);\n@@ -2094,6 +2097,7 @@ TEST(StreamExecutorGpuClientTest, CollectiveMemorySpaceSmoke) {\n   TF_ASSERT_OK_AND_ASSIGN(auto results,\n                           exe->Execute({{input.get()}}, ExecuteOptions()));\n   auto& buf = results[0][0];\n+  TF_ASSERT_OK(buf->GetReadyFuture().Await());\n \n   // Override default memory space to collective memory space.\n   EXPECT_EQ(buf->on_device_shape().layout().memory_space(),\n@@ -2616,8 +2620,10 @@ TEST(StreamExecutorGpuClientTest, NonZeroGPUDeviceTimeMeasurementMultiGPU) {\n   auto measurement0 = CreateDeviceTimeMeasurement();\n \n   // Test that running the program does not crash/hang.\n-  TF_ASSERT_OK(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto res,\n       executable->Execute(absl::MakeSpan(input_ptrs), ExecuteOptions()));\n+  TF_ASSERT_OK(res[0][0]->GetReadyFuture().Await());\n \n   // Check measurement after execution completes.\n   EXPECT_GT("
        }
    ],
    "stats": {
        "total": 9,
        "additions": 8,
        "deletions": 1
    }
}