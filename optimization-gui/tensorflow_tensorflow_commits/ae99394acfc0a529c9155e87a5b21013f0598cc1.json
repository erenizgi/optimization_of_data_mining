{
    "author": "junjiang-lab",
    "message": "Relax tfl.div op check to allow 6d broadcastable inputs.\n\nPiperOrigin-RevId: 804657332",
    "sha": "ae99394acfc0a529c9155e87a5b21013f0598cc1",
    "files": [
        {
            "sha": "c842d0db9edb46a80fc1ee19ee1aa01870b290a4",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.td",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ae99394acfc0a529c9155e87a5b21013f0598cc1/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ae99394acfc0a529c9155e87a5b21013f0598cc1/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td?ref=ae99394acfc0a529c9155e87a5b21013f0598cc1",
            "patch": "@@ -1620,7 +1620,7 @@ def TFL_DivOp : TFL_Op<\"div\", [\n     // TODO(fengliuai): NoQuantizableResult is only correct for int8\n     // quantization. update to handle Uint8 quantization.\n     BinaryOpSameElementTypeConstraint,\n-    TFL_OperandsHaveSameShapesOrBroadcastableShape<[0, 1], 5>,\n+    TFL_OperandsHaveSameShapesOrBroadcastableShape<[0, 1], 6>,\n     ResultsBroadcastableShape,\n     Pure,\n     QuantizableResult,"
        },
        {
            "sha": "31081e65fea0a722eb03a0a1bc0bf10613dd3840",
            "filename": "tensorflow/compiler/mlir/lite/tests/legalize-tf.mlir",
            "status": "modified",
            "additions": 11,
            "deletions": 4,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ae99394acfc0a529c9155e87a5b21013f0598cc1/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flegalize-tf.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ae99394acfc0a529c9155e87a5b21013f0598cc1/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flegalize-tf.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flegalize-tf.mlir?ref=ae99394acfc0a529c9155e87a5b21013f0598cc1",
            "patch": "@@ -1996,14 +1996,21 @@ func.func @mul_with_int32_7d_inputs(%arg0: tensor<1x1x1x1x1x3x1xi32>, %arg1 : te\n \n // CHECK-LABEL: testDivWithBroadcastToOps\n func.func @testDivWithBroadcastToOps(%arg0: tensor<1x2x1x4x5x6xi32>, %arg1: tensor<1x2x3x4x5x1xi32>) -> tensor<1x2x3x4x5x6xi32> {\n-  // CHECK: [[CST:%.*]] = arith.constant dense<[1, 2, 3, 4, 5, 6]> : tensor<6xi64>\n-  // CHECK: [[BCAST:%.*]] = \"tfl.broadcast_to\"(%arg0, [[CST]])\n-  // CHECK: [[BCAST_1:%.*]] = \"tfl.broadcast_to\"(%arg1, [[CST]])\n-  // CHECK: tfl.div [[BCAST]], [[BCAST_1]] {fused_activation_function = \"NONE\"} : tensor<1x2x3x4x5x6xi32>\n+  // CHECK: tfl.div(%arg0, %arg1) <{fused_activation_function = \"NONE\"}> : (tensor<1x2x1x4x5x6xi32>, tensor<1x2x3x4x5x1xi32>) -> tensor<1x2x3x4x5x6xi32>\n   %0 = \"tf.Div\"(%arg0, %arg1) : (tensor<1x2x1x4x5x6xi32>, tensor<1x2x3x4x5x1xi32>) -> tensor<1x2x3x4x5x6xi32>\n   func.return %0 : tensor<1x2x3x4x5x6xi32>\n }\n \n+// CHECK-LABEL: testDivWithBroadcastToOps7D\n+func.func @testDivWithBroadcastToOps7D(%arg0: tensor<1x2x1x4x5x6x7xi32>, %arg1: tensor<1x2x3x4x5x1x7xi32>) -> tensor<1x2x3x4x5x6x7xi32> {\n+  // CHECK: [[CST:%.*]] = arith.constant dense<[1, 2, 3, 4, 5, 6, 7]> : tensor<7xi64>\n+  // CHECK: [[BCAST:%.*]] = \"tfl.broadcast_to\"(%arg0, [[CST]])\n+  // CHECK: [[BCAST_1:%.*]] = \"tfl.broadcast_to\"(%arg1, [[CST]])\n+  // CHECK: tfl.div [[BCAST]], [[BCAST_1]] {fused_activation_function = \"NONE\"} : tensor<1x2x3x4x5x6x7xi32>\n+  %0 = \"tf.Div\"(%arg0, %arg1) : (tensor<1x2x1x4x5x6x7xi32>, tensor<1x2x3x4x5x1x7xi32>) -> tensor<1x2x3x4x5x6x7xi32>\n+  func.return %0 : tensor<1x2x3x4x5x6x7xi32>\n+}\n+\n // CHECK-LABEL: testFloorDivWithBroadcastToOps\n func.func @testFloorDivWithBroadcastToOps(%arg0: tensor<1x2x1x4x5x6xi32>, %arg1: tensor<1x2x3x4x5x1xi32>) -> tensor<1x2x3x4x5x6xi32> {\n   // CHECK: [[CST:%.*]] = arith.constant dense<[1, 2, 3, 4, 5, 6]> : tensor<6xi64>"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 12,
        "deletions": 5
    }
}