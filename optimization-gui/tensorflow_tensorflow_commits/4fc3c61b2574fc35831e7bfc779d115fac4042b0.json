{
    "author": "seherellis",
    "message": "[XLA:CollectivePipeliner] Fix two issues:\n1) Accept transpose as a formatting op in ForwardSink.\n2) Do not stop when a large collective was sunk in the previous iteration. Instead, delay sinking large collectives while sinking small collectives level by level and run an additional sinking iteration dedicated to large collectives at the end.\n\nPiperOrigin-RevId: 833425046",
    "sha": "4fc3c61b2574fc35831e7bfc779d115fac4042b0",
    "files": [
        {
            "sha": "562a7a18c509d84e7bd973f774373f84674bd411",
            "filename": "third_party/xla/xla/service/collective_pipeliner.cc",
            "status": "modified",
            "additions": 46,
            "deletions": 36,
            "changes": 82,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.cc?ref=4fc3c61b2574fc35831e7bfc779d115fac4042b0",
            "patch": "@@ -348,7 +348,7 @@ CheckStoreIntoSliceIsCompatible(\n     if (direction ==\n         collective_pipeliner_utils::PipeliningDirection::kForwardSink) {\n       // TODO(maggioni): Support these ops in forward sink.\n-      if (HloPredicateIsOp<HloOpcode::kConcatenate, HloOpcode::kGetTupleElement,\n+      if (HloPredicateIsOp<HloOpcode::kGetTupleElement,\n                            HloOpcode::kReduceScatter>(i)) {\n         return false;\n       }\n@@ -819,13 +819,17 @@ class WhileLoopAnalysis {\n       HloInstruction* while_instr, int64_t max_pipelining_per_loop,\n       bool pipeline_use_tree, bool process_different_sized_options,\n       TuplePointsToAnalysis* tuple_points_to_analysis,\n-      std::optional<ConstantValue> known_start = std::nullopt)\n+      std::optional<ConstantValue> known_start = std::nullopt,\n+      bool delay_sinking_large_collectives = false,\n+      int64_t collective_size_threshold = INT64_MAX)\n       : while_(while_instr),\n         loop_start_(known_start),\n         max_pipelining_per_loop_(max_pipelining_per_loop),\n         tuple_points_to_analysis_(tuple_points_to_analysis),\n         pipeline_use_tree_(pipeline_use_tree),\n-        process_different_sized_options_(process_different_sized_options) {}\n+        process_different_sized_options_(process_different_sized_options),\n+        delay_sinking_large_collectives_(delay_sinking_large_collectives),\n+        collective_size_threshold_(collective_size_threshold) {}\n   std::optional<ConstantValue> GetLoopIterationCount() const;\n   std::optional<ConstantValue> GetLoopStart() const;\n   std::optional<ConstantValue> GetLoopIncrement() const;\n@@ -926,6 +930,8 @@ class WhileLoopAnalysis {\n \n   bool pipeline_use_tree_;\n   bool process_different_sized_options_;\n+  bool delay_sinking_large_collectives_;\n+  int64_t collective_size_threshold_;\n };\n \n int64_t WhileLoopAnalysis::GetDUSIndex(const HloInstruction* dus) const {\n@@ -1368,6 +1374,17 @@ void WhileLoopAnalysis::CollectCollectivesToMove(\n     if (!should_process(instr)) {\n       continue;\n     }\n+    if (delay_sinking_large_collectives_ &&\n+        direction ==\n+            collective_pipeliner_utils::PipeliningDirection::kForwardSink &&\n+        ShapeUtil::ElementsIn(instr->shape()) >= collective_size_threshold_) {\n+      VLOG(1) << \"Delay sinking \" << instr->name() << \" because its size \"\n+              << ShapeUtil::ElementsIn(instr->shape())\n+              << \" is greater than the threshold \"\n+              << collective_size_threshold_;\n+      continue;\n+    }\n+\n     if (direction ==\n             collective_pipeliner_utils::PipeliningDirection::kForward ||\n         direction ==\n@@ -2462,6 +2479,17 @@ absl::Status TransformFormattingOp(\n     pipelined_map[formatting_op] = expanded_transpose;\n     return absl::OkStatus();\n   }\n+  if (formatting_op->opcode() == HloOpcode::kConcatenate) {\n+    HloConcatenateInstruction* concat =\n+        Cast<HloConcatenateInstruction>(formatting_op);\n+    HloInstruction* expanded_concat =\n+        loop_computation->AddInstruction(HloInstruction::CreateConcatenate(\n+            ComputeFullOutputShape(to_move, formatting_op->shape()),\n+            collect_operands(formatting_op),\n+            concat->concatenate_dimension() + 1));\n+    pipelined_map[formatting_op] = expanded_concat;\n+    return absl::OkStatus();\n+  }\n   return absl::InvalidArgumentError(\n       absl::StrCat(\"Unsupported instruction \", formatting_op->ToString()));\n }\n@@ -3233,24 +3261,6 @@ static absl::Status TransformLoopBackward(\n   return absl::OkStatus();\n }\n \n-bool IsForwardSinkIterationFeasible(HloInstruction* while_inst,\n-                                    int64_t collective_size_threshold) {\n-  for (HloInstruction* inst :\n-       while_inst->while_body()->root_instruction()->operands()) {\n-    if (inst->opcode() == HloOpcode::kDynamicUpdateSlice &&\n-        inst->operand(1)->IsCustomCall(\n-            CollectivePipeliner::kSunkByPreviousStep)) {\n-      HloInstruction* cc = inst->mutable_operand(1);\n-      if (ShapeUtil::ElementsIn(cc->shape()) >= collective_size_threshold) {\n-        VLOG(1) << \"Encountered a large collective which was sunk by the \"\n-                   \"previous step, should stop the iteration.\";\n-        return false;\n-      }\n-    }\n-  }\n-  return true;\n-}\n-\n absl::StatusOr<bool> CollectivePipeliner::RunPipeliner(\n     HloModule* module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n@@ -3280,7 +3290,9 @@ absl::StatusOr<bool> CollectivePipeliner::RunPipeliner(\n       auto loop_analysis = std::make_unique<WhileLoopAnalysis>(\n           instruction, config_.max_pipelining_per_loop,\n           config_.pipeline_use_tree, config_.process_different_sized_ops,\n-          tuple_points_to_analysis.get());\n+          tuple_points_to_analysis.get(), /*known_start=*/std::nullopt,\n+          config_.delay_sinking_large_collectives,\n+          config_.collective_size_threshold_to_delay_sinking);\n       loop_analysis->ComputeLoopStatistics();\n       if (loop_analysis->GetLoopIterationCount() &&\n           loop_analysis->GetLoopIterationCount()->GetUnsignedValue() > 1) {\n@@ -3297,12 +3309,6 @@ absl::StatusOr<bool> CollectivePipeliner::RunPipeliner(\n   for (auto& [instruction, loop_analysis] : loop_analyses) {\n     VLOG(1) << \"While iterations: \"\n             << loop_analysis->GetLoopIterationCount()->ToString();\n-    if (config_.pipelining_direction ==\n-            collective_pipeliner_utils::PipeliningDirection::kForwardSink &&\n-        !IsForwardSinkIterationFeasible(\n-            instruction, config_.collective_size_threshold_to_stop_sinking)) {\n-      continue;\n-    }\n     loop_analysis->CollectCollectivesToMove(\n         config_.level_to_operate_on, config_.pipelining_direction,\n         config_.should_process, config_.acceptable_formatting,\n@@ -3393,20 +3399,24 @@ absl::StatusOr<bool> CollectivePipeliner::RunImpl(\n     return RunPipeliner(module, execution_threads);\n   }\n \n-  // If the pipelining direction is kForwardSink, run the pipeliner until it\n-  // does not change the module anymore. The maximum number of iterations should\n-  // be equal to the maximum number of pipelineable collectives in a chain of\n-  // users plus one. In each iteration, we pipeline the last pipelineable\n-  // collectives, which do not have any other pipelineable collectives in their\n-  // user subtree.\n+  // If the pipelining direction is kForwardSink, first run the pipeliner on\n+  // small collectives iteratively until it does not change the module anymore.\n+  // In each iteration, we pipeline the last pipelineable collectives, which do\n+  // not have any other pipelineable collectives in their user subtrees. Then\n+  // run the pipeliner one last time on the large collectives.\n   bool changed = true;\n   int64_t iter = 0;\n   while (changed) {\n     TF_ASSIGN_OR_RETURN(changed, RunPipeliner(module, execution_threads));\n-    VLOG(1) << \"Finished running pipeliner's iteration: \" << iter;\n+    VLOG(1) << \"Finished running pipeliner's iteration for small collectives: \"\n+            << iter;\n     iter++;\n   }\n-  return iter > 1;\n+  config_.delay_sinking_large_collectives = false;\n+  TF_ASSIGN_OR_RETURN(changed, RunPipeliner(module, execution_threads));\n+  VLOG(1) << \"Finished running pipeliner's iteration for large collectives: \"\n+          << iter;\n+  return iter > 1 || changed;\n }\n \n }  // namespace xla"
        },
        {
            "sha": "646334f20dd01763ab0d0f214a9f485c2a6141c3",
            "filename": "third_party/xla/xla/service/collective_pipeliner.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner.h?ref=4fc3c61b2574fc35831e7bfc779d115fac4042b0",
            "patch": "@@ -108,7 +108,8 @@ class CollectivePipeliner : public HloModulePass {\n     bool should_add_loop_invariant_op_in_chain = false;\n     // Postprocessing hook which runs for every successfully pipelined op.\n     HloPostprocessor postprocess_pipelined_ops;\n-    int64_t collective_size_threshold_to_stop_sinking = INT64_MAX;\n+    int64_t collective_size_threshold_to_delay_sinking = INT64_MAX;\n+    bool delay_sinking_large_collectives = true;\n   };\n   static const char* const kInsertedByPreviousStep;\n   static const char* const kSunkByPreviousStep;\n@@ -155,7 +156,7 @@ class CollectivePipeliner : public HloModulePass {\n       const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n \n  private:\n-  const Config config_;\n+  Config config_;\n };\n \n }  // namespace xla"
        },
        {
            "sha": "7b060dcca05d666c7582407259c385b07e528011",
            "filename": "third_party/xla/xla/service/collective_pipeliner_test.cc",
            "status": "modified",
            "additions": 61,
            "deletions": 59,
            "changes": 120,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4fc3c61b2574fc35831e7bfc779d115fac4042b0/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_pipeliner_test.cc?ref=4fc3c61b2574fc35831e7bfc779d115fac4042b0",
            "patch": "@@ -108,7 +108,7 @@ absl::StatusOr<bool> RunOptimizer(\n     CollectivePipeliner::HloPostprocessor postprocess_backward_peeled_trailing =\n         {},\n     bool should_add_loop_invariant_op_in_chain = false,\n-    int64_t collective_size_threshold_to_stop_sinking = INT64_MAX) {\n+    int64_t collective_size_threshold_to_delay_sinking = INT64_MAX) {\n   CollectivePipeliner::Config config = {\n       /*level_to_operate_on=*/level_to_operate_on,\n       /*max_pipelining_per_loop=*/INT64_MAX,\n@@ -125,7 +125,7 @@ absl::StatusOr<bool> RunOptimizer(\n       postprocess_backward_rotated, postprocess_backward_peeled_trailing,\n       should_add_loop_invariant_op_in_chain,\n       /*postprocess_pipelined_ops=*/{},\n-      collective_size_threshold_to_stop_sinking};\n+      collective_size_threshold_to_delay_sinking};\n   HloPassPipeline pass(\"optimizer\");\n   pass.AddPass<HloVerifier>(/*layout_sensitive=*/false,\n                             /*allow_mixed_precision=*/false);\n@@ -3751,7 +3751,7 @@ ENTRY entry {\n }\n \n TEST_F(CollectivePipelinerTest,\n-       ForwardSinkDependentPipelineableCollectivesDoNotPipeline) {\n+       ForwardSinkDoNotStopPipeliningAfterLargeCollectives) {\n   constexpr absl::string_view hlo_string = R\"(\n HloModule module\n \n@@ -3762,71 +3762,66 @@ add {\n }\n \n add.1 {\n-  lhs.1 = bf16[] parameter(0)\n-  rhs.1 = bf16[] parameter(1)\n-  ROOT add.1 = bf16[] add(lhs.1, rhs.1)\n-}\n-\n-while_body.clone {\n-  sink_param.1 = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}, bf16[3,1,8,128]{3,2,1,0}) parameter(0)\n-  get-tuple-element.0 = s32[] get-tuple-element(sink_param.1), index=0\n-  constant.5 = s32[] constant(1)\n-  add.2 = s32[] add(get-tuple-element.0, constant.5)\n-  get-tuple-element.1 = bf16[3,8,128]{2,1,0} get-tuple-element(sink_param.1), index=1\n-  get-tuple-element.2 = bf16[3,8,128]{2,1,0} get-tuple-element(sink_param.1), index=2\n-  get-tuple-element.3 = bf16[3,1,8,128]{3,2,1,0} get-tuple-element(sink_param.1), index=3\n-  constant.6 = s32[] constant(3)\n-  subtract.0 = s32[] subtract(constant.6, get-tuple-element.0)\n-  constant.7 = s32[] constant(-1)\n-  add.3 = s32[] add(subtract.0, constant.7)\n-  constant.8 = s32[] constant(0)\n-  compare.0 = pred[] compare(add.3, constant.8), direction=LT\n-  constant.9 = s32[] constant(2)\n-  add.4 = s32[] add(subtract.0, constant.9)\n-  select.0 = s32[] select(compare.0, add.4, add.3)\n-  dynamic-slice.0 = bf16[1,8,128]{2,1,0} dynamic-slice(get-tuple-element.2, select.0, constant.8, constant.8), dynamic_slice_sizes={1,8,128}\n-  mul.1 = bf16[1,8,128]{2,1,0} multiply(dynamic-slice.0, dynamic-slice.0)\n-  ar.0 = bf16[1,8,128]{2,1,0} all-reduce(mul.1), channel_id=1, replica_groups={}, to_apply=add\n-  b.0 = bf16[1,8,128,32]{3,2,1,0} broadcast(ar.0), dimensions={0,1,2}\n-  constant.10 = bf16[] constant(0)\n-  reduce.1 = bf16[1,8,128]{2,1,0} reduce(b.0, constant.10), dimensions={3}, to_apply=add.1\n-  reshape.1 = bf16[1,1,8,128]{3,2,1,0} reshape(reduce.1)\n-  custom-call.2 = bf16[1,1,8,128]{3,2,1,0} custom-call(reshape.1), custom_call_target=\"SunkByPreviousStep\"\n-  constant.12 = s32[] constant(0)\n-  dynamic-update-slice.1 = bf16[3,1,8,128]{3,2,1,0} dynamic-update-slice(get-tuple-element.3, custom-call.2, select.0, constant.12, constant.12, constant.12)\n-  ROOT tuple.3 = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}, bf16[3,1,8,128]{3,2,1,0}) tuple(add.2, get-tuple-element.1, get-tuple-element.2, dynamic-update-slice.1)\n+  lhs = bf16[] parameter(0)\n+  rhs = bf16[] parameter(1)\n+  ROOT add = bf16[] add(lhs, rhs)\n }\n \n-while_cond.clone {\n-  sink_param = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}, bf16[3,1,8,128]{3,2,1,0}) parameter(0)\n-  gte.1 = s32[] get-tuple-element(sink_param), index=0\n-  constant.13 = s32[] constant(3)\n-  ROOT cmp.1 = pred[] compare(gte.1, constant.13), direction=LT\n+while_cond {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128], bf16[3,128,128], bf16[3,128,128]) parameter(0)\n+  gte = s32[] get-tuple-element(param), index=0\n+  constant.1 = s32[] constant(3)\n+  ROOT cmp = pred[] compare(gte, constant.1), direction=LT\n+}\n+\n+while_body {\n+  param = (s32[], bf16[3,8,128], bf16[3,8,128], bf16[3,128,128], bf16[3,128,128]) parameter(0)\n+  get-tuple-element.394 = s32[] get-tuple-element(param), index=0\n+  get-tuple-element.395 = bf16[3,8,128] get-tuple-element(param), index=1\n+  get-tuple-element.35 = bf16[3,8,128] get-tuple-element(param), index=2\n+  constant.2557 = s32[] constant(1)\n+  add.230 = s32[] add(get-tuple-element.394, constant.2557)\n+  constant.2559 = s32[] constant(3)\n+  subtract.139 = s32[] subtract(constant.2559, get-tuple-element.394)\n+  constant.2560 = s32[] constant(-1)\n+  add.231 = s32[] add(subtract.139, constant.2560)\n+  constant.2561 = s32[] constant(0)\n+  compare.747 = pred[] compare(add.231, constant.2561), direction=LT\n+  constant.2562 = s32[] constant(2)\n+  add.232 = s32[] add(subtract.139, constant.2562)\n+  select.1348 = s32[] select(compare.747, add.232, add.231)\n+  dynamic-slice.99 = bf16[1,8,128] dynamic-slice(get-tuple-element.35, select.1348, constant.2561, constant.2561), dynamic_slice_sizes={1,8,128}\n+  mul = bf16[1,8,128] multiply(dynamic-slice.99, dynamic-slice.99)\n+  ar.1 = bf16[1,8,128] all-reduce(mul), replica_groups={}, to_apply=add, channel_id=1\n+  b.1 = bf16[1,8,128,32] broadcast(ar.1), dimensions={0,1,2}\n+  constant = bf16[] constant(0)\n+  reduce = bf16[1,8,128] reduce(b.1, constant), dimensions={3}, to_apply=add.1\n+  ar.2 = bf16[1,8,128] all-reduce(reduce), replica_groups={}, to_apply=add, channel_id=2\n+  c1 = bf16[] constant(2.0)\n+  bc = bf16[1,8,128] broadcast(c1)\n+  mul1 = bf16[1,8,128] multiply(ar.2, bc)\n+  mul3 = bf16[1,8,128] multiply(mul1, ar.2)\n+  dynamic-update-slice.35 = bf16[3,8,128] dynamic-update-slice(get-tuple-element.395, mul3, select.1348, constant.2561, constant.2561)\n+  get-tuple-element.396 = bf16[3,128,128] get-tuple-element(param), index=3\n+  get-tuple-element.36 = bf16[3,128,128] get-tuple-element(param), index=4\n+  dynamic-slice.100 = bf16[1,128,128] dynamic-slice(get-tuple-element.36, select.1348, constant.2561, constant.2561), dynamic_slice_sizes={1,128,128}\n+  large-ar = bf16[1,128,128] all-reduce(dynamic-slice.100), replica_groups={}, to_apply=add, channel_id=3\n+  dynamic-update-slice.36 = bf16[3,128,128] dynamic-update-slice(get-tuple-element.396, large-ar, select.1348, constant.2561, constant.2561)\n+  ROOT tuple = (s32[], bf16[3,8,128], bf16[3,8,128], bf16[3,128,128], bf16[3,128,128]) tuple(add.230, dynamic-update-slice.35, get-tuple-element.35, dynamic-update-slice.36, get-tuple-element.36)\n }\n \n ENTRY entry {\n   c0 = s32[] constant(0)\n-  p0 = bf16[3,8,128]{2,1,0} parameter(0)\n-  constant.2 = bf16[] constant(0)\n-  broadcast = bf16[3,1,8,128]{3,2,1,0} broadcast(constant.2), dimensions={}\n-  tuple.2 = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}, bf16[3,1,8,128]{3,2,1,0}) tuple(c0, p0, p0, broadcast)\n-  while.1 = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}, bf16[3,1,8,128]{3,2,1,0}) while(tuple.2), condition=while_cond.clone, body=while_body.clone\n-  get-tuple-element.5 = s32[] get-tuple-element(while.1), index=0\n-  get-tuple-element.4 = bf16[3,1,8,128]{3,2,1,0} get-tuple-element(while.1), index=3\n-  ar.4 = bf16[3,1,8,128]{3,2,1,0} all-reduce(get-tuple-element.4), channel_id=3, replica_groups={}, to_apply=add\n-  c1.3 = bf16[] constant(2)\n-  broadcast.1 = bf16[3,1,8,128]{3,2,1,0} broadcast(c1.3), dimensions={}\n-  mul1.2 = bf16[3,1,8,128]{3,2,1,0} multiply(ar.4, broadcast.1)\n-  mul3.2 = bf16[3,1,8,128]{3,2,1,0} multiply(mul1.2, ar.4)\n-  reshape.2 = bf16[3,8,128]{2,1,0} reshape(mul3.2)\n-  get-tuple-element.6 = bf16[3,8,128]{2,1,0} get-tuple-element(while.1), index=2\n-  tuple.4 = (s32[], bf16[3,8,128]{2,1,0}, bf16[3,8,128]{2,1,0}) tuple(get-tuple-element.5, reshape.2, get-tuple-element.6)\n-  ROOT gte1 = bf16[3,8,128]{2,1,0} get-tuple-element(tuple.4), index=1\n+  p0 = bf16[3,8,128] parameter(0)\n+  p1 = bf16[3,128,128] parameter(1)\n+  tuple = (s32[], bf16[3,8,128], bf16[3,8,128], bf16[3,128,128], bf16[3,128,128]) tuple(c0, p0, p0, p1, p1)\n+  while = (s32[], bf16[3,8,128], bf16[3,8,128], bf16[3,128,128], bf16[3,128,128]) while(tuple), condition=while_cond, body=while_body\n+  ROOT gte1 = bf16[3,8,128] get-tuple-element(while), index=1\n }\n )\";\n   config_.set_use_spmd_partitioning(true);\n   auto module = ParseAndReturnUnverifiedModule(hlo_string, config_).value();\n-  EXPECT_FALSE(\n+  EXPECT_TRUE(\n       RunOptimizer(\n           module.get(), /*last_run=*/false,\n           /*level_to_operate_on=*/0,\n@@ -3842,8 +3837,15 @@ ENTRY entry {\n           /*postprocess_backward_rotated=*/{},\n           /*postprocess_backward_peeled_trailing=*/{},\n           /*should_add_loop_invariant_op_in_chain=*/false,\n-          /*collective_size_threshold_to_stop_sinking=*/1024)\n+          /*collective_size_threshold_to_delay_sinking=*/2048)\n           .value());\n+  XLA_VLOG_LINES(1, module->ToString());\n+  const HloInstruction* while_instr =\n+      FindInstruction(module.get(), HloOpcode::kWhile);\n+  EXPECT_TRUE(absl::c_none_of(while_instr->while_body()->instructions(),\n+                              [](const HloInstruction* instr) {\n+                                return instr->opcode() == HloOpcode::kAllReduce;\n+                              }));\n }\n \n TEST_F(CollectivePipelinerTest, ForwardSinkFirstDimNotMatchingLoopCount) {"
        }
    ],
    "stats": {
        "total": 207,
        "additions": 110,
        "deletions": 97
    }
}