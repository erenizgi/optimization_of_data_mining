{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Implement pass to rewrite dynamic vector extracts to static.\n\nPiperOrigin-RevId: 824427163",
    "sha": "dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
    "files": [
        {
            "sha": "5d1598dfc7412919a14ca1e097346b7649fd253b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD?ref=dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
            "patch": "@@ -48,6 +48,7 @@ cc_library(\n     srcs = [\n         \"elemental_tensor_to_vector.cc\",\n         \"lower_xtile_entry.cc\",\n+        \"rewrite_dynamic_vector_extract.cc\",\n         \"shlo_to_vector.cc\",\n         \"tensor_ops_to_vector.cc\",\n         \"xtile_to_vector.cc\",\n@@ -63,6 +64,7 @@ cc_library(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@llvm-project//llvm:Support\",\n+        \"@llvm-project//mlir:Analysis\",\n         \"@llvm-project//mlir:ArithDialect\",\n         \"@llvm-project//mlir:ArithOpsIncGen\",\n         \"@llvm-project//mlir:DataLayoutInterfaces\",\n@@ -75,6 +77,7 @@ cc_library(\n         \"@llvm-project//mlir:MemRefDialect\",\n         \"@llvm-project//mlir:Pass\",\n         \"@llvm-project//mlir:SCFDialect\",\n+        \"@llvm-project//mlir:SCFUtils\",\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TensorDialect\",\n         \"@llvm-project//mlir:TransformUtils\","
        },
        {
            "sha": "6ad787bce81a76a21371241c543c7c39780c2fb6",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h?ref=dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
            "patch": "@@ -38,6 +38,7 @@ std::unique_ptr<mlir::Pass> CreateLowerXTileEntryPass();\n std::unique_ptr<mlir::Pass> CreateShloToVectorPass();\n std::unique_ptr<mlir::Pass> CreateXTileToVectorPass();\n std::unique_ptr<mlir::Pass> CreateTensorOpsToVectorPass();\n+std::unique_ptr<mlir::Pass> CreateRewriteDynamicVectorExtractPass();\n \n #define GEN_PASS_REGISTRATION\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\""
        },
        {
            "sha": "2e6aca66e2c6a38db62e8998a144b2bdb18745a6",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.td",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td?ref=dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
            "patch": "@@ -76,3 +76,15 @@ def TensorOpsToVectorPass : Pass<\"xtile-cpu-tensor-ops-to-vector\",\n     \"mlir::vector::VectorDialect\",\n   ];\n }\n+\n+def RewriteDynamicVectorExtractPass : Pass<\"xtile-cpu-rewrite-dynamic-vector-extract\",\n+                                 \"mlir::ModuleOp\"> {\n+  let summary = \"Rewrite vector.extracts with dynamic indices.\";\n+\n+  let constructor = \"CreateRewriteDynamicVectorExtractPass()\";\n+\n+  let dependentDialects = [\n+    \"::mlir::vector::VectorDialect\",\n+    \"::mlir::memref::MemRefDialect\",\n+  ];\n+}"
        },
        {
            "sha": "a8633b7d6178adc2502a129d28f9c445a9558e73",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/rewrite_dynamic_vector_extract.cc",
            "status": "added",
            "additions": 262,
            "deletions": 0,
            "changes": 262,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc?ref=dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
            "patch": "@@ -0,0 +1,262 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cassert>\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"mlir/Analysis/SliceAnalysis.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/SCF/IR/SCF.h\"\n+#include \"mlir/Dialect/SCF/Utils/Utils.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OpDefinition.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/Visitors.h\"\n+#include \"mlir/Interfaces/DataLayoutInterfaces.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n+\n+namespace xla::cpu {\n+\n+#define GEN_PASS_DECL_REWRITEDYNAMICVECTOREXTRACTPASS\n+#define GEN_PASS_DEF_REWRITEDYNAMICVECTOREXTRACTPASS\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+struct FoldExtractIntoTransferRead\n+    : mlir::OpRewritePattern<mlir::vector::ExtractOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::vector::ExtractOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    if (!op.hasDynamicPosition()) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"extract does not have dynamic position\");\n+    }\n+\n+    auto transfer_read_op =\n+        op.getSource().getDefiningOp<mlir::vector::TransferReadOp>();\n+\n+    if (!transfer_read_op) {\n+      return rewriter.notifyMatchFailure(op,\n+                                         \"source is not a transfer_read op\");\n+    }\n+    auto vector_type = mlir::dyn_cast<mlir::VectorType>(op.getType());\n+    if (!vector_type) {\n+      // TODO(willfroom): Support scalars types.\n+      return rewriter.notifyMatchFailure(op, \"Output is not a vector type\");\n+    }\n+\n+    mlir::ValueRange transfer_read_indices = transfer_read_op.getIndices();\n+\n+    llvm::SmallVector<mlir::OpFoldResult> extended_positions(\n+        op.getMixedPosition());\n+    for (int64_t idx = extended_positions.size();\n+         idx < transfer_read_indices.size(); ++idx) {\n+      extended_positions.push_back(rewriter.getIndexAttr(0));\n+    }\n+\n+    llvm::SmallVector<mlir::Value> new_offsets;\n+    new_offsets.reserve(transfer_read_indices.size());\n+    for (auto [tile_offset, extract_offset] :\n+         llvm::zip(transfer_read_indices, extended_positions)) {\n+      if (auto static_position =\n+              mlir::dyn_cast<mlir::Attribute>(extract_offset)) {\n+        new_offsets.push_back(mlir::arith::AddIOp::create(\n+            rewriter, op.getLoc(), rewriter.getIndexType(), tile_offset,\n+            mlir::arith::ConstantIndexOp::create(\n+                rewriter, op.getLoc(),\n+                mlir::cast<mlir::IntegerAttr>(static_position).getInt())));\n+      } else {\n+        auto dynamic_position = mlir::dyn_cast<mlir::Value>(extract_offset);\n+        new_offsets.push_back(mlir::arith::AddIOp::create(\n+            rewriter, op.getLoc(), rewriter.getIndexType(), tile_offset,\n+            dynamic_position));\n+      }\n+    }\n+\n+    mlir::Value submask;\n+    if (auto mask = transfer_read_op.getMask()) {\n+      submask = mlir::vector::ExtractOp::create(rewriter, op.getLoc(), mask,\n+                                                op.getMixedPosition());\n+    }\n+\n+    int64_t rank = transfer_read_op.getBase().getType().getRank();\n+\n+    // Drop major dimensions which reflects the behaviour of vector::ExtractOp.\n+    int64_t num_dropped_dims = rank - vector_type.getRank();\n+    mlir::AffineMap new_permutation_map =\n+        mlir::AffineMap::getFilteredIdentityMap(\n+            rewriter.getContext(), rank, [&](mlir::AffineDimExpr expr) {\n+              return expr.getPosition() >= num_dropped_dims;\n+            });\n+\n+    llvm::SmallVector<mlir::Attribute> in_bounds(\n+        transfer_read_op.getInBounds().begin() + num_dropped_dims,\n+        transfer_read_op.getInBounds().end());\n+\n+    rewriter.replaceOpWithNewOp<mlir::vector::TransferReadOp>(\n+        op, vector_type, transfer_read_op.getBase(), new_offsets,\n+        new_permutation_map, transfer_read_op.getPadding(), submask,\n+        rewriter.getArrayAttr(in_bounds));\n+\n+    return mlir::success();\n+  }\n+};\n+\n+// FoldExtractIntoTransferRead creates its own dynamic extracts if a mask is\n+// present, so we need to fold these.\n+// We do this by shifting the offset and then extracting with static indices.\n+struct FoldExtractIntoCreateMask\n+    : mlir::OpRewritePattern<mlir::vector::ExtractOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::vector::ExtractOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    if (!op.hasDynamicPosition()) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"extract does not have dynamic position\");\n+    }\n+    auto mask_op = op.getSource().getDefiningOp<mlir::vector::CreateMaskOp>();\n+    if (!mask_op) {\n+      return rewriter.notifyMatchFailure(op, \"source is not a create_mask op\");\n+    }\n+\n+    mlir::ValueRange mask_operands = mask_op.getOperands();\n+\n+    llvm::SmallVector<mlir::OpFoldResult> extended_positions(\n+        op.getMixedPosition());\n+    for (int64_t idx = extended_positions.size(); idx < mask_operands.size();\n+         ++idx) {\n+      extended_positions.push_back(rewriter.getIndexAttr(0));\n+    }\n+\n+    llvm::SmallVector<mlir::Value> new_bounds;\n+    new_bounds.reserve(mask_operands.size());\n+    for (auto [mask_bound, extract_offset] :\n+         llvm::zip(mask_operands, extended_positions)) {\n+      if (auto static_position =\n+              mlir::dyn_cast<mlir::Attribute>(extract_offset)) {\n+        new_bounds.push_back(mlir::arith::SubIOp::create(\n+            rewriter, op.getLoc(), rewriter.getIndexType(), mask_bound,\n+            mlir::arith::ConstantIndexOp::create(\n+                rewriter, op.getLoc(),\n+                mlir::cast<mlir::IntegerAttr>(static_position).getInt())));\n+      } else {\n+        auto dynamic_position = mlir::dyn_cast<mlir::Value>(extract_offset);\n+        new_bounds.push_back(mlir::arith::SubIOp::create(\n+            rewriter, op.getLoc(), rewriter.getIndexType(), mask_bound,\n+            dynamic_position));\n+      }\n+    }\n+\n+    auto shifted_mask = mlir::vector::CreateMaskOp::create(\n+        rewriter, op.getLoc(), mask_op.getType(), new_bounds);\n+\n+    llvm::SmallVector<int64_t> zero_index(op.getMixedPosition().size(), 0);\n+\n+    rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(op, shifted_mask,\n+                                                         zero_index);\n+\n+    return mlir::success();\n+  }\n+};\n+\n+// Unroll loops that have a vector.extract that depend on the loop induction\n+// variable.\n+struct UnrollExtractLoops : mlir::OpRewritePattern<mlir::scf::ForOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::scf::ForOp op, mlir::PatternRewriter& rewriter) const override {\n+    if (op.getRegion().getOps<mlir::vector::ExtractOp>().empty()) {\n+      return rewriter.notifyMatchFailure(op,\n+                                         \"loop does not contain an extract\");\n+    }\n+\n+    llvm::SetVector<mlir::Operation*> slices;\n+    mlir::getForwardSlice(op.getInductionVar(), &slices);\n+\n+    for (auto slice : slices) {\n+      if (mlir::isa<mlir::vector::ExtractOp>(slice)) {\n+        return mlir::loopUnrollFull(op);\n+      }\n+    }\n+\n+    return rewriter.notifyMatchFailure(\n+        op, \"loop does not contain a dependent extract\");\n+  }\n+};\n+\n+class RewriteDynamicVectorExtractPass\n+    : public impl::RewriteDynamicVectorExtractPassBase<\n+          RewriteDynamicVectorExtractPass> {\n+ public:\n+  using RewriteDynamicVectorExtractPassBase::\n+      RewriteDynamicVectorExtractPassBase;\n+\n+  void runOnOperation() override {\n+    mlir::ModuleOp module = getOperation();\n+    mlir::MLIRContext* context = &getContext();\n+\n+    {\n+      mlir::RewritePatternSet patterns(context);\n+      patterns.add<FoldExtractIntoTransferRead, FoldExtractIntoCreateMask>(\n+          context);\n+      if (mlir::failed(\n+              mlir::applyPatternsGreedily(module, std::move(patterns)))) {\n+        signalPassFailure();\n+        return;\n+      }\n+    }\n+\n+    // As a final sledge hammer, we can unroll the loops if we have any\n+    // dependent extracts.\n+    {\n+      mlir::RewritePatternSet patterns(context);\n+      patterns.add<UnrollExtractLoops>(context);\n+      if (mlir::failed(\n+              mlir::applyPatternsGreedily(module, std::move(patterns)))) {\n+        signalPassFailure();\n+        return;\n+      }\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateRewriteDynamicVectorExtractPass() {\n+  return std::make_unique<RewriteDynamicVectorExtractPass>();\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "b405531cffa82bd06a6f43539fdefc3d5047706e",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/rewrite_dynamic_vector_extract.mlir",
            "status": "added",
            "additions": 104,
            "deletions": 0,
            "changes": 104,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/dfeccf211b235a2afbd5bcf05c9d88b94fe4746f/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir?ref=dfeccf211b235a2afbd5bcf05c9d88b94fe4746f",
            "patch": "@@ -0,0 +1,104 @@\n+// RUN: emitters_opt %s \\\n+// RUN: -xtile-cpu-rewrite-dynamic-vector-extract -canonicalize \\\n+// RUN: -split-input-file | FileCheck %s\n+\n+func.func @fold_vector_extract_into_transfer_read(\n+  %buffer: memref<8x4x2xf32>,\n+  %idx0: index,\n+  %idx1: index) -> vector<2xf32> {\n+  %c0 = arith.constant 0 : index\n+  %c0_f32 = arith.constant 0.0 : f32\n+  %c1 = arith.constant 1 : index\n+  %c3 = arith.constant 3 : index\n+  %c7 = arith.constant 7 : index\n+  %mask = vector.create_mask %c7, %c3, %c1 : vector<8x4x2xi1>\n+  %original_vector = vector.transfer_read %buffer[%c0, %c0, %c0],\n+    %c0_f32, %mask : memref<8x4x2xf32>, vector<8x4x2xf32>\n+  %subvector = vector.extract %original_vector[%idx0, %idx1]\n+    : vector<2xf32> from vector<8x4x2xf32>\n+  return %subvector : vector<2xf32>\n+}\n+\n+// CHECK:      func.func @fold_vector_extract_into_transfer_read(\n+// CHECK-SAME:   %[[BUFFER:.*]]: memref<8x4x2xf32>,\n+// CHECK-SAME:   %[[IDX0:.*]]: index,\n+// CHECK-SAME:   %[[IDX1:.*]]: index) -> vector<2xf32> {\n+// CHECK-DAG:    %[[PAD:.*]] = arith.constant 0.000000e+00 : f32\n+// CHECK-DAG:    %[[C0:.*]] = arith.constant 0 : index\n+// CHECK-DAG:    %[[C1:.*]] = arith.constant 1 : index\n+// CHECK-DAG:    %[[C3:.*]] = arith.constant 3 : index\n+// CHECK-DAG:    %[[C7:.*]] = arith.constant 7 : index\n+// CHECK:        %[[SHIFT_IDX0:.*]] = arith.subi %[[C7]], %[[IDX0]] : index\n+// CHECK:        %[[SHIFT_SUBIDX1:.*]] = arith.subi %[[C3]], %[[IDX1]] : index\n+// CHECK:        %[[SHIFT_MASK:.*]] = vector.create_mask\n+// CHECK-SAME:     %[[SHIFT_IDX0]], %[[SHIFT_SUBIDX1]], %[[C1]] : vector<8x4x2xi1>\n+// CHECK:        %[[SUBMASK:.*]] = vector.extract %[[SHIFT_MASK]][0, 0]\n+// CHECK-SAME:     : vector<2xi1> from vector<8x4x2xi1>\n+// CHECK:        %[[SUBVECTOR:.*]] = vector.transfer_read\n+// CHECK-SAME:     %[[BUFFER]][%[[IDX0]], %[[IDX1]], %[[C0]]], %[[PAD]], %[[SUBMASK]]\n+// CHECK-SAME:     {in_bounds = [true]} : memref<8x4x2xf32>, vector<2xf32>\n+// CHECK:        return %[[SUBVECTOR]] : vector<2xf32>\n+// CHECK:      }\n+\n+\n+// -----\n+\n+func.func @unroll_dependent_vector_extract(%input: vector<8x2xf32>) -> vector<2xf32> {\n+  %c0 = arith.constant 0 : index\n+  %c1 = arith.constant 1 : index\n+  %c8 = arith.constant 8 : index\n+  %c0_f32 = arith.constant 0. : f32\n+  %init = vector.broadcast %c0_f32 : f32 to vector<2xf32>\n+  %result = scf.for %index = %c0 to %c8 step %c1 iter_args(%carry = %init) -> vector<2xf32> {\n+    %extract = vector.extract %input[%index] : vector<2xf32> from vector<8x2xf32>\n+    %add = arith.addf %carry, %extract : vector<2xf32>\n+    scf.yield %add : vector<2xf32>\n+  }\n+  return %result : vector<2xf32>\n+}\n+\n+// CHECK-LABEL:    func.func @unroll_dependent_vector_extract(\n+// CHECK-NOT:       scf.for\n+// CHECK-COUNT-8:     vector.extract\n+\n+// -----\n+\n+func.func @unroll_indirect_dependent_vector_extract(%input: vector<8x2xf32>) -> vector<2xf32> {\n+  %c0 = arith.constant 0 : index\n+  %c1 = arith.constant 1 : index\n+  %c2 = arith.constant 2 : index\n+  %c4 = arith.constant 4 : index\n+  %c0_f32 = arith.constant 0. : f32\n+  %init = vector.broadcast %c0_f32 : f32 to vector<2xf32>\n+  %result = scf.for %index = %c0 to %c4 step %c1 iter_args(%carry = %init) -> vector<2xf32> {\n+    %strided_index = arith.muli %index, %c2 : index\n+    %extract = vector.extract %input[%strided_index] : vector<2xf32> from vector<8x2xf32>\n+    %add = arith.addf %carry, %extract : vector<2xf32>\n+    scf.yield %add : vector<2xf32>\n+  }\n+  return %result : vector<2xf32>\n+}\n+\n+// CHECK-LABEL:    func.func @unroll_indirect_dependent_vector_extract(\n+// CHECK-NOT:        scf.for\n+// CHECK-COUNT-4:     vector.extract\n+\n+// -----\n+\n+func.func @does_not_unroll_independent_vector_extract(%input: vector<8x2xf32>, %arg_index: index) -> vector<2xf32> {\n+  %c0 = arith.constant 0 : index\n+  %c1 = arith.constant 1 : index\n+  %c8 = arith.constant 8 : index\n+  %c0_f32 = arith.constant 0. : f32\n+  %init = vector.broadcast %c0_f32 : f32 to vector<2xf32>\n+  %result = scf.for %index = %c0 to %c8 step %c1 iter_args(%carry = %init) -> vector<2xf32> {\n+    %extract = vector.extract %input[%arg_index] : vector<2xf32> from vector<8x2xf32>\n+    %add = arith.addf %carry, %extract : vector<2xf32>\n+    scf.yield %add : vector<2xf32>\n+  }\n+  return %result : vector<2xf32>\n+}\n+\n+// CHECK-LABEL:    func.func @does_not_unroll_independent_vector_extract(\n+// CHECK:            scf.for\n+// CHECK-COUNT-1:     vector.extract"
        }
    ],
    "stats": {
        "total": 382,
        "additions": 382,
        "deletions": 0
    }
}