{
    "author": "bchetioui",
    "message": "[XLA:GPU] Add a filter in the Triton fusion emitter to allow using a transposed iteration schedule for fusions rooted in dot.\n\nThe intent is to improve L2 cache hits in the case where the left-hand side argument\nfully fits in L2.\n\nPiperOrigin-RevId: 821882872",
    "sha": "fe31cef146127f2ed920c33b34557faea6e6f238",
    "files": [
        {
            "sha": "11b5c77e432d9fc9107639241637481d1f93e8fe",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=fe31cef146127f2ed920c33b34557faea6e6f238",
            "patch": "@@ -861,8 +861,14 @@ xla_test(\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla:xla_proto_cc\",\n+        \"//xla/codegen/tiling:symbolic_tile_analysis\",\n+        \"//xla/codegen/tiling:tiled_hlo_computation\",\n+        \"//xla/codegen/tiling:tiled_hlo_instruction\",\n+        \"//xla/codegen/tiling:tiled_hlo_schedule\",\n+        \"//xla/codegen/tiling:tiling_specification\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/testlib:filecheck\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service:algorithm_util\",\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/service/gpu:gpu_device_info_for_tests\","
        },
        {
            "sha": "072135a52a0f86db01c10390d7c61acc06824667",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 39,
            "deletions": 3,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=fe31cef146127f2ed920c33b34557faea6e6f238",
            "patch": "@@ -1776,12 +1776,48 @@ absl::Status EmitGeneric(mlir::OpBuilder builder,\n                             ->config()\n                             .debug_options()\n                             .xla_gpu_unsupported_annotate_with_emitter_loc());\n-\n-  int64_t root_index = FindIndex(symbolic_tile_analysis.GetRoots(), root);\n+  absl::Span<const HloInstruction* const> roots =\n+      symbolic_tile_analysis.GetRoots();\n+  int64_t root_index = FindIndex(roots, root);\n+  TiledHloScheduleBuilder schedule_builder = CreateMajorToMinorTiledHloSchedule;\n+\n+  // TODO(b/417977182): this is a hacky heuristic to avoid regressing cases\n+  // involving hardcoded grid tiling in the legacy emitter, as we enable the new\n+  // one for `dot` fusions.\n+  //\n+  // The idea here is that, if `lhs` can fully fit in L2 cache, and `rhs` does\n+  // not, we should start with iterating over the full `lhs` in order to have it\n+  // in cache for all subsequent iterations over `rhs`. That means we should\n+  // iterate over `lhs`'s non-contracting dimensions first.\n+  //\n+  // Whenever it is not true that one of the operands can fit fully in cache, it\n+  // is more beneficial to use a \"planar snake\" space-filling curve to optimize\n+  // L2 cache hits, but this is not implemented yet.\n+  if (roots.size() == 1 && root->opcode() == HloOpcode::kDot) {\n+    int64_t lhs_bytes_size =\n+        Product(root->operand(0)->shape().dimensions()) *\n+        primitive_util::ByteWidth(root->operand(0)->shape().element_type());\n+    int64_t rhs_bytes_size =\n+        Product(root->operand(1)->shape().dimensions()) *\n+        primitive_util::ByteWidth(root->operand(1)->shape().element_type());\n+    if (lhs_bytes_size < rhs_bytes_size) {\n+      // Validates whether the expected invariants are upheld by the analysis to\n+      // ensure we don't crash later.\n+      //\n+      // TODO(b/417977182): use a \"conformance\" API instead of a builder to\n+      // reuse what we build here directly.\n+      absl::StatusOr<std::unique_ptr<TransposedDotTiledHloSchedule>>\n+          transposed_schedule = TransposedDotTiledHloSchedule::Create(\n+              symbolic_tile_analysis.GetTilingSpecification());\n+      if (transposed_schedule.ok()) {\n+        schedule_builder = TransposedDotTiledHloSchedule::Create;\n+      }\n+    }\n+  }\n   TF_RET_CHECK(root_index < symbolic_tile_analysis.GetRoots().size());\n   TF_ASSIGN_OR_RETURN(TiledHloComputation tiled_hlo_computation,\n                       symbolic_tile_analysis.ComputeTiledHloInstructions(\n-                          tiling, CreateMajorToMinorTiledHloSchedule,\n+                          tiling, schedule_builder,\n                           /*constraints_are_known_satisfied=*/false,\n                           /*compute_all_tile_offset_indexing_maps=*/true));\n   VLOG(3) << \"EmitGeneric: tiled HLO computation:\\n\""
        },
        {
            "sha": "a703db0c2834fd60a94bc0df42476aac21d63fad",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 227,
            "deletions": 1,
            "changes": 228,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/fe31cef146127f2ed920c33b34557faea6e6f238/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=fe31cef146127f2ed920c33b34557faea6e6f238",
            "patch": "@@ -15,10 +15,13 @@ limitations under the License.\n \n #include <array>\n #include <cstdint>\n+#include <memory>\n+#include <optional>\n #include <ostream>\n #include <string>\n+#include <tuple>\n #include <utility>\n-#include <variant>\n+#include <vector>\n \n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n@@ -44,6 +47,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/testlib/filecheck.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/primitive_util.h\"\n@@ -4274,6 +4278,228 @@ ENTRY entry {\n       kHloText, ErrorSpec{/*aabs=*/1e-1, /*arel=*/1e-2}));\n }\n \n+TEST_F(TritonEmitterTest, UseTransposedDotScheduleWhenDotLhsIsSmallerThanRhs) {\n+  constexpr int tile_batch = 1;\n+  constexpr int tile_m = 16;\n+  constexpr int tile_n = 8;\n+  constexpr int tile_k = 32;\n+  const std::string hlo_text =\n+      absl::Substitute(R\"(\n+\n+lhs {\n+  ROOT p0 = f32[2,32,64] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = f32[2,64,128] parameter(0)\n+}\n+\n+fusion {\n+  p0 = f32[2,32,64] parameter(0)\n+  p1 = f32[2,64,128] parameter(1)\n+\n+  lhs = f32[2,32,64] fusion(p0), kind=kCustom, calls=lhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$2\"]}]\n+      }\n+    }\n+  }\n+  rhs = f32[2,64,128] fusion(p1), kind=kCustom, calls=rhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$3\"]}]\n+      }\n+    }\n+  }\n+\n+  ROOT dot = f32[2,32,128] dot(lhs, rhs),\n+    lhs_batch_dims={0}, rhs_batch_dims={0},\n+    lhs_contracting_dims={2}, rhs_contracting_dims={1}\n+}\n+\n+ENTRY main {\n+  p0 = f32[2,32,64] parameter(0)\n+  p1 = f32[2,64,128] parameter(1)\n+  ROOT fusion = f32[2,32,128] fusion(p0, p1),\n+    kind=kCustom, calls=fusion, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_nested_gemm_fusion\",\n+        \"block_level_fusion_config\":{\n+          \"output_tiles\":[{\"sizes\":[\"$1\", \"$2\", \"$3\"]}],\n+          \"num_warps\":\"4\",\n+          \"num_ctas\":\"1\",\n+          \"num_stages\":\"1\"}}}\n+})\",\n+                       tile_k, tile_batch, tile_m, tile_n);\n+\n+  int64_t m = 32;\n+  int64_t n = 128;\n+\n+  int64_t num_m_tiles = (m / tile_m);\n+  int64_t num_n_tiles = (n / tile_n);\n+\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n+      this, hlo_text, \"fusion\",\n+      absl::Substitute(\n+          R\"(\n+CHECK-DAG: (pid_0) -> ((pid_0 mod $0) * $1)\n+CHECK-DAG: (pid_0) -> (((pid_0 floordiv $0) mod $2) * $3)\n+)\",\n+          num_m_tiles, tile_m, num_n_tiles, tile_n)));\n+\n+  // Ensure that the transposed schedule still produces correct numerics.\n+  EXPECT_TRUE(RunAndCompareNoHloPasses(\n+      hlo_text, ErrorSpec{/*aabs=*/2e-4, /*arel=*/1e-6}));\n+}\n+\n+TEST_F(TritonEmitterTest, UseMajorToMinorScheduleWhenDotLhsIsLargerThanRhs) {\n+  constexpr int tile_batch = 1;\n+  constexpr int tile_m = 16;\n+  constexpr int tile_n = 8;\n+  constexpr int tile_k = 32;\n+  const std::string hlo_text =\n+      absl::Substitute(R\"(\n+\n+lhs {\n+  ROOT p0 = f32[2,128,64] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = f32[2,64,32] parameter(0)\n+}\n+\n+fusion {\n+  p0 = f32[2,128,64] parameter(0)\n+  p1 = f32[2,64,32] parameter(1)\n+\n+  lhs = f32[2,128,64] fusion(p0), kind=kCustom, calls=lhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$2\"]}]\n+      }\n+    }\n+  }\n+  rhs = f32[2,64,32] fusion(p1), kind=kCustom, calls=rhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$3\"]}]\n+      }\n+    }\n+  }\n+\n+  ROOT dot = f32[2,128,32] dot(lhs, rhs),\n+    lhs_batch_dims={0}, rhs_batch_dims={0},\n+    lhs_contracting_dims={2}, rhs_contracting_dims={1}\n+}\n+\n+ENTRY main {\n+  p0 = f32[2,128,64] parameter(0)\n+  p1 = f32[2,64,32] parameter(1)\n+  ROOT fusion = f32[2,128,32] fusion(p0, p1),\n+    kind=kCustom, calls=fusion, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_nested_gemm_fusion\",\n+        \"block_level_fusion_config\":{\n+          \"output_tiles\":[{\"sizes\":[\"$1\", \"$2\", \"$3\"]}],\n+          \"num_warps\":\"4\",\n+          \"num_ctas\":\"1\",\n+          \"num_stages\":\"1\"}}}\n+})\",\n+                       tile_k, tile_batch, tile_m, tile_n);\n+\n+  int64_t m = 128;\n+  int64_t n = 32;\n+\n+  int64_t num_m_tiles = (m / tile_m);\n+  int64_t num_n_tiles = (n / tile_n);\n+\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n+      this, hlo_text, \"fusion\",\n+      absl::Substitute(\n+          R\"(\n+CHECK-DAG: (pid_0) -> ((pid_0 mod $0) * $1)\n+CHECK-DAG: (pid_0) -> (((pid_0 floordiv $0) mod $2) * $3)\n+)\",\n+          num_n_tiles, tile_n, num_m_tiles, tile_m)));\n+\n+  // Ensure that the major-to-minor schedule still produces correct numerics.\n+  EXPECT_TRUE(RunAndCompareNoHloPasses(\n+      hlo_text, ErrorSpec{/*aabs=*/2e-4, /*arel=*/1e-6}));\n+}\n+\n+TEST_F(TritonEmitterTest, UseMajorToMinorScheduleWhenFusionIsNotRootedInDot) {\n+  constexpr int tile_batch = 1;\n+  constexpr int tile_m = 16;\n+  constexpr int tile_n = 8;\n+  constexpr int tile_k = 32;\n+  const std::string hlo_text =\n+      absl::Substitute(R\"(\n+\n+lhs {\n+  ROOT p0 = f32[2,32,64] parameter(0)\n+}\n+\n+rhs {\n+  ROOT p0 = f32[2,64,128] parameter(0)\n+}\n+\n+fusion {\n+  p0 = f32[2,32,64] parameter(0)\n+  p1 = f32[2,64,128] parameter(1)\n+\n+  lhs = f32[2,32,64] fusion(p0), kind=kCustom, calls=lhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$2\"]}]\n+      }\n+    }\n+  }\n+  rhs = f32[2,64,128] fusion(p1), kind=kCustom, calls=rhs, backend_config={\n+    \"fusion_backend_config\":{\n+      \"kind\":\"__triton_nested_gemm_fusion\", \"block_level_fusion_config\":{\n+        \"output_tiles\":[{\"sizes\":[\"$0\", \"$1\", \"$3\"]}]\n+      }\n+    }\n+  }\n+\n+  dot = f32[2,32,128] dot(lhs, rhs),\n+    lhs_batch_dims={0}, rhs_batch_dims={0},\n+    lhs_contracting_dims={2}, rhs_contracting_dims={1}\n+  ROOT abs = f32[2,32,128] abs(dot)\n+}\n+\n+ENTRY main {\n+  p0 = f32[2,32,64] parameter(0)\n+  p1 = f32[2,64,128] parameter(1)\n+  ROOT fusion = f32[2,32,128] fusion(p0, p1),\n+    kind=kCustom, calls=fusion, backend_config={\n+      \"fusion_backend_config\":{\n+        \"kind\":\"__triton_nested_gemm_fusion\",\n+        \"block_level_fusion_config\":{\n+          \"output_tiles\":[{\"sizes\":[\"$1\", \"$2\", \"$3\"]}],\n+          \"num_warps\":\"4\",\n+          \"num_ctas\":\"1\",\n+          \"num_stages\":\"1\"}}}\n+})\",\n+                       tile_k, tile_batch, tile_m, tile_n);\n+\n+  int64_t m = 32;\n+  int64_t n = 128;\n+\n+  int64_t num_m_tiles = (m / tile_m);\n+  int64_t num_n_tiles = (n / tile_n);\n+\n+  TF_EXPECT_OK(CreateTritonIrAndFileCheck(\n+      this, hlo_text, \"fusion\",\n+      absl::Substitute(\n+          R\"(\n+CHECK-DAG: (pid_0) -> ((pid_0 mod $0) * $1)\n+CHECK-DAG: (pid_0) -> (((pid_0 floordiv $0) mod $2) * $3)\n+)\",\n+          num_n_tiles, tile_n, num_m_tiles, tile_m)));\n+}\n+\n struct ScaleDotTestParams {\n   std::string lhs_type;\n   std::string rhs_type;"
        }
    ],
    "stats": {
        "total": 276,
        "additions": 272,
        "deletions": 4
    }
}