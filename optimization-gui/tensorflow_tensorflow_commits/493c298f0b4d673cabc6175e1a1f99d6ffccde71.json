{
    "author": "olegshyshkov",
    "message": "[XLA:GPU] Fix combine decomposition when replica groups are shuffled.\n\nWhen replica groups for for singe host are not contiguous, we need an extra step to reorder offsets and sizes metadata operands.\n\nhttps://github.com/openxla/xla/pull/35096 was a similar change for dispatch ragged-all-to-all.\n\nPiperOrigin-RevId: 843157263",
    "sha": "493c298f0b4d673cabc6175e1a1f99d6ffccde71",
    "files": [
        {
            "sha": "578470d6f18e74025ea0ea33928c75f70228bc9f",
            "filename": "third_party/xla/xla/service/gpu/transforms/ragged_all_to_all_multi_host_decomposer.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 29,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/493c298f0b4d673cabc6175e1a1f99d6ffccde71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/493c298f0b4d673cabc6175e1a1f99d6ffccde71/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fragged_all_to_all_multi_host_decomposer.cc?ref=493c298f0b4d673cabc6175e1a1f99d6ffccde71",
            "patch": "@@ -103,12 +103,13 @@ HloInstruction* ShuffleMetadataOperandValues(\n \n   HloComputation* computation = hlo->parent();\n \n-  const Shape& shape = hlo->shape();\n-  CHECK_EQ(shape.dimensions().size(), 1);\n-\n-  int64_t num_elements = shape.dimensions(0);\n+  PrimitiveType element_type = hlo->shape().element_type();\n+  int64_t num_elements = ShapeUtil::ElementsIn(hlo->shape());\n   int64_t num_replicas = permutation.size();\n   int64_t num_elements_per_replica = num_elements / permutation.size();\n+  Shape linear_shape = ShapeUtil::MakeShape(element_type, {num_elements});\n+  Shape gather_shape = ShapeUtil::MakeShape(\n+      element_type, {num_replicas, num_elements_per_replica});\n \n   Array<int64_t> permutation_array({num_replicas, 1});\n   for (int64_t i = 0; i < permutation.size(); ++i) {\n@@ -119,11 +120,11 @@ HloInstruction* ShuffleMetadataOperandValues(\n       computation->AddInstruction(HloInstruction::CreateConstant(\n           LiteralUtil::CreateFromArray(permutation_array)));\n \n-  Shape new_shape = ShapeUtil::MakeShape(\n-      shape.element_type(), {num_replicas, num_elements_per_replica});\n+  hlo = computation->AddInstruction(\n+      HloInstruction::CreateReshape(linear_shape, hlo));\n \n   hlo = computation->AddInstruction(\n-      HloInstruction::CreateGather(new_shape, hlo, permutation_constant,\n+      HloInstruction::CreateGather(gather_shape, hlo, permutation_constant,\n                                    HloGatherInstruction::MakeGatherDimNumbers(\n                                        /*offset_dims=*/{1},\n                                        /*collapsed_slice_dims=*/{},\n@@ -132,7 +133,8 @@ HloInstruction* ShuffleMetadataOperandValues(\n                                    /*slice_sizes=*/{num_elements_per_replica},\n                                    /*indices_are_sorted=*/false));\n \n-  return computation->AddInstruction(HloInstruction::CreateReshape(shape, hlo));\n+  return computation->AddInstruction(\n+      HloInstruction::CreateReshape(linear_shape, hlo));\n }\n \n // Corrects the offsets in the local metadata to account for the number of input\n@@ -337,8 +339,11 @@ absl::StatusOr<bool> DecomposeCombineRaggedAllToAll(\n     HloRaggedAllToAllInstruction* ragged_all_to_all,\n     HloComputation* computation,\n     absl::Span<ReplicaGroup const> inter_host_replica_groups,\n-    absl::Span<ReplicaGroup const> intra_host_replica_groups, int64_t num_hosts,\n+    absl::Span<ReplicaGroup const> intra_host_replica_groups,\n+    absl::Span<int64_t const> replica_groups_permutation, int64_t num_hosts,\n     int64_t num_devices_in_replica, int64_t num_participating_devices) {\n+  const Shape& metadata_operand_shape = ragged_all_to_all->operand(2)->shape();\n+\n   auto* zero = computation->AddInstruction(\n       HloInstruction::CreateConstant(LiteralUtil::Zero(\n           ragged_all_to_all->operand(1)->shape().element_type())));\n@@ -359,6 +364,9 @@ absl::StatusOr<bool> DecomposeCombineRaggedAllToAll(\n \n   auto get_intra_host_metadata = [&](HloInstruction* metadata_operand,\n                                      bool correct_offsets) {\n+    metadata_operand = ShuffleMetadataOperandValues(metadata_operand,\n+                                                    replica_groups_permutation);\n+\n     metadata_operand =\n         computation->AddInstruction(HloInstruction::CreateReshape(\n             /*shape=*/ShapeUtil::MakeShape(\n@@ -383,8 +391,7 @@ absl::StatusOr<bool> DecomposeCombineRaggedAllToAll(\n             /*dimensions=*/{1, 0, 2}));\n \n     return computation->AddInstruction(HloInstruction::CreateReshape(\n-        /*shape=*/ragged_all_to_all->operand(2)->shape(),\n-        /*operand=*/metadata_operand));\n+        /*shape=*/metadata_operand_shape, /*operand=*/metadata_operand));\n   };\n \n   absl::InlinedVector<HloInstruction*, 4> intra_host_ragged_all_to_all_operands{\n@@ -443,36 +450,40 @@ absl::StatusOr<bool> DecomposeCombineRaggedAllToAll(\n           : std::nullopt,\n       /*split_dimension=*/0));\n \n-  HloInstruction* corrected_output_offsets = output_offsets;\n+  output_offsets = computation->AddInstruction(HloInstruction::CreateReshape(\n+      /*shape=*/metadata_operand_shape, /*operand=*/output_offsets));\n+\n+  std::vector<HloInstruction*> local_ragged_all_to_all_operands = {\n+      local_inputs,   ragged_all_to_all->mutable_operand(1),\n+      output_offsets, ragged_all_to_all->mutable_operand(5),\n+      output_offsets, ragged_all_to_all->mutable_operand(5),\n+  };\n+\n+  for (int i = 2; i < 6; ++i) {\n+    local_ragged_all_to_all_operands[i] = ShuffleMetadataOperandValues(\n+        local_ragged_all_to_all_operands[i], replica_groups_permutation);\n+  }\n \n-  corrected_output_offsets =\n+  HloInstruction* local_input_offsets =\n       computation->AddInstruction(HloInstruction::CreateReshape(\n           /*shape=*/ShapeUtil::MakeShape(\n               output_offsets->shape().element_type(),\n               {num_hosts, num_devices_in_replica_per_host,\n                num_updates_per_replica}),\n-          /*operand=*/corrected_output_offsets));\n+          /*operand=*/local_ragged_all_to_all_operands[2]));\n \n-  corrected_output_offsets =\n+  local_input_offsets =\n       CorrectOffsets(ragged_all_to_all->operand(1)->shape().dimensions(0),\n-                     corrected_output_offsets, computation);\n+                     local_input_offsets, computation);\n \n-  output_offsets = computation->AddInstruction(HloInstruction::CreateReshape(\n-      /*shape=*/ragged_all_to_all->operand(2)->shape(),\n-      /*operand=*/output_offsets));\n-\n-  corrected_output_offsets =\n+  local_ragged_all_to_all_operands[2] =\n       computation->AddInstruction(HloInstruction::CreateReshape(\n-          /*shape=*/ragged_all_to_all->operand(2)->shape(),\n-          /*operand=*/corrected_output_offsets));\n+          /*shape=*/metadata_operand_shape, /*operand=*/local_input_offsets));\n \n   HloInstruction* local_ragged_all_to_all =\n       computation->AddInstruction(HloInstruction::CreateRaggedAllToAll(\n           /*shape=*/ragged_all_to_all->shape(),\n-          /*operands=*/\n-          {local_inputs, ragged_all_to_all->mutable_operand(1),\n-           corrected_output_offsets, ragged_all_to_all->mutable_operand(5),\n-           output_offsets, ragged_all_to_all->mutable_operand(5)},\n+          /*operands=*/local_ragged_all_to_all_operands,\n           /*device_list=*/CollectiveDeviceList(degenerated_replica_groups),\n           /*channel_id=*/ragged_all_to_all->channel_id()));\n \n@@ -590,8 +601,8 @@ absl::StatusOr<bool> DecomposeRaggedAllToAll(\n   if (num_input_rows > num_output_rows) {\n     return DecomposeCombineRaggedAllToAll(\n         ragged_all_to_all, computation, inter_host_replica_groups,\n-        intra_host_replica_groups, num_hosts, num_devices_in_replica,\n-        num_participating_devices);\n+        intra_host_replica_groups, *replica_groups_permutation, num_hosts,\n+        num_devices_in_replica, num_participating_devices);\n   }\n \n   return DecomposeDispatchRaggedAllToAll("
        },
        {
            "sha": "257d2b9c2625b28ae5dc56ad2f182e8a7d0802bf",
            "filename": "third_party/xla/xla/tests/ragged_all_to_all_e2e_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/493c298f0b4d673cabc6175e1a1f99d6ffccde71/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/493c298f0b4d673cabc6175e1a1f99d6ffccde71/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fragged_all_to_all_e2e_test.cc?ref=493c298f0b4d673cabc6175e1a1f99d6ffccde71",
            "patch": "@@ -935,13 +935,6 @@ TEST_P(RaggedAllToAllMultiHostDecomposerTest,\n        RaggedAllToAll_8GPUs_SliceSize4_ShuffledReplicaGroups) {\n   auto [num_input_rows, num_output_rows] = GetParam();\n \n-  if (num_input_rows > num_output_rows) {\n-    // TODO(b/445380264): Fix decomposer for combine ragged-all-to-all.\n-    GTEST_SKIP()\n-        << \"The test will currently fail for combine ragged-all-to-all (when \"\n-           \"input is larger than output).\";\n-  }\n-\n   std::string kModuleReplicatedStr =\n       absl::Substitute(R\"(\n   HloModule module"
        }
    ],
    "stats": {
        "total": 76,
        "additions": 40,
        "deletions": 36
    }
}