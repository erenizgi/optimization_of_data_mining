{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 812275244",
    "sha": "d2fad649a5493d124f47369c779a75044123764b",
    "files": [
        {
            "sha": "d5bd6d9a3c63295411e270e7fdd6d1607c530892",
            "filename": "third_party/xla/xla/hlo/ir/backend_config.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.cc?ref=d2fad649a5493d124f47369c779a75044123764b",
            "patch": "@@ -61,7 +61,7 @@ absl::Status BackendConfigWrapper::GetProto(\n     tsl::protobuf::Message* output_proto) const {\n   output_proto->Clear();\n \n-  absl::WriterMutexLock lock{&mutex_};\n+  absl::WriterMutexLock lock{mutex_};\n   if (proto_ != nullptr) {\n     if (proto_->GetDescriptor() != output_proto->GetDescriptor()) {\n       return Internal(\"Mismatched backend config descriptors.\");\n@@ -88,12 +88,12 @@ BackendConfigWrapper& BackendConfigWrapper::operator=(\n \n   // Do not hold two mutexes at the same time to avoid deadlocks.\n   {\n-    absl::MutexLock other_lock{&other.mutex_};\n+    absl::MutexLock other_lock{other.mutex_};\n     temp_proto = std::move(other.proto_);\n     temp_string = std::move(other.raw_string_);\n   }\n \n-  absl::MutexLock this_lock{&mutex_};\n+  absl::MutexLock this_lock{mutex_};\n \n   proto_ = std::move(temp_proto);\n   raw_string_ = std::move(temp_string);\n@@ -105,13 +105,13 @@ bool BackendConfigWrapper::operator==(const BackendConfigWrapper& other) const {\n \n   // Do not hold two mutexes at the same time to avoid deadlocks.\n   {\n-    absl::MutexLock this_lock{&mutex_};\n+    absl::MutexLock this_lock{mutex_};\n     this_proto = proto_.get();\n   }\n \n   const std::string* other_raw_string = nullptr;\n   {\n-    absl::MutexLock other_lock{&other.mutex_};\n+    absl::MutexLock other_lock{other.mutex_};\n     if (this_proto != nullptr && other.proto_ != nullptr) {\n       using ::tsl::protobuf::util::MessageDifferencer;\n       return MessageDifferencer::Equals(*this_proto, *other.proto_);"
        },
        {
            "sha": "436df938f6f79a78518e11ba0944b1f7af8217cd",
            "filename": "third_party/xla/xla/hlo/ir/backend_config.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fbackend_config.h?ref=d2fad649a5493d124f47369c779a75044123764b",
            "patch": "@@ -65,7 +65,7 @@ class BackendConfigWrapper {\n   explicit BackendConfigWrapper(const tsl::protobuf::Message& proto)\n       : proto_(CloneBackendConfigProto(&proto)) {}\n   BackendConfigWrapper(const BackendConfigWrapper& other) {\n-    absl::MutexLock other_lock{&other.mutex_};\n+    absl::MutexLock other_lock{other.mutex_};\n     proto_ = CloneBackendConfigProto(other.proto_.get());\n     raw_string_ = other.raw_string_;\n   }\n@@ -87,13 +87,13 @@ class BackendConfigWrapper {\n   //\n   //          Prefer to use the safer (but potentially slower) GetProto().\n   const std::string& GetRawString() const {\n-    absl::WriterMutexLock lock{&mutex_};\n+    absl::WriterMutexLock lock{mutex_};\n     return GetRawStringWithoutMutex();\n   }\n   absl::Status GetProto(tsl::protobuf::Message* output_proto) const;\n \n   bool empty() const {\n-    absl::MutexLock lock{&mutex_};\n+    absl::MutexLock lock{mutex_};\n     return proto_ == nullptr && raw_string_.empty();\n   }\n "
        },
        {
            "sha": "276f82c35fe56785c55c7759e19cd24b872a4975",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instructions.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h?ref=d2fad649a5493d124f47369c779a75044123764b",
            "patch": "@@ -2239,7 +2239,7 @@ class HloCustomCallInstruction : public HloCallableInstruction {\n \n   void SetPerInstructionStorage(\n       std::unique_ptr<PerInstructionStorage> per_instruction_storage) {\n-    absl::MutexLock lock(&per_instruction_storage_mutex_);\n+    absl::MutexLock lock(per_instruction_storage_mutex_);\n     if (per_instruction_storage_ != nullptr) {\n       LOG(WARNING) << \"Not Overwriting existing per-instruction storage.\";\n       return;"
        },
        {
            "sha": "5f761b561744cfc8d200cc4277031ca9d3daa1a2",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=d2fad649a5493d124f47369c779a75044123764b",
            "patch": "@@ -1448,7 +1448,7 @@ HloComputation* HloModule::DeepCloneComputation(HloComputation* computation,\n }\n \n uint64_t HloModule::RandomNew64() const {\n-  absl::MutexLock l(&rng_mutex_);\n+  absl::MutexLock l(rng_mutex_);\n   return rng_();\n }\n "
        },
        {
            "sha": "ba2a9d463e9762358ef7034d0cb07d4ea30e1ae5",
            "filename": "third_party/xla/xla/hlo/ir/tile_assignment.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Ftile_assignment.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d2fad649a5493d124f47369c779a75044123764b/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Ftile_assignment.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Ftile_assignment.cc?ref=d2fad649a5493d124f47369c779a75044123764b",
            "patch": "@@ -476,13 +476,13 @@ int64_t IotaTileAssignment::value_at(absl::Span<const int64_t> index) const {\n \n TileAssignment::TileAssignment(const TileAssignment& other) {\n   iota_ = other.iota_;\n-  absl::MutexLock other_lock(&other.mu_);\n+  absl::MutexLock other_lock(other.mu_);\n   shared_array_ = other.shared_array_;\n   array_ = other.array_;\n }\n \n TileAssignment::TileAssignment(TileAssignment&& other) {\n-  absl::MutexLock other_lock(&other.mu_);\n+  absl::MutexLock other_lock(other.mu_);\n   iota_ = other.iota_;\n   shared_array_ = std::move(other.shared_array_);\n   array_ = other.array_;\n@@ -493,11 +493,11 @@ TileAssignment& TileAssignment::operator=(const TileAssignment& other) {\n   std::shared_ptr<const Array<int64_t>> shared_array;\n   const Array<int64_t>* array;\n   {\n-    absl::MutexLock other_lock(&other.mu_);\n+    absl::MutexLock other_lock(other.mu_);\n     shared_array = other.shared_array_;\n     array = other.array_;\n   }\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   shared_array_ = shared_array;\n   array_ = array;\n   return *this;\n@@ -508,11 +508,11 @@ TileAssignment& TileAssignment::operator=(TileAssignment&& other) {\n   std::shared_ptr<const Array<int64_t>> shared_array;\n   const Array<int64_t>* array;\n   {\n-    absl::MutexLock other_lock(&other.mu_);\n+    absl::MutexLock other_lock(other.mu_);\n     shared_array = std::move(other.shared_array_);\n     array = other.array_;\n   }\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   shared_array_ = shared_array;\n   array_ = array;\n   return *this;\n@@ -526,39 +526,39 @@ bool TileAssignment::operator==(const TileAssignment& other) const {\n }\n \n int64_t TileAssignment::operator()(absl::Span<const int64_t> indexes) const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? (*array_)(indexes) : iota_->value_at(indexes);\n }\n \n absl::Span<const int64_t> TileAssignment::dimensions() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? array_->dimensions() : iota_->dims();\n }\n \n int64_t TileAssignment::num_dimensions() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? array_->num_dimensions() : iota_->ndims();\n }\n \n int64_t TileAssignment::dim(int64_t n) const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? array_->dim(n) : iota_->dim(n);\n }\n int64_t TileAssignment::num_elements() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? array_->num_elements() : iota_->num_elements();\n }\n \n int64_t TileAssignment::first() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   return array_ ? *array_->begin() : 0;\n }\n \n void TileAssignment::Each(\n     absl::FunctionRef<void(absl::Span<const int64_t>, int64_t)> f) const {\n   Array<int64_t> const* array;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     MaybeMaterializeFullArray();\n     array = array_;\n   }\n@@ -570,7 +570,7 @@ absl::Status TileAssignment::EachStatus(\n     const {\n   Array<int64_t> const* array;\n   {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     MaybeMaterializeFullArray();\n     array = array_;\n   }\n@@ -632,18 +632,18 @@ bool TileAssignment::UsesDevice(int64_t device) const {\n }\n \n const Array<int64_t>& TileAssignment::array() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   MaybeMaterializeFullArray();\n   return *array_;\n }\n std::shared_ptr<const Array<int64_t>> TileAssignment::shared_array() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   MaybeMaterializeFullArray();\n   return shared_array_;\n }\n \n std::shared_ptr<Array<int64_t>> TileAssignment::shared_array_clone() const {\n-  absl::MutexLock lock(&mu_);\n+  absl::MutexLock lock(mu_);\n   MaybeMaterializeFullArray();\n   return std::make_shared<Array<int64_t>>(*array_);\n }"
        }
    ],
    "stats": {
        "total": 54,
        "additions": 27,
        "deletions": 27
    }
}