{
    "author": "akuegel",
    "message": "[XLA:GPU] Reuse MLIRContext from GpuCompiler for FusionBlockLevelRewriter.\n\nInitializing MLIRContext is very costly, so we should reuse it where possible.\n\nPiperOrigin-RevId: 811702379",
    "sha": "44d21ba3700c82fc905f644a11377b212e04cfdd",
    "files": [
        {
            "sha": "a1a3a37739ff5bd5a8384ef35da542f91b4b0a71",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -1361,6 +1361,7 @@ cc_library(\n         \"//xla/service/gpu/transforms:fusion_block_level_rewriter\",\n         \"//xla/service/gpu/transforms:fusion_dynamic_memcpy_rewriter\",\n         \"//xla/stream_executor:device_description\",\n+        \"@llvm-project//mlir:IR\",\n     ],\n )\n "
        },
        {
            "sha": "a8b83730b145a9edd7c6a793ce77cbffbecb29b6",
            "filename": "third_party/xla/xla/service/gpu/fusion_dispatch_pipeline.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.cc?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/service/gpu/fusion_dispatch_pipeline.h\"\n \n+#include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n #include \"xla/hlo/transforms/simplifiers/hlo_dce.h\"\n #include \"xla/service/gpu/transforms/fusion_block_level_rewriter.h\"\n@@ -28,10 +29,12 @@ namespace gpu {\n \n HloPassPipeline FusionDispatchPipeline(\n     const se::DeviceDescription& device_description,\n-    HloCostAnalysis::ShapeSizeFunction shape_size_fn) {\n+    HloCostAnalysis::ShapeSizeFunction shape_size_fn,\n+    mlir::MLIRContext* mlir_context) {\n   HloPassPipeline pipeline(\"fusion-dispatch-pipeline\");\n   pipeline.AddPass<HloDCE>();\n-  pipeline.AddPass<FusionBlockLevelRewriter>(device_description, shape_size_fn);\n+  pipeline.AddPass<FusionBlockLevelRewriter>(device_description, shape_size_fn,\n+                                             mlir_context);\n   pipeline.AddPass<FusionDynamicMemcpyRewriter>();\n   return pipeline;\n }"
        },
        {
            "sha": "2fae2a309bf1ace674b2e40d1d8e7deca9180df5",
            "filename": "third_party/xla/xla/service/gpu/fusion_dispatch_pipeline.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ffusion_dispatch_pipeline.h?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #ifndef XLA_SERVICE_GPU_FUSION_DISPATCH_PIPELINE_H_\n #define XLA_SERVICE_GPU_FUSION_DISPATCH_PIPELINE_H_\n \n+#include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n #include \"xla/stream_executor/device_description.h\"\n@@ -28,7 +29,8 @@ namespace gpu {\n // emitter possible.\n HloPassPipeline FusionDispatchPipeline(\n     const se::DeviceDescription& device_description,\n-    HloCostAnalysis::ShapeSizeFunction shape_size_fn);\n+    HloCostAnalysis::ShapeSizeFunction shape_size_fn,\n+    mlir::MLIRContext* mlir_context);\n \n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "cbae5c6b1fa0796a4b01c23d0494db07ceee3a80",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -2892,7 +2892,7 @@ HloRematerialization::Options CreateRematOpts(\n absl::Status GpuCompiler::RunPostSchedulingPipelines(\n     HloModule* module, int64_t scheduler_mem_limit,\n     const se::DeviceDescription& gpu_device_info,\n-    const GpuAliasInfo* alias_info) const {\n+    const GpuAliasInfo* alias_info) {\n   tsl::profiler::TraceMe traceme(\"RunPostSchedulingPipelines\");\n   TF_RETURN_IF_ERROR(RunPostSchedulingCopyInsertion(module, alias_info));\n   HloPassPipeline main_pipeline(\"post-scheduling-passes\");\n@@ -2946,8 +2946,8 @@ absl::Status GpuCompiler::RunPostSchedulingPipelines(\n   if (cuda_cc != nullptr && cuda_cc->IsAtLeastAmpere()) {\n     // This needs to run after every pass affecting fusions. The last passes\n     // that create new fusions are FusionWrapper and StreamAttributeAnnotator.\n-    main_pipeline.AddPass<HloPassPipeline>(\n-        FusionDispatchPipeline(gpu_device_info, ShapeSizeBytesFunction()));\n+    main_pipeline.AddPass<HloPassPipeline>(FusionDispatchPipeline(\n+        gpu_device_info, ShapeSizeBytesFunction(), mlir_context()));\n   }\n \n   // Pipeline with passes which wrap a scheduled module into command buffers."
        },
        {
            "sha": "6418057d6c5417e9f1b59a5276022a706127bc17",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.h?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -97,7 +97,7 @@ class GpuCompiler : public LLVMCompiler {\n   absl::Status RunPostSchedulingPipelines(\n       HloModule* module, int64_t scheduler_mem_limit,\n       const se::DeviceDescription& gpu_device_info,\n-      const GpuAliasInfo* alias_info) const;\n+      const GpuAliasInfo* alias_info);\n \n   std::string target_triple() const { return target_triple_; }\n   std::string data_layout() const { return data_layout_; }"
        },
        {
            "sha": "0d41d95b66dedb87dda23a5b296867425ca89055",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_block_level_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.cc?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -243,7 +243,6 @@ absl::StatusOr<bool> FusionBlockLevelRewriter::Run(\n   TF_RETURN_IF_ERROR(EnsureTritonSupportsComputeCapability(\n       device_info_.gpu_compute_capability()));\n \n-  MLIRContext ctx;\n   bool has_changed = false;\n \n   for (HloComputation* computation :\n@@ -255,7 +254,7 @@ absl::StatusOr<bool> FusionBlockLevelRewriter::Run(\n         ::xla::Cast<HloFusionInstruction>(computation->FusionInstruction());\n     TF_ASSIGN_OR_RETURN(\n         bool changed, ProcessFusionInstruction(fusion_instruction, device_info_,\n-                                               shape_size_, &ctx));\n+                                               shape_size_, mlir_context_));\n \n     has_changed |= changed;\n   }"
        },
        {
            "sha": "9d4320e69fd3a099bc64dc7e755649e4312c3903",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_block_level_rewriter.h",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter.h?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -19,6 +19,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/pass/hlo_pass_interface.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n@@ -31,8 +32,11 @@ class FusionBlockLevelRewriter : public HloModulePass {\n  public:\n   explicit FusionBlockLevelRewriter(\n       const se::DeviceDescription& device_info,\n-      HloCostAnalysis::ShapeSizeFunction shape_size)\n-      : device_info_(device_info), shape_size_(shape_size) {}\n+      HloCostAnalysis::ShapeSizeFunction shape_size,\n+      mlir::MLIRContext* mlir_context)\n+      : device_info_(device_info),\n+        shape_size_(shape_size),\n+        mlir_context_(mlir_context) {}\n \n   absl::string_view name() const override {\n     return \"fusion-block-level-rewriter\";\n@@ -46,6 +50,7 @@ class FusionBlockLevelRewriter : public HloModulePass {\n  private:\n   const se::DeviceDescription& device_info_;\n   HloCostAnalysis::ShapeSizeFunction shape_size_;\n+  mlir::MLIRContext* mlir_context_;\n };\n \n }  // namespace gpu"
        },
        {
            "sha": "38afffa3503525f5b33e2e56e46cd06384b48cc1",
            "filename": "third_party/xla/xla/service/gpu/transforms/fusion_block_level_rewriter_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 7,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44d21ba3700c82fc905f644a11377b212e04cfdd/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ffusion_block_level_rewriter_test.cc?ref=44d21ba3700c82fc905f644a11377b212e04cfdd",
            "patch": "@@ -68,6 +68,7 @@ class FusionBlockLevelRewriterTest : public HloHardwareIndependentTestBase {\n         true);\n     return debug_options;\n   }\n+  mlir::MLIRContext mlir_context_;\n };\n \n TEST_F(FusionBlockLevelRewriterTest,\n@@ -87,7 +88,8 @@ ENTRY entry {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n   EXPECT_THAT(\n-      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize)\n+      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize,\n+                               &mlir_context_)\n           .Run(module.get()),\n       absl_testing::IsOkAndHolds(false));\n }\n@@ -108,7 +110,8 @@ ENTRY entry {\n                           ParseAndReturnVerifiedModule(hlo_text));\n \n   EXPECT_THAT(\n-      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize)\n+      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize,\n+                               &mlir_context_)\n           .Run(module.get()),\n       absl_testing::IsOkAndHolds(true));\n   const HloInstruction* root = module->entry_computation()->root_instruction();\n@@ -138,7 +141,8 @@ ENTRY entry {\n       SymbolicTileAnalysis::AnalyzeComputation(\n           *module->GetComputationWithName(\"fusion_computation\"), &ctx)));\n   EXPECT_THAT(\n-      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize)\n+      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize,\n+                               &mlir_context_)\n           .Run(module.get()),\n       absl_testing::IsOkAndHolds(false));\n }\n@@ -162,12 +166,13 @@ ENTRY entry {\n       *module->GetComputationWithName(\"fusion_computation\"),\n       device_info_.gpu_compute_capability()));\n   EXPECT_THAT(\n-      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize)\n+      FusionBlockLevelRewriter(device_info_, HloCostAnalysis::DefaultShapeSize,\n+                               &mlir_context_)\n           .Run(module.get()),\n       absl_testing::IsOkAndHolds(false));\n }\n \n-TEST_F(HloHardwareIndependentTestBase, RewritesS32ReductionFusions) {\n+TEST_F(FusionBlockLevelRewriterTest, RewritesS32ReductionFusions) {\n   constexpr absl::string_view kHloText = R\"(\n \n %scalar_add_computation {\n@@ -197,8 +202,8 @@ ENTRY entry  {\n                           ParseAndReturnVerifiedModule(kHloText));\n   se::DeviceDescription device_info{TestGpuDeviceInfo::RTXA6000DeviceInfo(\n       se::CudaComputeCapability::Ampere())};\n-  FusionBlockLevelRewriter rewriter(device_info,\n-                                    HloCostAnalysis::DefaultShapeSize);\n+  FusionBlockLevelRewriter rewriter(\n+      device_info, HloCostAnalysis::DefaultShapeSize, &mlir_context_);\n   EXPECT_THAT(rewriter.Run(module.get()), absl_testing::IsOkAndHolds(true));\n   const HloInstruction* root = module->entry_computation()->root_instruction();\n   EXPECT_EQ(root->opcode(), HloOpcode::kFusion);"
        }
    ],
    "stats": {
        "total": 51,
        "additions": 33,
        "deletions": 18
    }
}