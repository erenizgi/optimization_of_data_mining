{
    "author": "ezhulenev",
    "message": "[xla:cpu] NFC: Rename protos for Xnn/Ynn fusion options\n\nPiperOrigin-RevId: 826304955",
    "sha": "56d3b1928078b98a3a9030535504020689b4725b",
    "files": [
        {
            "sha": "a2a4b1275e8f1e15b24adc098ed7213678e825e2",
            "filename": "third_party/xla/xla/backends/cpu/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -111,8 +111,8 @@ onednn_graph_cc_library(\n )\n \n tf_proto_library(\n-    name = \"xnnpack_config_proto\",\n-    srcs = [\"xnnpack_config.proto\"],\n+    name = \"xnn_fusion_options_proto\",\n+    srcs = [\"xnn_fusion_options.proto\"],\n )\n \n cc_library(\n@@ -219,6 +219,11 @@ xla_cc_test(\n     ],\n )\n \n+tf_proto_library(\n+    name = \"ynn_fusion_options_proto\",\n+    srcs = [\"ynn_fusion_options.proto\"],\n+)\n+\n cc_library(\n     name = \"ynn_support\",\n     srcs = [\"ynn_support.cc\"],"
        },
        {
            "sha": "3788b401dc22ff2db2902ee8046babaa86f58eda",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2FBUILD?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -91,8 +91,8 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla/backends/autotuner:codegen_backend\",\n+        \"//xla/backends/cpu:xnn_fusion_options_proto_cc\",\n         \"//xla/backends/cpu:xnn_support\",\n-        \"//xla/backends/cpu:xnnpack_config_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:compiler\",\n         \"//xla/service/cpu:backend_config_proto_cc\","
        },
        {
            "sha": "765a50a887cd54129e01a3ac9f4ede3cfd66aeed",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/xnnpack_backend.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.cc?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -23,8 +23,8 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n+#include \"xla/backends/cpu/xnn_fusion_options.pb.h\"\n #include \"xla/backends/cpu/xnn_support.h\"\n-#include \"xla/backends/cpu/xnnpack_config.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/compiler.h\"\n@@ -78,26 +78,26 @@ XnnpackBackend::GetSupportedConfigs(const HloInstruction& instr) {\n   TF_RETURN_IF_ERROR(CheckIfXnnFusion(instr));\n   std::vector<std::unique_ptr<xla::BackendConfig>> configs;\n   {\n-    Config config;\n-    config.set_use_threadpool(true);\n+    XnnFusionOptions options;\n+    options.set_use_threadpool(true);\n     auto any = std::make_unique<xla::BackendConfig>();\n-    any->PackFrom(config);\n+    any->PackFrom(options);\n     configs.push_back(std::move(any));\n   }\n \n   {\n-    Config config;\n-    config.set_use_threadpool(false);\n+    XnnFusionOptions options;\n+    options.set_use_threadpool(false);\n     auto any = std::make_unique<xla::BackendConfig>();\n-    any->PackFrom(config);\n+    any->PackFrom(options);\n     configs.push_back(std::move(any));\n   }\n   return configs;\n }\n absl::StatusOr<std::unique_ptr<xla::BackendConfig>>\n XnnpackBackend::GetDefaultConfig(const HloInstruction& instr) {\n   TF_RETURN_IF_ERROR(CheckIfXnnFusion(instr));\n-  auto config = std::make_unique<Config>();\n+  auto config = std::make_unique<XnnFusionOptions>();\n   config->set_use_threadpool(true);\n   auto any = std::make_unique<xla::BackendConfig>();\n   any->PackFrom(*config);\n@@ -110,11 +110,11 @@ absl::Status XnnpackBackend::ApplyConfig(HloInstruction& instr,\n   TF_ASSIGN_OR_RETURN(auto backend_config,\n                       instr.backend_config<xla::cpu::BackendConfig>());\n \n-  XnnpackBackend::Config xnn_config;\n-  config.UnpackTo(&xnn_config);\n+  XnnFusionOptions options;\n+  config.UnpackTo(&options);\n \n-  *backend_config.mutable_fusion_config()->mutable_xnn_fusion_config() =\n-      xnn_config;\n+  *backend_config.mutable_fusion_config()->mutable_xnn_fusion_options() =\n+      options;\n \n   TF_RETURN_IF_ERROR(instr.set_backend_config(backend_config));\n "
        },
        {
            "sha": "71b8b8c86d8011a53c12efd1d777cb3f897881b8",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/xnnpack_backend.h",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend.h?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -24,7 +24,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/autotuner/codegen_backend.h\"\n #include \"xla/backends/cpu/autotuner/cpu_codegen_backend.h\"\n-#include \"xla/backends/cpu/xnnpack_config.pb.h\"\n+#include \"xla/backends/cpu/xnn_fusion_options.pb.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/compiler.h\"\n \n@@ -37,8 +37,6 @@ class XnnpackBackend : public CpuCodegenBackend {\n   static absl::StatusOr<std::unique_ptr<CodegenBackend>> Create(\n       Compiler* compiler);\n \n-  using Config = XnnFusionBackendConfig;\n-\n   bool IsSupported(const HloInstruction& instr);\n \n   absl::StatusOr<std::vector<std::unique_ptr<xla::BackendConfig>>>"
        },
        {
            "sha": "ef9af614bc694a08fd43642d41a476980c458aae",
            "filename": "third_party/xla/xla/backends/cpu/autotuner/xnnpack_backend_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fautotuner%2Fxnnpack_backend_test.cc?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -77,10 +77,10 @@ TEST_F(XnnpackBackendTest, GetDefaultConfigTest) {\n   TF_ASSERT_OK_AND_ASSIGN(\n       auto config, backend_->GetDefaultConfig(\n                        *module->entry_computation()->root_instruction()));\n-  XnnFusionBackendConfig xnnpack_config;\n-  config->UnpackTo(&xnnpack_config);\n+  XnnFusionOptions xnn_fusion_options;\n+  config->UnpackTo(&xnn_fusion_options);\n \n-  EXPECT_TRUE(xnnpack_config.use_threadpool());\n+  EXPECT_TRUE(xnn_fusion_options.use_threadpool());\n }\n \n TEST_F(XnnpackBackendTest, InvalidFusionKind) {\n@@ -123,12 +123,12 @@ TEST_F(XnnpackBackendTest, GetSupportedConfigsTest) {\n                         *module->entry_computation()->root_instruction()));\n \n   EXPECT_EQ(configs.size(), 2);\n-  XnnFusionBackendConfig xnnpack_config0;\n-  configs[0]->UnpackTo(&xnnpack_config0);\n-  EXPECT_TRUE(xnnpack_config0.use_threadpool());\n-  XnnFusionBackendConfig xnnpack_config1;\n-  configs[1]->UnpackTo(&xnnpack_config1);\n-  EXPECT_FALSE(xnnpack_config1.use_threadpool());\n+  XnnFusionOptions xnn_fusion_options0;\n+  configs[0]->UnpackTo(&xnn_fusion_options0);\n+  EXPECT_TRUE(xnn_fusion_options0.use_threadpool());\n+  XnnFusionOptions xnn_fusion_options1;\n+  configs[1]->UnpackTo(&xnn_fusion_options1);\n+  EXPECT_FALSE(xnn_fusion_options1.use_threadpool());\n }\n \n TEST_F(XnnpackBackendTest, CompileSupportedBackends) {\n@@ -153,18 +153,18 @@ TEST_F(XnnpackBackendTest, EnsureConfigIsApplied) {\n                           backend_->GetSupportedConfigs(*fusion_instruction));\n \n   for (const auto& config : configs) {\n-    XnnFusionBackendConfig xnnpack_config;\n-    config->UnpackTo(&xnnpack_config);\n+    XnnFusionOptions xnn_fusion_options;\n+    config->UnpackTo(&xnn_fusion_options);\n     EXPECT_TRUE(backend_->ApplyConfig(*fusion_instruction, *config).ok());\n \n     TF_ASSERT_OK_AND_ASSIGN(\n         auto instruction_backend_config,\n         fusion_instruction->backend_config<BackendConfig>());\n \n     EXPECT_EQ(instruction_backend_config.fusion_config()\n-                  .xnn_fusion_config()\n+                  .xnn_fusion_options()\n                   .use_threadpool(),\n-              xnnpack_config.use_threadpool());\n+              xnn_fusion_options.use_threadpool());\n   }\n }\n "
        },
        {
            "sha": "6f103e8060f1f364ba02f0ca80ebb7e3095841fb",
            "filename": "third_party/xla/xla/backends/cpu/runtime/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2FBUILD?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -148,7 +148,8 @@ tf_proto_library(\n     create_grpc_library = True,\n     make_default_target_header_only = True,\n     protodeps = [\n-        \"//xla/backends/cpu:xnnpack_config_proto\",\n+        \"//xla/backends/cpu:xnn_fusion_options_proto\",\n+        \"//xla/backends/cpu:ynn_fusion_options_proto\",\n         \"//xla/service:buffer_assignment_proto\",\n         \"//xla:xla_data_proto\",\n         \"//xla/service:hlo_proto\",\n@@ -1197,7 +1198,8 @@ cc_library(\n         \":while_thunk\",\n         \"//xla:shape_util\",\n         \"//xla:util\",\n-        \"//xla/backends/cpu:xnnpack_config_proto_cc\",\n+        \"//xla/backends/cpu:xnn_fusion_options_proto_cc\",\n+        \"//xla/backends/cpu:ynn_fusion_options_proto_cc\",\n         \"//xla/backends/cpu/runtime/xnnpack:xnn_convolution_thunk\",\n         \"//xla/backends/cpu/runtime/xnnpack:xnn_dot_thunk\",\n         \"//xla/backends/cpu/runtime/xnnpack:xnn_fusion_thunk\",\n@@ -1216,7 +1218,9 @@ cc_library(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@local_tsl//tsl/platform:casts\",\n-    ],\n+    ] + if_ynnpack([\n+        \"//xla/backends/cpu/runtime/ynnpack:ynn_fusion_thunk\",\n+    ]),\n )\n \n cc_library("
        },
        {
            "sha": "2a1342211f0d7b9cc3364b03e7cb4bf03e4498af",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk.proto?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -17,7 +17,8 @@ syntax = \"proto3\";\n \n package xla.cpu;\n \n-import \"xla/backends/cpu/xnnpack_config.proto\";\n+import \"xla/backends/cpu/xnn_fusion_options.proto\";\n+import \"xla/backends/cpu/ynn_fusion_options.proto\";\n import \"xla/service/buffer_assignment.proto\";\n import \"xla/service/hlo.proto\";\n import \"xla/xla_data.proto\";\n@@ -169,7 +170,7 @@ message XnnFusionThunkProtoImpl {\n }\n \n message XnnFusionThunkProto {\n-  XnnFusionBackendConfig options = 1;\n+  XnnFusionOptions options = 1;\n \n   oneof impl {\n     XnnDotThunkProto xnn_dot_thunk = 2;\n@@ -178,6 +179,10 @@ message XnnFusionThunkProto {\n   }\n }\n \n+message YnnFusionThunkProto {\n+  YnnFusionOptions options = 1;\n+}\n+\n message DotThunkProto {\n   DotDimensionNumbers dot_dimensions = 1;\n   ShapeBufferAllocationSliceProto lhs_buffer_shape = 2;"
        },
        {
            "sha": "e60e29f7abfa5d12f9e2ea2ed5cef2bc2172bb6f",
            "filename": "third_party/xla/xla/backends/cpu/runtime/thunk_proto_serdes.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fthunk_proto_serdes.cc?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -61,7 +61,8 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/xnnpack/xnn_convolution_thunk.h\"\n #include \"xla/backends/cpu/runtime/xnnpack/xnn_dot_thunk.h\"\n #include \"xla/backends/cpu/runtime/xnnpack/xnn_fusion_thunk.h\"\n-#include \"xla/backends/cpu/xnnpack_config.pb.h\"\n+#include \"xla/backends/cpu/xnn_fusion_options.pb.h\"\n+#include \"xla/backends/cpu/ynn_fusion_options.pb.h\"\n #include \"xla/runtime/resource_use.h\"\n #include \"xla/runtime/work_group.h\"\n #include \"xla/service/buffer_assignment.h\""
        },
        {
            "sha": "56a5cfbf29992f702d65e2e8afc9389394fddfab",
            "filename": "third_party/xla/xla/backends/cpu/xnn_fusion_options.proto",
            "status": "renamed",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_fusion_options.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_fusion_options.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_fusion_options.proto?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -2,6 +2,6 @@ syntax = \"proto3\";\n \n package xla.cpu;\n \n-message XnnFusionBackendConfig {\n+message XnnFusionOptions {\n   bool use_threadpool = 1;\n }",
            "previous_filename": "third_party/xla/xla/backends/cpu/xnnpack_config.proto"
        },
        {
            "sha": "c5d826bda4bdbbde3196a1d1a433328a55e9ec46",
            "filename": "third_party/xla/xla/backends/cpu/xnn_gemm_config.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fxnn_gemm_config.h?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -16,9 +16,10 @@ limitations under the License.\n #ifndef XLA_BACKENDS_CPU_XNN_GEMM_CONFIG_H_\n #define XLA_BACKENDS_CPU_XNN_GEMM_CONFIG_H_\n \n+#include <functional>\n+\n #include \"xla/backends/cpu/codegen/target_machine_features.h\"\n #include \"xla/backends/cpu/runtime/dot_lib.h\"\n-#include \"xla/primitive_util.h\"\n #include \"xla/xla_data.pb.h\"\n \n namespace xla::cpu {"
        },
        {
            "sha": "5b4ed7e6c901b3109507323420821eda3f1e0ee7",
            "filename": "third_party/xla/xla/backends/cpu/ynn_fusion_options.proto",
            "status": "added",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_fusion_options.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_fusion_options.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_fusion_options.proto?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -0,0 +1,7 @@\n+syntax = \"proto3\";\n+\n+package xla.cpu;\n+\n+message YnnFusionOptions {\n+  bool use_threadpool = 1;\n+}"
        },
        {
            "sha": "91497026b0b059d0f6263253f2b0384fc4af4582",
            "filename": "third_party/xla/xla/service/cpu/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2FBUILD?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -1690,7 +1690,8 @@ tf_proto_library(\n     srcs = [\"backend_config.proto\"],\n     protodeps = [\n         \":onednn_config_proto\",\n-        \"//xla/backends/cpu:xnnpack_config_proto\",\n+        \"//xla/backends/cpu:xnn_fusion_options_proto\",\n+        \"//xla/backends/cpu:ynn_fusion_options_proto\",\n     ],\n )\n "
        },
        {
            "sha": "3da0ca6b17a641ae0f38dbe1babec3714ed9ef8d",
            "filename": "third_party/xla/xla/service/cpu/backend_config.proto",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbackend_config.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/56d3b1928078b98a3a9030535504020689b4725b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbackend_config.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fbackend_config.proto?ref=56d3b1928078b98a3a9030535504020689b4725b",
            "patch": "@@ -2,7 +2,8 @@ syntax = \"proto3\";\n \n package xla.cpu;\n \n-import \"xla/backends/cpu/xnnpack_config.proto\";\n+import \"xla/backends/cpu/xnn_fusion_options.proto\";\n+import \"xla/backends/cpu/ynn_fusion_options.proto\";\n import \"xla/service/cpu/onednn_config.proto\";\n \n // Backend config for a general custom call instruction, e.g. XLA FFI.\n@@ -19,7 +20,8 @@ message CustomCallBackendConfig {\n message FusionBackendConfig {\n   string kind = 1;\n   oneof custom_fusion_config_oneof {\n-    XnnFusionBackendConfig xnn_fusion_config = 2;\n+    XnnFusionOptions xnn_fusion_options = 2;\n+    YnnFusionOptions ynn_fusion_options = 3;\n   }\n }\n "
        }
    ],
    "stats": {
        "total": 108,
        "additions": 66,
        "deletions": 42
    }
}