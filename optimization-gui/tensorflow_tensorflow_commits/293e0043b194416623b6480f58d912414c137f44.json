{
    "author": "thomasjoerg",
    "message": "[XLA:GPU] DotMerger refactoring: Compare dots with the same queue_id only.\n\nTo do so, use the queue_id as part of the key of equivalence classes. This way, dots on different stream (with different queue_ids) do not need to be considered pair-wise for merging. This replaces the previous pairwise `can_merge` function.\n\nPiperOrigin-RevId: 845196209",
    "sha": "293e0043b194416623b6480f58d912414c137f44",
    "files": [
        {
            "sha": "be61f6be2a96c653610f3f15b3606bbeb017f278",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/dot_merger.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 14,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.cc?ref=293e0043b194416623b6480f58d912414c137f44",
            "patch": "@@ -415,10 +415,9 @@ absl::StatusOr<HloInstruction*> TryMergeOperand(HloInstruction* a,\n   return TryMergeLHSWithRHSOperand(b, a);\n }\n \n-absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n-                               std::function<bool(const HloInstruction* dot_a,\n-                                                  const HloInstruction* dot_b)>\n-                                   can_merge) {\n+absl::StatusOr<bool> MergeDots(\n+    HloComputation* comp, int64_t max_size_to_merge,\n+    std::function<int64_t(const HloInstruction* dot)> queue_id) {\n   auto is_merge_candidate = [&](HloInstruction* instr) {\n     int64_t bytes = ShapeUtil::ByteSizeOfElements(instr->shape());\n     for (const HloInstruction* operand : instr->operands()) {\n@@ -429,13 +428,17 @@ absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n \n   // Collect equivalence classes.  Specifically, create the map\n   //\n-  //   instruction -> [canonical dots that use the instruction].\n+  //   instruction, queue_id -> [canonical dots that use the instruction].\n+  //\n+  // queue_id is backend-specific. Dots with different queue_ids may run\n+  // concurrently on different streams and will not be merged.\n   //\n   // We'll then try to merge dots within each equivalence class.  A dot will be\n   // a member of two equivalence classes (because it has two operands), but if\n   // it's merged with a dot from one equivalence class, it won't also be merged\n   // in another class.\n-  absl::flat_hash_map<HloInstruction*, absl::flat_hash_set<HloInstruction*>>\n+  absl::flat_hash_map<std::pair<HloInstruction*, int64_t>,\n+                      absl::flat_hash_set<HloInstruction*>>\n       equivalence_classes;\n   for (HloInstruction* instr : comp->instructions()) {\n     // Cowardly skip instructions with control dependencies.\n@@ -445,11 +448,12 @@ absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n       continue;\n     }\n     for (HloInstruction* operand : instr->operands()) {\n-      equivalence_classes[operand].insert(instr);\n+      equivalence_classes[{operand, queue_id(instr)}].insert(instr);\n       // DotDecomposer inserts transposes to establish a normal form. Transposed\n       // operands still count as equivalent.\n       if (operand->opcode() == HloOpcode::kTranspose) {\n-        equivalence_classes[operand->mutable_operand(0)].insert(instr);\n+        equivalence_classes[{operand->mutable_operand(0), queue_id(instr)}]\n+            .insert(instr);\n       }\n     }\n   }\n@@ -462,7 +466,7 @@ absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n   //    us to merge.)\n   absl::erase_if(\n       equivalence_classes,\n-      [&](const std::pair<const HloInstruction*,\n+      [&](const std::pair<std::pair<const HloInstruction*, int64_t>,\n                           absl::flat_hash_set<HloInstruction*>>& kv) {\n         const auto& v = kv.second;\n         return v.size() < 2 || absl::c_none_of(v, is_merge_candidate);\n@@ -508,13 +512,14 @@ absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n   // them earlier because removing an instruction deletes it; we'd then have\n   // dangling pointers in our hashtable!)\n   absl::flat_hash_set<HloInstruction*> dead_instrs;\n-  std::vector<HloInstruction*> keys;\n+  std::vector<std::pair<HloInstruction*, int64_t>> keys;\n   keys.reserve(equivalence_classes.size());\n   for (auto& kv : equivalence_classes) {\n     keys.push_back(kv.first);\n   }\n-  absl::c_sort(keys, [](const HloInstruction* a, const HloInstruction* b) {\n-    return a->unique_id() < b->unique_id();\n+  absl::c_sort(keys, [](std::pair<const HloInstruction*, int64_t> a,\n+                        std::pair<const HloInstruction*, int64_t> b) {\n+    return a.first->unique_id() < b.first->unique_id();\n   });\n   for (auto key : keys) {\n     const auto& values = equivalence_classes[key];\n@@ -540,7 +545,6 @@ absl::StatusOr<bool> MergeDots(HloComputation* comp, int64_t max_size_to_merge,\n \n         if (dead_instrs.contains(a) || dead_instrs.contains(b) ||\n             (!is_merge_candidate(a) && !is_merge_candidate(b)) ||\n-            !can_merge(a, b) ||\n             // Perform reachability checks last since they can be expensive.\n             graph.IsReachableNonConst(a_id, b_id) ||\n             graph.IsReachableNonConst(b_id, a_id)) {\n@@ -599,7 +603,7 @@ absl::StatusOr<bool> DotMerger::RunImpl(\n   for (HloComputation* comp :\n        module->MakeNonfusionComputations(execution_threads)) {\n     TF_ASSIGN_OR_RETURN(bool changed_computation,\n-                        MergeDots(comp, max_size_to_merge_, can_merge_));\n+                        MergeDots(comp, max_size_to_merge_, queue_id_));\n     changed |= changed_computation;\n   }\n   return changed;"
        },
        {
            "sha": "e0da3f4f1952b8a0ff7d1145803b04de95e959a1",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/dot_merger.h",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger.h?ref=293e0043b194416623b6480f58d912414c137f44",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/pass/hlo_pass_interface.h\"\n \n@@ -59,10 +60,9 @@ class DotMerger : public HloModulePass {\n  public:\n   explicit DotMerger(\n       int64_t max_size_to_merge,\n-      std::function<bool(const HloInstruction* a, const HloInstruction* b)>\n-          can_merge = [](const HloInstruction* dot_a,\n-                         const HloInstruction* dot_b) -> bool { return true; })\n-      : max_size_to_merge_(max_size_to_merge), can_merge_(can_merge) {}\n+      std::function<int64_t(const HloInstruction* dot)> queue_id =\n+          [](const HloInstruction* dot) -> int64_t { return 0; })\n+      : max_size_to_merge_(max_size_to_merge), queue_id_(queue_id) {}\n \n   absl::string_view name() const override { return \"dot-merger\"; }\n \n@@ -73,9 +73,8 @@ class DotMerger : public HloModulePass {\n \n  private:\n   int64_t max_size_to_merge_;\n-  // Predicate function for backend-specific compatibility check.\n-  std::function<bool(const HloInstruction* dot_a, const HloInstruction* dot_b)>\n-      can_merge_;\n+  // Predicate function for backend-specific operation queue mapping.\n+  std::function<int64_t(const HloInstruction* dot)> queue_id_;\n };\n \n }  // namespace xla"
        },
        {
            "sha": "73ba972f33f3cca9e9a1fae365d43bb69281b053",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/dot_merger_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fdot_merger_test.cc?ref=293e0043b194416623b6480f58d912414c137f44",
            "patch": "@@ -831,18 +831,21 @@ TEST_F(DotMergerTest, NoMergeWithFalseCompatibility) {\n     lhs1 = f32[2,4,300,200] parameter(1)\n     rhs  = f32[2,4,200, 50] parameter(2)\n     dot0 = f32[2,4,100, 50] dot(lhs0, rhs), lhs_batch_dims={0,1}, rhs_batch_dims={0,1},\n-                                            lhs_contracting_dims={3}, rhs_contracting_dims={2}\n+        lhs_contracting_dims={3}, rhs_contracting_dims={2}, backend_config={\"operation_queue_id\":\"0\"}\n     dot1 = f32[2,4,300, 50] dot(lhs1, rhs), lhs_batch_dims={0,1}, rhs_batch_dims={0,1},\n-                                            lhs_contracting_dims={3}, rhs_contracting_dims={2}\n+        lhs_contracting_dims={3}, rhs_contracting_dims={2}, backend_config={\"operation_queue_id\":\"1\"}\n     ROOT tuple = (f32[2,4,100,50], f32[2,4,300,50]) tuple(dot0, dot1)\n   })\";\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(module_string));\n-  std::function<bool(const HloInstruction* dot_a, const HloInstruction* dot_b)>\n-      can_merge = [&](const HloInstruction* dot_a,\n-                      const HloInstruction* dot_b) -> bool { return false; };\n+  std::function<int64_t(const HloInstruction* dot)> queue_id =\n+      [&](const HloInstruction* dot) -> int64_t {\n+    // The queue_id will typically be taken from the backend_config, but deps on\n+    // backend-specific protos is avoided for testing.\n+    return dot->name() == \"dot1\" ? 1 : 0;\n+  };\n   DotMerger pass(/*max_size_to_merge=*/std::numeric_limits<int64_t>::max(),\n-                 can_merge);\n+                 queue_id);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_FALSE(changed);\n }"
        },
        {
            "sha": "f864daf9e86df2de238ea32c12af29ef35fe046b",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/293e0043b194416623b6480f58d912414c137f44/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=293e0043b194416623b6480f58d912414c137f44",
            "patch": "@@ -757,18 +757,15 @@ absl::Status RunOptimizationPasses(\n     // Only merge \"smallish\" dots.  This threshold defaults to 32MB today, with\n     // a flag to override.\n     // Do not merge dots when they are assigned different stream ids.\n-    std::function<bool(const HloInstruction* dot_a,\n-                       const HloInstruction* dot_b)>\n-        can_merge = [&](const HloInstruction* dot_a,\n-                        const HloInstruction* dot_b) -> bool {\n-      return dot_a->backend_config<GpuBackendConfig>()->operation_queue_id() ==\n-             dot_b->backend_config<GpuBackendConfig>()->operation_queue_id();\n+    std::function<int64_t(const HloInstruction* dot)> queue_id =\n+        [&](const HloInstruction* dot) -> int64_t {\n+      return dot->backend_config<GpuBackendConfig>()->operation_queue_id();\n     };\n     pipeline.AddPass<DotMerger>(\n         /*max_size_to_merge=*/int64_t{debug_options\n                                           .xla_gpu_dot_merger_threshold_mb()}\n             << 20,\n-        can_merge);\n+        queue_id);\n     pipeline.AddPass<SortSimplifier>();\n     pipeline.AddPass<TupleSimplifier>();\n     pipeline.AddPass<WhileLoopConstantSinking>();"
        }
    ],
    "stats": {
        "total": 71,
        "additions": 37,
        "deletions": 34
    }
}