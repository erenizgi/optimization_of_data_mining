{
    "author": "thomasjoerg",
    "message": "Reverts fa3c810dc0c94f61760d4480955036659ad9bf51\n\nPiperOrigin-RevId: 836569479",
    "sha": "44292ab9cc81e39a04b7dee416209c969cf532a9",
    "files": [
        {
            "sha": "165422bf9dd7f5a2041e2d5c5842e66cda49fa71",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/dot_decomposer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc?ref=44292ab9cc81e39a04b7dee416209c969cf532a9",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/layout_util.h\"\n #include \"xla/service/shape_inference.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -104,8 +105,8 @@ absl::Status CanonicalizeDot(HloDotInstruction* original_dot) {\n   HloInstruction* lhs_operand = original_dot->mutable_operand(0);\n   HloInstruction* transposed_lhs = computation->AddInstruction(\n       HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensions(lhs_transpose, lhs_shape), lhs_operand,\n-          lhs_transpose),\n+          ShapeUtil::PermuteDimensionsIgnoringLayout(lhs_transpose, lhs_shape),\n+          lhs_operand, lhs_transpose),\n       &lhs_operand->metadata());\n \n   std::vector<int64_t> lhs_reshape_dims = batch_dim_sizes;\n@@ -163,8 +164,8 @@ absl::Status CanonicalizeDot(HloDotInstruction* original_dot) {\n   HloInstruction* rhs_operand = original_dot->mutable_operand(1);\n   HloInstruction* transposed_rhs = computation->AddInstruction(\n       HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensions(rhs_transpose, rhs_shape), rhs_operand,\n-          rhs_transpose),\n+          ShapeUtil::PermuteDimensionsIgnoringLayout(rhs_transpose, rhs_shape),\n+          rhs_operand, rhs_transpose),\n       &rhs_operand->metadata());\n \n   std::vector<int64_t> rhs_reshape_dims = batch_dim_sizes;"
        },
        {
            "sha": "2c508759fef7b49a12c9fbdffbf6f30f75823e00",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/dot_decomposer_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 7,
            "changes": 23,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer_test.cc?ref=44292ab9cc81e39a04b7dee416209c969cf532a9",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n #include \"xla/hlo/utils/hlo_matchers.h\"\n #include \"xla/service/pattern_matcher.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -99,13 +100,21 @@ TEST_F(DotDecomposerTest, TransposeContractingDimsUponCanonicalization) {\n   TF_ASSERT_OK_AND_ASSIGN(bool canonicalized,\n                           DotDecomposer().Run(module.get()));\n   EXPECT_TRUE(canonicalized) << module->ToString();\n-  EXPECT_THAT(module->entry_computation()->root_instruction(),\n-              op::Reshape(AllOf(op::Dot(op::Reshape(op::Transpose()),\n-                                        op::Reshape(op::Transpose()),\n-                                        /*lhs_contracting_dim=*/1,\n-                                        /*rhs_contracting_dim=*/0),\n-                                op::Shape(\"f32[1024,1024]\"))))\n-      << module->ToString();\n+  const HloInstruction* dot = nullptr;\n+  const HloInstruction* lhs_transpose = nullptr;\n+  const HloInstruction* rhs_transpose = nullptr;\n+  EXPECT_THAT(\n+      module->entry_computation()->root_instruction(),\n+      GmockMatch(m::Reshape(\n+          m::Op(&dot)\n+              .WithOperand(0, m::Reshape(m::Transpose(&lhs_transpose)))\n+              .WithOperand(1, m::Reshape(m::Transpose(&rhs_transpose))))));\n+  EXPECT_THAT(dot, AllOf(op::Dot(op::Reshape(), op::Reshape(),\n+                                 /*lhs_contracting_dim=*/1,\n+                                 /*rhs_contracting_dim=*/0),\n+                         op::Shape(\"f32[1024,1024]\")));\n+  EXPECT_THAT(lhs_transpose, op::ShapeWithLayout(\"f32[32,32,512]\"));\n+  EXPECT_THAT(rhs_transpose, op::ShapeWithLayout(\"f32[512,1024]\"));\n }\n \n TEST_F(DotDecomposerTest, DontCanonicalizeIfNoNoncontractingDims) {"
        },
        {
            "sha": "321f9dfffab4cd141dc7007c2d1e3b00c6522c9c",
            "filename": "third_party/xla/xla/shape_util.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.cc?ref=44292ab9cc81e39a04b7dee416209c969cf532a9",
            "patch": "@@ -1264,7 +1264,7 @@ ShapeUtil::PackedFactorFor1DInterleavedArray(const Shape& shape) {\n       [&](int64_t dim) -> bool { return shape.dimensions()[dim] != 1; }, shape);\n }\n \n-/* static */ Shape ShapeUtil::PermuteDimensions(\n+/* static */ Shape ShapeUtil::PermuteDimensionsIgnoringLayout(\n     absl::Span<const int64_t> permutation, const Shape& shape) {\n   Shape new_shape = shape;\n   new_shape.clear_dimensions();\n@@ -1274,7 +1274,12 @@ ShapeUtil::PackedFactorFor1DInterleavedArray(const Shape& shape) {\n   for (int i = 0; i < permuted_dims.size(); ++i) {\n     new_shape.add_dimensions(permuted_dims[i], permuted_dynamic_dims[i]);\n   }\n+  return new_shape;\n+}\n \n+/* static */ Shape ShapeUtil::PermuteDimensions(\n+    absl::Span<const int64_t> permutation, const Shape& shape) {\n+  Shape new_shape = PermuteDimensionsIgnoringLayout(permutation, shape);\n   // If `shape` has a layout, by contract we choose a new layout such that the\n   // transpose defined by this permutation is a bitcast.\n   //"
        },
        {
            "sha": "fde70d0dd22ef56e3508007517bc8174acbb9259",
            "filename": "third_party/xla/xla/shape_util.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.h?ref=44292ab9cc81e39a04b7dee416209c969cf532a9",
            "patch": "@@ -827,6 +827,10 @@ class ShapeUtil {\n   // Drops any degenerate dimensions (i.e. dimensions of size 1)\n   static Shape DropDegenerateDimensions(const Shape& shape);\n \n+  // Permutes the dimensions of `shape` without changing the layout, if present.\n+  static Shape PermuteDimensionsIgnoringLayout(\n+      absl::Span<const int64_t> permutation, const Shape& shape);\n+\n   // Permutes the dimensions by the given permutation, so\n   // return_value.dimensions[i] = argument.dimensions[permutation[i]].\n   //"
        },
        {
            "sha": "ebfefa77e568d2374b739f72558572760b60be70",
            "filename": "third_party/xla/xla/shape_util_test.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/44292ab9cc81e39a04b7dee416209c969cf532a9/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util_test.cc?ref=44292ab9cc81e39a04b7dee416209c969cf532a9",
            "patch": "@@ -1022,6 +1022,24 @@ TEST(ShapeUtilTest, HasDegenerateDimensions) {\n       ShapeUtil::HasDegenerateDimensions(ShapeUtil::MakeShape(F32, {3, 0, 5})));\n }\n \n+TEST(ShapeUtilTest, PermuteDimensionsIgnoringLayout) {\n+  {\n+    Shape s =\n+        ShapeUtil::MakeShapeWithDenseLayout(F32, {10, 100, 1000}, {2, 1, 0});\n+    Shape permuted = ShapeUtil::PermuteDimensionsIgnoringLayout({1, 2, 0}, s);\n+    EXPECT_EQ(permuted, ShapeUtil::MakeShapeWithDenseLayout(\n+                            F32, {100, 1000, 10}, {2, 1, 0}));\n+  }\n+  {\n+    Shape s = ShapeUtil::MakeShape(F32, {10, 100, 1000});\n+    LayoutUtil::ClearLayout(&s);\n+    Shape permuted = ShapeUtil::PermuteDimensionsIgnoringLayout({1, 2, 0}, s);\n+    Shape expected = ShapeUtil::MakeShape(F32, {100, 1000, 10});\n+    LayoutUtil::ClearLayout(&expected);\n+    EXPECT_EQ(permuted, expected);\n+  }\n+}\n+\n TEST(ShapeUtilTest, PermuteDimensionsLayout) {\n   std::vector<int64_t> layout(3);\n   std::iota(layout.begin(), layout.end(), 0);"
        }
    ],
    "stats": {
        "total": 61,
        "additions": 49,
        "deletions": 12
    }
}