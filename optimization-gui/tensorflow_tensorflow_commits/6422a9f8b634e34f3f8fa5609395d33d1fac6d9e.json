{
    "author": "chsigg",
    "message": "Remove kTritonScaledDotFusionKind.\n\nThis change removes the `kTritonScaledDotFusionKind` and replaces it with `kTritonNestedGemmFusionKind`.\n\nAlso fixes lint issues and compilation errors in symbolic_tile_analysis.cc and fusion_emitter.cc related to nested fusion support.\n\nPiperOrigin-RevId: 836581986",
    "sha": "6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
    "files": [
        {
            "sha": "1bca3b31b11bb8ec4db98364078f3f87a49e01cb",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -102,7 +102,6 @@ TritonFusion::GenerateTritonKernelAndWrapper(\n \n   if (fusion_kind == kTritonFusionKind ||\n       fusion_kind == kTritonNestedGemmFusionKind ||\n-      fusion_kind == kTritonScaledDotFusionKind ||\n       fusion_kind == kTritonCollectiveFusionKind) {\n     if (!analysis_.fusion_backend_config().has_block_level_fusion_config()) {\n       return absl::InvalidArgumentError(absl::StrCat(\n@@ -180,7 +179,6 @@ absl::StatusOr<FusionEmissionResult> TritonFusion::Emit(\n     const std::vector<absl::string_view> kSupportedFusionKinds = {\n         kTritonFusionKind,\n         kTritonNestedGemmFusionKind,\n-        kTritonScaledDotFusionKind,\n         kTritonCollectiveFusionKind,\n     };\n "
        },
        {
            "sha": "8c3bba73ed8d117aee0147eb198e53febafacc21",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -1974,7 +1974,6 @@ absl::StatusOr<mlir::OwningOpRef<mlir::ModuleOp>> EmitXTileModule(\n   const std::vector<absl::string_view> kSupportedFusionKinds = {\n       kTritonFusionKind,\n       kTritonNestedGemmFusionKind,\n-      kTritonScaledDotFusionKind,\n       kTritonCollectiveFusionKind,\n   };\n "
        },
        {
            "sha": "853262de2cf703d85cc3cdfc2c96af3b78911b0a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -401,7 +401,7 @@ ENTRY e {\n     calls=triton_dot,\n     backend_config={\n       \"fusion_backend_config\": {\n-        kind: \"__triton_scaled_dot_fusion\",\n+        kind: \"__triton_nested_gemm_fusion\",\n         \"block_level_fusion_config\":{\n           \"output_tiles\":[{\"sizes\":[\"128\", \"256\"]}],\n           \"num_warps\":\"4\","
        },
        {
            "sha": "33fdb24c8dd3d38e3f68a4f07ddbd6bd223d8bd5",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -201,8 +201,7 @@ class GemmFusionCollector : public ConstDfsHloVisitorWithDefault {\n         gpu_config.fusion_backend_config();\n     if (backend_config.kind() != kTritonGemmFusionKind &&\n         backend_config.kind() != kCuDnnFusionKind &&\n-        backend_config.kind() != kCustomFusionKind &&\n-        backend_config.kind() != kTritonScaledDotFusionKind) {\n+        backend_config.kind() != kCustomFusionKind) {\n       return absl::OkStatus();\n     }\n \n@@ -460,7 +459,7 @@ absl::StatusOr<std::unique_ptr<HloModule>> CuDnnFusionExtractor(\n   GpuBackendConfig gpu_config;\n   FusionBackendConfig& backend_config =\n       *gpu_config.mutable_fusion_backend_config();\n-  backend_config.set_kind(std::string(kCuDnnFusionKind));\n+  backend_config.set_kind(kCuDnnFusionKind);\n   // Provided a plan ID the autotuner just compiles one plan.\n   backend_config.mutable_cudnn_fusion_config()->set_plan_id(plan_id);\n   TF_RETURN_IF_ERROR(root->set_backend_config(gpu_config));\n@@ -595,7 +594,10 @@ bool IsScaledDotFusion(const HloInstruction* fusion_instr) {\n   if (fusion_instr->fusion_kind() != HloInstruction::FusionKind::kCustom) {\n     return false;\n   }\n-  return IsGpuFusionKind(*fusion_instr, kTritonScaledDotFusionKind);\n+  return IsGpuFusionKind(*fusion_instr, kTritonGemmFusionKind) &&\n+         hlo_query::GetFirstInstructionWithOpcode(\n+             *fusion_instr->fused_instructions_computation(),\n+             HloOpcode::kScaledDot) != nullptr;\n }\n \n absl::Status RewriteGemmFusionToCall(HloInstruction* fusion_instr) {\n@@ -698,8 +700,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n   // Only autotune Triton, cuDNN, and custom kernel fusions.\n   if (fusion_backend_config.kind() != kTritonGemmFusionKind &&\n       fusion_backend_config.kind() != kCuDnnFusionKind &&\n-      fusion_backend_config.kind() != kCustomFusionKind &&\n-      fusion_backend_config.kind() != kTritonScaledDotFusionKind) {\n+      fusion_backend_config.kind() != kCustomFusionKind) {\n     return absl::OkStatus();\n   }\n \n@@ -762,7 +763,7 @@ absl::Status GemmFusionAutotunerRewriterVisitor::HandleFusion(\n \n   // Autotune result has a cuDNN fusion.\n   CHECK(autotune_result.has_algorithm());\n-  if (fusion_backend_config.kind() == kTritonScaledDotFusionKind) {\n+  if (IsScaledDotFusion(fusion_instr)) {\n     TF_ASSIGN_OR_RETURN(fusion_instr,\n                         CudnnScaledDotHelper::AddScaleSwizzle(\n                             Cast<HloFusionInstruction>(fusion_instr)));"
        },
        {
            "sha": "a99e88fc2c2e2c932f90c6f58507cb1f4f6e4377",
            "filename": "third_party/xla/xla/service/gpu/autotuning/gemm_fusion_autotuner_cuda.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_cuda.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_cuda.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fgemm_fusion_autotuner_cuda.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -20,6 +20,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/service/algorithm_util.h\"\n #include \"xla/service/gpu/autotuning/autotuner_util.h\"\n #include \"xla/service/gpu/autotuning/gemm_fusion_autotuner.h\"\n@@ -67,15 +68,16 @@ bool GemmFusionAutotunerImpl::AddLibConfigs(\n         debug_options_.xla_gpu_cudnn_gemm_fusion_level() > 1) ||\n        (cc.IsAtLeastBlackwell() &&\n         debug_options_.xla_gpu_cudnn_gemm_fusion_level() > 0));\n-  bool is_supported_triton_scaled_dot_fusion =\n-      IsGpuFusionKind(fusion, kTritonScaledDotFusionKind) &&\n+  bool is_cudnn_supported_scaled_dot_fusion =\n+      IsGpuFusionKind(fusion, kTritonNestedGemmFusionKind) &&\n+      dot->opcode() == HloOpcode::kScaledDot &&\n       dnn_version >= kCudnnSupportsBlockScaledDot &&\n       CudnnScaledDotHelper::IsSupported(Cast<HloScaledDotInstruction>(dot)) &&\n       cc.IsAtLeastBlackwell();\n \n   if (IsAutotuningEnabled() &&\n       (is_cudnn_fusion || is_supported_triton_dot_fusion ||\n-       is_supported_triton_scaled_dot_fusion)) {\n+       is_cudnn_supported_scaled_dot_fusion)) {\n     const int plan_count = GetCuDnnPlanCount(fusion, config_);\n     for (int plan_id = 0; plan_id < plan_count; ++plan_id) {\n       configs.push_back(CuDnnConfig{plan_id});"
        },
        {
            "sha": "1f889842500cfba688674ee8b291f8c93b008aab",
            "filename": "third_party/xla/xla/service/gpu/hlo_fusion_analysis.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 7,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fhlo_fusion_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fhlo_fusion_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fhlo_fusion_analysis.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -22,7 +22,6 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n-#include \"absl/algorithm/container.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n@@ -72,7 +71,9 @@ std::optional<TransposeDescription> FindConsistentTransposeHero(\n     }\n   }\n \n-  if (!tiled_transpose_hero) return std::nullopt;\n+  if (!tiled_transpose_hero) {\n+    return std::nullopt;\n+  }\n \n   for (auto* root : non_transpose_roots) {\n     // Roots that don't have a transpose hero, should have a shape compatible\n@@ -89,13 +90,21 @@ std::optional<TransposeDescription> FindConsistentTransposeHero(\n \n bool UseConcatenateFusion(absl::Span<const HloInstructionAdaptor> roots,\n                           absl::Span<const HloInstructionAdaptor> heroes) {\n-  if (heroes.size() != 1) return false;\n-  if (heroes.front().opcode() != HloOpcode::kConcatenate) return false;\n+  if (heroes.size() != 1) {\n+    return false;\n+  }\n+  if (heroes.front().opcode() != HloOpcode::kConcatenate) {\n+    return false;\n+  }\n   // The concat emitter does not support multiple outputs yet. TODO(csigg): fix.\n-  if (roots.front().shape().IsTuple()) return false;\n+  if (roots.front().shape().IsTuple()) {\n+    return false;\n+  }\n   // Limit the number of operands because the concat emitter produces code for\n   // each operand, hurting occupancy.\n-  if (heroes.front().instruction().operand_count() > 4) return false;\n+  if (heroes.front().instruction().operand_count() > 4) {\n+    return false;\n+  }\n   // The loop emitter is faster when warp divergence and occupancy are both low.\n   // TODO(csigg): exclude this case.\n   return true;\n@@ -114,7 +123,6 @@ HloFusionAnalysis::EmitterFusionKind GetEmitterFusionKind(\n   if (fusion_backend_config.kind() == kTritonFusionKind ||\n       fusion_backend_config.kind() == kTritonGemmFusionKind ||\n       fusion_backend_config.kind() == kTritonNestedGemmFusionKind ||\n-      fusion_backend_config.kind() == kTritonScaledDotFusionKind ||\n       fusion_backend_config.kind() == kTritonCollectiveFusionKind) {\n     return HloFusionAnalysis::EmitterFusionKind::kTriton;\n   }"
        },
        {
            "sha": "18499b6472dabe0b8fe9d28fc5db035829b8030a",
            "filename": "third_party/xla/xla/service/gpu/ir_emission_utils.h",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emission_utils.h?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -99,10 +99,6 @@ inline constexpr absl::string_view kTritonNestedGemmFusionKind =\n     \"__triton_nested_gemm_fusion\";\n \n // Fusions that use Triton have FusionBackendConfig.kind equal to this string.\n-// Used for fusions that implement a scaled dot.\n-inline constexpr absl::string_view kTritonScaledDotFusionKind =\n-    \"__triton_scaled_dot_fusion\";\n-\n inline constexpr absl::string_view kCuDnnFusionKind = \"__cudnn$fusion\";\n \n // Fusions that can be emitted using a dynamic memcpy. A dynamic memcpy depends"
        },
        {
            "sha": "1b36d029adeb816b8d70d1d8a4b202eba6573ee3",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_fusion.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -793,7 +793,9 @@ absl::StatusOr<Decision> CreateDotFusion(\n     return absl::OkStatus();\n   });\n \n-  if (is_pure_matmul) return Decision::NotProfitable(\"Pure Matmul\");\n+  if (is_pure_matmul) {\n+    return Decision::NotProfitable(\"Pure Matmul\");\n+  }\n \n   return Decision::Allow();\n }\n@@ -858,7 +860,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n                         dot_fusion->backend_config<GpuBackendConfig>());\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n-    backend_config.set_kind(std::string(kTritonGemmFusionKind));\n+    backend_config.set_kind(kTritonGemmFusionKind);\n     TF_RETURN_IF_ERROR(dot_fusion->set_backend_config(gpu_config));\n \n     if (fusion_output->IsRoot()) {\n@@ -951,7 +953,7 @@ class GemmFusionVisitor : public DfsHloRewriteVisitor {\n                         fusion->backend_config<GpuBackendConfig>());\n     FusionBackendConfig& backend_config =\n         *gpu_config.mutable_fusion_backend_config();\n-    backend_config.set_kind(kTritonScaledDotFusionKind);\n+    backend_config.set_kind(kTritonGemmFusionKind);\n     TF_RETURN_IF_ERROR(fusion->set_backend_config(gpu_config));\n     TF_RETURN_IF_ERROR(ReplaceInstruction(scaled_dot, fusion));\n     MarkAsChanged();"
        },
        {
            "sha": "c77d76d6954aed56941694885583da7f0e96886e",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_fusion_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6422a9f8b634e34f3f8fa5609395d33d1fac6d9e/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_fusion_test.cc?ref=6422a9f8b634e34f3f8fa5609395d33d1fac6d9e",
            "patch": "@@ -1526,7 +1526,7 @@ TEST_F(GemmFusionTest, ScaledDotIsFused) {\n     CHECK:   ROOT %[[FUSION:.*]] = bf16[4,4]{1,0} fusion(\n     CHECK:     kind=kCustom,\n     CHECK:     calls=%[[FUSION_DOT]]\n-    CHECK:     {\"kind\":\"__triton_scaled_dot_fusion\"}\n+    CHECK:     {\"kind\":\"__triton_gemm\"}\n   )\";\n   MatchHloModule(*module, kExpectedHloText);\n }"
        }
    ],
    "stats": {
        "total": 64,
        "additions": 35,
        "deletions": 29
    }
}