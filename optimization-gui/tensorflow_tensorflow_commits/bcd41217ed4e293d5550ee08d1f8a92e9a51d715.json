{
    "author": "EusebioDM",
    "message": "Add (de)serialization for the `ConvolutionReorderThunk`\n\nPiperOrigin-RevId: 819165377",
    "sha": "bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
    "files": [
        {
            "sha": "9116ee8cfcefaf8d29e6d6aac2857b132d8fc60e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 24,
            "deletions": 0,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -556,18 +556,40 @@ cc_library(\n     deps = [\n         \":convolution_filter_thunk_proto_cc\",\n         \":thunk\",\n+        \":thunk_proto_cc\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/service:buffer_assignment_proto_cc\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:dnn\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"convolution_reorder_thunk_test\",\n+    srcs = [\"convolution_reorder_thunk_test.cc\"],\n+    deps = [\n+        \":convolution_reorder_thunk\",\n+        \":thunk\",\n+        \":thunk_proto_cc\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@com_google_googletest//:gtest_main\",\n     ],\n )\n \n tf_proto_library(\n     name = \"convolution_filter_thunk_proto\",\n     srcs = [\"convolution_filter_thunk.proto\"],\n+    protodeps = [\"//xla/service:buffer_assignment_proto\"],\n )\n \n cc_library(\n@@ -2340,6 +2362,7 @@ tf_proto_library(\n     ],\n     protodeps = [\n         # keep sorted\n+        \":convolution_filter_thunk_proto\",\n         \":dynamic_slice_thunk_proto\",\n         \"//xla:xla_data_proto\",\n         \"//xla/service:buffer_assignment_proto\",\n@@ -2372,6 +2395,7 @@ cc_library(\n     hdrs = [\"thunk_proto_deserialization.h\"],\n     deps = [\n         \":conditional_thunk\",\n+        \":convolution_reorder_thunk\",\n         \":convolution_thunk\",\n         \":copy_thunk\",\n         \":cudnn_thunk\","
        },
        {
            "sha": "f691051f611d5fc4c90dcdde9ab7f8a7628ab68b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_filter_thunk.proto",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_filter_thunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_filter_thunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_filter_thunk.proto?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -2,6 +2,8 @@ syntax = \"proto3\";\n \n package xla.gpu;\n \n+import \"xla/service/buffer_assignment.proto\";\n+\n // Dimensions of the convolution filter.\n // See stream_executor::dnn::FilterDescriptor for more details.\n message ConvolutionFilterDimensions {\n@@ -14,3 +16,10 @@ message ConvolutionFilterDimensions {\n   // Width of the filter.\n   int64 input_filter_width = 4;\n }\n+\n+// Buffers for the bias input and output of the convolution reorder thunk.\n+// Serialized version of xla::gpu::ConvolutionReorderThunk::BiasBuffers.\n+message ConvolutionReorderBiasBuffers {\n+  xla.buffer_assignment.BufferAllocationSliceProto bias_input = 1;\n+  xla.buffer_assignment.BufferAllocationSliceProto bias_output = 2;\n+}"
        },
        {
            "sha": "c62d1ff735dd043aa8f80ce78cf1a190b4069bbb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_reorder_thunk.cc",
            "status": "modified",
            "additions": 58,
            "deletions": 1,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.cc?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -16,17 +16,21 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n \n #include <cstdint>\n+#include <memory>\n #include <optional>\n #include <utility>\n \n #include \"absl/log/check.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/convolution_filter_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/buffer_assignment.pb.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/dnn.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n namespace gpu {\n@@ -49,7 +53,8 @@ ConvolutionReorderThunk::ConvolutionReorderThunk(\n     BufferAllocation::Slice filter_input, BufferAllocation::Slice filter_output,\n     std::optional<BiasBuffers> biases)\n     : Thunk(Kind::kConvolutionReorder, thunk_info),\n-      filter_descriptor_(CreateFilterDescriptor(filter_dimensions)),\n+      filter_dimensions_(std::move(filter_dimensions)),\n+      filter_descriptor_(CreateFilterDescriptor(filter_dimensions_)),\n       filter_input_(filter_input),\n       filter_output_(filter_output),\n       biases_(biases) {}\n@@ -81,5 +86,57 @@ absl::Status ConvolutionReorderThunk::ExecuteOnStream(\n       std::move(bias_input), std::move(bias_output));\n }\n \n+absl::StatusOr<std::unique_ptr<ConvolutionReorderThunk>>\n+ConvolutionReorderThunk::FromProto(\n+    ThunkInfo thunk_info, const ConvolutionReorderThunkProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations) {\n+  TF_ASSIGN_OR_RETURN(BufferAllocation::Slice filter_input,\n+                      BufferAllocation::Slice::FromProto(proto.filter_input(),\n+                                                         buffer_allocations));\n+  TF_ASSIGN_OR_RETURN(BufferAllocation::Slice filter_output,\n+                      BufferAllocation::Slice::FromProto(proto.filter_output(),\n+                                                         buffer_allocations));\n+\n+  std::optional<BiasBuffers> biases;\n+  if (proto.has_biases()) {\n+    TF_ASSIGN_OR_RETURN(BufferAllocation::Slice bias_input,\n+                        BufferAllocation::Slice::FromProto(\n+                            proto.biases().bias_input(), buffer_allocations));\n+    TF_ASSIGN_OR_RETURN(BufferAllocation::Slice bias_output,\n+                        BufferAllocation::Slice::FromProto(\n+                            proto.biases().bias_output(), buffer_allocations));\n+    biases = {{bias_input, bias_output}};\n+  }\n+\n+  return std::make_unique<ConvolutionReorderThunk>(\n+      std::move(thunk_info), proto.filter_dimensions(), filter_input,\n+      filter_output, biases);\n+}\n+\n+absl::StatusOr<ThunkProto> ConvolutionReorderThunk::ToProto() const {\n+  ThunkProto thunk_proto;\n+  *thunk_proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  ConvolutionReorderThunkProto* reorder_proto =\n+      thunk_proto.mutable_convolution_reorder_thunk();\n+  *reorder_proto->mutable_filter_dimensions() = filter_dimensions_;\n+\n+  TF_ASSIGN_OR_RETURN(*reorder_proto->mutable_filter_input(),\n+                      filter_input_.ToProto());\n+  TF_ASSIGN_OR_RETURN(*reorder_proto->mutable_filter_output(),\n+                      filter_output_.ToProto());\n+\n+  if (biases_.has_value()) {\n+    ConvolutionReorderBiasBuffers* biases_proto =\n+        reorder_proto->mutable_biases();\n+    TF_ASSIGN_OR_RETURN(*biases_proto->mutable_bias_input(),\n+                        biases_->bias_input.ToProto());\n+    TF_ASSIGN_OR_RETURN(*biases_proto->mutable_bias_output(),\n+                        biases_->bias_output.ToProto());\n+  }\n+\n+  return thunk_proto;\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "064f7859b001b9cba2cb374f76349809466cbd5c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_reorder_thunk.h",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk.h?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -16,11 +16,15 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_RUNTIME_CONVOLUTION_REORDER_THUNK_H_\n #define XLA_BACKENDS_GPU_RUNTIME_CONVOLUTION_REORDER_THUNK_H_\n \n+#include <memory>\n #include <optional>\n \n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/convolution_filter_thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/dnn.h\"\n \n@@ -46,8 +50,14 @@ class ConvolutionReorderThunk : public Thunk {\n \n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  static absl::StatusOr<std::unique_ptr<ConvolutionReorderThunk>> FromProto(\n+      ThunkInfo thunk_info, const ConvolutionReorderThunkProto& proto,\n+      absl::Span<const BufferAllocation> buffer_allocations);\n+\n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n  private:\n-  // TODO: b/431980836 - Store the filter dimensions to use for serialization.\n+  const ConvolutionFilterDimensions filter_dimensions_;\n   const se::dnn::FilterDescriptor filter_descriptor_;\n   BufferAllocation::Slice filter_input_;\n   BufferAllocation::Slice filter_output_;"
        },
        {
            "sha": "69aaf54193541fe84951f7aa3c4f485854f6aa74",
            "filename": "third_party/xla/xla/backends/gpu/runtime/convolution_reorder_thunk_test.cc",
            "status": "added",
            "additions": 75,
            "deletions": 0,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconvolution_reorder_thunk_test.cc?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -0,0 +1,75 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n+\n+#include <memory>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla {\n+namespace gpu {\n+namespace {\n+\n+using ::tsl::proto_testing::EqualsProto;\n+using ::tsl::proto_testing::ParseTextProtoOrDie;\n+\n+TEST(ConvolutionReorderThunkTest, ProtoRoundTrip) {\n+  auto proto = ParseTextProtoOrDie<ThunkProto>(R\"pb(\n+    thunk_info { profile_annotation: \"test\" execution_stream_id: 0 }\n+    convolution_reorder_thunk {\n+      filter_dimensions {\n+        output_feature_map_count: 1\n+        input_feature_map_count: 2\n+        input_filter_height: 3\n+        input_filter_width: 4\n+      }\n+      filter_input { buffer_allocation_index: 0 offset: 0 size: 1024 }\n+      filter_output { buffer_allocation_index: 1 offset: 0 size: 512 }\n+      biases {\n+        bias_input { buffer_allocation_index: 2 offset: 0 size: 256 }\n+        bias_output { buffer_allocation_index: 3 offset: 0 size: 128 }\n+      }\n+    }\n+  )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations;\n+  buffer_allocations.emplace_back(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  buffer_allocations.emplace_back(/*index=*/1, /*size=*/512, /*color=*/0);\n+  buffer_allocations.emplace_back(/*index=*/2, /*size=*/256, /*color=*/0);\n+  buffer_allocations.emplace_back(/*index=*/3, /*size=*/128, /*color=*/0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Thunk::ThunkInfo thunk_info,\n+                          Thunk::ThunkInfo::FromProto(proto.thunk_info()));\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<ConvolutionReorderThunk> thunk,\n+      ConvolutionReorderThunk::FromProto(\n+          thunk_info, proto.convolution_reorder_thunk(), buffer_allocations));\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+}  // namespace\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "a73e43269d2b6820bbe56d2726ada0fb816ae235",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -17,9 +17,9 @@ syntax = \"proto3\";\n \n package xla.gpu;\n \n+import \"xla/backends/gpu/runtime/convolution_filter_thunk.proto\";\n import \"xla/backends/gpu/runtime/dynamic_slice_thunk.proto\";\n import \"xla/service/buffer_assignment.proto\";\n-import \"xla/service/gpu/backend_configs.proto\";\n import \"xla/service/gpu/gpu_conv_runner.proto\";\n import \"xla/service/gpu/gpu_norm_runner.proto\";\n import \"xla/service/gpu/launch_dimensions.proto\";\n@@ -206,6 +206,13 @@ message ConvolutionThunkProto {\n   xla.buffer_assignment.BufferAllocationSliceProto scratch_buffer = 4;\n }\n \n+message ConvolutionReorderThunkProto {\n+  ConvolutionFilterDimensions filter_dimensions = 1;\n+  xla.buffer_assignment.BufferAllocationSliceProto filter_input = 2;\n+  xla.buffer_assignment.BufferAllocationSliceProto filter_output = 3;\n+  optional ConvolutionReorderBiasBuffers biases = 4;\n+}\n+\n message ThunkProto {\n   ThunkInfoProto thunk_info = 1;\n \n@@ -234,6 +241,7 @@ message ThunkProto {\n     OutfeedThunkProto outfeed_thunk = 23;\n     NormThunkProto norm_thunk = 24;\n     ConvolutionThunkProto convolution_thunk = 25;\n+    ConvolutionReorderThunkProto convolution_reorder_thunk = 26;\n   }\n }\n "
        },
        {
            "sha": "2b36743b3905f0562b71b662fac1ccaa036cc5be",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcd41217ed4e293d5550ee08d1f8a92e9a51d715/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=bcd41217ed4e293d5550ee08d1f8a92e9a51d715",
            "patch": "@@ -28,6 +28,7 @@ limitations under the License.\n #include \"google/protobuf/descriptor.h\"\n #include \"google/protobuf/message.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n+#include \"xla/backends/gpu/runtime/convolution_reorder_thunk.h\"\n #include \"xla/backends/gpu/runtime/convolution_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n #include \"xla/backends/gpu/runtime/cudnn_thunk.h\"\n@@ -153,6 +154,11 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n       return ConvolutionThunk::FromProto(std::move(thunk_info),\n                                          thunk_proto.convolution_thunk(),\n                                          buffer_allocations);\n+    case ThunkProto::kConvolutionReorderThunk: {\n+      return ConvolutionReorderThunk::FromProto(\n+          std::move(thunk_info), thunk_proto.convolution_reorder_thunk(),\n+          buffer_allocations);\n+    }\n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n           GetStoredThunkTypeName(thunk_proto);"
        }
    ],
    "stats": {
        "total": 195,
        "additions": 192,
        "deletions": 3
    }
}