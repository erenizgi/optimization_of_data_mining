{
    "author": "unknown",
    "message": "[XLA:GPU] Implement KernelThunk::GetBuffers\n\nPiperOrigin-RevId: 813723347",
    "sha": "4295ff6afbcf12892fb3ea717a96a2398e171b31",
    "files": [
        {
            "sha": "07a85c6a2f673da0a0741760bb5bdf55deb035bc",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=4295ff6afbcf12892fb3ea717a96a2398e171b31",
            "patch": "@@ -833,6 +833,7 @@ cc_library(\n     hdrs = [\"kernel_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \":thunk_buffer\",\n         \":thunk_id\",\n         \":thunk_proto_cc\",\n         \"//xla:shape_util\",\n@@ -880,14 +881,20 @@ xla_test(\n         \":kernel_thunk\",\n         \":sequential_thunk\",\n         \":thunk\",\n+        \":thunk_buffer\",\n+        \":thunk_id\",\n         \":thunk_proto_cc\",\n+        \"//xla:literal\",\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/codegen/emitters:kernel_arguments\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service/gpu:buffer_allocations\",\n         \"//xla/service/gpu:launch_dimensions\",\n+        \"//xla/service/gpu/kernels:custom_kernel\",\n+        \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\","
        },
        {
            "sha": "e2da5a35b052e4c4a0aafaa4a3fcca74c59ba74a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc?ref=4295ff6afbcf12892fb3ea717a96a2398e171b31",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"llvm/ADT/STLExtras.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n@@ -53,6 +54,23 @@ limitations under the License.\n namespace xla {\n namespace gpu {\n \n+std::vector<ThunkBuffer> ThunkBuffersFromKernelArguments(\n+    absl::Span<const BufferAllocation::Slice> args,\n+    const std::vector<bool>& written) {\n+  std::vector<ThunkBuffer> buffers;\n+  buffers.reserve(args.size());\n+  for (int i = 0; i < args.size(); ++i) {\n+    buffers.push_back(ThunkBuffer{\n+        /*slice=*/args[i],\n+        // We assume that any buffer is either an input or an output of the\n+        // kernel, and inout buffers are represented as 2 separate arguments.\n+        /*is_content_defined_on_input=*/!written[i],\n+        /*is_content_defined_on_output=*/written[i],\n+    });\n+  }\n+  return buffers;\n+}\n+\n //===----------------------------------------------------------------------===//\n // KernelThunk\n //===----------------------------------------------------------------------===//\n@@ -255,6 +273,10 @@ absl::Status KernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n       launch_dimensions_, cluster_dim_, stream);\n }\n \n+std::vector<ThunkBuffer> KernelThunk::GetBuffers() const {\n+  return ThunkBuffersFromKernelArguments(absl::MakeConstSpan(args_), written_);\n+}\n+\n //===----------------------------------------------------------------------===//\n // CustomKernelThunk\n //===----------------------------------------------------------------------===//\n@@ -323,5 +345,9 @@ absl::Status CustomKernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n                         custom_kernel_.cluster_dims(), params.stream, args);\n }\n \n+std::vector<ThunkBuffer> CustomKernelThunk::GetBuffers() const {\n+  return ThunkBuffersFromKernelArguments(absl::MakeConstSpan(args_), written_);\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "47107bb3f0336d3c921195fe06fe0dd5313fd430",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.h",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.h?ref=4295ff6afbcf12892fb3ea717a96a2398e171b31",
            "patch": "@@ -31,6 +31,8 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -110,6 +112,8 @@ class KernelThunk : public Thunk {\n     return tma_metadata_;\n   }\n \n+  std::vector<ThunkBuffer> GetBuffers() const override;\n+\n  private:\n   // Buffer slices passed to the kernel as arguments.\n   std::vector<BufferAllocation::Slice> args_;\n@@ -173,6 +177,8 @@ class CustomKernelThunk : public Thunk {\n \n   int64_t shmem_bytes() const { return custom_kernel_.shared_memory_bytes(); }\n \n+  std::vector<ThunkBuffer> GetBuffers() const override;\n+\n  private:\n   // Buffer slices passed to the kernel as arguments.\n   std::vector<BufferAllocation::Slice> args_;"
        },
        {
            "sha": "b1ffecdffd6a6563c722f60fb740335c7cfd9821",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk_test.cc",
            "status": "modified",
            "additions": 98,
            "deletions": 0,
            "changes": 98,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4295ff6afbcf12892fb3ea717a96a2398e171b31/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk_test.cc?ref=4295ff6afbcf12892fb3ea717a96a2398e171b31",
            "patch": "@@ -33,14 +33,20 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n+#include \"xla/backends/gpu/runtime/thunk_buffer.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/literal.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n+#include \"xla/service/gpu/kernels/custom_kernel.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/service_executable_run_options.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/gpu/gpu_test_kernels.h\"\n #include \"xla/stream_executor/gpu/tma_metadata.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n@@ -263,6 +269,98 @@ TEST(KernelThunkTest, ToAndFromProto) {\n   EXPECT_THAT(reconstructed_thunk->tma_metadata(), tma_metadata);\n }\n \n+TEST(KernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n+  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n+  BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n+  emitters::KernelArgument arg0(ShapeUtil::MakeShape(F32, {512}), slice0);\n+  emitters::KernelArgument arg1(ShapeUtil::MakeShape(F32, {512}), slice1);\n+  arg0.set_written(false);\n+  arg1.set_written(true);\n+  emitters::KernelArguments kernel_arguments({arg0, arg1});\n+  KernelThunk thunk(Thunk::ThunkInfo(), \"kernel\", kernel_arguments,\n+                    LaunchDimensions(), se::ClusterDim(), /*shmem_bytes=*/0,\n+                    se::gpu::TmaMetadata());\n+\n+  std::vector<ThunkBuffer> buffers = thunk.GetBuffers();\n+\n+  ASSERT_THAT(buffers,\n+              testing::UnorderedElementsAre(\n+                  ThunkBuffer{slice0, /*is_content_defined_on_input=*/true,\n+                              /*is_content_defined_on_output=*/false},\n+                  ThunkBuffer{slice1, /*is_content_defined_on_input=*/false,\n+                              /*is_content_defined_on_output=*/true}));\n+}\n+\n+TEST(KernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n+  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n+  BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n+  emitters::KernelArgument arg0(ShapeUtil::MakeShape(F32, {512}), slice0);\n+  emitters::KernelArgument arg1(ShapeUtil::MakeShape(F32, {512}), slice1);\n+  arg0.set_written(false);\n+  arg1.set_written(true);\n+  emitters::KernelArguments kernel_arguments({arg0, arg1});\n+  KernelThunk thunk(Thunk::ThunkInfo(), \"kernel\", kernel_arguments,\n+                    LaunchDimensions(), se::ClusterDim(), /*shmem_bytes=*/0,\n+                    se::gpu::TmaMetadata());\n+\n+  std::vector<ThunkBuffer> buffers1 = thunk.GetBuffers();\n+  std::vector<ThunkBuffer> buffers2 = thunk.GetBuffers();\n+\n+  ASSERT_THAT(buffers1, testing::ContainerEq(buffers2));\n+}\n+\n+TEST(CustomKernelThunkTest, GetBuffersReturnsCorrectBuffers) {\n+  CustomKernel kernel(\n+      /*name=*/\"\",\n+      se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n+          /*ptx=*/\"\", /*kernel_name=*/\"\", /*arity=*/0),\n+      se::BlockDim(), se::ThreadDim(), /*shared_memory_bytes=*/0);\n+  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n+  BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n+  emitters::KernelArgument arg0(ShapeUtil::MakeShape(F32, {512}), slice0);\n+  emitters::KernelArgument arg1(ShapeUtil::MakeShape(F32, {512}), slice1);\n+  arg0.set_written(false);\n+  arg1.set_written(true);\n+  emitters::KernelArguments kernel_arguments({arg0, arg1});\n+  auto hlo = HloInstruction::CreateConstant(Literal());\n+  CustomKernelThunk thunk(hlo.get(), kernel, kernel_arguments, ThunkId{0});\n+\n+  std::vector<ThunkBuffer> buffers = thunk.GetBuffers();\n+\n+  ASSERT_THAT(buffers,\n+              testing::UnorderedElementsAre(\n+                  ThunkBuffer{slice0, /*is_content_defined_on_input=*/true,\n+                              /*is_content_defined_on_output=*/false},\n+                  ThunkBuffer{slice1, /*is_content_defined_on_input=*/false,\n+                              /*is_content_defined_on_output=*/true}));\n+}\n+\n+TEST(CustomKernelThunkTest, GetBuffersReturnsBuffersInConsistentOrder) {\n+  CustomKernel kernel(\n+      /*name=*/\"\",\n+      se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n+          /*ptx=*/\"\", /*kernel_name=*/\"\", /*arity=*/0),\n+      se::BlockDim(), se::ThreadDim(), /*shared_memory_bytes=*/0);\n+  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n+  BufferAllocation::Slice slice1(&alloc, /*offset=*/512, /*size=*/512);\n+  emitters::KernelArgument arg0(ShapeUtil::MakeShape(F32, {512}), slice0);\n+  emitters::KernelArgument arg1(ShapeUtil::MakeShape(F32, {512}), slice1);\n+  arg0.set_written(false);\n+  arg1.set_written(true);\n+  emitters::KernelArguments kernel_arguments({arg0, arg1});\n+  auto hlo = HloInstruction::CreateConstant(Literal());\n+  CustomKernelThunk thunk(hlo.get(), kernel, kernel_arguments, ThunkId{0});\n+\n+  std::vector<ThunkBuffer> buffers1 = thunk.GetBuffers();\n+  std::vector<ThunkBuffer> buffers2 = thunk.GetBuffers();\n+\n+  ASSERT_THAT(buffers1, testing::ContainerEq(buffers2));\n+}\n+\n class KernelThunkTmaPTXTest : public ::testing::TestWithParam<bool> {\n  public:\n   absl::StatusOr<std::unique_ptr<KernelThunk>> GetTmaKernelThunk() {"
        }
    ],
    "stats": {
        "total": 137,
        "additions": 137,
        "deletions": 0
    }
}