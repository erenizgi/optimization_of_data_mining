{
    "author": "chsigg",
    "message": "[xla:gpu] Emit `arith.index_cast` instead of `arith.index_castui`.\n\nPiperOrigin-RevId: 802161837",
    "sha": "7bbbb8785a76d9a220de5646d835a3e9975cfd35",
    "files": [
        {
            "sha": "50e5868b6908e8797478c4c691fb2a72832e2eec",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/convert_index_type.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Fconvert_index_type.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -85,13 +85,13 @@ class RewriteIndexBinaryElementwiseOp\n \n     Type index_type = IndexType::get(op->getContext());\n     Type dst_type = b.getIntegerType(index_bitwidth_);\n-    auto lhs = b.create<arith::IndexCastUIOp>(dst_type, op->getOperand(0));\n-    auto rhs = b.create<arith::IndexCastUIOp>(dst_type, op->getOperand(1));\n+    auto lhs = b.create<arith::IndexCastOp>(dst_type, op->getOperand(0));\n+    auto rhs = b.create<arith::IndexCastOp>(dst_type, op->getOperand(1));\n     auto new_op = b.create<BinaryElementwiseOp>(lhs, rhs);\n \n     rewriter.replaceAllUsesWith(\n         op.getResult(),\n-        b.create<arith::IndexCastUIOp>(index_type, new_op.getResult()));\n+        b.create<arith::IndexCastOp>(index_type, new_op.getResult()));\n \n     return mlir::success();\n   }\n@@ -115,9 +115,10 @@ struct ConvertIndexTypePass\n                  RewriteIndexBinaryElementwiseOp<arith::DivSIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::MulIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::RemUIOp>,\n+                 RewriteIndexBinaryElementwiseOp<arith::RemSIOp>,\n                  RewriteIndexBinaryElementwiseOp<arith::SubIOp>>(\n         ctx, *index_bitwidth);\n-    arith::IndexCastUIOp::getCanonicalizationPatterns(patterns, ctx);\n+    arith::IndexCastOp::getCanonicalizationPatterns(patterns, ctx);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "aa5e9f627c5c7fb086be95e4898caf92437fe2a0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/emitters/transforms/tests/convert_index_type.mlir",
            "status": "modified",
            "additions": 21,
            "deletions": 21,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Fconvert_index_type.mlir?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -7,10 +7,10 @@ func.func @addi_default(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @addi_default\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -24,10 +24,10 @@ module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<index, 32 : i32>>\n \n // CHECK-LABEL: @addi_32\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i32\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i32\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i32\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i32\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[V2]] : i32\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i32 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i32 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -43,9 +43,9 @@ module attributes {dlti.dl_spec = #dlti.dl_spec<#dlti.dl_entry<index, 32 : i32>>\n // CHECK-LABEL: @addi_const\n // CHECK-SAME: (%[[ARG0:.*]]: index) -> index {\n // CHECK: %[[C:.*]] = arith.constant 4 : i32\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i32\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i32\n // CHECK: %[[RI:.*]] = arith.addi %[[V1]], %[[C]] : i32\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i32 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i32 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -59,10 +59,10 @@ func.func @divui(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @divui\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i8\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i8\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i8\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i8\n // CHECK: %[[RI:.*]] = arith.divui %[[V1]], %[[V2]] : i8\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i8 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i8 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -74,10 +74,10 @@ func.func @muli(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @muli\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.muli %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n \n@@ -90,10 +90,10 @@ func.func @remui(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @remui\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.remui %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -105,10 +105,10 @@ func.func @subi(%arg0: index, %arg1: index) -> index {\n \n // CHECK-LABEL: @subi\n // CHECK-SAME: (%[[ARG0:.*]]: index, %[[ARG1:.*]]: index) -> index {\n-// CHECK: %[[V1:.*]] = arith.index_castui %[[ARG0]] : index to i64\n-// CHECK: %[[V2:.*]] = arith.index_castui %[[ARG1]] : index to i64\n+// CHECK: %[[V1:.*]] = arith.index_cast %[[ARG0]] : index to i64\n+// CHECK: %[[V2:.*]] = arith.index_cast %[[ARG1]] : index to i64\n // CHECK: %[[RI:.*]] = arith.subi %[[V1]], %[[V2]] : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %[[RI]] : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %[[RI]] : i64 to index\n // CHECK: return %[[R]] : index\n \n // -----\n@@ -128,5 +128,5 @@ func.func @complex(%arg0: index, %arg1: index, %arg2: index) -> index {\n // CHECK: arith.muli %{{.*}} : i64\n // CHECK: arith.muli %{{.*}} : i64\n // CHECK: arith.remui %{{.*}} : i64\n-// CHECK: %[[R:.*]] = arith.index_castui %{{.*}} : i64 to index\n+// CHECK: %[[R:.*]] = arith.index_cast %{{.*}} : i64 to index\n // CHECK: return %[[R]] : index"
        },
        {
            "sha": "27785cd15f7fc65cc294b5a10ba65453aecacb41",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -159,7 +159,7 @@ Value Cast(EmitterLocOpBuilder& b, Value value, Type dst_element_ty) {\n   }\n \n   if (src_ty.isIndex() || dst_ty.isIndex()) {\n-    return b.create<ma::IndexCastUIOp>(dst_ty, value);\n+    return b.create<ma::IndexCastOp>(dst_ty, value);\n   }\n \n   // All operations on bf16 are done through f32."
        },
        {
            "sha": "0017accf61c8a009737242dadbab41381335b8eb",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -179,7 +179,7 @@ Value EmitClampedIndex(EmitterLocOpBuilder b, Value value, int64_t lower,\n       value, CreateConst(b, value.getType(), lower).UnwrapUnsafe());\n   clamped_index = b.create<arith::MinSIOp>(\n       clamped_index, CreateConst(b, value.getType(), upper).UnwrapUnsafe());\n-  return b.create<arith::IndexCastUIOp>(b.getIndexType(), clamped_index);\n+  return b.create<arith::IndexCastOp>(b.getIndexType(), clamped_index);\n }\n \n absl::StatusOr<SmallVector<Value>> ComputeOffsetsForTile("
        },
        {
            "sha": "0abd3f5e8cc4a755e98c86b01da31c0c23ef3967",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_legacy_port_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_legacy_port_test.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -356,7 +356,7 @@ ENTRY e {\n     CHECK: %[[V2:.*]] = tensor.extract %[[ARG2]][] : tensor<i32>\n     CHECK: %[[CLAMP0:.*]] = arith.maxsi %[[V2]], %[[c0]] : i32\n     CHECK: %[[CLAMP1:.*]] = arith.minsi %[[CLAMP0]], %[[c3]] : i32\n-    CHECK: %[[OFFSET:.*]] = arith.index_castui %[[CLAMP1]] : i32 to index\n+    CHECK: %[[OFFSET:.*]] = arith.index_cast %[[CLAMP1]] : i32 to index\n     CHECK: triton_xla.extract from %[[ARG1]] {{.*}} [%[[OFFSET]], 0, 0] [1, 32, 32] [0, 1, 1]\n     CHECK: tt.dot\n   )\"));"
        },
        {
            "sha": "de121a2267532ca18979fa938e1632a7816c96bf",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -879,8 +879,7 @@ ENTRY main {\n                                           \"triton_softmax_computation\", R\"(\n CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}})\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-NEXT:       triton_xla.extract from %[[P0]]\n CHECK-SAME:       [%[[PID_INDEX]], 0] [1, 128] [1, 1]\n CHECK:            tt.reduce\n@@ -938,8 +937,7 @@ CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: !tt.ptr<f32>\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-DAG:        triton_xla.extract from %[[P0]] {{.*}} [%[[PID_INDEX]], 0] [1, 128] [1, 1] : tensor<1x128xf32>\n CHECK-DAG:        triton_xla.extract from %[[P1]] {{.*}} [0] [128] [1] : tensor<128xf32>\n CHECK:            tt.reduce\n@@ -999,8 +997,7 @@ CHECK:        #[[MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 125),\n CHECK:        #[[MAP1:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 mod 125), domain: pid_0 in [0, 1249]\">\n CHECK:        func.func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}})\n CHECK-DAG:        %[[PID:.*]] = tt.get_program_id x : i32\n-CHECK-DAG:        %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n-CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_castui %[[PID_I64]] : i64 to index\n+CHECK-DAG:        %[[PID_INDEX:.*]] = arith.index_cast %[[PID]] : i32 to index\n CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[PID_INDEX]]\n CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[PID_INDEX]]\n CHECK:            triton_xla.extract from %[[P0]] {{.*}} [%[[ROW_INDEX]], %[[COL_INDEX]], 0] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n@@ -1728,7 +1725,7 @@ ENTRY main {\n // CHECK-SAME:  : tensor<32xf32>\n \n // CHECK: %[[IOTA:.*]] = tt.make_range {end = 32 : i32, start = 0 : i32}\n-// CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_castui %[[TILE_OFFSET]]\n+// CHECK: %[[TILE_OFFSET_I32:.*]] = arith.index_cast %[[TILE_OFFSET]]\n // CHECK: %[[THRESHOLD:.*]] = arith.subi %[[C17]], %[[TILE_OFFSET_I32]]\n // CHECK: %[[THRESHOLD_SPLAT:.*]] = tt.splat %[[THRESHOLD]]\n // CHECK: %[[MASK:.*]] = arith.cmpi slt, %[[IOTA]], %[[THRESHOLD_SPLAT]]"
        },
        {
            "sha": "b047cc5b46df02e18effd022e4075030ddc1e7ef",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_extract_insert_to_triton.mlir",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_extract_insert_to_triton.mlir?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -78,7 +78,7 @@ module {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32xf32>\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<64xf32, #triton_xla.layout<[0]>>\n@@ -109,7 +109,7 @@ module {\n     %cst = arith.constant dense<0.000000e+00> : tensor<32xf32>\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<64xf32, #triton_xla.layout<[0]>>\n@@ -154,7 +154,7 @@ func.func @extract_with_non_unit_minor_dim_stride(%arg0: !tt.ptr<bf16>,\n func.func @extract_with_non_static_strides(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n   %0 = tt.get_program_id x : i32\n   %1 = arith.extsi %0 : i32 to i64\n-  %2 = arith.index_castui %1 : i64 to index\n+  %2 = arith.index_cast %1 : i64 to index\n   %extracted_tensor = triton_xla.extract from %arg0\n       as memref<1024x1024xbf16, #triton_xla.layout<[1, 0]>>\n       [0, 0] [16, 64] [%2, 1] : tensor<16x64xbf16>\n@@ -268,7 +268,7 @@ module {\n             %arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {\n     %0 = tt.get_program_id x : i32\n     %1 = arith.extsi %0 : i32 to i64\n-    %2 = arith.index_castui %1 : i64 to index\n+    %2 = arith.index_cast %1 : i64 to index\n     %3 = xla.apply_indexing #indexing_map(%2)\n     %extracted_tile = triton_xla.extract from %arg0\n         as memref<16x16xbf16, #triton_xla.layout<[1, 0]>>"
        },
        {
            "sha": "01a73f9e199ae30e806634265292470b7053d581",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_extract_insert_to_triton_pass.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7bbbb8785a76d9a220de5646d835a3e9975cfd35/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_extract_insert_to_triton_pass.cc?ref=7bbbb8785a76d9a220de5646d835a3e9975cfd35",
            "patch": "@@ -31,6 +31,7 @@ limitations under the License.\n #include \"llvm/ADT/SmallVector.h\"\n #include \"llvm/Support/CommandLine.h\"\n #include \"mlir/Analysis/SliceAnalysis.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/LLVMIR/NVVMDialect.h\"\n #include \"mlir/IR/AffineExpr.h\"\n@@ -80,12 +81,12 @@ bool AreRankedTensors(ArrayRef<Type> types) {\n   });\n }\n \n-SmallVector<Value> IndexCastUI(::xla::EmitterLocOpBuilder& builder, Type type,\n-                               ValueRange values) {\n+SmallVector<Value> IndexCast(::xla::EmitterLocOpBuilder& builder, Type type,\n+                             ValueRange values) {\n   SmallVector<Value> result;\n   result.reserve(values.size());\n   for (auto value : values) {\n-    result.push_back(builder.create<arith::IndexCastUIOp>(type, value));\n+    result.push_back(builder.create<arith::IndexCastOp>(type, value));\n   }\n   return result;\n }\n@@ -253,10 +254,10 @@ SmallVector<Value> ComputeResidualShape(::xla::EmitterLocOpBuilder& builder,\n             .UnwrapScalar();\n     // Offsets are necessarily positive since they represent a distance\n     // between 0 and the size of the tensor on the given axis. Therefore, it\n-    // is safe to use 'IndexCastUI' here. This allows index canonicalizations\n+    // is safe to use 'IndexCast' here. This allows index canonicalizations\n     // later on.\n     Value offset =\n-        builder.create<arith::IndexCastUIOp>(builder.getI64Type(), tile_offset);\n+        builder.create<arith::IndexCastOp>(builder.getI64Type(), tile_offset);\n     residual_shape.push_back(builder.create<arith::SubIOp>(size, offset));\n   }\n \n@@ -275,8 +276,8 @@ SmallVector<Value> ComputeStrides(::xla::EmitterLocOpBuilder& builder,\n   int64_t current_stride = 1;\n   for (int64_t cur_dim : minor_to_major_layout) {\n     strides[cur_dim] = builder.create<arith::MulIOp>(\n-        builder.create<arith::IndexCastUIOp>(builder.getI64Type(),\n-                                             tile_strides[cur_dim]),\n+        builder.create<arith::IndexCastOp>(builder.getI64Type(),\n+                                           tile_strides[cur_dim]),\n         ::xla::gpu::triton::CreateConst(builder, builder.getI64Type(),\n                                         current_stride)\n             .UnwrapScalar());\n@@ -300,7 +301,7 @@ Value ComputeLinearOffset(::xla::EmitterLocOpBuilder& builder,\n   auto bitcast_map =\n       ::xla::GetBitcastMap(xla_shape, linear_shape, builder.getContext());\n \n-  return builder.create<arith::IndexCastUIOp>(\n+  return builder.create<arith::IndexCastOp>(\n       builder.getI64Type(),\n       builder.create<::xla::ApplyIndexingOp>(offsets, bitcast_map)\n           .getResult(0));\n@@ -559,7 +560,7 @@ class RewriteExtract : public mlir::OpRewritePattern<ExtractOp> {\n \n       auto descriptor_load = builder.create<DescriptorLoadOp>(\n           normalized_tile_type, cast_to_tensor_desc,\n-          IndexCastUI(builder, builder.getI32Type(), normalized_offsets));\n+          IndexCast(builder, builder.getI32Type(), normalized_offsets));\n \n       // Insert a transpose if the layout is not normalized.\n       if (!IsNormalizedLayout(src_layout)) {\n@@ -665,7 +666,7 @@ class RewriteInsert : public mlir::OpRewritePattern<InsertOp> {\n       }\n       builder.create<DescriptorStoreOp>(\n           cast_to_tensor_desc, src,\n-          IndexCastUI(builder, builder.getI32Type(), normalized_offsets));\n+          IndexCast(builder, builder.getI32Type(), normalized_offsets));\n     } else {\n       auto ptr =\n           CreateAddPtrOp(builder, op.getDst(), offsets, dst_shape, dst_layout);"
        }
    ],
    "stats": {
        "total": 97,
        "additions": 48,
        "deletions": 49
    }
}