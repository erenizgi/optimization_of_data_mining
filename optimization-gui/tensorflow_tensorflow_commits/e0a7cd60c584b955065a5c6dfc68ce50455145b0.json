{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Enable native chlo.cosh -> kCosh HloInstruction lowering.\n\nThis change introduces `mhlo.cosh` as a distinct operation. Previously, `chlo.cosh` was always lowered to an expansion of other operations.\n\nPiperOrigin-RevId: 814086524",
    "sha": "e0a7cd60c584b955065a5c6dfc68ce50455145b0",
    "files": [
        {
            "sha": "df66133ff461a99a8d28a8dbd75afdbaec0838ce",
            "filename": "third_party/xla/docs/operation_semantics.md",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fdocs%2Foperation_semantics.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fdocs%2Foperation_semantics.md?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -2187,6 +2187,38 @@ For more information on `result_accuracy` see\n For StableHLO information see\n [StableHLO - cosine](https://openxla.org/stablehlo/spec#cosine).\n \n+## Cosh\n+\n+See also\n+[`XlaBuilder::Cosh`](https://github.com/openxla/xla/tree/main/xla/hlo/builder/xla_builder.h).\n+\n+Element-wise hyperbolic cosine `x -> cosh(x)`.\n+\n+**`Cosh(operand)`**\n+\n+Arguments | Type    | Semantics\n+--------- | ------- | ---------------------------\n+`operand` | `XlaOp` | The operand to the function\n+\n+Cosh also supports the optional `result_accuracy` argument:\n+\n+**`Cosh(operand, result_accuracy)`**\n+\n+| Arguments         | Type                      | Semantics                   |\n+| ----------------- | ------------------------- | --------------------------- |\n+| `operand`         | `XlaOp`                   | The operand to the function |\n+| `result_accuracy` | optional `ResultAccuracy` | The types of accuracy the   |\n+:                   :                           : user can request for unary  :\n+:                   :                           : ops with multiple           :\n+:                   :                           : implementations             :\n+\n+For more information on `result_accuracy` see\n+[Result Accuracy](https://github.com/openxla/stablehlo/blob/main/rfcs/20241015-result-accuracy.md).\n+\n+> **Note:** `Cosh` is only found in HLO and not found in StableHLO. CHLO `Cosh`\n+> in Frameworks will lower to HLO `Cosh` see\n+> [StableHLO - chlo.cosh](https://openxla.org/stablehlo/generated/chlo?hl=en#chlocosh_chlocoshop)\n+\n ## CustomCall\n \n See also"
        },
        {
            "sha": "7cb2332617cb995e60ace210e0ca85585038e639",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.cc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -1365,7 +1365,11 @@ XlaOp Atanh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n // +/-89.4159851, due to rounding error when computing x +/- log(1/2).  The\n // correct answer of 3.40281961e+38 (0x7f7fffec) is very close to max-float, so\n // we deem this acceptable.\n-XlaOp Cosh(XlaOp x) {\n+XlaOp Cosh(XlaOp x, const std::optional<ResultAccuracy>& result_accuracy,\n+           bool expand) {\n+  if (!expand) {\n+    return x.builder()->UnaryOp(HloOpcode::kCosh, x, result_accuracy);\n+  }\n   XlaBuilder* b = x.builder();\n   auto do_it = [&](XlaOp x) -> absl::StatusOr<XlaOp> {\n     TF_ASSIGN_OR_RETURN(auto shape, b->GetShape(x));"
        },
        {
            "sha": "90439b062ef2aa1038d328ef2a896b3f3deba59f",
            "filename": "third_party/xla/xla/hlo/builder/lib/math.h",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Flib%2Fmath.h?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -110,7 +110,9 @@ XlaOp Atanh(XlaOp x,\n             bool expand = true);\n \n // Computes the hyperbolic cosine of 'x'.\n-XlaOp Cosh(XlaOp x);\n+XlaOp Cosh(XlaOp x,\n+           const std::optional<ResultAccuracy>& result_accuracy = std::nullopt,\n+           bool expand = true);\n \n // Computes the hyperbolic sine of 'x'.\n XlaOp Sinh(XlaOp x);"
        },
        {
            "sha": "d54220c071398ef18de5661d93646507a2088c5f",
            "filename": "third_party/xla/xla/hlo/builder/xla_builder.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fxla_builder.h?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -1767,6 +1767,9 @@ class XlaBuilder {\n   friend XlaOp Clz(XlaOp operand);\n   friend XlaOp Cos(XlaOp operand,\n                    const std::optional<ResultAccuracy>& result_accuracy);\n+  friend XlaOp Cosh(XlaOp x,\n+                    const std::optional<ResultAccuracy>& result_accuracy,\n+                    bool expand);\n   friend XlaOp Sin(XlaOp operand,\n                    const std::optional<ResultAccuracy>& result_accuracy);\n   friend XlaOp Tan(XlaOp operand,"
        },
        {
            "sha": "ff170dcba8c80c3fd627292b3a9136a5cf191189",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/gen_hlo_op_writer.td",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fgen_hlo_op_writer.td?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -220,6 +220,7 @@ defvar CustomHloConverterOps = [\n   MHLO_ConvertOp,\n   MHLO_ConvolutionOp,\n   MHLO_CopyOp,\n+  MHLO_CoshOp,\n   MHLO_CosineOp,\n   MHLO_CustomCallOp,\n   MHLO_DomainOp,"
        },
        {
            "sha": "7c253dd7a95058ecf78b72303cae9cb69aacfce0",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/mlir_hlo_to_hlo.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Fmlir_hlo_to_hlo.cc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -5219,6 +5219,17 @@ LogicalResult ExportXlaOp(AcosOp op, OpLoweringContext ctx) {\n   return ExportElementwiseXlaOp<AcosOp, xla::Acos>(op, ctx);\n }\n \n+LogicalResult ExportXlaOp(CoshOp op, OpLoweringContext ctx) {\n+  auto& value_map = *ctx.values;\n+  xla::XlaOp operand;\n+  if (failed(GetXlaOp(op.getOperand(), value_map, &operand, op))) {\n+    return failure();\n+  }\n+  value_map[op] =\n+      xla::Cosh(operand, /*result_accuracy=*/std::nullopt, /*expand=*/false);\n+  return success();\n+}\n+\n LogicalResult ExportXlaOp(AcoshOp op, OpLoweringContext ctx) {\n   return ExportElementwiseXlaOp<AcoshOp, xla::Acosh>(op, ctx);\n }"
        },
        {
            "sha": "51186c37f0894561c2aeb6b58b59060a4be24ded",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2FBUILD?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -18,6 +18,7 @@ lit_test_suite(\n             \"call.mlir\",\n             \"case.mlir\",\n             \"composite.mlir\",\n+            \"cosh.mlir\",\n             \"dynamic.mlir\",\n             \"export-with-layouts.mlir\",\n             \"export.mlir\","
        },
        {
            "sha": "ce143833b36e72dc957a9c0129e172ede4dd494a",
            "filename": "third_party/xla/xla/hlo/translate/mhlo_to_hlo/tests/cosh.mlir",
            "status": "added",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fcosh.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fcosh.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftranslate%2Fmhlo_to_hlo%2Ftests%2Fcosh.mlir?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -0,0 +1,9 @@\n+// RUN: xla-translate -mlir-hlo-to-hlo-text %s | FileCheck %s\n+\n+module {\n+  func.func @main(%arg0: tensor<4xf32>) -> tensor<4xf32> {\n+    // CHECK: f32[4] cosh\n+    %0 = \"mhlo.cosh\"(%arg0) : (tensor<4xf32>) -> tensor<4xf32>\n+    func.return %0 : tensor<4xf32>\n+  }\n+}"
        },
        {
            "sha": "dab684bdafbab42189a2c05c3d2bce877ec69418",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/chlo_legalize_to_hlo/chlo_legalize_to_hlo_pass.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 4,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fchlo_legalize_to_hlo%2Fchlo_legalize_to_hlo_pass.cc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -51,26 +51,32 @@ namespace {\n \n ChloLegalizeToHighLevelMhloPassOptions FromPassOptions(bool enableAcosh,\n                                                        bool enableAcos,\n-                                                       bool enableAtanh) {\n+                                                       bool enableAtanh,\n+                                                       bool enableCosh) {\n   ChloLegalizeToHighLevelMhloPassOptions options;\n   options.enable_acosh_ = enableAcosh;\n   options.enable_acos_ = enableAcos;\n   options.enable_atanh_ = enableAtanh;\n+  options.enable_cosh_ = enableCosh;\n   return options;\n }\n \n-static bool qualifiesForDirectMhloLoweringAcosh(chlo::AcoshOp op) {\n+static bool qualifiesForDirectMhloLoweringAcos(chlo::AcosOp op) {\n   return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n-static bool qualifiesForDirectMhloLoweringAcos(chlo::AcosOp op) {\n+static bool qualifiesForDirectMhloLoweringAcosh(chlo::AcoshOp op) {\n   return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n static bool qualifiesForDirectMhloLoweringAtanh(chlo::AtanhOp op) {\n   return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n }\n \n+static bool qualifiesForDirectMhloLoweringCosh(chlo::CoshOp op) {\n+  return llvm::isa<FloatType>(getElementTypeOrSelf(op.getType()));\n+}\n+\n struct ChloLegalizeToHighLevelMhloPass\n     : public impl::ChloLegalizeToHighLevelMhloPassBase<\n           ChloLegalizeToHighLevelMhloPass> {\n@@ -87,7 +93,8 @@ struct ChloLegalizeToHighLevelMhloPass\n \n     chlo::populateChloToHighLevelMhloOpPatterns(\n         &context, &conversionPatterns,\n-        FromPassOptions(enable_acosh_, enable_acos_, enable_atanh_));\n+        FromPassOptions(enable_acosh_, enable_acos_, enable_atanh_,\n+                        enable_cosh_));\n \n     // Consider the mhlo dialect legal for tests. Also add helper dialects\n     // that are needed by the patterns.\n@@ -109,6 +116,11 @@ struct ChloLegalizeToHighLevelMhloPass\n             return !qualifiesForDirectMhloLoweringAtanh(op);\n           });\n     }\n+    if (enable_cosh_) {\n+      conversionTarget.addDynamicallyLegalOp<chlo::CoshOp>([](chlo::CoshOp op) {\n+        return !qualifiesForDirectMhloLoweringCosh(op);\n+      });\n+    }\n     conversionTarget\n         .addIllegalOp<chlo::TopKOp, chlo::ErfOp, chlo::RaggedDotOp>();\n \n@@ -233,6 +245,15 @@ LogicalResult convertAtanhChloToMhlo(chlo::AtanhOp op,\n   return success();\n }\n \n+LogicalResult convertCoshChloToMhlo(chlo::CoshOp op,\n+                                    PatternRewriter& rewriter) {\n+  if (!mhlo::qualifiesForDirectMhloLoweringCosh(op)) {\n+    return failure();\n+  }\n+  rewriter.replaceOpWithNewOp<mhlo::CoshOp>(op, op->getOperands());\n+  return success();\n+}\n+\n }  // namespace\n \n ChloLegalizeToHighLevelMhloPassOptions getDefaultChloToHighLevelMhloOptions() {\n@@ -244,6 +265,7 @@ ChloLegalizeToHighLevelMhloPassOptions getGpuChloToHighLevelMhloOptions() {\n   opts.enable_acosh_ = true;\n   opts.enable_acos_ = true;\n   opts.enable_atanh_ = true;\n+  opts.enable_cosh_ = true;\n   return opts;\n }\n \n@@ -267,6 +289,9 @@ void populateChloToHighLevelMhloOpPatterns(\n   if (options.enable_atanh_) {\n     patterns->add(mhlo::convertAtanhChloToMhlo, kBenefit);\n   }\n+  if (options.enable_cosh_) {\n+    patterns->add(mhlo::convertCoshChloToMhlo, kBenefit);\n+  }\n   patterns->add(mhlo::convertRaggedDotChloToMhlo, kBenefit);\n   populateWithGenerated(*patterns);\n }"
        },
        {
            "sha": "5edc5bd808aa26c23e00b4508b59606b05d64534",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_arithmetic/hlo_legalize_to_arithmetic.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_arithmetic%2Fhlo_legalize_to_arithmetic.cc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -209,6 +209,7 @@ void populateScalarHloToArithmeticConversionPatterns(\n       ScalarHloToArithmeticPattern<mhlo::ComplexOp>,\n       ScalarHloToArithmeticPattern<mhlo::ConvertOp>,\n       ScalarHloToArithmeticPattern<mhlo::CopyOp>,\n+      ScalarHloToArithmeticPattern<mhlo::CoshOp>,\n       ScalarHloToArithmeticPattern<mhlo::CosineOp>,\n       ScalarHloToArithmeticPattern<mhlo::DivOp>,\n       ScalarHloToArithmeticPattern<mhlo::ErfOp>,"
        },
        {
            "sha": "0253a32957fa1d094a4040da900c4ac5915cbfb0",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/hlo_legalize_to_stablehlo/hlo_legalize_to_stablehlo.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 17,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fhlo_legalize_to_stablehlo%2Fhlo_legalize_to_stablehlo.cc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -18,22 +18,20 @@ limitations under the License.\n #include <string>\n #include <type_traits>\n \n-#include \"llvm/ADT/ArrayRef.h\"\n-#include \"llvm/ADT/STLExtras.h\"\n #include \"llvm/ADT/SmallVector.h\"\n #include \"mhlo/IR/hlo_ops.h\"\n #include \"mhlo/transforms/map_stablehlo_to_hlo_op.h\"\n #include \"mhlo/transforms/rewriters.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/Diagnostics.h\"\n-#include \"mlir/IR/Location.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/Operation.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/SymbolTable.h\"\n-#include \"mlir/IR/Types.h\"\n+#include \"mlir/IR/ValueRange.h\"\n #include \"mlir/Support/DebugStringHelper.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Support/LogicalResult.h\"\n@@ -127,6 +125,11 @@ std::optional<int64_t> getPublicFeaturesNotInStablehlo(HloOpTy hloOp) {\n     // Version 1: Initial version for AtanhOp.\n     return 1;\n   }\n+  // StableHLO doesn't support Cosh yet.\n+  if constexpr (std::is_same<HloOpTy, mhlo::CoshOp>::value) {\n+    // Version 1: Initial version for CoshOp.\n+    return 1;\n+  }\n   return std::nullopt;\n }\n \n@@ -200,9 +203,10 @@ Attribute convertDenseArray(mlir::StringAttr hloName, Attribute hloAttr) {\n \n   // Handle DenseIntElementsAttr --> DenseI64ArrayAttr for StableHLO ops that\n   // use dense arrays. This is temporary while MHLO integrates this change.\n-  if (isDenseI64Array<StablehloOpTy>(hloName))\n+  if (isDenseI64Array<StablehloOpTy>(hloName)) {\n     return DenseI64ArrayAttr::get(\n         hloAttr.getContext(), llvm::to_vector(denseInts.getValues<int64_t>()));\n+  }\n \n   return {};\n }\n@@ -398,12 +402,13 @@ FailureOr<func::FuncOp> rewriteMhloRegionAsFunc(\n   // Must be isolated from above\n   SetVector<Value> values;\n   getUsedValuesDefinedAbove(region, values);\n-  if (!values.empty())\n+  if (!values.empty()) {\n     return notifyConversionFailure(\n         rewriter, op,\n         \"MHLO feature serialization in StableHLO only supports regions that \"\n         \"do not capture SSA values from above\",\n         op);\n+  }\n \n   // Insert into the parent module\n   OpBuilder::InsertionGuard g(rewriter);\n@@ -412,9 +417,10 @@ FailureOr<func::FuncOp> rewriteMhloRegionAsFunc(\n \n   // Convert so that function signature is correct\n   if (failed(rewriter.convertRegionTypes(&region, *typeConverter,\n-                                         /*entryConversion=*/nullptr)))\n+                                         /*entryConversion=*/nullptr))) {\n     return notifyConversionFailure(rewriter, op,\n                                    \"failed to convert region types\", op);\n+  }\n \n   // Create function with args that match block inputs / return types\n   rewriter.setInsertionPointToEnd(&module.getBodyRegion().front());\n@@ -456,19 +462,22 @@ LogicalResult convertAttributes(ConversionPatternRewriter& rewriter,\n     if constexpr (!std::is_same<HloOpTy, mhlo::AcosOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::AcoshOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::AtanhOp>::value &&\n+                  !std::is_same<HloOpTy, mhlo::CoshOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::ErfOp>::value &&\n                   !std::is_same<HloOpTy, mhlo::TopKOp>::value) {\n-      if (!stablehloAttr)\n+      if (!stablehloAttr) {\n         stablehloAttr = convertDenseArray<HloToStablehloOp<HloOpTy>>(\n             hloAttr.getName(), hloAttr.getValue());\n+      }\n     }\n \n     // Generic handler for all other attributes\n     if (!stablehloAttr) stablehloAttr = convertAttr(hloAttr.getValue());\n \n-    if (!stablehloAttr)\n+    if (!stablehloAttr) {\n       return notifyConversionFailure(rewriter, hloOp, \"failed to convert attr \",\n                                      hloAttr.getValue());\n+    }\n     stablehloAttrs.push_back({hloAttr.getName(), stablehloAttr});\n   }\n   return success();\n@@ -500,10 +509,11 @@ LogicalResult rewriteMhloOpAsCustomCall(HloOpTy hloOp,\n \n   // Convert MHLO attributes to StableHLO equivalents.\n   SmallVector<Type> stablehloTypes;\n-  if (failed(\n-          typeConverter->convertTypes(hloOp->getResultTypes(), stablehloTypes)))\n+  if (failed(typeConverter->convertTypes(hloOp->getResultTypes(),\n+                                         stablehloTypes))) {\n     return notifyConversionFailure(rewriter, hloOp,\n                                    \"failed to convert op types\", hloOp);\n+  }\n \n   // Convert MHLO attributes to StableHLO equivalents.\n   SmallVector<NamedAttribute> stablehloConvertedAttrs;\n@@ -524,14 +534,16 @@ LogicalResult rewriteMhloOpAsCustomCall(HloOpTy hloOp,\n       \"call_target_name\", rewriter.getStringAttr(stablehloCallTargetName)));\n   stablehloAttrs.push_back(rewriter.getNamedAttr(\n       \"mhlo.attributes\", rewriter.getDictionaryAttr(stablehloConvertedAttrs)));\n-  if (stablehloConvertedRegion)\n+  if (stablehloConvertedRegion) {\n     stablehloAttrs.push_back(rewriter.getNamedAttr(\n         \"called_computations\",\n         rewriter.getArrayAttr(FlatSymbolRefAttr::get(\n             rewriter.getContext(), stablehloConvertedRegion->getSymName()))));\n-  if (auto featureVersion = getPublicFeaturesNotInStablehlo(hloOp))\n+  }\n+  if (auto featureVersion = getPublicFeaturesNotInStablehlo(hloOp)) {\n     stablehloAttrs.push_back(rewriter.getNamedAttr(\n         \"mhlo.version\", rewriter.getI64IntegerAttr(featureVersion.value())));\n+  }\n   rewriter.replaceOpWithNewOp<stablehlo::CustomCallOp>(\n       hloOp, stablehloTypes, stablehloOperands, stablehloAttrs);\n   return success();\n@@ -552,14 +564,16 @@ class HloToStablehloCustomCallOpConverter\n   LogicalResult matchAndRewrite(\n       HloOpTy hloOp, typename HloOpTy::Adaptor adaptor,\n       ConversionPatternRewriter& rewriter) const final {\n-    if (hasPrivateFeaturesNotInStablehlo(hloOp))\n+    if (hasPrivateFeaturesNotInStablehlo(hloOp)) {\n       return notifyConversionFailure(\n           rewriter, hloOp, \"op has private features not in StableHLO\", hloOp);\n+    }\n     bool hasExperimentalFeatures = hasExperimentalFeaturesNotInStablehlo(hloOp);\n-    if (!allowExperimentalFeatures && hasExperimentalFeatures)\n+    if (!allowExperimentalFeatures && hasExperimentalFeatures) {\n       return notifyConversionFailure(\n           rewriter, hloOp,\n           \"op has experimental features, but conversion not enabled\", hloOp);\n+    }\n     auto hasPublicFeatures = hasPublicFeaturesNotInStablehlo(hloOp);\n     if (hasPublicFeatures || hasExperimentalFeatures) {\n       return rewriteMhloOpAsCustomCall(\n@@ -742,8 +756,9 @@ void populateHloToStablehloPatterns(RewritePatternSet* patterns,\n       patterns, converter, context, allowExperimentalFeatures,\n       allowXlaFeatures);\n \n-  populateHloToStablehloCustomCallPatterns<\n-      mhlo::AcosOp, mhlo::AcoshOp, mhlo::AtanhOp, mhlo::ErfOp, mhlo::TopKOp>(\n+  populateHloToStablehloCustomCallPatterns<mhlo::AcosOp, mhlo::AcoshOp,\n+                                           mhlo::AtanhOp, mhlo::CoshOp,\n+                                           mhlo::ErfOp, mhlo::TopKOp>(\n       patterns, converter, context, allowExperimentalFeatures);\n }\n "
        },
        {
            "sha": "0ceb6ca465599fbfe1d8edf9ec1532f7854c6ebe",
            "filename": "third_party/xla/xla/mlir_hlo/mhlo/transforms/mhlo_passes.td",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fmhlo%2Ftransforms%2Fmhlo_passes.td?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -28,7 +28,9 @@ def ChloLegalizeToHighLevelMhloPass : Pass<\"chlo-legalize-to-high-level-mhlo\", \"\n     Option<\"enable_acos_\", \"enable-acos\", \"bool\", /*default=*/\"false\",\n            \"Enable chlo.acos to mhlo.acos lowering.\">,\n     Option<\"enable_atanh_\", \"enable-atanh\", \"bool\", /*default=*/\"false\",\n-           \"Enable chlo.atanh to mhlo.atanh lowering.\">\n+           \"Enable chlo.atanh to mhlo.atanh lowering.\">,\n+    Option<\"enable_cosh_\", \"enable-cosh\", \"bool\", /*default=*/\"false\",\n+           \"Enable chlo.cosh to mhlo.cosh lowering.\">\n   ];\n   let dependentDialects = [\"mhlo::MhloDialect\"];\n }"
        },
        {
            "sha": "a4334cbe70e735118486560c10a8c8fa1f8b9fcf",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_preserve_high_level_ops.cpp",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_preserve_high_level_ops.cpp?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -257,6 +257,15 @@ struct AtanhOpToCustomCallPattern : public OpRewritePattern<chlo::AtanhOp> {\n   }\n };\n \n+struct CoshOpToCustomCallPattern : public OpRewritePattern<chlo::CoshOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::CoshOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOperationInCustomCall(rewriter, op, \"mhlo.cosh\",\n+                                         /*version=*/1);\n+  }\n+};\n+\n ///////\n // CHLO to CompositeOp Patterns\n ///////\n@@ -324,6 +333,14 @@ struct AtanhOpToCompositePattern : public OpRewritePattern<chlo::AtanhOp> {\n   }\n };\n \n+struct CoshOpToCompositePattern : public OpRewritePattern<chlo::CoshOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(chlo::CoshOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return wrapChloOpInComposite(op, /*version=*/1, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloPreserveHighLevelOpsPass\n@@ -350,6 +367,7 @@ struct ChloPreserveHighLevelOpsPass\n         AcosOpToCustomCallPattern,\n         AcoshOpToCustomCallPattern,\n         AtanhOpToCustomCallPattern,\n+        CoshOpToCustomCallPattern,\n         ErfOpToCustomCallPattern,\n         RaggedDotOpToCustomCallPattern,\n         TopKOpToCustomCallPattern>(ctx);\n@@ -358,6 +376,7 @@ struct ChloPreserveHighLevelOpsPass\n         AcosOpToCompositePattern,\n         AcoshOpToCompositePattern,\n         AtanhOpToCompositePattern,\n+        CoshOpToCompositePattern,\n         ErfOpToCompositePattern,\n         RaggedDotOpToCompositePattern,\n         TopKOpToCompositePattern>(ctx);"
        },
        {
            "sha": "d284c0cbf468291470b4d35bcb45c6c102690c8b",
            "filename": "third_party/xla/xla/mlir_hlo/stablehlo_ext/transforms/chlo_recompose_ops.cpp",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Fstablehlo_ext%2Ftransforms%2Fchlo_recompose_ops.cpp?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -296,6 +296,22 @@ struct AtanhOpRecomposePattern\n   }\n };\n \n+struct CoshOpRecomposePattern\n+    : public OpRewritePattern<stablehlo::CompositeOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n+                                PatternRewriter& rewriter) const override {\n+    if (op.getName() != \"chlo.cosh\") {\n+      return rewriter.notifyMatchFailure(op, \"not a chlo.cosh\");\n+    }\n+    if (op.getVersion() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"unsupported version for chlo.cosh composite\");\n+    }\n+    return recomposeChloOpFromCompositeOp<chlo::CoshOp>(op, rewriter);\n+  }\n+};\n+\n struct ErfOpRecomposePattern : public OpRewritePattern<stablehlo::CompositeOp> {\n   using OpRewritePattern::OpRewritePattern;\n   LogicalResult matchAndRewrite(stablehlo::CompositeOp op,\n@@ -415,6 +431,16 @@ struct AtanhOpCustomCallRecomposePattern\n   }\n };\n \n+struct CoshOpCustomCallRecomposePattern\n+    : public OpRewritePattern<stablehlo::CustomCallOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  LogicalResult matchAndRewrite(stablehlo::CustomCallOp op,\n+                                PatternRewriter& rewriter) const override {\n+    return recomposeChloOpFromCustomCall<chlo::CoshOp>(\n+        op, {\"mhlo.cosh\", \"chlo.cosh\"}, rewriter);\n+  }\n+};\n+\n }  // namespace\n \n struct ChloRecomposeOpsPass\n@@ -438,6 +464,7 @@ struct ChloRecomposeOpsPass\n       AcosOpCustomCallRecomposePattern,\n       AcoshOpCustomCallRecomposePattern,\n       AtanhOpCustomCallRecomposePattern,\n+      CoshOpCustomCallRecomposePattern,\n       ErfOpCustomCallRecomposePattern,\n       RaggedDotOpCustomCallRecomposePattern,\n       TanOpCustomCallRecomposePattern,\n@@ -448,6 +475,7 @@ struct ChloRecomposeOpsPass\n       AcosOpRecomposePattern,\n       AcoshOpRecomposePattern,\n       AtanhOpRecomposePattern,\n+      CoshOpRecomposePattern,\n       ErfOpRecomposePattern,\n       RaggedDotOpRecomposePattern,\n       TopKOpRecomposePattern>(ctx);"
        },
        {
            "sha": "238a0a57996f84a6fa4f166f5de69326a2fe43ae",
            "filename": "third_party/xla/xla/mlir_hlo/tests/Dialect/chlo/chlo_legalize_to_mhlo.mlir",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2FDialect%2Fchlo%2Fchlo_legalize_to_mhlo.mlir?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -1,5 +1,5 @@\n // RUN: mlir-hlo-opt --chlo-legalize-to-hlo --split-input-file -verify-diagnostics %s | FileCheck %s --dump-input-context=20\n-// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n+// RUN: mlir-hlo-opt --chlo-legalize-to-high-level-mhlo=\"enable-acosh enable-acos enable-atanh enable-cosh\" --split-input-file -verify-diagnostics %s | FileCheck %s --check-prefix=CHECK-HIGH-LEVEL\n \n // CHECK-LABEL: func.func @asin_bf16(\n // CHECK-SAME:    %[[TMP_arg0:.*]]: tensor<bf16>\n@@ -2675,6 +2675,7 @@ func.func @sinh_complex(%x : tensor<2xcomplex<f32>>) -> tensor<2xcomplex<f32>> {\n // CHECK-LABEL: @cosh_f32\n // CHECK-SAME: (%[[X:.*]]: tensor<f32>)\n func.func @cosh_f32(%x : tensor<f32>) -> tensor<f32> {\n+  // CHECK-HIGH-LEVEL: mhlo.cosh\n   // CHECK: %[[HALF:.*]] = mhlo.constant dense<5.000000e-01> : tensor<f32>\n   // CHECK: %[[LOG_HALF:.*]] = mhlo.log %[[HALF]] : tensor<f32>\n   // CHECK: %[[X_PLUS_LOG_HALF:.*]] = mhlo.add %[[X]], %[[LOG_HALF]] : tensor<f32>"
        },
        {
            "sha": "b52f88e48c6c017cc7d57ae516ec756d161735fa",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_preserve_high_level_ops.mlir",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_preserve_high_level_ops.mlir?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -103,6 +103,16 @@ func.func @atanh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n \n // -----\n \n+// CHECK-LABEL: func @cosh_preserve\n+func.func @cosh_preserve(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-CC: stablehlo.custom_call @mhlo.cosh(%arg0) {mhlo.attributes = {}, mhlo.version = 1 : i64} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  // CHECK: stablehlo.composite \"chlo.cosh\" %arg0 {decomposition = @chlo.cosh.impl, version = 1 : i32}\n+  %0 = chlo.cosh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @tan_no_preserve\n func.func @tan_no_preserve(%arg0: tensor<16xf32>) -> tensor<?xf32> {\n   // CHECK: chlo.tan"
        },
        {
            "sha": "6c5eff8348a370f7e4d0d0a8cb232d4a9bd0b380",
            "filename": "third_party/xla/xla/mlir_hlo/tests/stablehlo_ext/chlo_recompose_ops.mlir",
            "status": "modified",
            "additions": 32,
            "deletions": 3,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fmlir_hlo%2Ftests%2Fstablehlo_ext%2Fchlo_recompose_ops.mlir?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -10,7 +10,7 @@ func.func @erf_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x2\n   %0 = stablehlo.composite \"chlo.erf\" %arg0 {decomposition = @chlo.erf.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n }\n-// CHECK-NOT: @chlo.erf.imp\n+// CHECK-NOT: @chlo.erf.impl\n func.func private @chlo.erf.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n   %0 = chlo.erf %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n@@ -25,7 +25,7 @@ func.func @acosh_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20\n   %0 = stablehlo.composite \"chlo.acosh\" %arg0 {decomposition = @chlo.acosh.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n }\n-// CHECK-NOT: @chlo.acosh.imp\n+// CHECK-NOT: @chlo.acosh.impl\n func.func private @chlo.acosh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n   %0 = chlo.acosh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n@@ -55,14 +55,29 @@ func.func @acos_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x\n   %0 = stablehlo.composite \"chlo.acos\" %arg0 {decomposition = @chlo.acos.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n }\n-// CHECK-NOT: @chlo.acos.imp\n+// CHECK-NOT: @chlo.acos.impl\n func.func private @chlo.acos.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n   %0 = chlo.acos %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n   return %0 : tensor<?x20x20xbf16>\n }\n \n // -----\n \n+// CHECK-LABEL: func @cosh_recompose_composite\n+func.func @cosh_recompose_composite(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK-NEXT: chlo.cosh\n+  // CHECK-NOT: stablehlo.composite\n+  %0 = stablehlo.composite \"chlo.cosh\" %arg0 {decomposition = @chlo.cosh.impl, version = 1 : i32} : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+// CHECK-NOT: @chlo.cosh.impl\n+func.func private @chlo.cosh.impl(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  %0 = chlo.cosh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_composite\n func.func @ragged_dot_recompose_composite(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>\n@@ -152,6 +167,20 @@ func.func @atanh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf1\n \n // -----\n \n+// CHECK-LABEL: @cosh_recompose_cc\n+func.func @cosh_recompose_cc(%arg0: tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16> {\n+  // CHECK: %0 = chlo.cosh %arg0 : tensor<3x20x20xbf16> -> tensor<?x20x20xbf16>\n+  %0 = \"stablehlo.custom_call\"(%arg0) {\n+    backend_config = \"\",\n+    call_target_name = \"mhlo.cosh\",\n+    mhlo.attributes = {},\n+    mhlo.version = 1 : i64\n+  } : (tensor<3x20x20xbf16>) -> tensor<?x20x20xbf16>\n+  func.return %0 : tensor<?x20x20xbf16>\n+}\n+\n+// -----\n+\n // CHECK-LABEL: func @ragged_dot_recompose_cc\n func.func @ragged_dot_recompose_cc(%arg0: tensor<2x11x5xf32>, %arg1: tensor<3x2x5x7xf32>, %arg2: tensor<3xi64>) -> tensor<2x11x7xf32> {\n   // CHECK: \"chlo.ragged_dot\"(%arg0, %arg1, %arg2) <{precision_config = [#chlo<precision DEFAULT>, #chlo<precision DEFAULT>], ragged_dot_dimension_numbers = #chlo.ragged_dot<lhs_batching_dimensions = [0], rhs_batching_dimensions = [1], lhs_contracting_dimensions = [2], rhs_contracting_dimensions = [2], lhs_ragged_dimensions = [1], rhs_group_dimensions = [0]>}> : (tensor<2x11x5xf32>, tensor<3x2x5x7xf32>, tensor<3xi64>) -> tensor<2x11x7xf32>"
        },
        {
            "sha": "104ee4a8629785b064d2bfa5a072bb720bc8dbb9",
            "filename": "third_party/xla/xla/tests/exhaustive/exhaustive_unary_test_ops.inc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e0a7cd60c584b955065a5c6dfc68ce50455145b0/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fexhaustive%2Fexhaustive_unary_test_ops.inc?ref=e0a7cd60c584b955065a5c6dfc68ce50455145b0",
            "patch": "@@ -207,7 +207,8 @@ DEFINE_UNARY_TEST_OP(\n     AcosOp, { return [](XlaOp x) { return Acos(x); }; }, { return std::acos; });\n DEFINE_UNARY_TEST_OP(AsinOp, { return Asin; }, { return std::asin; });\n DEFINE_UNARY_TEST_OP(AtanOp, { return Atan; }, { return std::atan; });\n-DEFINE_UNARY_TEST_OP(CoshOp, { return Cosh; }, { return std::cosh; });\n+DEFINE_UNARY_TEST_OP(\n+    CoshOp, { return [](XlaOp x) { return Cosh(x); }; }, { return std::cosh; });\n DEFINE_UNARY_TEST_OP(SinhOp, { return Sinh; }, { return std::sinh; });\n DEFINE_UNARY_TEST_OP(\n     TanhOp, { return [](XlaOp x) { return Tanh(x); }; }, { return std::tanh; });"
        }
    ],
    "stats": {
        "total": 252,
        "additions": 223,
        "deletions": 29
    }
}