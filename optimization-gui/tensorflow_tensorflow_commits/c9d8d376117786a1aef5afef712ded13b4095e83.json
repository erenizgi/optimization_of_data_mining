{
    "author": "chsigg",
    "message": "[xla:gpu] Relax nested gemm fusion constraints.\n\nThis change removes dimension ordering constraints in `AcceptDotOperand`.\n\nPiperOrigin-RevId: 820542964",
    "sha": "c9d8d376117786a1aef5afef712ded13b4095e83",
    "files": [
        {
            "sha": "ff3b3d211820d4434efb2e1d87c9c3ffba68f75e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/cudnn_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc?ref=c9d8d376117786a1aef5afef712ded13b4095e83",
            "patch": "@@ -1097,8 +1097,7 @@ ENTRY e {\n ; CHECK: ENTRY\n ; CHECK-NEXT: parameter\n ; CHECK-NEXT: parameter\n-; CHECK-NEXT: ROOT\n-; CHECK-SAME: fusion\n+; CHECK-NEXT: fusion\n ; CHECK-NOT: cudnn\n )\");\n }"
        },
        {
            "sha": "f252a9c9d8ce0996525f5704caed26259867639a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/dot_algorithms_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fdot_algorithms_test.cc?ref=c9d8d376117786a1aef5afef712ded13b4095e83",
            "patch": "@@ -1819,7 +1819,8 @@ class PrecisionTests\n     module->mutable_config().set_debug_options(debug_options);\n     TF_ASSIGN_OR_RETURN(module, GetOptimizedModule(std::move(module)));\n     if (backend == Backend::kTriton) {\n-      TF_RETURN_IF_ERROR(CheckGemmPattern(*module, \"CHECK: __triton_gemm\"));\n+      TF_RETURN_IF_ERROR(CheckGemmPattern(\n+          *module, \"CHECK: {{__triton_gemm|__triton_nested_gemm_fusion}}\"));\n     } else if (backend == Backend::kBlas) {\n       TF_RETURN_IF_ERROR(CheckGemmPattern(*module, \"CHECK: __cublas$gemm\"));\n     } else {"
        },
        {
            "sha": "2fe109810a910f5c2a70d97d98f9b6b49cb72163",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler_test.cc?ref=c9d8d376117786a1aef5afef712ded13b4095e83",
            "patch": "@@ -833,7 +833,7 @@ ENTRY main {\n                      .rocm_compute_capability();\n \n   const std::string triton_keep_types = absl::Substitute(\n-      R\"(CHECK: fusion($0{{[^)]*}}, $1{{[^)]*}}){{.*}}\"kind\":\"__triton_gemm\")\",\n+      R\"(CHECK: fusion($0{{[^)]*}}, $1{{[^)]*}}){{.*}}\"kind\":\"{{__triton_gemm|__triton_nested_gemm_fusion}}\")\",\n       lhs_name, rhs_name);\n   const std::string cublaslt_keep_types = absl::Substitute(\n       R\"(CHECK: custom-call($0{{[^)]*}}, $1{{[^)]*}}){{.*}}custom_call_target=\"__cublas$$lt$$matmul$$f8\")\","
        },
        {
            "sha": "d3c9da510d762d1af3497adbd7ddd6f21e727542",
            "filename": "third_party/xla/xla/service/gpu/nvptx_compiler_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler_test.cc?ref=c9d8d376117786a1aef5afef712ded13b4095e83",
            "patch": "@@ -182,9 +182,7 @@ ENTRY e {\n   if (cc.IsAtLeastAmpere()) {\n     MatchOptimizedHlo(hlo_string, R\"(\n ; CHECK: ENTRY\n-; CHECK-NEXT: parameter\n-; CHECK-NEXT: parameter\n-; CHECK-NEXT: __triton_gemm\n+; CHECK: __triton_nested_gemm_fusion\n     )\");\n   } else {\n     MatchOptimizedHlo(hlo_string, R\"("
        },
        {
            "sha": "b37d5686fd69af3f065e230e306dcc30996387aa",
            "filename": "third_party/xla/xla/service/gpu/transforms/nest_gemm_fusion.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 31,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/c9d8d376117786a1aef5afef712ded13b4095e83/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fnest_gemm_fusion.cc?ref=c9d8d376117786a1aef5afef712ded13b4095e83",
            "patch": "@@ -1122,41 +1122,22 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n  private:\n   absl::Status AcceptDotOperand(const HloInstruction* operand,\n                                 absl::Span<const int64_t> batch_dims,\n-                                absl::Span<const int64_t> contracting_dims,\n-                                bool is_lhs) {\n+                                absl::Span<const int64_t> contracting_dims) {\n     if (contracting_dims.size() != 1) {\n-      return absl::InternalError(\n-          absl::StrCat(\"Expected \", is_lhs ? \"LHS\" : \"RHS\",\n-                       \" operand with exactly one contracting dimension, got \",\n-                       contracting_dims.size()));\n+      return absl::InternalError(absl::StrCat(\n+          \"Expected operand with exactly one contracting dimension, got \",\n+          contracting_dims.size()));\n     }\n \n     TF_ASSIGN_OR_RETURN(\n         std::vector<int64_t> non_contracting_dimensions,\n         GetNonContractingDims(operand->shape(), batch_dims, contracting_dims));\n-\n     if (non_contracting_dimensions.size() != 1) {\n       return absl::InternalError(absl::StrCat(\n-          \"Expected \", is_lhs ? \"LHS\" : \"RHS\",\n-          \" operand with exactly one non-contracting dimension, got \",\n+          \"Expected operand with exactly one non-contracting dimension, got \",\n           non_contracting_dimensions.size()));\n     }\n \n-    if (is_lhs) {\n-      if (non_contracting_dimensions[0] >= contracting_dims[0]) {\n-        return absl::InternalError(absl::StrCat(\n-            \"Expected LHS non-contracting dimension to be before contracting \"\n-            \"dimension, got \",\n-            non_contracting_dimensions[0], \" >= \", contracting_dims[0]));\n-      }\n-    } else {\n-      if (non_contracting_dimensions[0] <= contracting_dims[0]) {\n-        return absl::InternalError(absl::StrCat(\n-            \"Expected RHS non-contracting dimension to be after contracting \"\n-            \"dimension, got \",\n-            non_contracting_dimensions[0], \" <= \", contracting_dims[0]));\n-      }\n-    }\n     return absl::OkStatus();\n   }\n \n@@ -1170,11 +1151,9 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n     const HloInstruction* rhs = dot->operand(1);\n     auto dims = dot->dot_dimension_numbers();\n     TF_RETURN_IF_ERROR(AcceptDotOperand(lhs, dims.lhs_batch_dimensions(),\n-                                        dims.lhs_contracting_dimensions(),\n-                                        /*is_lhs=*/true));\n+                                        dims.lhs_contracting_dimensions()));\n     TF_RETURN_IF_ERROR(AcceptDotOperand(rhs, dims.rhs_batch_dimensions(),\n-                                        dims.rhs_contracting_dimensions(),\n-                                        /*is_lhs=*/false));\n+                                        dims.rhs_contracting_dimensions()));\n     return absl::OkStatus();\n   }\n \n@@ -1183,10 +1162,9 @@ class NestGemmFusionVisitor : public DfsHloRewriteVisitor {\n       return absl::OkStatus();\n     }\n     switch (instruction->opcode()) {\n-      case HloOpcode::kParameter:\n-      case HloOpcode::kConstant:\n-        return absl::OkStatus();\n       case HloOpcode::kBroadcast:\n+      case HloOpcode::kConstant:\n+      case HloOpcode::kParameter:\n         return absl::OkStatus();\n       case HloOpcode::kFusion:\n         return AcceptResultingFusion(Cast<HloFusionInstruction>(instruction));"
        }
    ],
    "stats": {
        "total": 52,
        "additions": 14,
        "deletions": 38
    }
}