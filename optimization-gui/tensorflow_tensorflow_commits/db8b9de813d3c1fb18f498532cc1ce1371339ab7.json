{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 845648984",
    "sha": "db8b9de813d3c1fb18f498532cc1ce1371339ab7",
    "files": [
        {
            "sha": "1813f7e9e020059d3e3d4fb8250e9ed6a6c78d1a",
            "filename": "tensorflow/core/kernels/data/batch_dataset_op.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fbatch_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fbatch_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fbatch_dataset_op.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -73,7 +73,7 @@ class BatchDatasetOp::Dataset : public DatasetBase {\n         op_version_(op_version),\n         traceme_metadata_(\n             {{\"batch_size\",\n-              strings::Printf(\"%lld\", static_cast<long long>(batch_size))},\n+              absl::StrFormat(\"%lld\", static_cast<long long>(batch_size))},\n              {\"drop_remainder\", drop_remainder ? \"true\" : \"false\"},\n              {\"parallel_copy\", parallel_copy ? \"true\" : \"false\"}}) {\n     input_->Ref();\n@@ -106,7 +106,7 @@ class BatchDatasetOp::Dataset : public DatasetBase {\n   ~Dataset() override { input_->Unref(); }\n \n   std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-      const string& prefix) const override {\n+      const std::string& prefix) const override {\n     name_utils::IteratorPrefixParams params;\n     params.op_version = op_version_;\n     return std::make_unique<Iterator>(Iterator::Params{\n@@ -121,7 +121,7 @@ class BatchDatasetOp::Dataset : public DatasetBase {\n     return output_shapes_;\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     name_utils::DatasetDebugStringParams params;\n     params.op_version = op_version_;\n     params.set_args(batch_size_);\n@@ -146,9 +146,9 @@ class BatchDatasetOp::Dataset : public DatasetBase {\n     return input_->CheckExternalState();\n   }\n \n-  absl::Status Get(OpKernelContext* ctx, int64 index,\n+  absl::Status Get(OpKernelContext* ctx, int64_t index,\n                    std::vector<Tensor>* out_tensors) const override {\n-    const int64 cardinality = Cardinality();\n+    const int64_t cardinality = Cardinality();\n     if (index < 0 || index >= cardinality) {\n       return errors::OutOfRange(\"Index out of range [0, \", cardinality,\n                                 \"):\", index);"
        },
        {
            "sha": "ad5ba2464ce9c3472236c1f298bcc74648fa007a",
            "filename": "tensorflow/core/kernels/data/cache_dataset_ops.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -86,7 +86,7 @@ class DatasetRandomAccessCache {\n \n   // Extends the temporary cache up to a given index and then updates\n   // out_tensors with the element at that index.\n-  absl::Status Get(OpKernelContext* ctx, int64 index,\n+  absl::Status Get(OpKernelContext* ctx, int64_t index,\n                    std::vector<Tensor>* out_tensors) {\n     if (!iter_resource_) {\n       TF_ASSIGN_OR_RETURN(iter_resource_,\n@@ -104,7 +104,7 @@ class DatasetRandomAccessCache {\n   std::vector<std::vector<Tensor>> GetCacheData() { return cache_; }\n \n  private:\n-  absl::Status ExtendTempCacheToIndex(int64 index, OpKernelContext* ctx) {\n+  absl::Status ExtendTempCacheToIndex(int64_t index, OpKernelContext* ctx) {\n     bool end_of_sequence;\n     while (cache_.size() <= index) {\n       std::vector<Tensor> out_tensors;\n@@ -169,7 +169,7 @@ class IteratorRandomAccessCache {\n class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n  public:\n   FileDatasetBase(OpKernelContext* ctx, const DatasetBase* input,\n-                  string filename, Env* env)\n+                  std::string filename, Env* env)\n       : DatasetBase(DatasetContext(ctx)),\n         input_(input),\n         filename_(std::move(filename)),\n@@ -184,7 +184,7 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n   ~FileDatasetBase() override { input_->Unref(); }\n \n   std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-      const string& prefix) const override {\n+      const std::string& prefix) const override {\n     name_utils::IteratorPrefixParams params;\n     params.dataset_prefix = kFileDatasetPrefix;\n     return std::make_unique<FileIterator>(FileIterator::Params{\n@@ -199,7 +199,7 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n     return input_->output_shapes();\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     name_utils::DatasetDebugStringParams params;\n     params.dataset_prefix = kFileDatasetPrefix;\n     return name_utils::DatasetDebugString(kDatasetType, params);\n@@ -225,7 +225,7 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n \n  private:\n   static size_t StringPaddingSize(size_t num_tensors) {\n-    return strings::Printf(kPaddingSizeStrFormat, num_tensors - 1).size();\n+    return absl::StrFormat(kPaddingSizeStrFormat, num_tensors - 1).size();\n   }\n \n   std::string FormatName(size_t item_index, size_t tensor_index) const {\n@@ -328,14 +328,14 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n       ~FileWriterIterator() override {\n         if (!dataset()->env_->FileExists(MetaFilename(filename_)).ok()) {\n           LOG(WARNING) << kIncompleteCacheErrorMessage;\n-          std::vector<string> cache_files;\n+          std::vector<std::string> cache_files;\n           absl::Status s = dataset()->env_->GetMatchingPaths(\n               absl::StrCat(filename_, \"*\"), &cache_files);\n           if (!s.ok()) {\n             LOG(WARNING) << \"Failed to get matching files on \" << filename_\n                          << \"* : \" << s.ToString();\n           }\n-          for (const string& path : cache_files) {\n+          for (const std::string& path : cache_files) {\n             s = dataset()->env_->DeleteFile(path);\n             if (!s.ok()) {\n               LOG(WARNING) << \"Failed to delete \" << path << \" : \"\n@@ -387,7 +387,7 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n         size_t tensor_index = 0;\n         for (const Tensor& t : *out_tensors) {\n           DCHECK_LT(tensor_index, dataset()->num_tensors_);\n-          string key = dataset()->FormatName(cur_index_, tensor_index++);\n+          std::string key = dataset()->FormatName(cur_index_, tensor_index++);\n           TF_RETURN_IF_ERROR(writer_->Add(key, t));\n         }\n         if (*end_of_sequence) {\n@@ -576,9 +576,9 @@ class CacheDatasetOp::FileDatasetBase : public DatasetBase {\n       std::unique_ptr<IteratorBase> input_impl_ TF_GUARDED_BY(mu_);\n       // The current prefix for the cache file. This is equal to\n       // `StrCat(dataset()->filename_, \"_\", shard_id_)`.\n-      string filename_;\n+      std::string filename_;\n       std::unique_ptr<BundleWriter> writer_ TF_GUARDED_BY(mu_);\n-      string lockfile_ TF_GUARDED_BY(mu_);\n+      std::string lockfile_ TF_GUARDED_BY(mu_);\n       bool lockfile_created_ TF_GUARDED_BY(mu_);\n       bool iteration_completed_ TF_GUARDED_BY(mu_);\n     };  // FileWriterIterator\n@@ -730,7 +730,7 @@ class CacheDatasetOp::FileDataset : public CacheDatasetOp::FileDatasetBase {\n class CacheDatasetOp::FileDatasetV2 : public CacheDatasetOp::FileDatasetBase {\n  public:\n   explicit FileDatasetV2(OpKernelContext* ctx, const DatasetBase* input,\n-                         string filename, Env* env,\n+                         std::string filename, Env* env,\n                          const Tensor& resource_handle)\n       : FileDatasetBase(ctx, input, filename, env),\n         resource_handle_(resource_handle) {}\n@@ -768,7 +768,7 @@ class CacheDatasetOp::MemoryDatasetBase : public DatasetBase {\n   ~MemoryDatasetBase() override { input_->Unref(); }\n \n   std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-      const string& prefix) const override {\n+      const std::string& prefix) const override {\n     name_utils::IteratorPrefixParams params;\n     params.dataset_prefix = kMemoryDatasetPrefix;\n     return std::make_unique<MemoryIterator>(\n@@ -785,7 +785,7 @@ class CacheDatasetOp::MemoryDatasetBase : public DatasetBase {\n     return input_->output_shapes();\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     name_utils::DatasetDebugStringParams params;\n     params.dataset_prefix = kMemoryDatasetPrefix;\n     return name_utils::DatasetDebugString(kDatasetType, params);\n@@ -795,7 +795,7 @@ class CacheDatasetOp::MemoryDatasetBase : public DatasetBase {\n     return input_->Cardinality(options);\n   };\n \n-  absl::Status Get(OpKernelContext* ctx, int64 index,\n+  absl::Status Get(OpKernelContext* ctx, int64_t index,\n                    std::vector<Tensor>* out_tensors) const override {\n     mutex_lock l(mu_);\n \n@@ -815,7 +815,7 @@ class CacheDatasetOp::MemoryDatasetBase : public DatasetBase {\n     return dataset_random_access_cache_->Get(ctx, index, out_tensors);\n   }\n \n-  absl::Status Get(AnyContext ctx, int64 index,\n+  absl::Status Get(AnyContext ctx, int64_t index,\n                    std::vector<Tensor>* out_tensors) const override {\n     mutex_lock l(mu_);\n     if (!iterator_random_access_cache_) {\n@@ -1182,7 +1182,7 @@ void CacheDatasetOp::MakeDataset(OpKernelContext* ctx, DatasetBase* input,\n   OP_REQUIRES_OK(ctx, ParseScalarArgument<tstring>(ctx, kFileName, &filename));\n   if (filename.empty()) {\n     static std::atomic<int64_t> resource_id_counter(0);\n-    const string& container = ctx->resource_manager()->default_container();\n+    const std::string& container = ctx->resource_manager()->default_container();\n     auto name = strings::StrCat(ctx->op_kernel().name(), \"/\", kMemoryCache, \"_\",\n                                 resource_id_counter.fetch_add(1));\n     if (op_version_ == 2) {"
        },
        {
            "sha": "ec4067c15110c3ff5663dc19ea8d18e9d8893390",
            "filename": "tensorflow/core/kernels/data/cache_dataset_ops_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_dataset_ops_test.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -32,10 +32,10 @@ constexpr char kMemoryDatasetPrefix[] = \"Memory\";\n class CacheDatasetParams : public DatasetParams {\n  public:\n   template <typename T>\n-  CacheDatasetParams(T input_dataset_params, string filename,\n+  CacheDatasetParams(T input_dataset_params, std::string filename,\n                      DataTypeVector output_dtypes,\n                      std::vector<PartialTensorShape> output_shapes,\n-                     string node_name)\n+                     std::string node_name)\n       : DatasetParams(std::move(output_dtypes), std::move(output_shapes),\n                       std::move(node_name)),\n         filename_(filename) {\n@@ -51,7 +51,8 @@ class CacheDatasetParams : public DatasetParams {\n     return {filename_tensor};\n   }\n \n-  absl::Status GetInputNames(std::vector<string>* input_names) const override {\n+  absl::Status GetInputNames(\n+      std::vector<std::string>* input_names) const override {\n     *input_names = {CacheDatasetOp::kInputDataset, CacheDatasetOp::kFileName};\n     return absl::OkStatus();\n   }\n@@ -63,12 +64,14 @@ class CacheDatasetParams : public DatasetParams {\n     return absl::OkStatus();\n   }\n \n-  string dataset_type() const override { return CacheDatasetOp::kDatasetType; }\n+  std::string dataset_type() const override {\n+    return CacheDatasetOp::kDatasetType;\n+  }\n \n-  string filename() const { return filename_; }\n+  std::string filename() const { return filename_; }\n \n  private:\n-  string filename_;\n+  std::string filename_;\n };\n \n class CacheDatasetOpTest : public DatasetOpsTestBase {\n@@ -82,14 +85,14 @@ class CacheDatasetOpTest : public DatasetOpsTestBase {\n \n   ~CacheDatasetOpTest() override {\n     if (!cache_filename_.empty()) {\n-      std::vector<string> cache_files;\n+      std::vector<std::string> cache_files;\n       absl::Status s = device_->env()->GetMatchingPaths(\n           absl::StrCat(cache_filename_, \"*\"), &cache_files);\n       if (!s.ok()) {\n         LOG(WARNING) << \"Failed to get matching files on \" << cache_filename_\n                      << \"* : \" << s;\n       }\n-      for (const string& path : cache_files) {\n+      for (const std::string& path : cache_files) {\n         s = device_->env()->DeleteFile(path);\n         if (!s.ok()) {\n           LOG(WARNING) << \"Failed to delete \" << path << \" : \" << s;"
        },
        {
            "sha": "0338ca1b3fcfc8531705fb21ca438e2a931ab07c",
            "filename": "tensorflow/core/kernels/data/cache_ops.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -80,7 +80,7 @@ AnonymousMemoryCacheHandleOp::AnonymousMemoryCacheHandleOp(\n                                               /* ref_counting */ true,\n                                               /* return_deleter */ true) {}\n \n-string AnonymousMemoryCacheHandleOp::name() { return kMemoryCache; }\n+std::string AnonymousMemoryCacheHandleOp::name() { return kMemoryCache; }\n \n absl::Status AnonymousMemoryCacheHandleOp::CreateResource(\n     OpKernelContext* ctx, std::unique_ptr<FunctionLibraryDefinition> flib_def,"
        },
        {
            "sha": "f91f261ea79bec37b07b602686432f31a836e736",
            "filename": "tensorflow/core/kernels/data/cache_ops.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fcache_ops.h?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -62,7 +62,7 @@ class MemoryCacheManager : public ResourceBase {\n  public:\n   MemoryCacheManager() : cache_(std::make_shared<MemoryCache>()) {}\n \n-  string DebugString() const override;\n+  std::string DebugString() const override;\n \n   std::shared_ptr<MemoryCache> get() { return cache_; }\n \n@@ -77,7 +77,7 @@ class AnonymousMemoryCacheHandleOp\n   explicit AnonymousMemoryCacheHandleOp(OpKernelConstruction* ctx);\n \n  private:\n-  string name() override;\n+  std::string name() override;\n   absl::Status CreateResource(\n       OpKernelContext* ctx, std::unique_ptr<FunctionLibraryDefinition> flib_def,\n       std::unique_ptr<ProcessFunctionLibraryRuntime> pflr,"
        },
        {
            "sha": "d9fed39b07ba88749366302cf55424104cb65cbb",
            "filename": "tensorflow/core/kernels/data/concatenate_dataset_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fconcatenate_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fconcatenate_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fconcatenate_dataset_op.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -105,7 +105,7 @@ class ConcatenateDatasetOp::Dataset : public DatasetBase {\n   }\n \n   std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-      const string& prefix) const override {\n+      const std::string& prefix) const override {\n     return std::make_unique<Iterator>(Iterator::Params{\n         this, name_utils::IteratorPrefix(kDatasetType, prefix)});\n   }\n@@ -124,7 +124,7 @@ class ConcatenateDatasetOp::Dataset : public DatasetBase {\n     return output_shapes_;\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     return name_utils::DatasetDebugString(kDatasetType);\n   }\n \n@@ -155,7 +155,7 @@ class ConcatenateDatasetOp::Dataset : public DatasetBase {\n     return to_concatenate_->CheckExternalState();\n   }\n \n-  absl::Status Get(OpKernelContext* ctx, int64 index,\n+  absl::Status Get(OpKernelContext* ctx, int64_t index,\n                    std::vector<Tensor>* out_tensors) const override {\n     TF_RETURN_IF_ERROR(CheckRandomAccessCompatible(index));\n     if (index < input_cardinality_) {"
        },
        {
            "sha": "cafd1d4880b37983f74e150727ff2d50ef402570",
            "filename": "tensorflow/core/kernels/data/dataset_ops.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fdataset_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/db8b9de813d3c1fb18f498532cc1ce1371339ab7/tensorflow%2Fcore%2Fkernels%2Fdata%2Fdataset_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fdataset_ops.cc?ref=db8b9de813d3c1fb18f498532cc1ce1371339ab7",
            "patch": "@@ -120,7 +120,7 @@ void DatasetToGraphOp::Compute(OpKernelContext* ctx) {\n DatasetCardinalityOp::DatasetCardinalityOp(OpKernelConstruction* ctx)\n     : OpKernel(ctx), cardinality_options_(new CardinalityOptions) {\n   if (ctx->HasAttr(kCardinalityOptions)) {\n-    string options_serialized;\n+    std::string options_serialized;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(kCardinalityOptions, &options_serialized));\n     if (!options_serialized.empty())\n       cardinality_options_->ParseFromString(options_serialized);\n@@ -141,7 +141,7 @@ void DatasetFromGraphOp::Compute(OpKernelContext* ctx) {\n   GraphDef graph_def;\n   OP_REQUIRES(ctx, graph_def.ParseFromString(graph_def_string),\n               errors::InvalidArgument(\"Could not parse GraphDef\"));\n-  string output_node;\n+  std::string output_node;\n   for (const auto& node : graph_def.node()) {\n     if (node.op() == FunctionLibraryDefinition::kRetOp) {\n       output_node = node.input(0);"
        }
    ],
    "stats": {
        "total": 79,
        "additions": 41,
        "deletions": 38
    }
}