{
    "author": "tensorflower-gardener",
    "message": "[XLA:Original Value] Introduce \"synthetic\" OriginalValue.\n\nThis change adds a `SyntheticCall` variant to `OriginalValue` to represent values that do not have a direct mapping to original arrays, such as the result of certain call instructions. This avoids creating empty or partially filled `TupleTree` structures. The `TupleTree` leaf iterator was also refactored to support default construction.\n\nPiperOrigin-RevId: 805218854",
    "sha": "6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
    "files": [
        {
            "sha": "5eb51e5986698da589d4d23ebec0f2ef4fa7cafd",
            "filename": "third_party/xla/xla/hlo/ir/hlo_module.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_module.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -1537,7 +1537,8 @@ void HloModule::OriginalValueRecoveryTable::AddRecoveryComputation(\n                                   replacing_inst->shape()));\n   std::shared_ptr<OriginalValue> replaced_original_value =\n       replaced_inst->original_value();\n-  if (!replaced_original_value) {\n+  if (!replaced_original_value ||\n+      replaced_original_value->is_synthetic_call()) {\n     return;\n   }\n   if (replacing_inst->original_value() == nullptr) {"
        },
        {
            "sha": "6b1f196572bba626a2e0c062a01943270bbb0400",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.cc",
            "status": "modified",
            "additions": 128,
            "deletions": 37,
            "changes": 165,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -15,13 +15,15 @@ limitations under the License.\n \n #include \"xla/hlo/ir/hlo_original_value.h\"\n \n+#include <algorithm>\n #include <cstdint>\n #include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n #include <vector>\n \n+#include \"absl/base/no_destructor.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n@@ -62,6 +64,15 @@ OriginalArray OriginalArray::FromProto(\n           ShapeIndex(original_array_proto.shape_index())};\n }\n \n+bool operator==(const OriginalArray& lhs, const OriginalArray& rhs) {\n+  return lhs.instruction_name == rhs.instruction_name &&\n+         lhs.shape_index == rhs.shape_index;\n+}\n+\n+bool operator!=(const OriginalArray& lhs, const OriginalArray& rhs) {\n+  return !(lhs == rhs);\n+}\n+\n namespace {\n using Node = TupleTree<std::optional<OriginalArray>>::Node;\n \n@@ -87,31 +98,88 @@ std::string NodeToString(const Node& node) {\n }\n }  // namespace\n \n+void OriginalValue::ClearInternalNodeValues() {\n+  if (is_synthetic_call()) {\n+    return;\n+  }\n+  mutable_tree()->ForEachMutableElement(\n+      [&](const ShapeIndex& index, std::optional<OriginalArray>* value) {\n+        if (!mutable_tree()->IsLeaf(index)) {\n+          *value = std::nullopt;\n+        }\n+      });\n+}\n+\n+OriginalValue::OriginalValue(\n+    TupleTree<std::optional<OriginalArray>>::Node&& root_node)\n+    : data_(TupleTree<std::optional<OriginalArray>>(std::move(root_node))) {\n+  ClearInternalNodeValues();\n+}\n+OriginalValue::OriginalValue(TupleTree<std::optional<OriginalArray>>&& tree)\n+    : data_(std::move(tree)) {\n+  ClearInternalNodeValues();\n+}\n+OriginalValue::OriginalValue(\n+    const TupleTree<std::optional<OriginalArray>>& tree)\n+    : data_(tree) {\n+  ClearInternalNodeValues();\n+}\n+\n+OriginalValue::OriginalValue(SyntheticCallType synthetic) : data_(synthetic) {}\n+\n+OriginalValue OriginalValue::SyntheticCall() {\n+  OriginalValue result(SyntheticCallType{});\n+  return result;\n+}\n+\n std::string OriginalValue::ToString() const {\n-  auto node_or = tree_.ToNode();\n+  if (is_synthetic_call()) {\n+    return \"[synthetic_call]\";\n+  }\n+  auto node_or = tree().ToNode();\n   CHECK_OK(node_or.status());\n   return NodeToString(*node_or);\n }\n \n+bool OriginalValue::operator==(const OriginalValue& other) const {\n+  if (is_synthetic_call() != other.is_synthetic_call()) {\n+    return false;\n+  }\n+  if (is_synthetic_call()) {\n+    return true;  // Synthetic == Synthetic\n+  }\n+  auto this_original_arrays = original_arrays();\n+  auto other_original_arrays = other.original_arrays();\n+  return std::equal(this_original_arrays.begin(), this_original_arrays.end(),\n+                    other_original_arrays.begin(), other_original_arrays.end());\n+}\n+\n OriginalValueProto OriginalValue::ToProto() const {\n   OriginalValueProto original_value_proto;\n-  tree_.ForEachElement([&original_value_proto](\n-                           const ShapeIndex& index,\n-                           const std::optional<OriginalArray>& value) {\n-    OriginalValueElementProto* original_value_node_proto =\n-        original_value_proto.add_elements();\n-    for (const auto& i : index) {\n-      original_value_node_proto->add_shape_index(i);\n-    }\n-    if (value.has_value()) {\n-      *original_value_node_proto->mutable_original_array() = value->ToProto();\n-    }\n-  });\n+  if (is_synthetic_call()) {\n+    original_value_proto.set_is_synthetic_call(true);\n+  } else {\n+    tree().ForEachElement([&original_value_proto](\n+                              const ShapeIndex& index,\n+                              const std::optional<OriginalArray>& value) {\n+      OriginalValueElementProto* original_value_node_proto =\n+          original_value_proto.add_elements();\n+      for (const auto& i : index) {\n+        original_value_node_proto->add_shape_index(i);\n+      }\n+      if (value.has_value()) {\n+        *original_value_node_proto->mutable_original_array() = value->ToProto();\n+      }\n+    });\n+  }\n   return original_value_proto;\n }\n \n std::shared_ptr<OriginalValue> OriginalValue::FromProto(\n     const xla::OriginalValueProto& original_value_proto) {\n+  if (original_value_proto.is_synthetic_call()) {\n+    return std::make_shared<OriginalValue>(OriginalValue::SyntheticCall());\n+  }\n   std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> nodes;\n   for (const auto& leaf : original_value_proto.elements()) {\n     ShapeIndex index(leaf.shape_index());\n@@ -129,34 +197,50 @@ std::shared_ptr<OriginalValue> OriginalValue::FromProto(\n \n std::shared_ptr<OriginalValue> OriginalValue::CreateFromInstruction(\n     const HloInstruction* instruction, absl::string_view prefix) {\n-  std::shared_ptr<OriginalValue> original_value =\n-      std::make_shared<OriginalValue>(\n-          TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n-\n   if (instruction->opcode() == HloOpcode::kGetTupleElement) {\n     const auto* tuple = instruction->operand(0);\n     std::shared_ptr<OriginalValue> tuple_original_value =\n         tuple->original_value();\n-    if (!tuple_original_value) {\n+    if (!tuple_original_value || tuple_original_value->is_synthetic_call()) {\n       return nullptr;\n     }\n-    original_value->CopySubtreeFrom(*tuple_original_value,\n-                                    {instruction->tuple_index()}, {});\n-  } else if (instruction->opcode() == HloOpcode::kTuple) {\n-    for (int64_t operand_number = 0;\n-         operand_number < instruction->operand_count(); ++operand_number) {\n-      auto element_original_value =\n-          instruction->operand(operand_number)->original_value();\n-      if (!element_original_value) {\n+    auto original_value = std::make_shared<OriginalValue>(\n+        TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n+    const auto& tuple_tree = tuple_original_value->tree();\n+    original_value->mutable_tree()->ForEachMutableElement(\n+        [&](const ShapeIndex& index, std::optional<OriginalArray>* value) {\n+          ShapeIndex src_index({instruction->tuple_index()});\n+          src_index.insert(src_index.end(), index.begin(), index.end());\n+          *value = tuple_tree.element(src_index);\n+        });\n+    return original_value;\n+  }\n+\n+  if (instruction->opcode() == HloOpcode::kTuple) {\n+    auto original_value = std::make_shared<OriginalValue>(\n+        TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n+    for (int64_t i = 0; i < instruction->operand_count(); ++i) {\n+      const HloInstruction* operand = instruction->operand(i);\n+      auto op_original_value = operand->original_value();\n+      if (!op_original_value || op_original_value->is_synthetic_call()) {\n         return nullptr;\n       }\n-      original_value->CopySubtreeFrom(*element_original_value, {},\n-                                      {operand_number});\n-    }\n-  } else {\n-    for (auto& leaf : original_value->mutable_original_arrays()) {\n-      leaf.second = {absl::StrCat(prefix, instruction->name()), leaf.first};\n+      const auto& op_tree = op_original_value->tree();\n+      op_tree.ForEachElement([&](const ShapeIndex& index,\n+                                 const std::optional<OriginalArray>& value) {\n+        ShapeIndex dest_index({i});\n+        dest_index.insert(dest_index.end(), index.begin(), index.end());\n+        *original_value->mutable_tree()->mutable_element(dest_index) = value;\n+      });\n     }\n+    return original_value;\n+  }\n+\n+  // Default case: create a new tree with leaves pointing to this instruction.\n+  auto original_value = std::make_shared<OriginalValue>(\n+      TupleTree<std::optional<OriginalArray>>(instruction->shape()));\n+  for (auto& leaf : original_value->mutable_original_arrays()) {\n+    leaf.second = {absl::StrCat(prefix, instruction->name()), leaf.first};\n   }\n   return original_value;\n }\n@@ -178,15 +262,14 @@ void CopyOriginalValue(const HloInstruction* src_instruction,\n     return;\n   }\n \n-  if (!clone) {\n+  if (!clone || original_value->is_synthetic_call()) {\n     dest_instruction->set_original_value(original_value);\n     return;\n   }\n \n-  std::shared_ptr<OriginalValue> original_value_clone =\n-      std::make_shared<OriginalValue>();\n-  original_value_clone->CopySubtreeFrom(*original_value, {}, {});\n-  dest_instruction->set_original_value(original_value_clone);\n+  // Deep clone the tree.\n+  auto cloned_tree = std::make_shared<OriginalValue>(original_value->tree());\n+  dest_instruction->set_original_value(cloned_tree);\n }\n \n void DeduplicateOriginalValues(HloModule* module) {\n@@ -208,4 +291,12 @@ void DeduplicateOriginalValues(HloModule* module) {\n   }\n }\n \n+/* static */\n+TupleTree<std::optional<OriginalArray>>&\n+OriginalValue::EmptyOriginalValueTupleTree() {\n+  static absl::NoDestructor<TupleTree<std::optional<OriginalArray>>>\n+      kEmptyTupleTree;\n+  return *kEmptyTupleTree;\n+}\n+\n }  // namespace xla"
        },
        {
            "sha": "e568c2ec4377e5cea33393e7e403e721970f5e49",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value.h",
            "status": "modified",
            "additions": 58,
            "deletions": 32,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value.h?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -17,11 +17,14 @@ limitations under the License.\n #define XLA_HLO_IR_HLO_ORIGINAL_VALUE_H_\n \n #include <algorithm>\n+#include <iterator>\n #include <memory>\n #include <optional>\n #include <string>\n #include <utility>\n+#include <variant>\n \n+#include \"absl/log/check.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -43,14 +46,8 @@ struct OriginalArray {\n   static OriginalArray FromProto(\n       const xla::OriginalArrayProto& original_array_proto);\n \n-  friend bool operator==(const OriginalArray& lhs, const OriginalArray& rhs) {\n-    return lhs.instruction_name == rhs.instruction_name &&\n-           lhs.shape_index == rhs.shape_index;\n-  }\n-\n-  friend bool operator!=(const OriginalArray& lhs, const OriginalArray& rhs) {\n-    return !(lhs == rhs);\n-  }\n+  friend bool operator==(const OriginalArray& lhs, const OriginalArray& rhs);\n+  friend bool operator!=(const OriginalArray& lhs, const OriginalArray& rhs);\n \n   template <typename H>\n   friend H AbslHashValue(H h, const OriginalArray& original_array) {\n@@ -63,62 +60,91 @@ struct OriginalArray {\n // HLO module.\n class OriginalValue {\n  public:\n-  OriginalValue() = default;\n+  // Constructor for a normal value with array information.\n   explicit OriginalValue(\n-      TupleTree<std::optional<OriginalArray>>::Node&& root_node)\n-      : tree_(std::move(root_node)) {}\n-  explicit OriginalValue(TupleTree<std::optional<OriginalArray>>&& tree)\n-      : tree_(std::move(tree)) {}\n-  explicit OriginalValue(const Shape& shape) : tree_(shape) {}\n+      TupleTree<std::optional<OriginalArray>>::Node&& root_node);\n+  explicit OriginalValue(TupleTree<std::optional<OriginalArray>>&& tree);\n+  explicit OriginalValue(const TupleTree<std::optional<OriginalArray>>& tree);\n+  explicit OriginalValue(const Shape& shape)\n+      : data_(TupleTree<std::optional<OriginalArray>>(shape)) {}\n+\n+  static OriginalValue SyntheticCall();\n+\n+  bool is_synthetic_call() const {\n+    return std::holds_alternative<SyntheticCallType>(data_);\n+  }\n+\n   std::string ToString() const;\n   OriginalValueProto ToProto() const;\n   static std::shared_ptr<OriginalValue> FromProto(\n       const xla::OriginalValueProto& original_value_proto);\n   static std::shared_ptr<OriginalValue> CreateFromInstruction(\n       const HloInstruction* instruction, absl::string_view prefix = \"\");\n \n+  const TupleTree<std::optional<OriginalArray>>& tree() const {\n+    CHECK(!is_synthetic_call())\n+        << \"Cannot get tree from a synthetic OriginalValue\";\n+    return std::get<TupleTree<std::optional<OriginalArray>>>(data_);\n+  }\n+  TupleTree<std::optional<OriginalArray>>* mutable_tree() {\n+    CHECK(!is_synthetic_call())\n+        << \"Cannot get tree from a synthetic OriginalValue\";\n+    return &std::get<TupleTree<std::optional<OriginalArray>>>(data_);\n+  }\n+\n   const std::optional<OriginalArray>& original_array(\n       ShapeIndexView index) const {\n-    return tree_.element(index);\n+    return tree().element(index);\n   }\n   std::optional<OriginalArray>* mutable_original_array(ShapeIndexView index) {\n-    return tree_.mutable_element(index);\n+    return mutable_tree()->mutable_element(index);\n   }\n \n   // Returns a const iterator over the pairs of ShapeIndex and\n   // std::optional<OriginalArray>.\n-  auto original_arrays() const { return tree_.leaves(); }\n+  auto original_arrays() const {\n+    if (is_synthetic_call()) {\n+      return std::as_const(EmptyOriginalValueTupleTree()).leaves();\n+    }\n+    return tree().leaves();\n+  }\n   // Returns a non-const iterator over the pairs of ShapeIndex and\n   // std::optional<OriginalArray>.\n-  auto mutable_original_arrays() { return tree_.leaves(); }\n-\n-  void CopySubtreeFrom(const OriginalValue& other, const ShapeIndex& src_index,\n-                       const ShapeIndex& dst_index) {\n-    tree_.CopySubtreeFrom(other.tree_, src_index, dst_index);\n+  auto mutable_original_arrays() {\n+    if (is_synthetic_call()) {\n+      return EmptyOriginalValueTupleTree().leaves();\n+    }\n+    return mutable_tree()->leaves();\n   }\n \n-  bool operator==(const OriginalValue& other) const {\n-    auto this_original_arrays = original_arrays();\n-    auto other_original_arrays = other.original_arrays();\n-    return std::equal(this_original_arrays.begin(), this_original_arrays.end(),\n-                      other_original_arrays.begin(),\n-                      other_original_arrays.end());\n-  }\n+  bool operator==(const OriginalValue& other) const;\n \n   bool operator!=(const OriginalValue& other) const {\n     return !(*this == other);\n   }\n \n   template <typename H>\n   friend H AbslHashValue(H h, const OriginalValue& value) {\n-    for (const auto& leaf : value.original_arrays()) {\n-      h = H::combine(std::move(h), leaf.first, leaf.second);\n+    h = H::combine(std::move(h), value.is_synthetic_call());\n+    auto original_arrays = value.original_arrays();\n+    h = H::combine(std::move(h), std::distance(original_arrays.begin(),\n+                                               original_arrays.end()));\n+    for (const auto& original_array : original_arrays) {\n+      h = H::combine(std::move(h), original_array);\n     }\n     return h;\n   }\n \n  private:\n-  TupleTree<std::optional<OriginalArray>> tree_;\n+  // Represents a synthetic value, e.g., from a call instruction that doesn't\n+  // have a direct mapping to original arrays and should be removed by inlining.\n+  struct SyntheticCallType {};\n+  explicit OriginalValue(SyntheticCallType synthetic);\n+  static TupleTree<std::optional<OriginalArray>>& EmptyOriginalValueTupleTree();\n+\n+  void ClearInternalNodeValues();\n+  std::variant<SyntheticCallType, TupleTree<std::optional<OriginalArray>>>\n+      data_;\n };\n \n // Copies the original value of the source to the destination instruction. This"
        },
        {
            "sha": "cc10ed1e6c0d7530e9ae687ef4736d4f7585610a",
            "filename": "third_party/xla/xla/hlo/ir/hlo_original_value_test.cc",
            "status": "modified",
            "additions": 123,
            "deletions": 14,
            "changes": 137,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_original_value_test.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -98,6 +98,11 @@ TEST(OriginalValueTest, ToStringTuple) {\n             \"({\\\"inst1\\\" {1}}, {\\\"inst2\\\" {2}}, ({\\\"inst3\\\" {3}}, {}))\");\n }\n \n+TEST(OriginalValueTest, ToStringSynthetic) {\n+  OriginalValue value = OriginalValue::SyntheticCall();\n+  EXPECT_EQ(value.ToString(), \"[synthetic_call]\");\n+}\n+\n TEST(OriginalValueTest, ProtoSerde) {\n   OriginalValue value(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n                                    Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n@@ -115,6 +120,14 @@ TEST(OriginalValueTest, ProtoSerde) {\n       OriginalValue::FromProto(proto_with_null);\n   EXPECT_EQ(value_with_null_from_proto->ToString(), value_with_null.ToString());\n   EXPECT_EQ(*value_with_null_from_proto, value_with_null);\n+\n+  // Test with synthetic call.\n+  OriginalValue value_synthetic = OriginalValue::SyntheticCall();\n+  OriginalValueProto proto_synthetic = value_synthetic.ToProto();\n+  std::shared_ptr<OriginalValue> value_synthetic_from_proto =\n+      OriginalValue::FromProto(proto_synthetic);\n+  EXPECT_TRUE(value_synthetic_from_proto->is_synthetic_call());\n+  EXPECT_EQ(*value_synthetic_from_proto, value_synthetic);\n }\n \n TEST(OriginalValueTest, ElementAccess) {\n@@ -151,20 +164,6 @@ TEST(OriginalValueTest, Elements) {\n   EXPECT_THAT(elements[2].second, Optional(Eq(OriginalArray{\"inst3\", {3}})));\n }\n \n-TEST(OriginalValueTest, CopySubtreeFrom) {\n-  OriginalValue src(\n-      Node::Tuple({Node::Leaf(OriginalArray{\"src1\", {1}}),\n-                   Node::Tuple({Node::Leaf(OriginalArray{\"src2\", {2}}),\n-                                Node::Leaf(OriginalArray{\"src3\", {3}})})}));\n-\n-  OriginalValue dst;\n-  dst.CopySubtreeFrom(src, {1}, {});\n-  EXPECT_EQ(dst.ToString(), \"({\\\"src2\\\" {2}}, {\\\"src3\\\" {3}})\");\n-\n-  dst.CopySubtreeFrom(src, {0}, {});\n-  EXPECT_EQ(dst.ToString(), \"{\\\"src1\\\" {1}}\");\n-}\n-\n TEST(OriginalValueTest, EqualityAndHashing) {\n   OriginalValue value1(Node::Leaf(OriginalArray{\"inst1\", {}}));\n   OriginalValue value2(Node::Leaf(OriginalArray{\"inst1\", {}}));\n@@ -173,18 +172,29 @@ TEST(OriginalValueTest, EqualityAndHashing) {\n                                     Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n   OriginalValue value5(Node::Tuple({Node::Leaf(OriginalArray{\"inst1\", {1}}),\n                                     Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+  OriginalValue value_with_root_value(Node::Tuple(\n+      OriginalArray{\"root\", {}}, {Node::Leaf(OriginalArray{\"inst1\", {1}}),\n+                                  Node::Leaf(OriginalArray{\"inst2\", {2}})}));\n+  OriginalValue synthetic1 = OriginalValue::SyntheticCall();\n+  OriginalValue synthetic2 = OriginalValue::SyntheticCall();\n \n   EXPECT_EQ(value1, value2);\n   EXPECT_NE(value1, value3);\n   EXPECT_NE(value1, value4);\n   EXPECT_EQ(value4, value5);\n+  EXPECT_EQ(value4, value_with_root_value);\n+  EXPECT_EQ(synthetic1, synthetic2);\n+  EXPECT_NE(value1, synthetic1);\n \n   EXPECT_TRUE(absl::VerifyTypeImplementsAbslHashCorrectly({\n       value1,\n       value2,\n       value3,\n       value4,\n       value5,\n+      value_with_root_value,\n+      synthetic1,\n+      synthetic2,\n   }));\n }\n \n@@ -242,6 +252,29 @@ ENTRY main {\n   EXPECT_EQ(gte->original_value()->ToString(), \"{\\\"p1\\\"}\");\n }\n \n+TEST_F(OriginalValueHloTest, CreateFromInstructionGteSynthetic) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  tuple = (f32[], f32[]) tuple(p0, p1)\n+  ROOT gte = f32[] get-tuple-element(tuple), index=1\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* tuple = FindInstruction(module.get(), \"tuple\");\n+  HloInstruction* gte = module->entry_computation()->root_instruction();\n+\n+  tuple->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n+  gte->set_original_value(OriginalValue::CreateFromInstruction(gte));\n+\n+  EXPECT_EQ(gte->original_value(), nullptr);\n+}\n+\n TEST_F(OriginalValueHloTest, CreateFromInstructionTuple) {\n   const char* hlo_string = R\"(\n HloModule test\n@@ -258,6 +291,30 @@ ENTRY main {\n   EXPECT_EQ(p0->original_value()->ToString(), \"({\\\"p0\\\" {0}}, {\\\"p0\\\" {1}})\");\n }\n \n+TEST_F(OriginalValueHloTest, CreateFromInstructionTupleWithSynthetic) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  ROOT tuple = (f32[], f32[]) tuple(p0, p1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* p1 = module->entry_computation()->parameter_instruction(1);\n+  HloInstruction* tuple = module->entry_computation()->root_instruction();\n+\n+  p0->set_original_value(OriginalValue::CreateFromInstruction(p0));\n+  p1->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n+  tuple->set_original_value(OriginalValue::CreateFromInstruction(tuple));\n+\n+  EXPECT_EQ(tuple->original_value(), nullptr);\n+}\n+\n TEST_F(OriginalValueHloTest, CopyOriginalValue) {\n   const char* hlo_string = R\"(\n HloModule test\n@@ -281,6 +338,29 @@ ENTRY main {\n   EXPECT_EQ(*p0->original_value(), *clone->original_value());\n }\n \n+TEST_F(OriginalValueHloTest, CopyOriginalValueSynthetic) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  ROOT p0 = f32[] parameter(0)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = module->entry_computation()->parameter_instruction(0);\n+  p0->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n+\n+  std::unique_ptr<HloInstruction> clone = p0->Clone();\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/false);\n+  EXPECT_EQ(p0->original_value(), clone->original_value());\n+\n+  CopyOriginalValue(p0, clone.get(), /*clone=*/true);\n+  EXPECT_EQ(p0->original_value(), clone->original_value());\n+}\n+\n TEST_F(OriginalValueHloTest, DeduplicateOriginalValues) {\n   const char* hlo_string = R\"(\n HloModule test\n@@ -325,5 +405,34 @@ ENTRY main {\n   EXPECT_NE(p0->original_value(), p1->original_value());\n }\n \n+TEST_F(OriginalValueHloTest, DeduplicateOriginalValuesWithSynthetic) {\n+  const char* hlo_string = R\"(\n+HloModule test\n+\n+ENTRY main {\n+  p0 = f32[] parameter(0)\n+  p1 = f32[] parameter(1)\n+  ROOT add = f32[] add(p0, p1)\n+}\n+)\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  HloInstruction* p0 = FindInstruction(module.get(), \"p0\");\n+  HloInstruction* p1 = FindInstruction(module.get(), \"p1\");\n+\n+  auto value1 = std::make_shared<OriginalValue>(OriginalValue::SyntheticCall());\n+  auto value2 = std::make_shared<OriginalValue>(OriginalValue::SyntheticCall());\n+\n+  p0->set_original_value(value1);\n+  p1->set_original_value(value2);\n+\n+  EXPECT_NE(p0->original_value(), p1->original_value());\n+  EXPECT_EQ(*p0->original_value(), *p1->original_value());\n+\n+  DeduplicateOriginalValues(module.get());\n+\n+  EXPECT_EQ(p0->original_value(), p1->original_value());\n+}\n+\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "29e299f26368879046b3938074cf1e716fd1b225",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser.cc",
            "status": "modified",
            "additions": 81,
            "deletions": 43,
            "changes": 124,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -592,9 +592,10 @@ class HloParserImpl : public HloParser {\n                   uint64_t lexer_skip_mask = kNoneMask);\n   bool ParseUnsignedIntegerType(PrimitiveType* primitive_type);\n   bool ParseOriginalArray(OriginalArray& original_array);\n-  bool ParseOriginalValueArrays(\n-      std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n-          original_value_arrays);\n+  bool ParseAndAddOriginalArray(\n+      const ShapeIndex& leaf_shape_index,\n+      std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>*);\n+  bool ParseOriginalValueImpl(std::optional<OriginalValue>& original_value);\n   bool ParseOriginalValueRecoveryTable(\n       OriginalValueRecoveryTable& original_value_recovery_table);\n   bool ParseCollectiveOpGroupMode(CollectiveOpGroupMode* result);\n@@ -5240,14 +5241,12 @@ bool HloParserImpl::ParseAttributeHelper(\n         return true;\n       }\n       case AttrTy::kOriginalValue: {\n-        std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n-        if (!ParseOriginalValueArrays(arrays)) {\n+        std::optional<OriginalValue> result;\n+        if (!ParseOriginalValueImpl(result)) {\n           return false;\n         }\n-        auto result = std::make_shared<OriginalValue>(\n-            TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n         static_cast<optional<std::shared_ptr<OriginalValue>>*>(attr_out_ptr)\n-            ->emplace(std::move(result));\n+            ->emplace(std::make_shared<OriginalValue>(std::move(*result)));\n         return true;\n       }\n       case AttrTy::kOriginalValueRecoveryTable: {\n@@ -6625,48 +6624,89 @@ bool HloParserImpl::ParseOriginalArray(OriginalArray& original_array) {\n   return true;\n }\n \n-// original_value ::= '{' '('* original_array [','] ')'* | original_value '}'\n-bool HloParserImpl::ParseOriginalValueArrays(\n-    std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>&\n+bool HloParserImpl::ParseAndAddOriginalArray(\n+    const ShapeIndex& leaf_shape_index,\n+    std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>*\n         original_value_arrays) {\n+  OriginalArray original_array;\n+  if (!ParseOriginalArray(original_array)) {\n+    return false;\n+  }\n+  if (original_array.instruction_name.empty()) {\n+    // The original value is not expected to have any leaf without values.\n+    // However we should not fail the execution here. This should\n+    // be done in HloVerifier instead.\n+    LOG(WARNING) << \"Found an empty leaf node in an original value\";\n+    original_value_arrays->emplace_back(leaf_shape_index, std::nullopt);\n+  } else {\n+    original_value_arrays->emplace_back(leaf_shape_index,\n+                                        std::move(original_array));\n+  }\n+  return true;\n+}\n+\n+// original_value ::= '{' '<synthetic_call>' | ( '('* original_array [','] ')'*\n+// | original_value ) '}'\n+bool HloParserImpl::ParseOriginalValueImpl(\n+    std::optional<OriginalValue>& original_value) {\n   VLOG(kDebugLevel) << \"ParseOriginalValue\";\n \n-  if (!ParseToken(TokKind::kLbrace, \"Expects '{'\")) {\n+  if (!ParseToken(TokKind::kLbrace, \"Expects '{' to start original value\")) {\n     return false;\n   }\n \n+  if (EatIfPresent(TokKind::kLsquare)) {\n+    if (lexer_.GetKind() != TokKind::kIdent ||\n+        lexer_.GetStrVal() != \"synthetic_call\") {\n+      return TokenError(\n+          \"Expects 'synthetic_call' after '[' for a synthetic_call value.\");\n+    }\n+    lexer_.Lex();  // Eat 'synthetic_call'.\n+    if (!ParseToken(TokKind::kRsquare,\n+                    \"Expects ']' to end '[synthetic_call]'\")) {\n+      return false;\n+    }\n+    if (!ParseToken(TokKind::kRbrace, \"Expects '}' to end original value\")) {\n+      return false;\n+    }\n+    original_value.emplace(OriginalValue::SyntheticCall());\n+    return true;\n+  }\n+\n+  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>>\n+      original_value_arrays;\n+\n   ShapeIndex leaf_shape_index;\n   while (lexer_.GetKind() != TokKind::kRbrace) {\n-    if (lexer_.GetKind() == TokKind::kLparen) {\n-      lexer_.Lex();\n-      leaf_shape_index.push_back(0);\n-    } else if (lexer_.GetKind() == TokKind::kRparen) {\n-      lexer_.Lex();\n-      leaf_shape_index.pop_back();\n-    } else if (lexer_.GetKind() == TokKind::kComma) {\n-      lexer_.Lex();\n-      ++leaf_shape_index.back();\n-    } else if (lexer_.GetKind() == TokKind::kLbrace) {\n-      OriginalArray original_array;\n-      if (!ParseOriginalArray(original_array)) {\n-        return false;\n-      }\n-      if (original_array.instruction_name.empty()) {\n-        // The original value is not expected to have any leaf without values.\n-        // However we should not fail the execution here. This should\n-        // be done in HloVerifier instead.\n-        LOG(WARNING) << \"Found an empty leaf node in an original value\";\n-        original_value_arrays.emplace_back(leaf_shape_index, std::nullopt);\n-      } else {\n-        original_value_arrays.emplace_back(leaf_shape_index,\n-                                           std::move(original_array));\n-      }\n-    } else {\n-      return false;\n+    switch (lexer_.GetKind()) {\n+      case TokKind::kLparen:\n+        lexer_.Lex();\n+        leaf_shape_index.push_back(0);\n+        break;\n+      case TokKind::kRparen:\n+        lexer_.Lex();\n+        leaf_shape_index.pop_back();\n+        break;\n+      case TokKind::kComma:\n+        lexer_.Lex();\n+        ++leaf_shape_index.back();\n+        break;\n+      case TokKind::kLbrace:\n+        if (!ParseAndAddOriginalArray(leaf_shape_index,\n+                                      &original_value_arrays)) {\n+          return false;\n+        }\n+        break;\n+      default:\n+        return TokenError(\n+            \"Expects '[synthetic]' or a tuple tree of original arrays in \"\n+            \"original_value field.\");\n     }\n   }\n \n   lexer_.Lex();\n+  original_value.emplace(TupleTree<std::optional<OriginalArray>>(\n+      absl::MakeSpan(original_value_arrays)));\n   return true;\n }\n \n@@ -7324,16 +7364,14 @@ absl::StatusOr<HloSharding> HloParserImpl::ParseShardingOnly() {\n absl::StatusOr<std::shared_ptr<OriginalValue>>\n HloParserImpl::ParseOriginalValueOnly() {\n   lexer_.Lex();\n-  std::vector<std::pair<ShapeIndex, std::optional<OriginalArray>>> arrays;\n-  if (!ParseOriginalValueArrays(arrays)) {\n+  std::optional<OriginalValue> original_value;\n+  if (!ParseOriginalValueImpl(original_value)) {\n     return InvalidArgument(\"Syntax error:\\n%s\", GetError());\n   }\n-  auto original_value = std::make_shared<OriginalValue>(\n-      TupleTree<std::optional<OriginalArray>>(absl::MakeSpan(arrays)));\n   if (lexer_.GetKind() != TokKind::kEof) {\n     return InvalidArgument(\"Syntax error:\\nExtra content after original value\");\n   }\n-  return original_value;\n+  return std::make_shared<OriginalValue>(std::move(*original_value));\n }\n \n absl::StatusOr<FrontendAttributes>"
        },
        {
            "sha": "268df042eaf56ff20e14c4fbaba749adfb9dff18",
            "filename": "third_party/xla/xla/hlo/parser/hlo_parser_test.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fparser%2Fhlo_parser_test.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -1547,6 +1547,18 @@ ENTRY %test (v1: f32[], v2: f32[3], v3: f32[2,3]) -> ((f32[], f32[3]), f32[2,3])\n )\"\n },\n \n+{\n+\"OriginalValueSynthetic\",\n+R\"(HloModule test, entry_computation_layout={(f32[])->f32[]}\n+\n+ENTRY %test (v1: f32[]) -> f32[] {\n+  %v1 = f32[] parameter(0), origin={[synthetic_call]}\n+  ROOT %add = f32[] add(f32[] %v1, f32[] %v1), origin={[synthetic_call]}\n+}\n+\n+)\"\n+},\n+\n {\n \"OriginalValueRecoveryTable\",\n R\"(HloModule test, entry_computation_layout={(f32[192]{0})->f32[1,17,17,192]{3,2,1,0}}, origin_recovery_table={"
        },
        {
            "sha": "bf00068dc52acd24a8719e396939b9568f71fe82",
            "filename": "third_party/xla/xla/hlo/testlib/hlo_hardware_independent_test_base.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftestlib%2Fhlo_hardware_independent_test_base.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftestlib%2Fhlo_hardware_independent_test_base.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftestlib%2Fhlo_hardware_independent_test_base.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -256,7 +256,7 @@ void HloHardwareIndependentTestBase::RunAndFilecheckHloRewrite(\n         RunFileCheck(\n             module->ToString(HloPrintOptions().set_print_large_constants(true)),\n             *expected));\n-    EXPECT_TRUE(filecheck_matches);\n+    EXPECT_TRUE(filecheck_matches) << module->ToString();\n     if (after_pass_checks) {\n       after_pass_checks(module.get());\n     }\n@@ -300,7 +300,7 @@ void HloHardwareIndependentTestBase::RunAndFilecheckHloModuleGroupRewrite(\n         RunFileCheck(module_group.module(index).ToString(\n                          HloPrintOptions().set_print_large_constants(true)),\n                      expected_str));\n-    EXPECT_TRUE(filecheck_matches);\n+    EXPECT_TRUE(filecheck_matches) << module_group.module(index).ToString();\n     index++;\n   }\n }"
        },
        {
            "sha": "ff4f58a1ce17116daf3298e42c6fa481502f468a",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -311,13 +311,11 @@ cc_library(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:call_inliner\",\n         \"//xla/service:hlo_creation_utils\",\n-        \"//xla/service:hlo_module_config\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "353883c0e38f6eb8433628e685db771c29022c9f",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/bitcast_dtypes_expander.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fbitcast_dtypes_expander.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fbitcast_dtypes_expander.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fbitcast_dtypes_expander.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/hlo/transforms/expanders/bitcast_dtypes_expander.h\"\n \n #include <cstdint>\n+#include <memory>\n #include <string>\n #include <vector>\n \n@@ -30,15 +31,14 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/service/call_inliner.h\"\n #include \"xla/service/hlo_creation_utils.h\"\n-#include \"xla/service/hlo_module_config.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/logging.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n \n@@ -118,6 +118,8 @@ absl::StatusOr<HloInstruction*> BitcastDtypesExpander::ExpandInstruction(\n   HloInstruction* call =\n       instruction->parent()->AddInstruction(HloInstruction::CreateCall(\n           instruction->shape(), instruction->operands(), computation));\n+  call->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n   HloInstruction* root = call->to_apply()->root_instruction();\n   // TODO(b/260601110): In theory, we shouldn't need to do it, but in practice\n   // this creates reshape/broadcast patterns that can be pretty bad if not"
        },
        {
            "sha": "5166af6fc8d37740fd40396877c1d75a53025361",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 11,
            "deletions": 7,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -2202,13 +2202,13 @@ cc_library(\n         \":hlo_creation_utils\",\n         \"//xla:shape_util\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n \n@@ -3055,6 +3055,9 @@ cc_library(\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:status\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n@@ -3067,9 +3070,6 @@ cc_library(\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:status\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n \n@@ -4715,6 +4715,8 @@ cc_library(\n         \"//xla:shape_util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n@@ -4725,8 +4727,6 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n \n@@ -5647,9 +5647,13 @@ cc_library(\n     hdrs = [\"select_and_scatter_expander.h\"],\n     deps = [\n         \":call_inliner\",\n+        \"//xla:comparison_util\",\n         \"//xla:literal_util\",\n+        \"//xla:shape_util\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/transforms/expanders:op_expander_pass\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n     ],\n )\n "
        },
        {
            "sha": "c75bb6278778d0de0ecc0068528cdbfc540a432e",
            "filename": "third_party/xla/xla/service/call_inliner.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 18,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcall_inliner.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -118,24 +118,7 @@ class SubcomputationInsertionVisitor : public DfsHloVisitorWithDefault {\n         outer_->AddInstruction(std::move(new_hlo));\n     TF_RETURN_IF_ERROR(NoteMapping(hlo, new_hlo_pointer));\n \n-    new_hlo_pointer->CopyOriginalValue(hlo, /*clone=*/true);\n-    if (std::shared_ptr<OriginalValue> original_value =\n-            new_hlo_pointer->original_value()) {\n-      for (auto& pair : original_value->mutable_original_arrays()) {\n-        std::optional<OriginalArray>& original_array = pair.second;\n-        if (original_array.has_value()) {\n-          std::string call_instruction_name;\n-          if (std::shared_ptr<OriginalValue> call_original_value =\n-                  call_->original_value()) {\n-            call_instruction_name = call_original_value->original_arrays()\n-                                        .begin()\n-                                        ->second->instruction_name;\n-          }\n-          original_array->instruction_name = absl::StrCat(\n-              call_instruction_name, \"/\", original_array->instruction_name);\n-        }\n-      }\n-    }\n+    PropagateOriginalValue(new_hlo_pointer, hlo);\n \n     // Account for control edges.\n     for (HloInstruction* control_predecessor : hlo->control_predecessors()) {\n@@ -221,6 +204,38 @@ class SubcomputationInsertionVisitor : public DfsHloVisitorWithDefault {\n     return absl::OkStatus();\n   }\n \n+  // Propagates original value information from the call and the original HLO\n+  // to the newly cloned HLO.\n+  void PropagateOriginalValue(HloInstruction* new_hlo_pointer,\n+                              HloInstruction* hlo) {\n+    std::shared_ptr<OriginalValue> call_original_value =\n+        call_->original_value();\n+    if (!call_original_value) {\n+      new_hlo_pointer->set_original_value(nullptr);\n+      return;\n+    }\n+    new_hlo_pointer->CopyOriginalValue(hlo, /*clone=*/true);\n+    if (call_original_value->is_synthetic_call()) {\n+      return;\n+    }\n+    std::shared_ptr<OriginalValue> original_value =\n+        new_hlo_pointer->original_value();\n+    if (!original_value) {\n+      return;\n+    }\n+    for (auto& pair : original_value->mutable_original_arrays()) {\n+      std::optional<OriginalArray>& original_array = pair.second;\n+      if (original_array.has_value()) {\n+        std::string call_instruction_name =\n+            call_original_value->original_arrays()\n+                .begin()\n+                ->second->instruction_name;\n+        original_array->instruction_name = absl::StrCat(\n+            call_instruction_name, \"/\", original_array->instruction_name);\n+      }\n+    }\n+  }\n+\n   HloInstruction* call_;\n   HloComputation* outer_;\n   CallInliner::InlinedInstructionMap subcomputation_hlo_to_new_hlo_;"
        },
        {
            "sha": "2bf4145c3257a08a05574e4d44cc7d60a2032ef3",
            "filename": "third_party/xla/xla/service/conditional_simplifier.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_simplifier.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -465,6 +465,7 @@ absl::StatusOr<bool> ConditionalSimplifier::TryRemoveConditional(\n \n   if (conditional->branch_count() == 1) {\n     HloInstruction* call_op = create_call(0);\n+    call_op->set_original_value(conditional->original_value());\n     TF_RETURN_IF_ERROR(computation->ReplaceInstruction(conditional, call_op));\n     TF_RETURN_IF_ERROR(CallInliner::Inline(call_op).status());\n     return true;\n@@ -481,6 +482,7 @@ absl::StatusOr<bool> ConditionalSimplifier::TryRemoveConditional(\n       }\n     }\n     HloInstruction* call_op = create_call(branch_index);\n+    call_op->set_original_value(conditional->original_value());\n     TF_RETURN_IF_ERROR(computation->ReplaceInstruction(conditional, call_op));\n     TF_RETURN_IF_ERROR(CallInliner::Inline(call_op).status());\n \n@@ -527,7 +529,9 @@ absl::StatusOr<bool> ConditionalSimplifier::TryRemoveConditional(\n   }\n \n   HloInstruction* true_call_op = create_call(0);\n+  true_call_op->set_original_value(conditional->original_value());\n   HloInstruction* false_call_op = create_call(1);\n+  false_call_op->set_original_value(conditional->original_value());\n   auto condition_broadcast = [&](const Shape& shape) {\n     if (ShapeUtil::IsScalar(shape)) {\n       return conditional->mutable_operand(0);"
        },
        {
            "sha": "95febe9bee07d95ac337c236c9c01bdee7f05afd",
            "filename": "third_party/xla/xla/service/conditional_to_select.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_to_select.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_to_select.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fconditional_to_select.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -81,10 +81,12 @@ static absl::StatusOr<bool> DoConditionalToSelect(HloInstruction* conditional) {\n   HloInstruction* if_call_op =\n       computation->AddInstruction(HloInstruction::CreateCall(\n           conditional->shape(), {true_operand}, true_computation));\n+  if_call_op->set_original_value(conditional->original_value());\n   conditional->SetupDerivedInstruction(if_call_op);\n   HloInstruction* else_call_op =\n       computation->AddInstruction(HloInstruction::CreateCall(\n           conditional->shape(), {false_operand}, false_computation));\n+  else_call_op->set_original_value(conditional->original_value());\n   conditional->SetupDerivedInstruction(else_call_op);\n   HloInstruction* condition = conditional->mutable_operand(0);\n   if (is_form2) {"
        },
        {
            "sha": "6ff32dcacc73756486e2e2b7f31ed5b4a792a239",
            "filename": "third_party/xla/xla/service/dynamic_dimension_inference.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fdynamic_dimension_inference.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fdynamic_dimension_inference.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fdynamic_dimension_inference.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -48,6 +48,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/call_inliner.h\"\n@@ -60,12 +61,12 @@ limitations under the License.\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/status.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n #include \"xla/window_util.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/status.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n \n@@ -95,6 +96,8 @@ WidenComputation(HloComputation* narrow_comp, const Shape& wide_shape) {\n   HloInstruction* call_narrow_comp = wide_comp->AddInstruction(\n       HloInstruction::CreateCall(narrow_comp->root_instruction()->shape(),\n                                  {truncated_parameter}, narrow_comp));\n+  call_narrow_comp->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n   wide_comp->set_root_instruction(call_narrow_comp,\n                                   /*accept_different_shape=*/true);\n   TF_ASSIGN_OR_RETURN(auto inline_map, CallInliner::Inline(call_narrow_comp));"
        },
        {
            "sha": "50e1ed1ce2089bc54df00cb665378b22c3f20164",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -2936,6 +2936,9 @@ absl::Status VerifyOriginalValue(const HloModule& module) {\n       if (instruction->original_value()) {\n         const auto& shape = instruction->shape();\n         const auto& original_value = instruction->original_value();\n+        if (original_value->is_synthetic_call()) {\n+          continue;\n+        }\n         absl::flat_hash_set<ShapeIndex> shape_leaf_indices;\n         ShapeUtil::ForEachLeafShape(\n             shape, [&](const Shape& /*subshape*/, const ShapeIndex& index) {"
        },
        {
            "sha": "b62cd6fa5390377ff0e6ce9a4f58b218faa12de7",
            "filename": "third_party/xla/xla/service/propagate_original_value_test.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 4,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fpropagate_original_value_test.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -98,12 +98,12 @@ TEST_F(PropagateOriginalValueTest, CallInlinerMultipleCallSites) {\n                             CallInliner(/*single_call_site=*/false));\n }\n \n-TEST_F(PropagateOriginalValueTest, CallInlinerNoCallInstructionName) {\n+TEST_F(PropagateOriginalValueTest,\n+       CallInlinerMissingOriginalValueInCallInstruction) {\n   const absl::string_view hlo_string = R\"(\n // CHECK-LABEL:test\n-// CHECK: %[[LHS:.*]] =\n-// CHECK:  %[[RHS:.*]] = f32[] constant(2), origin={{[{]}}{\"/rhs\"}\n-// CHECK: %[[ADD:.*]] = f32[] add(%[[LHS]], %[[RHS]]), origin={{[{]}}{\"/add\"}\n+// CHECK-NOT:origin\n+// CHECK-NOT:call(\n \n   HloModule test\n \n@@ -122,6 +122,31 @@ TEST_F(PropagateOriginalValueTest, CallInlinerNoCallInstructionName) {\n                             CallInliner(/*single_call_site=*/false));\n }\n \n+TEST_F(PropagateOriginalValueTest, CallInlinerSyntheticCallInstruction) {\n+  const absl::string_view hlo_string = R\"(\n+// CHECK-LABEL:test\n+// CHECK: %[[LHS:.*]] =\n+// CHECK:  %[[RHS:.*]] = f32[] constant(2), origin={{[{]}}{\"rhs\"}\n+// CHECK: %[[ADD:.*]] = f32[] add(%[[LHS]], %[[RHS]]), origin={{[{]}}{\"add\"}\n+// CHECK-NOT:call(\n+\n+  HloModule test\n+\n+  incr (lhs: f32[]) -> f32[] {\n+    lhs = f32[] parameter(0)\n+    rhs = f32[] constant(2), origin={{\"rhs\"}}\n+    ROOT add = f32[] add(f32[] lhs, f32[] rhs), origin={{\"add\"}}\n+  }\n+\n+  ENTRY main () -> f32[] {\n+    lhs = f32[] constant(42)\n+    ROOT call = f32[] call(f32[] lhs), to_apply=incr, origin={[synthetic_call]}\n+  })\";\n+\n+  RunAndFilecheckHloRewrite(hlo_string,\n+                            CallInliner(/*single_call_site=*/false));\n+}\n+\n TEST_F(OriginalValueRecoveryTableTest,\n        AlgebraicSimplifierReshapeAndBroadcastMerged) {\n   constexpr absl::string_view hlo_string = R\"("
        },
        {
            "sha": "dca1209bf7073c3ef1820036c55c90cb245e1d54",
            "filename": "third_party/xla/xla/service/scatter_simplifier.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_simplifier.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -157,6 +157,7 @@ absl::StatusOr<HloInstruction*> ScatterSimplifier::ExpandInstruction(\n \n     auto* call_op = scatter->AddInstruction(HloInstruction::CreateCall(\n         scatter->shape(), scatter_operands_and_updates, called_computation));\n+    call_op->set_original_value(scatter->original_value());\n     TF_RETURN_IF_ERROR(scatter->ReplaceAllUsesWith(call_op));\n     TF_ASSIGN_OR_RETURN(auto map, CallInliner::Inline(call_op));\n     return map[call_op];"
        },
        {
            "sha": "63cb38c62fbd7d6520ffc4d542d4b5d9e198cf06",
            "filename": "third_party/xla/xla/service/scatter_utils.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fscatter_utils.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/service/scatter_utils.h\"\n \n #include <cstdint>\n+#include <memory>\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n@@ -27,12 +28,13 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/service/call_inliner.h\"\n #include \"xla/service/hlo_creation_utils.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace xla {\n \n@@ -144,6 +146,8 @@ absl::StatusOr<HloComputation*> CallAndGetOutput(HloComputation* original,\n   HloInstruction* call_original = new_comp->AddInstruction(\n       HloInstruction::CreateCall(original_root->shape(),\n                                  new_comp->parameter_instructions(), original));\n+  call_original->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n   new_comp->set_root_instruction(\n       new_comp->AddInstruction(\n           HloInstruction::CreateGetTupleElement(call_original, output_index)),\n@@ -186,6 +190,8 @@ absl::StatusOr<HloComputation*> CallComputationAndGetIthOutputWithBinaryParams(\n \n   HloInstruction* call_original = new_comp->AddInstruction(\n       HloInstruction::CreateCall(original_root->shape(), operands, original));\n+  call_original->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n   new_comp->set_root_instruction(\n       new_comp->AddInstruction(\n           HloInstruction::CreateGetTupleElement(call_original, output_index)),"
        },
        {
            "sha": "a76b1bcdc015cc929066f4f2b3de1b2b1b2492cf",
            "filename": "third_party/xla/xla/service/select_and_scatter_expander.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fselect_and_scatter_expander.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fselect_and_scatter_expander.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fselect_and_scatter_expander.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -15,14 +15,23 @@ limitations under the License.\n \n #include \"xla/service/select_and_scatter_expander.h\"\n \n+#include <cstdint>\n+#include <memory>\n #include <numeric>\n #include <vector>\n \n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/comparison_util.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/call_inliner.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n \n namespace xla {\n \n@@ -93,6 +102,8 @@ absl::StatusOr<HloInstruction*> SelectAndScatterExpander::ExpandInstruction(\n     auto* call = builder.AddInstruction(\n         HloInstruction::CreateCall(sas->select()->root_instruction()->shape(),\n                                    {operand_lhs, operand_rhs}, sas->select()));\n+    call->set_original_value(\n+        std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n \n     auto* pred = builder.AddInstruction(HloInstruction::CreateBinary(\n         call->shape(), HloOpcode::kAnd, call, lhs_first_in_window));"
        },
        {
            "sha": "faa0a6d97061f4128307e6ed04eb3b8014b3fd45",
            "filename": "third_party/xla/xla/service/while_loop_simplifier.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_simplifier.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -1006,6 +1006,7 @@ static absl::StatusOr<bool> TryRemoveWhileLoop(HloInstruction* while_op) {\n       auto computation = while_op->parent();\n       auto call_op = computation->AddInstruction(HloInstruction::CreateCall(\n           while_op->shape(), while_op->operands(), while_op->while_body()));\n+      call_op->set_original_value(while_op->original_value());\n       TF_RETURN_IF_ERROR(computation->ReplaceInstruction(while_op, call_op));\n       call_op->set_metadata_op_name(\"\");\n       TF_ASSIGN_OR_RETURN(auto inlined_instructions_map,"
        },
        {
            "sha": "d69ba416c5d9619aacbef98d0ca6e68223513450",
            "filename": "third_party/xla/xla/service/while_loop_unroller.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_unroller.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_unroller.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_unroller.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -312,6 +312,7 @@ absl::StatusOr<bool> UnrollInternal(HloInstruction* while_op,\n     unrolled_body_call_op =\n         computation->AddInstruction(HloInstruction::CreateCall(\n             while_op->shape(), call_operands, unrolled_body));\n+    unrolled_body_call_op->set_original_value(while_op->original_value());\n     new_calls.push_back(unrolled_body_call_op);\n     call_operands.clear();\n     call_operands.push_back(unrolled_body_call_op);\n@@ -360,6 +361,7 @@ absl::StatusOr<UnrollResult> UnrollInternalWrappedAndReturnReplacement(\n         HloInstruction::CreateCall(while_op->shape(), call_operands,\n                                    unrolled_body),\n         absl::StrCat(while_op->name(), \"-unrolled-body-call-\", i));\n+    unrolled_body_call_op->set_original_value(while_op->original_value());\n     new_calls.push_back(unrolled_body_call_op);\n \n     call_operands.clear();"
        },
        {
            "sha": "048df27b788903f12842b64a5d742f694695abf8",
            "filename": "third_party/xla/xla/service/while_util.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_util.cc?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_original_value.h\"\n #include \"xla/layout_util.h\"\n #include \"xla/literal_util.h\"\n #include \"xla/service/call_inliner.h\"\n@@ -43,9 +44,9 @@ limitations under the License.\n #include \"xla/service/tuple_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n \n@@ -81,6 +82,8 @@ WidenWhileCondition(HloComputation* narrow_condition, const Shape& wide_shape) {\n   HloInstruction* call_narrow_cond = wide_while_cond->AddInstruction(\n       HloInstruction::CreateCall(ShapeUtil::MakeShape(PRED, {}),\n                                  {truncated_parameter}, narrow_condition));\n+  call_narrow_cond->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n \n   wide_while_cond->set_root_instruction(call_narrow_cond);\n \n@@ -110,6 +113,8 @@ WidenWhileBody(HloComputation* narrow_body, const Shape& wide_shape) {\n   HloInstruction* call_narrow_body =\n       wide_while_body->AddInstruction(HloInstruction::CreateCall(\n           narrow_shape, {truncated_parameter}, narrow_body));\n+  call_narrow_body->set_original_value(\n+      std::make_shared<OriginalValue>(OriginalValue::SyntheticCall()));\n \n   std::vector<HloInstruction*> live_through_values;\n   for (int i = narrow_shape.tuple_shapes().size();"
        },
        {
            "sha": "ab04c5681cd44ef59e8972e36f7058b1dd32e060",
            "filename": "third_party/xla/xla/xla_data.proto",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla_data.proto?ref=6dc423fc83a9fcc6aef7c4c666d319b9cb53c3a7",
            "patch": "@@ -1200,6 +1200,9 @@ message OriginalValueElementProto {\n \n message OriginalValueProto {\n   repeated OriginalValueElementProto elements = 1;\n+  // If true, the annotated instruction is a synthetic call and elements should\n+  // be ignored.\n+  bool is_synthetic_call = 2;\n }\n \n message GemmPerfTableEntry {"
        }
    ],
    "stats": {
        "total": 704,
        "additions": 533,
        "deletions": 171
    }
}