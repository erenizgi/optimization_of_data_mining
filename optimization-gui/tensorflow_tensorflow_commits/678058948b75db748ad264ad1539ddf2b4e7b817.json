{
    "author": "derdrdirk",
    "message": "[Autotuner] Limit CuDNN tests to CuDNN autotuner backend.\n\nPiperOrigin-RevId: 847842272",
    "sha": "678058948b75db748ad264ad1539ddf2b4e7b817",
    "files": [
        {
            "sha": "806b28020c6aca1f81ade659d1127fce90afb68a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/678058948b75db748ad264ad1539ddf2b4e7b817/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/678058948b75db748ad264ad1539ddf2b4e7b817/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2FBUILD?ref=678058948b75db748ad264ad1539ddf2b4e7b817",
            "patch": "@@ -95,7 +95,7 @@ xla_test(\n         \"//xla/hlo/testlib:pattern_matcher_gmock\",\n         \"//xla/hlo/testlib:verified_hlo_module\",\n         \"//xla/service:dump\",\n-        \"//xla/service:executable\",\n+        \"//xla/service:hlo_module_config\",\n         \"//xla/service:pattern_matcher\",\n         \"//xla/service/gpu:cudnn_support_utils\",\n         \"//xla/service/gpu:ir_emission_utils\",\n@@ -105,16 +105,16 @@ xla_test(\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:dnn\",\n         \"//xla/stream_executor:stream_executor_h\",\n-        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_googletest//:gtest_main\",\n-        \"@local_tsl//tsl/platform:env\",\n-        \"@local_tsl//tsl/platform:errors\",\n         \"@local_tsl//tsl/platform:path\",\n-        \"@local_tsl//tsl/platform:statusor\",\n-        \"@local_tsl//tsl/platform:test\",\n     ],\n )\n "
        },
        {
            "sha": "8ebf435947689e3cf3b4c3bbd2f5e660f1eabb53",
            "filename": "third_party/xla/xla/backends/gpu/codegen/cudnn_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 6,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/678058948b75db748ad264ad1539ddf2b4e7b817/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/678058948b75db748ad264ad1539ddf2b4e7b817/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcudnn_test.cc?ref=678058948b75db748ad264ad1539ddf2b4e7b817",
            "patch": "@@ -35,24 +35,24 @@ limitations under the License.\n #include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/service/dump.h\"\n-#include \"xla/service/executable.h\"\n #include \"xla/service/gpu/cudnn_support_utils.h\"\n #include \"xla/service/gpu/ir_emission_utils.h\"\n #include \"xla/service/gpu/stream_executor_util.h\"\n #include \"xla/service/gpu/tests/gpu_codegen_test.h\"\n #include \"xla/service/gpu/transforms/cudnn_fusion_compiler.h\"\n+#include \"xla/service/hlo_module_config.h\"\n #include \"xla/service/pattern_matcher.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/dnn.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n-#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/tsl/platform/env.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/platform/test.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/env.h\"\n-#include \"tsl/platform/errors.h\"\n #include \"tsl/platform/path.h\"\n-#include \"tsl/platform/statusor.h\"\n-#include \"tsl/platform/test.h\"\n \n namespace xla {\n namespace gpu {\n@@ -66,6 +66,10 @@ class CuDnnFusionTest : public GpuCodegenTest {\n     // autotuning.\n     debug_options.set_xla_gpu_autotune_level(0);\n     debug_options.set_xla_gpu_cudnn_gemm_fusion_level(2);\n+    // Only run the CuDNN backend.\n+    debug_options.clear_xla_gpu_experimental_autotune_backends();\n+    debug_options.add_xla_gpu_experimental_autotune_backends(\n+        DebugOptions::AUTOTUNE_BACKEND_CUDNN);\n     return debug_options;\n   }\n   se::CudaComputeCapability get_cuda_cc() const {\n@@ -261,12 +265,17 @@ e {\n                                      dnn_compiled_graphs);\n   EXPECT_THAT(cudnn_compiler.Run(module.get()),\n               absl_testing::IsOkAndHolds(false));\n+  // Single dot is not supported by cuDNN, so Triton should be used.\n+  HloModuleConfig config = GetModuleConfigForTest();\n+  config.mutable_debug_options().add_xla_gpu_experimental_autotune_backends(\n+      DebugOptions::AUTOTUNE_BACKEND_TRITON);\n   EXPECT_TRUE(RunAndCompareTwoModules(kHloText, R\"(e {\n     a = f32[32,96] parameter(0)\n     b = f32[96,64] parameter(1)\n     d = f32[32,64] dot(a, b),\n       lhs_contracting_dims={1}, rhs_contracting_dims={0}\n   })\",\n+                                      config, config,\n                                       ErrorSpec{/*aabs=*/1e-3, /*arel=*/1e-3}));\n }\n "
        }
    ],
    "stats": {
        "total": 33,
        "additions": 21,
        "deletions": 12
    }
}