{
    "author": "yangustc07",
    "message": "Add a unit test for revisiting elements after garbage collection.\n\nPiperOrigin-RevId: 817321791",
    "sha": "7e1d365551b469263a93bfbc73f80ad8c35881e9",
    "files": [
        {
            "sha": "5add62b32dfeb453cb9395387193feb7e11ca6e6",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2FBUILD?ref=7e1d365551b469263a93bfbc73f80ad8c35881e9",
            "patch": "@@ -131,7 +131,9 @@ tf_py_strict_test(\n     shard_count = 16,\n     deps = [\n         \":test_base\",\n+        \"//tensorflow/core/protobuf:for_core_protos_py_proto\",\n         \"//tensorflow/python/data/experimental/ops:data_service_ops\",\n+        \"//tensorflow/python/data/experimental/service:server_lib\",\n         \"//tensorflow/python/data/kernel_tests:test_base\",\n         \"//tensorflow/python/data/kernel_tests:tf_record_test_base\",\n         \"//tensorflow/python/data/ops:dataset_ops\","
        },
        {
            "sha": "2a7988b9af5a087b7745ed8a99d88cf2ba937e1a",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/data_service_ops_test.py",
            "status": "modified",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdata_service_ops_test.py?ref=7e1d365551b469263a93bfbc73f80ad8c35881e9",
            "patch": "@@ -569,37 +569,6 @@ def testDontGcJobsWithVisitationGuarantees(self):\n       time.sleep(0.1)\n     self.assertEqual(cluster.workers[0].num_tasks(), 1)\n \n-  @combinations.generate(test_base.eager_only_combinations())\n-  def testGcDynamicShardingJobIfRequested(self):\n-    dispatcher = server_lib.DispatchServer(\n-        service_config_pb2.DispatcherConfig(\n-            protocol=\"grpc\",\n-            job_gc_check_interval_ms=50,\n-            job_gc_timeout_ms=20,\n-            gc_dynamic_sharding_jobs=True,\n-        )\n-    )\n-    dispatcher_address = dispatcher.target.split(\"://\")[1]\n-    worker = server_lib.WorkerServer(\n-        server_lib.WorkerConfig(\n-            dispatcher_address=dispatcher_address, heartbeat_interval_ms=100\n-        )\n-    )\n-\n-    num_elements = 1000\n-    dataset = dataset_ops.Dataset.range(num_elements)\n-    dataset = dataset.apply(\n-        data_service_ops._distribute(\n-            processing_mode=data_service_ops.ShardingPolicy.DYNAMIC,\n-            service=dispatcher.target,\n-        )\n-    )\n-    it = iter(dataset)\n-    self.assertEqual(worker._num_tasks(), 1)\n-    del it\n-    while worker._num_tasks() > 0:\n-      time.sleep(0.1)\n-\n   @combinations.generate(test_base.eager_only_combinations())\n   def testGcAndRecreate(self):\n     cluster = self.make_test_cluster("
        },
        {
            "sha": "49b5f01acf0468c0a796113d263198c8d3d49dd5",
            "filename": "tensorflow/python/data/experimental/kernel_tests/service/dynamic_sharding_test.py",
            "status": "modified",
            "additions": 43,
            "deletions": 0,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7e1d365551b469263a93bfbc73f80ad8c35881e9/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fdata%2Fexperimental%2Fkernel_tests%2Fservice%2Fdynamic_sharding_test.py?ref=7e1d365551b469263a93bfbc73f80ad8c35881e9",
            "patch": "@@ -14,12 +14,15 @@\n # ==============================================================================\n \"\"\"Tests for dynamic sharding.\"\"\"\n import collections\n+import time\n \n from absl.testing import parameterized\n import numpy as np\n \n+from tensorflow.core.protobuf import service_config_pb2\n from tensorflow.python.data.experimental.kernel_tests.service import test_base as data_service_test_base\n from tensorflow.python.data.experimental.ops import data_service_ops\n+from tensorflow.python.data.experimental.service import server_lib\n from tensorflow.python.data.kernel_tests import test_base\n from tensorflow.python.data.kernel_tests import tf_record_test_base\n from tensorflow.python.data.ops import dataset_ops\n@@ -503,6 +506,46 @@ def testDifferentDatasetIdsForSameJob(self):\n     # dataset ID to the job name.\n     self.assertCountEqual(output, list(range(100)) * 2)\n \n+  @combinations.generate(test_base.eager_only_combinations())\n+  def testGcDynamicShardingJobIfRequested(self):\n+    dispatcher = server_lib.DispatchServer(\n+        service_config_pb2.DispatcherConfig(\n+            protocol=\"grpc\",\n+            job_gc_check_interval_ms=50,\n+            job_gc_timeout_ms=20,\n+            gc_dynamic_sharding_jobs=True,\n+        )\n+    )\n+    dispatcher_address = dispatcher.target.split(\"://\")[1]\n+    worker = server_lib.WorkerServer(\n+        server_lib.WorkerConfig(\n+            dispatcher_address=dispatcher_address, heartbeat_interval_ms=100\n+        )\n+    )\n+\n+    num_elements = 1000\n+    dataset = dataset_ops.Dataset.range(num_elements)\n+    dataset = dataset.apply(\n+        data_service_ops._distribute(\n+            processing_mode=data_service_ops.ShardingPolicy.DYNAMIC,\n+            service=dispatcher.target,\n+        )\n+    )\n+    it = iter(dataset)\n+    self.assertEqual(self.evaluate(next(it)), 0)\n+    self.assertEqual(worker._num_tasks(), 1)\n+    del it\n+    while worker._num_tasks() > 0:\n+      time.sleep(0.1)\n+\n+    # If re-creating the iterator with the same job, the elements are revisited.\n+    it = iter(dataset)\n+    self.assertEqual(self.evaluate(next(it)), 0)\n+    del it\n+    while worker._num_tasks() > 0:\n+      time.sleep(0.1)\n+    del worker\n+\n \n class DynamicShardingFilesTest(data_service_test_base.TestBase,\n                                tf_record_test_base.TFRecordTestBase,"
        }
    ],
    "stats": {
        "total": 76,
        "additions": 45,
        "deletions": 31
    }
}