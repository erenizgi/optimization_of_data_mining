{
    "author": "lrdxgm",
    "message": "Add constant folding for `tfl.ceil` on `f32` tensors.\n\nCode and tests are copied from `tfl.floor`, replacing `std::floor` with `std::ceil` in the code.\n\nPiperOrigin-RevId: 799784759",
    "sha": "f857d710ed2bbe0e3f3f41cc79c0c48f27dded08",
    "files": [
        {
            "sha": "3bd61fa793789d8a8f0c38f77736d76f6c6d2100",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.cc",
            "status": "modified",
            "additions": 20,
            "deletions": 0,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.cc?ref=f857d710ed2bbe0e3f3f41cc79c0c48f27dded08",
            "patch": "@@ -989,6 +989,26 @@ int64_t AddOp::GetArithmeticCount(Operation* op) {\n   return -1;\n }\n \n+//===----------------------------------------------------------------------===//\n+// CeilOp\n+//===----------------------------------------------------------------------===//\n+\n+OpFoldResult CeilOp::fold(FoldAdaptor adaptor) {\n+  if (!ShouldFoldOperation(this->getOperation())) return {};\n+\n+  auto operands = adaptor.getOperands();\n+  auto result_type = getType();\n+  if (!IsF32ShapedType(result_type)) return {};\n+\n+  auto compute = [](APFloat value) -> APFloat {\n+    float f = value.convertToFloat();\n+    float result = std::ceil(f);\n+    return APFloat(result);\n+  };\n+\n+  return ConstFoldUnaryOp(result_type, operands[0], compute);\n+}\n+\n //===----------------------------------------------------------------------===//\n // FloorOp\n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "a6940719fc36e9d999416526bc6a0bd5ceb65654",
            "filename": "tensorflow/compiler/mlir/lite/ir/tfl_ops.td",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fir%2Ftfl_ops.td?ref=f857d710ed2bbe0e3f3f41cc79c0c48f27dded08",
            "patch": "@@ -828,6 +828,8 @@ def TFL_CeilOp: TFL_Op<\"ceil\", [\n \n   let results = (outs TFL_FpTensor:$y);\n \n+  let hasFolder = 1;\n+\n   let extraClassDeclaration = [{\n     // Returns whether the return types are compatible.\n     static bool isCompatibleReturnTypes(TypeRange l, TypeRange r) {"
        },
        {
            "sha": "fd76b1a2666fe3933573df2cfcd3b3fa6f96ff72",
            "filename": "tensorflow/compiler/mlir/lite/tests/const-fold.mlir",
            "status": "modified",
            "additions": 16,
            "deletions": 3,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f857d710ed2bbe0e3f3f41cc79c0c48f27dded08/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Fconst-fold.mlir?ref=f857d710ed2bbe0e3f3f41cc79c0c48f27dded08",
            "patch": "@@ -1602,16 +1602,30 @@ func.func @select_float() -> tensor<4xf32> {\n \n   func.return %2 : tensor<4xf32>\n }\n-\n // CHECK: %cst = arith.constant dense<[1.000000e+00, 2.000000e+00, -3.000000e+00, -4.000000e+00]> : tensor<4xf32\n \n+// CHECK-LABEL: ceil\n+func.func @ceil() -> tensor<3xf32> {\n+  %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf32>\n+  %0 = \"tfl.ceil\"(%cst) : (tensor<3xf32>) -> tensor<3xf32>\n+  func.return %0 : tensor<3xf32>\n+}\n+// CHECK: %cst = arith.constant dense<[-1.000000e+00, 0.000000e+00, 1.000000e+00]> : tensor<3xf32>\n+\n+// CHECK-LABEL: ceil_f64\n+func.func @ceil_f64() -> tensor<3xf64> {\n+  %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf64>\n+  %0 = \"tfl.ceil\"(%cst) : (tensor<3xf64>) -> tensor<3xf64>\n+  func.return %0 : tensor<3xf64>\n+}\n+// CHECK: tfl.ceil\n+\n // CHECK-LABEL: floor\n func.func @floor() -> tensor<3xf32> {\n   %cst = arith.constant dense<[-1.0, 0.0, 0.99]> : tensor<3xf32>\n   %0 = \"tfl.floor\"(%cst) : (tensor<3xf32>) -> tensor<3xf32>\n   func.return %0 : tensor<3xf32>\n }\n-\n // CHECK: %cst = arith.constant dense<[-1.000000e+00, 0.000000e+00, 0.000000e+00]> : tensor<3xf32>\n \n // CHECK-LABEL: floor_f64\n@@ -1620,7 +1634,6 @@ func.func @floor_f64() -> tensor<3xf64> {\n   %0 = \"tfl.floor\"(%cst) : (tensor<3xf64>) -> tensor<3xf64>\n   func.return %0 : tensor<3xf64>\n }\n-\n // CHECK: tfl.floor\n \n // CHECK-LABEL: exp"
        }
    ],
    "stats": {
        "total": 41,
        "additions": 38,
        "deletions": 3
    }
}