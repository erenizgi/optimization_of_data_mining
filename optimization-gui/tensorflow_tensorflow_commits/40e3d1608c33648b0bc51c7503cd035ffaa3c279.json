{
    "author": "cota",
    "message": "re-enable TF XLA:GPU test\n\nPiperOrigin-RevId: 811727663",
    "sha": "40e3d1608c33648b0bc51c7503cd035ffaa3c279",
    "files": [
        {
            "sha": "aee8181273115ad808eee34a30143dacf2299b4a",
            "filename": "tensorflow/python/kernel_tests/distributions/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/40e3d1608c33648b0bc51c7503cd035ffaa3c279/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/40e3d1608c33648b0bc51c7503cd035ffaa3c279/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2FBUILD?ref=40e3d1608c33648b0bc51c7503cd035ffaa3c279",
            "patch": "@@ -27,7 +27,6 @@ cuda_py_strict_test(\n     size = \"medium\",\n     srcs = [\"util_test.py\"],\n     shard_count = 3,\n-    xla_enable_strict_auto_jit = False,  # TODO(b/144920376)\n     deps = [\n         \"//tensorflow/python/eager:context\",\n         \"//tensorflow/python/framework:constant_op\","
        },
        {
            "sha": "c8fc64fda090bfdaf4eb1ebcd1a9690a5b049bb3",
            "filename": "tensorflow/python/kernel_tests/distributions/util_test.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/40e3d1608c33648b0bc51c7503cd035ffaa3c279/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2Futil_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/40e3d1608c33648b0bc51c7503cd035ffaa3c279/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2Futil_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fpython%2Fkernel_tests%2Fdistributions%2Futil_test.py?ref=40e3d1608c33648b0bc51c7503cd035ffaa3c279",
            "patch": "@@ -925,9 +925,9 @@ def _testSoftplus(self, np_features, use_gpu=False):\n       softplus_inverse = du.softplus_inverse(softplus)\n       [tf_softplus, tf_softplus_inverse] = sess.run([\n           softplus, softplus_inverse])\n-    self.assertAllCloseAccordingToType(np_softplus, tf_softplus)\n     rtol = {\"float16\": 0.07, \"float32\": 0.003, \"float64\": 0.002}.get(\n         str(np_features.dtype), 1e-6)\n+    self.assertAllCloseAccordingToType(np_softplus, tf_softplus, rtol=rtol)\n     # This will test that we correctly computed the inverse by verifying we\n     # recovered the original input.\n     self.assertAllCloseAccordingToType("
        }
    ],
    "stats": {
        "total": 3,
        "additions": 1,
        "deletions": 2
    }
}