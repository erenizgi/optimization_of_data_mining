{
    "author": "basioli-k",
    "message": "[XLA:CPU][codegen] Implement transpose optimized for 8x8 tiles.\n\nPiperOrigin-RevId: 837773477",
    "sha": "4ba94b04bc6b88eed24a8548e6bef31947b7bbca",
    "files": [
        {
            "sha": "1f74e57abe45a5b078710cbe1bb4eedcaab9036f",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/transforms/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2FBUILD?ref=4ba94b04bc6b88eed24a8548e6bef31947b7bbca",
            "patch": "@@ -61,7 +61,9 @@ cc_library(\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TensorDialect\",\n         \"@llvm-project//mlir:TransformUtils\",\n+        \"@llvm-project//mlir:UBDialect\",\n         \"@llvm-project//mlir:VectorDialect\",\n+        \"@llvm-project//mlir:VectorUtils\",\n     ],\n )\n \n@@ -82,5 +84,8 @@ cc_library(\n         \"@llvm-project//mlir:LLVMDialect\",\n         \"@llvm-project//mlir:Support\",\n         \"@llvm-project//mlir:TransformUtils\",\n+        \"@llvm-project//mlir:UBDialect\",\n+        \"@llvm-project//mlir:VectorDialect\",\n+        \"@llvm-project//mlir:VectorUtils\",\n     ],\n )"
        },
        {
            "sha": "366345447548566ae644d040bfcce602abbf9d73",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/transforms/tests/lower_to_llvm.mlir",
            "status": "modified",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Flower_to_llvm.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Flower_to_llvm.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Ftests%2Flower_to_llvm.mlir?ref=4ba94b04bc6b88eed24a8548e6bef31947b7bbca",
            "patch": "@@ -139,3 +139,72 @@ func.func private @wrap_entry(\n // CHECK:         %[[ARG_2:.+]]: index, %[[ARG_3:.+]]: index, %[[ARG_4:.+]]: index)\n // CHECK:       return %[[ARG_0]], %[[ARG_1]], %[[ARG_3]], %[[ARG_2]], %[[ARG_4]]\n // CHECK:      }\n+\n+// -----\n+\n+func.func @test_8x8_vector_transpose_lowering(%arg0: vector<8x8xf32>) -> vector<8x8xf32> {\n+  %0 = vector.transpose %arg0, [1, 0] : vector<8x8xf32> to vector<8x8xf32>\n+  return %0 : vector<8x8xf32>\n+}\n+\n+// CHECK @test_8x8_vector_transpose_lowering(%[[ARG_0:.+]]: vector<8x8xf32>) -> vector<8x8xf32> {\n+// CHECK:      %[[POISON_RESULT:.+]] = ub.poison : vector<8x8xf32>\n+// CHECK:      %[[R0:.+]] = vector.extract %[[ARG_0]][0]\n+// CHECK:      %[[R1:.+]] = vector.extract %[[ARG_0]][1\n+// CHECK:      %[[R2:.+]] = vector.extract %[[ARG_0]][2]\n+// CHECK:      %[[R3:.+]] = vector.extract %[[ARG_0]][3]\n+// CHECK:      %[[R4:.+]] = vector.extract %[[ARG_0]][4]\n+// CHECK:      %[[R5:.+]] = vector.extract %[[ARG_0]][5]\n+// CHECK:      %[[R6:.+]] = vector.extract %[[ARG_0]][6]\n+// CHECK:      %[[R7:.+]] = vector.extract %[[ARG_0]][7]\n+\n+// CHECK:      %[[T0:.+]] = vector.shuffle %[[R0]], %[[R1]] [0, 8, 2, 10, 4, 12, 6, 14] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T1:.+]] = vector.shuffle %[[R0]], %[[R1]] [1, 9, 3, 11, 5, 13, 7, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T2:.+]] = vector.shuffle %[[R2]], %[[R3]] [0, 8, 2, 10, 4, 12, 6, 14] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T3:.+]] = vector.shuffle %[[R2]], %[[R3]] [1, 9, 3, 11, 5, 13, 7, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T4:.+]] = vector.shuffle %[[R4]], %[[R5]] [0, 8, 2, 10, 4, 12, 6, 14] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T5:.+]] = vector.shuffle %[[R4]], %[[R5]] [1, 9, 3, 11, 5, 13, 7, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T6:.+]] = vector.shuffle %[[R6]], %[[R7]] [0, 8, 2, 10, 4, 12, 6, 14] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[T7:.+]] = vector.shuffle %[[R6]], %[[R7]] [1, 9, 3, 11, 5, 13, 7, 15] : vector<8xf32>, vector<8xf32>\n+\n+// CHECK:      %[[U0:.+]] = vector.shuffle %[[T0]], %[[T2]] [0, 1, 8, 9, 4, 5, 12, 13] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U2:.+]] = vector.shuffle %[[T0]], %[[T2]] [2, 3, 10, 11, 6, 7, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U1:.+]] = vector.shuffle %[[T1]], %[[T3]] [0, 1, 8, 9, 4, 5, 12, 13] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U3:.+]] = vector.shuffle %[[T1]], %[[T3]] [2, 3, 10, 11, 6, 7, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U4:.+]] = vector.shuffle %[[T4]], %[[T6]] [0, 1, 8, 9, 4, 5, 12, 13] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U6:.+]] = vector.shuffle %[[T4]], %[[T6]] [2, 3, 10, 11, 6, 7, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U5:.+]] = vector.shuffle %[[T5]], %[[T7]] [0, 1, 8, 9, 4, 5, 12, 13] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[U7:.+]] = vector.shuffle %[[T5]], %[[T7]] [2, 3, 10, 11, 6, 7, 14, 15] : vector<8xf32>, vector<8xf32>\n+\n+// CHECK:      %[[W0:.+]] = vector.shuffle %[[U0]], %[[U4]] [0, 1, 2, 3, 8, 9, 10, 11] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W4:.+]] = vector.shuffle %[[U0]], %[[U4]] [4, 5, 6, 7, 12, 13, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W1:.+]] = vector.shuffle %[[U1]], %[[U5]] [0, 1, 2, 3, 8, 9, 10, 11] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W5:.+]] = vector.shuffle %[[U1]], %[[U5]] [4, 5, 6, 7, 12, 13, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W2:.+]] = vector.shuffle %[[U2]], %[[U6]] [0, 1, 2, 3, 8, 9, 10, 11] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W6:.+]] = vector.shuffle %[[U2]], %[[U6]] [4, 5, 6, 7, 12, 13, 14, 15] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W3:.+]] = vector.shuffle %[[U3]], %[[U7]] [0, 1, 2, 3, 8, 9, 10, 11] : vector<8xf32>, vector<8xf32>\n+// CHECK:      %[[W7:.+]] = vector.shuffle %[[U3]], %[[U7]] [4, 5, 6, 7, 12, 13, 14, 15] : vector<8xf32>, vector<8xf32>\n+\n+// CHECK:      %[[RES_0:.+]] = vector.insert %[[W0]], %[[POISON_RESULT]] [0]\n+// CHECK:      %[[RES_1:.+]] = vector.insert %[[W1]], %[[RES_0]] [1]\n+// CHECK:      %[[RES_2:.+]] = vector.insert %[[W2]], %[[RES_1]] [2]\n+// CHECK:      %[[RES_3:.+]] = vector.insert %[[W3]], %[[RES_2]] [3]\n+// CHECK:      %[[RES_4:.+]] = vector.insert %[[W4]], %[[RES_3]] [4]\n+// CHECK:      %[[RES_5:.+]] = vector.insert %[[W5]], %[[RES_4]] [5]\n+// CHECK:      %[[RES_6:.+]] = vector.insert %[[W6]], %[[RES_5]] [6]\n+// CHECK:      %[[RES_7:.+]] = vector.insert %[[W7]], %[[RES_6]] [7]\n+\n+// CHECK-NEXT: return %[[RES_7]] : vector<8x8xf32>\n+// CHECK:      }\n+\n+// -----\n+\n+func.func @test_other_vector_transpose_shape_falls_back_to_vector(%arg0: vector<8x16xf32>) -> vector<16x8xf32> {\n+  %0 = vector.transpose %arg0, [1, 0] : vector<8x16xf32> to vector<16x8xf32>\n+  return %0 : vector<16x8xf32>\n+}\n+\n+// CHECK @test_other_vector_transpose_shape_falls_back_to_vector(%[[ARG_0:.+]]: vector<8x16xf32>) -> vector<16x8xf32> {\n+// CHECK:      %[[RES:.+]] = vector.transpose %[[ARG_0]], [1, 0] : vector<8x16xf32> to vector<16x8xf32>\n+// CHECK-NEXT: return %[[RES]] : vector<16x8xf32>\n+// CHECK:      }"
        },
        {
            "sha": "fd71b9ee8d36f086e2a976a7d8bd4018d64b9f4e",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/transforms/xla_cpu_rewrite_patterns.cc",
            "status": "modified",
            "additions": 159,
            "deletions": 3,
            "changes": 162,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fxla_cpu_rewrite_patterns.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fxla_cpu_rewrite_patterns.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Ftransforms%2Fxla_cpu_rewrite_patterns.cc?ref=4ba94b04bc6b88eed24a8548e6bef31947b7bbca",
            "patch": "@@ -15,6 +15,7 @@ limitations under the License.\n \n #include \"xla/backends/cpu/codegen/emitters/transforms/xla_cpu_rewrite_patterns.h\"\n \n+#include <array>\n #include <cstdint>\n #include <string>\n \n@@ -28,11 +29,13 @@ limitations under the License.\n #include \"mlir/Dialect/LLVMIR/LLVMAttrs.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMTypes.h\"\n+#include \"mlir/Dialect/UB/IR/UBOps.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/Dialect/Vector/Utils/VectorUtils.h\"\n #include \"mlir/IR/Attributes.h\"\n #include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n-#include \"mlir/IR/ImplicitLocOpBuilder.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/Interfaces/DataLayoutInterfaces.h\"\n@@ -392,13 +395,166 @@ class WrapEntryWithCallFrame\n   int32_t vector_width_;\n };\n \n+// Implementation similar to https://gudok.xyz/transpose/#_64_bit_simd_0_74.\n+\n+// Example that follows changes in the first row.\n+// Let rows[i][j] = i * 8 + j\n+\n+// Round 1: Transpose 2x2 blocks\n+\n+// rows[0]: [0, 1, 2, 3, 4, 5, 6, 7]\n+// rows[1]: [8, 9, 10, 11, 12, 13, 14, 15]\n+\n+// maps to:\n+\n+// t0: [0, 8, 2, 10, 4, 12, 6, 14]\n+// t1: [1, 9, 3, 11, 5, 13, 7, 15]\n+\n+// Round 2: Transpose 4x4 blocks (Swapping 2-element pairs).\n+\n+// t0: [0, 8, 2, 10, 4, 12, 6, 14]\n+// t2: [16, 24, 18, 26, 20, 28, 22, 30]\n+\n+// maps to:\n+\n+// u0: [0, 8, 16, 24, 4, 12, 20, 28]\n+// u2: [2, 10, 18, 26, 6, 14, 22, 30]\n+\n+// Round 3: Transpose 8x8 blocks (Swapping 4-element groups across\n+// 128-bit lanes).\n+\n+// u0: [0, 8, 16, 24, 4, 12, 20, 28]\n+// u4: [32, 40, 48, 56, 36, 44, 52, 60]\n+\n+// maps to:\n+\n+// w0: [0, 8, 16, 24, 32, 40, 48, 56]     // Result row 0\n+// w4: [4, 12, 20, 28, 36, 44, 52, 60]    // Result row 4\n+mlir::Value Shuffle8x8(mlir::PatternRewriter& rewriter, mlir::Location loc,\n+                       mlir::Type result_type, mlir::Value source, int m,\n+                       int n) {\n+  llvm::SmallVector<mlir::Value> rows;\n+\n+  for (int row = 0; row < m; ++row) {\n+    rows.push_back(mlir::vector::ExtractOp::create(rewriter, loc, source, row));\n+  }\n+\n+  // Round 1\n+\n+  llvm::SmallVector<mlir::Value> rows_round1(rows.size());\n+\n+  // Interleave inside the 2x2 blocks.\n+  for (const auto i : {0, 2, 4, 6}) {\n+    constexpr int64_t kRound1Step = 1;\n+    constexpr std::array<int64_t, 8> kUpperBlockMask = {0, 8,  2, 10,\n+                                                        4, 12, 6, 14};\n+    constexpr std::array<int64_t, 8> kLowerBlockMask = {1, 9,  3, 11,\n+                                                        5, 13, 7, 15};\n+\n+    rows_round1[i] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows[i], rows[i + kRound1Step], kUpperBlockMask);\n+\n+    rows_round1[i + kRound1Step] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows[i], rows[i + kRound1Step], kLowerBlockMask);\n+  }\n+\n+  // Round 2\n+\n+  llvm::SmallVector<mlir::Value> rows_round2(rows.size());\n+\n+  // Interleave adjacent 2x2 blocks.\n+  for (const auto i : {0, 1, 4, 5}) {\n+    constexpr int64_t kRound2Step = 2;\n+    constexpr std::array<int64_t, 8> kUpperBlockMask = {0, 1, 8,  9,\n+                                                        4, 5, 12, 13};\n+    constexpr std::array<int64_t, 8> kLowerBlockMask = {2, 3, 10, 11,\n+                                                        6, 7, 14, 15};\n+    rows_round2[i] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows_round1[i], rows_round1[i + kRound2Step],\n+        kUpperBlockMask);\n+\n+    rows_round2[i + kRound2Step] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows_round1[i], rows_round1[i + kRound2Step],\n+        kLowerBlockMask);\n+  }\n+\n+  // Round 3\n+\n+  llvm::SmallVector<mlir::Value> rows_round3(rows.size());\n+\n+  // Interleave adjacent 4x4 blocks.\n+  for (const auto i : {0, 1, 2, 3}) {\n+    constexpr int64_t kRound3Step = 4;\n+    constexpr std::array<int64_t, 8> kUpperBlockMask = {0, 1, 2,  3,\n+                                                        8, 9, 10, 11};\n+    constexpr std::array<int64_t, 8> kLowerBlockMask = {4,  5,  6,  7,\n+                                                        12, 13, 14, 15};\n+    rows_round3[i] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows_round2[i], rows_round2[i + kRound3Step],\n+        kUpperBlockMask);\n+\n+    rows_round3[i + kRound3Step] = mlir::vector::ShuffleOp::create(\n+        rewriter, loc, rows_round2[i], rows_round2[i + kRound3Step],\n+        kLowerBlockMask);\n+  }\n+\n+  mlir::Value result = mlir::ub::PoisonOp::create(rewriter, loc, result_type);\n+\n+  for (int row_index = 0; row_index < rows_round3.size(); ++row_index) {\n+    result = mlir::vector::InsertOp::create(\n+        rewriter, loc, rows_round3[row_index], result, row_index);\n+  }\n+\n+  return result;\n+}\n+\n+struct LowerVector2DTransposeOp\n+    : public mlir::OpRewritePattern<mlir::vector::TransposeOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::vector::TransposeOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    auto src_gt_one_dims = isTranspose2DSlice(op);\n+    if (mlir::failed(src_gt_one_dims)) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"expected transposition on a 2D slice\");\n+    }\n+\n+    mlir::VectorType srcType = op.getSourceVectorType();\n+    int64_t m = srcType.getDimSize(std::get<0>(src_gt_one_dims.value()));\n+    int64_t n = srcType.getDimSize(std::get<1>(src_gt_one_dims.value()));\n+\n+    if (!(m == 8 && n == 8)) {\n+      return rewriter.notifyMatchFailure(\n+          op, \"expected transposition on a 8x8 vector\");\n+    }\n+\n+    // Reshape the n-D input vector with only two dimensions greater than one\n+    // to a 2-D vector.\n+    mlir::Location loc = op.getLoc();\n+    auto reshInputType =\n+        mlir::VectorType::get({m, n}, srcType.getElementType());\n+    auto reshInput = mlir::vector::ShapeCastOp::create(\n+        rewriter, loc, reshInputType, op.getVector());\n+\n+    auto output_type = mlir::VectorType::get({n, m}, srcType.getElementType());\n+\n+    auto res = Shuffle8x8(rewriter, loc, output_type, reshInput, m, n);\n+\n+    rewriter.replaceOpWithNewOp<mlir::vector::ShapeCastOp>(\n+        op, op.getResultVectorType(), res);\n+\n+    return mlir::success();\n+  }\n+};\n+\n }  // namespace\n \n void PopulateXlaCpuConversionPatterns(mlir::RewritePatternSet& patterns,\n                                       int32_t vector_width) {\n   patterns.add<LowerLoadOp, LowerWorkGroupIdOp, LowerSuccessOp,\n-               RewriteFunctionSignatures, LowerExtractWorkgroupIdOp>(\n-      patterns.getContext());\n+               RewriteFunctionSignatures, LowerExtractWorkgroupIdOp,\n+               LowerVector2DTransposeOp>(patterns.getContext());\n   patterns.add<WrapEntryWithCallFrame>(patterns.getContext(), vector_width);\n }\n "
        },
        {
            "sha": "436732c970c97876eb8f783dc28c14c04b93756c",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ba94b04bc6b88eed24a8548e6bef31947b7bbca/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=4ba94b04bc6b88eed24a8548e6bef31947b7bbca",
            "patch": "@@ -351,8 +351,11 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm, bool fast_min_max) {\n   pm.addPass(mlir::createConvertVectorToSCFPass(\n       mlir::VectorTransferToSCFOptions().enableFullUnroll(false)));\n   mlir::ConvertVectorToLLVMPassOptions options;\n+\n+  // If the tile size is 16x16 this will generate the most efficient code for\n+  // avx512 platforms.\n   options.vectorTransposeLowering =\n-      mlir::vector::VectorTransposeLowering::Shuffle1D;\n+      mlir::vector::VectorTransposeLowering::Shuffle16x16;\n   pm.addPass(mlir::createConvertVectorToLLVMPass(options));\n \n   pm.addPass(mlir::createConvertComplexToStandardPass());"
        }
    ],
    "stats": {
        "total": 241,
        "additions": 237,
        "deletions": 4
    }
}