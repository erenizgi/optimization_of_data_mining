{
    "author": "majiddadashi",
    "message": "Enable lowering from FQ Composite for 2-bit\n\nThis also adds an additional test for this lowering.\n\nPiperOrigin-RevId: 820534395",
    "sha": "46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9",
    "files": [
        {
            "sha": "1653eb8a737482f545b6ca96c612f5d5d8c14d26",
            "filename": "tensorflow/compiler/mlir/lite/quantization/common/quantization_lib/quantization.td",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fquantization%2Fcommon%2Fquantization_lib%2Fquantization.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fquantization%2Fcommon%2Fquantization_lib%2Fquantization.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Fquantization%2Fcommon%2Fquantization_lib%2Fquantization.td?ref=46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9",
            "patch": "@@ -56,6 +56,7 @@ class Int8UniformQuantizedType<int zero_pt, int smantissa, int sexp>\n \n // General uniform quantized types. The definitions can be used to specify\n // operand's tensor types.\n+def QI2 : QuantizedType<\"Uniform\", [2], 1>;\n def QI4 : QuantizedType<\"Uniform\", [4], 1>;\n def QUI8 : QuantizedType<\"Uniform\", [8], 0>;\n def QI8 : QuantizedType<\"Uniform\", [8], 1>;"
        },
        {
            "sha": "62434d956f8609e9146dfcb91786718f754bda9d",
            "filename": "tensorflow/compiler/mlir/lite/tests/lower_quant_annotations.mlir",
            "status": "modified",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flower_quant_annotations.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flower_quant_annotations.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftests%2Flower_quant_annotations.mlir?ref=46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9",
            "patch": "@@ -3,6 +3,8 @@\n func.func private @XlaCallModule_quant.fake_quant.impl_0(tensor<1x28x28x3xf32>) -> tensor<1x28x28x3xf32>\n func.func private @XlaCallModule_quant.fake_quant.impl_5_0(tensor<2x1x1x1xf32>) -> tensor<2x1x1x1xf32>\n func.func private @XlaCallModule_quant.fake_quant.impl_17_0(tensor<1x30x30x2xf32>) -> tensor<1x30x30x2xf32>\n+func.func private @XlaCallModule_quant.fake_quant.impl_i2_0(tensor<1x4xf32>) -> tensor<1x4xf32>\n+func.func private @XlaCallModule_quant.fake_quant.impl_i2_1(tensor<1x4xf32>) -> tensor<1x4xf32>\n // CHECK-LABEL: func.func @serving_default\n func.func @serving_default(%arg0: tensor<1x28x28x3xf32>) -> (tensor<1x30x30x2xf32>) {\n   %cst = arith.constant dense<[[0, 0], [1, 1], [1, 1], [0, 0]]> : tensor<4x2xi32>\n@@ -22,4 +24,15 @@ func.func @serving_default(%arg0: tensor<1x28x28x3xf32>) -> (tensor<1x30x30x2xf3\n   // CHECK-OFF: %[[DEQUANT2:.+]] = \"tfl.dequantize\"(%[[QUANT2]]) : (tensor<1x30x30x2x!quant.uniform<i8:f32, 0.018049469217658043:8>>) -> tensor<1x30x30x2xf32>\n   %5 = stablehlo.composite \"quant.fake_quant\" %4 {composite_attributes = {dtype = \"i8\", narrow_range = false, scale = dense<0.0180494692> : tensor<1xf32>, zero_point = dense<8> : tensor<1xi32>}, decomposition = @XlaCallModule_quant.fake_quant.impl_17_0} : (tensor<1x30x30x2xf32>) -> tensor<1x30x30x2xf32>\n   return %5 : tensor<1x30x30x2xf32>\n+}\n+\n+// CHECK-LABEL: func.func @i2_test\n+func.func @i2_test(%arg0: tensor<1x4xf32>) -> (tensor<1x4xf32>) {\n+  // CHECK: %[[QUANT0:.+]] = \"tfl.quantize\"(%arg0) <{qtype = tensor<1x4x!quant.uniform<i2:f32, 1.000000e+00>>}> : (tensor<1x4xf32>) -> tensor<1x4x!quant.uniform<i2:f32, 1.000000e+00>>\n+  // CHECK: %[[DEQUANT0:.+]] = \"tfl.dequantize\"(%[[QUANT0]]) : (tensor<1x4x!quant.uniform<i2:f32, 1.000000e+00>>) -> tensor<1x4xf32>\n+  %0 = stablehlo.composite \"quant.fake_quant\" %arg0 {composite_attributes = {dtype = \"i2\", narrow_range = false, scale = dense<1.0> : tensor<1xf32>, zero_point = dense<0> : tensor<1xi32>}, decomposition = @XlaCallModule_quant.fake_quant.impl_i2_0} : (tensor<1x4xf32>) -> tensor<1x4xf32>\n+  // CHECK: %[[QUANT1:.+]] = \"tfl.quantize\"(%[[DEQUANT0]]) <{qtype = tensor<1x4x!quant.uniform<i2<-1:1>:f32:1, {1.000000e+00,2.000000e+00,3.000000e+00,4.000000e+00}>>}> : (tensor<1x4xf32>) -> tensor<1x4x!quant.uniform<i2<-1:1>:f32:1, {1.000000e+00,2.000000e+00,3.000000e+00,4.000000e+00}>>\n+  // CHECK: %[[DEQUANT1:.+]] = \"tfl.dequantize\"(%[[QUANT1]]) : (tensor<1x4x!quant.uniform<i2<-1:1>:f32:1, {1.000000e+00,2.000000e+00,3.000000e+00,4.000000e+00}>>) -> tensor<1x4xf32>\n+  %1 = stablehlo.composite \"quant.fake_quant\" %0 {composite_attributes = {dtype = \"i2\", narrow_range = true, quantization_dimension = 1 : i32, scale = dense<[1.0, 2.0, 3.0, 4.0]> : tensor<4xf32>}, decomposition = @XlaCallModule_quant.fake_quant.impl_i2_1} : (tensor<1x4xf32>) -> tensor<1x4xf32>\n+  return %1 : tensor<1x4xf32>\n }\n\\ No newline at end of file"
        },
        {
            "sha": "6caa210779984436564bae085b8c806f6ec2cb87",
            "filename": "tensorflow/compiler/mlir/lite/transforms/lower_quant_annotations_helper.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_helper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_helper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fmlir%2Flite%2Ftransforms%2Flower_quant_annotations_helper.cc?ref=46f983d3ff7a38e3062d63ad5ef5d38ec77ca1f9",
            "patch": "@@ -71,12 +71,15 @@ LogicalResult FillCompositeParams(stablehlo::CompositeOp op,\n     return failure();\n   }\n   std::string dtype = dtype_attr.getValue().str();\n-  if (dtype == \"i8\") {\n-    num_bits = 8;\n+  if (dtype == \"i2\") {\n+    num_bits = 2;\n     is_signed = true;\n   } else if (dtype == \"i4\") {\n     num_bits = 4;\n     is_signed = true;\n+  } else if (dtype == \"i8\") {\n+    num_bits = 8;\n+    is_signed = true;\n   } else {\n     return failure();\n   }\n@@ -110,7 +113,16 @@ LogicalResult GetStorageParams(unsigned num_bits, bool narrow_range,\n                                bool is_signed, MLIRContext* ctx,\n                                Type& storage_type, int64_t& qmin,\n                                int64_t& qmax) {\n-  if (num_bits <= 4) {\n+  if (num_bits == 2) {\n+    storage_type = IntegerType::get(ctx, 2);\n+    if (is_signed) {\n+      qmin = -2;\n+      qmax = 1;\n+    } else {\n+      qmin = 0;\n+      qmax = 3;\n+    }\n+  } else if (num_bits <= 4) {\n     storage_type = IntegerType::get(ctx, 4);\n     if (is_signed) {\n       qmin = -8;"
        }
    ],
    "stats": {
        "total": 32,
        "additions": 29,
        "deletions": 3
    }
}