{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 847189531",
    "sha": "8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
    "files": [
        {
            "sha": "3163f4e62c320a2906ec9e549e0d803ccae4484c",
            "filename": "tensorflow/core/kernels/data/experimental/parallel_interleave_dataset_op.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 16,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fparallel_interleave_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fparallel_interleave_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fparallel_interleave_dataset_op.cc?ref=8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
            "patch": "@@ -112,9 +112,9 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n         output_shapes_(output_shapes),\n         traceme_metadata_(\n             {{\"block_length\",\n-              strings::Printf(\"%lld\", static_cast<long long>(block_length))},\n+              absl::StrFormat(\"%lld\", static_cast<long long>(block_length))},\n              {\"cycle_length\",\n-              strings::Printf(\"%lld\", static_cast<long long>(cycle_length))},\n+              absl::StrFormat(\"%lld\", static_cast<long long>(cycle_length))},\n              {\"deterministic\",\n               deterministic.IsDeterministic() || deterministic.IsDefault()\n                   ? \"true\"\n@@ -126,7 +126,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n   ~Dataset() override { input_->Unref(); }\n \n   std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-      const string& prefix) const override {\n+      const std::string& prefix) const override {\n     name_utils::IteratorPrefixParams params;\n     params.op_version = op_version_;\n     bool deterministic =\n@@ -143,7 +143,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n     return output_shapes_;\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     name_utils::DatasetDebugStringParams params;\n     params.op_version = op_version_;\n     return name_utils::DatasetDebugString(kDatasetType, params);\n@@ -949,7 +949,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n \n     absl::Status WriteWorkerStateLocked(IteratorStateWriter* writer, int index)\n         TF_EXCLUSIVE_LOCKS_REQUIRED(mu_, ckpt_mu_) {\n-      string iterator_name =\n+      std::string iterator_name =\n           strings::StrCat(prefix(), \"::\", kWorker, \"_\", index);\n       TF_RETURN_IF_ERROR(writer->WriteScalar(iterator_name, kInputSize,\n                                              workers_[index].input.size()));\n@@ -975,7 +975,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n     absl::Status ReadWorkerStateLocked(IteratorContext* ctx,\n                                        IteratorStateReader* reader, int index)\n         TF_EXCLUSIVE_LOCKS_REQUIRED(mu_, ckpt_mu_) {\n-      string worker_prefix =\n+      std::string worker_prefix =\n           strings::StrCat(prefix(), \"::\", kWorker, \"_\", index);\n       // Restore inputs.\n       int64_t input_size;\n@@ -1009,7 +1009,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n                                               IteratorStateWriter* writer,\n                                               int index)\n         TF_EXCLUSIVE_LOCKS_REQUIRED(mu_, ckpt_mu_) {\n-      string iterator_name =\n+      std::string iterator_name =\n           strings::StrCat(prefix(), \"::\", kWorkerThread, \"_\", index);\n       if (worker_thread_states_[index].iterator != nullptr) {\n         TF_RETURN_IF_ERROR(\n@@ -1043,7 +1043,7 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n                                              IteratorStateReader* reader,\n                                              int index,\n                                              WorkerThreadState* state) {\n-      string worker_prefix =\n+      std::string worker_prefix =\n           strings::StrCat(prefix(), \"::\", kWorkerThread, \"_\", index);\n       // Restore inputs.\n       int64_t input_size;\n@@ -1083,8 +1083,8 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n \n     absl::Status WriteOutputElemLocked(IteratorStateWriter* writer,\n                                        const OutputElem& output_elem,\n-                                       const string& iterator_name,\n-                                       const string& prefix)\n+                                       const std::string& iterator_name,\n+                                       const std::string& prefix)\n         TF_EXCLUSIVE_LOCKS_REQUIRED(mu_, ckpt_mu_) {\n       TF_RETURN_IF_ERROR(WriteStatusLocked(writer, iterator_name,\n                                            absl::StrCat(prefix, \"_\", kStatus),\n@@ -1103,8 +1103,8 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n     absl::Status ReadOutputElemLocked(IteratorContext* ctx,\n                                       IteratorStateReader* reader,\n                                       OutputElem* output_elem,\n-                                      const string& iterator_name,\n-                                      const string& prefix) {\n+                                      const std::string& iterator_name,\n+                                      const std::string& prefix) {\n       TF_RETURN_IF_ERROR(ReadStatusLocked(reader, iterator_name,\n                                           absl::StrCat(prefix, \"_\", kStatus),\n                                           &output_elem->status));\n@@ -1123,8 +1123,8 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n     }\n \n     absl::Status WriteStatusLocked(IteratorStateWriter* writer,\n-                                   const string& iterator_name,\n-                                   const string& prefix,\n+                                   const std::string& iterator_name,\n+                                   const std::string& prefix,\n                                    const absl::Status& status)\n         TF_EXCLUSIVE_LOCKS_REQUIRED(mu_, ckpt_mu_) {\n       TF_RETURN_IF_ERROR(\n@@ -1139,8 +1139,9 @@ class ParallelInterleaveDatasetOp::Dataset : public DatasetBase {\n     }\n \n     absl::Status ReadStatusLocked(IteratorStateReader* reader,\n-                                  const string& iterator_name,\n-                                  const string& prefix, absl::Status* status) {\n+                                  const std::string& iterator_name,\n+                                  const std::string& prefix,\n+                                  absl::Status* status) {\n       int64_t code_int;\n       TF_RETURN_IF_ERROR(reader->ReadScalar(\n           iterator_name, absl::StrCat(prefix, \"_\", kCode), &code_int));"
        },
        {
            "sha": "f5d94b30bbd7ba4f7e7bf274c23c7d3b52dc23a3",
            "filename": "tensorflow/core/kernels/data/experimental/random_dataset_op_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Frandom_dataset_op_test.cc?ref=8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
            "patch": "@@ -80,7 +80,7 @@ class RandomDatasetParams : public DatasetParams {\n                       bool rerandomize_each_iteration,\n                       DataTypeVector output_dtypes,\n                       std::vector<PartialTensorShape> output_shapes,\n-                      string node_name)\n+                      std::string node_name)\n       : DatasetParams(std::move(output_dtypes), std::move(output_shapes),\n                       std::move(node_name)),\n         seed_(CreateTensor<int64_t>(TensorShape({}), {seed})),\n@@ -98,7 +98,8 @@ class RandomDatasetParams : public DatasetParams {\n     return {seed_, seed2_, seed_generator_resource_};\n   }\n \n-  absl::Status GetInputNames(std::vector<string>* input_names) const override {\n+  absl::Status GetInputNames(\n+      std::vector<std::string>* input_names) const override {\n     *input_names = {RandomDatasetOp::kSeed, RandomDatasetOp::kSeed2};\n     if (op_version_ == 2) {\n       input_names->emplace_back(\"seed_generator\");\n@@ -117,7 +118,9 @@ class RandomDatasetParams : public DatasetParams {\n     return absl::OkStatus();\n   }\n \n-  string dataset_type() const override { return RandomDatasetOp::kDatasetType; }\n+  std::string dataset_type() const override {\n+    return RandomDatasetOp::kDatasetType;\n+  }\n \n  private:\n   Tensor seed_;"
        },
        {
            "sha": "01f96cb04ed82e91c8270ff44ab65b9804e58c71",
            "filename": "tensorflow/core/kernels/data/experimental/save_dataset_op_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsave_dataset_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsave_dataset_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsave_dataset_op_test.cc?ref=8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
            "patch": "@@ -38,7 +38,7 @@ class SaveDatasetV2Params : public DatasetParams {\n                       std::vector<FunctionDef> func_lib, bool use_shard_func,\n                       DataTypeVector output_dtypes,\n                       std::vector<PartialTensorShape> output_shapes,\n-                      string node_name, DataTypeVector type_arguments)\n+                      std::string node_name, DataTypeVector type_arguments)\n       : DatasetParams(std::move(output_dtypes), std::move(output_shapes),\n                       std::move(node_name)),\n         path_(path),\n@@ -59,7 +59,8 @@ class SaveDatasetV2Params : public DatasetParams {\n     return input_tensors;\n   }\n \n-  absl::Status GetInputNames(std::vector<string>* input_names) const override {\n+  absl::Status GetInputNames(\n+      std::vector<std::string>* input_names) const override {\n     input_names->clear();\n     input_names->emplace_back(SaveDatasetV2Op::kInputDataset);\n     input_names->emplace_back(SaveDatasetV2Op::kPath);\n@@ -78,11 +79,13 @@ class SaveDatasetV2Params : public DatasetParams {\n     return absl::OkStatus();\n   }\n \n-  string path() const { return path_; }\n+  std::string path() const { return path_; }\n \n-  string dataset_type() const override { return SaveDatasetV2Op::kDatasetType; }\n+  std::string dataset_type() const override {\n+    return SaveDatasetV2Op::kDatasetType;\n+  }\n \n-  string op_name() const override { return \"SaveDatasetV2\"; }\n+  std::string op_name() const override { return \"SaveDatasetV2\"; }\n \n   std::vector<FunctionDef> func_lib() const override { return func_lib_; }\n "
        },
        {
            "sha": "ff15bd00f4e1c6db587b82d31be90be662cf3ef0",
            "filename": "tensorflow/core/kernels/data/experimental/sleep_dataset_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsleep_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsleep_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsleep_dataset_op.cc?ref=8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
            "patch": "@@ -60,7 +60,7 @@ class SleepDatasetOp : public UnaryDatasetOpKernel {\n     ~Dataset() override { input_->Unref(); }\n \n     std::unique_ptr<IteratorBase> MakeIteratorInternal(\n-        const string& prefix) const override {\n+        const std::string& prefix) const override {\n       return std::make_unique<Iterator>(\n           Iterator::Params{this, absl::StrCat(prefix, \"::Sleep\")});\n     }\n@@ -72,7 +72,9 @@ class SleepDatasetOp : public UnaryDatasetOpKernel {\n       return input_->output_shapes();\n     }\n \n-    string DebugString() const override { return \"SleepDatasetOp::Dataset\"; }\n+    std::string DebugString() const override {\n+      return \"SleepDatasetOp::Dataset\";\n+    }\n \n     int64_t CardinalityInternal(CardinalityOptions options) const override {\n       return input_->Cardinality(options);"
        },
        {
            "sha": "3ab56ba9af36bd280476b913a94e118146881a26",
            "filename": "tensorflow/core/kernels/data/experimental/sql_dataset_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsql_dataset_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsql_dataset_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fdata%2Fexperimental%2Fsql_dataset_op.cc?ref=8633fb9dcf07ea96e327ef7af6d8958f8b5dbc6b",
            "patch": "@@ -72,7 +72,7 @@ class SqlDatasetOp : public DatasetOpKernel {\n     // TODO(b/64276826) Change this check when we add support for other\n     // databases.\n     OP_REQUIRES(ctx, driver_name == \"sqlite\",\n-                errors::InvalidArgument(tensorflow::strings::Printf(\n+                errors::InvalidArgument(absl::StrFormat(\n                     \"The database type, %s, is not supported by SqlDataset. \"\n                     \"The set of supported databases is: {'sqlite'}.\",\n                     driver_name.c_str())));"
        }
    ],
    "stats": {
        "total": 63,
        "additions": 36,
        "deletions": 27
    }
}