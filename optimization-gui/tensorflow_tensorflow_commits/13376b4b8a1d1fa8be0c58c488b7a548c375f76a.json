{
    "author": "loislo",
    "message": "[XLA:GPU] change 'checksum' field name to 'value'\n\nWe use this field for two different buffer debug kernels that have different semantic. Technically we could have two different structures but it does not makes much sense at the moment. Let's use the one that we already have with the generic name.\n\nPiperOrigin-RevId: 824532743",
    "sha": "13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
    "files": [
        {
            "sha": "e1355da6cbdf79796467681b8bdf76d46b44c998",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log.proto?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -26,8 +26,8 @@ message BufferDebugLogEntryProto {\n   // Thunk::buffer_uses().\n   uint64 buffer_idx = 2;\n \n-  // The checksum of the buffer.\n-  uint32 checksum = 3;\n+  // The value of the buffer.\n+  uint32 value = 3;\n }\n \n // A dump of a `BufferDebugLog` contents."
        },
        {
            "sha": "3253561fd9fae1096be53df428b08748582eee29",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffer_debug_log_structs.h",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffer_debug_log_structs.h?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -28,17 +28,16 @@ struct BufferDebugLogEntry {\n   // An ID that uniquely identifies a thunk and its specific input or output\n   // buffer.\n   ThunkBufferId entry_id;\n-  uint32_t checksum;\n+  uint32_t value;\n \n   template <typename Sink>\n   friend void AbslStringify(Sink& sink, const BufferDebugLogEntry& entry) {\n-    absl::Format(&sink, \"{entry_id: %v, checksum: %u}\", entry.entry_id,\n-                 entry.checksum);\n+    absl::Format(&sink, \"{entry_id: %v, value: %u}\", entry.entry_id,\n+                 entry.value);\n   }\n \n   bool operator==(const BufferDebugLogEntry& other) const {\n-    return std::tie(entry_id, checksum) ==\n-           std::tie(other.entry_id, other.checksum);\n+    return std::tie(entry_id, value) == std::tie(other.entry_id, other.value);\n   }\n \n   bool operator!=(const BufferDebugLogEntry& other) const {\n@@ -50,7 +49,7 @@ struct BufferDebugLogEntry {\n static_assert(_Alignof(BufferDebugLogEntry) == _Alignof(uint32_t));\n static_assert(sizeof(BufferDebugLogEntry) == sizeof(uint32_t) * 2);\n static_assert(offsetof(BufferDebugLogEntry, entry_id) == 0);\n-static_assert(offsetof(BufferDebugLogEntry, checksum) == sizeof(uint32_t));\n+static_assert(offsetof(BufferDebugLogEntry, value) == sizeof(uint32_t));\n \n struct BufferDebugLogHeader {\n   // The first entry in `BufferDebugLogEntry` following the header that has not"
        },
        {
            "sha": "b5dd5154267a387b5fecb1fa6bc9dd6e15f5b757",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_checksum_thunk_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_checksum_thunk_test.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -133,11 +133,11 @@ TEST_F(BuffersDebugChecksumThunkTest, CalculatesChecksums) {\n       UnorderedElementsAre(\n           BufferDebugLogEntry{\n               /*entry_id=*/ThunkBufferId::Create(ThunkId(123), 4).value(),\n-              /*checksum=*/12341234,\n+              /*value=*/12341234,\n           },\n           BufferDebugLogEntry{\n               /*entry_id=*/ThunkBufferId::Create(ThunkId(456), 8).value(),\n-              /*checksum=*/56785678,\n+              /*value=*/56785678,\n           }));\n }\n "
        },
        {
            "sha": "aef4777ab8a9f41d40d8358df11fe2761d121b00",
            "filename": "third_party/xla/xla/backends/gpu/runtime/buffers_nan_count_thunk_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_nan_count_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_nan_count_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fbuffers_nan_count_thunk_test.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -138,13 +138,11 @@ TEST_F(BuffersDebugNanCountThunkTest, CalculatesNanCounts) {\n       UnorderedElementsAre(\n           BufferDebugLogEntry{\n               /*entry_id=*/ThunkBufferId::Create(ThunkId(123), 4).value(),\n-              /*checksum=*/1,  // We use checksum field for NaN count. It will\n-                               // be generalised in the follow-up commits.\n+              /*value=*/1,\n           },\n           BufferDebugLogEntry{\n               /*entry_id=*/ThunkBufferId::Create(ThunkId(456), 8).value(),\n-              /*checksum=*/2,  // We use checksum field for NaN count. It will\n-                               // be generalised in the follow-up commits.\n+              /*value=*/2,\n           }));\n }\n "
        },
        {
            "sha": "6f05929f15912488effee83ab35b178a6ceacbc1",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_nan_count_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_nan_count_kernel_cuda_test.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -131,7 +131,7 @@ TEST_F(NanCountKernelTest, CountsNansForF32) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].checksum, 2);\n+  EXPECT_EQ(host_log[0].value, 2);\n }\n \n TEST_F(NanCountKernelTest, CountsNansForBf16) {\n@@ -150,7 +150,7 @@ TEST_F(NanCountKernelTest, CountsNansForBf16) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].checksum, 2);\n+  EXPECT_EQ(host_log[0].value, 2);\n }\n \n TEST_F(NanCountKernelTest, CountsNansInParallel) {\n@@ -171,8 +171,8 @@ TEST_F(NanCountKernelTest, CountsNansInParallel) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n-  EXPECT_EQ(host_log[0].checksum, 3);\n-  EXPECT_EQ(host_log[1].checksum, 3);\n+  EXPECT_EQ(host_log[0].value, 3);\n+  EXPECT_EQ(host_log[1].value, 3);\n }\n \n }  // namespace"
        },
        {
            "sha": "030203f3e1e1da69ef556facec509d7d23979c78",
            "filename": "third_party/xla/xla/stream_executor/cuda/buffer_debug_xor_checksum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fbuffer_debug_xor_checksum_kernel_cuda_test.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -142,7 +142,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+  EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n \n TEST_F(ChecksumKernelTest,\n@@ -158,7 +158,7 @@ TEST_F(ChecksumKernelTest,\n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n   // Assumes the device uses little-endian byte order.\n-  EXPECT_EQ(host_log[0].checksum, 0x55000000);\n+  EXPECT_EQ(host_log[0].value, 0x55000000);\n }\n \n TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n@@ -177,7 +177,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+  EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n \n TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n@@ -196,7 +196,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n-  EXPECT_EQ(host_log[0].checksum, kExpectedChecksum);\n+  EXPECT_EQ(host_log[0].value, kExpectedChecksum);\n }\n \n TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n@@ -218,11 +218,11 @@ TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 3);\n   EXPECT_EQ(host_log[0].entry_id, kId123);\n-  EXPECT_EQ(host_log[0].checksum, 0x01230123);\n+  EXPECT_EQ(host_log[0].value, 0x01230123);\n   EXPECT_EQ(host_log[1].entry_id, kId456);\n-  EXPECT_EQ(host_log[1].checksum, 0x04560456);\n+  EXPECT_EQ(host_log[1].value, 0x04560456);\n   EXPECT_EQ(host_log[2].entry_id, kId789);\n-  EXPECT_EQ(host_log[2].checksum, 0x07890789);\n+  EXPECT_EQ(host_log[2].value, 0x07890789);\n }\n \n TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n@@ -246,9 +246,9 @@ TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n   EXPECT_EQ(host_log[0].entry_id, kId123);\n-  EXPECT_EQ(host_log[0].checksum, 0x01230123);\n+  EXPECT_EQ(host_log[0].value, 0x01230123);\n   EXPECT_EQ(host_log[1].entry_id, kId456);\n-  EXPECT_EQ(host_log[1].checksum, 0x04560456);\n+  EXPECT_EQ(host_log[1].value, 0x04560456);\n }\n \n }  // namespace"
        },
        {
            "sha": "0aa57dc873f0e3090cbec81ac1bdc8e2f6f2cee2",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -966,6 +966,7 @@ xla_test(\n     backends = [\"gpu\"],\n     deps = [\n         \":buffer_debug_log\",\n+        \"//xla/backends/gpu/runtime:buffer_debug_log_proto_cc\",\n         \"//xla/backends/gpu/runtime:buffer_debug_log_structs\",\n         \"//xla/backends/gpu/runtime:thunk_buffer_id\",\n         \"//xla/backends/gpu/runtime:thunk_id\","
        },
        {
            "sha": "09fcd7262c2d7c6781d1c67a9d15b82ba1707a38",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -103,7 +103,7 @@ absl::StatusOr<xla::gpu::BufferDebugLogProto> BufferDebugLog::ReadProto(\n         buffer_debug_log_proto.add_entries();\n     entry_proto->set_thunk_id(entry.entry_id.thunk_id().value());\n     entry_proto->set_buffer_idx(entry.entry_id.buffer_idx());\n-    entry_proto->set_checksum(entry.checksum);\n+    entry_proto->set_value(entry.value);\n   }\n \n   return buffer_debug_log_proto;"
        },
        {
            "sha": "20b6cc66683e5f3022f90f139ea3ea87bacc288d",
            "filename": "third_party/xla/xla/stream_executor/gpu/buffer_debug_log_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/13376b4b8a1d1fa8be0c58c488b7a548c375f76a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fbuffer_debug_log_test.cc?ref=13376b4b8a1d1fa8be0c58c488b7a548c375f76a",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/backends/gpu/runtime/buffer_debug_log.pb.h\"\n #include \"xla/backends/gpu/runtime/buffer_debug_log_structs.h\"\n #include \"xla/backends/gpu/runtime/thunk_buffer_id.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n@@ -46,7 +47,6 @@ namespace {\n using ::tsl::proto_testing::EqualsProto;\n using ::xla::gpu::BufferDebugLogEntry;\n using ::xla::gpu::BufferDebugLogHeader;\n-using ::xla::gpu::BufferDebugLogProto;\n using ::xla::gpu::ThunkBufferId;\n using ::xla::gpu::ThunkId;\n \n@@ -128,9 +128,9 @@ TEST_F(BufferDebugLogTest, ReadAsProto) {\n                                        /*capacity=*/10};\n   const BufferDebugLogEntry entries[] = {\n       {/*entry_id=*/ThunkBufferId::Create(ThunkId(123), 4).value(),\n-       /*checksum=*/12341234},\n+       /*value=*/12341234},\n       {/*entry_id=*/ThunkBufferId::Create(ThunkId(567), 8).value(),\n-       /*checksum=*/56785678},\n+       /*value=*/56785678},\n   };\n   std::vector<uint8_t> log_data(sizeof(header) + sizeof(entries));\n   memcpy(log_data.data(), &header, sizeof(header));\n@@ -140,12 +140,12 @@ TEST_F(BufferDebugLogTest, ReadAsProto) {\n \n   BufferDebugLog device_log =\n       BufferDebugLog::FromDeviceMemoryUnchecked(log_buffer);\n-  TF_ASSERT_OK_AND_ASSIGN(BufferDebugLogProto log_proto,\n+  TF_ASSERT_OK_AND_ASSIGN(xla::gpu::BufferDebugLogProto log_proto,\n                           device_log.ReadProto(*stream_));\n \n   EXPECT_THAT(log_proto, EqualsProto(R\"pb(\n-                entries { thunk_id: 123 buffer_idx: 4 checksum: 12341234 }\n-                entries { thunk_id: 567 buffer_idx: 8 checksum: 56785678 }\n+                entries { thunk_id: 123 buffer_idx: 4 value: 12341234 }\n+                entries { thunk_id: 567 buffer_idx: 8 value: 56785678 }\n               )pb\"));\n }\n "
        }
    ],
    "stats": {
        "total": 66,
        "additions": 32,
        "deletions": 34
    }
}