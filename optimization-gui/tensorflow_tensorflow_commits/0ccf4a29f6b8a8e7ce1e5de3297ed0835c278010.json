{
    "author": "unknown",
    "message": "Extend ragged dot HloEvaluator to handle contracting mode.\n\nPiperOrigin-RevId: 810589369",
    "sha": "0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010",
    "files": [
        {
            "sha": "0ed1e077ce664a9066fb73e1d78a3e174f11a87e",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator_test.cc",
            "status": "modified",
            "additions": 417,
            "deletions": 3,
            "changes": 420,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_test.cc?ref=0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010",
            "patch": "@@ -1212,8 +1212,8 @@ TEST_F(HloEvaluatorTest, RaggedDotNonContractingWithBatchDimensions) {\n   // rhs[b,g,k,n]:\n   // f32[3,2,1,2] =\n   // {{{{ 0, 1 }}, {{ 2, 3 }}},\n-  //   {{ 4, 5 }}, {{ 6, 7 }}},\n-  //   {{ 8, 9 }}, {{ 10, 11 }}}},\n+  //  {{{ 4, 5 }}, {{ 6, 7 }}},\n+  //  {{{ 8, 9 }}, {{ 10, 11 }}}}\n   auto rhs_array = std::make_unique<Array4D<float>>(3, 2, 1, 2);\n   rhs_array->FillIota(0.f);\n   auto rhs_literal = LiteralUtil::CreateR4FromArray4D<float>(*rhs_array);\n@@ -1229,7 +1229,7 @@ TEST_F(HloEvaluatorTest, RaggedDotNonContractingWithBatchDimensions) {\n   HloInstruction* gs_instruction =\n       b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n \n-  // f32[g,m,n]\n+  // f32[b,m,n]\n   Shape output_shape = ShapeUtil::MakeShape(F32, {3, 4, 2});\n   DotDimensionNumbers dot_dnums;\n   dot_dnums.add_lhs_contracting_dimensions(2);\n@@ -1260,6 +1260,420 @@ TEST_F(HloEvaluatorTest, RaggedDotNonContractingWithBatchDimensions) {\n   EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n }\n \n+TEST_F(HloEvaluatorTest, RaggedDotContractingMode) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[m,k]:\n+  // f32[4,5] {\n+  //  { 1, 2, 3, 4, 5 },\n+  //  { 6, 7, 8, 9, 10 },\n+  //  { 11, 12, 13, 14, 15 },\n+  //  { 16, 17, 18, 19, 20 }\n+  // }\n+  auto lhs_array = std::make_unique<Array2D<float>>(4, 5);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::CreateR2FromArray2D<float>(*lhs_array);\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[k,n]:\n+  // f32[5,3]\n+  //  {{ 1, 2, 3 },\n+  //   { 4, 5, 6 },\n+  //   { 7, 8, 9 },\n+  //   { 10, 11, 12 },\n+  //   { 13, 14, 15 }}\n+  auto rhs_array = std::make_unique<Array2D<float>>(5, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::CreateR2FromArray2D<float>(*rhs_array);\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes s64[g]:\n+  // { 2, 3 }\n+  auto gs_literal = LiteralUtil::CreateR1<int64_t>({2, 3});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 4, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(1);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array3D<float>({\n+      {{9.f, 12.f, 15.f},\n+       {34.f, 47.f, 60.f},\n+       {59.f, 82.f, 105.f},\n+       {84.f, 117.f, 150.f}},\n+      {{126.f, 138.f, 150.f},\n+       {276.f, 303.f, 330.f},\n+       {426.f, 468.f, 510.f},\n+       {576.f, 633.f, 690.f}},\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR3FromArray3D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, RaggedDotContractingModeMixedPrecision) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[m,k]:\n+  // bf16[4,5] {\n+  //  { 1, 2, 3, 4, 5 },\n+  //  { 6, 7, 8, 9, 10 },\n+  //  { 11, 12, 13, 14, 15 },\n+  //  { 16, 17, 18, 19, 20 }\n+  // }\n+  auto lhs_array = std::make_unique<Array2D<float>>(4, 5);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::ConvertF32ToBF16(\n+      LiteralUtil::CreateR2FromArray2D<float>(*lhs_array));\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[k,n]:\n+  // bf16[5,3]\n+  //  {{ 1, 2, 3 },\n+  //   { 4, 5, 6 },\n+  //   { 7, 8, 9 },\n+  //   { 10, 11, 12 },\n+  //   { 13, 14, 15 }}\n+  auto rhs_array = std::make_unique<Array2D<float>>(5, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::ConvertF32ToBF16(\n+      LiteralUtil::CreateR2FromArray2D<float>(*rhs_array));\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes s64[g]:\n+  // { 2, 3 }\n+  auto gs_literal = LiteralUtil::CreateR1<int64_t>({2, 3});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 4, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(1);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array3D<float>({\n+      {{9.f, 12.f, 15.f},\n+       {34.f, 47.f, 60.f},\n+       {59.f, 82.f, 105.f},\n+       {84.f, 117.f, 150.f}},\n+      {{126.f, 138.f, 150.f},\n+       {276.f, 303.f, 330.f},\n+       {426.f, 468.f, 510.f},\n+       {576.f, 633.f, 690.f}},\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR3FromArray3D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, RaggedDotContractingModeGroupSizeSumLessThanK) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[m,k]:\n+  // f32[4,5] {\n+  //  { 1, 2, 3, 4, 5 },\n+  //  { 6, 7, 8, 9, 10 },\n+  //  { 11, 12, 13, 14, 15 },\n+  //  { 16, 17, 18, 19, 20 }\n+  // }\n+  auto lhs_array = std::make_unique<Array2D<float>>(4, 5);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::CreateR2FromArray2D<float>(*lhs_array);\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[k,n]:\n+  // f32[5,3]\n+  //  {{ 1, 2, 3 },\n+  //   { 4, 5, 6 },\n+  //   { 7, 8, 9 },\n+  //   { 10, 11, 12 },\n+  //   { 13, 14, 15 }}\n+  auto rhs_array = std::make_unique<Array2D<float>>(5, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::CreateR2FromArray2D<float>(*rhs_array);\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes s64[g]:\n+  // { 2, 2 }\n+  auto gs_literal = LiteralUtil::CreateR1<int64_t>({2, 2});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 4, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(1);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array3D<float>({\n+      {{9.f, 12.f, 15.f},\n+       {34.f, 47.f, 60.f},\n+       {59.f, 82.f, 105.f},\n+       {84.f, 117.f, 150.f}},\n+      {{61.f, 68.f, 75.f},\n+       {146.f, 163.f, 180.f},\n+       {231.f, 258.f, 285.f},\n+       {316.f, 353.f, 390.f}},\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR3FromArray3D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, RaggedDotContractingModeMultipleContractingDims) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[m,k1,k2,k3]:\n+  // f32[2,2,5,2] {\n+  //   {{{1, 2}, {3, 4}, {5, 6}, {7, 8}, {9, 10}},\n+  //    {{11, 12}, {13, 14}, {15, 16}, {17, 18}, {19, 20}}},\n+  //   {{{21, 22}, {23, 24}, {25, 26}, {27, 28}, {29, 30}},\n+  //    {{31, 32}, {33, 34}, {35, 36}, {37, 38}, {39, 40}}}\n+  // }\n+  auto lhs_array = std::make_unique<Array4D<float>>(2, 2, 5, 2);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::CreateR4FromArray4D<float>(*lhs_array);\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[k1,k2,k3,n]:\n+  // f32[2,5,2,3] {\n+  //   {{{1, 2, 3}, {4, 5, 6}},\n+  //    {{7, 8, 9}, {10, 11, 12}},\n+  //    {{13, 14, 15}, {16, 17, 18}},\n+  //    {{19, 20, 21}, {22, 23, 24}},\n+  //    {{25, 26, 27}, {28, 29, 30}}},\n+  //   {{{31, 32, 33}, {34, 35, 36}},\n+  //    {{37, 38, 39}, {40, 41, 42}},\n+  //    {{43, 44, 45}, {46, 47, 48}},\n+  //    {{49, 50, 51}, {52, 53, 54}},\n+  //    {{55, 56, 57}, {58, 59, 60}}}\n+  // }\n+  auto rhs_array = std::make_unique<Array4D<float>>(2, 5, 2, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::CreateR4FromArray4D<float>(*rhs_array);\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes s64[g]:\n+  // { 2, 3 }\n+  auto gs_literal = LiteralUtil::CreateR1<int64_t>({2, 3});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 2, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(1);\n+  dot_dnums.add_lhs_contracting_dimensions(2);\n+  dot_dnums.add_lhs_contracting_dimensions(3);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  dot_dnums.add_rhs_contracting_dimensions(1);\n+  dot_dnums.add_rhs_contracting_dimensions(2);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(2);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array3D<float>({\n+      {{1860.f, 1920.f, 1980.f},\n+       {5140.f, 5360.f, 5580.f}},\n+      {{6330.f, 6480.f, 6630.f},\n+       {14850.f, 15240.f, 15630.f}},\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR3FromArray3D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, RaggedDotContractingModeExtraLhsDim) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[m1,m2,k]:\n+  // f32[2,2,5] {\n+  //   {{ 1, 2, 3, 4, 5 },\n+  //    { 6, 7, 8, 9, 10 }},\n+  //   {{ 11, 12, 13, 14, 15 },\n+  //    { 16, 17, 18, 19, 20 }}\n+  // }\n+  auto lhs_array = std::make_unique<Array3D<float>>(2, 2, 5);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::CreateR3FromArray3D<float>(*lhs_array);\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[k,n]:\n+  // f32[5,3]\n+  //  {{ 1, 2, 3 },\n+  //   { 4, 5, 6 },\n+  //   { 7, 8, 9 },\n+  //   { 10, 11, 12 },\n+  //   { 13, 14, 15 }}\n+  auto rhs_array = std::make_unique<Array2D<float>>(5, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::CreateR2FromArray2D<float>(*rhs_array);\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes s64[g]:\n+  // { 2, 3 }\n+  auto gs_literal = LiteralUtil::CreateR1<int64_t>({2, 3});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 2, 2, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_contracting_dimensions(2);\n+  dot_dnums.add_rhs_contracting_dimensions(0);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(2);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array4D<float>({\n+      {{{9.f, 12.f, 15.f},\n+        {34.f, 47.f, 60.f}},\n+       {{59.f, 82.f, 105.f},\n+        {84.f, 117.f, 150.f}}},\n+      {{{126.f, 138.f, 150.f},\n+        {276.f, 303.f, 330.f}},\n+       {{426.f, 468.f, 510.f},\n+        {576.f, 633.f, 690.f}}},\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR4FromArray4D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n+TEST_F(HloEvaluatorTest, RaggedDotContractingModeWithBatchDimensions) {\n+  HloComputation::Builder b(TestName());\n+\n+  // lhs[b,m,k]:\n+  // f32[2,2,5] {\n+  //   {{ 1, 2, 3, 4, 5 },\n+  //    { 6, 7, 8, 9, 10 }},\n+  //   {{ 11, 12, 13, 14, 15 },\n+  //    { 16, 17, 18, 19, 20 }}\n+  // }\n+  auto lhs_array = std::make_unique<Array3D<float>>(2, 2, 5);\n+  lhs_array->FillIota(1.0f);\n+  auto lhs_literal = LiteralUtil::CreateR3FromArray3D<float>(*lhs_array);\n+  HloInstruction* lhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(lhs_literal)));\n+\n+  // rhs[b,k,n]:\n+  // f32[2,5,3]\n+  //  {{{ 1, 2, 3 },\n+  //    { 4, 5, 6 },\n+  //    { 7, 8, 9 },\n+  //    { 10, 11, 12 },\n+  //    { 13, 14, 15 }},\n+  //   {{ 16, 17, 18 },\n+  //    { 19, 20, 21 },\n+  //    { 22, 23, 24 },\n+  //    { 25, 26, 27 },\n+  //    { 28, 29, 30 }}\n+  auto rhs_array = std::make_unique<Array3D<float>>(2, 5, 3);\n+  rhs_array->FillIota(1.0f);\n+  auto rhs_literal = LiteralUtil::CreateR3FromArray3D<float>(*rhs_array);\n+  HloInstruction* rhs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(rhs_literal)));\n+\n+  // group_sizes[b,g]:\n+  // s64[2,2]\n+  // { { 2, 2 }, { 5, 0 } }\n+  auto gs_literal = LiteralUtil::CreateR2<int64_t>({{2, 2}, {5, 0}});\n+  HloInstruction* gs_instruction =\n+      b.AddInstruction(HloInstruction::CreateConstant(std::move(gs_literal)));\n+\n+  // output[g,b,m,n]\n+  // f32[2,2,2,3]\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {2, 2, 2, 3});\n+  DotDimensionNumbers dot_dnums;\n+  dot_dnums.add_lhs_batch_dimensions(0);\n+  dot_dnums.add_rhs_batch_dimensions(0);\n+  dot_dnums.add_lhs_contracting_dimensions(2);\n+  dot_dnums.add_rhs_contracting_dimensions(1);\n+  RaggedDotDimensionNumbers ragged_dot_dnums;\n+  ragged_dot_dnums.add_lhs_ragged_dimensions(2);\n+  *ragged_dot_dnums.mutable_dot_dimension_numbers() = dot_dnums;\n+  b.AddInstruction(HloInstruction::CreateRaggedDot(\n+      output_shape, lhs_instruction, rhs_instruction, gs_instruction,\n+      ragged_dot_dnums, DefaultPrecisionConfig(2)));\n+  m_->AddEntryComputation(b.Build());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(Literal result, Evaluate());\n+\n+  // clang-format off\n+  auto expected_array = Array4D<float>({\n+      {{{9.f, 12.f, 15.f},         // group 0, batch 0 -> [2] 2\n+        {34.f, 47.f, 60.f}},\n+       {{1460.f, 1525.f, 1590.f},  // group 0, batch 1 -> [5] 0\n+        {2010.f, 2100.f, 2190.f}}},\n+      {{{61.f, 68.f, 75.f},        // group 1, batch 0 -> 2 [2]\n+        {146.f, 163.f, 180.f}},\n+       {{0.f, 0.f, 0.f},           // group 1, batch 1 -> 5 [0]\n+        {0.f, 0.f, 0.f}}}\n+  });\n+  // clang-format on\n+  auto expected = LiteralUtil::CreateR4FromArray4D<float>(expected_array);\n+\n+  EXPECT_TRUE(LiteralTestUtil::Equal(expected, result));\n+}\n+\n HloInstruction* BF16Array2D(HloComputation::Builder& b, int rows, int cols,\n                             float value) {\n   auto array = std::make_unique<Array2D<float>>(rows, cols);"
        },
        {
            "sha": "74ed6f0cb8b936b6f19e3ee923b121e1db48d375",
            "filename": "third_party/xla/xla/hlo/evaluator/hlo_evaluator_typed_visitor.h",
            "status": "modified",
            "additions": 164,
            "deletions": 22,
            "changes": 186,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fevaluator%2Fhlo_evaluator_typed_visitor.h?ref=0ccf4a29f6b8a8e7ce1e5de3297ed0835c278010",
            "patch": "@@ -1334,21 +1334,12 @@ class HloEvaluatorTypedVisitor : public ConstDfsHloVisitorWithDefault {\n         rhs_literal.Convert(dot->shape().element_type()).value());\n   }\n \n-  absl::Status HandleRaggedDotWithLiterals(const HloInstruction* dot,\n-                                           const Literal& lhs_literal,\n-                                           const Literal& rhs_literal,\n-                                           const Literal& gs_literal) {\n+  absl::Status HandleRaggedDotNonContractingWithLiterals(\n+      const HloInstruction* dot, const Literal& lhs_literal,\n+      const Literal& rhs_literal, const Literal& gs_literal) {\n     auto ragged_dims = dot->ragged_dot_dimension_numbers();\n     auto dot_dims = ragged_dims.dot_dimension_numbers();\n-\n-    if (ragged_dims.rhs_group_dimensions_size() != 1) {\n-      return absl::UnimplementedError(\"Only one group dimension is supported.\");\n-    }\n-    if (ragged_dims.lhs_ragged_dimensions_size() != 1) {\n-      return absl::UnimplementedError(\n-          \"Only one ragged dimension is supported.\");\n-    }\n-    int64_t rhs_group_dim = ragged_dims.rhs_group_dimensions(0);\n+    // Shape inference should have checked that there is exactly one ragged dim.\n     int64_t lhs_ragged_dim = ragged_dims.lhs_ragged_dimensions(0);\n \n     int64_t lhs_rank = lhs_literal.shape().dimensions().size();\n@@ -1359,11 +1350,9 @@ class HloEvaluatorTypedVisitor : public ConstDfsHloVisitorWithDefault {\n     auto lhs_contracting = dot_dims.lhs_contracting_dimensions();\n     auto lhs_non_contracting = GetNonContractingDims(\n         lhs_rank, lhs_contracting, dot_dims.lhs_batch_dimensions());\n-    if (std::find(lhs_non_contracting.begin(), lhs_non_contracting.end(),\n-                  lhs_ragged_dim) == lhs_non_contracting.end()) {\n-      return absl::UnimplementedError(\n-          \"Ragged dimension must be a non-contracting dimension.\");\n-    }\n+\n+    // Shape inference should have checked that this mode has a group dim.\n+    int64_t rhs_group_dim = ragged_dims.rhs_group_dimensions(0);\n \n     auto rhs_contracting = dot_dims.rhs_contracting_dimensions();\n     // Group Dimension is also a contracting dimension.\n@@ -1377,7 +1366,7 @@ class HloEvaluatorTypedVisitor : public ConstDfsHloVisitorWithDefault {\n       int64_t dim_size = lhs_literal.shape().dimensions(lhs_contracting[i]);\n       contracting_dim_sizes.push_back(dim_size);\n     }\n-    int64_t total_contracting_size = Product(contracting_dim_sizes);\n+    const int64_t total_contracting_size = Product(contracting_dim_sizes);\n \n     Shape dot_shape = GetShapeWithLayout(dot->shape());\n     Literal result(dot_shape);\n@@ -1455,9 +1444,162 @@ class HloEvaluatorTypedVisitor : public ConstDfsHloVisitorWithDefault {\n     return absl::OkStatus();\n   }\n \n-  // This is currently only implemented for the ragged dimension being a non-\n-  // contracting dimension. For other modes, this will throw an unimplemented\n-  // error.\n+  absl::Status HandleRaggedDotBatchModeWithLiterals(const HloInstruction* dot,\n+                                                    const Literal& lhs_literal,\n+                                                    const Literal& rhs_literal,\n+                                                    const Literal& gs_literal) {\n+    return absl::UnimplementedError(\"Ragged Dot Batch Mode not implemented\");\n+  }\n+\n+  absl::Status HandleRaggedDotContractingWithLiterals(\n+      const HloInstruction* dot, const Literal& lhs_literal,\n+      const Literal& rhs_literal, const Literal& gs_literal) {\n+    auto ragged_dims = dot->ragged_dot_dimension_numbers();\n+    auto dot_dims = ragged_dims.dot_dimension_numbers();\n+    // Shape inference should have checked that there is exactly one ragged dim.\n+    int64_t lhs_ragged_dim = ragged_dims.lhs_ragged_dimensions(0);\n+\n+    int64_t lhs_rank = lhs_literal.shape().dimensions().size();\n+    int64_t rhs_rank = rhs_literal.shape().dimensions().size();\n+    int64_t gs_rank = gs_literal.shape().dimensions().size();\n+\n+    auto lhs_contracting = dot_dims.lhs_contracting_dimensions();\n+    auto lhs_non_contracting = GetNonContractingDims(\n+        lhs_rank, lhs_contracting, dot_dims.lhs_batch_dimensions());\n+\n+    auto rhs_contracting = dot_dims.rhs_contracting_dimensions();\n+    auto rhs_non_contracting = GetNonContractingDims(\n+        rhs_rank, rhs_contracting, dot_dims.rhs_batch_dimensions());\n+\n+    DimensionVector contracting_dim_sizes;\n+    contracting_dim_sizes.reserve(lhs_contracting.size());\n+    for (int64_t i = 0; i < lhs_contracting.size(); ++i) {\n+      int64_t dim_size = lhs_literal.shape().dimensions(lhs_contracting[i]);\n+      contracting_dim_sizes.push_back(dim_size);\n+    }\n+\n+    // We must find a match because we are in contracting mode.\n+    std::optional<int64_t> ragged_dim_as_contracting_dim;\n+    for (int64_t i = 0; i < lhs_contracting.size(); ++i) {\n+      if (lhs_ragged_dim == lhs_contracting[i]) {\n+        ragged_dim_as_contracting_dim = i;\n+        break;\n+      }\n+    }\n+    const int64_t ragged_dim_size =\n+        contracting_dim_sizes[ragged_dim_as_contracting_dim.value()];\n+    const int64_t total_contracting_size_excluding_ragged_dim =\n+        Product(contracting_dim_sizes) / ragged_dim_size;\n+\n+    Shape dot_shape = GetShapeWithLayout(dot->shape());\n+    Literal result(dot_shape);\n+    TF_RETURN_IF_ERROR(result.PopulateParallel<\n+                       ReturnT>([&](absl::Span<const int64_t> result_index,\n+                                    int /*thread_id*/) {\n+      // Locations in each operand that we read from to calculate the\n+      // result at result_index.\n+      DimensionVector lhs_index(lhs_rank);\n+      DimensionVector rhs_index(rhs_rank);\n+      DimensionVector group_index(gs_rank);\n+\n+      // The group dimension will always be first in the final product. We\n+      // handle it later since we need to fill in the batch dimensions first\n+      // to look up the relevant group sizes.\n+      int64_t gs_idx = 0;\n+      int64_t idx = 1;\n+      // Batch dimensions are next.\n+      for (int64_t i = 0; i < dot_dims.lhs_batch_dimensions_size(); ++i) {\n+        lhs_index[dot_dims.lhs_batch_dimensions(i)] = result_index[idx];\n+        rhs_index[dot_dims.rhs_batch_dimensions(i)] = result_index[idx];\n+        group_index[gs_idx++] = result_index[idx];\n+        ++idx;\n+      }\n+\n+      // We now go back handle the group dimension now that the batch has\n+      // been filled in.\n+      int64_t group_row_start = 0;  // inclusive\n+      int64_t group_row_end = 0;    // exclusive\n+      for (int i = 0; i <= result_index[0]; ++i) {\n+        group_index[gs_idx] = i;\n+        group_row_start = group_row_end;\n+        group_row_end += gs_literal.Get<int64_t>(group_index);\n+      }\n+      // Clamp group row start and end to the range of the contracting dim.\n+      group_row_start = std::max(group_row_start, INT64_C(0));\n+      group_row_start = std::min(group_row_start, ragged_dim_size);\n+      group_row_end = std::max(group_row_end, INT64_C(0));\n+      group_row_end = std::min(group_row_end, ragged_dim_size);\n+\n+      // Non-contracting dimensions - lhs, then rhs.\n+      for (int64_t i = 0; i < lhs_non_contracting.size(); ++i) {\n+        lhs_index[lhs_non_contracting[i]] = result_index[idx++];\n+      }\n+      for (int64_t i = 0; i < rhs_non_contracting.size(); ++i) {\n+        rhs_index[rhs_non_contracting[i]] = result_index[idx++];\n+      }\n+\n+      // Accumulate resulting product along the contracting dimensions.\n+      ElementwiseT result_val = static_cast<ElementwiseT>(0);\n+      for (int64_t i = 0; i < total_contracting_size_excluding_ragged_dim;\n+           ++i) {\n+        for (int64_t j = group_row_start; j < group_row_end; ++j) {\n+          lhs_index[lhs_contracting[ragged_dim_as_contracting_dim.value()]] = j;\n+          rhs_index[rhs_contracting[ragged_dim_as_contracting_dim.value()]] = j;\n+          const auto lhs =\n+              static_cast<ElementwiseT>(lhs_literal.Get<ReturnT>(lhs_index));\n+          const auto rhs =\n+              static_cast<ElementwiseT>(rhs_literal.Get<ReturnT>(rhs_index));\n+          result_val += ToArithmeticSafeType(lhs) * ToArithmeticSafeType(rhs);\n+        }\n+\n+        for (int64_t j = contracting_dim_sizes.size() - 1; j >= 0; --j) {\n+          if (j == ragged_dim_as_contracting_dim.value()) continue;\n+          ++lhs_index[lhs_contracting[j]];\n+          ++rhs_index[rhs_contracting[j]];\n+          if (lhs_index[lhs_contracting[j]] != contracting_dim_sizes[j]) {\n+            break;\n+          }\n+          lhs_index[lhs_contracting[j]] = 0;\n+          rhs_index[rhs_contracting[j]] = 0;\n+        }\n+      }\n+      return static_cast<ReturnT>(result_val);\n+    }));\n+\n+    parent_->SetEvaluatedLiteralFor(dot, std::move(result));\n+    return absl::OkStatus();\n+  }\n+\n+  absl::Status HandleRaggedDotWithLiterals(const HloInstruction* dot,\n+                                           const Literal& lhs_literal,\n+                                           const Literal& rhs_literal,\n+                                           const Literal& gs_literal) {\n+    auto ragged_dims = dot->ragged_dot_dimension_numbers();\n+    auto dot_dims = ragged_dims.dot_dimension_numbers();\n+    // Shape inference should have checked that there is exactly one ragged dim.\n+    int64_t lhs_ragged_dim = ragged_dims.lhs_ragged_dimensions(0);\n+\n+    if (std::find(dot_dims.lhs_contracting_dimensions().begin(),\n+                  dot_dims.lhs_contracting_dimensions().end(),\n+                  lhs_ragged_dim) !=\n+        dot_dims.lhs_contracting_dimensions().end()) {\n+      return HandleRaggedDotContractingWithLiterals(dot, lhs_literal,\n+                                                    rhs_literal, gs_literal);\n+    }\n+    if (std::find(dot_dims.lhs_batch_dimensions().begin(),\n+                  dot_dims.lhs_batch_dimensions().end(),\n+                  lhs_ragged_dim) != dot_dims.lhs_batch_dimensions().end()) {\n+      return HandleRaggedDotBatchModeWithLiterals(dot, lhs_literal, rhs_literal,\n+                                                  gs_literal);\n+    }\n+    return HandleRaggedDotNonContractingWithLiterals(dot, lhs_literal,\n+                                                     rhs_literal, gs_literal);\n+  }\n+\n+  // This is currently only implemented for the ragged dimension being a\n+  // non-batch dimension (i.e. it may be a contracting dimension or a\n+  // non-batch, non-contracting dimension). For the batch mode, this will throw\n+  // an unimplemented error.\n   absl::Status HandleRaggedDot(const HloInstruction* dot) override {\n     auto lhs = dot->operand(0);\n     auto rhs = dot->operand(1);"
        }
    ],
    "stats": {
        "total": 606,
        "additions": 581,
        "deletions": 25
    }
}