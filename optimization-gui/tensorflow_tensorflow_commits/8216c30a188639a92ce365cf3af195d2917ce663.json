{
    "author": "ezhulenev",
    "message": "[stream_executor:cuda] Use NCCL or NVSHMEM allocators to allocate collective memory\n\nGpuCollectives::Allocate and Free will be removed in followup changes.\nPiperOrigin-RevId: 843948327",
    "sha": "8216c30a188639a92ce365cf3af195d2917ce663",
    "files": [
        {
            "sha": "316f0e882b1b30c8d3550e3fe171b31d91b7883b",
            "filename": "third_party/xla/xla/backends/gpu/collectives/BUILD",
            "status": "modified",
            "additions": 28,
            "deletions": 55,
            "changes": 83,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -1,4 +1,3 @@\n-load(\"@bazel_skylib//rules:common_settings.bzl\", \"bool_flag\")\n load(\"@local_config_rocm//rocm:build_defs.bzl\", \"if_rocm_is_configured\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n load(\"//xla/stream_executor:build_defs.bzl\", \"if_cuda_or_rocm_is_configured\")\n@@ -20,57 +19,6 @@ package_group(\n     ],\n )\n \n-# Allows to explicitely disable nvshmem collectives using invocation flag.\n-bool_flag(\n-    name = \"nvshmem_enabled\",\n-    build_setting_default = True,\n-)\n-\n-# NVSHMEM requires builtin functions since it uses printf's for debugging.\n-config_setting(\n-    name = \"no_builtin_used\",\n-    values = {\n-        \"copt\": \"-fno-builtin\",\n-    },\n-)\n-\n-cc_library(\n-    name = \"nvshmem_collectives_if_builtin_used\",\n-    tags = [\n-        \"cuda-only\",\n-        \"gpu\",\n-    ],\n-    deps =\n-        select({\n-            \":no_builtin_used\": [],\n-            \"//conditions:default\": [\":nvshmem_collectives\"],\n-        }),\n-)\n-\n-config_setting(\n-    name = \"nvshmem_supported\",\n-    constraint_values = [\n-        \"@platforms//os:linux\",\n-    ],\n-    flag_values = {\n-        \":nvshmem_enabled\": \"True\",\n-    },\n-)\n-\n-# Since selects can't be nested we need to create this intermediate target\n-cc_library(\n-    name = \"nvshmem_collectives_if_supported\",\n-    tags = [\n-        \"cuda-only\",\n-        \"gpu\",\n-    ],\n-    deps =\n-        select({\n-            \":nvshmem_supported\": [\":nvshmem_collectives_if_builtin_used\"],\n-            \"//conditions:default\": [],\n-        }),\n-)\n-\n # Build target that registers all available GPU collectives implementations with the collectives\n # registry at link time.\n cc_library(\n@@ -373,6 +321,7 @@ cc_library(\n         \"@local_tsl//tsl/platform:numbers\",\n     ] + if_cuda_is_configured([\n         \"//xla/tsl/cuda:nccl\",\n+        \"//xla/stream_executor/cuda:nccl_memory_allocator\",  # buildcleaner: keep (static registration)\n     ]) + if_rocm_is_configured([\n         \"@local_config_rocm//rocm:rocm_headers\",\n         \"@local_config_rocm//rocm:rccl\",\n@@ -475,24 +424,22 @@ cc_library(\n         \"//xla/core/collectives:collectives_registry\",\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n-        \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/service:collective_ops_utils\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor/cuda:nvshmem\",\n+        \"//xla/stream_executor/cuda:nvshmem_memory_allocator\",  # buildcleaner: keep (static registration)\n         \"//xla/stream_executor/gpu:gpu_stream\",\n         \"//xla/tsl/concurrency:async_value\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/base\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n-        \"@com_google_absl//absl/time\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_config_cuda//cuda:cuda_headers\",\n         \"@local_tsl//tsl/platform:casts\",\n@@ -502,6 +449,32 @@ cc_library(\n     alwayslink = True,\n )\n \n+cc_library(\n+    name = \"nvshmem_collectives_if_builtin_used\",\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = select({\n+        \"//xla/stream_executor/cuda:no_builtin_used\": [],\n+        \"//conditions:default\": [\":nvshmem_collectives\"],\n+    }),\n+)\n+\n+cc_library(\n+    name = \"nvshmem_collectives_if_supported\",\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = select({\n+        \"//xla/stream_executor/cuda:nvshmem_supported\": [\n+            \":nvshmem_collectives_if_builtin_used\",\n+        ],\n+        \"//conditions:default\": [],\n+    }),\n+)\n+\n xla_test(\n     name = \"nccl_communicator_test\",\n     srcs = [\"nccl_communicator_test.cc\"],"
        },
        {
            "sha": "faa047a83318fce4bddbfd0f2c0fb6534a088ae3",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 54,
            "deletions": 0,
            "changes": 54,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -74,6 +74,24 @@ bool_flag(\n     ),\n )\n \n+# Allows to explicitely disable nvshmem collectives using invocation flag.\n+bool_flag(\n+    name = \"nvshmem_enabled\",\n+    build_setting_default = True,\n+)\n+\n+# NVSHMEM requires builtin functions since it uses printf's for debugging.\n+config_setting(\n+    name = \"no_builtin_used\",\n+    values = {\"copt\": \"-fno-builtin\"},\n+)\n+\n+config_setting(\n+    name = \"nvshmem_supported\",\n+    constraint_values = [\"@platforms//os:linux\"],\n+    flag_values = {\":nvshmem_enabled\": \"True\"},\n+)\n+\n config_setting(\n     name = \"libnvjitlink_support_enabled\",\n     flag_values = {\n@@ -100,8 +118,10 @@ cc_library(\n     deps = [\n         \":cuda_diagnostics\",\n         \":cuda_executor\",\n+        \":cuda_memory_allocator\",\n         \":cuda_platform_id\",\n         \":cuda_status\",\n+        \"//xla:debug_options_flags\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:executor_cache\",\n         \"//xla/stream_executor:platform\",\n@@ -928,6 +948,30 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"cuda_memory_allocator\",\n+    srcs = [\"cuda_memory_allocator.cc\"],\n+    hdrs = [\"cuda_memory_allocator.h\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \"//xla/stream_executor:memory_allocation\",\n+        \"//xla/stream_executor:memory_allocator\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/base:no_destructor\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/functional:any_invocable\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/synchronization\",\n+    ],\n+)\n+\n cc_library(\n     name = \"nccl_memory_allocator\",\n     srcs = [\"nccl_memory_allocator.cc\"],\n@@ -937,12 +981,14 @@ cc_library(\n         \"gpu\",\n     ],\n     deps = [\n+        \":cuda_memory_allocator\",\n         \"//xla:util\",\n         \"//xla/stream_executor:activate_context\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:memory_allocator\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/platform:initialize\",\n         \"//xla/tsl/cuda:nccl\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n@@ -952,6 +998,7 @@ cc_library(\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@local_tsl//tsl/platform:numbers\",\n     ],\n+    alwayslink = True,  # static registration\n )\n \n cc_library(\n@@ -988,10 +1035,13 @@ cc_library(\n         \"gpu\",\n     ],\n     deps = [\n+        \":cuda_memory_allocator\",\n         \":nvshmem\",\n         \"//xla/stream_executor:device_address\",\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:memory_allocator\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/platform:initialize\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n@@ -1002,6 +1052,7 @@ cc_library(\n         \"@local_tsl//tsl/platform:numbers\",\n         \"@nvshmem//:nvshmem_lib\",\n     ],\n+    alwayslink = True,  # static registration\n )\n \n cc_library(\n@@ -1206,6 +1257,7 @@ cc_library(\n         \":cuda_context\",\n         \":cuda_event\",\n         \":cuda_kernel\",\n+        \":cuda_memory_allocator\",\n         \":cuda_platform_id\",\n         \":cuda_status\",\n         \":cuda_stream\",\n@@ -1236,12 +1288,14 @@ cc_library(\n         \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:memory_allocation\",\n         \"//xla/stream_executor:memory_allocator\",\n+        \"//xla/stream_executor:memory_space\",\n         \"//xla/stream_executor:module_spec\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:plugin_registry\",\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor:stream\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:tensor_map\",\n         \"//xla/stream_executor/gpu:context\",\n         \"//xla/stream_executor/gpu:gpu_executor_header\",\n         \"//xla/stream_executor/gpu:multicast_memory\","
        },
        {
            "sha": "fa28dc809e5b0a6e9a98ba91db61b21202cf5e29",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 21,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"absl/base/call_once.h\"\n #include \"absl/base/casts.h\"\n #include \"absl/cleanup/cleanup.h\"\n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/check.h\"\n #include \"absl/numeric/int128.h\"\n@@ -61,6 +62,7 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_context.h\"\n #include \"xla/stream_executor/cuda/cuda_event.h\"\n #include \"xla/stream_executor/cuda/cuda_kernel.h\"\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/cuda/cuda_status.h\"\n #include \"xla/stream_executor/cuda/cuda_stream.h\"\n@@ -90,12 +92,14 @@ limitations under the License.\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n #include \"xla/stream_executor/memory_allocator.h\"\n+#include \"xla/stream_executor/memory_space.h\"\n #include \"xla/stream_executor/module_spec.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/plugin_registry.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/tensor_map.h\"\n #include \"xla/tsl/platform/env.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/logging.h\"\n@@ -1050,27 +1054,7 @@ CudaExecutor::CreateMemoryAllocator(MemorySpace type) {\n   }\n \n   if (type == MemorySpace::kCollective) {\n-    return std::make_unique<GenericMemoryAllocator>(\n-        [this](uint64_t size)\n-            -> absl::StatusOr<std::unique_ptr<MemoryAllocation>> {\n-          TF_ASSIGN_OR_RETURN(void* ptr, CollectiveMemoryAllocate(this, size));\n-          XLA_VLOG_DEVICE(2, device_ordinal())\n-              << \"allocated \" << ptr << \" for context \" << cuda_context_\n-              << \" of \" << size << \" bytes of collective memory\";\n-          return std::make_unique<GenericMemoryAllocation>(\n-              ptr, size, [this](void* location, uint64_t size) {\n-                auto status = CollectiveMemoryDeallocate(this, location);\n-                if (!status.ok()) {\n-                  XLA_LOG_DEVICE(ERROR, device_ordinal())\n-                      << \"failed to free collective memory at \" << location\n-                      << \"; result: \" << status;\n-                } else {\n-                  XLA_VLOG_DEVICE(2, device_ordinal())\n-                      << \"deallocated collective memory at \" << location\n-                      << \" for context \" << cuda_context_;\n-                }\n-              });\n-        });\n+    return CreateCollectiveMemoryAllocator(this, collective_allocator_type_);\n   }\n \n   if (type == MemorySpace::kHost) {"
        },
        {
            "sha": "00a6c0ca48f2a68b93ec26d37d93be38d5d4fdc7",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.h",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.h?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -40,6 +40,7 @@ limitations under the License.\n #include \"xla/stream_executor/command_buffer.h\"\n #include \"xla/stream_executor/cuda/cuda_context.h\"\n #include \"xla/stream_executor/cuda/cuda_kernel.h\"\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/dnn.h\"\n@@ -53,17 +54,22 @@ limitations under the License.\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n #include \"xla/stream_executor/memory_allocator.h\"\n+#include \"xla/stream_executor/memory_space.h\"\n #include \"xla/stream_executor/module_spec.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/tensor_map.h\"\n \n namespace stream_executor::gpu {\n \n // This class implements GpuExecutor for NVIDIA GPUs that use CUDA libraries.\n class CudaExecutor : public GpuExecutor {\n  public:\n-  CudaExecutor(Platform* platform, int device_ordinal)\n-      : GpuExecutor(platform, device_ordinal) {}\n+  CudaExecutor(Platform* platform, int device_ordinal,\n+               CollectiveAllocatorType collective_allocator_type)\n+      : GpuExecutor(platform, device_ordinal),\n+        collective_allocator_type_(collective_allocator_type) {}\n+\n   ~CudaExecutor() override;\n   std::unique_ptr<ActivateContext> Activate() override;\n   absl::Status Init() override;\n@@ -225,6 +231,8 @@ class CudaExecutor : public GpuExecutor {\n   // Returns true if a delay kernel is supported.\n   absl::StatusOr<bool> DelayKernelIsSupported();\n \n+  CollectiveAllocatorType collective_allocator_type_;\n+\n   bool is_vmm_supported_ = false;\n \n   bool is_rdma_supported_ = false;"
        },
        {
            "sha": "2aa70468f488ebadb4370706837d1171f6ca1010",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_memory_allocator.cc",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.cc?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -0,0 +1,87 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n+\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n+#include \"absl/base/const_init.h\"\n+#include \"absl/base/no_destructor.h\"\n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/functional/any_invocable.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/memory_allocator.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace stream_executor::gpu {\n+\n+// Per-process registry of collective allocator factories.\n+static absl::Mutex collective_allocators_mu(absl::kConstInit);\n+static absl::NoDestructor<\n+    absl::flat_hash_map<CollectiveAllocatorType, CollectiveAllocatorFactory>>\n+    collective_allocators ABSL_GUARDED_BY(collective_allocators_mu);\n+\n+namespace {\n+// Instead of failing early we return a memory allocator that always fails when\n+// asked to allocate collective memory.\n+//\n+// TODO(patrios): We should fail early, but in open source builds something is\n+// wrong with linking order and allocators are not registered.\n+class NoCollectiveMemoryAllocator : public MemoryAllocator {\n+ public:\n+  explicit NoCollectiveMemoryAllocator(CollectiveAllocatorType allocator_type)\n+      : allocator_type_(allocator_type) {}\n+\n+  absl::StatusOr<std::unique_ptr<MemoryAllocation>> Allocate(\n+      uint64_t size) override {\n+    return absl::UnimplementedError(absl::StrCat(\n+        \"No collective memory allocator registered for \", allocator_type_));\n+  }\n+\n+ private:\n+  CollectiveAllocatorType allocator_type_;\n+};\n+}  // namespace\n+\n+void RegisterCollectiveAllocatorFactory(\n+    CollectiveAllocatorType allocator_type,\n+    absl::AnyInvocable<std::unique_ptr<MemoryAllocator>(StreamExecutor*)>\n+        allocator_factory) {\n+  VLOG(1) << \"Registering collective allocator factory for \"\n+          << absl::StrCat(allocator_type);\n+  absl::MutexLock lock(collective_allocators_mu);\n+  collective_allocators->insert({allocator_type, std::move(allocator_factory)});\n+}\n+\n+absl::StatusOr<std::unique_ptr<MemoryAllocator>>\n+CreateCollectiveMemoryAllocator(StreamExecutor* executor,\n+                                CollectiveAllocatorType allocator_type) {\n+  absl::MutexLock lock(collective_allocators_mu);\n+  auto it = collective_allocators->find(allocator_type);\n+  if (it == collective_allocators->end()) {\n+    return std::make_unique<NoCollectiveMemoryAllocator>(allocator_type);\n+  }\n+  return it->second(executor);\n+}\n+\n+}  // namespace stream_executor::gpu"
        },
        {
            "sha": "6aef4027a7b77f637a35716cb9a9436c3a83ea99",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_memory_allocator.h",
            "status": "added",
            "additions": 62,
            "deletions": 0,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_memory_allocator.h?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -0,0 +1,62 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_CUDA_CUDA_MEMORY_ALLOCATOR_H_\n+#define XLA_STREAM_EXECUTOR_CUDA_CUDA_MEMORY_ALLOCATOR_H_\n+\n+#include <memory>\n+#include <string>\n+\n+#include \"absl/functional/any_invocable.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/stream_executor/memory_allocator.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace stream_executor::gpu {\n+\n+// A type of memory allocator for kCollective memory space.\n+enum class CollectiveAllocatorType { kNccl, kNvshmem };\n+\n+template <typename T>\n+void AbslStringify(std::string* str, CollectiveAllocatorType allocator_type) {\n+  switch (allocator_type) {\n+    case CollectiveAllocatorType::kNccl:\n+      *str = \"NCCL\";\n+      break;\n+    case CollectiveAllocatorType::kNvshmem:\n+      *str = \"NVSHMEM\";\n+      break;\n+  }\n+}\n+\n+using CollectiveAllocatorFactory =  // NOLINT\n+    absl::AnyInvocable<std::unique_ptr<MemoryAllocator>(StreamExecutor*)>;\n+\n+// Static registration of a collective memory allocator factory. NCCL and\n+// NVSHMEM allocators are not supported in all build configurations, and\n+// we rely on the static registration pattern as a way to ensure that\n+// we can dynamically select between available allocators.\n+void RegisterCollectiveAllocatorFactory(\n+    CollectiveAllocatorType allocator_type,\n+    CollectiveAllocatorFactory allocator_factory);\n+\n+// Creates a collective memory allocator for the given allocator type.\n+absl::StatusOr<std::unique_ptr<MemoryAllocator>>\n+CreateCollectiveMemoryAllocator(StreamExecutor* executor,\n+                                CollectiveAllocatorType allocator_type);\n+\n+}  // namespace stream_executor::gpu\n+\n+#endif  // XLA_STREAM_EXECUTOR_CUDA_CUDA_MEMORY_ALLOCATOR_H_"
        },
        {
            "sha": "5247fc7a9abe77b10d343b413d30d59b245cf56b",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_platform.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_platform.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_platform.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_platform.cc?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -26,8 +26,10 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"third_party/gpus/cuda/include/cuda.h\"\n #include \"third_party/gpus/cuda/nvml/include/nvml.h\"\n+#include \"xla/debug_options_flags.h\"\n #include \"xla/stream_executor/cuda/cuda_diagnostics.h\"\n #include \"xla/stream_executor/cuda/cuda_executor.h\"\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/cuda/cuda_status.h\"\n #include \"xla/stream_executor/device_description.h\"\n@@ -120,7 +122,13 @@ absl::StatusOr<StreamExecutor*> CudaPlatform::FindExisting(int ordinal) {\n \n absl::StatusOr<std::unique_ptr<StreamExecutor>>\n CudaPlatform::GetUncachedExecutor(int ordinal) {\n-  auto executor = std::make_unique<CudaExecutor>(this, ordinal);\n+  // TODO(b/468297040): We should not be using DebugOptions here.\n+  xla::DebugOptions debug_options = xla::GetDebugOptionsFromFlags();\n+  auto executor = std::make_unique<CudaExecutor>(\n+      this, ordinal,\n+      debug_options.xla_gpu_experimental_enable_nvshmem()\n+          ? CollectiveAllocatorType::kNvshmem\n+          : CollectiveAllocatorType::kNccl);\n   TF_RETURN_IF_ERROR(executor->Init());\n   return std::move(executor);\n }"
        },
        {
            "sha": "0d8e3bcbd0dc9c34ba208c1582b90cf147828455",
            "filename": "third_party/xla/xla/stream_executor/cuda/nccl_memory_allocator.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnccl_memory_allocator.cc?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -25,8 +25,10 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"third_party/nccl/nccl.h\"\n #include \"xla/stream_executor/activate_context.h\"\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/platform/initialize.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n@@ -106,3 +108,12 @@ absl::StatusOr<std::unique_ptr<MemoryAllocation>> NcclMemoryAllocator::Allocate(\n }\n \n }  // namespace stream_executor::gpu\n+\n+STREAM_EXECUTOR_REGISTER_MODULE_INITIALIZER(\n+    nccl_memory_allocator,\n+    stream_executor::gpu::RegisterCollectiveAllocatorFactory(\n+        stream_executor::gpu::CollectiveAllocatorType::kNccl,\n+        [](stream_executor::StreamExecutor* executor) {\n+          return std::make_unique<stream_executor::gpu::NcclMemoryAllocator>(\n+              executor);\n+        }));"
        },
        {
            "sha": "3988de1106c821a27e84ce1eaaf41977385b88e2",
            "filename": "third_party/xla/xla/stream_executor/cuda/nvshmem_memory_allocator.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnvshmem_memory_allocator.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8216c30a188639a92ce365cf3af195d2917ce663/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnvshmem_memory_allocator.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fnvshmem_memory_allocator.cc?ref=8216c30a188639a92ce365cf3af195d2917ce663",
            "patch": "@@ -25,9 +25,12 @@ limitations under the License.\n #include \"absl/strings/str_format.h\"\n #include \"third_party/nvshmem/nvshmem.h\"   // IWYU pragma: keep\n #include \"third_party/nvshmem/nvshmemx.h\"  // IWYU pragma: keep\n+#include \"xla/stream_executor/cuda/cuda_memory_allocator.h\"\n #include \"xla/stream_executor/cuda/nvshmem.h\"\n #include \"xla/stream_executor/device_address.h\"\n #include \"xla/stream_executor/memory_allocation.h\"\n+#include \"xla/stream_executor/platform/initialize.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"tsl/platform/numbers.h\"\n@@ -90,3 +93,12 @@ NvshmemMemoryAllocator::Allocate(uint64_t size) {\n }\n \n }  // namespace stream_executor::gpu\n+\n+STREAM_EXECUTOR_REGISTER_MODULE_INITIALIZER(\n+    nvshmem_memory_allocator,\n+    stream_executor::gpu::RegisterCollectiveAllocatorFactory(\n+        stream_executor::gpu::CollectiveAllocatorType::kNvshmem,\n+        [](stream_executor::StreamExecutor* executor) {\n+          return std::make_unique<\n+              stream_executor::gpu::NvshmemMemoryAllocator>();\n+        }));"
        }
    ],
    "stats": {
        "total": 357,
        "additions": 278,
        "deletions": 79
    }
}