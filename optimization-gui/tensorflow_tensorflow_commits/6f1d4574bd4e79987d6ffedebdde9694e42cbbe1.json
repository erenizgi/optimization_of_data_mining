{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 825902854",
    "sha": "6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
    "files": [
        {
            "sha": "84650b04395d70e176cc0410ee8433a0d045bb04",
            "filename": "tensorflow/core/kernels/string_strip_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_strip_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_strip_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_strip_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -43,7 +43,7 @@ class StringStripOp : public OpKernel {\n     for (int64_t i = 0; i < input.size(); ++i) {\n       absl::string_view entry(input(i));\n       str_util::RemoveWhitespaceContext(&entry);\n-      output(i) = string(entry);\n+      output(i) = std::string(entry);\n     }\n   }\n };"
        },
        {
            "sha": "a0486165a8ed2d71a9f9a80785f051e156cc149c",
            "filename": "tensorflow/core/kernels/string_to_hash_bucket_fast_op.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_fast_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_fast_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_fast_op.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -26,7 +26,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-template <uint64 hash(absl::string_view)>\n+template <uint64_t hash(absl::string_view)>\n class StringToHashBucketOp : public OpKernel {\n  public:\n   explicit StringToHashBucketOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n@@ -46,8 +46,8 @@ class StringToHashBucketOp : public OpKernel {\n \n     typedef decltype(input_flat.size()) Index;\n     for (Index i = 0; i < input_flat.size(); ++i) {\n-      const uint64 input_hash = hash(input_flat(i));\n-      const uint64 bucket_id = input_hash % num_buckets_;\n+      const uint64_t input_hash = hash(input_flat(i));\n+      const uint64_t bucket_id = input_hash % num_buckets_;\n       // The number of buckets is always in the positive range of int64 so is\n       // the resulting bucket_id. Casting the bucket_id from uint64 to int64 is\n       // safe."
        },
        {
            "sha": "e7bb536ee542b414fe10c030be81c02c983f6f2a",
            "filename": "tensorflow/core/kernels/string_to_hash_bucket_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -42,8 +42,8 @@ class LegacyStringToHashBucketOp : public OpKernel {\n \n     typedef decltype(input_flat.size()) Index;\n     for (Index i = 0; i < input_flat.size(); ++i) {\n-      const uint64 input_hash = Hash64(input_flat(i));\n-      const uint64 bucket_id = input_hash % num_buckets_;\n+      const uint64_t input_hash = Hash64(input_flat(i));\n+      const uint64_t bucket_id = input_hash % num_buckets_;\n       // The number of buckets is always in the positive range of int64 so is\n       // the resulting bucket_id. Casting the bucket_id from uint64 to int64 is\n       // safe."
        },
        {
            "sha": "a509ae2a337f2f4a3653b1bcafaec2194a8c26ca",
            "filename": "tensorflow/core/kernels/string_to_hash_bucket_op.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_to_hash_bucket_op.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -26,7 +26,7 @@ limitations under the License.\n \n namespace tensorflow {\n \n-template <uint64 hash(const uint64 (&)[2], const string&)>\n+template <uint64_t hash(const uint64_t (&)[2], const std::string&)>\n class StringToKeyedHashBucketOp : public OpKernel {\n  public:\n   explicit StringToKeyedHashBucketOp(OpKernelConstruction* ctx)\n@@ -53,8 +53,8 @@ class StringToKeyedHashBucketOp : public OpKernel {\n \n     typedef decltype(input_flat.size()) Index;\n     for (Index i = 0; i < input_flat.size(); ++i) {\n-      const uint64 input_hash = hash(key_, input_flat(i));\n-      const uint64 bucket_id = input_hash % num_buckets_;\n+      const uint64_t input_hash = hash(key_, input_flat(i));\n+      const uint64_t bucket_id = input_hash % num_buckets_;\n       // The number of buckets is always in the positive range of int64 so is\n       // the resulting bucket_id. Casting the bucket_id from uint64 to int64 is\n       // safe.\n@@ -64,7 +64,7 @@ class StringToKeyedHashBucketOp : public OpKernel {\n \n  private:\n   int64_t num_buckets_;\n-  uint64 key_[2];\n+  uint64_t key_[2];\n \n   StringToKeyedHashBucketOp(const StringToKeyedHashBucketOp&) = delete;\n   void operator=(const StringToKeyedHashBucketOp&) = delete;"
        },
        {
            "sha": "3d234a2349844819f5c2b0f9a24a5d3acb2827d9",
            "filename": "tensorflow/core/kernels/string_to_number_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_number_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_to_number_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_to_number_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -68,7 +68,7 @@ class StringToNumberOp : public OpKernel {\n                           StringToNumberOp<type>)\n REGISTER(float);\n REGISTER(double);\n-REGISTER(int32);\n+REGISTER(int32_t);\n REGISTER(int64_t);\n REGISTER(uint32_t);\n REGISTER(uint64_t);"
        },
        {
            "sha": "ff31e7c0c2816b2f34ca57f78de55d3ff660cbc9",
            "filename": "tensorflow/core/kernels/string_upper_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_upper_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_upper_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_upper_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -63,7 +63,7 @@ class StringUpperOp : public OpKernel {\n   }\n \n  private:\n-  string encoding_;\n+  std::string encoding_;\n };\n \n REGISTER_KERNEL_BUILDER(Name(\"StringUpper\").Device(DEVICE_CPU), StringUpperOp);"
        },
        {
            "sha": "a0185d1bcbddd27292ae4a7e019c36a1192f9198",
            "filename": "tensorflow/core/kernels/string_util.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_util.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -19,7 +19,7 @@ limitations under the License.\n namespace tensorflow {\n \n // Sets unit value based on str.\n-absl::Status ParseUnicodeEncoding(const string& str,\n+absl::Status ParseUnicodeEncoding(const std::string& str,\n                                   UnicodeEncoding* encoding) {\n   if (str == \"UTF-8\") {\n     *encoding = UnicodeEncoding::UTF8;\n@@ -36,7 +36,7 @@ absl::Status ParseUnicodeEncoding(const string& str,\n }\n \n // Sets unit value based on str.\n-absl::Status ParseCharUnit(const string& str, CharUnit* unit) {\n+absl::Status ParseCharUnit(const std::string& str, CharUnit* unit) {\n   if (str == \"BYTE\") {\n     *unit = CharUnit::BYTE;\n   } else if (str == \"UTF8_CHAR\") {\n@@ -50,7 +50,7 @@ absl::Status ParseCharUnit(const string& str, CharUnit* unit) {\n \n // Return the number of Unicode characters in a UTF-8 string.\n // Result may be incorrect if the input string is not valid UTF-8.\n-int32 UTF8StrLen(const string& str) {\n+int32_t UTF8StrLen(const std::string& str) {\n   const int32_t byte_size = str.size();\n   const char* const end = str.data() + byte_size;\n   const char* ptr = str.data();"
        },
        {
            "sha": "af790ad417c7783e23dd1a8cde0e9639b6c93e92",
            "filename": "tensorflow/core/kernels/string_util.h",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fstring_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fstring_util.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -33,14 +33,15 @@ enum class CharUnit { BYTE, UTF8_CHAR };\n inline bool IsTrailByte(char x) { return static_cast<signed char>(x) < -0x40; }\n \n // Sets `encoding` based on `str`.\n-absl::Status ParseUnicodeEncoding(const string& str, UnicodeEncoding* encoding);\n+absl::Status ParseUnicodeEncoding(const std::string& str,\n+                                  UnicodeEncoding* encoding);\n \n // Sets `unit` value based on `str`.\n-absl::Status ParseCharUnit(const string& str, CharUnit* unit);\n+absl::Status ParseCharUnit(const std::string& str, CharUnit* unit);\n \n // Returns the number of Unicode characters in a UTF-8 string.\n // Result may be incorrect if the input string is not valid UTF-8.\n-int32 UTF8StrLen(const string& str);\n+int32_t UTF8StrLen(const std::string& str);\n \n // Get the next UTF8 character position starting at the given position and\n // skipping the given number of characters. Position is a byte offset, and"
        },
        {
            "sha": "0b3fea3ab3e0d326658ab59edf56b6767f9d18ed",
            "filename": "tensorflow/core/kernels/substr_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsubstr_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsubstr_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsubstr_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -39,7 +39,7 @@ template <typename T>\n class SubstrOp : public OpKernel {\n  public:\n   explicit SubstrOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n-    string unit;\n+    std::string unit;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"unit\", &unit));\n     OP_REQUIRES_OK(ctx, ParseCharUnit(unit, &unit_));\n   }\n@@ -342,6 +342,6 @@ class SubstrOp : public OpKernel {\n   REGISTER_KERNEL_BUILDER(                                         \\\n       Name(\"Substr\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n       SubstrOp<type>);\n-REGISTER_SUBSTR(int32);\n+REGISTER_SUBSTR(int32_t);\n REGISTER_SUBSTR(int64_t);\n }  // namespace tensorflow"
        },
        {
            "sha": "4e630604e5f4c8e5649c0ab3c82c13de8ac61ff8",
            "filename": "tensorflow/core/kernels/substr_op_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsubstr_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsubstr_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsubstr_op_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -136,9 +136,9 @@ Graph* SetupSubstrGraph(const Tensor& input, const int32_t pos,\n                         const int32_t len, const char* const unit) {\n   Graph* g = new Graph(OpRegistry::Global());\n   Tensor position(DT_INT32, TensorShape({}));\n-  position.flat<int32>().setConstant(pos);\n+  position.flat<int32_t>().setConstant(pos);\n   Tensor length(DT_INT32, TensorShape({}));\n-  length.flat<int32>().setConstant(len);\n+  length.flat<int32_t>().setConstant(len);\n \n   TF_CHECK_OK(NodeBuilder(\"substr_op\", \"Substr\")\n                   .Input(test::graph::Constant(g, input))"
        },
        {
            "sha": "fb080f66fd5e52f07894064002905b87c3f2b566",
            "filename": "tensorflow/core/kernels/summary_audio_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -44,7 +44,7 @@ class SummaryAudioOp : public OpKernel {\n     OP_REQUIRES(c, tensor.dims() >= 2 && tensor.dims() <= 3,\n                 errors::InvalidArgument(\"Tensor must be 3-D or 2-D, got: \",\n                                         tensor.shape().DebugString()));\n-    const string& base_tag = tag.scalar<tstring>()();\n+    const std::string& base_tag = tag.scalar<tstring>()();\n \n     float sample_rate = sample_rate_attr_;\n     if (!has_sample_rate_attr_) {"
        },
        {
            "sha": "987f7bdc1833f3f87ef1db872fd941fabf6c409f",
            "filename": "tensorflow/core/kernels/summary_audio_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_audio_op_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -37,7 +37,7 @@ namespace tensorflow {\n namespace {\n \n static void EXPECT_SummaryMatches(const Summary& actual,\n-                                  const string& expected_str) {\n+                                  const std::string& expected_str) {\n   Summary expected;\n   CHECK(protobuf::TextFormat::ParseFromString(expected_str, &expected));\n   EXPECT_EQ(expected.DebugString(), actual.DebugString());"
        },
        {
            "sha": "6ca851979fd503edb8738a9b1c410e858a115907",
            "filename": "tensorflow/core/kernels/summary_image_op.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 12,
            "changes": 24,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -28,14 +28,14 @@ namespace tensorflow {\n \n class SummaryImageOp : public OpKernel {\n  public:\n-  typedef Eigen::Tensor<uint8, 2, Eigen::RowMajor> Uint8Image;\n+  typedef Eigen::Tensor<uint8_t, 2, Eigen::RowMajor> Uint8Image;\n \n   explicit SummaryImageOp(OpKernelConstruction* context) : OpKernel(context) {\n     int64_t max_images_tmp;\n     OP_REQUIRES_OK(context, context->GetAttr(\"max_images\", &max_images_tmp));\n     OP_REQUIRES(context, max_images_tmp < (1LL << 31),\n                 errors::InvalidArgument(\"max_images must be < 2^31\"));\n-    max_images_ = static_cast<int32>(max_images_tmp);\n+    max_images_ = static_cast<int32_t>(max_images_tmp);\n     const TensorProto* proto;\n     OP_REQUIRES_OK(context, context->GetAttr(\"bad_color\", &proto));\n     OP_REQUIRES_OK(context, context->device()->MakeTensorFromProto(\n@@ -61,7 +61,7 @@ class SummaryImageOp : public OpKernel {\n                 errors::InvalidArgument(\n                     \"Tensor must be 4-D with last dim 1, 3, or 4, not \",\n                     tensor.shape().DebugString()));\n-    const string& base_tag = tags.scalar<tstring>()();\n+    const std::string& base_tag = tags.scalar<tstring>()();\n \n     OP_REQUIRES(c,\n                 tensor.dim_size(0) < (1LL << 31) &&\n@@ -87,8 +87,8 @@ class SummaryImageOp : public OpKernel {\n     if (tensor.dtype() == DT_UINT8) {\n       // For uint8 input, no normalization is necessary\n       auto ith_image = [&tensor, batch_size, hw, depth](int i) {\n-        auto values = tensor.shaped<uint8, 3>({batch_size, hw, depth});\n-        return typename TTypes<uint8>::ConstMatrix(\n+        auto values = tensor.shaped<uint8_t, 3>({batch_size, hw, depth});\n+        return typename TTypes<uint8_t>::ConstMatrix(\n             &values(i, 0, 0), Eigen::DSizes<Eigen::DenseIndex, 2>(hw, depth));\n       };\n       OP_REQUIRES_OK(\n@@ -112,14 +112,14 @@ class SummaryImageOp : public OpKernel {\n   template <class T>\n   void NormalizeAndAddImages(OpKernelContext* c, const Tensor& tensor, int h,\n                              int w, int hw, int depth, int batch_size,\n-                             const string& base_tag, Summary* s) {\n+                             const std::string& base_tag, Summary* s) {\n     // For float and half images, nans and infs are replaced with bad_color.\n     OP_REQUIRES(c, bad_color_.dim_size(0) >= depth,\n                 errors::InvalidArgument(\n                     \"expected depth <= bad_color.size, got depth = \", depth,\n                     \", bad_color.size = \", bad_color_.dim_size(0)));\n-    auto bad_color_full = bad_color_.vec<uint8>();\n-    typename TTypes<uint8>::ConstVec bad_color(bad_color_full.data(), depth);\n+    auto bad_color_full = bad_color_.vec<uint8_t>();\n+    typename TTypes<uint8_t>::ConstVec bad_color(bad_color_full.data(), depth);\n \n     // Float images must be scaled and translated.\n     Uint8Image image(hw, depth);\n@@ -142,7 +142,7 @@ class SummaryImageOp : public OpKernel {\n   // differently in the float and uint8 cases: the float case needs a temporary\n   // buffer which can be shared across calls to ith_image, but the uint8 case\n   // does not.\n-  absl::Status AddImages(const string& tag, int batch_size, int w, int h,\n+  absl::Status AddImages(const std::string& tag, int batch_size, int w, int h,\n                          int depth,\n                          const std::function<Uint8Image(int)>& ith_image,\n                          Summary* s) {\n@@ -180,7 +180,7 @@ class SummaryImageOp : public OpKernel {\n   template <class T>\n   static void NormalizeFloatImage(int hw, int depth,\n                                   typename TTypes<T>::ConstMatrix values,\n-                                  typename TTypes<uint8>::ConstVec bad_color,\n+                                  typename TTypes<uint8_t>::ConstVec bad_color,\n                                   Uint8Image* image) {\n     if (!image->size()) return;  // Nothing to do for empty images\n \n@@ -241,15 +241,15 @@ class SummaryImageOp : public OpKernel {\n       }\n       if (finite) {\n         image->chip<0>(i) = (values.template chip<0>(i) * scale + offset)\n-                                .template cast<uint8>();\n+                                .template cast<uint8_t>();\n       } else {\n         image->chip<0>(i) = bad_color;\n       }\n     }\n   }\n \n  private:\n-  int32 max_images_;\n+  int32_t max_images_;\n   Tensor bad_color_;\n };\n "
        },
        {
            "sha": "43e4bb06b2710447cdec2e7a8c7b24bb5a4161bf",
            "filename": "tensorflow/core/kernels/summary_image_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_image_op_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -37,7 +37,7 @@ namespace tensorflow {\n namespace {\n \n static void EXPECT_SummaryMatches(const Summary& actual,\n-                                  const string& expected_str) {\n+                                  const std::string& expected_str) {\n   Summary expected;\n   CHECK(protobuf::TextFormat::ParseFromString(expected_str, &expected));\n   EXPECT_EQ(expected.DebugString(), actual.DebugString());"
        },
        {
            "sha": "0f743c4dfa2590bab6bec822fdba121c099043df",
            "filename": "tensorflow/core/kernels/summary_interface.h",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_interface.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_interface.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_interface.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -36,21 +36,21 @@ class SummaryWriterInterface : public ResourceBase {\n \n   // These are called in the OpKernel::Compute methods for the summary ops.\n   virtual absl::Status WriteTensor(int64_t global_step, Tensor t,\n-                                   const string& tag,\n-                                   const string& serialized_metadata) = 0;\n+                                   const std::string& tag,\n+                                   const std::string& serialized_metadata) = 0;\n \n   virtual absl::Status WriteScalar(int64_t global_step, Tensor t,\n-                                   const string& tag) = 0;\n+                                   const std::string& tag) = 0;\n \n   virtual absl::Status WriteHistogram(int64_t global_step, Tensor t,\n-                                      const string& tag) = 0;\n+                                      const std::string& tag) = 0;\n \n   virtual absl::Status WriteImage(int64_t global_step, Tensor t,\n-                                  const string& tag, int max_images,\n+                                  const std::string& tag, int max_images,\n                                   Tensor bad_color) = 0;\n \n   virtual absl::Status WriteAudio(int64_t global_step, Tensor t,\n-                                  const string& tag, int max_outputs_,\n+                                  const std::string& tag, int max_outputs_,\n                                   float sample_rate) = 0;\n \n   virtual absl::Status WriteGraph(int64_t global_step,"
        },
        {
            "sha": "bb1f5f8e755872bb529fb73f7c3af5d070449652",
            "filename": "tensorflow/core/kernels/summary_kernels.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 16,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_kernels.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_kernels.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_kernels.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -40,19 +40,19 @@ class CreateSummaryFileWriterOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"logdir\", &tmp));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(tmp->shape()),\n                 errors::InvalidArgument(\"logdir must be a scalar\"));\n-    const string logdir = tmp->scalar<tstring>()();\n+    const std::string logdir = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"max_queue\", &tmp));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(tmp->shape()),\n                 errors::InvalidArgument(\"max_queue must be a scalar\"));\n-    const int32_t max_queue = tmp->scalar<int32>()();\n+    const int32_t max_queue = tmp->scalar<int32_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"flush_millis\", &tmp));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(tmp->shape()),\n                 errors::InvalidArgument(\"flush_millis must be a scalar\"));\n-    const int32_t flush_millis = tmp->scalar<int32>()();\n+    const int32_t flush_millis = tmp->scalar<int32_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"filename_suffix\", &tmp));\n     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(tmp->shape()),\n                 errors::InvalidArgument(\"filename_suffix must be a scalar\"));\n-    const string filename_suffix = tmp->scalar<tstring>()();\n+    const std::string filename_suffix = tmp->scalar<tstring>()();\n \n     core::RefCountPtr<SummaryWriterInterface> s;\n     OP_REQUIRES_OK(ctx, LookupOrCreateResource<SummaryWriterInterface>(\n@@ -75,13 +75,13 @@ class CreateSummaryDbWriterOp : public OpKernel {\n   void Compute(OpKernelContext* ctx) override {\n     const Tensor* tmp;\n     OP_REQUIRES_OK(ctx, ctx->input(\"db_uri\", &tmp));\n-    const string db_uri = tmp->scalar<tstring>()();\n+    const std::string db_uri = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"experiment_name\", &tmp));\n-    const string experiment_name = tmp->scalar<tstring>()();\n+    const std::string experiment_name = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"run_name\", &tmp));\n-    const string run_name = tmp->scalar<tstring>()();\n+    const std::string run_name = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"user_name\", &tmp));\n-    const string user_name = tmp->scalar<tstring>()();\n+    const std::string user_name = tmp->scalar<tstring>()();\n \n     core::RefCountPtr<SummaryWriterInterface> s;\n     OP_REQUIRES_OK(\n@@ -140,9 +140,9 @@ class WriteSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"step\", &tmp));\n     const int64_t step = tmp->scalar<int64_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"tag\", &tmp));\n-    const string& tag = tmp->scalar<tstring>()();\n+    const std::string& tag = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"summary_metadata\", &tmp));\n-    const string& serialized_metadata = tmp->scalar<tstring>()();\n+    const std::string& serialized_metadata = tmp->scalar<tstring>()();\n \n     const Tensor* t;\n     OP_REQUIRES_OK(ctx, ctx->input(\"tensor\", &t));\n@@ -220,7 +220,7 @@ class WriteScalarSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"step\", &tmp));\n     const int64_t step = tmp->scalar<int64_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"tag\", &tmp));\n-    const string& tag = tmp->scalar<tstring>()();\n+    const std::string& tag = tmp->scalar<tstring>()();\n \n     const Tensor* t;\n     OP_REQUIRES_OK(ctx, ctx->input(\"value\", &t));\n@@ -242,7 +242,7 @@ class WriteHistogramSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"step\", &tmp));\n     const int64_t step = tmp->scalar<int64_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"tag\", &tmp));\n-    const string& tag = tmp->scalar<tstring>()();\n+    const std::string& tag = tmp->scalar<tstring>()();\n \n     const Tensor* t;\n     OP_REQUIRES_OK(ctx, ctx->input(\"values\", &t));\n@@ -260,7 +260,7 @@ class WriteImageSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"max_images\", &max_images_tmp));\n     OP_REQUIRES(ctx, max_images_tmp < (1LL << 31),\n                 errors::InvalidArgument(\"max_images must be < 2^31\"));\n-    max_images_ = static_cast<int32>(max_images_tmp);\n+    max_images_ = static_cast<int32_t>(max_images_tmp);\n   }\n \n   void Compute(OpKernelContext* ctx) override {\n@@ -270,7 +270,7 @@ class WriteImageSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"step\", &tmp));\n     const int64_t step = tmp->scalar<int64_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"tag\", &tmp));\n-    const string& tag = tmp->scalar<tstring>()();\n+    const std::string& tag = tmp->scalar<tstring>()();\n     const Tensor* bad_color;\n     OP_REQUIRES_OK(ctx, ctx->input(\"bad_color\", &bad_color));\n     OP_REQUIRES(\n@@ -285,7 +285,7 @@ class WriteImageSummaryOp : public OpKernel {\n   }\n \n  private:\n-  int32 max_images_;\n+  int32_t max_images_;\n };\n REGISTER_KERNEL_BUILDER(Name(\"WriteImageSummary\").Device(DEVICE_CPU),\n                         WriteImageSummaryOp);\n@@ -305,7 +305,7 @@ class WriteAudioSummaryOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, ctx->input(\"step\", &tmp));\n     const int64_t step = tmp->scalar<int64_t>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"tag\", &tmp));\n-    const string& tag = tmp->scalar<tstring>()();\n+    const std::string& tag = tmp->scalar<tstring>()();\n     OP_REQUIRES_OK(ctx, ctx->input(\"sample_rate\", &tmp));\n     const float sample_rate = tmp->scalar<float>()();\n "
        },
        {
            "sha": "3e456df7b6f88805fc24f27c7742909888d3c60b",
            "filename": "tensorflow/core/kernels/summary_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_op_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -39,7 +39,7 @@ namespace tensorflow {\n namespace {\n \n static void EXPECT_SummaryMatches(const Summary& actual,\n-                                  const string& expected_str) {\n+                                  const std::string& expected_str) {\n   Summary expected;\n   CHECK(protobuf::TextFormat::ParseFromString(expected_str, &expected));\n   EXPECT_EQ(expected.DebugString(), actual.DebugString());"
        },
        {
            "sha": "5bbcb254685b36273f8031b4cc5ffc021d3098af",
            "filename": "tensorflow/core/kernels/summary_tensor_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -43,7 +43,7 @@ class SummaryTensorOpV2 : public OpKernel {\n \n     Summary s;\n     Summary::Value* v = s.add_value();\n-    v->set_tag(string(tag.scalar<tstring>()()));  // NOLINT\n+    v->set_tag(std::string(tag.scalar<tstring>()()));  // NOLINT\n \n     if (tensor.dtype() == DT_STRING) {\n       // tensor_util.makeNdarray doesn't work for strings in tensor_content"
        },
        {
            "sha": "87a3dd2f0b9a22ffd7c82f12934efd7d63a05d32",
            "filename": "tensorflow/core/kernels/summary_tensor_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fsummary_tensor_op_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -37,7 +37,7 @@ namespace tensorflow {\n namespace {\n \n static void EXPECT_SummaryMatches(const Summary& actual,\n-                                  const string& expected_str) {\n+                                  const std::string& expected_str) {\n   Summary expected;\n   CHECK(protobuf::TextFormat::ParseFromString(expected_str, &expected));\n   EXPECT_EQ(expected.DebugString(), actual.DebugString());"
        },
        {
            "sha": "2919db1e1ce36f5bf0dab5fabe7fd9e7b6861aff",
            "filename": "tensorflow/core/kernels/tensor_array.h",
            "status": "modified",
            "additions": 12,
            "deletions": 10,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_array.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_array.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_array.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -136,8 +136,9 @@ class TensorArray : public ResourceBase {\n   // 'N' elements.  While the underlying storage is a std::vector and\n   // can hold more than MAX_INT entries, in practice we do not expect\n   // users to construct this many Tensors for storage in a TensorArray.\n-  TensorArray(const string& key, const DataType& dtype, const Tensor& handle,\n-              int32_t N, const PartialTensorShape& element_shape,\n+  TensorArray(const std::string& key, const DataType& dtype,\n+              const Tensor& handle, int32_t N,\n+              const PartialTensorShape& element_shape,\n               bool identical_element_shapes, bool dynamic_size,\n               bool multiple_writes_aggregate, bool is_grad, int32_t marked_size,\n               bool clear_after_read)\n@@ -193,7 +194,7 @@ class TensorArray : public ResourceBase {\n \n   template <typename Device, typename T>\n   absl::Status WriteOrAggregateMany(OpKernelContext* ctx,\n-                                    const std::vector<int32>& indices,\n+                                    const std::vector<int32_t>& indices,\n                                     std::vector<Tensor>* values) {\n     mutex_lock l(mu_);\n     int32_t i = 0;\n@@ -228,7 +229,8 @@ class TensorArray : public ResourceBase {\n   }\n \n   template <typename Device, typename T>\n-  absl::Status ReadMany(OpKernelContext* ctx, const std::vector<int32>& indices,\n+  absl::Status ReadMany(OpKernelContext* ctx,\n+                        const std::vector<int32_t>& indices,\n                         std::vector<Tensor>* values) {\n     mutex_lock l(mu_);\n     values->clear();\n@@ -260,7 +262,7 @@ class TensorArray : public ResourceBase {\n     return absl::OkStatus();\n   }\n \n-  string DebugString() const override {\n+  std::string DebugString() const override {\n     mutex_lock l(mu_);\n     CHECK(!closed_);\n     return absl::StrCat(\"TensorArray[\", tensors_.size(), \"]\");\n@@ -272,7 +274,7 @@ class TensorArray : public ResourceBase {\n   }\n \n   // Return the size of the TensorArray.\n-  absl::Status Size(int32* size) {\n+  absl::Status Size(int32_t* size) {\n     mutex_lock l(mu_);\n     TF_RETURN_IF_ERROR(LockedReturnIfClosed());\n     *size = tensors_.size();\n@@ -290,15 +292,15 @@ class TensorArray : public ResourceBase {\n   }\n \n   // Return the marked size of the TensorArray.\n-  absl::Status MarkedSize(int32* size) {\n+  absl::Status MarkedSize(int32_t* size) {\n     mutex_lock l(mu_);\n     TF_RETURN_IF_ERROR(LockedReturnIfClosed());\n     *size = marked_size_;\n     return absl::OkStatus();\n   }\n \n   // Return the size that should be used by pack or concat op.\n-  absl::Status PackOrConcatSize(int32* size) {\n+  absl::Status PackOrConcatSize(int32_t* size) {\n     mutex_lock l(mu_);\n     TF_RETURN_IF_ERROR(LockedReturnIfClosed());\n     *size = is_grad_ ? marked_size_ : tensors_.size();\n@@ -372,7 +374,7 @@ class TensorArray : public ResourceBase {\n     return absl::OkStatus();\n   }\n \n-  const string key_;\n+  const std::string key_;\n \n   const DataType dtype_;\n   Tensor handle_;\n@@ -401,7 +403,7 @@ class TensorArray : public ResourceBase {\n \n   // The size of the TensorArray after a (legacy) unpack or split is performed.\n   // -1 if there has been no unpack or split performed on the TensorArray.\n-  int32 marked_size_;\n+  int32_t marked_size_;\n \n   // The shape of each element in the TensorArray, may be partially known or not\n   // known at all."
        },
        {
            "sha": "bd2956c734a1b787e3ea11a74e3739ef815f6d6b",
            "filename": "tensorflow/core/kernels/tensor_array_ops.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 25,
            "changes": 50,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_array_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_array_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_array_ops.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -57,8 +57,8 @@ typedef Eigen::GpuDevice GPUDevice;\n \n namespace tensorflow {\n \n-absl::Status GetHandle(OpKernelContext* ctx, string* container,\n-                       string* ta_handle) {\n+absl::Status GetHandle(OpKernelContext* ctx, std::string* container,\n+                       std::string* ta_handle) {\n   {\n     Tensor tensor;\n     // Assuming that handle is the input at index 0.\n@@ -80,8 +80,8 @@ absl::Status GetHandle(OpKernelContext* ctx, string* container,\n }\n \n absl::Status GetTensorArray(OpKernelContext* ctx, TensorArray** tensor_array) {\n-  string container;\n-  string ta_handle;\n+  std::string container;\n+  std::string ta_handle;\n   if (ctx->input_dtype(0) != DT_RESOURCE) {\n     TF_RETURN_IF_ERROR(GetHandle(ctx, &container, &ta_handle));\n     ResourceMgr* rm = ctx->resource_manager();\n@@ -197,13 +197,13 @@ class TensorArrayOp : public TensorArrayCreationOp {\n           \"TensorArray size must be scalar, but had shape: \",\n           tensor_size->shape().DebugString());\n     }\n-    const int32_t size = tensor_size->scalar<int32>()();\n+    const int32_t size = tensor_size->scalar<int32_t>()();\n     if (size < 0) {\n       return errors::InvalidArgument(\"Size should be >= 0.\");\n     }\n \n     auto handle = tensor_array_output_handle->flat<tstring>();\n-    string unique_tensor_array_name =\n+    std::string unique_tensor_array_name =\n         absl::StrCat(tensor_array_name_, \"_\",\n                      TensorArray::tensor_array_counter.fetch_add(1));\n     handle(0) = \"_tensor_arrays\";\n@@ -230,7 +230,7 @@ class TensorArrayOp : public TensorArrayCreationOp {\n   bool identical_element_shapes_;\n   bool dynamic_size_;\n   bool clear_after_read_;\n-  string tensor_array_name_;  // The name used to create the TensorArray.\n+  std::string tensor_array_name_;  // The name used to create the TensorArray.\n \n   TensorArrayOp(const TensorArrayOp&) = delete;\n   void operator=(const TensorArrayOp&) = delete;\n@@ -314,8 +314,8 @@ class TensorArrayGradOp : public TensorArrayCreationOp {\n   absl::Status CreateTensorArray(OpKernelContext* ctx, ResourceMgr* rm,\n                                  Tensor* tensor_array_output_handle,\n                                  TensorArray** output_tensor_array) override {\n-    string container;\n-    string tensor_array_name;\n+    std::string container;\n+    std::string tensor_array_name;\n     if (ctx->input_dtype(0) != DT_RESOURCE) {\n       TF_RETURN_IF_ERROR(GetHandle(ctx, &container, &tensor_array_name));\n       if (container != \"_tensor_arrays\") {\n@@ -331,8 +331,8 @@ class TensorArrayGradOp : public TensorArrayCreationOp {\n         return errors::InvalidArgument(\"Wrong input container. \",\n                                        resource.name());\n       }\n-      tensor_array_name =\n-          string(absl::string_view(resource.name()).substr(container.size()));\n+      tensor_array_name = std::string(\n+          absl::string_view(resource.name()).substr(container.size()));\n     }\n \n     auto output_handle = tensor_array_output_handle->flat<tstring>();\n@@ -407,7 +407,7 @@ class TensorArrayGradOp : public TensorArrayCreationOp {\n   // The gradient source for creating the given\n   // gradient TensorArray.  This should be unique to each gradients\n   // call.  Typical values look like \"gradients\", \"gradients_1\", ...\n-  string source_;\n+  std::string source_;\n \n   TensorArrayGradOp(const TensorArrayGradOp&) = delete;\n   void operator=(const TensorArrayGradOp&) = delete;\n@@ -490,7 +490,7 @@ class TensorArrayWriteOp : public OpKernel {\n     TensorArray* tensor_array = nullptr;\n     OP_REQUIRES_OK(ctx, GetTensorArray(ctx, &tensor_array));\n     core::ScopedUnref unref(tensor_array);\n-    const int32_t index = tensor_index->scalar<int32>()();\n+    const int32_t index = tensor_index->scalar<int32_t>()();\n     OP_REQUIRES(\n         ctx, tensor_value->dtype() == tensor_array->ElemType(),\n         errors::InvalidArgument(\"TensorArray dtype is \",\n@@ -571,7 +571,7 @@ class TensorArrayReadOp : public OpKernel {\n     OP_REQUIRES_OK(ctx, GetTensorArray(ctx, &tensor_array));\n     core::ScopedUnref unref(tensor_array);\n \n-    const int32_t index = tensor_index->scalar<int32>()();\n+    const int32_t index = tensor_index->scalar<int32_t>()();\n     OP_REQUIRES(\n         ctx, dtype_ == tensor_array->ElemType(),\n         errors::InvalidArgument(\n@@ -669,7 +669,7 @@ class TensorArrayPackOrGatherOp : public OpKernel {\n \n     int32_t num_indices;\n     std::vector<Tensor> values;\n-    std::vector<int32> indices;\n+    std::vector<int32_t> indices;\n     if (LEGACY_PACK) {\n       OP_REQUIRES_OK(ctx, tensor_array->PackOrConcatSize(&num_indices));\n       indices.resize(num_indices);\n@@ -681,7 +681,7 @@ class TensorArrayPackOrGatherOp : public OpKernel {\n                   errors::InvalidArgument(\n                       \"Expected indices to be a vector, but received shape: \",\n                       tensor_indices->shape().DebugString()));\n-      const auto indices_t = tensor_indices->vec<int32>();\n+      const auto indices_t = tensor_indices->vec<int32_t>();\n       num_indices = tensor_indices->NumElements();\n       indices.resize(num_indices);\n       std::copy(indices_t.data(), indices_t.data() + num_indices,\n@@ -911,7 +911,7 @@ class TensorArrayConcatOp : public OpKernel {\n \n     // Read all the Tensors into a vector to keep track of their memory.\n     std::vector<Tensor> values;\n-    std::vector<int32> indices(array_size);\n+    std::vector<int32_t> indices(array_size);\n     std::iota(indices.begin(), indices.end(), 0);\n     absl::Status s = tensor_array->ReadMany<Device, T>(ctx, indices, &values);\n     OP_REQUIRES_OK(ctx, s);\n@@ -1110,7 +1110,7 @@ class TensorArrayUnpackOrScatterOp : public OpKernel {\n \n     OP_REQUIRES(ctx,\n                 FastBoundsCheck(element_shape.dim_size(0),\n-                                std::numeric_limits<int32>::max()),\n+                                std::numeric_limits<int32_t>::max()),\n                 errors::InvalidArgument(\"tensor dim0 too large to unpack\"));\n \n     OP_REQUIRES(\n@@ -1128,7 +1128,7 @@ class TensorArrayUnpackOrScatterOp : public OpKernel {\n \n     int32_t max_index;\n     int32_t num_values;\n-    std::vector<int32> write_indices;\n+    std::vector<int32_t> write_indices;\n     if (LEGACY_UNPACK) {\n       num_values = element_shape.dim_size(0);\n       max_index = num_values - 1;\n@@ -1147,7 +1147,7 @@ class TensorArrayUnpackOrScatterOp : public OpKernel {\n                       \"Expected len(indices) == values.shape[0], but saw: \",\n                       tensor_indices->NumElements(), \" vs. \",\n                       element_shape.dim_size(0)));\n-      const auto indices_t = tensor_indices->vec<int32>();\n+      const auto indices_t = tensor_indices->vec<int32_t>();\n       num_values = tensor_indices->NumElements();\n       max_index = (num_values == 0)\n                       ? -1\n@@ -1163,7 +1163,7 @@ class TensorArrayUnpackOrScatterOp : public OpKernel {\n \n     // If dynamic size, we may have to resize the TensorArray to fit.\n     if (dynamic_size && array_size < max_index + 1) {\n-      array_size = static_cast<int32>(max_index + 1);\n+      array_size = static_cast<int32_t>(max_index + 1);\n     }\n \n     if (LEGACY_UNPACK) {\n@@ -1310,11 +1310,11 @@ class TensorArraySplitOp : public OpKernel {\n                     tensor_lengths->shape().DebugString()));\n     OP_REQUIRES(ctx,\n                 FastBoundsCheck(tensor_lengths->NumElements(),\n-                                std::numeric_limits<int32>::max()),\n+                                std::numeric_limits<int32_t>::max()),\n                 errors::InvalidArgument(\n                     \"Expected lengths to have < max int32 entries\"));\n \n-    int32_t num_tensors = static_cast<int32>(tensor_lengths->NumElements());\n+    int32_t num_tensors = static_cast<int32_t>(tensor_lengths->NumElements());\n     auto tensor_lengths_t = tensor_lengths->vec<int64_t>();\n     std::vector<int64_t> cumulative_lengths;\n     cumulative_lengths.reserve(num_tensors);\n@@ -1402,7 +1402,7 @@ class TensorArraySplitOp : public OpKernel {\n     // Record the concat size of the TensorArray.\n     OP_REQUIRES_OK(ctx, tensor_array->SetMarkedSize(array_size));\n \n-    std::vector<int32> indices(array_size);\n+    std::vector<int32_t> indices(array_size);\n     std::iota(indices.begin(), indices.end(), 0);\n \n     absl::Status s = tensor_array->WriteOrAggregateMany<Device, T>(\n@@ -1467,7 +1467,7 @@ class TensorArraySizeOp : public OpKernel {\n     core::ScopedUnref unref(tensor_array);\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({}), &output));\n-    OP_REQUIRES_OK(ctx, tensor_array->Size(&(output->scalar<int32>()())));\n+    OP_REQUIRES_OK(ctx, tensor_array->Size(&(output->scalar<int32_t>()())));\n   }\n };\n "
        },
        {
            "sha": "e529750929c9a211c5cf93db980e174328c7a7cd",
            "filename": "tensorflow/core/kernels/tensor_cord.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -40,7 +40,7 @@ void TensorCord::Encode(VariantTensorData* data) const {\n }\n \n bool TensorCord::Decode(VariantTensorData data) {\n-  auto* str = new string(std::move(data.metadata_string()));\n+  auto* str = new std::string(std::move(data.metadata_string()));\n   Cleanup();\n   chunks_.push_back(new CordRep(absl::string_view(*str), &StringReleaser, str));\n   return true;\n@@ -57,7 +57,7 @@ void TensorCord::TensorBufReleaser(void* tensor_buffer) {\n }\n \n void TensorCord::StringReleaser(void* str_ptr) {\n-  delete static_cast<string*>(str_ptr);\n+  delete static_cast<std::string*>(str_ptr);\n }\n \n namespace {\n@@ -85,14 +85,15 @@ struct ResizeUninitializedTraits<\n };\n \n // Resize string `s` to `new_size`, leaving the data uninitialized.\n-static inline void STLStringResizeUninitialized(string* s, size_t new_size) {\n-  ResizeUninitializedTraits<string>::Resize(s, new_size);\n+static inline void STLStringResizeUninitialized(std::string* s,\n+                                                size_t new_size) {\n+  ResizeUninitializedTraits<std::string>::Resize(s, new_size);\n }\n \n }  // namespace\n \n-TensorCord::operator string() const {\n-  string out;\n+TensorCord::operator std::string() const {\n+  std::string out;\n   STLStringResizeUninitialized(&out, size());\n   char* data = const_cast<char*>(out.data());\n   for (auto* rep : chunks_) {"
        },
        {
            "sha": "75104f0022696c56da47b0bc72d524c88c670b85",
            "filename": "tensorflow/core/kernels/tensor_cord.h",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_cord.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -114,7 +114,7 @@ class TensorCord {\n   bool empty() const { return size() == 0; }\n \n   // NOTE: This performs an expensive copy of the underlying data.\n-  explicit operator string() const;\n+  explicit operator std::string() const;\n \n   class ChunkIterator {\n    public:\n@@ -188,9 +188,9 @@ class TensorCord {\n     return ChunkIterator(this, chunks_.size());\n   }\n \n-  static string TypeName() { return kTypeName; }\n+  static std::string TypeName() { return kTypeName; }\n \n-  string DebugString() const {\n+  std::string DebugString() const {\n     return absl::StrCat(\"<TensorCord size=\", size(), \">\");\n   }\n \n@@ -217,7 +217,7 @@ class TensorCord {\n       if (is_inline_) {\n         return absl::string_view(\n             rep_.internal.data() + 1,\n-            *reinterpret_cast<const uint8*>(rep_.internal.data()));\n+            *reinterpret_cast<const uint8_t*>(rep_.internal.data()));\n       } else {\n         return rep_.external.view;\n       }\n@@ -256,7 +256,7 @@ class TensorCord {\n \n       explicit _rep_union(absl::string_view view) {\n         DCHECK_LT(view.size(), kMaxInlineSize);\n-        *reinterpret_cast<uint8*>(internal.data()) = view.size();\n+        *reinterpret_cast<uint8_t*>(internal.data()) = view.size();\n         std::memcpy(static_cast<char*>(internal.data() + 1), view.data(),\n                     view.size());\n       }"
        },
        {
            "sha": "450f9a1bdd43bfea9c0173ad60c9cf9d88880b18",
            "filename": "tensorflow/core/kernels/tensor_cord_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_cord_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_cord_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -80,7 +80,7 @@ TEST(TensorCordTest, Copy) {\n   auto cleaner = [&cleaned]() { ++cleaned; };\n   auto thunk = CreateThunkFor(cleaner);\n   TensorCord tc_copy;\n-  string a = \"abc\";\n+  std::string a = \"abc\";\n   {\n     TensorCord tc(a, thunk, &cleaner);\n     tc_copy = tc;\n@@ -104,7 +104,7 @@ TEST(TensorCordTest, AppendCord) {\n   TensorCord tc_0(\"abc\", thunk_0, &cleaner_0);\n   TensorCord tc_1(\"cba\", thunk_1, &cleaner_1);\n   tc_0.Append(tc_1);\n-  EXPECT_EQ(string(tc_0), \"abccba\");\n+  EXPECT_EQ(std::string(tc_0), \"abccba\");\n   auto it = tc_0.chunk_begin();\n   EXPECT_EQ(*it, \"abc\");\n   ++it;\n@@ -128,7 +128,7 @@ TEST(TensorCordTest, AppendView) {\n   auto thunk_1 = CreateThunkFor(cleaner_1);\n   TensorCord tc_0(\"abc\", thunk_0, &cleaner_0);\n   tc_0.Append(\"cba\", thunk_1, &cleaner_1);\n-  EXPECT_EQ(string(tc_0), \"abccba\");\n+  EXPECT_EQ(std::string(tc_0), \"abccba\");\n   auto it = tc_0.chunk_begin();\n   EXPECT_EQ(*it, \"abc\");\n   ++it;\n@@ -147,7 +147,7 @@ TEST(TensorCordTest, Move) {\n   auto cleaner = [&cleaned]() { ++cleaned; };\n   auto thunk = CreateThunkFor(cleaner);\n   TensorCord tc_copy;\n-  string a = \"abc\";\n+  std::string a = \"abc\";\n   {\n     TensorCord tc(a, thunk, &cleaner);\n     tc_copy = std::move(tc);\n@@ -167,7 +167,7 @@ TEST(TensorCordTest, CopyConstructor) {\n   int cleaned = 0;\n   auto cleaner = [&cleaned]() { ++cleaned; };\n   auto thunk = CreateThunkFor(cleaner);\n-  string a = \"abc\";\n+  std::string a = \"abc\";\n   TensorCord tc(a, thunk, &cleaner);\n   TensorCord tc_copy(tc);\n   EXPECT_EQ(tc.size(), 3);\n@@ -187,7 +187,7 @@ TEST(TensorCordTest, MoveConstructor) {\n   int cleaned = 0;\n   auto cleaner = [&cleaned]() { ++cleaned; };\n   auto thunk = CreateThunkFor(cleaner);\n-  string a = \"abc\";\n+  std::string a = \"abc\";\n   TensorCord tc(a, thunk, &cleaner);\n   TensorCord tc_copy(std::move(tc));\n   EXPECT_EQ(tc_copy.size(), 3);\n@@ -236,7 +236,7 @@ void TensorCordFromAbslCordBenchmark(benchmark::State& state, int num_elem,\n                                      int string_size) {\n   std::vector<absl::Cord> cords(num_elem);\n   for (int i = 0; i < num_elem; ++i) {\n-    string s(string_size, 'a');\n+    std::string s(string_size, 'a');\n     cords[i] = s;\n   }\n "
        },
        {
            "sha": "122324cbdc314813c14f050d7f97ce2be741ad6e",
            "filename": "tensorflow/core/kernels/tensor_list.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_list.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_list.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_list.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -35,16 +35,16 @@ void TensorList::Encode(VariantTensorData* data) const {\n       invalid_indices.push_back(i);\n     }\n   }\n-  string metadata;\n+  std::string metadata;\n   // TODO(b/118838800): Add a proto for storing the metadata.\n   // Metadata format:\n   // <num_invalid_tensors><invalid_indices><element_dtype><element_shape_proto>\n-  core::PutVarint64(&metadata, static_cast<uint64>(invalid_indices.size()));\n+  core::PutVarint64(&metadata, static_cast<uint64_t>(invalid_indices.size()));\n   for (size_t i : invalid_indices) {\n-    core::PutVarint64(&metadata, static_cast<uint64>(i));\n+    core::PutVarint64(&metadata, static_cast<uint64_t>(i));\n   }\n-  core::PutVarint64(&metadata, static_cast<uint64>(element_dtype));\n-  core::PutVarint64(&metadata, static_cast<uint64>(max_num_elements));\n+  core::PutVarint64(&metadata, static_cast<uint64_t>(element_dtype));\n+  core::PutVarint64(&metadata, static_cast<uint64_t>(max_num_elements));\n   TensorShapeProto element_shape_proto;\n   element_shape.AsProto(&element_shape_proto);\n   element_shape_proto.AppendToString(&metadata);\n@@ -55,9 +55,9 @@ bool TensorList::Decode(const VariantTensorData& data) {\n   // TODO(srbs): Change the signature to Decode(VariantTensorData data) so\n   // that we do not have to copy each tensor individually below. This would\n   // require changing VariantTensorData::tensors() as well.\n-  string metadata;\n+  std::string metadata;\n   data.get_metadata(&metadata);\n-  uint64 scratch;\n+  uint64_t scratch;\n   absl::string_view iter(metadata);\n   std::vector<size_t> invalid_indices;\n   core::GetVarint64(&iter, &scratch);\n@@ -91,7 +91,7 @@ bool TensorList::Decode(const VariantTensorData& data) {\n   core::GetVarint64(&iter, &scratch);\n   max_num_elements = static_cast<int>(scratch);\n   TensorShapeProto element_shape_proto;\n-  element_shape_proto.ParseFromString(string(iter.data(), iter.size()));\n+  element_shape_proto.ParseFromString(iter);\n   element_shape = PartialTensorShape(element_shape_proto);\n   return true;\n }"
        },
        {
            "sha": "bf2363e1ae4d9b878b1a20f7fa6c4a76ae6914d0",
            "filename": "tensorflow/core/kernels/tensor_list.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_list.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_list.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_list.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -105,14 +105,14 @@ class TensorList {\n \n   static const char kTypeName[];\n \n-  string TypeName() const { return kTypeName; }\n+  std::string TypeName() const { return kTypeName; }\n \n   void Encode(VariantTensorData* data) const;\n \n   bool Decode(const VariantTensorData& data);\n \n   // TODO(apassos) fill this out\n-  string DebugString() const { return \"TensorList\"; }\n+  std::string DebugString() const { return \"TensorList\"; }\n \n   PartialTensorShape element_shape;\n "
        },
        {
            "sha": "7f307c859226a1a251ae97e6891d2ab45bcbdcff",
            "filename": "tensorflow/core/kernels/tensor_map.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_map.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_map.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_map.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -93,14 +93,14 @@ class TensorMap {\n \n   static const char kTypeName[];\n \n-  string TypeName() const { return kTypeName; }\n+  std::string TypeName() const { return kTypeName; }\n \n   void Encode(VariantTensorData* data) const;\n \n   bool Decode(const VariantTensorData& data);\n \n   // TODO(apassos) fill this out\n-  string DebugString() const { return \"TensorMap\"; }\n+  std::string DebugString() const { return \"TensorMap\"; }\n \n   // Access to the underlying tensor container.\n   absl::flat_hash_map<TensorKey, Tensor>& tensors() {"
        },
        {
            "sha": "5ea6d5242a719945a106ab65ad524ba579cc5245",
            "filename": "tensorflow/core/kernels/tensor_map_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_map_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_map_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_map_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -54,7 +54,7 @@ TEST(TensorMapTest, Insert) {\n   absl::flat_hash_map<TensorKey, Tensor>::iterator map_it =\n       tm.tensors().begin();\n   EXPECT_EQ(map_it->first, k);\n-  test::ExpectTensorEqual<int32>(map_it->second, v);\n+  test::ExpectTensorEqual<int32_t>(map_it->second, v);\n   map_it++;\n   EXPECT_EQ(map_it, tm.tensors().end());\n }\n@@ -68,7 +68,7 @@ TEST(TensorMapTest, Lookup) {\n   Tensor f = map_it->second;\n \n   EXPECT_EQ(map_it->first, k);\n-  test::ExpectTensorEqual<int32>(f, v);\n+  test::ExpectTensorEqual<int32_t>(f, v);\n }\n \n TEST(TensorMapTest, Erase) {\n@@ -91,7 +91,7 @@ TEST(TensorMapTest, SameKeyInsert) {\n   EXPECT_EQ(b2, false);\n   absl::flat_hash_map<TensorKey, Tensor>::iterator map_it = tm.find(k);\n   EXPECT_EQ(map_it->first, k);\n-  test::ExpectTensorEqual<int32>(map_it->second, v1);\n+  test::ExpectTensorEqual<int32_t>(map_it->second, v1);\n }\n \n TEST(TensorMapTest, Replace) {\n@@ -102,7 +102,7 @@ TEST(TensorMapTest, Replace) {\n   tm[k] = v2;\n   absl::flat_hash_map<TensorKey, Tensor>::iterator map_it = tm.find(k);\n   EXPECT_EQ(map_it->first, k);\n-  test::ExpectTensorEqual<int32>(map_it->second, v2);\n+  test::ExpectTensorEqual<int32_t>(map_it->second, v2);\n }\n \n TEST(TensorMapTest, ListKeys) {\n@@ -153,7 +153,7 @@ TEST(TensorMapTest, Copy) {\n   EXPECT_NE(tm.find(k), tm.tensors().end());\n   EXPECT_NE(tmc.find(k), tmc.tensors().end());\n   EXPECT_EQ(tm.find(k)->first, tmc.find(k)->first);\n-  test::ExpectTensorEqual<int32>(tm.find(k)->second, tmc.find(k)->second);\n+  test::ExpectTensorEqual<int32_t>(tm.find(k)->second, tmc.find(k)->second);\n }\n \n TEST(TensorMapTest, EncodeDecode) {\n@@ -169,7 +169,7 @@ TEST(TensorMapTest, EncodeDecode) {\n   EXPECT_NE(tm.find(k), tm.tensors().end());\n   EXPECT_NE(tmc.find(k), tmc.tensors().end());\n   EXPECT_EQ(tm.find(k)->first, tmc.find(k)->first);\n-  test::ExpectTensorEqual<int32>(tm.find(k)->second, tmc.find(k)->second);\n+  test::ExpectTensorEqual<int32_t>(tm.find(k)->second, tmc.find(k)->second);\n }\n \n }  // namespace"
        },
        {
            "sha": "d7e339a32dda531f5a86d4776e82eee243f521f0",
            "filename": "tensorflow/core/kernels/tensor_to_hash_bucket_op.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_to_hash_bucket_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftensor_to_hash_bucket_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftensor_to_hash_bucket_op.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -36,7 +36,7 @@ template <typename Device, typename T>\n struct LaunchTensorToHashBucket {\n   void operator()(OpKernelContext* c, const int64_t num_buckets, const T* input,\n                   const int num_elems, int64_t* output) {\n-    string format = \"%\";\n+    std::string format = \"%\";\n     switch (DataTypeToEnum<T>::value) {\n       case DT_INT8:\n       case DT_INT16:\n@@ -55,9 +55,9 @@ struct LaunchTensorToHashBucket {\n     }\n \n     for (int i = 0; i < num_elems; ++i) {\n-      string input_str = strings::Printf(format.c_str(), input[i]);\n-      const uint64 input_hash = Fingerprint64(input_str);\n-      const uint64 bucket_id = input_hash % num_buckets;\n+      std::string input_str = strings::Printf(format.c_str(), input[i]);\n+      const uint64_t input_hash = Fingerprint64(input_str);\n+      const uint64_t bucket_id = input_hash % num_buckets;\n       // The number of buckets is always in the positive range of int64 so is\n       // the resulting bucket_id. Casting the bucket_id from uint64 to int64 is\n       // safe."
        },
        {
            "sha": "cb190d3ac871c783c7ad4fadc5390aee356a57e2",
            "filename": "tensorflow/core/kernels/text_line_reader_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftext_line_reader_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftext_line_reader_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftext_line_reader_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -29,7 +29,7 @@ namespace tensorflow {\n \n class TextLineReader : public ReaderBase {\n  public:\n-  TextLineReader(const string& node_name, int skip_header_lines, Env* env)\n+  TextLineReader(const std::string& node_name, int skip_header_lines, Env* env)\n       : ReaderBase(absl::StrCat(\"TextLineReader '\", node_name, \"'\")),\n         skip_header_lines_(skip_header_lines),\n         env_(env),\n@@ -41,7 +41,7 @@ class TextLineReader : public ReaderBase {\n \n     input_buffer_.reset(new io::InputBuffer(file_.get(), kBufferSize));\n     for (; line_number_ < skip_header_lines_; ++line_number_) {\n-      string line_contents;\n+      std::string line_contents;\n       absl::Status status = input_buffer_->ReadLine(&line_contents);\n       if (absl::IsOutOfRange(status)) {\n         // We ignore an end of file error when skipping header lines."
        },
        {
            "sha": "8abc2eeaf2b7fa246601bc368aa7e365cc328cca",
            "filename": "tensorflow/core/kernels/tf_record_reader_op.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftf_record_reader_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftf_record_reader_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftf_record_reader_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -29,8 +29,8 @@ namespace tensorflow {\n \n class TFRecordReader : public ReaderBase {\n  public:\n-  TFRecordReader(const string& node_name, const string& compression_type,\n-                 Env* env)\n+  TFRecordReader(const std::string& node_name,\n+                 const std::string& compression_type, Env* env)\n       : ReaderBase(absl::StrCat(\"TFRecordReader '\", node_name, \"'\")),\n         env_(env),\n         offset_(0),\n@@ -76,10 +76,10 @@ class TFRecordReader : public ReaderBase {\n \n  private:\n   Env* const env_;\n-  uint64 offset_;\n+  uint64_t offset_;\n   std::unique_ptr<RandomAccessFile> file_;\n   std::unique_ptr<io::RecordReader> reader_;\n-  string compression_type_ = \"\";\n+  std::string compression_type_ = \"\";\n };\n \n class TFRecordReaderOp : public ReaderOpKernel {\n@@ -88,7 +88,7 @@ class TFRecordReaderOp : public ReaderOpKernel {\n       : ReaderOpKernel(context) {\n     Env* env = context->env();\n \n-    string compression_type;\n+    std::string compression_type;\n     OP_REQUIRES_OK(context,\n                    context->GetAttr(\"compression_type\", &compression_type));\n "
        },
        {
            "sha": "b02cf949a5d5e9f9f56e0ec0efce99b822a301b8",
            "filename": "tensorflow/core/kernels/tile_ops.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftile_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftile_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftile_ops.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -585,23 +585,23 @@ TF_CALL_complex128(HANDLE_TYPE_NAME_GPU);\n REGISTER_KERNEL_BUILDER(Name(\"Tile\")\n                             .Device(DEVICE_CPU)\n                             .HostMemory(\"multiples\")\n-                            .TypeConstraint<int32>(\"Tmultiples\"),\n-                        TileOp<CPUDevice, int32>);\n+                            .TypeConstraint<int32_t>(\"Tmultiples\"),\n+                        TileOp<CPUDevice, int32_t>);\n REGISTER_KERNEL_BUILDER(Name(\"Tile\")\n                             .Device(DEVICE_CPU)\n                             .HostMemory(\"multiples\")\n                             .TypeConstraint<int64_t>(\"Tmultiples\"),\n-                        TileOp<CPUDevice, int64>);\n+                        TileOp<CPUDevice, int64_t>);\n REGISTER_KERNEL_BUILDER(Name(\"TileGrad\")\n                             .Device(DEVICE_CPU)\n                             .HostMemory(\"multiples\")\n-                            .TypeConstraint<int32>(\"Tmultiples\"),\n-                        TileGradientOp<CPUDevice, int32>);\n+                            .TypeConstraint<int32_t>(\"Tmultiples\"),\n+                        TileGradientOp<CPUDevice, int32_t>);\n REGISTER_KERNEL_BUILDER(Name(\"TileGrad\")\n                             .Device(DEVICE_CPU)\n                             .HostMemory(\"multiples\")\n                             .TypeConstraint<int64_t>(\"Tmultiples\"),\n-                        TileGradientOp<CPUDevice, int64>);\n+                        TileGradientOp<CPUDevice, int64_t>);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n #define REGISTER_GPU_TILE(type)                                      \\"
        },
        {
            "sha": "1f4137b20f5d9509e4ec86a6b126d08e8bb444b9",
            "filename": "tensorflow/core/kernels/topk_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftopk_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftopk_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftopk_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -244,9 +244,10 @@ struct TopKFunctor<CPUDevice, T, Tidx> {\n     const double sort_cost = (k == num_cols) ? base_cost : 4 * base_cost;\n     const double copy_cost = 2 * k * Eigen::TensorOpCost::AddCost<T>();\n     const double total_cost = sort_cost + copy_cost;\n-    const int64_t final_cost = (total_cost >= static_cast<double>(kint64max))\n-                                   ? kint64max\n-                                   : static_cast<int64_t>(total_cost);\n+    const int64_t final_cost =\n+        (total_cost >= static_cast<double>(std::numeric_limits<int64_t>::max()))\n+            ? std::numeric_limits<int64_t>::max()\n+            : static_cast<int64_t>(total_cost);\n     auto worker_threads = *(context->device()->tensorflow_cpu_worker_threads());\n     Shard(worker_threads.num_threads, worker_threads.workers, num_rows,\n           final_cost, SortIndices);"
        },
        {
            "sha": "8e136527653774d850d2f96509be2829a24e4709",
            "filename": "tensorflow/core/kernels/training_ops.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 11,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftraining_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftraining_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftraining_ops.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -1566,9 +1566,9 @@ class SparseApplyProximalGradientDescentOp : public OpKernel {\n                               .TypeConstraint<Tindices>(\"Tindices\"),          \\\n                           SparseApplyProximalGradientDescentOp<T, Tindices>);\n \n-REGISTER_KERNELS(float, int32);\n+REGISTER_KERNELS(float, int32_t);\n REGISTER_KERNELS(float, int64_t);\n-REGISTER_KERNELS(double, int32);\n+REGISTER_KERNELS(double, int32_t);\n REGISTER_KERNELS(double, int64_t);\n #undef REGISTER_KERNELS\n \n@@ -2252,9 +2252,9 @@ class SparseApplyProximalAdagradOp : public OpKernel {\n           .TypeConstraint<Tindices>(\"Tindices\"),             \\\n       SparseApplyProximalAdagradOp<D##Device, T, Tindices>);\n \n-REGISTER_KERNELS(CPU, float, int32);\n+REGISTER_KERNELS(CPU, float, int32_t);\n REGISTER_KERNELS(CPU, float, int64_t);\n-REGISTER_KERNELS(CPU, double, int32);\n+REGISTER_KERNELS(CPU, double, int32_t);\n REGISTER_KERNELS(CPU, double, int64_t);\n \n #if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n@@ -2582,9 +2582,9 @@ class SparseApplyAdagradDAOp : public OpKernel {\n                               .TypeConstraint<Tindices>(\"Tindices\"),      \\\n                           SparseApplyAdagradDAOp<T, Tindices>);\n \n-REGISTER_KERNELS(float, int32);\n+REGISTER_KERNELS(float, int32_t);\n REGISTER_KERNELS(float, int64_t);\n-REGISTER_KERNELS(double, int32);\n+REGISTER_KERNELS(double, int32_t);\n REGISTER_KERNELS(double, int64_t);\n #undef REGISTER_KERNELS\n \n@@ -4465,15 +4465,15 @@ class SparseApplyCenteredRMSPropOp : public OpKernel {\n                               .TypeConstraint<Tindices>(\"Tindices\"),  \\\n                           SparseApplyCenteredRMSPropOp<T, Tindices>);\n \n-REGISTER_KERNELS(Eigen::half, int32);\n+REGISTER_KERNELS(Eigen::half, int32_t);\n REGISTER_KERNELS(Eigen::half, int64_t);\n-REGISTER_KERNELS(float, int32);\n+REGISTER_KERNELS(float, int32_t);\n REGISTER_KERNELS(float, int64_t);\n-REGISTER_KERNELS(double, int32);\n+REGISTER_KERNELS(double, int32_t);\n REGISTER_KERNELS(double, int64_t);\n-REGISTER_KERNELS(complex64, int32);\n+REGISTER_KERNELS(complex64, int32_t);\n REGISTER_KERNELS(complex64, int64_t);\n-REGISTER_KERNELS(complex128, int32);\n+REGISTER_KERNELS(complex128, int32_t);\n REGISTER_KERNELS(complex128, int64_t);\n \n #undef REGISTER_KERNELS"
        },
        {
            "sha": "496d0b181bf8d88c426d47a04a04597a769c8c66",
            "filename": "tensorflow/core/kernels/training_ops_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftraining_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftraining_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftraining_ops_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -75,7 +75,7 @@ static Node* Random(Graph* g, int m, int n) {\n \n static Node* Iota(Graph* g, int n) {\n   Tensor data(DT_INT32, TensorShape({n}));\n-  int32* base = data.flat<int32>().data();\n+  int32_t* base = data.flat<int32_t>().data();\n   for (int i = 0; i < n; ++i) base[i] = i;\n   return test::graph::Constant(g, data);\n }"
        },
        {
            "sha": "683be3ff01a8ce2af622b1352da699a3777a582b",
            "filename": "tensorflow/core/kernels/transpose_functor.h",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -34,7 +34,7 @@ namespace tensorflow {\n // REQUIRES: in.dim_size(perm[i]) == out->dim_size(i)\n template <typename Device>\n absl::Status DoTranspose(const Device& device, const Tensor& in,\n-                         const absl::Span<const int32> perm, Tensor* out);\n+                         const absl::Span<const int32_t> perm, Tensor* out);\n \n // Conjugate and transpose tensor 'in' into tensor 'out' according to dimension\n // permutation 'perm'.\n@@ -45,7 +45,7 @@ absl::Status DoTranspose(const Device& device, const Tensor& in,\n // REQUIRES: in.dim_size(perm[i]) == out->dim_size(i)\n template <typename Device>\n absl::Status DoConjugateTranspose(const Device& device, const Tensor& in,\n-                                  const absl::Span<const int32> perm,\n+                                  const absl::Span<const int32_t> perm,\n                                   Tensor* out);\n \n // Convenience versions of DoTranspose that only swap the last (inner) two\n@@ -64,22 +64,22 @@ absl::Status DoConjugateMatrixTranspose(const Device& device, const Tensor& in,\n template <typename Device, typename T, bool conjugate = false>\n struct Transpose {\n   static void run(const Device& d, const Tensor& in,\n-                  const absl::Span<const int32> perm, Tensor* out);\n+                  const absl::Span<const int32_t> perm, Tensor* out);\n };\n \n // Implementation details.\n namespace internal {\n \n typedef absl::InlinedVector<int64_t, 8UL> TransposeDimsVec;\n-typedef absl::InlinedVector<int32, 8UL> TransposePermsVec;\n+typedef absl::InlinedVector<int32_t, 8UL> TransposePermsVec;\n \n // Helper function that takes a tensor shape, a permutation, combines the\n // neighboring shapes if their indices in the permutation are consecutive.\n // The function outputs the combined shape and new permutation.\n // Example: Tensor shape {2, 3, 4, 5, 120} and permutation {0, 4, 1, 2, 3} will\n // produce new shape {2, 60, 120} and new permutation {0, 2, 1}.\n inline void ReduceTransposeDimensions(const TensorShape& shape,\n-                                      absl::Span<const int32> perm,\n+                                      absl::Span<const int32_t> perm,\n                                       TransposePermsVec* new_perm,\n                                       TransposeDimsVec* new_dims) {\n   CHECK_EQ(shape.dims(), perm.size());\n@@ -130,8 +130,8 @@ inline void ReduceTransposeDimensions(const TensorShape& shape,\n // That is, for all i, 0 <= perm[i] < input_shape.dims().\n // In practice, this is checked in TransposeOp::Compute prior to calling this\n // function, and the function sits here to facilitate unit testing.\n-inline bool NonSingletonDimensionsAlign(const TensorShape& input_shape,\n-                                        const std::vector<int32>& permutation) {\n+inline bool NonSingletonDimensionsAlign(\n+    const TensorShape& input_shape, const std::vector<int32_t>& permutation) {\n   int last_nonsingleton_perm_dim = -1;\n   for (int perm_dim : permutation) {\n     if (input_shape.dim_size(perm_dim) == 1) {\n@@ -148,7 +148,7 @@ inline bool NonSingletonDimensionsAlign(const TensorShape& input_shape,\n // Uses Eigen to transpose.\n template <typename Device, typename T, int NDIMS>\n void TransposeUsingEigen(const Device& d, const Tensor& in,\n-                         const absl::Span<const int32> perm, bool conjugate,\n+                         const absl::Span<const int32_t> perm, bool conjugate,\n                          Tensor* out) {\n   Eigen::array<int, NDIMS> p;\n   for (int i = 0; i < NDIMS; ++i) p[i] = perm[i];\n@@ -167,8 +167,8 @@ void TransposeUsingEigen(const Device& d, const Tensor& in,\n \n template <typename Device>\n absl::Status DoTransposeImpl(const Device& d, const Tensor& in,\n-                             const absl::Span<const int32> perm, bool conjugate,\n-                             Tensor* out) {\n+                             const absl::Span<const int32_t> perm,\n+                             bool conjugate, Tensor* out) {\n   // log a msg\n   CHECK_EQ(in.dims(), out->dims());\n   CHECK_EQ(in.dims(), perm.size());\n@@ -181,7 +181,7 @@ absl::Status DoTransposeImpl(const Device& d, const Tensor& in,\n     case DT_UINT8:\n     case DT_FLOAT8_E5M2:\n     case DT_FLOAT8_E4M3FN:\n-      Transpose<Device, uint8>::run(d, in, perm, out);\n+      Transpose<Device, uint8_t>::run(d, in, perm, out);\n       break;\n \n     case DT_BFLOAT16:\n@@ -190,20 +190,20 @@ absl::Status DoTransposeImpl(const Device& d, const Tensor& in,\n     case DT_QINT16:\n     case DT_QUINT16:\n     case DT_UINT16:\n-      Transpose<Device, uint16>::run(d, in, perm, out);\n+      Transpose<Device, uint16_t>::run(d, in, perm, out);\n       break;\n \n     case DT_FLOAT:\n     case DT_INT32:\n     case DT_QINT32:\n     case DT_UINT32:\n-      Transpose<Device, uint32>::run(d, in, perm, out);\n+      Transpose<Device, uint32_t>::run(d, in, perm, out);\n       break;\n \n     case DT_DOUBLE:\n     case DT_INT64:\n     case DT_UINT64:\n-      Transpose<Device, uint64>::run(d, in, perm, out);\n+      Transpose<Device, uint64_t>::run(d, in, perm, out);\n       break;\n \n     case DT_COMPLEX64:\n@@ -217,7 +217,7 @@ absl::Status DoTransposeImpl(const Device& d, const Tensor& in,\n         Transpose<Device, complex64, /*conjugate=*/true>::run(d, in, perm, out);\n #endif\n       } else {\n-        Transpose<Device, uint64>::run(d, in, perm, out);\n+        Transpose<Device, uint64_t>::run(d, in, perm, out);\n       }\n       break;\n "
        },
        {
            "sha": "7ce93d69c64c43626485043fb8b26ba57350ba99",
            "filename": "tensorflow/core/kernels/transpose_functor_cpu.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_cpu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_cpu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_functor_cpu.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -33,7 +33,7 @@ namespace {\n \n template <typename T, bool conjugate>\n void TransposeSimple(const CPUDevice& device, const Tensor& in,\n-                     const absl::Span<const int32> perm, Tensor* out) {\n+                     const absl::Span<const int32_t> perm, Tensor* out) {\n   const int ndims = in.dims();\n   absl::InlinedVector<int64_t, 8UL> in_strides =\n       ComputeStride<int64_t>(in.shape());\n@@ -73,7 +73,7 @@ void TransposeSimple(const CPUDevice& device, const Tensor& in,\n template <typename T, bool conjugate>\n struct Transpose<CPUDevice, T, conjugate> {\n   static void run(const CPUDevice& d, const Tensor& in,\n-                  const absl::Span<const int32> perm, Tensor* out) {\n+                  const absl::Span<const int32_t> perm, Tensor* out) {\n     switch (in.dims()) {\n       case 2:\n         internal::TransposeUsingEigen<CPUDevice, T, 2>(d, in, perm, conjugate,"
        },
        {
            "sha": "f3cebb3204378742060fc8cc2b0bcda3cf00b338",
            "filename": "tensorflow/core/kernels/transpose_op.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 17,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -50,10 +50,11 @@ class InvertPermutationOp : public OpKernel {\n         context, TensorShapeUtils::IsVector(input.shape()),\n         errors::InvalidArgument(\"invert_permutation expects a 1D vector.\"));\n     auto Tin = input.vec<T>();\n-    OP_REQUIRES(context,\n-                FastBoundsCheck(Tin.size(), std::numeric_limits<int32>::max()),\n-                errors::InvalidArgument(\"permutation of nonnegative int32s \"\n-                                        \"must have <= int32 max elements\"));\n+    OP_REQUIRES(\n+        context,\n+        FastBoundsCheck(Tin.size(), std::numeric_limits<int32_t>::max()),\n+        errors::InvalidArgument(\"permutation of nonnegative int32s \"\n+                                \"must have <= int32 max elements\"));\n     const T N = static_cast<T>(Tin.size());  // Safe: bounds-checked above.\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n@@ -72,18 +73,18 @@ class InvertPermutationOp : public OpKernel {\n };\n \n REGISTER_KERNEL_BUILDER(\n-    Name(\"InvertPermutation\").Device(DEVICE_CPU).TypeConstraint<int32>(\"T\"),\n-    InvertPermutationOp<int32>);\n+    Name(\"InvertPermutation\").Device(DEVICE_CPU).TypeConstraint<int32_t>(\"T\"),\n+    InvertPermutationOp<int32_t>);\n REGISTER_KERNEL_BUILDER(\n     Name(\"InvertPermutation\").Device(DEVICE_CPU).TypeConstraint<int64_t>(\"T\"),\n     InvertPermutationOp<int64_t>);\n \n REGISTER_KERNEL_BUILDER(Name(\"InvertPermutation\")\n                             .Device(DEVICE_DEFAULT)\n-                            .TypeConstraint<int32>(\"T\")\n+                            .TypeConstraint<int32_t>(\"T\")\n                             .HostMemory(\"x\")\n                             .HostMemory(\"y\"),\n-                        InvertPermutationOp<int32>);\n+                        InvertPermutationOp<int32_t>);\n REGISTER_KERNEL_BUILDER(Name(\"InvertPermutation\")\n                             .Device(DEVICE_DEFAULT)\n                             .TypeConstraint<int64_t>(\"T\")\n@@ -94,7 +95,7 @@ REGISTER_KERNEL_BUILDER(Name(\"InvertPermutation\")\n namespace {\n template <typename Tperm>\n absl::Status PermutationHelper(const Tensor& perm, const int dims,\n-                               std::vector<int32>* permutation) {\n+                               std::vector<int32_t>* permutation) {\n   auto Vperm = perm.vec<Tperm>();\n   if (dims != Vperm.size()) {\n     return errors::InvalidArgument(\"transpose expects a vector of size \", dims,\n@@ -105,7 +106,7 @@ absl::Status PermutationHelper(const Tensor& perm, const int dims,\n   // asynchrony boundary is permutation.\n   const volatile Tperm* perm_begin =\n       reinterpret_cast<const volatile Tperm*>(Vperm.data());\n-  *permutation = std::vector<int32>(perm_begin, perm_begin + dims);\n+  *permutation = std::vector<int32_t>(perm_begin, perm_begin + dims);\n \n   return absl::OkStatus();\n }\n@@ -136,10 +137,10 @@ void TransposeOp::Compute(OpKernelContext* ctx) {\n \n   // Although Tperm may be an int64 type, an int32 is sufficient to hold\n   // dimension range values, so the narrowing here should be safe.\n-  std::vector<int32> permutation;\n+  std::vector<int32_t> permutation;\n   const int dims = input.dims();\n   if (perm.dtype() == DT_INT32) {\n-    OP_REQUIRES_OK(ctx, PermutationHelper<int32>(perm, dims, &permutation));\n+    OP_REQUIRES_OK(ctx, PermutationHelper<int32_t>(perm, dims, &permutation));\n   } else {\n     OP_REQUIRES_OK(ctx, PermutationHelper<int64_t>(perm, dims, &permutation));\n   }\n@@ -191,17 +192,16 @@ void TransposeOp::Compute(OpKernelContext* ctx) {\n }\n \n absl::Status TransposeCpuOp::DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                                         absl::Span<const int32> perm,\n+                                         absl::Span<const int32_t> perm,\n                                          Tensor* out) {\n   typedef Eigen::ThreadPoolDevice CPUDevice;\n   return ::tensorflow::DoTranspose(ctx->eigen_device<CPUDevice>(), in, perm,\n                                    out);\n }\n \n-absl::Status ConjugateTransposeCpuOp::DoTranspose(OpKernelContext* ctx,\n-                                                  const Tensor& in,\n-                                                  absl::Span<const int32> perm,\n-                                                  Tensor* out) {\n+absl::Status ConjugateTransposeCpuOp::DoTranspose(\n+    OpKernelContext* ctx, const Tensor& in, absl::Span<const int32_t> perm,\n+    Tensor* out) {\n   typedef Eigen::ThreadPoolDevice CPUDevice;\n   return ::tensorflow::DoConjugateTranspose(ctx->eigen_device<CPUDevice>(), in,\n                                             perm, out);"
        },
        {
            "sha": "2e22a06107f61043014d130bbccc2801e99108f7",
            "filename": "tensorflow/core/kernels/transpose_op.h",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_op.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -29,7 +29,7 @@ class TransposeOp : public OpKernel {\n \n  protected:\n   virtual absl::Status DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                                   absl::Span<const int32> perm,\n+                                   absl::Span<const int32_t> perm,\n                                    Tensor* out) = 0;\n   virtual bool IsConjugate() const { return false; }\n };\n@@ -40,7 +40,8 @@ class TransposeCpuOp : public TransposeOp {\n \n  protected:\n   absl::Status DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                           absl::Span<const int32> perm, Tensor* out) override;\n+                           absl::Span<const int32_t> perm,\n+                           Tensor* out) override;\n };\n \n #if defined(INTEL_MKL)\n@@ -60,7 +61,8 @@ class TransposeGpuOp : public TransposeOp {\n \n  protected:\n   absl::Status DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                           absl::Span<const int32> perm, Tensor* out) override;\n+                           absl::Span<const int32_t> perm,\n+                           Tensor* out) override;\n };\n \n \n@@ -72,7 +74,8 @@ class ConjugateTransposeCpuOp : public TransposeOp {\n \n  protected:\n   absl::Status DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                           absl::Span<const int32> perm, Tensor* out) override;\n+                           absl::Span<const int32_t> perm,\n+                           Tensor* out) override;\n   bool IsConjugate() const override { return true; }\n };\n \n@@ -96,7 +99,8 @@ class ConjugateTransposeGpuOp : public TransposeOp {\n \n  protected:\n   absl::Status DoTranspose(OpKernelContext* ctx, const Tensor& in,\n-                           absl::Span<const int32> perm, Tensor* out) override;\n+                           absl::Span<const int32_t> perm,\n+                           Tensor* out) override;\n   bool IsConjugate() const override { return true; }\n };\n "
        },
        {
            "sha": "85a4e6e51fdc2f44e520d95975b874611a7d3b3e",
            "filename": "tensorflow/core/kernels/transpose_util_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftranspose_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftranspose_util_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -23,14 +23,14 @@ namespace tensorflow {\n class TransposeUtilTest : public ::testing::Test {\n  protected:\n   void TestDimensionReduction(const TensorShape& shape,\n-                              const absl::Span<const int32> perm,\n-                              const absl::Span<const int32> expected_perm,\n+                              const absl::Span<const int32_t> perm,\n+                              const absl::Span<const int32_t> expected_perm,\n                               const absl::Span<const int64_t> expected_dims) {\n     internal::TransposePermsVec new_perm;\n     internal::TransposeDimsVec new_dims;\n     internal::ReduceTransposeDimensions(shape, perm, &new_perm, &new_dims);\n \n-    absl::Span<const int32> computed_perm(new_perm);\n+    absl::Span<const int32_t> computed_perm(new_perm);\n     absl::Span<const int64_t> computed_dims(new_dims);\n     EXPECT_EQ(computed_perm, expected_perm);\n     EXPECT_EQ(computed_dims, expected_dims);"
        },
        {
            "sha": "1fb049a25c393ca103381584190d255bf1ff2c16",
            "filename": "tensorflow/core/kernels/typed_conditional_accumulator_base.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftyped_conditional_accumulator_base.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftyped_conditional_accumulator_base.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftyped_conditional_accumulator_base.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -35,8 +35,8 @@ class TypedConditionalAccumulatorBase : public ConditionalAccumulatorBase {\n  public:\n   TypedConditionalAccumulatorBase(const DataType& dtype,\n                                   const PartialTensorShape& shape,\n-                                  const string& name,\n-                                  const string& reduction_type)\n+                                  const std::string& name,\n+                                  const std::string& reduction_type)\n       : ConditionalAccumulatorBase(dtype, shape, name, reduction_type) {}\n \n   /**"
        },
        {
            "sha": "fe8a408c4088c14c0008e8ce2408e22654520827",
            "filename": "tensorflow/core/kernels/typed_queue.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftyped_queue.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Ftyped_queue.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Ftyped_queue.h?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -34,7 +34,7 @@ class TypedQueue : public QueueBase {\n  public:\n   TypedQueue(const int32_t capacity, const DataTypeVector& component_dtypes,\n              const std::vector<TensorShape>& component_shapes,\n-             const string& name);\n+             const std::string& name);\n \n   virtual absl::Status Initialize();  // Must be called before any other method.\n \n@@ -47,7 +47,7 @@ class TypedQueue : public QueueBase {\n template <typename SubQueue>\n TypedQueue<SubQueue>::TypedQueue(\n     int32_t capacity, const DataTypeVector& component_dtypes,\n-    const std::vector<TensorShape>& component_shapes, const string& name)\n+    const std::vector<TensorShape>& component_shapes, const std::string& name)\n     : QueueBase(capacity, component_dtypes, component_shapes, name) {}\n \n template <typename SubQueue>"
        },
        {
            "sha": "bce5ac67714c2420b78cf64c291773b9f67d63d1",
            "filename": "tensorflow/core/kernels/unary_ops_composition.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -43,22 +43,23 @@ struct UnaryOpsCompositionBase {\n     int cost;\n   };\n \n-  bool HasComputeFn(const string& name) {\n+  bool HasComputeFn(const std::string& name) {\n     return compute_fns.find(name) != compute_fns.end();\n   }\n \n  protected:\n-  void RegisterComputeFn(const string& name, ComputeFn compute_fn, int cost) {\n+  void RegisterComputeFn(const std::string& name, ComputeFn compute_fn,\n+                         int cost) {\n     VLOG(5) << \"Register compute fn: name=\" << name << \" cost=\" << cost;\n     compute_fns[name] = {compute_fn, cost};\n   }\n \n  private:\n   friend class UnaryOpsComposition<T>;\n \n-  absl::Status ExportComputeFns(const std::vector<string>& op_names,\n+  absl::Status ExportComputeFns(const std::vector<std::string>& op_names,\n                                 std::vector<ComputeFn>* fns, int* cost) {\n-    for (const string& op_name : op_names) {\n+    for (const std::string& op_name : op_names) {\n       auto it = compute_fns.find(op_name);\n       if (it == compute_fns.end())\n         return errors::InvalidArgument(\n@@ -72,7 +73,7 @@ struct UnaryOpsCompositionBase {\n     return absl::OkStatus();\n   }\n \n-  std::unordered_map<string, ComputeFnRegistration> compute_fns;\n+  std::unordered_map<std::string, ComputeFnRegistration> compute_fns;\n };\n \n template <typename T>\n@@ -151,7 +152,7 @@ class UnaryOpsComposition : public OpKernel {\n \n   Support support_;\n \n-  std::vector<string> op_names_;\n+  std::vector<std::string> op_names_;\n   std::vector<ComputeFn> fns_;\n   int cost_ = 0;\n };"
        },
        {
            "sha": "773f96261730817d167a949c89c0156a75c08a1e",
            "filename": "tensorflow/core/kernels/unary_ops_composition_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Funary_ops_composition_test.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -33,7 +33,8 @@ namespace {\n class UnaryOpsCompositionTest : public OpsTestBase {\n  protected:\n   template <typename T>\n-  void RunComposedOp(const std::vector<string> op_names, T input, T expected) {\n+  void RunComposedOp(const std::vector<std::string> op_names, T input,\n+                     T expected) {\n     TF_ASSERT_OK(NodeDefBuilder(\"unary_op_composition\", \"_UnaryOpsComposition\")\n                      .Input(FakeInput(DataTypeToEnum<T>::v()))\n                      .Attr(\"T\", DataTypeToEnum<T>::v())\n@@ -82,8 +83,9 @@ TEST_F(UnaryOpsCompositionTest, Compose_Tanh_Relu6_F) {\n \n // Performance benchmarks below.\n \n-string Function(int i) {\n-  std::vector<string> ops = {\"Tanh\", \"Relu\", \"Sigmoid\", \"Sqrt\", \"Log\", \"Exp\"};\n+std::string Function(int i) {\n+  std::vector<std::string> ops = {\"Tanh\", \"Relu\", \"Sigmoid\",\n+                                  \"Sqrt\", \"Log\",  \"Exp\"};\n   return ops[i % ops.size()];\n }\n \n@@ -127,7 +129,7 @@ static Graph* UnaryOpsCompo(int tensor_size, int repeat_graph,\n   Tensor t(DT_FLOAT, TensorShape({tensor_size}));\n   t.flat<float>() = t.flat<float>().setRandom();\n \n-  std::vector<string> functions;\n+  std::vector<std::string> functions;\n   for (int j = 0; j < num_functions; ++j) {\n     functions.push_back(Function(j));\n   }"
        },
        {
            "sha": "417aed9e39a9f8a80085745064c77df1b2e13dae",
            "filename": "tensorflow/core/kernels/unicode_ops.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 19,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Funicode_ops.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -117,7 +117,7 @@ void unicode_error_callback(const void* context, UConverterToUnicodeArgs* args,\n // encoding position.\n // callback: function(UChar32 codepoint, int num_bytes_consumed_from_source_str,\n //                    bool fatal_format_error)\n-void IterateUnicodeString(const string& str, UConverter* converter,\n+void IterateUnicodeString(const std::string& str, UConverter* converter,\n                           std::function<void(UChar32, int, bool)> callback) {\n   const char* source = str.data();\n   const char* limit = str.data() + str.length();\n@@ -165,7 +165,7 @@ class WrappedConverter {\n     }\n   }\n \n-  void init(const string& name) {\n+  void init(const std::string& name) {\n     if (converter_ && name == name_) {\n       // Note: this reset is not typically needed, but if not done, then in some\n       // cases the cached converter will maintain state of input endianness\n@@ -193,7 +193,7 @@ class WrappedConverter {\n   }\n \n   UConverter* converter_ = nullptr;\n-  string name_;\n+  std::string name_;\n };\n \n struct ErrorOptions {\n@@ -206,7 +206,7 @@ struct ErrorOptions {\n absl::Status GetErrorOptions(OpKernelConstruction* ctx, ErrorOptions* out) {\n   *out = ErrorOptions();\n \n-  string error_policy;\n+  std::string error_policy;\n   TF_RETURN_IF_ERROR(ctx->GetAttr(\"errors\", &error_policy));\n \n   if (error_policy == \"replace\") {\n@@ -251,7 +251,7 @@ class UnicodeTranscodeOp : public OpKernel {\n   explicit UnicodeTranscodeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n     OP_REQUIRES_OK(ctx, GetErrorOptions(ctx, &error_options_));\n \n-    string output_encoding;\n+    std::string output_encoding;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"output_encoding\", &output_encoding));\n     OP_REQUIRES_OK(ctx,\n                    ParseUnicodeEncoding(output_encoding, &output_encoding_));\n@@ -338,7 +338,7 @@ class UnicodeTranscodeOp : public OpKernel {\n     Encode(output_encoding_, source, s);\n   }\n \n-  string input_encoding_;\n+  std::string input_encoding_;\n   ErrorOptions error_options_;\n   UnicodeEncoding output_encoding_ = UnicodeEncoding::UTF8;\n };\n@@ -420,7 +420,7 @@ class UnicodeDecodeBaseOp : public OpKernel {\n     int row_split_index = 0;\n     SPLITS_TYPE next_row_split = 0;\n     for (int i = 0; i < input_vec.size(); ++i) {\n-      const string& input = input_vec(i);\n+      const std::string& input = input_vec(i);\n       // Convert input strings into unicode values. Output to a list of\n       // char_values, record row splits and char_to_byte_starts, which are all\n       // the fields needed to construct a RaggedTensor.\n@@ -441,7 +441,7 @@ class UnicodeDecodeBaseOp : public OpKernel {\n         ctx, ctx->allocate_output(\n                  \"char_values\", {static_cast<SPLITS_TYPE>(char_values.size())},\n                  &output_char_values));\n-    auto out_char_values = output_char_values->vec<int32>();\n+    auto out_char_values = output_char_values->vec<int32_t>();\n     if (generate_offsets_) {\n       DCHECK(offset_values.size() == char_values.size());\n       Tensor* output_offset_values;\n@@ -453,18 +453,18 @@ class UnicodeDecodeBaseOp : public OpKernel {\n \n       // Load output tensors from intermediate value arrays.\n       for (int i = 0; i < char_values.size(); ++i) {\n-        out_char_values(i) = static_cast<int32>(char_values[i]);\n+        out_char_values(i) = static_cast<int32_t>(char_values[i]);\n         out_offset_values(i) = offset_values[i];\n       }\n     } else {\n       for (int i = 0; i < char_values.size(); ++i) {\n-        out_char_values(i) = static_cast<int32>(char_values[i]);\n+        out_char_values(i) = static_cast<int32_t>(char_values[i]);\n       }\n     }\n   }\n \n  private:\n-  string input_encoding_;\n+  std::string input_encoding_;\n   ErrorOptions error_options_;\n   bool generate_offsets_ = false;\n };\n@@ -491,18 +491,18 @@ REGISTER_KERNEL_BUILDER(Name(\"UnicodeDecodeWithOffsets\")\n                             .TypeConstraint<int64_t>(\"Tsplits\"),\n                         UnicodeDecodeWithOffsetsOp<int64_t>);\n REGISTER_KERNEL_BUILDER(\n-    Name(\"UnicodeDecode\").Device(DEVICE_CPU).TypeConstraint<int32>(\"Tsplits\"),\n-    UnicodeDecodeOp<int32>);\n+    Name(\"UnicodeDecode\").Device(DEVICE_CPU).TypeConstraint<int32_t>(\"Tsplits\"),\n+    UnicodeDecodeOp<int32_t>);\n REGISTER_KERNEL_BUILDER(Name(\"UnicodeDecodeWithOffsets\")\n                             .Device(DEVICE_CPU)\n-                            .TypeConstraint<int32>(\"Tsplits\"),\n-                        UnicodeDecodeWithOffsetsOp<int32>);\n+                            .TypeConstraint<int32_t>(\"Tsplits\"),\n+                        UnicodeDecodeWithOffsetsOp<int32_t>);\n \n template <typename SPLITS_TYPE>\n class UnicodeEncodeOp : public OpKernel {\n  public:\n   explicit UnicodeEncodeOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n-    string encoding_tmp;\n+    std::string encoding_tmp;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"output_encoding\", &encoding_tmp));\n     OP_REQUIRES_OK(ctx, ParseUnicodeEncoding(encoding_tmp, &encoding_));\n     OP_REQUIRES_OK(ctx, GetErrorOptions(ctx, &error_options_));\n@@ -521,7 +521,7 @@ class UnicodeEncodeOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     // Get inputs\n     const Tensor& input_tensor = context->input(0);\n-    const auto input_tensor_flat = input_tensor.flat<int32>();\n+    const auto input_tensor_flat = input_tensor.flat<int32_t>();\n     const Tensor& input_splits = context->input(1);\n     const auto input_splits_flat = input_splits.flat<SPLITS_TYPE>();\n \n@@ -602,7 +602,7 @@ REGISTER_KERNEL_BUILDER(\n     Name(\"UnicodeEncode\").Device(DEVICE_CPU).TypeConstraint<int64_t>(\"Tsplits\"),\n     UnicodeEncodeOp<int64_t>);\n REGISTER_KERNEL_BUILDER(\n-    Name(\"UnicodeEncode\").Device(DEVICE_CPU).TypeConstraint<int32>(\"Tsplits\"),\n-    UnicodeEncodeOp<int32>);\n+    Name(\"UnicodeEncode\").Device(DEVICE_CPU).TypeConstraint<int32_t>(\"Tsplits\"),\n+    UnicodeEncodeOp<int32_t>);\n \n }  // namespace tensorflow"
        },
        {
            "sha": "7a378cd5054b33ee9a2e8a5e0314ad7a5bb485e3",
            "filename": "tensorflow/core/kernels/unicode_script_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funicode_script_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f1d4574bd4e79987d6ffedebdde9694e42cbbe1/tensorflow%2Fcore%2Fkernels%2Funicode_script_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Funicode_script_op.cc?ref=6f1d4574bd4e79987d6ffedebdde9694e42cbbe1",
            "patch": "@@ -26,13 +26,13 @@ class UnicodeScriptOp : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor* input_tensor;\n     OP_REQUIRES_OK(context, context->input(\"input\", &input_tensor));\n-    const auto& input_flat = input_tensor->flat<int32>();\n+    const auto& input_flat = input_tensor->flat<int32_t>();\n \n     Tensor* output_tensor = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(\"output\", input_tensor->shape(),\n                                             &output_tensor));\n-    auto output_flat = output_tensor->flat<int32>();\n+    auto output_flat = output_tensor->flat<int32_t>();\n \n     icu::ErrorCode status;\n     for (int i = 0; i < input_flat.size(); i++) {"
        }
    ],
    "stats": {
        "total": 496,
        "additions": 254,
        "deletions": 242
    }
}