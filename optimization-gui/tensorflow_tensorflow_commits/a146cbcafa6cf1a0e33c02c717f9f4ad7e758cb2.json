{
    "author": "beckerhe",
    "message": "Add serialization support to CustomKernelThunk\n\nThis is adding `ToProto` and `FromProto` functions to CustomKernelThunk which also required adding serialization support to `CustomKernel`.\n\nPiperOrigin-RevId: 833760226",
    "sha": "a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
    "files": [
        {
            "sha": "b9c78c485d9be0fdf017dd7e9d17950268db0183",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 15,
            "deletions": 4,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -2533,6 +2533,7 @@ tf_proto_library(\n         \"//xla/service/gpu:gpu_conv_runner_proto\",\n         \"//xla/service/gpu:gpu_norm_runner_proto\",\n         \"//xla/service/gpu:launch_dimensions_proto\",\n+        \"//xla/service/gpu/kernels:custom_kernel_proto\",\n         \"//xla/stream_executor:launch_dim_proto\",\n         \"//xla/stream_executor/gpu:gpu_blas_lt_proto\",\n         \"//xla/stream_executor/gpu:tma_metadata_proto\",\n@@ -2569,6 +2570,7 @@ cc_library(\n         \":cub_sort_thunk\",\n         \":cudnn_thunk\",\n         \":custom_call_thunk\",\n+        \":custom_kernel_thunk\",\n         \":dynamic_slice_thunk\",\n         \":fft_thunk\",\n         \":gemm_thunk\",\n@@ -2589,6 +2591,8 @@ cc_library(\n         \":while_thunk\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n+        \"//xla/stream_executor:kernel_spec\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/log:check\",\n@@ -2607,6 +2611,7 @@ xla_cc_test(\n     deps = [\n         \":conditional_thunk\",\n         \":copy_thunk\",\n+        \":custom_kernel_thunk\",\n         \":host_execute_thunk\",\n         \":host_send_recv_thunk\",\n         \":sequential_thunk\",\n@@ -2620,11 +2625,14 @@ xla_cc_test(\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service:hlo_module_config\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util:safe_reinterpret_cast\",\n         \"//xla/tsl/util/proto:parse_text_proto\",\n         \"//xla/tsl/util/proto:proto_matchers\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n@@ -3347,9 +3355,8 @@ cc_library(\n     deps = [\n         \":print_buffer_contents\",\n         \":thunk\",\n-        \":thunk_id\",\n+        \":thunk_proto_cc\",\n         \"//xla/codegen/emitters:kernel_arguments\",\n-        \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:buffer_use\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/service/gpu:launch_dimensions\",\n@@ -3365,12 +3372,12 @@ cc_library(\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/memory\",\n         \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@llvm-project//llvm:Support\",\n     ],\n )\n \n@@ -3387,6 +3394,10 @@ xla_cc_test(\n         \"//xla/service/gpu/kernels:custom_kernel\",\n         \"//xla/stream_executor:launch_dim\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n         \"@com_google_googletest//:gtest_main\",\n     ],\n )"
        },
        {
            "sha": "87250c700c4fc196ed57f214db85a87c9746c8c1",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_kernel_thunk.cc",
            "status": "modified",
            "additions": 51,
            "deletions": 0,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -16,18 +16,21 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n \n #include <memory>\n+#include <optional>\n #include <string>\n #include <utility>\n #include <vector>\n \n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n+#include \"absl/memory/memory.h\"\n #include \"absl/status/status.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/print_buffer_contents.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/runtime/buffer_use.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -121,5 +124,53 @@ Thunk::BufferUses CustomKernelThunk::buffer_uses() const {\n   return buffers;\n }\n \n+CustomKernelThunk::CustomKernelThunk(Thunk::ThunkInfo thunk_info,\n+                                     CustomKernel custom_kernel,\n+                                     std::vector<BufferAllocation::Slice> args,\n+                                     std::vector<bool> written)\n+    : Thunk(Kind::kCustomKernel, std::move(thunk_info)),\n+      args_(std::move(args)),\n+      written_(std::move(written)),\n+      custom_kernel_(std::move(custom_kernel)) {}\n+\n+absl::StatusOr<ThunkProto> CustomKernelThunk::ToProto() const {\n+  ThunkProto thunk_proto;\n+  *thunk_proto.mutable_thunk_info() = thunk_info().ToProto();\n+\n+  CustomKernelThunkProto* custom_kernel_thunk_proto =\n+      thunk_proto.mutable_custom_kernel_thunk();\n+  for (const BufferAllocation::Slice& arg : args_) {\n+    TF_ASSIGN_OR_RETURN(*custom_kernel_thunk_proto->add_args(), arg.ToProto());\n+  }\n+  for (bool written : written_) {\n+    custom_kernel_thunk_proto->add_written(written);\n+  }\n+  TF_ASSIGN_OR_RETURN(*custom_kernel_thunk_proto->mutable_custom_kernel(),\n+                      custom_kernel_.ToProto());\n+  return thunk_proto;\n+}\n+\n+absl::StatusOr<std::unique_ptr<CustomKernelThunk>> CustomKernelThunk::FromProto(\n+    ThunkInfo thunk_info, const CustomKernelThunkProto& proto,\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    const std::optional<se::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver) {\n+  TF_ASSIGN_OR_RETURN(\n+      CustomKernel custom_kernel,\n+      CustomKernel::FromProto(proto.custom_kernel(), symbol_resolver));\n+  std::vector<BufferAllocation::Slice> args;\n+  args.reserve(proto.args_size());\n+  for (const buffer_assignment::BufferAllocationSliceProto& arg_proto :\n+       proto.args()) {\n+    TF_ASSIGN_OR_RETURN(\n+        args.emplace_back(),\n+        BufferAllocation::Slice::FromProto(arg_proto, buffer_allocations));\n+  }\n+  std::vector<bool> written{proto.written().begin(), proto.written().end()};\n+  return absl::WrapUnique(new CustomKernelThunk(std::move(thunk_info),\n+                                                std::move(custom_kernel), args,\n+                                                std::move(written)));\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "8a74dc994a1da641c69a834c46909131efc919c6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_kernel_thunk.h",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk.h?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -18,15 +18,19 @@ limitations under the License.\n \n #include <cstdint>\n #include <memory>\n+#include <optional>\n #include <string>\n #include <vector>\n \n #include \"absl/base/thread_annotations.h\"\n #include \"absl/container/flat_hash_map.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/synchronization/mutex.h\"\n+#include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/gpu/kernels/custom_kernel.h\"\n@@ -70,7 +74,20 @@ class CustomKernelThunk : public Thunk {\n \n   BufferUses buffer_uses() const override;\n \n+  absl::StatusOr<ThunkProto> ToProto() const override;\n+\n+  static absl::StatusOr<std::unique_ptr<CustomKernelThunk>> FromProto(\n+      ThunkInfo thunk_info, const CustomKernelThunkProto& proto,\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      const std::optional<se::KernelLoaderSpec::SymbolResolver>&\n+          symbol_resolver = std::nullopt);\n+\n  private:\n+  // Private constructor for deserialization.\n+  CustomKernelThunk(Thunk::ThunkInfo thunk_info, CustomKernel custom_kernel,\n+                    std::vector<BufferAllocation::Slice> args,\n+                    std::vector<bool> written);\n+\n   // Buffer slices passed to the kernel as arguments.\n   std::vector<BufferAllocation::Slice> args_;\n   std::vector<Shape> args_shape_;"
        },
        {
            "sha": "9bcfd5db9d21a92ac6a10deb33b126536abeae28",
            "filename": "third_party/xla/xla/backends/gpu/runtime/custom_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 88,
            "deletions": 0,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcustom_kernel_thunk_test.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -15,8 +15,12 @@ limitations under the License.\n \n #include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n \n+#include <memory>\n+#include <vector>\n+\n #include <gmock/gmock.h>\n #include <gtest/gtest.h>\n+#include \"absl/status/status_matchers.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/codegen/emitters/kernel_arguments.h\"\n #include \"xla/runtime/buffer_use.h\"\n@@ -25,9 +29,17 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n \n namespace xla::gpu {\n namespace {\n+using absl_testing::IsOkAndHolds;\n+using ::testing::Field;\n+using ::testing::Optional;\n+using tsl::proto_testing::EqualsProto;\n+using tsl::proto_testing::ParseTextProtoOrDie;\n \n TEST(CustomKernelThunkTest, BufferUsesReturnsCorrectBuffers) {\n   Shape arg_shape = ShapeUtil::MakeShape(F32, {512});\n@@ -75,5 +87,81 @@ TEST(CustomKernelThunkTest, BufferUsesReturnsBuffersInConsistentOrder) {\n   ASSERT_THAT(buffers1, testing::ContainerEq(buffers2));\n }\n \n+TEST(CustomKernelThunkTest, ToProto) {\n+  CustomKernel kernel(\"name\",\n+                      se::KernelLoaderSpec::CreateCudaPtxInMemorySpec(\n+                          \"PTX\", \"kernel_name\", /*arity=*/1),\n+                      se::BlockDim(3, 2, 1), se::ThreadDim(4, 5, 6),\n+                      /*shared_memory_bytes=*/42);\n+\n+  Thunk::ThunkInfo thunk_info;\n+  thunk_info.profile_annotation = \"profile_annotation\";\n+  thunk_info.execution_stream_id = 7;\n+  thunk_info.thunk_id = 42;\n+\n+  BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+  BufferAllocation::Slice slice0(&alloc, /*offset=*/0, /*size=*/512);\n+  emitters::KernelArgument arg0(ShapeUtil::MakeShape(F32, {512}), slice0);\n+  arg0.set_written(true);\n+  emitters::KernelArguments kernel_arguments({arg0});\n+  CustomKernelThunk thunk(thunk_info, kernel, kernel_arguments);\n+\n+  EXPECT_THAT(thunk.ToProto(), IsOkAndHolds(EqualsProto(R\"pb(\n+                thunk_info {\n+                  profile_annotation: \"profile_annotation\"\n+                  execution_stream_id: 7\n+                  thunk_id: 42\n+                }\n+                custom_kernel_thunk {\n+                  custom_kernel {\n+                    name: \"name\"\n+                    kernel_spec {\n+                      kernel_name: \"kernel_name\"\n+                      ptx { data: \"PTX\" }\n+                      arity: 1\n+                    }\n+                    block_dims { coordinates { x: 3, y: 2, z: 1 } }\n+                    thread_dims { coordinates { x: 4, y: 5, z: 6 } }\n+                    shared_memory_bytes: 42\n+                  }\n+                  args { buffer_allocation_index: 0, offset: 0, size: 512 }\n+                  written: true\n+                }\n+              )pb\")));\n+}\n+\n+TEST(CustomKernelThunkTest, FromProto) {\n+  CustomKernelThunkProto proto = ParseTextProtoOrDie<CustomKernelThunkProto>(\n+      R\"pb(\n+        custom_kernel {\n+          name: \"test_kernel\"\n+          kernel_spec {\n+            ptx { data: \"PTX\" }\n+            arity: 1\n+          }\n+          block_dims { coordinates { x: 1, y: 1, z: 1 } }\n+          thread_dims { coordinates { x: 1, y: 1, z: 1 } }\n+          shared_memory_bytes: 42\n+        }\n+        args { buffer_allocation_index: 0, offset: 0, size: 1024 }\n+        written: true\n+      )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations;\n+  buffer_allocations.emplace_back(/*index=*/0, /*size=*/1024, /*color=*/0);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<CustomKernelThunk> thunk,\n+                          CustomKernelThunk::FromProto(\n+                              Thunk::ThunkInfo{}, proto, buffer_allocations));\n+\n+  EXPECT_THAT(thunk->custom_kernel().name(), \"test_kernel\");\n+  EXPECT_THAT(thunk->arguments(), testing::ElementsAre(BufferAllocation::Slice(\n+                                      &buffer_allocations[0], /*offset=*/0,\n+                                      /*size=*/1024)));\n+  EXPECT_THAT(thunk->written(), testing::ElementsAre(true));\n+  EXPECT_THAT(thunk->custom_kernel().kernel_spec().cuda_ptx_in_memory(),\n+              Optional(Field(&se::CudaPtxInMemory::ptx, \"PTX\")));\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "c34eabae9e45f4dbc73b68d60e833f1b03f4de37",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -25,6 +25,7 @@ import \"xla/ffi/attribute_map.proto\";\n import \"xla/service/buffer_assignment.proto\";\n import \"xla/service/gpu/gpu_conv_runner.proto\";\n import \"xla/service/gpu/gpu_norm_runner.proto\";\n+import \"xla/service/gpu/kernels/custom_kernel.proto\";\n import \"xla/service/gpu/launch_dimensions.proto\";\n import \"xla/service/hlo.proto\";\n import \"xla/stream_executor/gpu/gpu_blas_lt.proto\";\n@@ -292,6 +293,12 @@ message CustomCallThunkProto {\n   optional string called_computation = 7;\n }\n \n+message CustomKernelThunkProto {\n+  repeated xla.buffer_assignment.BufferAllocationSliceProto args = 1;\n+  repeated bool written = 2;\n+  CustomKernelProto custom_kernel = 3;\n+}\n+\n message ThunkProto {\n   ThunkInfoProto thunk_info = 1;\n \n@@ -329,6 +336,7 @@ message ThunkProto {\n     HostSendDoneThunkProto host_send_done_thunk = 33;\n     HostRecvThunkProto host_recv_thunk = 34;\n     HostRecvDoneThunkProto host_recv_done_thunk = 35;\n+    CustomKernelThunkProto custom_kernel_thunk = 36;\n   }\n }\n "
        },
        {
            "sha": "e323e9f722bee893ebf0218d347295c78a3f0077",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.cc",
            "status": "modified",
            "additions": 25,
            "deletions": 19,
            "changes": 44,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/cub_sort_thunk.h\"\n #include \"xla/backends/gpu/runtime/cudnn_thunk.h\"\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n+#include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/dynamic_slice_thunk.h\"\n #include \"xla/backends/gpu/runtime/fft_thunk.h\"\n #include \"xla/backends/gpu/runtime/gemm_thunk.h\"\n@@ -55,6 +56,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n namespace xla::gpu {\n@@ -84,17 +86,17 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n     absl::Span<const BufferAllocation> buffer_allocations,\n     const HloModule* absl_nullable hlo_module, absl::string_view platform_name,\n     HostExecuteAsyncEventsMap& host_executable_async_events_map,\n-    HostSendRecvAsyncEventsMap& host_send_recv_async_events_map) {\n+    HostSendRecvAsyncEventsMap& host_send_recv_async_events_map,\n+    const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver) {\n   TF_ASSIGN_OR_RETURN(Thunk::ThunkInfo thunk_info,\n                       Thunk::ThunkInfo::FromProto(thunk_proto.thunk_info()));\n-  auto deserializer =\n-      [&buffer_allocations, &hlo_module, &platform_name,\n-       &host_executable_async_events_map,\n-       &host_send_recv_async_events_map](const ThunkProto& thunk_proto) {\n-        return DeserializeThunkProtoImpl(\n-            thunk_proto, buffer_allocations, hlo_module, platform_name,\n-            host_executable_async_events_map, host_send_recv_async_events_map);\n-      };\n+  auto deserializer = [&](const ThunkProto& thunk_proto) {\n+    return DeserializeThunkProtoImpl(\n+        thunk_proto, buffer_allocations, hlo_module, platform_name,\n+        host_executable_async_events_map, host_send_recv_async_events_map,\n+        symbol_resolver);\n+  };\n \n   switch (thunk_proto.impl_case()) {\n     case ThunkProto::kSequentialThunk: {\n@@ -182,14 +184,12 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n           buffer_allocations);\n     case ThunkProto::kDynamicSliceThunk: {\n       auto deserializer =\n-          [hlo_module, platform_name, &host_executable_async_events_map,\n-           &host_send_recv_async_events_map](\n-              const ThunkProto& thunk_proto,\n+          [&](const ThunkProto& thunk_proto,\n               absl::Span<const BufferAllocation> custom_allocations) {\n-            return DeserializeThunkProtoImpl(thunk_proto, custom_allocations,\n-                                             hlo_module, platform_name,\n-                                             host_executable_async_events_map,\n-                                             host_send_recv_async_events_map);\n+            return DeserializeThunkProtoImpl(\n+                thunk_proto, custom_allocations, hlo_module, platform_name,\n+                host_executable_async_events_map,\n+                host_send_recv_async_events_map, symbol_resolver);\n           };\n       return DynamicSliceThunk::FromProto(std::move(thunk_info),\n                                           thunk_proto.dynamic_slice_thunk(),\n@@ -231,6 +231,10 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n       return OutfeedThunk::FromProto(std::move(thunk_info),\n                                      thunk_proto.outfeed_thunk(),\n                                      buffer_allocations);\n+    case ThunkProto::kCustomKernelThunk:\n+      return CustomKernelThunk::FromProto(std::move(thunk_info),\n+                                          thunk_proto.custom_kernel_thunk(),\n+                                          buffer_allocations, symbol_resolver);\n \n     default:\n       std::optional<absl::string_view> unsupported_thunk_type =\n@@ -254,13 +258,15 @@ absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProtoImpl(\n absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n     const ThunkProto& thunk_proto,\n     absl::Span<const BufferAllocation> buffer_allocations,\n-    const HloModule* absl_nullable hlo_module,\n-    absl::string_view platform_name) {\n+    const HloModule* absl_nullable hlo_module, absl::string_view platform_name,\n+    const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver) {\n   HostExecuteAsyncEventsMap host_executable_async_events_map;\n   HostSendRecvAsyncEventsMap host_send_recv_async_events_map;\n   return DeserializeThunkProtoImpl(\n       thunk_proto, buffer_allocations, hlo_module, platform_name,\n-      host_executable_async_events_map, host_send_recv_async_events_map);\n+      host_executable_async_events_map, host_send_recv_async_events_map,\n+      symbol_resolver);\n }\n \n }  // namespace xla::gpu"
        },
        {
            "sha": "473c221520594cce68e7ee7bfdc3a7e7af67006a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization.h",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization.h?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -17,6 +17,7 @@ limitations under the License.\n #define XLA_BACKENDS_GPU_RUNTIME_THUNK_PROTO_DESERIALIZATION_H_\n \n #include <memory>\n+#include <optional>\n \n #include \"absl/base/nullability.h\"\n #include \"absl/status/statusor.h\"\n@@ -26,14 +27,24 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/kernel_spec.h\"\n \n namespace xla::gpu {\n \n // Deserializes the given `thunk_proto` into a Thunk.\n+// - `buffer_allocations` is used to deserialize buffer slices.\n+// - `hlo_module` is used to deserialize thunks that reference HLO instructions.\n+// - `platform_name` is used to look up platform-specific kernels in the\n+//   GpuKernelRegistry.\n+// - `symbol_resolver` is used to deserialize custom kernels where the kernel is\n+//   not inlined in the proto, but rather loaded at runtime via symbol\n+//   resolution.\n absl::StatusOr<std::unique_ptr<Thunk>> DeserializeThunkProto(\n     const ThunkProto& thunk_proto,\n     absl::Span<const BufferAllocation> buffer_allocations,\n-    const HloModule* absl_nullable hlo_module, absl::string_view platform_name);\n+    const HloModule* absl_nullable hlo_module, absl::string_view platform_name,\n+    const std::optional<stream_executor::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver = std::nullopt);\n \n }  // namespace xla::gpu\n "
        },
        {
            "sha": "248f119c4f33d8732c53deadced0a0d5ee6c66f3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization_test.cc",
            "status": "modified",
            "additions": 85,
            "deletions": 0,
            "changes": 85,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -23,9 +23,11 @@ limitations under the License.\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/conditional_thunk.h\"\n #include \"xla/backends/gpu/runtime/copy_thunk.h\"\n+#include \"xla/backends/gpu/runtime/custom_kernel_thunk.h\"\n #include \"xla/backends/gpu/runtime/host_execute_thunk.h\"\n #include \"xla/backends/gpu/runtime/host_send_recv_thunk.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n@@ -40,14 +42,18 @@ limitations under the License.\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/hlo_module_config.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/util/proto/parse_text_proto.h\"\n #include \"xla/tsl/util/proto/proto_matchers.h\"\n+#include \"xla/tsl/util/safe_reinterpret_cast.h\"\n \n namespace xla::gpu {\n namespace {\n using ::testing::ElementsAre;\n+using ::testing::Field;\n using ::testing::IsEmpty;\n+using ::testing::Optional;\n using ::testing::Pointer;\n using ::testing::Property;\n using ::testing::WhenDynamicCastTo;\n@@ -755,5 +761,84 @@ TEST(ThunkProtoDeserializationTest, HostExecuteThunksRoundTrip) {\n   EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n }\n \n+TEST(ThunkProtoDeserializationTest, CustomKernelThunkRoundTrip) {\n+  ThunkProto proto = ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info { execution_stream_id: 7 }\n+        custom_kernel_thunk {\n+          custom_kernel {\n+            name: \"test_kernel\"\n+            kernel_spec {\n+              ptx { data: \"PTX\" }\n+              arity: 1\n+            }\n+            block_dims { coordinates { x: 1, y: 1, z: 1 } }\n+            thread_dims { coordinates { x: 1, y: 1, z: 1 } }\n+            shared_memory_bytes: 42\n+          }\n+          args { buffer_allocation_index: 0 }\n+          written: true\n+        }\n+      )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/1024, /*color=*/0)};\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Thunk> thunk,\n+      DeserializeThunkProto(proto, buffer_allocations, /*hlo_module=*/nullptr,\n+                            kTestPlatformName));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto round_trip_proto, thunk->ToProto());\n+  EXPECT_THAT(round_trip_proto, EqualsProto(proto));\n+}\n+\n+// A test symbol that we can resolve to.\n+void test_kernel(void* args) {}\n+\n+TEST(ThunkProtoDeserializationTest, CustomKernelThunkSymbolResolvingWorks) {\n+  ThunkProto proto = ParseTextProtoOrDie<ThunkProto>(\n+      R\"pb(\n+        thunk_info { execution_stream_id: 7 }\n+        custom_kernel_thunk {\n+          custom_kernel {\n+            name: \"test_kernel\"\n+            kernel_spec {\n+              in_process_symbol { persistent_name: \"test_kernel\" }\n+              arity: 1\n+            }\n+            block_dims { coordinates { x: 1, y: 1, z: 1 } }\n+            thread_dims { coordinates { x: 1, y: 1, z: 1 } }\n+            shared_memory_bytes: 42\n+          }\n+          args { buffer_allocation_index: 0 }\n+          written: true\n+        }\n+      )pb\");\n+\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/1024, /*color=*/0)};\n+\n+  auto symbol_resolver =\n+      [&](absl::string_view persistent_name) -> absl::StatusOr<void*> {\n+    if (persistent_name == \"test_kernel\") {\n+      return tsl::safe_reinterpret_cast<void*>(&test_kernel);\n+    }\n+    return absl::NotFoundError(\"Symbol not found\");\n+  };\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<Thunk> thunk,\n+      DeserializeThunkProto(proto, buffer_allocations, /*hlo_module=*/nullptr,\n+                            kTestPlatformName, symbol_resolver));\n+\n+  auto custom_kernel_thunk = dynamic_cast<CustomKernelThunk*>(thunk.get());\n+  ASSERT_NE(custom_kernel_thunk, nullptr);\n+  EXPECT_THAT(\n+      custom_kernel_thunk->custom_kernel().kernel_spec().in_process_symbol(),\n+      Optional(Field(&stream_executor::InProcessSymbol::symbol,\n+                     tsl::safe_reinterpret_cast<void*>(&test_kernel))));\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "b3c01bcbe132fe69da44788cbc32d93c2672f76e",
            "filename": "third_party/xla/xla/service/gpu/kernels/BUILD",
            "status": "modified",
            "additions": 35,
            "deletions": 1,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2FBUILD?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -1,8 +1,12 @@\n load(\"@local_config_cuda//cuda:build_defs.bzl\", \"cuda_library\")\n load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n-load(\"//xla:xla.default.bzl\", \"xla_cc_binary\")\n+load(\"//xla:xla.default.bzl\", \"xla_cc_binary\", \"xla_cc_test\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n load(\"//xla/tsl:tsl.bzl\", \"if_windows\")\n+load(\n+    \"//xla/tsl/platform:build_config.bzl\",\n+    \"tf_proto_library\",\n+)\n load(\n     \"//xla/tsl/platform/default:cuda_build_defs.bzl\",\n     \"if_cuda_is_configured\",\n@@ -56,19 +60,49 @@ cc_library(\n     ],\n )\n \n+tf_proto_library(\n+    name = \"custom_kernel_proto\",\n+    srcs = [\"custom_kernel.proto\"],\n+    protodeps = [\n+        \"//xla/stream_executor:kernel_spec_proto\",\n+        \"//xla/stream_executor:launch_dim_proto\",\n+    ],\n+    visibility = [\":friends\"],\n+)\n+\n cc_library(\n     name = \"custom_kernel\",\n     srcs = [\"custom_kernel.cc\"],\n     hdrs = [\"custom_kernel.h\"],\n     visibility = [\":friends\"],\n     deps = [\n+        \":custom_kernel_proto_cc\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n     ],\n )\n \n+xla_cc_test(\n+    name = \"custom_kernel_test\",\n+    srcs = [\"custom_kernel_test.cc\"],\n+    deps = [\n+        \":custom_kernel\",\n+        \":custom_kernel_proto_cc\",\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/util/proto:parse_text_proto\",\n+        \"//xla/tsl/util/proto:proto_matchers\",\n+        \"@com_google_absl//absl/base\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n # Bundle all custom fusions into a single target, so we can link all fusions and patterns by adding\n # a single dependency.\n cc_library("
        },
        {
            "sha": "d5b413bd166f9dfcef1bd731ff5de971db55ec94",
            "filename": "third_party/xla/xla/service/gpu/kernels/custom_kernel.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 0,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -20,10 +20,12 @@ limitations under the License.\n #include <string>\n #include <utility>\n \n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n \n namespace xla::gpu {\n \n@@ -79,4 +81,39 @@ std::string CustomKernel::ToString() const {\n       thread_dims_.y, thread_dims_.z, cluster_dims_str, shared_memory_bytes_);\n }\n \n+absl::StatusOr<CustomKernelProto> CustomKernel::ToProto() const {\n+  CustomKernelProto proto;\n+  proto.set_name(name_);\n+  TF_ASSIGN_OR_RETURN(*proto.mutable_kernel_spec(), kernel_spec_.ToProto());\n+  *proto.mutable_block_dims() = block_dims_.ToProto();\n+  *proto.mutable_thread_dims() = thread_dims_.ToProto();\n+  if (cluster_dims_.has_value()) {\n+    *proto.mutable_cluster_dim() = cluster_dims_->ToProto();\n+  }\n+  proto.set_shared_memory_bytes(shared_memory_bytes_);\n+  return proto;\n+}\n+\n+absl::StatusOr<CustomKernel> CustomKernel::FromProto(\n+    const CustomKernelProto& proto,\n+    const std::optional<se::KernelLoaderSpec::SymbolResolver>&\n+        symbol_resolver) {\n+  TF_ASSIGN_OR_RETURN(\n+      se::KernelLoaderSpec kernel_spec,\n+      se::KernelLoaderSpec::FromProto(proto.kernel_spec(), symbol_resolver));\n+  TF_ASSIGN_OR_RETURN(se::BlockDim block_dims,\n+                      se::BlockDim::FromProto(proto.block_dims()));\n+  TF_ASSIGN_OR_RETURN(se::ThreadDim thread_dims,\n+                      se::ThreadDim::FromProto(proto.thread_dims()));\n+  if (proto.has_cluster_dim()) {\n+    TF_ASSIGN_OR_RETURN(se::ClusterDim cluster_dims,\n+                        se::ClusterDim::FromProto(proto.cluster_dim()));\n+    return CustomKernel(proto.name(), std::move(kernel_spec), block_dims,\n+                        thread_dims, cluster_dims, proto.shared_memory_bytes());\n+  }\n+\n+  return CustomKernel(proto.name(), std::move(kernel_spec), block_dims,\n+                      thread_dims, proto.shared_memory_bytes());\n+}\n+\n }  // namespace xla::gpu"
        },
        {
            "sha": "a05def65fe7380135019ab6a0be385637ce40924",
            "filename": "third_party/xla/xla/service/gpu/kernels/custom_kernel.h",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.h?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -20,7 +20,9 @@ limitations under the License.\n #include <optional>\n #include <string>\n \n+#include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/service/gpu/kernels/custom_kernel.pb.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n \n@@ -67,6 +69,13 @@ class CustomKernel {\n \n   std::string ToString() const;\n \n+  absl::StatusOr<CustomKernelProto> ToProto() const;\n+\n+  static absl::StatusOr<CustomKernel> FromProto(\n+      const CustomKernelProto& proto,\n+      const std::optional<se::KernelLoaderSpec::SymbolResolver>&\n+          symbol_resolver = std::nullopt);\n+\n  private:\n   std::string name_;\n   se::KernelLoaderSpec kernel_spec_;"
        },
        {
            "sha": "cdf6929eefd654175302ed393d36836a7cdff678",
            "filename": "third_party/xla/xla/service/gpu/kernels/custom_kernel.proto",
            "status": "added",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel.proto?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -0,0 +1,18 @@\n+syntax = \"proto3\";\n+\n+package xla.gpu;\n+\n+import \"xla/stream_executor/kernel_spec.proto\";\n+import \"xla/stream_executor/launch_dim.proto\";\n+\n+option java_multiple_files = true;\n+option java_outer_classname = \"CustomKernel\";\n+\n+message CustomKernelProto {\n+  string name = 1;\n+  stream_executor.KernelLoaderSpecProto kernel_spec = 2;\n+  stream_executor.BlockDimProto block_dims = 3;\n+  stream_executor.ThreadDimProto thread_dims = 4;\n+  optional stream_executor.ClusterDimProto cluster_dim = 5;\n+  int64 shared_memory_bytes = 6;\n+}"
        },
        {
            "sha": "5da5d56d02c819c54c7b0229a9f2f51692bb5ec3",
            "filename": "third_party/xla/xla/service/gpu/kernels/custom_kernel_test.cc",
            "status": "added",
            "additions": 157,
            "deletions": 0,
            "changes": 157,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fkernels%2Fcustom_kernel_test.cc?ref=a146cbcafa6cf1a0e33c02c717f9f4ad7e758cb2",
            "patch": "@@ -0,0 +1,157 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/gpu/kernels/custom_kernel.h\"\n+\n+#include <optional>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/base/casts.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/service/gpu/kernels/custom_kernel.pb.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/tsl/util/proto/parse_text_proto.h\"\n+#include \"xla/tsl/util/proto/proto_matchers.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+using ::testing::Field;\n+using ::testing::Optional;\n+using tsl::proto_testing::ParseTextProtoOrDie;\n+\n+void SomeKernel(int* x) { *x = 42; }\n+\n+TEST(CustomKernelTest, ToProto) {\n+  CustomKernel custom_kernel(\n+      \"kernel_name\",\n+      stream_executor::KernelLoaderSpec::CreateSerializableInProcessSymbolSpec(\n+          \"persistent_kernel_name\",\n+          /*symbol=*/absl::bit_cast<void*>(&SomeKernel), \"kernel_name\",\n+          /*arity=*/42),\n+      stream_executor::BlockDim(1, 2, 3), stream_executor::ThreadDim(4, 5, 6),\n+      /*shared_memory_bytes=*/7);\n+  TF_ASSERT_OK_AND_ASSIGN(CustomKernelProto proto, custom_kernel.ToProto());\n+\n+  EXPECT_THAT(\n+      proto, tsl::proto_testing::EqualsProto(R\"pb(\n+        name: \"kernel_name\"\n+        kernel_spec {\n+          in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n+          kernel_name: \"kernel_name\"\n+          arity: 42\n+        }\n+        block_dims { coordinates { x: 1 y: 2 z: 3 } }\n+        thread_dims { coordinates { x: 4 y: 5 z: 6 } }\n+        shared_memory_bytes: 7\n+      )pb\"));\n+}\n+\n+TEST(CustomKernelTest, ToProtoWithClusterDims) {\n+  CustomKernel custom_kernel(\n+      \"kernel_name\",\n+      stream_executor::KernelLoaderSpec::CreateSerializableInProcessSymbolSpec(\n+          \"persistent_kernel_name\",\n+          /*symbol=*/absl::bit_cast<void*>(&SomeKernel), \"kernel_name_in_spec\",\n+          /*arity=*/42),\n+      stream_executor::BlockDim(1, 2, 3), stream_executor::ThreadDim(4, 5, 6),\n+      stream_executor::ClusterDim(7, 8, 9),\n+      /*shared_memory_bytes=*/10);\n+  TF_ASSERT_OK_AND_ASSIGN(CustomKernelProto proto, custom_kernel.ToProto());\n+\n+  EXPECT_THAT(\n+      proto, tsl::proto_testing::EqualsProto(R\"pb(\n+        name: \"kernel_name\"\n+        kernel_spec {\n+          in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n+          kernel_name: \"kernel_name_in_spec\"\n+          arity: 42\n+        }\n+        block_dims { coordinates { x: 1 y: 2 z: 3 } }\n+        thread_dims { coordinates { x: 4 y: 5 z: 6 } }\n+        cluster_dim { coordinates { x: 7 y: 8 z: 9 } }\n+        shared_memory_bytes: 10\n+      )pb\"));\n+}\n+\n+absl::StatusOr<void*> StaticSymbolResolver(absl::string_view persistent_name) {\n+  // Resolves a symbol to the address of SomeKernel - no matter what the\n+  // persistent name is.\n+  return absl::bit_cast<void*>(&SomeKernel);\n+}\n+\n+TEST(CustomKernelTest, FromProto) {\n+  auto proto = ParseTextProtoOrDie<CustomKernelProto>(R\"pb(\n+    name: \"kernel_name\"\n+    kernel_spec {\n+      in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n+      kernel_name: \"kernel_name_in_spec\"\n+      arity: 42\n+    }\n+    block_dims { coordinates { x: 1 y: 2 z: 3 } }\n+    thread_dims { coordinates { x: 4 y: 5 z: 6 } }\n+    shared_memory_bytes: 7\n+  )pb\");\n+  TF_ASSERT_OK_AND_ASSIGN(CustomKernel custom_kernel,\n+                          CustomKernel::FromProto(proto, StaticSymbolResolver));\n+  EXPECT_EQ(custom_kernel.name(), \"kernel_name\");\n+  EXPECT_EQ(custom_kernel.kernel_spec().kernel_name(), \"kernel_name_in_spec\");\n+  EXPECT_EQ(custom_kernel.kernel_spec().arity(), 42);\n+  EXPECT_THAT(custom_kernel.kernel_spec().in_process_symbol(),\n+              Optional(Field(&stream_executor::InProcessSymbol::symbol,\n+                             absl::bit_cast<void*>(&SomeKernel))));\n+  EXPECT_THAT(custom_kernel.kernel_spec().in_process_symbol(),\n+              Optional(Field(&stream_executor::InProcessSymbol::persistent_name,\n+                             \"persistent_kernel_name\")));\n+  EXPECT_EQ(custom_kernel.block_dims(), stream_executor::BlockDim(1, 2, 3));\n+  EXPECT_EQ(custom_kernel.thread_dims(), stream_executor::ThreadDim(4, 5, 6));\n+  EXPECT_EQ(custom_kernel.cluster_dims(), std::nullopt);\n+  EXPECT_EQ(custom_kernel.shared_memory_bytes(), 7);\n+}\n+\n+TEST(CustomKernelTest, FromProtoWithClusterDims) {\n+  auto proto = ParseTextProtoOrDie<CustomKernelProto>(R\"pb(\n+    name: \"kernel_name\"\n+    kernel_spec {\n+      in_process_symbol { persistent_name: \"persistent_kernel_name\" }\n+      kernel_name: \"kernel_name_in_spec\"\n+      arity: 42\n+    }\n+    block_dims { coordinates { x: 1 y: 2 z: 3 } }\n+    thread_dims { coordinates { x: 4 y: 5 z: 6 } }\n+    cluster_dim { coordinates { x: 7 y: 8 z: 9 } }\n+    shared_memory_bytes: 10\n+  )pb\");\n+  TF_ASSERT_OK_AND_ASSIGN(CustomKernel custom_kernel,\n+                          CustomKernel::FromProto(proto, StaticSymbolResolver));\n+  EXPECT_EQ(custom_kernel.name(), \"kernel_name\");\n+  EXPECT_EQ(custom_kernel.kernel_spec().kernel_name(), \"kernel_name_in_spec\");\n+  EXPECT_EQ(custom_kernel.kernel_spec().arity(), 42);\n+  EXPECT_THAT(custom_kernel.kernel_spec().in_process_symbol(),\n+              Optional(Field(&stream_executor::InProcessSymbol::symbol,\n+                             absl::bit_cast<void*>(&SomeKernel))));\n+  EXPECT_THAT(custom_kernel.kernel_spec().in_process_symbol(),\n+              Optional(Field(&stream_executor::InProcessSymbol::persistent_name,\n+                             \"persistent_kernel_name\")));\n+  EXPECT_EQ(custom_kernel.block_dims(), stream_executor::BlockDim(1, 2, 3));\n+  EXPECT_EQ(custom_kernel.thread_dims(), stream_executor::ThreadDim(4, 5, 6));\n+  EXPECT_EQ(custom_kernel.cluster_dims(), stream_executor::ClusterDim(7, 8, 9));\n+  EXPECT_EQ(custom_kernel.shared_memory_bytes(), 10);\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 582,
        "additions": 557,
        "deletions": 25
    }
}