{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 848382953",
    "sha": "7d0d53475633627ec999d904d58c6f50b352dd36",
    "files": [
        {
            "sha": "b31481ecbe25785c504b57dad6b84cb5714d9565",
            "filename": "third_party/xla/xla/hlo/transforms/host_offloader.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 22,
            "changes": 43,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7d0d53475633627ec999d904d58c6f50b352dd36/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7d0d53475633627ec999d904d58c6f50b352dd36/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fhost_offloader.cc?ref=7d0d53475633627ec999d904d58c6f50b352dd36",
            "patch": "@@ -249,11 +249,11 @@ absl::StatusOr<bool> HostOffloader::WalkDownHostMemoryOffloadPaths(\n       if (is_end_of_offload) {\n         // This DynamicSlice is the end of this path of host memory offload.\n         continue;\n-      } else {\n-        // This is not the end of host memory offload. This is treated as device\n-        // compute happening on host memory, convert it to host compute.\n-        need_to_wrap_instruction_as_host_compute = true;\n-      }\n+      }  // This is not the end of host memory offload. This is treated as\n+         // device\n+      // compute happening on host memory, convert it to host compute.\n+      need_to_wrap_instruction_as_host_compute = true;\n+\n     } else if (instruction->opcode() == HloOpcode::kSlice) {\n       TF_ASSIGN_OR_RETURN(bool is_end_of_offload,\n                           SliceLeadsToMoveToDeviceCustomCall(instruction));\n@@ -263,11 +263,11 @@ absl::StatusOr<bool> HostOffloader::WalkDownHostMemoryOffloadPaths(\n         // memory.\n         slices_to_dynamify.insert(instruction);\n         continue;\n-      } else {\n-        // This is not the end of host memory offload. This is treated as device\n-        // compute happening on host memory, convert it to host compute.\n-        need_to_wrap_instruction_as_host_compute = true;\n-      }\n+      }  // This is not the end of host memory offload. This is treated as\n+         // device\n+      // compute happening on host memory, convert it to host compute.\n+      need_to_wrap_instruction_as_host_compute = true;\n+\n     } else if (instruction->opcode() == HloOpcode::kCopy) {\n       if (instruction->shape() == instruction->operand(0)->shape()) {\n         need_to_wrap_instruction_as_host_compute = true;\n@@ -343,17 +343,16 @@ absl::StatusOr<bool> HostOffloader::WalkDownHostMemoryOffloadPaths(\n             \"Memory offloaded starting from %s is output streamed\",\n             starting_instruction_and_index.ToString());\n         continue;\n-      } else {\n-        if (VLOG_IS_ON(1)) {\n-          LOG(INFO) << \"Instruction trace leading to error:\";\n-          PrintTrace(instruction_and_shape_index, previous);\n-        }\n-        return absl::InvalidArgumentError(\n-            absl::StrFormat(\"Tensor which is moved to host (starting from %s) \"\n-                            \"is returned from the entry computation but the \"\n-                            \"layout for this output is not set to host memory.\",\n-                            starting_instruction->name()));\n       }\n+      if (VLOG_IS_ON(1)) {\n+        LOG(INFO) << \"Instruction trace leading to error:\";\n+        PrintTrace(instruction_and_shape_index, previous);\n+      }\n+      return absl::InvalidArgumentError(\n+          absl::StrFormat(\"Tensor which is moved to host (starting from %s) \"\n+                          \"is returned from the entry computation but the \"\n+                          \"layout for this output is not set to host memory.\",\n+                          starting_instruction->name()));\n     }\n     // Push successors onto the queue to be visited.\n     TF_ASSIGN_OR_RETURN(\n@@ -643,8 +642,8 @@ HostOffloader::GetStartingInstructions(\n       // Found a DynamicUpdateSlice.\n       result.push_back(instruction_and_shape);\n       continue;\n-    } else if (!InstructionIsAllowedBetweenMoveToHostAndDus(\n-                   current_instruction)) {\n+    }\n+    if (!InstructionIsAllowedBetweenMoveToHostAndDus(current_instruction)) {\n       // Found the start of \"normal\" memory offloading.\n       result.push_back(instruction_and_shape);\n       continue;"
        }
    ],
    "stats": {
        "total": 43,
        "additions": 21,
        "deletions": 22
    }
}