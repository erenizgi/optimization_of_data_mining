{
    "author": "khasanovaa",
    "message": "Add proto [de]serialization for HostExecuteDoneThunk\n\nPiperOrigin-RevId: 821029998",
    "sha": "4985a1c2f366e14bd995bc910077cc83c868dfce",
    "files": [
        {
            "sha": "8e44502f0bcebda33d98a2582d60ae688e5dfe89",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 3,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.cc?ref=4985a1c2f366e14bd995bc910077cc83c868dfce",
            "patch": "@@ -639,14 +639,35 @@ HostExecuteDoneThunk::HostExecuteDoneThunk(\n std::string HostExecuteDoneThunk::ToString(int indent) const { return \"\"; }\n \n absl::StatusOr<ThunkProto> HostExecuteDoneThunk::ToProto() const {\n-  return Unimplemented(\"Not implemented yet.\");\n+  ThunkProto proto;\n+  *proto.mutable_thunk_info() = thunk_info().ToProto();\n+  HostExecuteDoneThunkProto* host_execute_done_thunk_proto =\n+      proto.mutable_host_execute_done_thunk();\n+\n+  auto async_events_unique_id = GetAsyncEventsUniqueId();\n+  // By design, async_events_unique_id should always be present for\n+  // HostExecuteDoneThunk.\n+  CHECK_NE(async_events_unique_id, std::nullopt);\n+\n+  host_execute_done_thunk_proto->set_async_events_unique_id(\n+      async_events_unique_id.value().value());\n+\n+  return proto;\n }\n \n absl::StatusOr<std::unique_ptr<HostExecuteDoneThunk>>\n HostExecuteDoneThunk::FromProto(\n     ThunkInfo thunk_info, const HostExecuteDoneThunkProto& proto,\n-    absl::Span<const BufferAllocation> buffer_allocations) {\n-  return Unimplemented(\"Not implemented yet.\");\n+    absl::Span<const BufferAllocation> buffer_allocations,\n+    HostExecuteAsyncEventsMap& async_events_map) {\n+  // If async_events_map already contains an entry for the given unique id,\n+  // that means that the pairing start thunk is already serialized and we reuse\n+  // the id to connect them. Otherwise, create a new entry.\n+  auto [async_event_it, _] = async_events_map.try_emplace(\n+      AsyncEventsUniqueId(proto.async_events_unique_id()),\n+      std::make_shared<HostExecuteAsyncEvents>());\n+  return std::make_unique<HostExecuteDoneThunk>(thunk_info,\n+                                                async_event_it->second);\n }\n \n absl::Status HostExecuteDoneThunk::Initialize(const InitializeParams& params) {\n@@ -674,5 +695,13 @@ absl::Status HostExecuteDoneThunk::ExecuteOnStream(\n   return absl::OkStatus();\n }\n \n+std::optional<AsyncEventsUniqueId>\n+HostExecuteDoneThunk::GetAsyncEventsUniqueId() const {\n+  CHECK(async_events_)\n+      << \"async_events_ must not be null in HostExecuteDoneThunk\";\n+  // We rely on the fact that the pointer to async_events_ is unique.\n+  return absl::bit_cast<AsyncEventsUniqueId>(async_events_.get());\n+}\n+\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "ee1585fdf61e85831339dd24c952c5288fd662e6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk.h",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk.h?ref=4985a1c2f366e14bd995bc910077cc83c868dfce",
            "patch": "@@ -161,11 +161,14 @@ class HostExecuteDoneThunk : public Thunk {\n   absl::StatusOr<ThunkProto> ToProto() const override;\n   static absl::StatusOr<std::unique_ptr<HostExecuteDoneThunk>> FromProto(\n       ThunkInfo thunk_info, const HostExecuteDoneThunkProto& proto,\n-      absl::Span<const BufferAllocation> buffer_allocations);\n+      absl::Span<const BufferAllocation> buffer_allocations,\n+      HostExecuteAsyncEventsMap& async_events_map);\n \n   absl::Status Initialize(const InitializeParams& params) override;\n   absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n \n+  std::optional<AsyncEventsUniqueId> GetAsyncEventsUniqueId() const override;\n+\n  private:\n   std::shared_ptr<HostExecuteAsyncEvents> async_events_;\n };"
        },
        {
            "sha": "1b6f0e1f3abb70fd1e4b6857d519b8f95a5b2ef3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/host_execute_thunk_test.cc",
            "status": "modified",
            "additions": 63,
            "deletions": 0,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4985a1c2f366e14bd995bc910077cc83c868dfce/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fhost_execute_thunk_test.cc?ref=4985a1c2f366e14bd995bc910077cc83c868dfce",
            "patch": "@@ -640,6 +640,69 @@ TEST(HostExecuteStartThunkTest, ProtoRoundTrip) {\n   EXPECT_THAT(round_trip_proto, tsl::proto_testing::EqualsProto(proto));\n }\n \n+TEST(HostExecuteThunkTest, ProtoRoundTripPairing) {\n+  static constexpr char const* kHloModule = R\"(\n+    HloModule module\n+    ENTRY add_inplace {\n+      p0 = s32[] parameter(0)\n+      ROOT add = s32[] add(p0, p0)\n+    }\n+  )\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n+                          ParseAndReturnUnverifiedModule(kHloModule, {}));\n+\n+  BufferAllocation alloc_arg(/*index=*/0, 4, /*color=*/0);\n+  BufferAllocation alloc_result(/*index=*/1, 4, /*color=*/0);\n+\n+  BufferAllocation::Slice slice_arg(&alloc_arg, 0, 4);\n+  BufferAllocation::Slice slice_result(&alloc_result, 0, 4);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto start_thunk_orig,\n+                          CreateHostExecuteStartThunk(\n+                              Thunk::ThunkInfo(), *hlo_module,\n+                              {{slice_arg, ShapeUtil::MakeShape(S32, {})}},\n+                              {{slice_result, ShapeUtil::MakeShape(S32, {})}}));\n+\n+  HostExecuteDoneThunk done_thunk_orig(Thunk::ThunkInfo(),\n+                                       start_thunk_orig->async_events());\n+\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto start_proto, start_thunk_orig->ToProto());\n+  TF_ASSERT_OK_AND_ASSIGN(ThunkProto done_proto, done_thunk_orig.ToProto());\n+\n+  // Check that the ids are matching.\n+  EXPECT_EQ(start_proto.host_execute_start_thunk().async_events_unique_id(),\n+            done_proto.host_execute_done_thunk().async_events_unique_id());\n+\n+  std::vector<BufferAllocation> buffer_allocations = {\n+      BufferAllocation(/*index=*/0, /*size=*/4, /*color=*/0),\n+      BufferAllocation(/*index=*/1, /*size=*/4, /*color=*/0)};\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      Thunk::ThunkInfo start_thunk_info,\n+      Thunk::ThunkInfo::FromProto(start_proto.thunk_info()));\n+  TF_ASSERT_OK_AND_ASSIGN(Thunk::ThunkInfo done_thunk_info,\n+                          Thunk::ThunkInfo::FromProto(done_proto.thunk_info()));\n+\n+  HostExecuteAsyncEventsMap async_events_map;\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HostExecuteDoneThunk> done_thunk,\n+      HostExecuteDoneThunk::FromProto(done_thunk_info,\n+                                      done_proto.host_execute_done_thunk(),\n+                                      buffer_allocations, async_events_map));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<HostExecuteStartThunk> start_thunk,\n+      HostExecuteStartThunk::FromProto(start_thunk_info,\n+                                       start_proto.host_execute_start_thunk(),\n+                                       buffer_allocations, async_events_map));\n+\n+  EXPECT_EQ(async_events_map.size(), 1);\n+  EXPECT_EQ(start_thunk->GetAsyncEventsUniqueId(),\n+            done_thunk->GetAsyncEventsUniqueId());\n+}\n+\n }  // namespace\n \n }  // namespace gpu"
        }
    ],
    "stats": {
        "total": 103,
        "additions": 99,
        "deletions": 4
    }
}