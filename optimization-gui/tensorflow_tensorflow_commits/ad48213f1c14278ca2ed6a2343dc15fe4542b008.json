{
    "author": "KanishAnand",
    "message": "This is a mechanical change to replace `tile_assignment().dim(i)` by `dimension(i)` which more clearly reflects purpose of method instead of exposing implementation details.\nThis is a 1/N cl's to privatize `tile_assignment()` method.\n\nPiperOrigin-RevId: 838814431",
    "sha": "ad48213f1c14278ca2ed6a2343dc15fe4542b008",
    "files": [
        {
            "sha": "32bf9bbd61f04fefaf0916c6c238b5a8c953c025",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -1302,13 +1302,12 @@ bool ShardingIsConsistent(const HloSharding& partial_sharding,\n   }\n   for (size_t i = 0; i < partial_sharding.tile_assignment().num_dimensions();\n        ++i) {\n-    if (strict && partial_sharding.tile_assignment().dim(i) > 1 &&\n-        partial_sharding.tile_assignment().dim(i) ==\n-            complete_sharding.tile_assignment().dim(i)) {\n+    if (strict && partial_sharding.dimension(i) > 1 &&\n+        partial_sharding.dimension(i) == complete_sharding.dimension(i)) {\n       return true;\n     }\n-    if (!strict && partial_sharding.tile_assignment().dim(i) > 1 &&\n-        complete_sharding.tile_assignment().dim(i) > 1) {\n+    if (!strict && partial_sharding.dimension(i) > 1 &&\n+        complete_sharding.dimension(i) > 1) {\n       return true;\n     }\n   }"
        },
        {
            "sha": "d14f1824313f525e343ccfd159594abf283d2857",
            "filename": "third_party/xla/xla/hlo/experimental/auto_sharding/auto_sharding_util.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fexperimental%2Fauto_sharding%2Fauto_sharding_util.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -1083,7 +1083,7 @@ int64_t NumTileDimensions(const HloSharding& sharding) {\n   }\n   int64_t num_tile_dims = 0;\n   for (int i = 0; i < sharding.tile_assignment().num_dimensions(); i++) {\n-    if (sharding.tile_assignment().dim(i) != 1) {\n+    if (sharding.dimension(i) != 1) {\n       num_tile_dims++;\n     }\n   }\n@@ -1094,7 +1094,7 @@ bool TileAssignmentMatchesMesh(const HloSharding& sharding,\n                                const DeviceMesh& mesh) {\n   int sharded_dims = 0;\n   for (int i = 0; i < sharding.tile_assignment().num_dimensions(); ++i) {\n-    if (sharding.tile_assignment().dim(i) > 1) {\n+    if (sharding.dimension(i) > 1) {\n       sharded_dims++;\n     }\n   }\n@@ -1131,7 +1131,7 @@ absl::StatusOr<std::vector<int64_t>> GetTensorDimToMeshDimNoCrash(\n   std::vector<int64_t> tensor_dim_to_device_dim(tensor_shape_rank, -1);\n   int mesh_index = 0;\n   for (int i = 0; i < tensor_shape_rank; ++i) {\n-    if (spec.tile_assignment().dim(i) != 1) {\n+    if (spec.dimension(i) != 1) {\n       while (device_mesh.dim(axes[mesh_index]) == 1) {\n         mesh_index++;\n       }\n@@ -1167,7 +1167,7 @@ GetTensorDimToMeshDimMixedMeshSharding(int64_t tensor_shape_rank,\n   std::vector<absl::btree_set<int64_t>> tensor_dim_to_mesh_axis_mapping;\n   int mesh_axis_idx = 0;\n   for (int i = 0; i < sharding.tile_assignment().num_dimensions(); ++i) {\n-    if (sharding.tile_assignment().dim(i) == 1) {\n+    if (sharding.dimension(i) == 1) {\n       tensor_dim_to_mesh_axis_mapping.push_back({});\n       continue;\n     }\n@@ -1183,7 +1183,7 @@ GetTensorDimToMeshDimMixedMeshSharding(int64_t tensor_shape_rank,\n       product *= device_mesh.dim(axes[mesh_axis_idx]);\n       mesh_axes_for_this_tensor_dim.insert(axes[mesh_axis_idx]);\n       mesh_axis_idx++;\n-    } while (product < sharding.tile_assignment().dim(i));\n+    } while (product < sharding.dimension(i));\n     CHECK(!mesh_axes_for_this_tensor_dim.empty());\n     tensor_dim_to_mesh_axis_mapping.push_back(mesh_axes_for_this_tensor_dim);\n   }\n@@ -1213,7 +1213,7 @@ absl::StatusOr<Shape> ComputeIntermediateShape(const HloSharding& src_sharding,\n   // Find an intermediate shape\n   std::vector<int64_t> inter_shape_dims;\n   for (size_t i = 0; i < shape.dimensions().size(); ++i) {\n-    if (sharding_1d->tile_assignment().dim(i) == 1) {\n+    if (sharding_1d->dimension(i) == 1) {\n       inter_shape_dims.push_back(shape.dimensions(i));\n     } else {\n       // TODO(b/333750146): Support this case instead of bailing here\n@@ -2193,7 +2193,7 @@ AdjustShardingWithPartialMeshShapePerElement(\n                 ? sharding.tile_assignment().num_dimensions() - 1\n                 : sharding.tile_assignment().num_dimensions();\n   for (int i = 0; i < end; ++i) {\n-    if (sharding.tile_assignment().dim(i) == 1) {\n+    if (sharding.dimension(i) == 1) {\n       new_tile_assignment_dimensions.push_back(1);\n       continue;\n     }\n@@ -2206,7 +2206,7 @@ AdjustShardingWithPartialMeshShapePerElement(\n       }\n       product *= original_device_mesh.dim(axes[mesh_axis_idx]);\n       mesh_axis_idx++;\n-    } while (product < sharding.tile_assignment().dim(i));\n+    } while (product < sharding.dimension(i));\n     new_tile_assignment_dimensions.push_back(partial_product);\n   }\n   int64_t total_devices_considered = Product(new_tile_assignment_dimensions);\n@@ -2544,7 +2544,7 @@ bool IsShardingMisaligned(const HloSharding& sharding, const Shape& shape) {\n \n   for (size_t i = 0; i < shape.dimensions().size(); ++i) {\n     int64_t shape_dim = shape.dimensions()[i];\n-    int64_t sharding_dim = sharding.tile_assignment().dim(i);\n+    int64_t sharding_dim = sharding.dimension(i);\n     if (shape_dim % sharding_dim != 0) {\n       return true;\n     }"
        },
        {
            "sha": "61f994c7e8f5d968476cd2fdddb2a0c471b3e6fd",
            "filename": "third_party/xla/xla/hlo/ir/hlo_sharding.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -1182,7 +1182,7 @@ int64_t HloSharding::NumTiles(absl::Span<const int64_t> dims) const {\n   int64_t num_tiles = 1;\n   for (auto d : dims) {\n     CHECK(d < tile_assignment().num_dimensions());\n-    num_tiles *= tile_assignment().dim(d);\n+    num_tiles *= dimension(d);\n   }\n   return num_tiles;\n }"
        },
        {
            "sha": "37d09224a4b6a196dcb91f3943d65d9bd0b29282",
            "filename": "third_party/xla/xla/hlo/ir/hlo_sharding.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_sharding.h?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -508,6 +508,11 @@ class HloSharding {\n   // REQUIRES: !IsReplicated() && !IsTuple()\n   const TileAssignment& tile_assignment() const { return tile_assignment_; }\n \n+  // Returns number of shards in the given dimension.\n+  int64_t dimension(int64_t dim_index) const {\n+    return tile_assignment().dim(dim_index);\n+  }\n+\n   // Gets the subgroup types array.\n   // REQUIRES: !IsTuple()\n   const std::vector<OpSharding::Type>& subgroup_types() const {"
        },
        {
            "sha": "9f3afe49da1c639c6d2a6a45db14b6512eaacd12",
            "filename": "third_party/xla/xla/hlo/utils/hlo_sharding_util.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 54,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fhlo_sharding_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fhlo_sharding_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Futils%2Fhlo_sharding_util.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -231,8 +231,8 @@ bool IsSubTilingOrEqualSharding(const Shape& potential_sharded_shape,\n       potential_subsharding.tile_assignment().dimensions().end());\n   for (int64_t i = 0; i < tiled_data_rank; ++i) {\n     const auto shape_i = potential_sharded_shape.dimensions(i);\n-    const auto p_tile_dim_i = potential_subsharding.tile_assignment().dim(i);\n-    const auto s_tile_dim_i = sharding.tile_assignment().dim(i);\n+    const auto p_tile_dim_i = potential_subsharding.dimension(i);\n+    const auto s_tile_dim_i = sharding.dimension(i);\n     if (p_tile_dim_i < s_tile_dim_i) {\n       return false;\n     }\n@@ -276,8 +276,7 @@ bool IsSubTilingOrEqualSharding(const Shape& potential_sharded_shape,\n     std::vector<int> perm(reshape_dims.size());\n     absl::c_iota(perm, 0);\n     for (int64_t i = 0; i < tiled_data_rank; ++i) {\n-      if (potential_subsharding.tile_assignment().dim(i) !=\n-          sharding.tile_assignment().dim(i)) {\n+      if (potential_subsharding.dimension(i) != sharding.dimension(i)) {\n         auto element = perm[i + 1];\n         perm.erase(perm.begin() + i + 1);\n         perm.push_back(element);\n@@ -463,8 +462,8 @@ bool MergeShardingIfCompatible(const HloSharding& to_merge,\n   int64_t num_merge_groups = 1;\n   int64_t num_dst_groups = 1;\n   for (int64_t i = 0; i < to_merge.TiledDataRank(); ++i) {\n-    int64_t merge_dim = to_merge.tile_assignment().dim(i);\n-    int64_t dst_dim = dst->tile_assignment().dim(i);\n+    int64_t merge_dim = to_merge.dimension(i);\n+    int64_t dst_dim = dst->dimension(i);\n     num_merge_groups *= merge_dim;\n     num_dst_groups *= dst_dim;\n     if (dst_dim == merge_dim) {\n@@ -498,8 +497,8 @@ bool MergeShardingIfCompatible(const HloSharding& to_merge,\n   int64_t replication;\n \n   if (to_merge_man_dim >= 0) {\n-    int64_t man_group_size = to_merge.tile_assignment().dim(to_merge_man_dim);\n-    if (man_group_size != dst->tile_assignment().dim(dst_man_dim)) {\n+    int64_t man_group_size = to_merge.dimension(to_merge_man_dim);\n+    if (man_group_size != dst->dimension(dst_man_dim)) {\n       return false;\n     }\n     merge_old_tile_dim.push_back(man_group_size);\n@@ -546,7 +545,7 @@ bool MergeShardingIfCompatible(const HloSharding& to_merge,\n             DimensionVector& perm,\n             const int64_t perm_counter) -> std::vector<TileAssignment> {\n       if (!sharding.HasPartialReplication() ||\n-          sharding.tile_assignment().dim(sharding.SubgroupReplicationDim()) ==\n+          sharding.dimension(sharding.SubgroupReplicationDim()) ==\n               replication) {\n         return {sharding.tile_assignment()};\n       }\n@@ -623,11 +622,11 @@ bool MergeShardingIfCompatible(const HloSharding& to_merge,\n                                int64_t manual_dim) {\n       int64_t group_id = 0;\n       for (int64_t i = 0; i < to_merge.TiledDataRank(); ++i) {\n-        group_id *= sharding.tile_assignment().dim(i);\n+        group_id *= sharding.dimension(i);\n         group_id += tile_indices[i];\n       }\n       if (manual_dim >= 0) {\n-        group_id *= sharding.tile_assignment().dim(manual_dim);\n+        group_id *= sharding.dimension(manual_dim);\n         group_id += tile_indices[manual_dim];\n       }\n       return group_id;\n@@ -641,12 +640,12 @@ bool MergeShardingIfCompatible(const HloSharding& to_merge,\n               to_merge.tile_assignment().num_dimensions());\n           DimensionVector dst_index(dst->tile_assignment().num_dimensions());\n           for (int64_t i = 0; i < to_merge.TiledDataRank(); ++i) {\n-            if (to_merge.tile_assignment().dim(i) == 1) {\n+            if (to_merge.dimension(i) == 1) {\n               to_merge_index[i] = 0;\n             } else {\n               to_merge_index[i] = indices[i];\n             }\n-            if (dst->tile_assignment().dim(i) == 1) {\n+            if (dst->dimension(i) == 1) {\n               dst_index[i] = 0;\n             } else {\n               dst_index[i] = indices[i];\n@@ -928,7 +927,7 @@ std::optional<HloSharding> ReshapeSharding(const Shape& source_shape,\n       return false;\n     }\n     source_size = source_shape.dimensions()[source_index];\n-    source_tile_dim = source_sharding.tile_assignment().dim(source_index);\n+    source_tile_dim = source_sharding.dimension(source_index);\n     return true;\n   };\n   auto advance_target = [&]() {\n@@ -1009,9 +1008,8 @@ std::optional<HloSharding> ReshapeSharding(const Shape& source_shape,\n \n   for (int64_t i = sharding.TiledDataRank();\n        i < sharding.tile_assignment().num_dimensions(); ++i) {\n-    target_tile_dims.push_back(i == sharding.SubgroupReplicationDim()\n-                                   ? 1\n-                                   : sharding.tile_assignment().dim(i));\n+    target_tile_dims.push_back(\n+        i == sharding.SubgroupReplicationDim() ? 1 : sharding.dimension(i));\n   }\n \n   auto subgroup_types = sharding.subgroup_types();\n@@ -1068,7 +1066,7 @@ HloSharding PropagateShardingThroughReshape(const Shape& source_shape,\n          end_dim > start_dim; --end_dim) {\n       DimensionVector grouped_tiling_dims(source_shape.dimensions().size(), 1);\n       for (int64_t i = start_dim; i < end_dim; ++i) {\n-        grouped_tiling_dims[i] = sharding.tile_assignment().dim(i);\n+        grouped_tiling_dims[i] = sharding.dimension(i);\n       }\n       HloSharding grouped_sharding =\n           HloSharding::Tile(TileAssignment(grouped_tiling_dims));\n@@ -1186,11 +1184,11 @@ HloSharding PropagateShardingAlongDimsAndReplicateOthers(\n   std::vector<int64_t> target_tile_dims(target_shape_rank, 1);\n   for (int i = 0; i < source_dims.size(); ++i) {\n     target_tile_dims[target_dims[i]] =\n-        source_sharding.tile_assignment().dim(source_dims[i]);\n+        source_sharding.dimension(source_dims[i]);\n   }\n   for (int64_t i = replicate_other_dims.TiledDataRank();\n        i < replicate_other_dims.tile_assignment().num_dimensions(); ++i) {\n-    target_tile_dims.push_back(replicate_other_dims.tile_assignment().dim(i));\n+    target_tile_dims.push_back(replicate_other_dims.dimension(i));\n   }\n \n   auto target_tile_assignment =\n@@ -1250,8 +1248,8 @@ HloSharding GatherEffectiveOutputSharding(const HloInstruction& hlo) {\n   int64_t num_elements = 1;\n   for (int64_t i = 0; i < hlo.shape().dimensions().size(); ++i) {\n     if (!absl::c_binary_search(dnums.offset_dims(), i)) {\n-      tile_assignment_dims[i] = hlo.sharding().tile_assignment().dim(i);\n-      num_elements *= hlo.sharding().tile_assignment().dim(i);\n+      tile_assignment_dims[i] = hlo.sharding().dimension(i);\n+      num_elements *= hlo.sharding().dimension(i);\n     } else {\n       tile_assignment_dims[i] = 1;\n     }\n@@ -1281,7 +1279,7 @@ HloSharding GatherEffectiveOutputSharding(const HloInstruction& hlo) {\n       slice_limits(hlo.shape().dimensions().size());\n   for (int64_t i = 0; i < hlo.shape().dimensions().size(); ++i) {\n     if (!absl::c_binary_search(dnums.offset_dims(), i)) {\n-      slice_limits[i] = hlo.sharding().tile_assignment().dim(i);\n+      slice_limits[i] = hlo.sharding().dimension(i);\n     } else {\n       slice_limits[i] = 1;\n     }\n@@ -1342,7 +1340,7 @@ HloSharding ScatterEffectiveIndexSharding(\n   int64_t index_dim = 0;\n   for (int64_t i = 0; i < scatter.shape().dimensions().size(); ++i) {\n     if (absl::c_binary_search(dnums.inserted_window_dims(), i)) {\n-      num_elements *= index_sharding.tile_assignment().dim(index_dim);\n+      num_elements *= index_sharding.dimension(index_dim);\n       index_dim++;\n     }\n   }\n@@ -1365,7 +1363,7 @@ HloSharding ScatterEffectiveIndexSharding(\n   DimensionVector slice_starts(index_rank, 0LL), slice_limits(index_rank);\n   for (int64_t i = 0; i < index_rank; ++i) {\n     if (i < index_dim) {\n-      slice_limits[i] = index_sharding.tile_assignment().dim(i);\n+      slice_limits[i] = index_sharding.dimension(i);\n     } else {\n       slice_limits[i] = 1;\n     }\n@@ -1390,8 +1388,8 @@ HloSharding ScatterEffectiveDataSharding(const HloSharding& data_sharding,\n   for (int64_t i = 0; i < scatter.shape().dimensions().size(); ++i) {\n     if (absl::c_binary_search(dnums.inserted_window_dims(), i)) {\n       CHECK_LT(i, data_rank);\n-      tile_assignment_dims[i] = data_sharding.tile_assignment().dim(i);\n-      num_elements *= data_sharding.tile_assignment().dim(i);\n+      tile_assignment_dims[i] = data_sharding.dimension(i);\n+      num_elements *= data_sharding.dimension(i);\n     }\n   }\n   if (num_elements == data_sharding.tile_assignment().num_elements()) {\n@@ -1810,7 +1808,7 @@ HloSharding PartiallyReplicateTiledShardingOnDims(\n       continue;\n     }\n     valid_dims_to_replicate.push_back(dim);\n-    group_count *= sharding.tile_assignment().dim(dim);\n+    group_count *= sharding.dimension(dim);\n   }\n   if (group_count == 1) {\n     return sharding;\n@@ -1880,7 +1878,7 @@ HloSharding ReplicateAllDataDims(const HloSharding& sharding,\n     DimensionVector new_tile_shape(data_rank, 1);\n     for (int64_t i = result.TiledDataRank();\n          i < result.tile_assignment().num_dimensions(); ++i) {\n-      new_tile_shape.push_back(result.tile_assignment().dim(i));\n+      new_tile_shape.push_back(result.dimension(i));\n     }\n     auto tile = result.tile_assignment().Reshape(new_tile_shape);\n     result = HloSharding::Subgroup(tile, result.subgroup_types());\n@@ -1898,9 +1896,9 @@ HloSharding RemoveShapeDimensions(const HloSharding& sharding,\n                          dims_to_remove.size());\n   for (int64_t i = 0; i < sharding.tile_assignment().num_dimensions(); ++i) {\n     if (absl::c_linear_search(dims_to_remove, i)) {\n-      CHECK_EQ(sharding.tile_assignment().dim(i), 1);\n+      CHECK_EQ(sharding.dimension(i), 1);\n     } else {\n-      new_tile_shape.push_back(sharding.tile_assignment().dim(i));\n+      new_tile_shape.push_back(sharding.dimension(i));\n     }\n   }\n   auto new_tile = sharding.tile_assignment().Reshape(new_tile_shape);\n@@ -1948,7 +1946,7 @@ std::optional<HloSharding> TransposeShardingWithCollapsedDims(\n   DimensionVector perm(src_to_tgt.size());\n   for (int64_t i = 0; i < src_non_subgroup_dims; ++i) {\n     if (src_to_tgt[i] < 0) {\n-      if (source.tile_assignment().dim(i) > 1) {\n+      if (source.dimension(i) > 1) {\n         return std::nullopt;\n       }\n       perm[src_non_subgroup_dims - skipped_src_dims] = i;\n@@ -1971,7 +1969,7 @@ std::optional<HloSharding> TransposeShardingWithCollapsedDims(\n       if (i >= tgt_non_subgroup_dims) {\n         dim += skipped_src_dims;\n       }\n-      tgt_tiles[i] = tgt_sharding.tile_assignment().dim(dim);\n+      tgt_tiles[i] = tgt_sharding.dimension(dim);\n     }\n   }\n   auto reshape_tiles = tgt_sharding.tile_assignment().Reshape(tgt_tiles);\n@@ -2348,16 +2346,14 @@ GroupedSharding GroupShardingOnDims(const HloSharding& sharding,\n       sharding.tile_assignment().num_dimensions());\n   for (int64_t i = 0; i < decomposed_tiling_dims.size(); ++i) {\n     // Set default values for group_dim_size and group_dim_shard.\n-    decomposed_tiling_dims[i] =\n-        std::make_pair(1, sharding.tile_assignment().dim(i));\n+    decomposed_tiling_dims[i] = std::make_pair(1, sharding.dimension(i));\n   }\n \n   DimensionVector group_dim_sizes(group_dims.size());\n   for (int64_t i = 0; i < group_dims.size(); ++i) {\n-    CHECK_EQ(\n-        sharding.tile_assignment().dim(group_dims[i]) % group_dim_shards[i], 0);\n+    CHECK_EQ(sharding.dimension(group_dims[i]) % group_dim_shards[i], 0);\n     group_dim_sizes[i] =\n-        sharding.tile_assignment().dim(group_dims[i]) / group_dim_shards[i];\n+        sharding.dimension(group_dims[i]) / group_dim_shards[i];\n \n     decomposed_tiling_dims[group_dims[i]].first = group_dim_sizes[i];\n     decomposed_tiling_dims[group_dims[i]].second = group_dim_shards[i];\n@@ -2484,11 +2480,11 @@ GroupedSharding GroupShardingOnReplicatedDim(\n             ? sharding.tile_assignment().dimensions().back()\n             : 1;\n \n-    const int64_t max_replicable_dimensions = absl::c_accumulate(\n-        replicable_dims, reps_on_last_tile_dim,\n-        [&](int64_t product, int64_t dim) {\n-          return product * sharding.tile_assignment().dim(dim);\n-        });\n+    const int64_t max_replicable_dimensions =\n+        absl::c_accumulate(replicable_dims, reps_on_last_tile_dim,\n+                           [&](int64_t product, int64_t dim) {\n+                             return product * sharding.dimension(dim);\n+                           });\n \n     if (max_replicable_dimensions % num_groups == 0 &&\n         num_groups % reps_on_last_tile_dim == 0) {\n@@ -2501,8 +2497,8 @@ GroupedSharding GroupShardingOnReplicatedDim(\n           tile_dims.push_back(1);\n         }\n         for (auto replicable_dim : replicable_dims) {\n-          for (auto factor : PrimeFactorization(\n-                   sharding.tile_assignment().dim(replicable_dim))) {\n+          for (auto factor :\n+               PrimeFactorization(sharding.dimension(replicable_dim))) {\n             if (dimensions_to_borrow % factor == 0) {\n               tile_dims[replicable_dim] /= factor;\n               tile_dims.back() *= factor;\n@@ -2832,7 +2828,7 @@ bool DeviceGroupsAreMatch(GroupedSharding& lhs, GroupedSharding& rhs,\n HloSharding SplitShardingDimension(const HloSharding& sharding,\n                                    int64_t dimension, int64_t new_dim_size) {\n   CHECK_GT(sharding.TiledDataRank(), dimension);\n-  CHECK_EQ(sharding.tile_assignment().dim(dimension) % new_dim_size, 0)\n+  CHECK_EQ(sharding.dimension(dimension) % new_dim_size, 0)\n       << \"dim size \" << new_dim_size;\n   DimensionVector dimensions(sharding.tile_assignment().dimensions().begin(),\n                              sharding.tile_assignment().dimensions().end());\n@@ -2890,7 +2886,7 @@ std::optional<int64_t> GetFirstTargetDimToMoveShardingTiles(\n   if (shape.dimensions().size() < 2 || shape.dimensions(source_dim) == 1) {\n     return std::nullopt;\n   }\n-  if (!sharding.IsTiled() || sharding.tile_assignment().dim(source_dim) == 1) {\n+  if (!sharding.IsTiled() || sharding.dimension(source_dim) == 1) {\n     return std::nullopt;\n   }\n \n@@ -2902,8 +2898,7 @@ std::optional<int64_t> GetFirstTargetDimToMoveShardingTiles(\n       continue;\n     }\n     const int64_t merged_tile_dims =\n-        sharding.tile_assignment().dim(source_dim) *\n-        sharding.tile_assignment().dim(dim);\n+        sharding.dimension(source_dim) * sharding.dimension(dim);\n     if (shape.dimensions(dim) % merged_tile_dims == 0) {\n       return dim;\n     }\n@@ -2959,8 +2954,7 @@ Shape UntileLeafShape(const HloSharding& sharding, const Shape& shape) {\n   // sharding.TiledDataRank() == i < shape.dimensions_size() is not always true?\n   for (int64_t i = 0;\n        i < sharding.TiledDataRank() && i < shape.dimensions().size(); ++i) {\n-    result_shape.set_dimensions(\n-        i, shape.dimensions(i) * sharding.tile_assignment().dim(i));\n+    result_shape.set_dimensions(i, shape.dimensions(i) * sharding.dimension(i));\n   }\n   return result_shape;\n }\n@@ -2994,9 +2988,8 @@ Shape TileLeafShape(const HloSharding& sharding, const Shape& shape) {\n   Shape result_shape = shape;\n   for (int64_t i = 0;\n        i < sharding.TiledDataRank() && i < shape.dimensions().size(); ++i) {\n-    CHECK_EQ(shape.dimensions(i) % sharding.tile_assignment().dim(i), 0);\n-    result_shape.set_dimensions(\n-        i, shape.dimensions(i) / sharding.tile_assignment().dim(i));\n+    CHECK_EQ(shape.dimensions(i) % sharding.dimension(i), 0);\n+    result_shape.set_dimensions(i, shape.dimensions(i) / sharding.dimension(i));\n   }\n   return result_shape;\n }"
        },
        {
            "sha": "ca53c86728d44216487347432b2e98cdbe500cd0",
            "filename": "third_party/xla/xla/python/pjrt_ifrt/xla_sharding.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_sharding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_sharding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fpjrt_ifrt%2Fxla_sharding.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -208,7 +208,7 @@ HloSharding::Disassemble(\n \n     is_even_sharding = true;\n     for (int i = 0; i < tiled_data_rank; ++i) {\n-      if (shape.dims()[i] % xla_hlo_sharding_.tile_assignment().dim(i) != 0) {\n+      if (shape.dims()[i] % xla_hlo_sharding_.dimension(i) != 0) {\n         is_even_sharding = false;\n         break;\n       }"
        },
        {
            "sha": "495fb66f36c94520484b8c941a7d1cd55618d5f0",
            "filename": "third_party/xla/xla/service/sharding_propagation.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fsharding_propagation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fsharding_propagation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fsharding_propagation.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -1215,10 +1215,10 @@ bool InferConvolutionShardingFromOperands(HloInstruction* instruction,\n         }\n         for (const auto& dim : dims) {\n           if (lhs_or_rhs == 0) {\n-            partitions *= sharding.tile_assignment().dim(dim.lhs);\n+            partitions *= sharding.dimension(dim.lhs);\n           } else {\n             CHECK_EQ(lhs_or_rhs, 1);\n-            partitions *= sharding.tile_assignment().dim(dim.rhs);\n+            partitions *= sharding.dimension(dim.rhs);\n           }\n         }\n         return partitions;\n@@ -1292,7 +1292,7 @@ std::optional<HloSharding> InferBroadcastOperandSharding(\n   for (int64_t i = 0; i < instruction.shape().dimensions().size(); ++i) {\n     if (absl::c_count(instruction.dimensions(), i) == 0) {\n       dims_to_replicate.push_back(i);\n-      if (instruction.sharding().tile_assignment().dim(i) > 1) {\n+      if (instruction.sharding().dimension(i) > 1) {\n         needs_replication = true;\n       }\n     }\n@@ -1336,7 +1336,7 @@ bool InferReduceShardingFromOperand(HloInstruction* instruction,\n     if (operand->sharding().IsReplicated() ||\n         (!is_spmd &&\n          absl::c_any_of(instruction->dimensions(), [operand](int64_t dim) {\n-           return operand->sharding().tile_assignment().dim(dim) > 1;\n+           return operand->sharding().dimension(dim) > 1;\n          }))) {\n       // We are reducing along one of the sharded dimensions. We only\n       // support this in SPMD.\n@@ -1834,7 +1834,7 @@ std::optional<HloSharding> ShardingPropagation::GetShardingFromUser(\n         for (int64_t i = 0; i < target_tile_assignment_dimensions.size(); ++i) {\n           if (absl::c_find(dimensions, i) == dimensions.end()) {\n             target_tile_assignment_dimensions[i] =\n-                user_sharding.tile_assignment().dim(next_output_dim++);\n+                user_sharding.dimension(next_output_dim++);\n           } else {\n             target_tile_assignment_dimensions[i] = 1;\n           }\n@@ -2290,13 +2290,13 @@ bool ShardingPropagation::InferShardingFromOperands(\n         } else {\n           const int64_t source_dim = std::distance(dimensions.begin(), it);\n           target_tile_assignment_dimensions.push_back(\n-              op->sharding().tile_assignment().dim(source_dim));\n+              op->sharding().dimension(source_dim));\n         }\n       }\n       for (int64_t i = op->sharding().TiledDataRank();\n            i < op->sharding().tile_assignment().num_dimensions(); ++i) {\n         target_tile_assignment_dimensions.push_back(\n-            op->sharding().tile_assignment().dim(i));\n+            op->sharding().dimension(i));\n       }\n       auto new_tile_assignment = op->sharding().tile_assignment().Reshape(\n           target_tile_assignment_dimensions);\n@@ -2476,7 +2476,7 @@ bool ShardingPropagation::InferShardingFromOperands(\n       CHECK(sort);\n       const int64_t sort_dim = sort->sort_dimension();\n       if (!operand->sharding().IsTileMaximal() &&\n-          operand->sharding().tile_assignment().dim(sort_dim) != 1 &&\n+          operand->sharding().dimension(sort_dim) != 1 &&\n           !hlo_sharding_util::GetFirstTargetDimToMoveShardingTiles(\n                operand->shape(), operand->sharding(), sort_dim)\n                .has_value()) {\n@@ -3557,7 +3557,7 @@ absl::StatusOr<bool> ShardingPropagation::RunImpl(\n       }\n     }\n     for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-      if (shape.dimensions(i) % sharding.tile_assignment().dim(i) != 0) {\n+      if (shape.dimensions(i) % sharding.dimension(i) != 0) {\n         return false;\n       }\n     }"
        },
        {
            "sha": "98df9415e02f92bb901a5db166cce1efa17412c4",
            "filename": "third_party/xla/xla/service/spmd/custom_call_handler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fcustom_call_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fcustom_call_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fcustom_call_handler.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -103,8 +103,8 @@ absl::Status SpmdPartitioningVisitor::HandleCustomCallTopK(\n   const int64_t sort_dim = 1;\n \n   CHECK(sharding.IsTiled());\n-  const int64_t shard_count = sharding.tile_assignment().dim(sort_dim);\n-  const int64_t batch_dim_partition = sharding.tile_assignment().dim(batch_dim);\n+  const int64_t shard_count = sharding.dimension(sort_dim);\n+  const int64_t batch_dim_partition = sharding.dimension(batch_dim);\n \n   const int64_t input_size = hlo->operand(0)->shape().dimensions(sort_dim);\n   const int64_t batch_size = hlo->shape().tuple_shapes(0).dimensions(batch_dim);"
        },
        {
            "sha": "16b758812af2a1a6931f4ce194888ad667fc583b",
            "filename": "third_party/xla/xla/service/spmd/dot_handler.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fdot_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fdot_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fdot_handler.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -674,14 +674,13 @@ std::optional<WindowedEinsumConfig> GetWindowedEinsumConfiguration(\n     int lhs_non_windowing_sharded_dim_count = 0;\n     for (int64_t i = 0; i < lhs_tile_assignment.num_dimensions(); ++i) {\n       if (lhs_tile_assignment.dim(i) > 1 &&\n-          output_sharding.tile_assignment().dim(\n-              indices_map.lhs_to_output_indices[i]) == 1) {\n+          output_sharding.dimension(indices_map.lhs_to_output_indices[i]) ==\n+              1) {\n         lhs_windowing_dim = i;\n         ++lhs_windowing_dim_count;\n       }\n       if (lhs_tile_assignment.dim(i) > 1 &&\n-          output_sharding.tile_assignment().dim(\n-              indices_map.lhs_to_output_indices[i]) ==\n+          output_sharding.dimension(indices_map.lhs_to_output_indices[i]) ==\n               lhs_tile_assignment.dim(i)) {\n         lhs_non_windowing_sharded_dim = i;\n         ++lhs_non_windowing_sharded_dim_count;\n@@ -909,7 +908,7 @@ absl::StatusOr<HloInstruction*> EmitWindowedDotGeneral(\n   int64_t slice_sharding_dim = -1;\n   for (int64_t i = 0; i < slice_sharding->tile_assignment().num_dimensions();\n        ++i) {\n-    if (slice_sharding->tile_assignment().dim(i) > 1) {\n+    if (slice_sharding->dimension(i) > 1) {\n       slice_sharding_dim = i;\n       break;\n     }\n@@ -1975,7 +1974,7 @@ absl::StatusOr<HloInstruction*> PartitionBaseCase(\n       } else {\n         CHECK_EQ(e_config->windowed_op, WindowedEinsumOperand::LHS);\n         for (int64_t dim : e_config->windowing_dims) {\n-          loop_partitions *= lhs_sharding.tile_assignment().dim(dim);\n+          loop_partitions *= lhs_sharding.dimension(dim);\n         }\n       }\n "
        },
        {
            "sha": "3919c494acae089fbb28ac301ba581e84f2b1b9a",
            "filename": "third_party/xla/xla/service/spmd/gather_scatter_handler.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 7,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fgather_scatter_handler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fgather_scatter_handler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fgather_scatter_handler.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -109,8 +109,7 @@ GatherScatterOperandPartitionedOnTrivialSliceDims(\n   int64_t trivial_slice_dims_partitions = 1;\n   for (int64_t dim : index_map) {\n     if (slice_size[dim] == 1) {\n-      trivial_slice_dims_partitions *=\n-          operand.sharding().tile_assignment().dim(dim);\n+      trivial_slice_dims_partitions *= operand.sharding().dimension(dim);\n       slice_dims.push_back(dim);\n     }\n   }\n@@ -273,7 +272,7 @@ IndexBoundsForGatherScatterOperandPartitionedOnTrivialSliceDims(\n   std::vector<HloInstruction*> max_indices;\n   for (int64_t i = 0; i < index_map.size(); ++i) {\n     int64_t dim = index_map[i];\n-    int64_t partitions = operand.sharding().tile_assignment().dim(dim);\n+    int64_t partitions = operand.sharding().dimension(dim);\n     if (partitions == 1 || !absl::c_linear_search(trivial_slice_dims, dim)) {\n       min_indices.push_back(CreateR0WithType<int32_t>(indices_type, 0, b));\n       max_indices.push_back(CreateR0WithType<int32_t>(\n@@ -447,7 +446,7 @@ absl::StatusOr<HloInstruction*> PartitionGatherOperandPassthroughDimensions(\n     const int64_t num_tiles = operand.sharding().TotalNumTiles();\n     absl::InlinedVector<int64_t, 4> output_grouping_dims;\n     for (int64_t i = 0; i < maybe_passthrough->TiledDataRank(); ++i) {\n-      if (maybe_passthrough->tile_assignment().dim(i) != 1) {\n+      if (maybe_passthrough->dimension(i) != 1) {\n         output_grouping_dims.push_back(i);\n       }\n     }\n@@ -1356,7 +1355,7 @@ absl::StatusOr<HloInstruction*> PartitionScatterOperandPassthroughDimensions(\n     const int64_t num_tiles = operands[0].sharding().TotalNumTiles();\n     absl::InlinedVector<int64_t, 4> update_grouping_dims;\n     for (int64_t i = 0; i < maybe_passthrough->TiledDataRank(); ++i) {\n-      if (maybe_passthrough->tile_assignment().dim(i) != 1) {\n+      if (maybe_passthrough->dimension(i) != 1) {\n         update_grouping_dims.push_back(i);\n       }\n     }\n@@ -1884,8 +1883,7 @@ absl::Status SpmdPartitioningVisitor::HandleScatter(HloInstruction* hlo) {\n   // guaranteed by the scatter semantics.\n   for (auto i = 0; i != indices.num_dimensions(); ++i) {\n     if (indices.base_shape().dimensions(i) !=\n-        indices_sharding.tile_assignment().dim(i) *\n-            indices.hlo()->shape().dimensions(i)) {\n+        indices_sharding.dimension(i) * indices.hlo()->shape().dimensions(i)) {\n       // Reshard only when we know that some dimension is padded.\n       indices = indices.Replicate().Reshard(\n           indices_sharding, /*pad_value=*/LiteralUtil::CreateR0<int32_t>(-1));"
        },
        {
            "sha": "c0d7c10c20f47a5850a508c719cd6bca05827db4",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner.cc",
            "status": "modified",
            "additions": 72,
            "deletions": 89,
            "changes": 161,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -614,9 +614,8 @@ PartitionedHlo PartitionedHlo::ReshardNoCache(\n         // dims first.\n         std::vector<int64_t> equal_dims;\n         for (int64_t dim = 0; dim < hlo_->shape().dimensions().size(); ++dim) {\n-          if (sharding().tile_assignment().dim(dim) == 1 ||\n-              target.tile_assignment().dim(dim) !=\n-                  sharding().tile_assignment().dim(dim)) {\n+          if (sharding().dimension(dim) == 1 ||\n+              target.dimension(dim) != sharding().dimension(dim)) {\n             continue;\n           }\n           equal_dims.push_back(dim);\n@@ -735,8 +734,7 @@ HloInstruction* PartitionedHlo::PadWithValueHlo(\n     if (absl::c_linear_search(left_padded_dims, dim)) {\n       direction = ComparisonDirection::kGe;\n       index_limit =\n-          index_shape.dimensions(dim) * sharding.tile_assignment().dim(dim) -\n-          index_limit;\n+          index_shape.dimensions(dim) * sharding.dimension(dim) - index_limit;\n     }\n     auto limit = state_.b->AddInstruction(HloInstruction::CreateConstant(\n         LiteralUtil::CreateR0<int32_t>(index_limit)));\n@@ -750,7 +748,7 @@ HloInstruction* PartitionedHlo::PadWithValueHlo(\n   auto offsets = MakePartitionOffsets(base_shape_, sharding,\n                                       state_.partition_id, state_.b);\n   for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-    if (base_shape_.dimensions(i) % sharding.tile_assignment().dim(i) == 0 ||\n+    if (base_shape_.dimensions(i) % sharding.dimension(i) == 0 ||\n         absl::c_linear_search(skipped_dims, i)) {\n       continue;\n     }\n@@ -861,7 +859,7 @@ PartitionedHlo::ReshardAsWindowedInput(const Window& window,\n   }\n   for (int64_t i = 0; i < base_shape_.dimensions().size(); ++i) {\n     // Do not pad non-partitioned dimensions.\n-    int64_t shard_count = target.tile_assignment().dim(i);\n+    int64_t shard_count = target.dimension(i);\n     trimmed_target_sharding_tile_shape[i] = shard_count;\n     if (shard_count == 1) {\n       offsets_on_padded_shape[i] = state_.b->AddInstruction(\n@@ -1137,7 +1135,7 @@ PartitionedHlo::ReshardAsWindowedInput(const Window& window,\n       // Do not pad non-partitioned dimensions or partitioned dimensions that\n       // are already sharded in a way that where the windowed sharding matches\n       // the sharding we want.\n-      if (target.tile_assignment().dim(i) == 1 ||\n+      if (target.dimension(i) == 1 ||\n           (can_leave_dimension_partitioned[i] && !sharding().IsReplicated())) {\n         // For can_leave_dimension_partitioned[i], we also check sharding() is\n         // not replicated, because handle_all_windowed_dimensions_are_replicated\n@@ -1250,7 +1248,7 @@ PartitionedHlo::ReshardAsWindowedInput(const Window& window,\n   // concat in the previous dimension, which is not optimal. We should generate\n   // halos only concating slices, instead of slicing concats.\n   for (int dim = 0; dim < base_shape_.dimensions().size(); ++dim) {\n-    int64_t shard_count = halo_exchange_target->tile_assignment().dim(dim);\n+    int64_t shard_count = halo_exchange_target->dimension(dim);\n     if (shard_count == 1 || can_leave_dimension_partitioned[dim]) {\n       continue;\n     }\n@@ -1358,7 +1356,7 @@ HloInstruction* PartitionedHlo::ReplicatePartial(\n   // broadcast_dims where the full size is less than half of allgather size, and\n   // we will use dus->allreduce on them.\n   for (int64_t i : dims) {\n-    int64_t partitions = sharding().tile_assignment().dim(i);\n+    int64_t partitions = sharding().dimension(i);\n     if (partitions == 1) {\n       continue;\n     }\n@@ -1432,7 +1430,7 @@ HloInstruction* PartitionedHlo::ReplicatePartial(\n         LiteralUtil::Zero(shard_shape.element_type())));\n     std::vector<int64_t> masking_dims;\n     for (int64_t dim : dus_ar_dims) {\n-      if (shard_shape.dimensions(dim) * sharding().tile_assignment().dim(dim) !=\n+      if (shard_shape.dimensions(dim) * sharding().dimension(dim) !=\n           base_shape().dimensions(dim)) {\n         // DUS will be out-of-bound and offset will be clamped, so we need to\n         // mask this dim with 0.\n@@ -1499,8 +1497,8 @@ PartitionedHlo::ReshardToPartialReplicateWithAllGather(\n   std::vector<int64_t> replicate_dims;\n   std::vector<int64_t> replicate_factors;\n   for (int64_t dim = 0; dim < rank; dim++) {\n-    int64_t replicate_factor = temp_sharding.tile_assignment().dim(dim) /\n-                               target.tile_assignment().dim(dim);\n+    int64_t replicate_factor =\n+        temp_sharding.dimension(dim) / target.dimension(dim);\n     if (replicate_factor > 1) {\n       replicate_dims.push_back(dim);\n       replicate_factors.push_back(replicate_factor);\n@@ -1563,13 +1561,11 @@ PartitionedHlo::ReshardFromPartialReplicateWithDynamicSlice(\n   tiling_dim_factors.reserve(target.tile_assignment().num_dimensions());\n   const auto& temp_target_sharding = target_compatible_sharding.value();\n   for (int64_t dim = 0; dim < rank; dim++) {\n-    if (temp_target_sharding.tile_assignment().dim(dim) >\n-        sharding().tile_assignment().dim(dim)) {\n+    if (temp_target_sharding.dimension(dim) > sharding().dimension(dim)) {\n       expand_tile_dims.push_back(dim);\n     }\n-    tiling_dim_factors.emplace_back(\n-        temp_target_sharding.tile_assignment().dim(dim) /\n-        sharding().tile_assignment().dim(dim));\n+    tiling_dim_factors.emplace_back(temp_target_sharding.dimension(dim) /\n+                                    sharding().dimension(dim));\n   }\n \n   // Add another dimension in tiling_dim_factors if target is partial replicate.\n@@ -1593,8 +1589,7 @@ PartitionedHlo::ReshardFromPartialReplicateWithDynamicSlice(\n   auto padded_base_shape = shard_shape;\n   for (int64_t i = 0; i < padded_base_shape.dimensions().size(); ++i) {\n     padded_base_shape.set_dimensions(\n-        i, padded_base_shape.dimensions(i) *\n-               temp_target_sharding.tile_assignment().dim(i));\n+        i, padded_base_shape.dimensions(i) * temp_target_sharding.dimension(i));\n   }\n   auto offsets = MakePartitionOffsets(padded_base_shape, temp_target_sharding,\n                                       state_.partition_id, state_.b);\n@@ -1724,8 +1719,8 @@ PartitionedHlo PartitionedHlo::ReshardWithAllToAll(\n   VLOG(5) << \"Source dim: \" << source_dim;\n   VLOG(5) << \"Target dim: \" << target_dim;\n   CHECK_NE(source_dim, target_dim);\n-  const int64_t group_size = sharding().tile_assignment().dim(source_dim) /\n-                             sharding().tile_assignment().dim(target_dim);\n+  const int64_t group_size =\n+      sharding().dimension(source_dim) / sharding().dimension(target_dim);\n   VLOG(5) << \"Group size: \" << group_size;\n   const HloSharding temp_target =\n       GetAllToAllSharding(sharding(), {source_dim}, {target_dim});\n@@ -1736,9 +1731,8 @@ PartitionedHlo PartitionedHlo::ReshardWithAllToAll(\n     pd->set_edge_padding_low(0);\n     if (i == target_dim) {\n       pd->set_edge_padding_high(\n-          RoundUpTo(base_shape_.dimensions(i),\n-                    temp_target.tile_assignment().dim(i)) -\n-          hlo_->shape().dimensions(i) * sharding().tile_assignment().dim(i));\n+          RoundUpTo(base_shape_.dimensions(i), temp_target.dimension(i)) -\n+          hlo_->shape().dimensions(i) * sharding().dimension(i));\n     } else {\n       pd->set_edge_padding_high(0);\n     }\n@@ -1830,10 +1824,10 @@ PartitionedHlo PartitionedHlo::ReshardWithAllToAll(\n   auto current_source_base_padded_shape = base_shape_;\n   padded_source_base_shape.set_dimensions(\n       source_dim, RoundUpTo(base_shape_.dimensions(source_dim),\n-                            temp_target.tile_assignment().dim(source_dim)));\n+                            temp_target.dimension(source_dim)));\n   current_source_base_padded_shape.set_dimensions(\n-      source_dim, hlo_->shape().dimensions(source_dim) *\n-                      sharding().tile_assignment().dim(source_dim));\n+      source_dim,\n+      hlo_->shape().dimensions(source_dim) * sharding().dimension(source_dim));\n \n   VLOG(5) << \"Original sharded shape: \" << hlo_->shape();\n   VLOG(5) << \"Base shape: \" << base_shape_.ToString();\n@@ -1877,17 +1871,15 @@ PartitionedHlo PartitionedHlo::TryMultipleSourceTargetDims(\n     bool dims_already_seen =\n         seen_dims.contains(source_dim) || seen_dims.contains(target_dim);\n     bool source_dim_divisible =\n-        base_shape_.dimensions(source_dim) %\n-            sharding().tile_assignment().dim(source_dim) ==\n+        base_shape_.dimensions(source_dim) % sharding().dimension(source_dim) ==\n         0;\n-    bool target_dim_divisible = base_shape_.dimensions(target_dim) %\n-                                    target.tile_assignment().dim(target_dim) ==\n-                                0;\n+    bool target_dim_divisible =\n+        base_shape_.dimensions(target_dim) % target.dimension(target_dim) == 0;\n     if (!dims_already_seen && source_dim_divisible && target_dim_divisible) {\n       eligible_source_dims.push_back(source_dim);\n       eligible_target_dims.push_back(target_dim);\n-      group_sizes.push_back(sharding().tile_assignment().dim(source_dim) /\n-                            sharding().tile_assignment().dim(target_dim));\n+      group_sizes.push_back(sharding().dimension(source_dim) /\n+                            sharding().dimension(target_dim));\n       seen_dims.insert(source_dim);\n       seen_dims.insert(target_dim);\n     } else {\n@@ -2071,8 +2063,8 @@ PatternMatchMergeOrSplitSharding(const Shape& base_shape,\n   std::vector<int64_t> diff_index_1;\n   std::vector<int64_t> diff_index_2;\n   for (int64_t i = 0; i < target.TiledDataRank(); ++i) {\n-    int64_t si = source.tile_assignment().dim(i);\n-    int64_t ti = target.tile_assignment().dim(i);\n+    int64_t si = source.dimension(i);\n+    int64_t ti = target.dimension(i);\n     if (si == ti) {\n       continue;\n     }\n@@ -2093,21 +2085,19 @@ PatternMatchMergeOrSplitSharding(const Shape& base_shape,\n   // Iterate combination of diff_index_1 and diff_index_2.\n   for (int64_t i : diff_index_2) {\n     for (int64_t j : diff_index_1) {\n-      if (source.tile_assignment().dim(i) * source.tile_assignment().dim(j) !=\n-          target.tile_assignment().dim(i) * target.tile_assignment().dim(j)) {\n+      if (source.dimension(i) * source.dimension(j) !=\n+          target.dimension(i) * target.dimension(j)) {\n         continue;\n       }\n-      int64_t new_dim_size = std::min(source.tile_assignment().dim(i),\n-                                      target.tile_assignment().dim(i));\n+      int64_t new_dim_size = std::min(source.dimension(i), target.dimension(i));\n       return CreateSplitShardingTuple(source, target, i, new_dim_size);\n     }\n   }\n \n   // Iterate each index in diff_index_2.\n   for (int64_t i : diff_index_2) {\n-    if (source.tile_assignment().dim(i) > target.tile_assignment().dim(i)) {\n-      return CreateSplitShardingTuple(source, target, i,\n-                                      target.tile_assignment().dim(i));\n+    if (source.dimension(i) > target.dimension(i)) {\n+      return CreateSplitShardingTuple(source, target, i, target.dimension(i));\n     }\n   }\n \n@@ -2126,13 +2116,13 @@ std::optional<HloSharding> PatternMatchPartiallyReplicateDim(\n   const int64_t target_replicated_dim = target.SubgroupReplicationDim();\n   const int64_t source_replicated_size =\n       source.HasPartialReplication()\n-          ? source.tile_assignment().dim(source.SubgroupReplicationDim())\n+          ? source.dimension(source.SubgroupReplicationDim())\n           : 1;\n   CHECK_NE(target_replicated_dim, -1) << \"Expected replicated dim\";\n   for (int i = 0; i < source.TiledDataRank(); ++i) {\n-    if (source.tile_assignment().dim(i) == 1 ||\n-        source.tile_assignment().dim(i) * source_replicated_size !=\n-            target.tile_assignment().dim(target_replicated_dim)) {\n+    if (source.dimension(i) == 1 ||\n+        source.dimension(i) * source_replicated_size !=\n+            target.dimension(target_replicated_dim)) {\n       continue;\n     }\n     auto replicated_sharding =\n@@ -2154,11 +2144,10 @@ PartitionedHlo SplitReshapeHelper(const PartitionedHlo& to_reshape,\n   std::vector<int64_t> base_shape_dim(\n       to_reshape.base_shape().dimensions().begin(),\n       to_reshape.base_shape().dimensions().end());\n-  base_shape_dim.insert(\n-      base_shape_dim.begin() + dim_to_split + 1,\n-      dim_size * target_sharding.tile_assignment().dim(dim_to_split + 1));\n+  base_shape_dim.insert(base_shape_dim.begin() + dim_to_split + 1,\n+                        dim_size * target_sharding.dimension(dim_to_split + 1));\n   base_shape_dim[dim_to_split] /=\n-      dim_size * target_sharding.tile_assignment().dim(dim_to_split + 1);\n+      dim_size * target_sharding.dimension(dim_to_split + 1);\n   Shape shape = ShapeUtil::MakeShape(original_shape.element_type(), shape_dim);\n   HloInstruction* reshaped_instr = to_reshape.state().b->AddInstruction(\n       HloInstruction::CreateReshape(shape, to_reshape.hlo()));\n@@ -2252,10 +2241,9 @@ std::optional<PartitionedHlo> PartitionedHlo::TryComplexReshardHandling(\n     // modified. Try to remove the partial replication to simplify the step from\n     // source to target sharding.\n     for (int64_t i = 0; i < target.tile_assignment().num_dimensions(); ++i) {\n-      if (target.tile_assignment().dim(i) !=\n-              sharding().tile_assignment().dim(i) &&\n-          sharding().tile_assignment().dim(i) == 1 &&\n-          target.tile_assignment().dim(i) % partial_repl_amount == 0) {\n+      if (target.dimension(i) != sharding().dimension(i) &&\n+          sharding().dimension(i) == 1 &&\n+          target.dimension(i) % partial_repl_amount == 0) {\n         first_different_dimension = i;\n         break;\n       }\n@@ -2310,22 +2298,21 @@ PartitionedHlo::ReshardPartialReplicateWithAllToAll(\n       partial_replicate_sharding.tile_assignment().dimensions().back();\n   if (((tile_sharding.tile_assignment().num_dimensions() + 1) !=\n        partial_replicate_sharding.tile_assignment().num_dimensions()) ||\n-      (partial_replicate_sharding.tile_assignment().dim(0) != 1)) {\n+      (partial_replicate_sharding.dimension(0) != 1)) {\n     return std::nullopt;\n   }\n   int to_replicate_dim = -1;\n   for (int i = tile_sharding.tile_assignment().num_dimensions() - 1; i >= 0;\n        --i) {\n-    if (tile_sharding.tile_assignment().dim(i) > 1 &&\n-        (to_replicate_dim == -1)) {\n-      if (tile_sharding.tile_assignment().dim(i) != num_replicas) {\n+    if (tile_sharding.dimension(i) > 1 && (to_replicate_dim == -1)) {\n+      if (tile_sharding.dimension(i) != num_replicas) {\n         return std::nullopt;\n       }\n       to_replicate_dim = i;\n     }\n \n-    if (tile_sharding.tile_assignment().dim(i) !=\n-        partial_replicate_sharding.tile_assignment().dim(i + 1)) {\n+    if (tile_sharding.dimension(i) !=\n+        partial_replicate_sharding.dimension(i + 1)) {\n       return std::nullopt;\n     }\n   }\n@@ -2953,8 +2940,7 @@ absl::Status SpmdPartitioningVisitor::HandleSort(HloInstruction* hlo) {\n     auto input = hlo->operand(0);\n     auto index = hlo->operand(1);\n     const HloSharding& input_sharding = input->sharding();\n-    const int64_t partition_count =\n-        input_sharding.tile_assignment().dim(sort_dim);\n+    const int64_t partition_count = input_sharding.dimension(sort_dim);\n     const int64_t input_size = input->shape().dimensions(sort_dim);\n     const auto element_type = input->shape().element_type();\n     const auto index_type = index->shape().element_type();\n@@ -3050,8 +3036,7 @@ absl::Status SpmdPartitioningVisitor::HandleSort(HloInstruction* hlo) {\n   // -- output tuple elements have the same sharding\n   // -- the current sharding is tiled\n   if (subshape.dimensions().size() > 1 && same_subsharding &&\n-      cur_sharding.IsTiled() &&\n-      cur_sharding.tile_assignment().dim(sort_dim) != 1) {\n+      cur_sharding.IsTiled() && cur_sharding.dimension(sort_dim) != 1) {\n     // Pick the new dimension to move the sharding into\n     std::vector<HloInstruction*> new_operands;\n     std::vector<HloSharding> new_shardings;\n@@ -3114,7 +3099,7 @@ absl::Status SpmdPartitioningVisitor::HandleSort(HloInstruction* hlo) {\n     return DefaultAction(hlo);\n   }\n   for (int64_t dim : hlo->dimensions()) {\n-    if (sharding.tile_assignment().dim(dim) > 1) {\n+    if (sharding.dimension(dim) > 1) {\n       return DefaultAction(hlo);\n     }\n   }\n@@ -3402,7 +3387,7 @@ absl::Status SpmdPartitioningVisitor::HandleReshape(HloInstruction* hlo) {\n       CHECK(operand_propagated_back->IsTiled());\n       Shape inner_operand_base_shape = operand_base_shape;\n       for (int64_t i = 0; i < operand_base_shape.dimensions().size(); ++i) {\n-        if (operand_propagated_back->tile_assignment().dim(i) > 1) {\n+        if (operand_propagated_back->dimension(i) > 1) {\n           operand_group_dims.push_back(i);\n           inner_operand_base_shape.set_dimensions(\n               i, operand.hlo()->shape().dimensions(i));\n@@ -3415,12 +3400,12 @@ absl::Status SpmdPartitioningVisitor::HandleReshape(HloInstruction* hlo) {\n           sharding.NumTiles() > propagated.NumTiles();\n       std::vector<int64_t> output_group_dims;\n       for (int64_t i = 0; i < inner_base_shape.dimensions().size(); ++i) {\n-        int64_t num_shards = propagated.tile_assignment().dim(i);\n+        int64_t num_shards = propagated.dimension(i);\n         if (num_shards > 1) {\n           inner_base_shape.set_dimensions(\n               i, CeilOfRatio(base_shape.dimensions(i), num_shards));\n           output_group_dims.push_back(i);\n-          if (num_shards != sharding.tile_assignment().dim(i)) {\n+          if (num_shards != sharding.dimension(i)) {\n             use_original_output_sharding = false;\n           }\n         }\n@@ -3468,7 +3453,7 @@ absl::Status SpmdPartitioningVisitor::HandleIota(HloInstruction* hlo) {\n     auto iota = b_.AddInstruction(HloInstruction::CreateIota(\n         MakePartitionedShape(hlo->shape(), sharding), dimension));\n \n-    if (sharding.tile_assignment().dim(dimension) > 1) {\n+    if (sharding.dimension(dimension) > 1) {\n       auto partition_ordinals = MakeTiledPartitionOrdinals(\n           sharding, MakePartitioningState().partition_id, &b_);\n       auto multiplier = b_.AddInstruction(HloInstruction::CreateConstant(\n@@ -3575,7 +3560,7 @@ absl::Status SpmdPartitioningVisitor::HandleAllReduce(HloInstruction* hlo) {\n             if (i == hlo->sharding().SubgroupManualDim()) {\n               continue;\n             }\n-            group_id *= hlo->sharding().tile_assignment().dim(i);\n+            group_id *= hlo->sharding().dimension(i);\n             group_id += indices[i];\n           }\n           partition_to_group_id[partition] = group_id;\n@@ -3690,7 +3675,7 @@ absl::Status SpmdPartitioningVisitor::HandleDynamicSlice(HloInstruction* hlo) {\n     return DefaultAction(hlo);\n   }\n   for (int64_t i = 0; i < hlo->shape().dimensions().size(); ++i) {\n-    if (hlo->sharding().tile_assignment().dim(i) != 1 &&\n+    if (hlo->sharding().dimension(i) != 1 &&\n         hlo->dynamic_slice_sizes()[i] !=\n             hlo->operand(0)->shape().dimensions(i)) {\n       // We currently do not partition the sliced dimensions.\n@@ -4247,7 +4232,7 @@ absl::Status SpmdPartitioningVisitor::HandleReduce(HloInstruction* hlo) {\n     const bool reduce_sharded_dimension =\n         !inputs[0].sharding().IsTileMaximal() &&\n         absl::c_any_of(hlo->dimensions(), [&](int64_t i) {\n-          return inputs[0].sharding().tile_assignment().dim(i) > 1;\n+          return inputs[0].sharding().dimension(i) > 1;\n         });\n     if (reduce_sharded_dimension) {\n       if (inputs[0].sharding().ReplicateOnLastTileDim()) {\n@@ -4272,7 +4257,7 @@ absl::Status SpmdPartitioningVisitor::HandleReduce(HloInstruction* hlo) {\n           for (int64_t dim : hlo->dimensions()) {\n             expanded_shape.set_dimensions(dim, 1);\n             all_gather_shape.set_dimensions(\n-                dim, inputs[0].sharding().tile_assignment().dim(dim));\n+                dim, inputs[0].sharding().dimension(dim));\n           }\n           auto reshape = b_.AddInstruction(\n               HloInstruction::CreateReshape(expanded_shape, gte));\n@@ -4765,7 +4750,7 @@ absl::Status SpmdPartitioningVisitor::HandleSelectAndScatter(\n   auto source_shard_hlo = source.hlo();\n   auto data_shard_hlo = operand.hlo();\n   for (int64_t i = 0; i < hlo->shape().dimensions().size(); ++i) {\n-    int64_t shard_count = hlo->sharding().tile_assignment().dim(i);\n+    int64_t shard_count = hlo->sharding().dimension(i);\n     if (shard_count == 1) {\n       continue;\n     }\n@@ -4854,7 +4839,7 @@ absl::Status SpmdPartitioningVisitor::HandleSelectAndScatter(\n \n   Window window_on_shard = hlo->window();\n   for (int64_t i = 0; i < window_on_shard.dimensions_size(); ++i) {\n-    int64_t shard_count = hlo->sharding().tile_assignment().dim(i);\n+    int64_t shard_count = hlo->sharding().dimension(i);\n     if (shard_count == 1) {\n       continue;\n     }\n@@ -4880,7 +4865,7 @@ absl::Status SpmdPartitioningVisitor::HandleSelectAndScatter(\n     std::vector<HloInstruction*> slice_offsets(shard_shape.dimensions().size(),\n                                                zero);\n     for (int64_t i = 0; i < window_on_shard.dimensions_size(); ++i) {\n-      if (hlo->sharding().tile_assignment().dim(i) == 1) {\n+      if (hlo->sharding().dimension(i) == 1) {\n         continue;\n       }\n       int64_t pad_low = hlo->window().dimensions(i).padding_low();\n@@ -4975,7 +4960,7 @@ absl::Status SpmdPartitioningVisitor::HandleRaggedDot(HloInstruction* hlo) {\n   std::vector<int64_t> sharded_lhs_contracting_dims;\n   if (lhs.sharding().IsTiled()) {\n     for (int64_t dim : dot_dnums.lhs_contracting_dimensions()) {\n-      if (lhs.sharding().tile_assignment().dim(dim) > 1) {\n+      if (lhs.sharding().dimension(dim) > 1) {\n         sharded_lhs_contracting_dims.push_back(dim);\n       }\n     }\n@@ -5241,7 +5226,7 @@ SpmdPartitioner::AllGatherShardsInternal(\n     HloInstruction* result = operand;\n     Shape result_shape = operand->shape();\n     for (auto it = selected_dims.rbegin(); it != selected_dims.rend(); ++it) {\n-      if (sharding.tile_assignment().dim(*it) == 1) {\n+      if (sharding.dimension(*it) == 1) {\n         continue;\n       }\n       // Attempt to generate partition groups in iota format. If infeasible,\n@@ -5311,8 +5296,7 @@ SpmdPartitioner::AllGatherShardsInternal(\n   // If n > 1 dimensions are partitioned, split the leading dimension to n.\n   std::vector<int64_t> tiled_dims;\n   for (int64_t i = 0; i < sharding.tile_assignment().num_dimensions(); ++i) {\n-    if (sharding.tile_assignment().dim(i) > 1 &&\n-        absl::c_linear_search(selected_dims, i)) {\n+    if (sharding.dimension(i) > 1 && absl::c_linear_search(selected_dims, i)) {\n       tiled_dims.push_back(i);\n     }\n   }\n@@ -5321,7 +5305,7 @@ SpmdPartitioner::AllGatherShardsInternal(\n     split_dim_shape.reserve(tiled_dims.size() +\n                             operand->shape().dimensions().size());\n     for (int64_t i : tiled_dims) {\n-      split_dim_shape.push_back(sharding.tile_assignment().dim(i));\n+      split_dim_shape.push_back(sharding.dimension(i));\n     }\n     for (int64_t dim : operand->shape().dimensions()) {\n       split_dim_shape.push_back(dim);\n@@ -5335,7 +5319,7 @@ SpmdPartitioner::AllGatherShardsInternal(\n   std::vector<int64_t> xpose_permutation(result->shape().dimensions().size());\n   int64_t split_dims_added = 0;\n   for (int64_t i = 0; i < xpose_permutation.size(); ++i) {\n-    if (sharding.tile_assignment().dim(i - split_dims_added) == 1 ||\n+    if (sharding.dimension(i - split_dims_added) == 1 ||\n         !absl::c_linear_search(selected_dims, i - split_dims_added)) {\n       xpose_permutation[i] = i + tiled_dims.size() - split_dims_added;\n     } else {\n@@ -5352,8 +5336,7 @@ SpmdPartitioner::AllGatherShardsInternal(\n   // Reshape to the desired shape.\n   auto ag_shape = operand->shape();\n   for (int64_t i : tiled_dims) {\n-    ag_shape.set_dimensions(\n-        i, ag_shape.dimensions(i) * sharding.tile_assignment().dim(i));\n+    ag_shape.set_dimensions(i, ag_shape.dimensions(i) * sharding.dimension(i));\n   }\n   result = b->AddInstruction(HloInstruction::CreateReshape(ag_shape, result));\n   return {result, ag};\n@@ -5400,7 +5383,7 @@ HloInstruction* SpmdPartitioner::AllReduceAlongShardingDimsInternal(\n \n   auto result = operand;\n   for (auto it = selected_dims.rbegin(); it != selected_dims.rend(); ++it) {\n-    if (sharding.tile_assignment().dim(*it) == 1) {\n+    if (sharding.dimension(*it) == 1) {\n       continue;\n     }\n     // Attempt to generate partition groups in iota format. If infeasible,\n@@ -5833,7 +5816,7 @@ absl::Status SpmdPartitioner::PreprocessHlos(\n               merged_padding = std::nullopt;\n               break;\n             }\n-            if (hlo->sharding().tile_assignment().dim(i) != 1 &&\n+            if (hlo->sharding().dimension(i) != 1 &&\n                 (dim.edge_padding_low() != 0 || dim.edge_padding_high() != 0) &&\n                 hlo->shape().dimensions(i) != operand->shape().dimensions(i)) {\n               // There are padding, slicing, and sharding on this dim.\n@@ -5863,7 +5846,7 @@ absl::Status SpmdPartitioner::PreprocessHlos(\n       }\n       if (hlo->opcode() == HloOpcode::kConcatenate) {\n         const int64_t dim = hlo->concatenate_dimension();\n-        if (hlo->sharding().tile_assignment().dim(dim) == 1) {\n+        if (hlo->sharding().dimension(dim) == 1) {\n           continue;\n         }\n "
        },
        {
            "sha": "7e336324ffa24d5b19843d8d5c335e95331fee11",
            "filename": "third_party/xla/xla/service/spmd/spmd_partitioner_util.cc",
            "status": "modified",
            "additions": 38,
            "deletions": 40,
            "changes": 78,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_partitioner_util.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -302,7 +302,7 @@ bool EvenlyPartitions(const Shape& shape, const HloSharding& sharding) {\n   }\n   if (shape.IsArray()) {\n     for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-      if (shape.dimensions(i) % sharding.tile_assignment().dim(i) != 0) {\n+      if (shape.dimensions(i) % sharding.dimension(i) != 0) {\n         return false;\n       }\n     }\n@@ -387,7 +387,7 @@ std::vector<HloInstruction*> MakePartitionOffsets(\n   std::vector<HloInstruction*> offsets;\n \n   for (int64_t i = 0; i < shape.dimensions().size(); ++i) {\n-    if (sharding.tile_assignment().dim(i) == 1 ||\n+    if (sharding.dimension(i) == 1 ||\n         (!dims.empty() && !absl::c_linear_search(dims, i))) {\n       offsets.push_back(b->AddInstruction(\n           HloInstruction::CreateConstant(LiteralUtil::Zero(S32))));\n@@ -429,7 +429,7 @@ Shape GetPaddedShapeForUnevenPartitioning(const Shape& base_shape,\n   Shape padded_base_shape = base_shape;\n   for (int64_t i = 0; i < padded_base_shape.dimensions().size(); ++i) {\n     padded_base_shape.set_dimensions(\n-        i, shard_shape.dimensions(i) * sharding.tile_assignment().dim(i));\n+        i, shard_shape.dimensions(i) * sharding.dimension(i));\n   }\n   return padded_base_shape;\n }\n@@ -705,8 +705,8 @@ std::optional<HloSharding> PartialReplicateReshardCompatibleSharding(\n   std::vector<int64_t> expand_tile_sizes;\n   int64_t num_expand_dims = 0;\n   for (int64_t dim = 0; dim < rank; dim++) {\n-    int64_t partial_tile_size = partial_sharding.tile_assignment().dim(dim);\n-    int64_t target_tile_size = target_sharding.tile_assignment().dim(dim);\n+    int64_t partial_tile_size = partial_sharding.dimension(dim);\n+    int64_t target_tile_size = target_sharding.dimension(dim);\n     if (target_tile_size % partial_tile_size != 0) {\n       return std::nullopt;\n     }\n@@ -783,8 +783,8 @@ std::optional<HloInstruction*> TileToPartialReplicateHaloExchange(\n   auto result = hlo;\n   auto hlo_shape = hlo->shape();\n   for (auto dim : replicate_dims) {\n-    int64_t src_shard_count = src_sharding.tile_assignment().dim(dim);\n-    int64_t dst_shard_count = dst_sharding.tile_assignment().dim(dim);\n+    int64_t src_shard_count = src_sharding.dimension(dim);\n+    int64_t dst_shard_count = dst_sharding.dimension(dim);\n     int64_t src_per_dst_shard_size =\n         padded_src_shape.dimensions(dim) / dst_shard_count;\n     // Calculate per shard size using the sharding to compare if dst_sharding\n@@ -855,7 +855,7 @@ std::optional<HloInstruction*> PadFromPartialReplicateShape(\n   // Pad the dimensions needs halo exchange and record the padded dims that\n   // won't need halo exchange.\n   for (auto dim : expand_tile_dims) {\n-    int64_t src_shard_count = src_sharding.tile_assignment().dim(dim);\n+    int64_t src_shard_count = src_sharding.dimension(dim);\n     int64_t src_per_shard_size =\n         padded_src_shape.dimensions(dim) / src_shard_count;\n     // Calculate per shard size using the sharding to compare if dst_sharding\n@@ -929,7 +929,7 @@ std::optional<int64_t> UniqueTiledDim(const HloSharding& sharding) {\n                      ? sharding.tile_assignment().num_dimensions() - 1\n                      : sharding.tile_assignment().num_dimensions();\n   for (int64_t i = 0; i < rank; ++i) {\n-    if (sharding.tile_assignment().dim(i) > 1) {\n+    if (sharding.dimension(i) > 1) {\n       if (dim != -1) {\n         return std::nullopt;\n       }\n@@ -1116,7 +1116,7 @@ std::optional<HloInstruction*> ExchangeHalo(\n     const SPMDCollectiveOpsCreator& collective_ops_creator,\n     int64_t* next_channel_id, SpmdBuilder* b) {\n   int64_t input_shard_size = hlo->shape().dimensions(dim);\n-  int64_t shard_count = target.tile_assignment().dim(dim);\n+  int64_t shard_count = target.dimension(dim);\n \n   std::vector<HloInstruction*> concat_pieces;\n \n@@ -1299,7 +1299,7 @@ HloInstruction* ExchangeHaloCompact(\n     const SPMDCollectiveOpsCreator& collective_ops_creator,\n     int64_t* next_channel_id, SpmdBuilder* b) {\n   int64_t input_shard_size = hlo->shape().dimensions(dim);\n-  int64_t shard_count = sharding.tile_assignment().dim(dim);\n+  int64_t shard_count = sharding.dimension(dim);\n   auto grouped =\n       hlo_sharding_util::GroupShardingOnAllDimsExcept(sharding, {dim});\n   auto g_creator = GetPerGroupCollectiveOpsCreator(collective_ops_creator,\n@@ -1757,7 +1757,7 @@ std::optional<HloInstruction*> ExchangeHaloAndGetValidData(\n     const SPMDCollectiveOpsCreator& collective_ops_creator,\n     int64_t* next_channel_id, SpmdBuilder* b, bool mask_invalid_region,\n     bool force_mask_in_compact) {\n-  int64_t shard_count = target.tile_assignment().dim(dim);\n+  int64_t shard_count = target.dimension(dim);\n   if (explicit_left_padding_on_full_shape ==\n       left_halo_size_function.Calculate(0)) {\n     int64_t max_halo =\n@@ -1946,7 +1946,7 @@ HloInstruction* HaloExchangeToPadOnLeft(PartitionedHlo& original,\n     int64_t low_padding = 0;\n     if (absl::c_linear_search(dims, i)) {\n       low_padding = RoundUpTo(original.base_shape().dimensions(i),\n-                              original.sharding().tile_assignment().dim(i)) -\n+                              original.sharding().dimension(i)) -\n                     original.base_shape().dimensions(i);\n     }\n     dim->set_padding_low(low_padding);\n@@ -2094,15 +2094,15 @@ std::optional<int64_t> GetKValueInTopKWhenPartitionSortDim(\n   // Check if partitioned at sort dimension.\n   for (int64_t dim = 0; dim < sort->shape().tuple_shapes(0).dimensions().size();\n        ++dim) {\n-    if (sharding.tile_assignment().dim(dim) > 1) {\n+    if (sharding.dimension(dim) > 1) {\n       if (dim != sort_dim) {\n         return std::nullopt;\n       }\n     }\n   }\n \n   // Checks if partition size is smaller than k.\n-  const int64_t shard_count = sharding.tile_assignment().dim(sort_dim);\n+  const int64_t shard_count = sharding.dimension(sort_dim);\n \n   if (shard_count <= 1) {\n     return std::nullopt;\n@@ -2143,7 +2143,7 @@ int64_t ShardCountAtDim(const HloSharding& sharding, int64_t dim) {\n     // DotConvolutionDimsInfo.\n     return 1;\n   }\n-  return sharding.tile_assignment().dim(dim);\n+  return sharding.dimension(dim);\n }\n \n std::optional<std::vector<std::pair<int64_t, int64_t>>>\n@@ -2160,11 +2160,11 @@ GetReshardAllToAllSourceTargetDims(const HloSharding& source,\n   std::map<int64_t, std::vector<int64_t>> source_size_to_dim;\n   std::map<int64_t, std::vector<int64_t>> target_size_to_dim;\n   for (int64_t i = 0; i < source.tile_assignment().num_dimensions(); ++i) {\n-    if (source.tile_assignment().dim(i) == target.tile_assignment().dim(i)) {\n+    if (source.dimension(i) == target.dimension(i)) {\n       continue;\n     }\n-    source_size_to_dim[source.tile_assignment().dim(i)].push_back(i);\n-    target_size_to_dim[target.tile_assignment().dim(i)].push_back(i);\n+    source_size_to_dim[source.dimension(i)].push_back(i);\n+    target_size_to_dim[target.dimension(i)].push_back(i);\n   }\n   // In order to shard via AllToAll, source_size_to_dim and target_size_to_dim\n   // must have the same distribution.\n@@ -2194,7 +2194,7 @@ GetReshardAllToAllSourceTargetDims(const HloSharding& source,\n   while (!source_size_to_dim.empty()) {\n     int64_t source_size = source_size_to_dim.begin()->first;\n     int64_t i = source_size_to_dim.begin()->second.back();\n-    int64_t target_i_size = target.tile_assignment().dim(i);\n+    int64_t target_i_size = target.dimension(i);\n     if (target_i_size == source_size) {\n       remove_entry(source_size, i, source_size_to_dim);\n       remove_entry(source_size, i, target_size_to_dim);\n@@ -2206,7 +2206,7 @@ GetReshardAllToAllSourceTargetDims(const HloSharding& source,\n       // If possible, find a j where the target partition count is not one, so\n       // that when we swap, the resulting size-1 dimension will still be useful\n       // to other dimensions.\n-      while (target.tile_assignment().dim(j) == 1) {\n+      while (target.dimension(j) == 1) {\n         if (++j_it == source_size_to_dim[target_i_size].end()) {\n           break;\n         }\n@@ -2215,7 +2215,7 @@ GetReshardAllToAllSourceTargetDims(const HloSharding& source,\n     } else if (target_i_size % source_size == 0) {\n       // If possible, find a j where the target partition count is source_size,\n       // so that we can do a single swap.\n-      while (target.tile_assignment().dim(j) != source_size) {\n+      while (target.dimension(j) != source_size) {\n         if (++j_it == source_size_to_dim[target_i_size].end()) {\n           break;\n         }\n@@ -2464,7 +2464,7 @@ std::optional<std::vector<int64_t>> FindMatchingPartitionedDimsForGrouping(\n   if (device_groups.num_devices_per_group() < 2) {\n     // Trivial case: single member groups\n     for (int64_t i = 0; i < sharding.tile_assignment().num_dimensions(); ++i) {\n-      if (sharding.tile_assignment().dim(i) > 1) {\n+      if (sharding.dimension(i) > 1) {\n         dims.push_back(i);\n       }\n     }\n@@ -2483,7 +2483,7 @@ std::optional<std::vector<int64_t>> FindMatchingPartitionedDimsForGrouping(\n     if (device_to_index[device_groups(0, 0)][i] ==\n         device_to_index[device_groups(0, 1)][i]) {\n       dims.push_back(i);\n-      group_count *= sharding.tile_assignment().dim(i);\n+      group_count *= sharding.dimension(i);\n     }\n   }\n   if (group_count != device_groups.num_groups()) {\n@@ -2516,9 +2516,8 @@ HloSharding CreateMatchingShardingOnDims(\n                                             1);\n   int num_tiles = 1;\n   for (int i = 0, end = target_dims.size(); i < end; ++i) {\n-    num_tiles *= source_sharding.tile_assignment().dim(source_dims[i]);\n-    tile_dims[target_dims[i]] =\n-        source_sharding.tile_assignment().dim(source_dims[i]);\n+    num_tiles *= source_sharding.dimension(source_dims[i]);\n+    tile_dims[target_dims[i]] = source_sharding.dimension(source_dims[i]);\n   }\n   // If there is some partition across non-parallel dimensions in the\n   // other operand then partially replicate for the new\n@@ -2588,9 +2587,8 @@ GatherScatterOperandsShardedAcrossParallelDims(\n         to_adjust->tile_assignment().dimensions().begin(),\n         to_adjust->tile_assignment().dimensions().end());\n     for (int i = 0; i < to_adjust_dims.size(); ++i) {\n-      int64_t target_dim = target->tile_assignment().dim(target_dims[i]);\n-      int64_t to_adjust_dim =\n-          to_adjust->tile_assignment().dim(to_adjust_dims[i]);\n+      int64_t target_dim = target->dimension(target_dims[i]);\n+      int64_t to_adjust_dim = to_adjust->dimension(to_adjust_dims[i]);\n       if (target_dim < to_adjust_dim) {\n         return std::nullopt;\n       }\n@@ -2628,7 +2626,7 @@ GatherScatterOperandsShardedAcrossParallelDims(\n       new_operand_shard.tile_assignment().dimensions().end());\n   for (int i = 0; i < indices_parallel_dims.size(); ++i) {\n     operand_shard_tile_dims[operand_parallel_dims[i]] =\n-        new_index_shard.tile_assignment().dim(indices_parallel_dims[i]);\n+        new_index_shard.dimension(indices_parallel_dims[i]);\n   }\n   auto operand_shard_tiles =\n       new_operand_shard.tile_assignment().Reshape(operand_shard_tile_dims);\n@@ -2803,7 +2801,7 @@ std::optional<PartitionedHlo::WindowedInputShardReturnValue> ReshardDataForPad(\n     dim->set_padding_low(pd.edge_padding_low());\n     dim->set_padding_high(pd.edge_padding_high());\n     dim->set_base_dilation(pd.interior_padding() + 1);\n-    const int64_t shard_count = target_sharding.tile_assignment().dim(i);\n+    const int64_t shard_count = target_sharding.dimension(i);\n     // Need masking only if there is non-zero padding value or the operand is\n     // unevenly partitioned. Halo exchange fills 0 in collective permute result\n     // for non-destination cores.\n@@ -2912,10 +2910,10 @@ std::vector<std::vector<int64_t>> GetPartitionGroupsAcrossTargetDims(\n               it != target_dims.end()) {\n             int64_t group_size =\n                 group_sizes[std::distance(target_dims.begin(), it)];\n-            group_id *= sharding.tile_assignment().dim(dim) / group_size;\n+            group_id *= sharding.dimension(dim) / group_size;\n             group_id += indices[dim] / group_size;\n           } else {\n-            group_id *= sharding.tile_assignment().dim(dim);\n+            group_id *= sharding.dimension(dim);\n             group_id += indices[dim];\n           }\n         }\n@@ -2964,13 +2962,13 @@ std::optional<IotaReplicaGroupList> GetIotaPartitionGroupsAcrossTargetDims(\n   for (int64_t dim = 0; dim < sharding.tile_assignment().num_dimensions();\n        ++dim) {\n     if (auto it = absl::c_find(target_dims, dim); it != target_dims.end()) {\n-      int64_t current_val = sharding.tile_assignment().dim(dim);\n+      int64_t current_val = sharding.dimension(dim);\n       int64_t group_size = group_sizes[std::distance(target_dims.begin(), it)];\n       reshape_dimensions.push_back(current_val / group_size);\n       reshape_dimensions.push_back(group_size);\n       target_dim_locations.push_back(reshape_dimensions.size() - 1);\n     } else {\n-      reshape_dimensions.push_back(sharding.tile_assignment().dim(dim));\n+      reshape_dimensions.push_back(sharding.dimension(dim));\n     }\n   }\n \n@@ -3023,7 +3021,7 @@ std::optional<IotaReplicaGroupList> GetIotaPartitionGroupsForReplication(\n \n   int64_t group_size = 1;\n   for (int64_t i : replication_dims) {\n-    group_size *= sharding.tile_assignment().dim(i);\n+    group_size *= sharding.dimension(i);\n   }\n \n   int64_t num_replica_groups =\n@@ -3122,7 +3120,7 @@ DynamicUpdateSliceAnalysis AnalyzeDynamicUpdateSlice(\n     }\n     analysis.slice_dims.push_back(i);\n \n-    if (hlo->sharding().tile_assignment().dim(i) == 1) {\n+    if (hlo->sharding().dimension(i) == 1) {\n       continue;\n     }\n     analysis.partitioned_slice_dims.push_back(i);\n@@ -3140,8 +3138,8 @@ DynamicUpdateSliceAnalysis AnalyzeDynamicUpdateSlice(\n                           : hlo->operand(i + 2)->literal().Get<int>({});\n       int64_t end_index = start_index + slice_size - 1;\n \n-      int64_t per_partition_size = CeilOfRatio(\n-          hlo->shape().dimensions(i), hlo->sharding().tile_assignment().dim(i));\n+      int64_t per_partition_size =\n+          CeilOfRatio(hlo->shape().dimensions(i), hlo->sharding().dimension(i));\n       if (start_index / per_partition_size != end_index / per_partition_size) {\n         update_on_a_single_partition = false;\n       }"
        },
        {
            "sha": "d0537c0fbcefcd5cad00e3c82d09c3048196560a",
            "filename": "third_party/xla/xla/service/spmd/spmd_prepare.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_prepare.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_prepare.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fspmd%2Fspmd_prepare.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -127,10 +127,10 @@ absl::StatusOr<bool> ProcessScatter(HloInstruction* hlo,\n   // scatter would have no value.\n   for (int i = 0; i < lhs_parallel_dims->operand_dims.size(); ++i) {\n     if (lhs_operand->sharding().IsTiled() &&\n-        lhs_operand->sharding().tile_assignment().dim(\n-            lhs_parallel_dims->operand_dims[i]) != 1 &&\n-        lhs_indices->sharding().tile_assignment().dim(\n-            lhs_parallel_dims->indices_dims[i]) != 1) {\n+        lhs_operand->sharding().dimension(lhs_parallel_dims->operand_dims[i]) !=\n+            1 &&\n+        lhs_indices->sharding().dimension(lhs_parallel_dims->indices_dims[i]) !=\n+            1) {\n       any_sharded_parallel_dim = true;\n       break;\n     }"
        },
        {
            "sha": "da4ddbc04fb6daf97fc20d70f123b3ef2847289c",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad48213f1c14278ca2ed6a2343dc15fe4542b008/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=ad48213f1c14278ca2ed6a2343dc15fe4542b008",
            "patch": "@@ -1488,8 +1488,8 @@ class CollectiveOpsTestE2EShardedUnsharded : public CollectiveOpsTestE2E {\n                            const HloSharding& sharding) {\n     if (!sharding.IsReplicated()) {\n       for (int k = 0; k < sharding.tile_assignment().num_dimensions(); ++k) {\n-        if (sharding.tile_assignment().dim(k) > 1) {\n-          dims_per_shard[k] /= sharding.tile_assignment().dim(k);\n+        if (sharding.dimension(k) > 1) {\n+          dims_per_shard[k] /= sharding.dimension(k);\n           sharded_dims.push_back(k);\n         }\n       }"
        }
    ],
    "stats": {
        "total": 433,
        "additions": 204,
        "deletions": 229
    }
}