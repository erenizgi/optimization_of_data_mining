{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809862152",
    "sha": "3e2ed19cfcb590653ad3c1439696853c48c33dd2",
    "files": [
        {
            "sha": "3736b595019457c48b81216ee73fd6b7c6e247f6",
            "filename": "tensorflow/core/data/captured_function.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fcaptured_function.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fcaptured_function.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fcaptured_function.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -246,7 +246,7 @@ absl::Status CreateFunctionLibraryDefinition(\n   DCHECK(lib_def != nullptr);\n   const FunctionDef* fdef = lib_def->Find(func_name);\n   if (TF_PREDICT_FALSE(fdef == nullptr)) {\n-    return errors::FailedPrecondition(strings::StrCat(\n+    return errors::FailedPrecondition(absl::StrCat(\n         \"Could not find required function definition \", func_name));\n   }\n   *result = std::make_unique<FunctionLibraryDefinition>(\n@@ -429,7 +429,7 @@ absl::Status MakeIteratorFromInputElement(\n       GetDatasetFromVariantTensor(return_values[0], &returned_dataset));\n \n   // Create an iterator for the dataset that was returned by `f`.\n-  std::string iterator_prefix = strings::StrCat(prefix, \"[\", thread_index, \"]\");\n+  std::string iterator_prefix = absl::StrCat(prefix, \"[\", thread_index, \"]\");\n \n   IteratorContext nested_ctx = MakeNestedIteratorContext(ctx);\n   TF_RETURN_IF_ERROR(returned_dataset->MakeIterator(\n@@ -842,7 +842,7 @@ absl::Status InstantiatedCapturedFunction::Run(\n     if (was_recording) node->record_stop(EnvTime::NowNanos());\n     TF_RETURN_IF_ERROR(lib_->RunSync(std::move(f_opts), f_handle_, &frame));\n     if (ctx->stats_aggregator()) {\n-      string prefix_with_func_name = strings::StrCat(\n+      string prefix_with_func_name = absl::StrCat(\n           node->name(), stats_utils::kDelimiter, captured_func_->func().name());\n       ctx->stats_aggregator()->AddToHistogram(\n           stats_utils::ExecutionTimeHistogramName(prefix_with_func_name),\n@@ -904,7 +904,7 @@ absl::Status InstantiatedCapturedFunction::RunWithBorrowedArgs(\n     // Resource usage for function execution is gathered from the executor.\n     TF_RETURN_IF_ERROR(lib_->RunSync(std::move(f_opts), f_handle_, &frame));\n     if (ctx->stats_aggregator()) {\n-      string prefix_with_func_name = strings::StrCat(\n+      string prefix_with_func_name = absl::StrCat(\n           node->name(), stats_utils::kDelimiter, captured_func_->func().name());\n       ctx->stats_aggregator()->AddToHistogram(\n           stats_utils::ExecutionTimeHistogramName(prefix_with_func_name),"
        },
        {
            "sha": "14f385dcaa48cb9994c37e4bf1a25046dbb1627b",
            "filename": "tensorflow/core/data/dataset_utils.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 16,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fdataset_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fdataset_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fdataset_utils.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -569,7 +569,7 @@ absl::flat_hash_set<string> GetExperiments(\n   }\n   // Stochastically include live experiments unless they are opted out.\n   for (const auto& [experiment_name, experiment_selector] : live_experiments) {\n-    uint64_t name_hash = hash_func(strings::StrCat(job_name, experiment_name));\n+    uint64_t name_hash = hash_func(absl::StrCat(job_name, experiment_name));\n     std::mt19937_64 rng{name_hash};\n     std::bernoulli_distribution d{0.5};\n     bool evens = d(rng);\n@@ -669,15 +669,14 @@ absl::Status ReadBatch(IteratorContext* ctx, IteratorStateReader* reader,\n                        const string& batch_prefix, std::vector<Tensor>* batch) {\n   int64_t output_size;\n   TF_RETURN_IF_ERROR(reader->ReadScalar(\n-      FullName(iterator_prefix,\n-               strings::StrCat(batch_prefix, \"_\", kOutputSize)),\n+      FullName(iterator_prefix, absl::StrCat(batch_prefix, \"_\", kOutputSize)),\n       &output_size));\n   batch->reserve(output_size);\n   for (int i = 0; i < output_size; i++) {\n     Tensor t;\n     TF_RETURN_IF_ERROR(\n         reader->ReadTensor(ctx->flr(), FullName(iterator_prefix, batch_prefix),\n-                           strings::StrCat(kOutput, \"_\", i), &t));\n+                           absl::StrCat(kOutput, \"_\", i), &t));\n     // If the batch was not full, we may have stored only the relevant slice.\n     // Since tensors in `BatchResult.output` are expected to have the leading\n     // dimension of size batch_size, we build a larger tensor and copy the slice\n@@ -702,22 +701,20 @@ absl::Status WriteBatch(int64_t batch_size, int64_t num_elements,\n                         const string& batch_prefix, IteratorStateWriter* writer,\n                         std::vector<Tensor>* batch) {\n   TF_RETURN_IF_ERROR(writer->WriteScalar(\n-      FullName(iterator_prefix,\n-               strings::StrCat(batch_prefix, \"_\", kOutputSize)),\n+      FullName(iterator_prefix, absl::StrCat(batch_prefix, \"_\", kOutputSize)),\n       batch->size()));\n   for (int i = 0; i < batch->size(); i++) {\n     // If the batch is not full, we only store the first `num_elements` values.\n     // The rest of the batch tensor is *uninitialized* and accessing that will\n     // raise msan errors.\n     if (num_elements < batch_size) {\n-      TF_RETURN_IF_ERROR(\n-          writer->WriteTensor(FullName(iterator_prefix, batch_prefix),\n-                              strings::StrCat(kOutput, \"_\", i),\n-                              (*batch)[i].Slice(0, num_elements)));\n+      TF_RETURN_IF_ERROR(writer->WriteTensor(\n+          FullName(iterator_prefix, batch_prefix),\n+          absl::StrCat(kOutput, \"_\", i), (*batch)[i].Slice(0, num_elements)));\n     } else {\n       TF_RETURN_IF_ERROR(\n           writer->WriteTensor(FullName(iterator_prefix, batch_prefix),\n-                              strings::StrCat(kOutput, \"_\", i), (*batch)[i]));\n+                              absl::StrCat(kOutput, \"_\", i), (*batch)[i]));\n     }\n   }\n   return absl::OkStatus();\n@@ -727,14 +724,13 @@ absl::Status ReadStatus(const string& iterator_prefix, const string& prefix,\n                         IteratorStateReader* reader, absl::Status* status) {\n   int64_t code_int;\n   TF_RETURN_IF_ERROR(reader->ReadScalar(\n-      FullName(iterator_prefix, strings::StrCat(prefix, \"_\", kCode)),\n-      &code_int));\n+      FullName(iterator_prefix, absl::StrCat(prefix, \"_\", kCode)), &code_int));\n   absl::StatusCode code = static_cast<absl::StatusCode>(code_int);\n \n   if (code != absl::StatusCode::kOk) {\n     tstring error_message;\n     TF_RETURN_IF_ERROR(reader->ReadScalar(\n-        FullName(iterator_prefix, strings::StrCat(prefix, \"_\", kMessage)),\n+        FullName(iterator_prefix, absl::StrCat(prefix, \"_\", kMessage)),\n         &error_message));\n     *status = absl::Status(code, error_message);\n   } else {\n@@ -747,11 +743,11 @@ absl::Status WriteStatus(const string& iterator_prefix, const string& prefix,\n                          const absl::Status& status,\n                          IteratorStateWriter* writer) {\n   TF_RETURN_IF_ERROR(writer->WriteScalar(\n-      FullName(iterator_prefix, strings::StrCat(prefix, \"_\", kCode)),\n+      FullName(iterator_prefix, absl::StrCat(prefix, \"_\", kCode)),\n       static_cast<int64_t>(status.code())));\n   if (!status.ok()) {\n     TF_RETURN_IF_ERROR(writer->WriteScalar(\n-        FullName(iterator_prefix, strings::StrCat(prefix, \"_\", kMessage)),\n+        FullName(iterator_prefix, absl::StrCat(prefix, \"_\", kMessage)),\n         std::string(status.message())));\n   }\n   return absl::OkStatus();"
        },
        {
            "sha": "133bfb08e4ea7a2fc8c02b413a7a1776acfdeca1",
            "filename": "tensorflow/core/data/dataset_utils.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fdataset_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fdataset_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fdataset_utils.h?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -52,7 +52,7 @@ absl::Status CreateWeakHandle(OpKernelContext* ctx, T* resource,\n                               ResourceHandle* handle) {\n   static std::atomic<int64_t> resource_id_counter(0);\n   string unique_name =\n-      strings::StrCat(container_name, resource_id_counter.fetch_add(1));\n+      absl::StrCat(container_name, resource_id_counter.fetch_add(1));\n   ResourceMgr* mgr = ctx->resource_manager();\n   TF_RETURN_IF_ERROR(mgr->Create<T>(container_name, unique_name, resource));\n "
        },
        {
            "sha": "e08d37baf61c1072be9c399f6c7549f5f55575af",
            "filename": "tensorflow/core/data/name_utils.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fname_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fname_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fname_utils.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -36,16 +36,16 @@ string OpName(const string& dataset_type) {\n \n string OpName(const string& dataset_type, const OpNameParams& params) {\n   if (params.op_version == 1) {\n-    return strings::StrCat(dataset_type, kDataset);\n+    return absl::StrCat(dataset_type, kDataset);\n   }\n-  return strings::StrCat(dataset_type, kDataset, kVersion, params.op_version);\n+  return absl::StrCat(dataset_type, kDataset, kVersion, params.op_version);\n }\n \n string ArgsToString(const std::vector<string>& args) {\n   if (args.empty()) {\n     return \"\";\n   }\n-  return strings::StrCat(\"(\", absl::StrJoin(args, \", \"), \")\");\n+  return absl::StrCat(\"(\", absl::StrJoin(args, \", \"), \")\");\n }\n \n string DatasetDebugString(const string& dataset_type) {\n@@ -68,8 +68,8 @@ string IteratorPrefix(const string& dataset_type, const string& prefix) {\n string IteratorPrefix(const string& dataset_type, const string& prefix,\n                       const IteratorPrefixParams& params) {\n   if (params.op_version == 1) {\n-    return strings::StrCat(prefix, kDelimiter, params.dataset_prefix,\n-                           dataset_type);\n+    return absl::StrCat(prefix, kDelimiter, params.dataset_prefix,\n+                        dataset_type);\n   }\n   return strings::StrCat(prefix, kDelimiter, params.dataset_prefix,\n                          dataset_type, kVersion, params.op_version);"
        },
        {
            "sha": "2e21ef8b9a8097d2c81c273d025a23349fa97ecc",
            "filename": "tensorflow/core/data/rewrite_utils.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Frewrite_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Frewrite_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Frewrite_utils.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -85,13 +85,13 @@ void AddFakeSinks(FunctionDef* function_def) {\n   for (const auto& output : function_def->signature().output_arg()) {\n     NodeDef* node = function_def->add_node_def();\n     tensorflow::grappler::function_utils::SetUniqueFunctionNodeName(\n-        strings::StrCat(\"FakeSink\", counter++), function_def, node);\n+        absl::StrCat(\"FakeSink\", counter++), function_def, node);\n     node->set_op(\"Identity\");\n     node->add_input(function_def->ret().at(output.name()));\n     (*node->mutable_attr())[\"T\"].set_type(output.type());\n \n     (*function_def->mutable_ret())[output.name()] =\n-        strings::StrCat(node->name(), \":output:0\");\n+        absl::StrCat(node->name(), \":output:0\");\n   }\n }\n "
        },
        {
            "sha": "48941df25217cc7e23367438f2a5c8220b9179c5",
            "filename": "tensorflow/core/data/serialization_utils.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 9,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fserialization_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fserialization_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fserialization_utils.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -279,7 +279,7 @@ absl::Status VariantTensorDataReader::ReadScalarInternal(absl::string_view n,\n absl::Status VariantTensorDataReader::ReadTensorInternal(\n     FunctionLibraryRuntime* flr, absl::string_view n, absl::string_view key,\n     Tensor* val) const {\n-  if (Contains(n, strings::StrCat(key, kIsDataset))) {\n+  if (Contains(n, absl::StrCat(key, kIsDataset))) {\n     return ReadDatasetInternal(flr, n, key, val);\n   }\n   string name(n);\n@@ -305,9 +305,8 @@ absl::Status VariantTensorDataReader::ReadDatasetInternal(\n   }\n   tstring output_node, serialized_graph_def;\n   TF_RETURN_IF_ERROR(\n-      ReadScalar(n, strings::StrCat(key, kOutputNode), &output_node));\n-  TF_RETURN_IF_ERROR(\n-      ReadScalar(n, strings::StrCat(key), &serialized_graph_def));\n+      ReadScalar(n, absl::StrCat(key, kOutputNode), &output_node));\n+  TF_RETURN_IF_ERROR(ReadScalar(n, key, &serialized_graph_def));\n   GraphDef graph_def;\n   graph_def.ParseFromString(serialized_graph_def);\n   TF_RETURN_IF_ERROR(FromGraphDef(flr, graph_def, {}, output_node, val));\n@@ -373,7 +372,7 @@ void VariantTensorDataWriter::MaybeFlush() {\n     const string name = keys.first;\n     string metadata = name;\n     for (size_t i = 0; i < keys_[name].size(); ++i) {\n-      strings::StrAppend(&metadata, kDelimiter, keys_[name][i]);\n+      absl::StrAppend(&metadata, kDelimiter, keys_[name][i]);\n     }\n     data_[name]->set_metadata(metadata);\n   }\n@@ -454,9 +453,9 @@ absl::Status VariantTensorDataWriter::WriteDatasetInternal(\n   }\n   string result;\n   graph_def.SerializeToString(&result);\n-  TF_RETURN_IF_ERROR(WriteScalar(n, strings::StrCat(key, kIsDataset), \"\"));\n+  TF_RETURN_IF_ERROR(WriteScalar(n, absl::StrCat(key, kIsDataset), \"\"));\n   TF_RETURN_IF_ERROR(\n-      WriteScalar(n, strings::StrCat(key, kOutputNode), output_node));\n+      WriteScalar(n, absl::StrCat(key, kOutputNode), output_node));\n   TF_RETURN_IF_ERROR(WriteScalar(n, key, result));\n   return absl::OkStatus();\n }\n@@ -537,9 +536,9 @@ const CompressedElement* IteratorStateVariant::GetCompressedElement(\n \n std::string IteratorStateVariant::DebugString() const {\n   if (data_) {\n-    return strings::StrCat(\"IteratorStateVariant<\", data_->DebugString(), \">\");\n+    return absl::StrCat(\"IteratorStateVariant<\", data_->DebugString(), \">\");\n   } else {\n-    return strings::StrCat(\"IteratorStateVariant<empty>\");\n+    return absl::StrCat(\"IteratorStateVariant<empty>\");\n   }\n }\n "
        },
        {
            "sha": "349b84be1b49de3ddb6caf9f0c0e70975b654beb",
            "filename": "tensorflow/core/data/serialization_utils_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fserialization_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e2ed19cfcb590653ad3c1439696853c48c33dd2/tensorflow%2Fcore%2Fdata%2Fserialization_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fdata%2Fserialization_utils_test.cc?ref=3e2ed19cfcb590653ad3c1439696853c48c33dd2",
            "patch": "@@ -104,7 +104,7 @@ TEST(SerializationUtilsTest, VariantTensorDataRoundtrip) {\n \n TEST(SerializationUtilsTest, VariantTensorDataNonExistentKey) {\n   VariantTensorData data;\n-  strings::StrAppend(&data.metadata_, \"key1\", \"@@\");\n+  absl::StrAppend(&data.metadata_, \"key1\", \"@@\");\n   data.tensors_.push_back(Tensor(DT_INT64, {1}));\n   std::vector<const VariantTensorData*> reader_data;\n   reader_data.push_back(&data);\n@@ -141,7 +141,7 @@ TEST(SerializationUtilsTest, VariantTensorDataRoundtripIteratorName) {\n \n TEST(SerializationUtilsTest, VariantTensorDataNonExistentKeyIteratorName) {\n   VariantTensorData data;\n-  strings::StrAppend(&data.metadata_, \"key1\", \"@@\");\n+  absl::StrAppend(&data.metadata_, \"key1\", \"@@\");\n   data.tensors_.push_back(Tensor(DT_INT64, {1}));\n   std::vector<const VariantTensorData*> reader_data;\n   reader_data.push_back(&data);"
        }
    ],
    "stats": {
        "total": 73,
        "additions": 34,
        "deletions": 39
    }
}