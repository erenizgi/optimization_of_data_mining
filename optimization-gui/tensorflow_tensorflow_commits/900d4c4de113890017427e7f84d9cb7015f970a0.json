{
    "author": "beckerhe",
    "message": "Move KernelArgs into its own file\n\nThis is a pure cleanup change that moves the `KernelArgs` type and its related functions into its own file. In detail this is doing the following:\n\n- Moves `stream_executor::KernelArgs` and related types and functions from `kernel.h` into the new file `kernel_args.h`\n- Move the corresponding tests from `kernel_test.cc` into `kernel_args_test.cc`\n- Moves the one-line implementaton of `Kernel::set_name` from `kernel.cc` into `kernel.h` and removes the now-empty `kernel.cc`\n- Some clang-tidy cleanups in kernel_args.h (no-else-after-return)\n- dependency and include fixups for users of `kernel.h` (and now `kernel_args.h`)\n\nPiperOrigin-RevId: 830799843",
    "sha": "900d4c4de113890017427e7f84d9cb7015f970a0",
    "files": [
        {
            "sha": "de5a34b2492a85ab31eb0cc651e2e2e4c30a8025",
            "filename": "third_party/xla/xla/stream_executor/BUILD",
            "status": "modified",
            "additions": 23,
            "deletions": 8,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2FBUILD?ref=900d4c4de113890017427e7f84d9cb7015f970a0",
            "patch": "@@ -638,10 +638,10 @@ xla_cc_test(\n \n cc_library(\n     name = \"kernel\",\n-    srcs = [\"kernel.cc\"],\n     hdrs = [\"kernel.h\"],\n     deps = [\n         \":device_memory\",\n+        \":kernel_args\",\n         \":kernel_metadata\",\n         \":launch_dim\",\n         \":stream\",\n@@ -675,7 +675,7 @@ cc_library(\n     name = \"kernel_args_packed_vector\",\n     hdrs = [\"kernel_args_packed_vector.h\"],\n     deps = [\n-        \":kernel\",\n+        \":kernel_args\",\n         \"@com_google_absl//absl/types:span\",\n     ],\n )\n@@ -911,16 +911,31 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"kernel_args\",\n+    hdrs = [\"kernel_args.h\"],\n+    deps = [\n+        \":device_memory\",\n+        \":kernel_metadata\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n+        \"@com_google_absl//absl/functional:overload\",\n+        \"@com_google_absl//absl/log:check\",\n+        \"@com_google_absl//absl/meta:type_traits\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/types:span\",\n+    ],\n+)\n+\n xla_cc_test(\n-    name = \"kernel_test\",\n-    srcs = [\"kernel_test.cc\"],\n+    name = \"kernel_args_test\",\n+    srcs = [\"kernel_args_test.cc\"],\n     deps = [\n         \":device_memory\",\n-        \":kernel\",\n+        \":kernel_args\",\n         \":kernel_metadata\",\n-        \":platform\",\n-        \":platform_manager\",\n-        \":stream_executor_h\",\n         \"//xla/stream_executor/host:host_platform\",\n         \"//xla/tsl/platform:statusor\",\n         \"//xla/tsl/platform:test_main\","
        },
        {
            "sha": "298ea10a70555f8d951e4dacf13e28029aac42ce",
            "filename": "third_party/xla/xla/stream_executor/kernel.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 26,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/bcf015cf00be006de7f7180cd76045a201d55f9f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/bcf015cf00be006de7f7180cd76045a201d55f9f/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.cc?ref=bcf015cf00be006de7f7180cd76045a201d55f9f",
            "patch": "@@ -1,26 +0,0 @@\n-/* Copyright 2015 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/stream_executor/kernel.h\"\n-\n-#include <string>\n-\n-#include \"absl/strings/string_view.h\"\n-\n-namespace stream_executor {\n-\n-void Kernel::set_name(absl::string_view name) { name_ = std::string(name); }\n-\n-}  // namespace stream_executor"
        },
        {
            "sha": "ac0815683d5359c543a804d720c3c7a411f29549",
            "filename": "third_party/xla/xla/stream_executor/kernel.h",
            "status": "modified",
            "additions": 2,
            "deletions": 531,
            "changes": 533,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel.h?ref=900d4c4de113890017427e7f84d9cb7015f970a0",
            "patch": "@@ -67,7 +67,6 @@ limitations under the License.\n #ifndef XLA_STREAM_EXECUTOR_KERNEL_H_\n #define XLA_STREAM_EXECUTOR_KERNEL_H_\n \n-#include <array>\n #include <cassert>\n #include <cstddef>\n #include <cstdint>\n@@ -76,90 +75,19 @@ limitations under the License.\n #include <memory>\n #include <optional>\n #include <string>\n-#include <tuple>\n-#include <type_traits>\n #include <utility>\n-#include <variant>\n \n-#include \"absl/base/optimization.h\"\n-#include \"absl/container/inlined_vector.h\"\n-#include \"absl/functional/overload.h\"\n #include \"absl/log/check.h\"\n-#include \"absl/meta/type_traits.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n-#include \"absl/types/span.h\"\n-#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n #include \"xla/stream_executor/kernel_metadata.h\"\n #include \"xla/stream_executor/launch_dim.h\"\n #include \"xla/stream_executor/stream.h\"\n \n namespace stream_executor {\n \n-//===----------------------------------------------------------------------===//\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments\n-//===----------------------------------------------------------------------===//\n-\n-// A virtual base class for passing kernel arguments to a stream executor APIs.\n-class KernelArgs {\n- public:\n-  template <typename T>\n-  using IsKernelArgs = std::enable_if_t<std::is_base_of<KernelArgs, T>::value>;\n-\n-  enum class Kind {\n-    // A list of type-erased DeviceMemoryBase pointers to on-device memory. This\n-    // type of kernel arguments used only when the kernel has to do its own\n-    // custom packing, e.g. wrap all device pointers into a custom\n-    // structure, but can't be implemented as a TypedKernel because it has to be\n-    // passed around as a generic Kernel.\n-    kDeviceMemoryArray,\n-\n-    // A list of kernel arguments packed into a storage that can be passed\n-    // directly to device kernel as void** kernel parameters.\n-    kPackedArray\n-  };\n-\n-  virtual ~KernelArgs() = default;\n-\n-  // Gets the number of arguments added so far, including shared memory\n-  // arguments.\n-  virtual size_t number_of_arguments() const = 0;\n-\n-  // Gets the total number of shared memory bytes added so far.\n-  virtual uint64_t number_of_shared_bytes() const = 0;\n-\n-  virtual Kind kind() const = 0;\n-};\n-\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments packed array\n-//===----------------------------------------------------------------------===//\n-\n-// A virtual base class for passing kernel arguments packed into a storage so\n-// that we have stable addresses for all arguments. This is a low level API for\n-// passing arguments in a platform-specific way that relies on the knowledge of\n-// the ABI of the underlying platform.\n-//\n-// For example `cuLaunchKernel` accepts arguments as `void** kernelParams`, and\n-// packed array base guarantees that `argument_addresses` are compatible with\n-// the CUDA APIs.\n-//\n-// See: https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html\n-class KernelArgsPackedArrayBase : public KernelArgs {\n- public:\n-  // Gets the list of argument addresses.\n-  virtual absl::Span<const void* const> argument_addresses() const = 0;\n-\n-  static bool classof(const KernelArgs* args) {\n-    return args->kind() == Kind::kPackedArray;\n-  }\n-\n-  Kind kind() const final { return Kind::kPackedArray; }\n-};\n-\n //===----------------------------------------------------------------------===//\n // Kernel\n //===----------------------------------------------------------------------===//\n@@ -203,7 +131,7 @@ class Kernel {\n   }\n \n   absl::string_view name() const { return name_; }\n-  void set_name(absl::string_view name);\n+  void set_name(std::string name) { name_ = std::move(name); }\n \n   // Launches a data parallel kernel with the given thread/block\n   // dimensionality and already-packed args/sizes to pass to the underlying\n@@ -295,463 +223,6 @@ class TypedKernel {\n \n   std::unique_ptr<Kernel> kernel_;\n };\n-\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments LLVM-style RTTI library\n-//===----------------------------------------------------------------------===//\n-\n-template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n-T* Cast(KernelArgs* args) {\n-  CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n-                          << typeid(T).name();\n-  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return static_cast<const T*>(args);\n-}\n-\n-template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n-const T* Cast(const KernelArgs* args) {\n-  CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n-                          << typeid(T).name();\n-  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return static_cast<const T*>(args);\n-}\n-\n-template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n-const T* DynCast(const KernelArgs* args) {\n-  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n-  return T::classof(args) ? static_cast<const T*>(args) : nullptr;\n-}\n-\n-template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n-const T* DynCastOrNull(const KernelArgs* args) {\n-  return args && T::classof(args) ? static_cast<const T*>(args) : nullptr;\n-}\n-\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments device memory array\n-//===----------------------------------------------------------------------===//\n-\n-class KernelArgsDeviceMemoryArray : public KernelArgs {\n- public:\n-  KernelArgsDeviceMemoryArray(absl::Span<const DeviceMemoryBase> args,\n-                              size_t shared_memory_bytes)\n-      : device_memory_args_(args.begin(), args.end()),\n-        shared_memory_bytes_(shared_memory_bytes) {}\n-\n-  static bool classof(const KernelArgs* args) {\n-    return args->kind() == Kind::kDeviceMemoryArray;\n-  }\n-\n-  Kind kind() const final { return Kind::kDeviceMemoryArray; }\n-\n-  size_t number_of_arguments() const final {\n-    return device_memory_args_.size() + (shared_memory_bytes_ > 0);\n-  }\n-\n-  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n-\n-  absl::Span<const DeviceMemoryBase> device_memory_args() const {\n-    return device_memory_args_;\n-  }\n-\n-  const void* device_memory_ptr(size_t index) const {\n-    return device_memory_args_[index].opaque();\n-  }\n-\n-  size_t device_memory_size(size_t index) const {\n-    return device_memory_args_[index].size();\n-  }\n-\n- private:\n-  absl::InlinedVector<DeviceMemoryBase, 4> device_memory_args_;\n-  size_t shared_memory_bytes_ = 0;\n-};\n-\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments packing for device memory and POD args\n-//===----------------------------------------------------------------------===//\n-\n-// KernelArgsPackedArray is optimized for packing DeviceMemoryBase pointers\n-// and POD arguments (i.e. scalars) when the number and type of arguments are\n-// not known at compile time.\n-\n-namespace internal {\n-\n-// An empty storage for packing just the device memory arguments, that are\n-// stored directly in the `KernelArgsPackedArray`.\n-struct EmptyArgs {\n-  static constexpr size_t kSize = 0;\n-};\n-\n-// A storage for POD generic arguments that are smaller than `size` and require\n-// alignment smaller or equal to `alignment`.\n-template <size_t capacity, size_t size = 8,\n-          size_t alignment = alignof(std::max_align_t)>\n-class PodArgs {\n- public:\n-  static constexpr size_t kSize = size;\n-\n- protected:\n-  template <typename T>\n-  const std::byte* add_pod_argument(const T& arg) {\n-    static_assert(std::is_trivially_copyable_v<T> &&\n-                      sizeof(T) <= size & alignof(T) <= alignment,\n-                  \"Type is not compatible with POD arguments storage\");\n-\n-    assert(num_args_ < capacity && \"pod args overflow\");\n-    std::byte* arg_storage = args_storage_[num_args_++].storage;\n-    std::memcpy(arg_storage, &arg, sizeof(T));\n-\n-    return arg_storage;\n-  }\n-\n- private:\n-  struct Arg {\n-    alignas(alignment) std::byte storage[size];\n-  };\n-\n-  size_t num_args_ = 0;\n-  std::array<Arg, capacity> args_storage_;\n-};\n-\n-template <typename ArgsStorage>\n-static constexpr bool is_pod_args_v = false;\n-\n-template <size_t capacity, size_t size, size_t alignment>\n-static constexpr bool is_pod_args_v<PodArgs<capacity, size, alignment>> = true;\n-\n-}  // namespace internal\n-\n-// An array of arguments for a kernel call.\n-//\n-// The template parameter `num_args` is the maximum number of arguments which\n-// can be stored in the array.\n-template <size_t num_args, typename ArgsStorage = internal::PodArgs<num_args>>\n-class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n- public:\n-  KernelArgsPackedArray() = default;\n-\n-  // KernelArgsPackedArray is not copyable or movable because argument addresses\n-  // point to inline storage that can't be moved.\n-  KernelArgsPackedArray(const KernelArgsPackedArray&) = delete;\n-  KernelArgsPackedArray& operator=(const KernelArgsPackedArray&) = delete;\n-\n-  // Adds an argument to the list.\n-  template <typename T>\n-  void add_argument(const T& arg) {\n-    if constexpr (internal::is_pod_args_v<ArgsStorage>) {\n-      argument_addresses_[number_of_argument_addresses_++] =\n-          ArgsStorage::add_pod_argument(arg);\n-    } else {\n-      // https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2593r0.html\n-      static_assert(sizeof(T) == 0, \"Arguments storage is not supported\");\n-    }\n-  }\n-\n-  // Adds a device memory argument to the list.\n-  void add_device_memory_argument(const DeviceMemoryBase& arg) {\n-    const void** copy_ptr =\n-        &device_memory_opaque_pointers_[number_of_argument_addresses_];\n-    *copy_ptr = arg.opaque();\n-    argument_addresses_[number_of_argument_addresses_] = copy_ptr;\n-    ++number_of_argument_addresses_;\n-  }\n-\n-  // Adds a shared memory argument to the list.\n-  //\n-  // The only significant information about a shared argument is its size, so\n-  // that is the only parameter in this function.\n-  void add_shared_bytes(size_t number_of_bytes) {\n-    shared_memory_bytes_ += number_of_bytes;\n-  }\n-\n-  // Gets the number of arguments added so far, including shared memory\n-  // arguments.\n-  size_t number_of_arguments() const final {\n-    return number_of_argument_addresses_ + (shared_memory_bytes_ > 0);\n-  }\n-\n-  // Gets the total number of shared memory bytes added so far.\n-  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n-\n-  // Gets the list of argument addresses.\n-  absl::Span<const void* const> argument_addresses() const final {\n-    return absl::Span<const void* const>(argument_addresses_.data(),\n-                                         number_of_argument_addresses_);\n-  }\n-\n- private:\n-  // A place to store copies of opaque pointers from device memory arguments.\n-  std::array<const void*, num_args> device_memory_opaque_pointers_;\n-\n-  // Addresses for non-shared-memory arguments.\n-  std::array<const void*, num_args> argument_addresses_;\n-\n-  // Shared memory required by a kernel.\n-  size_t shared_memory_bytes_ = 0;\n-\n-  // Number of significant entries in argument_addresses_.\n-  size_t number_of_argument_addresses_ = 0;\n-};\n-\n-using KernelArgument = std::variant<DeviceMemoryBase, TensorMap, int64_t>;\n-\n-namespace internal {\n-template <int n>\n-std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n-    absl::Span<const DeviceMemoryBase> args, uint32_t shared_mem_bytes) {\n-  auto packed = std::make_unique<KernelArgsPackedArray<n, EmptyArgs>>();\n-  for (const DeviceMemoryBase& buf : args) {\n-    packed->add_device_memory_argument(buf);\n-  }\n-  if (shared_mem_bytes > 0) {\n-    packed->add_shared_bytes(shared_mem_bytes);\n-  }\n-  return packed;\n-}\n-\n-template <int n, typename ArgsStorage>\n-std::unique_ptr<KernelArgsPackedArray<n, ArgsStorage>> PackKernelArgsImpl(\n-    absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n-  auto packed = std::make_unique<KernelArgsPackedArray<n, ArgsStorage>>();\n-  for (const auto& arg : args) {\n-    std::visit(\n-        absl::Overload{\n-            [&](const DeviceMemoryBase& device_memory) {\n-              packed->add_device_memory_argument(device_memory);\n-            },\n-            [&](int64_t int_arg) {\n-              if constexpr (ArgsStorage::kSize >= sizeof(int64_t)) {\n-                packed->add_argument(int_arg);\n-              }\n-            },\n-            [&](const TensorMap& tensor_map) {\n-              if constexpr (ArgsStorage::kSize >= sizeof(tensor_map.storage)) {\n-                packed->add_argument(tensor_map.storage);\n-              }\n-            },\n-        },\n-        arg);\n-  }\n-  if (shared_mem_bytes > 0) {\n-    packed->add_shared_bytes(shared_mem_bytes);\n-  }\n-  return packed;\n-}\n-\n-template <int n>\n-std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n-    absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n-  const int32_t pod_size = [](absl::Span<const KernelArgument> args) {\n-    bool has_int = false;\n-    for (const auto& arg : args) {\n-      if (std::holds_alternative<TensorMap>(arg)) {\n-        return 128;\n-      }\n-      if (std::holds_alternative<int64_t>(arg)) {\n-        has_int = true;\n-      }\n-    }\n-    return has_int ? 64 : 0;\n-  }(args);\n-\n-  switch (pod_size) {\n-    case 128:\n-      return PackKernelArgsImpl<n, PodArgs<n, 128, 64>>(args, shared_mem_bytes);\n-    case 64:\n-      return PackKernelArgsImpl<n, PodArgs<n, 64, 64>>(args, shared_mem_bytes);\n-    case 0:\n-      return PackKernelArgsImpl<n, EmptyArgs>(args, shared_mem_bytes);\n-    default:\n-      ABSL_UNREACHABLE();\n-  }\n-}\n-}  // namespace internal\n-\n-template <typename ArgType>\n-inline absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>\n-PackKernelArgs(absl::Span<const ArgType> args, uint32_t shared_mem_bytes) {\n-  static constexpr int kKernelArgsLimit = 1024;\n-\n-  if (args.size() > kKernelArgsLimit) {\n-    return absl::InvalidArgumentError(absl::StrCat(\n-        \"Can't pack device memory arguments array of size \", args.size(),\n-        \" which is larger than the maximum supported size of \",\n-        kKernelArgsLimit));\n-  }\n-\n-  // Specialize kernel arguments array for small sizes to allocate a smaller\n-  // chunk of memory and hopefully hit a small allocations cache.\n-  if (args.size() <= 4) {\n-    return internal::PackKernelArgs<4>(args, shared_mem_bytes);\n-  } else if (args.size() <= 8) {\n-    return internal::PackKernelArgs<8>(args, shared_mem_bytes);\n-  } else if (args.size() <= 16) {\n-    return internal::PackKernelArgs<16>(args, shared_mem_bytes);\n-  } else if (args.size() <= 32) {\n-    return internal::PackKernelArgs<32>(args, shared_mem_bytes);\n-  } else if (args.size() <= 64) {\n-    return internal::PackKernelArgs<64>(args, shared_mem_bytes);\n-  } else if (args.size() <= 256) {\n-    return internal::PackKernelArgs<256>(args, shared_mem_bytes);\n-  } else if (args.size() <= 512) {\n-    return internal::PackKernelArgs<512>(args, shared_mem_bytes);\n-  }\n-\n-  return internal::PackKernelArgs<kKernelArgsLimit>(args, shared_mem_bytes);\n-}\n-\n-template <typename ArgType>\n-inline absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>\n-PackKernelArgs(absl::Span<const ArgType> args, const KernelMetadata& metadata) {\n-  return PackKernelArgs(args, metadata.shared_memory_bytes().value_or(0));\n-}\n-\n-//===----------------------------------------------------------------------===//\n-// Kernel arguments packing for statically know argument types\n-//===----------------------------------------------------------------------===//\n-\n-// KernelArgsPackedTuple is optimized for packing arguments when their types are\n-// known at compile time, and somewhat similar to `std::tuple` but with a few\n-// special rules for passing device memory arguments.\n-\n-namespace internal {\n-\n-// PackedArgType template specialization defines what storage type we'll be\n-// using for each kernel argument type:\n-//\n-//   (1) We always strip references and store a copy of an argument.\n-//   (2) We do not support pointer arguments, as we should not be passing a\n-//       pointers to host memory to device kernels.\n-//   (3) DeviceMemory passed as an opaque `void*` pointer.\n-//   (4) We have a special case for passing pointers to DeviceMemory where we\n-//       also pass it as an opaque device pointer.\n-template <typename T>\n-struct PackedArgType {\n-  static_assert(!std::is_pointer_v<T>, \"cannot pass raw pointer to the device\");\n-  using Type = T;\n-};\n-\n-template <>\n-struct PackedArgType<DeviceMemoryBase> {\n-  using Type = const void*;\n-};\n-\n-template <typename T>\n-struct PackedArgType<DeviceMemory<T>> {\n-  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n-};\n-\n-template <>\n-struct PackedArgType<DeviceMemoryBase*> {\n-  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n-};\n-\n-template <>\n-struct PackedArgType<const DeviceMemoryBase*> {\n-  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n-};\n-\n-template <typename T>\n-struct PackedArgType<DeviceMemory<T>*> {\n-  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n-};\n-\n-template <typename T>\n-struct PackedArgType<const DeviceMemory<T>*> {\n-  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n-};\n-\n-// Overload set for packing kernel arguments. This overload set matches\n-// supported kernel arguments types defined by `PackedArgType`.\n-template <typename T, std::enable_if_t<!std::is_pointer_v<T>>* = nullptr>\n-T PackArg(const T& arg) {\n-  return arg;\n-}\n-\n-inline const void* PackArg(const DeviceMemoryBase& arg) { return arg.opaque(); }\n-inline const void* PackArg(const DeviceMemoryBase* arg) {\n-  return PackArg(*arg);\n-}\n-\n-template <typename T>\n-const void* PackArg(const DeviceMemory<T>& arg) {\n-  return arg.opaque();\n-}\n-\n-template <typename T>\n-const void* PackArg(const DeviceMemory<T>* arg) {\n-  return PackArg(*arg);\n-}\n-\n-}  // namespace internal\n-\n-template <typename... Args>\n-class KernelArgsPackedTuple : public KernelArgsPackedArrayBase {\n- public:\n-  static constexpr size_t kSize = sizeof...(Args);\n-\n-  using Storage = std::tuple<\n-      typename internal::PackedArgType<absl::remove_cvref_t<Args>>::Type...>;\n-\n-  explicit KernelArgsPackedTuple(Args... args, size_t shared_memory_bytes)\n-      : storage_(internal::PackArg(std::forward<Args>(args))...),\n-        shared_memory_bytes_(shared_memory_bytes) {\n-    InitializeArgumentAddresses(std::make_index_sequence<kSize>{});\n-  }\n-\n-  // KernelArgsPackedTuple is not copyable or movable because argument addresses\n-  // point to inline storage that can't be moved.\n-  KernelArgsPackedTuple(const KernelArgsPackedTuple&) = delete;\n-  KernelArgsPackedTuple& operator=(const KernelArgsPackedTuple&) = delete;\n-\n-  size_t number_of_arguments() const final {\n-    return kSize + (shared_memory_bytes_ > 0);\n-  }\n-\n-  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n-\n-  absl::Span<const void* const> argument_addresses() const final {\n-    return absl::Span<const void* const>(argument_addresses_.data(), kSize);\n-  }\n-\n-  // Compile time check that KernelArgsPackedTuple is compatible with\n-  // `OtherArgs`: after stripping const and reference all types match.\n-  template <typename... OtherArgs>\n-  static void CheckCompatibleStaticAssert() {\n-    static constexpr size_t kOtherSize = sizeof...(OtherArgs);\n-    static_assert(kSize == kOtherSize, \"length of arguments packs must match\");\n-\n-    using StrippedArgs = std::tuple<absl::remove_cvref_t<Args>...>;\n-    using StrippedOtherArgs = std::tuple<absl::remove_cvref_t<OtherArgs>...>;\n-    static_assert(std::is_same_v<StrippedArgs, StrippedOtherArgs>,\n-                  \"arguments types do not match\");\n-  }\n-\n- private:\n-  template <size_t... Is>\n-  void InitializeArgumentAddresses(std::index_sequence<Is...>) {\n-    ((argument_addresses_[Is] = &std::get<Is>(storage_)), ...);\n-  }\n-\n-  // Storage for packed kernel arguments.\n-  Storage storage_;\n-\n-  // Shared memory required by a kernel.\n-  size_t shared_memory_bytes_ = 0;\n-\n-  // Pointers into `storage_`.\n-  std::array<const void*, kSize> argument_addresses_;\n-};\n-\n-// Packs the given arguments into a KernelArgsPackedTuple.\n-template <typename... Args>\n-std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(int64_t shmem_bytes,\n-                                                          Args... args) {\n-  using PackedArgs = KernelArgsPackedTuple<Args...>;\n-  return std::make_unique<PackedArgs>(std::forward<Args>(args)..., shmem_bytes);\n-}\n-\n // Packs the given arguments into a KernelArgsPackedTuple with compile-time type\n // checks that arguments are compatible with TypedKernel signature.\n template <typename... Params, typename... Args>"
        },
        {
            "sha": "e57ed57e4e544b9a245f3e5b2789fddea4b027c2",
            "filename": "third_party/xla/xla/stream_executor/kernel_args.h",
            "status": "added",
            "additions": 569,
            "deletions": 0,
            "changes": 569,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args.h?ref=900d4c4de113890017427e7f84d9cb7015f970a0",
            "patch": "@@ -0,0 +1,569 @@\n+/* Copyright 2015 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_KERNEL_ARGS_H_\n+#define XLA_STREAM_EXECUTOR_KERNEL_ARGS_H_\n+\n+#include <array>\n+#include <cassert>\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstring>\n+#include <memory>\n+#include <tuple>\n+#include <type_traits>\n+#include <utility>\n+#include <variant>\n+\n+#include \"absl/base/optimization.h\"\n+#include \"absl/container/inlined_vector.h\"\n+#include \"absl/functional/overload.h\"\n+#include \"absl/log/check.h\"\n+#include \"absl/meta/type_traits.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/types/span.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/kernel_metadata.h\"\n+\n+namespace stream_executor {\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments\n+//===----------------------------------------------------------------------===//\n+\n+// A virtual base class for passing kernel arguments to a stream executor APIs.\n+class KernelArgs {\n+ public:\n+  template <typename T>\n+  using IsKernelArgs = std::enable_if_t<std::is_base_of<KernelArgs, T>::value>;\n+\n+  enum class Kind {\n+    // A list of type-erased DeviceMemoryBase pointers to on-device memory. This\n+    // type of kernel arguments used only when the kernel has to do its own\n+    // custom packing, e.g. wrap all device pointers into a custom\n+    // structure, but can't be implemented as a TypedKernel because it has to be\n+    // passed around as a generic Kernel.\n+    kDeviceMemoryArray,\n+\n+    // A list of kernel arguments packed into a storage that can be passed\n+    // directly to device kernel as void** kernel parameters.\n+    kPackedArray\n+  };\n+\n+  virtual ~KernelArgs() = default;\n+\n+  // Gets the number of arguments added so far, including shared memory\n+  // arguments.\n+  virtual size_t number_of_arguments() const = 0;\n+\n+  // Gets the total number of shared memory bytes added so far.\n+  virtual uint64_t number_of_shared_bytes() const = 0;\n+\n+  virtual Kind kind() const = 0;\n+};\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments packed array\n+//===----------------------------------------------------------------------===//\n+\n+// A virtual base class for passing kernel arguments packed into a storage so\n+// that we have stable addresses for all arguments. This is a low level API for\n+// passing arguments in a platform-specific way that relies on the knowledge of\n+// the ABI of the underlying platform.\n+//\n+// For example `cuLaunchKernel` accepts arguments as `void** kernelParams`, and\n+// packed array base guarantees that `argument_addresses` are compatible with\n+// the CUDA APIs.\n+//\n+// See: https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__EXEC.html\n+class KernelArgsPackedArrayBase : public KernelArgs {\n+ public:\n+  // Gets the list of argument addresses.\n+  virtual absl::Span<const void* const> argument_addresses() const = 0;\n+\n+  static bool classof(const KernelArgs* args) {\n+    return args->kind() == Kind::kPackedArray;\n+  }\n+\n+  Kind kind() const final { return Kind::kPackedArray; }\n+};\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments LLVM-style RTTI library\n+//===----------------------------------------------------------------------===//\n+\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+T* Cast(KernelArgs* args) {\n+  CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n+                          << typeid(T).name();\n+  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n+  return static_cast<const T*>(args);\n+}\n+\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* Cast(const KernelArgs* args) {\n+  CHECK(T::classof(args)) << \"Invalid arguments casting to a destination type: \"\n+                          << typeid(T).name();\n+  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n+  return static_cast<const T*>(args);\n+}\n+\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* DynCast(const KernelArgs* args) {\n+  CHECK(args != nullptr) << \"Casted arguments must be not null\";\n+  return T::classof(args) ? static_cast<const T*>(args) : nullptr;\n+}\n+\n+template <class T, KernelArgs::IsKernelArgs<T>* = nullptr>\n+const T* DynCastOrNull(const KernelArgs* args) {\n+  return args && T::classof(args) ? static_cast<const T*>(args) : nullptr;\n+}\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments device memory array\n+//===----------------------------------------------------------------------===//\n+\n+class KernelArgsDeviceMemoryArray : public KernelArgs {\n+ public:\n+  KernelArgsDeviceMemoryArray(absl::Span<const DeviceMemoryBase> args,\n+                              size_t shared_memory_bytes)\n+      : device_memory_args_(args.begin(), args.end()),\n+        shared_memory_bytes_(shared_memory_bytes) {}\n+\n+  static bool classof(const KernelArgs* args) {\n+    return args->kind() == Kind::kDeviceMemoryArray;\n+  }\n+\n+  Kind kind() const final { return Kind::kDeviceMemoryArray; }\n+\n+  size_t number_of_arguments() const final {\n+    return device_memory_args_.size() + (shared_memory_bytes_ > 0);\n+  }\n+\n+  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n+\n+  absl::Span<const DeviceMemoryBase> device_memory_args() const {\n+    return device_memory_args_;\n+  }\n+\n+  const void* device_memory_ptr(size_t index) const {\n+    return device_memory_args_[index].opaque();\n+  }\n+\n+  size_t device_memory_size(size_t index) const {\n+    return device_memory_args_[index].size();\n+  }\n+\n+ private:\n+  absl::InlinedVector<DeviceMemoryBase, 4> device_memory_args_;\n+  size_t shared_memory_bytes_ = 0;\n+};\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments packing for device memory and POD args\n+//===----------------------------------------------------------------------===//\n+\n+// KernelArgsPackedArray is optimized for packing DeviceMemoryBase pointers\n+// and POD arguments (i.e. scalars) when the number and type of arguments are\n+// not known at compile time.\n+\n+namespace internal {\n+\n+// An empty storage for packing just the device memory arguments, that are\n+// stored directly in the `KernelArgsPackedArray`.\n+struct EmptyArgs {\n+  static constexpr size_t kSize = 0;\n+};\n+\n+// A storage for POD generic arguments that are smaller than `size` and require\n+// alignment smaller or equal to `alignment`.\n+template <size_t capacity, size_t size = 8,\n+          size_t alignment = alignof(std::max_align_t)>\n+class PodArgs {\n+ public:\n+  static constexpr size_t kSize = size;\n+\n+ protected:\n+  template <typename T>\n+  const std::byte* add_pod_argument(const T& arg) {\n+    static_assert(std::is_trivially_copyable_v<T> &&\n+                      sizeof(T) <= size & alignof(T) <= alignment,\n+                  \"Type is not compatible with POD arguments storage\");\n+\n+    assert(num_args_ < capacity && \"pod args overflow\");\n+    std::byte* arg_storage = args_storage_[num_args_++].storage;\n+    std::memcpy(arg_storage, &arg, sizeof(T));\n+\n+    return arg_storage;\n+  }\n+\n+ private:\n+  struct Arg {\n+    alignas(alignment) std::byte storage[size];\n+  };\n+\n+  size_t num_args_ = 0;\n+  std::array<Arg, capacity> args_storage_;\n+};\n+\n+template <typename ArgsStorage>\n+static constexpr bool is_pod_args_v = false;\n+\n+template <size_t capacity, size_t size, size_t alignment>\n+static constexpr bool is_pod_args_v<PodArgs<capacity, size, alignment>> = true;\n+\n+}  // namespace internal\n+\n+// An array of arguments for a kernel call.\n+//\n+// The template parameter `num_args` is the maximum number of arguments which\n+// can be stored in the array.\n+template <size_t num_args, typename ArgsStorage = internal::PodArgs<num_args>>\n+class KernelArgsPackedArray : public KernelArgsPackedArrayBase, ArgsStorage {\n+ public:\n+  KernelArgsPackedArray() = default;\n+\n+  // KernelArgsPackedArray is not copyable or movable because argument addresses\n+  // point to inline storage that can't be moved.\n+  KernelArgsPackedArray(const KernelArgsPackedArray&) = delete;\n+  KernelArgsPackedArray& operator=(const KernelArgsPackedArray&) = delete;\n+\n+  // Adds an argument to the list.\n+  template <typename T>\n+  void add_argument(const T& arg) {\n+    if constexpr (internal::is_pod_args_v<ArgsStorage>) {\n+      argument_addresses_[number_of_argument_addresses_++] =\n+          ArgsStorage::add_pod_argument(arg);\n+    } else {\n+      // https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p2593r0.html\n+      static_assert(sizeof(T) == 0, \"Arguments storage is not supported\");\n+    }\n+  }\n+\n+  // Adds a device memory argument to the list.\n+  void add_device_memory_argument(const DeviceMemoryBase& arg) {\n+    const void** copy_ptr =\n+        &device_memory_opaque_pointers_[number_of_argument_addresses_];\n+    *copy_ptr = arg.opaque();\n+    argument_addresses_[number_of_argument_addresses_] = copy_ptr;\n+    ++number_of_argument_addresses_;\n+  }\n+\n+  // Adds a shared memory argument to the list.\n+  //\n+  // The only significant information about a shared argument is its size, so\n+  // that is the only parameter in this function.\n+  void add_shared_bytes(size_t number_of_bytes) {\n+    shared_memory_bytes_ += number_of_bytes;\n+  }\n+\n+  // Gets the number of arguments added so far, including shared memory\n+  // arguments.\n+  size_t number_of_arguments() const final {\n+    return number_of_argument_addresses_ + (shared_memory_bytes_ > 0);\n+  }\n+\n+  // Gets the total number of shared memory bytes added so far.\n+  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n+\n+  // Gets the list of argument addresses.\n+  absl::Span<const void* const> argument_addresses() const final {\n+    return absl::Span<const void* const>(argument_addresses_.data(),\n+                                         number_of_argument_addresses_);\n+  }\n+\n+ private:\n+  // A place to store copies of opaque pointers from device memory arguments.\n+  std::array<const void*, num_args> device_memory_opaque_pointers_;\n+\n+  // Addresses for non-shared-memory arguments.\n+  std::array<const void*, num_args> argument_addresses_;\n+\n+  // Shared memory required by a kernel.\n+  size_t shared_memory_bytes_ = 0;\n+\n+  // Number of significant entries in argument_addresses_.\n+  size_t number_of_argument_addresses_ = 0;\n+};\n+\n+using KernelArgument = std::variant<DeviceMemoryBase, TensorMap, int64_t>;\n+\n+namespace internal {\n+template <int n>\n+std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n+    absl::Span<const DeviceMemoryBase> args, uint32_t shared_mem_bytes) {\n+  auto packed = std::make_unique<KernelArgsPackedArray<n, EmptyArgs>>();\n+  for (const DeviceMemoryBase& buf : args) {\n+    packed->add_device_memory_argument(buf);\n+  }\n+  if (shared_mem_bytes > 0) {\n+    packed->add_shared_bytes(shared_mem_bytes);\n+  }\n+  return packed;\n+}\n+\n+template <int n, typename ArgsStorage>\n+std::unique_ptr<KernelArgsPackedArray<n, ArgsStorage>> PackKernelArgsImpl(\n+    absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n+  auto packed = std::make_unique<KernelArgsPackedArray<n, ArgsStorage>>();\n+  for (const auto& arg : args) {\n+    std::visit(\n+        absl::Overload{\n+            [&](const DeviceMemoryBase& device_memory) {\n+              packed->add_device_memory_argument(device_memory);\n+            },\n+            [&](int64_t int_arg) {\n+              if constexpr (ArgsStorage::kSize >= sizeof(int64_t)) {\n+                packed->add_argument(int_arg);\n+              }\n+            },\n+            [&](const TensorMap& tensor_map) {\n+              if constexpr (ArgsStorage::kSize >= sizeof(tensor_map.storage)) {\n+                packed->add_argument(tensor_map.storage);\n+              }\n+            },\n+        },\n+        arg);\n+  }\n+  if (shared_mem_bytes > 0) {\n+    packed->add_shared_bytes(shared_mem_bytes);\n+  }\n+  return packed;\n+}\n+\n+template <int n>\n+std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(\n+    absl::Span<const KernelArgument> args, uint32_t shared_mem_bytes) {\n+  const int32_t pod_size = [](absl::Span<const KernelArgument> args) {\n+    bool has_int = false;\n+    for (const auto& arg : args) {\n+      if (std::holds_alternative<TensorMap>(arg)) {\n+        return 128;\n+      }\n+      if (std::holds_alternative<int64_t>(arg)) {\n+        has_int = true;\n+      }\n+    }\n+    return has_int ? 64 : 0;\n+  }(args);\n+\n+  switch (pod_size) {\n+    case 128:\n+      return PackKernelArgsImpl<n, PodArgs<n, 128, 64>>(args, shared_mem_bytes);\n+    case 64:\n+      return PackKernelArgsImpl<n, PodArgs<n, 64, 64>>(args, shared_mem_bytes);\n+    case 0:\n+      return PackKernelArgsImpl<n, EmptyArgs>(args, shared_mem_bytes);\n+    default:\n+      ABSL_UNREACHABLE();\n+  }\n+}\n+}  // namespace internal\n+\n+template <typename ArgType>\n+inline absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>\n+PackKernelArgs(absl::Span<const ArgType> args, uint32_t shared_mem_bytes) {\n+  static constexpr int kKernelArgsLimit = 1024;\n+\n+  if (args.size() > kKernelArgsLimit) {\n+    return absl::InvalidArgumentError(absl::StrCat(\n+        \"Can't pack device memory arguments array of size \", args.size(),\n+        \" which is larger than the maximum supported size of \",\n+        kKernelArgsLimit));\n+  }\n+\n+  // Specialize kernel arguments array for small sizes to allocate a smaller\n+  // chunk of memory and hopefully hit a small allocations cache.\n+  if (args.size() <= 4) {\n+    return internal::PackKernelArgs<4>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 8) {\n+    return internal::PackKernelArgs<8>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 16) {\n+    return internal::PackKernelArgs<16>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 32) {\n+    return internal::PackKernelArgs<32>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 64) {\n+    return internal::PackKernelArgs<64>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 256) {\n+    return internal::PackKernelArgs<256>(args, shared_mem_bytes);\n+  }\n+  if (args.size() <= 512) {\n+    return internal::PackKernelArgs<512>(args, shared_mem_bytes);\n+  }\n+\n+  return internal::PackKernelArgs<kKernelArgsLimit>(args, shared_mem_bytes);\n+}\n+\n+template <typename ArgType>\n+inline absl::StatusOr<std::unique_ptr<KernelArgsPackedArrayBase>>\n+PackKernelArgs(absl::Span<const ArgType> args, const KernelMetadata& metadata) {\n+  return PackKernelArgs(args, metadata.shared_memory_bytes().value_or(0));\n+}\n+\n+//===----------------------------------------------------------------------===//\n+// Kernel arguments packing for statically know argument types\n+//===----------------------------------------------------------------------===//\n+\n+// KernelArgsPackedTuple is optimized for packing arguments when their types are\n+// known at compile time, and somewhat similar to `std::tuple` but with a few\n+// special rules for passing device memory arguments.\n+\n+namespace internal {\n+\n+// PackedArgType template specialization defines what storage type we'll be\n+// using for each kernel argument type:\n+//\n+//   (1) We always strip references and store a copy of an argument.\n+//   (2) We do not support pointer arguments, as we should not be passing a\n+//       pointers to host memory to device kernels.\n+//   (3) DeviceMemory passed as an opaque `void*` pointer.\n+//   (4) We have a special case for passing pointers to DeviceMemory where we\n+//       also pass it as an opaque device pointer.\n+template <typename T>\n+struct PackedArgType {\n+  static_assert(!std::is_pointer_v<T>, \"cannot pass raw pointer to the device\");\n+  using Type = T;\n+};\n+\n+template <>\n+struct PackedArgType<DeviceMemoryBase> {\n+  using Type = const void*;\n+};\n+\n+template <typename T>\n+struct PackedArgType<DeviceMemory<T>> {\n+  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n+};\n+\n+template <>\n+struct PackedArgType<DeviceMemoryBase*> {\n+  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n+};\n+\n+template <>\n+struct PackedArgType<const DeviceMemoryBase*> {\n+  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n+};\n+\n+template <typename T>\n+struct PackedArgType<DeviceMemory<T>*> {\n+  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n+};\n+\n+template <typename T>\n+struct PackedArgType<const DeviceMemory<T>*> {\n+  using Type = typename PackedArgType<DeviceMemoryBase>::Type;\n+};\n+\n+// Overload set for packing kernel arguments. This overload set matches\n+// supported kernel arguments types defined by `PackedArgType`.\n+template <typename T, std::enable_if_t<!std::is_pointer_v<T>>* = nullptr>\n+T PackArg(const T& arg) {\n+  return arg;\n+}\n+\n+inline const void* PackArg(const DeviceMemoryBase& arg) { return arg.opaque(); }\n+inline const void* PackArg(const DeviceMemoryBase* arg) {\n+  return PackArg(*arg);\n+}\n+\n+template <typename T>\n+const void* PackArg(const DeviceMemory<T>& arg) {\n+  return arg.opaque();\n+}\n+\n+template <typename T>\n+const void* PackArg(const DeviceMemory<T>* arg) {\n+  return PackArg(*arg);\n+}\n+\n+}  // namespace internal\n+\n+template <typename... Args>\n+class KernelArgsPackedTuple : public KernelArgsPackedArrayBase {\n+ public:\n+  static constexpr size_t kSize = sizeof...(Args);\n+\n+  using Storage = std::tuple<\n+      typename internal::PackedArgType<absl::remove_cvref_t<Args>>::Type...>;\n+\n+  explicit KernelArgsPackedTuple(Args... args, size_t shared_memory_bytes)\n+      : storage_(internal::PackArg(std::forward<Args>(args))...),\n+        shared_memory_bytes_(shared_memory_bytes) {\n+    InitializeArgumentAddresses(std::make_index_sequence<kSize>{});\n+  }\n+\n+  // KernelArgsPackedTuple is not copyable or movable because argument addresses\n+  // point to inline storage that can't be moved.\n+  KernelArgsPackedTuple(const KernelArgsPackedTuple&) = delete;\n+  KernelArgsPackedTuple& operator=(const KernelArgsPackedTuple&) = delete;\n+\n+  size_t number_of_arguments() const final {\n+    return kSize + (shared_memory_bytes_ > 0);\n+  }\n+\n+  uint64_t number_of_shared_bytes() const final { return shared_memory_bytes_; }\n+\n+  absl::Span<const void* const> argument_addresses() const final {\n+    return absl::Span<const void* const>(argument_addresses_.data(), kSize);\n+  }\n+\n+  // Compile time check that KernelArgsPackedTuple is compatible with\n+  // `OtherArgs`: after stripping const and reference all types match.\n+  template <typename... OtherArgs>\n+  static void CheckCompatibleStaticAssert() {\n+    static constexpr size_t kOtherSize = sizeof...(OtherArgs);\n+    static_assert(kSize == kOtherSize, \"length of arguments packs must match\");\n+\n+    using StrippedArgs = std::tuple<absl::remove_cvref_t<Args>...>;\n+    using StrippedOtherArgs = std::tuple<absl::remove_cvref_t<OtherArgs>...>;\n+    static_assert(std::is_same_v<StrippedArgs, StrippedOtherArgs>,\n+                  \"arguments types do not match\");\n+  }\n+\n+ private:\n+  template <size_t... Is>\n+  void InitializeArgumentAddresses(std::index_sequence<Is...>) {\n+    ((argument_addresses_[Is] = &std::get<Is>(storage_)), ...);\n+  }\n+\n+  // Storage for packed kernel arguments.\n+  Storage storage_;\n+\n+  // Shared memory required by a kernel.\n+  size_t shared_memory_bytes_ = 0;\n+\n+  // Pointers into `storage_`.\n+  std::array<const void*, kSize> argument_addresses_;\n+};\n+\n+// Packs the given arguments into a KernelArgsPackedTuple.\n+template <typename... Args>\n+std::unique_ptr<KernelArgsPackedArrayBase> PackKernelArgs(int64_t shmem_bytes,\n+                                                          Args... args) {\n+  using PackedArgs = KernelArgsPackedTuple<Args...>;\n+  return std::make_unique<PackedArgs>(std::forward<Args>(args)..., shmem_bytes);\n+}\n+\n+}  // namespace stream_executor\n+\n+#endif  // XLA_STREAM_EXECUTOR_KERNEL_ARGS_H_"
        },
        {
            "sha": "d10baf7a96b6887e98af79b6329b1d34a57b9dcf",
            "filename": "third_party/xla/xla/stream_executor/kernel_args_packed_vector.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_packed_vector.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_packed_vector.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_packed_vector.h?ref=900d4c4de113890017427e7f84d9cb7015f970a0",
            "patch": "@@ -22,7 +22,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/types/span.h\"\n-#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n \n namespace stream_executor {\n "
        },
        {
            "sha": "017247a3110b0afe26ffbdbcd1cc2b69b0243361",
            "filename": "third_party/xla/xla/stream_executor/kernel_args_test.cc",
            "status": "renamed",
            "additions": 1,
            "deletions": 9,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/900d4c4de113890017427e7f84d9cb7015f970a0/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fkernel_args_test.cc?ref=900d4c4de113890017427e7f84d9cb7015f970a0",
            "patch": "@@ -13,7 +13,7 @@ See the License for the specific language governing permissions and\n limitations under the License.\n ==============================================================================*/\n \n-#include \"xla/stream_executor/kernel.h\"\n+#include \"xla/stream_executor/kernel_args.h\"\n \n #include <cstdint>\n #include <memory>\n@@ -26,9 +26,6 @@ limitations under the License.\n #include \"benchmark/benchmark.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/kernel_metadata.h\"\n-#include \"xla/stream_executor/platform.h\"\n-#include \"xla/stream_executor/platform_manager.h\"\n-#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n namespace stream_executor {\n@@ -67,11 +64,6 @@ static_assert(\n     std::is_same_v<ArgsStorage<DeviceMemoryBase*, const DeviceMemoryBase*>,\n                    std::tuple<const void*, const void*>>);\n \n-static StreamExecutor* NewStreamExecutor() {\n-  Platform* platform = PlatformManager::PlatformWithName(\"Host\").value();\n-  return platform->ExecutorForDevice(/*ordinal=*/0).value();\n-}\n-\n TEST(KernelTest, PackDeviceMemoryArguments) {\n   DeviceMemoryBase a(reinterpret_cast<void*>(0x12345678));\n   DeviceMemoryBase b(reinterpret_cast<void*>(0x87654321));",
            "previous_filename": "third_party/xla/xla/stream_executor/kernel_test.cc"
        }
    ],
    "stats": {
        "total": 1171,
        "additions": 596,
        "deletions": 575
    }
}