{
    "author": "shawnwang18",
    "message": "PR #33655: [XLA:GPU] Set NCCL kernels to highest priority in cuda graph\n\nImported from GitHub PR https://github.com/openxla/xla/pull/33655\n\nüìù Summary of Changes\nThis PR change the default priority for NCCL kernels in command buffer to highest priority, which is the same as when NCCL is running without cuda-graph.\n\nüéØ Justification\nTest below workloads on GB200 clusters, the PR's perf improvements, all have perf improvements, I think we should make the default setting.\n\n<img width=\"283\" height=\"155\" alt=\"image\" src=\"https://github.com/user-attachments/assets/377a7776-912b-42d3-a48e-a948be56c3c5\" />\n\nüöÄ Kind of Contribution\n‚ö°Ô∏è Performance Improvement,\n\nüß™ Unit Tests:\nChange the default settings for command buffer command, not new feature.\n\nCopybara import of the project:\n\n--\ne50386a638abf6e346c1c8f2ca2512d924406676 by Shawn Wang <shawnw@nvidia.com>:\n\nSet NCCL kernels to highest priority in cuda graph\n\nMerging this change closes #33655\n\nPiperOrigin-RevId: 829330139",
    "sha": "7c09e90f2f6a17ba0e5c387c2530c19547f709f4",
    "files": [
        {
            "sha": "001bfe94ebd7a5f51c776a368cf0108ee2833861",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7c09e90f2f6a17ba0e5c387c2530c19547f709f4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7c09e90f2f6a17ba0e5c387c2530c19547f709f4/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=7c09e90f2f6a17ba0e5c387c2530c19547f709f4",
            "patch": "@@ -2001,7 +2001,7 @@ CommandBufferCmd::BufferUseVector CustomCallCmd::buffers() const {\n CollectiveCmd::CollectiveCmd(\n     CommandBufferCmdType cmd_type, CollectiveConfig config,\n     std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n-    : CommandBufferCmd(cmd_type),\n+    : CommandBufferCmd(cmd_type, se::StreamPriority::Highest),\n       config_(std::move(config)),\n       async_events_(std::move(async_events)) {}\n "
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}