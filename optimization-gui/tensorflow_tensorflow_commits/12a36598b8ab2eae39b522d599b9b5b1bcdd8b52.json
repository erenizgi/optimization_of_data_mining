{
    "author": "subhankarshah",
    "message": "[XLA:MSA] Perform block prefetching before allocating reserved scoped allocations but reserve alternate memory for reserved scoped allocations in advance.\n* Do not rely on repack allocation blocks being empty to colocate scoped allocations\n\nPiperOrigin-RevId: 834494068",
    "sha": "12a36598b8ab2eae39b522d599b9b5b1bcdd8b52",
    "files": [
        {
            "sha": "fc822cf421ce33c00b7584cf372ece22e9b7bc01",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 59,
            "deletions": 38,
            "changes": 97,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=12a36598b8ab2eae39b522d599b9b5b1bcdd8b52",
            "patch": "@@ -2003,13 +2003,12 @@ absl::Status MsaAlgorithm::ProcessColoredBuffers() {\n   return absl::OkStatus();\n }\n \n-int64_t MsaAlgorithm::MaxScopedMemoryOffset() {\n+int64_t MsaAlgorithm::MaxScopedMemorySize() {\n   const std::vector<HloInstruction*>& instruction_sequence =\n       hlo_live_range_.flattened_instruction_sequence().instructions();\n   int64_t max_reserved_scoped_memory = 0;\n-  for (BreadthFirstMidpointIterator it(0, instruction_sequence.size() - 1);\n-       !it.End(); it.Next()) {\n-    HloInstruction* instruction = instruction_sequence[it.value()];\n+  for (int64_t i = 0; i < instruction_sequence.size(); ++i) {\n+    HloInstruction* instruction = instruction_sequence[i];\n     int64_t reserved_scoped_memory =\n         std::min(options_.reserved_scoped_memory_fn(\n                      instruction, /*operands_in_alternate_memory=*/{},\n@@ -2172,7 +2171,8 @@ void PopulateExistingBlockPrefetchedValues(\n \n }  // namespace\n \n-absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches() {\n+absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches(\n+    int64_t block_prefetching_starting_offset) {\n   if (options_.hlo_position_to_custom_call_prefetch_details.empty()) {\n     return absl::OkStatus();\n   }\n@@ -2215,10 +2215,6 @@ absl::Status MsaAlgorithm::AllocateAndScheduleExistingBlockPrefetches() {\n                         value_to_use_intervals.at(b).first_use_time;\n                });\n \n-  // We need to reserve a continuous block of memory for the block prefetches,\n-  // since scoped allocations are initially placed at offset 0 we place the\n-  // block prefetches at the end of the reserved scoped allocations.\n-  int64_t block_prefetching_starting_offset = MaxScopedMemoryOffset();\n   // All block prefetches should be placed within this limit.\n   int64_t block_prefetching_limit_bytes =\n       block_prefetching_starting_offset +\n@@ -2513,7 +2509,8 @@ void MsaAlgorithm::ColocateAndFinalizeValuesAliasedToExistingBlockPrefetches(\n   MarkRepackAllocationBlocksColocated(colocations);\n }\n \n-absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n+absl::Status MsaAlgorithm::CreateNewBlockPrefetches(\n+    int64_t block_prefetching_starting_offset) {\n   if (!options_.hlo_position_to_custom_call_prefetch_details.empty() ||\n       options_.reserved_bytes_for_block_prefetches <= 0) {\n     return absl::OkStatus();\n@@ -2604,10 +2601,6 @@ absl::Status MsaAlgorithm::CreateNewBlockPrefetches() {\n                         value_to_use_intervals.at(b).first_use_time;\n                });\n \n-  // Block allocations can also happen in the fragmented scoped memory, so we\n-  // need to account for the max reserved scoped memory in the block prefetched\n-  // memory limit.\n-  int64_t block_prefetching_starting_offset = MaxScopedMemoryOffset();\n   int64_t block_prefetching_limit_bytes =\n       block_prefetching_starting_offset +\n       options_.reserved_bytes_for_block_prefetches;\n@@ -2904,6 +2897,37 @@ void MsaAlgorithm::ColocateAndFinalizeValuesAliasedToNewBlockPrefetches(\n   MarkRepackAllocationBlocksColocated(colocations);\n }\n \n+int64_t MsaAlgorithm::ReserveAlternateMemoryForScopedMemoryAllocations() {\n+  int64_t max_scoped_memory_size = MaxScopedMemorySize();\n+  int program_start_time = 0;\n+  int program_end_time =\n+      hlo_live_range_.flattened_instruction_sequence().instructions().size() -\n+      1;\n+  MsaBufferInterval interval;\n+  interval.buffer = nullptr;\n+  interval.size = max_scoped_memory_size;\n+  interval.start = program_start_time;\n+  interval.end = program_end_time;\n+  interval.need_allocation = true;\n+  HeapSimulator::Chunk chunk_candidate =\n+      FindChunkCandidate(interval, /*preferred_offset=*/0);\n+  CHECK_EQ(chunk_candidate.offset, 0);\n+  CHECK_EQ(chunk_candidate.size, max_scoped_memory_size);\n+  CommitChunk(interval, chunk_candidate);\n+  return max_scoped_memory_size;\n+}\n+\n+void MsaAlgorithm::FreeAlternateMemoryForScopedMemoryAllocations(\n+    int64_t max_scoped_memory_size) {\n+  int program_start_time = 0;\n+  int program_end_time =\n+      hlo_live_range_.flattened_instruction_sequence().instructions().size() -\n+      1;\n+  HeapSimulator::Chunk chunk = HeapSimulator::Chunk::FromOffsetSize(\n+      /*offset=*/0, /*size=*/max_scoped_memory_size);\n+  interval_tree_.Remove(program_start_time, program_end_time, chunk);\n+}\n+\n absl::StatusOr<HeapSimulator::Result<HloValue>> MsaAlgorithm::Finish() {\n   // Note: Memory Space Assignment creates a HeapSimulator and passes an\n   // MsaAlgorithm object to it. buffer_intervals_ is populated by calling the\n@@ -2916,10 +2940,19 @@ absl::StatusOr<HeapSimulator::Result<HloValue>> MsaAlgorithm::Finish() {\n           << (options_.sliced_prefetch_options.max_slices() >= 2 ? \"enabled\"\n                                                                  : \"disabled\");\n \n-  AllocateReservedScopedAllocations();\n+  // Reserve alternate memory for scoped memory allocations before block\n+  // prefetches are allocated strictly above the MaxScopedMemorySize().\n+  int64_t max_scoped_memory_size =\n+      ReserveAlternateMemoryForScopedMemoryAllocations();\n \n-  TF_RETURN_IF_ERROR(AllocateAndScheduleExistingBlockPrefetches());\n-  TF_RETURN_IF_ERROR(CreateNewBlockPrefetches());\n+  TF_RETURN_IF_ERROR(\n+      AllocateAndScheduleExistingBlockPrefetches(max_scoped_memory_size));\n+  TF_RETURN_IF_ERROR(CreateNewBlockPrefetches(max_scoped_memory_size));\n+\n+  // Free the alternate memory reserved for scoped memory allocations before\n+  // allocating the scoped memory allocations.\n+  FreeAlternateMemoryForScopedMemoryAllocations(max_scoped_memory_size);\n+  AllocateReservedScopedAllocations();\n \n   std::vector<MsaBufferInterval> sorted_buffer_intervals =\n       GetSortedBufferIntervals();\n@@ -5067,12 +5100,7 @@ void MsaAlgorithm::AllocateCrossProgramPrefetchBuffer(\n void MsaAlgorithm::AllocateReservedScopedAllocations() {\n   const std::vector<HloInstruction*>& instruction_sequence =\n       hlo_live_range_.flattened_instruction_sequence().instructions();\n-  if (options_.allocate_reserved_scoped_memory_at_same_offset) {\n-    // If we are co-locating scoped allocations, then we need to make sure that\n-    // the repack allocation blocks are empty, because we mark all the repack\n-    // allocation blocks as co-located in a loop below.\n-    CHECK(repack_allocation_blocks_.empty());\n-  }\n+  std::vector<AllocationBlock*> colocations;\n   for (BreadthFirstMidpointIterator it(0, instruction_sequence.size() - 1);\n        !it.End(); it.Next()) {\n     HloInstruction* instruction = instruction_sequence[it.value()];\n@@ -5085,42 +5113,34 @@ void MsaAlgorithm::AllocateReservedScopedAllocations() {\n       continue;\n     }\n     AllocateScopedAllocation(instruction, /*is_post_module=*/false,\n-                             reserved_scoped_memory, it.value());\n+                             reserved_scoped_memory, it.value(), colocations);\n   }\n   // If requested, make all scoped allocations to colocate with each other so\n   // that when we repack, all scoped allocations get the same offsets. Since\n   // they will all have the same scoped memory addresses, this increases the\n   // opportunity to deduplicate different ops.  However, this may hurt the\n   // memory packing efficiency.\n   if (options_.allocate_reserved_scoped_memory_at_same_offset) {\n-    for (auto allocation_block_it = repack_allocation_blocks_.begin();\n-         allocation_block_it != repack_allocation_blocks_.end() &&\n-         std::next(allocation_block_it) != repack_allocation_blocks_.end();\n-         ++allocation_block_it) {\n-      allocation_block_it->next_colocated = &*std::next(allocation_block_it);\n-    }\n-    if (!repack_allocation_blocks_.empty()) {\n-      repack_allocation_blocks_.back().next_colocated =\n-          &repack_allocation_blocks_.front();\n-    }\n+    MarkRepackAllocationBlocksColocated(colocations);\n   }\n \n+  colocations.clear();\n   // Allocate post-module scoped allocation if requested. It never needs to be\n   // colocated with other scoped allocations.\n   if (options_.post_module_scoped_alternate_memory_size_in_bytes > 0) {\n     AllocateScopedAllocation(\n         /*instruction=*/module_->entry_computation()->root_instruction(),\n         /*is_post_module=*/true,\n         options_.post_module_scoped_alternate_memory_size_in_bytes,\n-        hlo_live_range_.schedule_end_time());\n+        hlo_live_range_.schedule_end_time(), colocations);\n   }\n \n   ClearPendingChunks();\n }\n \n-void MsaAlgorithm::AllocateScopedAllocation(HloInstruction* instruction,\n-                                            bool is_post_module, int64_t size,\n-                                            int64_t time) {\n+void MsaAlgorithm::AllocateScopedAllocation(\n+    HloInstruction* instruction, bool is_post_module, int64_t size,\n+    int64_t time, std::vector<AllocationBlock*>& colocations) {\n   VLOG(1) << \"Allocate reserved scoped memory at \" << time << \" (\"\n           << (is_post_module ? \"<post-module>\" : instruction->name())\n           << \"): \" << size;\n@@ -5147,6 +5167,7 @@ void MsaAlgorithm::AllocateScopedAllocation(HloInstruction* instruction,\n       /*initial_offset=*/0, allocations_->back().get()));\n   repack_allocation_blocks_.back().next_colocated =\n       &repack_allocation_blocks_.back();\n+  colocations.push_back(&repack_allocation_blocks_.back());\n }\n \n int64_t MsaAlgorithm::GetCorrectedUseTime("
        },
        {
            "sha": "4daa9c9f25e16137dfb77fac3f6c0818761b0b40",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 17,
            "deletions": 5,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=12a36598b8ab2eae39b522d599b9b5b1bcdd8b52",
            "patch": "@@ -365,13 +365,15 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   //\n   // REQUIRED: Scoped vmem must be allocated at offset 0 at the time this method\n   //           is called.\n-  absl::Status AllocateAndScheduleExistingBlockPrefetches();\n+  absl::Status AllocateAndScheduleExistingBlockPrefetches(\n+      int64_t block_prefetching_starting_offset);\n \n   // Create, allocate and schedule new block prefetches.\n   //\n   // REQUIRED: Scoped vmem must be allocated at offset 0 at the time this method\n   //           is called.\n-  absl::Status CreateNewBlockPrefetches();\n+  absl::Status CreateNewBlockPrefetches(\n+      int64_t block_prefetching_starting_offset);\n \n   // Creates colocated allocations for values aliased to the new block\n   // prefetches and finalizes them.\n@@ -401,7 +403,7 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n \n   // Returns the maximum amount of scoped memory that is reserved at any time in\n   // the program.\n-  int64_t MaxScopedMemoryOffset();\n+  int64_t MaxScopedMemorySize();\n \n   // Finds and returns the earliest block prefetch start time subject to the\n   // following constraints:\n@@ -698,9 +700,11 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   // Allocates buffers for instructions that need reserved scoped allocations in\n   // the alternate memory space.\n   void AllocateReservedScopedAllocations();\n+\n+  // Creates a ScopedAllocation for the given instruction.\n   void AllocateScopedAllocation(HloInstruction* instruction,\n-                                bool is_post_module, int64_t size,\n-                                int64_t time);\n+                                bool is_post_module, int64_t size, int64_t time,\n+                                std::vector<AllocationBlock*>& colocations);\n \n   // Returns the AliasedOffset object associated with the allocation.\n   AliasedOffset* GetAliasedOffset(const Allocation& allocation);\n@@ -1234,6 +1238,14 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   bool IsPositionColoredInDefaultMemoryAtTime(const HloPosition& position,\n                                               int64_t time) const;\n \n+  // Reserves a chunk in alternate memory of size MaxScopedMemorySize() for\n+  // the entire program duration for scoped memory allocations.\n+  int64_t ReserveAlternateMemoryForScopedMemoryAllocations();\n+\n+  // Frees the alternate memory reserved for scoped memory allocations.\n+  void FreeAlternateMemoryForScopedMemoryAllocations(\n+      int64_t max_scoped_memory_size);\n+\n   HloModule* module_ = nullptr;\n   AllocationSequence* allocations_;\n   // Edge time indices store start and end times allocations in alternate"
        },
        {
            "sha": "08af63308cf5c52090e15ce3c0be86d2b9b3b8ad",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/12a36598b8ab2eae39b522d599b9b5b1bcdd8b52/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=12a36598b8ab2eae39b522d599b9b5b1bcdd8b52",
            "patch": "@@ -14916,6 +14916,82 @@ ENTRY entry {\n       /*operand_memory_space=*/kDefaultMemorySpace);\n }\n \n+TEST_F(MemorySpaceAssignmentTest,\n+       TestBlockPrefetchingWithAliasingAndScopedAllocations) {\n+  // Simple block prefetching test where p0 is block prefetched and aliases with\n+  // custom_call2 and custom_call8 which is used at add13. This makes the\n+  // effective aliased live range of the block prefetch p0 to be the entire\n+  // program duration. We also have a scoped allocation for negate10 which\n+  // reserves 24 bytes of scoped memory. The alternate memory is enough for\n+  // prefetching p0 and allocating scoped memory for negate10.\n+\n+  // If we allocate scoped memory before block prefetching, 24 bytes of scoped\n+  // memory for negate10 will be allocated at offset 0. Block prefetch for p0\n+  // will also get offset 0, but we would not be able to extend it past the\n+  // scoped allocation of negate10 when we try to extend it for the entire live\n+  // range.\n+\n+  // To make sure we dont allocate block prefetches below MaxScopedMemorySize\n+  // we reserve memory for scoped allocations before block prefetching and\n+  // process scoped allocations after block prefetching.\n+  absl::string_view hlo_string = R\"(\n+HloModule module, is_scheduled=true\n+\n+ENTRY entry {\n+  p0 = f32[2,3]{1,0} parameter(0)\n+  p1 = f32[2,3]{1,0} parameter(1)\n+  custom_call2 = f32[2,3]{1,0} custom-call(p0), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate3 = f32[2,3]{1,0} negate(p1)\n+  negate4 = f32[2,3]{1,0} negate(negate3)\n+  negate5 = f32[2,3]{1,0} negate(negate4)\n+  negate6 = f32[2,3]{1,0} negate(negate5)\n+  negate7 = f32[2,3]{1,0} negate(negate6)\n+  custom_call8 = f32[2,3]{1,0} custom-call(custom_call2), custom_call_target=\"tpu_custom_call\", output_to_operand_aliasing={{}: (0, {})}\n+  negate9 = f32[2,3]{1,0} negate(negate7)\n+  negate10 = f32[2,3]{1,0} negate(negate9)\n+  negate11 = f32[2,3]{1,0} negate(negate10)\n+  negate12 = f32[2,3]{1,0} negate(negate11)\n+  ROOT add13 = f32[2,3]{1,0} add(custom_call8, negate12)\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_string));\n+  Options memory_space_options = DefaultMemorySpaceOptions();\n+  memory_space_options.max_size_in_bytes = 48;\n+  memory_space_options.reserved_bytes_for_block_prefetches = 24;\n+  memory_space_options.max_outstanding_block_prefetches = 10;\n+  memory_space_options.max_outstanding_prefetches = 0;\n+  memory_space_options.block_prefetched_positions = GetHloPositions(\n+      /*module=*/module.get(),\n+      /*instruction_names=*/{\"p0\"});\n+  memory_space_options.reserved_scoped_memory_fn =\n+      [&](const HloInstruction* instruction,\n+          const absl::flat_hash_set<std::pair<int, ShapeIndex>>\n+              operands_in_alternate_memory,\n+          const absl::flat_hash_set<ShapeIndex> outputs_in_alternate_memory) {\n+        if (instruction->name() == \"negate10\") {\n+          return 24;\n+        }\n+        return 0;\n+      };\n+\n+  XLA_LOG_LINES(INFO, \"Before MSA: \\n\" + module->ToString());\n+  AssignMemorySpaceUsingCostAnalysis(module.get(),\n+                                     std::move(memory_space_options));\n+  XLA_LOG_LINES(INFO, \"After MSA: \\n\" + module->ToString());\n+\n+  std::vector<std::string> prefetched_uses = {\"custom_call2\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/prefetched_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCopyDone,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+\n+  std::vector<std::string> aliased_uses = {\"custom_call8\", \"add13\"};\n+  CheckOperandOpcodeAndMemorySpaceForInstructionNames(\n+      /*module=*/module.get(), /*instruction_names=*/aliased_uses,\n+      /*operand_index=*/0, /*operand_opcode=*/HloOpcode::kCustomCall,\n+      /*operand_memory_space=*/kAlternateMemorySpace);\n+}\n+\n TEST_F(MemorySpaceAssignmentTest,\n        TestBlockPrefetchingWithInputOutputAliasConfig) {\n   absl::string_view hlo_string = R\"("
        }
    ],
    "stats": {
        "total": 195,
        "additions": 152,
        "deletions": 43
    }
}