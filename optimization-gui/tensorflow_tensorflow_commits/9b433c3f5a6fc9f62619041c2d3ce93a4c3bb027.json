{
    "author": "majnemer",
    "message": "Remove deprecated `Shape(const ShapeProto&)` constructor.\n\nThis change removes the deprecated `Shape(const ShapeProto&)` constructor and updates its call sites to use `Shape::FromProto` instead, which returns a `StatusOr<Shape>`. The call sites now explicitly handle the potential error status.\n\nPiperOrigin-RevId: 825288664",
    "sha": "9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027",
    "files": [
        {
            "sha": "71676585ce0916a3b753535587d853c7a2e3f690",
            "filename": "third_party/xla/xla/hlo/builder/value_inference.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fvalue_inference.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fvalue_inference.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fbuilder%2Fvalue_inference.cc?ref=9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027",
            "patch": "@@ -411,7 +411,8 @@ struct PostorderDFSVisitor {\n     for (int64_t operand_id : proto->operand_ids()) {\n       const HloInstructionProto* operand =\n           handle_to_instruction(operand_id).value();\n-      auto operand_shape = std::make_unique<Shape>(operand->shape());\n+      auto operand_shape = Shape::FromProto(operand->shape());\n+      TF_CHECK_OK(operand_shape.status());\n \n       if (operand_shape->IsArray() &&\n           ShapeUtil::ElementsIn(*operand_shape) > kLargeShapeElementLimit &&\n@@ -1715,7 +1716,12 @@ absl::StatusOr<Literal> ValueInference::SimplifyOp(int64_t handle) {\n   TF_ASSIGN_OR_RETURN(auto* inst, builder_->LookUpInstructionByHandle(handle));\n   TF_ASSIGN_OR_RETURN(HloOpcode opcode, StringToHloOpcode(inst->opcode()));\n   std::vector<Literal> operands;\n-  auto output_shape = std::make_unique<const Shape>(inst->shape());\n+  std::unique_ptr<Shape> output_shape;\n+  {\n+    TF_ASSIGN_OR_RETURN(auto output_shape_stack,\n+                        Shape::FromProto(inst->shape()));\n+    output_shape = std::make_unique<Shape>(std::move(output_shape_stack));\n+  }\n   switch (opcode) {\n     case HloOpcode::kSlice:\n     case HloOpcode::kConcatenate:"
        },
        {
            "sha": "374621ba14cd4eb6683ea51e342b65851c1408c5",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instruction.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instruction.cc?ref=9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027",
            "patch": "@@ -997,7 +997,8 @@ absl::StatusOr<std::unique_ptr<HloInstruction>> HloInstruction::CreateFromProto(\n             proto.operand_shapes_with_layout();\n         operand_shapes.reserve(operand_shapes_with_layout.size());\n         for (const ShapeProto& shape_proto : operand_shapes_with_layout) {\n-          operand_shapes.emplace_back(shape_proto);\n+          TF_ASSIGN_OR_RETURN(Shape shape, Shape::FromProto(shape_proto));\n+          operand_shapes.emplace_back(std::move(shape));\n         }\n         TF_RET_CHECK(proto.called_computation_ids_size() <= 1);\n         if (proto.called_computation_ids_size() == 1) {"
        },
        {
            "sha": "b385704f7058e144600ad5845fe52577de2b5230",
            "filename": "third_party/xla/xla/shape.h",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fshape.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027/third_party%2Fxla%2Fxla%2Fshape.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape.h?ref=9b433c3f5a6fc9f62619041c2d3ce93a4c3bb027",
            "patch": "@@ -77,12 +77,6 @@ class Shape {\n   Shape& operator=(const Shape&);\n   Shape& operator=(Shape&&) noexcept;\n \n-  // Constructs a shape from a ShapeProto. Results in an invalid shape (as\n-  // opposed to crashing) if the proto has logically invalid fields.\n-  ABSL_DEPRECATE_AND_INLINE()\n-  explicit Shape(const ShapeProto& shape_proto)\n-      : Shape(FromProto(shape_proto).value_or(Shape())) {}\n-\n   // Creates a token, opaque or buffer shape.\n   // Precondition:\n   //  - `element_type` must be TOKEN, OPAQUE_TYPE or BUFFER.\n@@ -695,12 +689,6 @@ class ProgramShape {\n   ProgramShape& operator=(const ProgramShape&);\n   ProgramShape& operator=(ProgramShape&&);\n \n-  // Constructs a ProgramShape from a ProgramShapeProto protobuf. If the\n-  // ProgramShapeProto is invalid, an empty ProgramShape is constructed.\n-  ABSL_DEPRECATE_AND_INLINE()\n-  explicit ProgramShape(const ProgramShapeProto& program_shape_proto)\n-      : ProgramShape(FromProto(program_shape_proto).value_or(ProgramShape())) {}\n-\n   // Creates a ProgramShape from a ProgramShapeProto protobuf.\n   static absl::StatusOr<ProgramShape> FromProto(\n       const ProgramShapeProto& program_shape_proto);"
        }
    ],
    "stats": {
        "total": 25,
        "additions": 10,
        "deletions": 15
    }
}