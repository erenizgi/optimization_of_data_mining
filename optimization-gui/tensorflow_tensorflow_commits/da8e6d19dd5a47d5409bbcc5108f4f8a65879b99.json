{
    "author": "bixia1",
    "message": "Fix HloValueAnalysis to work with the latest attribute  _xla_host_transfer_rendezvous.\n\nPreviously, the pass expects a Send/Recv pair to have the same string value in attribute _xla_host_transfer_rendezvous, this is not always true. We have to remove the substrings args_dtoh_ or retvals_htod_ from the attribute value, if there are such subtrings, to find the matching Send/Recv pair.\n\nPiperOrigin-RevId: 810710847",
    "sha": "da8e6d19dd5a47d5409bbcc5108f4f8a65879b99",
    "files": [
        {
            "sha": "0816c39b78f190944d04e80e8d79c1298f8ebfcd",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_value_semantics_analysis.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 4,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8e6d19dd5a47d5409bbcc5108f4f8a65879b99/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8e6d19dd5a47d5409bbcc5108f4f8a65879b99/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis.cc?ref=da8e6d19dd5a47d5409bbcc5108f4f8a65879b99",
            "patch": "@@ -54,6 +54,32 @@ limitations under the License.\n #include \"xla/util.h\"\n \n namespace xla {\n+namespace {\n+std::optional<std::string> GetRendezvous(const HloInstruction& instruction) {\n+  auto attr_iter = instruction.frontend_attributes().map().find(\n+      kXlaHostTransferRendezvousNameAttr);\n+  if (attr_iter == instruction.frontend_attributes().map().end()) {\n+    return std::nullopt;\n+  }\n+  std::string rendezvous = attr_iter->second;\n+  std::string to_remove =\n+      instruction.opcode() == HloOpcode::kSend ? \"args_dtoh_\" : \"retvals_htod_\";\n+  size_t pos = rendezvous.find(to_remove);\n+\n+  // Currently, there are at least two possible paths that generate this\n+  // attribute. In one path, pairing Send/Recv have the same attribute value\n+  // while in another path, they have different attribute values.\n+  // See b/446669371.\n+  if (pos != std::string::npos) {\n+    rendezvous.erase(pos, to_remove.length());\n+  } else {\n+    VLOG(1) << \"Can't find Send/Recv specific substring, Send/Recv should \"\n+               \"have the same attribute value: \"\n+            << rendezvous;\n+  }\n+  return rendezvous;\n+}\n+}  // namespace\n \n SendRecvGroupMap::SendRecvGroupMap(const HloModule& hlo_module) {\n   for (HloComputation* computation : hlo_module.computations()) {\n@@ -62,8 +88,11 @@ SendRecvGroupMap::SendRecvGroupMap(const HloModule& hlo_module) {\n           instruction->opcode() != HloOpcode::kRecv) {\n         continue;\n       }\n-      std::string rendezvous = instruction->frontend_attributes().map().at(\n-          kXlaHostTransferRendezvousNameAttr);\n+      auto rendezvous_result = GetRendezvous(*instruction);\n+      if (!rendezvous_result.has_value()) {\n+        continue;\n+      }\n+      const std::string& rendezvous = *rendezvous_result;\n       auto send_recv_iter = host_transfer_rendezvous_map_.find(rendezvous);\n       if (send_recv_iter == host_transfer_rendezvous_map_.end()) {\n         auto insert_success = host_transfer_rendezvous_map_.insert(\n@@ -85,8 +114,12 @@ absl::StatusOr<HloInstruction*> SendRecvGroupMap::GetMatchingSendOrRecv(\n       send_or_recv->opcode() != HloOpcode::kRecv) {\n     return InvalidArgument(\"Expecting only send or recv\");\n   }\n-  std::string rendezvous = send_or_recv->frontend_attributes().map().at(\n-      kXlaHostTransferRendezvousNameAttr);\n+\n+  auto rendezvous_result = GetRendezvous(*send_or_recv);\n+  if (!rendezvous_result.has_value()) {\n+    return Internal(\"Missing rendezvous attribute\");\n+  }\n+  const std::string& rendezvous = *rendezvous_result;\n   auto send_recv_iter = host_transfer_rendezvous_map_.find(rendezvous);\n   if (send_recv_iter == host_transfer_rendezvous_map_.end()) {\n     return Internal(\"Missing send or recv from send recv group.\");"
        },
        {
            "sha": "1643b783f9cfc082d8e550b31b8940e4509ddb94",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_value_semantics_analysis_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/da8e6d19dd5a47d5409bbcc5108f4f8a65879b99/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/da8e6d19dd5a47d5409bbcc5108f4f8a65879b99/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_value_semantics_analysis_test.cc?ref=da8e6d19dd5a47d5409bbcc5108f4f8a65879b99",
            "patch": "@@ -795,14 +795,14 @@ TEST_F(EinsumDepthAnalysisTest, SendWithRecv) {\n       arg_0 = s32[] parameter(0)\n       arg_1 = token[] parameter(1)\n \n-      send.0 = (s32[], u32[], token[]) send(s32[] arg_0, token[] arg_1), channel_id=3, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"rendezvous1\"}\n-      send-done.1 = token[] send-done((s32[], u32[], token[]) send.0), channel_id=3, is_host_transfer=true, sharding={maximal device=0}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"rendezvous1\"}\n+      send.0 = (s32[], u32[], token[]) send(s32[] arg_0, token[] arg_1), channel_id=3, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"host_compute_channel_0_args_dtoh_0\"}\n+      send-done.1 = token[] send-done((s32[], u32[], token[]) send.0), channel_id=3, is_host_transfer=true, sharding={maximal device=0}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"host_compute_channel_0_args_dtoh_0\"}\n \n-      recv.2 = (s32[], u32[], token[]) recv(token[] send-done.1), channel_id=4, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"rendezvous1\"}\n-      recv-done.3 = (s32[], token[]) recv-done((s32[], u32[], token[]) recv.2), channel_id=4, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"rendezvous1\"}\n+      recv.2 = (s32[], u32[], token[]) recv(token[] send-done.1), channel_id=4, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"host_compute_channel_0_retvals_htod_0\"}\n+      recv-done.3 = (s32[], token[]) recv-done((s32[], u32[], token[]) recv.2), channel_id=4, is_host_transfer=true, sharding={{maximal device=0}, {maximal device=0}}, frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\", _xla_host_transfer_rendezvous=\"host_compute_channel_0_retvals_htod_0\"}\n \n       get-tuple-element.4 = token[] get-tuple-element((s32[], token[]) recv-done.3), index=1, sharding={maximal device=0}\n-      ROOT %after-all.2 = token[] after-all(get-tuple-element.4), frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\",_xla_host_transfer_rendezvous=\"rendezvous1\"}\n+      ROOT %after-all.2 = token[] after-all(get-tuple-element.4), frontend_attributes={_xla_host_transfer_handler_name=\"tf_rendezvous\",_xla_host_transfer_rendezvous=\"host_compute_channel_0_retvals_htod_0\"}\n     }\n   )\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module,"
        }
    ],
    "stats": {
        "total": 51,
        "additions": 42,
        "deletions": 9
    }
}