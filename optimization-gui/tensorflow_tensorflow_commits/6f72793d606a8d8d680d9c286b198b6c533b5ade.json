{
    "author": "thcmbs",
    "message": "[XLA:GPU]Extract transpose normalization logic to utils\n\nPre-requisite to performing normalization OTF and remove the pass\n\nNo-op in terms of behavior\n\nPiperOrigin-RevId: 842250914",
    "sha": "6f72793d606a8d8d680d9c286b198b6c533b5ade",
    "files": [
        {
            "sha": "e653fc2cc8b7e3ad12b6a26837a8ba3505ecebaa",
            "filename": "third_party/xla/xla/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2FBUILD?ref=6f72793d606a8d8d680d9c286b198b6c533b5ade",
            "patch": "@@ -565,6 +565,7 @@ xla_cc_test(\n         \"//xla/tsl/platform:test_benchmark\",\n         \"//xla/tsl/platform:test_main\",\n         \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\","
        },
        {
            "sha": "26d9a8f87049c05bccb13afce8016337b8310d99",
            "filename": "third_party/xla/xla/service/gpu/transforms/transpose_dimension_grouper.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 119,
            "changes": 121,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftranspose_dimension_grouper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftranspose_dimension_grouper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Ftranspose_dimension_grouper.cc?ref=6f72793d606a8d8d680d9c286b198b6c533b5ade",
            "patch": "@@ -18,7 +18,6 @@ limitations under the License.\n #include <cstddef>\n #include <cstdint>\n #include <functional>\n-#include <numeric>\n #include <vector>\n \n #include \"absl/container/flat_hash_set.h\"\n@@ -42,126 +41,10 @@ namespace xla {\n namespace gpu {\n \n namespace {\n-// Returns the indices of the first elements of all consecutive subarrays of the\n-// given array. For example:\n-// ConsecutiveSegments({m, m+1, m+2, n, k, k+1}) = {0, 3, 4}\n-absl::InlinedVector<size_t, 3> ConsecutiveSegments(\n-    absl::Span<const int64_t> xs) {\n-  absl::InlinedVector<size_t, 3> is = {0};\n-  for (size_t i = 1; i < xs.size(); ++i) {\n-    if (1 != xs[i] - xs[i - 1]) {\n-      is.push_back(i);\n-    }\n-  }\n-  return is;\n-}\n-\n-// Merges the sequences of dimensions of the given shape which start at the\n-// given indices `segs`.\n-Shape MergeDimensions(absl::Span<const size_t> segs, const Shape &shape) {\n-  std::vector<int64_t> dimensions;\n-  const auto size = segs.size();\n-  dimensions.reserve(size);\n-  for (size_t i = 1; i <= size; ++i) {\n-    dimensions.push_back(std::accumulate(\n-        shape.dimensions().begin() + segs[i - 1],\n-        shape.dimensions().begin() +\n-            (segs.size() == i ? shape.dimensions().size() : segs[i]),\n-        int64_t{1}, std::multiplies<int64_t>()));\n-  }\n-  return ShapeUtil::MakeShapeWithDescendingLayout(shape.element_type(),\n-                                                  dimensions);\n-}\n-\n-absl::InlinedVector<int64_t, 3> GetNormalizedTransposeShapeHelper(\n-    const Shape &output_shape, absl::Span<int64_t const> output_to_input,\n-    absl::InlinedVector<int64_t, 3> &permutation) {\n-  absl::InlinedVector<size_t, 3> segments =\n-      ConsecutiveSegments(output_to_input);\n-  Shape normalized_shape = MergeDimensions(segments, output_shape);\n-  absl::InlinedVector<int64_t, 3> normalized_dims(\n-      normalized_shape.dimensions().begin(),\n-      normalized_shape.dimensions().end());\n-  if (segments.size() == 1) {\n-    return normalized_dims;\n-  }\n-  // Derive the permutation from the segments.\n-  std::vector<int64_t> segment_to_normalized_dim(\n-      output_shape.dimensions().size(), -1);\n-  for (size_t segment : segments) {\n-    segment_to_normalized_dim[output_to_input[segment]] = 0;\n-  }\n-  int64_t normalized_dim = 0;\n-  for (int64_t i = 0; i < segment_to_normalized_dim.size(); ++i) {\n-    if (segment_to_normalized_dim[i] >= 0) {\n-      segment_to_normalized_dim[i] = normalized_dim++;\n-    }\n-  }\n-  permutation.reserve(segments.size());\n-  for (int64_t i = 0; i < segments.size(); ++i) {\n-    permutation.push_back(\n-        segment_to_normalized_dim[output_to_input[segments[i]]]);\n-  }\n-  return normalized_dims;\n-}\n-\n-// In this case, we care about transposes that permute dimensions of a shape\n-// that can be viewed as several logical components in the order of major to\n-// minor. As an example, let's consider a 0-2-1 transpose:\n-//\n-// If a shape can be viewed as three logical components 0-1-2 in the order of\n-// major to minor, a 0-2-1-transpose changes the order of such logical\n-// components to 0-2-1. We call the shape being transposed the input shape and\n-// the transposed shape the output shape. The logical view of the input/output\n-// shapes for the transpose are called the 0-1-2/0-2-1 shapes or the normalized\n-// shapes. The original input/output shapes are called unnormalized shapes.\n-//\n-// 'output_shape' should have the default layout (enforced by the caller).\n-//\n-// 'dimensions' specifies the kind of the unnormalized transpose and defines the\n-// permutation of the input shape that will result in the provided output shape.\n-// So to compute the input shape, we need to apply the inverse permutation of\n-// 'dimensions'.\n-//\n-// 'permutation' is an output parameter and specifies the kind of the normalized\n-// transpose.\n-//\n-// The method returns the dimensions for the normalized transpose shape.\n-//\n-// Example: Suppose the unnormalized output shape is [32, 1, 10, 11], and\n-// 'dimensions' is set to {3, 1, 0, 2}. This means the corresponding input shape\n-// is [10, 1, 11, 32]. The normalized output shape is [32, 110] with\n-// 'permutation' set to {1,0}.\n-absl::InlinedVector<int64_t, 3> GetNormalizedLogicalTransposeShape(\n-    const Shape &output_shape, absl::Span<int64_t const> dimensions,\n-    absl::InlinedVector<int64_t, 3> &permutation) {\n-  permutation.clear();\n-  // Drop degenerate dimensions.\n-  absl::InlinedVector<int64_t, 3> delta(output_shape.dimensions().size() + 1,\n-                                        0);\n-  auto input_dimensions =\n-      Permute(output_shape.dimensions(), InversePermutation(dimensions));\n-  for (int i = 0; i < output_shape.dimensions().size(); ++i) {\n-    delta[i + 1] = delta[i];\n-    if (input_dimensions[i] == static_cast<int64_t>(1)) {\n-      ++delta[i + 1];\n-    }\n-  }\n-  absl::InlinedVector<int64_t, 3> new_dimensions;\n-  for (int i = 0; i < dimensions.size(); i++) {\n-    if (output_shape.dimensions(i) != 1) {\n-      new_dimensions.push_back(dimensions[i] - delta[dimensions[i]]);\n-    }\n-  }\n-\n-  return GetNormalizedTransposeShapeHelper(\n-      ShapeUtil::DropDegenerateDimensions(output_shape), new_dimensions,\n-      permutation);\n-}\n \n class TransposeDimensionGroupVisitor : public DfsHloRewriteVisitor {\n  public:\n-  absl::Status HandleTranspose(HloInstruction *transpose) override {\n+  absl::Status HandleTranspose(HloInstruction* transpose) override {\n     VLOG(4) << \"Input: \" << transpose->ToString();\n     if (!LayoutUtil::IsMonotonicWithDim0Major(transpose->shape().layout()) ||\n         !LayoutUtil::IsMonotonicWithDim0Major(\n@@ -174,7 +57,7 @@ class TransposeDimensionGroupVisitor : public DfsHloRewriteVisitor {\n           \"transpose and its operand\");\n     }\n     absl::InlinedVector<int64_t, 3> permutation;\n-    auto normalized_dims = GetNormalizedLogicalTransposeShape(\n+    auto normalized_dims = ShapeUtil::GetNormalizedLogicalTransposeShape(\n         transpose->shape(), transpose->dimensions(), permutation);\n     if (normalized_dims.size() == 1 ||\n         normalized_dims == transpose->shape().dimensions()) {"
        },
        {
            "sha": "1fbea10079413bf0220b7e372b44a4ff5006f675",
            "filename": "third_party/xla/xla/shape_util.cc",
            "status": "modified",
            "additions": 95,
            "deletions": 0,
            "changes": 95,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.cc?ref=6f72793d606a8d8d680d9c286b198b6c533b5ade",
            "patch": "@@ -2336,6 +2336,101 @@ int64_t ShapeUtil::ForEachState::CalculateNumSteps() const {\n   });\n }\n \n+namespace {\n+\n+// Returns the indices of the first elements of all consecutive subarrays of the\n+// given array. For example:\n+// ConsecutiveSegments({m, m+1, m+2, n, k, k+1}) = {0, 3, 4}\n+absl::InlinedVector<size_t, 3> ConsecutiveSegments(\n+    absl::Span<const int64_t> xs) {\n+  absl::InlinedVector<size_t, 3> is = {0};\n+  for (size_t i = 1; i < xs.size(); ++i) {\n+    if (1 != xs[i] - xs[i - 1]) {\n+      is.push_back(i);\n+    }\n+  }\n+  return is;\n+}\n+\n+// Merges the sequences of dimensions of the given shape which start at the\n+// given indices `segs`.\n+Shape MergeDimensions(absl::Span<const size_t> segs, const Shape& shape) {\n+  std::vector<int64_t> dimensions;\n+  const auto size = segs.size();\n+  dimensions.reserve(size);\n+  for (size_t i = 1; i <= size; ++i) {\n+    dimensions.push_back(std::accumulate(\n+        shape.dimensions().begin() + segs[i - 1],\n+        shape.dimensions().begin() +\n+            (segs.size() == i ? shape.dimensions().size() : segs[i]),\n+        int64_t{1}, std::multiplies<int64_t>()));\n+  }\n+  return ShapeUtil::MakeShapeWithDescendingLayout(shape.element_type(),\n+                                                  dimensions);\n+}\n+\n+absl::InlinedVector<int64_t, 3> GetNormalizedTransposeShapeHelper(\n+    const Shape& output_shape, absl::Span<int64_t const> output_to_input,\n+    absl::InlinedVector<int64_t, 3>& permutation) {\n+  absl::InlinedVector<size_t, 3> segments =\n+      ConsecutiveSegments(output_to_input);\n+  Shape normalized_shape = MergeDimensions(segments, output_shape);\n+  absl::InlinedVector<int64_t, 3> normalized_dims(\n+      normalized_shape.dimensions().begin(),\n+      normalized_shape.dimensions().end());\n+  if (segments.size() == 1) {\n+    return normalized_dims;\n+  }\n+  // Derive the permutation from the segments.\n+  std::vector<int64_t> segment_to_normalized_dim(\n+      output_shape.dimensions().size(), -1);\n+  for (size_t segment : segments) {\n+    segment_to_normalized_dim[output_to_input[segment]] = 0;\n+  }\n+  int64_t normalized_dim = 0;\n+  for (int64_t i = 0; i < segment_to_normalized_dim.size(); ++i) {\n+    if (segment_to_normalized_dim[i] >= 0) {\n+      segment_to_normalized_dim[i] = normalized_dim++;\n+    }\n+  }\n+  permutation.reserve(segments.size());\n+  for (int64_t i = 0; i < segments.size(); ++i) {\n+    permutation.push_back(\n+        segment_to_normalized_dim[output_to_input[segments[i]]]);\n+  }\n+  return normalized_dims;\n+}\n+\n+}  // namespace\n+\n+/*static*/ absl::InlinedVector<int64_t, 3>\n+ShapeUtil::GetNormalizedLogicalTransposeShape(\n+    const Shape& output_shape, absl::Span<int64_t const> dimensions,\n+    absl::InlinedVector<int64_t, 3>& permutation) {\n+  permutation.clear();\n+  // Drop degenerate dimensions.\n+  absl::InlinedVector<int64_t, 3> delta(output_shape.dimensions().size() + 1,\n+                                        0);\n+  auto input_dimensions =\n+      Permute(output_shape.dimensions(), InversePermutation(dimensions));\n+  for (int i = 0; i < output_shape.dimensions().size(); ++i) {\n+    delta[i + 1] = delta[i];\n+    if (input_dimensions[i] == static_cast<int64_t>(1)) {\n+      ++delta[i + 1];\n+    }\n+  }\n+  absl::InlinedVector<int64_t, 3> new_dimensions;\n+  for (int i = 0; i < dimensions.size(); i++) {\n+    if (output_shape.dimensions(i) != 1) {\n+      new_dimensions.push_back(dimensions[i] - delta[dimensions[i]]);\n+    }\n+  }\n+\n+  return GetNormalizedTransposeShapeHelper(\n+      ShapeUtil::DropDegenerateDimensions(output_shape), new_dimensions,\n+      permutation);\n+}\n+\n /*static*/ void ShapeUtil::FlattenTupleShape(\n     const Shape& shape, std::vector<const Shape*>& flattened) {\n   if (shape.IsTuple()) {"
        },
        {
            "sha": "12cd8e59bd58c7b2d386debb49a7e8d11a809e2f",
            "filename": "third_party/xla/xla/shape_util.h",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util.h?ref=6f72793d606a8d8d680d9c286b198b6c533b5ade",
            "patch": "@@ -435,6 +435,38 @@ class ShapeUtil {\n   static bool IsEffectivelyMostMajorDimension(const Shape& shape,\n                                               int64_t dimension);\n \n+  // In this case, we care about transposes that permute dimensions of a shape\n+  // that can be viewed as several logical components in the order of major to\n+  // minor. As an example, let's consider a 0-2-1 transpose:\n+  //\n+  // If a shape can be viewed as three logical components 0-1-2 in the order of\n+  // major to minor, a 0-2-1-transpose changes the order of such logical\n+  // components to 0-2-1. We call the shape being transposed the input shape and\n+  // the transposed shape the output shape. The logical view of the input/output\n+  // shapes for the transpose are called the 0-1-2/0-2-1 shapes or the\n+  // normalized shapes. The original input/output shapes are called unnormalized\n+  // shapes.\n+  //\n+  // 'output_shape' should have the default layout (enforced by the caller).\n+  //\n+  // 'dimensions' specifies the kind of the unnormalized transpose and defines\n+  // the permutation of the input shape that will result in the provided output\n+  // shape. So to compute the input shape, we need to apply the inverse\n+  // permutation of 'dimensions'.\n+  //\n+  // 'permutation' is an output parameter and specifies the kind of the\n+  // normalized transpose.\n+  //\n+  // The method returns the dimensions for the normalized transpose shape.\n+  //\n+  // Example: Suppose the unnormalized output shape is [32, 1, 10, 11], and\n+  // 'dimensions' is set to {3, 1, 0, 2}. This means the corresponding input\n+  // shape is [10, 1, 11, 32]. The normalized output shape is [32, 110] with\n+  // 'permutation' set to {1,0}.\n+  static absl::InlinedVector<int64_t, 3> GetNormalizedLogicalTransposeShape(\n+      const Shape& output_shape, absl::Span<int64_t const> dimensions,\n+      absl::InlinedVector<int64_t, 3>& permutation);\n+\n   // Returns an empty tuple shape. Can be used as a sentinel Shape value.\n   static Shape MakeNil() { return Shape(std::vector<Shape>{}); }\n "
        },
        {
            "sha": "265e36b839b289e4001e55e44e90cc1d40fcda9b",
            "filename": "third_party/xla/xla/shape_util_test.cc",
            "status": "modified",
            "additions": 124,
            "deletions": 0,
            "changes": 124,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6f72793d606a8d8d680d9c286b198b6c533b5ade/third_party%2Fxla%2Fxla%2Fshape_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fshape_util_test.cc?ref=6f72793d606a8d8d680d9c286b198b6c533b5ade",
            "patch": "@@ -22,8 +22,10 @@ limitations under the License.\n #include <variant>\n #include <vector>\n \n+#include <gmock/gmock.h>\n #include <gtest/gtest.h>\n #include \"absl/algorithm/container.h\"\n+#include \"absl/container/inlined_vector.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n@@ -45,6 +47,7 @@ namespace xla {\n namespace {\n \n using ::testing::ElementsAre;\n+using ::testing::IsEmpty;\n \n TEST(ShapeUtilTest, GetDimensionHelperCanNegativeIndex) {\n   Shape matrix = ShapeUtil::MakeShape(F32, {2, 3});\n@@ -1776,5 +1779,126 @@ void BM_ForEachIndexNoStatus(::testing::benchmark::State& state) {\n \n BENCHMARK(BM_ForEachIndexNoStatus)->Arg(0)->Arg(1)->Arg(2);\n \n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {32, 1, 10, 11});\n+  absl::InlinedVector<int64_t, 3> dimensions = {3, 1, 0, 2};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(32, 110));\n+  EXPECT_THAT(permutation, ElementsAre(1, 0));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape2) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {20, 30, 50});\n+  absl::InlinedVector<int64_t, 3> dimensions = {1, 2, 0};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(600, 50));\n+  EXPECT_THAT(permutation, ElementsAre(1, 0));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_NoTranspose) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {64, 1, 128});\n+  absl::InlinedVector<int64_t, 3> dimensions = {0, 2, 1};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(8192));\n+  EXPECT_THAT(permutation, IsEmpty());\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_Simple2D) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {64, 128});\n+  absl::InlinedVector<int64_t, 3> dimensions = {1, 0};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(64, 128));\n+  EXPECT_THAT(permutation, ElementsAre(1, 0));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_Simple3D_021) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {8, 16, 32768});\n+  absl::InlinedVector<int64_t, 3> dimensions = {0, 2, 1};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(8, 16, 32768));\n+  EXPECT_THAT(permutation, ElementsAre(0, 2, 1));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_Simple3D_210) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {16, 32768, 8});\n+  absl::InlinedVector<int64_t, 3> dimensions = {2, 1, 0};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(16, 32768, 8));\n+  EXPECT_THAT(permutation, ElementsAre(2, 1, 0));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_Simple4D) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {16, 32768, 8, 4});\n+  absl::InlinedVector<int64_t, 3> dimensions = {2, 0, 3, 1};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(16, 32768, 8, 4));\n+  EXPECT_THAT(permutation, ElementsAre(2, 0, 3, 1));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_NormalizeTo3D) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {8, 16, 32, 32, 32});\n+  absl::InlinedVector<int64_t, 3> dimensions = {0, 4, 1, 2, 3};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(8, 16, 32768));\n+  EXPECT_THAT(permutation, ElementsAre(0, 2, 1));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_LargeShapeSizeOverflow) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {16, 4096, 4096, 128});\n+  absl::InlinedVector<int64_t, 3> dimensions = {3, 0, 1, 2};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(16, 2147483648));\n+  EXPECT_THAT(permutation, ElementsAre(1, 0));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_DegenerateDims) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {1, 32, 1, 64, 1, 3, 1});\n+  absl::InlinedVector<int64_t, 3> dimensions = {6, 1, 4, 5, 2, 3, 0};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(32, 64, 3));\n+  EXPECT_THAT(permutation, ElementsAre(0, 2, 1));\n+}\n+\n+TEST(ShapeUtilTest, GetNormalizedLogicalTransposeShape_TransposeWithGrouping) {\n+  Shape output_shape = ShapeUtil::MakeShape(F32, {10, 1, 32, 100, 2});\n+  absl::InlinedVector<int64_t, 3> dimensions = {2, 1, 3, 0, 4};\n+  absl::InlinedVector<int64_t, 3> permutation;\n+  auto normalized_shape = ShapeUtil::GetNormalizedLogicalTransposeShape(\n+      output_shape, dimensions, permutation);\n+\n+  EXPECT_THAT(normalized_shape, ElementsAre(320, 100, 2));\n+  EXPECT_THAT(permutation, ElementsAre(1, 0, 2));\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 373,
        "additions": 254,
        "deletions": 119
    }
}