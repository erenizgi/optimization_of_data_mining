{
    "author": "ezhulenev",
    "message": "[xla:cpu] Use work_item instead of a task in WorkQueue/Worker API\n\nTo avoid confusion because of different kinds of tasks we have in Worker/WorkQueue and a SlinklyThreadPool in XLA use a more generic \"work item\" name.\n\nPiperOrigin-RevId: 823191886",
    "sha": "d55e5c1d9f3f47a5e6459851bb6ba856e642575d",
    "files": [
        {
            "sha": "82c843b4025b3176fb8e9badbbba5767c3781507",
            "filename": "third_party/xla/xla/backends/cpu/runtime/kernel.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 12,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.cc?ref=d55e5c1d9f3f47a5e6459851bb6ba856e642575d",
            "patch": "@@ -62,10 +62,10 @@ static absl::InlinedVector<XLA_CPU_KernelArg, 8> ConvertBuffersToKernelArgs(\n }\n \n template <bool num_workgroups_x_only>\n-class Kernel::ParallelTask {\n+class Kernel::Task {\n  public:\n-  ParallelTask(XLA_CPU_Kernel* kernel, NumWorkGroups num_workgroups,\n-               absl::Span<const XLA_CPU_KernelArg> args);\n+  Task(XLA_CPU_Kernel* kernel, NumWorkGroups num_workgroups,\n+       absl::Span<const XLA_CPU_KernelArg> args);\n \n   // Invokes a host kernel for a given task index.\n   absl::Status operator()(size_t task_index) const;\n@@ -87,7 +87,7 @@ class Kernel::ParallelTask {\n };\n \n template <bool num_workgroups_x_only>\n-Kernel::ParallelTask<num_workgroups_x_only>::ParallelTask(\n+Kernel::Task<num_workgroups_x_only>::Task(\n     XLA_CPU_Kernel* kernel, NumWorkGroups num_workgroups,\n     absl::Span<const XLA_CPU_KernelArg> args)\n     : kernel_(kernel),\n@@ -98,7 +98,7 @@ Kernel::ParallelTask<num_workgroups_x_only>::ParallelTask(\n       stride_y_(num_workgroups.x) {}\n \n template <bool num_workgroups_x_only>\n-absl::Status Kernel::ParallelTask<num_workgroups_x_only>::operator()(\n+absl::Status Kernel::Task<num_workgroups_x_only>::operator()(\n     size_t task_index) const {\n   DCHECK_LT(task_index, num_tasks_) << \"Task index out of range\";  // Crash OK\n \n@@ -117,7 +117,7 @@ absl::Status Kernel::ParallelTask<num_workgroups_x_only>::operator()(\n }\n \n template <bool num_workgroups_x_only>\n-XLA_CPU_WorkGroupId Kernel::ParallelTask<num_workgroups_x_only>::Delinearize(\n+XLA_CPU_WorkGroupId Kernel::Task<num_workgroups_x_only>::Delinearize(\n     uint64_t task_index) const {\n   // In the most common case we parallelize only over the `x` dimension.\n   if constexpr (num_workgroups_x_only) {\n@@ -197,14 +197,12 @@ tsl::AsyncValueRef<LaunchEvent> Kernel::Launch(\n                        std::numeric_limits<uint16_t>::max());\n \n   if (ABSL_PREDICT_TRUE(num_workgroups.y == 1 && num_workgroups.z == 1)) {\n-    return Worker::Parallelize(\n-        device->getPool(), num_workers, num_tasks,\n-        ParallelTask<true>(kernel_, num_workgroups, args));\n+    return Worker::Parallelize(device->getPool(), num_workers, num_tasks,\n+                               Task<true>(kernel_, num_workgroups, args));\n   }\n \n-  return Worker::Parallelize(\n-      device->getPool(), num_workers, num_tasks,\n-      ParallelTask<false>(kernel_, num_workgroups, args));\n+  return Worker::Parallelize(device->getPool(), num_workers, num_tasks,\n+                             Task<false>(kernel_, num_workgroups, args));\n }\n \n }  // namespace xla::cpu"
        },
        {
            "sha": "9fddf45cd93b6e4ba1a772c7852df6d80b391cd9",
            "filename": "third_party/xla/xla/backends/cpu/runtime/kernel.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fkernel.h?ref=d55e5c1d9f3f47a5e6459851bb6ba856e642575d",
            "patch": "@@ -105,9 +105,9 @@ class Kernel {\n   }\n \n  private:\n-  // A kernel parallel task that is used to parallelize host kernel execution.\n+  // A kernel task that is used to parallelize host kernel execution.\n   template <bool num_workgroups_x_only>\n-  class ParallelTask;\n+  class Task;\n \n   std::unique_ptr<KernelFunction> function_;\n   XLA_CPU_Kernel* kernel_;  // pointer to the kernel owned by `function_`"
        },
        {
            "sha": "c6924978a9ed816ae085d7667d86bf000de44063",
            "filename": "third_party/xla/xla/backends/cpu/runtime/work_queue.h",
            "status": "modified",
            "additions": 70,
            "deletions": 70,
            "changes": 140,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue.h?ref=d55e5c1d9f3f47a5e6459851bb6ba856e642575d",
            "patch": "@@ -40,17 +40,17 @@ limitations under the License.\n \n namespace xla::cpu {\n \n-// A work queue that partitions `num_tasks` tasks into `num_partitions`\n-// partitions processed by parallel workers.\n+// A work queue that partitions `num_work_items` work items into\n+// `num_partitions` partitions processed by parallel workers.\n class WorkQueue {\n  public:\n-  WorkQueue(size_t num_tasks, size_t num_partitions);\n+  WorkQueue(size_t num_work_items, size_t num_partitions);\n \n-  // Returns the next task in the given partition. Returns std::nullopt\n+  // Returns the next work item in the given partition. Returns std::nullopt\n   // if the partition is complete.\n   std::optional<size_t> Pop(size_t partition_index);\n \n-  // Return the partition [begin, end) task range.\n+  // Return the partition [begin, end) work items range.\n   std::pair<size_t, size_t> partition_range(size_t partition_index) const;\n \n   size_t num_partitions() const { return partitions_.size(); }\n@@ -63,7 +63,7 @@ class WorkQueue {\n   struct Partition {\n     void Initialize(size_t begin, size_t end);\n \n-    // Tracks index of the next task in the assigned partition.\n+    // Tracks index of the next work item in the assigned partition.\n     ABSL_CACHELINE_ALIGNED std::atomic<size_t> index;\n     size_t begin;\n     size_t end;\n@@ -85,34 +85,34 @@ class WorkQueue {\n   ABSL_CACHELINE_ALIGNED std::atomic<size_t> num_work_stealing_workers_;\n };\n \n-// Worker processes tasks from the work queue starting from the assigned\n+// Worker processes work items from the work queue starting from the assigned\n // work partition. Once the assigned partition is complete it tries to pop\n-// the task from the next partition. Once the work queue is empty (the worker\n-// wraps around to the initial partition) it returns and empty task.\n+// the work item from the next partition. Once the work queue is empty (the\n+// worker wraps around to the initial partition) it returns and empty work item.\n class Worker {\n  public:\n   Worker(size_t worker_index, WorkQueue* queue);\n \n   std::optional<size_t> Pop();\n \n   // Schedule `num_workers` workers into the Eigen thread pool that process\n-  // `num_tasks` parallel tasks and return an async value that becomes\n+  // `num_work_items` parallel work items and return an async value that becomes\n   // available when all workers are completed.\n-  template <typename ParallelTask>\n+  template <typename ParallelWork>\n   static tsl::AsyncValueRef<tsl::Chain> Parallelize(\n       Eigen::ThreadPoolInterface* thread_pool, size_t num_workers,\n-      size_t num_tasks, ParallelTask&& parallel_task);\n+      size_t num_work_items, ParallelWork&& parallel_work);\n \n  private:\n-  template <typename ParallelTask>\n+  template <typename ParallelWork>\n   struct ParallelizeContext;\n \n-  template <typename ParallelTask>\n-  static absl::Status ExecuteInline(size_t num_tasks,\n-                                    ParallelTask&& parallel_task);\n+  template <typename ParallelWork>\n+  static absl::Status ExecuteInline(size_t num_work_items,\n+                                    ParallelWork&& parallel_work);\n \n-  template <typename ParallelTask>\n-  static void Parallelize(std::shared_ptr<ParallelizeContext<ParallelTask>> ctx,\n+  template <typename ParallelWork>\n+  static void Parallelize(std::shared_ptr<ParallelizeContext<ParallelWork>> ctx,\n                           uint16_t start_index, uint16_t end_index);\n \n   size_t worker_index_;\n@@ -126,14 +126,14 @@ inline void WorkQueue::Partition::Initialize(size_t begin, size_t end) {\n   this->end = end;\n }\n \n-inline WorkQueue::WorkQueue(size_t num_tasks, size_t num_partitions)\n+inline WorkQueue::WorkQueue(size_t num_work_items, size_t num_partitions)\n     : partitions_(num_partitions),\n-      empty_(num_tasks == 0),\n+      empty_(num_work_items == 0),\n       num_work_stealing_workers_(0) {\n-  size_t partition_size = num_tasks / num_partitions;\n-  size_t rem_tasks = num_tasks % num_partitions;\n+  size_t partition_size = num_work_items / num_partitions;\n+  size_t rem_work_items = num_work_items % num_partitions;\n   for (size_t i = 0, begin = 0, end = 0; i < num_partitions; ++i, begin = end) {\n-    end = begin + partition_size + ((i < rem_tasks) ? 1 : 0);\n+    end = begin + partition_size + ((i < rem_work_items) ? 1 : 0);\n     partitions_[i].Initialize(begin, end);\n   }\n }\n@@ -148,7 +148,7 @@ inline std::optional<size_t> WorkQueue::Pop(size_t partition_index) {\n     return std::nullopt;\n   }\n \n-  // Try to acquire the next task in the partition.\n+  // Try to acquire the next work item in the partition.\n   size_t index = partition.index.fetch_add(1, std::memory_order_relaxed);\n   return ABSL_PREDICT_FALSE(index >= partition.end) ? std::nullopt\n                                                     : std::make_optional(index);\n@@ -183,18 +183,18 @@ inline Worker::Worker(size_t worker_index, WorkQueue* queue)\n       queue_(queue) {}\n \n inline std::optional<size_t> Worker::Pop() {\n-  std::optional<size_t> task = queue_->Pop(partition_index_);\n-  if (ABSL_PREDICT_TRUE(task)) {\n-    return task;\n+  std::optional<size_t> work_item = queue_->Pop(partition_index_);\n+  if (ABSL_PREDICT_TRUE(work_item)) {\n+    return work_item;\n   }\n \n-  // If we didn't find a task in the initially assigned partition, notify the\n-  // work queue that we are switching to work stealing mode.\n+  // If we didn't find a work item in the initially assigned partition, notify\n+  // the work queue that we are switching to work stealing mode.\n   if (ABSL_PREDICT_FALSE(partition_index_ == worker_index_)) {\n     queue_->NotifyWorkStealingWorker();\n   }\n \n-  while (!task.has_value() && !queue_->IsEmpty()) {\n+  while (!work_item.has_value() && !queue_->IsEmpty()) {\n     // Wrap around to the first partition.\n     if (ABSL_PREDICT_FALSE(++partition_index_ >= queue_->num_partitions())) {\n       partition_index_ = 0;\n@@ -206,44 +206,44 @@ inline std::optional<size_t> Worker::Pop() {\n       break;\n     }\n \n-    task = queue_->Pop(partition_index_);\n+    work_item = queue_->Pop(partition_index_);\n   }\n \n-  return task;\n+  return work_item;\n }\n \n-template <typename ParallelTask>\n+template <typename ParallelWork>\n struct Worker::ParallelizeContext {\n   ParallelizeContext(Eigen::ThreadPoolInterface* thread_pool,\n                      tsl::CountDownAsyncValueRef<tsl::Chain> count_down,\n-                     size_t num_tasks, ParallelTask&& parallel_task);\n+                     size_t num_work_items, ParallelWork&& parallel_work);\n \n   Eigen::ThreadPoolInterface* thread_pool;\n   tsl::CountDownAsyncValueRef<tsl::Chain> count_down;\n \n   WorkQueue work_queue;\n-  ParallelTask parallel_task;\n+  ParallelWork parallel_work;\n };\n \n-template <typename ParallelTask>\n-Worker::ParallelizeContext<ParallelTask>::ParallelizeContext(\n+template <typename ParallelWork>\n+Worker::ParallelizeContext<ParallelWork>::ParallelizeContext(\n     Eigen::ThreadPoolInterface* thread_pool,\n-    tsl::CountDownAsyncValueRef<tsl::Chain> count_down, size_t num_tasks,\n-    ParallelTask&& parallel_task)\n+    tsl::CountDownAsyncValueRef<tsl::Chain> count_down, size_t num_work_items,\n+    ParallelWork&& parallel_work)\n     : thread_pool(thread_pool),\n       count_down(std::move(count_down)),\n-      work_queue(num_tasks, /*num_partitions=*/this->count_down.count()),\n-      parallel_task(std::forward<ParallelTask>(parallel_task)) {}\n+      work_queue(num_work_items, /*num_partitions=*/this->count_down.count()),\n+      parallel_work(std::forward<ParallelWork>(parallel_work)) {}\n \n-template <typename ParallelTask>\n+template <typename ParallelWork>\n // NOLINTNEXTLINE(readability-function-cognitive-complexity)\n-void Worker::Parallelize(std::shared_ptr<ParallelizeContext<ParallelTask>> ctx,\n+void Worker::Parallelize(std::shared_ptr<ParallelizeContext<ParallelWork>> ctx,\n                          uint16_t start_index, uint16_t end_index) {\n   DCHECK_LT(start_index, end_index) << \"Invalid worker index range\";\n \n-  using R = std::invoke_result_t<ParallelTask, size_t>;\n+  using R = std::invoke_result_t<ParallelWork, size_t>;\n   static_assert(std::is_same_v<R, absl::Status> || std::is_void_v<R>,\n-                \"Unsupported parallel task return type\");\n+                \"Unsupported parallel work return type\");\n \n   // Recursively split assigned workers into two halves and schedule the\n   // right half into the thread pool.\n@@ -254,7 +254,7 @@ void Worker::Parallelize(std::shared_ptr<ParallelizeContext<ParallelTask>> ctx,\n     }\n \n     // If we have workers in the work stealing mode, we can skip scheduling\n-    // more tasks as existing workers will process remaining partitions. By\n+    // more workers as existing workers will process remaining partitions. By\n     // doing this optimization we avoid unnecessary thread pool overheads.\n     size_t skip_workers =\n         ctx->work_queue.DecrementWorkStealingWorkers(end_index - start_index);\n@@ -283,54 +283,54 @@ void Worker::Parallelize(std::shared_ptr<ParallelizeContext<ParallelTask>> ctx,\n \n   // Execute the `start_index` worker in the caller thread.\n   Worker worker(start_index, &ctx->work_queue);\n-  size_t num_processed_tasks = 0;\n+  size_t num_processed_work_items = 0;\n \n   // Keep track of the first error status encountered by any of the workers.\n   absl::Status status;\n \n-  while (std::optional<size_t> task = worker.Pop()) {\n+  while (std::optional<size_t> work_item = worker.Pop()) {\n     if constexpr (std::is_same_v<R, absl::Status>) {\n       if (ABSL_PREDICT_TRUE(status.ok())) {\n-        status.Update(ctx->parallel_task(*task));\n+        status.Update(ctx->parallel_work(*work_item));\n       }\n     } else {\n-      ctx->parallel_task(*task);\n+      ctx->parallel_work(*work_item);\n     }\n-    ++num_processed_tasks;\n+    ++num_processed_work_items;\n   }\n \n-  ctx->count_down.CountDown(num_processed_tasks, std::move(status));\n+  ctx->count_down.CountDown(num_processed_work_items, std::move(status));\n }\n \n-template <typename ParallelTask>\n+template <typename ParallelWork>\n ABSL_ATTRIBUTE_ALWAYS_INLINE absl::Status Worker::ExecuteInline(\n-    size_t num_tasks, ParallelTask&& parallel_task) {\n-  using R = std::invoke_result_t<ParallelTask, size_t>;\n+    size_t num_work_items, ParallelWork&& parallel_work) {\n+  using R = std::invoke_result_t<ParallelWork, size_t>;\n   static_assert(std::is_same_v<R, absl::Status> || std::is_void_v<R>,\n-                \"Unsupported parallel task return type\");\n+                \"Unsupported parallel work return type\");\n \n-  for (size_t i = 0; i < num_tasks; ++i) {\n+  for (size_t i = 0; i < num_work_items; ++i) {\n     if constexpr (std::is_same_v<R, absl::Status>) {\n-      absl::Status status = parallel_task(i);\n+      absl::Status status = parallel_work(i);\n       if (ABSL_PREDICT_FALSE(!status.ok())) {\n         return status;\n       }\n     } else {\n-      parallel_task(i);\n+      parallel_work(i);\n     }\n   }\n \n   return absl::OkStatus();\n }\n \n-template <typename ParallelTask>\n+template <typename ParallelWork>\n ABSL_ATTRIBUTE_ALWAYS_INLINE tsl::AsyncValueRef<tsl::Chain> Worker::Parallelize(\n     Eigen::ThreadPoolInterface* thread_pool, size_t num_workers,\n-    size_t num_tasks, ParallelTask&& parallel_task) {\n+    size_t num_work_items, ParallelWork&& parallel_work) {\n   // Short-circuit single-threaded execution.\n   if (ABSL_PREDICT_FALSE(num_workers == 1)) {\n-    if (absl::Status status =\n-            ExecuteInline(num_tasks, std::forward<ParallelTask>(parallel_task));\n+    if (absl::Status status = ExecuteInline(\n+            num_work_items, std::forward<ParallelWork>(parallel_work));\n         ABSL_PREDICT_FALSE(!status.ok())) {\n       return status;\n     }\n@@ -341,16 +341,16 @@ ABSL_ATTRIBUTE_ALWAYS_INLINE tsl::AsyncValueRef<tsl::Chain> Worker::Parallelize(\n   if (ABSL_PREDICT_FALSE(num_workers > std::numeric_limits<uint16_t>::max())) {\n     num_workers = std::numeric_limits<uint16_t>::max();\n   }\n-  // Ensure we don't launch more workers than tasks.\n-  // Extra workers would be idle or cause out-of-bounds partition access.\n-  num_workers = std::min(num_tasks, num_workers);\n+  // Ensure we don't launch more workers than work items. Extra workers would be\n+  // idle or cause out-of-bounds partition access.\n+  num_workers = std::min(num_work_items, num_workers);\n \n-  tsl::CountDownAsyncValueRef<tsl::Chain> count_down(num_tasks);\n+  tsl::CountDownAsyncValueRef<tsl::Chain> count_down(num_work_items);\n   auto execute_event = count_down.AsRef();\n \n-  auto ctx = std::make_shared<ParallelizeContext<ParallelTask>>(\n-      thread_pool, std::move(count_down), num_tasks,\n-      std::forward<ParallelTask>(parallel_task));\n+  auto ctx = std::make_shared<ParallelizeContext<ParallelWork>>(\n+      thread_pool, std::move(count_down), num_work_items,\n+      std::forward<ParallelWork>(parallel_work));\n \n   Parallelize(std::move(ctx), 0, num_workers);\n "
        },
        {
            "sha": "7b4a988e16d69fd2d66f4daea07d1811a07daf06",
            "filename": "third_party/xla/xla/backends/cpu/runtime/work_queue_test.cc",
            "status": "modified",
            "additions": 46,
            "deletions": 45,
            "changes": 91,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d55e5c1d9f3f47a5e6459851bb6ba856e642575d/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fruntime%2Fwork_queue_test.cc?ref=d55e5c1d9f3f47a5e6459851bb6ba856e642575d",
            "patch": "@@ -41,39 +41,39 @@ TEST(WorkQueueTest, WorkQueuePartitions) {\n   };\n \n   {\n-    WorkQueue queue(/*num_tasks=*/2, /*num_partitions=*/4);\n+    WorkQueue queue(/*num_work_items=*/2, /*num_partitions=*/4);\n     EXPECT_EQ(queue.partition_range(0), task_range(0, 1));\n     EXPECT_EQ(queue.partition_range(1), task_range(1, 2));\n     EXPECT_EQ(queue.partition_range(2), task_range(2, 2));\n     EXPECT_EQ(queue.partition_range(3), task_range(2, 2));\n   }\n \n   {\n-    WorkQueue queue(/*num_tasks=*/4, /*num_partitions=*/4);\n+    WorkQueue queue(/*num_work_items=*/4, /*num_partitions=*/4);\n     EXPECT_EQ(queue.partition_range(0), task_range(0, 1));\n     EXPECT_EQ(queue.partition_range(1), task_range(1, 2));\n     EXPECT_EQ(queue.partition_range(2), task_range(2, 3));\n     EXPECT_EQ(queue.partition_range(3), task_range(3, 4));\n   }\n \n   {\n-    WorkQueue queue(/*num_tasks=*/5, /*num_partitions=*/4);\n+    WorkQueue queue(/*num_work_items=*/5, /*num_partitions=*/4);\n     EXPECT_EQ(queue.partition_range(0), task_range(0, 2));\n     EXPECT_EQ(queue.partition_range(1), task_range(2, 3));\n     EXPECT_EQ(queue.partition_range(2), task_range(3, 4));\n     EXPECT_EQ(queue.partition_range(3), task_range(4, 5));\n   }\n \n   {\n-    WorkQueue queue(/*num_tasks=*/9, /*num_partitions=*/4);\n+    WorkQueue queue(/*num_work_items=*/9, /*num_partitions=*/4);\n     EXPECT_EQ(queue.partition_range(0), task_range(0, 3));\n     EXPECT_EQ(queue.partition_range(1), task_range(3, 5));\n     EXPECT_EQ(queue.partition_range(2), task_range(5, 7));\n     EXPECT_EQ(queue.partition_range(3), task_range(7, 9));\n   }\n \n   {\n-    WorkQueue queue(/*num_tasks=*/14, /*num_partitions=*/4);\n+    WorkQueue queue(/*num_work_items=*/14, /*num_partitions=*/4);\n     EXPECT_EQ(queue.partition_range(0), task_range(0, 4));\n     EXPECT_EQ(queue.partition_range(1), task_range(4, 8));\n     EXPECT_EQ(queue.partition_range(2), task_range(8, 11));\n@@ -107,17 +107,17 @@ TEST(WorkQueueTest, WorkQueue) {\n     for (size_t num_partitions : {1, 2, 3, 4, 5, 6, 7, 8}) {\n       WorkQueue queue(size, num_partitions);\n \n-      std::vector<size_t> expected_tasks(size);\n-      absl::c_iota(expected_tasks, 0);\n+      std::vector<size_t> expected_work_items(size);\n+      absl::c_iota(expected_work_items, 0);\n \n-      std::vector<size_t> tasks;\n+      std::vector<size_t> work_items;\n       for (size_t i = 0; i < num_partitions; ++i) {\n-        while (std::optional<size_t> task = queue.Pop(i)) {\n-          tasks.push_back(*task);\n+        while (std::optional<size_t> work_item = queue.Pop(i)) {\n+          work_items.push_back(*work_item);\n         }\n       }\n \n-      EXPECT_EQ(tasks, expected_tasks);\n+      EXPECT_EQ(work_items, expected_work_items);\n     }\n   }\n }\n@@ -126,21 +126,21 @@ TEST(WorkQueueTest, Worker) {\n   for (size_t size : {1, 2, 4, 8, 16, 32, 64}) {\n     for (size_t num_partitions : {1, 2, 3, 4, 5, 6, 7, 8}) {\n       // We check that no matter what is the initial partition, the worker\n-      // processes all tasks in the queue.\n+      // processes all work items in the queue.\n       for (size_t i = 0; i < num_partitions; ++i) {\n         WorkQueue queue(size, num_partitions);\n         Worker worker(i, &queue);\n \n-        std::vector<size_t> expected_tasks(size);\n-        absl::c_iota(expected_tasks, 0);\n+        std::vector<size_t> expected_work_items(size);\n+        absl::c_iota(expected_work_items, 0);\n \n-        std::vector<size_t> tasks;\n-        while (std::optional<size_t> task = worker.Pop()) {\n-          tasks.push_back(*task);\n+        std::vector<size_t> work_items;\n+        while (std::optional<size_t> work_item = worker.Pop()) {\n+          work_items.push_back(*work_item);\n         }\n \n-        absl::c_sort(tasks);  // we pop tasks out of order\n-        EXPECT_EQ(tasks, expected_tasks);\n+        absl::c_sort(work_items);  // we pop work_items out of order\n+        EXPECT_EQ(work_items, expected_work_items);\n       }\n     }\n   }\n@@ -154,22 +154,22 @@ TEST(WorkQueueTest, WorkerConcurrency) {\n \n   WorkQueue queue(size, num_partitions);\n \n-  // Check that we pop exactly `size` tasks.\n-  std::atomic<size_t> num_tasks(0);\n+  // Check that we pop exactly `size` work_items.\n+  std::atomic<size_t> num_work_items(0);\n \n   absl::BlockingCounter counter(num_partitions);\n   for (size_t i = 0; i < num_partitions; ++i) {\n     threads.Schedule([&, i] {\n       Worker worker(i, &queue);\n-      while (std::optional<size_t> task = worker.Pop()) {\n-        ++num_tasks;\n+      while (std::optional<size_t> work_item = worker.Pop()) {\n+        ++num_work_items;\n       }\n       counter.DecrementCount();\n     });\n   }\n \n   counter.Wait();\n-  EXPECT_EQ(num_tasks.load(), size);\n+  EXPECT_EQ(num_work_items.load(), size);\n }\n \n TEST(WorkQueueTest, WorkerParallelize) {\n@@ -215,71 +215,72 @@ TEST(WorkQueueTest, WorkerParallelizeVariousWorkerTaskRatios) {\n   tsl::thread::ThreadPool threads(tsl::Env::Default(), \"test\", 16);\n \n   struct TestCase {\n-    size_t num_tasks;\n+    size_t num_work_items;\n     size_t num_workers;\n   };\n \n   std::vector<TestCase> test_cases = {\n-      {0, 1},     // Edge: no tasks\n+      {0, 1},     // Edge: no work_items\n       {1, 1},     // Edge: single task, single worker\n       {1, 8},     // Edge: single task, many workers\n       {8, 1},     // Serial execution\n-      {8, 4},     // Fewer workers than tasks\n+      {8, 4},     // Fewer workers than work_items\n       {8, 8},     // Equal\n-      {8, 16},    // More workers than tasks\n-      {1024, 8},  // Many tasks, fewer workers\n-      {1024, 64}  // Many tasks, many workers\n+      {8, 16},    // More workers than work_items\n+      {1024, 8},  // Many work_items, fewer workers\n+      {1024, 64}  // Many work_items, many workers\n   };\n \n   for (const auto& test : test_cases) {\n-    std::vector<size_t> data(test.num_tasks, 0);\n+    std::vector<size_t> data(test.num_work_items, 0);\n \n     auto event = Worker::Parallelize(\n-        threads.AsEigenThreadPool(), test.num_workers, test.num_tasks,\n+        threads.AsEigenThreadPool(), test.num_workers, test.num_work_items,\n         [&](size_t task_index) { ++data[task_index]; });\n \n     tsl::BlockUntilReady(event);\n \n-    // Verify that all tasks were executed once (if any exist)\n-    std::vector<size_t> expected(test.num_tasks, 1);\n-    EXPECT_EQ(data, expected) << \"Failed for num_tasks=\" << test.num_tasks\n-                              << \", num_workers=\" << test.num_workers;\n+    // Verify that all work_items were executed once (if any exist)\n+    std::vector<size_t> expected(test.num_work_items, 1);\n+    EXPECT_EQ(data, expected)\n+        << \"Failed for num_work_items=\" << test.num_work_items\n+        << \", num_workers=\" << test.num_workers;\n   }\n }\n \n //===----------------------------------------------------------------------===//\n // Performance benchmarks.\n //===----------------------------------------------------------------------===//\n \n-static void BM_PopTask(benchmark::State& state) {\n+static void BM_PopWorkItem(benchmark::State& state) {\n   std::optional<WorkQueue> queue;\n   std::optional<Worker> worker;\n \n   size_t n = 0;\n   for (auto _ : state) {\n     if (n++ % (1024 * 10) == 0) {\n-      queue.emplace(/*num_tasks=*/1024 * 10, /*num_partitions=*/10);\n+      queue.emplace(/*num_work_items=*/1024 * 10, /*num_partitions=*/10);\n       worker.emplace(0, &*queue);\n     }\n     worker->Pop();\n   }\n }\n \n-BENCHMARK(BM_PopTask);\n+BENCHMARK(BM_PopWorkItem);\n \n-static void BM_PopTaskMultiThreaded(benchmark::State& state) {\n+static void BM_PopWorkItemMultiThreaded(benchmark::State& state) {\n   size_t num_threads = state.range(0);\n-  tsl::thread::ThreadPool threads(tsl::Env::Default(), \"benchmark\",\n-                                  num_threads);\n+  tsl::thread::ThreadPool threads(tsl::Env::Default(), \"bench\", num_threads);\n \n   for (auto _ : state) {\n     absl::BlockingCounter counter(num_threads);\n-    WorkQueue queue(/*num_tasks=*/1024 * 10, /*num_partitions=*/num_threads);\n+    WorkQueue queue(/*num_work_items=*/1024 * 10,\n+                    /*num_partitions=*/num_threads);\n \n     for (size_t i = 0; i < num_threads; ++i) {\n       threads.Schedule([i, &queue, &counter] {\n         Worker worker(i, &queue);\n-        while (std::optional<size_t> task = worker.Pop()) {\n+        while (std::optional<size_t> work_item = worker.Pop()) {\n         }\n         counter.DecrementCount();\n       });\n@@ -291,7 +292,7 @@ static void BM_PopTaskMultiThreaded(benchmark::State& state) {\n   state.SetItemsProcessed(state.iterations() * 1024 * 10);\n }\n \n-BENCHMARK(BM_PopTaskMultiThreaded)\n+BENCHMARK(BM_PopWorkItemMultiThreaded)\n     ->MeasureProcessCPUTime()\n     ->Arg(2)\n     ->Arg(4)"
        }
    ],
    "stats": {
        "total": 257,
        "additions": 128,
        "deletions": 129
    }
}