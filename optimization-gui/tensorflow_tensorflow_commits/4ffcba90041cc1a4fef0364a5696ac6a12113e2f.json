{
    "author": "basioli-k",
    "message": "[XLA][codegen] Emit stablehlo reduce op from the fusion emitter and lower it to triton for the triton backend.\n\nPiperOrigin-RevId: 826102479",
    "sha": "4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
    "files": [
        {
            "sha": "630ced0becc72024938d16552109801d058a95d0",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 37,
            "deletions": 9,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
            "patch": "@@ -69,6 +69,7 @@ limitations under the License.\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypeInterfaces.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Diagnostics.h\"\n #include \"mlir/IR/DialectRegistry.h\"\n #include \"mlir/IR/Location.h\"\n #include \"mlir/IR/MLIRContext.h\"\n@@ -412,14 +413,22 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n                                                      neutral.UnwrapUnsafe()));\n   }\n \n-  ttir::ReduceOp reduction =\n-      b.create<ttir::ReduceOp>(input.UnwrapUnsafe(), reduction_dimension);\n+  Value init_value = b.create<mlir::tensor::FromElementsOp>(\n+      mlir::RankedTensorType::get(\n+          /*shape=*/{}, values[tiled_hlo_reduce.operand(1)].getType()),\n+      values[tiled_hlo_reduce.operand(1)].UnwrapScalar());\n+\n+  stablehlo::ReduceOp reduction = b.create<stablehlo::ReduceOp>(\n+      input.UnwrapTensor(), init_value, reduction_dimension);\n   {\n     TF_ASSIGN_OR_RETURN(Type result_ty,\n                         TritonType(b, hlo_reduce.shape().element_type()));\n+    result_ty = mlir::RankedTensorType::get({}, result_ty);\n+\n     mlir::Location loc = b.getLoc();\n     mlir::Block* reducer = b.createBlock(&reduction->getRegion(0), {},\n                                          {result_ty, result_ty}, {loc, loc});\n+    b.setInsertionPointToStart(reducer);\n \n     HloComputation* reduction_computation = hlo_reduce.to_apply();\n \n@@ -430,27 +439,46 @@ absl::StatusOr<ScalarOrTensor> EmitReduce(\n       if (instr->opcode() == HloOpcode::kParameter) {\n         int parameter_number = instr->parameter_number();\n         TF_RET_CHECK(parameter_number < 2);\n-        TF_RET_CHECK(region_values\n-                         .insert({instr, ScalarOrTensor(reducer->getArgument(\n-                                             parameter_number))})\n-                         .second);\n+        auto argument = mlir::cast<mlir::TypedValue<mlir::RankedTensorType>>(\n+            reducer->getArgument(parameter_number));\n+\n+        if (!argument) {\n+          return Internal(\"Expected reducer argument to be a tensor.\");\n+        }\n+\n+        // Emit extract op so that the reducer can be lowered to triton, as the\n+        // triton reducer can only work with scalars.\n+        auto extracted_argument =\n+            ScalarOrTensor(b.create<mlir::tensor::ExtractOp>(\n+                                argument.getType().getElementType(), argument)\n+                               .getResult());\n+        TF_RET_CHECK(region_values.insert({instr, extracted_argument}).second);\n       } else {\n         to_emit.push_back(instr);\n       }\n     }\n \n     TF_RET_CHECK(!to_emit.empty());\n \n-    b.setInsertionPointToStart(reducer);\n     TF_ASSIGN_OR_RETURN(\n         ScalarOrTensor result,\n         EmitScope(b, libdevice_path, device_info, /*analysis=*/nullptr, to_emit,\n                   region_values));\n-    b.create<ttir::ReduceReturnOp>(SmallVector<Value>({result.UnwrapUnsafe()}));\n+    // Emit from_elements op so that the reducer can be lowered to triton, as\n+    // the triton reducer can only work with scalars.\n+    auto result_as_scalar = b.create<mlir::tensor::FromElementsOp>(\n+        result_ty, result.UnwrapUnsafe());\n+    b.create<stablehlo::ReturnOp>(SmallVector<Value>({result_as_scalar}));\n     b.setInsertionPointAfter(reduction);\n   }\n \n-  return ScalarOrTensor(reduction.getResult().front());\n+  auto result = reduction.getResult(0);\n+  if (mlir::cast<ShapedType>(result.getType()).getRank() == 0) {\n+    result = b.create<mlir::tensor::ExtractOp>(\n+        mlir::cast<ShapedType>(result.getType()).getElementType(), result);\n+  }\n+\n+  return ScalarOrTensor(result);\n }\n \n // Emit code corresponding to a fusion instruction somehow nested within the"
        },
        {
            "sha": "1efd2daeed68e303fef2621e310905bc2804e022",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 246,
            "deletions": 51,
            "changes": 297,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
            "patch": "@@ -341,11 +341,19 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n-CHECK:  \"tt.reduce\"(%[[LOAD:.*]]) <{axis = 1 : i32}>\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n+CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%{{.*}} init: %{{.*}}) across dimensions = [1] : (tensor<4x4xf32>, tensor<f32>) -> tensor<4xf32>\n )\"));\n \n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:  \"tt.reduce\"(%[[LOAD:.*]]) <{axis = 1 : i32}>\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"fused_computation\")));\n+\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -379,13 +387,29 @@ ENTRY entry_computation {\n         \"num_ctas\":1,\"num_stages\":1,\"is_tma_allowed\":false}}}\n }\n )\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText, \"fused_reduce\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"fused_reduce\", R\"(\n+CHECK: stablehlo.reduce\n+CHECK: reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)\n+CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG0]][] : tensor<f32>\n+CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG1]][] : tensor<f32>\n+CHECK:   %[[ADD:.*]] = arith.addf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n+CHECK:   %[[MIN:.*]] = arith.minimumf %[[ADD]]\n+CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[MIN]] : tensor<f32>\n+CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK: \"tt.reduce\"\n CHECK: ^bb0(%[[ARG0:.*]]: f32, %[[ARG1:.*]]: f32)\n CHECK: %[[ADD:.*]] = arith.addf %[[ARG0]], %[[ARG1]]\n CHECK: %[[MIN:.*]] = arith.minimumf %[[ADD]]\n CHECK: tt.reduce.return %[[MIN]]\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"fused_reduce\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -421,14 +445,26 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n-CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 1 : i32}>\n+CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%[[ABS]] init: %{{.*}}) across dimensions = [1] : (tensor<64x512xf32>, tensor<f32>) -> tensor<64xf32>\n CHECK:  xtile.insert %[[REDUCE]] {{.*}} : tensor<64xf32>\n CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<64x512xf32>\n )\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK-COUNT-1:  xtile.extract\n+CHECK:  %[[ABS:.*]] = math.absf\n+CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 1 : i32}>\n+CHECK:  xtile.insert %[[REDUCE]] {{.*}} : tensor<64xf32>\n+CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<64x512xf32>\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"fused_computation\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -463,15 +499,26 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n+CHECK-COUNT-1:  xtile.extract\n+CHECK:  %[[ABS:.*]] = math.absf\n+CHECK:  %[[REDUCE:.*]] = stablehlo.reduce(%[[ABS]] init: %{{.*}}) across dimensions = [0]\n+CHECK:  xtile.insert %[[ABS]]\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK-COUNT-1:  xtile.extract\n CHECK:  %[[ABS:.*]] = math.absf\n-CHECK: %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 0 : i32}>\n+CHECK:  %[[REDUCE:.*]] = \"tt.reduce\"(%[[ABS:.*]]) <{axis = 0 : i32}>\n CHECK: %[[SCALAR_TENSOR:.*]] = tensor.from_elements %[[REDUCE]] : tensor<f32>\n CHECK: xtile.insert %[[SCALAR_TENSOR]] into %arg1\n-CHECK: xtile.insert %[[ABS]] {{.*}} : tensor<512xf32>\n-)\"));\n+CHECK:  xtile.insert %[[ABS]] {{.*}} : tensor<512xf32>\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"fused_computation\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -831,12 +878,24 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"fused_computation\", R\"(\n CHECK-COUNT-1:  xtile.extract\n-CHECK: tt.reduce\n+CHECK: stablehlo.reduce\n CHECK-COUNT-2:  xtile.insert\n )\"));\n+\n+  TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK-COUNT-1:  xtile.extract\n+CHECK: tt.reduce\n+CHECK-COUNT-2:  xtile.insert\n+  )\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"fused_computation\")));\n+\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -915,9 +974,10 @@ ENTRY main {\n       auto xtile_module_and_hlo_module,\n       CreateXTileIrAndFileCheck(this, kHloText, \"triton_reduction_computation\",\n                                 R\"(\n-CHECK:  stablehlo.iota\n-CHECK:  stablehlo.broadcast_in_dim\n-CHECK:  \"tt.reduce\"(%[[SELECT:.*]]) <{axis = 2 : i32}>\n+\n+        CHECK:  stablehlo.iota\n+        CHECK:  stablehlo.broadcast_in_dim\n+        CHECK:  stablehlo.reduce(%[[SELECT:.*]] init: %{{.*}}) across dimensions = [2] : (tensor<4x2x8x8x1xf32>, tensor<f32>) -> tensor<4x2x8x1xf32>\n           )\"));\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n@@ -970,12 +1030,15 @@ CHECK:  %[[LOAD:.*]] = xtile.extract\n CHECK:  %[[RANGE:.*]] = stablehlo.iota\n CHECK:  %[[BROADCAST:.*]] = stablehlo.broadcast_in_dim %[[RANGE]]\n CHECK:  %[[CMPI:.*]] = arith.cmpi slt, %[[BROADCAST]]\n-CHECK:  %[[SELECT:.*]] = arith.select %[[CMPI]], %[[LOAD]]\n-CHECK:  \"tt.reduce\"(%[[SELECT]]) <{axis = 0 : i32}>\n-CHECK:  ^bb0(%[[ARG2:.*]]: f32, %[[ARG3:.*]]: f32):\n-CHECK:    %[[MAXIMUM:.*]] = arith.maximumf %[[ARG2]], %[[ARG3]] : f32\n-CHECK:    tt.reduce.return %[[MAXIMUM]] : f32\n-CHECK:  })\n+CHECK:  %[[SELECT:.*]] = arith.select %[[CMPI]], %[[LOAD]], %{{.*}}\n+CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%[[SELECT]] init: %{{.*}}) across dimensions = [0] : (tensor<8x4xf32>, tensor<f32>) -> tensor<4xf32>\n+CHECK:   reducer(%[[ARG0:.*]]: tensor<f32>, %[[ARG1:.*]]: tensor<f32>)  {\n+CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG0]][] : tensor<f32>\n+CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG1]][] : tensor<f32>\n+CHECK:   %[[MAX:.*]] = arith.maximumf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n+CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[MAX]] : tensor<f32>\n+CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK: }\n           )\"));\n \n   TF_ASSERT_OK(LowerXTileIrToTritonAndFileCheck(\n@@ -1030,9 +1093,31 @@ ENTRY main {\n         \"num_warps\":\"1\",\n         \"num_ctas\":\"1\",\n         \"num_stages\":\"1\"}}}})\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_softmax_computation\", R\"(\n-CHECK:        xtile.entry_func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[PID:.*]]: index)\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(\n+                              this, kHloText, \"triton_softmax_computation\", R\"(\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[PID:.*]]: index)\n+CHECK-DAG:        %[[EXTRACT_IDX_0:.*]] = xla.apply_indexing #indexing_map(%[[PID]])\n+CHECK-NEXT:       xtile.extract %[[P0]]\n+CHECK-SAME:       [%[[PID]], %[[EXTRACT_IDX_0]]] [1, 128] [1, 1]\n+CHECK:            stablehlo.reduce\n+CHECK-NEXT:       reducer(%[[ARG2:[^:]*]]: tensor<f32>, %[[ARG3:[^:]*]]: tensor<f32>)  {\n+CHECK-NEXT:           %[[ARG2_EXTRACTED:.*]] = tensor.extract %[[ARG2]][] : tensor<f32>\n+CHECK-NEXT:           %[[ARG3_EXTRACTED:.*]] = tensor.extract %[[ARG3]][] : tensor<f32>\n+CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG2_EXTRACTED]], %[[ARG3_EXTRACTED]] : f32\n+CHECK-NEXT:           %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[ADD]] : tensor<f32>\n+CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK-NEXT:       }\n+CHECK:            arith.mulf\n+CHECK-SAME:       tensor<1x128xf32>\n+CHECK:            xtile.insert {{.*}}[%[[PID]], %{{.*}}] [1, 128] [1, 1]\n+CHECK:            return\n+CHECK:        }\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[PID:.*]]: index)\n CHECK-DAG:        %[[C_0:.*]] = arith.constant 0 : index\n CHECK-NEXT:       xtile.extract %[[P0]]\n CHECK-SAME:       [%[[PID]], %[[C_0]]] [1, 128] [1, 1]\n@@ -1046,7 +1131,9 @@ CHECK-SAME:       tensor<1x128xf32>\n CHECK:            xtile.insert {{.*}}[%[[PID]], %[[C_0]]] [1, 128] [1, 1]\n CHECK:            return\n CHECK:        }\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_softmax_computation\")));\n }\n \n // TODO(b/353484968): Tests that don't run RunAndCompareNoHloPasses should be\n@@ -1084,9 +1171,35 @@ ENTRY main {\n         \"num_warps\":\"1\",\n         \"num_ctas\":\"1\",\n         \"num_stages\":\"1\"}}}})\";\n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_softmax_computation\", R\"(\n-CHECK:         xtile.entry_func @triton_fn(\n+\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(\n+                              this, kHloText, \"triton_softmax_computation\", R\"(\n+CHECK:         xtile.entry_func @xtile_dialect_fn(\n+CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: memref<127xf32>\n+CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                      %[[TID:[A-Za-z0-9_]*]]: index)\n+CHECK-DAG:        %[[EXTRACT_IDX_0:.*]] = xla.apply_indexing #indexing_map(%[[TID]])\n+CHECK-DAG:        xtile.extract %[[P0]][%[[TID]], %[[EXTRACT_IDX_0]]] [1, 128] [1, 1] : {{.*}} -> tensor<1x128xf32>\n+CHECK-DAG:        %[[EXTRACT_IDX_1:.*]] = xla.apply_indexing #indexing_map(%[[TID]])\n+CHECK-DAG:        xtile.extract %[[P1]][%[[EXTRACT_IDX_1]]] [128] [1] : {{.*}} -> tensor<128xf32>\n+CHECK:            stablehlo.reduce\n+CHECK-NEXT:       reducer(%[[ARG3:[^:]*]]: tensor<f32>, %[[ARG4:[^:]*]]: tensor<f32>)  {\n+CHECK-NEXT:           %[[ARG3_EXTRACTED:.*]] = tensor.extract %[[ARG3]][] : tensor<f32>\n+CHECK-NEXT:           %[[ARG4_EXTRACTED:.*]] = tensor.extract %[[ARG4]][] : tensor<f32>\n+CHECK-NEXT:           %[[ADD:.*]] = arith.addf %[[ARG3_EXTRACTED]], %[[ARG4_EXTRACTED]] : f32\n+CHECK-NEXT:           %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[ADD]] : tensor<f32>\n+CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK-NEXT:       }\n+CHECK:            arith.mulf\n+CHECK-DAG:        xtile.insert {{.*}} into %[[P2]]\n+CHECK-SAME:       [%[[TID]], %{{.*}}] [1, 128] [1, 1] : tensor<1x128xf32>\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:         xtile.entry_func @xtile_dialect_fn(\n CHECK-SAME:                      %[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n CHECK-SAME:                      %[[P1:[A-Za-z0-9_]*]]: memref<127xf32>\n CHECK-SAME:                      %[[P2:[A-Za-z0-9_]*]]: memref<125x127xf32>\n@@ -1102,7 +1215,9 @@ CHECK-NEXT:       }) : (tensor<1x128xf32>) -> tensor<1xf32>\n CHECK:            arith.mulf\n CHECK-DAG:        xtile.insert {{.*}} into %[[P2]]\n CHECK-SAME:       [%[[TID]], %[[C_0]]] [1, 128] [1, 1] : tensor<1x128xf32>\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_softmax_computation\")));\n }\n \n TEST_F(TritonEmitterTest, TestGenericEmitterWithMultipleTiledDimensions) {\n@@ -1145,11 +1260,38 @@ ENTRY main {\n           \"num_stages\":\"1\"}}}\n })\";\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_softmax_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(auto xtile_module_and_hlo_module,\n+                          CreateXTileIrAndFileCheck(\n+                              this, kHloText, \"triton_softmax_computation\", R\"(\n CHECK:        #[[MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 125), domain: pid_0 in [0, 1249]\">\n CHECK:        #[[MAP1:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 mod 125), domain: pid_0 in [0, 1249]\">\n-CHECK:        xtile.entry_func @triton_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}}, %[[TID:.*]]: index)\n+CHECK:        #[[C_0_MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (0), domain: pid_0 in [0, 1249]\">\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}}, %[[TID:.*]]: index)\n+CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[TID]]\n+CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n+CHECK-DAG:        %[[C_0:.*]] = xla.apply_indexing #[[C_0_MAP]](%[[TID]])\n+CHECK:            xtile.extract %[[P0]][%[[ROW_INDEX]], %[[COL_INDEX]], %[[C_0]]] [1, 1, 128] [1, 1, 1] : {{.*}} -> tensor<1x1x128xf32>\n+CHECK:            %[[C_0_COPY:.*]] = xla.apply_indexing #[[C_0_MAP]](%[[TID]])\n+CHECK:            xtile.extract %[[P1]][%[[C_0_COPY]]] [128] [1] : {{.*}} -> tensor<128xf32>\n+CHECK-DAG:        %[[ROW_INDEX_COPY:.*]] = xla.apply_indexing #[[MAP]](%[[TID]]\n+CHECK-DAG:        %[[COL_INDEX_COPY:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n+CHECK:            xtile.extract %[[P2]][%[[ROW_INDEX_COPY]], %[[COL_INDEX_COPY]]] [1, 1] [1, 1] : {{.*}} -> tensor<1x1xf32>\n+CHECK:            stablehlo.reduce\n+CHECK-NEXT:       reducer(%[[ARG4:[^:]*]]: tensor<f32>, %[[ARG5:[^:]*]]: tensor<f32>)  {\n+CHECK-NEXT:           %[[ARG4_EXTRACTED:.*]] = tensor.extract %[[ARG4]][] : tensor<f32>\n+CHECK-NEXT:           %[[ARG5_EXTRACTED:.*]] = tensor.extract %[[ARG5]][] : tensor<f32>\n+CHECK-NEXT:           %[[MAX:.*]] = arith.maximumf %[[ARG4_EXTRACTED]], %[[ARG5_EXTRACTED]] : f32\n+CHECK-NEXT:           %[[FROM_ELEMENTS_MAX:.*]] = tensor.from_elements %[[MAX]] : tensor<f32>\n+CHECK-NEXT:           stablehlo.return %[[FROM_ELEMENTS_MAX]] : tensor<f32>\n+CHECK-NEXT:       }\n+CHECK:            xtile.insert {{.*}} into %[[P3]]{{.*}}\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:        #[[MAP:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 floordiv 125), domain: pid_0 in [0, 1249]\">\n+CHECK:        #[[MAP1:.*]] = #xla.indexing_map<\"(pid_0) -> (pid_0 mod 125), domain: pid_0 in [0, 1249]\">\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:.*]]: {{.*}}, %[[P1:.*]]: {{.*}}, %[[P2:.*]]: {{.*}}, %[[P3:.*]]: {{.*}}, %[[TID:.*]]: index)\n CHECK-DAG:        %[[C_0:.*]] = arith.constant 0 : index\n CHECK-DAG:        %[[ROW_INDEX:.*]] = xla.apply_indexing #[[MAP]](%[[TID]]\n CHECK-DAG:        %[[COL_INDEX:.*]] = xla.apply_indexing #[[MAP1]](%[[TID]]\n@@ -1163,7 +1305,9 @@ CHECK-NEXT:           tt.reduce.return %[[MAX]] : f32\n CHECK-NEXT:       }) : (tensor<1x1x128xf32>) -> tensor<1x1xf32>\n CHECK:            xtile.insert {{.*}} into %[[P3]]\n CHECK-SAME:       [%[[ROW_INDEX]], %[[COL_INDEX]], %[[C_0]]] [1, 1, 128] [1, 1, 1] : tensor<1x1x128xf32>\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_softmax_computation\")));\n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n \n@@ -1543,12 +1687,26 @@ ENTRY main {\n         \"output_tiles\":[{\"sizes\":[\"1\"]}],\n         \"num_warps\":\"1\",\n         \"num_ctas\":\"1\",\n-        \"num_stages\":\"1\"}}}\n+          \"num_stages\":\"1\"}}}\n })\";\n \n-  TF_EXPECT_OK(CreateTritonIrAndFileCheck(this, kHloText,\n-                                          \"triton_reduction_computation\", R\"(\n-CHECK:        xtile.entry_func @triton_fn(%[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_reduction_computation\",\n+                                R\"(\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n+CHECK-SAME:                               %[[P1:[A-Za-z0-9_]*]]: memref<125xf32>\n+CHECK-SAME:                               %[[P2:[A-Za-z0-9_]*]]: memref<125xf32>\n+CHECK-DAG:        xtile.extract {{.*}} -> tensor<1xf32>\n+CHECK-DAG:        xtile.extract {{.*}} -> tensor<1x128xf32>\n+CHECK: %[[REDUCE:.*]] = stablehlo.reduce(%[[REDUCE_ARG:.*]] init: %{{.*}}) across dimensions = [1] : (tensor<1x128xf32>,    tensor<f32>) -> tensor<1xf32>\n+CHECK:            arith.mulf {{.*}} tensor<1xf32>\n+CHECK:            xtile.insert {{.*}} : tensor<1xf32>\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n+CHECK:        xtile.entry_func @xtile_dialect_fn(%[[P0:[A-Za-z0-9_]*]]: memref<125x127xf32>\n CHECK-SAME:                               %[[P1:[A-Za-z0-9_]*]]: memref<125xf32>\n CHECK-SAME:                               %[[P2:[A-Za-z0-9_]*]]: memref<125xf32>\n CHECK-DAG:        xtile.extract {{.*}} -> tensor<1xf32>\n@@ -1557,7 +1715,9 @@ CHECK:            tt.reduce\n CHECK:              (tensor<1x128xf32>) -> tensor<1xf32>\n CHECK:            arith.mulf {{.*}} tensor<1xf32>\n CHECK:            xtile.insert {{.*}} : tensor<1xf32>\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_reduction_computation\")));\n }\n \n TEST_F(TritonEmitterTest,\n@@ -2414,13 +2574,24 @@ ENTRY main {\n         \"num_ctas\":\"1\",\n         \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+CHECK:     xtile.extract\n+CHECK:     stablehlo.reduce\n+CHECK:     stablehlo.broadcast_in_dim\n+CHECK:     xtile.insert\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:     xtile.extract\n CHECK:     tt.reduce\n CHECK:     tt.broadcast\n CHECK:     xtile.insert\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }\n@@ -2859,14 +3030,26 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+CHECK:     xtile.extract {{.*}} -> tensor<f32>\n+CHECK:     stablehlo.broadcast_in_dim\n+CHECK:     arith.addf\n+CHECK:     stablehlo.reduce\n+CHECK:     xtile.insert {{.*}} : tensor<f32>\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:     xtile.extract {{.*}} -> tensor<f32>\n CHECK:     tt.splat\n CHECK:     arith.addf\n CHECK:     tt.reduce\n CHECK:     xtile.insert {{.*}} : tensor<f32>\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(\n       kHloText, ErrorSpec{/*aabs=*/6e-1, /*arel=*/6e-1}));\n@@ -2949,14 +3132,26 @@ ENTRY entry_computation {\n           \"num_ctas\":\"1\",\n           \"num_stages\":\"1\"}}}\n })\";\n-  TF_EXPECT_OK(\n-      CreateTritonIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      auto xtile_module_and_hlo_module,\n+      CreateXTileIrAndFileCheck(this, kHloText, \"triton_computation\", R\"(\n+CHECK:     xtile.extract\n+CHECK:     tt.reshape\n+CHECK:     stablehlo.reduce\n+CHECK:     stablehlo.reduce\n+CHECK:     xtile.insert\n+)\"));\n+\n+  TF_EXPECT_OK(LowerXTileIrToTritonAndFileCheck(\n+      this, xtile_module_and_hlo_module.first.get(), R\"(\n CHECK:     xtile.extract\n CHECK:     tt.reshape\n CHECK:     tt.reduce\n CHECK:     tt.reduce\n CHECK:     xtile.insert\n-)\"));\n+)\",\n+      GetFusionInstruction(*xtile_module_and_hlo_module.second,\n+                           \"triton_computation\")));\n \n   EXPECT_TRUE(RunAndCompareNoHloPasses(kHloText, kExactMatch));\n }"
        },
        {
            "sha": "276f6e765807ebd639d982207a4dfade8fce0aac",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_shared_dialect_test.cc",
            "status": "modified",
            "additions": 45,
            "deletions": 0,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_shared_dialect_test.cc?ref=4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
            "patch": "@@ -184,6 +184,51 @@ CHECK: %[[RES:.*]] = stablehlo.broadcast_in_dim %[[RES_FROM_ELEMENTS]], dims = [\n )\"));\n }\n \n+TEST_F(XTileDialectTest, HloReduceIsLoweredToStableHloReduce) {\n+  constexpr absl::string_view kHloText = R\"(\n+HloModule t\n+\n+add {\n+  a = f32[] parameter(0)\n+  b = f32[] parameter(1)\n+  ROOT add = f32[] add(a, b)\n+}\n+\n+reduce_fusion {\n+  p0 = f32[150,160] parameter(0)\n+  const = f32[] constant(0.0)\n+  ROOT broadcast = f32[160] reduce(p0, const), dimensions={0}, to_apply=add\n+}\n+\n+ENTRY e {\n+  p0 = f32[150,160] parameter(0)\n+  ROOT custom-call = f32[160] fusion(p0), kind=kCustom,\n+    calls=reduce_fusion,\n+    backend_config={\"fusion_backend_config\": {kind: \"__triton\"}}\n+})\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(kHloText));\n+\n+  BlockLevelParameters block_level_parameters;\n+  block_level_parameters.output_tile_sizes = {{16}};\n+\n+  TF_EXPECT_OK(CreateXTileIrAndFileCheck(\n+      this, *module->GetComputationWithName(\"reduce_fusion\"),\n+      block_level_parameters,\n+      R\"(\n+CHECK: %[[REDUCE_INPUT:.*]] = arith.select {{.*}}\n+CHECK: %[[INIT_VALUE_FROM_ELEMENTS:.*]] = tensor.from_elements %{{.*}} : tensor<f32>\n+CHECK: %[[RES:.*]] = stablehlo.reduce(%[[REDUCE_INPUT]] init: %[[INIT_VALUE_FROM_ELEMENTS]]) across dimensions = [0] : (tensor<256x16xf32>, tensor<f32>) -> tensor<16xf32>\n+CHECK: reducer(%[[ARG_0:.*]]: tensor<f32>, %[[ARG_1:.*]]: tensor<f32>)  {\n+CHECK:   %[[EXTRACTED_0:.*]] = tensor.extract %[[ARG_0]][] : tensor<f32>\n+CHECK:   %[[EXTRACTED_1:.*]] = tensor.extract %[[ARG_1]][] : tensor<f32>\n+CHECK:   %[[SUM:.*]] = arith.addf %[[EXTRACTED_0]], %[[EXTRACTED_1]] : f32\n+CHECK:   %[[FROM_ELEMENTS:.*]] = tensor.from_elements %[[SUM]] : tensor<f32>\n+CHECK:   stablehlo.return %[[FROM_ELEMENTS]] : tensor<f32>\n+CHECK: }\n+)\"));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "dad13f5868400ea0dc05740781fcbe80557a0318",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/stablehlo_lower_to_triton.cc",
            "status": "modified",
            "additions": 175,
            "deletions": 4,
            "changes": 179,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fstablehlo_lower_to_triton.cc?ref=4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
            "patch": "@@ -114,8 +114,9 @@ class LowerBroadcastInDim\n       auto broadcast_dim_input_element_type =\n           broadcast_dim_input.getType().getElementType();\n \n-      auto extracted = rewriter.create<mlir::tensor::ExtractOp>(\n-          op.getLoc(), broadcast_dim_input_element_type, broadcast_dim_input);\n+      auto extracted = mlir::tensor::ExtractOp::create(\n+          rewriter, op.getLoc(), broadcast_dim_input_element_type,\n+          broadcast_dim_input);\n \n       rewriter.replaceOpWithNewOp<ttir::SplatOp>(op, op.getResult().getType(),\n                                                  extracted);\n@@ -142,14 +143,184 @@ class LowerBroadcastInDim\n   }\n };\n \n+class LowerReduce : public mlir::OpRewritePattern<stablehlo::ReduceOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+ private:\n+  mlir::LogicalResult matchAndRewrite(\n+      stablehlo::ReduceOp op, mlir::PatternRewriter& rewriter) const override {\n+    if (mlir::failed(VerifyOpIsCompatibleWithTritonReduce(op, rewriter))) {\n+      return mlir::failure();\n+    }\n+\n+    int32_t axis = op.getDimensions()[0];\n+\n+    // In case shlo returns a 0 rank tensor triton needs to return a scalar as\n+    // triton doesn't support 0 rank tensors.\n+    SmallVector<Type> adjusted_result_types;\n+    adjusted_result_types.reserve(op.getNumResults());\n+    for (auto result : op.getResults()) {\n+      auto shaped_type = cast<mlir::ShapedType>(result.getType());\n+      if (shaped_type.getRank() == 0) {\n+        adjusted_result_types.push_back(shaped_type.getElementType());\n+      } else {\n+        adjusted_result_types.push_back(shaped_type);\n+      }\n+    }\n+\n+    auto triton_reduce_op = ttir::ReduceOp::create(\n+        rewriter, op.getLoc(), adjusted_result_types, op.getInputs(), axis);\n+\n+    Region& triton_reduce_region = triton_reduce_op.getCombineOp();\n+    rewriter.cloneRegionBefore(op.getBody(), triton_reduce_region,\n+                               triton_reduce_region.end());\n+    Block& triton_reduce_region_block = triton_reduce_region.front();\n+    for (mlir::BlockArgument& argument :\n+         triton_reduce_region_block.getArguments()) {\n+      auto extract_op = cast<mlir::tensor::ExtractOp>(*argument.user_begin());\n+\n+      auto scalar_type =\n+          cast<mlir::RankedTensorType>(argument.getType()).getElementType();\n+      argument.setType(scalar_type);\n+      rewriter.replaceOp(extract_op, argument);\n+    }\n+\n+    Operation* terminator = triton_reduce_region_block.getTerminator();\n+    rewriter.setInsertionPointToEnd(&triton_reduce_region_block);\n+    SmallVector<Value> return_operands;\n+    for (Value operand : terminator->getOperands()) {\n+      auto defining_op = operand.getDefiningOp();\n+      return_operands.push_back(mlir::tensor::ExtractOp::create(\n+          rewriter, defining_op->getLoc(),\n+          cast<mlir::RankedTensorType>(operand.getType()).getElementType(),\n+          defining_op->getResult(0)));\n+    }\n+    rewriter.replaceOpWithNewOp<ttir::ReduceReturnOp>(terminator,\n+                                                      return_operands);\n+\n+    rewriter.replaceOp(op, triton_reduce_op);\n+\n+    // Replace usages of the original op results. If the original result was a\n+    // 0-rank tensor, we need to wrap the scalar result of tt.reduce in a\n+    // tensor.from_elements op.\n+    rewriter.setInsertionPointAfter(triton_reduce_op);\n+    for (const auto& triton_result : triton_reduce_op.getResults()) {\n+      if (mlir::isa<mlir::ShapedType>(triton_result.getType())) {\n+        continue;\n+      }\n+      auto extract_op =\n+          cast<mlir::tensor::ExtractOp>(*triton_result.user_begin());\n+\n+      rewriter.replaceOp(extract_op, triton_result);\n+    }\n+    return mlir::success();\n+  }\n+\n+  // Verifies that the stablehlo reduce op can be lowered to a triton reduce\n+  // op.\n+  // This checks that proper emitting of `tensor.from_elements` and\n+  // `tensor.extract` on reducer inputs and outputs has happened. It also checks\n+  // that `tensor.extract` was emitted on the result of the reduce operation if\n+  // the result is a zero rank tensor.\n+  mlir::LogicalResult VerifyOpIsCompatibleWithTritonReduce(\n+      stablehlo::ReduceOp op, mlir::PatternRewriter& rewriter) const {\n+    if (mlir::failed(VerifyReducerArgs(op, rewriter))) {\n+      return mlir::failure();\n+    }\n+\n+    if (mlir::failed(VerifyReducerResults(op, rewriter))) {\n+      return mlir::failure();\n+    }\n+\n+    if (mlir::failed(VerifyResults(op, rewriter))) {\n+      return mlir::failure();\n+    }\n+\n+    // Check that the reduction is along a single dimension.\n+    auto dimensions = op.getDimensions();\n+    if (dimensions.size() != 1) {\n+      return rewriter.notifyMatchFailure(\n+          op->getLoc(), \"tt.reduce only supports single dimension reductions.\");\n+    }\n+\n+    return mlir::success();\n+  }\n+\n+  mlir::LogicalResult VerifyReducerArgs(stablehlo::ReduceOp op,\n+                                        mlir::PatternRewriter& rewriter) const {\n+    // Check that all arguments get extracted into a scalar.\n+    for (mlir::BlockArgument& argument : op.getBody().front().getArguments()) {\n+      if (!argument.hasOneUse()) {\n+        return rewriter.notifyMatchFailure(\n+            op, \"Expected a single user for an argument to a reduce combiner.\");\n+      }\n+      if (!dyn_cast<mlir::tensor::ExtractOp>(*argument.user_begin())) {\n+        return rewriter.notifyMatchFailure(op,\n+                                           \"Expected a tensor extract op as \"\n+                                           \"user of reduce combiner argument.\");\n+      }\n+    }\n+\n+    return mlir::success();\n+  }\n+\n+  mlir::LogicalResult VerifyReducerResults(\n+      stablehlo::ReduceOp op, mlir::PatternRewriter& rewriter) const {\n+    // Check that all outputs get created by a from_elements op.\n+    for (Value operand : op.getBody().front().getTerminator()->getOperands()) {\n+      if (!operand.hasOneUse()) {\n+        return rewriter.notifyMatchFailure(\n+            op->getLoc(),\n+            \"Expected a single user for an output of a reduce combiner.\");\n+      }\n+      auto from_elements =\n+          operand.getDefiningOp<mlir::tensor::FromElementsOp>();\n+      if (!from_elements) {\n+        return rewriter.notifyMatchFailure(op->getLoc(),\n+                                           \"Expected a from_elements op as \"\n+                                           \"user of reduce combiner output.\");\n+      }\n+    }\n+    return mlir::success();\n+  }\n+\n+  mlir::LogicalResult VerifyResults(stablehlo::ReduceOp op,\n+                                    mlir::PatternRewriter& rewriter) const {\n+    // Check that all results get created by a from_elements op.\n+    for (Value result : op.getResults()) {\n+      auto shaped_type = cast<mlir::ShapedType>(result.getType());\n+      // If the result is a shaped type, then we don't need to do anything.\n+      if (shaped_type.getRank() != 0) {\n+        continue;\n+      }\n+\n+      if (!result.hasOneUse()) {\n+        return rewriter.notifyMatchFailure(\n+            op->getLoc(), \"Expected a single user for reduce result.\");\n+      }\n+\n+      auto extract_op = dyn_cast<mlir::tensor::ExtractOp>(*result.user_begin());\n+\n+      if (!extract_op) {\n+        return rewriter.notifyMatchFailure(\n+            op->getLoc(),\n+            \"Expected a tensor extract op as \"\n+            \"the only user of 0 rank reduce result.\");\n+      }\n+    }\n+    return mlir::success();\n+  }\n+};\n+\n class StableHLOLowerToTritonPass\n     : public impl::StableHLOLowerToTritonPassBase<StableHLOLowerToTritonPass> {\n  public:\n   void runOnOperation() override {\n     mlir::MLIRContext* mlir_context = &getContext();\n     mlir::RewritePatternSet patterns(mlir_context);\n-    patterns.add<LowerTranspose, LowerIotaToMakeRange, LowerBroadcastInDim>(\n-        mlir_context);\n+    patterns.add<LowerTranspose, LowerIotaToMakeRange, LowerBroadcastInDim,\n+                 LowerReduce>(mlir_context);\n \n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {"
        },
        {
            "sha": "cf6221de14df4270399c39384f08e1a2cf911857",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/stable_hlo_to_triton_lowering.mlir",
            "status": "modified",
            "additions": 122,
            "deletions": 0,
            "changes": 122,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4ffcba90041cc1a4fef0364a5696ac6a12113e2f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Fstable_hlo_to_triton_lowering.mlir?ref=4ffcba90041cc1a4fef0364a5696ac6a12113e2f",
            "patch": "@@ -53,3 +53,125 @@ func.func @lower_broadcast_in_dim_on_0d_tensor_produced_by_from_elements_to_spla\n   // CHECK: return %[[RES]] : tensor<4x2xf32>\n   return %0 : tensor<4x2xf32>\n }\n+\n+// CHECK: func @reduce(%[[ARG0:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n+func.func @reduce(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[RES:.*]] = \"tt.reduce\"(%[[ARG0]]) <{axis = 0 : i32}> ({\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  //CHECK: ^bb0(%[[ARG1:.*]]: f32, %[[ARG2:.*]]: f32):\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n+    // CHECK: tt.reduce.return %[[RES]] : f32\n+    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n+    %3 = tensor.from_elements %2 : tensor<f32>\n+    stablehlo.return %3 : tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n+  return %1 : tensor<8xf32>\n+}\n+\n+// CHECK: func @reduce_to_scalar_followed_by_extract(%[[ARG0:.*]]: tensor<16xf32>) -> f32\n+func.func @reduce_to_scalar_followed_by_extract(%arg0: tensor<16xf32>) -> f32 {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[REDUCE_RESULT:.*]] = \"tt.reduce\"(%[[ARG0]]) <{axis = 0 : i32}> ({\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  //CHECK: ^bb0(%[[ARG1:.*]]: f32, %[[ARG2:.*]]: f32):\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    // CHECK: %[[RES:.*]] = arith.addf %[[ARG1]], %[[ARG2]] : f32\n+    // CHECK: tt.reduce.return %[[RES]] : f32\n+    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n+    %3 = tensor.from_elements %2 : tensor<f32>\n+    stablehlo.return %3 : tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n+  // CHECK-NOT: tensor.from_elements\n+  // CHECK-NOT: tensor.extract\n+  %extract = tensor.extract %1[] : tensor<f32>\n+  // CHECK: return %[[REDUCE_RESULT:.*]] : f32\n+  return %extract : f32\n+}\n+\n+// CHECK: func @reduce_to_zero_rank_tensor_without_extract_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16xf32>) -> tensor<f32>\n+func.func @reduce_to_zero_rank_tensor_without_extract_falls_back_to_stablehlo(%arg0: tensor<16xf32>) -> tensor<f32> {\n+  // CHECK: %[[CST:.*]] = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[REDUCE_RESULT:.*]] = stablehlo.reduce(%[[ARG0]] init: %[[CST]]) across dimensions = [0] : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n+    %3 = tensor.from_elements %2 : tensor<f32>\n+    stablehlo.return %3 : tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16xf32>, tensor<f32>) -> tensor<f32>\n+  return %1 : tensor<f32>\n+}\n+\n+// CHECK: func @reduce_over_multiple_dimensions_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8x4xf32>) -> tensor<4xf32>\n+func.func @reduce_over_multiple_dimensions_falls_back_to_stablehlo(%arg0: tensor<16x8x4xf32>) -> tensor<4xf32> {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) across dimensions = [0, 1] : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %2 = arith.addf %extracted_arg1, %extracted_arg2 : f32\n+    %3 = tensor.from_elements %2 : tensor<f32>\n+    stablehlo.return %3 : tensor<f32>\n+  }) {dimensions = array<i64: 0, 1>} : (tensor<16x8x4xf32>, tensor<f32>) -> tensor<4xf32>\n+  // CHECK: return %[[RES]] : tensor<4xf32>\n+  return %1 : tensor<4xf32>\n+}\n+\n+// CHECK: func @reduce_without_extract_on_input_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n+func.func @reduce_without_extract_on_input_falls_back_to_stablehlo(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) applies stablehlo.add across dimensions = [0] : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    %2 = stablehlo.add %arg1, %arg2 : tensor<f32>\n+    stablehlo.return %2 : tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n+  // CHECK: return %[[RES]] : tensor<8xf32>\n+  return %1 : tensor<8xf32>\n+}\n+\n+// CHECK: func @reduce_without_from_elements_on_output_falls_back_to_stablehlo(%[[ARG0:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n+func.func @reduce_without_from_elements_on_output_falls_back_to_stablehlo(%arg0: tensor<16x8xf32>) -> tensor<8xf32> {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[RES:.*]] = stablehlo.reduce(%[[ARG0]] init: %{{.*}}) across dimensions = [0] : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n+  %1 = \"stablehlo.reduce\"(%arg0, %0) ({\n+  ^bb0(%arg1: tensor<f32>, %arg2: tensor<f32>):\n+    %extracted_arg1 = tensor.extract %arg1[] : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2[] : tensor<f32>\n+    %from_elements_arg1 = tensor.from_elements %extracted_arg1 : tensor<f32>\n+    %from_elements_arg2 = tensor.from_elements %extracted_arg2 : tensor<f32>\n+    %2 = stablehlo.add %from_elements_arg1, %from_elements_arg2 : tensor<f32>\n+    stablehlo.return %2 : tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<f32>) -> tensor<8xf32>\n+  // CHECK: return %[[RES]] : tensor<8xf32>\n+  return %1 : tensor<8xf32>\n+}\n+\n+// CHECK: func @reduce_with_multiple_inputs(%[[ARG0:.*]]: tensor<16x8xf32>, %[[ARG1:.*]]: tensor<16x8xf32>) -> tensor<8xf32>\n+func.func @reduce_with_multiple_inputs(%arg0: tensor<16x8xf32>, %arg1: tensor<16x8xf32>) -> tensor<8xf32> {\n+  %0 = stablehlo.constant dense<0.000000e+00> : tensor<f32>\n+  // CHECK: %[[REDUCE_RESULT:.*]] = \"tt.reduce\"(%[[ARG0]], %[[ARG1]]) <{axis = 0 : i32}> ({\n+  %1, %2 = \"stablehlo.reduce\"(%arg0, %arg1, %0, %0) ({\n+  ^bb0(%arg0_reducer: tensor<f32>, %arg1_reducer: tensor<f32>, %arg2_reducer: tensor<f32>, %arg3_reducer: tensor<f32>):\n+    %extracted_arg0 = tensor.extract %arg0_reducer[] : tensor<f32>\n+    %extracted_arg1 = tensor.extract %arg1_reducer[] : tensor<f32>\n+    %2 = arith.addf %extracted_arg0, %extracted_arg1 : f32\n+    %3 = tensor.from_elements %2 : tensor<f32>\n+    %extracted_arg2 = tensor.extract %arg2_reducer[] : tensor<f32>\n+    %extracted_arg3 = tensor.extract %arg3_reducer[] : tensor<f32>\n+    %4 = arith.addf %extracted_arg2, %extracted_arg3 : f32\n+    %5 = tensor.from_elements %4 : tensor<f32>\n+    stablehlo.return %3, %5 : tensor<f32>, tensor<f32>\n+  }) {dimensions = array<i64: 0>} : (tensor<16x8xf32>, tensor<16x8xf32>, tensor<f32>, tensor<f32>) -> (tensor<8xf32>, tensor<8xf32>)\n+  return %1 : tensor<8xf32>\n+}\n+"
        }
    ],
    "stats": {
        "total": 689,
        "additions": 625,
        "deletions": 64
    }
}