{
    "author": "junwhanahn",
    "message": "Move program property calculation to compilation and remove `CompiledIfrtIrProgram::mlir_module`\n\nPiperOrigin-RevId: 805924384",
    "sha": "a578f79fa154a7a4f8ebf2e587d8edec352b670e",
    "files": [
        {
            "sha": "c5c036c143883061e42c36c8a5a0c093b816ebd4",
            "filename": "third_party/xla/xla/python/ifrt/ir/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2FBUILD?ref=a578f79fa154a7a4f8ebf2e587d8edec352b670e",
            "patch": "@@ -473,6 +473,7 @@ cc_library(\n         \":ir\",\n         \"//xla:status_macros\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/pjrt:pjrt_layout\",\n         \"//xla/python/ifrt\",\n         \"//xla/python/ifrt:attribute_map\",\n         \"//xla/python/ifrt/ir/transforms:debug\",\n@@ -487,7 +488,9 @@ cc_library(\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n+        \"@llvm-project//llvm:Support\",\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:Pass\","
        },
        {
            "sha": "88f8f93d6a8e62ed04045de996d0a7c9a8fffc6b",
            "filename": "third_party/xla/xla/python/ifrt/ir/compiled_ifrt_ir_program.cc",
            "status": "modified",
            "additions": 189,
            "deletions": 4,
            "changes": 193,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.cc?ref=a578f79fa154a7a4f8ebf2e587d8edec352b670e",
            "patch": "@@ -27,26 +27,34 @@ limitations under the License.\n #include \"absl/log/check.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n+#include \"absl/strings/str_format.h\"\n #include \"absl/types/span.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"llvm/Support/Casting.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OwningOpRef.h\"\n+#include \"mlir/IR/SymbolTable.h\"\n #include \"mlir/IR/Types.h\"\n+#include \"mlir/IR/Value.h\"\n #include \"mlir/Pass/PassManager.h\"\n #include \"mlir/Support/DebugStringHelper.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Support/LogicalResult.h\"\n+#include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array_spec.h\"\n #include \"xla/python/ifrt/attribute_map.h\"\n #include \"xla/python/ifrt/client.h\"\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n #include \"xla/python/ifrt/dtype.h\"\n #include \"xla/python/ifrt/ir/atom_program_compiler.h\"\n+#include \"xla/python/ifrt/ir/constants.h\"\n #include \"xla/python/ifrt/ir/ifrt_dialect.h\"\n #include \"xla/python/ifrt/ir/ifrt_ir_program.h\"\n+#include \"xla/python/ifrt/ir/ifrt_ops.h\"\n #include \"xla/python/ifrt/ir/transforms/debug.h\"\n #include \"xla/python/ifrt/ir/transforms/passes.h\"\n #include \"xla/python/ifrt/ir/transforms/utils.h\"\n@@ -129,6 +137,164 @@ absl::StatusOr<std::vector<xla::ifrt::ArraySpec>> ExtractOutSpecs(\n   return out_specs;\n }\n \n+absl::StatusOr<std::shared_ptr<const xla::PjRtLayout>>\n+GetParameterLayoutFromConsumer(\n+    xla::ifrt::Client* client,\n+    const AtomExecutableMap& atom_program_executables,\n+    absl::Span<const xla::ifrt::ArraySpec> in_specs,\n+    absl::Span<const xla::ifrt::ArraySpec> out_specs,\n+    mlir::SymbolTableCollection& symbol_table, mlir::OpOperand& param_operand) {\n+  if (auto call_op = llvm::dyn_cast<xla::ifrt::CallLoadedExecutableOp>(\n+          param_operand.getOwner())) {\n+    // The parameter is used by a CallLoadedExecutableOp, return the layout\n+    // from the atom program executable.\n+    xla::ifrt::LoadedExecutableOp loaded_exec_op =\n+        call_op.getCalleeOp(symbol_table);\n+    auto atom_program_name = loaded_exec_op.getSymName().str();\n+    auto exec_it = atom_program_executables.find(atom_program_name);\n+    if (exec_it != atom_program_executables.end()) {\n+      TF_ASSIGN_OR_RETURN(auto exec_layouts,\n+                          exec_it->second->GetParameterLayouts());\n+      return std::move(exec_layouts[param_operand.getOperandNumber()]);\n+    } else {\n+      return absl::FailedPreconditionError(absl::StrFormat(\n+          \"Could not find SPMD executable %s\", atom_program_name));\n+    }\n+  } else if (auto return_op = llvm::dyn_cast<mlir::func::ReturnOp>(\n+                 param_operand.getOwner())) {\n+    // TODO(b/382761415): AUTO layouts should be handled during IFRT IR program\n+    // compilation so that by the time this method is called there should be no\n+    // AUTO layouts.\n+    // The parameter is not used by any atom program, return device default\n+    // layout.\n+    const auto& out_spec = out_specs[param_operand.getOperandNumber()];\n+    TF_ASSIGN_OR_RETURN(auto shard_shape,\n+                        out_spec.sharding->GetShardShape(out_spec.shape));\n+    return client->GetDefaultLayout(\n+        out_spec.dtype, shard_shape.dims(),\n+        out_spec.sharding->devices()->devices().front(),\n+        out_spec.sharding->memory_kind());\n+  } else if (auto copy_arrays =\n+                 llvm::dyn_cast<ifrt::CopyArraysOp>(param_operand.getOwner())) {\n+    // If the parameter is used by a CopyArraysOp, we assume a default layout.\n+    if (auto arg = llvm::dyn_cast<mlir::BlockArgument>(param_operand.get())) {\n+      const auto& arg_spec = in_specs[arg.getArgNumber()];\n+      TF_ASSIGN_OR_RETURN(auto shard_shape,\n+                          arg_spec.sharding->GetShardShape(arg_spec.shape));\n+      return client->GetDefaultLayout(\n+          arg_spec.dtype, shard_shape.dims(),\n+          arg_spec.sharding->devices()->devices().front(),\n+          arg_spec.sharding->memory_kind());\n+    } else {\n+      return absl::FailedPreconditionError(absl::StrFormat(\n+          \"Parameter used by CopyArraysOp does not originate from a block \"\n+          \"argument. Parameter used by %s\",\n+          xla::ifrt::OperationToString(param_operand.getOwner(),\n+                                       mlir::OpPrintingFlags())));\n+    }\n+  } else {\n+    return absl::FailedPreconditionError(absl::StrFormat(\n+        \"Layouts are supported only for programs that have parameters used \"\n+        \"only by CallLoadedExecutableOp ops. Used by %s\",\n+        xla::ifrt::OperationToString(param_operand.getOwner(),\n+                                     mlir::OpPrintingFlags())));\n+  }\n+}\n+\n+absl::Status PopulateLayouts(mlir::ModuleOp mlir_module,\n+                             xla::ifrt::Client* client,\n+                             const AtomExecutableMap& atom_program_executables,\n+                             absl::Span<xla::ifrt::ArraySpec> in_specs,\n+                             absl::Span<xla::ifrt::ArraySpec> out_specs) {\n+  auto main_func = xla::ifrt::GetMainFunction(mlir_module);\n+  mlir::SymbolTableCollection symbol_table;\n+\n+  for (mlir::BlockArgument& arg : main_func.getArguments()) {\n+    std::shared_ptr<const xla::PjRtLayout> parameter_layout;\n+    if (arg.use_empty()) {\n+      // The argument is not used. Return device default layout.\n+      const auto& arg_spec = in_specs[arg.getArgNumber()];\n+      TF_ASSIGN_OR_RETURN(auto shard_shape,\n+                          arg_spec.sharding->GetShardShape(arg_spec.shape));\n+      TF_ASSIGN_OR_RETURN(parameter_layout,\n+                          client->GetDefaultLayout(\n+                              arg_spec.dtype, shard_shape.dims(),\n+                              arg_spec.sharding->devices()->devices().front(),\n+                              arg_spec.sharding->memory_kind()));\n+    } else {\n+      mlir::OpOperand& first_use = *arg.getUses().begin();\n+      TF_ASSIGN_OR_RETURN(parameter_layout,\n+                          GetParameterLayoutFromConsumer(\n+                              client, atom_program_executables, in_specs,\n+                              out_specs, symbol_table, first_use));\n+      for (mlir::OpOperand& use : llvm::drop_begin(arg.getUses())) {\n+        TF_ASSIGN_OR_RETURN(auto layout_from_executable,\n+                            GetParameterLayoutFromConsumer(\n+                                client, atom_program_executables, in_specs,\n+                                out_specs, symbol_table, use));\n+        // Verify that all uses of the parameter have the same layout.\n+        if (*parameter_layout != *layout_from_executable) {\n+          return absl::InternalError(absl::StrFormat(\n+              \"Parameter %d is used by atom programs with incompatible \"\n+              \"layouts: %s vs. %s. This happens because support for layout \"\n+              \"progation within MPMD programs is limited. Contact \"\n+              \"ml-pathways-team@ for help\",\n+              arg.getArgNumber(), parameter_layout->ToString(),\n+              layout_from_executable->ToString()));\n+        }\n+      }\n+    }\n+    in_specs[arg.getArgNumber()].layout = std::move(parameter_layout);\n+  }\n+\n+  for (mlir::OpOperand& return_operand :\n+       main_func.front().getTerminator()->getOpOperands()) {\n+    auto& out_spec = out_specs[return_operand.getOperandNumber()];\n+    if (mlir::BlockArgument block_arg =\n+            llvm::dyn_cast<mlir::BlockArgument>(return_operand.get())) {\n+      // The output is an argument of the IFRT IR program. Assume device\n+      // default layout.\n+      TF_ASSIGN_OR_RETURN(auto shard_shape,\n+                          out_spec.sharding->GetShardShape(out_spec.shape));\n+      TF_ASSIGN_OR_RETURN(out_spec.layout,\n+                          client->GetDefaultLayout(\n+                              out_spec.dtype, shard_shape.dims(),\n+                              out_spec.sharding->devices()->devices().front(),\n+                              out_spec.sharding->memory_kind()));\n+      continue;\n+    }\n+    auto op_result = llvm::cast<mlir::OpResult>(return_operand.get());\n+    if (xla::ifrt::CallLoadedExecutableOp owner_call_op =\n+            llvm::dyn_cast<xla::ifrt::CallLoadedExecutableOp>(\n+                op_result.getOwner())) {\n+      xla::ifrt::LoadedExecutableOp loaded_exec_op =\n+          owner_call_op.getCalleeOp(symbol_table);\n+      auto atom_program_name = loaded_exec_op.getSymName().str();\n+      auto exec_it = atom_program_executables.find(atom_program_name);\n+      if (exec_it != atom_program_executables.end()) {\n+        TF_ASSIGN_OR_RETURN(auto exec_layouts,\n+                            exec_it->second->GetOutputLayouts());\n+        // Since this method is a temporary solution, we are ok with calling\n+        // GetOutputLayouts for an executable multiple times. In this way, we\n+        // avoid std::moving the same unique_ptr if an atom program result is\n+        // returned multiple times.\n+        out_spec.layout = std::move(exec_layouts[op_result.getResultNumber()]);\n+      } else {\n+        return absl::FailedPreconditionError(absl::StrFormat(\n+            \"Could not find SPMD executable %s\", atom_program_name));\n+      }\n+    } else {\n+      return absl::FailedPreconditionError(absl::StrFormat(\n+          \"Layouts are supported only for programs that have outputs produced \"\n+          \"by a CallLoadedExecutableOp. Produced by %s\",\n+          xla::ifrt::OperationToString(op_result.getOwner(),\n+                                       mlir::OpPrintingFlags())));\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n }  // namespace\n \n absl::StatusOr<CompiledIfrtIrProgram> CompiledIfrtIrProgram::Create(\n@@ -235,16 +401,35 @@ absl::StatusOr<CompiledIfrtIrProgram> CompiledIfrtIrProgram::Create(\n   TF_ASSIGN_OR_RETURN(std::vector<xla::ifrt::ArraySpec> out_specs,\n                       ExtractOutSpecs(mlir_module, client, devices));\n \n+  absl::Status layout_status =\n+      PopulateLayouts(mlir_module, client, *atom_executable_map,\n+                      absl::MakeSpan(in_specs), absl::MakeSpan(out_specs));\n+  if (!layout_status.ok()) {\n+    for (auto& spec : in_specs) {\n+      spec.layout = nullptr;\n+    }\n+    for (auto& spec : out_specs) {\n+      spec.layout = nullptr;\n+    }\n+  }\n+\n+  mlir::func::FuncOp main_func = xla::ifrt::GetMainFunction(mlir_module);\n+  std::vector<int> donatable_input_indices;\n+  for (const auto [idx, arg] : llvm::enumerate(main_func.getArguments())) {\n+    if (main_func.getArgAttr(idx, xla::ifrt::kIfrtDonatedArgAttrName) !=\n+        nullptr) {\n+      donatable_input_indices.push_back(idx);\n+    }\n+  }\n+\n   return CompiledIfrtIrProgram{\n       /*program_name=*/mlir_module.getName().value_or(\"unknown\").str(),\n       /*atom_program_executables=*/std::move(atom_executable_map),\n       /*in_specs=*/std::move(in_specs),\n       /*out_specs=*/std::move(out_specs),\n+      /*layout_status=*/layout_status,\n+      /*donatable_input_indices=*/std::move(donatable_input_indices),\n       /*program=*/std::move(ifrt_ir_program),\n-      // TODO(b/382761415): Do not store the mlir module once we can get the\n-      // layouts from the IFRT IR ArrayType. It is currently necessary to clone\n-      // to avoid accessing the module from different threads.\n-      /*mlir_module=*/mlir::OwningOpRef<mlir::ModuleOp>(mlir_module.clone()),\n       /*device_assignments=*/std::move(device_assignments),\n   };\n }"
        },
        {
            "sha": "5896dfc52c41d90177d88f4a6def32c16b72c018",
            "filename": "third_party/xla/xla/python/ifrt/ir/compiled_ifrt_ir_program.h",
            "status": "modified",
            "additions": 10,
            "deletions": 11,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a578f79fa154a7a4f8ebf2e587d8edec352b670e/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt%2Fir%2Fcompiled_ifrt_ir_program.h?ref=a578f79fa154a7a4f8ebf2e587d8edec352b670e",
            "patch": "@@ -19,9 +19,8 @@ limitations under the License.\n #include <string>\n #include <vector>\n \n+#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n-#include \"mlir/IR/BuiltinOps.h\"\n-#include \"mlir/IR/OwningOpRef.h\"\n #include \"xla/python/ifrt/array_spec.h\"\n #include \"xla/python/ifrt/client.h\"\n #include \"xla/python/ifrt/device.h\"\n@@ -46,16 +45,16 @@ struct CompiledIfrtIrProgram {\n   // Specifications of the program outputs.\n   std::vector<xla::ifrt::ArraySpec> out_specs;\n \n-  // Hold the IfrtIRProgram to avoid the module from being destroyed, in the\n-  // case where the IfrtIRProgram owns the MLIR module.\n-  std::unique_ptr<xla::ifrt::IfrtIRProgram> program;\n+  // Indicates whether the program supports querying input/output layout. If\n+  // this is OK, `in_specs` and `out_specs` will have `layout` field populated.\n+  // Otherwise, the layout field will be nullptr.\n+  absl::Status layout_status;\n+\n+  // The indices of the donatable inputs in the program.\n+  std::vector<int> donatable_input_indices;\n \n-  // TODO(b/382761415): Remove this field once the layouts in the types are\n-  // populated.\n-  // Note: It is important for the mlir_module to be after the program because\n-  // the module is using the MLIR context of the program, and thus must be\n-  // destroyed before the program.\n-  mlir::OwningOpRef<mlir::ModuleOp> mlir_module;\n+  // The input program.\n+  std::unique_ptr<xla::ifrt::IfrtIRProgram> program;\n \n   // Mapping from logical device ids in IFRT IR MLIR module to runtime device\n   // ids obtained from IFRT client."
        }
    ],
    "stats": {
        "total": 217,
        "additions": 202,
        "deletions": 15
    }
}