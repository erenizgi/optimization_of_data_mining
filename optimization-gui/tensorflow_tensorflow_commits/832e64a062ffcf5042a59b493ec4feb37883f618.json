{
    "author": "pschuh",
    "message": "Move ExecutePrepare and ExecuteLaunch to CommonPjRtClient.\n\nPiperOrigin-RevId: 845472618",
    "sha": "832e64a062ffcf5042a59b493ec4feb37883f618",
    "files": [
        {
            "sha": "86833819c6c3569984b3c118df7d962161261575",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.cc",
            "status": "modified",
            "additions": 120,
            "deletions": 0,
            "changes": 120,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/832e64a062ffcf5042a59b493ec4feb37883f618/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/832e64a062ffcf5042a59b493ec4feb37883f618/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc?ref=832e64a062ffcf5042a59b493ec4feb37883f618",
            "patch": "@@ -747,6 +747,126 @@ std::vector<std::unique_ptr<PjRtBuffer>> CommonPjRtClient::CreateOutputs(\n   return res;\n }\n \n+absl::Status CommonPjRtLoadedExecutable::ExecutePrepare(\n+    ExecuteLaunchArgs& launch_args,\n+    absl::Span<PjRtBuffer* const> argument_handles, int replica, int partition,\n+    const ExecuteOptions& options, size_t host_callback_idx,\n+    PjRtDevice* device) const {\n+  tsl::profiler::TraceMe traceme(\"CommonPjRtLoadedExecutable::ExecutePrepare\");\n+  TF_ASSIGN_OR_RETURN(auto executable,\n+                      StartRawExecutable(options, replica, partition, device));\n+  // Fill in device to launch_args so it will be present even if ExecutePrepare\n+  // fails with OOM.\n+  device = executable->device();\n+  launch_args.device = device;\n+\n+  // Execute takes `extra_deps` and waits for those to be\n+  // fulfilled before executing the program and returning an available\n+  // `execute_event` signaling that the program execution is complete. To avoid\n+  // clobbering inputs, we must ensure that\n+  //   `extra_deps` = inputs' definition events + donated inputs' usage events.\n+  // This also ensures that the returned `execute_event` dominates all inputs'\n+  // events, and thus output buffer only need to contain `execute_event` as the\n+  // single definition event.\n+  launch_args.extra_deps =\n+      client()->CreateDeviceEventSet(argument_handles.size());\n+  launch_args.control_deps =\n+      client()->CreateDeviceEventSet(argument_handles.size());\n+\n+  bool is_error = false;\n+  TF_RETURN_IF_ERROR(CommonPjRtClient::PrepareArguments(\n+      options, argument_handles, ParametersThatMustBeDonated(),\n+      *launch_args.extra_deps, *launch_args.control_deps,\n+      launch_args.input_buffers, launch_args.device_buffers, device, replica,\n+      partition, parameter_device_shapes_, is_error));\n+\n+  absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>\n+      output_leaf_buffers;\n+  if (!is_error) {\n+    // Allocate output with input reuse. Any allocation errors are returned\n+    // immediately. Derived classes may use custom logic for allocation.\n+    TF_ASSIGN_OR_RETURN(output_leaf_buffers,\n+                        client()->AllocateOutputBuffersWithInputReuse(\n+                            output_device_shape_, launch_args.device_buffers,\n+                            input_output_alias_config(), device,\n+                            output_memory_space_kind_ids_));\n+    VLOG(3) << \"Created output buffer: \" << output_device_shape_.ToString();\n+\n+    TF_RETURN_IF_ERROR(CheckBufferCompatibilities(\n+        options, launch_args.input_buffers, argument_handles));\n+  }\n+\n+  TF_RETURN_IF_ERROR(executable->Load(options, host_callback_idx));\n+\n+  launch_args.executable = std::move(executable);\n+  launch_args.options = &options;\n+  launch_args.is_predetermined_error = is_error;\n+  launch_args.output_leaf_buffers = std::move(output_leaf_buffers);\n+  return absl::OkStatus();\n+}\n+\n+absl::Span<int const> CommonPjRtLoadedExecutable::ParametersThatMustBeDonated()\n+    const {\n+  return parameters_that_must_be_donated_;\n+}\n+\n+absl::Status CommonPjRtLoadedExecutable::CheckBufferCompatibilities(\n+    const ExecuteOptions& options,\n+    absl::Span<const tsl::RCReference<CommonPjRtRawBuffer>> input_buffers,\n+    absl::Span<PjRtBuffer* const> argument_handles) const {\n+  if (input_buffers.size() != input_buffer_sizes_in_bytes_.size()) {\n+    return InvalidArgument(\n+        \"Execution supplied %lld buffers but compiled program expected %lld \"\n+        \"buffers\",\n+        input_buffers.size(), input_buffer_sizes_in_bytes_.size());\n+  }\n+  for (int i = 0; i < input_buffers.size(); ++i) {\n+    size_t buffer_size = input_buffers[i]->GetOnDeviceSizeInBytes();\n+    if (input_buffer_sizes_in_bytes_[i] != buffer_size) {\n+      const auto& expected_shape = parameter_device_shapes_[i];\n+      const auto& actual_shape = argument_handles[i]->on_device_shape();\n+      return InvalidArgument(\n+          \"Executable(%s) expected parameter %d of size %lld (%s) but got \"\n+          \"buffer with incompatible size %lld (%s)\",\n+          name(), i, input_buffer_sizes_in_bytes_[i],\n+          expected_shape.ToString(true), buffer_size,\n+          actual_shape.ToString(true));\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n+PjRtLoadedExecutable::Result CommonPjRtLoadedExecutable::ExecuteLaunch(\n+    ExecuteLaunchArgs& launch_args, bool fill_future) const {\n+  CHECK(launch_args.extra_deps.get()) << \"extra_deps is nullptr\";\n+  CHECK(launch_args.control_deps.get()) << \"control_deps is nullptr\";\n+  auto results =\n+      std::move(*launch_args.executable)\n+          .Execute(*launch_args.options, launch_args.input_buffers,\n+                   launch_args.output_leaf_buffers, *launch_args.extra_deps,\n+                   *launch_args.control_deps,\n+                   launch_args.is_predetermined_error, fill_future);\n+  {\n+    tsl::profiler::TraceMe t3(\"Handle input event recording\");\n+    // Handle input event recording.\n+    for (CommonPjRtBuffer::ScopedHold& b : launch_args.device_buffers) {\n+      if (b.type() == CommonPjRtBuffer::ScopedHold::kUsage) {\n+        b.ConvertUsageHold(results.primary_execute_event);\n+      } else {\n+        CHECK(b.type() == CommonPjRtBuffer::ScopedHold::kDonation);\n+        b.ConfirmDonation();\n+      }\n+    }\n+  }\n+  return PjRtLoadedExecutable::Result(\n+      {/*future=*/std::move(results.future),\n+       /*buffers=*/client()->CreateOutputs(\n+           output_device_shape_, results.primary_execute_event,\n+           launch_args.device, output_memory_space_kind_ids_,\n+           std::move(launch_args.output_leaf_buffers),\n+           launch_args.is_predetermined_error)});\n+}\n+\n absl::StatusOr<std::unique_ptr<PjRtBuffer>>\n CommonPjRtBufferImpl::CopyToCpuMemorySpace(const xla::Shape& dst_shape,\n                                            PjRtMemorySpace* dst_memory_space) {"
        },
        {
            "sha": "839403ce4e7a6758aa28f890175224e42727900a",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.h",
            "status": "modified",
            "additions": 107,
            "deletions": 0,
            "changes": 107,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/832e64a062ffcf5042a59b493ec4feb37883f618/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/832e64a062ffcf5042a59b493ec4feb37883f618/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h?ref=832e64a062ffcf5042a59b493ec4feb37883f618",
            "patch": "@@ -152,6 +152,11 @@ class CommonPjRtClient : public PjRtClient {\n     return CreateLinkedEventPromise(memory_space, \"CreateLinkedEventPromise\");\n   }\n \n+  virtual std::unique_ptr<PjRtDeviceEventSet> CreateDeviceEventSet(\n+      size_t preallocated_size) const {\n+    LOG(FATAL) << \"Implement\";\n+  }\n+\n   // Registers the necessary debug information for an allocation event.\n   // TODO(parkers): Once everything is unified this should be controlled\n   // by a non-device-specific config instead of delegating this control\n@@ -263,6 +268,108 @@ class CommonPjRtClient : public PjRtClient {\n       bool is_predetermined_error);\n };\n \n+// Represents the launch state for a loaded executable. This state must be\n+// reconstructed each time we want to launch the executable.\n+class PjRtRawLoadedExecutable {\n+ public:\n+  virtual ~PjRtRawLoadedExecutable() = default;\n+\n+  virtual PjRtDevice* device() = 0;\n+\n+  virtual absl::Status Load(const ExecuteOptions& options,\n+                            size_t host_callback_idx) = 0;\n+\n+  struct RawExecuteResult {\n+    std::optional<tsl::Future<>> future;\n+    tsl::RCReference<PjRtDeviceEvent> primary_execute_event;\n+  };\n+  virtual RawExecuteResult Execute(\n+      const ExecuteOptions& options,\n+      absl::Span<const tsl::RCReference<CommonPjRtRawBuffer>> inputs,\n+      absl::Span<const tsl::RCReference<CommonPjRtRawBuffer>> results,\n+      PjRtDeviceEventSet& extra_deps, PjRtDeviceEventSet& control_deps,\n+      bool is_predetermined_error, bool fill_future) && = 0;\n+};\n+\n+class CommonPjRtLoadedExecutable : public PjRtLoadedExecutable {\n+ public:\n+  CommonPjRtLoadedExecutable(CommonPjRtClient* client,\n+                             std::vector<Shape> parameter_device_shapes,\n+                             Shape output_device_shape,\n+                             std::vector<int> output_memory_space_kind_ids,\n+                             std::vector<PjRtDevice*> addressable_devices)\n+      : parameter_device_shapes_(std::move(parameter_device_shapes)),\n+        output_device_shape_(std::move(output_device_shape)),\n+        output_memory_space_kind_ids_(std::move(output_memory_space_kind_ids)),\n+        addressable_devices_(std::move(addressable_devices)) {}\n+\n+  CommonPjRtClient* client() const override = 0;\n+\n+  absl::Span<PjRtDevice* const> addressable_devices() const override {\n+    return addressable_devices_;\n+  }\n+\n+ protected:\n+  // Execute is split into Prepare and Launch.\n+  // Prepare can fail and be retried, while Launch is guaranteed to succeed.\n+  struct ExecuteLaunchArgs {\n+    PjRtDevice* device;\n+    std::unique_ptr<PjRtRawLoadedExecutable> executable;\n+    absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4> input_buffers;\n+    absl::InlinedVector<CommonPjRtBuffer::ScopedHold, 4> device_buffers;\n+    std::unique_ptr<PjRtDeviceEventSet> extra_deps;\n+    std::unique_ptr<PjRtDeviceEventSet> control_deps;\n+    absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>\n+        output_leaf_buffers;\n+    bool is_predetermined_error;\n+    const ExecuteOptions* options;\n+  };\n+\n+  virtual absl::StatusOr<std::unique_ptr<PjRtRawLoadedExecutable>>\n+  StartRawExecutable(const ExecuteOptions& options, int replica, int partition,\n+                     PjRtDevice* device) const = 0;\n+\n+  // Returns a sorted list of the parameters that must be donated as a\n+  // side-effect of the execution. Derived classes may use custom logic.\n+  absl::Span<int const> ParametersThatMustBeDonated() const;\n+\n+  virtual const HloInputOutputAliasConfig& input_output_alias_config()\n+      const = 0;\n+\n+  // Checks that the input buffers passed in by the user have the correct size\n+  // on device for the compiled program.\n+  absl::Status CheckBufferCompatibilities(\n+      const ExecuteOptions& options,\n+      absl::Span<const tsl::RCReference<CommonPjRtRawBuffer>> input_buffers,\n+      absl::Span<PjRtBuffer* const> argument_handles) const;\n+\n+  absl::Status ExecutePrepare(ExecuteLaunchArgs& launch_args,\n+                              absl::Span<PjRtBuffer* const> argument_handles,\n+                              int replica, int partition,\n+                              const ExecuteOptions& options,\n+                              size_t host_callback_idx,\n+                              PjRtDevice* device) const;\n+\n+  Result ExecuteLaunch(ExecuteLaunchArgs& launch_args, bool fill_future) const;\n+\n+  // Parameter shapes.\n+  std::vector<Shape> parameter_device_shapes_;\n+  // A sorted vector of parameters that have any aliased buffers and thus must\n+  // be donated when executing the computation.\n+  std::vector<int> parameters_that_must_be_donated_;\n+  // Result layouts (device shapes).\n+  Shape output_device_shape_;\n+  // memory_space()->kind_id() for each output buffer.\n+  std::vector<int> output_memory_space_kind_ids_;\n+  // Size on device of each leaf buffer of the compiled program, cached here\n+  // for performance reasons.\n+  std::vector<int64_t> input_buffer_sizes_in_bytes_;\n+  // addressable_devices_[i] is the Device to which\n+  // addressable_device_logical_ids_[i] is assigned. shared_ptrs instead of\n+  // unique_ptrs to play well with the Python bindings (see xla.cc).\n+  std::vector<PjRtDevice*> addressable_devices_;\n+};\n+\n // TODO(parkers): Merge everything here into CommonPjRtBuffer.\n class CommonPjRtBufferImpl : public CommonPjRtBuffer {\n  public:"
        }
    ],
    "stats": {
        "total": 227,
        "additions": 227,
        "deletions": 0
    }
}