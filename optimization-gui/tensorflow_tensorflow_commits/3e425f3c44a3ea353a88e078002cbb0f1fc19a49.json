{
    "author": "hyeontaek",
    "message": "[IFRT] Migrate `Array::pjrt_layout()` callers to interpret `nullptr` as a default layout\n\n`Array::pjrt_layout()` will be changed to return `nullptr` to indicate a default layout, where the callers can obtain the corresponding concrete default layout by using `Client::GetDefaultPjRtLayout()`.\n\nThis change adds `nullptr` handling preemptively before the new `Array::pjrt_layout()` semantics becomes effective so that the existing code works as before.\n\nTests using `Array::pjrt_layout()` method calls are minimally updated to add a non-nullness check. They will be updated as `Array::pjrt_layout()` actually returns `nullptr`.\n\nPiperOrigin-RevId: 818618831",
    "sha": "3e425f3c44a3ea353a88e078002cbb0f1fc19a49",
    "files": [
        {
            "sha": "f86952b26d7b7cdc3e89a848dcbe593aa2cdc7e0",
            "filename": "third_party/xla/xla/python/transfer/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e425f3c44a3ea353a88e078002cbb0f1fc19a49/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e425f3c44a3ea353a88e078002cbb0f1fc19a49/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2FBUILD?ref=3e425f3c44a3ea353a88e078002cbb0f1fc19a49",
            "patch": "@@ -266,6 +266,7 @@ cc_library(\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/pjrt:pjrt_client\",\n+        \"//xla/pjrt:pjrt_layout\",\n         \"//xla/pjrt/distributed:key_value_store_interface\",\n         \"//xla/python/ifrt\",\n         \"//xla/python/pjrt_ifrt\","
        },
        {
            "sha": "442357d44bccdcb051448216d686bfd59866b265",
            "filename": "third_party/xla/xla/python/transfer/pjrt_transfer_server.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 0,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/3e425f3c44a3ea353a88e078002cbb0f1fc19a49/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2Fpjrt_transfer_server.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/3e425f3c44a3ea353a88e078002cbb0f1fc19a49/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2Fpjrt_transfer_server.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Ftransfer%2Fpjrt_transfer_server.cc?ref=3e425f3c44a3ea353a88e078002cbb0f1fc19a49",
            "patch": "@@ -37,6 +37,7 @@ limitations under the License.\n #include \"xla/layout.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/pjrt_layout.h\"\n #include \"xla/python/ifrt/array.h\"\n #include \"xla/python/ifrt/device.h\"\n #include \"xla/python/ifrt/device_list.h\"\n@@ -250,6 +251,17 @@ absl::Status PjRtTransferServer::CrossHostPull(\n \n     auto pjrt_layout = arrays[i]->pjrt_layout();\n     std::optional<xla::Layout> layout;\n+    if (pjrt_layout.ok() && *pjrt_layout == nullptr) {\n+      TF_ASSIGN_OR_RETURN(\n+          xla::ifrt::Shape shard_shape,\n+          arrays[i]->sharding().GetShardShape(arrays[i]->shape()));\n+      TF_ASSIGN_OR_RETURN(\n+          std::shared_ptr<const xla::PjRtLayout> layout,\n+          arrays[i]->client()->GetDefaultPjRtLayout(\n+              arrays[i]->dtype(), shard_shape.dims(),\n+              arrays[i]->sharding().devices()->devices().front(),\n+              arrays[i]->sharding().memory_kind()));\n+    }\n     if (pjrt_layout.ok()) {\n       layout = (*pjrt_layout)->xla_layout();\n     }\n@@ -345,6 +357,16 @@ PjRtTransferServer::CopyArraysForCrossHost(\n                         arrays[i]->shared_ptr_sharding()->WithDeviceAssignment(\n                             dst_devices, memory_kind));\n     TF_ASSIGN_OR_RETURN(auto new_layout, arrays[i]->pjrt_layout());\n+    if (new_layout == nullptr) {\n+      TF_ASSIGN_OR_RETURN(\n+          xla::ifrt::Shape shard_shape,\n+          arrays[i]->sharding().GetShardShape(arrays[i]->shape()));\n+      TF_ASSIGN_OR_RETURN(\n+          new_layout, arrays[i]->client()->GetDefaultPjRtLayout(\n+                          arrays[i]->dtype(), shard_shape.dims(),\n+                          arrays[i]->sharding().devices()->devices().front(),\n+                          arrays[i]->sharding().memory_kind()));\n+    }\n     PjRtArray::PjRtBuffers array_buffers;\n     array_buffers.reserve(buffers_by_device.size());\n     for (auto& [_, bufs] : buffers_by_device) {"
        }
    ],
    "stats": {
        "total": 23,
        "additions": 23,
        "deletions": 0
    }
}