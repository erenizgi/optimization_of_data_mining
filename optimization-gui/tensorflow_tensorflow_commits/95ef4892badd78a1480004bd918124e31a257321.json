{
    "author": "beckerhe",
    "message": "Remove unused gpu_types.h header and build target.\n\nThe gpu_types.h header is no longer included by any code and can be safely removed. This also allows for the removal of the associated build target.\n\nPiperOrigin-RevId: 845790036",
    "sha": "95ef4892badd78a1480004bd918124e31a257321",
    "files": [
        {
            "sha": "4796e6b3e31cbd60c8575f84ea70bcb687f13619",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=95ef4892badd78a1480004bd918124e31a257321",
            "patch": "@@ -193,7 +193,7 @@ xla_test(\n     name = \"custom_call_test\",\n     srcs = [\"custom_call_test.cc\"],\n     backends = [\"gpu\"],\n-    local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]),\n+    local_defines = if_cuda_is_configured([\"GOOGLE_CUDA=1\"]) + if_rocm_is_configured([\"TENSORFLOW_USE_ROCM=1\"]),\n     tags = [\"no-oneapi\"],  # TODO(intel-tf): Remove it when macro substitutions for SYCL are available in xla/stream_executor/sycl/*.\n     deps = [\n         \"//xla:debug_options_flags\",\n@@ -219,7 +219,6 @@ xla_test(\n         \"//xla/stream_executor:device_address_allocator\",\n         \"//xla/stream_executor:scratch_allocator\",\n         \"//xla/stream_executor:stream\",\n-        \"//xla/stream_executor/gpu:gpu_types_header\",\n         \"//xla/tests:client_library_test_runner_mixin\",\n         \"//xla/tests:hlo_test_base\",\n         \"//xla/tests:xla_internal_test_main\",  # fixdeps: keep"
        },
        {
            "sha": "4807574fcdbdb96ea241974a18aea683980f4708",
            "filename": "third_party/xla/xla/service/gpu/custom_call_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 11,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fcustom_call_test.cc?ref=95ef4892badd78a1480004bd918124e31a257321",
            "patch": "@@ -59,7 +59,6 @@ limitations under the License.\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/stream_executor/device_address.h\"\n-#include \"xla/stream_executor/gpu/gpu_types.h\"\n #include \"xla/stream_executor/scratch_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tests/client_library_test_runner_mixin.h\"\n@@ -76,13 +75,15 @@ limitations under the License.\n #define gpuMemcpy cudaMemcpy\n #define gpuMemcpyDeviceToHost cudaMemcpyDeviceToHost\n #define gpuMemcpyHostToDevice cudaMemcpyHostToDevice\n+#define gpuStream CUstream\n #elif TENSORFLOW_USE_ROCM\n #define gpuSuccess hipSuccess\n #define gpuMemcpyAsync hipMemcpyAsync\n #define gpuMemcpyDeviceToDevice hipMemcpyDeviceToDevice\n #define gpuMemcpy hipMemcpy\n #define gpuMemcpyDeviceToHost hipMemcpyDeviceToHost\n #define gpuMemcpyHostToDevice hipMemcpyHostToDevice\n+#define gpuStream hipStream_t\n #endif\n \n namespace xla {\n@@ -123,8 +124,8 @@ struct TokenTestCase {\n   std::string opaque;\n };\n \n-void Callback_Tokens(se::gpu::GpuStreamHandle stream, void** buffers,\n-                     const char* opaque, size_t opaque_len) {\n+void Callback_Tokens(gpuStream stream, void** buffers, const char* opaque,\n+                     size_t opaque_len) {\n   for (int i = 0; i < opaque_len; ++i) {\n     char c = opaque[i];\n     ASSERT_TRUE(c == 'A' || c == 'T');\n@@ -190,9 +191,8 @@ class CustomCallTokensTest\n   }\n };\n \n-void Callback_WithStatusSucceeded(se::gpu::GpuStreamHandle /*stream*/,\n-                                  void** /*buffers*/, const char* /*opaque*/,\n-                                  size_t /*opaque_len*/,\n+void Callback_WithStatusSucceeded(gpuStream /*stream*/, void** /*buffers*/,\n+                                  const char* /*opaque*/, size_t /*opaque_len*/,\n                                   XlaCustomCallStatus* status) {\n   XlaCustomCallStatusSetSuccess(status);\n }\n@@ -210,9 +210,8 @@ TEST_F(CustomCallTest, WithStatusSucceeded) {\n   TF_ASSERT_OK(ExecuteAndTransfer(&b, {}).status());\n }\n \n-void Callback_WithStatusFailed(se::gpu::GpuStreamHandle /*stream*/,\n-                               void** /*buffers*/, const char* /*opaque*/,\n-                               size_t /*opaque_len*/,\n+void Callback_WithStatusFailed(gpuStream /*stream*/, void** /*buffers*/,\n+                               const char* /*opaque*/, size_t /*opaque_len*/,\n                                XlaCustomCallStatus* status) {\n   XlaCustomCallStatusSetFailure(status, \"Failed\", 6);\n }\n@@ -875,8 +874,8 @@ TEST_F(CustomCallTest, AsyncCustomCalls) {\n \n class CustomCallHloTest : public HloTestBase {};\n \n-void CallBack_AddOne(se::gpu::GpuStreamHandle stream, void** buffers,\n-                     const char* /*opaque*/, size_t /*opaque_len*/) {\n+void CallBack_AddOne(gpuStream stream, void** buffers, const char* /*opaque*/,\n+                     size_t /*opaque_len*/) {\n   // Expect that the input and output buffers are the same.\n   if (buffers[0] != buffers[1]) {\n     return;"
        },
        {
            "sha": "bf76eb7cea13a44431fb8933cea813d05ae93317",
            "filename": "third_party/xla/xla/stream_executor/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 22,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/95ef4892badd78a1480004bd918124e31a257321/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2FBUILD?ref=95ef4892badd78a1480004bd918124e31a257321",
            "patch": "@@ -5,10 +5,6 @@ load(\n     \"@local_config_rocm//rocm:build_defs.bzl\",\n     \"if_rocm_is_configured\",\n )\n-load(\n-    \"@local_config_sycl//sycl:build_defs.bzl\",\n-    \"if_sycl_is_configured\",\n-)\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\")\n load(\n     \"//xla/stream_executor:build_defs.bzl\",\n@@ -254,24 +250,6 @@ cc_library(\n     ],\n )\n \n-cc_library(\n-    name = \"gpu_types_header\",\n-    hdrs = [\"gpu_types.h\"],\n-    defines = if_rocm_is_configured([\n-        \"TENSORFLOW_USE_ROCM=1\",\n-    ]) + if_sycl_is_configured([\n-        \"TENSORFLOW_USE_SYCL=1\",\n-    ]),\n-    tags = [\"gpu\"],\n-    deps = if_cuda_is_configured([\n-        \"@local_config_cuda//cuda:cuda_headers\",\n-    ]) + if_rocm_is_configured([\n-        \"@local_config_rocm//rocm:rocm_headers\",\n-    ]) + if_sycl_is_configured([\n-        \"@local_config_sycl//sycl:sycl_headers\",\n-    ]),\n-)\n-\n cc_library(\n     name = \"gpu_asm_opts\",\n     hdrs = [\"gpu_asm_opts.h\"],"
        },
        {
            "sha": "84c5d400c991069be6bb8a6755dd9bede0b3326c",
            "filename": "third_party/xla/xla/stream_executor/gpu/gpu_types.h",
            "status": "removed",
            "additions": 0,
            "deletions": 55,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b22ae073cde56e9043683784da17232238d1d8b2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_types.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b22ae073cde56e9043683784da17232238d1d8b2/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_types.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fgpu_types.h?ref=b22ae073cde56e9043683784da17232238d1d8b2",
            "patch": "@@ -1,55 +0,0 @@\n-/* Copyright 2019 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-// GPU (SYCL / ROCm / CUDA) specific type handle resolution\n-\n-#ifndef XLA_STREAM_EXECUTOR_GPU_GPU_TYPES_H_\n-#define XLA_STREAM_EXECUTOR_GPU_GPU_TYPES_H_\n-\n-#if TENSORFLOW_USE_SYCL\n-\n-#include \"sycl/sycl.hpp\"\n-\n-#elif TENSORFLOW_USE_ROCM\n-\n-#include \"rocm/include/hip/hip_runtime.h\"\n-#include \"rocm/include/hiprand/hiprand.h\"\n-\n-#else  // CUDA\n-\n-#include \"third_party/gpus/cuda/include/cuda.h\"\n-\n-#endif\n-\n-namespace stream_executor {\n-namespace gpu {\n-\n-#if TENSORFLOW_USE_SYCL\n-\n-using GpuStreamHandle = ::sycl::queue*;\n-\n-#elif TENSORFLOW_USE_ROCM\n-\n-using GpuStreamHandle = hipStream_t;\n-#else  // CUDA\n-\n-using GpuStreamHandle = CUstream;\n-\n-#endif\n-\n-}  // namespace gpu\n-}  // namespace stream_executor\n-\n-#endif  // XLA_STREAM_EXECUTOR_GPU_GPU_TYPES_H_"
        }
    ],
    "stats": {
        "total": 101,
        "additions": 11,
        "deletions": 90
    }
}