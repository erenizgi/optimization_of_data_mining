{
    "author": "thomasjoerg",
    "message": "[XLA:GPU] Pre-factor DotDecomposer: Extract repetitive code for handling LHS and RHS operands during dot canonicalization.\n\nAlso use a consistent naming scheme using the prefixes `original` and `canonical` to refer to the existing dot and the canonical replacement being built.\n\nPiperOrigin-RevId: 838735497",
    "sha": "5fb03342f2e1b7ffdd6b47daddf20062ab62f68c",
    "files": [
        {
            "sha": "14937dca203513c1e2a4d5f066a44728684d36cb",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/BUILD",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5fb03342f2e1b7ffdd6b47daddf20062ab62f68c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5fb03342f2e1b7ffdd6b47daddf20062ab62f68c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2FBUILD?ref=5fb03342f2e1b7ffdd6b47daddf20062ab62f68c",
            "patch": "@@ -339,20 +339,18 @@ cc_library(\n     hdrs = [\"dot_decomposer.h\"],\n     deps = [\n         \"//xla:shape_util\",\n+        \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n-        \"//xla/service:shape_inference\",\n+        \"//xla/tsl/platform:errors\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/container:flat_hash_set\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:errors\",\n-        \"@local_tsl//tsl/platform:logging\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n "
        },
        {
            "sha": "34e0c13f9a01ee4ada55ea9e7ca5c752141826de",
            "filename": "third_party/xla/xla/hlo/transforms/expanders/dot_decomposer.cc",
            "status": "modified",
            "additions": 171,
            "deletions": 163,
            "changes": 334,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5fb03342f2e1b7ffdd6b47daddf20062ab62f68c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5fb03342f2e1b7ffdd6b47daddf20062ab62f68c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fexpanders%2Fdot_decomposer.cc?ref=5fb03342f2e1b7ffdd6b47daddf20062ab62f68c",
            "patch": "@@ -15,7 +15,6 @@ limitations under the License.\n \n #include \"xla/hlo/transforms/expanders/dot_decomposer.h\"\n \n-#include <algorithm>\n #include <cstdint>\n #include <memory>\n #include <utility>\n@@ -33,19 +32,121 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/layout_util.h\"\n-#include \"xla/service/shape_inference.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/util.h\"\n #include \"xla/xla_data.pb.h\"\n-#include \"tsl/platform/errors.h\"\n-#include \"tsl/platform/logging.h\"\n-#include \"tsl/platform/statusor.h\"\n \n namespace xla {\n \n namespace {\n \n+bool IsCanonical(Shape operand_shape,\n+                 absl::Span<const int64_t> contracting_dimensions,\n+                 absl::Span<const int64_t> batch_dimensions) {\n+  // A dot is not canonical if there is more than one contracting dimension.\n+  if (contracting_dimensions.size() != 1) {\n+    return false;\n+  }\n+  // A dot is not canonical if it has more than one non-contracting\n+  // dimension.\n+  if (batch_dimensions.size() + 2 < operand_shape.dimensions().size()) {\n+    return false;\n+  }\n+  if (batch_dimensions.empty() && contracting_dimensions.empty()) {\n+    return false;\n+  }\n+  // Check that batch dims, if present, are canonical.\n+  std::vector<int64_t> canonical_batch_dims(batch_dimensions.size());\n+  absl::c_iota(canonical_batch_dims, 0);\n+  if (!absl::c_equal(batch_dimensions, canonical_batch_dims)) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+HloInstruction* CanonicalizeOperand(\n+    HloInstruction* operand, absl::Span<const int64_t> original_batch_dims,\n+    absl::Span<const int64_t> original_contracting_dims,\n+    absl::Span<const int64_t> canonical_batch_dims,\n+    const std::vector<bool>& canonical_batch_dynamic_dims,\n+    tsl::protobuf::RepeatedField<int64_t>* canonical_contracting_dims,\n+    bool contracting_dim_as_most_minor) {\n+  const Shape& operand_shape = operand->shape();\n+  const int64_t rank = operand_shape.dimensions().size();\n+  const int64_t num_non_contracting_dims =\n+      rank - original_batch_dims.size() - original_contracting_dims.size();\n+  std::vector<int64_t> non_contracting_dims;\n+  non_contracting_dims.reserve(num_non_contracting_dims);\n+  int64_t contracting_size = 1;\n+  bool contracting_dynamic = false;\n+  int64_t non_contracting_size = 1;\n+  bool non_contracting_dynamic = false;\n+  for (int64_t i = 0; i < rank; ++i) {\n+    if (absl::c_linear_search(original_contracting_dims, i)) {\n+      contracting_size *= operand_shape.dimensions(i);\n+      contracting_dynamic |= operand_shape.is_dynamic_dimension(i);\n+    } else if (!absl::c_linear_search(original_batch_dims, i)) {\n+      non_contracting_dims.push_back(i);\n+      non_contracting_size *= operand_shape.dimensions(i);\n+      non_contracting_dynamic |= operand_shape.is_dynamic_dimension(i);\n+    }\n+  }\n+  std::vector<int64_t> permutation;\n+  permutation.reserve(rank);\n+  permutation.insert(permutation.end(), original_batch_dims.begin(),\n+                     original_batch_dims.end());\n+  if (contracting_dim_as_most_minor) {\n+    permutation.insert(permutation.end(), non_contracting_dims.begin(),\n+                       non_contracting_dims.end());\n+    permutation.insert(permutation.end(), original_contracting_dims.begin(),\n+                       original_contracting_dims.end());\n+  } else {\n+    permutation.insert(permutation.end(), original_contracting_dims.begin(),\n+                       original_contracting_dims.end());\n+    permutation.insert(permutation.end(), non_contracting_dims.begin(),\n+                       non_contracting_dims.end());\n+  }\n+  HloComputation* computation = operand->parent();\n+  HloInstruction* transpose_op = computation->AddInstruction(\n+      HloInstruction::CreateTranspose(\n+          ShapeUtil::PermuteDimensionsIgnoringLayout(permutation,\n+                                                     operand_shape),\n+          operand, permutation),\n+      &operand->metadata());\n+\n+  std::vector<int64_t> reshape_dims(canonical_batch_dims.begin(),\n+                                    canonical_batch_dims.end());\n+  std::vector<bool> reshape_dynamic_dims(canonical_batch_dynamic_dims.begin(),\n+                                         canonical_batch_dynamic_dims.end());\n+  if (contracting_dim_as_most_minor) {\n+    canonical_contracting_dims->Add(canonical_batch_dims.size() +\n+                                    (non_contracting_size != 1 ? 1 : 0));\n+    if (non_contracting_size != 1) {\n+      reshape_dims.push_back(non_contracting_size);\n+      reshape_dynamic_dims.push_back(non_contracting_dynamic);\n+    }\n+    reshape_dims.push_back(contracting_size);\n+    reshape_dynamic_dims.push_back(contracting_dynamic);\n+  } else {\n+    canonical_contracting_dims->Add(canonical_batch_dims.size());\n+    reshape_dims.push_back(contracting_size);\n+    reshape_dynamic_dims.push_back(contracting_dynamic);\n+    if (non_contracting_size != 1) {\n+      reshape_dims.push_back(non_contracting_size);\n+      reshape_dynamic_dims.push_back(non_contracting_dynamic);\n+    }\n+  }\n+  // Reshape the contracting and non-contracting dimensions together.\n+  return computation->AddInstruction(\n+      HloInstruction::CreateReshape(\n+          ShapeUtil::MakeShape(operand_shape.element_type(), reshape_dims,\n+                               reshape_dynamic_dims),\n+          transpose_op),\n+      &transpose_op->metadata());\n+}\n+\n // Convert a dot into a canonical form;\n // * Non-contracting dimensions are reshaped together,\n // * Contracting dimensions are reshaped together,\n@@ -56,158 +157,84 @@ absl::Status CanonicalizeDot(HloDotInstruction* original_dot) {\n   auto computation = original_dot->parent();\n   const auto& original_dnums = original_dot->dot_dimension_numbers();\n   const int64_t num_batch_dims = original_dnums.lhs_batch_dimensions_size();\n-  const int64_t num_contracting_dims =\n-      original_dnums.lhs_contracting_dimensions_size();\n+  std::vector<int64_t> canonical_batch_dims;\n+  canonical_batch_dims.reserve(num_batch_dims);\n+  std::vector<bool> canonical_batch_dynamic_dims;\n+  canonical_batch_dynamic_dims.reserve(num_batch_dims);\n \n-  const auto& lhs_shape = original_dot->operand(0)->shape();\n+  HloInstruction* lhs_operand = original_dot->mutable_operand(0);\n+  HloInstruction* rhs_operand = original_dot->mutable_operand(1);\n+  const auto& lhs_shape = lhs_operand->shape();\n   const int64_t lhs_rank = lhs_shape.dimensions().size();\n-  const int64_t num_lhs_non_contracting_dims =\n-      lhs_rank - num_batch_dims - num_contracting_dims;\n-\n-  std::vector<int64_t> lhs_non_contracting_dims;\n-  lhs_non_contracting_dims.reserve(num_lhs_non_contracting_dims);\n-  int64_t lhs_contracting_size = 1;\n-  bool lhs_contracting_dynamic = false;\n-  int64_t lhs_non_contracting_size = 1;\n-  bool lhs_non_contracting_dynamic = false;\n-  std::vector<int64_t> batch_dim_sizes;\n-  batch_dim_sizes.reserve(num_batch_dims);\n-  std::vector<bool> batch_dynamic_dims;\n-  batch_dynamic_dims.reserve(num_batch_dims);\n   for (int64_t i = 0; i < lhs_rank; ++i) {\n-    if (absl::c_linear_search(original_dnums.lhs_contracting_dimensions(), i)) {\n-      lhs_contracting_size *= lhs_shape.dimensions(i);\n-      lhs_contracting_dynamic |= lhs_shape.is_dynamic_dimension(i);\n-    } else if (absl::c_linear_search(original_dnums.lhs_batch_dimensions(),\n-                                     i)) {\n-      batch_dim_sizes.push_back(lhs_shape.dimensions(i));\n-      batch_dynamic_dims.push_back(lhs_shape.is_dynamic_dimension(i));\n-    } else {\n-      lhs_non_contracting_dims.push_back(i);\n-      lhs_non_contracting_size *= lhs_shape.dimensions(i);\n-      lhs_non_contracting_dynamic |= lhs_shape.is_dynamic_dimension(i);\n+    if (absl::c_linear_search(original_dnums.lhs_batch_dimensions(), i)) {\n+      canonical_batch_dims.push_back(lhs_shape.dimensions(i));\n+      canonical_batch_dynamic_dims.push_back(lhs_shape.is_dynamic_dimension(i));\n     }\n   }\n+  DotDimensionNumbers canonical_dnums;\n+  std::vector<int64_t> canonical_dot_dims = canonical_batch_dims;\n+  std::vector<bool> canonical_dot_dynamic_dims = canonical_batch_dynamic_dims;\n+  for (int64_t i = 0; i < num_batch_dims; ++i) {\n+    canonical_dnums.add_lhs_batch_dimensions(i);\n+    canonical_dnums.add_rhs_batch_dimensions(i);\n+  }\n+\n   // The canonical form of the lhs is\n   // [BatchDims, NonContractingDimsProduct, ContractingsDimsProduct]\n   // However, [ContractingDim, NonContractingDim] is considered canonical too.\n   // If NonContractingDimsProduct is 1, it is omitted.\n-  std::vector<int64_t> lhs_transpose;\n-  lhs_transpose.reserve(lhs_rank);\n-  lhs_transpose.insert(lhs_transpose.end(),\n-                       original_dnums.lhs_batch_dimensions().begin(),\n-                       original_dnums.lhs_batch_dimensions().end());\n-  lhs_transpose.insert(lhs_transpose.end(), lhs_non_contracting_dims.begin(),\n-                       lhs_non_contracting_dims.end());\n-  lhs_transpose.insert(lhs_transpose.end(),\n-                       original_dnums.lhs_contracting_dimensions().begin(),\n-                       original_dnums.lhs_contracting_dimensions().end());\n-  HloInstruction* lhs_operand = original_dot->mutable_operand(0);\n-  HloInstruction* transposed_lhs = computation->AddInstruction(\n-      HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensionsIgnoringLayout(lhs_transpose, lhs_shape),\n-          lhs_operand, lhs_transpose),\n-      &lhs_operand->metadata());\n \n-  std::vector<int64_t> lhs_reshape_dims = batch_dim_sizes;\n-  std::vector<bool> lhs_reshape_dynamic_dims = batch_dynamic_dims;\n-  if (lhs_non_contracting_size != 1) {\n-    lhs_reshape_dims.push_back(lhs_non_contracting_size);\n-    lhs_reshape_dynamic_dims.push_back(lhs_non_contracting_dynamic);\n-  }\n-  lhs_reshape_dims.push_back(lhs_contracting_size);\n-  lhs_reshape_dynamic_dims.push_back(lhs_contracting_dynamic);\n-  // Reshape the contracting and non-contracting dimensions together.\n-  HloInstruction* reshaped_lhs = computation->AddInstruction(\n-      HloInstruction::CreateReshape(\n-          ShapeUtil::MakeShape(lhs_shape.element_type(), lhs_reshape_dims,\n-                               lhs_reshape_dynamic_dims),\n-          transposed_lhs),\n-      &transposed_lhs->metadata());\n-\n-  const auto& rhs_shape = original_dot->operand(1)->shape();\n-  const int64_t rhs_rank = rhs_shape.dimensions().size();\n-  const int64_t num_rhs_non_contracting_dims =\n-      rhs_rank - num_batch_dims - num_contracting_dims;\n-  std::vector<int64_t> rhs_non_contracting_dims;\n-  rhs_non_contracting_dims.reserve(num_rhs_non_contracting_dims);\n-  int64_t rhs_non_contracting_size = 1;\n-  bool rhs_non_contracting_dynamic = false;\n-  int64_t rhs_contracting_size = 1;\n-  bool rhs_contracting_dynamic = false;\n-  for (int64_t i = 0; i < rhs_rank; ++i) {\n-    if (absl::c_linear_search(original_dnums.rhs_contracting_dimensions(), i)) {\n-      rhs_contracting_size *= rhs_shape.dimensions(i);\n-      rhs_contracting_dynamic |= rhs_shape.is_dynamic_dimension(i);\n-    } else if (!absl::c_linear_search(original_dnums.rhs_batch_dimensions(),\n-                                      i)) {\n-      rhs_non_contracting_dims.push_back(i);\n-      rhs_non_contracting_size *= rhs_shape.dimensions(i);\n-      rhs_non_contracting_dynamic |= rhs_shape.is_dynamic_dimension(i);\n-    }\n+  HloInstruction* reshaped_lhs =\n+      CanonicalizeOperand(lhs_operand, original_dnums.lhs_batch_dimensions(),\n+                          original_dnums.lhs_contracting_dimensions(),\n+                          canonical_batch_dims, canonical_batch_dynamic_dims,\n+                          canonical_dnums.mutable_lhs_contracting_dimensions(),\n+                          /*contracting_dim_as_most_minor=*/true);\n+  const auto& canonical_lhs_shape = reshaped_lhs->shape();\n+  const auto& canonical_lhs_non_contracting_dims =\n+      GetNonContractingDims(canonical_lhs_shape.dimensions().size(),\n+                            canonical_dnums.lhs_batch_dimensions(),\n+                            canonical_dnums.lhs_contracting_dimensions());\n+  // At this point of canonicalization, there are 0 or 1 non-contracting dims.\n+  if (canonical_lhs_non_contracting_dims.size() == 1) {\n+    int64_t lhs_non_contracting_dim = canonical_lhs_non_contracting_dims.at(0);\n+    canonical_dot_dims.push_back(\n+        canonical_lhs_shape.dimensions(lhs_non_contracting_dim));\n+    canonical_dot_dynamic_dims.push_back(\n+        canonical_lhs_shape.is_dynamic_dimension(lhs_non_contracting_dim));\n   }\n \n   // The canonical form of the rhs is\n   // [BatchDims, ContractingsDimsProduct, NonContractingDimsProduct]\n   // However, [NonContractingDim, ContractingDim] is considered canonical too.\n   // If NonContractingDimsProduct is 1, it is omitted.\n-  std::vector<int64_t> rhs_transpose;\n-  rhs_transpose.reserve(rhs_rank);\n-  rhs_transpose.insert(rhs_transpose.end(),\n-                       original_dnums.rhs_batch_dimensions().begin(),\n-                       original_dnums.rhs_batch_dimensions().end());\n-  rhs_transpose.insert(rhs_transpose.end(),\n-                       original_dnums.rhs_contracting_dimensions().begin(),\n-                       original_dnums.rhs_contracting_dimensions().end());\n-  rhs_transpose.insert(rhs_transpose.end(), rhs_non_contracting_dims.begin(),\n-                       rhs_non_contracting_dims.end());\n-  HloInstruction* rhs_operand = original_dot->mutable_operand(1);\n-  HloInstruction* transposed_rhs = computation->AddInstruction(\n-      HloInstruction::CreateTranspose(\n-          ShapeUtil::PermuteDimensionsIgnoringLayout(rhs_transpose, rhs_shape),\n-          rhs_operand, rhs_transpose),\n-      &rhs_operand->metadata());\n-\n-  std::vector<int64_t> rhs_reshape_dims = batch_dim_sizes;\n-  rhs_reshape_dims.push_back(rhs_contracting_size);\n-  std::vector<bool> rhs_reshape_dynamic_dims = batch_dynamic_dims;\n-  rhs_reshape_dynamic_dims.push_back(rhs_contracting_dynamic);\n-  if (rhs_non_contracting_size != 1) {\n-    rhs_reshape_dims.push_back(rhs_non_contracting_size);\n-    rhs_reshape_dynamic_dims.push_back(rhs_non_contracting_dynamic);\n-  }\n-  // Reshape the contracting and non-contracting dimensions together.\n-  HloInstruction* reshaped_rhs = computation->AddInstruction(\n-      HloInstruction::CreateReshape(\n-          ShapeUtil::MakeShape(rhs_shape.element_type(), rhs_reshape_dims,\n-                               rhs_reshape_dynamic_dims),\n-          transposed_rhs),\n-      &transposed_rhs->metadata());\n+  HloInstruction* reshaped_rhs =\n+      CanonicalizeOperand(rhs_operand, original_dnums.rhs_batch_dimensions(),\n+                          original_dnums.rhs_contracting_dimensions(),\n+                          canonical_batch_dims, canonical_batch_dynamic_dims,\n+                          canonical_dnums.mutable_rhs_contracting_dimensions(),\n+                          /*contracting_dim_as_most_minor=*/false);\n \n-  std::vector<int64_t> dot_dims = batch_dim_sizes;\n-  std::vector<bool> dot_dynamic_dims = batch_dynamic_dims;\n-  if (lhs_non_contracting_size != 1) {\n-    dot_dims.push_back(lhs_non_contracting_size);\n-    dot_dynamic_dims.push_back(lhs_non_contracting_dynamic);\n-  }\n-  if (rhs_non_contracting_size != 1) {\n-    dot_dims.push_back(rhs_non_contracting_size);\n-    dot_dynamic_dims.push_back(rhs_non_contracting_dynamic);\n+  const auto& canonical_rhs_shape = reshaped_rhs->shape();\n+  const auto& canonical_rhs_non_contracting_dims =\n+      GetNonContractingDims(canonical_rhs_shape.dimensions().size(),\n+                            canonical_dnums.rhs_batch_dimensions(),\n+                            canonical_dnums.rhs_contracting_dimensions());\n+  // At this point of canonicalization, there are 0 or 1 non-contracting dims.\n+  if (canonical_rhs_non_contracting_dims.size() == 1) {\n+    int64_t rhs_non_contracting_dim = canonical_rhs_non_contracting_dims.at(0);\n+    canonical_dot_dims.push_back(\n+        canonical_rhs_shape.dimensions(rhs_non_contracting_dim));\n+    canonical_dot_dynamic_dims.push_back(\n+        canonical_rhs_shape.is_dynamic_dimension(rhs_non_contracting_dim));\n   }\n \n-  DotDimensionNumbers dot_dnums;\n-  for (int64_t i = 0; i < num_batch_dims; ++i) {\n-    dot_dnums.add_lhs_batch_dimensions(i);\n-    dot_dnums.add_rhs_batch_dimensions(i);\n-  }\n-  dot_dnums.add_lhs_contracting_dimensions(\n-      num_batch_dims + (lhs_non_contracting_size != 1 ? 1 : 0));\n-  dot_dnums.add_rhs_contracting_dimensions(num_batch_dims);\n-\n   HloInstruction* dot = computation->AddInstruction(HloInstruction::CreateDot(\n-      ShapeUtil::MakeShape(original_dot->shape().element_type(), dot_dims,\n-                           dot_dynamic_dims),\n-      reshaped_lhs, reshaped_rhs, dot_dnums, original_dot->precision_config()));\n+      ShapeUtil::MakeShape(original_dot->shape().element_type(),\n+                           canonical_dot_dims, canonical_dot_dynamic_dims),\n+      reshaped_lhs, reshaped_rhs, canonical_dnums,\n+      original_dot->precision_config()));\n   original_dot->SetupDerivedInstruction(dot);\n \n   std::unique_ptr<HloInstruction> replacement =\n@@ -234,31 +261,12 @@ absl::StatusOr<bool> DotDecomposer::RunImpl(\n         continue;\n       }\n       const DotDimensionNumbers& dnums = instruction->dot_dimension_numbers();\n-      // A dot it not canonical if there is more than one contracting dimension.\n-      if (dnums.lhs_contracting_dimensions_size() != 1) {\n-        non_canonical_dots.push_back(instruction);\n-        continue;\n-      }\n-      // A dot is not canonical if it has more than one non-contracting\n-      // dimension.\n-      if (dnums.lhs_batch_dimensions_size() + 2 <\n-              instruction->operand(0)->shape().dimensions().size() ||\n-          dnums.rhs_batch_dimensions_size() + 2 <\n-              instruction->operand(1)->shape().dimensions().size()) {\n-        non_canonical_dots.push_back(instruction);\n-        continue;\n-      }\n-      if (dnums.lhs_batch_dimensions().empty() &&\n-          dnums.lhs_contracting_dimensions().empty()) {\n-        non_canonical_dots.push_back(instruction);\n-        continue;\n-      }\n-      // Check that batch dims, if present, are canonical.\n-      std::vector<int64_t> canonical_batch_dims(\n-          dnums.lhs_batch_dimensions_size());\n-      absl::c_iota(canonical_batch_dims, 0);\n-      if (!absl::c_equal(dnums.lhs_batch_dimensions(), canonical_batch_dims) ||\n-          !absl::c_equal(dnums.rhs_batch_dimensions(), canonical_batch_dims)) {\n+      if (!IsCanonical(instruction->operand(0)->shape(),\n+                       dnums.lhs_contracting_dimensions(),\n+                       dnums.lhs_batch_dimensions()) ||\n+          !IsCanonical(instruction->operand(1)->shape(),\n+                       dnums.rhs_contracting_dimensions(),\n+                       dnums.rhs_batch_dimensions())) {\n         non_canonical_dots.push_back(instruction);\n       }\n     }"
        }
    ],
    "stats": {
        "total": 340,
        "additions": 173,
        "deletions": 167
    }
}