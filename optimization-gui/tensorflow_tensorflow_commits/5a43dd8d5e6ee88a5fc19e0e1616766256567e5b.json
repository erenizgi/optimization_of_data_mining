{
    "author": "unknown",
    "message": "[XLA:GPU] Add SdcThunk\n\nA Thunk that calculates checksums for all configured buffers and stores them in\nan SdcLog.\n\nPiperOrigin-RevId: 819258906",
    "sha": "5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
    "files": [
        {
            "sha": "28b6edbac7dd04febc4e52ee8cb855acec3d6733",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 56,
            "deletions": 0,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -2900,6 +2900,62 @@ xla_test(\n     ],\n )\n \n+cc_library(\n+    name = \"sdc_thunk\",\n+    srcs = [\"sdc_thunk.cc\"],\n+    hdrs = [\"sdc_thunk.h\"],\n+    deps = [\n+        \":sdc_buffer_id\",\n+        \":thunk\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n+        \"//xla/stream_executor/cuda:cuda_platform_id\",\n+        \"//xla/stream_executor/cuda:sdc_log\",\n+        \"//xla/stream_executor/gpu:gpu_kernel_registry\",\n+        \"//xla/stream_executor/gpu:sdc_xor_checksum_kernel\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"sdc_thunk_test\",\n+    srcs = [\"sdc_thunk_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \":sdc_buffer_id\",\n+        \":sdc_log_structs\",\n+        \":sdc_thunk\",\n+        \":thunk\",\n+        \":thunk_id\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:executable\",\n+        \"//xla/service/gpu:buffer_allocations\",\n+        \"//xla/service/gpu:resource_requests\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n+        \"//xla/stream_executor/cuda:sdc_log\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n tf_proto_library(\n     name = \"sdc_proto\",\n     srcs = [\"sdc.proto\"],"
        },
        {
            "sha": "7dd14d6f99c242ebc70fdd502e8d8b66d2093a13",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_log_structs.h",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -18,6 +18,7 @@ limitations under the License.\n \n #include <cstddef>\n #include <cstdint>\n+#include <tuple>\n \n #include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n \n@@ -34,6 +35,13 @@ struct SdcLogEntry {\n     absl::Format(&sink, \"{entry_id: %v, checksum: %u}\", entry.entry_id,\n                  entry.checksum);\n   }\n+\n+  bool operator==(const SdcLogEntry& other) const {\n+    return std::tie(entry_id, checksum) ==\n+           std::tie(other.entry_id, other.checksum);\n+  }\n+\n+  bool operator!=(const SdcLogEntry& other) const { return !(*this == other); }\n };\n \n // The struct layout must match on both host and device."
        },
        {
            "sha": "d2fa47e07c48d793976b8fdc4aa0be344f96162a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk.cc",
            "status": "added",
            "additions": 106,
            "deletions": 0,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.cc?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -0,0 +1,106 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n+\n+#include <cstdint>\n+#include <string>\n+\n+#include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n+#include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n+#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n+#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n+#include \"xla/stream_executor/launch_dim.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+\n+namespace se = stream_executor;\n+\n+absl::Status SdcThunk::Initialize(const InitializeParams& params) {\n+  if (params.executor->GetPlatform()->id() != se::cuda::kCudaPlatformId) {\n+    VLOG(1) << \"[SDC LOG] Not supported on non-CUDA platforms, skipping\";\n+    return absl::OkStatus();\n+  }\n+  if (!params.executor->GetDeviceDescription()\n+           .cuda_compute_capability()\n+           .IsAtLeastPascal()) {\n+    VLOG(1) << \"[SDC LOG] Not supported on CUDA architectures older than \"\n+               \"Pascal due to missing atomic fetch_add with system scope, \"\n+               \"skipping\";\n+    return absl::OkStatus();\n+  }\n+\n+  se::gpu::GpuKernelRegistry registry =\n+      se::gpu::GpuKernelRegistry::GetGlobalRegistry();\n+  TF_ASSIGN_OR_RETURN(\n+      kernel_,\n+      registry.LoadKernel<se::gpu::SdcXorChecksumKernel>(params.executor));\n+\n+  VLOG(1) << \"[SDC LOG] SDC kernel loaded\";\n+  return absl::OkStatus();\n+}\n+\n+absl::Status SdcThunk::ExecuteOnStream(const ExecuteParams& params) {\n+  se::StreamExecutor* executor = params.stream->parent();\n+  if (!kernel_.has_value()) {\n+    // Initialize didn't load the kernel. This can happen when we're running on\n+    // an unsupported platform.\n+    VLOG(1) << \"[SDC LOG] SDC kernel not loaded, skipping\";\n+    return absl::OkStatus();\n+  }\n+\n+  VLOG(1) << \"[SDC LOG] SdcThunk::ExecuteOnStream\";\n+\n+  const se::ThreadDim thread_dim(\n+      executor->GetDeviceDescription().threads_per_block_limit(), 1, 1);\n+\n+  se::DeviceMemory<uint8_t> log_ptr(\n+      params.buffer_allocations->GetDeviceAddress(log_slice_));\n+  se::cuda::SdcLog sdc_log =\n+      se::cuda::SdcLog::FromDeviceMemoryUnchecked(log_ptr);\n+\n+  for (const auto& [entry_id, buffer] : buffers_) {\n+    se::DeviceMemory<uint8_t> device_buffer(\n+        params.buffer_allocations->GetDeviceAddress(buffer));\n+\n+    TF_RETURN_IF_ERROR(\n+        kernel_->Launch(thread_dim, se::BlockDim(1, 1, 1), params.stream,\n+                        entry_id, device_buffer, device_buffer.size(),\n+                        sdc_log.GetDeviceHeader(), sdc_log.GetDeviceEntries()));\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n+std::string SdcThunk::ToString(int indent) const {\n+  std::string result;\n+  absl::StrAppend(&result, \", buffers = \", buffers_.size());\n+  for (const auto& [buffer_id, buffer] : buffers_) {\n+    absl::StrAppend(&result, \"\\n\", std::string(indent + 2, ' '),\n+                    \"buffer_id: \", buffer_id, \", buffer: \", buffer.ToString());\n+  }\n+  return result;\n+}\n+\n+}  // namespace xla::gpu"
        },
        {
            "sha": "727793784c6bd6ac1fd1702b9a3011dd64f1e599",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk.h",
            "status": "added",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk.h?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -0,0 +1,61 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_\n+\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/gpu/sdc_xor_checksum_kernel.h\"\n+\n+namespace xla::gpu {\n+\n+class SdcThunk : public Thunk {\n+ public:\n+  explicit SdcThunk(\n+      ThunkInfo info, BufferAllocation::Slice log_slice,\n+      absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice> buffers)\n+      : Thunk(Thunk::Kind::kSdc, std::move(info)),\n+        log_slice_(log_slice),\n+        buffers_(std::move(buffers)) {}\n+\n+  absl::Status Initialize(const InitializeParams& params) override;\n+  absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n+\n+  std::string ToString(int indent) const override;\n+\n+  BufferUses buffer_uses() const override {\n+    // Intentionally left empty to not checksum the checksumming thunk.\n+    return {};\n+  }\n+\n+ private:\n+  // Loaded in Initialize.\n+  std::optional<stream_executor::gpu::SdcXorChecksumKernel::KernelType> kernel_;\n+  BufferAllocation::Slice log_slice_;\n+  absl::flat_hash_map<SdcBufferId, BufferAllocation::Slice> buffers_;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_THUNK_H_"
        },
        {
            "sha": "eab1df922092e3c996978723b67dda39fb9c42ba",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_thunk_test.cc",
            "status": "added",
            "additions": 141,
            "deletions": 0,
            "changes": 141,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_thunk_test.cc?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -0,0 +1,141 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/sdc_thunk.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <memory>\n+#include <optional>\n+#include <vector>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/service/gpu/buffer_allocations.h\"\n+#include \"xla/service/gpu/resource_requests.h\"\n+#include \"xla/service/service_executable_run_options.h\"\n+#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/platform.h\"\n+#include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla::gpu {\n+namespace {\n+\n+namespace se = stream_executor;\n+\n+using ::stream_executor::cuda::SdcLog;\n+using ::testing::UnorderedElementsAre;\n+\n+class SdcThunkTest : public ::testing::Test {\n+ protected:\n+  void SetUp() override {\n+    TF_ASSERT_OK_AND_ASSIGN(platform_,\n+                            se::PlatformManager::PlatformWithName(\"CUDA\"));\n+    TF_ASSERT_OK_AND_ASSIGN(executor_, platform_->ExecutorForDevice(0));\n+    TF_ASSERT_OK_AND_ASSIGN(stream_, executor_->CreateStream(std::nullopt));\n+    allocator_ =\n+        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_->parent());\n+\n+    if (!executor_->GetDeviceDescription()\n+             .cuda_compute_capability()\n+             .IsAtLeastPascal()) {\n+      GTEST_SKIP() << \"SDC checksumming is not supported on CUDA architectures \"\n+                      \"older than Pascal due to missing atomic fetch_add\";\n+    }\n+  }\n+\n+  se::Platform* platform_;\n+  se::StreamExecutor* executor_;\n+  std::unique_ptr<se::Stream> stream_;\n+  std::unique_ptr<se::StreamExecutorMemoryAllocator> allocator_;\n+};\n+\n+TEST_F(SdcThunkTest, CalculatesChecksums) {\n+  static constexpr size_t kLogSize = SdcLog::RequiredSizeForEntries(10);\n+  static constexpr size_t kInputSize = 1024;\n+  static constexpr size_t kInputCount = 2;\n+  static constexpr size_t kTotalDeviceMemoryBytes =\n+      kLogSize + kInputSize * kInputCount;\n+  // Setup memory allocations for the log and inputs\n+  BufferAllocation alloc(/*index=*/0,\n+                         /*size=*/kTotalDeviceMemoryBytes,\n+                         /*color=*/0);\n+  BufferAllocation::Slice log_slice(&alloc, /*offset=*/0, kLogSize);\n+  BufferAllocation::Slice inputs[kInputCount];\n+  for (int i = 0; i < kInputCount; ++i) {\n+    inputs[i] = BufferAllocation::Slice(\n+        &alloc, /*offset=*/kLogSize + i * kInputSize, kInputSize);\n+  }\n+  BufferAllocations allocations(\n+      {executor_->AllocateArray<uint8_t>(kTotalDeviceMemoryBytes)},\n+      executor_->device_ordinal(), allocator_.get());\n+  se::DeviceMemoryBase log_mem = allocations.GetDeviceAddress(log_slice);\n+  se::DeviceMemoryBase inputs0_mem = allocations.GetDeviceAddress(inputs[0]);\n+  se::DeviceMemoryBase inputs1_mem = allocations.GetDeviceAddress(inputs[1]);\n+  // Initialize the log in device memory\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      SdcLog device_log,\n+      SdcLog::CreateOnDevice(*stream_, se::DeviceMemory<uint8_t>(log_mem)));\n+  // Fill inputs with some data\n+  std::vector<uint32_t> zeros(1024, 0);\n+  zeros[123] = 12341234;  // expected checksum for inputs_mem[0]\n+  TF_ASSERT_OK(stream_->Memcpy(&inputs0_mem, zeros.data(), zeros.size()));\n+  zeros[123] = 56785678;  // expected checksum for inputs_mem[1]\n+  TF_ASSERT_OK(stream_->Memcpy(&inputs1_mem, zeros.data(), zeros.size()));\n+  // Setup parameters for Initialize/Prepare/ExecuteOnStream\n+  Thunk::InitializeParams init_params;\n+  init_params.executor = executor_;\n+  init_params.stream = stream_.get();\n+  ResourceRequests resource_requests;\n+  auto execute_params = Thunk::ExecuteParams::Create(\n+      ServiceExecutableRunOptions(), allocations, stream_.get(),\n+      /*command_buffer_trace_stream=*/stream_.get(),\n+      /*collective_params=*/nullptr, /*collective_cliques=*/nullptr);\n+\n+  SdcThunk thunk(Thunk::ThunkInfo(), log_slice,\n+                 {{SdcBufferId::Create(ThunkId(123), 4).value(), inputs[0]},\n+                  {SdcBufferId::Create(ThunkId(456), 8).value(), inputs[1]}});\n+  TF_ASSERT_OK(thunk.Initialize(init_params));\n+  TF_ASSERT_OK(thunk.Prepare(Thunk::PrepareParams{}, resource_requests));\n+  TF_ASSERT_OK(thunk.ExecuteOnStream(execute_params));\n+  TF_ASSERT_OK_AND_ASSIGN(std::vector<SdcLogEntry> entries,\n+                          device_log.ReadFromDevice(*stream_));\n+\n+  // SdcThunk launches a kernel for each input buffer, they may complete in any\n+  // order.\n+  EXPECT_THAT(entries,\n+              UnorderedElementsAre(\n+                  SdcLogEntry{\n+                      /*entry_id=*/SdcBufferId::Create(ThunkId(123), 4).value(),\n+                      /*checksum=*/12341234,\n+                  },\n+                  SdcLogEntry{\n+                      /*entry_id=*/SdcBufferId::Create(ThunkId(456), 8).value(),\n+                      /*checksum=*/56785678,\n+                  }));\n+}\n+\n+}  // namespace\n+}  // namespace xla::gpu"
        },
        {
            "sha": "7c448d1cfd7063d4068dbd6d09418a685c68466f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -314,6 +314,7 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kReduceScatterDone);\n     CASE(kReduceScatterStart);\n     CASE(kReplicaId);\n+    CASE(kSdc);\n     CASE(kSelectK);\n     CASE(kSend);\n     CASE(kSendDone);"
        },
        {
            "sha": "d22bb8d4d435b7edd1468f15bc50609656d5b1b2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -192,6 +192,7 @@ class Thunk {\n     kReduceScatterDone,\n     kReduceScatterStart,\n     kReplicaId,\n+    kSdc,\n     kSelectK,\n     kSend,\n     kSendDone,"
        },
        {
            "sha": "b50f1f8fdb52f114675a9801f9f5894bc75d88f1",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5a43dd8d5e6ee88a5fc19e0e1616766256567e5b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=5a43dd8d5e6ee88a5fc19e0e1616766256567e5b",
            "patch": "@@ -426,7 +426,6 @@ cc_library(\n     name = \"sdc_log\",\n     srcs = [\"sdc_log.cc\"],\n     hdrs = [\"sdc_log.h\"],\n-    tags = [\"gpu\"],\n     deps = [\n         \"//xla/backends/gpu/runtime:sdc_log_structs\",\n         \"//xla/backends/gpu/runtime:sdc_proto_cc\","
        }
    ],
    "stats": {
        "total": 375,
        "additions": 374,
        "deletions": 1
    }
}