{
    "author": "bchetioui",
    "message": "[XLA:GPU] Add a flag to detect unstable reduction post-optimizations.\n\nThis is helpful to use instead of the other flag, as it can avoid catching\ncases where a pre-optimization is present in the input HLO but is harmless\nbecause it gets optimized out.\n\nPiperOrigin-RevId: 835299856",
    "sha": "ddfba4b3cb54126758fe2297b2ea7489a9219402",
    "files": [
        {
            "sha": "5c7d28f617a3340616ed63468abc666d308dd249",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=ddfba4b3cb54126758fe2297b2ea7489a9219402",
            "patch": "@@ -470,6 +470,8 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_gpu_experimental_enable_triton_warp_specialization(false);\n   opts.set_xla_gpu_experimental_enable_command_buffer_on_thunks(true);\n   opts.set_xla_detect_unstable_reductions(DebugOptions::DETECTION_MODE_NONE);\n+  opts.set_xla_detect_unstable_reductions_post_optimizations(\n+      DebugOptions::DETECTION_MODE_NONE);\n   opts.set_xla_gpu_experimental_scaled_dot_with_triton(false);\n   opts.set_xla_gpu_experimental_use_raft_select_k(false);\n \n@@ -904,6 +906,16 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n         return false;\n       };\n \n+  auto setter_for_xla_detect_unstable_reductions_post_optimizations =\n+      [debug_options, detection_mode](const std::string& value) {\n+        if (auto mode = detection_mode(debug_options, value)) {\n+          debug_options->set_xla_detect_unstable_reductions_post_optimizations(\n+              mode.value());\n+          return true;\n+        }\n+        return false;\n+      };\n+\n   // Custom \"sub-parser\" for\n   // xla_gpu_experimental_thunk_buffer_debug_filter_by_thunk_id_ranges.\n   auto setter_for_thunk_buffer_debug_filter_by_thunk_id =\n@@ -2659,6 +2671,15 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n                 \"that checks for unstable reductions in HLO computations. \"\n                 \"Acceptable values are: 'none', 'log', and 'crash'. 'none' is \"\n                 \"the default.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_detect_unstable_reductions_post_optimizations\",\n+      setter_for_xla_detect_unstable_reductions_post_optimizations,\n+      DebugOptions::DetectionMode_Name(\n+          debug_options->xla_detect_unstable_reductions_post_optimizations()),\n+      \"Controls the behavior of the unstable reduction detector pass \"\n+      \"that checks for unstable reductions in HLO computations after \"\n+      \"optimizations. Acceptable values are: 'none', 'log', and \"\n+      \"'crash'. 'none' is the default.\"));\n   flag_list->push_back(tsl::Flag(\n       \"xla_gpu_experimental_use_raft_select_k\",\n       bool_setter_for("
        },
        {
            "sha": "400bf258b77dd4e62964f445dca4e1d82987fa6b",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=ddfba4b3cb54126758fe2297b2ea7489a9219402",
            "patch": "@@ -1452,6 +1452,17 @@ absl::Status GpuCompiler::OptimizeHloModule(\n   TF_RETURN_IF_ERROR(\n       RunCollectiveScheduleLinearizerPasses(hlo_module, stream_exec));\n \n+  {\n+    HloPassPipeline pipeline(\"invariant-checkers\");\n+    if (hlo_module->config()\n+            .debug_options()\n+            .xla_detect_unstable_reductions_post_optimizations() !=\n+        DebugOptions::DETECTION_MODE_NONE) {\n+      pipeline.AddPass<UnstableReductionDetector>();\n+    }\n+    TF_RETURN_IF_ERROR(pipeline.Run(hlo_module).status());\n+  }\n+\n   TF_RETURN_IF_ERROR(RunAsyncDotPasses(hlo_module));\n   {\n     HloPassPipeline pipeline(\"autotune-fusion-emitters\");"
        },
        {
            "sha": "5c3cd2673b7b11cf31acc9ad7033463ce3b8188b",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ddfba4b3cb54126758fe2297b2ea7489a9219402/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=ddfba4b3cb54126758fe2297b2ea7489a9219402",
            "patch": "@@ -1328,9 +1328,15 @@ message DebugOptions {\n     DETECTION_MODE_WARNING = 1;\n     DETECTION_MODE_FAIL = 2;\n   }\n-  // Whether to enable checks for unstable reductions in computations.\n+  // Whether to enable checks for unstable reductions in computations\n+  // pre-optimizations.\n   optional DetectionMode xla_detect_unstable_reductions = 403;\n \n+  // Whether to enable checks for unstable reductions in computations\n+  // post-optimizations.\n+  optional DetectionMode xla_detect_unstable_reductions_post_optimizations =\n+      432;\n+\n   // Whether to enable checks for NaN values in computations.\n   optional DetectionMode xla_gpu_detect_nan = 426;\n \n@@ -1430,7 +1436,7 @@ message DebugOptions {\n   // Note: when adding a new flag, please add it to one of the hardware-specific\n   // or hardware-agnostic sections at the top of this proto message.\n \n-  // Next id: 432\n+  // Next id: 433\n \n   // Extra options to pass to the compilation backend (e.g. LLVM); specific\n   // interpretation of these values is left to the backend."
        }
    ],
    "stats": {
        "total": 42,
        "additions": 40,
        "deletions": 2
    }
}