{
    "author": "pifon2a",
    "message": "[XLA:GPU] Move AsyncStreamKind and CollectiveOpGroupMode to xla_data.proto.\n\nThis is a preparation CL before adding serialization for collective thunks.\n\nPiperOrigin-RevId: 820091670",
    "sha": "6c440133b8ec40d0b37a730951530a24623905ed",
    "files": [
        {
            "sha": "b0f39ba0a170976ce3ee56a20dc5f8b9251e9ee5",
            "filename": "third_party/xla/xla/backends/gpu/codegen/custom.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Fcustom.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -1333,7 +1333,7 @@ absl::StatusOr<FusionEmissionResult> EmitCollective(\n           Thunk::ThunkInfo::WithProfileAnnotation(\n               instr, ir_emitter_context.GetNextThunkId()),\n           /*async_events=*/async_events,\n-          /*async_stream_kind=*/AsyncStreamKind::kCollective);\n+          /*async_stream_kind=*/AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n       seq.emplace_back(std::move(collective_done_thunk));\n     }\n   } else {"
        },
        {
            "sha": "c38c4beb4b2b96cbfb80a842f329a1913bafc878",
            "filename": "third_party/xla/xla/backends/gpu/collectives/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2FBUILD?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -109,6 +109,7 @@ cc_library(\n     srcs = [\"gpu_clique_key.cc\"],\n     hdrs = [\"gpu_clique_key.h\"],\n     deps = [\n+        \"//xla:xla_data_proto_cc\",\n         \"//xla/core/collectives:clique_key\",\n         \"//xla/service:global_device_id\",\n         \"//xla/tsl/lib/gtl:int_type\","
        },
        {
            "sha": "b91733d78f3ec845bdd1c52405858c6bb9b34c68",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_clique_key.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -36,7 +36,7 @@ limitations under the License.\n namespace xla::gpu {\n \n bool IsP2PStreamKind(AsyncStreamKind stream_kind) {\n-  return stream_kind != AsyncStreamKind::kCollective;\n+  return stream_kind != AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n }\n \n CollectiveStreamId GetCollectiveStreamId(bool is_async,"
        },
        {
            "sha": "0ee7587aae7b40191d00ee0bdcbe8e5738f6e6c4",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_clique_key.h",
            "status": "modified",
            "additions": 4,
            "deletions": 15,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key.h?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -25,26 +25,14 @@ limitations under the License.\n #include \"xla/core/collectives/clique_key.h\"\n #include \"xla/service/global_device_id.h\"\n #include \"xla/tsl/lib/gtl/int_type.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla::gpu {\n \n-// In XLA:GPU we use different streams for different kinds of collective\n-// operations, and include the async stream kind into the GPU clique key.\n-//\n-// We carefully isolate different kinds of collectives using separate\n-// communicators and guarantee that all collective operations have a total order\n-// that will not create a deadlock.\n-enum class AsyncStreamKind : int64_t {\n-  kCollective = 0,  // Stream for asynchronous collective ops.\n-  kP2P0 = 1,        // One Stream for P2P Send and Recv ops.\n-  kP2P1 = 2,        // Another Stream for P2P Send and Recv ops.\n-  kMemCpyP2P = 3,   // Stream for MemCpyP2P\n-};\n-\n bool IsP2PStreamKind(AsyncStreamKind stream_kind);\n \n inline constexpr int64_t kAsyncStreamTotal =\n-    static_cast<int64_t>(AsyncStreamKind::kMemCpyP2P) + 1;\n+    static_cast<int64_t>(AsyncStreamKind::ASYNC_STREAM_KIND_MEMCPYP2P) + 1;\n \n // Strongly-typed wrapper to represent collective stream ID.\n TSL_LIB_GTL_DEFINE_INT_TYPE(CollectiveStreamId, uint64_t);\n@@ -53,7 +41,8 @@ TSL_LIB_GTL_DEFINE_INT_TYPE(CollectiveStreamId, uint64_t);\n // These IDs can be used, for example, to look up the NCCL communicator.\n CollectiveStreamId GetCollectiveStreamId(\n     bool is_async, CollectiveStreamId stream_id = CollectiveStreamId(1),\n-    AsyncStreamKind stream_kind = AsyncStreamKind::kCollective);\n+    AsyncStreamKind stream_kind =\n+        AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n \n // Clique key for identifying a particular collectives clique on a GPU backend.\n class GpuCliqueKey : public CliqueKey {"
        },
        {
            "sha": "8263cd88ad737c6aa623bf5abc6542481773d622",
            "filename": "third_party/xla/xla/backends/gpu/collectives/gpu_clique_key_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 9,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcollectives%2Fgpu_clique_key_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -202,19 +202,21 @@ TEST(GpuCliqueIdStringTest, ToString) {\n \n TEST(GpuCliqueKeyTest, GetCollectiveStreamId) {\n   EXPECT_EQ(GetCollectiveStreamId(false, CollectiveStreamId(0),\n-                                  AsyncStreamKind::kP2P0),\n+                                  AsyncStreamKind::ASYNC_STREAM_KIND_P2P0),\n             CollectiveStreamId(0));\n+  EXPECT_EQ(\n+      GetCollectiveStreamId(true, CollectiveStreamId(0),\n+                            AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n+      CollectiveStreamId(1));\n   EXPECT_EQ(GetCollectiveStreamId(true, CollectiveStreamId(0),\n-                                  AsyncStreamKind::kCollective),\n-            CollectiveStreamId(1));\n-  EXPECT_EQ(GetCollectiveStreamId(true, CollectiveStreamId(0),\n-                                  AsyncStreamKind::kP2P0),\n-            CollectiveStreamId(2));\n-  EXPECT_EQ(GetCollectiveStreamId(true, CollectiveStreamId(2),\n-                                  AsyncStreamKind::kCollective),\n+                                  AsyncStreamKind::ASYNC_STREAM_KIND_P2P0),\n             CollectiveStreamId(2));\n+  EXPECT_EQ(\n+      GetCollectiveStreamId(true, CollectiveStreamId(2),\n+                            AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n+      CollectiveStreamId(2));\n   EXPECT_EQ(GetCollectiveStreamId(true, CollectiveStreamId(1),\n-                                  AsyncStreamKind::kP2P0),\n+                                  AsyncStreamKind::ASYNC_STREAM_KIND_P2P0),\n             CollectiveStreamId(1));\n }\n "
        },
        {
            "sha": "79fce6bdbe447ec458457f541213cda348d654fe",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -1539,6 +1539,7 @@ cc_library(\n     hdrs = [\"collective_thunk.h\"],\n     deps = [\n         \":thunk\",\n+        \":thunk_proto_cc\",\n         \"//xla:debug_options_flags\",\n         \"//xla:shape_util\",\n         \"//xla:util\","
        },
        {
            "sha": "0db4b965bdfc5d79b8ca7cf5ce21a890174f56d0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -74,7 +74,8 @@ AllGatherStartThunk::AllGatherStartThunk(ThunkInfo thunk_info,\n                                          std::vector<Buffer> buffers,\n                                          bool p2p_memcpy_enabled)\n     : CollectiveThunk(Thunk::kAllGatherStart, thunk_info,\n-                      IsGPUSyncCollective(*inst), AsyncStreamKind::kCollective),\n+                      IsGPUSyncCollective(*inst),\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(impl::GetAllGatherConfig(inst)),\n       buffers_(std::move(buffers)) {\n   CHECK_EQ(config_.config.operand_count, buffers_.size());"
        },
        {
            "sha": "2946e85fbd5212951ac53eb1befbc2bfe6781611",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -112,7 +112,8 @@ absl::Status RunAllReduce(ReductionKind reduction_kind,\n AllReduceReduceScatterThunkBase::AllReduceReduceScatterThunkBase(\n     Thunk::Kind kind, ThunkInfo thunk_info, AllReduceConfig config,\n     std::vector<Buffer> buffers, bool is_sync)\n-    : CollectiveThunk(kind, thunk_info, is_sync, AsyncStreamKind::kCollective),\n+    : CollectiveThunk(kind, thunk_info, is_sync,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(std::move(config)),\n       buffers_(std::move(buffers)) {\n   CHECK_EQ(config_.config.operand_count, buffers_.size());"
        },
        {
            "sha": "b1e004b1b1be53e0c1ad0e4cd52de4eb14d52f9b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -81,7 +81,7 @@ AllToAllStartThunk::AllToAllStartThunk(\n     std::vector<CollectiveThunk::Buffer> buffers, bool p2p_memcpy_enabled)\n     : CollectiveThunk(Thunk::kAllToAllStart, thunk_info,\n                       IsGPUSyncCollective(*instr),\n-                      AsyncStreamKind::kCollective),\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(GetAllToAllConfig(instr)),\n       buffers_(std::move(buffers)),\n       p2p_memcpy_enabled_(p2p_memcpy_enabled) {\n@@ -248,7 +248,7 @@ absl::StatusOr<bool> AllToAllStartThunk::RunCollective(\n \n AsyncStreamKind AllToAllStartThunk::GetAsyncStreamKind() const {\n   if (is_local() && p2p_memcpy_enabled_) {\n-    return AsyncStreamKind::kMemCpyP2P;\n+    return AsyncStreamKind::ASYNC_STREAM_KIND_MEMCPYP2P;\n   }\n   return CollectiveThunk::GetAsyncStreamKind();\n }"
        },
        {
            "sha": "86820ab04f3432c45dbafcf1051815275134fdec",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_broadcast_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -48,7 +48,7 @@ CollectiveBroadcastStartThunk::CollectiveBroadcastStartThunk(\n     std::vector<Buffer> buffers, bool p2p_memcpy_enabled)\n     : CollectiveThunk(Thunk::kCollectiveBroadcastStart, thunk_info,\n                       IsGPUSyncCollective(*instr),\n-                      AsyncStreamKind::kCollective),\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(GetCollectiveConfig(instr, std::nullopt)),\n       buffers_(std::move(buffers)) {}\n "
        },
        {
            "sha": "48b298e0bbb1768c56d5d31254d0ad1a17d0bd4f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_broadcast_thunk_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_broadcast_thunk_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -130,7 +130,7 @@ ENTRY test_computation {\n \n   auto cb_done_thunk = std::make_unique<CollectiveDoneThunk>(\n       Kind::kCollectiveBroadcastDone, Thunk::ThunkInfo{}, async_events,\n-      AsyncStreamKind::kCollective);\n+      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n \n   ThunkSequence thunk_sequence;\n   thunk_sequence.push_back(std::move(cb_start_thunk));"
        },
        {
            "sha": "8f63cbfc3e5dcbbc0c7c3228ba90749d198fde58",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -311,7 +311,7 @@ absl::Status CollectiveKernelThunk::ExecuteOnStream(\n   se::Stream* stream = params.stream;\n   if (is_async_) {\n     stream = params.collective_params->async_streams.at(\n-        static_cast<int64_t>(AsyncStreamKind::kCollective));\n+        static_cast<int64_t>(AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n   }\n   const int device_ordinal = stream->parent()->device_ordinal();\n "
        },
        {
            "sha": "38ef1d2cb7289c01ab34f85ed03cc510a1c8d29e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -168,7 +168,8 @@ TEST(CollectiveKernelThunkTest, ExecutesPtxKernel) {\n       /* replica_groups=*/{replica_group},\n       /* collective_op_kind=*/RendezvousKey::CollectiveOpKind::kCrossReplica,\n       /* op_id=*/0,\n-      /* group_mode=*/CollectiveOpGroupMode::kCrossReplica,\n+      /* group_mode=*/\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n       /* use_symmetric_buffer=*/false};\n   const int64_t aligned_input_size_bytes =\n       xla::RoundUpTo<uint64_t>(kInputSizeBytes, kXlaAllocatedBufferAlignBytes);"
        },
        {
            "sha": "5db7609fe161a341f4d6b140d5188b8b7a9222fe",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_permute_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_permute_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -71,7 +71,8 @@ absl::StatusOr<const int64_t> GetCurrentId(\n       const DeviceAssignment::LogicalID current_logical_id,\n       collective_params->device_assn->LogicalIdForDevice(global_device_id));\n   const int64_t current_id =\n-      config.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   return current_id;\n@@ -129,7 +130,8 @@ CollectivePermuteStartThunk::CollectivePermuteStartThunk(\n   // With a collective permute, all execution instances together form one\n   // replica group.\n   const int64_t num_participants =\n-      config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? replica_count\n           : partition_count;\n   config.replica_groups.emplace_back();"
        },
        {
            "sha": "dbdffe424660d4dc09fc60305c115c4a1c4d804e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -163,14 +163,15 @@ bool CollectiveConfig::IsDegenerate(int64_t replica_count,\n       });\n \n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n       return all_groups_singleton || (groups_empty && replica_count == 1);\n-    case CollectiveOpGroupMode::kCrossPartition:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION:\n       return all_groups_singleton || (groups_empty && partition_count == 1);\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition:\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION:\n       return (all_groups_singleton && partition_count == 1) ||\n              (groups_empty && replica_count == 1 && partition_count == 1);\n-    case CollectiveOpGroupMode::kFlattenedID:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID:\n       CHECK(!groups_empty)\n           << \"replica groups cannot be empty if use_global_device_ids = true\";\n       return all_groups_singleton;\n@@ -305,7 +306,8 @@ absl::StatusOr<GpuCliqueKey> GetCollectiveGpuCliqueKey(\n                       CollectiveThunk::GetGpuCollectives(params));\n   return GetGpuCliqueKey(collectives, params, collective_config.replica_groups,\n                          collective_config.group_mode,\n-                         AsyncStreamKind::kCollective, use_nccl);\n+                         AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE,\n+                         use_nccl);\n }\n \n absl::StatusOr<CommunicatorHandle> GetComm("
        },
        {
            "sha": "4925c1c402352d387dc8bd6f698d61812837f174",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.h?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -1,3 +1,4 @@\n+#include \"xla/backends/gpu/runtime/thunk.pb.h\"\n /* Copyright 2019 The OpenXLA Authors.\n \n Licensed under the Apache License, Version 2.0 (the \"License\");\n@@ -233,7 +234,7 @@ class CollectiveDoneThunk : public Thunk {\n \n  private:\n   std::shared_ptr<CollectiveThunk::AsyncEvents> async_events_;\n-  AsyncStreamKind stream_kind_ = AsyncStreamKind::kCollective;\n+  AsyncStreamKind stream_kind_ = AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n   // NCCL stream id assigned by execution stream assignment.\n   CollectiveStreamId stream_id_ = CollectiveStreamId(1);\n };"
        },
        {
            "sha": "57baba95380daeb37d590a3de0db4925e1e7ebd5",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 26,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -2004,7 +2004,7 @@ absl::Status CollectiveCmd::Prepare(\n       GpuCliqueKey clique_key,\n       GetGpuCliqueKey(collectives, *params.collective_params,\n                       config().replica_groups, config().group_mode,\n-                      AsyncStreamKind::kCollective));\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n   return resource_requests.AddClique(clique_key);\n }\n \n@@ -2078,11 +2078,12 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n                       Thunk::GetGpuCollectives(execute_params));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(collectives, *execute_params.collective_params,\n-                              *execute_params.collective_cliques,\n-                              config().replica_groups, config().group_mode,\n-                              AsyncStreamKind::kCollective));  // Use constant\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n@@ -2143,11 +2144,12 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n                       Thunk::GetGpuCollectives(execute_params));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(collectives, *execute_params.collective_params,\n-                              *execute_params.collective_cliques,\n-                              config().replica_groups, config().group_mode,\n-                              AsyncStreamKind::kCollective));  // Use constant\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n   return RecordTracedCommand(execute_params, record_params, record_action,\n                              command_buffer, [&](se::Stream* stream) {\n@@ -2208,11 +2210,12 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n \n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n                       Thunk::GetGpuCollectives(execute_params));\n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(collectives, *execute_params.collective_params,\n-                              *execute_params.collective_cliques,\n-                              config().replica_groups, config().group_mode,\n-                              AsyncStreamKind::kCollective));  // Use constant\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n@@ -2270,11 +2273,12 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n                       Thunk::GetGpuCollectives(execute_params));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(collectives, *execute_params.collective_params,\n-                              *execute_params.collective_cliques,\n-                              config().replica_groups, config().group_mode,\n-                              AsyncStreamKind::kCollective));  // Use constant\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n@@ -2333,11 +2337,12 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n                       Thunk::GetGpuCollectives(execute_params));\n \n-  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n-                      GetComm(collectives, *execute_params.collective_params,\n-                              *execute_params.collective_cliques,\n-                              config().replica_groups, config().group_mode,\n-                              AsyncStreamKind::kCollective));  // Use constant\n+  TF_ASSIGN_OR_RETURN(\n+      CommunicatorHandle comm_handle,\n+      GetComm(collectives, *execute_params.collective_params,\n+              *execute_params.collective_cliques, config().replica_groups,\n+              config().group_mode,\n+              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n \n   return RecordTracedCommand(execute_params, record_params,\n                              std::move(record_action), command_buffer,"
        },
        {
            "sha": "e6361d2ac1fd953e2365b2a403659f08234b4982",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -158,7 +158,7 @@ std::unique_ptr<CollectiveDoneThunk> CreateAllGatherDoneThunk(\n       static_cast<const AllGatherStartThunk*>(start_thunk)->async_events();\n   return std::make_unique<CollectiveDoneThunk>(\n       Thunk::kAllGatherDone, Thunk::ThunkInfo(), std::move(async_events),\n-      AsyncStreamKind::kCollective);\n+      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n }\n \n std::unique_ptr<WhileThunk> CreateWhileThunk("
        },
        {
            "sha": "acf2ae6e48aa68ea9d2133a4205e6b70d1f8af1d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_collective_permute_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -66,7 +66,8 @@ absl::StatusOr<const int64_t> GetCurrentId(\n       const DeviceAssignment::LogicalID current_logical_id,\n       collective_params->device_assn->LogicalIdForDevice(global_device_id));\n   const int64_t current_id =\n-      config.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   return current_id;\n@@ -101,7 +102,8 @@ NvshmemCollectivePermuteStartThunk::NvshmemCollectivePermuteStartThunk(\n   // With a collective permute, all execution instances together form one\n   // replica group.\n   const int64_t num_participants =\n-      config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? replica_count\n           : partition_count;\n   config.replica_groups.emplace_back();"
        },
        {
            "sha": "f2959c7204e05bd317d9b1c2eaaa9193fc6b73e0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_collective_permute_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_permute_thunk.h?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -41,7 +41,8 @@ class NvshmemCollectivePermuteStartThunk : public NvshmemCollectiveThunk {\n       int64_t replica_count, int64_t partition_count,\n       const std::vector<CollectiveThunk::Buffer>& buffers,\n       bool p2p_memcpy_enabled = false,\n-      AsyncStreamKind stream_kind = AsyncStreamKind::kCollective);\n+      AsyncStreamKind stream_kind =\n+          AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE);\n \n   static const char* GetHloOpName() { return \"collective-permute-start\"; }\n "
        },
        {
            "sha": "ae73d07909cd8a0c2d3d80b88d4c017539ce4eaf",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_collective_thunk.h",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_collective_thunk.h?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -68,7 +68,7 @@ class NvshmemCollectiveThunk : public Thunk {\n                                             se::Stream& stream) = 0;\n   virtual const CollectiveConfig& config() const = 0;\n   virtual AsyncStreamKind GetAsyncStreamKind() const {\n-    return AsyncStreamKind::kCollective;\n+    return AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n   }\n \n  private:\n@@ -95,7 +95,8 @@ class NvshmemCollectiveDoneThunk : public Thunk {\n \n  private:\n   std::shared_ptr<CollectiveThunk::AsyncEvents> async_events_;\n-  AsyncStreamKind async_stream_kind_ = AsyncStreamKind::kCollective;\n+  AsyncStreamKind async_stream_kind_ =\n+      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n };\n \n //===----------------------------------------------------------------------===//"
        },
        {
            "sha": "d8660018c0b28384f812f4cebdc968035a8670c7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_recv_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_recv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_recv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_recv_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -87,7 +87,8 @@ absl::Status NvshmemRecvThunk::RunNvshmemCollective(const ExecuteParams& params,\n                       params.collective_params->device_assn->LogicalIdForDevice(\n                           global_device_id));\n   const int64_t current_id =\n-      config_.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config_.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   std::string device_string ="
        },
        {
            "sha": "71e8eff682cddb81f39183779bfb847bd444b3e3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/nvshmem_send_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_send_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_send_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fnvshmem_send_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -91,7 +91,8 @@ absl::Status NvshmemSendThunk::RunNvshmemCollective(const ExecuteParams& params,\n                       params.collective_params->device_assn->LogicalIdForDevice(\n                           global_device_id));\n   const int64_t current_id =\n-      config_.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config_.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   std::string device_string ="
        },
        {
            "sha": "ce84026bbb3e1c41773f7bba063d8e443057fdef",
            "filename": "third_party/xla/xla/backends/gpu/runtime/p2p_thunk_common.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fp2p_thunk_common.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -98,7 +98,8 @@ P2PConfig GetP2PConfigForSendRecv(const HloSendRecvInstruction* instr,\n \n   // All execution instances of a Send/Recv together form a replica group.\n   const int64_t num_participants =\n-      config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? replica_count\n           : partition_count;\n   config.replica_groups.emplace_back();\n@@ -176,15 +177,15 @@ AsyncStreamKind GetStreamKindForP2P(const HloInstruction* instr) {\n     const auto it = fe_map.find(kCollectiveStreamAttrName);\n     if (it != fe_map.end() && it->second == kCollectiveStreamP2P) {\n       // Use any of the two p2p streams.\n-      return AsyncStreamKind::kP2P0;\n+      return AsyncStreamKind::ASYNC_STREAM_KIND_P2P0;\n     }\n   }\n \n   const auto it = fe_map.find(kSendRecvPipelineAttr);\n   if (it != fe_map.end() && it->second == \"1\") {\n-    return AsyncStreamKind::kP2P1;\n+    return AsyncStreamKind::ASYNC_STREAM_KIND_P2P1;\n   }\n-  return AsyncStreamKind::kP2P0;\n+  return AsyncStreamKind::ASYNC_STREAM_KIND_P2P0;\n }\n \n }  // namespace gpu"
        },
        {
            "sha": "aa16a0be4cc92c484236dd7511433f9e42f21a25",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -409,7 +409,7 @@ RaggedAllToAllStartThunk::RaggedAllToAllStartThunk(\n     std::vector<CollectiveThunk::Buffer> buffers, bool p2p_memcpy_enabled)\n     : CollectiveThunk(Thunk::kRaggedAllToAllStart, thunk_info,\n                       IsGPUSyncCollective(*instr),\n-                      AsyncStreamKind::kCollective),\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       config_(GetRaggedAllToAllConfig(instr)),\n       buffers_(std::move(buffers)),\n       p2p_memcpy_enabled_(p2p_memcpy_enabled),"
        },
        {
            "sha": "8a6490fcc856859079ab6e244dcc76a38f60b880",
            "filename": "third_party/xla/xla/backends/gpu/runtime/recv_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -79,7 +79,8 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n                       params.collective_params->device_assn->LogicalIdForDevice(\n                           global_device_id));\n   const int64_t current_id =\n-      config_.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config_.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   std::string device_string = GetDeviceString(*params.collective_params);"
        },
        {
            "sha": "e9d64080e64b38ef4c753d79f780ef361353da19",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -82,7 +82,8 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n                       params.collective_params->device_assn->LogicalIdForDevice(\n                           global_device_id));\n   const int64_t current_id =\n-      config_.config.group_mode == CollectiveOpGroupMode::kCrossReplica\n+      config_.config.group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n           ? current_logical_id.replica_id\n           : current_logical_id.computation_id;\n   std::string device_string = GetDeviceString(*params.collective_params);"
        },
        {
            "sha": "4e324fd4811b7c53a30f95529adcc70f80c3b97e",
            "filename": "third_party/xla/xla/hlo/ir/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2FBUILD?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -405,6 +405,7 @@ cc_library(\n     hdrs = [\"collective_op_group_mode.h\"],\n     deps = [\n         \"//xla:util\",\n+        \"//xla:xla_data_proto_cc\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\","
        },
        {
            "sha": "7331f16decc6c15615bbfff2bfe1f35870fbc764",
            "filename": "third_party/xla/xla/hlo/ir/collective_op_group_mode.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 8,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -21,6 +21,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/util.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla {\n namespace {\n@@ -31,11 +32,15 @@ struct CollectiveOpGroupModeInfo {\n };\n \n const CollectiveOpGroupModeInfo kGroupModeInfos[] = {\n-    {CollectiveOpGroupMode::kCrossReplica, \"cross_replica\"},\n-    {CollectiveOpGroupMode::kCrossPartition, \"cross_partition\"},\n-    {CollectiveOpGroupMode::kCrossReplicaAndPartition,\n+    {CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n+     \"cross_replica\"},\n+    {CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION,\n+     \"cross_partition\"},\n+    {CollectiveOpGroupMode::\n+         COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION,\n      \"cross_replica_and_partition\"},\n-    {CollectiveOpGroupMode::kFlattenedID, \"flattened_id\"},\n+    {CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID,\n+     \"flattened_id\"},\n };\n \n }  // namespace\n@@ -70,15 +75,16 @@ absl::StatusOr<CollectiveOpGroupMode> GetCollectiveOpGroupMode(\n       return InvalidArgument(\n           \"Cannot have use_global_device_ids=true without channel_id\");\n     }\n-    return CollectiveOpGroupMode::kCrossReplica;\n+    return CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA;\n   }\n   if (!use_global_device_ids.has_value()) {\n-    return CollectiveOpGroupMode::kCrossPartition;\n+    return CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION;\n   }\n   if (!*use_global_device_ids) {\n-    return CollectiveOpGroupMode::kCrossReplicaAndPartition;\n+    return CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION;\n   }\n-  return CollectiveOpGroupMode::kFlattenedID;\n+  return CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID;\n }\n \n }  // namespace xla"
        },
        {
            "sha": "8bc99930697075689ec3fe386f07db3e573a7a16",
            "filename": "third_party/xla/xla/hlo/ir/collective_op_group_mode.h",
            "status": "modified",
            "additions": 1,
            "deletions": 39,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode.h?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -20,48 +20,10 @@ limitations under the License.\n \n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/xla_data.pb.h\"\n \n namespace xla {\n \n-// There are broadly 4 modes that collective communication ops use to describe\n-// which sets of devices are participating with a given device in the operation.\n-// These modes are determined by the values of channel_id (optional) and\n-// use_global_device_ids (optional). The modes are as follows:\n-//\n-// kCrossReplica:\n-//    implied by: no channel id, use_global_device_ids = false, or\n-//                no channel_id, no use_global_device_ids:\n-//    replica_groups contain replica_id, group contains all replicas for the\n-//    current partition\n-//\n-// kCrossPartition:\n-//    implied by: channel_id is set, no use_global_device_ids:\n-//    replica_groups contain partition_id, group contains all partitions for the\n-//    current replica.\n-//\n-// kCrossReplicaAndPartition:\n-//    implied by: channel_id is set, use_global_device_ids = false:\n-//    replica_groups contain replica_id, group contains all replicas for all\n-//    partitions (as opposed to just current partition).\n-//\n-// kFlattenedID:\n-//    implied by: channel_id is set, use_global_device_ids = true:\n-//    replica_groups contain flattened-ids, group contains devices that are\n-//    listed in the flattened-id list.\n-//\n-// Rest of the combinations are invalid.\n-//\n-// Since the actual value of channel_id does not matter, we use a bool argument\n-// `has_channel_id`, and optional<bool> for use_global_device_ids.\n-// Note that use_global_device_ids true requires channel_id to be set as well.\n-// Additionally, if use_global_device_ids = true, replica groups cannot be\n-// empty (verified in the HLO verifier).\n-enum class CollectiveOpGroupMode {\n-  kCrossReplica,\n-  kCrossPartition,\n-  kCrossReplicaAndPartition,\n-  kFlattenedID,\n-};\n \n absl::string_view CollectiveOpGroupModeToString(\n     CollectiveOpGroupMode group_mode);"
        },
        {
            "sha": "41ff4fb647db886d85a9655ffdb119937194b806",
            "filename": "third_party/xla/xla/hlo/ir/collective_op_group_mode_test.cc",
            "status": "modified",
            "additions": 26,
            "deletions": 15,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fcollective_op_group_mode_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -28,28 +28,33 @@ namespace xla {\n namespace {\n \n TEST(CollectiveOpGroupModeTest, ToString) {\n-  EXPECT_EQ(CollectiveOpGroupModeToString(CollectiveOpGroupMode::kCrossReplica),\n+  EXPECT_EQ(CollectiveOpGroupModeToString(\n+                CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA),\n             \"cross_replica\");\n   EXPECT_EQ(\n-      CollectiveOpGroupModeToString(CollectiveOpGroupMode::kCrossPartition),\n+      CollectiveOpGroupModeToString(\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION),\n       \"cross_partition\");\n   EXPECT_EQ(CollectiveOpGroupModeToString(\n-                CollectiveOpGroupMode::kCrossReplicaAndPartition),\n+                CollectiveOpGroupMode::\n+                    COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION),\n             \"cross_replica_and_partition\");\n-  EXPECT_EQ(CollectiveOpGroupModeToString(CollectiveOpGroupMode::kFlattenedID),\n+  EXPECT_EQ(CollectiveOpGroupModeToString(\n+                CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID),\n             \"flattened_id\");\n }\n \n TEST(CollectiveOpGroupModeTest, FromString) {\n   EXPECT_EQ(StringToCollectiveOpGroupMode(\"cross_replica\").value(),\n-            CollectiveOpGroupMode::kCrossReplica);\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA);\n   EXPECT_EQ(StringToCollectiveOpGroupMode(\"cross_partition\").value(),\n-            CollectiveOpGroupMode::kCrossPartition);\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION);\n   EXPECT_EQ(\n       StringToCollectiveOpGroupMode(\"cross_replica_and_partition\").value(),\n-      CollectiveOpGroupMode::kCrossReplicaAndPartition);\n+      CollectiveOpGroupMode::\n+          COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION);\n   EXPECT_EQ(StringToCollectiveOpGroupMode(\"flattened_id\").value(),\n-            CollectiveOpGroupMode::kFlattenedID);\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID);\n }\n \n // Tests for GetCollectOpGroupMode\n@@ -72,14 +77,20 @@ struct TestCase {\n \n std::vector<TestCase> GetTestCases() {\n   const std::vector<TestCase> test_cases = {\n-      // clang-format off\n       // has_channel_id, use_global_device_ids, expected mode\n-      {false, std::nullopt,  CollectiveOpGroupMode::kCrossReplica},\n-      {false, false,         CollectiveOpGroupMode::kCrossReplica},\n-      {false, true,          std::nullopt},\n-      {true,  std::nullopt,  CollectiveOpGroupMode::kCrossPartition},\n-      {true,  false,         CollectiveOpGroupMode::kCrossReplicaAndPartition},\n-      {true,  true,          CollectiveOpGroupMode::kFlattenedID},\n+      // clang-format off\n+      {false, std::nullopt,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n+      {false, false,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n+      {false, true, std::nullopt},\n+      {true, std::nullopt,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n+      {true, false,\n+       CollectiveOpGroupMode::\n+           COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION},\n+      {true, true,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID},\n       // clang-format on\n   };\n   return test_cases;"
        },
        {
            "sha": "976397dd542f16282cc7a30fe8c74c09e0a13d3d",
            "filename": "third_party/xla/xla/hlo/transforms/collectives/collective_quantizer.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 4,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollective_quantizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollective_quantizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fcollectives%2Fcollective_quantizer.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -318,8 +318,10 @@ absl::StatusOr<bool> MatchDequantization(HloInstruction* instr) {\n     // partitions, not replicas.\n     TF_ASSIGN_OR_RETURN(CollectiveOpGroupMode group_mode,\n                         GetCollectiveOpGroupMode(instr));\n-    if (group_mode != CollectiveOpGroupMode::kCrossPartition &&\n-        group_mode != CollectiveOpGroupMode::kFlattenedID) {\n+    if (group_mode !=\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION &&\n+        group_mode !=\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n       return false;\n     }\n     TF_ASSIGN_OR_RETURN(\n@@ -387,8 +389,10 @@ absl::StatusOr<bool> MatchQuantization(HloInstruction* instr) {\n     // partitions, not replicas.\n     TF_ASSIGN_OR_RETURN(CollectiveOpGroupMode group_mode,\n                         GetCollectiveOpGroupMode(instr));\n-    if (group_mode != CollectiveOpGroupMode::kCrossPartition &&\n-        group_mode != CollectiveOpGroupMode::kFlattenedID) {\n+    if (group_mode !=\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION &&\n+        group_mode !=\n+            CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n       return false;\n     }\n     TF_ASSIGN_OR_RETURN("
        },
        {
            "sha": "9196add5cabbbf05874868a2a0e744ab754f352d",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/all_gather_pad_ds_simplifier.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fall_gather_pad_ds_simplifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fall_gather_pad_ds_simplifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fall_gather_pad_ds_simplifier.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -769,7 +769,9 @@ std::optional<PatternMatchResult> MatchDynamicSlicePadAllGather(\n   // Match all-gather for kFlattenedID collective mode.\n   absl::StatusOr<CollectiveOpGroupMode> mode = GetCollectiveOpGroupMode(ag_hlo);\n \n-  if (!mode.ok() || mode.value() != CollectiveOpGroupMode::kFlattenedID) {\n+  if (!mode.ok() ||\n+      mode.value() !=\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n     VLOG(2) << \"AG does not use global device ids or channel id \"\n             << ag_hlo->ToString();\n     return std::nullopt;"
        },
        {
            "sha": "877ab2b40f9575db60158da7dd1dafb0458f1f5e",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -4718,7 +4718,6 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@local_tsl//tsl/platform:statusor\",\n     ],\n )\n \n@@ -5225,7 +5224,6 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/functional:function_ref\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\","
        },
        {
            "sha": "27488fcc5d2bbd4632d6dd9b82d9cb39d91617cd",
            "filename": "third_party/xla/xla/service/collective_decomposer_utils.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 5,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_decomposer_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_decomposer_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_decomposer_utils.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -64,11 +64,12 @@ CreateStartIndicesForCollectiveDecomposition(\n \n   HloInstruction *participant_id;\n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n       participant_id =\n           computation->AddInstruction(HloInstruction::CreateReplicaId());\n       break;\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition:\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION:\n       // For this mode, the replica groups contain replica_id's, but the\n       // participant are replicas with the given replica_id across all\n       // partitions (ordered in partition id order, see\n@@ -82,14 +83,18 @@ CreateStartIndicesForCollectiveDecomposition(\n       participant_id =\n           computation->AddInstruction(HloInstruction::CreateReplicaId());\n       break;\n-    case CollectiveOpGroupMode::kCrossPartition:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION:\n       participant_id =\n           computation->AddInstruction(HloInstruction::CreatePartitionId());\n       break;\n-    case CollectiveOpGroupMode::kFlattenedID:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID:\n       participant_id = create_flattened_id(\n           computation->AddInstruction(HloInstruction::CreateReplicaId()));\n       break;\n+    default: {\n+      return absl::InvalidArgumentError(\n+          absl::StrCat(\"Unsupported group mode: \", group_mode));\n+    }\n   }\n \n   auto is_trivial_group = [](absl::Span<const ReplicaGroup> replica_groups) {\n@@ -152,7 +157,8 @@ CreateStartIndicesForCollectiveDecomposition(\n \n   // For cross-replica and partition mode, we need to scale the index (which is\n   // the replica index) by num_partitions and add partition_id;\n-  if (group_mode == CollectiveOpGroupMode::kCrossReplicaAndPartition) {\n+  if (group_mode == CollectiveOpGroupMode::\n+                        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION) {\n     index = create_flattened_id(index);\n   }\n "
        },
        {
            "sha": "c9cba232b6b2354f6d39d585e363392afcb073f7",
            "filename": "third_party/xla/xla/service/collective_ops_utils.cc",
            "status": "modified",
            "additions": 60,
            "deletions": 28,
            "changes": 88,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -271,14 +271,17 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n \n   // If replica groups are empty, assume a group with all replicas.\n   if (replica_groups.empty()) {\n-    if (group_mode == CollectiveOpGroupMode::kFlattenedID) {\n+    if (group_mode ==\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n       // replica groups contain flattened-ids and cannot be empty.\n       TF_RET_CHECK(!replica_groups.empty())\n-          << \"replica groups cannot be empty for kFlattenedID mode\";\n+          << \"replica groups cannot be empty for \"\n+             \"COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID mode\";\n     }\n \n     int total_participant_count;\n-    if (group_mode == CollectiveOpGroupMode::kCrossPartition) {\n+    if (group_mode ==\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION) {\n       // replica group are partition ids.\n       total_participant_count = partition_count;\n     } else {\n@@ -295,7 +298,7 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n \n   std::vector<std::vector<GlobalDeviceId>> groups;\n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA: {\n       for (const auto& replica_group : participating_replica_groups) {\n         // replica_group contains replica id, participants contains all\n         // replica_group's replica_ids for the current partition.\n@@ -313,7 +316,7 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n       }\n       return groups;\n     }\n-    case CollectiveOpGroupMode::kCrossPartition: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION: {\n       for (const auto& replica_group : participating_replica_groups) {\n         // replica_group contains partition id, participants contains all\n         // replica_group's partition_ids for the current replica_id.\n@@ -330,7 +333,8 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n       }\n       return groups;\n     }\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n       for (const auto& replica_group : participating_replica_groups) {\n         std::vector<GlobalDeviceId> participants;\n         participants.reserve(replica_group.replica_ids().size() *\n@@ -349,7 +353,7 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n       }\n       return groups;\n     }\n-    case CollectiveOpGroupMode::kFlattenedID: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n       for (const auto& replica_group : participating_replica_groups) {\n         std::vector<GlobalDeviceId> participants;\n         participants.reserve(replica_group.replica_ids().size());\n@@ -365,6 +369,10 @@ GetParticipatingDevicesGroups(const DeviceAssignment& device_assignment,\n       }\n       return groups;\n     }\n+    default: {\n+      return InvalidArgument(\"Invalid collective op group mode: %d\",\n+                             static_cast<int>(group_mode));\n+    }\n   }\n }\n \n@@ -391,7 +399,8 @@ absl::StatusOr<CollectiveDeviceList> GetParticipatingFlattenedIdGroups(\n absl::StatusOr<CollectiveDeviceList> GetParticipatingFlattenedIdGroups(\n     const CollectiveDeviceList& collective_device_list,\n     CollectiveOpGroupMode group_mode, int replica_count, int partition_count) {\n-  if (group_mode == CollectiveOpGroupMode::kFlattenedID) {\n+  if (group_mode ==\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n     return collective_device_list;\n   }\n   std::vector<ReplicaGroup> filled_empty_replica_group;\n@@ -401,14 +410,17 @@ absl::StatusOr<CollectiveDeviceList> GetParticipatingFlattenedIdGroups(\n   if (collective_device_list.replica_groups().empty()) {\n     filled_empty_replica_group.emplace_back();\n     const int64_t id_count =\n-        group_mode == CollectiveOpGroupMode::kCrossPartition ? partition_count\n-                                                             : replica_count;\n+        group_mode ==\n+                CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION\n+            ? partition_count\n+            : replica_count;\n     for (int i = 0; i < id_count; ++i) {\n       filled_empty_replica_group.back().add_replica_ids(i);\n     }\n     original_replica_groups = filled_empty_replica_group;\n   }\n-  if (group_mode == CollectiveOpGroupMode::kCrossReplica) {\n+  if (group_mode ==\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA) {\n     flattened_replica_groups.resize(original_replica_groups.size() *\n                                     partition_count);\n     for (int64_t i = 0, current_group_offset = 0;\n@@ -424,7 +436,8 @@ absl::StatusOr<CollectiveDeviceList> GetParticipatingFlattenedIdGroups(\n         }\n       }\n     }\n-  } else if (group_mode == CollectiveOpGroupMode::kCrossPartition) {\n+  } else if (group_mode ==\n+             CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION) {\n     flattened_replica_groups.resize(original_replica_groups.size() *\n                                     replica_count);\n     for (int64_t i = 0, current_group_offset = 0;\n@@ -440,7 +453,9 @@ absl::StatusOr<CollectiveDeviceList> GetParticipatingFlattenedIdGroups(\n       }\n     }\n   } else {\n-    CHECK(group_mode == CollectiveOpGroupMode::kCrossReplicaAndPartition);\n+    CHECK(group_mode ==\n+          CollectiveOpGroupMode::\n+              COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION);\n     flattened_replica_groups.resize(original_replica_groups.size());\n     for (int64_t i = 0; i < original_replica_groups.size(); ++i) {\n       for (int64_t replica_id : original_replica_groups.at(i).replica_ids()) {\n@@ -498,7 +513,7 @@ absl::StatusOr<std::vector<GlobalDeviceId>> GetParticipatingDevices(\n \n   std::vector<GlobalDeviceId> participants;\n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA: {\n       // This is a cross replica operation. replica group contains replica id.\n       // use current replica id to find the set of participating replicas. If\n       // replica groups are empty, assume a group with all replicas.\n@@ -518,7 +533,7 @@ absl::StatusOr<std::vector<GlobalDeviceId>> GetParticipatingDevices(\n       return participants;\n     }\n \n-    case CollectiveOpGroupMode::kCrossPartition: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION: {\n       // replica_groups contain partition_id, group contains all partitions for\n       // the current replica.\n       TF_ASSIGN_OR_RETURN(std::vector<int> participating_partitions,\n@@ -534,7 +549,8 @@ absl::StatusOr<std::vector<GlobalDeviceId>> GetParticipatingDevices(\n       return participants;\n     }\n \n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n       // replica_groups contain replica_ids. Group contains replicas for all\n       // partitions.\n       TF_ASSIGN_OR_RETURN(std::vector<int> participating_replicas,\n@@ -553,7 +569,7 @@ absl::StatusOr<std::vector<GlobalDeviceId>> GetParticipatingDevices(\n       return participants;\n     }\n \n-    case CollectiveOpGroupMode::kFlattenedID: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n       // replica groups contain flattened-ids and cannot be empty.\n       TF_RET_CHECK(!replica_groups.empty())\n           << \"replica groups cannot be empty for kFlattenedID mode\";\n@@ -580,6 +596,10 @@ absl::StatusOr<std::vector<GlobalDeviceId>> GetParticipatingDevices(\n       }\n       return participants;\n     }\n+    default: {\n+      return InvalidArgument(\"Invalid collective op group mode: %d\",\n+                             static_cast<int>(group_mode));\n+    }\n   }\n }\n \n@@ -592,14 +612,16 @@ absl::StatusOr<std::vector<int64_t>> GetPariticipantCountsForReplicaGroups(\n   // If replica groups are empty, assume a group with all replicas.\n   std::optional<ReplicaGroup> all_replica_groups;\n   if (replica_groups.empty()) {\n-    if (group_mode == CollectiveOpGroupMode::kFlattenedID) {\n+    if (group_mode ==\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n       // replica groups contain flattened-ids and cannot be empty.\n       TF_RET_CHECK(!replica_groups.empty())\n           << \"replica groups cannot be empty for kFlattenedID mode\";\n     }\n \n     int total_participant_count;\n-    if (group_mode == CollectiveOpGroupMode::kCrossPartition) {\n+    if (group_mode ==\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION) {\n       // replica group are partition ids.\n       total_participant_count = num_partitions;\n     } else {\n@@ -616,7 +638,7 @@ absl::StatusOr<std::vector<int64_t>> GetPariticipantCountsForReplicaGroups(\n   }\n \n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA: {\n       for (const auto& replica_group : replica_groups) {\n         for (int partition_id = 0; partition_id < num_partitions;\n              ++partition_id) {\n@@ -625,25 +647,30 @@ absl::StatusOr<std::vector<int64_t>> GetPariticipantCountsForReplicaGroups(\n       }\n       return participant_counts;\n     }\n-    case CollectiveOpGroupMode::kCrossPartition: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION: {\n       for (const auto& replica_group : replica_groups) {\n         participant_counts.push_back(replica_group.replica_ids().size());\n       }\n       return participant_counts;\n     }\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n       for (const auto& replica_group : replica_groups) {\n         participant_counts.push_back(replica_group.replica_ids().size() *\n                                      num_partitions);\n       }\n       return participant_counts;\n     }\n-    case CollectiveOpGroupMode::kFlattenedID: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n       for (const auto& replica_group : replica_groups) {\n         participant_counts.push_back(replica_group.replica_ids().size());\n       }\n       return participant_counts;\n     }\n+    default: {\n+      return InvalidArgument(\"Invalid collective op group mode: %d\",\n+                             static_cast<int>(group_mode));\n+    }\n   }\n }\n \n@@ -896,25 +923,30 @@ int64_t GetSubgroupSize(const HloCollectiveInstruction* hlo,\n                         CollectiveOpGroupMode group_mode) {\n   const HloModuleConfig& config = hlo->GetModule()->config();\n   switch (group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica:\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n       int64_t replica_subgroup_size =\n           hlo->replica_groups().empty()\n               ? config.replica_count()\n               : hlo->replica_groups()[0].replica_ids_size();\n-      if (group_mode == CollectiveOpGroupMode::kCrossReplicaAndPartition) {\n+      if (group_mode ==\n+          CollectiveOpGroupMode::\n+              COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION) {\n         // Replicas from all partitions participate.\n         replica_subgroup_size *= config.num_partitions();\n       }\n       return replica_subgroup_size;\n     }\n-    case CollectiveOpGroupMode::kFlattenedID:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID:\n       // Empty replica groups not allowed in this mode.\n       return hlo->replica_groups()[0].replica_ids_size();\n-    case CollectiveOpGroupMode::kCrossPartition:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION:\n       return hlo->replica_groups().empty()\n                  ? config.num_partitions()\n                  : hlo->replica_groups()[0].replica_ids_size();\n+    default:\n+      LOG(FATAL) << \"Invalid collective op group mode: \" << group_mode;\n   }\n }\n "
        },
        {
            "sha": "4e3bdcfccb0d899cadb96ce9781000266a216b2a",
            "filename": "third_party/xla/xla/service/collective_ops_utils_test.cc",
            "status": "modified",
            "additions": 44,
            "deletions": 31,
            "changes": 75,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_ops_utils_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -71,9 +71,10 @@ std::vector<ReplicaGroup> CreateReplicaGroups(\n \n TEST(CollectiveOpsUtilsTest, GetParticipatingIDs_NoReplicaGroups) {\n   std::vector<int> actual =\n-      GetParticipatingIDs(CollectiveOpGroupMode::kFlattenedID,\n-                          /*current_id=*/0, /*total_participant_count=*/3,\n-                          /*groups=*/{})\n+      GetParticipatingIDs(\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID,\n+          /*current_id=*/0, /*total_participant_count=*/3,\n+          /*groups=*/{})\n           .value();\n   std::vector<int> expected = {0, 1, 2};\n   EXPECT_EQ(actual, expected);\n@@ -89,10 +90,10 @@ TEST(CollectiveOpsUtilsTest, GetParticipatingIDs_ReplicaGroups) {\n   replica_groups[2].add_replica_ids(3);\n \n   std::vector<int> actual =\n-      GetParticipatingIDs(CollectiveOpGroupMode::kFlattenedID,\n-                          /*current_id=*/1,\n-                          /*total_participant_count=*/std::nullopt,\n-                          replica_groups)\n+      GetParticipatingIDs(\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID,\n+          /*current_id=*/1,\n+          /*total_participant_count=*/std::nullopt, replica_groups)\n           .value();\n   std::vector<int> expected = {1, 5};\n   EXPECT_EQ(actual, expected);\n@@ -556,12 +557,19 @@ std::vector<TestCase> GetTestCases() {\n   const std::vector<TestCase> test_cases = {\n       // clang-format off\n       // has_channel_id, use_global_device_ids, expected mode\n-      {false, std::nullopt, CollectiveOpGroupMode::kCrossReplica},\n-      {false, false,         CollectiveOpGroupMode::kCrossReplica},\n-      {false, true,          std::nullopt},\n-      {true,  std::nullopt, CollectiveOpGroupMode::kCrossPartition},\n-      {true,  false,         CollectiveOpGroupMode::kCrossReplicaAndPartition},\n-      {true,  true,          CollectiveOpGroupMode::kFlattenedID},\n+      // No channel id, no global device ids.\n+      {false, std::nullopt,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n+      {false, false,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n+      {false, true, std::nullopt},\n+      {true, std::nullopt,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n+      {true, false,\n+       CollectiveOpGroupMode::\n+           COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION},\n+      {true, true,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID},\n       // clang-format on\n   };\n   return test_cases;\n@@ -595,32 +603,36 @@ struct TestCaseForInstruction {\n std::vector<TestCaseForInstruction> GetTestCasesForInstruction() {\n   return std::vector<TestCaseForInstruction>{\n       //  opcode, has_channel_id, use_global_device_ids, expected_group_mode\n-      {HloOpcode::kAllGather, true, true, CollectiveOpGroupMode::kFlattenedID},\n+      {HloOpcode::kAllGather, true, true,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID},\n       {HloOpcode::kAllGather, true, false,\n-       CollectiveOpGroupMode::kCrossReplicaAndPartition},\n+       CollectiveOpGroupMode::\n+           COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION},\n       {HloOpcode::kAllGather, false, false,\n-       CollectiveOpGroupMode::kCrossReplica},\n-      {HloOpcode::kAllReduce, true, true, CollectiveOpGroupMode::kFlattenedID},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n+      {HloOpcode::kAllReduce, true, true,\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID},\n       {HloOpcode::kAllReduce, true, false,\n-       CollectiveOpGroupMode::kCrossReplicaAndPartition},\n+       CollectiveOpGroupMode::\n+           COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION},\n       {HloOpcode::kAllReduce, false, false,\n-       CollectiveOpGroupMode::kCrossReplica},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n       {HloOpcode::kAllToAll, true, std::nullopt,\n-       CollectiveOpGroupMode::kCrossPartition},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n       {HloOpcode::kAllToAll, false, std::nullopt,\n-       CollectiveOpGroupMode::kCrossReplica},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n       {HloOpcode::kCollectiveBroadcast, true, std::nullopt,\n-       CollectiveOpGroupMode::kCrossPartition},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n       {HloOpcode::kCollectiveBroadcast, false, std::nullopt,\n-       CollectiveOpGroupMode::kCrossReplica},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n       {HloOpcode::kCollectivePermute, true, std::nullopt,\n-       CollectiveOpGroupMode::kCrossPartition},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n       {HloOpcode::kCollectivePermute, false, std::nullopt,\n-       CollectiveOpGroupMode::kCrossReplica},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA},\n       {HloOpcode::kRaggedAllToAll, true, std::nullopt,\n-       CollectiveOpGroupMode::kCrossPartition},\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION},\n       {HloOpcode::kRaggedAllToAll, false, std::nullopt,\n-       CollectiveOpGroupMode::kCrossReplica}};\n+       CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA}};\n }\n \n class GetCollectOpGroupModeTestForInstruction\n@@ -1211,31 +1223,32 @@ std::vector<TestCase> GetTestCases() {\n       {\n           \"CrossReplicaEmptyGroup\",\n           {},\n-          CollectiveOpGroupMode::kCrossReplica,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n           8,\n           1,\n           {8},\n       },\n       {\n           \"CrossReplicaWithPartitions\",\n           {{0, 1}, {2, 3}},\n-          CollectiveOpGroupMode::kCrossReplica,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n           4,\n           2,\n           {2, 2, 2, 2},\n       },\n       {\n           \"CrossReplicaAndPartition\",\n           {{0, 1}, {2, 3}},\n-          CollectiveOpGroupMode::kCrossReplicaAndPartition,\n+          CollectiveOpGroupMode::\n+              COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION,\n           4,\n           2,\n           {4, 4},\n       },\n       {\n           \"FlattenedID\",\n           {{0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}},\n-          CollectiveOpGroupMode::kFlattenedID,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID,\n           4,\n           2,\n           {1, 1, 1, 1, 1, 1, 1, 1},"
        },
        {
            "sha": "83372b1bffe25290ee410de7c8961a4a372c32bb",
            "filename": "third_party/xla/xla/service/collective_opt_utils.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_opt_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_opt_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcollective_opt_utils.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -655,10 +655,12 @@ MatchPermutedSliceAndPartitionOffset(const HloAllGatherInstruction* ag,\n     return std::nullopt;\n   }\n \n-  // Only matches for kFlattenedID collective mode.\n+  // Only matches for COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID collective mode.\n   absl::StatusOr<CollectiveOpGroupMode> mode = GetCollectiveOpGroupMode(ag);\n \n-  if (!mode.ok() || mode.value() != CollectiveOpGroupMode::kFlattenedID) {\n+  if (!mode.ok() ||\n+      mode.value() !=\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n     VLOG(2) << \"AG does not use global device ids or channel id \"\n             << ag->ToString();\n     return std::nullopt;"
        },
        {
            "sha": "c103401b2d98f58c7483338602d0fb4ad15bf78e",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -2362,7 +2362,7 @@ absl::Status IrEmitterUnnested::EmitCollectiveGroupStartThunk(\n   }\n   auto thunk = std::make_unique<CollectiveGroupThunk>(\n       instr, Thunk::Kind::kGroupStart, std::move(scoped_thunk_sequence_),\n-      stream_kind.value_or(AsyncStreamKind::kCollective),\n+      stream_kind.value_or(AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE),\n       ir_emitter_context_->GetNextThunkId());\n   emit_group_thunks_ = false;\n \n@@ -2392,7 +2392,7 @@ absl::Status IrEmitterUnnested::EmitCollectiveAsyncDone(\n     return absl::OkStatus();\n   }\n \n-  AsyncStreamKind stream_kind = AsyncStreamKind::kCollective;\n+  AsyncStreamKind stream_kind = AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n   if (is_send_recv) {\n     stream_kind = GetStreamKindForP2P(start);\n   }\n@@ -2425,7 +2425,7 @@ absl::Status IrEmitterUnnested::EmitNvshmemAsyncDone(\n     return absl::OkStatus();\n   }\n \n-  AsyncStreamKind stream_kind = AsyncStreamKind::kCollective;\n+  AsyncStreamKind stream_kind = AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE;\n   if (is_send_recv) {\n     stream_kind = GetStreamKindForP2P(start);\n   }"
        },
        {
            "sha": "bc65cf0fd333e4491e718e80eb4cc265ac75c9ba",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2FBUILD?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -595,7 +595,6 @@ cc_library(\n         \"//xla/hlo/pass:hlo_pass\",\n         \"//xla/hlo/utils:hlo_query\",\n         \"//xla/service:collective_ops_utils\",\n-        \"//xla/service:collective_permute_cycle\",\n         \"//xla/service:source_target_pairs\",\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "936d54e76709787b309f81783528b75700cfb9d5",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/all_reduce_blueconnect.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fall_reduce_blueconnect.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fall_reduce_blueconnect.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fall_reduce_blueconnect.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -75,21 +75,26 @@ struct DecomposedReplicaGroups {\n static std::optional<GlobalDeviceId> TryConvertingReplicaIdToDeviceId(\n     int64_t replica_id, const DeviceAssignment& device_assignment,\n     CollectiveOpGroupMode collective_group_mode) {\n-  if (collective_group_mode == CollectiveOpGroupMode::kCrossReplica) {\n+  if (collective_group_mode ==\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA) {\n     if (device_assignment.computation_count() != 1) {\n       // If there are multiple partitions, the replica_id may refer to multiple\n       // devices on different partitions.\n       return std::nullopt;\n     }\n     return GlobalDeviceId{device_assignment(replica_id, /*computation_id=*/0)};\n-  } else if (collective_group_mode == CollectiveOpGroupMode::kFlattenedID) {\n+  }\n+  if (collective_group_mode ==\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID) {\n     int partition_count = device_assignment.computation_count();\n     int64_t actual_replica_id = replica_id / partition_count;\n     int64_t partition_id = replica_id % partition_count;\n     return GlobalDeviceId{device_assignment(actual_replica_id, partition_id)};\n   }\n \n-  // kCrossPartition and kCrossReplicaAndPartition are unsupported.\n+  // COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION and\n+  // COLLECTIVE_OP_GROUP_MODE_FLATTENED_CROSS_REPLICA_AND_PARTITION are\n+  // unsupported.\n   VLOG(1) << \"Skip AllReduceBlueConnect because of unsupported \"\n              \"CollectiveOpGroupMode \"\n           << CollectiveOpGroupModeToString(collective_group_mode);"
        },
        {
            "sha": "703f9e1fc0ea18a24d121fe9d35d8b31bd1d176b",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_permute_cycle_decomposer.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_permute_cycle_decomposer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_permute_cycle_decomposer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_permute_cycle_decomposer.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -190,14 +190,13 @@ absl::StatusOr<HloInstruction*> CreatePartitionOrReplicaId(\n     HloComputation* computation, CollectiveOpGroupMode mode,\n     absl::string_view cp_name) {\n   switch (mode) {\n-    case CollectiveOpGroupMode::kCrossReplica:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n       return computation->AddInstruction(HloInstruction::CreateReplicaId(),\n                                          absl::StrCat(cp_name, \"-rep-id\"));\n-    case CollectiveOpGroupMode::kCrossPartition:\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION:\n       return computation->AddInstruction(HloInstruction::CreatePartitionId(),\n                                          absl::StrCat(cp_name, \"-part-id\"));\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition:\n-    case CollectiveOpGroupMode::kFlattenedID:\n+    default:\n       return absl::InternalError(\n           absl::StrFormat(\"Unexpected collective group mode for %s\", cp_name));\n   }\n@@ -232,7 +231,8 @@ absl::Status DecomposeCollectivePermuteCycle(\n       AddCP(cp, computation, back_pairs, \"-bwd\", attrs.first, cp->channel_id());\n \n   // Forward edge.\n-  bool is_cross_partition = (mode == CollectiveOpGroupMode::kCrossPartition);\n+  bool is_cross_partition =\n+      (mode == CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION);\n   std::optional<int64_t> fwd_channel_id =\n       is_cross_partition ? std::optional(next_channel_id) : std::nullopt;\n   HloInstruction* fwd_cp ="
        },
        {
            "sha": "40bd821e8c273eac8652fa16933b6c655c15c0c6",
            "filename": "third_party/xla/xla/service/gpu/transforms/collectives/collective_select_folder.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_select_folder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_select_folder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcollectives%2Fcollective_select_folder.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -108,9 +108,11 @@ static std::optional<FoldableSelect> MatchFoldableSelect(\n   // Match replica-id or partition-id.\n   CollectiveOpGroupMode collective_mode;\n   if (HloPredicateIsOp<HloOpcode::kReplicaId>(id_op)) {\n-    collective_mode = CollectiveOpGroupMode::kCrossReplica;\n+    collective_mode =\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA;\n   } else if (HloPredicateIsOp<HloOpcode::kPartitionId>(id_op)) {\n-    collective_mode = CollectiveOpGroupMode::kCrossPartition;\n+    collective_mode =\n+        CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION;\n   } else {\n     return std::nullopt;\n   }"
        },
        {
            "sha": "ec3eb27978c84cb9f185774a8e1408e11e160663",
            "filename": "third_party/xla/xla/service/hlo_verifier.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 10,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fhlo_verifier.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -431,29 +431,34 @@ static absl::Status CheckReplicaGroups(HloInstruction* hlo,\n     int64_t replica_count = hlo->GetModule()->config().replica_count();\n     int64_t num_partitions = hlo->GetModule()->config().num_partitions();\n     switch (group_mode) {\n-      case CollectiveOpGroupMode::kCrossReplica:\n-      case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+      case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n+      case CollectiveOpGroupMode::\n+          COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n         TF_RET_CHECK(replica_count == 1 || n == replica_count)\n             << \"In \" << CollectiveOpGroupModeToString(group_mode)\n             << \" mode, replica groups should contain \" << replica_count\n             << \" replicas, but found \" << n << \": \" << hlo->ToString();\n         break;\n       }\n-      case CollectiveOpGroupMode::kCrossPartition: {\n+      case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION: {\n         TF_RET_CHECK(num_partitions == 1 || n == num_partitions)\n             << \"In \" << CollectiveOpGroupModeToString(group_mode)\n             << \" mode, replica groups should contain \" << num_partitions\n             << \" partitions, but found \" << n << \": \" << hlo->ToString();\n         break;\n       }\n-      case CollectiveOpGroupMode::kFlattenedID: {\n+      case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n         const int64_t num_flattened_ids = replica_count * num_partitions;\n         TF_RET_CHECK(num_flattened_ids == 1 || n == num_flattened_ids)\n             << \"In \" << CollectiveOpGroupModeToString(group_mode)\n             << \" mode, replica groups should contain \" << num_flattened_ids\n             << \" flattened IDs, but found \" << n << \": \" << hlo->ToString();\n         break;\n       }\n+      default: {\n+        return InvalidArgument(\"Invalid collective op group mode: %d\",\n+                               static_cast<int>(group_mode));\n+      }\n     }\n \n     if (uniform_replica_group_size) {\n@@ -464,7 +469,8 @@ static absl::Status CheckReplicaGroups(HloInstruction* hlo,\n       }\n     }\n   } else {\n-    TF_RET_CHECK(group_mode != CollectiveOpGroupMode::kFlattenedID)\n+    TF_RET_CHECK(group_mode !=\n+                 CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID)\n         << \"Replica groups must be specified in flattened-id mode\";\n   }\n \n@@ -814,12 +820,14 @@ absl::Status CheckDuplicatedSourceOrTarget(\n   // source-target pairs. Also, based on the group formation mode, check if the\n   // source and target IDs are within expected range.\n \n-  // Note: for collective-permute, only kCrossReplica and kCrossPartition modes\n-  // are valid.\n+  // Note: for collective-permute, only COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID\n+  // and kCrossPartition modes are valid.\n   const HloModuleConfig& config = collective_permute->GetModule()->config();\n-  const int64_t limit = group_mode == CollectiveOpGroupMode::kCrossReplica\n-                            ? config.replica_count()\n-                            : config.num_partitions();\n+  const int64_t limit =\n+      group_mode ==\n+              CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA\n+          ? config.replica_count()\n+          : config.num_partitions();\n   absl::flat_hash_map<int64_t, std::vector<int64_t>> seen_source_to_targets;\n   absl::flat_hash_map<int64_t, std::vector<int64_t>> seen_target_to_sources;\n   int allowed_seen_count = 1;"
        },
        {
            "sha": "eca621898484d78167ffcf0a34d1f2fea1bbd2ef",
            "filename": "third_party/xla/xla/service/reduce_scatter_decomposer_test.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 16,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Freduce_scatter_decomposer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Freduce_scatter_decomposer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Freduce_scatter_decomposer_test.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -41,11 +41,12 @@ class ReduceScatterDecomposerTest : public HloHardwareIndependentTestBase {\n   };\n   void RunPass(\n       absl::string_view hlo_module, PassAction action,\n-      CollectiveOpGroupMode mode = CollectiveOpGroupMode::kCrossReplica,\n+      CollectiveOpGroupMode mode =\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n       int64_t shard_size = 0, int64_t shard_dimension = 0,\n       int64_t replica_count = 2,\n-      std::function<bool(const HloInstruction *)> should_decompose =\n-          [](const HloInstruction *) { return true; },\n+      std::function<bool(const HloInstruction*)> should_decompose =\n+          [](const HloInstruction*) { return true; },\n       std::optional<std::pair<std::string, std::string>> attribute =\n           std::nullopt) {\n     const int64_t partition_count = 2;\n@@ -66,19 +67,22 @@ class ReduceScatterDecomposerTest : public HloHardwareIndependentTestBase {\n     Literal multiplier = LiteralUtil::CreateR0<uint32_t>(shard_size);\n     ::testing::Matcher<const ::xla::HloInstruction *> id_matcher = [&]() {\n       switch (mode) {\n-        case CollectiveOpGroupMode::kCrossPartition:\n+        case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION:\n           return op::PartitionId();\n-        case CollectiveOpGroupMode::kCrossReplica:\n+        case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA:\n           return op::ReplicaId();\n-        case CollectiveOpGroupMode::kCrossReplicaAndPartition:\n+        case CollectiveOpGroupMode::\n+            COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION:\n           return op::ReplicaId();\n-        case CollectiveOpGroupMode::kFlattenedID: {\n+        case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n           return op::Add(\n               op::Multiply(op::ReplicaId(),\n                            op::Constant(LiteralUtil::CreateR0<uint32_t>(\n                                partition_count))),\n               op::PartitionId());\n         }\n+        default:\n+          LOG(FATAL) << \"Unsupported mode: \" << static_cast<int>(mode);\n       }\n     }();\n     auto root = module->entry_computation()->root_instruction();\n@@ -88,7 +92,8 @@ class ReduceScatterDecomposerTest : public HloHardwareIndependentTestBase {\n     if (action == PassAction::kTableLookup) {\n       slice_index = op::Reshape(op::DynamicSlice(op::Constant(), id_matcher));\n     }\n-    if (mode == CollectiveOpGroupMode::kCrossReplicaAndPartition) {\n+    if (mode == CollectiveOpGroupMode::\n+                    COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION) {\n       slice_index = op::Add(\n           op::Multiply(\n               slice_index,\n@@ -128,7 +133,7 @@ ENTRY main {\n }\n )\";\n   RunPass(hlo_string, PassAction::kTrivialGroups,\n-          CollectiveOpGroupMode::kCrossReplica,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n           /*shard_size=*/4);\n }\n \n@@ -148,7 +153,7 @@ ENTRY main {\n }\n )\";\n   RunPass(hlo_string, PassAction::kTableLookup,\n-          CollectiveOpGroupMode::kCrossReplica,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n           /*shard_size=*/4);\n }\n \n@@ -170,7 +175,8 @@ ENTRY main {\n }\n )\";\n   RunPass(hlo_string, PassAction::kTrivialGroups,\n-          CollectiveOpGroupMode::kCrossReplicaAndPartition,\n+          CollectiveOpGroupMode::\n+              COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION,\n           /*shard_size=*/2, /*shard_dimension=*/1);\n }\n \n@@ -196,9 +202,9 @@ ENTRY main {\n   // partition_id will be simplified by the pass to just partition_id\n   RunPass(\n       hlo_string, PassAction::kTrivialGroups,\n-      CollectiveOpGroupMode::kCrossPartition,\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION,\n       /*shard_size=*/4, /*shard_dimension=*/1, /*replica_count=*/1,\n-      /*should_decompose =*/[](const HloInstruction *) { return true; },\n+      /*should_decompose =*/[](const HloInstruction*) { return true; },\n       std::make_pair(\"_scheduling_group_id\", \"1\"));\n }\n \n@@ -218,7 +224,7 @@ ENTRY main {\n }\n )\";\n   RunPass(hlo_string, PassAction::kTableLookup,\n-          CollectiveOpGroupMode::kFlattenedID,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID,\n           /*shard_size=*/2, /*shard_dimension=*/1);\n }\n \n@@ -256,9 +262,9 @@ ENTRY main {\n }\n )\";\n   RunPass(hlo_string, PassAction::kNoChange,\n-          CollectiveOpGroupMode::kCrossReplica,\n+          CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA,\n           /*shard_size=*/0, /*shard_dimension=*/0,\n-          /*replica_count=*/2, [](const HloInstruction *) { return false; });\n+          /*replica_count=*/2, [](const HloInstruction*) { return false; });\n }\n \n }  // namespace"
        },
        {
            "sha": "76cc18204706eb846bb7a832b2200b4d8c0af25c",
            "filename": "third_party/xla/xla/service/while_loop_all_reduce_code_motion.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_all_reduce_code_motion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_all_reduce_code_motion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fwhile_loop_all_reduce_code_motion.cc?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -100,25 +100,26 @@ bool IsValueReplicatedWithinEachAllReduceGroup(\n           << \" all_reduce_group_mode: \"\n           << CollectiveOpGroupModeToString(all_reduce_group_mode);\n   switch (all_reduce_group_mode) {\n-    case CollectiveOpGroupMode::kCrossReplica: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA: {\n       return cross_replica_replication_analysis == nullptr ||\n              cross_replica_replication_analysis->HloInstructionIsReplicatedAt(\n                  &instruction, index, replica_groups);\n     }\n-    case CollectiveOpGroupMode::kCrossPartition: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION: {\n       return cross_partition_replication_analysis == nullptr ||\n              cross_partition_replication_analysis->HloInstructionIsReplicatedAt(\n                  &instruction, index, replica_groups);\n     }\n-    case CollectiveOpGroupMode::kCrossReplicaAndPartition: {\n+    case CollectiveOpGroupMode::\n+        COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION: {\n       return (cross_replica_replication_analysis == nullptr ||\n               cross_replica_replication_analysis->HloInstructionIsReplicatedAt(\n                   &instruction, index, replica_groups)) &&\n              (cross_partition_replication_analysis == nullptr ||\n               cross_partition_replication_analysis\n                   ->HloInstructionIsReplicatedAt(&instruction, index));\n     }\n-    case CollectiveOpGroupMode::kFlattenedID: {\n+    case CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID: {\n       if (num_replicas == 1) {\n         return cross_partition_replication_analysis == nullptr ||\n                cross_partition_replication_analysis\n@@ -137,6 +138,10 @@ bool IsValueReplicatedWithinEachAllReduceGroup(\n               cross_partition_replication_analysis\n                   ->HloInstructionIsReplicatedAt(&instruction, index));\n     }\n+    default: {\n+      LOG(FATAL) << \"Unsupported all-reduce group mode: \"\n+                 << CollectiveOpGroupModeToString(all_reduce_group_mode);\n+    }\n   }\n }\n "
        },
        {
            "sha": "698b570808c31041c453421598840cbc15588b64",
            "filename": "third_party/xla/xla/xla_data.proto",
            "status": "modified",
            "additions": 57,
            "deletions": 0,
            "changes": 57,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6c440133b8ec40d0b37a730951530a24623905ed/third_party%2Fxla%2Fxla%2Fxla_data.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla_data.proto?ref=6c440133b8ec40d0b37a730951530a24623905ed",
            "patch": "@@ -157,6 +157,63 @@ enum PrimitiveType {\n //   https://www.tensorflow.org/code/tensorflow/compiler/xla/tools/driver.cc\n // )\n \n+// In XLA:GPU we use different streams for different kinds of collective\n+// operations, and include the async stream kind into the GPU clique key.\n+//\n+// We carefully isolate different kinds of collectives using separate\n+// communicators and guarantee that all collective operations have a total order\n+// that will not create a deadlock.\n+enum AsyncStreamKind {\n+  // Stream for asynchronous collective ops.\n+  ASYNC_STREAM_KIND_COLLECTIVE = 0;\n+  // One Stream for P2P Send and Recv ops.\n+  ASYNC_STREAM_KIND_P2P0 = 1;\n+  // Another Stream for P2P Send and Recv ops.\n+  ASYNC_STREAM_KIND_P2P1 = 2;\n+  // Stream for MemCpyP2P\n+  ASYNC_STREAM_KIND_MEMCPYP2P = 3;\n+}\n+\n+// There are broadly 4 modes that collective communication ops use to describe\n+// which sets of devices are participating with a given device in the operation.\n+// These modes are determined by the values of channel_id (optional) and\n+// use_global_device_ids (optional). The modes are as follows:\n+//\n+// kCrossReplica:\n+//    implied by: no channel id, use_global_device_ids = false, or\n+//                no channel_id, no use_global_device_ids:\n+//    replica_groups contain replica_id, group contains all replicas for the\n+//    current partition\n+//\n+// kCrossPartition:\n+//    implied by: channel_id is set, no use_global_device_ids:\n+//    replica_groups contain partition_id, group contains all partitions for the\n+//    current replica.\n+//\n+// kCrossReplicaAndPartition:\n+//    implied by: channel_id is set, use_global_device_ids = false:\n+//    replica_groups contain replica_id, group contains all replicas for all\n+//    partitions (as opposed to just current partition).\n+//\n+// kFlattenedID:\n+//    implied by: channel_id is set, use_global_device_ids = true:\n+//    replica_groups contain flattened-ids, group contains devices that are\n+//    listed in the flattened-id list.\n+//\n+// Rest of the combinations are invalid.\n+//\n+// Since the actual value of channel_id does not matter, we use a bool argument\n+// `has_channel_id`, and optional<bool> for use_global_device_ids.\n+// Note that use_global_device_ids true requires channel_id to be set as well.\n+// Additionally, if use_global_device_ids = true, replica groups cannot be\n+// empty (verified in the HLO verifier).\n+enum CollectiveOpGroupMode {\n+  COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA = 0;\n+  COLLECTIVE_OP_GROUP_MODE_CROSS_PARTITION = 1;\n+  COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA_AND_PARTITION = 2;\n+  COLLECTIVE_OP_GROUP_MODE_FLATTENED_ID = 3;\n+}\n+\n // Describes the padding configuration for Pad operation. The padding amount on\n // both edges as well as between the elements are specified for each dimension.\n message PaddingConfig {"
        }
    ],
    "stats": {
        "total": 658,
        "additions": 396,
        "deletions": 262
    }
}