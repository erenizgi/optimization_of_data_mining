{
    "author": "kanvi-nervana",
    "message": "PR #28762: [XLA:GPU] Add sycl_kernel component and test\n\nImported from GitHub PR https://github.com/openxla/xla/pull/28762\n\nco-author: @bhavani-subramanian\nThis PR adds the sycl_kernel component and corresponding test. It depends on #27943\nCopybara import of the project:\n\n--\n7d454bee71a65804c193068b08fcbdc57bc0bd30 by kanvi khanna <kanvi.khanna@intel.com>:\n\nAdd sycl_kernel component and test\n\n--\n71fc897b56cf3c5fcda787cba207e3e7658a6d77 by kanvi khanna <kanvi.khanna@intel.com>:\n\nformat build file\n\n--\n29b7419e1b2dce586a2d70540b242ed86c4d77ee by Bhavani Subramanian <bhavani1.subramanian@intel.com>:\n\nCleaned up sycl_kernel\n\n--\n8cf3203fb4ba799e91e906790792cee86f69bd6a by Bhavani Subramanian <bhavani1.subramanian@intel.com>:\n\nMinor formatting change\n\n--\n1fa4be1351be367b5459cf8ed0491c13da552caa by Bhavani Subramanian <bhavani1.subramanian@intel.com>:\n\nUpdated SYCL CI scripts to build all targets under stream_executor/sycl\n\n--\na50d20ed5d0b3196e70e290304084a182081b453 by Bhavani Subramanian <bhavani1.subramanian@intel.com>:\n\nUpdated golden_commands.txt for SYCL to test all targets under stream_executor/sycl\n\n--\n44a89fddab0169685b3bced41893343fd45076ec by ag.ramesh <ag.ramesh@intel.com>:\n\nupdated golden_commands.txt\n\nMerging this change closes #28762\n\nPiperOrigin-RevId: 797214158",
    "sha": "4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
    "files": [
        {
            "sha": "33d6dd5016be898f761c495d072854168e40262d",
            "filename": "third_party/xla/build_tools/ci/build.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fbuild.py?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -52,10 +52,7 @@\n     \"//build_tools/...\",\n     \"@local_tsl//tsl/...\",\n )\n-_XLA_ONEAPI_TARGET_PATTERNS = (\n-    \"//xla/stream_executor/sycl:stream_executor_sycl\",\n-    \"//xla/stream_executor/sycl:sycl_status_test\",\n-)\n+_XLA_ONEAPI_TARGET_PATTERNS = (\"//xla/stream_executor/sycl/...\",)\n _XLA_CPU_PRESUBMIT_BENCHMARKS_DEFAULT_TARGET_PATTERNS = (\n     \"//xla/tools/multihost_hlo_runner:hlo_runner_main\",\n     \"//xla/tools:compute_xspace_stats_main\","
        },
        {
            "sha": "9c8a278f13215b9eb2e95bf19850999fc464f475",
            "filename": "third_party/xla/build_tools/ci/golden_commands.txt",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fci%2Fgolden_commands.txt?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -65,8 +65,8 @@ bazel test --build_tag_filters=-no_oss,requires-gpu-nvidia,gpu,-rocm-only,-oneap\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_L4_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_LINUX_X86_GPU_ONEAPI_GITHUB_ACTIONS\n-parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build --nobuild -- //xla/stream_executor/sycl:stream_executor_sycl //xla/stream_executor/sycl:sycl_status_test\n-bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build -- //xla/stream_executor/sycl:stream_executor_sycl //xla/stream_executor/sycl:sycl_status_test\n+parallel --ungroup --retries 3 --delay 15 --nonall -- bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build --nobuild -- //xla/stream_executor/sycl/...\n+bazel build --build_tag_filters=oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --test_tag_filters=oneapi-only,-requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi --config=sycl --config=sycl_hermetic --config=icpx_clang --color=yes --test_output=errors --verbose_failures --keep_going --nobuild_tests_only --profile=profile.json.gz --flaky_test_attempts=3 --jobs=150 --bes_upload_mode=fully_async --//xla/tsl:ci_build -- //xla/stream_executor/sycl/...\n bazel analyze-profile profile.json.gz\n # END BuildType.XLA_LINUX_X86_GPU_ONEAPI_GITHUB_ACTIONS\n # BEGIN BuildType.XLA_MACOS_ARM64_CPU_KOKORO"
        },
        {
            "sha": "126b9899d8aa4e08ad6a57c3dfd123b59d5bd016",
            "filename": "third_party/xla/build_tools/sycl/ci_build_xla.sh",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_build_xla.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_build_xla.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_build_xla.sh?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -23,8 +23,8 @@\n # This script only builds modules and tests, it doesn't execute them. It\n # can be run on any system and doesn't need an Intel GPU.\n bazel build \\\n-      --config=sycl_hermetic --verbose_failures -c opt\\\n+      --config=sycl_hermetic --verbose_failures -c opt \\\n       --build_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n       --test_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n-      //xla/stream_executor/sycl:stream_executor_sycl \\\n-      //xla/stream_executor/sycl:sycl_status_test\n+      --show_result=30 \\\n+      //xla/stream_executor/sycl/..."
        },
        {
            "sha": "763eaf4b02a8f3fbfff973684934aaba0fbbe3f6",
            "filename": "third_party/xla/build_tools/sycl/ci_test_xla.sh",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fbuild_tools%2Fsycl%2Fci_test_xla.sh?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -22,4 +22,5 @@ bazel test \\\n       --verbose_failures -c opt \\\n       --build_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n       --test_tag_filters=gpu,oneapi-only,requires-gpu-intel,-requires-gpu-amd,-requires-gpu-nvidia,-no_oss,-cuda-only,-rocm-only,-no-oneapi \\\n-      //xla/stream_executor/sycl:sycl_status_test\n+      //xla/stream_executor/sycl:sycl_status_test \\\n+      //xla/stream_executor/sycl:sycl_kernel_test_intelgpu_any"
        },
        {
            "sha": "56f20484ad99f45450a211662c3fbda72424d14e",
            "filename": "third_party/xla/xla/stream_executor/sycl/BUILD",
            "status": "modified",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2FBUILD?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -10,6 +10,7 @@ load(\n     \"//xla/stream_executor:build_defs.bzl\",\n     \"stream_executor_friends\",\n )\n+load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n load(\"//xla/tsl:tsl.bzl\", \"internal_visibility\", \"tsl_copts\")\n load(\"//xla/tsl/platform:build_config_root.bzl\", \"if_static\")\n load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n@@ -147,3 +148,41 @@ cc_library(\n     ],\n     alwayslink = 1,\n )\n+\n+cc_library(\n+    name = \"sycl_kernel\",\n+    srcs = [\"sycl_kernel.cc\"],\n+    hdrs = [\"sycl_kernel.h\"],\n+    tags = [\n+        \"gpu\",\n+        \"oneapi-only\",\n+    ],\n+    deps = [\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@local_config_sycl//sycl:sycl_headers\",\n+        \"@local_tsl//tsl/platform:logging\",\n+    ],\n+)\n+\n+xla_test(\n+    name = \"sycl_kernel_test\",\n+    srcs = [\"sycl_kernel_test.cc\"],\n+    backends = [\"gpu\"],\n+    tags = [\n+        \"gpu\",\n+        \"oneapi-only\",\n+    ],\n+    deps = [\n+        \"//xla/stream_executor:kernel\",\n+        \"//xla/stream_executor:launch_dim\",\n+        \"//xla/stream_executor:platform\",\n+        \"//xla/stream_executor:platform_manager\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/tsl/platform:status_matchers\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"//xla/tsl/platform:test\",\n+        \"@com_google_googletest//:gtest_main\",\n+        \"@local_config_sycl//sycl:sycl_headers\",\n+    ],\n+)"
        },
        {
            "sha": "64a6bbd64c9388650ea2e721cba8c544e7b0e013",
            "filename": "third_party/xla/xla/stream_executor/sycl/sycl_kernel.cc",
            "status": "added",
            "additions": 108,
            "deletions": 0,
            "changes": 108,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.cc?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -0,0 +1,108 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/stream_executor/sycl/sycl_kernel.h\"\n+\n+namespace stream_executor {\n+namespace gpu {\n+\n+// TODO(intel-tf): Implement this feature in SYCL\n+absl::StatusOr<int32_t> SyclKernel::GetMaxOccupiedBlocksPerCore(\n+    ThreadDim threads, size_t dynamic_shared_memory_bytes) const {\n+  return absl::UnimplementedError(\n+      \"GetMaxOccupiedBlocksPerCore is unimplemented for SYCL platform.\");\n+}\n+\n+// TODO(intel-tf): Implement this feature in SYCL\n+absl::StatusOr<KernelMetadata> SyclKernel::GetKernelMetadata() {\n+  return absl::UnimplementedError(\n+      \"GetKernelMetadata is unimplemented for SYCL platform.\");\n+}\n+\n+absl::Status SyclKernel::Launch(const ThreadDim& thread_dims,\n+                                const BlockDim& block_dims,\n+                                const std::optional<ClusterDim>& cluster_dims,\n+                                Stream* stream, const KernelArgs& args) {\n+  VLOG(2) << thread_dims.ToString() << \", \" << block_dims.ToString() << \", \"\n+          << (cluster_dims.has_value() ? cluster_dims.value().ToString()\n+                                       : \"ClusterDim{std::nullopt}\");\n+\n+  if (cluster_dims.has_value()) {\n+    VLOG(2) << cluster_dims.value().ToString();\n+  }\n+\n+  ::sycl::kernel* function = gpu_function();\n+  if (function == nullptr) {\n+    return absl::InternalError(\"SYCL kernel function is not set\");\n+  }\n+\n+  // Launch kernels with packed arguments.\n+  const auto launch = [this, &cluster_dims, &thread_dims, &block_dims,\n+                       &function,\n+                       stream](const KernelArgsPackedArrayBase& packed) {\n+    // Use an extra argument when using shared memory.\n+    bool has_shared_memory = packed.number_of_shared_bytes() > 0;\n+    int32_t expected_number_of_arguments =\n+        Arity() + (has_shared_memory ? 1 : 0);\n+\n+    CHECK_EQ(expected_number_of_arguments, packed.number_of_arguments())\n+        << \"Kernel \" << name() << \" has \" << packed.number_of_arguments()\n+        << \" arguments, but expected \" << expected_number_of_arguments\n+        << \"; arity=\" << Arity() << \"; has_shared_memory=\" << has_shared_memory\n+        << \"; number_of_shared_bytes=\" << packed.number_of_shared_bytes();\n+\n+    std::vector<void*> kernel_args;\n+    const auto& arg_addrs = packed.argument_addresses();\n+    // If there are no arguments to pass (e.g., when using shared memory),\n+    // we can skip packing the kernel arguments.\n+    if (arg_addrs.empty() && packed.number_of_arguments() == 0) {\n+      return stream->LaunchKernel(thread_dims, block_dims, cluster_dims,\n+                                  function, name(), nullptr,\n+                                  packed.number_of_shared_bytes());\n+    } else {\n+      kernel_args.reserve(arg_addrs.size());\n+      for (const void* const arg : arg_addrs) {\n+        kernel_args.push_back(\n+            reinterpret_cast<void*>(*static_cast<const uint64_t*>(arg)));\n+      }\n+      size_t kernel_args_size = kernel_args.size();\n+      std::array<void*, 2> config = {kernel_args.data(), &kernel_args_size};\n+      return stream->LaunchKernel(thread_dims, block_dims, cluster_dims,\n+                                  function, name(),\n+                                  reinterpret_cast<void**>(config.data()),\n+                                  packed.number_of_shared_bytes());\n+    }\n+  };\n+\n+  // If arguments are already packed we can just launch the kernel.\n+  if (auto* packed = DynCast<KernelArgsPackedArrayBase>(&args)) {\n+    return launch(*packed);\n+  }\n+\n+  // For device memory array we rely on a custom kernel arguments packing.\n+  if (auto* device_mem = DynCast<KernelArgsDeviceMemoryArray>(&args)) {\n+    auto& pack = args_packing();\n+    if (!pack) {\n+      return absl::InternalError(\n+          \"Kernel is missing a custom arguments packing function for device \"\n+          \"memory arguments array\");\n+    }\n+\n+    TF_ASSIGN_OR_RETURN(auto packed, pack(*this, *device_mem));\n+    return launch(*packed);\n+  }\n+\n+  return absl::InternalError(\"Unsupported kernel arguments type\");\n+}\n+\n+}  // namespace gpu\n+}  // namespace stream_executor"
        },
        {
            "sha": "cad81dc285487ad2fd68b3973bbf01bcf238660e",
            "filename": "third_party/xla/xla/stream_executor/sycl/sycl_kernel.h",
            "status": "added",
            "additions": 60,
            "deletions": 0,
            "changes": 60,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel.h?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -0,0 +1,60 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_STREAM_EXECUTOR_SYCL_SYCL_KERNEL_H_\n+#define XLA_STREAM_EXECUTOR_SYCL_SYCL_KERNEL_H_\n+\n+#include <sycl/sycl.hpp>\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"tsl/platform/logging.h\"\n+\n+namespace stream_executor::gpu {\n+\n+class SyclKernel : public Kernel {\n+ public:\n+  explicit SyclKernel(StreamExecutor* executor) : executor_(executor) {}\n+\n+  // Note that the function is unloaded when the module is unloaded, and the\n+  // module that the function is contained in is owned by the StreamExecutor.\n+  ~SyclKernel() override { executor_->UnloadKernel(this); }\n+\n+  void set_arity(unsigned arity) { arity_ = arity; }\n+  unsigned Arity() const override { return arity_; }\n+\n+  absl::StatusOr<int32_t> GetMaxOccupiedBlocksPerCore(\n+      ThreadDim threads, size_t dynamic_shared_memory_bytes) const override;\n+\n+  // Simple accessor methods.\n+  ::sycl::kernel* gpu_function() const { return sycl_function_; }\n+  void set_gpu_function(::sycl::kernel* sycl_function) {\n+    sycl_function_ = sycl_function;\n+  }\n+\n+  // Collects metadata for the specified kernel.\n+  absl::StatusOr<KernelMetadata> GetKernelMetadata();\n+\n+ private:\n+  absl::Status Launch(const ThreadDim& thread_dims, const BlockDim& block_dims,\n+                      const std::optional<ClusterDim>& cluster_dims,\n+                      Stream* stream, const KernelArgs& args) override;\n+\n+  StreamExecutor* executor_ = nullptr;\n+\n+  ::sycl::kernel* sycl_function_ = nullptr;  // wrapped SYCL kernel handle\n+  unsigned arity_ = 0;  // number of formal parameters the kernel takes\n+};\n+\n+}  // namespace stream_executor::gpu\n+\n+#endif  // XLA_STREAM_EXECUTOR_SYCL_SYCL_KERNEL_H_"
        },
        {
            "sha": "9183cf31536a58de26fd0f9aed8407a976a4970a",
            "filename": "third_party/xla/xla/stream_executor/sycl/sycl_kernel_test.cc",
            "status": "added",
            "additions": 138,
            "deletions": 0,
            "changes": 138,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_kernel_test.cc?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -0,0 +1,138 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+    http://www.apache.org/licenses/LICENSE-2.0\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <gtest/gtest.h>\n+#include \"xla/stream_executor/platform_manager.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/status_matchers.h\"\n+\n+namespace stream_executor::gpu {\n+namespace {\n+using tsl::testing::IsOkAndHolds;\n+\n+TEST(SyclKernelTest, CheckKernelLoading) {\n+  TF_ASSERT_OK_AND_ASSIGN(Platform * platform,\n+                          PlatformManager::PlatformWithName(\"SYCL\"));\n+  TF_ASSERT_OK_AND_ASSIGN(StreamExecutor * executor,\n+                          platform->ExecutorForDevice(0));\n+\n+  // TODO(intel-tf): This is a temporary workaround to get the test working.\n+  // This will be replaced with hlo-based spv binary generation once MLIR\n+  // changes are in place.\n+  const unsigned char kAddSpv[] = {\n+      0x03, 0x02, 0x23, 0x07, 0x00, 0x04, 0x01, 0x00, 0x15, 0x00, 0x2B, 0x00,\n+      0x3F, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x11, 0x00, 0x02, 0x00,\n+      0x06, 0x00, 0x00, 0x00, 0x11, 0x00, 0x02, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0x11, 0x00, 0x02, 0x00, 0x0B, 0x00, 0x00, 0x00, 0x11, 0x00, 0x02, 0x00,\n+      0x05, 0x00, 0x00, 0x00, 0x0B, 0x00, 0x05, 0x00, 0x01, 0x00, 0x00, 0x00,\n+      0x4F, 0x70, 0x65, 0x6E, 0x43, 0x4C, 0x2E, 0x73, 0x74, 0x64, 0x00, 0x00,\n+      0x0E, 0x00, 0x03, 0x00, 0x02, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x0F, 0x00, 0x08, 0x00, 0x06, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n+      0x77, 0x72, 0x61, 0x70, 0x70, 0x65, 0x64, 0x5F, 0x61, 0x64, 0x64, 0x00,\n+      0x0C, 0x00, 0x00, 0x00, 0x0B, 0x00, 0x00, 0x00, 0x10, 0x00, 0x03, 0x00,\n+      0x10, 0x00, 0x00, 0x00, 0x1F, 0x00, 0x00, 0x00, 0x03, 0x00, 0x03, 0x00,\n+      0x04, 0x00, 0x00, 0x00, 0xA0, 0x86, 0x01, 0x00, 0x05, 0x00, 0x05, 0x00,\n+      0x10, 0x00, 0x00, 0x00, 0x77, 0x72, 0x61, 0x70, 0x70, 0x65, 0x64, 0x5F,\n+      0x61, 0x64, 0x64, 0x00, 0x05, 0x00, 0x0B, 0x00, 0x0B, 0x00, 0x00, 0x00,\n+      0x5F, 0x5F, 0x73, 0x70, 0x69, 0x72, 0x76, 0x5F, 0x42, 0x75, 0x69, 0x6C,\n+      0x74, 0x49, 0x6E, 0x4C, 0x6F, 0x63, 0x61, 0x6C, 0x49, 0x6E, 0x76, 0x6F,\n+      0x63, 0x61, 0x74, 0x69, 0x6F, 0x6E, 0x49, 0x64, 0x00, 0x00, 0x00, 0x00,\n+      0x05, 0x00, 0x09, 0x00, 0x0C, 0x00, 0x00, 0x00, 0x5F, 0x5F, 0x73, 0x70,\n+      0x69, 0x72, 0x76, 0x5F, 0x42, 0x75, 0x69, 0x6C, 0x74, 0x49, 0x6E, 0x57,\n+      0x6F, 0x72, 0x6B, 0x67, 0x72, 0x6F, 0x75, 0x70, 0x49, 0x64, 0x00, 0x00,\n+      0x47, 0x00, 0x04, 0x00, 0x0D, 0x00, 0x00, 0x00, 0x2D, 0x00, 0x00, 0x00,\n+      0x00, 0x40, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00, 0x0D, 0x00, 0x00, 0x00,\n+      0x2C, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00,\n+      0x0D, 0x00, 0x00, 0x00, 0x26, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0x47, 0x00, 0x04, 0x00, 0x0E, 0x00, 0x00, 0x00, 0x2D, 0x00, 0x00, 0x00,\n+      0x00, 0x40, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00, 0x0E, 0x00, 0x00, 0x00,\n+      0x2C, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00,\n+      0x0E, 0x00, 0x00, 0x00, 0x26, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0x47, 0x00, 0x04, 0x00, 0x0F, 0x00, 0x00, 0x00, 0x2D, 0x00, 0x00, 0x00,\n+      0x00, 0x40, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00, 0x0F, 0x00, 0x00, 0x00,\n+      0x2C, 0x00, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00,\n+      0x0F, 0x00, 0x00, 0x00, 0x26, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0x47, 0x00, 0x03, 0x00, 0x0B, 0x00, 0x00, 0x00, 0x16, 0x00, 0x00, 0x00,\n+      0x47, 0x00, 0x0D, 0x00, 0x0B, 0x00, 0x00, 0x00, 0x29, 0x00, 0x00, 0x00,\n+      0x5F, 0x5F, 0x73, 0x70, 0x69, 0x72, 0x76, 0x5F, 0x42, 0x75, 0x69, 0x6C,\n+      0x74, 0x49, 0x6E, 0x4C, 0x6F, 0x63, 0x61, 0x6C, 0x49, 0x6E, 0x76, 0x6F,\n+      0x63, 0x61, 0x74, 0x69, 0x6F, 0x6E, 0x49, 0x64, 0x00, 0x00, 0x00, 0x00,\n+      0x01, 0x00, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00, 0x0B, 0x00, 0x00, 0x00,\n+      0x0B, 0x00, 0x00, 0x00, 0x1B, 0x00, 0x00, 0x00, 0x47, 0x00, 0x03, 0x00,\n+      0x0C, 0x00, 0x00, 0x00, 0x16, 0x00, 0x00, 0x00, 0x47, 0x00, 0x0B, 0x00,\n+      0x0C, 0x00, 0x00, 0x00, 0x29, 0x00, 0x00, 0x00, 0x5F, 0x5F, 0x73, 0x70,\n+      0x69, 0x72, 0x76, 0x5F, 0x42, 0x75, 0x69, 0x6C, 0x74, 0x49, 0x6E, 0x57,\n+      0x6F, 0x72, 0x6B, 0x67, 0x72, 0x6F, 0x75, 0x70, 0x49, 0x64, 0x00, 0x00,\n+      0x01, 0x00, 0x00, 0x00, 0x47, 0x00, 0x04, 0x00, 0x0C, 0x00, 0x00, 0x00,\n+      0x0B, 0x00, 0x00, 0x00, 0x1A, 0x00, 0x00, 0x00, 0x16, 0x00, 0x03, 0x00,\n+      0x02, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x20, 0x00, 0x04, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x13, 0x00, 0x02, 0x00, 0x04, 0x00, 0x00, 0x00, 0x21, 0x00, 0x06, 0x00,\n+      0x05, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x15, 0x00, 0x04, 0x00,\n+      0x06, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x15, 0x00, 0x04, 0x00, 0x07, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x17, 0x00, 0x04, 0x00, 0x08, 0x00, 0x00, 0x00,\n+      0x07, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x20, 0x00, 0x04, 0x00,\n+      0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n+      0x2B, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x0A, 0x00, 0x00, 0x00,\n+      0x80, 0x00, 0x00, 0x00, 0x3B, 0x00, 0x04, 0x00, 0x09, 0x00, 0x00, 0x00,\n+      0x0B, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x3B, 0x00, 0x04, 0x00,\n+      0x09, 0x00, 0x00, 0x00, 0x0C, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n+      0x36, 0x00, 0x05, 0x00, 0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n+      0x00, 0x00, 0x00, 0x00, 0x05, 0x00, 0x00, 0x00, 0x37, 0x00, 0x03, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x0D, 0x00, 0x00, 0x00, 0x37, 0x00, 0x03, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x0E, 0x00, 0x00, 0x00, 0x37, 0x00, 0x03, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x0F, 0x00, 0x00, 0x00, 0xF8, 0x00, 0x02, 0x00,\n+      0x1F, 0x00, 0x00, 0x00, 0x3D, 0x00, 0x06, 0x00, 0x08, 0x00, 0x00, 0x00,\n+      0x11, 0x00, 0x00, 0x00, 0x0B, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x01, 0x00, 0x00, 0x00, 0x51, 0x00, 0x05, 0x00, 0x07, 0x00, 0x00, 0x00,\n+      0x12, 0x00, 0x00, 0x00, 0x11, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x71, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n+      0x12, 0x00, 0x00, 0x00, 0x3D, 0x00, 0x06, 0x00, 0x08, 0x00, 0x00, 0x00,\n+      0x14, 0x00, 0x00, 0x00, 0x0C, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x01, 0x00, 0x00, 0x00, 0x51, 0x00, 0x05, 0x00, 0x07, 0x00, 0x00, 0x00,\n+      0x15, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n+      0x71, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00, 0x16, 0x00, 0x00, 0x00,\n+      0x15, 0x00, 0x00, 0x00, 0x84, 0x00, 0x05, 0x00, 0x06, 0x00, 0x00, 0x00,\n+      0x17, 0x00, 0x00, 0x00, 0x16, 0x00, 0x00, 0x00, 0x0A, 0x00, 0x00, 0x00,\n+      0x80, 0x00, 0x05, 0x00, 0x06, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n+      0x17, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00, 0x46, 0x00, 0x05, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x19, 0x00, 0x00, 0x00, 0x0D, 0x00, 0x00, 0x00,\n+      0x18, 0x00, 0x00, 0x00, 0x3D, 0x00, 0x06, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x1A, 0x00, 0x00, 0x00, 0x19, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n+      0x04, 0x00, 0x00, 0x00, 0x46, 0x00, 0x05, 0x00, 0x03, 0x00, 0x00, 0x00,\n+      0x1B, 0x00, 0x00, 0x00, 0x0E, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n+      0x3D, 0x00, 0x06, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1C, 0x00, 0x00, 0x00,\n+      0x1B, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0x81, 0x00, 0x05, 0x00, 0x02, 0x00, 0x00, 0x00, 0x1D, 0x00, 0x00, 0x00,\n+      0x1A, 0x00, 0x00, 0x00, 0x1C, 0x00, 0x00, 0x00, 0x46, 0x00, 0x05, 0x00,\n+      0x03, 0x00, 0x00, 0x00, 0x1E, 0x00, 0x00, 0x00, 0x0F, 0x00, 0x00, 0x00,\n+      0x18, 0x00, 0x00, 0x00, 0x3E, 0x00, 0x05, 0x00, 0x1E, 0x00, 0x00, 0x00,\n+      0x1D, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n+      0xFD, 0x00, 0x01, 0x00, 0x38, 0x00, 0x01, 0x00};\n+  constexpr size_t kAddSpvSize = sizeof(kAddSpv);\n+\n+  KernelLoaderSpec spec = KernelLoaderSpec::CreateCudaCubinInMemorySpec(\n+      absl::Span<const uint8_t>(reinterpret_cast<const uint8_t*>(kAddSpv),\n+                                kAddSpvSize),\n+      \"wrapped_add\", 3);\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<Kernel> sycl_kernel,\n+                          executor->LoadKernel(spec));\n+\n+  EXPECT_EQ(sycl_kernel->Arity(), 3);\n+  // TODO(intel-tf): Add check for GetMaxOccupiedBlocksPerCore\n+}\n+\n+}  // namespace\n+}  // namespace stream_executor::gpu"
        },
        {
            "sha": "f32ab81258386eaffd3e57f619796cbe752cfda7",
            "filename": "third_party/xla/xla/stream_executor/sycl/sycl_platform.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_platform.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4aa4e23c4af92ec96c769f87fc50cb92e0530b89/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_platform.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fsycl%2Fsycl_platform.cc?ref=4aa4e23c4af92ec96c769f87fc50cb92e0530b89",
            "patch": "@@ -49,16 +49,19 @@ const std::string& SyclPlatform::Name() const { return name_; }\n \n absl::StatusOr<std::unique_ptr<DeviceDescription>>\n SyclPlatform::DescriptionForDevice(int ordinal) const {\n-  return absl::UnimplementedError(\"Unimplemented\");\n+  return absl::UnimplementedError(\n+      \"DescriptionForDevice is unimplemented for SYCL platform.\");\n }\n \n absl::StatusOr<StreamExecutor*> SyclPlatform::ExecutorForDevice(int ordinal) {\n-  return absl::UnimplementedError(\"Unimplemented\");\n+  return absl::UnimplementedError(\n+      \"ExecutorForDevice is unimplemented for SYCL platform.\");\n }\n \n absl::StatusOr<std::unique_ptr<StreamExecutor>>\n SyclPlatform::GetUncachedExecutor(int ordinal) {\n-  return absl::UnimplementedError(\"Unimplemented\");\n+  return absl::UnimplementedError(\n+      \"GetUncachedExecutor is unimplemented for SYCL platform.\");\n }\n \n }  // namespace gpu"
        }
    ],
    "stats": {
        "total": 372,
        "additions": 359,
        "deletions": 13
    }
}