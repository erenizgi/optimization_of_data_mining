{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Add lowering for tensor extract and from_elements & fix dot with scalar output.\n\nPiperOrigin-RevId: 820368257",
    "sha": "168eb2c36a811113bd136edcf77bbadc743bbe06",
    "files": [
        {
            "sha": "e0c2aa9c25d11cf3bef3cb163cbc5036390c613b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/fusion_compiler.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ffusion_compiler.cc?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -233,6 +233,7 @@ static void AddTiledLoweringPasses(mlir::OpPassManager& pm) {\n   pm.addPass(CreateElementalTensorToVectorPass());\n   pm.addPass(CreateShloToVectorPass());\n   pm.addPass(CreateLowerXTileEntryPass());\n+  pm.addPass(CreateTensorOpsToVectorPass());\n   pm.addPass(cpu::createLowerToLLVMPass());\n   pm.addPass(mlir::createConvertVectorToSCFPass(\n       mlir::VectorTransferToSCFOptions().enableFullUnroll(false)));"
        },
        {
            "sha": "78865fac30548814f0c7579a9e50f2edc74c5d78",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_kernel_test.py",
            "status": "modified",
            "additions": 31,
            "deletions": 2,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -55,8 +55,8 @@ def compare_kernel(\n         np.asarray(output_tensor), expected_output(*inputs)\n     )\n   else:\n-    np.testing.assert_array_almost_equal(\n-        np.asarray(output_tensor), expected_output(*inputs)\n+    np.testing.assert_array_almost_equal_nulp(\n+        np.asarray(output_tensor), expected_output(*inputs), nulp=3\n     )\n \n \n@@ -174,6 +174,35 @@ def test_dot_single_tile(self):\n         False,\n     )\n \n+  def test_dot_scalar_output(self):\n+    ir = \"\"\"\n+      module @test_dot_scalar_output {\n+        xtile.entry_func @test_dot_scalar_output(\n+            %lhs: memref<8x16xf32>,\n+            %rhs: memref<16x8xf32>,\n+            %output: memref<f32>,\n+            %tile_id: index) attributes {xtile.tiling_info = #xtile.tiling_info<tile_count:1, tiles_per_workgroup:1>} {\n+          %offset = arith.constant 0 : index\n+          %lhs_tile = xtile.extract %lhs[%offset, %offset][8, 16][1, 1] : memref<8x16xf32> -> tensor<8x16xf32>\n+          %rhs_tile = xtile.extract %rhs[%offset, %offset][16, 8][1, 1] : memref<16x8xf32> -> tensor<16x8xf32>\n+          %result = stablehlo.dot_general %lhs_tile, %rhs_tile, contracting_dims = [1, 0] x [0, 1] : (tensor<8x16xf32>, tensor<16x8xf32>) -> tensor<f32>\n+          xtile.insert %result into %output[][][] : tensor<f32> -> memref<f32>\n+          xtile.return\n+        }\n+      }\n+    \"\"\"\n+\n+    compare_kernel(\n+        ir,\n+        \"test_dot_scalar_output\",\n+        1,\n+        [(8, 16), (16, 8)],\n+        (1,),\n+        np.float32,\n+        lambda lhs, rhs: np.tensordot(lhs, rhs, axes=([1, 0], [0, 1])),\n+        False,\n+    )\n+\n   def test_dot_fusion_single_tile(self):\n     ir = \"\"\"\n       module @dot_fusion_single_tile {"
        },
        {
            "sha": "81491115e242f3ad69891369ac71f16500ffc86b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 0,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2FBUILD?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -28,16 +28,33 @@ gentbl_cc_library(\n     deps = [\"@llvm-project//mlir:PassBaseTdFiles\"],\n )\n \n+cc_library(\n+    name = \"lowering_utils\",\n+    srcs = [\n+        \"lowering_utils.cc\",\n+    ],\n+    hdrs = [\"lowering_utils.h\"],\n+    visibility = [\"//visibility:private\"],\n+    deps = [\n+        \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:Support\",\n+        \"@llvm-project//mlir:TensorDialect\",\n+        \"@llvm-project//mlir:VectorDialect\",\n+    ],\n+)\n+\n cc_library(\n     name = \"passes\",\n     srcs = [\n         \"elemental_tensor_to_vector.cc\",\n         \"lower_xtile_entry.cc\",\n         \"shlo_to_vector.cc\",\n+        \"tensor_ops_to_vector.cc\",\n         \"xtile_to_vector.cc\",\n     ],\n     hdrs = [\"passes.h\"],\n     deps = [\n+        \":lowering_utils\",\n         \":passes_inc_gen\",\n         \"//xla/backends/cpu/codegen/emitters/ir:xla_cpu\",\n         \"//xla/codegen/emitters/ir:xla\","
        },
        {
            "sha": "b55bb4754d2951ea56e9e237954adc5acc1987ec",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/lowering_utils.cc",
            "status": "added",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.cc?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -0,0 +1,69 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n+\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/Support/LLVM.h\"\n+\n+namespace xla::cpu {\n+\n+mlir::VectorType GetVectorType(mlir::RankedTensorType tensor_type) {\n+  return mlir::VectorType::get(tensor_type.getShape(),\n+                               tensor_type.getElementType());\n+}\n+\n+mlir::TypedValue<mlir::VectorType> CastToVector(mlir::OpBuilder& builder,\n+                                                mlir::Value input) {\n+  if (input.getType().isIntOrFloat()) {\n+    return builder.create<mlir::vector::FromElementsOp>(\n+        input.getLoc(), mlir::VectorType::get({}, input.getType()), input);\n+  }\n+\n+  auto input_tensor =\n+      mlir::cast<mlir::TypedValue<mlir::RankedTensorType>>(input);\n+  auto vector_type = GetVectorType(input_tensor.getType());\n+  auto cast_op = builder.create<mlir::UnrealizedConversionCastOp>(\n+      input.getLoc(), vector_type, input_tensor);\n+  return mlir::cast<mlir::TypedValue<mlir::VectorType>>(cast_op.getResult(0));\n+}\n+\n+mlir::RankedTensorType GetTensorType(mlir::VectorType vector_type) {\n+  return mlir::RankedTensorType::get(vector_type.getShape(),\n+                                     vector_type.getElementType());\n+}\n+\n+mlir::TypedValue<mlir::RankedTensorType> CastToTensor(mlir::OpBuilder& builder,\n+                                                      mlir::Value input) {\n+  if (input.getType().isIntOrFloat()) {\n+    return builder.create<mlir::tensor::FromElementsOp>(\n+        input.getLoc(), mlir::RankedTensorType::get({}, input.getType()),\n+        input);\n+  }\n+\n+  auto input_vector = mlir::cast<mlir::TypedValue<mlir::VectorType>>(input);\n+  auto tensor_type = GetTensorType(input_vector.getType());\n+  auto cast_op = builder.create<mlir::UnrealizedConversionCastOp>(\n+      input.getLoc(), tensor_type, input_vector);\n+  return mlir::cast<mlir::TypedValue<mlir::RankedTensorType>>(\n+      cast_op.getResult(0));\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "1ffd2a54db532e11417fb209bc11870e20dda16e",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h",
            "status": "added",
            "additions": 51,
            "deletions": 0,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Flowering_utils.h?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -0,0 +1,51 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_CPU_CODEGEN_TILED_TRANSFORMS_LOWERING_UTILS_H_\n+#define XLA_BACKENDS_CPU_CODEGEN_TILED_TRANSFORMS_LOWERING_UTILS_H_\n+\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Value.h\"\n+\n+namespace xla::cpu {\n+\n+// Get the vector type that has the same shape and element type as the tensor\n+// type.\n+mlir::VectorType GetVectorType(mlir::RankedTensorType tensor_type);\n+\n+// Cast the input to a vector value.\n+// If the input is a scalar it will be simply constructed as a\n+// vector.from_elements to create a 0D vector.\n+// If it is a vector it will be cast to a vector using an unrealized cast op.\n+// Any other type will crash.\n+mlir::TypedValue<mlir::VectorType> CastToVector(mlir::OpBuilder& builder,\n+                                                mlir::Value input);\n+\n+// Get the tensor type that has the same shape and element type as the vector\n+// type.\n+mlir::RankedTensorType GetTensorType(mlir::VectorType vector_type);\n+\n+// Cast the input to a tensor value.\n+// If the input is a scalar it will be simply constructed as a\n+// tensor.from_elements to create a 0D tensor.\n+// If it is a vector it will be cast to a tensor using an unrealized cast op.\n+// Any other type will crash.\n+mlir::TypedValue<mlir::RankedTensorType> CastToTensor(mlir::OpBuilder& builder,\n+                                                      mlir::Value input);\n+\n+}  // namespace xla::cpu\n+\n+#endif  // XLA_BACKENDS_CPU_CODEGEN_TILED_TRANSFORMS_LOWERING_UTILS_H_"
        },
        {
            "sha": "b092d7d18cb5fe3042e937cc227eb73844318483",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.h?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -37,6 +37,7 @@ std::unique_ptr<mlir::Pass> CreateElementalTensorToVectorPass();\n std::unique_ptr<mlir::Pass> CreateLowerXTileEntryPass();\n std::unique_ptr<mlir::Pass> CreateShloToVectorPass();\n std::unique_ptr<mlir::Pass> CreateXTileToVectorPass();\n+std::unique_ptr<mlir::Pass> CreateTensorOpsToVectorPass();\n \n #define GEN_PASS_REGISTRATION\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\""
        },
        {
            "sha": "2d5789080505f010a96e6d7bbf210e14d4751c8f",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/passes.td",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fpasses.td?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -65,3 +65,14 @@ def ElementalTensorToVectorPass : Pass<\"xtile-cpu-elemental-tensor-to-vector\",\n     \"mlir::vector::VectorDialect\",\n   ];\n }\n+\n+def TensorOpsToVectorPass : Pass<\"xtile-cpu-tensor-ops-to-vector\",\n+                                 \"mlir::ModuleOp\"> {\n+  let summary = \"Lowering tensor dialect ops to vector ops\";\n+\n+  let constructor = \"CreateTensorOpsToVectorPass()\";\n+\n+  let dependentDialects = [\n+    \"mlir::vector::VectorDialect\",\n+  ];\n+}"
        },
        {
            "sha": "8012c9da15ef60966ed4dab46e5e879431d9e76b",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/shlo_to_vector.cc",
            "status": "modified",
            "additions": 31,
            "deletions": 42,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -29,6 +29,8 @@ limitations under the License.\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Dialect.h\"\n+#include \"mlir/IR/Location.h\"\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n@@ -37,6 +39,7 @@ limitations under the License.\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n #include \"stablehlo/dialect/StablehloOps.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n #include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n \n namespace xla::cpu {\n@@ -47,20 +50,6 @@ namespace xla::cpu {\n \n namespace {\n \n-mlir::VectorType GetVectorType(mlir::RankedTensorType tensor_type) {\n-  return mlir::VectorType::get(tensor_type.getShape(),\n-                               tensor_type.getElementType());\n-}\n-\n-mlir::TypedValue<mlir::VectorType> CastToVector(\n-    mlir::PatternRewriter& rewriter,\n-    mlir::TypedValue<mlir::RankedTensorType> tensor_value) {\n-  auto vector_type = GetVectorType(tensor_value.getType());\n-  auto cast_op = rewriter.create<mlir::UnrealizedConversionCastOp>(\n-      tensor_value.getLoc(), vector_type, tensor_value);\n-  return mlir::cast<mlir::TypedValue<mlir::VectorType>>(cast_op.getResult(0));\n-}\n-\n mlir::AffineMapAttr GetOperandIndexingMap(\n     mlir::OpBuilder& builder, int64_t iterator_count, int64_t rank,\n     llvm::ArrayRef<int64_t> batch_dims,\n@@ -146,14 +135,10 @@ struct LowerDotGeneral : mlir::OpRewritePattern<mlir::stablehlo::DotGeneralOp> {\n     auto rhs_vector = CastToVector(rewriter, op.getRhs());\n     auto rhs_rank = rhs_vector.getType().getRank();\n \n-    auto result_vector_type = GetVectorType(op.getResult().getType());\n-    auto zero_const = rewriter.create<mlir::arith::ConstantOp>(\n-        op->getLoc(), result_vector_type.getElementType(),\n-        rewriter.getZeroAttr(result_vector_type.getElementType()));\n-    // TODO(willfroom): Ensure this is being folded into the accumilator in the\n+    // TODO(willfroom): Ensure this is being folded into the accumulator in the\n     // dot loop.\n-    mlir::Value accumulator = rewriter.create<mlir::vector::BroadcastOp>(\n-        op->getLoc(), result_vector_type, zero_const);\n+    mlir::Value accumulator =\n+        GetAccumulator(rewriter, op->getLoc(), op.getType());\n \n     mlir::stablehlo::DotDimensionNumbersAttr dimension_numbers =\n         op.getDotDimensionNumbers();\n@@ -188,15 +173,30 @@ struct LowerDotGeneral : mlir::OpRewritePattern<mlir::stablehlo::DotGeneralOp> {\n     mlir::ArrayAttr iterator_types = GetIteratorTypes(\n         rewriter, iterator_count, lhs_batch.size(), lhs_contracting.size());\n \n-    mlir::Value result_vector = rewriter.create<mlir::vector::ContractionOp>(\n+    mlir::Value result = rewriter.create<mlir::vector::ContractionOp>(\n         op->getLoc(), lhs_vector, rhs_vector, accumulator, indexing_maps,\n         iterator_types);\n \n-    rewriter.replaceOpWithNewOp<mlir::UnrealizedConversionCastOp>(\n-        op, op.getResult().getType(), result_vector);\n+    rewriter.replaceOp(op, CastToTensor(rewriter, result));\n \n     return mlir::success();\n   }\n+\n+ private:\n+  mlir::Value GetAccumulator(mlir::OpBuilder& builder, mlir::Location loc,\n+                             mlir::RankedTensorType result_type) const {\n+    mlir::Type element_type = result_type.getElementType();\n+    auto zero_const = builder.create<mlir::arith::ConstantOp>(\n+        loc, element_type, builder.getZeroAttr(element_type));\n+\n+    if (result_type.getRank() == 0) {\n+      return zero_const;\n+    }\n+\n+    auto result_vector_type = GetVectorType(result_type);\n+    return builder.create<mlir::vector::BroadcastOp>(loc, result_vector_type,\n+                                                     zero_const);\n+  }\n };\n \n struct LowerTranspose : mlir::OpRewritePattern<mlir::stablehlo::TransposeOp> {\n@@ -205,24 +205,13 @@ struct LowerTranspose : mlir::OpRewritePattern<mlir::stablehlo::TransposeOp> {\n   mlir::LogicalResult matchAndRewrite(\n       mlir::stablehlo::TransposeOp op,\n       mlir::PatternRewriter& rewriter) const override {\n-    mlir::RankedTensorType source_tensor_type = op.getOperand().getType();\n-    auto source_vector_type = mlir::VectorType::get(\n-        source_tensor_type.getShape(), source_tensor_type.getElementType());\n-    mlir::Value source_vector =\n-        rewriter\n-            .create<mlir::UnrealizedConversionCastOp>(\n-                op->getLoc(), source_vector_type, op.getOperand())\n-            .getResult(0);\n-\n-    mlir::Value dest_vector = rewriter.create<mlir::vector::TransposeOp>(\n-        op->getLoc(), source_vector, op.getPermutation());\n-\n-    mlir::RankedTensorType dest_tensor_type = op.getResult().getType();\n-    mlir::Value dest_tensor =\n-        rewriter\n-            .create<mlir::UnrealizedConversionCastOp>(\n-                op->getLoc(), dest_tensor_type, dest_vector)\n-            .getResult(0);\n+    mlir::Value source_vector = CastToVector(rewriter, op.getOperand());\n+\n+    mlir::TypedValue<mlir::VectorType> dest_vector =\n+        rewriter.create<mlir::vector::TransposeOp>(op->getLoc(), source_vector,\n+                                                   op.getPermutation());\n+\n+    mlir::Value dest_tensor = CastToTensor(rewriter, dest_vector);\n \n     rewriter.replaceAllUsesWith(op, dest_tensor);\n     return mlir::success();"
        },
        {
            "sha": "819d1ae685e24e735ff8165f767b52407164f37f",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tensor_ops_to_vector.cc",
            "status": "added",
            "additions": 103,
            "deletions": 0,
            "changes": 103,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftensor_ops_to_vector.cc?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -0,0 +1,103 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cassert>\n+#include <memory>\n+#include <utility>\n+\n+#include \"llvm/ADT/SmallVector.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"  // IWYU pragma: keep\n+#include \"mlir/Dialect/Tensor/IR/Tensor.h\"\n+#include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n+#include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/MLIRContext.h\"\n+#include \"mlir/IR/OpDefinition.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/Visitors.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/lowering_utils.h\"\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h\"\n+\n+namespace xla::cpu {\n+\n+#define GEN_PASS_DECL_TENSOROPSTOVECTORPASS\n+#define GEN_PASS_DEF_TENSOROPSTOVECTORPASS\n+#include \"xla/backends/cpu/codegen/tiled/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+struct LowerFromElements\n+    : mlir::OpRewritePattern<mlir::tensor::FromElementsOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::tensor::FromElementsOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    mlir::VectorType vector_type = GetVectorType(op.getType());\n+    mlir::Value vector_from_elements =\n+        rewriter.create<mlir::vector::FromElementsOp>(op.getLoc(), vector_type,\n+                                                      op->getOperands());\n+    rewriter.replaceOpWithNewOp<mlir::UnrealizedConversionCastOp>(\n+        op, op.getType(), vector_from_elements);\n+    return mlir::success();\n+  }\n+};\n+\n+struct LowerExtract : mlir::OpRewritePattern<mlir::tensor::ExtractOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::tensor::ExtractOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    mlir::Value vector_input = CastToVector(rewriter, op.getTensor());\n+    llvm::SmallVector<mlir::OpFoldResult> indices(op.getIndices());\n+    rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(op, vector_input,\n+                                                         indices);\n+    return mlir::success();\n+  }\n+};\n+\n+class TensorOpsToVectorPass\n+    : public impl::TensorOpsToVectorPassBase<TensorOpsToVectorPass> {\n+ public:\n+  using TensorOpsToVectorPassBase::TensorOpsToVectorPassBase;\n+\n+  void runOnOperation() override {\n+    mlir::MLIRContext* context = &getContext();\n+    mlir::RewritePatternSet patterns(context);\n+    patterns.add<LowerFromElements, LowerExtract>(context);\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n+      signalPassFailure();\n+      return;\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<mlir::Pass> CreateTensorOpsToVectorPass() {\n+  return std::make_unique<TensorOpsToVectorPass>();\n+}\n+\n+}  // namespace xla::cpu"
        },
        {
            "sha": "7437038aa450e51fcc5dc261e765f9247190a845",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/shlo_to_vector.mlir",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -22,3 +22,18 @@ func.func @dot_general(%lhs : tensor<1024x32xf32>, %rhs : tensor<32x1024xf32>) -\n }\n \n // -----\n+\n+// CHECK-DAG: #[[INPUT_MAP:.*]] = affine_map<(d0) -> (d0)>\n+// CHECK-DAG: #[[OUTPUT_MAP:.*]] = affine_map<(d0) -> ()>\n+func.func @dot_scalar_output(%lhs : tensor<1024xf32>, %rhs : tensor<1024xf32>) -> tensor<f32> {\n+  // CHECK: %[[ACCUMULATOR:.*]] = arith.constant 0.000000e+00 : f32\n+  // CHECK: %[[RESULT:.*]] = vector.contract\n+  // CHECK-SAME: {indexing_maps = [#[[INPUT_MAP]], #[[INPUT_MAP]], #[[OUTPUT_MAP]]],\n+  // CHECK-SAME: iterator_types = [\"reduction\"],\n+  // CHECK-SAME: kind = #vector.kind<add>}\n+  // CHECK-SAME: %[[ACCUMULATOR]] : vector<1024xf32>, vector<1024xf32> into f32\n+  // CHECK: %[[RESULT_TENSOR:.*]] = tensor.from_elements %[[RESULT]] : tensor<f32>\n+  %result = stablehlo.dot_general %lhs, %rhs, contracting_dims = [0] x [0] : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<f32>\n+  // CHECK: return %[[RESULT_TENSOR]] : tensor<f32>\n+  return %result : tensor<f32>\n+}"
        },
        {
            "sha": "17ab409e4deaca8d28a0b5cf9bc2ef9cbe581d39",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/tensor_ops_to_vector.mlir",
            "status": "added",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Ftensor_ops_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/168eb2c36a811113bd136edcf77bbadc743bbe06/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Ftensor_ops_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Ftensor_ops_to_vector.mlir?ref=168eb2c36a811113bd136edcf77bbadc743bbe06",
            "patch": "@@ -0,0 +1,15 @@\n+// RUN: emitters_opt %s -xtile-cpu-tensor-ops-to-vector -split-input-file | FileCheck %s\n+\n+func.func @from_elements(%input : f32) -> tensor<f32> {\n+  // CHECK: vector.from_elements %{{.*}} : vector<f32>\n+  %result = tensor.from_elements %input : tensor<f32>\n+  return %result : tensor<f32>\n+}\n+\n+// -----\n+\n+func.func @extract(%input : tensor<f32>) -> f32 {\n+  // CHECK: vector.extract %{{.*}}[] : f32 from vector<f32>\n+  %result = tensor.extract %input[] : tensor<f32>\n+  return %result : f32\n+}"
        }
    ],
    "stats": {
        "total": 389,
        "additions": 345,
        "deletions": 44
    }
}