{
    "author": "ezhulenev",
    "message": "[xla] Migrate to PjRtFuture<>::MakePromise() API\n\nSome of the Schedule() APIs require copyable std::function parameter, in such cases wrap move-only promise into std::shared_ptr\n\nPiperOrigin-RevId: 805666259",
    "sha": "91df08ef8dc151f4006c40af081159becb2c9d67",
    "files": [
        {
            "sha": "1cc188ab6d73f97629e8cf7a85d735d501f1e936",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/executable.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fexecutable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fexecutable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fexecutable.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -376,15 +376,16 @@ LoadedExecutable::LoadedExecutable(\n   // eagerly schedule this fetch since, in some implementations, it may take a\n   // long time for sharding information to be available.\n \n-  auto promise = Future<std::shared_ptr<Metadata>>::CreatePromise();\n-  metadata_future_ = Future<std::shared_ptr<Metadata>>(promise);\n+  auto [promise, future] = Future<std::shared_ptr<Metadata>>::MakePromise();\n+  metadata_future_ = std::move(future);\n \n   auto req = std::make_unique<LoadedExecutableMetadataRequest>();\n   req->set_loaded_executable_handle(handle_);\n \n-  auto on_done = [promise](absl::StatusOr<\n-                           std::shared_ptr<LoadedExecutableMetadataResponse>>\n-                               response) mutable {\n+  auto on_done = [promise = std::move(promise)](\n+                     absl::StatusOr<\n+                         std::shared_ptr<LoadedExecutableMetadataResponse>>\n+                         response) mutable {\n     if (!response.ok()) {\n       LOG(ERROR) << \"LoadedExecutableMetadata: Got \" << response.status();\n       promise.Set(response.status());"
        },
        {
            "sha": "3275f11d56f5409e5073222e3a91fadba8226a55",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/grpc_client.cc",
            "status": "modified",
            "additions": 33,
            "deletions": 35,
            "changes": 68,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -66,42 +66,40 @@ absl::StatusOr<std::unique_ptr<Client>> AttemptConnection(\n     absl::string_view server_address, int attempt_no,\n     const ClientConnectionOptions& options) {\n   std::unique_ptr<RpcHelper> rpc_helper;\n-  auto init_response_promise =\n-      Future<std::shared_ptr<InitResponse>>::CreatePromise();\n+  auto [init_response_promise, init_response_future] =\n+      Future<std::shared_ptr<InitResponse>>::MakePromise();\n \n   // TODO(b/266635130): Move gRPC stub creation to be outside of `Client` so\n   // that we can pass mock `ClientSession` to the client.\n   auto control_path_stub = CreateGrpcStub(server_address);\n \n-  auto session_disconnect_cb =\n-      [init_response =\n-           Future<std::shared_ptr<InitResponse>>(init_response_promise),\n-       on_disconnect = options.on_disconnect,\n-       attempt_no](absl::Status s) mutable {\n-        // If the `rpc_helper->Init().OnReady(cb)` statement below has returned,\n-        // the callback cb in that statement (which sets `init_response`) is\n-        // guaranteed by `GrpcClientSession::Create()` to be called before\n-        // `session_disconnect_cb`.\n-        // TODO(madthanu): The above statement is false (even if we wanted to,\n-        // we cannot meaningfully enforce or document the guarantee of\n-        // the returned Future's OnReady being called before another callback),\n-        // although the exact way init_response_promise is set below makes it\n-        // work most of the time.\n-        if (init_response.IsReady() && init_response.Await().ok()) {\n-          // If the init RPC has already completed successfully, we have\n-          // already or will be returning OK from the `AttemptConnection` call.\n-          LOG(WARNING) << \"IFRT proxy server disconnected: \" << s\n-                       << \"; Stack trace: \" << tsl::CurrentStackTrace();\n-          if (on_disconnect != nullptr) {\n-            on_disconnect(s);\n-          }\n-        } else {\n-          // Otherwise, we are going to return an error from\n-          // `AttemptConnection`. So do not invoke `on_disconnect`.\n-          LOG(INFO) << \"GrpcClientSession attempt \" << attempt_no\n-                    << \" failed: \" << s;\n-        }\n-      };\n+  auto session_disconnect_cb = [init_response = init_response_future,\n+                                on_disconnect = options.on_disconnect,\n+                                attempt_no](absl::Status s) mutable {\n+    // If the `rpc_helper->Init().OnReady(cb)` statement below has returned,\n+    // the callback cb in that statement (which sets `init_response`) is\n+    // guaranteed by `GrpcClientSession::Create()` to be called before\n+    // `session_disconnect_cb`.\n+    // TODO(madthanu): The above statement is false (even if we wanted to,\n+    // we cannot meaningfully enforce or document the guarantee of\n+    // the returned Future's OnReady being called before another callback),\n+    // although the exact way init_response_promise is set below makes it\n+    // work most of the time.\n+    if (init_response.IsReady() && init_response.Await().ok()) {\n+      // If the init RPC has already completed successfully, we have\n+      // already or will be returning OK from the `AttemptConnection` call.\n+      LOG(WARNING) << \"IFRT proxy server disconnected: \" << s\n+                   << \"; Stack trace: \" << tsl::CurrentStackTrace();\n+      if (on_disconnect != nullptr) {\n+        on_disconnect(s);\n+      }\n+    } else {\n+      // Otherwise, we are going to return an error from\n+      // `AttemptConnection`. So do not invoke `on_disconnect`.\n+      LOG(INFO) << \"GrpcClientSession attempt \" << attempt_no\n+                << \" failed: \" << s;\n+    }\n+  };\n \n   GrpcIfrtSessionMetadata metadata;\n   {\n@@ -143,11 +141,11 @@ absl::StatusOr<std::unique_ptr<Client>> AttemptConnection(\n   // not, instead of combining it with the Request that will fetch device\n   // information (which can take a while, depending on the IFRT backend).\n   rpc_helper->Init(std::make_unique<InitRequest>())\n-      .OnReady([&](auto resp) mutable { init_response_promise.Set(resp); });\n+      .OnReady([promise = std::move(init_response_promise)](auto resp) mutable {\n+        promise.Set(resp);\n+      });\n \n-  TF_ASSIGN_OR_RETURN(\n-      auto init_response,\n-      Future<std::shared_ptr<InitResponse>>(init_response_promise).Await());\n+  TF_ASSIGN_OR_RETURN(auto init_response, init_response_future.Await());\n \n   bool reuse_control_path_stub_for_data_path =\n       GetGlobalClientFlags()->synchronous_host_buffer_store ||"
        },
        {
            "sha": "0314692c215eb609e2ff743fc31caa27158a34e8",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/grpc_client_session.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client_session.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client_session.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_client_session.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -124,22 +124,25 @@ GrpcClientSession::GrpcClientSession(\n \n Future<std::shared_ptr<IfrtResponse>> GrpcClientSession::Enqueue(\n     std::unique_ptr<IfrtRequest> request) {\n-  auto promise = Future<std::shared_ptr<IfrtResponse>>::CreatePromise();\n+  auto [promise, future] = Future<std::shared_ptr<IfrtResponse>>::MakePromise();\n+  auto shared_promise = std::make_shared<decltype(promise)>(std::move(promise));\n   absl::Status status = Enqueue(\n       std::move(request),\n-      [promise, queue = user_futures_work_queue_.get()](\n+      [promise = std::move(shared_promise),\n+       queue = user_futures_work_queue_.get()](\n           absl::StatusOr<std::shared_ptr<IfrtResponse>> response) mutable {\n         queue->Schedule([promise = std::move(promise),\n                          response = std::move(response)]() mutable -> void {\n-          promise.Set(std::move(response));\n+          promise->Set(std::move(response));\n         });\n       });\n   if (!status.ok()) {\n-    user_futures_work_queue_->Schedule([promise, status]() mutable -> void {\n-      promise.Set(std::move(status));\n-    });\n+    user_futures_work_queue_->Schedule(\n+        [promise = std::move(shared_promise), status]() mutable -> void {\n+          promise->Set(std::move(status));\n+        });\n   }\n-  return Future<std::shared_ptr<IfrtResponse>>(std::move(promise));\n+  return std::move(future);\n }\n \n absl::Status GrpcClientSession::Enqueue(std::unique_ptr<IfrtRequest> req,"
        },
        {
            "sha": "78caec250e181b4ae99128224e0ac49fc93c2b5f",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/grpc_host_buffer.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_host_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_host_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Fgrpc_host_buffer.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -28,7 +28,6 @@\n #include \"absl/strings/string_view.h\"\n #include \"grpcpp/client_context.h\"\n #include \"grpcpp/support/client_callback.h\"\n-#include \"grpcpp/support/status.h\"\n #include \"grpcpp/support/sync_stream.h\"\n #include \"xla/pjrt/distributed/util.h\"\n #include \"xla/pjrt/semaphore.h\"\n@@ -195,14 +194,17 @@ Future<> GrpcClientHostBufferStore::Store(uint64_t handle,\n }\n \n Future<absl::Cord> GrpcClientHostBufferStore::Lookup(uint64_t handle) {\n-  auto promise = Future<absl::Cord>::CreatePromise();\n+  auto [promise, future] = Future<absl::Cord>::MakePromise();\n \n   XFlowHelper flow(\"GrpcClientHostBufferStore::Lookup\");\n   flow.InstantActivity<XFlowHelper::kSend>();\n \n   auto reservation = ScopedAcquireSemaphore(lookup_throttler_);\n   work_queue_->Schedule([this, reservation = std::move(reservation), handle,\n-                         promise, flow]() mutable -> void {\n+                         promise =\n+                             std::make_shared<Future<absl::Cord>::Promise>(\n+                                 std::move(promise)),\n+                         flow]() mutable -> void {\n     auto span = flow.Span<XFlowHelper::kRecv>();\n     GrpcHostBufferLookupRequest request;\n     request.set_handle(handle);\n@@ -223,15 +225,15 @@ Future<absl::Cord> GrpcClientHostBufferStore::Lookup(uint64_t handle) {\n \n     absl::Status status = xla::FromGrpcStatus(stream->Finish());\n     if (status.ok()) {\n-      promise.Set(std::move(data));\n+      promise->Set(std::move(data));\n     } else {\n-      promise.Set(status);\n+      promise->Set(status);\n     }\n     VLOG(3) << \"GrpcClientHostBufferStore::Lookup done \"\n             << request.ShortDebugString();\n   });\n \n-  return Future<absl::Cord>(promise);\n+  return std::move(future);\n }\n \n Future<> GrpcClientHostBufferStore::Delete(uint64_t handle) {"
        },
        {
            "sha": "ede447813e7020bb51fcf18b86c09de7dc1c4e7b",
            "filename": "third_party/xla/xla/python/ifrt_proxy/client/rpc_helper.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fclient%2Frpc_helper.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -251,8 +251,9 @@ Future<std::shared_ptr<Resp>> DoRpc(RpcHelper::Batcher* batcher,\n   XFlowHelper x_flow_helper(profiling_name);\n   auto traceme = x_flow_helper.Span<XFlowHelper::kSend>();\n \n-  auto promise = Future<std::shared_ptr<Resp>>::CreatePromise();\n-  auto on_ready = [promise, has_resp, get_resp, profiling_name, x_flow_helper](\n+  auto [promise, future] = Future<std::shared_ptr<Resp>>::MakePromise();\n+  auto on_ready = [promise = std::move(promise), has_resp, get_resp,\n+                   profiling_name, x_flow_helper](\n                       absl::StatusOr<std::shared_ptr<IfrtResponse>> r) mutable {\n     if (!r.ok()) {\n       VLOG(3) << profiling_name << \" response: \" << r.status();\n@@ -307,9 +308,9 @@ Future<std::shared_ptr<Resp>> DoRpc(RpcHelper::Batcher* batcher,\n     promise.Set(std::move(result));\n   };\n   VLOG(3) << ifrt_req->ShortDebugString();\n-  batcher->Immediate(std::move(ifrt_req)).OnReady(on_ready);\n+  batcher->Immediate(std::move(ifrt_req)).OnReady(std::move(on_ready));\n \n-  return Future<std::shared_ptr<Resp>>(promise);\n+  return std::move(future);\n }\n \n #define RPC(METHOD, PROPERTY)                                                 \\"
        },
        {
            "sha": "bbe1c476adedbef7bd1bbc19c7bc027d8f7d3454",
            "filename": "third_party/xla/xla/python/ifrt_proxy/server/ifrt_backend.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 22,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/91df08ef8dc151f4006c40af081159becb2c9d67/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpython%2Fifrt_proxy%2Fserver%2Fifrt_backend.cc?ref=91df08ef8dc151f4006c40af081159becb2c9d67",
            "patch": "@@ -359,20 +359,19 @@ class IfrtBackend::InOrderRequestsProcessor {\n \n   Future<Response> Push(std::unique_ptr<IfrtRequest> request) {\n     VLOG(3) << \"Enqueuing \" << request->ShortDebugString();\n-    auto promise = Future<Response>::CreatePromise();\n-    Future<Response> result(promise);\n+    auto [promise, future] = Future<Response>::MakePromise();\n     absl::MutexLock l(&mu_);\n     if (shutdown_msg_.has_value()) {\n       promise.Set(absl::InternalError(absl::StrCat(\n           \"InOrderRequestsProcessor already stopped: \", *shutdown_msg_)));\n-      return result;\n+      return std::move(future);\n     }\n     absl::string_view req_name = GetRequestName(request.get());\n     Entry entry{/*req=*/std::move(request), /*promise=*/std::move(promise),\n                 XFlowHelper(req_name)};\n     entry.xflow.InstantActivity<XFlowHelper::kSend>();\n     entries_.push_back(std::move(entry));\n-    return result;\n+    return std::move(future);\n   }\n \n   ~InOrderRequestsProcessor() {\n@@ -667,9 +666,12 @@ Future<BackendInterface::Response> IfrtBackend::AsyncExecute(\n     absl::MutexLock lock(&in_flight_count_mutex_);\n     ++in_flight_count_;\n   }\n-  auto promise = Future<Response>::CreatePromise();\n-  auto f = [this, promise, handle_fn = std::move(handle_fn)]() mutable {\n-    promise.Set(handle_fn());\n+  auto [promise, future] = Future<Response>::MakePromise();\n+  auto f = [this,\n+            promise =\n+                std::make_shared<Future<Response>::Promise>(std::move(promise)),\n+            handle_fn = std::move(handle_fn)]() mutable {\n+    promise->Set(handle_fn());\n     {\n       absl::MutexLock lock(&in_flight_count_mutex_);\n       --in_flight_count_;\n@@ -680,7 +682,7 @@ Future<BackendInterface::Response> IfrtBackend::AsyncExecute(\n   } else {\n     tsl::Env::Default()->SchedClosure(std::move(f));\n   }\n-  return Future<Response>(std::move(promise));\n+  return std::move(future);\n }\n \n /////////////////////////////////////////////////////////////////////////////\n@@ -784,11 +786,13 @@ Future<BackendInterface::Response> IfrtBackend::HandleCheckFutureRequest(\n     futures_.erase(it);\n   }\n \n-  auto promise = Future<BackendInterface::Response>::CreatePromise();\n+  auto [promise, resp_future] =\n+      Future<BackendInterface::Response>::MakePromise();\n   // With PjRtFuture, the `Future` needs to be owned by one or more owners until\n   // `OnReady()`'s lambda gets executed. So, capture a copy of `future` in the\n   // lambda, making the lambda itself an owner of `future`.\n-  future.OnReady([op_id = request->request_metadata().op_id(), promise,\n+  future.OnReady([op_id = request->request_metadata().op_id(),\n+                  promise = std::move(promise),\n                   hold = future](absl::Status status) mutable {\n     if (!status.ok()) {\n       promise.Set(std::move(status));\n@@ -799,7 +803,7 @@ Future<BackendInterface::Response> IfrtBackend::HandleCheckFutureRequest(\n     promise.Set(std::move(ifrt_resp));\n   });\n \n-  return Future<BackendInterface::Response>(std::move(promise));\n+  return std::move(resp_future);\n }\n \n Future<BackendInterface::Response> IfrtBackend::HandleCheckValueReadyRequest(\n@@ -817,10 +821,8 @@ Future<BackendInterface::Response> IfrtBackend::HandleCheckValueReadyRequest(\n     values.push_back(*std::move(array));\n   }\n \n-  auto ifrt_response_promise =\n-      Future<BackendInterface::Response>::CreatePromise();\n-  Future<BackendInterface::Response> ifrt_response_future(\n-      ifrt_response_promise);\n+  auto [ifrt_response_promise, ifrt_response_future] =\n+      Future<BackendInterface::Response>::MakePromise();\n \n   client_->GetReadyFuture(values).OnReady(\n       [op_id = request->request_metadata().op_id(),\n@@ -834,7 +836,7 @@ Future<BackendInterface::Response> IfrtBackend::HandleCheckValueReadyRequest(\n         ifrt_response->mutable_check_value_ready_response();\n         promise.Set(std::move(ifrt_response));\n       });\n-  return ifrt_response_future;\n+  return std::move(ifrt_response_future);\n }\n \n absl::StatusOr<BackendInterface::Response>\n@@ -1103,8 +1105,8 @@ IfrtBackend::HandleCopyToStringHostBufferRequest(\n       host_buffer->data(), /*byte_strides=*/std::nullopt,\n       ArrayCopySemantics::kAlwaysCopy);\n \n-  auto resp_promise = Future<BackendInterface::Response>::CreatePromise();\n-  Future<BackendInterface::Response> resp_future(resp_promise);\n+  auto [resp_promise, resp_future] =\n+      Future<BackendInterface::Response>::MakePromise();\n \n   // Make the response proto when the copy is done.\n   auto response_maker =\n@@ -1130,7 +1132,7 @@ IfrtBackend::HandleCopyToStringHostBufferRequest(\n     promise.Set(response_maker(status));\n   });\n \n-  return resp_future;\n+  return std::move(resp_future);\n }\n \n Future<BackendInterface::Response> IfrtBackend::HandleCopyToHostBufferRequest(\n@@ -1180,8 +1182,8 @@ Future<BackendInterface::Response> IfrtBackend::HandleCopyToHostBufferRequest(\n       (*array)->CopyToHostBuffer(mem_region->zeroth_element(), byte_strides,\n                                  ArrayCopySemantics::kAlwaysCopy);\n \n-  auto resp_promise = Future<BackendInterface::Response>::CreatePromise();\n-  Future<BackendInterface::Response> resp_future(resp_promise);\n+  auto [resp_promise, resp_future] =\n+      Future<BackendInterface::Response>::MakePromise();\n   auto on_ready = [this, op_id = request->request_metadata().op_id(),\n                    host_buffer = std::move(host_buffer),\n                    host_buffer_handle = copy_to_host.host_buffer_handle()](\n@@ -1200,7 +1202,7 @@ Future<BackendInterface::Response> IfrtBackend::HandleCopyToHostBufferRequest(\n       [promise = std::move(resp_promise), on_ready = std::move(on_ready)](\n           absl::Status status) mutable { promise.Set(on_ready(status)); });\n \n-  return resp_future;\n+  return std::move(resp_future);\n }\n \n absl::StatusOr<BackendInterface::Response>"
        }
    ],
    "stats": {
        "total": 165,
        "additions": 86,
        "deletions": 79
    }
}