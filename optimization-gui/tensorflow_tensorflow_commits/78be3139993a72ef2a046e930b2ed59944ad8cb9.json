{
    "author": "chsigg",
    "message": "Streamline implementation of `convert-unsupported-types` pass.\n\nPiperOrigin-RevId: 805790968",
    "sha": "78be3139993a72ef2a046e930b2ed59944ad8cb9",
    "files": [
        {
            "sha": "ab4158dc8d59b7ccf6a7c900472ae41b08ba441e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_convert_unsupported_types.mlir",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78be3139993a72ef2a046e930b2ed59944ad8cb9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78be3139993a72ef2a046e930b2ed59944ad8cb9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_convert_unsupported_types.mlir?ref=78be3139993a72ef2a046e930b2ed59944ad8cb9",
            "patch": "@@ -1,4 +1,4 @@\n-// RUN: xla-opt --split-input-file --convert-unsupported-types --canonicalize  %s | FileCheck %s\n+// RUN: xla-opt --convert-unsupported-types %s | FileCheck %s\n \n module {\n   // CHECK:   func.func @triton_fn(%arg0: !tt.ptr<f8E4M3FN>, %arg1: !tt.ptr<i8>, %arg2: !tt.ptr<f8E4M3FN>, %arg3: !tt.ptr<i8>, %arg4: !tt.ptr<f32>) {"
        },
        {
            "sha": "3a1dc77b8ecee1f8ec4d1fee649e2ace472b0cf1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_convert_unsupported_types.cc",
            "status": "modified",
            "additions": 43,
            "deletions": 90,
            "changes": 133,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78be3139993a72ef2a046e930b2ed59944ad8cb9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78be3139993a72ef2a046e930b2ed59944ad8cb9/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_convert_unsupported_types.cc?ref=78be3139993a72ef2a046e930b2ed59944ad8cb9",
            "patch": "@@ -12,7 +12,6 @@ limitations under the License.\n ==============================================================================*/\n \n #include <memory>\n-#include <optional>\n #include <utility>\n \n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n@@ -23,7 +22,6 @@ limitations under the License.\n #include \"mlir/IR/BuiltinTypes.h\"\n #include \"mlir/IR/PatternMatch.h\"\n #include \"mlir/IR/Value.h\"\n-#include \"mlir/IR/ValueRange.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"mlir/Support/LLVM.h\"\n #include \"mlir/Support/LogicalResult.h\"\n@@ -37,85 +35,20 @@ namespace mlir::triton::xla {\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n \n namespace {\n-class UnsupportedTypesConverter : public TypeConverter {\n- public:\n-  UnsupportedTypesConverter() : TypeConverter() {\n-    // Fallback to the no conversion for all other types.\n-    addConversion([](Type type) -> std::optional<Type> { return type; });\n-\n-    // Convert F8E8M0FNUType to i8. This is a workaround for the fact that\n-    // Triton doesn't support F8E8M0FNUType natively.\n-    addConversion([](Float8E8M0FNUType type) -> std::optional<Type> {\n-      return IntegerType::get(type.getContext(), 8);\n-    });\n-\n-    // Helper conversions for the nontrivial types.\n-    addConversion([this](Type type) -> std::optional<Type> {\n-      if (auto shaped_type = dyn_cast<ShapedType>(type)) {\n-        Type new_type = convertType(shaped_type.getElementType());\n-        return shaped_type.clone(new_type);\n-      }\n-      return std::nullopt;\n-    });\n-    addConversion([this](Type type) -> std::optional<Type> {\n-      if (auto pointer_type = dyn_cast<triton::PointerType>(type)) {\n-        Type new_type = convertType(pointer_type.getPointeeType());\n-        return triton::PointerType::get(new_type,\n-                                        pointer_type.getAddressSpace());\n-      }\n-      return std::nullopt;\n-    });\n-    addConversion([this](Type type) -> std::optional<Type> {\n-      if (auto func_type = dyn_cast<FunctionType>(type)) {\n-        SmallVector<Type> new_inputs = convertTypes(func_type.getInputs());\n-        SmallVector<Type> new_results = convertTypes(func_type.getResults());\n-        if (new_inputs != func_type.getInputs() ||\n-            new_results != func_type.getResults()) {\n-          return FunctionType::get(func_type.getContext(), new_inputs,\n-                                   new_results);\n-        }\n-      }\n-      return std::nullopt;\n-    });\n-  }\n-\n-  // Helper method to convert a range of types.\n-  SmallVector<Type> convertTypes(ArrayRef<Type> types) {\n-    SmallVector<Type> new_types;\n-    for (auto type : types) {\n-      new_types.push_back(convertType(type));\n-    }\n-    return new_types;\n-  }\n-};\n \n-struct RewriteF8ToI8ConversionPattern final : ConversionPattern {\n-  RewriteF8ToI8ConversionPattern(const TypeConverter& converter,\n-                                 MLIRContext* ctx)\n-      : ConversionPattern::ConversionPattern(\n-            converter, Pattern::MatchAnyOpTypeTag(), 1, ctx) {}\n+template <typename OpType>\n+struct GenericOpConversionPattern final : public OpConversionPattern<OpType> {\n+  using OpConversionPattern<OpType>::OpConversionPattern;\n \n   LogicalResult matchAndRewrite(\n-      Operation* op, ArrayRef<Value> operands,\n+      OpType op, typename OpType::Adaptor adaptor,\n       ConversionPatternRewriter& rewriter) const override {\n-    if (getTypeConverter()->isLegal(op)) {\n-      return failure();\n+    Operation* replacement = rewriter.clone(*op);\n+    replacement->setOperands(adaptor.getOperands());\n+    const TypeConverter* converter = this->getTypeConverter();\n+    for (auto result : replacement->getResults()) {\n+      result.setType(converter->convertType(result.getType()));\n     }\n-\n-    if (!isa<ExtractOp, InsertOp, arith::BitcastOp>(op)) {\n-      return failure();\n-    }\n-\n-    const TypeConverter* converter = getTypeConverter();\n-    SmallVector<Type> result_types;\n-    if (failed(converter->convertTypes(op->getResultTypes(), result_types))) {\n-      // Note to anyone looking for this error message: this is a \"can't\n-      // happen\". If you're seeing it, there's a bug.\n-      return op->emitOpError(\"The op is not legal but type conversion failed.\");\n-    }\n-    Operation* replacement = rewriter.create(\n-        op->getLoc(), op->getName().getIdentifier(), operands, result_types,\n-        op->getAttrs(), op->getSuccessors(), /*regions=*/{});\n     rewriter.replaceOp(op, replacement);\n     return success();\n   }\n@@ -129,26 +62,46 @@ class TritonXLAConvertUnsupportedTypesPass\n \n  private:\n   void runOnOperation() override {\n-    auto* ctx = &getContext();\n-    auto module = getOperation();\n-    UnsupportedTypesConverter converter;\n+    TypeConverter converter;\n+    converter.addConversion([](Type type) { return type; });\n+    converter.addConversion([&](Float8E8M0FNUType type) {\n+      return IntegerType::get(type.getContext(), 8);\n+    });\n+    converter.addConversion([&](ShapedType type) {\n+      return type.clone(converter.convertType(type.getElementType()));\n+    });\n \n-    ConversionTarget target(*ctx);\n-    target.markUnknownOpDynamicallyLegal([&](Operation* op) {\n-      if (auto func_op = dyn_cast<func::FuncOp>(op)) {\n-        return converter.isLegal(func_op.getFunctionType());\n+    converter.addConversion([&](triton::PointerType type) {\n+      return triton::PointerType::get(\n+          converter.convertType(type.getPointeeType()), type.getAddressSpace());\n+    });\n+    converter.addConversion([&](FunctionType type) -> Type {\n+      SmallVector<Type> new_inputs, new_results;\n+      if (failed(converter.convertTypes(type.getInputs(), new_inputs)) ||\n+          failed(converter.convertTypes(type.getResults(), new_results))) {\n+        return nullptr;\n       }\n-      return converter.isLegal(op);\n+      return type.clone(new_inputs, new_results);\n     });\n \n+    auto* ctx = &getContext();\n+    ConversionTarget target(*ctx);\n+    target.addDynamicallyLegalOp<func::FuncOp>([&](func::FuncOp op) {\n+      return converter.isSignatureLegal(op.getFunctionType()) &&\n+             converter.isLegal(&op.getBody());\n+    });\n+    target.markUnknownOpDynamicallyLegal(\n+        [&](Operation* op) { return converter.isLegal(op); });\n+\n     RewritePatternSet patterns(ctx);\n-    patterns.add<RewriteF8ToI8ConversionPattern>(converter,\n-                                                 patterns.getContext());\n+    patterns.add<GenericOpConversionPattern<ExtractOp>,\n+                 GenericOpConversionPattern<InsertOp>,\n+                 GenericOpConversionPattern<arith::BitcastOp>>(converter, ctx);\n     scf::populateSCFStructuralTypeConversions(converter, patterns);\n-    populateFunctionOpInterfaceTypeConversionPattern<mlir::func::FuncOp>(\n-        patterns, converter);\n-\n-    if (failed(applyPartialConversion(module, target, std::move(patterns)))) {\n+    populateFunctionOpInterfaceTypeConversionPattern<func::FuncOp>(patterns,\n+                                                                   converter);\n+    if (failed(applyPartialConversion(getOperation(), target,\n+                                      std::move(patterns)))) {\n       return signalPassFailure();\n     }\n   }"
        }
    ],
    "stats": {
        "total": 135,
        "additions": 44,
        "deletions": 91
    }
}