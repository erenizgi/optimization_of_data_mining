{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Add lowering for StableHLO DotGeneral.\n\nPiperOrigin-RevId: 820214413",
    "sha": "78e02816b874b308a217d3fddd611034014c7fcf",
    "files": [
        {
            "sha": "477a06167279d8fd7b77f2059fa19044dc2c8750",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/tiled_kernel_test.py",
            "status": "modified",
            "additions": 71,
            "deletions": 3,
            "changes": 74,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftiled_kernel_test.py?ref=78e02816b874b308a217d3fddd611034014c7fcf",
            "patch": "@@ -33,6 +33,7 @@ def compare_kernel(\n     output_shape: tuple[int, ...],\n     dtype,\n     expected_output: Callable[[np.ndarray, ...], np.ndarray],\n+    exact: bool = True,\n ) -> None:\n   mlir_emitter = cpu_testlib.MlirTestKernelEmitter(\n       ir, kernel_name, (num_workgroups, 1, 1)\n@@ -49,9 +50,14 @@ def compare_kernel(\n   output_tensor = create_literal(np.zeros(output_shape, dtype=dtype))\n   runner.call(input_tensors + [output_tensor])\n \n-  np.testing.assert_array_equal(\n-      np.asarray(output_tensor), expected_output(*inputs)\n-  )\n+  if exact:\n+    np.testing.assert_array_equal(\n+        np.asarray(output_tensor), expected_output(*inputs)\n+    )\n+  else:\n+    np.testing.assert_array_almost_equal(\n+        np.asarray(output_tensor), expected_output(*inputs)\n+    )\n \n \n class XtileLoweringTest(absltest.TestCase):\n@@ -139,6 +145,68 @@ def test_add_tranpose(self):\n         lambda arg: arg + arg.transpose(),\n     )\n \n+  def test_dot_single_tile(self):\n+    ir = \"\"\"\n+      module @dot_single_tile {\n+        xtile.entry_func @dot_single_tile(\n+            %lhs: memref<8x16xf32>,\n+            %rhs: memref<16x8xf32>,\n+            %output: memref<8x8xf32>,\n+            %tile_id: index) attributes {xtile.tiling_info = #xtile.tiling_info<tile_count:1, tiles_per_workgroup:1>} {\n+          %offset = arith.constant 0 : index\n+          %lhs_tile = xtile.extract %lhs[%offset, %offset][8, 16][1, 1] : memref<8x16xf32> -> tensor<8x16xf32>\n+          %rhs_tile = xtile.extract %rhs[%offset, %offset][16, 8][1, 1] : memref<16x8xf32> -> tensor<16x8xf32>\n+          %result = stablehlo.dot_general %lhs_tile, %rhs_tile, contracting_dims = [1] x [0] : (tensor<8x16xf32>, tensor<16x8xf32>) -> tensor<8x8xf32>\n+          xtile.insert %result into %output[%offset, %offset][8, 8][1, 1] : tensor<8x8xf32> -> memref<8x8xf32>\n+          xtile.return\n+        }\n+      }\n+    \"\"\"\n+\n+    compare_kernel(\n+        ir,\n+        \"dot_single_tile\",\n+        1,\n+        [(8, 16), (16, 8)],\n+        (8, 8),\n+        np.float32,\n+        lambda lhs, rhs: lhs @ rhs,\n+        False,\n+    )\n+\n+  def test_dot_fusion_single_tile(self):\n+    ir = \"\"\"\n+      module @dot_fusion_single_tile {\n+        xtile.entry_func @dot_fusion_single_tile(\n+            %lhs_0: memref<8x16xf32>,\n+            %lhs_1: memref<8x16xf32>,\n+            %rhs: memref<16x1xf32>,\n+            %output: memref<8x1xf32>,\n+            %tile_id: index) attributes {xtile.tiling_info = #xtile.tiling_info<tile_count:1, tiles_per_workgroup:1>} {\n+          %offset = arith.constant 0 : index\n+          %lhs_0_tile = xtile.extract %lhs_0[%offset, %offset][8, 16][1, 1] : memref<8x16xf32> -> tensor<8x16xf32>\n+          %lhs_1_tile = xtile.extract %lhs_1[%offset, %offset][8, 16][1, 1] : memref<8x16xf32> -> tensor<8x16xf32>\n+          %add_lhs = arith.addf %lhs_0_tile, %lhs_1_tile : tensor<8x16xf32>\n+          %rhs_tile = xtile.extract %rhs[%offset, %offset][16, 1][1, 1] : memref<16x1xf32> -> tensor<16xf32>\n+          %result = stablehlo.dot_general %add_lhs, %rhs_tile, contracting_dims = [1] x [0] : (tensor<8x16xf32>, tensor<16xf32>) -> tensor<8xf32>\n+          %tanh_result = math.tanh %result : tensor<8xf32>\n+          xtile.insert %tanh_result into %output[%offset, %offset][8, 1][1, 1] : tensor<8xf32> -> memref<8x1xf32>\n+          xtile.return\n+        }\n+      }\n+    \"\"\"\n+\n+    compare_kernel(\n+        ir,\n+        \"dot_fusion_single_tile\",\n+        1,\n+        [(8, 16), (8, 16), (16, 1)],\n+        (8, 1),\n+        np.float32,\n+        lambda lhs_0, lhs_1, rhs: np.tanh((lhs_0 + lhs_1) @ rhs),\n+        False,\n+    )\n+\n \n if __name__ == \"__main__\":\n   absltest.main()"
        },
        {
            "sha": "f5091aa3bc5e6e72caa63207792120257d145fcb",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/shlo_to_vector.cc",
            "status": "modified",
            "additions": 158,
            "deletions": 1,
            "changes": 159,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Fshlo_to_vector.cc?ref=78e02816b874b308a217d3fddd611034014c7fcf",
            "patch": "@@ -14,13 +14,18 @@ limitations under the License.\n ==============================================================================*/\n \n #include <cassert>\n+#include <cstdint>\n #include <memory>\n #include <utility>\n \n+#include \"llvm/ADT/ArrayRef.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n #include \"mlir/Dialect/Func/IR/FuncOps.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"  // IWYU pragma: keep\n #include \"mlir/Dialect/Vector/IR/VectorOps.h\"\n #include \"mlir/IR/AffineExpr.h\"\n+#include \"mlir/IR/Attributes.h\"\n+#include \"mlir/IR/Builders.h\"\n #include \"mlir/IR/BuiltinAttributes.h\"\n #include \"mlir/IR/BuiltinOps.h\"\n #include \"mlir/IR/BuiltinTypes.h\"\n@@ -42,6 +47,158 @@ namespace xla::cpu {\n \n namespace {\n \n+mlir::VectorType GetVectorType(mlir::RankedTensorType tensor_type) {\n+  return mlir::VectorType::get(tensor_type.getShape(),\n+                               tensor_type.getElementType());\n+}\n+\n+mlir::TypedValue<mlir::VectorType> CastToVector(\n+    mlir::PatternRewriter& rewriter,\n+    mlir::TypedValue<mlir::RankedTensorType> tensor_value) {\n+  auto vector_type = GetVectorType(tensor_value.getType());\n+  auto cast_op = rewriter.create<mlir::UnrealizedConversionCastOp>(\n+      tensor_value.getLoc(), vector_type, tensor_value);\n+  return mlir::cast<mlir::TypedValue<mlir::VectorType>>(cast_op.getResult(0));\n+}\n+\n+mlir::AffineMapAttr GetOperandIndexingMap(\n+    mlir::OpBuilder& builder, int64_t iterator_count, int64_t rank,\n+    llvm::ArrayRef<int64_t> batch_dims,\n+    llvm::ArrayRef<int64_t> contracting_dims, int64_t free_dim_offset) {\n+  llvm::SmallVector<unsigned> targets(rank, -1);\n+  unsigned idx = 0;\n+  for (int64_t dim : batch_dims) {\n+    targets[dim] = idx++;\n+  }\n+  for (int64_t dim : contracting_dims) {\n+    targets[dim] = idx++;\n+  }\n+  for (unsigned& target : targets) {\n+    if (target == -1) {\n+      target = free_dim_offset + idx++;\n+    }\n+  }\n+  auto affine_map = mlir::AffineMap::getMultiDimMapWithTargets(\n+      iterator_count, targets, builder.getContext());\n+\n+  return mlir::AffineMapAttr::get(affine_map);\n+}\n+\n+mlir::AffineMapAttr GetOutputIndexingMap(mlir::OpBuilder& builder,\n+                                         int64_t iterator_count,\n+                                         int64_t batch_dim_count,\n+                                         int64_t contracting_dim_count) {\n+  llvm::SmallVector<unsigned> targets(iterator_count - contracting_dim_count);\n+  unsigned idx = 0;\n+  for (int64_t dim = 0; dim != batch_dim_count; ++dim) {\n+    targets[dim] = idx++;\n+  }\n+  idx += contracting_dim_count;\n+  int64_t total_free_dims =\n+      iterator_count - batch_dim_count - contracting_dim_count;\n+  for (int64_t dim = 0; dim != total_free_dims; ++dim) {\n+    targets[batch_dim_count + dim] = idx++;\n+  }\n+  auto affine_map = mlir::AffineMap::getMultiDimMapWithTargets(\n+      iterator_count, targets, builder.getContext());\n+\n+  return mlir::AffineMapAttr::get(affine_map);\n+}\n+\n+mlir::ArrayAttr GetIteratorTypes(mlir::OpBuilder& builder,\n+                                 int64_t iterator_count,\n+                                 int64_t batch_dim_count,\n+                                 int64_t contracting_dim_count) {\n+  llvm::SmallVector<mlir::Attribute> iterator_types;\n+  iterator_types.reserve(iterator_count);\n+  for (int64_t dim = 0; dim != batch_dim_count; ++dim) {\n+    iterator_types.push_back(builder.getAttr<mlir::vector::IteratorTypeAttr>(\n+        mlir::vector::IteratorType::parallel));\n+  }\n+  for (int64_t dim = 0; dim != contracting_dim_count; ++dim) {\n+    iterator_types.push_back(builder.getAttr<mlir::vector::IteratorTypeAttr>(\n+        mlir::vector::IteratorType::reduction));\n+  }\n+  int64_t free_dims = iterator_count - batch_dim_count - contracting_dim_count;\n+  for (int64_t dim = 0; dim != free_dims; ++dim) {\n+    iterator_types.push_back(builder.getAttr<mlir::vector::IteratorTypeAttr>(\n+        mlir::vector::IteratorType::parallel));\n+  }\n+\n+  return mlir::ArrayAttr::get(builder.getContext(), iterator_types);\n+}\n+\n+// Lowers from stablehlo.dot_general to vector.contract.\n+// The vector contract is very general as described here:\n+// https://mlir.llvm.org/docs/Dialects/Vector/#vectorcontract-vectorcontractionop\n+// In this lowering the iteration order attribute passed is of the form:\n+// (batch..., contracting..., free_lhs..., free_rhs...)\n+// TODO(willfroom): Check if there is any performance impact on the order.\n+struct LowerDotGeneral : mlir::OpRewritePattern<mlir::stablehlo::DotGeneralOp> {\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      mlir::stablehlo::DotGeneralOp op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    auto lhs_vector = CastToVector(rewriter, op.getLhs());\n+    auto lhs_rank = lhs_vector.getType().getRank();\n+\n+    auto rhs_vector = CastToVector(rewriter, op.getRhs());\n+    auto rhs_rank = rhs_vector.getType().getRank();\n+\n+    auto result_vector_type = GetVectorType(op.getResult().getType());\n+    auto zero_const = rewriter.create<mlir::arith::ConstantOp>(\n+        op->getLoc(), result_vector_type.getElementType(),\n+        rewriter.getZeroAttr(result_vector_type.getElementType()));\n+    // TODO(willfroom): Ensure this is being folded into the accumilator in the\n+    // dot loop.\n+    mlir::Value accumulator = rewriter.create<mlir::vector::BroadcastOp>(\n+        op->getLoc(), result_vector_type, zero_const);\n+\n+    mlir::stablehlo::DotDimensionNumbersAttr dimension_numbers =\n+        op.getDotDimensionNumbers();\n+\n+    llvm::ArrayRef<int64_t> lhs_batch =\n+        dimension_numbers.getLhsBatchingDimensions();\n+    llvm::ArrayRef<int64_t> lhs_contracting =\n+        dimension_numbers.getLhsContractingDimensions();\n+\n+    llvm::ArrayRef<int64_t> rhs_batch =\n+        dimension_numbers.getRhsBatchingDimensions();\n+    llvm::ArrayRef<int64_t> rhs_contracting =\n+        dimension_numbers.getRhsContractingDimensions();\n+\n+    int64_t lhs_free_dims =\n+        lhs_rank - lhs_batch.size() - lhs_contracting.size();\n+    int64_t rhs_free_dims =\n+        rhs_rank - rhs_batch.size() - rhs_contracting.size();\n+    int64_t iterator_count = lhs_batch.size() + lhs_contracting.size() +\n+                             lhs_free_dims + rhs_free_dims;\n+\n+    mlir::Attribute lhs_indexing_map = GetOperandIndexingMap(\n+        rewriter, iterator_count, lhs_rank, lhs_batch, lhs_contracting, 0);\n+    mlir::Attribute rhs_indexing_map =\n+        GetOperandIndexingMap(rewriter, iterator_count, rhs_rank, rhs_batch,\n+                              rhs_contracting, lhs_free_dims);\n+    mlir::Attribute output_indexing_map = GetOutputIndexingMap(\n+        rewriter, iterator_count, lhs_batch.size(), lhs_contracting.size());\n+\n+    mlir::ArrayAttr indexing_maps = rewriter.getArrayAttr(\n+        {lhs_indexing_map, rhs_indexing_map, output_indexing_map});\n+    mlir::ArrayAttr iterator_types = GetIteratorTypes(\n+        rewriter, iterator_count, lhs_batch.size(), lhs_contracting.size());\n+\n+    mlir::Value result_vector = rewriter.create<mlir::vector::ContractionOp>(\n+        op->getLoc(), lhs_vector, rhs_vector, accumulator, indexing_maps,\n+        iterator_types);\n+\n+    rewriter.replaceOpWithNewOp<mlir::UnrealizedConversionCastOp>(\n+        op, op.getResult().getType(), result_vector);\n+\n+    return mlir::success();\n+  }\n+};\n+\n struct LowerTranspose : mlir::OpRewritePattern<mlir::stablehlo::TransposeOp> {\n   using OpRewritePattern::OpRewritePattern;\n \n@@ -79,7 +236,7 @@ class ShloToVectorPass : public impl::ShloToVectorPassBase<ShloToVectorPass> {\n   void runOnOperation() override {\n     mlir::MLIRContext* context = &getContext();\n     mlir::RewritePatternSet patterns(context);\n-    patterns.add<LowerTranspose>(context);\n+    patterns.add<LowerTranspose, LowerDotGeneral>(context);\n     if (mlir::failed(\n             mlir::applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n       signalPassFailure();"
        },
        {
            "sha": "971210401300fa37edd13c7246502592d77cd2cb",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/shlo_to_vector.mlir",
            "status": "modified",
            "additions": 16,
            "deletions": 0,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/78e02816b874b308a217d3fddd611034014c7fcf/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Fshlo_to_vector.mlir?ref=78e02816b874b308a217d3fddd611034014c7fcf",
            "patch": "@@ -6,3 +6,19 @@ func.func @transpose(%input : tensor<1024x32xf32>) -> tensor<32x1024xf32> {\n   return %transposed : tensor<32x1024xf32>\n }\n // -----\n+\n+// CHECK-DAG: #[[LHS_MAP:.*]] = affine_map<(d0, d1, d2) -> (d1, d0)>\n+// CHECK-DAG: #[[RHS_MAP:.*]] = affine_map<(d0, d1, d2) -> (d0, d2)>\n+// CHECK-DAG: #[[OUTPUT_MAP:.*]] = affine_map<(d0, d1, d2) -> (d1, d2)>\n+func.func @dot_general(%lhs : tensor<1024x32xf32>, %rhs : tensor<32x1024xf32>) -> tensor<1024x1024xf32> {\n+  // CHECK: %[[ACCUMULATOR:.*]] = arith.constant dense<0.000000e+00> : vector<1024x1024xf32>\n+  // CHECK: vector.contract\n+  // CHECK-SAME: {indexing_maps = [#[[LHS_MAP]], #[[RHS_MAP]], #[[OUTPUT_MAP]]],\n+  // CHECK-SAME: iterator_types = [\"reduction\", \"parallel\", \"parallel\"],\n+  // CHECK-SAME: kind = #vector.kind<add>}\n+  // CHECK-SAME: %[[ACCUMULATOR]] : vector<1024x32xf32>, vector<32x1024xf32> into vector<1024x1024xf32>\n+  %result = stablehlo.dot_general %lhs, %rhs, contracting_dims = [1] x [0] : (tensor<1024x32xf32>, tensor<32x1024xf32>) -> tensor<1024x1024xf32>\n+  return %result : tensor<1024x1024xf32>\n+}\n+\n+// -----"
        }
    ],
    "stats": {
        "total": 249,
        "additions": 245,
        "deletions": 4
    }
}