{
    "author": "unknown",
    "message": "[XLA:GPU] ThunkPassPipeline: pass HloModule* to Run()\n\nThis allows SDC log dumper to derive unique path for each module execution.\n\nPiperOrigin-RevId: 819781581",
    "sha": "f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
    "files": [
        {
            "sha": "10682c2accb86febd4bc533e42e7bf4a94645927",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -2752,6 +2752,7 @@ cc_library(\n     hdrs = [\"thunk_pass_pipeline.h\"],\n     deps = [\n         \":sequential_thunk\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:statusor\",\n@@ -2769,6 +2770,7 @@ xla_cc_test(\n         \":sequential_thunk\",\n         \":thunk\",\n         \":thunk_pass_pipeline\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:statusor\",\n@@ -2797,6 +2799,7 @@ cc_library(\n         \":while_thunk\",\n         \"//xla:util\",\n         \"//xla/ffi:ffi_api\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n@@ -2865,9 +2868,11 @@ cc_library(\n     deps = [\n         \":sequential_thunk\",\n         \":thunk_pass_pipeline\",\n+        \"//xla/hlo/ir:hlo\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/stream_executor:device_description\",\n         \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/base:nullability\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n     ],"
        },
        {
            "sha": "952673948d82dadc721e824170d0b66c56e33d39",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -27,6 +27,7 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/algorithm/container.h\"\n+#include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/functional/overload.h\"\n #include \"absl/log/log.h\"\n@@ -46,6 +47,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n #include \"xla/ffi/ffi_api.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n@@ -415,6 +417,7 @@ std::string CommandBufferConversionPass::CommandBufferConfig::ToString() const {\n \n absl::StatusOr<bool> CommandBufferConversionPass::Run(\n     SequentialThunk* root_thunk, const DebugOptions& debug_options,\n+    const HloModule* absl_nullable hlo_module,\n     const se::DeviceDescription& device_info,\n     ThunkPassBufferAllocator& allocator) {\n   tsl::profiler::TraceMe traceme(\"CommandBufferConversionPass\");\n@@ -471,16 +474,16 @@ absl::StatusOr<bool> CommandBufferConversionPass::Run(\n       auto while_thunk = static_cast<WhileThunk*>(thunk.get());\n       TF_ASSIGN_OR_RETURN(bool changed_in_body,\n                           Run(while_thunk->body_thunk_sequence(), debug_options,\n-                              device_info, allocator));\n+                              hlo_module, device_info, allocator));\n       changed |= changed_in_body;\n     } else if (thunk->kind() == Thunk::kConditional) {\n       // If a `ConditionalThunk` itself is not eligible for conversion into a\n       // command buffer, we attempt to convert thunks within its branches.\n       auto conditional_thunk = static_cast<ConditionalThunk*>(thunk.get());\n       for (auto& branch_thunk : conditional_thunk->branch_thunks()) {\n-        TF_ASSIGN_OR_RETURN(\n-            bool changed_in_branch,\n-            Run(branch_thunk.get(), debug_options, device_info, allocator));\n+        TF_ASSIGN_OR_RETURN(bool changed_in_branch,\n+                            Run(branch_thunk.get(), debug_options, hlo_module,\n+                                device_info, allocator));\n         changed |= changed_in_branch;\n       }\n     }"
        },
        {
            "sha": "5ea3cdece941408e9e5024842dbea8041ca35135",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass.h?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -16,14 +16,13 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_RUNTIME_COMMAND_BUFFER_CONVERSION_PASS_H_\n #define XLA_BACKENDS_GPU_RUNTIME_COMMAND_BUFFER_CONVERSION_PASS_H_\n \n-#include <string>\n-\n #include \"absl/base/nullability.h\"\n #include \"absl/container/flat_hash_set.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/stream_executor/device_description.h\"\n \n namespace xla {\n@@ -41,6 +40,7 @@ class CommandBufferConversionPass : public ThunkPassInterface {\n \n   absl::StatusOr<bool> Run(SequentialThunk* root_thunk,\n                            const DebugOptions& debug_options,\n+                           const HloModule* absl_nullable hlo_module,\n                            const se::DeviceDescription& device_info,\n                            ThunkPassBufferAllocator& allocator) override;\n   struct CommandBufferConfig {"
        },
        {
            "sha": "5b2d21123b5450790d9c9e068911addba91369d6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass_test.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 14,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -248,7 +248,8 @@ TEST(CommandBufferConversionPassTest, ConvertsToCommandBufferThunk) {\n   // supported in command buffers. The expected transformation is:\n   // SequentialThunk(CopyThunk) ->\n   // SequentialThunk(CommandBufferThunk(CopyThunk))\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   EXPECT_THAT(root_thunk->thunks(), ThunkKindsAre(Thunk::kCommandBuffer));\n@@ -287,7 +288,8 @@ TEST(CommandBufferConversionPassTest, PartiallyConvertsToCommandBufferThunk) {\n \n   ASSERT_EQ(root_thunk->thunks().size(), 3);\n \n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: (Copy, Gemm, Copy) -> (CommandBuffer(Copy), Gemm,\n@@ -335,7 +337,8 @@ TEST(CommandBufferConversionPassTest, ConvertsAsyncPairToCommandBuffer) {\n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n   FakeErrorAllocator allocator;\n   CommandBufferConversionPass pass(\"test\");\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation:\n@@ -381,7 +384,8 @@ TEST(CommandBufferConversionPassTest,\n   CommandBufferConversionPass pass(\"test\");\n   // Expected no transformation, because there is a non-convertible thunk in\n   // between the asyncs.\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(false));\n   EXPECT_THAT(root_thunk->thunks(),\n               ThunkKindsAre(Thunk::kAllGatherStart, Thunk::kCopy,\n@@ -413,7 +417,8 @@ TEST(CommandBufferConversionPassTest, ConvertCrossedAsyncs) {\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::COLLECTIVES);\n \n   FakeErrorAllocator allocator;\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: Convert all 4 thunks into command buffer\n@@ -458,7 +463,8 @@ TEST(CommandBufferConversionPassTest, ConvertNestedAsyncs) {\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n \n   FakeErrorAllocator allocator;\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: Convert all 5 thunks into command buffer\n@@ -507,7 +513,8 @@ TEST(CommandBufferConversionPassTest, DontConvertAsyncsIfUnpairedStart) {\n   debug_options.add_xla_gpu_enable_command_buffer(DebugOptions::FUSION);\n \n   FakeErrorAllocator allocator;\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: {Copy, AllGatherStart0, AllGatherStart1,\n@@ -564,7 +571,8 @@ TEST(CommandBufferConversionPassTest, ConvertsAsyncPairsMixedWithOtherThunks) {\n   se::DeviceDescription device_info = TestGpuDeviceInfo::CudaOrRocmDeviceInfo();\n   FakeErrorAllocator allocator;\n   CommandBufferConversionPass pass(\"test\");\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation:\n@@ -605,7 +613,8 @@ TEST(CommandBufferConversionPassTest, DontConvertIfNotMinGraphSize) {\n \n   // The size of the sequence is less than the min graph size, so it should not\n   // be converted to a command buffer.\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(false));\n   EXPECT_THAT(root_thunk->thunks(), ThunkKindsAre(Thunk::kCopy));\n }\n@@ -641,7 +650,8 @@ TEST(CommandBufferConversionPassTest, ConvertWhileThunk) {\n   FakeErrorAllocator allocator;\n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: (While({Copy}, {Gemm})) ->\n@@ -703,7 +713,8 @@ TEST(CommandBufferConversionPassTest,\n   FakeErrorAllocator allocator;\n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation is: kConditional({kCopy}, {kAllGatherStart, kCopy})\n@@ -753,7 +764,8 @@ TEST(CommandBufferConversionPassTest, ConvertWhileThunkWithAsyncPair) {\n   FakeErrorAllocator allocator;\n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // Expected transformation: (While({Copy}, {AllGatherStart, Copy,\n@@ -800,7 +812,8 @@ TEST(CommandBufferConversionPassTest, ConvertsCuDnnThunkToCommandBufferThunk) {\n \n   // The expected transformation is: SequentialThunk(CuDnnThunk) ->\n   // SequentialThunk(CommandBufferThunk(CuDnnThunk))\n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n   EXPECT_THAT(root_thunk->thunks(), ThunkKindsAre(Thunk::kCommandBuffer));\n \n@@ -846,7 +859,8 @@ TEST(CommandBufferConversionPassTest, ConvertTheBodyOfWhileThunk) {\n   FakeErrorAllocator allocator;\n   ASSERT_EQ(root_thunk->thunks().size(), 1);\n \n-  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, device_info, allocator),\n+  ASSERT_THAT(pass.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                       device_info, allocator),\n               IsOkAndHolds(true));\n \n   // While thunk is not converted itself, because it has a non-convertible thunk"
        },
        {
            "sha": "631c42cc3efb9954e3deac570fb1f9ca407cba7e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -15,9 +15,11 @@ limitations under the License.\n \n #include \"xla/backends/gpu/runtime/thunk_checksum_tracing_pass.h\"\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -27,6 +29,7 @@ namespace gpu {\n \n absl::StatusOr<bool> ThunkChecksumTracingPass::Run(\n     SequentialThunk* root_thunk, const DebugOptions& debug_options,\n+    const HloModule* absl_nullable hlo_module,\n     const se::DeviceDescription& device_info,\n     ThunkPassBufferAllocator& allocator) {\n   TF_ASSIGN_OR_RETURN(BufferAllocation * log_alloc,"
        },
        {
            "sha": "864b1b2bef32cc93d3ca8a78ff4662688d606606",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass.h?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -16,10 +16,12 @@ limitations under the License.\n #ifndef XLA_BACKENDS_GPU_RUNTIME_THUNK_CHECKSUM_TRACING_PASS_H_\n #define XLA_BACKENDS_GPU_RUNTIME_THUNK_CHECKSUM_TRACING_PASS_H_\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_pass_pipeline.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/stream_executor/device_description.h\"\n \n namespace xla {\n@@ -34,6 +36,7 @@ class ThunkChecksumTracingPass : public ThunkPassInterface {\n \n   absl::StatusOr<bool> Run(SequentialThunk* root_thunk,\n                            const DebugOptions& debug_options,\n+                           const HloModule* absl_nullable hlo_module,\n                            const se::DeviceDescription& device_info,\n                            ThunkPassBufferAllocator& allocator) override;\n };"
        },
        {
            "sha": "422aba3248c2d04396da45ac651a122c9eb5cc99",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_checksum_tracing_pass_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_checksum_tracing_pass_test.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -58,8 +58,8 @@ TEST(ThunkChecksumTracingPassTest, CreatesLogAlloc) {\n   FakeThunkPassBufferAllocator allocator;\n \n   TF_ASSERT_OK_AND_ASSIGN(\n-      bool changed,\n-      pass.Run(root_thunk.get(), debug_options, device_info, allocator));\n+      bool changed, pass.Run(root_thunk.get(), debug_options,\n+                             /*hlo_module=*/nullptr, device_info, allocator));\n   EXPECT_FALSE(changed);\n   EXPECT_TRUE(allocator.CreatedAlloc());\n }"
        },
        {
            "sha": "6763e8eac9ef72e546567cc0e7d058752aa726fe",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_pass_pipeline.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -17,9 +17,11 @@ limitations under the License.\n \n #include <memory>\n \n+#include \"absl/base/nullability.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n@@ -28,13 +30,15 @@ namespace gpu {\n \n absl::StatusOr<bool> ThunkPassPipeline::Run(\n     SequentialThunk* root_thunk, const DebugOptions& debug_options,\n+    const HloModule* absl_nullable hlo_module,\n     const se::DeviceDescription& device_info,\n     ThunkPassBufferAllocator& allocator) {\n   bool changed = false;\n   for (const auto& pass : passes_) {\n     VLOG(1) << \"Running ThunkPass: \" << pass->name();\n-    TF_ASSIGN_OR_RETURN(bool pass_changed, pass->Run(root_thunk, debug_options,\n-                                                     device_info, allocator));\n+    TF_ASSIGN_OR_RETURN(bool pass_changed,\n+                        pass->Run(root_thunk, debug_options, hlo_module,\n+                                  device_info, allocator));\n     changed |= pass_changed;\n   }\n   return changed;"
        },
        {
            "sha": "4531c7b1502bffc29d7a1e50eb6a9c2ee3dc8593",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_pass_pipeline.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline.h?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/device_description.h\"\n \n@@ -49,6 +50,7 @@ class ThunkPassInterface {\n \n   virtual absl::StatusOr<bool> Run(SequentialThunk* root_thunk,\n                                    const DebugOptions& debug_options,\n+                                   const HloModule* absl_nullable hlo_module,\n                                    const se::DeviceDescription& device_info,\n                                    ThunkPassBufferAllocator& allocator) = 0;\n \n@@ -69,6 +71,7 @@ class ThunkPassPipeline : public ThunkPassInterface {\n   // Returns true if any pass changed the thunk tree.\n   absl::StatusOr<bool> Run(SequentialThunk* root_thunk,\n                            const DebugOptions& debug_options,\n+                           const HloModule* absl_nullable hlo_module,\n                            const se::DeviceDescription& device_info,\n                            ThunkPassBufferAllocator& allocator) override;\n "
        },
        {
            "sha": "4806bafbd9124c93c245a4b3325a777ca97beb26",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_pass_pipeline_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_pass_pipeline_test.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/service/buffer_assignment.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/tsl/platform/statusor.h\"\n@@ -40,6 +41,7 @@ class TestPass : public ThunkPassInterface {\n   absl::string_view name() const override { return \"test-pass\"; }\n   absl::StatusOr<bool> Run(SequentialThunk* root_thunk,\n                            const DebugOptions& debug_options,\n+                           const HloModule* hlo_module,\n                            const se::DeviceDescription& device_info,\n                            ThunkPassBufferAllocator& /*allocator*/) override {\n     root_thunk->thunks().push_back(std::make_unique<SequentialThunk>(\n@@ -69,7 +71,8 @@ TEST(ThunkPassPipelineTest, PipelineRunsPass) {\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       bool changed,\n-      pipeline.Run(root_thunk.get(), debug_options, device_info, allocator));\n+      pipeline.Run(root_thunk.get(), debug_options, /*hlo_module=*/nullptr,\n+                   device_info, allocator));\n   EXPECT_TRUE(changed);\n   EXPECT_EQ(root_thunk->thunks().size(), 1);\n }"
        },
        {
            "sha": "7a266bcab9410ecebb45c7115cac6f8592ac1026",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -782,7 +782,6 @@ cc_library(\n         \"@com_google_absl//absl/synchronization\",\n         \"@com_google_absl//absl/time\",\n         \"@com_google_absl//absl/types:span\",\n-        \"@com_google_protobuf//:protobuf\",\n         \"@local_tsl//tsl/platform:random\",\n         \"@local_tsl//tsl/profiler/lib:scoped_annotation\",\n         \"@local_tsl//tsl/profiler/lib:traceme\","
        },
        {
            "sha": "3a0252b8598736c2f8dc687008154beeaed81b52",
            "filename": "third_party/xla/xla/service/gpu/gpu_executable.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f0ea4b75e3a1c0b4c30ae26c78b30821a995098d/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_executable.cc?ref=f0ea4b75e3a1c0b4c30ae26c78b30821a995098d",
            "patch": "@@ -182,8 +182,9 @@ static absl::Status RunThunkPasses(const DebugOptions& debug_options,\n     pipeline.AddPass(std::make_unique<CommandBufferConversionPass>(\n         hlo_module ? hlo_module->name() : \"Anonymous\"));\n   }\n-  TF_ASSIGN_OR_RETURN(bool changed, pipeline.Run(root_thunk, debug_options,\n-                                                 device_info, allocator));\n+  TF_ASSIGN_OR_RETURN(bool changed,\n+                      pipeline.Run(root_thunk, debug_options, hlo_module,\n+                                   device_info, allocator));\n   if (changed) {\n     VLOG(3) << \"Thunk passes changed the thunk tree.\";\n     if (hlo_module && DumpingEnabledForHloModule(*hlo_module)) {"
        }
    ],
    "stats": {
        "total": 94,
        "additions": 66,
        "deletions": 28
    }
}