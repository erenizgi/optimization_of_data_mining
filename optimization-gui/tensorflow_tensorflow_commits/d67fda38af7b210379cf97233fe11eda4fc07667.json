{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 815463476",
    "sha": "d67fda38af7b210379cf97233fe11eda4fc07667",
    "files": [
        {
            "sha": "4f931785029e4fc1e295eab92a39e8a124fdc0cf",
            "filename": "tensorflow/core/grappler/optimizers/dependency_optimizer.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fdependency_optimizer.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -691,7 +691,7 @@ void DependencyOptimizer::GroupCrossDeviceControlEdges(bool host_granularity) {\n             do {\n               group_name = AddPrefixToNodeName(\n                   node->name(),\n-                  strings::StrCat(\"GroupCrossDeviceControlEdges_\", num_noops));\n+                  absl::StrCat(\"GroupCrossDeviceControlEdges_\", num_noops));\n               noop = node_map_->GetNode(group_name);\n               ++num_noops;\n             } while (noop != nullptr);"
        },
        {
            "sha": "e16324d54d025e980118b3448182befb211ff4ed",
            "filename": "tensorflow/core/grappler/optimizers/graph_optimizer_stage.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -102,15 +102,15 @@ const string MakeOptimizedNodeName(const NodeScopeAndName& node,\n       << \"Either optimized node name prefix or sub-scope must be non-empty\";\n   string optimized_node_name;\n   if (!node.scope.empty()) {\n-    strings::StrAppend(&optimized_node_name, node.scope, \"/\");\n+    absl::StrAppend(&optimized_node_name, node.scope, \"/\");\n   }\n   if (!sub_scope.empty()) {\n-    strings::StrAppend(&optimized_node_name, sub_scope, \"/\");\n+    absl::StrAppend(&optimized_node_name, sub_scope, \"/\");\n   }\n   if (!prefix.empty()) {\n-    strings::StrAppend(&optimized_node_name, prefix, \"_\");\n+    absl::StrAppend(&optimized_node_name, prefix, \"_\");\n   }\n-  strings::StrAppend(&optimized_node_name, node.name);\n+  absl::StrAppend(&optimized_node_name, node.name);\n   return optimized_node_name;\n }\n \n@@ -121,7 +121,7 @@ const string MakeOptimizedNodeName(const NodeScopeAndName& root,\n   string optimized_node_name = MakeOptimizedNodeName(root, sub_scope, prefix);\n   for (const string& node_name : node_names) {\n     auto name_and_scope = ParseNodeScopeAndName(node_name);\n-    strings::StrAppend(&optimized_node_name, \"_\", name_and_scope.name);\n+    absl::StrAppend(&optimized_node_name, \"_\", name_and_scope.name);\n   }\n   return optimized_node_name;\n }"
        },
        {
            "sha": "8aa4de31a51d948293495c25c4a29c9a0a1e8c0f",
            "filename": "tensorflow/core/grappler/optimizers/graph_optimizer_stage.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fgraph_optimizer_stage.h?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -167,7 +167,7 @@ class GraphOptimizerStage {\n   }\n   const string OptimizedNodeName(const NodeScopeAndName& node,\n                                  const string& rewrite_rule) const {\n-    const string prefix = strings::StrCat(stage_name_, \"_\", rewrite_rule);\n+    const string prefix = absl::StrCat(stage_name_, \"_\", rewrite_rule);\n     return MakeOptimizedNodeName(node, optimizer_name_, prefix);\n   }\n "
        },
        {
            "sha": "c3c1e49737442ef1f59863b2d5cd7274f52525c5",
            "filename": "tensorflow/core/grappler/optimizers/implementation_selector.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fimplementation_selector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fimplementation_selector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fimplementation_selector.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -212,7 +212,7 @@ absl::Status UpdateNodeDef(utils::MutableNodeView* node_view,\n             name_index[1]);\n       }\n       for (int i = 1; i <= -diff; ++i)\n-        node_def->add_input(strings::StrCat(node_name, \":\", i + last_index));\n+        node_def->add_input(absl::StrCat(node_name, \":\", i + last_index));\n     }\n \n     // Add control dependencies back."
        },
        {
            "sha": "463b918bb714bc5767e7e8340a41a5ca9218f549",
            "filename": "tensorflow/core/grappler/optimizers/loop_optimizer.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Floop_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Floop_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Floop_optimizer.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -177,7 +177,7 @@ absl::Status LoopInvariantNodeMotionOptimizer::HandleConst(\n       return errors::InvalidArgument(\"LoopCond node of Frame \", frame_id,\n                                      \" doesn't connect to any Switch node\");\n     }\n-    string switch_output = StrCat(switch_node->name(), \":1\");\n+    string switch_output = absl::StrCat(switch_node->name(), \":1\");\n     const string ctrl_dep = ConstantFolding::AddControlDependency(\n         switch_output, optimized_graph_, node_map_.get());\n     const_node->add_input(ctrl_dep);\n@@ -230,7 +230,7 @@ absl::Status LoopInvariantNodeMotionOptimizer::HandleInvariantNode(\n         new_enter->set_op(\"Enter\");\n         new_enter->set_device(node->device());\n         new_enter->set_name(AddPrefixToNodeName(\n-            StrCat(fname, \"_enter_\", new_enter_id_++), kLoopOptimizer));\n+            absl::StrCat(fname, \"_enter_\", new_enter_id_++), kLoopOptimizer));\n         AttrValue data_type;\n         data_type.set_type(output_type);\n         new_enter->mutable_attr()->insert({\"T\", data_type});\n@@ -984,7 +984,7 @@ absl::Status LoopOptimizer::RemoveDeadBranches(\n       int live_port_id = (dead_port_id + 1) % 2;\n       string live_output_name = sw_node->name();\n       if (live_port_id == 1) {\n-        live_output_name = StrCat(sw_node->name(), \":1\");\n+        live_output_name = absl::StrCat(sw_node->name(), \":1\");\n       }\n \n       // Get consumers of live port and update the input names"
        },
        {
            "sha": "62ec4e134749adbb2b59f9d44e7e3cc8e52e042e",
            "filename": "tensorflow/core/grappler/optimizers/memory_optimizer.cc",
            "status": "modified",
            "additions": 17,
            "deletions": 18,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmemory_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmemory_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmemory_optimizer.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -359,7 +359,7 @@ AddRecomputeControlDependencyNodes(\n     new_trigger_node->set_device(original_recomputed_node->device());\n     if (current_trigger_node != nullptr) {\n       *new_trigger_node->add_input() =\n-          strings::StrCat(\"^\", current_trigger_node->name());\n+          absl::StrCat(\"^\", current_trigger_node->name());\n     }\n     current_trigger_node = new_trigger_node;\n     triggers[original_recomputed_node] = current_trigger_node;\n@@ -370,7 +370,7 @@ AddRecomputeControlDependencyNodes(\n                  ->second;\n          ++target_input_iterator) {\n       *current_trigger_node->add_input() =\n-          strings::StrCat(\"^\", (*target_input_iterator)->name());\n+          absl::StrCat(\"^\", (*target_input_iterator)->name());\n       VLOG(2) << \"  Recomputation trigger \" << current_trigger_node->name()\n               << \" depends on \" << (*target_input_iterator)->name();\n     }\n@@ -428,7 +428,7 @@ void RecomputeSubgraph(\n     // Each recomputed node gets a control dependency to prevent it from being\n     // recomputed immediately.\n     *copied_node->add_input() =\n-        strings::StrCat(\"^\", triggers[original_node]->name());\n+        absl::StrCat(\"^\", triggers[original_node]->name());\n   }\n   // Set the inputs of nodes in the target subgraph to the recomputed nodes\n   // where applicable.\n@@ -529,7 +529,7 @@ bool SchedulingPass(Cluster* cluster, std::unique_ptr<GraphMemory>* memory_ptr,\n     for (const auto& input : view.GetFanins(node, false)) {\n       if (input.node->device() == node.device()) {\n         string tensor_name =\n-            strings::StrCat(input.node->name(), \":\", input.port_id);\n+            absl::StrCat(input.node->name(), \":\", input.port_id);\n         addn_list[tensor_name].insert(&node);\n       }\n     }\n@@ -565,7 +565,7 @@ bool SchedulingPass(Cluster* cluster, std::unique_ptr<GraphMemory>* memory_ptr,\n     }\n \n     for (const auto& live : mem_usage.live_tensors) {\n-      string tensor_name = strings::StrCat(live.node, \":\", live.output_id);\n+      string tensor_name = absl::StrCat(live.node, \":\", live.output_id);\n       auto it = addn_list.find(tensor_name);\n       if (it != addn_list.end()) {\n         addn_to_rewrite.insert(it->second.begin(), it->second.end());\n@@ -665,7 +665,7 @@ bool SchedulingPass(Cluster* cluster, std::unique_ptr<GraphMemory>* memory_ptr,\n     }\n \n     const string& device = node->device();\n-    const string tmp_var_name = strings::StrCat(node->name(), \"/tmp_var\");\n+    const string tmp_var_name = absl::StrCat(node->name(), \"/tmp_var\");\n     if (view.GetNode(tmp_var_name) != nullptr) {\n       VLOG(1) << \"Temporary variable already exists \" << tmp_var_name;\n       return false;\n@@ -688,14 +688,14 @@ bool SchedulingPass(Cluster* cluster, std::unique_ptr<GraphMemory>* memory_ptr,\n \n     // Initialize it to zero\n     NodeDef* zeros = item->graph.add_node();\n-    zeros->set_name(strings::StrCat(node->name(), \"/tmp_var_zeros\"));\n+    zeros->set_name(absl::StrCat(node->name(), \"/tmp_var_zeros\"));\n     zeros->set_op(\"ZerosLike\");\n     zeros->set_device(device);\n     (*zeros->mutable_attr())[\"T\"].set_type(dtype);\n     *zeros->add_input() = node->input(min_input_id);\n \n     NodeDef* initialize = item->graph.add_node();\n-    initialize->set_name(strings::StrCat(node->name(), \"/tmp_var_initializer\"));\n+    initialize->set_name(absl::StrCat(node->name(), \"/tmp_var_initializer\"));\n     initialize->set_op(\"Assign\");\n     initialize->set_device(device);\n     (*initialize->mutable_attr())[\"T\"].set_type(dtype);\n@@ -710,8 +710,7 @@ bool SchedulingPass(Cluster* cluster, std::unique_ptr<GraphMemory>* memory_ptr,\n       const string& input = node->input(i);\n       if (!IsControlInput(input)) {\n         NodeDef* accumulate = item->graph.add_node();\n-        accumulate->set_name(\n-            strings::StrCat(node->name(), \"/tmp_var_accum_\", i));\n+        accumulate->set_name(absl::StrCat(node->name(), \"/tmp_var_accum_\", i));\n         accumulate->set_op(\"AssignAdd\");\n         accumulate->set_device(device);\n         (*accumulate->mutable_attr())[\"T\"].set_type(dtype);\n@@ -764,9 +763,9 @@ absl::Status BuildSwapPair(\n                                    \" since it expects a reference\");\n   }\n \n-  string tensor_to_swap = strings::StrCat(node->name(), \"_\", input_to_swap);\n-  string swap_out_name = strings::StrCat(\"swap_out_\", tensor_to_swap);\n-  string swap_in_name = strings::StrCat(\"swap_in_\", tensor_to_swap);\n+  string tensor_to_swap = absl::StrCat(node->name(), \"_\", input_to_swap);\n+  string swap_out_name = absl::StrCat(\"swap_out_\", tensor_to_swap);\n+  string swap_in_name = absl::StrCat(\"swap_in_\", tensor_to_swap);\n   if (name_map.find(swap_out_name) != name_map.end() ||\n       name_map.find(swap_in_name) != name_map.end()) {\n     return errors::InvalidArgument(\"Input \", input_to_swap, \" of node \",\n@@ -787,7 +786,7 @@ absl::Status BuildSwapPair(\n   // Colocate the swap_out_ and swap_in_ nodes with the node itself.\n   swap_out_node->set_device(node->device());\n   swap_in_node->set_device(node->device());\n-  string coloc_group = strings::StrCat(\"loc@\", tensor_to_swap);\n+  string coloc_group = absl::StrCat(\"loc@\", tensor_to_swap);\n   (*swap_out_node->mutable_attr())[\"_class\"].mutable_list()->add_s(coloc_group);\n   (*swap_in_node->mutable_attr())[\"_class\"].mutable_list()->add_s(coloc_group);\n   (*node->mutable_attr())[\"_class\"].mutable_list()->add_s(coloc_group);\n@@ -1092,7 +1091,7 @@ static bool IdentifySwappingCandidates(\n           break;\n         }\n         string input_name =\n-            strings::StrCat(input.node->name(), \":\", input.port_id);\n+            absl::StrCat(input.node->name(), \":\", input.port_id);\n         if (skip_list->find(input_name) != skip_list->end()) {\n           valid = false;\n           break;\n@@ -1236,7 +1235,7 @@ bool SwappingPass(RewriterConfig::MemOptType optimization_level,\n \n     // Swap all the tensors that are marked with the 'swap_to_host' attribute.\n     for (int input_id : swap_info.inputs_to_swap) {\n-      string input_name = strings::StrCat(node->name(), \":\", input_id);\n+      string input_name = absl::StrCat(node->name(), \":\", input_id);\n       if (skip_list->find(input_name) != skip_list->end()) {\n         continue;\n       } else {\n@@ -1262,8 +1261,8 @@ bool SwappingPass(RewriterConfig::MemOptType optimization_level,\n       *node->mutable_input(input_id) = swap_nodes.second->name();\n \n       // Add the control dependencies needed to delay the execution of the swap.\n-      out_trigger->add_input(strings::StrCat(\"^\", swap_nodes.first->name()));\n-      swap_nodes.second->add_input(strings::StrCat(\"^\", in_trigger->name()));\n+      out_trigger->add_input(absl::StrCat(\"^\", swap_nodes.first->name()));\n+      swap_nodes.second->add_input(absl::StrCat(\"^\", in_trigger->name()));\n \n       // Make sure we won't try to swap the swap nodes in subsequent passes.\n       skip_list->insert(swap_nodes.first->name());"
        },
        {
            "sha": "20a8e5067df85ec6fdb8292584e4e7c58f648876",
            "filename": "tensorflow/core/grappler/optimizers/model_pruner.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmodel_pruner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmodel_pruner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fmodel_pruner.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -277,7 +277,7 @@ string NewIdentityFromIdentityN(int pos, const NodeDef& identity_n,\n   // TODO(lyandy): Migrate over to GrapplerOptimizerStage and use\n   // OptimizedNodeName for new node name.\n   string new_node_name =\n-      strings::StrCat(identity_n.name(), \"-\", pos, \"-grappler-ModelPruner\");\n+      absl::StrCat(identity_n.name(), \"-\", pos, \"-grappler-ModelPruner\");\n   if (node_map->NodeExists(new_node_name)) {\n     return \"\";\n   }\n@@ -348,7 +348,7 @@ absl::Status RewriteIdentityNAndInputsOutputs(\n           // inputs.\n           int new_pos = terminal_input_pos[input_tensor.index()];\n           string updated_input_name =\n-              new_pos > 0 ? strings::StrCat(node->name(), \":\", new_pos)\n+              new_pos > 0 ? absl::StrCat(node->name(), \":\", new_pos)\n                           : node->name();\n           output->set_input(i, updated_input_name);\n         }"
        },
        {
            "sha": "b97fb16935970610b242e3078b929e4a080193b6",
            "filename": "tensorflow/core/grappler/optimizers/pin_to_host_optimizer.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fpin_to_host_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fpin_to_host_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fpin_to_host_optimizer.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -283,8 +283,8 @@ string TryFindHostDevice(const gtl::FlatSet<string>& devices,\n          {std::pair<string, string>(\"GPU\", \"CPU:0\"),\n           std::pair<string, string>(\"/device\", \"/device:CPU:0\")}) {\n       const string device_host =\n-          strings::StrCat(device.substr(0, device.rfind(device_match.first)),\n-                          device_match.second);\n+          absl::StrCat(device.substr(0, device.rfind(device_match.first)),\n+                       device_match.second);\n       if (devices.find(device_host) != devices.end()) {\n         return device_host;\n       }"
        },
        {
            "sha": "902d619946d0525a6394d420990afca8031d0b22",
            "filename": "tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fscoped_allocator_optimizer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fscoped_allocator_optimizer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fscoped_allocator_optimizer.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -233,8 +233,8 @@ absl::Status MaybeRewriteInput(ScopedAllocatorOptimizer* sa_opti,\n   // Create new Identity op.\n   int unique_id;\n   LOG_WARNING_AND_RETURN_IF_ERROR(sa_opti->NewIdentityId(&unique_id));\n-  string identity_name = strings::StrCat(\"scoped_allocator_identity_\",\n-                                         unique_id, \"_\", invocation_count);\n+  string identity_name = absl::StrCat(\"scoped_allocator_identity_\", unique_id,\n+                                      \"_\", invocation_count);\n   NodeDefBuilder identity_builder(identity_name, \"Identity\");\n   identity_builder.Device(op->device());\n   identity_builder.Attr(\"T\", dtype);\n@@ -556,7 +556,7 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n       VLOG(2) << \"To input \" << i << \": \" << nd.from_node_def->name()\n               << \" add control input \"\n               << \"^\" << sa_name;\n-      nd.from_node_def->add_input(strings::StrCat(\"^\", sa_name));\n+      nd.from_node_def->add_input(absl::StrCat(\"^\", sa_name));\n       // This attribute says: allocate output_slot from\n       // ScopedAllocator instance sa_id + 1 + i.\n       ScopedAllocatorOptimizer::ExtendNodeAttr(kScopedAllocatorAttrName,\n@@ -580,7 +580,7 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n           continue;\n         }\n         sa_node->add_input(\n-            strings::StrCat(\"^\", inputs_to_first[i].from_node_def->name()));\n+            absl::StrCat(\"^\", inputs_to_first[i].from_node_def->name()));\n         node_map->AddOutput(inputs_to_first[i].from_node_def->name(), sa_name);\n         added_delay_edge = true;\n         VLOG(2) << \"Adding control dependency from \"\n@@ -754,7 +754,7 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n                   << n->name();\n           // However, we may already have dropped it at the clear() below,\n           // so if we fail to find it, that's okay.\n-          absl::Status ignore = RemoveEdge(strings::StrCat(\"^\", old_op->name()),\n+          absl::Status ignore = RemoveEdge(absl::StrCat(\"^\", old_op->name()),\n                                            old_op->name(), n, node_map);\n           continue;\n         }\n@@ -769,11 +769,11 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n             VLOG(3) << \"match pos=\" << position;\n             if (position == -1) {\n               // It was a control edge\n-              *n->mutable_input(i) = strings::StrCat(\"^\", sas_name);\n+              *n->mutable_input(i) = absl::StrCat(\"^\", sas_name);\n             } else {\n               CHECK_EQ(0, position)\n                   << \"name \" << n->input(i) << \" pos \" << position;\n-              *n->mutable_input(i) = strings::StrCat(sas_name, \":\", op_idx);\n+              *n->mutable_input(i) = absl::StrCat(sas_name, \":\", op_idx);\n             }\n             node_map->UpdateInput(n->name(), old_op->name(), sas_name);\n             VLOG(3) << \"breaking on success\";\n@@ -833,7 +833,7 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n       VLOG(1) << \"Rewrite\";\n       string op_names;\n       for (auto& nd : ops) {\n-        strings::StrAppend(&op_names, nd->name(), \", \");\n+        absl::StrAppend(&op_names, nd->name(), \", \");\n       }\n       VLOG(1) << \"UnaryElementwiseRewriter::Rewrite \" << op_name\n               << \" to: \" << op_names;\n@@ -858,29 +858,29 @@ class UnaryElementwiseRewriter : public ScopedAllocatorOptimizer::Rewriter {\n \n     int sa_id = sa_opti->NewScopedAllocatorId(input_shapes.size());\n     string sa_name =\n-        strings::StrCat(\"scoped_allocator_\", sa_id, \"_\", invocation_count);\n+        absl::StrCat(\"scoped_allocator_\", sa_id, \"_\", invocation_count);\n     TF_RETURN_IF_ERROR(ConstructScopedAllocatorNode(\n         sa_opti, graph, node_map, ops, device_name, dtype, sa_id, sa_name,\n         input_shapes, inputs, sa_shape));\n \n     // Build a ScopedAllocatorConcat below all of the input nodes.\n     std::vector<NodeDefBuilder::NodeOut> sac_inputs;\n-    string sac_name = strings::StrCat(\"scoped_allocator_concat_\", sa_id, \"_\",\n-                                      invocation_count);\n+    string sac_name =\n+        absl::StrCat(\"scoped_allocator_concat_\", sa_id, \"_\", invocation_count);\n     TF_RETURN_IF_ERROR(BuildSAConcatNode(\n         graph, node_map, ops, op_instance_names, device_name, dtype, sa_id,\n         sa_name, sac_name, sa_shape, &sac_inputs));\n \n     // Construct a new instance of the parallel op and insert it\n     // immediately below the new ScopedAllocatorConcat.\n-    string sa_op_name = strings::StrCat(sa_name, \"_\", op_name);\n+    string sa_op_name = absl::StrCat(sa_name, \"_\", op_name);\n     TF_RETURN_IF_ERROR(BuildReplacementOp(graph, node_map, ops, device_name,\n                                           dtype, op_name, sac_name,\n                                           sa_op_name));\n \n     // Build a ScopedAllocatorSplit split below the new Op.\n-    string sas_name = strings::StrCat(\"scoped_allocator_split_\", sa_id, \"_\",\n-                                      invocation_count);\n+    string sas_name =\n+        absl::StrCat(\"scoped_allocator_split_\", sa_id, \"_\", invocation_count);\n     TF_RETURN_IF_ERROR(BuildSplitNode(graph, node_map, ops, input_shapes,\n                                       sac_inputs, device_name, dtype, op_name,\n                                       sa_id, sas_name, sa_name, sa_op_name));"
        },
        {
            "sha": "41b028826e070380779c607a021616e8c7fc7f0e",
            "filename": "tensorflow/core/grappler/optimizers/static_schedule.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fstatic_schedule.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d67fda38af7b210379cf97233fe11eda4fc07667/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fstatic_schedule.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fgrappler%2Foptimizers%2Fstatic_schedule.cc?ref=d67fda38af7b210379cf97233fe11eda4fc07667",
            "patch": "@@ -85,7 +85,7 @@ absl::Status EstimateEarliestExecutionTimes(\n       auto it = name_map.find(node_name);\n       if (it == name_map.end()) {\n         return errors::InvalidArgument(\n-            strings::StrCat(\"Unknown input node \", input));\n+            absl::StrCat(\"Unknown input node \", input));\n       }\n       const NodeDef* fanin = it->second;\n       fanouts[fanin].push_back(&node);\n@@ -148,7 +148,7 @@ absl::Status EstimateRequiredTimes(\n       auto it = name_map.find(node_name);\n       if (it == name_map.end()) {\n         return errors::InvalidArgument(\n-            strings::StrCat(\"Unknown input node \", input));\n+            absl::StrCat(\"Unknown input node \", input));\n       }\n       const NodeDef* fanin = it->second;\n       pending_fanouts[fanin] += 1;"
        }
    ],
    "stats": {
        "total": 97,
        "additions": 48,
        "deletions": 49
    }
}