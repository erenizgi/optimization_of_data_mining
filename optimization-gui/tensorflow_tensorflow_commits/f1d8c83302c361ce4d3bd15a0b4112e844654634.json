{
    "author": "pschuh",
    "message": "Generalize CommonPjRtClient::PrepareArguments for processing all the input\nargument handles. This requires introducing a new EventSet concept for\ncollecting the definition and device events before passing all of this to\nthe internal Execute() function.\n\nPiperOrigin-RevId: 841913034",
    "sha": "f1d8c83302c361ce4d3bd15a0b4112e844654634",
    "files": [
        {
            "sha": "0f895ff6047f2ef61d64919a2ff705a039f5cc8c",
            "filename": "third_party/xla/xla/pjrt/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2FBUILD?ref=f1d8c83302c361ce4d3bd15a0b4112e844654634",
            "patch": "@@ -143,7 +143,9 @@ cc_library(\n         \":device_event\",\n         \":host_callback\",\n         \":pjrt_client\",\n+        \":pjrt_executable\",\n         \":raw_buffer\",\n+        \":utils\",\n         \"//xla:future\",\n         \"//xla:literal\",\n         \"//xla:shape_util\",\n@@ -155,6 +157,7 @@ cc_library(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n         \"@com_google_absl//absl/functional:any_invocable\",\n         \"@com_google_absl//absl/log\","
        },
        {
            "sha": "03436e55390afbb34dc15b04a003858fd0faea42",
            "filename": "third_party/xla/xla/pjrt/abstract_tracked_device_buffer.h",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fabstract_tracked_device_buffer.h?ref=f1d8c83302c361ce4d3bd15a0b4112e844654634",
            "patch": "@@ -98,6 +98,18 @@ class AbstractTrackedDeviceBuffer {\n         \"WaitUntilBufferReadyOnStream is only implemented for GPU.\");\n   }\n \n+  // TODO(parkers): definition events are fixed, so we should just store them\n+  // directly.\n+  // Returns true if there is an error in any of the events.\n+  virtual bool AddDefinitionEventsToSet(PjRtDeviceEventSet& events) {\n+    LOG(FATAL) << \"TODO IMPLEMENT: AddDefinitionEventsToSet.\";\n+    return false;\n+  }\n+\n+  virtual void AddUsageEventsToSet(PjRtDeviceEventSet& events) {\n+    LOG(FATAL) << \"TODO IMPLEMENT: AddUsageEventsToSet.\";\n+  }\n+\n  protected:\n   void ReleaseDeviceMemory() {\n     raw_buffer_ = tsl::RCReference<CommonPjRtRawBuffer>();"
        },
        {
            "sha": "d3756104d08943d9e9a3e978f0678d53e7462ab2",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.cc",
            "status": "modified",
            "additions": 136,
            "deletions": 0,
            "changes": 136,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.cc?ref=f1d8c83302c361ce4d3bd15a0b4112e844654634",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/container/flat_hash_map.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/functional/any_invocable.h\"\n #include \"absl/log/check.h\"\n@@ -47,7 +48,9 @@ limitations under the License.\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/host_callback.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n+#include \"xla/pjrt/pjrt_executable.h\"\n #include \"xla/pjrt/raw_buffer.h\"\n+#include \"xla/pjrt/utils.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/shape.h\"\n #include \"xla/shape_util.h\"\n@@ -426,6 +429,139 @@ void CommonPjRtClient::ScheduleRemoteSend(\n   usage_event_promise->SetError(error);\n }\n \n+absl::Status CommonPjRtClient::PrepareArguments(\n+    const ExecuteOptions& options,\n+    absl::Span<PjRtBuffer* const> argument_handles,\n+    absl::Span<int const> donated_params, PjRtDeviceEventSet& extra_deps,\n+    PjRtDeviceEventSet& control_deps,\n+    absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>&\n+        input_buffers,\n+    absl::InlinedVector<CommonPjRtBuffer::ScopedHold, 4>& device_buffers,\n+    PjRtDevice* device, int replica, int partition,\n+    absl::Span<const Shape> parameter_device_shapes, bool& is_error) {\n+  input_buffers.reserve(argument_handles.size());\n+  device_buffers.reserve(argument_handles.size());\n+  auto donate_it = donated_params.begin();\n+  {\n+    tsl::profiler::TraceMe t2(\"Handle inputs\");\n+    // State for `TestBufferDonationClashes`.\n+    absl::flat_hash_map<const void*, std::pair<bool, int>> donation_clashes;\n+    donation_clashes.reserve(argument_handles.size());\n+    // The first element is the argument index of the donated buffer, and the\n+    // second element is the size in bytes of the donated buffer.\n+    std::vector<std::pair<int, size_t>> donated_buffer_stats;\n+    for (int i = 0; i < argument_handles.size(); ++i) {\n+      PjRtBuffer* handle = argument_handles[i];\n+      auto* tfrt_buffer = tensorflow::down_cast<CommonPjRtBufferImpl*>(handle);\n+      if (tfrt_buffer->device() != device) {\n+        return InvalidArgument(\n+            \"Buffer passed to Execute() as argument %d to replica %d is on \"\n+            \"device %s, but replica is assigned to device %s.\",\n+            i, replica, tfrt_buffer->device()->DebugString(),\n+            device->DebugString());\n+      }\n+      const bool donated_param =\n+          donate_it != donated_params.end() && *donate_it == i;\n+      const bool donation_denied_at_runtime =\n+          options.non_donatable_input_indices.contains(i);\n+      if (donated_param && donation_denied_at_runtime &&\n+          tfrt_buffer->on_device_shape().has_layout() &&\n+          tfrt_buffer->on_device_shape().layout().memory_space() ==\n+              Layout::kHostMemorySpace) {\n+        return absl::UnimplementedError(\n+            \"pinned_host buffers do not support donation denial at runtime via \"\n+            \"`ExecuteOptions::non_donatable_input_indices`\");\n+      }\n+      bool must_donate = donated_param && !donation_denied_at_runtime;\n+      if (must_donate) {\n+        ++donate_it;\n+        if (VLOG_IS_ON(1)) {\n+          TF_ASSIGN_OR_RETURN(size_t on_device_size,\n+                              tfrt_buffer->GetOnDeviceSizeInBytes());\n+          donated_buffer_stats.emplace_back(std::make_pair(i, on_device_size));\n+        }\n+      }\n+      TF_RETURN_IF_ERROR(TestBufferDonationClashes(\n+          tfrt_buffer, donation_clashes, must_donate, i, replica, partition));\n+      device_buffers.emplace_back(tfrt_buffer->GetBufferWithHold(\n+          must_donate ? CommonPjRtBuffer::ScopedHold::kDonation\n+                      : CommonPjRtBuffer::ScopedHold::kUsage));\n+      CommonPjRtBuffer::ScopedHold& hold = device_buffers.back();\n+      if (!hold.ok()) {\n+        return InvalidArgument(\n+            \"Invalid buffer passed to Execute() as argument %d to replica %d: \"\n+            \"%s\",\n+            i, replica, hold.status().ToString());\n+      }\n+      auto* device_buffer = hold.buffer();\n+\n+      const bool is_handle_dynamic_shape =\n+          handle->on_device_shape().is_dynamic();\n+\n+      const Shape& expected_shape = parameter_device_shapes[i];\n+      if (device_buffer->raw_buffer()) {\n+        tsl::RCReference<CommonPjRtRawBuffer> actual_buffer =\n+            device_buffer->raw_buffer();\n+        if (is_handle_dynamic_shape && !expected_shape.is_dynamic()) {\n+          TF_ASSIGN_OR_RETURN(auto handle_logical_device_shape,\n+                              handle->logical_on_device_shape());\n+          auto status_or_buffer =\n+              actual_buffer->RemoveDynamicShapeMetadataIfPresent(\n+                  handle_logical_device_shape);\n+\n+          if (!status_or_buffer.ok()) {\n+            absl::Status status = status_or_buffer.status();\n+            tsl::errors::AppendToMessage(\n+                &status, absl::StrCat(\"; Error when preparing the input buffer \"\n+                                      \"to Execute() as argument \",\n+                                      i, \" to replica \", replica));\n+            return status;\n+          }\n+          actual_buffer = std::move(status_or_buffer).value();\n+        }\n+        input_buffers.push_back(std::move(actual_buffer));\n+      } else {\n+        is_error = true;\n+      }\n+\n+      // Definition events are never modified after buffer construction.\n+      is_error |= device_buffer->AddDefinitionEventsToSet(extra_deps);\n+      // If we are trying to donate this buffer, we must wait on its usage\n+      // events as well as its definition events to ensure that all reads on\n+      // this buffer (e.g., d2h transfer) have been completed before it can be\n+      // mutated. Usage holds on this buffer are excluded during a donation hold\n+      // so we know that its usage events won't be modified while we are\n+      // enqueueing, but we ignore any errors from usage events.\n+      if (must_donate) {\n+        device_buffer->AddUsageEventsToSet(control_deps);\n+      }\n+    }\n+    // Debug logging of buffer donation and input buffer shapes and size.\n+    if (VLOG_IS_ON(1)) {\n+      // Buffer donation information.\n+      if (!argument_handles.empty()) {\n+        LOG(INFO) << donated_buffer_stats.size() << \" arguments out of total \"\n+                  << argument_handles.size() << \" arguments will be donated.\";\n+        for (auto [index, buffer_size] : donated_buffer_stats) {\n+          LOG(INFO) << \"Argument \" << index << \" with size \" << buffer_size\n+                    << \" will be donated.\";\n+        }\n+      }\n+      // Input buffers shape and size.\n+      for (int i = 0; i < input_buffers.size(); ++i) {\n+        size_t buffer_size = input_buffers[i]->GetOnDeviceSizeInBytes();\n+        TF_ASSIGN_OR_RETURN(Shape actual_input_shape,\n+                            argument_handles[i]->logical_on_device_shape());\n+        VLOG(2) << \"input buffer with index \" << i\n+                << \" has shape: \" << actual_input_shape.ToString()\n+                << \" and size: \" << buffer_size;\n+      }\n+    }\n+  }\n+\n+  return absl::OkStatus();\n+}\n+\n absl::StatusOr<absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>>\n CommonPjRtClient::AllocateOutputBuffersWithInputReuse(\n     const Shape& output_device_shape,"
        },
        {
            "sha": "5470a087376444fcfbf2d7754bafd0fa8551e3d9",
            "filename": "third_party/xla/xla/pjrt/common_pjrt_client.h",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fcommon_pjrt_client.h?ref=f1d8c83302c361ce4d3bd15a0b4112e844654634",
            "patch": "@@ -236,6 +236,17 @@ class CommonPjRtClient : public PjRtClient {\n       Future<std::string> serialized_descriptor,\n       PjRtBuffer::RemoteSendCallback on_done);\n \n+  static absl::Status PrepareArguments(\n+      const ExecuteOptions& options,\n+      absl::Span<PjRtBuffer* const> argument_handles,\n+      absl::Span<int const> donated_params, PjRtDeviceEventSet& extra_deps,\n+      PjRtDeviceEventSet& control_deps,\n+      absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>&\n+          input_buffers,\n+      absl::InlinedVector<CommonPjRtBuffer::ScopedHold, 4>& device_buffers,\n+      PjRtDevice* device, int replica, int partition,\n+      absl::Span<const Shape> parameter_device_shapes, bool& is_error);\n+\n   absl::StatusOr<absl::InlinedVector<tsl::RCReference<CommonPjRtRawBuffer>, 4>>\n   AllocateOutputBuffersWithInputReuse(\n       const Shape& output_device_shape,"
        },
        {
            "sha": "5e307e0dcc5cc9acde353dfe71b429744bfd4e54",
            "filename": "third_party/xla/xla/pjrt/device_event.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fdevice_event.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/f1d8c83302c361ce4d3bd15a0b4112e844654634/third_party%2Fxla%2Fxla%2Fpjrt%2Fdevice_event.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fdevice_event.h?ref=f1d8c83302c361ce4d3bd15a0b4112e844654634",
            "patch": "@@ -106,6 +106,13 @@ class PjRtDeviceEventPromise : public PjRtDeviceEventOrPromise {\n   virtual void SetReady() = 0;\n };\n \n+// A collection of events. This is not an event itself because we may want to\n+// add events in the future.\n+class PjRtDeviceEventSet {\n+ public:\n+  virtual ~PjRtDeviceEventSet() = default;\n+};\n+\n }  // namespace xla\n \n #endif  // XLA_PJRT_DEVICE_EVENT_H_"
        }
    ],
    "stats": {
        "total": 169,
        "additions": 169,
        "deletions": 0
    }
}