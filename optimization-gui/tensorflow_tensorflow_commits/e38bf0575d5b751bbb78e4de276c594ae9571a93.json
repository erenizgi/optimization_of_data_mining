{
    "author": "shawnwang18",
    "message": "PR #30624: [XLA:GPU] Refactoring the command dependency implementation through token resources\n\nImported from GitHub PR https://github.com/openxla/xla/pull/30624\n\nüìù Summary of Changes\nIn command buffer, there are two places that relies on resource dependency to specify command order.\n1.  When command buffer preserves the control dependency that is original existed across HLO operators.\n2.  When specifying the dependency for cuda-graph topology inferred from LHS scheduling.\n\nThis PR introduces a unified way to specify the token dependency across commands:\n1.  Each CommandBufferCmd has a local variable of type `std::shared_ptr<Resource> token_`,\n2. On instantiating CommandBufferCmd, auto create a Write resource use for local token resources;\n3. If other commands has execution dependency on current command, then other command needs to include a READ resource use of the token resource of current command in other commands' resoure_use vector.\n\nIn this approach, LHS and control dependency has the unified way to describe the dependency across commands.\n\nüéØ Justification\nMore clean and easy to understand design.\n\nüöÄ Kind of Contribution\n‚ôªÔ∏è Cleanup\n\nüß™ Unit Tests:\nThis PR reimplements existing feature, so it is already covered by current unit tests.\nxla/backends/gpu/runtime/command_buffer_thunk_test.cc\n\nCopybara import of the project:\n\n--\ne206e98d0631ee79e3ec284007f71132a8d01f51 by Shawn Wang <shawnw@nvidia.com>:\n\nRefactoring the resource dependency in command buffer, and now cuda graph topology is using the same set of token resources to specify LHS topology and control depenency from original HLO operations\n\n--\na946942e60873945a4b741ee360628d3b7a6843c by Shawn Wang <shawnw@nvidia.com>:\n\nfix typo\n\nMerging this change closes #30624\n\nPiperOrigin-RevId: 800841689",
    "sha": "e38bf0575d5b751bbb78e4de276c594ae9571a93",
    "files": [
        {
            "sha": "884f0f13a0e1c28f1790146c71a49e727ce9f8c8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 53,
            "deletions": 92,
            "changes": 145,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=e38bf0575d5b751bbb78e4de276c594ae9571a93",
            "patch": "@@ -238,16 +238,12 @@ namespace {\n class CommandOperation : public ExecutionGraph::Operation {\n  public:\n   explicit CommandOperation(CommandBufferCmd::BufferUseVector buffers,\n-                            ResourceUseVector resources,\n                             const CommandBufferCmd* cmd)\n       : name_(absl::StrFormat(\"cmd %s: %s\", cmd->ToString(),\n                               cmd->profile_annotation())),\n         buffers_(std::move(buffers)),\n-        resources_(std::move(resources)),\n         cmd_(cmd),\n-        token_(Resource::Create(Resource::Kind::kToken)) {\n-    resources_.push_back(ResourceUse::Write(token_));\n-  }\n+        resources_(cmd_->resources()) {}\n \n   absl::string_view name() const final { return name_; }\n   absl::Span<const BufferUse> BufferUses() const final { return buffers_; }\n@@ -258,7 +254,6 @@ class CommandOperation : public ExecutionGraph::Operation {\n     resources_.push_back(resource_use);\n   }\n \n-  std::shared_ptr<Resource> token() const { return token_; }\n   const CommandBufferCmd* cmd() const { return cmd_; }\n \n   std::string ToString() const final {\n@@ -271,16 +266,15 @@ class CommandOperation : public ExecutionGraph::Operation {\n       resource_reprs.push_back(\n           absl::StrFormat(\"%s@%p(%s)\", kind, use.resource().get(), access));\n     }\n-\n     return absl::StrFormat(\"%s resources=[%s]\", cmd_->ToString(),\n                            absl::StrJoin(resource_reprs, \", \"));\n   }\n \n  private:\n   std::string name_;\n   CommandBufferCmd::BufferUseVector buffers_;\n-  ResourceUseVector resources_;\n   const CommandBufferCmd* cmd_;\n+  ResourceUseVector resources_;\n \n   // The token resource is used to specify dependency other than buffer data\n   // flow, e.g, LHS topology will use token resouce to specify dependency across\n@@ -304,7 +298,7 @@ static std::vector<CommandOperation> CreateCommandOperations(\n     // For concurrent synchronization mode, pass in buffer and resouces for\n     // dependency inference.\n     for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n-      operations.emplace_back(cmd->buffers(), cmd->resources(), cmd.get());\n+      operations.emplace_back(cmd->buffers(), cmd.get());\n     }\n   }\n \n@@ -313,8 +307,7 @@ static std::vector<CommandOperation> CreateCommandOperations(\n     // For LHS mode, don't pass in buffers.\n     // Will use token resource to specify dependency across commands.\n     for (const std::unique_ptr<CommandBufferCmd>& cmd : commands) {\n-      operations.emplace_back(CommandBufferCmd::BufferUseVector{},\n-                              cmd->resources(), cmd.get());\n+      operations.emplace_back(CommandBufferCmd::BufferUseVector{}, cmd.get());\n     }\n \n     auto is_async_start = [](const CommandOperation& op) -> bool {\n@@ -352,18 +345,18 @@ static std::vector<CommandOperation> CreateCommandOperations(\n             continue;\n           }\n           operations[i].add_resouce_use(\n-              ResourceUse::Read(operations[j].token()));\n+              ResourceUse::Read(commands[j]->token()));\n           break;\n         }\n       } else if (is_async_done(operations[i])) {\n         int64_t async_start_cmd_id = find_async_start_cmd_id(i);\n         CHECK_NE(async_start_cmd_id, -1);\n         operations[i].add_resouce_use(\n-            ResourceUse::Read(operations[async_start_cmd_id].token()));\n+            ResourceUse::Read(commands[async_start_cmd_id]->token()));\n         CHECK_GT(i, 0);\n         if ((i - 1) != async_start_cmd_id) {\n           operations[i].add_resouce_use(\n-              ResourceUse::Read(operations[i - 1].token()));\n+              ResourceUse::Read(commands[i - 1]->token()));\n         }\n       } else {\n         for (int64_t j = i - 1; j >= 0; --j) {\n@@ -373,7 +366,7 @@ static std::vector<CommandOperation> CreateCommandOperations(\n             continue;\n           }\n           operations[i].add_resouce_use(\n-              ResourceUse::Read(operations[j].token()));\n+              ResourceUse::Read(commands[j]->token()));\n           break;\n         }\n       }\n@@ -830,9 +823,8 @@ absl::StatusOr<se::CommandBuffer*> TracedCommandBuffer::GetOrTraceCommandBuffer(\n // TracedCommandBufferCmd\n //===----------------------------------------------------------------------===//\n \n-TracedCommandBufferCmd::TracedCommandBufferCmd(CommandBufferCmdType cmd_type,\n-                                               ResourceUseVector resources)\n-    : CommandBufferCmd(cmd_type, std::move(resources)) {}\n+TracedCommandBufferCmd::TracedCommandBufferCmd(CommandBufferCmdType cmd_type)\n+    : CommandBufferCmd(cmd_type) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*>\n TracedCommandBufferCmd::RecordTracedCommand(\n@@ -871,8 +863,7 @@ TracedCommandBufferCmd::RecordTracedCommand(\n // EmptyCmd\n //===----------------------------------------------------------------------===//\n \n-EmptyCmd::EmptyCmd(ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kEmptyCmd, std::move(resources)) {}\n+EmptyCmd::EmptyCmd() : CommandBufferCmd(CommandBufferCmdType::kEmptyCmd) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*> EmptyCmd::Record(\n     const Thunk::ExecuteParams& execute_params,\n@@ -894,9 +885,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> EmptyCmd::Record(\n //===----------------------------------------------------------------------===//\n \n AsyncDoneCmd::AsyncDoneCmd(\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kAsyncDone, std::move(resources)),\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n+    : CommandBufferCmd(CommandBufferCmdType::kAsyncDone),\n       async_events_(std::move(async_events)) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*> AsyncDoneCmd::Record(\n@@ -917,10 +907,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> AsyncDoneCmd::Record(\n // ComputationId\n //===----------------------------------------------------------------------===//\n \n-ComputationIdCmd::ComputationIdCmd(BufferAllocation::Slice dest, Kind kind,\n-                                   ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kComputationIdCmd,\n-                       std::move(resources)),\n+ComputationIdCmd::ComputationIdCmd(BufferAllocation::Slice dest, Kind kind)\n+    : CommandBufferCmd(CommandBufferCmdType::kComputationIdCmd),\n       dest_(dest),\n       kind_(kind) {}\n \n@@ -969,9 +957,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> ComputationIdCmd::Record(\n LaunchCmd::LaunchCmd(std::string kernel_name,\n                      absl::Span<const BufferAllocation::Slice> args,\n                      absl::Span<const MemoryAccess> args_access,\n-                     LaunchDimensions dims, int64_t shmem_bytes,\n-                     ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kLaunchCmd, std::move(resources)),\n+                     LaunchDimensions dims, int64_t shmem_bytes)\n+    : CommandBufferCmd(CommandBufferCmdType::kLaunchCmd),\n       kernel_name_(std::move(kernel_name)),\n       args_(args.begin(), args.end()),\n       args_access_(args_access.begin(), args_access.end()),\n@@ -1061,10 +1048,8 @@ CommandBufferCmd::BufferUseVector LaunchCmd::buffers() const {\n \n CustomKernelLaunchCmd::CustomKernelLaunchCmd(\n     absl::Span<const BufferAllocation::Slice> args,\n-    absl::Span<const MemoryAccess> args_access, CustomKernel custom_kernel,\n-    ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kCustomKernelLaunchCmd,\n-                       std::move(resources)),\n+    absl::Span<const MemoryAccess> args_access, CustomKernel custom_kernel)\n+    : CommandBufferCmd(CommandBufferCmdType::kCustomKernelLaunchCmd),\n       args_(args.begin(), args.end()),\n       args_access_(args_access.begin(), args_access.end()),\n       custom_kernel_(std::move(custom_kernel)) {}\n@@ -1143,10 +1128,8 @@ CommandBufferCmd::BufferUseVector CustomKernelLaunchCmd::buffers() const {\n \n MemcpyDeviceToDeviceCmd::MemcpyDeviceToDeviceCmd(BufferAllocation::Slice dst,\n                                                  BufferAllocation::Slice src,\n-                                                 int64_t num_bytes,\n-                                                 ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kMemcpyDeviceToDeviceCmd,\n-                       std::move(resources)),\n+                                                 int64_t num_bytes)\n+    : CommandBufferCmd(CommandBufferCmdType::kMemcpyDeviceToDeviceCmd),\n       dst_(dst),\n       src_(src),\n       num_bytes_(num_bytes) {}\n@@ -1189,9 +1172,8 @@ CommandBufferCmd::BufferUseVector MemcpyDeviceToDeviceCmd::buffers() const {\n // MemzeroCmd\n //===----------------------------------------------------------------------===//\n \n-MemzeroCmd::MemzeroCmd(BufferAllocation::Slice dst, ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kMemzeroCmd, std::move(resources)),\n-      dst_(dst) {}\n+MemzeroCmd::MemzeroCmd(BufferAllocation::Slice dst)\n+    : CommandBufferCmd(CommandBufferCmdType::kMemzeroCmd), dst_(dst) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*> MemzeroCmd::Record(\n     const Thunk::ExecuteParams& execute_params,\n@@ -1229,10 +1211,8 @@ CommandBufferCmd::BufferUseVector MemzeroCmd::buffers() const {\n // Memset32Cmd\n //===----------------------------------------------------------------------===//\n \n-Memset32Cmd::Memset32Cmd(BufferAllocation::Slice dst, uint32_t bit_pattern,\n-                         ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kMemset32Cmd,\n-                       std::move(resources)),\n+Memset32Cmd::Memset32Cmd(BufferAllocation::Slice dst, uint32_t bit_pattern)\n+    : CommandBufferCmd(CommandBufferCmdType::kMemset32Cmd),\n       dst_(dst),\n       bit_pattern_(bit_pattern) {}\n \n@@ -1273,9 +1253,8 @@ CommandBufferCmd::BufferUseVector Memset32Cmd::buffers() const {\n // ChildCmd\n //===----------------------------------------------------------------------===//\n \n-ChildCmd::ChildCmd(CommandBufferCmdExecutor child_commands,\n-                   ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kChildCmd, std::move(resources)),\n+ChildCmd::ChildCmd(CommandBufferCmdExecutor child_commands)\n+    : CommandBufferCmd(CommandBufferCmdType::kChildCmd),\n       child_commands_(std::move(child_commands)) {}\n \n bool ChildCmd::requires_initialization() {\n@@ -1325,9 +1304,8 @@ absl::StatusOr<const se::CommandBuffer::Command*> ChildCmd::Record(\n //===----------------------------------------------------------------------===//\n \n CaseCmd::CaseCmd(BufferAllocation::Slice index, bool index_is_bool,\n-                 std::vector<CommandBufferCmdExecutor> branches,\n-                 ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kCaseCmd, std::move(resources)),\n+                 std::vector<CommandBufferCmdExecutor> branches)\n+    : CommandBufferCmd(CommandBufferCmdType::kCaseCmd),\n       index_(index),\n       index_is_bool_(index_is_bool),\n       branches_(std::move(branches)) {}\n@@ -1401,9 +1379,8 @@ CommandBufferCmd::BufferUseVector CaseCmd::buffers() const {\n \n WhileCmd::WhileCmd(BufferAllocation::Slice pred,\n                    CommandBufferCmdExecutor cond_commands,\n-                   CommandBufferCmdExecutor body_commands,\n-                   ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kWhileCmd, std::move(resources)),\n+                   CommandBufferCmdExecutor body_commands)\n+    : CommandBufferCmd(CommandBufferCmdType::kWhileCmd),\n       pred_(pred),\n       cond_commands_(std::move(cond_commands)),\n       body_commands_(std::move(body_commands)) {}\n@@ -1468,10 +1445,8 @@ CommandBufferCmd::BufferUseVector WhileCmd::buffers() const {\n GemmCmd::GemmCmd(GemmConfig config, const BufferAllocation::Slice& lhs_buffer,\n                  const BufferAllocation::Slice& rhs_buffer,\n                  const BufferAllocation::Slice& output_buffer,\n-                 const BufferAllocation::Slice& workspace, bool deterministic,\n-                 ResourceUseVector resources)\n-    : TracedCommandBufferCmd(CommandBufferCmdType::kGemmCmd,\n-                             std::move(resources)),\n+                 const BufferAllocation::Slice& workspace, bool deterministic)\n+    : TracedCommandBufferCmd(CommandBufferCmdType::kGemmCmd),\n       config_(std::move(config)),\n       lhs_buffer_(lhs_buffer),\n       rhs_buffer_(rhs_buffer),\n@@ -1525,10 +1500,8 @@ CommandBufferCmd::BufferUseVector GemmCmd::buffers() const {\n // CublasLtCmd\n //===----------------------------------------------------------------------===//\n \n-CublasLtCmd::CublasLtCmd(const CublasLtMatmulThunk& matmul_thunk,\n-                         ResourceUseVector resources)\n-    : TracedCommandBufferCmd(CommandBufferCmdType::kCublasLtCmd,\n-                             std::move(resources)),\n+CublasLtCmd::CublasLtCmd(const CublasLtMatmulThunk& matmul_thunk)\n+    : TracedCommandBufferCmd(CommandBufferCmdType::kCublasLtCmd),\n       CublasLtMatmulThunk(matmul_thunk) {}\n \n absl::Status CublasLtCmd::Initialize(const Thunk::InitializeParams& params,\n@@ -1605,10 +1578,8 @@ CommandBufferCmd::BufferUseVector CublasLtCmd::buffers() const {\n //===----------------------------------------------------------------------===//\n \n CuDnnCmd::CuDnnCmd(absl::Span<const BufferAllocation::Slice> args,\n-                   const std::shared_ptr<se::dnn::LazyDnnGraph> graph,\n-                   ResourceUseVector resources)\n-    : TracedCommandBufferCmd(CommandBufferCmdType::kCuDnnCmd,\n-                             std::move(resources)),\n+                   const std::shared_ptr<se::dnn::LazyDnnGraph> graph)\n+    : TracedCommandBufferCmd(CommandBufferCmdType::kCuDnnCmd),\n       args_(args.cbegin(), args.cend()),\n       graph_(graph) {}\n \n@@ -1856,9 +1827,8 @@ CommandBufferCmd::BufferUseVector CustomCallCmd::buffers() const {\n \n CollectiveCmd::CollectiveCmd(\n     CommandBufferCmdType cmd_type, CollectiveConfig config,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n-    : CommandBufferCmd(cmd_type, std::move(resources)),\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n+    : CommandBufferCmd(cmd_type),\n       config_(std::move(config)),\n       async_events_(std::move(async_events)) {}\n \n@@ -1910,10 +1880,9 @@ CollectiveCmd::RecordTracedCommand(\n AllReduceCmd::AllReduceCmd(\n     CollectiveConfig config, ReductionKind reduction_kind,\n     absl::Span<const CollectiveThunk::Buffer> buffers,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n     : CollectiveCmd(CommandBufferCmdType::kAllReduceCmd, std::move(config),\n-                    std::move(async_events), std::move(resources)),\n+                    std::move(async_events)),\n       reduction_kind_(reduction_kind),\n       buffers_(buffers.begin(), buffers.end()) {}\n \n@@ -1973,10 +1942,9 @@ CommandBufferCmd::BufferUseVector AllReduceCmd::buffers() const {\n ReduceScatterCmd::ReduceScatterCmd(\n     CollectiveConfig config, ReductionKind reduction_kind,\n     absl::Span<const CollectiveThunk::Buffer> buffers,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n     : CollectiveCmd(CommandBufferCmdType::kReduceScatterCmd, std::move(config),\n-                    std::move(async_events), std::move(resources)),\n+                    std::move(async_events)),\n       reduction_kind_(reduction_kind),\n       buffers_(buffers.begin(), buffers.end()) {}\n \n@@ -2038,10 +2006,9 @@ CommandBufferCmd::BufferUseVector ReduceScatterCmd::buffers() const {\n AllToAllCmd::AllToAllCmd(\n     CollectiveConfig config, bool has_split_dimension,\n     absl::Span<const CollectiveThunk::Buffer> buffers,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n     : CollectiveCmd(CommandBufferCmdType::kAllToAllCmd, std::move(config),\n-                    std::move(async_events), std::move(resources)),\n+                    std::move(async_events)),\n       has_split_dimension_(has_split_dimension),\n       buffers_(buffers.begin(), buffers.end()) {}\n \n@@ -2099,10 +2066,9 @@ CommandBufferCmd::BufferUseVector AllToAllCmd::buffers() const {\n \n AllGatherCmd::AllGatherCmd(\n     CollectiveConfig config, absl::Span<const CollectiveThunk::Buffer> buffers,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n     : CollectiveCmd(CommandBufferCmdType::kAllGatherCmd, std::move(config),\n-                    std::move(async_events), std::move(resources)),\n+                    std::move(async_events)),\n       buffers_(buffers.begin(), buffers.end()) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n@@ -2160,11 +2126,9 @@ CommandBufferCmd::BufferUseVector AllGatherCmd::buffers() const {\n \n CollectiveBroadcastCmd::CollectiveBroadcastCmd(\n     CollectiveConfig config, absl::Span<const CollectiveThunk::Buffer> buffers,\n-    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-    ResourceUseVector resources)\n+    std::shared_ptr<CollectiveThunk::AsyncEvents> async_events)\n     : CollectiveCmd(CommandBufferCmdType::kCollectiveBroadcastCmd,\n-                    std::move(config), std::move(async_events),\n-                    std::move(resources)),\n+                    std::move(config), std::move(async_events)),\n       buffers_(buffers.begin(), buffers.end()) {}\n \n absl::StatusOr<const se::CommandBuffer::Command*>\n@@ -2228,10 +2192,8 @@ DynamicSliceFusionCmd::DynamicSliceFusionCmd(\n     std::vector<std::optional<std::vector<DynamicSliceThunk::Offset>>> offsets,\n     std::vector<std::optional<Shape>> orig_shapes,\n     std::vector<std::optional<Shape>> sliced_shapes,\n-    std::vector<std::optional<uint64_t>> offset_byte_sizes,\n-    ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kDynamicSliceFusionCmd,\n-                       std::move(resources)),\n+    std::vector<std::optional<uint64_t>> offset_byte_sizes)\n+    : CommandBufferCmd(CommandBufferCmdType::kDynamicSliceFusionCmd),\n       embedded_commands_(std::move(embedded_commands)),\n       fake_allocations_(std::move(fake_allocations)) {\n   // Zip all arguments together to create a list of SliceDef.\n@@ -2491,9 +2453,8 @@ CommandBufferCmd::BufferUseVector DynamicSliceFusionCmd::buffers() const {\n DynamicSliceCopyFusionCmd::DynamicSliceCopyFusionCmd(\n     const BufferAllocation::Slice& source_buffer,\n     const BufferAllocation::Slice& destination_buffer, uint64_t mem_size,\n-    DynamicMemcpyThunk::Offsets offsets, ResourceUseVector resources)\n-    : CommandBufferCmd(CommandBufferCmdType::kDynamicSliceCopyFusionCmd,\n-                       std::move(resources)),\n+    DynamicMemcpyThunk::Offsets offsets)\n+    : CommandBufferCmd(CommandBufferCmdType::kDynamicSliceCopyFusionCmd),\n       source_buffer_(source_buffer),\n       destination_buffer_(destination_buffer),\n       mem_size_(mem_size),"
        },
        {
            "sha": "1818d0ae228cc59589408c1a4a2eb95eb43ea0ba",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.h",
            "status": "modified",
            "additions": 44,
            "deletions": 55,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h?ref=e38bf0575d5b751bbb78e4de276c594ae9571a93",
            "patch": "@@ -126,11 +126,12 @@ using ResourceUseVector = absl::InlinedVector<ResourceUse, 1>;\n \n class CommandBufferCmd {\n  public:\n-  CommandBufferCmd(CommandBufferCmdType cmd_type, ResourceUseVector resources,\n+  CommandBufferCmd(CommandBufferCmdType cmd_type,\n                    se::StreamPriority priority = se::StreamPriority::Default)\n-      : cmd_type_(cmd_type),\n-        resources_(std::move(resources)),\n-        priority_(priority) {}\n+      : cmd_type_(cmd_type), priority_(priority) {\n+    token_ = Resource::Create(Resource::kToken);\n+    resources_.push_back(ResourceUse::Write(token_));\n+  }\n \n   virtual ~CommandBufferCmd() = default;\n \n@@ -292,6 +293,12 @@ class CommandBufferCmd {\n   // Returns all buffers used by the cmd. These will be used to track cmd\n   // updates, thus they need to be consistent across calls to the function.\n   virtual BufferUseVector buffers() const { return {}; }\n+\n+  std::shared_ptr<Resource> token() const { return token_; }\n+\n+  void add_resouce_use(ResourceUse resource_use) {\n+    resources_.push_back(resource_use);\n+  }\n   ResourceUseVector resources() const { return resources_; }\n \n   // Returns true if command implemented as a nested command buffer.\n@@ -313,8 +320,14 @@ class CommandBufferCmd {\n  private:\n   std::string profile_annotation_;\n   CommandBufferCmdType cmd_type_;\n+\n   ResourceUseVector resources_;\n \n+  // The token resource is used to specify additional dependency across\n+  // commands, like control dependency across HLO operators, and LHS scheduling\n+  // dependency.\n+  std::shared_ptr<Resource> token_;\n+\n   // Command priority, currently only support default, lowest and highest\n   // priority.\n   se::StreamPriority priority_ = se::StreamPriority::Default;\n@@ -533,8 +546,7 @@ class TracedCommandBuffer : public CommandBufferCmd::State {\n // A base class for commands implemented as tracing of stream activities.\n class TracedCommandBufferCmd : public CommandBufferCmd {\n  protected:\n-  explicit TracedCommandBufferCmd(CommandBufferCmdType cmd_type,\n-                                  ResourceUseVector resources = {});\n+  explicit TracedCommandBufferCmd(CommandBufferCmdType cmd_type);\n \n   // Creates a command buffer by calling a user-provided `trace` function and\n   // adds it as a nested command to `command_buffer`. Traced command buffers\n@@ -552,7 +564,7 @@ class TracedCommandBufferCmd : public CommandBufferCmd {\n \n class EmptyCmd : public CommandBufferCmd {\n  public:\n-  explicit EmptyCmd(ResourceUseVector resources = {});\n+  explicit EmptyCmd();\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -569,8 +581,7 @@ class EmptyCmd : public CommandBufferCmd {\n class AsyncDoneCmd : public CommandBufferCmd {\n  public:\n   explicit AsyncDoneCmd(\n-      std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-      ResourceUseVector resources = {});\n+      std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -596,8 +607,7 @@ class ComputationIdCmd : public CommandBufferCmd {\n  public:\n   enum class Kind { kReplica, kPartition };\n \n-  ComputationIdCmd(BufferAllocation::Slice dest, Kind kind,\n-                   ResourceUseVector resources = {});\n+  ComputationIdCmd(BufferAllocation::Slice dest, Kind kind);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -620,8 +630,7 @@ class LaunchCmd : public CommandBufferCmd {\n   LaunchCmd(std::string kernel_name,\n             absl::Span<const BufferAllocation::Slice> args,\n             absl::Span<const BufferUse::MemoryAccess> args_access,\n-            LaunchDimensions dims, int64_t shmem_bytes,\n-            ResourceUseVector resources = {});\n+            LaunchDimensions dims, int64_t shmem_bytes);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -655,8 +664,7 @@ class CustomKernelLaunchCmd : public CommandBufferCmd {\n  public:\n   CustomKernelLaunchCmd(absl::Span<const BufferAllocation::Slice> args,\n                         absl::Span<const BufferUse::MemoryAccess> args_access,\n-                        CustomKernel custom_kernel,\n-                        ResourceUseVector resources = {});\n+                        CustomKernel custom_kernel);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -687,8 +695,7 @@ class CustomKernelLaunchCmd : public CommandBufferCmd {\n class MemcpyDeviceToDeviceCmd : public CommandBufferCmd {\n  public:\n   MemcpyDeviceToDeviceCmd(BufferAllocation::Slice dst,\n-                          BufferAllocation::Slice src, int64_t num_bytes,\n-                          ResourceUseVector resources = {});\n+                          BufferAllocation::Slice src, int64_t num_bytes);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -709,7 +716,7 @@ class MemcpyDeviceToDeviceCmd : public CommandBufferCmd {\n \n class MemzeroCmd : public CommandBufferCmd {\n  public:\n-  MemzeroCmd(BufferAllocation::Slice dst, ResourceUseVector resources = {});\n+  MemzeroCmd(BufferAllocation::Slice dst);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -728,8 +735,7 @@ class MemzeroCmd : public CommandBufferCmd {\n \n class Memset32Cmd : public CommandBufferCmd {\n  public:\n-  Memset32Cmd(BufferAllocation::Slice dst, uint32_t bit_pattern,\n-              ResourceUseVector resources = {});\n+  Memset32Cmd(BufferAllocation::Slice dst, uint32_t bit_pattern);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -749,8 +755,7 @@ class Memset32Cmd : public CommandBufferCmd {\n \n class ChildCmd : public CommandBufferCmd {\n  public:\n-  ChildCmd(CommandBufferCmdExecutor child_commands,\n-           ResourceUseVector resources = {});\n+  ChildCmd(CommandBufferCmdExecutor child_commands);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -783,8 +788,7 @@ class ChildCmd : public CommandBufferCmd {\n class CaseCmd : public CommandBufferCmd {\n  public:\n   CaseCmd(BufferAllocation::Slice index, bool index_is_bool,\n-          std::vector<CommandBufferCmdExecutor> branches,\n-          ResourceUseVector resources = {});\n+          std::vector<CommandBufferCmdExecutor> branches);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -813,8 +817,7 @@ class CaseCmd : public CommandBufferCmd {\n class WhileCmd : public CommandBufferCmd {\n  public:\n   WhileCmd(BufferAllocation::Slice pred, CommandBufferCmdExecutor cond_commands,\n-           CommandBufferCmdExecutor body_commands,\n-           ResourceUseVector resources = {});\n+           CommandBufferCmdExecutor body_commands);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -845,8 +848,7 @@ class GemmCmd : public TracedCommandBufferCmd {\n   GemmCmd(GemmConfig config, const BufferAllocation::Slice& lhs_buffer,\n           const BufferAllocation::Slice& rhs_buffer,\n           const BufferAllocation::Slice& output_buffer,\n-          const BufferAllocation::Slice& workspace, bool deterministic,\n-          ResourceUseVector resources = {});\n+          const BufferAllocation::Slice& workspace, bool deterministic);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -876,8 +878,7 @@ class GemmCmd : public TracedCommandBufferCmd {\n \n class CublasLtCmd : public TracedCommandBufferCmd, public CublasLtMatmulThunk {\n  public:\n-  CublasLtCmd(const CublasLtMatmulThunk& matmul_thunk,\n-              ResourceUseVector resources = {});\n+  CublasLtCmd(const CublasLtMatmulThunk& matmul_thunk);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -904,8 +905,7 @@ class CublasLtCmd : public TracedCommandBufferCmd, public CublasLtMatmulThunk {\n class CuDnnCmd : public TracedCommandBufferCmd {\n  public:\n   CuDnnCmd(absl::Span<const BufferAllocation::Slice> args,\n-           std::shared_ptr<se::dnn::LazyDnnGraph> graph,\n-           ResourceUseVector resources = {});\n+           std::shared_ptr<se::dnn::LazyDnnGraph> graph);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -939,9 +939,8 @@ class CustomCallCmd : public CommandBufferCmd {\n   CustomCallCmd(std::string target_name, CustomCallTarget call_target,\n                 std::vector<std::optional<Slice>> operands,\n                 std::vector<std::optional<Slice>> results,\n-                absl::string_view opaque, ResourceUseVector resources = {})\n-      : CommandBufferCmd(CommandBufferCmdType::kCustomCallCmd,\n-                         std::move(resources)),\n+                absl::string_view opaque)\n+      : CommandBufferCmd(CommandBufferCmdType::kCustomCallCmd),\n         target_name_(std::move(target_name)),\n         call_target_(std::move(call_target)),\n         opaque_(opaque),\n@@ -952,10 +951,8 @@ class CustomCallCmd : public CommandBufferCmd {\n                 std::vector<std::optional<Slice>> operands,\n                 std::vector<std::optional<Slice>> results,\n                 ffi::CallFrame call_frame,\n-                const HloComputation* called_computation,\n-                ResourceUseVector resources = {})\n-      : CommandBufferCmd(CommandBufferCmdType::kCustomCallCmd,\n-                         std::move(resources)),\n+                const HloComputation* called_computation)\n+      : CommandBufferCmd(CommandBufferCmdType::kCustomCallCmd),\n         target_name_(std::move(target_name)),\n         handler_(handler),\n         call_frame_(std::move(call_frame)),\n@@ -1015,8 +1012,7 @@ class CustomCallCmd : public CommandBufferCmd {\n class CollectiveCmd : public CommandBufferCmd {\n  public:\n   CollectiveCmd(CommandBufferCmdType cmd_type, CollectiveConfig config,\n-                std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-                ResourceUseVector resources = {});\n+                std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::Status Prepare(\n       const Thunk::PrepareParams& params,\n@@ -1053,8 +1049,7 @@ class AllReduceCmd : public CollectiveCmd {\n  public:\n   AllReduceCmd(CollectiveConfig config, ReductionKind reduction_kind,\n                absl::Span<const CollectiveThunk::Buffer> buffers,\n-               std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-               ResourceUseVector resources = {});\n+               std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -1076,8 +1071,7 @@ class ReduceScatterCmd : public CollectiveCmd {\n  public:\n   ReduceScatterCmd(CollectiveConfig config, ReductionKind reduction_kind,\n                    absl::Span<const CollectiveThunk::Buffer> buffers,\n-                   std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-                   ResourceUseVector resources = {});\n+                   std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -1099,8 +1093,7 @@ class AllToAllCmd : public CollectiveCmd {\n  public:\n   AllToAllCmd(CollectiveConfig config, bool has_split_dimension,\n               absl::Span<const CollectiveThunk::Buffer> buffers,\n-              std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-              ResourceUseVector resources = {});\n+              std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -1122,8 +1115,7 @@ class AllGatherCmd : public CollectiveCmd {\n  public:\n   AllGatherCmd(CollectiveConfig config,\n                absl::Span<const CollectiveThunk::Buffer> buffers,\n-               std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-               ResourceUseVector resources = {});\n+               std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -1145,8 +1137,7 @@ class CollectiveBroadcastCmd : public CollectiveCmd {\n   CollectiveBroadcastCmd(\n       CollectiveConfig config,\n       absl::Span<const CollectiveThunk::Buffer> buffers,\n-      std::shared_ptr<CollectiveThunk::AsyncEvents> async_events,\n-      ResourceUseVector resources = {});\n+      std::shared_ptr<CollectiveThunk::AsyncEvents> async_events);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,\n@@ -1173,8 +1164,7 @@ class DynamicSliceFusionCmd : public CommandBufferCmd {\n           offsets,\n       std::vector<std::optional<Shape>> orig_shapes,\n       std::vector<std::optional<Shape>> sliced_shapes,\n-      std::vector<std::optional<uint64_t>> offset_byte_sizes,\n-      ResourceUseVector resources = {});\n+      std::vector<std::optional<uint64_t>> offset_byte_sizes);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -1228,8 +1218,7 @@ class DynamicSliceCopyFusionCmd : public CommandBufferCmd {\n   DynamicSliceCopyFusionCmd(const BufferAllocation::Slice& source_buffer,\n                             const BufferAllocation::Slice& destination_buffer,\n                             uint64_t mem_size,\n-                            DynamicMemcpyThunk::Offsets offsets,\n-                            ResourceUseVector resources = {});\n+                            DynamicMemcpyThunk::Offsets offsets);\n \n   absl::StatusOr<const se::CommandBuffer::Command*> Record(\n       const Thunk::ExecuteParams& execute_params,"
        },
        {
            "sha": "4e3d27ec110f357171247b6b94f1b708e8af9134",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_emitter.cc",
            "status": "modified",
            "additions": 85,
            "deletions": 125,
            "changes": 210,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc?ref=e38bf0575d5b751bbb78e4de276c594ae9571a93",
            "patch": "@@ -76,47 +76,37 @@ static auto ArgsAccess(const std::vector<bool>& written) {\n   return args_access;\n }\n \n-static absl::StatusOr<Command> Convert(const KernelThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const KernelThunk& thunk) {\n   return std::make_unique<LaunchCmd>(\n       thunk.kernel_name(), thunk.arguments(), ArgsAccess(thunk.written()),\n-      thunk.launch_dimensions(), thunk.shmem_bytes(), resources);\n+      thunk.launch_dimensions(), thunk.shmem_bytes());\n }\n \n-static absl::StatusOr<Command> Convert(const CustomKernelThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const CustomKernelThunk& thunk) {\n   return std::make_unique<CustomKernelLaunchCmd>(\n-      thunk.arguments(), ArgsAccess(thunk.written()), thunk.custom_kernel(),\n-      resources);\n+      thunk.arguments(), ArgsAccess(thunk.written()), thunk.custom_kernel());\n }\n \n-static absl::StatusOr<Command> Convert(const DeviceToDeviceCopyThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const DeviceToDeviceCopyThunk& thunk) {\n   return std::make_unique<MemcpyDeviceToDeviceCmd>(\n-      thunk.destination(), thunk.source(), thunk.size_bytes(), resources);\n+      thunk.destination(), thunk.source(), thunk.size_bytes());\n }\n \n-static absl::StatusOr<Command> Convert(const DynamicMemcpyThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const DynamicMemcpyThunk& thunk) {\n   return std::make_unique<DynamicSliceCopyFusionCmd>(\n-      thunk.source(), thunk.destination(), thunk.mem_size(), thunk.offsets(),\n-      resources);\n+      thunk.source(), thunk.destination(), thunk.mem_size(), thunk.offsets());\n }\n \n-static absl::StatusOr<Command> Convert(const MemzeroThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<MemzeroCmd>(thunk.destination(), resources);\n+static absl::StatusOr<Command> Convert(const MemzeroThunk& thunk) {\n+  return std::make_unique<MemzeroCmd>(thunk.destination());\n }\n \n-static absl::StatusOr<Command> Convert(const Memset32BitValueThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<Memset32Cmd>(thunk.destination(), thunk.value(),\n-                                       resources);\n+static absl::StatusOr<Command> Convert(const Memset32BitValueThunk& thunk) {\n+  return std::make_unique<Memset32Cmd>(thunk.destination(), thunk.value());\n }\n \n static absl::StatusOr<Command> Convert(\n-    const WhileThunk& thunk, ResourceUseVector resources,\n-    const ConvertToCommandsOptions& options) {\n+    const WhileThunk& thunk, const ConvertToCommandsOptions& options) {\n   TF_ASSIGN_OR_RETURN(\n       CommandBufferCmdExecutor cond_cmds,\n       ConvertToCommands(thunk.condition_thunk_sequence()->thunks(), options));\n@@ -125,34 +115,29 @@ static absl::StatusOr<Command> Convert(\n       ConvertToCommands(thunk.body_thunk_sequence()->thunks(), options));\n \n   return std::make_unique<WhileCmd>(thunk.condition_result_buffer(),\n-                                    std::move(cond_cmds), std::move(body_cmds),\n-                                    resources);\n+                                    std::move(cond_cmds), std::move(body_cmds));\n }\n \n-static absl::StatusOr<Command> Convert(const GemmThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const GemmThunk& thunk) {\n   if (!thunk.workspace().has_value()) {\n     return absl::InternalError(\n         \"Gemm thunk does not contain a workspace buffer\");\n   }\n-  return std::make_unique<GemmCmd>(thunk.config(), thunk.lhs_buffer(),\n-                                   thunk.rhs_buffer(), thunk.output_buffer(),\n-                                   thunk.workspace().value(),\n-                                   thunk.deterministic(), resources);\n+  return std::make_unique<GemmCmd>(\n+      thunk.config(), thunk.lhs_buffer(), thunk.rhs_buffer(),\n+      thunk.output_buffer(), thunk.workspace().value(), thunk.deterministic());\n }\n \n-static absl::StatusOr<Command> Convert(const CublasLtMatmulThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const CublasLtMatmulThunk& thunk) {\n   if (!thunk.workspace().has_value()) {\n     return absl::InternalError(\n         \"Gemm thunk does not contain a workspace buffer\");\n   }\n-  return std::make_unique<CublasLtCmd>(thunk, resources);\n+  return std::make_unique<CublasLtCmd>(thunk);\n }\n \n static absl::StatusOr<Command> Convert(\n-    const ConditionalThunk& thunk, ResourceUseVector resources,\n-    const ConvertToCommandsOptions& options) {\n+    const ConditionalThunk& thunk, const ConvertToCommandsOptions& options) {\n   std::vector<CommandBufferCmdExecutor> branch_cmds;\n   branch_cmds.reserve(thunk.branch_thunks().size());\n   if (thunk.branch_index_is_bool()) {\n@@ -174,39 +159,33 @@ static absl::StatusOr<Command> Convert(\n   }\n   return std::make_unique<CaseCmd>(thunk.branch_index_buffer(),\n                                    thunk.branch_index_is_bool(),\n-                                   std::move(branch_cmds), resources);\n+                                   std::move(branch_cmds));\n }\n \n-static absl::StatusOr<Command> Convert(const AllReduceStartThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const AllReduceStartThunk& thunk) {\n   return std::make_unique<AllReduceCmd>(thunk.config(), thunk.reduction_kind(),\n-                                        thunk.buffers(), thunk.async_events(),\n-                                        resources);\n+                                        thunk.buffers(), thunk.async_events());\n }\n \n-static absl::StatusOr<Command> Convert(const ReduceScatterStartThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const ReduceScatterStartThunk& thunk) {\n   return std::make_unique<ReduceScatterCmd>(\n       thunk.config(), thunk.reduction_kind(), thunk.buffers(),\n-      thunk.async_events(), resources);\n+      thunk.async_events());\n }\n \n-static absl::StatusOr<Command> Convert(const AllToAllStartThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<AllToAllCmd>(\n-      thunk.config(), thunk.has_split_dimension(), thunk.buffers(),\n-      thunk.async_events(), resources);\n+static absl::StatusOr<Command> Convert(const AllToAllStartThunk& thunk) {\n+  return std::make_unique<AllToAllCmd>(thunk.config(),\n+                                       thunk.has_split_dimension(),\n+                                       thunk.buffers(), thunk.async_events());\n }\n \n-static absl::StatusOr<Command> Convert(const AllGatherStartThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const AllGatherStartThunk& thunk) {\n   return std::make_unique<AllGatherCmd>(thunk.config(), thunk.buffers(),\n-                                        thunk.async_events(), resources);\n+                                        thunk.async_events());\n }\n \n static absl::StatusOr<Command> Convert(\n-    const DynamicSliceThunk& thunk, ResourceUseVector resources,\n-    const ConvertToCommandsOptions& options) {\n+    const DynamicSliceThunk& thunk, const ConvertToCommandsOptions& options) {\n   TF_ASSIGN_OR_RETURN(\n       CommandBufferCmdExecutor embedded_cmds,\n       ConvertToCommands(thunk.get_embedded_thunk()->thunks(), options));\n@@ -220,23 +199,20 @@ static absl::StatusOr<Command> Convert(\n   return std::make_unique<DynamicSliceFusionCmd>(\n       std::move(embedded_cmds), thunk.get_arguments(),\n       std::move(fake_allocations), thunk.get_offsets(), thunk.get_orig_shapes(),\n-      thunk.get_sliced_shapes(), thunk.get_offset_byte_sizes(), resources);\n+      thunk.get_sliced_shapes(), thunk.get_offset_byte_sizes());\n }\n \n-static absl::StatusOr<Command> Convert(const PartitionIdThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<ComputationIdCmd>(\n-      thunk.dest(), ComputationIdCmd::Kind::kPartition, resources);\n+static absl::StatusOr<Command> Convert(const PartitionIdThunk& thunk) {\n+  return std::make_unique<ComputationIdCmd>(thunk.dest(),\n+                                            ComputationIdCmd::Kind::kPartition);\n }\n \n-static absl::StatusOr<Command> Convert(const ReplicaIdThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<ComputationIdCmd>(\n-      thunk.dest(), ComputationIdCmd::Kind::kReplica, resources);\n+static absl::StatusOr<Command> Convert(const ReplicaIdThunk& thunk) {\n+  return std::make_unique<ComputationIdCmd>(thunk.dest(),\n+                                            ComputationIdCmd::Kind::kReplica);\n }\n \n-static absl::StatusOr<Command> Convert(const CustomCallThunk& thunk,\n-                                       ResourceUseVector resources) {\n+static absl::StatusOr<Command> Convert(const CustomCallThunk& thunk) {\n   if (auto bundle = thunk.bundle(); bundle.has_value()) {\n     return std::make_unique<CustomCallCmd>(\n         thunk.target_name(), bundle->execute, thunk.operands(), thunk.results(),\n@@ -245,14 +221,12 @@ static absl::StatusOr<Command> Convert(const CustomCallThunk& thunk,\n   } else {\n     return std::make_unique<CustomCallCmd>(\n         thunk.target_name(), thunk.call_target(), thunk.operands(),\n-        thunk.results(), thunk.opaque(), resources);\n+        thunk.results(), thunk.opaque());\n   }\n }\n \n-static absl::StatusOr<Command> Convert(const CuDnnThunk& thunk,\n-                                       ResourceUseVector resources) {\n-  return std::make_unique<CuDnnCmd>(thunk.arguments(), thunk.graph(),\n-                                    resources);\n+static absl::StatusOr<Command> Convert(const CuDnnThunk& thunk) {\n+  return std::make_unique<CuDnnCmd>(thunk.arguments(), thunk.graph());\n }\n \n //===----------------------------------------------------------------------===//\n@@ -266,17 +240,14 @@ static absl::StatusOr<Command> CopyMetadata(absl::StatusOr<Command> cmd,\n }\n \n template <typename ThunkType, typename... Args>\n-static absl::StatusOr<Command> Convert(const Thunk& thunk,\n-                                       ResourceUseVector resources,\n-                                       Args&&... args) {\n-  return CopyMetadata(Convert(static_cast<const ThunkType&>(thunk), resources,\n+static absl::StatusOr<Command> Convert(const Thunk& thunk, Args&&... args) {\n+  return CopyMetadata(Convert(static_cast<const ThunkType&>(thunk),\n                               std::forward<Args>(args)...),\n                       thunk);\n }\n \n static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n                                    const Thunk& thunk,\n-                                   ResourceUseVector resources,\n                                    const ConvertToCommandsOptions& options) {\n   auto append = [&](absl::StatusOr<Command> command) -> absl::Status {\n     if (command.ok()) {\n@@ -288,45 +259,45 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n \n   switch (thunk.kind()) {\n     case Thunk::Kind::kConditional:\n-      return append(Convert<ConditionalThunk>(thunk, resources, options));\n+      return append(Convert<ConditionalThunk>(thunk, options));\n     case Thunk::Kind::kCopy:\n       if (dynamic_cast<const DynamicMemcpyThunk*>(&thunk)) {\n-        return append(Convert<DynamicMemcpyThunk>(thunk, resources));\n+        return append(Convert<DynamicMemcpyThunk>(thunk));\n       } else {\n-        return append(Convert<DeviceToDeviceCopyThunk>(thunk, resources));\n+        return append(Convert<DeviceToDeviceCopyThunk>(thunk));\n       }\n     case Thunk::Kind::kCustomCall:\n-      return append(Convert<CustomCallThunk>(thunk, resources));\n+      return append(Convert<CustomCallThunk>(thunk));\n     case Thunk::Kind::kCustomKernel:\n-      return append(Convert<CustomKernelThunk>(thunk, resources));\n+      return append(Convert<CustomKernelThunk>(thunk));\n     case Thunk::Kind::kKernel:\n-      return append(Convert<KernelThunk>(thunk, resources));\n+      return append(Convert<KernelThunk>(thunk));\n     case Thunk::Kind::kGemm:\n-      return append(Convert<GemmThunk>(thunk, resources));\n+      return append(Convert<GemmThunk>(thunk));\n     case Thunk::Kind::kCublasLtMatmul:\n-      return append(Convert<CublasLtMatmulThunk>(thunk, resources));\n+      return append(Convert<CublasLtMatmulThunk>(thunk));\n     case Thunk::Kind::kMemset32BitValue:\n-      return append(Convert<Memset32BitValueThunk>(thunk, resources));\n+      return append(Convert<Memset32BitValueThunk>(thunk));\n     case Thunk::Kind::kMemzero:\n-      return append(Convert<MemzeroThunk>(thunk, resources));\n+      return append(Convert<MemzeroThunk>(thunk));\n     case Thunk::Kind::kAllGatherStart:\n-      return append(Convert<AllGatherStartThunk>(thunk, resources));\n+      return append(Convert<AllGatherStartThunk>(thunk));\n     case Thunk::Kind::kAllReduceStart:\n-      return append(Convert<AllReduceStartThunk>(thunk, resources));\n+      return append(Convert<AllReduceStartThunk>(thunk));\n     case Thunk::Kind::kReduceScatterStart:\n-      return append(Convert<ReduceScatterStartThunk>(thunk, resources));\n+      return append(Convert<ReduceScatterStartThunk>(thunk));\n     case Thunk::Kind::kAllToAllStart:\n-      return append(Convert<AllToAllStartThunk>(thunk, resources));\n+      return append(Convert<AllToAllStartThunk>(thunk));\n     case Thunk::Kind::kPartitionId:\n-      return append(Convert<PartitionIdThunk>(thunk, resources));\n+      return append(Convert<PartitionIdThunk>(thunk));\n     case Thunk::Kind::kReplicaId:\n-      return append(Convert<ReplicaIdThunk>(thunk, resources));\n+      return append(Convert<ReplicaIdThunk>(thunk));\n     case Thunk::Kind::kWhile:\n-      return append(Convert<WhileThunk>(thunk, resources, options));\n+      return append(Convert<WhileThunk>(thunk, options));\n     case Thunk::Kind::kCuDnn:\n-      return append(Convert<CuDnnThunk>(thunk, resources));\n+      return append(Convert<CuDnnThunk>(thunk));\n     case Thunk::Kind::kDynamicSlice:\n-      return append(Convert<DynamicSliceThunk>(thunk, resources, options));\n+      return append(Convert<DynamicSliceThunk>(thunk, options));\n \n     // Sequential thunk does not have any special semantics and we simply inline\n     // all nested thunks into command buffer.\n@@ -342,26 +313,23 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n       if (options.synchronization_mode ==\n           CommandBufferCmdExecutor::SynchronizationMode::kLHS) {\n         return append(absl::StatusOr<Command>(std::make_unique<AsyncDoneCmd>(\n-            static_cast<const CollectiveDoneThunk&>(thunk).async_events(),\n-            resources)));\n+            static_cast<const CollectiveDoneThunk&>(thunk).async_events())));\n       } else {\n-        if (resources.empty()) {\n+        if (thunk.control_predecessors().empty()) {\n           return absl::OkStatus();\n         }\n-        // If there control dependencies between these thunks, we will create\n-        // an empty command act as dependency nodes.\n-        return append(\n-            absl::StatusOr<Command>(std::make_unique<EmptyCmd>(resources)));\n+        // If there are control dependencies between these thunks, create an\n+        // empty command to act as a dependency node.\n+        return append(absl::StatusOr<Command>(std::make_unique<EmptyCmd>()));\n       }\n \n     case Thunk::Kind::kWaitForStreams:\n-      if (resources.empty()) {\n+      if (thunk.control_predecessors().empty()) {\n         return absl::OkStatus();\n       }\n-      // If there control dependencies between these thunks, we will create\n-      // an empty command act as dependency nodes.\n-      return append(\n-          absl::StatusOr<Command>(std::make_unique<EmptyCmd>(resources)));\n+      // If there are control dependencies between these thunks, create an\n+      // empty command to act as a dependency node.\n+      return append(absl::StatusOr<Command>(std::make_unique<EmptyCmd>()));\n \n     case Thunk::Kind::kCommandBuffer:\n       return Internal(\n@@ -379,28 +347,20 @@ static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n static absl::Status AppendCommands(CommandBufferCmdSequence& cmd_sequence,\n                                    const ThunkSequence& sequence,\n                                    const ConvertToCommandsOptions& options) {\n-  absl::flat_hash_map<const Thunk*, std::vector<const Thunk*>>\n-      thunk_to_control_successors;\n-  for (auto& thunk : sequence) {\n-    for (const Thunk* control_predecessor : thunk->control_predecessors()) {\n-      thunk_to_control_successors[control_predecessor].push_back(thunk.get());\n-    }\n-  }\n-\n-  absl::flat_hash_map<const Thunk*, ResourceUseVector> thunk_to_resources;\n-  for (const auto& [thunk, control_successors] : thunk_to_control_successors) {\n-    std::shared_ptr<Resource> resource =\n-        Resource::Create(Resource::Kind::kToken);\n-    for (const Thunk* control_successor : control_successors) {\n-      thunk_to_resources[control_successor].push_back(\n-          ResourceUse::Read(resource));\n-    }\n-    thunk_to_resources[thunk].push_back(ResourceUse::Write(resource));\n+  absl::flat_hash_map<const Thunk*, int64_t> thunk_to_index;\n+  for (const std::unique_ptr<Thunk>& thunk : sequence) {\n+    TF_RETURN_IF_ERROR(AppendCommands(cmd_sequence, *thunk, options));\n+    thunk_to_index[thunk.get()] = cmd_sequence.size() - 1;\n   }\n \n+  // Convert thunk control dependencies to token resource dependency, where the\n+  // predecessor has the token write, and control successor does the token read.\n   for (const std::unique_ptr<Thunk>& thunk : sequence) {\n-    TF_RETURN_IF_ERROR(AppendCommands(\n-        cmd_sequence, *thunk, thunk_to_resources[thunk.get()], options));\n+    for (const Thunk* control_predecessor : thunk->control_predecessors()) {\n+      cmd_sequence[thunk_to_index[control_predecessor]]->add_resouce_use(\n+          ResourceUse::Read(\n+              cmd_sequence[thunk_to_index[thunk.get()]]->token()));\n+    }\n   }\n \n   return absl::OkStatus();"
        },
        {
            "sha": "54cb7dac5c711784b2cc15d4224afd6113e480e2",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/e38bf0575d5b751bbb78e4de276c594ae9571a93/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=e38bf0575d5b751bbb78e4de276c594ae9571a93",
            "patch": "@@ -854,7 +854,7 @@ TEST(CommandBufferThunkTest, ChildGemmCmd) {\n       CommandBufferCmdExecutor::Create(std::move(child_commands), serialize));\n \n   CommandBufferCmdSequence commands;\n-  commands.Emplace<ChildCmd>(std::move(child_executor), ResourceUseVector{});\n+  commands.Emplace<ChildCmd>(std::move(child_executor));\n \n   TF_ASSERT_OK_AND_ASSIGN(\n       CommandBufferCmdExecutor executor,"
        }
    ],
    "stats": {
        "total": 456,
        "additions": 183,
        "deletions": 273
    }
}