{
    "author": "pschuh",
    "message": "Add more precise stream synchronization which allows more aggressive stream\nsynchronization in raw buffer APIs (namely CopyRawHostToDeviceAndReturnEvent\nand CopyRawDeviceToHostAndReturnEvent). Old buffers will require no\nsynchronization, but recent buffers will get a cached compute_stream event\nand then it will sync with this compute_stream event repeatedly instead of\nsyncing with the stream itself.\n\nPiperOrigin-RevId: 819380480",
    "sha": "5c5d76e7ad467e0151da38b91eb46acde990fab4",
    "files": [
        {
            "sha": "0c28a30d31360ccc5b7daefd1dc5b43ad9fbb43d",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -1941,7 +1941,10 @@ StreamExecutorGpuClient::RunAsync(\n     buffers_in_result.insert(result_buffer);\n \n     p.second = RawSEDeviceMemory::Create(\n-        result_buffer, device->local_device_id(), memory_allocator);\n+        result_buffer,\n+        tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n+            ->local_device_state(),\n+        memory_allocator);\n   }\n \n   TF_RETURN_IF_ERROR(gpu_exec->ExecuteThunks(buffer_allocations, run_options));"
        },
        {
            "sha": "7d04d1056d2024b4bbef3844a0b46b2799201bc7",
            "filename": "third_party/xla/xla/pjrt/local_device_state.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -324,14 +324,17 @@ absl::Status LocalDeviceState::AllocateAndRecordEvent(\n \n absl::StatusOr<BufferSequencingEventRef>\n LocalDeviceState::GetEventForComputeStreamSyncPoint(\n-    size_t sync_point, tsl::thread::ThreadPool* thread_pool) {\n+    size_t sync_point, tsl::thread::ThreadPool* thread_pool,\n+    bool nullptr_if_past) {\n   mu_.lock();\n   size_t cur_sync_point = next_compute_stream_sync_point_.load();\n   if (sync_point < base_compute_event_sequence_id_ + compute_events_.size()) {\n     BufferSequencingEventRef event;\n     if (sync_point < base_compute_event_sequence_id_) {\n-      DCHECK_GT(compute_events_.size(), 0);\n-      event = compute_events_.front();\n+      if (!nullptr_if_past) {\n+        DCHECK_GT(compute_events_.size(), 0);\n+        event = compute_events_.front();\n+      }\n     } else {\n       event = compute_events_[sync_point - base_compute_event_sequence_id_];\n     }"
        },
        {
            "sha": "675b6b81459f05cd2dc3aa2d42a832f249bdd8ad",
            "filename": "third_party/xla/xla/pjrt/local_device_state.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Flocal_device_state.h?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -220,7 +220,8 @@ class LocalDeviceState {\n   // which only incur the expense of constructing a cuda event if they're really\n   // needed. This allows constructing a definition event per buffer.\n   absl::StatusOr<BufferSequencingEventRef> GetEventForComputeStreamSyncPoint(\n-      size_t sync_point, tsl::thread::ThreadPool* thread_pool);\n+      size_t sync_point, tsl::thread::ThreadPool* thread_pool,\n+      bool nullptr_if_past = false);\n \n  private:\n   absl::Status SynchronizeAllActivity();"
        },
        {
            "sha": "316b5a0b76c730e15c153bcb5fbf956afb265f69",
            "filename": "third_party/xla/xla/pjrt/pjrt_stream_executor_client.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 14,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fpjrt_stream_executor_client.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -533,8 +533,8 @@ PjRtStreamExecutorClient::AllocateRawBuffer(\n       auto buffer,\n       allocator()->Allocate(local_device->local_device_id().value(),\n                             on_device_bytes_count, true, layout_memory_space));\n-  auto mem = RawSEDeviceMemory::Create(buffer.Release(),\n-                                       device->local_device_id(), allocator());\n+  auto mem =\n+      RawSEDeviceMemory::Create(buffer.Release(), local_device, allocator());\n   if (local_device->allocation_model() !=\n       LocalDeviceState::kComputeSynchronized) {\n     DCHECK(client()->backend().transfer_manager()->CanBufferBeAccessedNow(\n@@ -576,13 +576,13 @@ PjRtStreamExecutorClient::DefineBuffer(\n \n void PjRtStreamExecutorClient::WaitForAllocation(\n     se::Stream* stream, const CommonPjRtRawBuffer& raw_buffer) {\n-  auto* local_device =\n+  auto event =\n       tensorflow::down_cast<const PjRtStreamExecutorRawBuffer*>(&raw_buffer)\n-          ->local_device();\n-  if (local_device->allocation_model() ==\n-      LocalDeviceState::kComputeSynchronized) {\n-    CHECK(stream);\n-    CHECK_OK(stream->WaitFor(local_device->compute_stream()));\n+          ->device_buffer()\n+          ->GetDefinitionEvent(thread_pool(), /*nullptr_if_past=*/true);\n+  CHECK_OK(event.status());\n+  if (*event) {\n+    (*event)->WaitForEventOnStream(stream);\n   }\n }\n \n@@ -647,8 +647,7 @@ AllocateDestinationBuffer(const Shape& on_host_shape, PjRtDevice* device,\n         << on_device_shape.ToString(true) << \" vs \"\n         << old_on_device_shape.ToString(true);\n     DCHECK_EQ(on_device_bytes_count, dst_buffer.buffer({}).size());\n-    mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}),\n-                                    device->local_device_id(),\n+    mem = RawSEDeviceMemory::Create(dst_buffer.buffer({}), local_device,\n                                     dst_buffer.memory_allocator());\n     dst_buffer.clear();\n     if (local_device->allocation_model() !=\n@@ -2045,9 +2044,8 @@ MakeTupleHelper(\n   auto iterator_end = execution_input.end();\n   // First set the root tuple table which is the first buffer in the ShapeTree.\n   input_iterator->second = {\n-      true,\n-      RawSEDeviceMemory::Create(owned_root_table_memory.Release(),\n-                                local_device->local_device_id(), allocator)};\n+      true, RawSEDeviceMemory::Create(owned_root_table_memory.Release(),\n+                                      local_device, allocator)};\n   ++input_iterator;\n   // Then set each sub-tuple in turn from the parameters.\n   for (const PjRtStreamExecutorBuffer::ScopedHold& device_buffer :\n@@ -2566,7 +2564,10 @@ PjRtStreamExecutorClient::RunAsync(\n   for (auto& buf : released_ssb.buffers()) {\n     CHECK(it != results.end());\n     it->second = RawSEDeviceMemory::Create(\n-        buf.second, device->local_device_id(), allocator);\n+        buf.second,\n+        tensorflow::down_cast<PjRtStreamExecutorDevice*>(device)\n+            ->local_device_state(),\n+        allocator);\n     ++it;\n   }\n   CHECK(it == results.end());"
        },
        {
            "sha": "c94d8dccd053ff6a74a5dcc29f0b001e3ba93ff1",
            "filename": "third_party/xla/xla/pjrt/se_raw_buffer.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 10,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fse_raw_buffer.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -36,6 +36,7 @@ limitations under the License.\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/threadpool.h\"\n #include \"tsl/platform/casts.h\"\n #include \"tsl/profiler/lib/connected_traceme.h\"\n@@ -119,11 +120,12 @@ PjRtStreamExecutorRawBuffer::CopyRawHostToDeviceAndReturnEvent(\n   auto device_event = BufferSequencingEvent::Create(client_->thread_pool());\n   client_->thread_pool()->Schedule(\n       [client = client_, device_event, local_device = local_device_, stream,\n-       buffer = device_buffer_, src, offset, transfer_size]() mutable {\n-        se::DeviceMemoryBase sub_buffer = buffer->mem();\n+       src, offset, transfer_size, buf = tsl::FormRef(this)]() mutable {\n+        se::DeviceMemoryBase sub_buffer = buf->device_buffer_->mem();\n         if (transfer_size < sub_buffer.size()) {\n           sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n         }\n+        client->WaitForAllocation(stream, *buf);\n         auto status = stream->Memcpy(&sub_buffer, src, transfer_size);\n         if (status.ok()) {\n           status = client->AllocateAndRecordEvent(device_event, local_device,\n@@ -145,11 +147,12 @@ PjRtStreamExecutorRawBuffer::CopyRawDeviceToHostAndReturnEvent(\n   auto device_event = BufferSequencingEvent::Create(client_->thread_pool());\n   client_->thread_pool()->Schedule(\n       [client = client_, device_event, local_device = local_device_, stream,\n-       buffer = device_buffer_, dst, offset, transfer_size]() mutable {\n-        se::DeviceMemoryBase sub_buffer = buffer->mem();\n+       dst, offset, transfer_size, buf = tsl::FormRef(this)]() mutable {\n+        se::DeviceMemoryBase sub_buffer = buf->device_buffer_->mem();\n         if (transfer_size < sub_buffer.size()) {\n           sub_buffer = sub_buffer.GetByteSlice(offset, transfer_size);\n         }\n+        client->WaitForAllocation(stream, *buf);\n         auto status = stream->Memcpy(dst, sub_buffer, transfer_size);\n         if (status.ok()) {\n           status = client->AllocateAndRecordEvent(device_event, local_device,\n@@ -207,12 +210,11 @@ absl::StatusOr<tsl::RCReference<PjRtDeviceEvent>>\n PjRtStreamExecutorRawBuffer::MakeAllocationReadyEvent() {\n   auto* client =\n       tensorflow::down_cast<PjRtStreamExecutorClient*>(memory_space_->client());\n-  auto result = BufferSequencingEvent::Create(client->thread_pool());\n-  if (local_device_->allocation_model() ==\n-      LocalDeviceState::kComputeSynchronized) {\n-    TF_RETURN_IF_ERROR(client->AllocateAndRecordEvent(\n-        result, local_device_, local_device_->compute_stream()));\n-  } else {\n+  TF_ASSIGN_OR_RETURN(auto result,\n+                      device_buffer_->GetDefinitionEvent(\n+                          client->thread_pool(), /*nullptr_if_past=*/false));\n+  if (!result) {\n+    result = BufferSequencingEvent::Create(client->thread_pool());\n     auto stream = local_device_->BorrowStreamFromPool();\n     auto status =\n         client->AllocateAndRecordEvent(result, local_device_, stream.get());"
        },
        {
            "sha": "ab2df443e3278c01e34fce16b888ce45a5bee05a",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 6,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -17,9 +17,11 @@ limitations under the License.\n \n #include <algorithm>\n #include <atomic>\n+#include <cstddef>\n #include <cstdint>\n #include <functional>\n #include <iterator>\n+#include <limits>\n #include <memory>\n #include <string>\n #include <utility>\n@@ -32,8 +34,10 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n+#include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/device_event.h\"\n #include \"xla/pjrt/event_pool.h\"\n+#include \"xla/pjrt/local_device_state.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/pjrt/se_raw_buffer.h\"\n@@ -46,6 +50,7 @@ limitations under the License.\n #include \"xla/tsl/concurrency/async_value_ref.h\"\n #include \"xla/tsl/concurrency/ref_count.h\"\n #include \"xla/tsl/platform/logging.h\"\n+#include \"xla/tsl/platform/threadpool.h\"\n #include \"tsl/profiler/lib/connected_traceme.h\"\n #include \"tsl/profiler/lib/context_types.h\"\n \n@@ -66,15 +71,22 @@ ShapedBuffer RawSEDeviceMemory::AsShapedBuffer(\n \n class AllocatedRawSEDeviceMemory : public RawSEDeviceMemory {\n  public:\n-  AllocatedRawSEDeviceMemory(se::DeviceMemoryBase value, int device_ordinal,\n+  AllocatedRawSEDeviceMemory(se::DeviceMemoryBase value,\n+                             LocalDeviceState* local_device,\n                              se::DeviceMemoryAllocator* allocator)\n       : RawSEDeviceMemory(value),\n         allocator_(allocator),\n-        device_ordinal_(device_ordinal) {}\n+        local_device_(local_device) {\n+    if (local_device_->allocation_model() ==\n+        LocalDeviceState::kComputeSynchronized) {\n+      sync_point_ = local_device_->GetNextComputeStreamSyncPoint();\n+    }\n+  }\n \n   ~AllocatedRawSEDeviceMemory() override {\n     if (allocator_) {\n-      absl::Status status = allocator_->Deallocate(device_ordinal_, mem());\n+      absl::Status status = allocator_->Deallocate(\n+          local_device_->local_device_id().value(), mem());\n       if (!status.ok()) {\n         LOG(ERROR) << \"Buffer deallocation failed: \" << status;\n       }\n@@ -83,15 +95,26 @@ class AllocatedRawSEDeviceMemory : public RawSEDeviceMemory {\n \n   void UnsafeReleaseMemory() override { allocator_ = nullptr; }\n \n+  absl::StatusOr<BufferSequencingEventRef> GetDefinitionEvent(\n+      tsl::thread::ThreadPool* thread_pool,\n+      bool nullptr_if_past) const override {\n+    if (sync_point_ != std::numeric_limits<size_t>::max()) {\n+      return local_device_->GetEventForComputeStreamSyncPoint(\n+          sync_point_, thread_pool, nullptr_if_past);\n+    }\n+    return BufferSequencingEventRef();\n+  }\n+\n  private:\n   se::DeviceMemoryAllocator* allocator_;\n-  int device_ordinal_;\n+  LocalDeviceState* local_device_;\n+  size_t sync_point_ = std::numeric_limits<size_t>::max();\n };\n \n tsl::RCReference<RawSEDeviceMemory> RawSEDeviceMemory::Create(\n-    se::DeviceMemoryBase value, PjRtLocalDeviceId device_id,\n+    se::DeviceMemoryBase value, LocalDeviceState* local_device,\n     se::DeviceMemoryAllocator* allocator) {\n-  return tsl::MakeRef<AllocatedRawSEDeviceMemory>(value, device_id.value(),\n+  return tsl::MakeRef<AllocatedRawSEDeviceMemory>(value, local_device,\n                                                   allocator);\n }\n "
        },
        {
            "sha": "83cabee4116374e93db0f5763b139c1f63fb1fef",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer.h",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer.h?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"xla/pjrt/abstract_tracked_device_buffer.h\"\n #include \"xla/pjrt/buffer_sequencing_event.h\"\n #include \"xla/pjrt/event_pool.h\"\n+#include \"xla/pjrt/local_device_state.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n #include \"xla/service/executable.h\"\n@@ -70,12 +71,19 @@ class RawSEDeviceMemory : public tsl::ReferenceCounted<RawSEDeviceMemory> {\n                               const Shape& on_device_shape) const;\n \n   static tsl::RCReference<RawSEDeviceMemory> Create(\n-      se::DeviceMemoryBase value, PjRtLocalDeviceId device_id,\n+      se::DeviceMemoryBase value, LocalDeviceState* local_device,\n       se::DeviceMemoryAllocator* allocator);\n   static tsl::RCReference<RawSEDeviceMemory> CreateForeign(\n       se::DeviceMemoryBase value,\n       absl::AnyInvocable<void() &&> on_delete_callback);\n \n+  // Returns a definition event (or nullptr if the definition is known to be in\n+  // the past).\n+  virtual absl::StatusOr<BufferSequencingEventRef> GetDefinitionEvent(\n+      tsl::thread::ThreadPool* thread_pool, bool nullptr_if_past) const {\n+    return BufferSequencingEventRef();\n+  }\n+\n  private:\n   se::DeviceMemoryBase value_;\n };"
        },
        {
            "sha": "cf999fcf46859f1277025f619cfd18c31f719a7b",
            "filename": "third_party/xla/xla/pjrt/tracked_device_buffer_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/5c5d76e7ad467e0151da38b91eb46acde990fab4/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftracked_device_buffer_test.cc?ref=5c5d76e7ad467e0151da38b91eb46acde990fab4",
            "patch": "@@ -16,6 +16,7 @@ limitations under the License.\n #include \"xla/pjrt/tracked_device_buffer.h\"\n \n #include <memory>\n+#include <utility>\n #include <vector>\n \n #include \"absl/log/log.h\"\n@@ -93,9 +94,9 @@ absl::StatusOr<std::shared_ptr<TrackedDeviceBuffer>> MakeArray(\n                 /*device_ordinal=*/0,\n                 client->backend().transfer_manager()->GetByteSizeRequirement(\n                     subshape)));\n-        device_buffers.push_back(RawSEDeviceMemory::Create(\n-            device_memory.Release(), device->local_device_id(),\n-            client->backend().memory_allocator()));\n+        auto se_mem = *device_memory;\n+        device_buffers.push_back(RawSEDeviceMemory::CreateForeign(\n+            se_mem, [device_memory = std::move(device_memory)]() {}));\n         return absl::OkStatus();\n       }));\n   return std::make_shared<TrackedDeviceBuffer>("
        }
    ],
    "stats": {
        "total": 120,
        "additions": 81,
        "deletions": 39
    }
}