{
    "author": "alexander-shaposhnikov",
    "message": "Add initial bits to support reductions.\n\nPiperOrigin-RevId: 825292462",
    "sha": "b81ecb432f495db6f8bb917cb8811561474fc06b",
    "files": [
        {
            "sha": "f6bd16546bf6cc1d01c8e28c727c885a393faa0d",
            "filename": "third_party/xla/xla/backends/cpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2FBUILD?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -239,6 +239,7 @@ cc_library(\n         \"//xla/backends/cpu/runtime:dot_lib\",\n         \"//xla/backends/cpu/runtime/ynnpack:ynn_interop\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/service:pattern_matcher\",\n         \"//xla/tsl/platform:statusor\",\n         \"@XNNPACK//ynnpack\",\n         \"@com_google_absl//absl/base:no_destructor\","
        },
        {
            "sha": "c749376eca78ed3f726bc7b4f0e656fe1969d6a2",
            "filename": "third_party/xla/xla/backends/cpu/transforms/BUILD",
            "status": "modified",
            "additions": 17,
            "deletions": 1,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2FBUILD?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -3,6 +3,7 @@ load(\"//xla/tsl:tsl.bzl\", \"internal_visibility\")\n load(\"//xla/tsl/mkl:build_defs.bzl\", \"if_graph_api\")\n load(\"//xla/tsl/mkl:graph.bzl\", \"onednn_graph_cc_library\")\n load(\"//xla/tsl/platform:rules_cc.bzl\", \"cc_library\")\n+load(\"//xla/tsl/xnnpack:build_defs.bzl\", \"if_ynnpack\")\n \n package(\n     # copybara:uncomment default_applicable_licenses = [\"//tensorflow:license\"],\n@@ -42,7 +43,7 @@ cc_library(\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@local_tsl//tsl/platform:protobuf\",\n-    ],\n+    ] + if_ynnpack([\":ynn_matcher\"]),\n )\n \n xla_cc_test(\n@@ -115,6 +116,21 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"ynn_matcher\",\n+    hdrs = [\"ynn_matcher.h\"],\n+    deps = [\n+        \":library_matcher\",\n+        \"//xla/backends/cpu/codegen:target_machine_features\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"@com_google_absl//absl/base:no_destructor\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@local_tsl//tsl/platform:protobuf\",\n+    ] + if_ynnpack([\"//xla/backends/cpu:ynn_support\"]),\n+)\n+\n cc_library(\n     name = \"xnn_graph_fusion\",\n     srcs = [\"xnn_graph_fusion.cc\"],"
        },
        {
            "sha": "1ad43a7a1f9da55017a48838bd2c292ede27f012",
            "filename": "third_party/xla/xla/backends/cpu/transforms/library_rewriter.h",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter.h?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -39,6 +39,10 @@ limitations under the License.\n #include \"xla/backends/cpu/transforms/onednn_matcher.h\"\n #endif  // XLA_ONEDNN_USE_GRAPH_API\n \n+#ifdef XLA_YNNPACK\n+#include \"xla/backends/cpu/transforms/ynn_matcher.h\"\n+#endif\n+\n namespace xla::cpu {\n \n enum class FusionDirection {\n@@ -50,8 +54,10 @@ enum class FusionDirection {\n struct LibraryRewriterOptions {\n   bool use_onednn = false;\n   bool use_xnnpack = false;\n+  bool use_ynnpack = false;\n   const tsl::protobuf::RepeatedField<int>* onednn_fusion_types = nullptr;\n   const tsl::protobuf::RepeatedField<int>* xnn_fusion_types = nullptr;\n+  const tsl::protobuf::RepeatedField<int>* ynn_fusion_types = nullptr;\n };\n \n // Rewrites suitable Dot operations into library fusions.\n@@ -74,6 +80,14 @@ class LibraryRewriter : public HloModulePass {\n       libs_.push_back(std::make_unique<XnnMatcher>(target_machine_features_,\n                                                    options_.xnn_fusion_types));\n     }\n+#ifdef XLA_YNNPACK\n+    if (options_.use_ynnpack && options_.ynn_fusion_types != nullptr &&\n+        !options_.ynn_fusion_types->empty()) {\n+      libs_.push_back(std::make_unique<YnnMatcher>(target_machine_features_,\n+                                                   options_.ynn_fusion_types));\n+    }\n+#endif  // XLA_YNNPACK\n+\n     for (std::unique_ptr<LibraryMatcher>& lib : libs_) {\n       supported_ops_.merge(lib->SupportedOps());\n     }"
        },
        {
            "sha": "2646ee286b02594f9026b0539f7d2231855dec2e",
            "filename": "third_party/xla/xla/backends/cpu/transforms/library_rewriter_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Flibrary_rewriter_test.cc?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -101,11 +101,16 @@ class CpuLibraryTest : public TargetMachineTestBase {\n     tsl::protobuf::RepeatedField<int> empty_fusion_types;\n     bool use_onednn = spec.lib == \"onednn\";\n     bool use_xnnpack = spec.lib == \"xnn\";\n+    bool use_ynnpack = spec.lib == \"ynn\";\n     LibraryRewriterOptions options = {\n-        use_onednn, use_xnnpack,\n+        use_onednn,\n+        use_xnnpack,\n+        use_ynnpack,\n         /*onednn_fusion_types=*/\n         use_onednn ? &fusion_types : &empty_fusion_types,\n-        /*xnn_fusion_types=*/use_xnnpack ? &fusion_types : &empty_fusion_types};\n+        /*xnn_fusion_types=*/use_xnnpack ? &fusion_types : &empty_fusion_types,\n+        /*ynn_fusion_types=*/use_ynnpack ? &fusion_types : &empty_fusion_types,\n+    };\n     LibraryRewriter rewriter(features.get(), options);\n     EXPECT_EQ(expected.changed, rewriter.Run(module.get()).value());\n     if (!expected.changed) {"
        },
        {
            "sha": "731b7e5f6b6d6f50e2f88cf17a600e1eb2444725",
            "filename": "third_party/xla/xla/backends/cpu/transforms/ynn_matcher.h",
            "status": "added",
            "additions": 115,
            "deletions": 0,
            "changes": 115,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fynn_matcher.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fynn_matcher.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Ftransforms%2Fynn_matcher.h?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -0,0 +1,115 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_CPU_TRANSFORMS_YNN_MATCHER_H_\n+#define XLA_BACKENDS_CPU_TRANSFORMS_YNN_MATCHER_H_\n+\n+#include <string>\n+\n+#include \"absl/base/no_destructor.h\"\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/backends/cpu/codegen/target_machine_features.h\"\n+#include \"xla/backends/cpu/transforms/library_matcher.h\"\n+#include \"xla/backends/cpu/ynn_support.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"tsl/platform/protobuf.h\"\n+\n+namespace xla::cpu {\n+\n+class YnnMatcher : public LibraryMatcher {\n+ public:\n+  explicit YnnMatcher(const TargetMachineFeatures* target_machine_features,\n+                      const tsl::protobuf::RepeatedField<int>* fusion_types)\n+      : LibraryMatcher(target_machine_features, fusion_types) {}\n+  ~YnnMatcher() override = default;\n+\n+  // Returns the set of supported HLO instructions.\n+  absl::flat_hash_set<HloOpcode> SupportedOps() const override {\n+    static const absl::NoDestructor<absl::flat_hash_set<HloOpcode>>\n+        kSupportedOps{[]() {\n+          absl::flat_hash_set<HloOpcode> supported_ops{\n+              HloOpcode::kDot, HloOpcode::kReduce, HloOpcode::kConstant};\n+          for (const auto& [op, _] : GetYnnUnaryOpMap()) {\n+            supported_ops.insert(op);\n+          }\n+          for (const auto& [op, _] : GetYnnBinaryOpMap()) {\n+            supported_ops.insert(op);\n+          }\n+          return supported_ops;\n+        }()};\n+    return *kSupportedOps;\n+  }\n+\n+  // Returns true if the HLO instruction is supported by the library.\n+  absl::StatusOr<bool> IsOpSupported(const HloInstruction* instr) override {\n+    if (instr->opcode() == HloOpcode::kDot) {\n+      return IsDotSupportedByYnn(instr->dot_dimension_numbers(),\n+                                 instr->operand(0)->shape(),\n+                                 instr->operand(1)->shape(), instr->shape());\n+    }\n+    if (instr->opcode() == HloOpcode::kReduce) {\n+      return IsReduceOpSupportedByYnn(instr);\n+    }\n+    if (instr->IsConstant()) {\n+      return IsConstantSupportedByYnn(instr);\n+    }\n+    // TODO(b/441837668): Need to get the reduction performance right before\n+    // enabling fusions. Fusions make performance analysis quite challenging.\n+    if (fuse_reduce_) {\n+      return false;\n+    }\n+    if (instr->IsElementwise()) {\n+      return IsElementwiseOpSupportedByYnn(instr);\n+    }\n+    return false;\n+  }\n+\n+  // Returns true if we should start a new fusion containing just the given HLO\n+  // instruction. We control the instructions that can start a fusion with the\n+  // `--xla_cpu_experimental_ynn_fusion_type` flag.\n+  bool ShouldCreateFusion(const HloInstruction* instr) override {\n+    if (fuse_dot_ && instr->opcode() == HloOpcode::kDot) {\n+      return true;\n+    }\n+    if (fuse_reduce_ && instr->opcode() == HloOpcode::kReduce) {\n+      return true;\n+    }\n+    return fuse_eltwise_ && instr->IsElementwise();\n+  }\n+\n+  PrimitiveType LibraryOpOutputType(const HloInstruction* instr) override {\n+    auto out_type = instr->shape().element_type();\n+    if (instr->opcode() != HloOpcode::kDot) {\n+      return out_type;\n+    }\n+    return out_type == BF16 ? F32 : out_type;\n+  }\n+\n+  // Returns a prefix string for the fusion op's name.\n+  std::string fusion_prefix() const override { return \"ynn_\"; }\n+\n+  // Returns a string for FusionBackendConfig's fusion kind.\n+  absl::string_view fusion_kind() const override { return kYnnFusionKind; }\n+\n+ private:\n+  absl::flat_hash_set<DebugOptions::LibraryFusionType> fusion_types_;\n+};\n+\n+}  // namespace xla::cpu\n+\n+#endif  // XLA_BACKENDS_CPU_TRANSFORMS_YNN_MATCHER_H_"
        },
        {
            "sha": "59bfd5df79257b7b51415f2faf2ef7056aa1d685",
            "filename": "third_party/xla/xla/backends/cpu/ynn_emitter.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 0,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_emitter.cc?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"xla/backends/cpu/runtime/dot_lib.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n #include \"xla/backends/cpu/ynn_support.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_instructions.h\"\n@@ -206,6 +207,48 @@ static absl::StatusOr<uint32_t> DefineBinaryOp(ynn_subgraph_t subgraph,\n   return out;\n }\n \n+static absl::StatusOr<uint32_t> DefineReduceOp(ynn_subgraph_t subgraph,\n+                                               TensorIdMap& tensor_ids,\n+                                               const HloInstruction* instr) {\n+  VLOG(3) << absl::StreamFormat(\"Define tensor value for reduce op: %s\",\n+                                instr->ToString());\n+  CHECK_EQ(instr->opcode(), HloOpcode::kReduce);\n+  const HloReduceInstruction* reduce_instr = Cast<HloReduceInstruction>(instr);\n+  const HloInstruction* input = instr->operand(0);\n+  const HloInstruction* init = instr->operand(1);\n+  CHECK_EQ(input->shape().element_type(), instr->shape().element_type());\n+  CHECK_EQ(init->shape().element_type(), instr->shape().element_type());\n+\n+  ynn_reduce_operator ynn_reduce_op = ynn_reduce_invalid;\n+  CHECK_EQ(reduce_instr->to_apply()->num_parameters(), 2);\n+  CHECK_EQ(reduce_instr->to_apply()->instruction_count(), 3);\n+\n+  switch (reduce_instr->to_apply()->root_instruction()->opcode()) {\n+    case HloOpcode::kAdd:\n+      ynn_reduce_op = ynn_reduce_sum;\n+      break;\n+    case HloOpcode::kMaximum:\n+      ynn_reduce_op = ynn_reduce_max;\n+      break;\n+    case HloOpcode::kMinimum:\n+      ynn_reduce_op = ynn_reduce_min;\n+      break;\n+    default:\n+      LOG(FATAL) << \"Unsupported reduction: \" << instr->to_apply()->ToString();\n+  }\n+\n+  const absl::Span<const int64_t> reduce_dims = reduce_instr->dimensions();\n+  const std::vector<int32_t> dims(reduce_dims.begin(), reduce_dims.end());\n+  TF_ASSIGN_OR_RETURN(auto in, FindTensorValue(tensor_ids, input));\n+  TF_ASSIGN_OR_RETURN(auto init_id, FindTensorValue(tensor_ids, init));\n+  TF_ASSIGN_OR_RETURN(auto out, DefineTensorValue(subgraph, instr));\n+\n+  YNN_RETURN_IF_ERROR(\n+      ynn_define_reduce(subgraph, ynn_reduce_op, /*num_axes=*/dims.size(),\n+                        /*axes=*/dims.data(), in, init_id, &out, /*flags=*/0));\n+  return out;\n+}\n+\n //===----------------------------------------------------------------------===//\n // Emit YNNPACK subgraph for the given HLO computation.\n //===----------------------------------------------------------------------===//\n@@ -279,6 +322,11 @@ static absl::StatusOr<YnnSubgraph> EmitYnnSubgraph(\n                             DefineBitcastOp(subgraph.get(), tensor_ids, instr));\n       } break;\n \n+      case HloOpcode::kReduce: {\n+        TF_ASSIGN_OR_RETURN(tensor_ids[instr],\n+                            DefineReduceOp(subgraph.get(), tensor_ids, instr));\n+      } break;\n+\n       default: {\n         return InvalidArgument(\"Unsupported fusion instruction: %s\",\n                                instr->ToString());"
        },
        {
            "sha": "5c033092bd92d4f271a9346ccd7f4978039cb462",
            "filename": "third_party/xla/xla/backends/cpu/ynn_support.cc",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.cc?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -27,9 +27,12 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"xla/backends/cpu/runtime/dot_lib.h\"\n #include \"xla/backends/cpu/runtime/ynnpack/ynn_interop.h\"\n+#include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/layout_util.h\"\n+#include \"xla/service/pattern_matcher.h\"\n #include \"xla/shape.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\"\n@@ -203,4 +206,36 @@ absl::StatusOr<bool> IsDotSupportedByYnn(\n   return true;\n }\n \n+bool IsReduceOpSupportedByYnn(const HloInstruction* hlo) {\n+  CHECK_EQ(hlo->opcode(), HloOpcode::kReduce);\n+  if (!YnnType(hlo->shape().element_type()).ok()) {\n+    return false;\n+  }\n+  const HloReduceInstruction* reduce = Cast<HloReduceInstruction>(hlo);\n+  CHECK_NE(reduce, nullptr);\n+  // TODO(ashaposhnikov): we can support this edge case,\n+  // planning to come back to this later.\n+  if (reduce->dimensions().empty()) {\n+    return false;\n+  }\n+\n+  HloInstruction* init = reduce->init_values().front();\n+  const PrimitiveType type = init->shape().element_type();\n+  // TODO(ashaposhnikov): The list of supported types can be extended.\n+  if (type != F32) {\n+    return false;\n+  }\n+  if (type != hlo->shape().element_type()) {\n+    return false;\n+  }\n+\n+  const HloComputation* to_apply = reduce->to_apply();\n+  CHECK_NE(to_apply, nullptr);\n+  return Match(to_apply->root_instruction(),\n+               match::AnyOf<HloInstruction>(match::Add(), match::Maximum(),\n+                                            match::Minimum())\n+                   .WithBinaryOperandsAnyOrder(match::Parameter(0),\n+                                               match::Parameter(1)));\n+}\n+\n }  // namespace xla::cpu"
        },
        {
            "sha": "8504a5d4f861f43d7aaba64510d10d95fe624d9a",
            "filename": "third_party/xla/xla/backends/cpu/ynn_support.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fynn_support.h?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -62,6 +62,9 @@ absl::StatusOr<bool> IsDotSupportedByYnn(\n     const DotDimensionNumbers& dot_dimensions, const Shape& lhs_shape,\n     const Shape& rhs_shape, const Shape& out_shape);\n \n+// Returns true if the reduce op is supported by YNNPACK.\n+bool IsReduceOpSupportedByYnn(const HloInstruction* hlo);\n+\n }  // namespace xla::cpu\n \n #endif  // XLA_BACKENDS_CPU_YNN_SUPPORT_H_"
        },
        {
            "sha": "ee7471ae9c77ff265135f5f064391fe090755f91",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b81ecb432f495db6f8bb917cb8811561474fc06b/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=b81ecb432f495db6f8bb917cb8811561474fc06b",
            "patch": "@@ -969,14 +969,20 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n   // XNNPACK ops availability checks depend on the layout information,\n   // so until another solution is developed the passes creating XNNPACK fusions\n   // have to run after layout assignment.\n+  const bool use_ynnpack = absl::c_linear_search(\n+      debug_options.xla_cpu_experimental_ynn_fusion_type(),\n+      DebugOptions::LIBRARY_FUSION_TYPE_REDUCE);\n   LibraryRewriterOptions options = {\n       /*use_onednn=*/debug_options.xla_cpu_use_onednn(),\n       /*use_xnnpack=*/debug_options.xla_cpu_use_xnnpack(),\n+      /*use_ynnpack=*/use_ynnpack,\n       /*onednn_fusion_types=*/\n       &debug_options.xla_cpu_experimental_onednn_fusion_type(),\n       /*xnn_fusion_types=*/\n-      &debug_options.xla_cpu_experimental_xnn_fusion_type()};\n-  if (options.use_onednn || options.use_xnnpack) {\n+      &debug_options.xla_cpu_experimental_xnn_fusion_type(),\n+      /*ynn_fusion_types=*/\n+      &debug_options.xla_cpu_experimental_ynn_fusion_type()};\n+  if (options.use_onednn || options.use_xnnpack || options.use_ynnpack) {\n     HloPassPipeline lib_pipeline(\"dot-library-passes\");\n     lib_pipeline.AddPass<DotDecomposer>();\n     lib_pipeline.AddPass<LibraryRewriter>(target_machine_features, options);"
        }
    ],
    "stats": {
        "total": 253,
        "additions": 248,
        "deletions": 5
    }
}