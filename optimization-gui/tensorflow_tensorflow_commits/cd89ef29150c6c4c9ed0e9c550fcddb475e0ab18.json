{
    "author": "derdrdirk",
    "message": "[Autotuner] Create default allocator from stream_executor if external_allocator is a nullpointer in the GpuProfiler.\n\nPiperOrigin-RevId: 799557272",
    "sha": "cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
    "files": [
        {
            "sha": "8e734d12a7fe700717ffbd6b644bd8773e91b654",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2FBUILD?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -559,6 +559,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/gpu:redzone_allocator\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\","
        },
        {
            "sha": "0f2ee8b773cea1302f23e0b4f5a098ceff3a9981",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/autotuner_main.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fautotuner_main.cc?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -107,7 +107,7 @@ absl::Status Autotune(HloModule& module, const std::string& autotune_cache_dir,\n       std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n           stream_executor);\n   auto profiler =\n-      GpuProfiler::Create(stream_executor, allocator.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_executor, ProfileOptions(), allocator.get());\n   if (profiler == nullptr) {\n     return absl::InternalError(\"Failed to create profiler\");\n   }"
        },
        {
            "sha": "c08b21a635831d32595e943283827803472f706b",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 3,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.cc?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -41,6 +41,7 @@ limitations under the License.\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/gpu/redzone_allocator.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"tsl/platform/casts.h\"\n@@ -88,14 +89,24 @@ int GetScratchBytes(const Executable* executable) {\n }  // namespace\n \n std::unique_ptr<GpuProfiler> GpuProfiler::Create(\n-    se::StreamExecutor* stream_executor, se::DeviceMemoryAllocator* allocator,\n-    ProfileOptions options) {\n+    se::StreamExecutor* stream_executor, ProfileOptions options,\n+    se::DeviceMemoryAllocator* external_allocator) {\n+  std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator;\n+  se::DeviceMemoryAllocator* active_allocator = external_allocator;\n+\n+  if (active_allocator == nullptr) {\n+    owned_allocator =\n+        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_executor);\n+    active_allocator = owned_allocator.get();\n+  }\n+\n   auto stream = stream_executor->CreateStream();\n   if (!stream.ok()) {\n     LOG(ERROR) << \"Failed to create stream: \" << stream.status();\n     return nullptr;\n   }\n-  return absl::WrapUnique(new GpuProfiler(stream_executor, allocator,\n+  return absl::WrapUnique(new GpuProfiler(stream_executor, active_allocator,\n+                                          std::move(owned_allocator),\n                                           std::move(stream.value()), options));\n }\n "
        },
        {
            "sha": "42f42dd17ca029027b4bbc2bd7e0a6fbb673693e",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler.h",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler.h?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -41,8 +41,8 @@ struct GpuInputBuffers : public InputBuffers {\n class GpuProfiler : public Profiler {\n  public:\n   static std::unique_ptr<GpuProfiler> Create(\n-      stream_executor::StreamExecutor* stream_executor,\n-      se::DeviceMemoryAllocator* allocator, ProfileOptions options);\n+      stream_executor::StreamExecutor* stream_executor, ProfileOptions options,\n+      se::DeviceMemoryAllocator* external_allocator = nullptr);\n \n   // The input buffers shapes are taken from the attatched HloModule to the\n   // executable.\n@@ -60,12 +60,13 @@ class GpuProfiler : public Profiler {\n                                  float rtol) override;\n \n  private:\n-  explicit GpuProfiler(se::StreamExecutor* stream_executor,\n-                       se::DeviceMemoryAllocator* allocator,\n-                       std::unique_ptr<se::Stream> stream,\n-                       ProfileOptions options)\n+  explicit GpuProfiler(\n+      se::StreamExecutor* stream_executor, se::DeviceMemoryAllocator* allocator,\n+      std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator,\n+      std::unique_ptr<se::Stream> stream, ProfileOptions options)\n       : stream_executor_(stream_executor),\n         allocator_(allocator),\n+        owned_allocator_(std::move(owned_allocator)),\n         stream_(std::move(stream)),\n         options_(options) {}\n \n@@ -75,6 +76,7 @@ class GpuProfiler : public Profiler {\n \n   se::StreamExecutor* stream_executor_;\n   se::DeviceMemoryAllocator* allocator_;\n+  std::unique_ptr<se::DeviceMemoryAllocator> owned_allocator_;\n   std::unique_ptr<se::Stream> stream_;\n   ProfileOptions options_;\n };"
        },
        {
            "sha": "bef0c60d5e477eca55945dc77505efa101ca174b",
            "filename": "third_party/xla/xla/backends/gpu/autotuner/gpu_profiler_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fautotuner%2Fgpu_profiler_test.cc?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -137,7 +137,7 @@ TEST_F(GpuProfilerTest, ProfileWithSharedBuffersWithoutOutputBuffer) {\n \n   ProfileOptions options;\n   options.should_populate_output_buffer = false;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n                                              std::move(executables)));\n   EXPECT_EQ(profiles.size(), 2);\n@@ -168,7 +168,7 @@ TEST_F(GpuProfilerTest, ProfileWithSharedBuffers) {\n   executables.push_back(std::make_unique<MockExecutable>(module, 1));\n \n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n                                              std::move(executables)));\n   EXPECT_THAT(profiles, ElementsAre(IsOkAndHolds(Field(\n@@ -191,7 +191,7 @@ TEST_F(GpuProfilerTest, FailingExecutablesReturnStatus) {\n   executables.push_back(std::make_unique<MockExecutable>(module, 3000));\n \n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(auto profiles, profiler->ProfileWithSharedBuffers(\n                                              std::move(executables)));\n   EXPECT_EQ(profiles.size(), 3);\n@@ -216,7 +216,7 @@ TEST_F(GpuProfilerTest, CreateInputBuffersAndProfile) {\n   MockExecutable mock_executable(module, 1000);\n \n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(&mock_executable));\n   TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,\n@@ -240,7 +240,7 @@ TEST_P(GpuProfilerTestWithRedzonePadding, CheckInputBuffers) {\n   MockExecutable mock_executable(module, 1000);\n   ProfileOptions options;\n   options.redzone_padding_bytes = GetParam();\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(&mock_executable));\n   TF_EXPECT_OK(profiler->CheckInputBuffers(*buffers));\n@@ -252,7 +252,7 @@ INSTANTIATE_TEST_SUITE_P(GpuProfilerTestWithRedzonePadding,\n \n TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreSame) {\n   ProfileOptions options;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n \n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n   auto allocator =\n@@ -270,7 +270,7 @@ TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreSame) {\n \n TEST_F(GpuProfilerTest, CheckOutputBufferWhenBuffersAreDifferent) {\n   ProfileOptions options;\n-  auto profiler = GpuProfiler::Create(stream_exec_, allocator_.get(), options);\n+  auto profiler = GpuProfiler::Create(stream_exec_, options, allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, stream_exec_->CreateStream());\n   auto allocator =\n       std::make_unique<stream_executor::StreamExecutorMemoryAllocator>(\n@@ -311,7 +311,7 @@ ENTRY %entry_computation (transpose.562: bf16[32,120,6,512], Arg_1.2: f32[3072,5\n                           compiler.RunBackend(std::move(module), stream_exec_,\n                                               GpuCompiler::CompileOptions()));\n   auto profiler =\n-      GpuProfiler::Create(stream_exec_, allocator_.get(), ProfileOptions());\n+      GpuProfiler::Create(stream_exec_, ProfileOptions(), allocator_.get());\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<InputBuffers> buffers,\n                           profiler->CreateInputBuffers(gpu_executable.get()));\n   TF_ASSERT_OK_AND_ASSIGN(ProfileResult profile,"
        },
        {
            "sha": "ffb3601e43be9766ca1ed9960f5671c3ac8e8c30",
            "filename": "third_party/xla/xla/service/gpu/autotuning/autotuner_pass.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fautotuning%2Fautotuner_pass.cc?ref=cd89ef29150c6c4c9ed0e9c550fcddb475e0ab18",
            "patch": "@@ -49,7 +49,7 @@ absl::StatusOr<std::unique_ptr<AutotunerPass>> AutotunerPass::Create(\n     stream_executor::StreamExecutor* stream_executor,\n     tsl::thread::ThreadPool* thread_pool, InstructionFilterFn should_autotune) {\n   std::unique_ptr<GpuProfiler> profiler =\n-      GpuProfiler::Create(stream_executor, allocator, ProfileOptions());\n+      GpuProfiler::Create(stream_executor, ProfileOptions(), allocator);\n \n   std::unique_ptr<AutotunerCacheInterface> cache = nullptr;\n   const std::string& cache_dir ="
        }
    ],
    "stats": {
        "total": 52,
        "additions": 33,
        "deletions": 19
    }
}