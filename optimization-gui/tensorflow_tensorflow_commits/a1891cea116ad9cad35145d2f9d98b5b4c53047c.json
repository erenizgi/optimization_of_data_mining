{
    "author": "sergachev",
    "message": "PR #31994: [NFC] Move computation simplification methods from command buffer scheduling to a new library.\n\nImported from GitHub PR https://github.com/openxla/xla/pull/31994\n\nCopybara import of the project:\n\n--\ndd037f3ef1c2da262029a9ebc34845ddb3c8a7f1 by Ilia Sergachev <isergachev@nvidia.com>:\n\n[NFC] Move computation simplification methods from command buffer scheduling to a new library.\n\n--\n2594c7a473945f5d410ae8e8894b7e90f5812c1e by Ilia Sergachev <isergachev@nvidia.com>:\n\nAddress review feedback.\n\nMerging this change closes #31994\n\nPiperOrigin-RevId: 819631409",
    "sha": "a1891cea116ad9cad35145d2f9d98b5b4c53047c",
    "files": [
        {
            "sha": "701b607575e3b40c948fff75820319268d07c63c",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/BUILD",
            "status": "modified",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2FBUILD?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -113,6 +113,33 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"computation_canonicalizers\",\n+    srcs = [\"computation_canonicalizers.cc\"],\n+    hdrs = [\"computation_canonicalizers.h\"],\n+    deps = [\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/tsl/platform:errors\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/status:statusor\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"computation_canonicalizers_test\",\n+    srcs = [\"computation_canonicalizers_test.cc\"],\n+    deps = [\n+        \":computation_canonicalizers\",\n+        \"//xla/hlo/parser:hlo_parser\",\n+        \"//xla/hlo/testlib:filecheck\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/hlo/testlib:verified_hlo_module\",\n+        \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n xla_cc_test(\n     name = \"broadcast_canonicalizer_test\",\n     srcs = [\"broadcast_canonicalizer_test.cc\"],"
        },
        {
            "sha": "e75d6c5300c2b60fecfdbdb1e0d5e3fbf5fc3255",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/computation_canonicalizers.cc",
            "status": "added",
            "additions": 112,
            "deletions": 0,
            "changes": 112,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.cc?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -0,0 +1,112 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/hlo/transforms/simplifiers/computation_canonicalizers.h\"\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/ir/hlo_schedule.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+\n+namespace xla {\n+\n+namespace {\n+static bool IsConstant(const HloInstruction* hlo) {\n+  return HloPredicateIsOp<HloOpcode::kConstant>(hlo);\n+}\n+\n+static bool IsParameter(const HloInstruction* hlo) {\n+  return HloPredicateIsOp<HloOpcode::kParameter>(hlo);\n+}\n+\n+static bool IsGetTupleElement(const HloInstruction* hlo) {\n+  return HloPredicateIsOp<HloOpcode::kGetTupleElement>(hlo);\n+}\n+}  // namespace\n+\n+absl::StatusOr<bool> MoveGTEsRightAfterTupleDefinition(\n+    HloComputation& computation) {\n+  HloInstructionSequence new_sequence;\n+  HloSchedule& schedule = computation.parent()->schedule();\n+  const HloInstructionSequence sequence =\n+      schedule.GetOrCreateSequence(&computation);\n+\n+  absl::flat_hash_set<HloInstruction*> moved_gtes;\n+\n+  for (HloInstruction* inst : sequence.instructions()) {\n+    if (!moved_gtes.contains(inst)) {\n+      new_sequence.push_back(inst);\n+    }\n+    if (!inst->shape().IsTuple()) {\n+      continue;\n+    }\n+    for (HloInstruction* user : inst->users()) {\n+      if (IsGetTupleElement(user) && !user->HasControlDependencies()) {\n+        new_sequence.push_back(user);\n+        moved_gtes.insert(user);\n+      }\n+    }\n+  }\n+\n+  bool changed = new_sequence != sequence;\n+  schedule.set_sequence(&computation, std::move(new_sequence));\n+  return changed;\n+}\n+\n+absl::StatusOr<bool> MoveParametersAndConstantsToFront(\n+    HloComputation& computation) {\n+  HloInstructionSequence new_sequence;\n+  HloSchedule& schedule = computation.parent()->schedule();\n+  HloInstructionSequence& sequence = schedule.GetOrCreateSequence(&computation);\n+\n+  for (HloInstruction* inst : sequence.instructions()) {\n+    if (IsParameter(inst) || IsConstant(inst)) {\n+      new_sequence.push_back(inst);\n+\n+      // Because we move instruction to the front of the computation we can't\n+      // have any control predecessors, however silently dropping them is unsafe\n+      // as we can have transitive dependencies that define schedule order, so\n+      // we forward control predecessors to all users.\n+      for (HloInstruction* control_predecessor : inst->control_predecessors()) {\n+        for (HloInstruction* user : inst->users()) {\n+          TF_RETURN_IF_ERROR(control_predecessor->AddControlDependencyTo(user));\n+        }\n+      }\n+      TF_RETURN_IF_ERROR(inst->DropAllControlDeps());\n+    }\n+  }\n+\n+  for (HloInstruction* inst : sequence.instructions()) {\n+    if (!IsParameter(inst) && !IsConstant(inst)) {\n+      new_sequence.push_back(inst);\n+    }\n+  }\n+\n+  schedule.set_sequence(&computation, new_sequence);\n+  const auto& old_instructions = sequence.instructions();\n+  const auto& new_instructions = new_sequence.instructions();\n+  for (size_t i = 0; i < old_instructions.size(); ++i) {\n+    if (old_instructions[i] != new_instructions[i]) {\n+      return true;\n+    }\n+  }\n+  return false;\n+}\n+\n+}  // namespace xla"
        },
        {
            "sha": "2b9736cfedf063b52143a19ebb3a6a665110b25c",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/computation_canonicalizers.h",
            "status": "added",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers.h?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -0,0 +1,39 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_HLO_TRANSFORMS_SIMPLIFIERS_COMPUTATION_CANONICALIZERS_H_\n+#define XLA_HLO_TRANSFORMS_SIMPLIFIERS_COMPUTATION_CANONICALIZERS_H_\n+\n+#include \"absl/status/statusor.h\"\n+#include \"xla/hlo/ir/hlo_computation.h\"\n+\n+namespace xla {\n+\n+// This function moves kParameter and kConstant instructions in a computation to\n+// the beginning of the computation. This simplifies other transformations like\n+// the construction of command buffer computations because we don't need to deal\n+// with parameters and constants that have users outside of a command buffer.\n+// Returns true if there is a change in the order of instructions, false\n+// otherwise.\n+absl::StatusOr<bool> MoveParametersAndConstantsToFront(HloComputation&);\n+\n+// Moves GetTupleElement instructions to right after the instruction that\n+// produces the tuple. Returns whether the computation was changed. This is run,\n+// for instance, before command buffer scheduling.\n+absl::StatusOr<bool> MoveGTEsRightAfterTupleDefinition(HloComputation&);\n+\n+}  // namespace xla\n+\n+#endif  // XLA_HLO_TRANSFORMS_SIMPLIFIERS_COMPUTATION_CANONICALIZERS_H_"
        },
        {
            "sha": "62217c091037d59a7b885a2d47272ab3552f01ce",
            "filename": "third_party/xla/xla/hlo/transforms/simplifiers/computation_canonicalizers_test.cc",
            "status": "added",
            "additions": 102,
            "deletions": 0,
            "changes": 102,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Ftransforms%2Fsimplifiers%2Fcomputation_canonicalizers_test.cc?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -0,0 +1,102 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+#include \"xla/hlo/transforms/simplifiers/computation_canonicalizers.h\"\n+\n+#include <gtest/gtest.h>\n+#include \"xla/hlo/parser/hlo_parser.h\"\n+#include \"xla/hlo/testlib/filecheck.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n+#include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace {\n+\n+using ComputationCanonicalizersTest = HloHardwareIndependentTestBase;\n+\n+TEST_F(ComputationCanonicalizersTest, MoveParametersToFront) {\n+  const char* hlo = R\"(\n+      HloModule TestModule, is_scheduled=true\n+\n+      %fused_computation (param_0: s32[], param_1: s32[]) -> s32[] {\n+        %p0 = s32[] parameter(0)\n+        %p1 = s32[] parameter(1)\n+        ROOT %add = s32[] add(s32[] %p0, s32[] %p1)\n+      }\n+\n+      %fused_computation.1 (param_0: s32[], param_1: s32[]) -> s32[] {\n+        %p0 = s32[] parameter(0)\n+        %p1 = s32[] parameter(1)\n+        ROOT %add = s32[] add(s32[] %p0, s32[] %p1)\n+      }\n+\n+      ENTRY %main (a: s32[], b: s32[], c: s32[]) -> s32[] {\n+        %a = s32[] parameter(0)\n+        %b = s32[] parameter(1)\n+        %fusion = s32[] fusion(s32[] %a, s32[] %b), kind=kLoop, calls=%fused_computation\n+        %c = s32[] parameter(2)\n+        ROOT %fusion.1 = s32[] fusion(s32[] %a, s32[] %c), kind=kLoop, calls=%fused_computation.1\n+      })\";\n+\n+  const char* expected = R\"(\n+// CHECK: ENTRY %main (a: s32[], b: s32[], c: s32[]) -> s32[] {\n+// CHECK:   %a = s32[] parameter(0)\n+// CHECK:   %b = s32[] parameter(1)\n+// CHECK:   %c = s32[] parameter(2)\n+// CHECK:   %fusion = s32[] fusion(%a, %b), kind=kLoop, calls=%fused_computation\n+// CHECK:   ROOT %fusion.1 = s32[] fusion(%a, %c), kind=kLoop, calls=%fused_computation.1\n+// CHECK: })\";\n+\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo));\n+  TF_ASSERT_OK(MoveParametersAndConstantsToFront(*module->entry_computation()));\n+  EXPECT_THAT(\n+      RunFileCheck(\n+          module->ToString(HloPrintOptions{}.set_print_operand_shape(false)),\n+          expected),\n+      absl_testing::IsOkAndHolds(true));\n+}\n+\n+TEST_F(ComputationCanonicalizersTest, MoveGTEsRightAfterTupleDefinition) {\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+HloModule m, is_scheduled=true\n+e {\n+  a = s32[] parameter(0)\n+  b = s32[] parameter(1)\n+  t = tuple(a, b)\n+  x = s32[] add(a, b)\n+  g0 = s32[] get-tuple-element(t), index=0\n+  g1 = s32[] get-tuple-element(t), index=1\n+  r = s32[] multiply(g0, g1)\n+})\"));\n+  EXPECT_THAT(MoveGTEsRightAfterTupleDefinition(*module->entry_computation()),\n+              absl_testing::IsOkAndHolds(true));\n+  EXPECT_THAT(RunFileCheck(module->ToString(),\n+                           R\"(\n+// CHECK:      parameter\n+// CHECK-NEXT: parameter\n+// CHECK-NEXT: tuple\n+// CHECK-NEXT: get-tuple-element\n+// CHECK-NEXT: get-tuple-element\n+// CHECK-NEXT: add\n+// CHECK-NEXT: multiply\n+)\"),\n+              absl_testing::IsOkAndHolds(true));\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        },
        {
            "sha": "bf89498df7948fd0b04880a98a6332e184a58e52",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -368,6 +368,7 @@ cc_library(\n         \"//xla/ffi:ffi_api\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/pass:hlo_pass\",\n+        \"//xla/hlo/transforms/simplifiers:computation_canonicalizers\",\n         \"//xla/hlo/utils:hlo_longest_prefix\",\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service/gpu:backend_configs_cc\","
        },
        {
            "sha": "42cadb348df845d654ec258c6da90e3db49cf051",
            "filename": "third_party/xla/xla/service/gpu/transforms/command_buffer_scheduling.cc",
            "status": "modified",
            "additions": 40,
            "deletions": 120,
            "changes": 160,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.cc?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -37,7 +37,6 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n-#include \"llvm/ADT/STLExtras.h\"\n #include \"xla/ffi/ffi_api.h\"\n #include \"xla/hlo/ir/hlo_casting_utils.h\"\n #include \"xla/hlo/ir/hlo_clone_context.h\"\n@@ -46,6 +45,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instructions.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_schedule.h\"\n+#include \"xla/hlo/transforms/simplifiers/computation_canonicalizers.h\"\n #include \"xla/hlo/utils/hlo_longest_prefix.h\"\n #include \"xla/hlo/utils/hlo_traversal.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n@@ -87,10 +87,6 @@ static bool IsParameter(const HloInstruction* hlo) {\n   return HloPredicateIsOp<HloOpcode::kParameter>(hlo);\n }\n \n-static bool IsGetTupleElement(const HloInstruction* hlo) {\n-  return HloPredicateIsOp<HloOpcode::kGetTupleElement>(hlo);\n-}\n-\n // Returns true if instruction is no-op at run time and doesn't have a\n // corresponding Thunk or Command (metadata only operation).\n static bool IsNoOp(const HloInstruction* hlo) {\n@@ -324,7 +320,7 @@ static bool IsCommand(const HloInstruction* hlo,\n     return config.enabled_commands.contains(DebugOptions::FUSION);\n   }\n \n-  if (auto* sort = DynCast<HloSortInstruction>(hlo)) {\n+  if (DynCast<HloSortInstruction>(hlo)) {\n     return config.enabled_commands.contains(DebugOptions::FUSION);\n   }\n \n@@ -379,73 +375,6 @@ static void RemoveTrailingNoOps(HloInstructionSequence& seq) {\n   }\n }\n \n-// Moves GetTupleElement instructions to right after the instruction that\n-// produces the tuple. Returns whether the computation was changed. This is run\n-// before command buffer scheduling.\n-//\n-// The motivation is to ensure the live range of large elements in the tuple are\n-// not extended due to the creation of command buffers. For example, consider\n-// the following input HLO to this pass.\n-//\n-//     x = f32[] parameter(0)\n-//     t = (f32[], f32[10000]) custom-call()\n-//     ... # Many instructions, none which use t\n-//     x_squared = f32[] multiply(x, x)\n-//     t0 = f32[] get-tuple-element(t), index=0\n-//     y = f32[] add(x_squared, t0)\n-//\n-// The 10000-element buffer can immediately be freed after the custom-call, as\n-// it is unused. However, if `t0` is not moved right after `t`, then the\n-// scheudling of command buffers might turn the HLO into the following,\n-// extending the live range of the 10000-element buffer as 't' is passed to the\n-// command buffer:\n-//\n-//     command_buffer {\n-//       t = (f32[], f32[10000]) paramter(0)\n-//       x_squared = f32[] multiply(x, x)\n-//       t0 = f32[] get-tuple-element(t), index=0\n-//       ROOT y = f32[] add(x_squared, t0)\n-//     }\n-//\n-//     main {\n-//       x = f32[] parameter(0)\n-//       t = (f32[], f32[10000]) custom-call()\n-//       ... # Many instructions, none which use t\n-//       ROOT y = f32[] call(t), to_apply=command_buffer\n-//     }\n-//\n-// Moving the GTE right after `t` solves this, as command-buffers never start\n-// with a GTE, so it's impossible for a command buffer to contain the GTE but\n-// not the custom-call itself.\n-static absl::StatusOr<bool> MoveGTEsRightAfterTupleDefinition(\n-    HloComputation* computation) {\n-  HloInstructionSequence new_sequence;\n-  HloSchedule& schedule = computation->parent()->schedule();\n-  const HloInstructionSequence sequence =\n-      schedule.GetOrCreateSequence(computation);\n-\n-  absl::flat_hash_set<HloInstruction*> moved_gtes;\n-\n-  for (HloInstruction* inst : sequence.instructions()) {\n-    if (!moved_gtes.contains(inst)) {\n-      new_sequence.push_back(inst);\n-    }\n-    if (!inst->shape().IsTuple()) {\n-      continue;\n-    }\n-    for (HloInstruction* user : inst->users()) {\n-      if (IsGetTupleElement(user) && !user->HasControlDependencies()) {\n-        new_sequence.push_back(user);\n-        moved_gtes.insert(user);\n-      }\n-    }\n-  }\n-\n-  bool changed = new_sequence != sequence;\n-  schedule.set_sequence(computation, std::move(new_sequence));\n-  return changed;\n-}\n-\n //===----------------------------------------------------------------------===//\n // Discovering sequences of compatible Hlo instructions\n //===----------------------------------------------------------------------===//\n@@ -621,51 +550,6 @@ CommandBufferScheduling::CollectCommandBufferSequences(\n   return sequences;\n }\n \n-// This function moves kParameter and kConstant instructions in a computation to\n-// the beginning of the computation. This simplifies the construction of command\n-// buffer computations because we don't need to deal with parameters and\n-// constants that have users outside of a command buffer.\n-// Returns true if there is a change in the order of instructions, false\n-// otherwise.\n-absl::StatusOr<bool> CommandBufferScheduling::MoveParametersAndConstantsToFront(\n-    HloComputation* computation) {\n-  HloInstructionSequence new_sequence;\n-  HloSchedule& schedule = computation->parent()->schedule();\n-  HloInstructionSequence& sequence = schedule.GetOrCreateSequence(computation);\n-\n-  for (HloInstruction* inst : sequence.instructions()) {\n-    if (IsParameter(inst) || IsConstant(inst)) {\n-      new_sequence.push_back(inst);\n-\n-      // Because we move instruction to the front of the computation we can't\n-      // have any control predecessors, however silently dropping them is unsafe\n-      // as we can have transitive dependencies that define schedule order, so\n-      // we forward control predecessors to all users.\n-      for (HloInstruction* control_predecessor : inst->control_predecessors()) {\n-        for (HloInstruction* user : inst->users()) {\n-          TF_RETURN_IF_ERROR(control_predecessor->AddControlDependencyTo(user));\n-        }\n-      }\n-      TF_RETURN_IF_ERROR(inst->DropAllControlDeps());\n-    }\n-  }\n-\n-  for (HloInstruction* inst : sequence.instructions()) {\n-    if (!IsParameter(inst) && !IsConstant(inst)) {\n-      new_sequence.push_back(inst);\n-    }\n-  }\n-\n-  schedule.set_sequence(computation, new_sequence);\n-  for (auto [old_i, new_i] :\n-       llvm::zip(sequence.instructions(), new_sequence.instructions())) {\n-    if (old_i != new_i) {\n-      return true;\n-    }\n-  }\n-  return false;\n-}\n-\n //===----------------------------------------------------------------------===//\n // Prepares command buffer from sequence of instructions\n //===----------------------------------------------------------------------===//\n@@ -992,9 +876,45 @@ absl::StatusOr<bool> CommandBufferScheduling::Run(\n       continue;\n     }\n \n-    TF_ASSIGN_OR_RETURN(bool changed_, MoveParametersAndConstantsToFront(comp));\n+    TF_ASSIGN_OR_RETURN(bool changed_,\n+                        MoveParametersAndConstantsToFront(*comp));\n     changed |= changed_;\n-    TF_ASSIGN_OR_RETURN(changed_, MoveGTEsRightAfterTupleDefinition(comp));\n+    // The motivation for MoveGTEsRightAfterTupleDefinition is to ensure the\n+    // live range of large elements in the tuple are not extended due to the\n+    // creation of command buffers. For example, consider the following input\n+    // HLO to this pass.\n+    //\n+    //     x = f32[] parameter(0)\n+    //     t = (f32[], f32[10000]) custom-call()\n+    //     ... # Many instructions, none which use t\n+    //     x_squared = f32[] multiply(x, x)\n+    //     t0 = f32[] get-tuple-element(t), index=0\n+    //     y = f32[] add(x_squared, t0)\n+    //\n+    // The 10000-element buffer can immediately be freed after the custom-call,\n+    // as it is unused. However, if `t0` is not moved right after `t`, then the\n+    // scheudling of command buffers might turn the HLO into the following,\n+    // extending the live range of the 10000-element buffer as 't' is passed to\n+    // the command buffer:\n+    //\n+    //     command_buffer {\n+    //       t = (f32[], f32[10000]) paramter(0)\n+    //       x_squared = f32[] multiply(x, x)\n+    //       t0 = f32[] get-tuple-element(t), index=0\n+    //       ROOT y = f32[] add(x_squared, t0)\n+    //     }\n+    //\n+    //     main {\n+    //       x = f32[] parameter(0)\n+    //       t = (f32[], f32[10000]) custom-call()\n+    //       ... # Many instructions, none which use t\n+    //       ROOT y = f32[] call(t), to_apply=command_buffer\n+    //     }\n+    //\n+    // Moving the GTE right after `t` solves this, as command-buffers never\n+    // start with a GTE, so it's impossible for a command buffer to contain the\n+    // GTE but not the custom-call itself.\n+    TF_ASSIGN_OR_RETURN(changed_, MoveGTEsRightAfterTupleDefinition(*comp));\n     changed |= changed_;\n \n     std::vector<HloInstructionSequence> sequences ="
        },
        {
            "sha": "702d22a0356b4979384c143466edf6d76f97ce41",
            "filename": "third_party/xla/xla/service/gpu/transforms/command_buffer_scheduling.h",
            "status": "modified",
            "additions": 0,
            "deletions": 9,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling.h?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -94,15 +94,6 @@ class CommandBufferScheduling : public HloModulePass {\n       HloInstructionSequence schedule, const CommandBufferConfig& config,\n       int32_t min_num_commands = 1);\n \n-  // Moves kParameter and kConstant instructions in a computation to\n-  // the beginning of the computation. This simplifies the construction of\n-  // command buffer computations because we don't need to deal with parameters\n-  // and constants that have users outside of a command buffer.\n-  // Returns true if there is a change in the order of instructions, false\n-  // otherwise.\n-  static absl::StatusOr<bool> MoveParametersAndConstantsToFront(\n-      HloComputation* computation);\n-\n   struct CommandBuffer {\n     // Command buffer arguments (call instruction arguments).\n     std::vector<HloInstruction*> arguments;"
        },
        {
            "sha": "ec5b234a171c9a2ea342ef0e77fcf2c0839b2ba3",
            "filename": "third_party/xla/xla/service/gpu/transforms/command_buffer_scheduling_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 45,
            "changes": 45,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a1891cea116ad9cad35145d2f9d98b5b4c53047c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcommand_buffer_scheduling_test.cc?ref=a1891cea116ad9cad35145d2f9d98b5b4c53047c",
            "patch": "@@ -532,51 +532,6 @@ TEST_F(CommandBufferSchedulingTest, CollectCommandBufferSequence) {\n   EXPECT_EQ(seq_1[1]->opcode(), HloOpcode::kFusion);\n }\n \n-TEST_F(CommandBufferSchedulingTest, MoveParametersToFront) {\n-  const char* hlo = R\"(\n-      HloModule TestModule, is_scheduled=true\n-\n-      %fused_computation (param_0: s32[], param_1: s32[]) -> s32[] {\n-        %p0 = s32[] parameter(0)\n-        %p1 = s32[] parameter(1)\n-        ROOT %add = s32[] add(s32[] %p0, s32[] %p1)\n-      }\n-\n-      %fused_computation.1 (param_0: s32[], param_1: s32[]) -> s32[] {\n-        %p0 = s32[] parameter(0)\n-        %p1 = s32[] parameter(1)\n-        ROOT %add = s32[] add(s32[] %p0, s32[] %p1)\n-      }\n-\n-      ENTRY %main (a: s32[], b: s32[], c: s32[]) -> s32[] {\n-        %a = s32[] parameter(0)\n-        %b = s32[] parameter(1)\n-        %fusion = s32[] fusion(s32[] %a, s32[] %b), kind=kLoop, calls=%fused_computation\n-        %c = s32[] parameter(2)\n-        ROOT %fusion.1 = s32[] fusion(s32[] %a, s32[] %c), kind=kLoop, calls=%fused_computation.1\n-      })\";\n-\n-  const char* expected = R\"(\n-// CHECK: ENTRY %main (a: s32[], b: s32[], c: s32[]) -> s32[] {\n-// CHECK:   %a = s32[] parameter(0)\n-// CHECK:   %b = s32[] parameter(1)\n-// CHECK:   %c = s32[] parameter(2)\n-// CHECK:   %fusion = s32[] fusion(%a, %b), kind=kLoop, calls=%fused_computation\n-// CHECK:   ROOT %fusion.1 = s32[] fusion(%a, %c), kind=kLoop, calls=%fused_computation.1\n-// CHECK: })\";\n-\n-  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> module,\n-                          ParseAndReturnVerifiedModule(hlo));\n-  TF_ASSERT_OK(CommandBufferScheduling::MoveParametersAndConstantsToFront(\n-      module->entry_computation()));\n-  TF_ASSERT_OK_AND_ASSIGN(\n-      bool filecheck_matches,\n-      RunFileCheck(\n-          module->ToString(HloPrintOptions{}.set_print_operand_shape(false)),\n-          expected));\n-  EXPECT_TRUE(filecheck_matches);\n-}\n-\n TEST_F(CommandBufferSchedulingTest, PrepareCommandBuffer) {\n   const char* hlo = R\"(\n       HloModule TestModule, is_scheduled=true"
        }
    ],
    "stats": {
        "total": 495,
        "additions": 321,
        "deletions": 174
    }
}