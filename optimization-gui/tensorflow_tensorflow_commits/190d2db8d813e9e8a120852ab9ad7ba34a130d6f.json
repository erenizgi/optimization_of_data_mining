{
    "author": "derdrdirk",
    "message": "Enable CublasLt via GemmRewriter configuration. Moves DebugOptions flag `xla_gpu_enable_cublas_lt` out of GemmRewriter pass.\nThis change is required to enable autotuning both: Cublas and CublasLt kernels.\n\nPiperOrigin-RevId: 845232642",
    "sha": "190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
    "files": [
        {
            "sha": "c0d7d088081e52db4f3f5cbc88c755940f279699",
            "filename": "third_party/xla/xla/backends/gpu/runtime/gpublas_lt_matmul_thunk_test.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fgpublas_lt_matmul_thunk_test.cc?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -191,12 +191,14 @@ void GpuBlasLtMatmulThunkTest::CreateExecuteThunksFromHLO(\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           this->ParseAndReturnVerifiedModule(hlo_string));\n \n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n   TF_ASSERT_OK_AND_ASSIGN(\n       bool changed,\n-      RunHloPass(\n-          GemmRewriter(gpu_comp(executor),\n-                       /*toolkit_version=*/se::SemanticVersion{12, 4, 0}),\n-          module.get()));\n+      RunHloPass(GemmRewriter(gpu_comp(executor),\n+                              /*toolkit_version=*/se::SemanticVersion{12, 4, 0},\n+                              options),\n+                 module.get()));\n   ASSERT_TRUE(changed);\n \n   GpuBlasLtThunkBuilder builder(executor, gpu_comp(executor));"
        },
        {
            "sha": "ca28137784bfdf2074e5a29c4cc303047eb50c67",
            "filename": "third_party/xla/xla/service/gpu/gpu_compiler.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fgpu_compiler.cc?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -1638,7 +1638,8 @@ void AddGemmRewriterPasses(HloPassPipeline& pipeline,\n       GemmRewriterOptions{GemmRewriterOptions::DType::kFp8Only, bias_mode});\n   pipeline.AddPass<GemmRewriter>(\n       gpu_version, toolkit_version,\n-      GemmRewriterOptions{GemmRewriterOptions::DType::kNonFp8Only, bias_mode});\n+      GemmRewriterOptions{GemmRewriterOptions::DType::kNonFp8Only, bias_mode,\n+                          debug_options.xla_gpu_enable_cublaslt()});\n }\n }  // namespace\n "
        },
        {
            "sha": "12c6abf3a46270181dbf1b4733ca33d0f94cfa15",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -1546,7 +1546,6 @@ xla_test(\n         \"//xla/hlo/testlib:filecheck\",\n         \"//xla/hlo/testlib:pattern_matcher_gmock\",\n         \"//xla/hlo/testlib:test\",\n-        \"//xla/service:buffer_assignment\",\n         \"//xla/service:executable\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service:pattern_matcher\",\n@@ -1557,7 +1556,6 @@ xla_test(\n         \"//xla/stream_executor:semantic_version\",\n         \"//xla/stream_executor:stream_executor_memory_allocator\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/status:statusor\","
        },
        {
            "sha": "a877a45991fb7809558849f7e4dd6afdf4144125",
            "filename": "third_party/xla/xla/service/gpu/transforms/cublas_gemm_rewriter_test.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 5,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcublas_gemm_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcublas_gemm_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcublas_gemm_rewriter_test.cc?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -2467,7 +2467,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = true;\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -2544,7 +2546,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = true;\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -2827,7 +2831,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -3145,7 +3151,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = true;\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   SCOPED_TRACE(module->ToString());\n   EXPECT_TRUE(changed);\n@@ -3434,7 +3442,9 @@ ENTRY %test (x: f32[2,3,4], y: f32[4,5,7], z: f32[7]) -> f32[2,3,5,7] {\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text, config));\n \n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = true;\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n "
        },
        {
            "sha": "1481eebc29a044e79d0c51294a1214edbf4ad5fa",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.cc?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -2047,10 +2047,7 @@ class GemmRewriterVisitor : public DfsHloRewriteVisitor {\n   absl::StatusOr<absl::string_view> GetNonFp8GemmCustomCallTarget(\n       const HloInstruction& instr,\n       const GemmBackendConfig& gemm_backend_config) const {\n-    if (!instr.GetModule()\n-             ->config()\n-             .debug_options()\n-             .xla_gpu_enable_cublaslt()) {\n+    if (!options_.enable_cublaslt) {\n       // cublasLt is not enabled.\n       return absl::string_view(kGemmCallTarget);\n     }"
        },
        {
            "sha": "e4b9bf8cc9d9f8f6f6c5d6bef1c6aa4308fba69c",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter.h?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -72,6 +72,10 @@ struct GemmRewriterOptions {\n   // In this case, the two GEMMs can be scheduled in parallel.\n   enum class BiasMode { kBias, kNoBias };\n   BiasMode bias_mode = BiasMode::kBias;\n+\n+  // Enables the use of cublasLt for non-FP8 GEMMs.\n+  // FP8 GEMMs are always rewritten to use cublasLt.\n+  bool enable_cublaslt = false;\n };\n \n class GemmRewriter : public HloModulePass {"
        },
        {
            "sha": "9249133b3ad766e5e30c90b9cfc42d9c7560e49b",
            "filename": "third_party/xla/xla/service/gpu/transforms/gemm_rewriter_test.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 10,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/190d2db8d813e9e8a120852ab9ad7ba34a130d6f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fgemm_rewriter_test.cc?ref=190d2db8d813e9e8a120852ab9ad7ba34a130d6f",
            "patch": "@@ -35,7 +35,6 @@ limitations under the License.\n #include \"xla/hlo/testlib/filecheck.h\"\n #include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n #include \"xla/hlo/testlib/test.h\"\n-#include \"xla/service/buffer_assignment.h\"\n #include \"xla/service/executable.h\"\n #include \"xla/service/gpu/gpu_executable.h\"\n #include \"xla/service/gpu/tests/gpu_codegen_test.h\"\n@@ -47,7 +46,6 @@ limitations under the License.\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/semantic_version.h\"\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n-#include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/xla.pb.h\"\n \n@@ -1273,7 +1271,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1297,7 +1297,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1321,7 +1323,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n   EXPECT_THAT(\n@@ -1342,7 +1346,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1366,7 +1372,9 @@ ENTRY test {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1394,7 +1402,9 @@ ENTRY main {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1422,7 +1432,9 @@ ENTRY main {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n \n@@ -1452,7 +1464,9 @@ ENTRY main {\n \n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n                           ParseAndReturnVerifiedModule(hlo_text));\n-  GemmRewriter pass(Capability(), GetToolkitVersion());\n+  GemmRewriterOptions options;\n+  options.enable_cublaslt = GetDebugOptionsForTest().xla_gpu_enable_cublaslt();\n+  GemmRewriter pass(Capability(), GetToolkitVersion(), options);\n   TF_ASSERT_OK_AND_ASSIGN(bool changed, this->RunHloPass(&pass, module.get()));\n   EXPECT_TRUE(changed);\n "
        }
    ],
    "stats": {
        "total": 78,
        "additions": 52,
        "deletions": 26
    }
}