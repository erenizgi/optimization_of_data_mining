{
    "author": "qukhan",
    "message": "Add a function to stop building a weight cache.\n\nWhen using the same weight cache provider across threads, the cache building\nrun will have all the threads try to build the cache. With this, we can setup\nan initial interpreter that builds the cache, signal to the weight provider\nthat there is no building to do anymore and then setup the other threads.\n\nPiperOrigin-RevId: 827941244",
    "sha": "6496783e62e69487f9830e278ae3cd67a44c8ef6",
    "files": [
        {
            "sha": "6ab8553c5d1fb6a04b26e2bc51887a22fbc9f7d1",
            "filename": "tensorflow/lite/delegates/xnnpack/README.md",
            "status": "modified",
            "additions": 10,
            "deletions": 2,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6496783e62e69487f9830e278ae3cd67a44c8ef6/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2FREADME.md",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6496783e62e69487f9830e278ae3cd67a44c8ef6/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2FREADME.md",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2FREADME.md?ref=6496783e62e69487f9830e278ae3cd67a44c8ef6",
            "patch": "@@ -277,6 +277,12 @@ TfLiteDelegate* delegate1 = TfLiteXNNPackDelegateCreate(&xnnpack_options);\n if (interpreter1->ModifyGraphWithDelegate(delegate1) != kTfLiteOk) {\n   // Handle errors...\n }\n+// Signal to the weight cache provider that there's no building to be done\n+// anymore. That way subsequent interpreter setups won't try to continue\n+// building the cache.\n+weight_cache.StopBuild();\n+\n+// Modify graph with delegate, as above...\n TfLiteDelegate* delegate2 = TfLiteXNNPackDelegateCreate(&xnnpack_options);\n if (interpreter2->ModifyGraphWithDelegate(delegate2) != kTfLiteOk) {\n   // Handle errors...\n@@ -287,8 +293,10 @@ if (interpreter2->ModifyGraphWithDelegate(delegate2) != kTfLiteOk) {\n // directly read from disk the 2nd time.\n ```\n \n-Warning: Sharing the cache is not thread safe for writing. You should always do\n-one full run of one of the interpreters before starting threading.\n+Warning: Sharing the cache is not thread safe for building. You should always do\n+one full run of one of the interpreters before starting threading. **Once the\n+building run is done**, call `weight_cache.StopBuild()` before using the weight\n+cache provider to build other delegate instances.\n \n ## Profiling\n "
        },
        {
            "sha": "82057aa3f03a8ae431173836bd25b4bcd6bb0728",
            "filename": "tensorflow/lite/delegates/xnnpack/weight_cache.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6496783e62e69487f9830e278ae3cd67a44c8ef6/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6496783e62e69487f9830e278ae3cd67a44c8ef6/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Flite%2Fdelegates%2Fxnnpack%2Fweight_cache.h?ref=6496783e62e69487f9830e278ae3cd67a44c8ef6",
            "patch": "@@ -248,6 +248,11 @@ class MMapWeightCacheProvider {\n   [[nodiscard /*Starting to build a cache file may fail.*/]]\n   bool StartBuild(const char* file_path, FileDescriptor fd = FileDescriptor());\n \n+  // If the cache is still being built, this signals that all of the building\n+  // operations are done and that `CanStartBuildStep()` should now return\n+  // `false`.\n+  void StopBuild() { building_run_ = false; }\n+\n   // Sets the weight file path and loads it.\n   [[nodiscard /*Loading a cache file may fail.*/]]\n   bool Load(const std::string& path, FileDescriptor fd = FileDescriptor());"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 15,
        "deletions": 2
    }
}