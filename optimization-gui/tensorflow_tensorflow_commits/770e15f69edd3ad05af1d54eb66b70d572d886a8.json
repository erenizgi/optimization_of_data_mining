{
    "author": "tensorflower-gardener",
    "message": "[Autotuner] Crash on correctness checks if requested.\n\n- Fixes the behavior of xla_gpu_crash_on_verification_failures XLA Flag.\n\nPiperOrigin-RevId: 807607836",
    "sha": "770e15f69edd3ad05af1d54eb66b70d572d886a8",
    "files": [
        {
            "sha": "2ff2c3e85a6ac9bbea5667cb28b5015794d7eedf",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/770e15f69edd3ad05af1d54eb66b70d572d886a8/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/770e15f69edd3ad05af1d54eb66b70d572d886a8/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.cc?ref=770e15f69edd3ad05af1d54eb66b70d572d886a8",
            "patch": "@@ -296,6 +296,9 @@ absl::StatusOr<std::vector<Autotuner::ConfigResult>> Autotuner::ProfileAll(\n         failure =\n             CheckBuffers(*input_buffers, profile_result->output_buffer.value(),\n                          reference_output.value());\n+        if (failure.has_value()) {\n+          CHECK(!autotune_config_.crash_on_check_failure);\n+        }\n       }\n     }\n     results_vec.push_back(\n@@ -360,7 +363,6 @@ std::optional<Autotuner::Failure> Autotuner::CheckBuffers(\n     ScopedShapedBuffer& reference_output) {\n   absl::Status status = profiler_->CheckInputBuffers(input_buffers);\n   if (!status.ok()) {\n-    CHECK(!autotune_config_.crash_on_check_failure);\n     return Failure{FailureKind::kRedzoneCheckFailed, status.ToString()};\n   }\n   status = profiler_->CheckOutputBuffer(output_buffer, reference_output,"
        },
        {
            "sha": "732b38ef42e887602e51144e5b224e224bbb57d0",
            "filename": "third_party/xla/xla/backends/autotuner/autotuner.h",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/770e15f69edd3ad05af1d54eb66b70d572d886a8/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/770e15f69edd3ad05af1d54eb66b70d572d886a8/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fautotuner%2Fautotuner.h?ref=770e15f69edd3ad05af1d54eb66b70d572d886a8",
            "patch": "@@ -43,8 +43,6 @@ using InstructionFilterFn = absl::FunctionRef<bool(const xla::HloInstruction&)>;\n namespace xla {\n \n struct AutotuneConfig {\n-  // Whether to skip configs that failed to compile.\n-  bool skip_failing_configs = true;\n   // Whether to check the correctness of the output buffers and OOM reads on\n   // Input Buffers.\n   bool check_buffers = true;"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}