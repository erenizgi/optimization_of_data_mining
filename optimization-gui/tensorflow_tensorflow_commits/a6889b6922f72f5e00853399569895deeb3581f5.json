{
    "author": "pschuh",
    "message": "Switch to using CommonAsyncHostToDeviceTransferManager.\n\nPiperOrigin-RevId: 822701589",
    "sha": "a6889b6922f72f5e00853399569895deeb3581f5",
    "files": [
        {
            "sha": "b09be9a80c6662567bd057ed20f876b48441a0fa",
            "filename": "third_party/xla/xla/pjrt/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6889b6922f72f5e00853399569895deeb3581f5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6889b6922f72f5e00853399569895deeb3581f5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2FBUILD?ref=a6889b6922f72f5e00853399569895deeb3581f5",
            "patch": "@@ -79,6 +79,7 @@ cc_library(\n         \"//xla/core/collectives:communicator\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/builder:xla_computation\",\n+        \"//xla/pjrt:common_pjrt_client\",\n         \"//xla/pjrt:device_event\",\n         \"//xla/pjrt:event_pool\",\n         \"//xla/pjrt:host_memory_spaces\","
        },
        {
            "sha": "acc5c118805fbb13860516434152364f4dd4795d",
            "filename": "third_party/xla/xla/pjrt/gpu/se_gpu_pjrt_client.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6889b6922f72f5e00853399569895deeb3581f5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6889b6922f72f5e00853399569895deeb3581f5/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fgpu%2Fse_gpu_pjrt_client.cc?ref=a6889b6922f72f5e00853399569895deeb3581f5",
            "patch": "@@ -71,6 +71,7 @@ limitations under the License.\n #include \"xla/pjrt/gpu/gpu_topology.pb.h\"\n #include \"xla/pjrt/gpu/se_gpu_topology_description.h\"\n #include \"xla/pjrt/host_memory_spaces.h\"\n+#include \"xla/pjrt/host_to_device_transfer_manager.h\"\n #include \"xla/pjrt/local_device_state.h\"\n #include \"xla/pjrt/pjrt_client.h\"\n #include \"xla/pjrt/pjrt_common.h\"\n@@ -663,13 +664,8 @@ StreamExecutorGpuClient::CreateBuffersForAsyncHostToDevice(\n     absl::Span<const PjRtClient::ShapeSpec> shape_specs,\n     std::optional<absl::Span<const std::optional<Layout>>> device_layouts,\n     PjRtMemorySpace* memory_space) {\n-  CHECK_EQ(memory_space->devices().size(), 1);\n-  PjRtDevice* device = memory_space->devices()[0];\n-  auto* stream_executor_device =\n-      tensorflow::down_cast<PjRtStreamExecutorDevice*>(device);\n-  return xla::GpuAsyncHostToDeviceTransferManager::Create(\n-      shape_specs, std::move(device_layouts), stream_executor_device, this,\n-      memory_space);\n+  return xla::CreateAsyncHostToDeviceTransferManager(\n+      shape_specs, std::move(device_layouts), memory_space);\n }\n \n absl::StatusOr<absl::flat_hash_map<GlobalDeviceId, IncarnationId>>"
        }
    ],
    "stats": {
        "total": 11,
        "additions": 4,
        "deletions": 7
    }
}