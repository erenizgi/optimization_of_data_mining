{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 809669135",
    "sha": "882c84b941d25187624426065359921c1c19091c",
    "files": [
        {
            "sha": "8ed9ff5ce7c01679cb78b0dd82396cc909771ca2",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/882c84b941d25187624426065359921c1c19091c/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/882c84b941d25187624426065359921c1c19091c/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_test.cc?ref=882c84b941d25187624426065359921c1c19091c",
            "patch": "@@ -88,7 +88,7 @@ class TestCApiFactory {\n  public:\n   void Register(std::function<const PJRT_Api*()> factory,\n                 absl::string_view platform_name) {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     CHECK(!factory_);\n     factory_ = std::move(factory);\n     CHECK(platform_name_.empty()) << \"Platform name already provided\";\n@@ -97,13 +97,13 @@ class TestCApiFactory {\n   }\n \n   std::function<const PJRT_Api*()> Get() const {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     CHECK(factory_) << \"Test didn't call RegisterPjRtCApiTestFactory()\";\n     return factory_;\n   }\n \n   std::string GetPlatformName() const {\n-    absl::MutexLock lock(&mu_);\n+    absl::MutexLock lock(mu_);\n     CHECK(!platform_name_.empty())\n         << \"Test didn't call RegisterPjRtCApiTestFactory()\";\n     return platform_name_;"
        },
        {
            "sha": "4413ac9347c2d2e61a51af2346a70328a6542ed1",
            "filename": "third_party/xla/xla/pjrt/c/pjrt_c_api_wrapper_impl.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/882c84b941d25187624426065359921c1c19091c/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/882c84b941d25187624426065359921c1c19091c/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Fc%2Fpjrt_c_api_wrapper_impl.cc?ref=882c84b941d25187624426065359921c1c19091c",
            "patch": "@@ -1528,7 +1528,7 @@ PJRT_Error* PJRT_Executable_GetCostAnalysis(\n       PJRT_Executable_GetCostAnalysis_Args_STRUCT_SIZE, args->struct_size));\n \n   {\n-    absl::MutexLock lock(&args->executable->mutex);\n+    absl::MutexLock lock(args->executable->mutex);\n     if (!args->executable->cost_analysis_ran) {\n       PJRT_RETURN_IF_ERROR(PopulateExecutableCostAnalysis(args->executable));\n       args->executable->cost_analysis_ran = true;\n@@ -1552,7 +1552,7 @@ PJRT_Error* PJRT_Executable_OutputElementTypes(\n       PJRT_Executable_OutputElementTypes_Args_STRUCT_SIZE, args->struct_size));\n \n   {\n-    absl::MutexLock lock(&args->executable->mutex);\n+    absl::MutexLock lock(args->executable->mutex);\n     if (!args->executable->out_type_ran) {\n       PJRT_RETURN_IF_ERROR(\n           PopulateExecutableOutputElementTypes(args->executable));\n@@ -1572,7 +1572,7 @@ PJRT_Error* PJRT_Executable_OutputDimensions(\n       PJRT_Executable_OutputDimensions_Args_STRUCT_SIZE, args->struct_size));\n \n   {\n-    absl::MutexLock lock(&args->executable->mutex);\n+    absl::MutexLock lock(args->executable->mutex);\n     if (!args->executable->out_dimension_ran) {\n       PJRT_RETURN_IF_ERROR(\n           PopulateExecutableOutputDimensions(args->executable));\n@@ -1593,7 +1593,7 @@ PJRT_Error* PJRT_Executable_OutputMemoryKinds(\n       PJRT_Executable_OutputMemoryKinds_Args_STRUCT_SIZE, args->struct_size));\n \n   {\n-    absl::MutexLock lock(&args->executable->mutex);\n+    absl::MutexLock lock(args->executable->mutex);\n     if (!args->executable->memory_kind_ran) {\n       PJRT_RETURN_IF_ERROR(\n           PopulateExecutableOutputMemoryKinds(args->executable));\n@@ -1984,7 +1984,7 @@ PJRT_Error* PJRT_Buffer_UnpaddedDimensions(\n   std::optional<std::vector<int64_t>>& unpadded_dims =\n       args->buffer->unpadded_dims;\n   {\n-    absl::MutexLock lock(&args->buffer->mu);\n+    absl::MutexLock lock(args->buffer->mu);\n     if (!unpadded_dims.has_value()) {\n       PJRT_ASSIGN_OR_RETURN(std::vector<int64_t> dims,\n                             args->buffer->buffer->logical_dimensions());\n@@ -2006,7 +2006,7 @@ PJRT_Error* PJRT_Buffer_DynamicDimensionIndices(\n   std::optional<std::vector<size_t>>& dyn_dim_indices =\n       args->buffer->dynamic_dim_indices;\n   {\n-    absl::MutexLock lock(&args->buffer->mu);\n+    absl::MutexLock lock(args->buffer->mu);\n     if (!dyn_dim_indices.has_value()) {\n       std::vector<size_t>& dyn_dim_indices_value = dyn_dim_indices.emplace();\n       for (int i = 0; i < is_dyn_dim.size(); ++i) {\n@@ -2030,7 +2030,7 @@ PJRT_Error* PJRT_Buffer_GetMemoryLayout(\n   std::optional<BufferMemoryLayoutData>& layout_data =\n       args->buffer->layout_data;\n   {\n-    absl::MutexLock lock(&args->buffer->mu);\n+    absl::MutexLock lock(args->buffer->mu);\n     if (!layout_data.has_value()) {\n       // TODO(skyewm): change PJRT C API to also use opaque layout type\n       std::shared_ptr<const xla::PjRtLayout> pjrt_layout ="
        }
    ],
    "stats": {
        "total": 20,
        "additions": 10,
        "deletions": 10
    }
}