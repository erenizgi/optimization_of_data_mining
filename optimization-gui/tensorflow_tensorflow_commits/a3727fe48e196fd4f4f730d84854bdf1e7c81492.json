{
    "author": "tensorflower-gardener",
    "message": "[XLA:MSA] Restructure window prefetching by performing it after all buffers have been allocated.\n\nCurrently we window prefetch while we allocate buffers in MSA: once we determine that an operand will live in HBM, we try window prefetching it. The size of the buffer to prefetch is determined pre-MSA.\n\nOne drawback of this approach is that the buffer sizes are not aware of memory space assignment. So they may be smaller than they could have been at the lowering time.\n\nThis CL addresses this issue. In this CL, we perform window prefetch after all buffers have been allocated, at which time we have the knowledge of which operands and output will be in the alternate memory. With this knowledge, the buffer size will be consistent with buffer size derived at lowering time.\n\nIn order to implement this solution, we refactored the code in MSA that is relevant to window prefetch. We are making the following changes:\n\n1. removed the sites in AllocateSegment where WindowPrefetch is called and consolidate all the window prefetch logic in two functions: WindowPrefetch, which gathers the set of prefetchable operands; and WindowPrefetchOperand which does the actual prefetch.\n\n2. introduced a new lambda `op_span_size_fn` in the Options struct in order for the algorithm to get window buffer size.\n\n3. refactored WindowPrefetchableAllocation.\n\nPiperOrigin-RevId: 802676048",
    "sha": "a3727fe48e196fd4f4f730d84854bdf1e7c81492",
    "files": [
        {
            "sha": "85925718216ad9ef2982be006792d533763bc092",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dataflow_analysis.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.cc?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -329,7 +329,7 @@ HloValue& HloDataflowAnalysis::GetValueDefinedAt(\n HloValue* HloDataflowAnalysis::NewHloValue(HloInstruction* instruction,\n                                            const ShapeIndex& index,\n                                            bool is_phi) {\n-  const int64_t value_id = next_value_id_++;\n+  const int64_t value_id = NewValueId();\n   auto result =\n       values_.insert({value_id, std::make_unique<HloValue>(\n                                     value_id, instruction, index, is_phi)});"
        },
        {
            "sha": "8c88c63e1dcffba32eb5f60257d10fa84c2a4098",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dataflow_analysis.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dataflow_analysis.h?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -126,6 +126,9 @@ class HloDataflowAnalysis {\n   // Returns a vector of all HloValues stabily sorted by HloValue::Id.\n   const std::vector<HloValue*>& values() const { return values_vector_; }\n \n+  // Returns a new value Id to use.\n+  HloValue::Id NewValueId() { return next_value_id_++; }\n+\n   // Returns the call graph used for computing the dataflow.\n   const CallGraph& call_graph() const { return *call_graph_; }\n "
        },
        {
            "sha": "bfb59838981d8e25fbf1c070fdde5d1bca14a18d",
            "filename": "third_party/xla/xla/service/memory_space_assignment/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2FBUILD?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -590,6 +590,7 @@ cc_library(\n         \"//xla/hlo/analysis:hlo_dataflow_analysis\",\n         \"//xla/hlo/analysis:hlo_operand_index\",\n         \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/transforms:memory_space_propagation\",\n         \"//xla/hlo/utils:hlo_live_range\",\n         \"//xla/service:buffer_value\",\n         \"//xla/service:call_graph\","
        },
        {
            "sha": "f248ada4f6803e38218de7df3bf52f5addc1f22e",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.cc",
            "status": "modified",
            "additions": 202,
            "deletions": 74,
            "changes": 276,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.cc?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -58,6 +58,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/hlo/ir/hlo_schedule.h\"\n+#include \"xla/hlo/transforms/memory_space_propagation.h\"\n #include \"xla/hlo/utils/hlo_live_range.h\"\n #include \"xla/layout.h\"\n #include \"xla/service/buffer_value.h\"\n@@ -2680,6 +2681,10 @@ absl::StatusOr<HeapSimulator::Result<HloValue>> MsaAlgorithm::Finish() {\n     }\n   }\n \n+  if (options_.enable_window_prefetch) {\n+    CHECK_OK(WindowPrefetch());\n+  }\n+\n   if (options_.expanded_scoped_alternate_memory_mode ==\n       ExpandedScopedAlternateMemoryMode::ENABLED) {\n     ExtendScopedAlternateMemoryAllocations();\n@@ -3249,7 +3254,8 @@ absl::StatusOr<AllocationResult> MsaAlgorithm::AllocateAllocationValues(\n           definition_time_for_allocation_value.at(&allocation_value_to_update),\n           RequiresNoCopyAlternateMemAllocation(allocation_value_to_update),\n           all_use_times, entry.only_extend_existing_allocation,\n-          allocation_values.subspan(0, alloc_value_idx));\n+          allocation_values.subspan(0, alloc_value_idx),\n+          /*shape_override=*/std::nullopt);\n       if (options_.allocation_request_modifier_testing_fn) {\n         options_.allocation_request_modifier_testing_fn(request);\n       }\n@@ -3428,7 +3434,8 @@ AllocationRequest MsaAlgorithm::CreateAllocationRequest(\n     bool require_no_copy_alternate_mem_allocation,\n     const std::vector<int64_t>& all_use_times,\n     bool only_extend_existing_allocation,\n-    absl::Span<AllocationValue> processed_allocation_values) {\n+    absl::Span<AllocationValue> processed_allocation_values,\n+    std::optional<Shape> shape_override) {\n   const HloUse& hlo_use = use.hlo_use;\n   const auto& instruction_schedule = hlo_live_range_.instruction_schedule();\n   bool require_copy_allocation = false;\n@@ -3684,6 +3691,9 @@ AllocationRequest MsaAlgorithm::CreateAllocationRequest(\n     request.allocation_value_to_update = &allocation_value_to_update;\n   }\n \n+  if (shape_override.has_value()) {\n+    request.shape_override = shape_override;\n+  }\n   request.end_time = use_time;\n   request.only_extend_existing_allocation = only_extend_existing_allocation;\n   request.processed_allocation_values = processed_allocation_values;\n@@ -5711,7 +5721,7 @@ AllocationResult MsaAlgorithm::AllocateSegment(AllocationRequest& request) {\n       }\n     }\n     AllocationResult prefetch_result =\n-        Prefetch(request, **prev_allocation_in_default_mem_it, nullptr,\n+        Prefetch(request, **prev_allocation_in_default_mem_it,\n                  /*force_prefetch=*/\n                  request.require_end_colored_in_alternate_memory);\n     if (prefetch_result == AllocationResult::kSuccess) {\n@@ -5779,11 +5789,7 @@ AllocationResult MsaAlgorithm::AllocateSegment(AllocationRequest& request) {\n   // default memory.\n   (*prev_allocation_in_default_mem_it)->Extend(request.end_time);\n   (*prev_allocation_in_default_mem_it)->AddUse(request.use->hlo_use);\n-\n-  // If the buffer is placed in default memory, we can try window prefetching\n-  // it, which will try to prefetch only a window worth of data to alternate\n-  // memory.\n-  WindowPrefetch(request, **prev_allocation_in_default_mem_it);\n+  uses_in_default_memory_.insert(request.use->hlo_use);\n   return allocation_result;\n }\n \n@@ -6324,81 +6330,203 @@ std::string DescribeSlicedBufferMove(\n \n }  // namespace\n \n-AllocationResult MsaAlgorithm::WindowPrefetch(\n-    const AllocationRequest& request,\n-    Allocation& prev_allocation_in_default_mem) {\n-  if (!options_.enable_window_prefetch) {\n-    return AllocationResult::kSuccess;\n+void MsaAlgorithm::WindowPrefetchOperand(const HloUse& use, int64_t bytes) {\n+  CHECK(options_.enable_window_prefetch);\n+\n+  HloInstruction* instruction = use.instruction;\n+  ShapeIndex shape_index = use.operand_index;\n+  HloInstruction* operand = instruction->mutable_operand(use.operand_number);\n+  // Find the defining position of the operand.\n+  for (int i = 0; i < use.operand_index.size(); ++i) {\n+    CHECK(operand->opcode() == HloOpcode::kGetTupleElement);\n+    operand = operand->mutable_operand(0);\n+  }\n+\n+  // Create a new HloValue for the window buffer.\n+  HloValue::Id new_value_id = alias_analysis_.dataflow_analysis().NewValueId();\n+  HloValue hlo_value(new_value_id, operand, shape_index);\n+  int64_t start_time = hlo_live_range_.instruction_schedule().at(operand);\n+  int64_t end_time = hlo_live_range_.instruction_schedule().at(instruction);\n+\n+  // Create a buffer interval, which has the same start and end time as the\n+  // operand. The hlo value is the operand.\n+  MsaBufferInterval buffer_interval;\n+  buffer_interval.buffer = &hlo_value;\n+  buffer_interval.size = bytes;\n+  buffer_interval.start = start_time;\n+  buffer_interval.end = end_time;\n+  buffer_interval.need_allocation = true;\n+\n+  // Create an allocation_values using the buffer interval.\n+  std::vector<AllocationValue> allocation_values;\n+  allocation_values.emplace_back(&hlo_value, hlo_value.defining_position(),\n+                                 bytes);\n+  allocation_values[0].AddUse(use, end_time);\n+\n+  // Create an allocation request using the allocation_value.\n+  AllocationValue& allocation_value = allocation_values[0];\n+  AllocationValue::Use& allocation_value_use = allocation_value.uses()[0];\n+  std::vector<int64_t> all_use_times = {end_time};\n+  AllocationRequest request = CreateAllocationRequest(\n+      allocation_value, allocation_value,\n+      /*use=*/allocation_value_use, /*previous_use=*/nullptr,\n+      /*preferred_offset=*/nullptr,\n+      /*definition_time=*/start_time,\n+      /*require_no_copy_alternate_mem_allocation=*/false,\n+      /*all_use_times=*/all_use_times,\n+      /*only_extend_existing_allocation=*/false,\n+      /*processed_allocation_values=*/{},\n+      /*shape_override=*/\n+      ShapeUtil::MakeValidatedShape(U8, {bytes}).value());\n+\n+  // Create a dummy allocation that is in the default memory, this is needed for\n+  // creating a WindowPrefetchedAllocation. This allocation does not need to be\n+  // appended to the allocation sequence.\n+  PinnedAllocation dummy_prev_allocation(\n+      /*defining_position=*/{operand, shape_index}, MemorySpace::kDefault,\n+      /*chunk=*/std::nullopt, request.inclusive_start_time, request.end_time);\n+\n+  // Construct the options needed for creating the window prefetch allocation.\n+  WindowPrefetchedAllocation::Options options;\n+  options.bytes = bytes;\n+  options.alternate_memory_space = options_.alternate_memory_space;\n+  options.notify_operand_appended_fn = options_.notify_operand_appended_fn;\n+  request.window_prefetch_options = &options;\n+\n+  if (options_.window_prefetch_mode == WindowPrefetchMode::kWindowPrefetch) {\n+    // Window prefetch mode\n+    Prefetch(request, dummy_prev_allocation);\n+  } else {\n+    // Window exposure mode, we only need to find a chunk for the window\n+    // buffer.\n+    CHECK(options_.window_prefetch_mode == WindowPrefetchMode::kWindowExposure);\n+    // Adjust the start time of the buffer interval to be the use time. This is\n+    // because we only need the buffer to be alive at the use time.\n+    buffer_interval.start = end_time;\n+    std::optional<Chunk> candidate_chunk = FindBestChunkCandidate(\n+        request, /*preferred_offset=*/nullptr, &buffer_interval);\n+    if (candidate_chunk.has_value()) {\n+      AddToPendingChunks(buffer_interval, *candidate_chunk);\n+\n+      AllocationSequence* allocation_sequence =\n+          allocation_value.mutable_allocation_sequence();\n+      allocation_sequence->push_back(\n+          std::make_unique<WindowPrefetchedAllocation>(\n+              dummy_prev_allocation, use, *candidate_chunk, end_time - 1,\n+              end_time, options));\n+      CreateOrAddToAliasedOffset(*allocation_sequence->back(),\n+                                 /*aliased_offset=*/nullptr);\n+      allocation_sequence->back()->AddUse(use);\n+    }\n+  }\n+  // Finalize the allocation values. This adds the newly created allocation to\n+  // allocations_.\n+  FinalizeAllocations(absl::MakeSpan(allocation_values));\n+}\n+\n+absl::Status MsaAlgorithm::WindowPrefetch() {\n+  CHECK(options_.enable_window_prefetch);\n+\n+  absl::flat_hash_set<HloInstruction*> window_prefetchable_instructions;\n+\n+  // At this point, we don't have the memory space colored in the original\n+  // instruction, but we know which operands and outputs are in the alternate\n+  // memory. So we clone the instruction and color the operands and outputs that\n+  // are in the alternate memory. Then we propagate the memory space to the\n+  // cloned computation and use the cloned computation to determine the operand\n+  // span size.\n+\n+  // Map of the original instruction to a clone of the instruction.\n+  absl::flat_hash_map<HloInstruction*, HloInstruction*> cloned_insts;\n+  const std::vector<HloInstruction*>& instruction_sequence =\n+      hlo_live_range_.flattened_instruction_sequence().instructions();\n+  for (HloInstruction* instruction : instruction_sequence) {\n+    if (!instruction->IsOutputFusion() && !instruction->IsLoopFusion()) {\n+      continue;\n+    }\n+\n+    window_prefetchable_instructions.insert(instruction);\n+\n+    // This lambda sets an hlo's memory space to the alternate memory space.\n+    auto color_hlo = [&](HloInstruction* hlo, ShapeIndex shape_index) {\n+      ShapeUtil::GetMutableSubshape(hlo->mutable_shape(), shape_index)\n+          ->mutable_layout()\n+          ->set_memory_space(options_.alternate_memory_space);\n+    };\n+\n+    // Make a clone of the instruction.\n+    HloInstruction* cloned =\n+        instruction->parent()->AddInstruction(instruction->Clone());\n+    cloned_insts[instruction] = cloned;\n+\n+    // Color the cloned instruction's fused parameters.\n+    auto it = operands_in_alternate_memory_map_.find(instruction);\n+    if (it != operands_in_alternate_memory_map_.end()) {\n+      for (const auto& [i, _] : it->second) {\n+        // For the operand in the alternate memory, color the parameter. Because\n+        // we color the fused parameters, it is the full shape of the parameter.\n+        // By using the full shape, we assume that the parameter is not a\n+        // tuple and one or more of the tensors in that parameter are in\n+        // alternate memory. Let's add a check to make sure that the parameter\n+        // is not a tuple.\n+        if (cloned->fused_parameters()[i]->shape().IsTuple()) {\n+          LOG(ERROR) << \"Tuple parameter: \"\n+                     << cloned->fused_parameters()[i]->shape().ToString(true);\n+          return absl::FailedPreconditionError(\n+              \"Tuple parameter not supported for window prefetch.\");\n+        }\n+        color_hlo(cloned->fused_parameters()[i], {});\n+      }\n+    }\n+\n+    // Color the cloned instruction's outputs.\n+    if (auto it = outputs_in_alternate_memory_map_.find(instruction);\n+        it != outputs_in_alternate_memory_map_.end()) {\n+      for (const auto& shape_index : it->second) {\n+        color_hlo(cloned->fused_expression_root(), shape_index);\n+      }\n+    }\n   }\n \n-  const HloUse use = request.use->hlo_use;\n-  VLOG(3) << \"Considering window prefetch for use=\" << use.ToString();\n+  // Propagate the memory space to the cloned fusion computations.\n+  TF_ASSIGN_OR_RETURN(auto dataflow_analysis,\n+                      HloDataflowAnalysis::Run(*module_, /*ssa_form=*/false,\n+                                               /*bitcast_defines_value=*/true));\n+  MemorySpacePropagation memory_space_propagation(std::move(dataflow_analysis));\n+  for (auto [_, cloned] : cloned_insts) {\n+    for (HloComputation* computation : cloned->called_computations()) {\n+      memory_space_propagation.RunOnComputation(computation);\n+    }\n+  }\n \n-  // Get the window prefetch details for this use.\n-  WindowPrefetchDetail details =\n-      options_.window_prefetch_detail_fn(use.instruction);\n-  for (const WindowPrefetchDetail::WindowDetail& window : details.windows()) {\n-    if (window.operand() != use.operand_number) {\n+  // Prefetch the window buffers.\n+  for (const HloUse& use : uses_in_default_memory_) {\n+    if (!window_prefetchable_instructions.contains(use.instruction)) {\n       continue;\n     }\n \n-    // Construct the options needed for creating the window prefetch allocation.\n-    WindowPrefetchedAllocation::Options options;\n-    options.bytes = window.size();\n-    options.alternate_memory_space = options_.alternate_memory_space;\n-    options.notify_operand_appended_fn = options_.notify_operand_appended_fn;\n-\n-    // Construct the request for prefetching the content of the window.\n-    AllocationRequest window_prefetch_request = request;\n-    window_prefetch_request.window_prefetch_options = &options;\n-    window_prefetch_request.size = window.size();\n-    int64_t end_time = request.end_time;\n-    window_prefetch_request.end_time = end_time;\n-    std::vector<int64_t> all_use_times = {end_time};\n-    window_prefetch_request.all_use_times = all_use_times;\n-\n-    if (options_.window_prefetch_mode == WindowPrefetchMode::kWindowPrefetch) {\n-      // Window prefetch mode\n-      const Shape shape = ShapeUtil::MakeShape(U8, {window.size()});\n-      Prefetch(window_prefetch_request, prev_allocation_in_default_mem, &shape);\n-    } else {\n-      // Window exposure mode, we only need to find a chunk for the window\n-      // buffer.\n-      CHECK(options_.window_prefetch_mode ==\n-            WindowPrefetchMode::kWindowExposure);\n-      MsaBufferInterval alternate_mem_interval;\n-      alternate_mem_interval.buffer =\n-          request.allocation_value_to_update->value();\n-      alternate_mem_interval.size = window.size();\n-      alternate_mem_interval.end = end_time;\n-      alternate_mem_interval.start = end_time;\n-      std::optional<Chunk> candidate_chunk = FindBestChunkCandidate(\n-          window_prefetch_request, /*preferred_offset=*/nullptr,\n-          &alternate_mem_interval);\n-      if (candidate_chunk.has_value()) {\n-        AddToPendingChunks(alternate_mem_interval, *candidate_chunk);\n-\n-        AllocationSequence* allocation_sequence =\n-            request.allocation_value_to_update->mutable_allocation_sequence();\n-        allocation_sequence->push_back(\n-            std::make_unique<WindowPrefetchedAllocation>(\n-                prev_allocation_in_default_mem, use, *candidate_chunk,\n-                end_time - 1, end_time, options));\n-        CreateOrAddToAliasedOffset(*allocation_sequence->back(),\n-                                   /*aliased_offset=*/nullptr);\n-        allocation_sequence->back()->AddUse(use);\n-      }\n+    CHECK(options_.op_span_size_fn);\n+    int64_t span_size = options_.op_span_size_fn(\n+        use.instruction, cloned_insts[use.instruction], use.operand_number);\n+    if (span_size != 0) {\n+      WindowPrefetchOperand(use, span_size);\n     }\n   }\n-  return AllocationResult::kSuccess;\n+\n+  // Remove the cloned instructions.\n+  for (auto [_, cloned] : cloned_insts) {\n+    HloComputation* computation = cloned->parent();\n+    TF_CHECK_OK(computation->RemoveInstruction(cloned));\n+    computation->Cleanup();\n+  }\n+  return absl::OkStatus();\n }\n \n AllocationResult MsaAlgorithm::Prefetch(\n     const AllocationRequest& request,\n-    Allocation& prev_allocation_in_default_mem, const Shape* shape,\n-    bool force_prefetch) {\n-  AllocationResult result = PrefetchWithResourceConstraints(\n-      request, prev_allocation_in_default_mem, shape);\n+    Allocation& prev_allocation_in_default_mem, bool force_prefetch) {\n+  AllocationResult result =\n+      PrefetchWithResourceConstraints(request, prev_allocation_in_default_mem);\n   if (result == AllocationResult::kSuccess || !force_prefetch) {\n     return result;\n   }\n@@ -6436,7 +6564,7 @@ AllocationResult MsaAlgorithm::Prefetch(\n \n AllocationResult MsaAlgorithm::PrefetchWithResourceConstraints(\n     const AllocationRequest& request,\n-    Allocation& prev_allocation_in_default_mem, const Shape* shape) {\n+    Allocation& prev_allocation_in_default_mem) {\n   // Try partially placing the buffer in the alternate space. The time that is\n   // overlapped will be used to asynchronously copy the buffer from the\n   // default memory to the alternate memory.\n@@ -6477,8 +6605,8 @@ AllocationResult MsaAlgorithm::PrefetchWithResourceConstraints(\n     return check_result;\n   }\n   const HloUse& use = request.use->hlo_use;\n-  if (shape != nullptr) {\n-    context.full_shape = shape;\n+  if (request.shape_override.has_value()) {\n+    context.full_shape = &*request.shape_override;\n   } else {\n     context.full_shape = &ShapeUtil::GetSubshape(\n         use.instruction->operand(use.operand_number)->shape(),"
        },
        {
            "sha": "0308af96ef3b9624717d17a3fe0ca12c6c7b8b74",
            "filename": "third_party/xla/xla/service/memory_space_assignment/algorithm.h",
            "status": "modified",
            "additions": 17,
            "deletions": 9,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Falgorithm.h?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -692,6 +692,9 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   //\n   // * processed_allocation_values: The AllocationValues that have already been\n   //   processed for the same parent HloValue as is used in the request.\n+  // * shape_override: This shape if provided will be used to determine the\n+  //   space needed for the allocation. It overrides the shape used in\n+  //   PrefetchContext.\n   AllocationRequest CreateAllocationRequest(\n       AllocationValue& allocation_value,\n       AllocationValue& allocation_value_to_update,\n@@ -700,7 +703,8 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n       bool require_no_copy_alternate_mem_allocation,\n       const std::vector<int64_t>& all_use_times,\n       bool only_extend_existing_allocation,\n-      absl::Span<AllocationValue> processed_allocation_values);\n+      absl::Span<AllocationValue> processed_allocation_values,\n+      std::optional<Shape> shape_override);\n \n   // Returns true, if the allocation value requires a pinned allocation in the\n   // alternate memory space.\n@@ -782,13 +786,12 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   // will prefetch even if the resource constraints for a prefetch are not met.\n   AllocationResult Prefetch(const AllocationRequest& request,\n                             Allocation& prev_allocation_in_default_mem,\n-                            const Shape* shape = nullptr,\n                             bool force_prefetch = false);\n \n   // Prefetch to alternate memory iff the resource constraints are met.\n   AllocationResult PrefetchWithResourceConstraints(\n       const AllocationRequest& request,\n-      Allocation& prev_allocation_in_default_mem, const Shape* shape = nullptr);\n+      Allocation& prev_allocation_in_default_mem);\n \n   // Helper methods used to implement Prefetch().\n   //\n@@ -818,13 +821,15 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   std::string AlternateMemoryAllocationAttemptToString(\n       bool for_sliced_solution, const PrefetchContext& context) const;\n \n-  // Try to prefetch a window worth of data into the alternate memory.\n-  AllocationResult WindowPrefetch(const AllocationRequest& request,\n-                                  Allocation& prev_allocation_in_default_mem);\n+  // Performs window prefetching.\n+  absl::Status WindowPrefetch();\n \n-  // Find the best possible chunk candidate, where it has the longest possible\n-  // availability if no preferred offset is given, or at the preferred_offset if\n-  // it is given.\n+  // Window prefetches the specified operand of the given instruction.\n+  void WindowPrefetchOperand(const HloUse& use, int64_t bytes);\n+\n+  // Find the best possible chunk candidate, where it has the longest\n+  // possible availability if no preferred offset is given, or at the\n+  // preferred_offset if it is given.\n   std::optional<Chunk> FindBestChunkCandidate(\n       const AllocationRequest& request, const AliasedOffset* preferred_offset,\n       MsaBufferInterval* alternate_mem_interval) const;\n@@ -1255,6 +1260,9 @@ class MsaAlgorithm : public GlobalDecreasingSizeBestFitHeap<HloValue> {\n   // default memory, to meet buffer coloring requirements.\n   absl::flat_hash_map<HloPosition, std::vector<int64_t>>\n       default_memory_coloring_requirements_;\n+\n+  // Set of HloUses that are in the default memory.\n+  absl::flat_hash_set<HloUse> uses_in_default_memory_;\n };\n \n }  // namespace memory_space_assignment"
        },
        {
            "sha": "7f9b61d25d4a0e6fb817419c5daaad35c001b4a7",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 9,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.cc?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -968,18 +968,17 @@ WindowPrefetchedAllocation::WindowPrefetchedAllocation(\n           InclusiveToExclusiveEndTime(prefetch_done_schedule_before_time),\n           /*cross_program_prefetch_index=*/std::nullopt),\n       options_(options),\n-      prev_allocation_(prev_allocation),\n+      defining_position_(prev_allocation.defining_position()),\n       use_(use),\n       prefetch_start_schedule_after_(prefetch_start_schedule_after_time),\n       prefetch_done_schedule_before_(prefetch_done_schedule_before_time),\n       bytes_(chunk.size) {}\n \n HloPosition WindowPrefetchedAllocation::defining_position() const {\n-  HloPosition defining_position = original_defining_position();\n-  if (defining_position.instruction == nullptr) {\n-    return prev_allocation_.defining_position();\n+  if (defining_position_.instruction != nullptr) {\n+    return defining_position_;\n   }\n-  return defining_position;\n+  return original_defining_position();\n }\n \n int64_t WindowPrefetchedAllocation::earliest_available_time() const {\n@@ -1017,10 +1016,11 @@ absl::Status WindowPrefetchedAllocation::InsertWindowPrefetchInstruction(\n \n absl::Status WindowPrefetchedAllocation::Process(\n     const BitcastSplitFn& bitcast_split_fn) {\n-  HloInstruction* producing_instruction = AddGetTupleElements();\n-  HloComputation* computation = producing_instruction->parent();\n   HloInstruction* use_instruction = use_.instruction;\n   int64_t use_operand = use_instruction->operand_count();\n+  HloInstruction* producing_instruction =\n+      use_instruction->mutable_operand(use_.operand_number);\n+  HloComputation* computation = producing_instruction->parent();\n   CHECK_EQ(use_instruction->opcode(), HloOpcode::kFusion);\n \n   TF_RETURN_IF_ERROR(InsertWindowPrefetchInstruction(\n@@ -1032,7 +1032,8 @@ absl::Status WindowPrefetchedAllocation::Process(\n                                       use_operand);\n \n   // Set the original defining position to the window prefetch instruction.\n-  set_original_defining_position(HloPosition{prefetch_instruction_, {}});\n+  set_original_defining_position(defining_position_);\n+  defining_position_ = {prefetch_instruction_, {}};\n   AddUse(HloUse{use_instruction, use_operand});\n   return absl::OkStatus();\n }\n@@ -1045,7 +1046,6 @@ void WindowPrefetchedAllocation::MarkIfNeeded(\n void WindowPrefetchedAllocation::MarkNeeded(\n     absl::flat_hash_set<const Allocation*>& needed_allocations) const {\n   needed_allocations.insert(this);\n-  prev_allocation_.MarkNeeded(needed_allocations);\n }\n \n std::string WindowPrefetchedAllocation::ToString() const {"
        },
        {
            "sha": "a37f7f7faf5ab5a9965909b37aae56736c4b27fd",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation.h",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation.h?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -531,7 +531,7 @@ class WindowPrefetchedAllocation final : public Allocation {\n \n   Options options_;\n   HloInstruction* prefetch_instruction_ = nullptr;\n-  Allocation& prev_allocation_;\n+  HloPosition defining_position_;\n   HloUse use_;\n   int64_t prefetch_start_schedule_after_;\n   int64_t prefetch_done_schedule_before_;"
        },
        {
            "sha": "c6c3555a002ffa1050adbb53b29735b36410b41e",
            "filename": "third_party/xla/xla/service/memory_space_assignment/allocation_value.h",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fallocation_value.h?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -276,6 +276,9 @@ struct AllocationRequest {\n   // done some of the heap allocation for us. So this request picks up where it\n   // left off.\n   std::optional<int64_t> no_copy_chunk_inclusive_start_time;\n+  // An optional override for the shape for PrefetchContext::full_shape, which\n+  // is used to calculate space needed for the prefetch.\n+  std::optional<Shape> shape_override;\n   // Indicates if the AllocationRequest start time (definition time) has an\n   // alternate memory color requirement.\n   bool require_start_colored_in_alternate_memory = false;"
        },
        {
            "sha": "92e59c2be4d0c2a62f87e3f33f406802a64a8792",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment.proto",
            "status": "modified",
            "additions": 0,
            "deletions": 14,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment.proto?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -46,20 +46,6 @@ message SlicedPrefetchOptions {\n   uint64 preferred_slice_size = 5;\n }\n \n-// Memory space assignment options for prefetching windows of data\n-message WindowPrefetchDetail {\n-  message WindowDetail {\n-    reserved 3;\n-\n-    // Index of the operand that is window prefetched.\n-    int64 operand = 1;\n-    // Window buffer size in bytes.\n-    int64 size = 2;\n-  }\n-\n-  repeated WindowDetail windows = 1;\n-}\n-\n // Options for memory-bound loop optimizations in memory space assignment. If\n // enabled, this pass can optimize memory-bound unrolled loops to maximize the\n // bandwidth utilized and minimize the execution time."
        },
        {
            "sha": "94123cc2845cf9fa9ebfa77229918513f3e3ec06",
            "filename": "third_party/xla/xla/service/memory_space_assignment/memory_space_assignment_test.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 96,
            "changes": 106,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Fmemory_space_assignment_test.cc?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -9994,24 +9994,11 @@ entry {\n   TF_ASSERT_OK_AND_ASSIGN(auto module,\n                           ParseAndReturnVerifiedModule(hlo_string));\n \n-  // Get info about window prefetch buffers, such as which operands they\n-  // correspond to and their sizes.\n-  auto window_prefetch_detail_fn = [&](const HloInstruction* instruction) {\n-    WindowPrefetchDetail window_prefetch_detail;\n-    const HloInstruction* fusion = FindInstruction(module.get(), \"fusion\");\n-    if (instruction == fusion) {\n-      for (int i = 0; i < 3; ++i) {\n-        auto* operand = window_prefetch_detail.add_windows();\n-        operand->set_operand(i);\n-        operand->set_size(32);\n-      }\n-    }\n-    return window_prefetch_detail;\n-  };\n-\n   Options options = DefaultMemorySpaceOptions();\n   options.enable_window_prefetch = true;\n-  options.window_prefetch_detail_fn = window_prefetch_detail_fn;\n+  options.op_span_size_fn =\n+      [&](HloInstruction* original_hlo, HloInstruction* cloned_hlo,\n+          int64_t operand_index) -> int64_t { return 32; };\n   AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/0);\n   const HloInstruction* fusion = FindInstruction(module.get(), \"fusion\");\n@@ -10057,15 +10044,13 @@ entry {\n \n   // Get info about window prefetch buffers, such as which operands they\n   // correspond to and their sizes.\n-  auto window_prefetch_detail_fn = [&](const HloInstruction* instruction) {\n-    WindowPrefetchDetail window_prefetch_detail;\n-    const HloInstruction* fusion = FindInstruction(module.get(), \"t3\");\n-    if (instruction == fusion) {\n-      auto* window_buffer = window_prefetch_detail.add_windows();\n-      window_buffer->set_operand(0);\n-      window_buffer->set_size(32);\n+  auto op_span_size_fn = [&](HloInstruction* original_hlo,\n+                             HloInstruction* cloned_hlo,\n+                             int64_t operand_index) -> int64_t {\n+    if (original_hlo->name() == \"t3\" && operand_index == 0) {\n+      return 32;\n     }\n-    return window_prefetch_detail;\n+    return 0;\n   };\n \n   // Set the reserved scoped memory of the negate instruction to be 128MB. This\n@@ -10083,7 +10068,7 @@ entry {\n \n   Options options = DefaultMemorySpaceOptions();\n   options.enable_window_prefetch = true;\n-  options.window_prefetch_detail_fn = window_prefetch_detail_fn;\n+  options.op_span_size_fn = op_span_size_fn;\n   options.reserved_scoped_memory_fn = reserved_scoped_memory_fn;\n   AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n                     /*min_prefetch_interval=*/0);\n@@ -10094,77 +10079,6 @@ entry {\n   EXPECT_GT(fusion->operand_count(), 1);\n }\n \n-// This test verifies that window prefetched operands are seen by the\n-// reserved_scoped_memory_fn. Because window prefetched operands allocates space\n-// in the alternate memory, which will be identified as prefetched_operands.\n-// Therefore they will be seen by reserved_scoped_memory_fn.\n-TEST_F(MemorySpaceAssignmentTest,\n-       WindowPrefetchedOperandsAreSeenByReservedScopedMemoryFn) {\n-  absl::string_view hlo_string = R\"(\n-  HloModule module, is_scheduled=true\n-\n-  fused_computation {\n-    param0 = f32[1024] parameter(0)\n-    param1 = f32[1024] parameter(1)\n-    ROOT root = f32[1024] add(param0, param1)\n-  }\n-\n-  ENTRY Entry {\n-    param0 = f32[1024] parameter(0)\n-    param1 = f32[1024] parameter(1)\n-    ROOT fusion = f32[1024] fusion(param0, param1), kind=kLoop, calls=fused_computation\n-  }\n-  )\";\n-  TF_ASSERT_OK_AND_ASSIGN(auto module,\n-                          ParseAndReturnVerifiedModule(hlo_string));\n-  const HloInstruction* fusion = FindInstruction(module.get(), \"fusion\");\n-  bool seen_window_prefetched_operand = false;\n-\n-  Options options = DefaultMemorySpaceOptions();\n-  options.max_repacks = 10;\n-  options.repack_after_every_allocation = true;\n-  options.reduce_scoped_memory_limit = true;\n-  options.reserved_scoped_memory_fn =\n-      [&](const HloInstruction* instruction,\n-          const absl::flat_hash_set<std::pair<int, ShapeIndex>>\n-              operands_in_alternate_memory,\n-          const absl::flat_hash_set<ShapeIndex> outputs_in_alternate_memory) {\n-        if (instruction == fusion && !operands_in_alternate_memory.empty()) {\n-          seen_window_prefetched_operand = true;\n-        }\n-        return 1;\n-      };\n-\n-  // Make sure that the alternate memory is larger than the fusion operand's\n-  // full size, but smaller than its span buffer size, so that it will be window\n-  // prefetched.\n-  options.enable_window_prefetch = true;\n-  ASSERT_LT(options.max_size_in_bytes, 1024);\n-  ASSERT_GT(options.max_size_in_bytes, 32);\n-  // This lambda instructs MSA to allocate 32 bytes in the alternate memory as\n-  // span buffer of the fusion instruction.\n-  options.window_prefetch_detail_fn =\n-      [&](const HloInstruction* instruction) -> WindowPrefetchDetail {\n-    WindowPrefetchDetail detail;\n-    if (instruction == fusion) {\n-      WindowPrefetchDetail::WindowDetail* window = detail.add_windows();\n-      window->set_operand(0);\n-      window->set_size(32);\n-    }\n-    return detail;\n-  };\n-\n-  // Run memory space assignment and verify that window prefetched operands are\n-  // seen by the reserved_scoped_memory_fn.\n-  absl::flat_hash_map<std::pair<int64_t, int64_t>, int64_t> repack_map;\n-  FakeMemorySpaceAssignmentRepacker repacker =\n-      FakeMemorySpaceAssignmentRepacker(repack_map, nullptr);\n-  options.repacker = &repacker;\n-  AssignMemorySpace(module.get(), options, /*max_prefetch_interval=*/10,\n-                    /*min_prefetch_interval=*/0);\n-  EXPECT_TRUE(seen_window_prefetched_operand);\n-}\n-\n using AsynchronousCopyOrderingTest = ::testing::Test;\n \n TEST_F(AsynchronousCopyOrderingTest, Simple) {"
        },
        {
            "sha": "da8fa62efb3738f6295a62aac87743168d3e38ee",
            "filename": "third_party/xla/xla/service/memory_space_assignment/options.h",
            "status": "modified",
            "additions": 17,
            "deletions": 5,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a3727fe48e196fd4f4f730d84854bdf1e7c81492/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fmemory_space_assignment%2Foptions.h?ref=a3727fe48e196fd4f4f730d84854bdf1e7c81492",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n #include \"xla/layout.h\"\n #include \"xla/service/buffer_value.h\"\n #include \"xla/service/hlo_value.h\"\n@@ -62,8 +63,6 @@ using ReservedScopedMemoryFunction = std::function<int64_t(\n     const absl::flat_hash_set<ShapeIndex>& /*outputs_in_alternate_memory*/)>;\n using PositionRequiresContiguousAllocationFunction =\n     std::function<bool(const HloPosition&)>;\n-using WindowPrefetchDetailFunction =\n-    std::function<WindowPrefetchDetail(const HloInstruction*)>;\n using WindowPrefetchNotifyOperandAppendedFunction =\n     std::function<void(HloInstruction*, int64_t, int64_t)>;\n using IsAsyncSliceImplementedFunction =\n@@ -81,6 +80,9 @@ using ShapeSizeFn = std::function<int64_t(const Shape&)>;\n using AsyncInstructionBwAdjustmentFactorFn =\n     std::function<std::optional<float>(const HloInstruction*)>;\n using HloPositionOrUse = std::variant<HloPosition, HloUse>;\n+using OpSpanSizeFn = std::function<int64_t(\n+    HloInstruction* original_hlo, HloInstruction* hlo_with_memory_spaces,\n+    int64_t operand_index)>;\n \n // MSA allows for custom post-allocation transformations. When a post-allocation\n // transformation is performed on an instruction, this result is returned. It\n@@ -173,9 +175,19 @@ struct Options {\n       position_requires_contiguous_allocation_fn =\n           [](const HloPosition&) { return false; };\n \n-  // This function is called to get details about window prefetches.\n-  WindowPrefetchDetailFunction window_prefetch_detail_fn =\n-      [](const HloInstruction*) { return WindowPrefetchDetail(); };\n+  // This function is used to determine the size of the span buffer for a given\n+  // operand. The size should be the total size required by the operand. If\n+  // pipelining is disabled, this is one iteration worth of data; if pipelining\n+  // is enabled and double buffering is used, this is two iterations worth of\n+  // data.\n+  //\n+  // `hlo_with_memory_spaces` is a clone of `original_hlo` but with the memory\n+  // space assignment propagated within its computation. It is used to determine\n+  // the operand span size of the operand. `operand_index` is the index of the\n+  // operand which is being considered.\n+  OpSpanSizeFn op_span_size_fn = [](HloInstruction* original_hlo,\n+                                    HloInstruction* hlo_with_memory_spaces,\n+                                    int64_t operand_index) { return 0; };\n \n   // This function is called to notify that an operand has been appended as a\n   // window prefetch buffer."
        }
    ],
    "stats": {
        "total": 473,
        "additions": 264,
        "deletions": 209
    }
}