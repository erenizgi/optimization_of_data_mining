{
    "author": "pifon2a",
    "message": "[XLA:GPU] Ignore zero-sized constants in layout normalization.\n\nPiperOrigin-RevId: 822571991",
    "sha": "a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c",
    "files": [
        {
            "sha": "38ccd1fa6276f1c55deb5b4a022729c1fb0ee97b",
            "filename": "third_party/xla/xla/service/layout_normalization.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization.cc?ref=a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c",
            "patch": "@@ -86,13 +86,12 @@ class LayoutNormalizationVisitor : public DfsHloRewriteVisitor {\n \n   // To handle a constant, just give the literal data a new layout.\n   absl::Status HandleConstant(HloInstruction* hlo) override {\n+    Shape shape = hlo->shape();\n     Literal& literal = *Cast<HloConstantInstruction>(hlo)->mutable_literal();\n-    if (literal.shape().IsTuple()) {\n-      // TODO(cheshire): Tuple constants.\n+    if (literal.shape().IsTuple() || ShapeUtil::IsZeroElementArray(shape)) {\n       return absl::OkStatus();\n     }\n \n-    Shape shape = hlo->shape();\n     Shape normalized_shape = Normalize(shape);\n     *literal.mutable_shape_do_not_use() = normalized_shape;\n     // Ensure element_size_in_bits of literal is 0, because literals do not"
        },
        {
            "sha": "67790c37ad9f3f6b783dab684140a3fe47e399f1",
            "filename": "third_party/xla/xla/service/layout_normalization_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flayout_normalization_test.cc?ref=a34be3eb68a0e040b1424a38bfe5cf8aa7fd381c",
            "patch": "@@ -601,6 +601,17 @@ ENTRY main {\n   )\");\n }\n \n+TEST_F(LayoutNormalizationTest, ZeroSizedConstant) {\n+  const char* hlo = R\"(\n+  HloModule zero_sized_constant, entry_computation_layout={()->s32[0,179]{0,1}}\n+  ENTRY main() -> s32[0,179] {\n+    ROOT %constant = s32[0,179]{1,0} constant({  })\n+  })\";\n+  TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule(hlo));\n+  TF_ASSERT_OK_AND_ASSIGN(auto status, LayoutNormalization().Run(module.get()));\n+  EXPECT_FALSE(status);\n+}\n+\n TEST_F(LayoutNormalizationTest, ConstantAvoidRevisitOfUser) {\n   const char* hlo = R\"(\n HloModule module"
        }
    ],
    "stats": {
        "total": 16,
        "additions": 13,
        "deletions": 3
    }
}