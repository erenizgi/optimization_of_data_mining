{
    "author": "WillFroom",
    "message": "[XLA:CPU][XTile] Fix scalar extract dynamic folding and only create the size of mask needed in FoldExtractIntoCreateMask.\n\nPiperOrigin-RevId: 827525725",
    "sha": "8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26",
    "files": [
        {
            "sha": "ec5d86f460ade85d5cfefbba2c9e62729468c756",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/rewrite_dynamic_vector_extract.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 18,
            "changes": 65,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Frewrite_dynamic_vector_extract.cc?ref=8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"mlir/IR/MLIRContext.h\"\n #include \"mlir/IR/OpDefinition.h\"\n #include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/TypeUtilities.h\"\n #include \"mlir/IR/Value.h\"\n #include \"mlir/IR/Visitors.h\"\n #include \"mlir/Interfaces/DataLayoutInterfaces.h\"\n@@ -103,11 +104,6 @@ struct FoldExtractIntoTransferRead\n       return rewriter.notifyMatchFailure(op,\n                                          \"source is not a transfer_read op\");\n     }\n-    auto vector_type = mlir::dyn_cast<mlir::VectorType>(op.getType());\n-    if (!vector_type) {\n-      // TODO(willfroom): Support scalars types.\n-      return rewriter.notifyMatchFailure(op, \"Output is not a vector type\");\n-    }\n \n     mlir::ValueRange transfer_read_indices = transfer_read_op.getIndices();\n \n@@ -137,30 +133,49 @@ struct FoldExtractIntoTransferRead\n       }\n     }\n \n+    // Output of extract can be either a vector or a scalar.\n+    auto maybe_vector_type = mlir::dyn_cast<mlir::VectorType>(op.getType());\n+\n     mlir::Value submask;\n     if (auto mask = transfer_read_op.getMask()) {\n-      submask = mlir::vector::ExtractOp::create(rewriter, op.getLoc(), mask,\n-                                                op.getMixedPosition());\n+      // Transfer read result and mask must be non-0D vectors.\n+      auto sub_mask_type = mlir::VectorType::get(\n+          maybe_vector_type ? maybe_vector_type.getShape() : 1,\n+          rewriter.getI1Type());\n+      submask = mlir::vector::ExtractOp::create(\n+          rewriter, op.getLoc(), sub_mask_type, mask, op.getDynamicPosition(),\n+          op.getStaticPosition());\n     }\n \n-    int64_t rank = transfer_read_op.getBase().getType().getRank();\n+    int64_t input_rank = transfer_read_op.getBase().getType().getRank();\n+    int64_t output_rank = maybe_vector_type ? maybe_vector_type.getRank() : 1;\n \n     // Drop major dimensions which reflects the behaviour of vector::ExtractOp.\n-    int64_t num_dropped_dims = rank - vector_type.getRank();\n+    int64_t num_dropped_dims = input_rank - output_rank;\n     mlir::AffineMap new_permutation_map =\n         mlir::AffineMap::getFilteredIdentityMap(\n-            rewriter.getContext(), rank, [&](mlir::AffineDimExpr expr) {\n+            rewriter.getContext(), input_rank, [&](mlir::AffineDimExpr expr) {\n               return expr.getPosition() >= num_dropped_dims;\n             });\n \n     llvm::SmallVector<mlir::Attribute> in_bounds(\n         transfer_read_op.getInBounds().begin() + num_dropped_dims,\n         transfer_read_op.getInBounds().end());\n \n-    rewriter.replaceOpWithNewOp<mlir::vector::TransferReadOp>(\n-        op, vector_type, transfer_read_op.getBase(), new_offsets,\n-        new_permutation_map, transfer_read_op.getPadding(), submask,\n-        rewriter.getArrayAttr(in_bounds));\n+    auto output_type = mlir::VectorType::get(\n+        maybe_vector_type ? maybe_vector_type.getShape() : 1,\n+        mlir::getElementTypeOrSelf(op.getType()));\n+    auto new_transfer_read = mlir::vector::TransferReadOp::create(\n+        rewriter, op.getLoc(), output_type, transfer_read_op.getBase(),\n+        new_offsets, new_permutation_map, transfer_read_op.getPadding(),\n+        submask, rewriter.getArrayAttr(in_bounds));\n+\n+    if (maybe_vector_type) {\n+      rewriter.replaceOp(op, new_transfer_read);\n+    } else {\n+      rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(\n+          op, new_transfer_read, 0);\n+    }\n \n     return mlir::success();\n   }\n@@ -213,13 +228,27 @@ struct FoldExtractIntoCreateMask\n       }\n     }\n \n+    // As we are going to extract only the output shape vector from the minor\n+    // dimensions we only need to create a mask of size 1 for the remaining\n+    // dimensions.\n+    llvm::SmallVector<int64_t> new_mask_shape;\n+    if (auto output_shape = mlir::dyn_cast<mlir::ShapedType>(op.getType())) {\n+      new_mask_shape.assign(\n+          mask_op.getType().getRank() - output_shape.getRank(), 1);\n+      new_mask_shape.append(output_shape.getShape().begin(),\n+                            output_shape.getShape().end());\n+    } else {\n+      new_mask_shape.assign(mask_op.getType().getRank(), 1);\n+    }\n+\n     auto shifted_mask = mlir::vector::CreateMaskOp::create(\n-        rewriter, op.getLoc(), mask_op.getType(), new_bounds);\n+        rewriter, op.getLoc(),\n+        mlir::VectorType::get(new_mask_shape, rewriter.getI1Type()),\n+        new_bounds);\n \n     llvm::SmallVector<int64_t> zero_index(op.getMixedPosition().size(), 0);\n-\n-    rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(op, shifted_mask,\n-                                                         zero_index);\n+    rewriter.replaceOpWithNewOp<mlir::vector::ExtractOp>(\n+        op, op.getType(), shifted_mask, mlir::ValueRange{}, zero_index);\n \n     return mlir::success();\n   }"
        },
        {
            "sha": "df94d5f80924363d38c30e9562c236c49e208726",
            "filename": "third_party/xla/xla/backends/cpu/codegen/tiled/transforms/tests/rewrite_dynamic_vector_extract.mlir",
            "status": "modified",
            "additions": 45,
            "deletions": 2,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Ftiled%2Ftransforms%2Ftests%2Frewrite_dynamic_vector_extract.mlir?ref=8a8b7a2c7b0d239270c09ee6a3703c6f3a3a8a26",
            "patch": "@@ -31,16 +31,59 @@ func.func @fold_vector_extract_into_transfer_read(\n // CHECK:        %[[SHIFT_IDX0:.*]] = arith.subi %[[C7]], %[[IDX0]] : index\n // CHECK:        %[[SHIFT_SUBIDX1:.*]] = arith.subi %[[C3]], %[[IDX1]] : index\n // CHECK:        %[[SHIFT_MASK:.*]] = vector.create_mask\n-// CHECK-SAME:     %[[SHIFT_IDX0]], %[[SHIFT_SUBIDX1]], %[[C1]] : vector<8x4x2xi1>\n+// CHECK-SAME:     %[[SHIFT_IDX0]], %[[SHIFT_SUBIDX1]], %[[C1]] : vector<1x1x2xi1>\n // CHECK:        %[[SUBMASK:.*]] = vector.extract %[[SHIFT_MASK]][0, 0]\n-// CHECK-SAME:     : vector<2xi1> from vector<8x4x2xi1>\n+// CHECK-SAME:     : vector<2xi1> from vector<1x1x2xi1>\n // CHECK:        %[[SUBVECTOR:.*]] = vector.transfer_read\n // CHECK-SAME:     %[[BUFFER]][%[[IDX0]], %[[IDX1]], %[[C0]]], %[[PAD]], %[[SUBMASK]]\n // CHECK-SAME:     {in_bounds = [true]} : memref<8x4x2xf32>, vector<2xf32>\n // CHECK:        return %[[SUBVECTOR]] : vector<2xf32>\n // CHECK:      }\n \n \n+// -----\n+\n+func.func @extract_scalar_folds_correctly(\n+  %buffer: memref<8x4x2xf32>,\n+  %idx0: index,\n+  %idx1: index,\n+  %idx2: index) -> f32 {\n+  %c0 = arith.constant 0 : index\n+  %c0_f32 = arith.constant 0.0 : f32\n+  %c1 = arith.constant 1 : index\n+  %c3 = arith.constant 3 : index\n+  %c7 = arith.constant 7 : index\n+  %mask = vector.create_mask %c7, %c3, %c1 : vector<8x4x2xi1>\n+  %original_vector = vector.transfer_read %buffer[%c0, %c0, %c0],\n+    %c0_f32, %mask : memref<8x4x2xf32>, vector<8x4x2xf32>\n+  %scalar = vector.extract %original_vector[%idx0, %idx1, %idx2]\n+    : f32 from vector<8x4x2xf32>\n+  return %scalar : f32\n+}\n+\n+// CHECK: func.func @extract_scalar_folds_correctly(\n+// CHECK-SAME: %[[BUFFER:[^ ]*]]: memref<8x4x2xf32>,\n+// CHECK-SAME: %[[IDX0:[^ ]*]]: index,\n+// CHECK-SAME: %[[IDX1:[^ ]*]]: index,\n+// CHECK-SAME: %[[IDX2:[^ ]*]]: index) -> f32 {\n+// CHECK:   %[[PAD:.*]] = arith.constant 0.000000e+00 : f32\n+// CHECK:   %[[C1:.*]] = arith.constant 1 : index\n+// CHECK:   %[[C3:.*]] = arith.constant 3 : index\n+// CHECK:   %[[C7:.*]] = arith.constant 7 : index\n+// CHECK:   %[[SHIFT_IDX0:.*]] = arith.subi %[[C7]], %[[IDX0]] : index\n+// CHECK:   %[[SHIFT_IDX1:.*]] = arith.subi %[[C3]], %[[IDX1]] : index\n+// CHECK:   %[[SHIFT_IDX2:.*]] = arith.subi %[[C1]], %[[IDX2]] : index\n+// CHECK:   %[[MASK:.*]] = vector.create_mask %0, %1, %2 : vector<1x1x1xi1>\n+// CHECK:   %[[SUBMASK:.*]] = vector.extract %[[MASK]][0, 0, 0]\n+// CHECK-SAME: : vector<1xi1> from vector<1x1x1xi1>\n+// CHECK:   %[[READ:.*]] = vector.transfer_read %[[BUFFER]]\n+// CHECK-SAME: [%[[IDX0]], %[[IDX1]], %[[IDX2]]], %[[PAD]], %[[SUBMASK]]\n+// CHECK-SAME: : memref<8x4x2xf32>, vector<1xf32>\n+// CHECK:   %[[SCALAR:.*]] = vector.extract %[[READ]][0] : f32 from vector<1xf32>\n+// CHECK:   return %[[SCALAR]] : f32\n+// CHECK: }\n+\n+\n // -----\n \n func.func @unroll_dependent_vector_extract(%input: vector<8x2xf32>) -> vector<2xf32> {"
        }
    ],
    "stats": {
        "total": 112,
        "additions": 92,
        "deletions": 20
    }
}