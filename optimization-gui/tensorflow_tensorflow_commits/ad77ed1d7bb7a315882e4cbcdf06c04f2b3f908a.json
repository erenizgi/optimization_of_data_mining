{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add custom call to build collective kernel metadata.\n\nThis metadata can later be passed as additional parameter to collective fusions.\n\nPiperOrigin-RevId: 833743549",
    "sha": "ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
    "files": [
        {
            "sha": "e5afb0abb3035b13fabaeb52a107152be0f0b54a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 35,
            "deletions": 3,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -1227,6 +1227,7 @@ cc_library(\n     hdrs = [\"collective_kernel_thunk.h\"],\n     deps = [\n         \":all_reduce\",\n+        \":collective_metadata_thunk\",\n         \":collective_thunk\",\n         \":thunk\",\n         \"//xla:shape_util\",\n@@ -1236,7 +1237,6 @@ cc_library(\n         \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/service:collective_ops_utils\",\n-        \"//xla/service:rendezvous\",\n         \"//xla/service/gpu:gpu_constants\",\n         \"//xla/service/gpu:launch_dimensions\",\n         \"//xla/service/gpu:stream_executor_util\",\n@@ -1247,10 +1247,8 @@ cc_library(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:all_reduce_kernel\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n-        \"//xla/stream_executor/gpu:gpu_executor_header\",\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/container:inlined_vector\",\n@@ -1785,6 +1783,40 @@ cc_library(\n     ],\n )\n \n+cc_library(\n+    name = \"collective_metadata_thunk\",\n+    srcs = [\"collective_metadata_thunk.cc\"],\n+    hdrs = [\"collective_metadata_thunk.h\"],\n+    deps = [\n+        \":collective_thunk\",\n+        \":thunk\",\n+        \"//xla:shape_util\",\n+        \"//xla:status_macros\",\n+        \"//xla/backends/gpu/collectives:gpu_clique_key\",\n+        \"//xla/core/collectives:rank_id\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/runtime:device_id\",\n+        \"//xla/service:buffer_assignment\",\n+        \"//xla/service:collective_ops_utils\",\n+        \"//xla/service:rendezvous\",\n+        \"//xla/service/gpu:backend_configs_cc\",\n+        \"//xla/stream_executor:device_memory\",\n+        \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n+        \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n+        \"//xla/stream_executor/gpu:gpu_executor_header\",\n+        \"//xla/tsl/platform:errors\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/algorithm:container\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+        \"@com_google_absl//absl/types:span\",\n+        \"@com_google_protobuf//:protobuf_lite\",\n+    ],\n+)\n+\n cc_library(\n     name = \"sequential_thunk\",\n     srcs = [\"sequential_thunk.cc\"],"
        },
        {
            "sha": "00e1ac8743127e010d9267b056d5cc282cab664e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_test.cc",
            "status": "modified",
            "additions": 11,
            "deletions": 10,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_test.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -153,14 +153,15 @@ class AllReduceKernelTest : public ::testing::Test,\n     std::vector<se::DeviceMemoryBase> metadata_buffers;\n     // One for signal and one for input parameters.\n     constexpr int kNumPeerParameters = 2;\n-    size_t param_to_peers_size =\n-        sizeof(uint64_t) * kNumPeerParameters * num_ranks;\n-    std::vector<uint64_t> param_to_peers_ptrs;\n-    for (const auto& local_input_buffer : local_input_buffers) {\n-      param_to_peers_ptrs.push_back((uint64_t)local_input_buffer.opaque());\n+    size_t param_to_peers_size = sizeof(void*) * kNumPeerParameters * num_ranks;\n+    std::vector<void*> param_to_peers_ptrs;\n+    for (const stream_executor::DeviceMemoryBase& local_input_buffer :\n+         local_input_buffers) {\n+      param_to_peers_ptrs.push_back(local_input_buffer.opaque());\n     }\n-    for (const auto& signal_flags_buffer : signal_flags_buffers) {\n-      param_to_peers_ptrs.push_back((uint64_t)signal_flags_buffer.opaque());\n+    for (const stream_executor::DeviceMemoryBase& signal_flags_buffer :\n+         signal_flags_buffers) {\n+      param_to_peers_ptrs.push_back(signal_flags_buffer.opaque());\n     }\n \n     for (int i = 0; i < num_ranks; ++i) {\n@@ -174,9 +175,9 @@ class AllReduceKernelTest : public ::testing::Test,\n         TF_ASSIGN_OR_RETURN(\n             void* mapped_memory,\n             multicast_memory->MapMemory(allocated_buffers[i], gpu_executor));\n-        metadata.multicast_buffer_ptr = (uint64_t)mapped_memory;\n+        metadata.multicast_buffer_ptr = mapped_memory;\n       } else {\n-        metadata.multicast_buffer_ptr = 0;\n+        metadata.multicast_buffer_ptr = nullptr;\n       }\n \n       // First map from parameter to peer ptrs and then metadata.\n@@ -187,7 +188,7 @@ class AllReduceKernelTest : public ::testing::Test,\n           metadata_buffers[i].GetByteSlice(sizeof(CollectiveKernelMetadata),\n                                            param_to_peers_size);\n       metadata.param_to_peers =\n-          reinterpret_cast<uint64_t*>(param_to_peers_ptrs_buffer.opaque());\n+          reinterpret_cast<void**>(param_to_peers_ptrs_buffer.opaque());\n \n       TF_RETURN_IF_ERROR(streams[i]->Memcpy(&metadata_buffers[i], &metadata,\n                                             sizeof(CollectiveKernelMetadata)));"
        },
        {
            "sha": "98a44bfe28ce61b6b574d9ceff3742c77b41c7ad",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 127,
            "changes": 142,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -22,7 +22,6 @@ limitations under the License.*/\n #include <utility>\n #include <vector>\n \n-#include \"absl/algorithm/container.h\"\n #include \"absl/container/inlined_vector.h\"\n #include \"absl/log/log.h\"\n #include \"absl/status/status.h\"\n@@ -33,20 +32,19 @@ limitations under the License.*/\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/runtime/all_reduce.h\"\n+#include \"xla/backends/gpu/runtime/collective_metadata_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/service/gpu/gpu_constants.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n #include \"xla/service/gpu/stream_executor_util.h\"\n-#include \"xla/service/rendezvous.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/status_macros.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_handle.h\"\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n #include \"xla/stream_executor/gpu/collective_kernel_metadata.h\"\n-#include \"xla/stream_executor/gpu/gpu_executor.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n@@ -138,138 +136,26 @@ int64_t CollectiveKernelThunk::GetInputSizeBytes() const {\n              collective_config_.operand_element_type[0]);\n }\n \n-struct BaseRangePtrRendezvousValue {\n-  RankId rank;\n-  se::DeviceMemoryBase buffer_ptr;\n-  se::DeviceMemoryBase signal_ptr;\n-\n-  bool operator<(const BaseRangePtrRendezvousValue& other) const {\n-    return rank < other.rank;\n-  }\n-};\n-\n absl::Status CollectiveKernelThunk::ExchangeStateMetadata(\n     const GpuCliqueKey& clique_key, const InitializeParams& params,\n     StreamState& state) {\n-  BaseRangePtrRendezvousValue rendezvous_value;\n   const std::optional<RankId> rank =\n       clique_key.rank(params.collective_params->global_device_id);\n   TF_RET_CHECK(rank.has_value())\n       << \"Device \" << params.collective_params->global_device_id\n       << \"is not in the clique.\";\n-  rendezvous_value.rank = rank.value();\n-  rendezvous_value.buffer_ptr = state.local_buffers_handle.memory();\n-  rendezvous_value.signal_ptr = state.signal_buffers_handle.memory();\n-\n-  auto rendezvous_fn =\n-      [](absl::Span<const BaseRangePtrRendezvousValue* const> values) {\n-        std::vector<BaseRangePtrRendezvousValue> values_copy;\n-        for (const auto& value : values) {\n-          values_copy.push_back(*value);\n-        }\n-        // Sort to make sure that values are in the same order as the\n-        // devices are ordered in the communicator.\n-        absl::c_sort(values_copy);\n-        return values_copy;\n-      };\n-  const int64_t num_ranks = clique_key.num_devices();\n-  std::string start_rendezvous_key = absl::StrFormat(\n-      \"Initializing one-shot all-reduce for device %d, clique %s\",\n-      params.executor->device_ordinal(), clique_key.ToString());\n-  TF_ASSIGN_OR_RETURN(std::shared_ptr<std::vector<BaseRangePtrRendezvousValue>>\n-                          rendezvous_values,\n-                      Rendezvous<std::vector<BaseRangePtrRendezvousValue>>(\n-                          /*name=*/start_rendezvous_key, /*key=*/clique_key,\n-                          /*value=*/rendezvous_value, /*num_threads=*/num_ranks,\n-                          rendezvous_fn));\n-\n-  if (rendezvous_values->size() > num_ranks) {\n-    return absl::InvalidArgumentError(absl::StrFormat(\n-        \"Multi-device kernels require at most %d peers.\", num_ranks));\n-  }\n-  CollectiveKernelMetadata metadata;\n-  metadata.rank = rank.value().value();\n-  metadata.multicast_buffer_ptr =\n-      reinterpret_cast<uint64_t>(state.multicast_device_ptr);\n-\n-  std::vector<uint64_t> param_to_peers_ptrs;\n-  param_to_peers_ptrs.reserve(rendezvous_values->size() * 2);\n-  for (const auto& value : *rendezvous_values) {\n-    param_to_peers_ptrs.push_back(\n-        reinterpret_cast<uint64_t>(value.buffer_ptr.opaque()));\n-  }\n-  for (const auto& value : *rendezvous_values) {\n-    param_to_peers_ptrs.push_back(\n-        reinterpret_cast<uint64_t>(value.signal_ptr.opaque()));\n-  }\n-\n-  size_t param_to_peers_ptrs_size_bytes =\n-      param_to_peers_ptrs.size() * sizeof(uint64_t);\n-  se::DeviceMemoryBase metadata_ptr = params.executor->Allocate(\n-      sizeof(CollectiveKernelMetadata) + param_to_peers_ptrs_size_bytes, 0);\n-  se::DeviceMemoryBase param_to_peers_ptrs_buffer = metadata_ptr.GetByteSlice(\n-      sizeof(CollectiveKernelMetadata), param_to_peers_ptrs_size_bytes);\n-  VLOG(3) << \"[\" << params.executor->device_ordinal() << \"]\"\n-          << \" ExchangeStateMetadata: metadata_ptr = \" << metadata_ptr.opaque()\n-          << \", param_to_peers_ptrs_buffer = \"\n-          << param_to_peers_ptrs_buffer.opaque()\n-          << \", param_to_peers_ptrs_size = \" << param_to_peers_ptrs.size();\n-  metadata.param_to_peers =\n-      reinterpret_cast<uint64_t*>(param_to_peers_ptrs_buffer.opaque());\n-  TF_RETURN_IF_ERROR(params.stream->Memcpy(&metadata_ptr, (void*)&metadata,\n-                                           sizeof(CollectiveKernelMetadata)));\n-  TF_RETURN_IF_ERROR(params.stream->Memcpy(&param_to_peers_ptrs_buffer,\n-                                           param_to_peers_ptrs.data(),\n-                                           param_to_peers_ptrs_size_bytes));\n-  TF_RETURN_IF_ERROR(params.stream->BlockHostUntilDone());\n-\n-  state.metadata = metadata_ptr;\n-  return absl::OkStatus();\n-}\n-\n-absl::Status Barrier(int device_number, const GpuCliqueKey& clique_key) {\n-  std::string start_rendezvous_key = absl::StrFormat(\n-      \"Barrier for device %d, \"\n-      \"clique %s\",\n-      device_number, clique_key.ToString());\n-  return Rendezvous(\n-      /*name=*/\n-      start_rendezvous_key, /*key=*/clique_key,\n-      /*num_threads=*/clique_key.num_local_participants());\n-}\n-\n-absl::Status CollectiveKernelThunk::SetupMultimem(\n-    const GpuCliqueKey& clique_key, const se::StreamExecutor* stream_executor,\n-    StreamState& state) {\n-  const stream_executor::gpu::GpuExecutor* gpu_executor =\n-      dynamic_cast<const stream_executor::gpu::GpuExecutor*>(stream_executor);\n-  if (gpu_executor == nullptr) {\n-    return absl::UnimplementedError(\"Multicast is not supported on device.\");\n-  }\n-\n-  size_t data_size = buffers_[0].source_buffer.size();\n-  int device_number = gpu_executor->device_ordinal();\n-\n-  if (device_number == 0) {\n-    TF_ASSIGN_OR_RETURN(multicast_memory_,\n-                        gpu_executor->CreateMulticastMemory(\n-                            data_size, clique_key.num_local_participants()));\n-  }\n-\n-  // Wait for all devices to create the multicast object.\n-  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n-\n-  // Add current devices to the multicast object.\n-  TF_RETURN_IF_ERROR(multicast_memory_->SubscribeDevice(device_number));\n \n-  // Wait for all devices to register the multicast object.\n-  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n+  std::vector<se::DeviceMemoryBase> parameters;\n+  parameters.push_back(state.local_buffers_handle.memory());\n+  parameters.push_back(state.signal_buffers_handle.memory());\n \n-  TF_ASSIGN_OR_RETURN(state.multicast_device_ptr,\n-                      multicast_memory_->MapMemory(\n-                          state.local_buffers_handle.memory(), gpu_executor));\n-\n-  return absl::OkStatus();\n+  const size_t param_to_peers_ptrs_size_bytes =\n+      parameters.size() * clique_key.num_devices() * sizeof(uint64_t);\n+  state.metadata = params.executor->Allocate(\n+      sizeof(CollectiveKernelMetadata) + param_to_peers_ptrs_size_bytes, 0);\n+  return CollectiveMetadataThunk::ConstructCollectiveMetadata(\n+      std::move(parameters), params.stream, clique_key,\n+      state.multicast_device_ptr, rank.value().value(), state.metadata);\n }\n \n absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n@@ -356,8 +242,10 @@ absl::Status CollectiveKernelThunk::Initialize(const InitializeParams& params) {\n \n   if (state != nullptr) {\n     if (strategy == AllReduceStrategy::kMultimem) {\n-      se::StreamExecutor* stream_executor = params.executor;\n-      TF_RETURN_IF_ERROR(SetupMultimem(clique_key, stream_executor, *state));\n+      TF_ASSIGN_OR_RETURN(state->multicast_device_ptr,\n+                          address_space_provider_.SetupMultimemAddressSpace(\n+                              clique_key, params.executor,\n+                              state->local_buffers_handle.memory()));\n     }\n     TF_RETURN_IF_ERROR(ExchangeStateMetadata(clique_key, params, *state));\n   }"
        },
        {
            "sha": "e4849f354c009960fc57492b36453ad200f5837b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.h",
            "status": "modified",
            "additions": 2,
            "deletions": 10,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -30,14 +30,14 @@ limitations under the License.*/\n #include \"absl/synchronization/mutex.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/backends/gpu/runtime/collective_metadata_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/service/collective_ops_utils.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_handle.h\"\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n-#include \"xla/stream_executor/gpu/gpu_executor.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/stream.h\"\n \n@@ -150,13 +150,6 @@ class CollectiveKernelThunk : public Thunk {\n                                      const InitializeParams& params,\n                                      StreamState& state);\n \n-  // Initializes and multimem memory. Each thunk participant should call this\n-  // method once. Multimem should be setup before usage when multimem strategy\n-  // is selected.\n-  absl::Status SetupMultimem(const GpuCliqueKey& clique_key,\n-                             const se::StreamExecutor* stream_executor,\n-                             StreamState& state);\n-\n   // Whether the one-shot kernel is enabled.\n   const bool collective_kernel_enabled_;\n   // Whether the collective is run on an async stream.\n@@ -171,8 +164,7 @@ class CollectiveKernelThunk : public Thunk {\n   // Reference to the buffer related information required for the collective.\n   std::vector<CollectiveThunk::Buffer> buffers_;\n \n-  std::unique_ptr<stream_executor::gpu::GpuExecutor::MulticastMemory>\n-      multicast_memory_;\n+  CollectiveMetadataThunk::MultimemAddressSpaceProvider address_space_provider_;\n   // Guard access to the stream state across different threads (which control\n   // different streams).\n   absl::Mutex mutex_;"
        },
        {
            "sha": "9177031c22e9258cb01df6a36815dc53068a2323",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.cc",
            "status": "added",
            "additions": 273,
            "deletions": 0,
            "changes": 273,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -0,0 +1,273 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/collective_metadata_thunk.h\"\n+\n+#include <cstddef>\n+#include <cstdint>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"absl/types/span.h\"\n+#include \"google/protobuf/repeated_ptr_field.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/core/collectives/rank_id.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/layout.h\"\n+#include \"xla/runtime/device_id.h\"\n+#include \"xla/service/collective_ops_utils.h\"\n+#include \"xla/service/gpu/backend_configs.pb.h\"\n+#include \"xla/service/rendezvous.h\"\n+#include \"xla/status_macros.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/collective_kernel_metadata.h\"\n+#include \"xla/stream_executor/gpu/gpu_executor.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+\n+// TODO(460077850): Support global device ids and channel id.\n+CollectiveConfig CollectiveMetadataThunk::GetCollectiveConfig(\n+    const HloInstruction& hlo) {\n+  CollectiveConfig config;\n+  config.operand_count = hlo.operands().size();\n+  config.operand_element_type.reserve(config.operand_count);\n+  for (int i = 0; i < config.operand_count; i++) {\n+    config.operand_element_type.push_back(\n+        hlo.operand(i)->shape().element_type());\n+  }\n+\n+  config.collective_op_kind = RendezvousKey::kCrossReplica;\n+  config.op_id = static_cast<int64_t>(hlo.GetModule()->unique_id());\n+  if (hlo.has_backend_config()) {\n+    xla::gpu::GpuBackendConfig backend_config =\n+        hlo.backend_config<GpuBackendConfig>().value_or(GpuBackendConfig());\n+    if (backend_config.has_collective_metadata_backend_config()) {\n+      ::google::protobuf::RepeatedPtrField<ReplicaGroup> replica_groups =\n+          backend_config.collective_metadata_backend_config()\n+              .collective_devices()\n+              .replica_groups();\n+      config.replica_groups = std::vector<ReplicaGroup>(replica_groups.begin(),\n+                                                        replica_groups.end());\n+    }\n+  }\n+\n+  config.group_mode =\n+      CollectiveOpGroupMode::COLLECTIVE_OP_GROUP_MODE_CROSS_REPLICA;\n+\n+  return config;\n+}\n+\n+struct CollectiveMetadataRendezvousValue {\n+  RankId rank;\n+  std::vector<se::DeviceMemoryBase> parameters;\n+\n+  bool operator<(const CollectiveMetadataRendezvousValue& other) const {\n+    return rank < other.rank;\n+  }\n+};\n+\n+absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n+    std::vector<se::DeviceMemoryBase> parameters, se::Stream* stream,\n+    const GpuCliqueKey& clique_key, void* multimem_address_space,\n+    int device_ordinal, se::DeviceMemoryBase destination) {\n+  auto rendezvous_fn =\n+      [](absl::Span<const CollectiveMetadataRendezvousValue* const> values) {\n+        std::vector<CollectiveMetadataRendezvousValue> values_copy;\n+        for (const auto& value : values) {\n+          values_copy.push_back(*value);\n+        }\n+        // Sort to make sure that values are in the same order as the\n+        // devices are ordered in the communicator.\n+        absl::c_sort(values_copy);\n+        return values_copy;\n+      };\n+\n+  std::string start_rendezvous_key =\n+      absl::StrFormat(\"[%d] Initializing collective metadata for clique %s\",\n+                      device_ordinal, clique_key.ToString());\n+\n+  CollectiveMetadataRendezvousValue rendezvous_value;\n+  rendezvous_value.rank = device_ordinal;\n+  rendezvous_value.parameters = std::move(parameters);\n+\n+  TF_ASSIGN_OR_RETURN(\n+      std::shared_ptr<std::vector<CollectiveMetadataRendezvousValue>>\n+          rendezvous_values,\n+      Rendezvous<std::vector<CollectiveMetadataRendezvousValue>>(\n+          /*name=*/start_rendezvous_key, /*key=*/clique_key,\n+          /*value=*/rendezvous_value, /*num_threads=*/clique_key.num_devices(),\n+          rendezvous_fn));\n+\n+  CollectiveKernelMetadata metadata;\n+  metadata.rank = clique_key.rank(GlobalDeviceId(device_ordinal))\n+                      .value_or(RankId(-1))\n+                      .value();\n+  if (metadata.rank == -1) {\n+    return absl::InternalError(\n+        absl::StrFormat(\"Device %d not found in clique %s\", device_ordinal,\n+                        clique_key.ToString()));\n+  }\n+  metadata.multicast_buffer_ptr = multimem_address_space;\n+  TF_RET_CHECK(rendezvous_values->size() > 0)\n+      << \"Not enough devices in the clique.\";\n+  const size_t num_parameters = (*rendezvous_values)[0].parameters.size();\n+  for (const auto& value : *rendezvous_values) {\n+    TF_RET_CHECK(value.parameters.size() == num_parameters);\n+  }\n+\n+  std::vector<void*> param_to_peers_ptrs;\n+  param_to_peers_ptrs.reserve(rendezvous_values->size() * num_parameters);\n+  for (int param = 0; param < num_parameters; ++param) {\n+    for (int peer = 0; peer < clique_key.num_devices(); ++peer) {\n+      param_to_peers_ptrs.push_back(\n+          (*rendezvous_values)[peer].parameters[param].opaque());\n+    }\n+  }\n+\n+  const int param_to_peers_ptrs_size =\n+      param_to_peers_ptrs.size() * sizeof(void*);\n+  se::DeviceMemoryBase param_to_peers_ptrs_buffer = destination.GetByteSlice(\n+      sizeof(CollectiveKernelMetadata), param_to_peers_ptrs_size);\n+\n+  metadata.param_to_peers =\n+      reinterpret_cast<void**>(param_to_peers_ptrs_buffer.opaque());\n+\n+  TF_RETURN_IF_ERROR(stream->Memcpy(&destination, &metadata,\n+                                    sizeof(CollectiveKernelMetadata)));\n+  TF_RETURN_IF_ERROR(stream->Memcpy(&param_to_peers_ptrs_buffer,\n+                                    param_to_peers_ptrs.data(),\n+                                    param_to_peers_ptrs_size));\n+  return stream->BlockHostUntilDone();\n+}\n+\n+absl::Status CollectiveMetadataThunk::Initialize(\n+    const InitializeParams& params) {\n+  TF_ASSIGN_OR_RETURN(\n+      const GpuCliqueKey clique_key,\n+      GetCollectiveGpuCliqueKey(*params.collective_params, collective_config_,\n+                                /*use_nccl=*/false));\n+  const int64_t num_ranks = clique_key.num_devices();\n+  TF_RET_CHECK(result_.size() ==\n+               sizeof(CollectiveKernelMetadata) +\n+                   num_ranks * parameters_.size() * sizeof(uint64_t));\n+\n+  std::vector<se::DeviceMemoryBase> parameters;\n+  parameters.reserve(parameters_.size());\n+  for (const CollectiveMetadataThunk::Buffer& parameter : parameters_) {\n+    parameters.push_back(\n+        params.buffer_allocations->GetDeviceAddress(parameter.slice));\n+  }\n+  se::DeviceMemoryBase result_ptr =\n+      params.buffer_allocations->GetDeviceAddress(result_);\n+\n+  TF_ASSIGN_OR_RETURN(void* multimem_address_space,\n+                      SetupMultimem(clique_key, params));\n+  return ConstructCollectiveMetadata(\n+      std::move(parameters), params.stream, clique_key, multimem_address_space,\n+      params.executor->device_ordinal(), result_ptr);\n+}\n+\n+absl::Status CollectiveMetadataThunk::ExecuteOnStream(\n+    const ExecuteParams& params) {\n+  return absl::OkStatus();\n+}\n+\n+absl::StatusOr<void*> CollectiveMetadataThunk::SetupMultimem(\n+    const GpuCliqueKey& clique_key, const InitializeParams& params) {\n+  se::DeviceMemoryBase memory_range;\n+  for (const CollectiveMetadataThunk::Buffer& parameter : parameters_) {\n+    if (parameter.memory_space == xla::Layout::kGenericFastMemorySpace) {\n+      TF_ASSIGN_OR_RETURN(\n+          memory_range,\n+          params.executor->GetMemoryRange(\n+              params.buffer_allocations->GetDeviceAddress(parameter.slice)));\n+      break;\n+    }\n+  }\n+\n+  // Since there is no parameter in the collective memory space, we don't need\n+  // to set up the multicast memory.\n+  if (memory_range.is_null()) {\n+    return nullptr;\n+  }\n+  return address_space_provider_.SetupMultimemAddressSpace(\n+      clique_key, params.executor, memory_range);\n+}\n+\n+absl::Status Barrier(int device_number, const GpuCliqueKey& clique_key) {\n+  std::string start_rendezvous_key = absl::StrFormat(\n+      \"Barrier for device %d, \"\n+      \"clique %s\",\n+      device_number, clique_key.ToString());\n+  return Rendezvous(\n+      /*name=*/\n+      start_rendezvous_key, /*key=*/clique_key,\n+      /*num_threads=*/clique_key.num_local_participants());\n+}\n+\n+absl::StatusOr<void*> CollectiveMetadataThunk::MultimemAddressSpaceProvider::\n+    SetupMultimemAddressSpace(const GpuCliqueKey& clique_key,\n+                              const se::StreamExecutor* stream_executor,\n+                              se::DeviceMemoryBase mapped_memory) {\n+  const auto* gpu_executor =\n+      dynamic_cast<const stream_executor::gpu::GpuExecutor*>(stream_executor);\n+  if (gpu_executor == nullptr) {\n+    return absl::UnimplementedError(\"Multicast is not supported on device.\");\n+  }\n+  int device_number = gpu_executor->device_ordinal();\n+  TF_RET_CHECK(clique_key.num_local_participants() > 0)\n+      << \"Number of local participants must be greater than 0.\";\n+  int64_t first_device = clique_key.devices()[0].value();\n+\n+  if (device_number == first_device) {\n+    TF_ASSIGN_OR_RETURN(\n+        std::unique_ptr<stream_executor::gpu::GpuExecutor::MulticastMemory>\n+            multicast_memory,\n+        gpu_executor->CreateMulticastMemory(\n+            mapped_memory.size(), clique_key.num_local_participants()));\n+    first_device_to_multicast_memory_.emplace(device_number,\n+                                              std::move(multicast_memory));\n+  }\n+\n+  // Wait for all devices to create the multicast object.\n+  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n+\n+  TF_RET_CHECK(first_device_to_multicast_memory_.contains(first_device))\n+      << \"Multicast memory is not created for device \" << first_device;\n+  // Add current devices to the multicast object.\n+  TF_RETURN_IF_ERROR(\n+      first_device_to_multicast_memory_[first_device]->SubscribeDevice(\n+          device_number));\n+\n+  // Wait for all devices to register the multicast object.\n+  TF_RETURN_IF_ERROR(Barrier(device_number, clique_key));\n+\n+  return first_device_to_multicast_memory_[first_device]->MapMemory(\n+      mapped_memory, gpu_executor);\n+};\n+\n+}  // namespace gpu\n+}  // namespace xla"
        },
        {
            "sha": "e7496227f256b9cb38c6f853f8865c711f496e72",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.h",
            "status": "added",
            "additions": 96,
            "deletions": 0,
            "changes": 96,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -0,0 +1,96 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_METADATA_THUNK_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_METADATA_THUNK_H_\n+\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n+#include \"xla/backends/gpu/runtime/thunk.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/service/buffer_assignment.h\"\n+#include \"xla/stream_executor/device_memory.h\"\n+#include \"xla/stream_executor/gpu/gpu_executor.h\"\n+#include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n+\n+namespace xla {\n+namespace gpu {\n+class CollectiveMetadataThunk : public Thunk {\n+ public:\n+  struct Buffer {\n+    BufferAllocation::Slice slice;\n+    int64_t memory_space;\n+  };\n+\n+  class MultimemAddressSpaceProvider {\n+   public:\n+    // Initializes and multimem memory. Each thunk participant should call this\n+    // method once. Multimem should be setup before usage when multimem strategy\n+    // is selected.\n+    absl::StatusOr<void*> SetupMultimemAddressSpace(\n+        const GpuCliqueKey& clique_key,\n+        const se::StreamExecutor* stream_executor,\n+        se::DeviceMemoryBase mapped_memory);\n+\n+   private:\n+    absl::flat_hash_map<\n+        int,\n+        std::unique_ptr<stream_executor::gpu::GpuExecutor::MulticastMemory>>\n+        first_device_to_multicast_memory_;\n+  };\n+\n+  explicit CollectiveMetadataThunk(ThunkInfo thunk_info,\n+                                   CollectiveConfig collective_config,\n+                                   std::vector<Buffer> parameters,\n+                                   BufferAllocation::Slice result)\n+      : Thunk(Thunk::Kind::kCollectiveMetadata, thunk_info),\n+        collective_config_(std::move(collective_config)),\n+        parameters_(std::move(parameters)),\n+        result_(result) {}\n+  absl::Status Initialize(const InitializeParams& params) override;\n+  absl::Status ExecuteOnStream(const ExecuteParams& params) override;\n+\n+  static CollectiveConfig GetCollectiveConfig(const HloInstruction& hlo);\n+\n+  // Constructs and places the collective metadata on the device.\n+  // All participants should call this method to construct their local\n+  // metadata.\n+  static absl::Status ConstructCollectiveMetadata(\n+      std::vector<se::DeviceMemoryBase> parameters, se::Stream* stream,\n+      const GpuCliqueKey& clique_key, void* multimem_address_space,\n+      int device_ordinal, se::DeviceMemoryBase destination);\n+\n+  absl::StatusOr<void*> SetupMultimem(const GpuCliqueKey& clique_key,\n+                                      const InitializeParams& params);\n+\n+ private:\n+  const CollectiveConfig collective_config_;\n+  std::vector<Buffer> parameters_;\n+  MultimemAddressSpaceProvider address_space_provider_;\n+  BufferAllocation::Slice result_;\n+};\n+}  // namespace gpu\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_COLLECTIVE_METADATA_THUNK_H_"
        },
        {
            "sha": "d1dcaca60a5452a64c94fa5150640e990d7ced9d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -263,6 +263,7 @@ Thunk::ExecuteParams::ExecuteParams(\n     CASE(kCollectiveBroadcastDone);\n     CASE(kCollectiveBroadcastStart);\n     CASE(kCollectiveKernel);\n+    CASE(kCollectiveMetadata);\n     CASE(kCollectivePermute);\n     CASE(kCollectivePermuteDone);\n     CASE(kCollectivePermuteStart);\n@@ -457,6 +458,5 @@ ThunkInfoProto Thunk::ThunkInfo::ToProto() const {\n   return proto;\n }\n \n-\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "d3849676e1be6c23196b662d9d6649a2e16e71a6",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.h",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -143,6 +143,7 @@ class Thunk {\n     kCollectiveBroadcastDone,\n     kCollectiveBroadcastStart,\n     kCollectiveKernel,\n+    kCollectiveMetadata,\n     kCollectivePermute,\n     kCollectivePermuteDone,\n     kCollectivePermuteStart,"
        },
        {
            "sha": "1c2463d5459791ca2b1f7cde5b865966e9ec1859",
            "filename": "third_party/xla/xla/hlo/ir/hlo_instructions.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fir%2Fhlo_instructions.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -2930,6 +2930,8 @@ inline constexpr absl::string_view kPinCustomCallTarget = \"Pin\";\n inline constexpr absl::string_view kUnpinCustomCallTarget = \"Unpin\";\n inline constexpr absl::string_view kCreateBufferCustomCallTarget =\n     \"CreateBuffer\";\n+inline constexpr absl::string_view kCollectiveMetadataCustomCallTarget =\n+    \"CollectiveMetadata\";\n \n }  // namespace xla\n "
        },
        {
            "sha": "a1df54459a302d97790afaaec1b0c1c1bf814c39",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -486,6 +486,7 @@ cc_library(\n         \"//xla/backends/gpu/runtime:collective_broadcast_thunk\",\n         \"//xla/backends/gpu/runtime:collective_group_thunk\",\n         \"//xla/backends/gpu/runtime:collective_kernel_thunk\",\n+        \"//xla/backends/gpu/runtime:collective_metadata_thunk\",\n         \"//xla/backends/gpu/runtime:collective_permute_thunk\",\n         \"//xla/backends/gpu/runtime:collective_thunk\",\n         \"//xla/backends/gpu/runtime:command_buffer_cmd\","
        },
        {
            "sha": "4d3c77a3a63c383fcf48a9dec8f6d56aa8c79196",
            "filename": "third_party/xla/xla/service/gpu/backend_configs.proto",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fbackend_configs.proto?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -136,6 +136,11 @@ message CollectiveBackendConfig {\n   reserved 2, 4;\n }\n \n+// Backend config for collective metadata operation.\n+message CollectiveMetadataBackendConfig {\n+  CollectiveDeviceListProto collective_devices = 1;\n+}\n+\n // Backend config for cost model estimates.\n message ReificationCost {\n   // Total execution time of the reified op.\n@@ -361,7 +366,7 @@ enum DeviceType {\n }\n \n // Generic backend config for XLA:GPU\n-// Next-Id: 16\n+// Next-Id: 17\n message GpuBackendConfig {\n   // Specifies which operation queue the current instruction will run on.\n   // A backend may have multiple operation queues to run instructions\n@@ -395,6 +400,8 @@ message GpuBackendConfig {\n     BlockScaledDotBackendConfig block_scaled_dot_backend_config = 13;\n \n     NativeEmitterBackendConfig native_emitter_backend_config = 15;\n+\n+    CollectiveMetadataBackendConfig collective_metadata_backend_config = 16;\n   }\n \n   // This attribute instructs the latency-hiding scheduler to"
        },
        {
            "sha": "49c3aafb1aa1410894f6d724885ae139443302b0",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -80,6 +80,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/collective_broadcast_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_group_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_kernel_thunk.h\"\n+#include \"xla/backends/gpu/runtime/collective_metadata_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_permute_thunk.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/command_buffer_cmd.h\"\n@@ -1937,6 +1938,31 @@ bool IsNvshmemCollective(const HloInstruction* instr) {\n   return false;\n }\n \n+absl::Status IrEmitterUnnested::EmitCollectiveMetadata(\n+    const HloInstruction* instr) {\n+  std::vector<CollectiveMetadataThunk::Buffer> buffers;\n+  buffers.reserve(instr->operands().size());\n+  for (const HloInstruction* operand : instr->operands()) {\n+    TF_ASSIGN_OR_RETURN(BufferAllocation::Slice slice,\n+                        GetAllocationSliceForHlo(operand, {}));\n+    buffers.push_back({slice, operand->shape().layout().memory_space()});\n+  }\n+\n+  // Operation result should be a tuple where the last element is the buffer for\n+  // the metadata.\n+  ShapeIndex result_shape_index = {static_cast<int64_t>(buffers.size())};\n+  TF_ASSIGN_OR_RETURN(BufferAllocation::Slice result,\n+                      GetAllocationSliceForHlo(instr, result_shape_index));\n+\n+  auto thunk = std::make_unique<CollectiveMetadataThunk>(\n+      Thunk::ThunkInfo::WithProfileAnnotation(\n+          instr, ir_emitter_context_->GetNextThunkId()),\n+      CollectiveMetadataThunk::GetCollectiveConfig(*instr), std::move(buffers),\n+      result);\n+  AddThunkToThunkSequence(std::move(thunk));\n+  return absl::OkStatus();\n+}\n+\n absl::Status IrEmitterUnnested::EmitCollectivePermute(\n     const HloCollectivePermuteInstruction* instr) {\n   // First output is aliased.\n@@ -3300,6 +3326,9 @@ absl::Status IrEmitterUnnested::EmitHloInstruction(\n           instr->custom_call_target() == kCreateBufferCustomCallTarget) {\n         return absl::OkStatus();\n       }\n+      if (instr->custom_call_target() == kCollectiveMetadataCustomCallTarget) {\n+        return EmitCollectiveMetadata(instr);\n+      }\n       return EmitCustomCallThunk(custom_call);\n     }\n     case HloOpcode::kFusion:"
        },
        {
            "sha": "1ab715d41287bb45cf24e3091992280ce8056aaa",
            "filename": "third_party/xla/xla/service/gpu/ir_emitter_unnested.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fir_emitter_unnested.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -176,6 +176,8 @@ class IrEmitterUnnested : public IrEmitter {\n   template <typename ThunkType>\n   absl::Status EmitReplicaOrPartitionId(const HloInstruction* instr);\n \n+  absl::Status EmitCollectiveMetadata(const HloInstruction* instr);\n+\n   absl::Status EmitCollectivePermute(\n       const HloCollectivePermuteInstruction* instr);\n "
        },
        {
            "sha": "adb77859f7715e2bc12d044a2fd0e5b7c96a5dee",
            "filename": "third_party/xla/xla/stream_executor/gpu/all_reduce_kernel_lib.cu.h",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fall_reduce_kernel_lib.cu.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fall_reduce_kernel_lib.cu.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fall_reduce_kernel_lib.cu.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -90,8 +90,9 @@ __device__ __forceinline__ RestrictedPtr<T> GetPeerPtr(\n     const CollectiveKernelMetadata& metadata) {\n   uint64_t argument_offset = num_ranks * argument_index;\n   uint64_t current_base =\n-      metadata.param_to_peers[argument_offset + metadata.rank];\n-  uint64_t peer_base = metadata.param_to_peers[argument_offset + peer_rank];\n+      (uint64_t)metadata.param_to_peers[argument_offset + metadata.rank];\n+  uint64_t peer_base =\n+      (uint64_t)metadata.param_to_peers[argument_offset + peer_rank];\n   uint64_t offset = (uint64_t)ptr - current_base;\n \n   return (RestrictedPtr<T>)(peer_base + offset);\n@@ -103,10 +104,10 @@ __device__ __forceinline__ RestrictedPtr<T> GetMultimemPtr(\n     const CollectiveKernelMetadata& metadata) {\n   uint64_t argument_offset = num_ranks * argument_index;\n   uint64_t current_base =\n-      metadata.param_to_peers[argument_offset + metadata.rank];\n+      (uint64_t)metadata.param_to_peers[argument_offset + metadata.rank];\n   uint64_t offset = (uint64_t)ptr - current_base;\n \n-  return (RestrictedPtr<T>)(metadata.multicast_buffer_ptr + offset);\n+  return (RestrictedPtr<T>)((uint64_t)metadata.multicast_buffer_ptr + offset);\n }\n \n template <PlatformType T = PlatformType::NOGPU>"
        },
        {
            "sha": "8dcd2069e8f3b79101b1cf0d0d4be3b6fbcea2ec",
            "filename": "third_party/xla/xla/stream_executor/gpu/collective_kernel_metadata.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fcollective_kernel_metadata.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fcollective_kernel_metadata.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fgpu%2Fcollective_kernel_metadata.h?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -33,10 +33,10 @@ limitations under the License.\n // ]\n struct CollectiveKernelMetadata {\n   uint64_t rank;\n-  uint64_t* param_to_peers;\n+  void** param_to_peers;\n \n   // Root pointer for multicast buffer for current device.\n-  uint64_t multicast_buffer_ptr;\n+  void* multicast_buffer_ptr;\n };\n \n #endif  // XLA_STREAM_EXECUTOR_GPU_COLLECTIVE_KERNEL_METADATA_H_"
        },
        {
            "sha": "75c2118d2bd0b445004efc5dcdac42563eb520ef",
            "filename": "third_party/xla/xla/tests/BUILD",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2FBUILD?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -2874,6 +2874,7 @@ xla_test(\n         \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n         \"//xla/stream_executor/integrations:device_mem_allocator\",\n+        \"//xla/stream_executor/integrations:stream_executor_allocator\",\n         \"//xla/stream_executor/integrations:tf_allocator_adapter\",\n         \"//xla/tsl/framework:bfc_allocator\",\n         \"//xla/tsl/framework:device_id\",\n@@ -2893,7 +2894,11 @@ xla_test(\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/types:span\",\n         \"@local_tsl//tsl/platform:regexp\",\n-    ],\n+    ] + if_google([\n+        # In OSS this dependency is added automatically for xla_test targets. See\n+        # third_party/tensorflow/compiler/xla/xla.default.bzl.\n+        \"//xla/tsl/framework:allocator\",\n+    ]),\n )\n \n xla_test("
        },
        {
            "sha": "13863bc77feb1775f7f3d811745479b94fd6791c",
            "filename": "third_party/xla/xla/tests/collective_ops_e2e_test.cc",
            "status": "modified",
            "additions": 202,
            "deletions": 17,
            "changes": 219,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftests%2Fcollective_ops_e2e_test.cc?ref=ad77ed1d7bb7a315882e4cbcdf06c04f2b3f908a",
            "patch": "@@ -14,6 +14,7 @@ limitations under the License.\n ==============================================================================*/\n \n #include <algorithm>\n+#include <array>\n #include <cmath>\n #include <cstddef>\n #include <cstdint>\n@@ -48,6 +49,7 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_sharding.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n+#include \"xla/hlo/testlib/verified_hlo_module.h\"\n #include \"xla/hlo/utils/hlo_matchers.h\"\n #include \"xla/literal.h\"\n #include \"xla/literal_util.h\"\n@@ -63,11 +65,13 @@ limitations under the License.\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"xla/stream_executor/integrations/device_mem_allocator.h\"\n+#include \"xla/stream_executor/integrations/stream_executor_allocator.h\"\n #include \"xla/stream_executor/integrations/tf_allocator_adapter.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tests/literal_test_util.h\"\n #include \"xla/tests/test_utils.h\"\n+#include \"xla/tsl/framework/allocator.h\"\n #include \"xla/tsl/framework/bfc_allocator.h\"\n #include \"xla/tsl/framework/device_id.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n@@ -97,14 +101,24 @@ DeviceAssignment MakeDeviceAssn(int64_t num_replicas) {\n \n std::unique_ptr<tsl::BFCAllocator> CreateAllocator(se::StreamExecutor* executor,\n                                                    int64_t device_ordinal,\n-                                                   std::string name_suffix,\n+                                                   bool is_collective,\n                                                    size_t memory_size) {\n+  std::string name_suffix = is_collective ? \"_collectives_bfc\" : \"_bfc\";\n   tsl::BFCAllocator::Options opts;\n   opts.allow_growth = false;\n+  std::unique_ptr<tsl::SubAllocator> device_mem_allocator;\n+  if (is_collective) {\n+    device_mem_allocator = std::make_unique<se::StreamExecutorAllocator>(\n+        executor->CreateMemoryAllocator(se::MemoryType::kCollective).value(),\n+        /*memory_type=*/stream_executor::MemoryType::kCollective,\n+        device_ordinal);\n+  } else {\n+    device_mem_allocator = std::make_unique<se::DeviceMemAllocator>(\n+        executor, tsl::PlatformDeviceId(device_ordinal));\n+  }\n   return std::make_unique<tsl::BFCAllocator>(\n-      std::make_unique<se::DeviceMemAllocator>(\n-          executor, tsl::PlatformDeviceId(device_ordinal)),\n-      memory_size, absl::StrCat(\"GPU_\", device_ordinal, name_suffix), opts);\n+      std::move(device_mem_allocator), memory_size,\n+      absl::StrCat(\"GPU_\", device_ordinal, name_suffix), opts);\n }\n \n template <typename Type>\n@@ -136,14 +150,15 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n           CheckStatus(platform->ExecutorForDevice(i));\n       // Common memory allocator for device i.\n       allocators.emplace_back(\n-          CreateAllocator(executor, i, \"_bfc\", common_buffers_size), nullptr, 0,\n-          i, platform);\n+          CreateAllocator(executor, i, /*is_collective=*/false,\n+                          common_buffers_size),\n+          nullptr, 0, i, platform);\n \n       // Collectives and symmetric memory allocator for device i.\n-      allocators.emplace_back(CreateAllocator(executor, i, \"_collectives_bfc\",\n-                                              collectives_buffers_size),\n-                              nullptr, (int)gpu::MemorySpaceColor::kCollective,\n-                              i, platform);\n+      allocators.emplace_back(\n+          CreateAllocator(executor, i, /*is_collective=*/true,\n+                          collectives_buffers_size),\n+          nullptr, (int)gpu::MemorySpaceColor::kCollective, i, platform);\n     }\n \n     hlo_runner_ = std::make_unique<HloRunner>(\n@@ -222,6 +237,18 @@ class CollectiveOpsE2ETestBase : public HloHardwareIndependentTestBase {\n         num_replicas, /*run_hlo_passes=*/false, &device_assignment);\n   }\n \n+  const se::GpuComputeCapability& Capability() {\n+    return hlo_runner_->backend()\n+        .default_stream_executor()\n+        ->GetDeviceDescription()\n+        .gpu_compute_capability();\n+  }\n+\n+  bool IsHopperAndHigher() {\n+    return Capability().IsCuda() &&\n+           Capability().cuda_compute_capability()->IsAtLeastHopper();\n+  }\n+\n  protected:\n   std::unique_ptr<HloRunner> hlo_runner_;\n   std::unique_ptr<HloRunner> reference_hlo_runner_;\n@@ -236,13 +263,6 @@ class CollectiveOpsTestE2E : public CollectiveOpsE2ETestBase {\n         Capability().IsCuda() ? \"f8e5m2\" : \"f8e5m2fnuz\";\n   }\n \n-  const se::GpuComputeCapability& Capability() {\n-    return hlo_runner_->backend()\n-        .default_stream_executor()\n-        ->GetDeviceDescription()\n-        .gpu_compute_capability();\n-  }\n-\n   bool HasFp8Support() {\n     if (Capability().IsCuda()) {\n       return Capability().cuda_compute_capability()->IsAtLeast(8, 9);\n@@ -4624,5 +4644,170 @@ INSTANTIATE_TEST_SUITE_P(\n                           std::get<1>(info.param) ? \"one_shot\" : \"nccl\");\n     });\n \n+class CollectiveMetadataTest : public CollectiveOpsE2ETestBase {\n+ protected:\n+  void SetUp() override {\n+    CollectiveOpsE2ETestBase::SetUp();\n+    if (!IsHopperAndHigher()) {\n+      GTEST_SKIP() << \"Test requires Hopper or newer architecture since it's \"\n+                      \"using a multicast.\";\n+    }\n+  }\n+};\n+\n+TEST_F(CollectiveMetadataTest, ConstructCollectiveMetadata) {\n+  constexpr int kNumReplicas = 2;\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> unoptimized_module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+  HloModule test, replica_count=2\n+\n+  ENTRY test_computation {\n+    param_0 = f32[4] parameter(0)\n+    param_1 = f32[4] parameter(1)\n+    copy_1 = f32[4]{0:S(1)} copy(param_1)\n+\n+    const_0 = f32[1] constant({10})\n+\n+    result_tuple = (f32[4], f32[4]{0:S(1)}, f32[1], u64[9]) custom-call(param_0, copy_1, const_0), custom_call_target=\"CollectiveMetadata\", output_to_operand_aliasing={{0}: (0, {}), {1}: (1, {})}\n+    ROOT get_tuple_element = u64[9] get-tuple-element(result_tuple), index=3\n+  })\"));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<OpaqueExecutable> executable,\n+      hlo_runner_->CreateExecutable(std::move(unoptimized_module),\n+                                    /*run_hlo_passes=*/false));\n+  const std::array<Literal, 2> arguments = {\n+      LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f}),\n+      LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f})};\n+  DeviceAssignment device_assignment = MakeDeviceAssn(kNumReplicas);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<Literal> result,\n+      ExecuteReplicated(\n+          /*executable_provider*/ [&](int64_t) { return executable.get(); },\n+          /*argument_count_provider*/ [&](int64_t) { return arguments.size(); },\n+          /*argument_provider*/\n+          [&](int64_t replica_id, int64_t arg_index) {\n+            return &arguments[arg_index];\n+          },\n+          kNumReplicas,\n+          /*run_hlo_passes=*/false, &device_assignment));\n+\n+  ASSERT_EQ(result.size(), kNumReplicas);\n+  Literal first_result = std::move(result[0]);\n+  Literal second_result = std::move(result[1]);\n+\n+  absl::Span<const uint64_t> first_result_data = first_result.data<uint64_t>();\n+  absl::Span<const uint64_t> second_result_data =\n+      second_result.data<uint64_t>();\n+  constexpr int kNumElements = 9;\n+  ASSERT_EQ(first_result_data.size(), kNumElements);\n+  ASSERT_EQ(second_result_data.size(), kNumElements);\n+\n+  // Check the rank in the first position.\n+  EXPECT_EQ(first_result_data[0], 0);\n+  EXPECT_EQ(second_result_data[0], 1);\n+\n+  // Check pointer to peers in the second position.\n+  EXPECT_NE(first_result_data[1], 0);\n+  EXPECT_NE(second_result_data[1], 0);\n+\n+  // Check pointer to multimem metadata in the third position.\n+  EXPECT_NE(first_result_data[2], 0);\n+  EXPECT_NE(second_result_data[2], 0);\n+\n+  // Check param_to_peers structure.\n+  for (int i = 3; i < kNumElements; ++i) {\n+    EXPECT_NE(first_result_data[i], 0);\n+    EXPECT_EQ(second_result_data[i], first_result_data[i]);\n+  }\n+}\n+\n+TEST_F(CollectiveMetadataTest, ConstructCollectiveMetadataWithReplicaGroup) {\n+  constexpr int kNumReplicas = 4;\n+  if (hlo_runner_->device_count() < kNumReplicas) {\n+    GTEST_SKIP() << \"Test requires at least \" << kNumReplicas << \" devices (\"\n+                 << hlo_runner_->device_count() << \" available)\";\n+  }\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<VerifiedHloModule> unoptimized_module,\n+                          ParseAndReturnVerifiedModule(R\"(\n+  HloModule test, replica_count=4\n+\n+  ENTRY test_computation {\n+    param_0 = f32[4] parameter(0)\n+    param_1 = f32[4] parameter(1)\n+    copy_1 = f32[4]{0:S(1)} copy(param_1)\n+\n+    result_tuple = (f32[4], f32[4]{0:S(1)}, u64[7]) custom-call(param_0, copy_1), custom_call_target=\"CollectiveMetadata\", output_to_operand_aliasing={{0}: (0, {}), {1}: (1, {})}, backend_config=\"{\\\"collective_metadata_backend_config\\\":{\\\"collective_devices\\\": { \\\"replica_groups\\\": [{\\\"replica_ids\\\": [0,1]}, {\\\"replica_ids\\\": [2,3]}]}}}\"\n+    ROOT get_tuple_element = u64[7] get-tuple-element(result_tuple), index=2\n+  })\"));\n+\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::unique_ptr<OpaqueExecutable> executable,\n+      hlo_runner_->CreateExecutable(std::move(unoptimized_module),\n+                                    /*run_hlo_passes=*/false));\n+  const std::array<Literal, 2> arguments = {\n+      LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f}),\n+      LiteralUtil::CreateR1<float>({1.0f, 2.0f, 3.0f, 4.0f})};\n+  DeviceAssignment device_assignment = MakeDeviceAssn(kNumReplicas);\n+  TF_ASSERT_OK_AND_ASSIGN(\n+      std::vector<Literal> result,\n+      ExecuteReplicated(\n+          /*executable_provider*/ [&](int64_t) { return executable.get(); },\n+          /*argument_count_provider*/ [&](int64_t) { return arguments.size(); },\n+          /*argument_provider*/\n+          [&](int64_t replica_id, int64_t arg_index) {\n+            return &arguments[arg_index];\n+          },\n+          kNumReplicas,\n+          /*run_hlo_passes=*/false, &device_assignment));\n+\n+  ASSERT_EQ(result.size(), kNumReplicas);\n+  Literal replica_0_result_0 = std::move(result[0]);\n+  Literal replica_0_result_1 = std::move(result[1]);\n+  Literal replica_1_result_0 = std::move(result[2]);\n+  Literal replica_1_result_1 = std::move(result[3]);\n+\n+  absl::Span<const uint64_t> replica_0_result_0_data =\n+      replica_0_result_0.data<uint64_t>();\n+  absl::Span<const uint64_t> replica_0_result_1_data =\n+      replica_0_result_1.data<uint64_t>();\n+  absl::Span<const uint64_t> replica_1_result_0_data =\n+      replica_1_result_0.data<uint64_t>();\n+  absl::Span<const uint64_t> replica_1_result_1_data =\n+      replica_1_result_1.data<uint64_t>();\n+\n+  // Check the rank in the first position.\n+  constexpr int kNumElements = 7;\n+  ASSERT_EQ(replica_0_result_0_data.size(), kNumElements);\n+  ASSERT_EQ(replica_0_result_1_data.size(), kNumElements);\n+  ASSERT_EQ(replica_1_result_0_data.size(), kNumElements);\n+  ASSERT_EQ(replica_1_result_1_data.size(), kNumElements);\n+\n+  EXPECT_EQ(replica_0_result_0_data[0], 0);\n+  EXPECT_EQ(replica_0_result_1_data[0], 1);\n+  EXPECT_EQ(replica_1_result_0_data[0], 0);\n+  EXPECT_EQ(replica_1_result_1_data[0], 1);\n+\n+  // Check pointer to peers in the second position.\n+  EXPECT_NE(replica_0_result_0_data[1], 0);\n+  EXPECT_NE(replica_0_result_1_data[1], 0);\n+  EXPECT_NE(replica_1_result_0_data[1], 0);\n+  EXPECT_NE(replica_1_result_1_data[1], 0);\n+\n+  // Check pointer to multimem metadata in the third position.\n+  EXPECT_NE(replica_0_result_0_data[2], 0);\n+  EXPECT_NE(replica_0_result_1_data[2], 0);\n+  EXPECT_NE(replica_1_result_0_data[2], 0);\n+  EXPECT_NE(replica_1_result_1_data[2], 0);\n+\n+  // Check param_to_peers structure.\n+  for (int i = 3; i < kNumElements; ++i) {\n+    EXPECT_NE(replica_0_result_0_data[i], 0);\n+    EXPECT_EQ(replica_0_result_1_data[i], replica_0_result_0_data[i]);\n+    EXPECT_NE(replica_1_result_0_data[i], 0);\n+    EXPECT_EQ(replica_1_result_1_data[i], replica_1_result_0_data[i]);\n+  }\n+}\n+\n }  // namespace\n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 867,
        "additions": 691,
        "deletions": 176
    }
}