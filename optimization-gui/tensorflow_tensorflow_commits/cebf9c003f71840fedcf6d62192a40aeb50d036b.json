{
    "author": "tensorflower-gardener",
    "message": "Enable nvtx ext payload parsing in CUPTI. Special for NVTX payload schema used in NCCL, i.e. static schema.\n\nPiperOrigin-RevId: 835366537",
    "sha": "cebf9c003f71840fedcf6d62192a40aeb50d036b",
    "files": [
        {
            "sha": "bdddd7bc54230f508fa431ec584d0b769fcc6c7b",
            "filename": "third_party/xla/xla/backends/profiler/gpu/BUILD",
            "status": "modified",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2FBUILD?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -234,6 +234,7 @@ cc_library(\n         \":cupti_buffer_events\",\n         \":cupti_collector\",\n         \":cupti_interface\",\n+        \":cupti_marker_data_parser\",\n         \":cupti_pm_sampler_factory\",\n         \":cupti_utils\",\n         \"//xla/tsl/platform:env\",\n@@ -244,6 +245,7 @@ cc_library(\n         \"//xla/tsl/profiler/utils:per_thread\",\n         \"//xla/tsl/profiler/utils:xplane_builder\",\n         \"//xla/tsl/profiler/utils:xplane_schema\",\n+        \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/base:core_headers\",\n         \"@com_google_absl//absl/cleanup\",\n         \"@com_google_absl//absl/container:flat_hash_map\",\n@@ -505,6 +507,64 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"cupti_nvtx_ext_payload\",\n+    srcs = if_cuda_newer_than(\n+        \"13_0\",\n+        [\"cupti_nvtx_ext_payload.cc\"],\n+        [],\n+    ),\n+    hdrs = if_cuda_newer_than(\n+        \"13_0\",\n+        [\"cupti_nvtx_ext_payload.h\"],\n+        [],\n+    ),\n+    # copybara:uncomment compatible_with = [\"//buildenv/target:non_prod\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \"//xla/tsl/cuda:cupti\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/synchronization\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+        \"@local_tsl//tsl/platform\",\n+        \"@local_tsl//tsl/platform:macros\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"cupti_marker_data_parser\",\n+    srcs = if_cuda_newer_than(\n+        \"13_0\",\n+        [\"cupti_marker_data_parser_ext.cc\"],\n+        [\"cupti_marker_data_parser.cc\"],\n+    ),\n+    hdrs = [\"cupti_marker_data_parser.h\"],\n+    # copybara:uncomment compatible_with = [\"//buildenv/target:non_prod\"],\n+    tags = [\n+        \"cuda-only\",\n+        \"gpu\",\n+    ],\n+    deps = [\n+        \"//xla/tsl/cuda:cupti\",\n+        \"@com_google_absl//absl/base:core_headers\",\n+        \"@com_google_absl//absl/container:flat_hash_map\",\n+        \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/strings\",\n+        \"@com_google_absl//absl/synchronization\",\n+        \"@local_config_cuda//cuda:cuda_headers\",\n+    ] + if_cuda_newer_than(\n+        \"13_0\",\n+        [\":cupti_nvtx_ext_payload\"],\n+        [],\n+    ),\n+)\n+\n cc_library(\n     name = \"cupti_collector\",\n     srcs = [\"cupti_collector.cc\"],\n@@ -558,6 +618,7 @@ cc_library(\n     visibility = [\"//visibility:public\"],\n     deps = [\n         \":cupti_interface\",\n+        \":cupti_marker_data_parser\",\n         \":cupti_utils\",\n         \"//xla/tsl/cuda:cupti\",\n         \"//xla/tsl/profiler/utils:buffer_pool\","
        },
        {
            "sha": "7167139a85b4103e7985940329a819d6605fb675",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -16,12 +16,16 @@ limitations under the License.\n #include \"xla/backends/profiler/gpu/cupti_buffer_events.h\"\n \n #include <cstdint>\n+#include <optional>\n+#include <string>\n+#include <utility>\n \n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/string_view.h\"\n #include \"third_party/gpus/cuda/extras/CUPTI/include/cupti_activity.h\"\n #include \"third_party/gpus/cuda/include/cuda.h\"\n #include \"xla/backends/profiler/gpu/cupti_interface.h\"\n+#include \"xla/backends/profiler/gpu/cupti_marker_data_parser.h\"\n #include \"xla/backends/profiler/gpu/cupti_utils.h\"\n #include \"tsl/platform/errors.h\"\n #include \"tsl/platform/mem.h\"\n@@ -268,6 +272,29 @@ void AddMarkerActivityEvent(CuptiEventCollectorDelegate &collector,\n   }\n }\n \n+void AddMarkerDataActivityEvent(CuptiEventCollectorDelegate& collector,\n+                                void* marker_data_trace) {\n+  std::optional<std::pair<std::string, uint32_t>> result =\n+      ParseMarkerDataActivity(marker_data_trace);\n+  if (result.has_value() && !result.value().first.empty()) {\n+    collector.receive(CuptiTracerEvent{\n+        /* .type = */ CuptiTracerEventType::MarkerData,\n+        /* .source = */ CuptiTracerEventSource::Activity,\n+        /* .name = */ std::move(result.value().first),\n+        /* .annotation = */ \"\",\n+        /* .nvtx_range = */ \"\",\n+        /* .start_time_ns = */ 0,\n+        /* .end_time_ns = */ 0,\n+        /* .device_id = */ 0,\n+        /* .correlation_id = */ 0,\n+        /* .thread_id = */ 0,\n+        /* .context_id = */ 0,\n+        /* .stream_id = */ 0,\n+        /* .graph_id = */ result.value().second,\n+    });\n+  }\n+}\n+\n void AddMemcpyActivityEvent(CuptiEventCollectorDelegate &collector,\n                             const CuptiActivityMemcpyTy *memcpy) {\n   CuptiTracerEvent event{};\n@@ -576,6 +603,9 @@ static absl::Status ConvertActivityBuffer(\n           AddMarkerActivityEvent(\n               collector, reinterpret_cast<CuptiActivityMarkerTy *>(record));\n           break;\n+        case CUPTI_ACTIVITY_KIND_MARKER_DATA:\n+          AddMarkerDataActivityEvent(collector, static_cast<void*>(record));\n+          break;\n         default:\n           VLOG(3) << \"Activity type \" << record->kind << \" is not supported.\";\n           break;\n@@ -643,6 +673,8 @@ const char *GetTraceEventTypeName(const CuptiTracerEventType &type) {\n       return \"ThreadMarkerEnd\";\n     case CuptiTracerEventType::CudaGraphNodeMap:\n       return \"CudaGraphNodeMap\";\n+    case CuptiTracerEventType::MarkerData:\n+      return \"MarkerData\";\n     case CuptiTracerEventType::Unsupported:\n       return \"\";\n   }"
        },
        {
            "sha": "2a3db2f266bbd0beff7b1d246e5194a6292086d9",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_buffer_events.h",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_buffer_events.h?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -144,6 +144,10 @@ struct CudaGraphDetails {\n                                 // node is cloned.\n };\n \n+struct MarkerDataDetails {\n+  absl::string_view marker_string;\n+};\n+\n inline std::string ToXStat(const KernelDetails& kernel_info,\n                            double occupancy_pct) {\n   return absl::StrCat(\n@@ -180,6 +184,7 @@ enum class CuptiTracerEventType {\n   ThreadMarkerStart = 17,\n   ThreadMarkerEnd = 18,\n   CudaGraphNodeMap = 19,\n+  MarkerData = 20,\n   Generic = 100,\n };\n \n@@ -242,6 +247,8 @@ struct CuptiTracerEvent {\n     GenericDetails generic_info;\n     // Used for `source` DriverCallback, `type` must be CudaGraph.\n     CudaGraphDetails cuda_graph_info;\n+    // Used for `source` Activity, `type` must be ThreadMarkerRange.\n+    MarkerDataDetails marker_data_info;\n   };\n };\n "
        },
        {
            "sha": "c52d3af6c02fcd56dd28059a642a16af962d4be4",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_collector.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 1,
            "changes": 25,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_collector.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -355,6 +355,12 @@ class PerDeviceCollector {\n                               event.cuda_graph_info.orig_graph_id);\n         }\n       }\n+    } else if (event.type == CuptiTracerEventType::ThreadMarkerRange) {\n+      if (!event.marker_data_info.marker_string.empty()) {\n+        xevent.AddStatValue(*plane->GetOrCreateStatMetadata(\n+                                GetStatTypeStr(StatType::kMarkerPayloadString)),\n+                            event.marker_data_info.marker_string);\n+      }\n     }\n \n     std::vector<Annotation> annotation_stack =\n@@ -834,7 +840,8 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n       num_activity_events_++;\n     }\n     if (event.type == CuptiTracerEventType::ThreadMarkerStart ||\n-        event.type == CuptiTracerEventType::ThreadMarkerEnd) {\n+        event.type == CuptiTracerEventType::ThreadMarkerEnd ||\n+        event.type == CuptiTracerEventType::MarkerData) {\n       // Process the nvtx marker, merge thread range start/end if appropriate.\n       // If merged, the event will contains the merged content, and be used for\n       // followed AddEvent() processing.\n@@ -948,6 +955,8 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n       cuda_graph_node_id_map_;\n   // Map from graph_id to original graph_id\n   absl::flat_hash_map<uint32_t, uint32_t> cuda_graph_id_map_;\n+  // For marker data strings.\n+  StringDeduper string_deduper_;\n \n   // process the nvtx marker, a)cache range start event, or b)merge range end\n   // with its corresponding start event. If merged, the event be updated with\n@@ -957,6 +966,8 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n     auto it = nvtx_markers_.find(marker_id);\n     if (event.type == CuptiTracerEventType::ThreadMarkerStart) {\n       if (it == nvtx_markers_.end()) {\n+        // clear the marker data string.\n+        event.marker_data_info.marker_string = \"\";\n         nvtx_markers_[marker_id] =\n             std::make_unique<CuptiTracerEvent>(std::move(event));\n       } else {\n@@ -969,12 +980,24 @@ class CuptiTraceCollectorImpl : public CuptiTraceCollector {\n         it->second->end_time_ns = event.end_time_ns;\n         it->second->graph_id = 0;\n         event = std::move(*it->second);\n+        event.marker_data_info.marker_string =\n+            it->second->marker_data_info.marker_string;\n         nvtx_markers_.erase(it);\n         return true;  // The event is merged for further processing.\n       } else {\n         LOG_IF(ERROR, ++num_unmatched_nvtx_marker_end_ < 100)\n             << \"Unmatched nvtx thread range end marker id: \" << marker_id;\n       }\n+    } else if (event.type == CuptiTracerEventType::MarkerData) {\n+      if (it == nvtx_markers_.end()) {\n+        LOG_IF(ERROR, ++num_unmatched_nvtx_marker_end_ < 100)\n+            << \"Unmatched marker data for marker id: \" << marker_id;\n+      } else {\n+        if (!event.name.empty()) {\n+          it->second->marker_data_info.marker_string =\n+              string_deduper_.Dedup(event.name);\n+        }\n+      }\n     }\n     // No merged event is generated, return false.\n     return false;"
        },
        {
            "sha": "887b9e4dff80fe9fd76957f4f53bcb69fba9fea4",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_marker_data_parser.cc",
            "status": "added",
            "additions": 40,
            "deletions": 0,
            "changes": 40,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -0,0 +1,40 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/profiler/gpu/cupti_marker_data_parser.h\"\n+\n+#include <cstdint>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"third_party/gpus/cuda/extras/CUPTI/include/cupti_activity.h\"\n+\n+namespace xla {\n+namespace profiler {\n+\n+// For early version of cuda/cupti, where marker data is not fully supported,\n+// return nullopt for not including marker data.\n+std::optional<CUpti_ActivityKind> GetActivityMarkerDataKind() {\n+  return std::nullopt;\n+}\n+\n+std::optional<std::pair<std::string, uint32_t>> ParseMarkerDataActivity(\n+    void* marker_data_activity) {\n+  return std::nullopt;\n+}\n+\n+}  // namespace profiler\n+}  // namespace xla"
        },
        {
            "sha": "a7c86b6c86ae73ab605f650502c460e3cd3d1201",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_marker_data_parser.h",
            "status": "added",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser.h?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -0,0 +1,41 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_PROFILER_GPU_CUPTI_MARKER_DATA_PARSER_H_\n+#define XLA_BACKENDS_PROFILER_GPU_CUPTI_MARKER_DATA_PARSER_H_\n+\n+#include <cstdint>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"third_party/gpus/cuda/extras/CUPTI/include/cupti_activity.h\"\n+\n+namespace xla {\n+namespace profiler {\n+\n+// Returns the list of activity kinds for supported marker data kinds.\n+// Start supporting marker data from 13.0 with CUpti_ActivityMarkerData2.\n+// So before that, return empty list. The list will be used when starting\n+// cupti activity tracing.\n+std::optional<CUpti_ActivityKind> GetActivityMarkerDataKind();\n+\n+std::optional<std::pair<std::string, uint32_t>> ParseMarkerDataActivity(\n+    void* marker_data_activity);\n+\n+}  // namespace profiler\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_PROFILER_GPU_CUPTI_MARKER_DATA_PARSER_H_"
        },
        {
            "sha": "d2cb2d3e6efdf99d5a927847ac2337ba0f527e68",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_marker_data_parser_ext.cc",
            "status": "added",
            "additions": 63,
            "deletions": 0,
            "changes": 63,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser_ext.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser_ext.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_marker_data_parser_ext.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -0,0 +1,63 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <cstdlib>\n+#include <optional>\n+#include <string>\n+#include <utility>\n+\n+#include \"third_party/gpus/cuda/extras/CUPTI/include/cupti.h\"\n+#include \"third_party/gpus/cuda/include/nvtx3/nvToolsExtPayload.h\"\n+#include \"xla/backends/profiler/gpu/cupti_marker_data_parser.h\"\n+#include \"xla/backends/profiler/gpu/cupti_nvtx_ext_payload.h\"\n+\n+namespace xla {\n+namespace profiler {\n+\n+// For cuda version after 13.0. Return CUPTI_ACTIVITY_KIND_MARKER_DATA to\n+// indicate cupti activities should include it when starting tracing.\n+std::optional<CUpti_ActivityKind> GetActivityMarkerDataKind() {\n+  return CUPTI_ACTIVITY_KIND_MARKER_DATA;\n+}\n+\n+std::optional<std::pair<std::string, uint32_t>> ParseMarkerDataActivity(\n+    void* marker_data_activity) {\n+  auto* marker_data =\n+      static_cast<CUpti_ActivityMarkerData2*>(marker_data_activity);\n+  if (marker_data->payloadKind ==\n+      CUPTI_METRIC_VALUE_KIND_NVTX_EXTENDED_PAYLOAD) {\n+    uint64_t payloadAddress =\n+        marker_data->payload.metricValueNvtxExtendedPayload;\n+    auto* payload = reinterpret_cast<nvtxPayloadData_t*>(payloadAddress);\n+\n+    std::string result_str;\n+    CuptiParseNvtxPayload(marker_data->cuptiDomainId, payload, result_str);\n+\n+    // Free the payload memory allocated by CUPTI.\n+    if (payload != nullptr) {\n+      if (payload->payload != nullptr) {\n+        free(const_cast<void*>(payload->payload));\n+        payload->payload = nullptr;\n+      }\n+      free(payload);\n+    }\n+    return std::make_pair(std::move(result_str), marker_data->id);\n+  }\n+  return std::nullopt;\n+}\n+\n+}  // namespace profiler\n+}  // namespace xla"
        },
        {
            "sha": "43cd14b02feeeab0250c83d97a0467501098ad74",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_nvtx_ext_payload.cc",
            "status": "added",
            "additions": 675,
            "deletions": 0,
            "changes": 675,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -0,0 +1,675 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/profiler/gpu/cupti_nvtx_ext_payload.h\"\n+\n+#include <algorithm>\n+#include <atomic>\n+#include <cstddef>\n+#include <cstdint>\n+#include <cstdlib>\n+#include <limits>\n+#include <memory>\n+#include <string>\n+#include <utility>\n+#include <vector>\n+\n+#include \"absl/base/thread_annotations.h\"\n+#include \"absl/container/flat_hash_map.h\"\n+#include \"absl/log/log.h\"\n+#include \"absl/strings/str_cat.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"absl/synchronization/mutex.h\"\n+#include \"third_party/gpus/cuda/extras/CUPTI/include/cupti.h\"\n+#include \"third_party/gpus/cuda/include/nvtx3/nvToolsExt.h\"\n+#include \"third_party/gpus/cuda/include/nvtx3/nvToolsExtPayload.h\"\n+\n+extern \"C\" CUptiResult CUPTIAPI cuptiActivityGetNvtxExtPayloadAttr(\n+    uint32_t cupti_domain_id, uint64_t schema_id,\n+    CUpti_NvtxExtPayloadAttr* payload_attributes);\n+\n+extern \"C\" const nvtxPayloadEntryTypeInfo_t*\n+cuptiActivityGetNvtxExtPayloadEntryTypeInfo();\n+\n+namespace xla {\n+namespace profiler {\n+\n+namespace {\n+\n+// Define the size as unknown or invalid. For unknown size, dynamic automatic\n+// detection may be used to determine the size. Invalid size indicates\n+// the size is not applicable or not supported.\n+static constexpr size_t kSizeUnknown = 0;\n+static constexpr size_t kSizeInvalid = std::numeric_limits<size_t>::max();\n+\n+inline bool AreValidSizes(size_t a, size_t b) {\n+  return a != kSizeInvalid && b != kSizeInvalid;\n+}\n+\n+inline bool IsFixedSize(size_t a) {\n+  return a != kSizeUnknown && a != kSizeInvalid;\n+}\n+\n+inline bool AreFixedSizes(size_t a, size_t b) {\n+  return IsFixedSize(a) && IsFixedSize(b);\n+}\n+\n+inline const char* NullCStringToEmpty(const char* str) {\n+  return str ? str : \"\";\n+}\n+\n+// Define the attributes of NVTX payload schema or enum, which are similar to\n+// those maintained by NVTX and CUPTI.\n+struct NvtxPayloadAttributes {\n+  uint32_t payload_type = 0;  // CUPTI_NVTX_EXT_PAYLOAD_TYPE_ SCHEMA or ENUM\n+  uint32_t domain_id = 0;\n+  uint64_t schema_id = 0;\n+  std::string name = {};\n+\n+  bool IsEnum() const {\n+    return payload_type == CUPTI_NVTX_EXT_PAYLOAD_TYPE_ENUM;\n+  }\n+  bool IsSchema() const {\n+    return payload_type == CUPTI_NVTX_EXT_PAYLOAD_TYPE_SCHEMA;\n+  }\n+};\n+\n+struct NvtxSchemaEntry {\n+  uint64_t flags = 0;            // currently only 0 is supported\n+  uint64_t type = 0;             // predefined type or custom schema ID\n+  std::string name = {};         // name of field\n+  std::string description = {};  // description of field\n+  uint64_t extent = 0;           // string or array length or union selector\n+  uint64_t offset = 0;           // offset in the structure (in bytes)\n+};\n+\n+// Field of schema_type: NVTX_PAYLOAD_SCHEMA_TYPE_*, where * could be\n+// INVALID(0), STATIC, DYNAMIC, UNION, UNION_WITH_INTERNAL_SELECTOR.\n+// Currently only STATIC is supported.\n+struct NvtxPayloadSchema : public NvtxPayloadAttributes {\n+  uint64_t field_mask = 0;\n+  uint64_t schema_type = NVTX_PAYLOAD_SCHEMA_TYPE_INVALID;\n+  uint64_t flags = 0;\n+  uint64_t payload_static_size = 0;\n+  uint64_t pack_and_align = 0;\n+  std::vector<NvtxSchemaEntry> entries = {};\n+  std::atomic<bool> processed = false;\n+\n+  NvtxPayloadSchema(uint32_t domain_id, uint64_t schema_id,\n+                    nvtxPayloadSchemaAttr_t& schema_attr);\n+};\n+\n+struct NvtxEnumEntry {\n+  std::string name = {};\n+  uint64_t value = 0;\n+  int8_t is_flag = 0;\n+};\n+\n+struct NvtxPayloadEnum : public NvtxPayloadAttributes {\n+  uint64_t field_mask = 0;\n+  uint64_t size_of_enum = 0;\n+  std::vector<NvtxEnumEntry> entries = {};\n+\n+  NvtxPayloadEnum(uint32_t domain_id, uint64_t schema_id,\n+                  nvtxPayloadEnumAttr_t& enum_attr);\n+};\n+\n+// Maps schema IDs to the corresponding NVTX payload attributes in single\n+// domain.\n+class NvtxSchemaIdToSchema {\n+  absl::Mutex mutex_ = {};\n+  uint32_t domain_id_ ABSL_GUARDED_BY(mutex_) = 0;\n+  absl::flat_hash_map<uint64_t, std::unique_ptr<NvtxPayloadAttributes>> schemas_\n+      ABSL_GUARDED_BY(mutex_) = {};\n+\n+ public:\n+  explicit NvtxSchemaIdToSchema(uint32_t domain_id) : domain_id_(domain_id) {}\n+\n+  // Get the NVTX payload attributes for the given schema ID. If the schema is\n+  // not found, query CUPTI for the attributes.\n+  NvtxPayloadAttributes* GetNvtxPayloadAttributes(uint64_t schema_id);\n+};\n+\n+class NvtxDomainSchemas {\n+ public:\n+  // Get the per-domain NVTX payload schemas for given domain_id.\n+  static NvtxSchemaIdToSchema& ForDomain(uint32_t p_domain_id) {\n+    static NvtxDomainSchemas* singleton_instance = new NvtxDomainSchemas();\n+    return singleton_instance->GetNvtxDomainSchemas(p_domain_id);\n+  }\n+\n+ private:\n+  absl::Mutex mutex_ = {};\n+  // Maps domain IDs to the corresponding per-domain NVTX payload schemas, note\n+  // that it is pointer stable for the value type NvtxSchemaIdToSchema.\n+  absl::flat_hash_map<uint32_t, std::unique_ptr<NvtxSchemaIdToSchema>>\n+      all_domains_schemas_ ABSL_GUARDED_BY(mutex_) = {};\n+\n+  NvtxSchemaIdToSchema& GetNvtxDomainSchemas(uint32_t domain_id) {\n+    absl::MutexLock lock(mutex_);\n+    auto it = all_domains_schemas_.find(domain_id);\n+    if (it == all_domains_schemas_.end()) {\n+      it = all_domains_schemas_\n+               .insert({domain_id,\n+                        std::make_unique<NvtxSchemaIdToSchema>(domain_id)})\n+               .first;\n+    }\n+    return *(it->second);\n+  }\n+};\n+\n+NvtxPayloadSchema::NvtxPayloadSchema(uint32_t p_domain_id, uint64_t p_schema_id,\n+                                     nvtxPayloadSchemaAttr_t& schema_attr)\n+    : NvtxPayloadAttributes{CUPTI_NVTX_EXT_PAYLOAD_TYPE_SCHEMA, p_domain_id,\n+                            p_schema_id, NullCStringToEmpty(schema_attr.name)},\n+      field_mask(schema_attr.fieldMask),\n+      schema_type(schema_attr.type),\n+      flags(schema_attr.flags),\n+      payload_static_size(schema_attr.payloadStaticSize),\n+      pack_and_align(schema_attr.packAlign),\n+      processed(false) {\n+  // Populate the schema's entries from the CUPTI-provided array.\n+  this->entries.reserve(schema_attr.numEntries);\n+  for (size_t i = 0; i < schema_attr.numEntries; ++i) {\n+    const nvtxPayloadSchemaEntry_t& entry = schema_attr.entries[i];\n+    this->entries.push_back(\n+        NvtxSchemaEntry{entry.flags, entry.type, NullCStringToEmpty(entry.name),\n+                        NullCStringToEmpty(entry.description),\n+                        entry.arrayOrUnionDetail, entry.offset});\n+  }\n+  if (schema_attr.entries != nullptr) {\n+    // Free the CUPTI-allocated payload entries array if it was allocated.\n+    free(const_cast<void*>(static_cast<const void*>(schema_attr.entries)));\n+  }\n+  schema_attr.entries = nullptr;  // Make sure it is marked as released.\n+}\n+\n+NvtxPayloadEnum::NvtxPayloadEnum(uint32_t p_domain_id, uint64_t p_schema_id,\n+                                 nvtxPayloadEnumAttr_t& enum_attr)\n+    : NvtxPayloadAttributes{CUPTI_NVTX_EXT_PAYLOAD_TYPE_ENUM, p_domain_id,\n+                            p_schema_id, NullCStringToEmpty(enum_attr.name)},\n+      field_mask(enum_attr.fieldMask),\n+      size_of_enum(enum_attr.sizeOfEnum) {\n+  this->entries.reserve(enum_attr.numEntries);\n+  for (size_t i = 0; i < enum_attr.numEntries; ++i) {\n+    const nvtxPayloadEnum_t& entry = enum_attr.entries[i];\n+    this->entries.push_back(\n+        NvtxEnumEntry{entry.name, entry.value, entry.isFlag});\n+  }\n+  if (enum_attr.entries != nullptr) {\n+    // Free the CUPTI-allocated payload entries array if it was allocated.\n+    free(const_cast<void*>(static_cast<const void*>(enum_attr.entries)));\n+  }\n+  enum_attr.entries = nullptr;  // Make sure it is marked as released.\n+}\n+\n+NvtxPayloadAttributes* NvtxSchemaIdToSchema::GetNvtxPayloadAttributes(\n+    uint64_t schema_id) {\n+  absl::MutexLock lock(mutex_);\n+  auto schema = schemas_.find(schema_id);\n+  if (schema != schemas_.end()) {\n+    return schema->second.get();\n+  }\n+\n+  // If the schema is not found, query CUPTI for the attributes.\n+  CUpti_NvtxExtPayloadAttr cupti_payload_attrs = {0};\n+  CUptiResult result = cuptiActivityGetNvtxExtPayloadAttr(domain_id_, schema_id,\n+                                                          &cupti_payload_attrs);\n+  if (result != CUPTI_SUCCESS) {\n+    VLOG(1) << \"Could not get NVTX payload attributes from CUPTI for schema:\"\n+            << schema_id << \" in domain: \" << domain_id_;\n+    return nullptr;\n+  }\n+  if (cupti_payload_attrs.attributes == nullptr) {\n+    VLOG(1) << \"Payload schema/enum attribute is null from CUPTI for schema:\"\n+            << schema_id << \" in domain: \" << domain_id_;\n+    return nullptr;\n+  }\n+\n+  NvtxPayloadAttributes* attrs = nullptr;\n+  if (cupti_payload_attrs.type == CUPTI_NVTX_EXT_PAYLOAD_TYPE_SCHEMA) {\n+    auto [it, inserted] = schemas_.insert(\n+        {schema_id, std::make_unique<NvtxPayloadSchema>(\n+                        domain_id_, schema_id,\n+                        *reinterpret_cast<nvtxPayloadSchemaAttr_t*>(\n+                            cupti_payload_attrs.attributes))});\n+    attrs = it->second.get();\n+  } else if (cupti_payload_attrs.type == CUPTI_NVTX_EXT_PAYLOAD_TYPE_ENUM) {\n+    auto [it, inserted] = schemas_.insert(\n+        {schema_id, std::make_unique<NvtxPayloadEnum>(\n+                        domain_id_, schema_id,\n+                        *reinterpret_cast<nvtxPayloadEnumAttr_t*>(\n+                            cupti_payload_attrs.attributes))});\n+    attrs = it->second.get();\n+  }\n+  // Free the CUPTI-allocated payload attribute memory by above call to\n+  // cuptiActivityGetNvtxExtPayloadAttr().\n+  free(cupti_payload_attrs.attributes);\n+\n+  return attrs;\n+}\n+\n+struct PayloadSizeAndAlign {\n+  uint16_t size = 0;   // Size of the data type in bytes\n+  uint16_t align = 0;  // Alignment of the data type in bytes\n+};\n+\n+// Get the singleton instance of the predefined payload types from CUPTI.\n+const std::vector<PayloadSizeAndAlign>& PredefinedPayloadTypes() {\n+  static std::vector<PayloadSizeAndAlign>* predefined_types = []() {\n+    auto* global_data = new std::vector<PayloadSizeAndAlign>();\n+    // Query CUPTI for the NVTX payload entry type information.\n+    const nvtxPayloadEntryTypeInfo_t* payload_type_info =\n+        cuptiActivityGetNvtxExtPayloadEntryTypeInfo();\n+    if (payload_type_info == nullptr) {\n+      LOG(ERROR) << (\"Could not initialize NVTX predefined payload type!\");\n+      return global_data;\n+    }\n+\n+    // The first element in fact defines the length of the info array.\n+    global_data->reserve(payload_type_info->size);\n+    for (uint16_t i = 0; i < payload_type_info->size; ++i) {\n+      global_data->emplace_back(payload_type_info[i].size,\n+                                payload_type_info[i].align);\n+    }\n+    VLOG(9) << \"Initialized NVTX predefined payload type info with \"\n+            << global_data->size() << \" entries.\";\n+    return global_data;\n+  }();\n+  return *predefined_types;\n+}\n+\n+size_t GetSizeOfFixedSizeTypes(uint64_t type) {\n+  switch (type) {\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT16:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_BF16:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING_UTF16:\n+      return 2;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT32:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_TF32:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING_UTF32:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CATEGORY:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_COLOR_ARGB:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_TID_UINT32:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_PID_UINT32:\n+      return 4;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT64:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_TID_UINT64:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_PID_UINT64:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_SCOPE_ID:\n+      return 8;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT128:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT128:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT128:\n+      return 16;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_BYTE:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING_UTF8:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UNION_SELECTOR:\n+      return 1;\n+    default:\n+      return kSizeInvalid;\n+  }\n+}\n+\n+/**\n+ * @brief Returns the size (in bytes) of a predefined NVTX payload entry type.\n+ *\n+ * For standard NVTX types, size and alignment data is fetched from\n+ * g_nvtxData.nvtxPayloadDataTypes. For special cases (not in the standard\n+ * array), GetSizeOfFixedSizeTypes() is used. Handles special cases for\n+ * registered string handles and unknown types.\n+ *\n+ * @param type The NVTX payload entry type identifier.\n+ * @return The size in bytes of the type, or InvalidTypeSize (usually 0) if\n+ * unknown.\n+ */\n+size_t GetSizeOfPayloadPredefinedType(uint64_t type) {\n+  // If the type is within the range of the info array, use the global data\n+  // types vector.\n+  if (type < NVTX_PAYLOAD_ENTRY_TYPE_INFO_ARRAY_SIZE) {\n+    // Check if the type index is valid for the vector.\n+    if (type >= PredefinedPayloadTypes().size()) {\n+      VLOG(1) << \"NVTX payload entry type:\" << type\n+              << \" is not found among pre-defined payload types.\";\n+      return kSizeInvalid;\n+    }\n+    return PredefinedPayloadTypes()[type].size;\n+  }\n+  if (type < NVTX_PAYLOAD_ENTRY_TYPE_NVTX_REGISTERED_STRING_HANDLE) {\n+    // If the type is not in the info array, but is less than the string handle\n+    // type, use the fixed size types.\n+    return GetSizeOfFixedSizeTypes(type);\n+  }\n+  if (type == NVTX_PAYLOAD_ENTRY_TYPE_NVTX_REGISTERED_STRING_HANDLE &&\n+      NVTX_PAYLOAD_ENTRY_TYPE_ADDRESS < PredefinedPayloadTypes().size()) {\n+    // If the type is the registered string handle, use the address type's size.\n+    return PredefinedPayloadTypes()[NVTX_PAYLOAD_ENTRY_TYPE_ADDRESS].size;\n+  }\n+  return kSizeInvalid;\n+}\n+\n+size_t AlignTo(size_t offset, size_t type_size, size_t alignment) {\n+  // The entry_offset is treated as a pointer for alignment calculation.\n+  void* addr_to_align = reinterpret_cast<void*>(offset);\n+\n+  // The buffer size is not known, so use SIZE_MAX as a placeholder.\n+  size_t sz = SIZE_MAX;\n+\n+  // Use std::align to compute the next aligned address.\n+  // NOTE: This requires C++17 or later.\n+  void* aligned_addr = std::align(alignment, type_size, addr_to_align, sz);\n+  return aligned_addr ? reinterpret_cast<size_t>(aligned_addr) : offset;\n+}\n+\n+// Align the entry. entry_size and entry_align are valid size. If manual_offset\n+// is not zero, it must be less than orig_offset, otherwise the entry will be\n+// used as the starting offset of the entry. If manual_offset is zero, the\n+// orig_offset will be aligned to the next multiple of entry_align. Note that\n+// when entry_idx is zero, manual offset should be set to zero.\n+// Returns false if the manual_offset is not valid, otherwise true.\n+bool AlignEntryOffset(size_t& orig_offset, size_t manual_offset,\n+                      size_t entry_size, size_t entry_align, size_t entry_idx) {\n+  if (manual_offset != 0 && manual_offset < orig_offset) {\n+    return false;\n+  }\n+  orig_offset = manual_offset ? manual_offset\n+                              : AlignTo(orig_offset, entry_size, entry_align);\n+  return true;\n+}\n+\n+// Declare in advance for recursion with UpdateSizeAndAlignForSchema().\n+std::pair<size_t, size_t> GetSizeAndAlign(NvtxSchemaIdToSchema& domain_schemas,\n+                                          const NvtxSchemaEntry& entry,\n+                                          int depth);\n+\n+void UpdateSizeAndAlignForSchema(NvtxSchemaIdToSchema& domain_schemas,\n+                                 NvtxPayloadSchema& schema, int depth) {\n+  if (schema.processed) {\n+    return;\n+  }\n+  if (schema.schema_type != NVTX_PAYLOAD_SCHEMA_TYPE_STATIC) {\n+    schema.payload_static_size = kSizeInvalid;\n+  } else if (AreValidSizes(schema.pack_and_align, schema.payload_static_size)) {\n+    // Calculate size and alignment for the schema by iterating through its\n+    // entries. Verify or update the size and alignment of the whole schema.\n+    // It may recursively update for nested schemas.\n+    size_t schema_size = 0LL, schema_align = 0LL, entry_idx = 0LL;\n+    for (const NvtxSchemaEntry& entry : schema.entries) {\n+      auto [entry_size, entry_align] =\n+          GetSizeAndAlign(domain_schemas, entry, depth + 1);\n+\n+      if (!AreFixedSizes(entry_size, entry_align) ||\n+          !AlignEntryOffset(schema_size, entry_idx ? entry.offset : 0,\n+                            entry_size, entry_align, entry_idx)) {\n+        schema.pack_and_align = kSizeInvalid;\n+        schema.payload_static_size = kSizeInvalid;\n+        break;\n+      }\n+      entry_idx++;\n+\n+      // Increasing size and update alignment\n+      schema_size += entry_size;\n+      schema_align = std::max(schema_align, entry_align);\n+    }\n+    if (schema.pack_and_align == kSizeUnknown) {\n+      schema.pack_and_align = schema_align;\n+    }\n+    if (schema.payload_static_size == kSizeUnknown) {\n+      schema.payload_static_size = schema_size;\n+    } else if (schema.payload_static_size < schema_size) {\n+      schema.payload_static_size = kSizeInvalid;\n+    }\n+  }\n+  schema.processed = true;\n+}\n+\n+std::pair<size_t, size_t> GetSizeAndAlign(NvtxSchemaIdToSchema& domain_schemas,\n+                                          const NvtxSchemaEntry& entry,\n+                                          int depth = 0) {\n+  if (entry.flags != 0) {  // No support for flags other than zero.\n+    return {kSizeInvalid, kSizeInvalid};\n+  }\n+  // Limit depth of nested schemas, also avoid circular reference.\n+  if (depth > 5) {\n+    VLOG(1) << \"NVTX payload schema nested too deeply\";\n+    return {kSizeInvalid, kSizeInvalid};\n+  }\n+\n+  if (entry.type < NVTX_PAYLOAD_SCHEMA_ID_STATIC_START) {\n+    size_t type_size = GetSizeOfPayloadPredefinedType(entry.type);\n+    // Handle fixed size strings.\n+    bool use_extent = (type_size != kSizeInvalid &&\n+                       entry.type >= NVTX_PAYLOAD_ENTRY_TYPE_CSTRING &&\n+                       entry.type <= NVTX_PAYLOAD_ENTRY_TYPE_CSTRING_UTF32);\n+    return {type_size * (use_extent ? entry.extent : 1), type_size};\n+  }\n+\n+  if (NvtxPayloadAttributes* payload_attributes =\n+          domain_schemas.GetNvtxPayloadAttributes(entry.type);\n+      payload_attributes != nullptr) {\n+    if (payload_attributes->IsEnum()) {\n+      auto& payload_enum = *static_cast<NvtxPayloadEnum*>(payload_attributes);\n+      return {payload_enum.size_of_enum, payload_enum.size_of_enum};\n+    }\n+    if (payload_attributes->IsSchema()) {\n+      auto& schema = *static_cast<NvtxPayloadSchema*>(payload_attributes);\n+      UpdateSizeAndAlignForSchema(domain_schemas, schema, depth);\n+      return {schema.payload_static_size, schema.pack_and_align};\n+    }\n+  }\n+  return {kSizeInvalid, kSizeInvalid};\n+}\n+\n+template <typename T>\n+T ValueOf(const char* payload_data) {\n+  return *reinterpret_cast<const T*>(payload_data);\n+}\n+\n+void ParseValueOfPredefinedType(const NvtxSchemaEntry& entry,\n+                                const char* payload_base, std::string& output) {\n+  switch (entry.type) {\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CHAR:\n+      absl::StrAppend(&output, absl::string_view(payload_base, 1));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UCHAR:\n+      absl::StrAppend(&output, ValueOf<unsigned char>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_SHORT:\n+      absl::StrAppend(&output, ValueOf<int16_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_USHORT:\n+      absl::StrAppend(&output, ValueOf<uint16_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT:\n+      absl::StrAppend(&output, ValueOf<int>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT:\n+      absl::StrAppend(&output, ValueOf<unsigned int>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_LONG:\n+      absl::StrAppend(&output, ValueOf<int32_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_ULONG:\n+      absl::StrAppend(&output, ValueOf<uint32_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_LONGLONG:\n+      absl::StrAppend(&output, ValueOf<int64_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_ULONGLONG:\n+      absl::StrAppend(&output, ValueOf<uint64_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT8:\n+      absl::StrAppend(&output, ValueOf<int8_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT8:\n+      absl::StrAppend(&output, ValueOf<uint8_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT16:\n+      absl::StrAppend(&output, ValueOf<int16_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT16:\n+      absl::StrAppend(&output, ValueOf<uint16_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT32:\n+      absl::StrAppend(&output, ValueOf<int32_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT32:\n+      absl::StrAppend(&output, ValueOf<uint32_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_INT64:\n+      absl::StrAppend(&output, ValueOf<int64_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_UINT64:\n+      absl::StrAppend(&output, ValueOf<uint64_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT:\n+      absl::StrAppend(&output, ValueOf<float>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_DOUBLE:\n+      absl::StrAppend(&output, ValueOf<double>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_LONGDOUBLE:\n+      absl::StrAppend(&output,\n+                      std::to_string(ValueOf<long double>(payload_base)));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_SIZE:\n+      absl::StrAppend(&output, ValueOf<size_t>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT32:\n+      absl::StrAppend(&output, ValueOf<float>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_FLOAT64:\n+      absl::StrAppend(&output, ValueOf<double>(payload_base));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_ADDRESS:\n+      absl::StrAppend(&output, absl::Hex(ValueOf<void*>(payload_base)));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING:\n+    case NVTX_PAYLOAD_ENTRY_TYPE_CSTRING_UTF8:\n+      absl::StrAppend(&output, absl::string_view(payload_base, entry.extent));\n+      break;\n+    case NVTX_PAYLOAD_ENTRY_TYPE_BYTE:\n+      absl::StrAppend(&output, absl::Hex(ValueOf<unsigned char>(payload_base)));\n+      break;\n+    default:\n+      VLOG(3) << \"NVTX payload schema entry type \" << entry.type\n+              << \" is not supported as a predefined type.\";\n+      break;\n+  }\n+}\n+\n+size_t ParseValueOfPayloadEnum(const NvtxPayloadEnum* enum_attrs,\n+                               const char* payload_base, std::string& output) {\n+  auto size_of_enum = enum_attrs->size_of_enum;\n+  if (size_of_enum == 8 || size_of_enum == 4) {\n+    uint64_t enum_value =\n+        size_of_enum == 8\n+            ? *reinterpret_cast<const uint64_t*>(payload_base)\n+            : static_cast<uint64_t>(\n+                  *reinterpret_cast<const uint32_t*>(payload_base));\n+    for (const NvtxEnumEntry& entry : enum_attrs->entries) {\n+      if (entry.value == enum_value) {\n+        absl::StrAppend(&output, entry.name, \"(\", enum_value, \")\");\n+        return size_of_enum;\n+      }\n+    }\n+    absl::StrAppend(&output, \"UNKNOWN_ENUM_VALUE(\", enum_value, \")\");\n+  }\n+  return size_of_enum;\n+}\n+\n+size_t ParseNvtxExtPayloadEntry(NvtxSchemaIdToSchema& domain_schemas,\n+                                const NvtxSchemaEntry& entry,\n+                                const char* payload_base, uint64_t payload_size,\n+                                std::string& result_str, int depth) {\n+  auto [entry_size, entry_align] =\n+      GetSizeAndAlign(domain_schemas, entry, depth);\n+  if (!AreFixedSizes(entry_size, entry_align)) {\n+    return kSizeInvalid;\n+  }\n+  if (payload_size < entry_size) {\n+    VLOG(1) << \"NVTX payload size \" << payload_size << \" < entry size \"\n+            << entry_size << \" for entry \" << entry.name << \" (\" << entry.type\n+            << \")\";\n+    return kSizeInvalid;\n+  }\n+\n+  if (!entry.name.empty()) {\n+    absl::StrAppend(&result_str, entry.name, \" : \");\n+  }\n+\n+  if (entry.type < NVTX_PAYLOAD_SCHEMA_ID_STATIC_START) {\n+    ParseValueOfPredefinedType(entry, payload_base, result_str);\n+    return entry_size;\n+  }\n+\n+  NvtxPayloadAttributes* payload_attributes =\n+      domain_schemas.GetNvtxPayloadAttributes(entry.type);\n+  if (payload_attributes == nullptr) {\n+    return kSizeInvalid;\n+  }\n+\n+  if (payload_attributes->IsEnum()) {\n+    auto& payload_enum = *static_cast<NvtxPayloadEnum*>(payload_attributes);\n+    ParseValueOfPayloadEnum(&payload_enum, payload_base, result_str);\n+    return entry_size;\n+  }\n+\n+  if (payload_attributes->IsSchema()) {\n+    auto& schema = *static_cast<NvtxPayloadSchema*>(payload_attributes);\n+    size_t entry_offset = 0, entry_idx = 0;\n+    absl::StrAppend(&result_str, depth ? \"{\" : \"\");\n+    for (const NvtxSchemaEntry& entry : schema.entries) {\n+      auto [entry_size, entry_align] = GetSizeAndAlign(domain_schemas, entry);\n+      // Align the entry_offset.\n+      if (!AreFixedSizes(entry_size, entry_align) ||\n+          !AlignEntryOffset(entry_offset, entry_idx ? entry.offset : 0,\n+                            entry_size, entry_align, entry_idx) ||\n+          entry_offset > payload_size) {\n+        return kSizeInvalid;\n+      }\n+      if (entry_idx) {\n+        absl::StrAppend(&result_str, \", \");\n+      }\n+      ParseNvtxExtPayloadEntry(\n+          domain_schemas, entry, payload_base + entry_offset,\n+          payload_size - entry_offset, result_str, depth + 1);\n+\n+      entry_offset += entry_size;\n+      entry_idx++;\n+    }\n+    absl::StrAppend(&result_str, depth ? \"}\" : \"\");\n+  }\n+  return entry_size;\n+}\n+\n+}  // namespace\n+\n+void CuptiParseNvtxPayload(uint32_t cupti_domain_id,\n+                           nvtxPayloadData_t* payload_data,\n+                           std::string& result_str) {\n+  if (payload_data != nullptr && payload_data->payload != nullptr &&\n+      payload_data->size > 0) {\n+    ParseNvtxExtPayloadEntry(\n+        NvtxDomainSchemas::ForDomain(cupti_domain_id),\n+        NvtxSchemaEntry{.type = payload_data->schemaId, .name = \"\"},\n+        reinterpret_cast<const char*>(payload_data->payload),\n+        payload_data->size, result_str, /*depth=*/0);\n+  }\n+}\n+\n+}  // namespace profiler\n+}  // namespace xla"
        },
        {
            "sha": "f17d9762b262d812cccc08f4f29a6936e768ef7d",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_nvtx_ext_payload.h",
            "status": "added",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_nvtx_ext_payload.h?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -0,0 +1,34 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_PROFILER_GPU_CUPTI_NVTX_EXT_PAYLOAD_H_\n+#define XLA_BACKENDS_PROFILER_GPU_CUPTI_NVTX_EXT_PAYLOAD_H_\n+\n+#include <cstdint>\n+#include <string>\n+\n+#include \"third_party/gpus/cuda/include/nvtx3/nvToolsExtPayload.h\"\n+\n+namespace xla {\n+namespace profiler {\n+\n+void CuptiParseNvtxPayload(uint32_t cupti_domain_id,\n+                           nvtxPayloadData_t* payload_data,\n+                           std::string& result_str);\n+\n+}  // namespace profiler\n+}  // namespace xla\n+\n+#endif  // XLA_BACKENDS_PROFILER_GPU_CUPTI_NVTX_EXT_PAYLOAD_H_"
        },
        {
            "sha": "61d0d939d7551b882ad1b448a014416ca28b9dce",
            "filename": "third_party/xla/xla/backends/profiler/gpu/cupti_tracer.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 4,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fprofiler%2Fgpu%2Fcupti_tracer.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include <utility>\n #include <vector>\n \n+#include \"absl/algorithm/container.h\"\n #include \"absl/base/optimization.h\"\n #include \"absl/cleanup/cleanup.h\"\n #include \"absl/container/flat_hash_map.h\"\n@@ -49,6 +50,7 @@ limitations under the License.\n #include \"xla/backends/profiler/gpu/cupti_buffer_events.h\"\n #include \"xla/backends/profiler/gpu/cupti_collector.h\"\n #include \"xla/backends/profiler/gpu/cupti_interface.h\"\n+#include \"xla/backends/profiler/gpu/cupti_marker_data_parser.h\"\n #include \"xla/backends/profiler/gpu/cupti_pm_sampler.h\"\n #include \"xla/backends/profiler/gpu/cupti_pm_sampler_factory.h\"\n #include \"xla/backends/profiler/gpu/cupti_utils.h\"\n@@ -1088,14 +1090,18 @@ absl::Status CuptiTracer::Enable(\n   if (option_->enable_nvtx_tracking) {\n     VLOG(1) << \"NVTX tracking Enabled.\";\n     std::vector<CUpti_ActivityKind>& activities = option_->activities_selected;\n-    if (std::find(activities.begin(), activities.end(),\n-                  CUPTI_ACTIVITY_KIND_MARKER) == activities.end()) {\n+    if (!absl::c_contains(activities, CUPTI_ACTIVITY_KIND_MARKER)) {\n       VLOG(1) << \"Adding CUPTI_ACTIVITY_KIND_MARKER to activities:\"\n               << (int)CUPTI_ACTIVITY_KIND_MARKER;\n       activities.push_back(CUPTI_ACTIVITY_KIND_MARKER);\n     }\n-    // TODO: Add CUPTI_ACTIVITY_KIND_MARKER_DATA to activities after cupti\n-    // more detailed data could be provided by cupti.\n+    // If marker data is supported, add it to activities.\n+    if (GetActivityMarkerDataKind().has_value() &&\n+        !absl::c_contains(activities, CUPTI_ACTIVITY_KIND_MARKER_DATA)) {\n+      VLOG(1) << \"Adding CUPTI_ACTIVITY_KIND_MARKER_DATA to activities:\"\n+              << (int)CUPTI_ACTIVITY_KIND_MARKER_DATA;\n+      activities.push_back(GetActivityMarkerDataKind().value());\n+    }\n   }\n \n   cupti_driver_api_hook_ = std::make_unique<CuptiDriverApiHookWithActivityApi>("
        },
        {
            "sha": "ecf6acd684bb815e7f7c2fa25db3e330805abfc8",
            "filename": "third_party/xla/xla/tsl/profiler/utils/xplane_schema.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.cc?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -384,7 +384,8 @@ const StatTypeMap& GetStatTypeMap() {\n        {\"cuda_graph_map_id\", kCudaGraphMapId},\n        {\"cuda_graph_map_value_id\", kCudaGraphMapValueId},\n        {\"cuda_graph_node_map_id\", kCudaGraphNodeMapId},\n-       {\"graph_metadata_line_id\", kGraphMetadataLineId}});\n+       {\"graph_metadata_line_id\", kGraphMetadataLineId},\n+       {\"marker_payload\", kMarkerPayloadString}});\n   DCHECK_EQ(stat_type_map->size(), kNumStatTypes);\n   return *stat_type_map;\n }"
        },
        {
            "sha": "0204c8d0915848a87c4570303057e619b39f4c1b",
            "filename": "third_party/xla/xla/tsl/profiler/utils/xplane_schema.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/cebf9c003f71840fedcf6d62192a40aeb50d036b/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftsl%2Fprofiler%2Futils%2Fxplane_schema.h?ref=cebf9c003f71840fedcf6d62192a40aeb50d036b",
            "patch": "@@ -372,7 +372,8 @@ enum StatType {\n   kCudaGraphMapValueId,\n   kCudaGraphNodeMapId,\n   kGraphMetadataLineId,\n-  kLastStatType = kGraphMetadataLineId,\n+  kMarkerPayloadString,\n+  kLastStatType = kMarkerPayloadString,\n };\n \n enum MegaScaleStatType : uint8_t {"
        }
    ],
    "stats": {
        "total": 998,
        "additions": 991,
        "deletions": 7
    }
}