{
    "author": "bixia1",
    "message": "Add `kDotDependent` to `DimensionInfo`, to indicate a DOT operation can reach the operands of the operation through def-use chains.\n\nExtend `HloDimensionAnalysis` to collect such information.\n\nPiperOrigin-RevId: 831468081",
    "sha": "6ee9872872dd71cb50dfca6255089cf7e9553a8f",
    "files": [
        {
            "sha": "5a49c3f5af13adbd58c079da4c023080d0c4bdc7",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis.cc",
            "status": "modified",
            "additions": 113,
            "deletions": 42,
            "changes": 155,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.cc?ref=6ee9872872dd71cb50dfca6255089cf7e9553a8f",
            "patch": "@@ -35,14 +35,24 @@ limitations under the License.\n #include \"xla/hlo/ir/hlo_computation.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n #include \"xla/shape_tree.h\"\n #include \"xla/shape_util.h\"\n #include \"xla/tsl/platform/errors.h\"\n \n namespace xla {\n \n-bool HloDimensionAnalysis::IsInstructionWeight(\n-    const HloInstruction* instruction) const {\n+static void ClearDotDependent(ShapeTree<DimensionInfo>& dimension_info_tree) {\n+  dimension_info_tree.ForEachMutableElement(\n+      [&](const ShapeIndex& index, DimensionInfo* dimension_info) {\n+        if (dimension_info_tree.IsLeaf(index) &&\n+            *dimension_info == DimensionInfo::kDotDependent) {\n+          *dimension_info = DimensionInfo::kUnknown;\n+        }\n+      });\n+}\n+\n+bool HloDimensionAnalysis::IsWeight(const HloInstruction* instruction) const {\n   auto it = info_map_.find(instruction);\n   if (it == info_map_.end()) {\n     return false;\n@@ -53,6 +63,31 @@ bool HloDimensionAnalysis::IsInstructionWeight(\n                         });\n }\n \n+bool HloDimensionAnalysis::IsDotDependent(\n+    const HloInstruction* instruction) const {\n+  auto it = info_map_.find(instruction);\n+  if (it == info_map_.end()) {\n+    return false;\n+  }\n+  return absl::c_any_of(it->second.leaves(),\n+                        [](const std::pair<ShapeIndex, DimensionInfo>& leaf) {\n+                          return leaf.second == DimensionInfo::kDotDependent;\n+                        });\n+}\n+\n+bool HloDimensionAnalysis::IsKnownDimensionInfo(\n+    const HloInstruction* instruction) const {\n+  auto it = info_map_.find(instruction);\n+  if (it == info_map_.end()) {\n+    return false;\n+  }\n+  return absl::c_any_of(it->second.leaves(),\n+                        [](const std::pair<ShapeIndex, DimensionInfo>& leaf) {\n+                          return leaf.second == DimensionInfo::kWeight ||\n+                                 leaf.second == DimensionInfo::kDotDependent;\n+                        });\n+}\n+\n std::optional<ShapeTree<DimensionInfo>> HloDimensionAnalysis::GetDimensionInfo(\n     const HloInstruction* instruction) const {\n   auto it = info_map_.find(instruction);\n@@ -62,25 +97,29 @@ std::optional<ShapeTree<DimensionInfo>> HloDimensionAnalysis::GetDimensionInfo(\n   return it->second;\n }\n \n-absl::Status HloDimensionAnalysis::SetInstructionAsWeight(\n-    HloInstruction* instruction) {\n+absl::Status HloDimensionAnalysis::SetDimensionInfo(\n+    const HloInstruction* instruction, DimensionInfo value) {\n+  CHECK(value == DimensionInfo::kWeight ||\n+        value == DimensionInfo::kDotDependent)\n+      << \"Unsupported dimension info: \" << value;\n   auto [it, success] = info_map_.emplace(\n       std::piecewise_construct, std::forward_as_tuple(instruction),\n       std::forward_as_tuple(instruction->shape(), DimensionInfo::kUnknown));\n \n   if (!success) {\n-    return absl::InternalError(absl::StrCat(\n-        \"Instruction \", instruction->ToString(), \" already has weight info.\"));\n+    return absl::InternalError(absl::StrCat(\"Instruction \",\n+                                            instruction->ToString(),\n+                                            \" already has dimension info.\"));\n   }\n \n   ShapeTree<DimensionInfo>& dim_info_tree = it->second;\n   dim_info_tree.ForEachMutableElement(\n-      [&](const ShapeIndex& index, DimensionInfo* operation_info) {\n+      [&](const ShapeIndex& index, DimensionInfo* dimension_info) {\n         if (dim_info_tree.IsLeaf(index)) {\n-          *operation_info = DimensionInfo::kWeight;\n+          *dimension_info = value;\n           return;\n         }\n-        *operation_info = DimensionInfo::kTuple;\n+        *dimension_info = DimensionInfo::kUnknown;\n       });\n   return absl::OkStatus();\n }\n@@ -90,7 +129,7 @@ absl::Status HloDimensionAnalysis::SetDimensionInfo(\n   auto [it, success] = info_map_.emplace(target, std::move(annotation));\n   if (!success) {\n     return absl::InternalError(absl::StrCat(\"Instruction \", target->ToString(),\n-                                            \" already has dimensioin info.\"));\n+                                            \" already has dimension info.\"));\n   }\n   return absl::OkStatus();\n }\n@@ -101,11 +140,20 @@ absl::Status HloDimensionAnalysis::AnnotateEntryComputationParameters(\n   const auto& params = module.entry_computation()->parameter_instructions();\n   info_map_.reserve(params.size());\n   for (HloInstruction* instruction : params) {\n-    TF_RETURN_IF_ERROR(SetInstructionAsWeight(instruction));\n+    TF_RETURN_IF_ERROR(SetDimensionInfo(instruction, DimensionInfo::kWeight));\n   }\n   return absl::OkStatus();\n }\n \n+bool HloDimensionAnalysis::IsDotOrHasDotDependent(\n+    const HloInstruction* op) const {\n+  if (HloPredicateIsOp<HloOpcode::kDot, HloOpcode::kConvolution,\n+                       HloOpcode::kRaggedDot>(op)) {\n+    return true;\n+  }\n+  return IsDotDependent(op);\n+}\n+\n absl::StatusOr<std::unique_ptr<HloDimensionAnalysis>> HloDimensionAnalysis::Run(\n     const HloModule& module,\n     const absl::flat_hash_set<absl::string_view>& execution_threads) {\n@@ -131,12 +179,13 @@ absl::Status HloDimensionAnalysis::RunOnComputation(\n     absl::Span<const HloInstruction* const> operands) {\n   CHECK_EQ(computation.num_parameters(), operands.size());\n   for (int i = 0; i < computation.num_parameters(); ++i) {\n-    auto operation_info_iter = info_map_.find(operands[i]);\n-    if (operation_info_iter == info_map_.end()) {\n+    auto dimension_info_iter = info_map_.find(operands[i]);\n+    if (dimension_info_iter == info_map_.end()) {\n       continue;\n     }\n+    ClearDotDependent(dimension_info_iter->second);\n     TF_RETURN_IF_ERROR(SetDimensionInfo(computation.parameter_instructions()[i],\n-                                        operation_info_iter->second));\n+                                        dimension_info_iter->second));\n   }\n   return RunOnComputation(computation);\n }\n@@ -152,31 +201,42 @@ absl::Status HloDimensionInfoPropagation::Run(\n   return absl::OkStatus();\n }\n \n-absl::Status HloDimensionInfoPropagation::DefaultAction(\n-    HloInstruction* instruction) {\n-  return absl::OkStatus();\n-}\n-\n #define RETURN_IF_ALREADY_PROPAGATED(instruction) \\\n   if (analysis_->HasDimensionInfo(instruction)) { \\\n     return absl::OkStatus();                      \\\n   }\n \n+absl::Status HloDimensionInfoPropagation::DefaultAction(\n+    HloInstruction* instruction) {\n+  RETURN_IF_ALREADY_PROPAGATED(instruction);\n+  // For non-weight, we want to find out whether the instruction has a\n+  // dot-dependent operand.\n+  for (const HloInstruction* operand : instruction->operands()) {\n+    if (analysis_->IsDotOrHasDotDependent(operand)) {\n+      TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n+          instruction, ShapeTree<DimensionInfo>(instruction->shape(),\n+                                                DimensionInfo::kDotDependent)));\n+      break;\n+    }\n+  }\n+  return absl::OkStatus();\n+}\n+\n absl::Status HloDimensionInfoPropagation::HandleTuple(HloInstruction* tuple) {\n   RETURN_IF_ALREADY_PROPAGATED(tuple);\n-  bool has_operation_info = false;\n+  bool has_dim_info = false;\n   ShapeTree<DimensionInfo> dim_info_tree(tuple->shape(),\n                                          DimensionInfo::kUnknown);\n   for (int64_t idx = 0; idx < tuple->operand_count(); ++idx) {\n     const HloInstruction* operand = tuple->operand(idx);\n-    if (analysis_->IsInstructionWeight(operand)) {\n+    if (analysis_->IsKnownDimensionInfo(operand)) {\n       dim_info_tree.CopySubtreeFrom(*analysis_->GetDimensionInfo(operand), {},\n                                     {idx});\n-      has_operation_info = true;\n+      has_dim_info = true;\n     }\n   }\n \n-  if (has_operation_info) {\n+  if (has_dim_info) {\n     TF_RETURN_IF_ERROR(\n         analysis_->SetDimensionInfo(tuple, std::move(dim_info_tree)));\n   }\n@@ -188,13 +248,13 @@ absl::Status HloDimensionInfoPropagation::HandleGetTupleElement(\n     HloInstruction* get_tuple_element) {\n   RETURN_IF_ALREADY_PROPAGATED(get_tuple_element);\n   const HloInstruction* operand = get_tuple_element->operand(0);\n-  if (analysis_->IsInstructionWeight(operand)) {\n-    ShapeTree<DimensionInfo> dim_info_tree(get_tuple_element->shape(),\n-                                           DimensionInfo::kUnknown);\n-    dim_info_tree.CopySubtreeFrom(*analysis_->GetDimensionInfo(operand),\n-                                  {get_tuple_element->tuple_index()}, {});\n+  if (analysis_->IsKnownDimensionInfo(operand)) {\n+    ShapeTree<DimensionInfo> dimension_info(get_tuple_element->shape(),\n+                                            DimensionInfo::kUnknown);\n+    dimension_info.CopySubtreeFrom(*analysis_->GetDimensionInfo(operand),\n+                                   {get_tuple_element->tuple_index()}, {});\n     TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(get_tuple_element,\n-                                                   std::move(dim_info_tree)));\n+                                                   std::move(dimension_info)));\n   }\n   return absl::OkStatus();\n }\n@@ -204,9 +264,11 @@ absl::Status HloDimensionInfoPropagation::HandleCall(HloInstruction* call) {\n   HloComputation* computation = call->called_computations()[0];\n   TF_RETURN_IF_ERROR(\n       analysis_->RunOnComputation(*computation, call->operands()));\n-  if (analysis_->IsInstructionWeight(computation->root_instruction())) {\n-    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n-        call, *analysis_->GetDimensionInfo(computation->root_instruction())));\n+  if (analysis_->IsWeight(computation->root_instruction())) {\n+    ShapeTree<DimensionInfo> dimension_info_tree =\n+        *analysis_->GetDimensionInfo(computation->root_instruction());\n+    ClearDotDependent(dimension_info_tree);\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(call, dimension_info_tree));\n   }\n   return absl::OkStatus();\n }\n@@ -219,10 +281,12 @@ absl::Status HloDimensionInfoPropagation::HandleWhile(\n   HloComputation* computation = xla_while->while_body();\n   TF_RETURN_IF_ERROR(\n       analysis_->RunOnComputation(*computation, xla_while->operands()));\n-  if (analysis_->IsInstructionWeight(computation->root_instruction())) {\n-    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n-        xla_while,\n-        *analysis_->GetDimensionInfo(computation->root_instruction())));\n+  if (analysis_->IsWeight(computation->root_instruction())) {\n+    ShapeTree<DimensionInfo> dimension_info_tree =\n+        *analysis_->GetDimensionInfo(computation->root_instruction());\n+    ClearDotDependent(dimension_info_tree);\n+    TF_RETURN_IF_ERROR(\n+        analysis_->SetDimensionInfo(xla_while, dimension_info_tree));\n   }\n   return absl::OkStatus();\n }\n@@ -232,8 +296,11 @@ absl::Status HloDimensionInfoPropagation::HandleWhile(\n absl::Status HloDimensionInfoPropagation::HandleSimpleOp(HloInstruction* op) {\n   RETURN_IF_ALREADY_PROPAGATED(op);\n   const HloInstruction* operand = op->operand(0);\n-  if (analysis_->IsInstructionWeight(operand)) {\n-    TF_RETURN_IF_ERROR(analysis_->SetInstructionAsWeight(op));\n+  if (analysis_->IsWeight(operand)) {\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(op, DimensionInfo::kWeight));\n+  } else if (analysis_->IsDotOrHasDotDependent(operand)) {\n+    TF_RETURN_IF_ERROR(\n+        analysis_->SetDimensionInfo(op, DimensionInfo::kDotDependent));\n   }\n   return absl::OkStatus();\n }\n@@ -250,9 +317,13 @@ absl::Status HloDimensionInfoPropagation::HandleDynamicUpdateSlice(\n   // be a weight.\n   const HloInstruction* operand = dynamic_update_slice->operand(0);\n   const HloInstruction* update = dynamic_update_slice->operand(1);\n-  if (analysis_->IsInstructionWeight(operand) ||\n-      analysis_->IsInstructionWeight(update)) {\n-    TF_RETURN_IF_ERROR(analysis_->SetInstructionAsWeight(dynamic_update_slice));\n+  if (analysis_->IsWeight(operand) || analysis_->IsWeight(update)) {\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(dynamic_update_slice,\n+                                                   DimensionInfo::kWeight));\n+  } else if (analysis_->IsDotDependent(operand) ||\n+             analysis_->IsDotDependent(update)) {\n+    TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n+        dynamic_update_slice, DimensionInfo::kDotDependent));\n   }\n   return absl::OkStatus();\n }\n@@ -297,7 +368,7 @@ absl::Status HloDimensionInfoPropagation::HandleOptimizationBarrier(\n       << \"Optimization barrier must have exactly one operand.\";\n   const HloInstruction* optimization_barrier_operand =\n       optimization_barrier->operand(0);\n-  if (analysis_->IsInstructionWeight(optimization_barrier_operand)) {\n+  if (analysis_->IsKnownDimensionInfo(optimization_barrier_operand)) {\n     TF_RETURN_IF_ERROR(analysis_->SetDimensionInfo(\n         optimization_barrier,\n         *analysis_->GetDimensionInfo(optimization_barrier_operand)));"
        },
        {
            "sha": "f9b5452997c76f06106b28147b00573f0886ac8e",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis.h",
            "status": "modified",
            "additions": 30,
            "deletions": 8,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis.h?ref=6ee9872872dd71cb50dfca6255089cf7e9553a8f",
            "patch": "@@ -41,17 +41,32 @@ limitations under the License.\n namespace xla {\n \n enum DimensionInfo : uint8_t {\n+  // kDotDependent indicates there is a DOT that can reach an operand of the\n+  // instruction. We want to use this information to distinguish between\n+  // WeightGradient and ActivationGradient as follows to help decide whether\n+  // we can overlap the all-gather/reduce-scatter with other dot operations\n+  // outside the chain:\n+  //\n+  // ActivationGradient: a DOT, there is another DOT that can reach the operands\n+  // of this DOT via def-use chain.\n+  //\n+  // WeightGradient: a DOT, no other DOT can reach the operand of this DOT via\n+  // def-use chain.\n+  //\n+  // Because we don't schedule instructions across computation boundaries, we\n+  // don't propagate kDotDependent across computation boundaries. On the other\n+  // hand, we propagate kWeight across computation boundaries.\n   kWeight,\n-  kTuple,\n+  kDotDependent,\n   kUnknown,\n };\n \n inline std::string DimensionInfoToString(DimensionInfo dim_info) {\n   switch (dim_info) {\n     case DimensionInfo::kWeight:\n       return \"weight\";\n-    case DimensionInfo::kTuple:\n-      return \"tuple\";\n+    case DimensionInfo::kDotDependent:\n+      return \"dot_dependent\";\n     case DimensionInfo::kUnknown:\n       return \"unknown\";\n   }\n@@ -77,7 +92,11 @@ class HloDimensionAnalysis {\n   }\n \n   // Whether any leaf in the instruction shape is a weight.\n-  bool IsInstructionWeight(const HloInstruction* instruction) const;\n+  bool IsWeight(const HloInstruction* instruction) const;\n+  // Whether any leaf in the instruction shape is dot dependent.\n+  bool IsDotDependent(const HloInstruction* instruction) const;\n+  // Whether any leaf in the instructon shape is a weight or dot dependent.\n+  bool IsKnownDimensionInfo(const HloInstruction* instruction) const;\n \n   // Returns map of HLO instructions to their dimension info.\n   // If an instruction is not found in the map, it means that we have not\n@@ -88,16 +107,19 @@ class HloDimensionAnalysis {\n   std::optional<ShapeTree<DimensionInfo>> GetDimensionInfo(\n       const HloInstruction* instruction) const;\n \n+  bool IsDotOrHasDotDependent(const HloInstruction* op) const;\n+\n  protected:\n   explicit HloDimensionAnalysis(\n       const HloModule& module,\n       const absl::flat_hash_set<absl::string_view>& execution_threads)\n       : module_(module), execution_threads_(execution_threads) {}\n \n-  // Sets the instruction as a weight. This is used to annotate the entry\n-  // computation parameters and other instructions that are known to be\n-  // weights.\n-  absl::Status SetInstructionAsWeight(HloInstruction* instruction);\n+  // Sets the instruction DimensionInfo to indicate it is a weight or\n+  // dot-dependent. This is used to annotate the entry computation parameters\n+  // and other instructions that are known to be weights or dot-dependents.\n+  absl::Status SetDimensionInfo(const HloInstruction* instruction,\n+                                DimensionInfo value);\n \n   // Sets the dimension info for the given target instruction.\n   absl::Status SetDimensionInfo(const HloInstruction* target,"
        },
        {
            "sha": "bebba7ab5298655ec7a95e9c53ac1dc3a99782cf",
            "filename": "third_party/xla/xla/hlo/analysis/hlo_dimension_analysis_test.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 0,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6ee9872872dd71cb50dfca6255089cf7e9553a8f/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Fhlo_dimension_analysis_test.cc?ref=6ee9872872dd71cb50dfca6255089cf7e9553a8f",
            "patch": "@@ -40,6 +40,14 @@ class HloDimensionAnalysisTest : public HloHardwareIndependentTestBase {\n     return dim_info.has_value() &&\n            (*dim_info).element({}) == DimensionInfo::kWeight;\n   }\n+  bool HasDotDependent(const HloDimensionAnalysis& hlo_dimension_analysis,\n+                       HloModule* module, absl::string_view instruction_name) {\n+    HloInstruction* instruction = FindInstruction(module, instruction_name);\n+    std::optional<ShapeTree<DimensionInfo>> dimension_info =\n+        hlo_dimension_analysis.GetDimensionInfo(instruction);\n+    return dimension_info.has_value() &&\n+           (*dimension_info).element({}) == DimensionInfo::kDotDependent;\n+  }\n };\n \n TEST_F(HloDimensionAnalysisTest, OneMatmul) {\n@@ -83,6 +91,13 @@ ENTRY entry {\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"copy\"));\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"Arg_1.2\"));\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"all-gather\"));\n+\n+  EXPECT_FALSE(HasDotDependent(*hlo_dimension_analysis, module.get(), \"dot.0\"));\n+  EXPECT_TRUE(\n+      HasDotDependent(*hlo_dimension_analysis, module.get(), \"maximum.33\"));\n+  EXPECT_TRUE(\n+      HasDotDependent(*hlo_dimension_analysis, module.get(), \"select.35\"));\n+  EXPECT_TRUE(HasDotDependent(*hlo_dimension_analysis, module.get(), \"dot.2\"));\n }\n \n TEST_F(HloDimensionAnalysisTest, RepeatWhile) {\n@@ -239,6 +254,19 @@ ENTRY entry {\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"reshape.22\"));\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"reshape.23\"));\n   EXPECT_TRUE(IsWeight(*hlo_dimension_analysis, module.get(), \"reshape.24\"));\n+\n+  EXPECT_FALSE(HasDotDependent(*hlo_dimension_analysis, module.get(), \"dot.0\"));\n+  EXPECT_TRUE(HasDotDependent(*hlo_dimension_analysis, module.get(), \"dot.1\"));\n+  EXPECT_TRUE(\n+      HasDotDependent(*hlo_dimension_analysis, module.get(), \"reshape.90\"));\n+  EXPECT_TRUE(\n+      HasDotDependent(*hlo_dimension_analysis, module.get(), \"reshape.95\"));\n+  // Index 2 of the while result is dot-dependent.\n+  EXPECT_TRUE(HasDotDependent(*hlo_dimension_analysis, module.get(),\n+                              \"dynamic-update-slice.99\"));\n+  // Check the dot-dependent while result is not propagated to the call site.\n+  EXPECT_FALSE(HasDotDependent(*hlo_dimension_analysis, module.get(),\n+                               \"get-tuple-element.179\"));\n }\n \n }  // namespace xla"
        }
    ],
    "stats": {
        "total": 221,
        "additions": 171,
        "deletions": 50
    }
}