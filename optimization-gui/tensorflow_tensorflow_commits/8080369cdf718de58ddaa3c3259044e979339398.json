{
    "author": "ezhulenev",
    "message": "[xla:gpu] Update GetComm API to pass clique key directly\n\nPiperOrigin-RevId: 838871654",
    "sha": "8080369cdf718de58ddaa3c3259044e979339398",
    "files": [
        {
            "sha": "5fdeab4e9761abaaccbd295850d48e592ddf9880",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -1361,6 +1361,7 @@ cc_library(\n     srcs = [\"all_to_all_thunk.cc\"],\n     hdrs = [\"all_to_all_thunk.h\"],\n     deps = [\n+        \":collective_execution\",\n         \":collective_thunk\",\n         \":thunk\",\n         \"//xla:shape_util\","
        },
        {
            "sha": "33e1dc02f4c15b1b99abb86e6e9d3a8e4f3e00eb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 3,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -35,6 +35,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n #include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n+#include \"xla/backends/gpu/runtime/collective_execution.h\"\n #include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/core/collectives/communicator.h\"\n@@ -122,10 +123,16 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n \n   if (is_local() && p2p_memcpy_enabled_) {\n     AsyncStreamKind stream_kind = GetAsyncStreamKind();\n+\n     TF_ASSIGN_OR_RETURN(\n-        CommunicatorHandle comm_handle,\n-        GetComm(*params.collective_params, *params.collective_cliques,\n-                config().replica_groups, config().group_mode, stream_kind));\n+        GpuCliqueKey clique_key,\n+        GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n+                        config().group_mode, stream_kind));\n+\n+    TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                        GetComm(*params.collective_params,\n+                                *params.collective_cliques, clique_key));\n+\n     TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm_handle.comm->NumRanks());\n     se::StreamExecutor* executor = params.executor;\n     {"
        },
        {
            "sha": "6ab22406afbe850ef44fe2f4328ff0790f1e9439",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_execution.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 7,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.cc?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -134,16 +134,15 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n \n absl::StatusOr<CommunicatorHandle> GetComm(\n     const CollectiveParams& params, const CollectiveCliques& collective_cliques,\n-    absl::Span<const ReplicaGroup> replica_groups,\n-    CollectiveOpGroupMode group_mode, AsyncStreamKind stream_kind) {\n-  TF_ASSIGN_OR_RETURN(\n-      GpuCliqueKey clique_key,\n-      GetGpuCliqueKey(params, replica_groups, group_mode, stream_kind));\n-\n+    const GpuCliqueKey& clique_key) {\n   std::optional<RankId> rank = clique_key.rank(params.global_device_id);\n+  if (!rank.has_value()) {\n+    return InvalidArgument(\"Rank not found for device %v\",\n+                           params.global_device_id);\n+  }\n+\n   TF_ASSIGN_OR_RETURN(Communicator * comm,\n                       collective_cliques.GetComm(clique_key, *rank));\n-\n   return CommunicatorHandle(comm, std::move(clique_key));\n }\n "
        },
        {
            "sha": "0d28b94b3633abc171576a1713766bc192027497",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_execution.h",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_execution.h?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -50,12 +50,11 @@ absl::StatusOr<GpuCliqueKey> GetGpuCliqueKey(\n     CollectiveOpGroupMode group_mode, AsyncStreamKind stream_kind,\n     bool include_participant_groups = true);\n \n-// Returns a communicator handle from the set of acquired cliques acquired\n-// before the XLA:GPU execution.\n+// Returns a communicator handle for the given `clique_key` and `params` from\n+// the set of cliques acquired before the XLA:GPU execution.\n absl::StatusOr<CommunicatorHandle> GetComm(\n     const CollectiveParams& params, const CollectiveCliques& collective_cliques,\n-    absl::Span<const ReplicaGroup> replica_groups,\n-    CollectiveOpGroupMode group_mode, AsyncStreamKind stream_kind);\n+    const GpuCliqueKey& clique_key);\n \n }  // namespace xla::gpu\n "
        },
        {
            "sha": "8dd657e70db8e7fee5912d1205a4cf73808b209c",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 10,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -36,8 +36,6 @@ limitations under the License.\n #include \"absl/time/time.h\"\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n-#include \"xla/backends/gpu/collectives/gpu_collectives.h\"\n-#include \"xla/backends/gpu/runtime/collective_cliques.h\"\n #include \"xla/backends/gpu/runtime/collective_execution.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n@@ -47,9 +45,7 @@ limitations under the License.\n #include \"xla/hlo/ir/collective_op_group_mode.h\"\n #include \"xla/primitive_util.h\"\n #include \"xla/runtime/device_id.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/service/computation_placer.h\"\n-#include \"xla/service/global_device_id.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/rendezvous.h\"\n #include \"xla/shape.h\"\n@@ -298,10 +294,16 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n       \"[%d] Starting %s %s.\", params.stream->parent()->device_ordinal(),\n       IsAsync() ? \"async\" : \"sync\", Thunk::KindToString(kind()));\n   AsyncStreamKind stream_kind = GetAsyncStreamKind();\n+\n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*params.collective_params, *params.collective_cliques,\n-              config().replica_groups, config().group_mode, stream_kind));\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n+                      config().group_mode, stream_kind));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*params.collective_params,\n+                              *params.collective_cliques, clique_key));\n+\n   se::StreamExecutor* executor = params.stream->parent();\n   int64_t async_stream_idx = static_cast<int64_t>(stream_kind);\n \n@@ -374,10 +376,14 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n absl::StatusOr<std::vector<Communicator*>> CollectiveThunk::GetCommunicators(\n     const ExecuteParams& params) const {\n   AsyncStreamKind stream_kind = GetAsyncStreamKind();\n+\n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*params.collective_params, *params.collective_cliques,\n-              config().replica_groups, config().group_mode, stream_kind));\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*params.collective_params, config().replica_groups,\n+                      config().group_mode, stream_kind));\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*params.collective_params,\n+                              *params.collective_cliques, clique_key));\n   return std::vector<Communicator*>{comm_handle.comm};\n }\n "
        },
        {
            "sha": "96c8f9f359aab0141d894491bc37bff0c46407ee",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 48,
            "deletions": 31,
            "changes": 79,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8080369cdf718de58ddaa3c3259044e979339398/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=8080369cdf718de58ddaa3c3259044e979339398",
            "patch": "@@ -77,7 +77,6 @@ limitations under the License.\n #include \"xla/service/computation_placer.h\"\n #include \"xla/service/custom_call_status.h\"\n #include \"xla/service/custom_call_status_internal.h\"\n-#include \"xla/service/global_device_id.h\"\n #include \"xla/service/gpu/buffer_allocations.h\"\n #include \"xla/service/gpu/kernels/custom_kernel.h\"\n #include \"xla/service/gpu/launch_dimensions.h\"\n@@ -2151,11 +2150,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n@@ -2214,11 +2216,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   return RecordTracedCommand(execute_params, record_params, record_action,\n                              command_buffer, [&](se::Stream* stream) {\n@@ -2278,11 +2283,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   // MemCpy case is not currently supported in CommandBuffer.\n   return RecordTracedCommand(\n@@ -2339,11 +2347,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   return RecordTracedCommand(\n       execute_params, record_params, std::move(record_action), command_buffer,\n@@ -2400,11 +2411,14 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   return RecordTracedCommand(execute_params, record_params,\n                              std::move(record_action), command_buffer,\n@@ -2462,11 +2476,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> CollectivePermuteCmd::Record(\n   }\n \n   TF_ASSIGN_OR_RETURN(\n-      CommunicatorHandle comm_handle,\n-      GetComm(*execute_params.collective_params,\n-              *execute_params.collective_cliques, config().replica_groups,\n-              config().group_mode,\n-              AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));  // Use constant\n+      GpuCliqueKey clique_key,\n+      GetGpuCliqueKey(*execute_params.collective_params,\n+                      config().replica_groups, config().group_mode,\n+                      AsyncStreamKind::ASYNC_STREAM_KIND_COLLECTIVE));\n+\n+  TF_ASSIGN_OR_RETURN(CommunicatorHandle comm_handle,\n+                      GetComm(*execute_params.collective_params,\n+                              *execute_params.collective_cliques, clique_key));\n \n   std::string device_string =\n       CollectiveThunk::GetDeviceString(*execute_params.collective_params);"
        }
    ],
    "stats": {
        "total": 139,
        "additions": 84,
        "deletions": 55
    }
}