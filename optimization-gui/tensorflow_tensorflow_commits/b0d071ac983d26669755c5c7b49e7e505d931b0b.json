{
    "author": "unknown",
    "message": "[XLA:GPU] Extract common SdcLog helper structs, add SdcBufferId\n\nHaving SdcLogEntry/SdcLogHeader separated from SdcLog makes it possible to use\nthem in xla/service/dump.cc without causing dependency cycles. Also, none of\nthem have anything CUDA-specific.\n\nSdcBufferId is a helper wrapper over uint32_t entry_id that clearly defines how\nthe thunk and buffer IDs are packed within the value.\n\nPiperOrigin-RevId: 817211040",
    "sha": "b0d071ac983d26669755c5c7b49e7e505d931b0b",
    "files": [
        {
            "sha": "d1ae629f10b5387283ef9035366395cc6a6f5b29",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -3,6 +3,7 @@ load(\"@rules_cc//cc:cc_library.bzl\", \"cc_library\")\n load(\"//xla:xla.default.bzl\", \"xla_cc_test\", \"xla_internal\")\n load(\"//xla/tests:build_defs.bzl\", \"xla_test\")\n load(\"//xla/tsl:tsl.bzl\", \"internal_visibility\", \"nvtx_headers\")\n+load(\"//xla/tsl:tsl.default.bzl\", \"get_compatible_with_portable\")\n load(\"//xla/tsl/platform:build_config.bzl\", \"tf_proto_library\")\n load(\"//xla/tsl/platform/default:cuda_build_defs.bzl\", \"if_cuda_is_configured\")\n \n@@ -1704,6 +1705,7 @@ cc_library(\n cc_library(\n     name = \"thunk_id\",\n     hdrs = [\"thunk_id.h\"],\n+    compatible_with = get_compatible_with_portable(),\n     deps = [\n         \"//xla/tsl/lib/gtl:int_type\",\n     ],\n@@ -2800,3 +2802,37 @@ xla_test(\n         \"@com_google_googletest//:gtest\",\n     ],\n )\n+\n+cc_library(\n+    name = \"sdc_buffer_id\",\n+    hdrs = [\"sdc_buffer_id.h\"],\n+    compatible_with = get_compatible_with_portable(),\n+    deps = [\n+        \":thunk_id\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:str_format\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"sdc_buffer_id_test\",\n+    srcs = [\"sdc_buffer_id_test.cc\"],\n+    deps = [\n+        \":sdc_buffer_id\",\n+        \":thunk_id\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:status_matchers\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n+cc_library(\n+    name = \"sdc_log_structs\",\n+    hdrs = [\"sdc_log_structs.h\"],\n+    compatible_with = get_compatible_with_portable(),\n+    deps = [\n+        \":sdc_buffer_id\",\n+    ],\n+)"
        },
        {
            "sha": "3d18fb1576cd25bcf8780d621dce422afa472518",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_buffer_id.h",
            "status": "added",
            "additions": 99,
            "deletions": 0,
            "changes": 99,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id.h?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -0,0 +1,99 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_format.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n+\n+namespace xla::gpu {\n+\n+// An ID that identifies a buffer within a program. It's a combination of the\n+// thunk ID and the buffer index within the thunk.\n+//\n+// A single buffer can be referred to by multiple SdcBufferIds, when it's being\n+// used in different thunks.\n+class SdcBufferId {\n+ public:\n+  SdcBufferId() = default;\n+\n+  // Creates a SdcBufferId that represents the `buffer_idx`-th buffer of a thunk\n+  // with `thunk_info`.\n+  //\n+  // Returns an error if `buffer_idx` is too large to be represented in a\n+  // SdcBufferId.\n+  static absl::StatusOr<SdcBufferId> Create(ThunkId thunk_id,\n+                                            size_t buffer_idx) {\n+    if (buffer_idx >= (1 << kBitsReservedForBufferIndex)) {\n+      return absl::InvalidArgumentError(absl::StrFormat(\n+          \"Buffer index (%u) is too large to be represented in a SdcBufferId \"\n+          \"(max = %u)\",\n+          buffer_idx, (1 << kBitsReservedForBufferIndex) - 1));\n+    }\n+\n+    const uint32_t value = (static_cast<uint32_t>(thunk_id.value())\n+                            << kBitsReservedForBufferIndex) |\n+                           static_cast<uint32_t>(buffer_idx);\n+    return SdcBufferId(value);\n+  }\n+\n+  ThunkId thunk_id() const {\n+    return ThunkId(value_ >> kBitsReservedForBufferIndex);\n+  }\n+  size_t buffer_idx() const {\n+    return value_ & ((1 << kBitsReservedForBufferIndex) - 1);\n+  }\n+\n+  // Raw numeric value of the ID, for use in SdcLogEntry::entry_id.\n+  uint32_t value() const { return value_; }\n+\n+  bool operator==(const SdcBufferId& other) const {\n+    return value_ == other.value_;\n+  }\n+  bool operator!=(const SdcBufferId& other) const { return !(*this == other); }\n+\n+  template <typename Sink>\n+  friend void AbslStringify(Sink& sink, const SdcBufferId& buffer_id) {\n+    absl::Format(&sink, \"{thunk_id: %u, buffer_idx: %u}\",\n+                 buffer_id.thunk_id().value(), buffer_id.buffer_idx());\n+  }\n+\n+  template <typename H>\n+  friend H AbslHashValue(H h, const SdcBufferId& buffer_id) {\n+    return H::combine(std::move(h), buffer_id.value_);\n+  }\n+\n+ private:\n+  // Out of 32 bits available in SDC entry id, reserve that much for the\n+  // buffer index. This limits us to:\n+  // - 2^kBitsReservedForBufferIndex max buffers per thunk\n+  // - 2^(32-kBitsReservedForBufferIndex) max thunks\n+  // Which hopefully is enough.\n+  static constexpr size_t kBitsReservedForBufferIndex = 8;\n+\n+  explicit SdcBufferId(uint32_t value) : value_(value) {}\n+\n+  uint32_t value_ = 0;\n+};\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_BUFFER_ID_H_"
        },
        {
            "sha": "d88887e5ee3a371f20dc66aca231663e56ba5b13",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_buffer_id_test.cc",
            "status": "added",
            "additions": 48,
            "deletions": 0,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_buffer_id_test.cc?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -0,0 +1,48 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/status/status.h\"\n+#include \"absl/status/status_matchers.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+\n+namespace {\n+\n+TEST(SdcBufferIdTest, CreateFailsForLargeBufferIndex) {\n+  EXPECT_THAT(xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n+                                            /*buffer_idx=*/256),\n+              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+}\n+\n+TEST(SdcBufferIdTest, CreateSucceedsForSmallBufferIndex) {\n+  EXPECT_THAT(xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n+                                            /*buffer_idx=*/255),\n+              absl_testing::IsOk());\n+}\n+\n+TEST(SdcBufferIdTest, CorrectlyStoresAndExtractsThunkIdAndBufferIndex) {\n+  TF_ASSERT_OK_AND_ASSIGN(xla::gpu::SdcBufferId buffer_id,\n+                          xla::gpu::SdcBufferId::Create(xla::gpu::ThunkId(123),\n+                                                        /*buffer_idx=*/45));\n+\n+  EXPECT_THAT(buffer_id.thunk_id(), xla::gpu::ThunkId(123));\n+  EXPECT_THAT(buffer_id.buffer_idx(), 45);\n+}\n+\n+}  // namespace"
        },
        {
            "sha": "af08c9ac60db32160bc6ac14c8a3e76d6b60e4e8",
            "filename": "third_party/xla/xla/backends/gpu/runtime/sdc_log_structs.h",
            "status": "added",
            "additions": 61,
            "deletions": 0,
            "changes": 61,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsdc_log_structs.h?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -0,0 +1,61 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_\n+#define XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_\n+\n+#include <cstddef>\n+#include <cstdint>\n+\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+\n+namespace xla::gpu {\n+\n+struct SdcLogEntry {\n+  // An ID that uniquely identifies a thunk and its specific input or output\n+  // buffer.\n+  SdcBufferId entry_id;\n+  uint32_t checksum;\n+\n+  template <typename Sink>\n+  friend void AbslStringify(Sink& sink, const SdcLogEntry& entry) {\n+    absl::Format(&sink, \"{entry_id: %v, checksum: %u}\", entry.entry_id,\n+                 entry.checksum);\n+  }\n+};\n+\n+// The struct layout must match on both host and device.\n+static_assert(_Alignof(SdcLogEntry) == _Alignof(uint32_t));\n+static_assert(sizeof(SdcLogEntry) == sizeof(uint32_t) * 2);\n+static_assert(offsetof(SdcLogEntry, entry_id) == 0);\n+static_assert(offsetof(SdcLogEntry, checksum) == sizeof(uint32_t));\n+\n+struct SdcLogHeader {\n+  // The first entry in `SdcLogEntry` following the header that has not\n+  // been written to. May be bigger than `capacity` if the log was truncated.\n+  uint32_t write_idx;\n+  // The number of `SdcLogEntry` structs the log can hold.\n+  uint32_t capacity;\n+};\n+\n+// The struct layout must match on both host and device.\n+static_assert(_Alignof(SdcLogHeader) == _Alignof(uint32_t));\n+static_assert(sizeof(SdcLogHeader) == sizeof(uint32_t) * 2);\n+static_assert(offsetof(SdcLogHeader, write_idx) == 0);\n+static_assert(offsetof(SdcLogHeader, capacity) == sizeof(uint32_t));\n+\n+}  // namespace xla::gpu\n+\n+#endif  // XLA_BACKENDS_GPU_RUNTIME_SDC_LOG_STRUCTS_H_"
        },
        {
            "sha": "0d0fab910ec84e393abc92907ead4b42752e5381",
            "filename": "third_party/xla/xla/stream_executor/cuda/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2FBUILD?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -430,6 +430,7 @@ cc_library(\n     hdrs = [\"sdc_log.h\"],\n     tags = [\"gpu\"],\n     deps = [\n+        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_allocator\",\n         \"//xla/stream_executor:stream\",\n@@ -446,6 +447,7 @@ xla_test(\n     backends = [\"gpu\"],\n     deps = [\n         \":sdc_log\",\n+        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:platform\",\n         \"//xla/stream_executor:platform_manager\",\n@@ -469,7 +471,8 @@ cuda_library(\n     ],\n     deps = [\n         \":cuda_platform_id\",\n-        \":sdc_log\",\n+        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n+        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel\",\n         \"//xla/stream_executor:kernel_spec\",\n@@ -489,6 +492,9 @@ xla_test(\n     deps = [\n         \":sdc_log\",\n         \":sdc_xor_checksum_kernel_cuda\",\n+        \"//xla/backends/gpu/runtime:sdc_buffer_id\",\n+        \"//xla/backends/gpu/runtime:sdc_log_structs\",\n+        \"//xla/backends/gpu/runtime:thunk_id\",\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:kernel_spec\",\n         \"//xla/stream_executor:launch_dim\","
        },
        {
            "sha": "56a393d9db4178ac9d35611a88522a5859824e27",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_log.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.cc?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -24,13 +24,17 @@ limitations under the License.\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n #include \"xla/tsl/platform/errors.h\"\n \n namespace stream_executor::cuda {\n \n+using ::xla::gpu::SdcLogEntry;\n+using ::xla::gpu::SdcLogHeader;\n+\n absl::StatusOr<SdcLog> SdcLog::CreateOnDevice(\n     Stream& stream, DeviceMemory<uint8_t> log_buffer) {\n   if (log_buffer.is_null()) {"
        },
        {
            "sha": "a5a20351383d5500595c8e3c3a6a0e9166636c08",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_log.h",
            "status": "modified",
            "additions": 14,
            "deletions": 37,
            "changes": 51,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log.h?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -21,47 +21,21 @@ limitations under the License.\n #include <vector>\n \n #include \"absl/status/statusor.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n-#include \"xla/stream_executor/device_memory_allocator.h\"\n #include \"xla/stream_executor/stream.h\"\n \n namespace stream_executor::cuda {\n \n-struct SdcLogEntry {\n-  // An ID that uniquely identifies a thunk and its specific input or output\n-  // buffer.\n-  uint32_t entry_id;\n-  uint32_t checksum;\n-};\n-\n-// The struct layout must match on both host and device.\n-static_assert(_Alignof(SdcLogEntry) == _Alignof(uint32_t));\n-static_assert(sizeof(SdcLogEntry) == sizeof(uint32_t) * 2);\n-static_assert(offsetof(SdcLogEntry, entry_id) == 0);\n-static_assert(offsetof(SdcLogEntry, checksum) == sizeof(uint32_t));\n-\n-struct SdcLogHeader {\n-  // The first entry in `SdcLogEntry` following the header that has not\n-  // been written to. May be bigger than `capacity` if the log was truncated.\n-  uint32_t write_idx;\n-  // The number of `SdcLogEntry` structs the log can hold.\n-  uint32_t capacity;\n-};\n-\n-// The struct layout must match on both host and device.\n-static_assert(_Alignof(SdcLogHeader) == _Alignof(uint32_t));\n-static_assert(sizeof(SdcLogHeader) == sizeof(uint32_t) * 2);\n-static_assert(offsetof(SdcLogHeader, write_idx) == 0);\n-static_assert(offsetof(SdcLogHeader, capacity) == sizeof(uint32_t));\n-\n // A device memory buffer that holds a SdcLogHeader and a variable number of\n // SdcLogEntry structs.\n class SdcLog {\n  public:\n   // Returns the number of bytes required to store a log with `entries`\n   // entries.\n   static constexpr size_t RequiredSizeForEntries(size_t entries) {\n-    return sizeof(SdcLogHeader) + sizeof(SdcLogEntry) * entries;\n+    return sizeof(xla::gpu::SdcLogHeader) +\n+           sizeof(xla::gpu::SdcLogEntry) * entries;\n   }\n \n   // Initializes an empty `SdcLog` using a `log_buffer` allocated in device\n@@ -81,7 +55,8 @@ class SdcLog {\n   //\n   // `stream` must be associated with the same device as the one used to create\n   // the log.\n-  absl::StatusOr<SdcLogHeader> ReadHeaderFromDevice(Stream& stream) const;\n+  absl::StatusOr<xla::gpu::SdcLogHeader> ReadHeaderFromDevice(\n+      Stream& stream) const;\n \n   // Reads all entries from the device log into host memory.\n   //\n@@ -90,24 +65,26 @@ class SdcLog {\n   //\n   // `stream` must be associated with the same device as the one used to create\n   // the log.\n-  absl::StatusOr<std::vector<SdcLogEntry>> ReadFromDevice(Stream& stream) const;\n+  absl::StatusOr<std::vector<xla::gpu::SdcLogEntry>> ReadFromDevice(\n+      Stream& stream) const;\n \n   // Returns a view of the `SdcLogHeader`.\n   //\n   // The returned `DeviceMemory` gets invalidated when the `SdcLog` is\n   // destroyed.\n-  DeviceMemory<SdcLogHeader> GetDeviceHeader() const {\n-    return DeviceMemory<SdcLogHeader>(\n-        memory_.GetByteSlice(0, sizeof(SdcLogHeader)));\n+  DeviceMemory<xla::gpu::SdcLogHeader> GetDeviceHeader() const {\n+    return DeviceMemory<xla::gpu::SdcLogHeader>(\n+        memory_.GetByteSlice(0, sizeof(xla::gpu::SdcLogHeader)));\n   }\n \n   // Returns a view of the `SdcLogEntry` array.\n   //\n   // The returned `DeviceMemory` gets invalidated when the `SdcLog` is\n   // destroyed.\n-  DeviceMemory<SdcLogEntry> GetDeviceEntries() const {\n-    return DeviceMemory<SdcLogEntry>(memory_.GetByteSlice(\n-        sizeof(SdcLogHeader), memory_.size() - sizeof(SdcLogHeader)));\n+  DeviceMemory<xla::gpu::SdcLogEntry> GetDeviceEntries() const {\n+    return DeviceMemory<xla::gpu::SdcLogEntry>(\n+        memory_.GetByteSlice(sizeof(xla::gpu::SdcLogHeader),\n+                             memory_.size() - sizeof(xla::gpu::SdcLogHeader)));\n   }\n \n  private:"
        },
        {
            "sha": "5db609edbbc08b176da8043679e82257051b1b6a",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_log_test.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 32,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_log_test.cc?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -24,6 +24,7 @@ limitations under the License.\n #include <gtest/gtest.h>\n #include \"absl/status/status.h\"\n #include \"absl/status/status_matchers.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/platform.h\"\n #include \"xla/stream_executor/platform_manager.h\"\n@@ -32,82 +33,79 @@ limitations under the License.\n #include \"xla/stream_executor/stream_executor_memory_allocator.h\"\n #include \"xla/tsl/platform/statusor.h\"\n \n-namespace se = stream_executor;\n-\n+namespace stream_executor::cuda {\n namespace {\n \n+using ::xla::gpu::SdcLogEntry;\n+using ::xla::gpu::SdcLogHeader;\n+\n class SdcLogTest : public ::testing::Test {\n  protected:\n   void SetUp() override {\n     TF_ASSERT_OK_AND_ASSIGN(platform_,\n-                            se::PlatformManager::PlatformWithName(\"CUDA\"));\n+                            PlatformManager::PlatformWithName(\"CUDA\"));\n     TF_ASSERT_OK_AND_ASSIGN(executor_, platform_->ExecutorForDevice(0));\n     TF_ASSERT_OK_AND_ASSIGN(stream_, executor_->CreateStream(std::nullopt));\n     allocator_ =\n-        std::make_unique<se::StreamExecutorMemoryAllocator>(stream_->parent());\n+        std::make_unique<StreamExecutorMemoryAllocator>(stream_->parent());\n   }\n \n-  se::Platform* platform_;\n-  se::StreamExecutor* executor_;\n-  std::unique_ptr<se::Stream> stream_;\n-  std::unique_ptr<se::StreamExecutorMemoryAllocator> allocator_;\n+  Platform* platform_;\n+  StreamExecutor* executor_;\n+  std::unique_ptr<Stream> stream_;\n+  std::unique_ptr<StreamExecutorMemoryAllocator> allocator_;\n };\n \n TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesEmptyLog) {\n-  se::DeviceMemory<uint8_t> log_buffer =\n-      executor_->AllocateArray<uint8_t>(1024);\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(1024);\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::SdcLog device_log,\n-      se::cuda::SdcLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n+                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n \n   EXPECT_EQ(host_log.size(), 0);\n }\n \n TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesLogWithCorrectCapacity) {\n   constexpr size_t kMaxEntries = 10;\n-  constexpr size_t kExpectedHeaderSize = sizeof(se::cuda::SdcLogHeader);\n-  constexpr size_t kExpectedEntriesSize =\n-      sizeof(se::cuda::SdcLogEntry) * kMaxEntries;\n-  se::DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n+  constexpr size_t kExpectedHeaderSize = sizeof(SdcLogHeader);\n+  constexpr size_t kExpectedEntriesSize = sizeof(SdcLogEntry) * kMaxEntries;\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n       kExpectedHeaderSize + kExpectedEntriesSize);\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::SdcLog device_log,\n-      se::cuda::SdcLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n+                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n \n   EXPECT_EQ(device_log.GetDeviceHeader().size(), kExpectedHeaderSize);\n   EXPECT_EQ(device_log.GetDeviceEntries().size(), kExpectedEntriesSize);\n }\n \n TEST_F(SdcLogTest, CreateSdcLogOnDevice_InitializesHeader) {\n   constexpr size_t kMaxEntries = 123;\n-  se::DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      se::cuda::SdcLog::RequiredSizeForEntries(kMaxEntries));\n+  DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n+      SdcLog::RequiredSizeForEntries(kMaxEntries));\n \n-  TF_ASSERT_OK_AND_ASSIGN(\n-      se::cuda::SdcLog device_log,\n-      se::cuda::SdcLog::CreateOnDevice(*stream_, log_buffer));\n-  TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLogHeader header,\n+  TF_ASSERT_OK_AND_ASSIGN(SdcLog device_log,\n+                          SdcLog::CreateOnDevice(*stream_, log_buffer));\n+  TF_ASSERT_OK_AND_ASSIGN(SdcLogHeader header,\n                           device_log.ReadHeaderFromDevice(*stream_));\n \n   EXPECT_EQ(header.write_idx, 0);\n   EXPECT_EQ(header.capacity, kMaxEntries);\n }\n \n TEST_F(SdcLogTest, CreateSdcLogOnDevice_FailsForNullBuffer) {\n-  EXPECT_THAT(\n-      se::cuda::SdcLog::CreateOnDevice(*stream_, se::DeviceMemory<uint8_t>()),\n-      absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n+  EXPECT_THAT(SdcLog::CreateOnDevice(*stream_, DeviceMemory<uint8_t>()),\n+              absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n TEST_F(SdcLogTest, CreateSdcLogOnDevice_FailsForTooSmallBuffer) {\n-  se::DeviceMemory<uint8_t> log_buffer = executor_->AllocateArray<uint8_t>(\n-      se::cuda::SdcLog::RequiredSizeForEntries(1) - 1);\n+  DeviceMemory<uint8_t> log_buffer =\n+      executor_->AllocateArray<uint8_t>(SdcLog::RequiredSizeForEntries(1) - 1);\n \n-  EXPECT_THAT(se::cuda::SdcLog::CreateOnDevice(*stream_, log_buffer),\n+  EXPECT_THAT(SdcLog::CreateOnDevice(*stream_, log_buffer),\n               absl_testing::StatusIs(absl::StatusCode::kInvalidArgument));\n }\n \n }  // namespace\n+}  // namespace stream_executor::cuda"
        },
        {
            "sha": "f90bd2f9b2bc59281b9db2fb26b543847b740c0f",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.cu.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 4,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.cu.cc?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -22,6 +22,8 @@ limitations under the License.\n \n #include \"absl/base/casts.h\"\n #include \"third_party/gpus/cuda/include/cuda/atomic\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n #include \"xla/stream_executor/cuda/cuda_platform_id.h\"\n #include \"xla/stream_executor/gpu/gpu_kernel_registry.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n@@ -117,10 +119,10 @@ __device__ void ReduceXor(const uint32_t* input, uint64_t input_size,\n // LIMITATIONS:\n // - Only a single thread block is supported.\n // - Block dimensions must be a power of 2.\n-__global__ void AppendChecksum(uint32_t entry_id, const uint8_t* input,\n-                               uint64_t input_size,\n-                               se::cuda::SdcLogHeader* log_header,\n-                               se::cuda::SdcLogEntry* log_entries) {\n+__global__ void AppendChecksum(xla::gpu::SdcBufferId entry_id,\n+                               const uint8_t* input, uint64_t input_size,\n+                               xla::gpu::SdcLogHeader* log_header,\n+                               xla::gpu::SdcLogEntry* log_entries) {\n   const uint32_t block_size = blockDim.x * blockDim.y * blockDim.z;\n   const uint32_t* input_u32 = reinterpret_cast<const uint32_t*>(input);\n   const uint64_t input_u32_size = input_size / sizeof(uint32_t);"
        },
        {
            "sha": "a20b07bb04c9470f25e31b7bb43f7fbefab0b6f9",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda.h",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda.h?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -19,7 +19,8 @@ limitations under the License.\n #include <cstdint>\n \n #include \"absl/status/statusor.h\"\n-#include \"xla/stream_executor/cuda/sdc_log.h\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/kernel.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n@@ -31,9 +32,9 @@ namespace stream_executor::cuda {\n //\n // This kernel MUST execute on a single thread block.\n struct SdcXorChecksumKernel {\n-  using KernelType =\n-      TypedKernel<uint32_t, DeviceMemory<uint8_t>, uint64_t,\n-                  DeviceMemory<SdcLogHeader>, DeviceMemory<SdcLogEntry>>;\n+  using KernelType = TypedKernel<xla::gpu::SdcBufferId, DeviceMemory<uint8_t>,\n+                                 uint64_t, DeviceMemory<xla::gpu::SdcLogHeader>,\n+                                 DeviceMemory<xla::gpu::SdcLogEntry>>;\n };\n \n absl::StatusOr<KernelLoaderSpec> GetSdcXorChecksumKernelSpec();"
        },
        {
            "sha": "f794fd98b8680d3120c7646f4097f3b5fbcdba83",
            "filename": "third_party/xla/xla/stream_executor/cuda/sdc_xor_checksum_kernel_cuda_test.cc",
            "status": "modified",
            "additions": 30,
            "deletions": 16,
            "changes": 46,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b0d071ac983d26669755c5c7b49e7e505d931b0b/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fsdc_xor_checksum_kernel_cuda_test.cc?ref=b0d071ac983d26669755c5c7b49e7e505d931b0b",
            "patch": "@@ -28,6 +28,9 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/string_view.h\"\n+#include \"xla/backends/gpu/runtime/sdc_buffer_id.h\"\n+#include \"xla/backends/gpu/runtime/sdc_log_structs.h\"\n+#include \"xla/backends/gpu/runtime/thunk_id.h\"\n #include \"xla/stream_executor/cuda/sdc_log.h\"\n #include \"xla/stream_executor/device_memory.h\"\n #include \"xla/stream_executor/kernel_spec.h\"\n@@ -47,6 +50,11 @@ namespace se = stream_executor;\n namespace stream_executor::cuda {\n namespace {\n \n+using xla::gpu::SdcBufferId;\n+using xla::gpu::SdcLogEntry;\n+using xla::gpu::SdcLogHeader;\n+using xla::gpu::ThunkId;\n+\n class ChecksumKernelTest : public ::testing::Test {\n  protected:\n   void SetUp() override {\n@@ -70,7 +78,7 @@ class ChecksumKernelTest : public ::testing::Test {\n \n   template <typename T>\n   absl::Status AppendChecksumOnDevice(\n-      uint32_t entry_id, const T& input, se::cuda::SdcLog& sdc_log,\n+      SdcBufferId entry_id, const T& input, se::cuda::SdcLog& sdc_log,\n       stream_executor::ThreadDim dim = stream_executor::ThreadDim(1, 1, 1)) {\n     // Load kernel\n     TF_ASSIGN_OR_RETURN(se::KernelLoaderSpec spec,\n@@ -121,7 +129,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumForMultipleOf32Bit) {\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n@@ -135,7 +143,7 @@ TEST_F(ChecksumKernelTest,\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, kInput, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), kInput, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 1);\n@@ -153,7 +161,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallel) {\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log,\n+  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log,\n                                       se::ThreadDim(2, 4, 8)));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n@@ -171,7 +179,7 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/0, input, device_log,\n+  TF_EXPECT_OK(AppendChecksumOnDevice(SdcBufferId(), input, device_log,\n                                       se::ThreadDim(128, 4, 2)));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n@@ -181,45 +189,51 @@ TEST_F(ChecksumKernelTest, ComputesCorrectChecksumInParallelWithMaxThreads) {\n \n TEST_F(ChecksumKernelTest, AppendsChecksumsToLog) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(1024);\n+  SdcBufferId kId123 = SdcBufferId::Create(ThunkId(123), 0).value();\n+  SdcBufferId kId456 = SdcBufferId::Create(ThunkId(456), 0).value();\n+  SdcBufferId kId789 = SdcBufferId::Create(ThunkId(789), 0).value();\n   constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/123, kInput123, device_log));\n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/456, kInput456, device_log));\n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/789, kInput789, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId789, kInput789, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 3);\n-  EXPECT_EQ(host_log[0].entry_id, 123);\n+  EXPECT_EQ(host_log[0].entry_id, kId123);\n   EXPECT_EQ(host_log[0].checksum, 0x01230123);\n-  EXPECT_EQ(host_log[1].entry_id, 456);\n+  EXPECT_EQ(host_log[1].entry_id, kId456);\n   EXPECT_EQ(host_log[1].checksum, 0x04560456);\n-  EXPECT_EQ(host_log[2].entry_id, 789);\n+  EXPECT_EQ(host_log[2].entry_id, kId789);\n   EXPECT_EQ(host_log[2].checksum, 0x07890789);\n }\n \n TEST_F(ChecksumKernelTest, DiscardsOverflowingChecksums) {\n   se::DeviceMemory<uint8_t> mem = executor_->AllocateArray<uint8_t>(\n       sizeof(SdcLogHeader) + sizeof(SdcLogEntry) * 2);\n+  SdcBufferId kId123 = SdcBufferId::Create(ThunkId(123), 0).value();\n+  SdcBufferId kId456 = SdcBufferId::Create(ThunkId(456), 0).value();\n+  SdcBufferId kId789 = SdcBufferId::Create(ThunkId(789), 0).value();\n   constexpr std::array<uint32_t, 1> kInput123 = {0x01230123};\n   constexpr std::array<uint32_t, 1> kInput456 = {0x04560456};\n   constexpr std::array<uint32_t, 1> kInput789 = {0x07890789};\n   TF_ASSERT_OK_AND_ASSIGN(se::cuda::SdcLog device_log,\n                           se::cuda::SdcLog::CreateOnDevice(*stream_, mem));\n \n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/123, kInput123, device_log));\n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/456, kInput456, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId123, kInput123, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId456, kInput456, device_log));\n   // This entry will be discarded.\n-  TF_EXPECT_OK(AppendChecksumOnDevice(/*entry_id=*/789, kInput789, device_log));\n+  TF_EXPECT_OK(AppendChecksumOnDevice(kId789, kInput789, device_log));\n \n   TF_ASSERT_OK_AND_ASSIGN(auto host_log, device_log.ReadFromDevice(*stream_));\n   ASSERT_GE(host_log.size(), 2);\n-  EXPECT_EQ(host_log[0].entry_id, 123);\n+  EXPECT_EQ(host_log[0].entry_id, kId123);\n   EXPECT_EQ(host_log[0].checksum, 0x01230123);\n-  EXPECT_EQ(host_log[1].entry_id, 456);\n+  EXPECT_EQ(host_log[1].entry_id, kId456);\n   EXPECT_EQ(host_log[1].checksum, 0x04560456);\n }\n "
        }
    ],
    "stats": {
        "total": 434,
        "additions": 340,
        "deletions": 94
    }
}