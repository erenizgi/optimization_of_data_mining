{
    "author": "ZixuanJiang",
    "message": "Add `AllReduceReduceScatterReorder` pass to rewrite `all-reduce + reduce-scatter` as `reduce-scatter + all-reduce` if\n1. the all-reduce only has one user, which is the reduce-scatter\n2. AR and RS share the same reduction type\n\nPiperOrigin-RevId: 834439260",
    "sha": "a6f0d07159b1af801d2777d5177d92b2ef1d21b2",
    "files": [
        {
            "sha": "2df40a21b8a13587c3f2e09a886102b735f52a29",
            "filename": "third_party/xla/xla/service/BUILD",
            "status": "modified",
            "additions": 30,
            "deletions": 0,
            "changes": 30,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2FBUILD?ref=a6f0d07159b1af801d2777d5177d92b2ef1d21b2",
            "patch": "@@ -231,6 +231,36 @@ xla_cc_test(\n     ],\n )\n \n+cc_library(\n+    name = \"all_reduce_reduce_scatter_reorder_cc\",\n+    srcs = [\"all_reduce_reduce_scatter_reorder.cc\"],\n+    hdrs = [\"all_reduce_reduce_scatter_reorder.h\"],\n+    deps = [\n+        \":collective_ops_utils\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/pass:hlo_pass_interface\",\n+        \"//xla/tsl/platform:errors\",\n+        \"@com_google_absl//absl/container:flat_hash_set\",\n+        \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+    ],\n+)\n+\n+xla_cc_test(\n+    name = \"all_reduce_reduce_scatter_reorder_test\",\n+    srcs = [\"all_reduce_reduce_scatter_reorder_test.cc\"],\n+    deps = [\n+        \":all_reduce_reduce_scatter_reorder_cc\",\n+        \"//xla:xla_data_proto_cc\",\n+        \"//xla/hlo/ir:hlo\",\n+        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n+        \"//xla/tsl/platform:statusor\",\n+        \"@com_google_absl//absl/strings:string_view\",\n+        \"@com_google_googletest//:gtest_main\",\n+    ],\n+)\n+\n cc_library(\n     name = \"float_support\",\n     srcs = [\"float_support.cc\"],"
        },
        {
            "sha": "e738bc918a92562930ec5b207e4f6fd5dbcca001",
            "filename": "third_party/xla/xla/service/all_reduce_reduce_scatter_reorder.cc",
            "status": "added",
            "additions": 90,
            "deletions": 0,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.cc?ref=a6f0d07159b1af801d2777d5177d92b2ef1d21b2",
            "patch": "@@ -0,0 +1,90 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/all_reduce_reduce_scatter_reorder.h\"\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/service/collective_ops_utils.h\"\n+#include \"xla/tsl/platform/errors.h\"\n+\n+namespace xla {\n+\n+namespace {\n+// Returns true if\n+// 1. `inst` is an all-reduce instruction.\n+// 2. `inst` has a single user.\n+// 3. The user is a reduce-scatter instruction.\n+// 4. The all-reduce and reduce-scatter have the same reduction type.\n+bool IsAllReduceReduceScatter(const HloInstruction* ar) {\n+  if (ar->opcode() != HloOpcode::kAllReduce) {\n+    return false;\n+  }\n+  if (ar->user_count() != 1) {\n+    return false;\n+  }\n+  const HloInstruction* rs = ar->users().front();\n+  if (rs->opcode() != HloOpcode::kReduceScatter) {\n+    return false;\n+  }\n+  if (MatchReductionComputation(ar->to_apply()) &&\n+      MatchReductionComputation(ar->to_apply()) !=\n+          MatchReductionComputation(rs->to_apply())) {\n+    return false;\n+  }\n+  return true;\n+}\n+\n+// Before: operand -> old_ar -> old_rs -> users\n+// After:  operand -> new_rs -> new_ar -> users\n+//\n+// old_rs, new_rs, and new_ar share the same shape, while old_ar has a larger\n+// shape.\n+absl::Status ReorderAllReduceReduceScatter(HloInstruction* old_ar) {\n+  HloComputation* computation = old_ar->parent();\n+  HloInstruction* old_rs = old_ar->users().front();\n+  HloInstruction* new_rs = computation->AddInstruction(\n+      old_rs->CloneWithNewOperands(old_rs->shape(), old_ar->operands()));\n+  HloInstruction* new_ar = computation->AddInstruction(\n+      old_ar->CloneWithNewOperands(old_rs->shape(), {new_rs}));\n+  TF_RETURN_IF_ERROR(old_rs->ReplaceUsesWith(old_rs->users(), new_ar));\n+\n+  TF_RETURN_IF_ERROR(computation->RemoveInstruction(old_rs));\n+  TF_RETURN_IF_ERROR(computation->RemoveInstruction(old_ar));\n+  return absl::OkStatus();\n+}\n+}  // namespace\n+\n+absl::StatusOr<bool> AllReduceReduceScatterReorder::RunImpl(\n+    HloModule* module,\n+    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n+  bool changed = false;\n+  for (auto computation : module->computations(execution_threads)) {\n+    for (HloInstruction* inst : computation->MakeInstructionPostOrder()) {\n+      if (IsAllReduceReduceScatter(inst)) {\n+        TF_RETURN_IF_ERROR(ReorderAllReduceReduceScatter(inst));\n+        changed = true;\n+      }\n+    }\n+  }\n+  return changed;\n+}\n+\n+}  // namespace xla"
        },
        {
            "sha": "ed4915b7f428f5e772bc4c644f435e4ce480d368",
            "filename": "third_party/xla/xla/service/all_reduce_reduce_scatter_reorder.h",
            "status": "added",
            "additions": 49,
            "deletions": 0,
            "changes": 49,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder.h?ref=a6f0d07159b1af801d2777d5177d92b2ef1d21b2",
            "patch": "@@ -0,0 +1,49 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#ifndef XLA_SERVICE_ALL_REDUCE_REDUCE_SCATTER_REORDER_H_\n+#define XLA_SERVICE_ALL_REDUCE_REDUCE_SCATTER_REORDER_H_\n+\n+#include \"absl/container/flat_hash_set.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/pass/hlo_pass_interface.h\"\n+\n+namespace xla {\n+\n+// Rewrites all-reduce + reduce-scatter to reduce-scatter + all-reduce such that\n+// the all-reduce is on a smaller tensor. The proof of equivalence is below.\n+//\n+//   AR_1 + RS_2\n+// = AR_1 + AR_2 + DS_2\n+// = AR_2 + AR_1 + DS_2\n+// = AR_2 + DS_2 + AR_1\n+// = RS_2 + AR_1\n+class AllReduceReduceScatterReorder : public HloModulePass {\n+ public:\n+  absl::string_view name() const override {\n+    return \"all-reduce-reduce-scatter-reorder\";\n+  }\n+\n+ protected:\n+  absl::StatusOr<bool> RunImpl(\n+      HloModule* module,\n+      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n+};\n+\n+}  // namespace xla\n+\n+#endif  // XLA_SERVICE_ALL_REDUCE_REDUCE_SCATTER_REORDER_H_"
        },
        {
            "sha": "708c7d30ec4c1ef43a2a31cb7435460efeb80d04",
            "filename": "third_party/xla/xla/service/all_reduce_reduce_scatter_reorder_test.cc",
            "status": "added",
            "additions": 131,
            "deletions": 0,
            "changes": 131,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/a6f0d07159b1af801d2777d5177d92b2ef1d21b2/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fall_reduce_reduce_scatter_reorder_test.cc?ref=a6f0d07159b1af801d2777d5177d92b2ef1d21b2",
            "patch": "@@ -0,0 +1,131 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include \"xla/service/all_reduce_reduce_scatter_reorder.h\"\n+\n+#include <memory>\n+\n+#include <gmock/gmock.h>\n+#include <gtest/gtest.h>\n+#include \"absl/strings/string_view.h\"\n+#include \"xla/hlo/ir/hlo_instruction.h\"\n+#include \"xla/hlo/ir/hlo_module.h\"\n+#include \"xla/hlo/ir/hlo_opcode.h\"\n+#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n+#include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/xla_data.pb.h\"\n+\n+namespace xla {\n+namespace {\n+\n+class AllReduceReduceScatterReorderTest\n+    : public HloHardwareIndependentTestBase {\n+ public:\n+  AllReduceReduceScatterReorder pass_;\n+};\n+\n+TEST_F(AllReduceReduceScatterReorderTest, KeepingReplicaGroups) {\n+  absl::string_view hlo_text = R\"(\n+  sum {\n+    a = f32[] parameter(0)\n+    b = f32[] parameter(1)\n+    ROOT sum = f32[] add(a, b)\n+  }\n+\n+  ENTRY main {\n+    p0 = f32[8] parameter(0)\n+    ar = f32[8] all-reduce(p0), replica_groups={{0,1}, {2,3}}, to_apply=sum\n+    ROOT rs = f32[4] reduce-scatter(ar), dimensions={0}, replica_groups={{0,2}, {1,3}}, to_apply=sum\n+  }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_text));\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunHloPass(&pass_, module.get()));\n+  EXPECT_TRUE(changed);\n+\n+  HloInstruction* param = module->entry_computation()->parameter_instruction(0);\n+  HloInstruction* new_rs = param->users().front();\n+  HloInstruction* new_ar = new_rs->users().front();\n+\n+  EXPECT_EQ(new_rs->replica_groups().size(), 2);\n+  EXPECT_THAT(new_rs->replica_groups()[0].replica_ids(),\n+              ::testing::ElementsAre(0, 2));\n+  EXPECT_THAT(new_rs->replica_groups()[1].replica_ids(),\n+              ::testing::ElementsAre(1, 3));\n+\n+  EXPECT_EQ(new_ar->replica_groups().size(), 2);\n+  EXPECT_THAT(new_ar->replica_groups()[0].replica_ids(),\n+              ::testing::ElementsAre(0, 1));\n+  EXPECT_THAT(new_ar->replica_groups()[1].replica_ids(),\n+              ::testing::ElementsAre(2, 3));\n+\n+  EXPECT_EQ(new_rs->opcode(), HloOpcode::kReduceScatter);\n+  EXPECT_EQ(new_ar->opcode(), HloOpcode::kAllReduce);\n+\n+  EXPECT_EQ(new_rs->shape().dimensions(0), 4);\n+  EXPECT_EQ(new_ar->shape().dimensions(0), 4);\n+\n+  EXPECT_EQ(new_ar, module->entry_computation()->root_instruction());\n+}\n+\n+TEST_F(AllReduceReduceScatterReorderTest, AllReduceMultipleUsers) {\n+  absl::string_view hlo_text = R\"(\n+  sum {\n+    a = f32[] parameter(0)\n+    b = f32[] parameter(1)\n+    ROOT sum = f32[] add(a, b)\n+  }\n+\n+  ENTRY main {\n+    p0 = f32[8] parameter(0)\n+    ar = f32[8] all-reduce(p0), replica_groups={}, to_apply=sum\n+    rs = f32[4] reduce-scatter(ar), dimensions={0}, replica_groups={}, to_apply=sum\n+    ROOT tuple = (f32[8], f32[4]) tuple(ar, rs)\n+  }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_text));\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunHloPass(&pass_, module.get()));\n+  EXPECT_FALSE(changed);\n+}\n+\n+TEST_F(AllReduceReduceScatterReorderTest, DifferentReductionFunctions) {\n+  absl::string_view hlo_text = R\"(\n+  sum {\n+    a = f32[] parameter(0)\n+    b = f32[] parameter(1)\n+    ROOT sum = f32[] add(a, b)\n+  }\n+\n+  product {\n+    a = f32[] parameter(0)\n+    b = f32[] parameter(1)\n+    ROOT product = f32[] multiply(a, b)\n+  }\n+\n+  ENTRY main {\n+    p0 = f32[8] parameter(0)\n+    ar = f32[8] all-reduce(p0), replica_groups={}, to_apply=sum\n+    ROOT rs = f32[4] reduce-scatter(ar), dimensions={0}, replica_groups={}, to_apply=product\n+  }\n+  )\";\n+  TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> module,\n+                          ParseAndReturnVerifiedModule(hlo_text));\n+  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunHloPass(&pass_, module.get()));\n+  EXPECT_FALSE(changed);\n+}\n+\n+}  // namespace\n+}  // namespace xla"
        }
    ],
    "stats": {
        "total": 300,
        "additions": 300,
        "deletions": 0
    }
}