{
    "author": "WillFroom",
    "message": "[XLA:GPU][XTile] Fold / squeeze xtile.mask when lowering to triton.\n\nPiperOrigin-RevId: 836532355",
    "sha": "8dcfef8084e942754843ce21884c73d7848aff0f",
    "files": [
        {
            "sha": "98851a1d7429b0864fe93881a3496d709d143781",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_fold_transpose.mlir",
            "status": "modified",
            "additions": 8,
            "deletions": 0,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_fold_transpose.mlir?ref=8dcfef8084e942754843ce21884c73d7848aff0f",
            "patch": "@@ -71,3 +71,11 @@ func.func @push_transpose_up_through_reshape(%arg0: tensor<4x8x2xf32>) -> tensor\n   %1 = tt.trans %0 {order = array<i32: 1, 0>} : tensor<4x16xf32> -> tensor<16x4xf32>\n   return %1 : tensor<16x4xf32>\n }\n+\n+// CHECK-LABEL: func @push_transpose_up_through_mask\n+func.func @push_transpose_up_through_mask(%arg0: tensor<4x8xf32>, %arg1: f32) -> tensor<8x4xf32> {\n+  // CHECK: xtile.mask %{{.*}} bounds [7, 3], %arg1 : tensor<8x4xf32>\n+  %0 = xtile.mask %arg0 bounds [3, 7], %arg1 : tensor<4x8xf32>\n+  %1 = tt.trans %0 {order = array<i32: 1, 0>} : tensor<4x8xf32> -> tensor<8x4xf32>\n+  return %1 : tensor<8x4xf32>\n+}"
        },
        {
            "sha": "42eb59d0824897e41022c5cadf00ab82e085d63e",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_squeeze_dims.mlir",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_squeeze_dims.mlir?ref=8dcfef8084e942754843ce21884c73d7848aff0f",
            "patch": "@@ -256,3 +256,14 @@ func.func @squeeze_dims_to_reshape(%arg0: tensor<4x1x8xf32>) -> tensor<4x8xf32>\n   %0 = triton_xla.squeeze_dims %arg0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n   return %0 : tensor<4x8xf32>\n }\n+\n+// -----\n+\n+// CHECK-LABEL: func @push_squeeze_dims_up_through_mask\n+func.func @push_squeeze_dims_up_through_mask(\n+    %arg0: tensor<4x1x8xf32>, %arg1: f32) -> tensor<4x8xf32> {\n+  // CHECK: xtile.mask %{{.*}} bounds [4, 6], %arg1 : tensor<4x8xf32>\n+  %0 = xtile.mask %arg0 bounds [4, 1, 6], %arg1 : tensor<4x1x8xf32>\n+  %1 = triton_xla.squeeze_dims %0 {axis = 1 : i32} : tensor<4x1x8xf32> -> tensor<4x8xf32>\n+  return %1 : tensor<4x8xf32>\n+}"
        },
        {
            "sha": "515743f7f93617d9762c57e28cbe35da157620b3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_fold_transpose_pass.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_fold_transpose_pass.cc?ref=8dcfef8084e942754843ce21884c73d7848aff0f",
            "patch": "@@ -317,6 +317,26 @@ LogicalResult PushTransposeUpThroughReshape(TransOp op,\n   return success();\n }\n \n+LogicalResult PushTransposeUpThroughMask(TransOp op,\n+                                         PatternRewriter& rewriter) {\n+  auto mask_op = op.getSrc().getDefiningOp<::xla::xtile::MaskOp>();\n+  if (!mask_op) {\n+    return rewriter.notifyMatchFailure(op, \"source is not a mask op\");\n+  }\n+\n+  llvm::SmallVector<int64_t> new_bounds(op.getOrder().size());\n+  for (auto [idx, dim] : llvm::enumerate(op.getOrder())) {\n+    new_bounds[idx] = mask_op.getBounds()[dim];\n+  }\n+\n+  auto new_transpose = TransOp::create(rewriter, op.getLoc(),\n+                                       mask_op.getSource(), op.getOrderAttr());\n+\n+  rewriter.replaceOpWithNewOp<::xla::xtile::MaskOp>(\n+      op, op.getType(), new_transpose, new_bounds, mask_op.getValue());\n+  return success();\n+}\n+\n class TritonXLAFoldTransposePass\n     : public impl::TritonXLAFoldTransposePassBase<TritonXLAFoldTransposePass> {\n  public:\n@@ -332,6 +352,7 @@ class TritonXLAFoldTransposePass\n     patterns.add(PushTransposeUpThroughElementwise);\n     patterns.add(PushTransposeUpThroughExpandDims);\n     patterns.add(PushTransposeUpThroughReshape);\n+    patterns.add(PushTransposeUpThroughMask);\n     if (failed(applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n       return signalPassFailure();\n     }"
        },
        {
            "sha": "15b92bf130a67984bd0dc6586bf12302285c58fe",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_squeeze_dims_pass.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8dcfef8084e942754843ce21884c73d7848aff0f/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_squeeze_dims_pass.cc?ref=8dcfef8084e942754843ce21884c73d7848aff0f",
            "patch": "@@ -486,6 +486,24 @@ LogicalResult ReorderSqueezeDims(SqueezeDimsOp op, PatternRewriter& rewriter) {\n   return success();\n }\n \n+LogicalResult PushSqueezeDimsUpThroughMask(::xla::xtile::MaskOp op,\n+                                           PatternRewriter& rewriter) {\n+  std::optional<uint32_t> axis = GetSqueezeDimsUserAxis(op);\n+  if (!axis) {\n+    return rewriter.notifyMatchFailure(op, \"No squeeze_dims users.\");\n+  }\n+\n+  auto new_operand = SqueezeTensorValue(rewriter, op.getSource(), *axis);\n+\n+  llvm::SmallVector<int64_t> new_bounds(op.getBounds());\n+  new_bounds.erase(new_bounds.begin() + *axis);\n+\n+  auto new_mask = ::xla::xtile::MaskOp::create(\n+      rewriter, op.getLoc(), new_operand, new_bounds, op.getValue());\n+  ReplaceOpWithExpandDimsOf(rewriter, op, new_mask->getResults(), *axis);\n+  return success();\n+}\n+\n // Converts squeeze_dims to tt.reshape.\n LogicalResult SqueezeDimsToReshape(SqueezeDimsOp op,\n                                    PatternRewriter& rewriter) {\n@@ -525,6 +543,7 @@ class TritonXLASqueezeDimsPass\n     patterns.add(PushSqueezeDimsUpThroughReduce);\n     patterns.add(PushSqueezeDimsUpThroughTrans);\n     patterns.add(ReorderSqueezeDims);\n+    patterns.add(PushSqueezeDimsUpThroughMask);\n     if (failed(applyPatternsGreedily(getOperation(), std::move(patterns)))) {\n       return signalPassFailure();\n     }"
        }
    ],
    "stats": {
        "total": 59,
        "additions": 59,
        "deletions": 0
    }
}