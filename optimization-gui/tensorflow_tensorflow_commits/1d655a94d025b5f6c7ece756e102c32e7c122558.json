{
    "author": "ermilovmaxim",
    "message": "Add Shape to ConditionalThunk buffer_uses\n\nModify Thunk's serialization\n\nPiperOrigin-RevId: 843541791",
    "sha": "1d655a94d025b5f6c7ece756e102c32e7c122558",
    "files": [
        {
            "sha": "e51e4f946e99555b552a3e9ce7601816b1b08676",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -449,6 +449,7 @@ cc_library(\n     deps = [\n         \":host_memory_pool\",\n         \":sequential_thunk\",\n+        \":shaped_slice\",\n         \":thunk\",\n         \":thunk_proto_cc\",\n         \"//xla:status_macros\",\n@@ -481,8 +482,10 @@ xla_cc_test(\n     deps = [\n         \":conditional_thunk\",\n         \":sequential_thunk\",\n+        \":shaped_slice\",\n         \":thunk\",\n         \":thunk_proto_cc\",\n+        \"//xla:shape_util\",\n         \"//xla/service:buffer_assignment\",\n         \"//xla/tsl/lib/core:status_test_util\",\n         \"//xla/tsl/platform:statusor\",\n@@ -2243,6 +2246,7 @@ xla_cc_test(\n         \":thunk\",\n         \":thunk_proto_cc\",\n         \":while_thunk\",\n+        \"//xla:shape_util\",\n         \"//xla/service:buffer_assignment\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n@@ -3307,6 +3311,7 @@ xla_cc_test(\n         \":custom_call_thunk\",\n         \":runtime_intrinsics\",\n         \":sequential_thunk\",\n+        \":shaped_slice\",\n         \":thunk\",\n         \":thunk_buffer_debug_pass\",\n         \":thunk_id\","
        },
        {
            "sha": "f5cbe9d43370fcb6c0427ce05e819df624f193a9",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -1505,11 +1505,11 @@ absl::StatusOr<const se::CommandBuffer::Command*> ChildCmd::Record(\n // CaseCmd\n //===----------------------------------------------------------------------===//\n \n-CaseCmd::CaseCmd(BufferAllocation::Slice index, bool index_is_bool,\n+CaseCmd::CaseCmd(ShapedSlice index,\n                  std::vector<CommandBufferCmdExecutor> branches)\n     : CommandBufferCmd(CommandBufferCmdType::kCaseCmd),\n       index_(index),\n-      index_is_bool_(index_is_bool),\n+      index_is_bool_(index.shape.element_type() == PRED),\n       branches_(std::move(branches)) {}\n \n absl::Status CaseCmd::Initialize(const Thunk::InitializeParams& params,\n@@ -1525,7 +1525,7 @@ absl::StatusOr<const se::CommandBuffer::Command*> CaseCmd::Record(\n     const RecordParams& record_params, RecordAction record_action,\n     se::CommandBuffer* command_buffer) {\n   se::DeviceAddressBase index =\n-      execute_params.buffer_allocations->GetDeviceAddress(index_);\n+      execute_params.buffer_allocations->GetDeviceAddress(index_.slice);\n \n   VLOG(5) << \"CaseCmd:\";\n   VLOG(5) << \"  index: \" << index_ << \" (\" << index.opaque() << \")\";\n@@ -1568,7 +1568,7 @@ bool CaseCmd::force_update() {\n \n CommandBufferCmd::BufferUseVector CaseCmd::buffers() const {\n   absl::flat_hash_set<BufferUse> buffers;\n-  buffers.emplace(BufferUse::Read(index_));\n+  buffers.emplace(BufferUse::Read(index_.slice, index_.shape));\n   for (auto& branch : branches_) {\n     buffers.insert(branch.buffers().begin(), branch.buffers().end());\n   }"
        },
        {
            "sha": "f6bc947262cde56e721880799beae8f25ba11d9a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.h",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.h?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -869,8 +869,7 @@ class ChildCmd : public CommandBufferCmd {\n \n class CaseCmd : public CommandBufferCmd {\n  public:\n-  CaseCmd(BufferAllocation::Slice index, bool index_is_bool,\n-          std::vector<CommandBufferCmdExecutor> branches);\n+  CaseCmd(ShapedSlice index, std::vector<CommandBufferCmdExecutor> branches);\n \n   absl::Status Initialize(const Thunk::InitializeParams& params,\n                           StateManager& state) override;\n@@ -889,7 +888,7 @@ class CaseCmd : public CommandBufferCmd {\n   BufferUseVector buffers() const override;\n \n  private:\n-  BufferAllocation::Slice index_;\n+  ShapedSlice index_;\n   bool index_is_bool_;\n   std::vector<CommandBufferCmdExecutor> branches_;\n };"
        },
        {
            "sha": "8865fdf58530608a3187aef412ceac251f6e825b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd_emitter.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd_emitter.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -160,7 +160,6 @@ static absl::StatusOr<Command> Convert(\n     }\n   }\n   return std::make_unique<CaseCmd>(thunk.branch_index_buffer(),\n-                                   thunk.branch_index_is_bool(),\n                                    std::move(branch_cmds));\n }\n "
        },
        {
            "sha": "f03e3c3b3e944e2880db3376387b7163dfe30264",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_conversion_pass_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_conversion_pass_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -183,16 +183,17 @@ std::unique_ptr<ConditionalThunk> CreateConditionalThunk(\n     std::vector<std::vector<std::unique_ptr<Thunk>>> branch_thunks) {\n   BufferAllocation alloc(0, 1024, 0);\n   BufferAllocation::Slice slice(&alloc, 0, 1024);\n+  Shape shape = ShapeUtil::MakeShape(S32, {});\n \n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunk_sequences;\n   for (auto& thunks : branch_thunks) {\n     branch_thunk_sequences.push_back(std::make_unique<SequentialThunk>(\n         Thunk::ThunkInfo(), std::move(thunks)));\n   }\n \n-  return std::make_unique<ConditionalThunk>(Thunk::ThunkInfo(), slice,\n-                                            std::move(branch_thunk_sequences),\n-                                            /*branch_index_is_bool=*/false);\n+  return std::make_unique<ConditionalThunk>(Thunk::ThunkInfo(),\n+                                            ShapedSlice{slice, shape},\n+                                            std::move(branch_thunk_sequences));\n }\n \n std::unique_ptr<CustomCallThunk> CreateCustomCallThunk("
        },
        {
            "sha": "b67163dc79450883ad9dbff47ad56bfc78acafcb",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_thunk_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_thunk_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -1384,6 +1384,8 @@ TEST(CommandBufferThunkTest, CaseCmd) {\n   BufferAllocation alloc_b(/*index=*/2, byte_length, /*color=*/0);\n \n   BufferAllocation::Slice slice_i(&alloc_i, 0, sizeof(int32_t));\n+  Shape i_shape = ShapeUtil::MakeShape(S32, {});\n+\n   BufferAllocation::Slice slice_a(&alloc_a, 0, byte_length);\n   BufferAllocation::Slice slice_b(&alloc_b, 0, byte_length);\n \n@@ -1417,7 +1419,7 @@ TEST(CommandBufferThunkTest, CaseCmd) {\n \n   // Prepare commands sequence for thunk.\n   CommandBufferCmdSequence commands;\n-  commands.Emplace<CaseCmd>(slice_i, false, std::move(branches));\n+  commands.Emplace<CaseCmd>(ShapedSlice{slice_i, i_shape}, std::move(branches));\n   TF_ASSERT_OK_AND_ASSIGN(\n       CommandBufferCmdExecutor executor,\n       CommandBufferCmdExecutor::Create(std::move(commands), serialize));"
        },
        {
            "sha": "49602cbf3fda36a38684e0552da43b2e73cf3a7b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/conditional_thunk.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 15,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/host_memory_pool.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n@@ -48,14 +49,18 @@ namespace xla {\n namespace gpu {\n \n ConditionalThunk::ConditionalThunk(\n-    ThunkInfo thunk_info,\n-    const BufferAllocation::Slice& branch_index_buffer_index,\n-    std::vector<std::unique_ptr<SequentialThunk>>&& branch_thunks,\n-    bool branch_index_is_bool)\n+    ThunkInfo thunk_info, const ShapedSlice& branch_index_buffer_index,\n+    std::vector<std::unique_ptr<SequentialThunk>>&& branch_thunks)\n     : Thunk(Kind::kConditional, thunk_info),\n       branch_index_buffer_index_(branch_index_buffer_index),\n       branch_thunks_(std::move(branch_thunks)),\n-      branch_index_is_bool_(branch_index_is_bool) {}\n+      branch_index_is_bool_(branch_index_buffer_index.shape.element_type() ==\n+                            PRED) {\n+  PrimitiveType element_type = branch_index_buffer_index.shape.element_type();\n+  CHECK(element_type == PRED || element_type == S32);\n+  CHECK_EQ(branch_index_buffer_index.shape.dimensions(),\n+           std::vector<int64_t>{});\n+}\n \n absl::Status ConditionalThunk::Prepare(const PrepareParams& params) {\n   if (branch_index_is_bool_) {\n@@ -111,7 +116,8 @@ absl::Status ConditionalThunk::ExecuteOnStream(const ExecuteParams& params) {\n   }();\n \n   se::DeviceAddressBase branch_index_address =\n-      params.buffer_allocations->GetDeviceAddress(branch_index_buffer_index_);\n+      params.buffer_allocations->GetDeviceAddress(\n+          branch_index_buffer_index_.slice);\n   if (branch_index_is_bool_) {\n     TF_RETURN_IF_ERROR(stream.Memcpy(std::get<bool*>(branch_index_or_pred),\n                                      branch_index_address, sizeof(bool)));\n@@ -191,19 +197,16 @@ absl::StatusOr<ThunkProto> ConditionalThunk::ToProto() const {\n     *conditional_thunk_proto->add_branch_thunks() =\n         std::move(seq_thunk_proto).sequential_thunk();\n   }\n-\n-  conditional_thunk_proto->set_branch_index_is_bool(branch_index_is_bool_);\n   return proto;\n }\n \n absl::StatusOr<std::unique_ptr<ConditionalThunk>> ConditionalThunk::FromProto(\n     ThunkInfo thunk_info, const ConditionalThunkProto& thunk_proto,\n     absl::Span<const BufferAllocation> buffer_allocations,\n     const Deserializer& deserializer) {\n-  TF_ASSIGN_OR_RETURN(\n-      BufferAllocation::Slice branch_index_buffer_index,\n-      BufferAllocation::Slice::FromProto(thunk_proto.branch_index_buffer(),\n-                                         buffer_allocations));\n+  TF_ASSIGN_OR_RETURN(ShapedSlice branch_index_buffer_index,\n+                      ShapedSlice::FromProto(thunk_proto.branch_index_buffer(),\n+                                             buffer_allocations));\n \n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks;\n   branch_thunks.reserve(thunk_proto.branch_thunks_size());\n@@ -213,9 +216,9 @@ absl::StatusOr<std::unique_ptr<ConditionalThunk>> ConditionalThunk::FromProto(\n         SequentialThunk::FromProto(thunk_info, seq_thunk_proto, deserializer));\n     branch_thunks.push_back(std::move(seq_thunk));\n   }\n-  return std::make_unique<ConditionalThunk>(\n-      std::move(thunk_info), branch_index_buffer_index,\n-      std::move(branch_thunks), thunk_proto.branch_index_is_bool());\n+  return std::make_unique<ConditionalThunk>(std::move(thunk_info),\n+                                            branch_index_buffer_index,\n+                                            std::move(branch_thunks));\n }\n \n std::string ConditionalThunk::ToString(int indent) const {"
        },
        {
            "sha": "cc03a6cdc4c0fafe38406fd209698772a8905d36",
            "filename": "third_party/xla/xla/backends/gpu/runtime/conditional_thunk.h",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk.h?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -29,6 +29,7 @@ limitations under the License.\n #include \"absl/types/span.h\"\n #include \"xla/backends/gpu/runtime/host_memory_pool.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/runtime/buffer_use.h\"\n@@ -51,10 +52,8 @@ namespace gpu {\n class ConditionalThunk : public Thunk {\n  public:\n   ConditionalThunk(\n-      ThunkInfo thunk_info,\n-      const BufferAllocation::Slice& branch_index_buffer_index,\n-      std::vector<std::unique_ptr<SequentialThunk>>&& branch_thunks,\n-      bool branch_index_is_bool);\n+      ThunkInfo thunk_info, const ShapedSlice& branch_index_buffer_index,\n+      std::vector<std::unique_ptr<SequentialThunk>>&& branch_thunks);\n \n   ConditionalThunk(const ConditionalThunk&) = delete;\n   ConditionalThunk& operator=(const ConditionalThunk&) = delete;\n@@ -67,7 +66,7 @@ class ConditionalThunk : public Thunk {\n     return branch_thunks_;\n   }\n \n-  const BufferAllocation::Slice& branch_index_buffer() const {\n+  const ShapedSlice& branch_index_buffer() const {\n     return branch_index_buffer_index_;\n   }\n \n@@ -82,7 +81,8 @@ class ConditionalThunk : public Thunk {\n \n   BufferUses buffer_uses() const override {\n     return {\n-        BufferUse::Read(branch_index_buffer_index_),\n+        BufferUse::Read(branch_index_buffer_index_.slice,\n+                        branch_index_buffer_index_.shape),\n     };\n   }\n \n@@ -105,7 +105,7 @@ class ConditionalThunk : public Thunk {\n   std::string ToString(int indent) const override;\n \n  private:\n-  const BufferAllocation::Slice branch_index_buffer_index_;\n+  const ShapedSlice branch_index_buffer_index_;\n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks_;\n   bool branch_index_is_bool_;\n "
        },
        {
            "sha": "4207aca6afbbb7d044d892c32b3db938df883e81",
            "filename": "third_party/xla/xla/backends/gpu/runtime/conditional_thunk_test.cc",
            "status": "modified",
            "additions": 36,
            "deletions": 22,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fconditional_thunk_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -27,9 +27,12 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"google/protobuf/text_format.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/tsl/platform/test.h\"\n@@ -67,18 +70,16 @@ struct DummyThunk : public Thunk {\n \n std::unique_ptr<ConditionalThunk> CreateConditionalThunk(\n     const Thunk::ThunkInfo& thunk_info,\n-    const BufferAllocation::Slice& branch_index_buffer_index,\n-    std::vector<ThunkSequence> branch_thunk_sequences,\n-    bool kBranchIndexIsBool) {\n+    const ShapedSlice& branch_index_buffer_index,\n+    std::vector<ThunkSequence> branch_thunk_sequences) {\n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks;\n   for (auto& thunk_sequence : branch_thunk_sequences) {\n     branch_thunks.push_back(std::make_unique<SequentialThunk>(\n         thunk_info, std::move(thunk_sequence)));\n   }\n \n   return std::make_unique<ConditionalThunk>(\n-      thunk_info, branch_index_buffer_index, std::move(branch_thunks),\n-      kBranchIndexIsBool);\n+      thunk_info, branch_index_buffer_index, std::move(branch_thunks));\n }\n \n TEST(ConditionalThunkTest, BufferUses) {\n@@ -87,7 +88,10 @@ TEST(ConditionalThunkTest, BufferUses) {\n   thunk_info.execution_stream_id = 123;\n \n   BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n+\n+  constexpr bool kBranchIndexIsBool = true;\n   BufferAllocation::Slice slice(&alloc, /*offset=*/0, /*size=*/256);\n+  Shape shape = ShapeUtil::MakeShape(PRED, {});\n \n   ThunkSequence false_seq;\n   false_seq.push_back(std::make_unique<DummyThunk>(Kind::kGemm, thunk_info));\n@@ -101,12 +105,11 @@ TEST(ConditionalThunkTest, BufferUses) {\n   branch_thunk_sequences.push_back(std::move(false_seq));\n   branch_thunk_sequences.push_back(std::move(true_seq));\n \n-  constexpr bool kBranchIndexIsBool = true;\n   std::unique_ptr<ConditionalThunk> thunk = CreateConditionalThunk(\n-      thunk_info, slice, std::move(branch_thunk_sequences), kBranchIndexIsBool);\n+      thunk_info, {slice, shape}, std::move(branch_thunk_sequences));\n \n   EXPECT_EQ(thunk->branch_index_is_bool(), kBranchIndexIsBool);\n-  EXPECT_EQ(thunk->branch_index_buffer(), slice);\n+  EXPECT_EQ(thunk->branch_index_buffer().slice, slice);\n \n   auto thunk_matcher = Pointee(Property(&Thunk::kind, Thunk::Kind::kGemm));\n   auto branch_matcher = Pointee(Property(\n@@ -122,6 +125,7 @@ TEST(ConditionalThunkTest, ToProto) {\n \n   BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n   BufferAllocation::Slice slice(&alloc, /*offset=*/0, /*size=*/256);\n+  Shape shape = ShapeUtil::MakeShape(PRED, {});\n \n   ThunkSequence false_seq;\n   false_seq.push_back(std::make_unique<DummyThunk>(Kind::kGemm, thunk_info));\n@@ -135,9 +139,8 @@ TEST(ConditionalThunkTest, ToProto) {\n   branch_thunk_seq.push_back(std::move(false_seq));\n   branch_thunk_seq.push_back(std::move(true_seq));\n \n-  constexpr bool kBranchIndexIsBool = true;\n   std::unique_ptr<ConditionalThunk> thunk = CreateConditionalThunk(\n-      thunk_info, slice, std::move(branch_thunk_seq), kBranchIndexIsBool);\n+      thunk_info, {slice, shape}, std::move(branch_thunk_seq));\n   TF_ASSERT_OK_AND_ASSIGN(ThunkProto proto, thunk->ToProto());\n \n   std::string expected = R\"pb(\n@@ -146,7 +149,13 @@ TEST(ConditionalThunkTest, ToProto) {\n       execution_stream_id: 123\n     }\n     conditional_thunk {\n-      branch_index_buffer { size: 256 }\n+      branch_index_buffer {\n+        slice { size: 256 }\n+        shape {\n+          element_type: PRED\n+          layout { tail_padding_alignment_in_elements: 1 }\n+        }\n+      }\n       branch_thunks {\n         thunks {\n           thunk_info {\n@@ -175,7 +184,6 @@ TEST(ConditionalThunkTest, ToProto) {\n           }\n         }\n       }\n-      branch_index_is_bool: true\n     }\n   )pb\";\n   EXPECT_THAT(proto, EqualsProto(expected));\n@@ -190,7 +198,13 @@ TEST(ConditionalThunkTest, FromProto) {\n           execution_stream_id: 123\n         }\n         conditional_thunk {\n-          branch_index_buffer { offset: 8 size: 256 buffer_allocation_index: 0 }\n+          branch_index_buffer {\n+            slice { offset: 8 size: 256 buffer_allocation_index: 0 }\n+            shape {\n+              element_type: PRED\n+              layout { tail_padding_alignment_in_elements: 1 }\n+            }\n+          }\n           branch_thunks {\n             thunks {\n               thunk_info {\n@@ -219,7 +233,6 @@ TEST(ConditionalThunkTest, FromProto) {\n               }\n             }\n           }\n-          branch_index_is_bool: true\n         }\n       )pb\",\n       &proto));\n@@ -248,6 +261,8 @@ TEST(ConditionalThunkTest, ToString) {\n \n   BufferAllocation alloc(/*index=*/0, /*size=*/1024, /*color=*/0);\n   BufferAllocation::Slice slice(&alloc, /*offset=*/0, /*size=*/256);\n+  Shape bool_shape = ShapeUtil::MakeShape(PRED, {});\n+  Shape int_shape = ShapeUtil::MakeShape(S32, {});\n \n   auto create_branch_thunk_sequences = [&]() -> std::vector<ThunkSequence> {\n     ThunkSequence false_seq;\n@@ -264,9 +279,8 @@ TEST(ConditionalThunkTest, ToString) {\n   };\n \n   ThunkSequence thunk_sequence;\n-  thunk_sequence.push_back(\n-      CreateConditionalThunk(thunk_info, slice, create_branch_thunk_sequences(),\n-                             /*kBranchIndexIsBool=*/true));\n+  thunk_sequence.push_back(CreateConditionalThunk(\n+      thunk_info, {slice, bool_shape}, create_branch_thunk_sequences()));\n   auto sequential_thunk =\n       std::make_unique<SequentialThunk>(thunk_info, std::move(thunk_sequence));\n   EXPECT_EQ(sequential_thunk->ToString(/*indent=*/0),\n@@ -277,9 +291,8 @@ TEST(ConditionalThunkTest, ToString) {\n             \"    000: kGemm\\t\\n\"\n             \"    000: kGemm\\t\\n\\n\");\n \n-  std::unique_ptr<ConditionalThunk> thunk =\n-      CreateConditionalThunk(thunk_info, slice, create_branch_thunk_sequences(),\n-                             /*kBranchIndexIsBool=*/false);\n+  std::unique_ptr<ConditionalThunk> thunk = CreateConditionalThunk(\n+      thunk_info, {slice, int_shape}, create_branch_thunk_sequences());\n \n   EXPECT_EQ(thunk->ToString(/*indent=*/0),\n             \"\\n\"\n@@ -292,14 +305,15 @@ TEST(ConditionalThunkTest, ToString) {\n \n TEST(ConditionalThunkTest, TransformAllNestedThunks) {\n   BufferAllocation::Slice slice;\n+  Shape shape = ShapeUtil::MakeShape(S32, {});\n+\n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks;\n   branch_thunks.push_back(\n       std::make_unique<SequentialThunk>(Thunk::ThunkInfo(), ThunkSequence()));\n   branch_thunks.push_back(\n       std::make_unique<SequentialThunk>(Thunk::ThunkInfo(), ThunkSequence()));\n   auto conditional_thunk = std::make_unique<ConditionalThunk>(\n-      Thunk::ThunkInfo(), slice, std::move(branch_thunks),\n-      /*branch_index_is_bool=*/false);\n+      Thunk::ThunkInfo(), ShapedSlice{slice, shape}, std::move(branch_thunks));\n \n   TF_EXPECT_OK(conditional_thunk->TransformAllNestedThunks([](auto) {\n     return std::make_unique<DummyThunk>(Kind::kCustomCall, Thunk::ThunkInfo());"
        },
        {
            "sha": "bec1a8fedb07a1748e4c549c9004108589448e07",
            "filename": "third_party/xla/xla/backends/gpu/runtime/for_all_thunks_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffor_all_thunks_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffor_all_thunks_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Ffor_all_thunks_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -30,6 +30,8 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/thunk.pb.h\"\n #include \"xla/backends/gpu/runtime/while_thunk.h\"\n #include \"xla/service/buffer_assignment.h\"\n+#include \"xla/shape.h\"\n+#include \"xla/shape_util.h\"\n \n namespace xla::gpu {\n namespace {\n@@ -106,11 +108,14 @@ TEST(ForAllThunksTest, ConditionalThunk) {\n       Thunk::ThunkInfo(), std::move(thunk_sequence));\n   SequentialThunk* sequential_thunk_ptr = sequential_thunk.get();\n \n+  BufferAllocation alloc(0, 1024, 0);\n+  BufferAllocation::Slice slice(&alloc, 0, 4);\n+  Shape shape = ShapeUtil::MakeShape(S32, {});\n+\n   std::vector<std::unique_ptr<SequentialThunk>> branch_thunks;\n   branch_thunks.push_back(std::move(sequential_thunk));\n-  ConditionalThunk conditional_thunk(\n-      Thunk::ThunkInfo(), BufferAllocation::Slice(), std::move(branch_thunks),\n-      /*branch_index_is_bool=*/false);\n+  ConditionalThunk conditional_thunk(Thunk::ThunkInfo(), {slice, shape},\n+                                     std::move(branch_thunks));\n \n   EXPECT_THAT(GetAllThunks(&conditional_thunk),\n               UnorderedElementsAre(thunk_ptr, sequential_thunk_ptr,"
        },
        {
            "sha": "5a698ae7e8046fd2d1909732eb88fdceda0ba392",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk.proto",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk.proto?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -71,9 +71,8 @@ message DeviceToDeviceCopyThunkProto {\n }\n \n message ConditionalThunkProto {\n-  xla.buffer_assignment.BufferAllocationSliceProto branch_index_buffer = 1;\n+  ShapedSliceProto branch_index_buffer = 1;\n   repeated SequentialThunkProto branch_thunks = 2;\n-  bool branch_index_is_bool = 3;\n }\n \n message WhileThunkProto {"
        },
        {
            "sha": "135f3e42694bd2fff173e0f19b705d9335af345e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_buffer_debug_pass_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 4,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_buffer_debug_pass_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -32,6 +32,7 @@ limitations under the License.\n #include \"xla/backends/gpu/runtime/custom_call_thunk.h\"\n #include \"xla/backends/gpu/runtime/runtime_intrinsics.h\"\n #include \"xla/backends/gpu/runtime/sequential_thunk.h\"\n+#include \"xla/backends/gpu/runtime/shaped_slice.h\"\n #include \"xla/backends/gpu/runtime/thunk.h\"\n #include \"xla/backends/gpu/runtime/thunk_buffer_debug_saver_inserter.h\"\n #include \"xla/backends/gpu/runtime/thunk_id.h\"\n@@ -300,11 +301,13 @@ TEST_F(ThunkBufferDebugPassTest, RecursivelyInsertsBuffersDebugChecksumThunks) {\n       SequentialThunk::FromThunk(std::move(conditional_branch0_thunk)));\n   branch_thunks.push_back(\n       SequentialThunk::FromThunk(std::move(conditional_branch1_thunk)));\n+\n+  Shape condition_shape = ShapeUtil::MakeShape(PRED, {});\n+  BufferAllocation::Slice condition_slice = CreateSlice();\n+\n   auto conditional_thunk = std::make_unique<ConditionalThunk>(\n-      Thunk::ThunkInfo(),\n-      /*branch_index_buffer_index=*/BufferAllocation::Slice(),\n-      std::move(branch_thunks),\n-      /*branch_index_is_bool=*/true);\n+      Thunk::ThunkInfo(), ShapedSlice{condition_slice, condition_shape},\n+      std::move(branch_thunks));\n   const Thunk* const conditional_thunk_ptr = conditional_thunk.get();\n   std::vector<std::unique_ptr<Thunk>> while_body_thunks;\n   while_body_thunks.push_back(std::move(while_body_fake_thunk));"
        },
        {
            "sha": "ca04379d3bf19498959ad1686d966616d7a05c9d",
            "filename": "third_party/xla/xla/backends/gpu/runtime/thunk_proto_deserialization_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fthunk_proto_deserialization_test.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -436,7 +436,10 @@ TEST(ThunkProtoDeserializationTest, ConditionalThunk) {\n           execution_stream_id: 123\n         }\n         conditional_thunk {\n-          branch_index_buffer { offset: 8 size: 256 buffer_allocation_index: 5 }\n+          branch_index_buffer {\n+            slice { offset: 8 size: 1 buffer_allocation_index: 5 }\n+            shape { element_type: PRED }\n+          }\n           branch_thunks {\n             thunks {\n               thunk_info {\n@@ -569,7 +572,6 @@ TEST(ThunkProtoDeserializationTest, ConditionalThunk) {\n               }\n             }\n           }\n-          branch_index_is_bool: true\n         }\n       )pb\");\n "
        },
        {
            "sha": "2dc34ce63ca7ea2484b67c683b8499dc4f772da5",
            "filename": "third_party/xla/xla/service/gpu/thunk_emitter.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/1d655a94d025b5f6c7ece756e102c32e7c122558/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fthunk_emitter.cc?ref=1d655a94d025b5f6c7ece756e102c32e7c122558",
            "patch": "@@ -428,12 +428,13 @@ absl::StatusOr<ThunkSequence> ThunkEmitter::EmitConditional(\n   }\n   TF_ASSIGN_OR_RETURN(auto slice,\n                       GetAllocationSliceForHlo(instr->operand(0), {}));\n-  bool branch_index_is_bool = instr->operand(0)->shape().element_type() == PRED;\n \n-  return GetThunkSequence(std::make_unique<ConditionalThunk>(\n+  auto placeholder = GetThunkSequence(std::make_unique<ConditionalThunk>(\n       Thunk::ThunkInfo::WithProfileAnnotation(\n           instr, ir_emitter_context_->GetNextThunkId()),\n-      slice, std::move(branch_thunks), branch_index_is_bool));\n+      ShapedSlice{slice, instr->operand(0)->shape()},\n+      std::move(branch_thunks)));\n+  return placeholder;\n }\n \n // Input = {dynamic array(with dynamic dimension meta data at the end)}"
        }
    ],
    "stats": {
        "total": 173,
        "additions": 103,
        "deletions": 70
    }
}