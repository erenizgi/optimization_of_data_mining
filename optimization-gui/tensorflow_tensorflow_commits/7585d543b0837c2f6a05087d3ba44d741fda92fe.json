{
    "author": "hawkinsp",
    "message": "[PJRT] Change BuildPlanNodes, ChooseParallelizationStrategy, and the loop ordering code to look only at Loop objects, not other parts of the transpose plan.\n\nThis simplifies the code since we can compute the properties of a loop nest once from the transpose specification, and then subsequent phases can work on those loops only, rather than looking up properties of dimensions in other data structures.\n\nRefactoring only, no behavior changes intended.\n\nPiperOrigin-RevId: 845900348",
    "sha": "7585d543b0837c2f6a05087d3ba44d741fda92fe",
    "files": [
        {
            "sha": "b352f02d531325c39d2cbe417fe1ac4383cc0738",
            "filename": "third_party/xla/xla/pjrt/transpose.cc",
            "status": "modified",
            "additions": 94,
            "deletions": 101,
            "changes": 195,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7585d543b0837c2f6a05087d3ba44d741fda92fe/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7585d543b0837c2f6a05087d3ba44d741fda92fe/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.cc?ref=7585d543b0837c2f6a05087d3ba44d741fda92fe",
            "patch": "@@ -91,6 +91,7 @@ limitations under the License.\n #include \"absl/functional/function_ref.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/strings/str_join.h\"\n #include \"absl/synchronization/blocking_counter.h\"\n@@ -712,15 +713,11 @@ static absl::Status ParseTilingSpecification(\n }\n \n // Helper function that builds a plan.\n-void TransposePlan::BuildPlanNodes(\n-    absl::Span<int64_t const> inverse_permutation, int thread_id,\n-    std::vector<TransposePlan::Node>& nodes) {\n+void TransposePlan::BuildPlanNodes(int thread_id,\n+                                   std::vector<TransposePlan::Node>& nodes) {\n   VLOG(8) << \"Before plan build: \" << ToString();\n   const int ndim = a_dims_.size();\n   DCHECK_GT(ndim, 0);\n-  const int pos_stride1a = ndim - 1;\n-  const int pos_stride1b_in_a = permutation_.back();\n-  const int pos_stride1a_in_b = inverse_permutation[pos_stride1a];\n \n   // We build plans in a depth-first order, visiting loops from outermost to\n   // innermost. We use a stack (depth-first) order to handle trailing partial\n@@ -745,8 +742,10 @@ void TransposePlan::BuildPlanNodes(\n   };\n   std::stack<Agendum> agenda;\n \n-  int total_tasks =\n-      absl::c_accumulate(loop_parallelism_, int{1}, std::multiplies<int>());\n+  int total_tasks = 1;\n+  for (const Loop& loop : loop_order_) {\n+    total_tasks *= loop.parallelism;\n+  }\n \n   agenda.push(Agendum{/*loop_id=*/0, /*parent_node_id=*/-1,\n                       /*num_tasks_at_loop=*/total_tasks,\n@@ -777,12 +776,8 @@ void TransposePlan::BuildPlanNodes(\n       if (!inner_kernel_is_memcpy_) {\n         Node node;\n         node.start = node.end = node.inc = -1;\n-        node.lda = a_tiling_[pos_stride1b_in_a] > 1\n-                       ? lda_tile_[pos_stride1b_in_a]\n-                       : lda_[pos_stride1b_in_a];\n-        node.ldb = b_tiling_[pos_stride1a_in_b] > 1\n-                       ? ldb_tile_[pos_stride1a_in_b]\n-                       : ldb_[pos_stride1a_in_b];\n+        node.lda = sentinel_lda_;\n+        node.ldb = sentinel_ldb_;\n         nodes.push_back(node);\n       }\n       DCHECK(!(inner_kernel_is_memcpy_ && agendum.parent_node_id >= 0));\n@@ -791,38 +786,34 @@ void TransposePlan::BuildPlanNodes(\n \n     const Loop& loop = loop_order_[agendum.loop_id];\n     int a_dim = loop.dim_in_a;\n-    int b_dim = inverse_permutation[a_dim];\n-    DCHECK(a_tiling_[a_dim] == 1 || b_tiling_[b_dim] == 1 ||\n-           a_tiling_[a_dim] == b_tiling_[b_dim]);\n-    int64_t tile_size = std::max(a_tiling_[a_dim], b_tiling_[b_dim]);\n \n     // Compute the number of tasks for the next loop iteration.\n     int task_id_at_loop = agendum.task_id_at_loop;\n-    int num_tasks_at_loop =\n-        agendum.num_tasks_at_loop / loop_parallelism_[agendum.loop_id];\n+    int num_tasks_at_loop = agendum.num_tasks_at_loop / loop.parallelism;\n     int task_id_at_next_loop = task_id_at_loop % num_tasks_at_loop;\n \n+    Node node;\n+    node.lda = loop.lda;\n+    node.ldb = loop.ldb;\n+    node.inc = 1;\n+    node.is_inner_dim_in_a = loop.is_inner_dim_in_a;\n+    node.is_inner_dim_in_b = loop.is_inner_dim_in_b;\n+    if (node.is_inner_dim_in_a) {\n+      node.inc = inner_block_elems_ * outer_block_elems_a_;\n+    } else if (node.is_inner_dim_in_b) {\n+      node.inc = inner_block_elems_ * outer_block_elems_b_;\n+    }\n+\n+    int task_id = task_id_at_loop / num_tasks_at_loop;\n+\n     if (loop.tile_interior) {\n       // We are visiting the tile interior of a tiled dimension.\n       bool partial = agendum.partial_tiles[a_dim];\n \n-      Node node;\n-      node.lda = a_tiling_[a_dim] > 1 ? lda_tile_[a_dim] : lda_[a_dim];\n-      node.ldb = b_tiling_[b_dim] > 1 ? ldb_tile_[b_dim] : ldb_[b_dim];\n-      node.inc = 1;\n-      node.is_inner_dim_in_a = (a_dim == pos_stride1a);\n-      node.is_inner_dim_in_b = (a_dim == pos_stride1b_in_a);\n-      if (node.is_inner_dim_in_a) {\n-        node.inc = inner_block_elems_ * outer_block_elems_a_;\n-      } else if (node.is_inner_dim_in_b) {\n-        node.inc = inner_block_elems_ * outer_block_elems_b_;\n-      }\n-\n-      int task_id = task_id_at_loop / num_tasks_at_loop;\n-      int64_t size = partial ? a_dims_[a_dim] % tile_size : tile_size;\n+      int64_t size = partial ? loop.dim_size % loop.tile_size : loop.tile_size;\n       int64_t num_iterations = CeilOfRatio(size, node.inc);\n-      int64_t num_iterations_per_task = CeilOfRatio<int64_t>(\n-          num_iterations, loop_parallelism_[agendum.loop_id]);\n+      int64_t num_iterations_per_task =\n+          CeilOfRatio<int64_t>(num_iterations, loop.parallelism);\n       node.start = std::min(size, task_id * num_iterations_per_task * node.inc);\n       node.end =\n           std::min(size, (task_id + 1) * num_iterations_per_task * node.inc);\n@@ -845,15 +836,14 @@ void TransposePlan::BuildPlanNodes(\n     } else {\n       // We are either visiting an untiled dimension, or the loop that iterates\n       // over tile exteriors.\n-      int task_id = task_id_at_loop / num_tasks_at_loop;\n-      int64_t num_complete_tiles = a_dims_[a_dim] / tile_size;\n-      bool has_partial_tile = (a_dims_[a_dim] % tile_size != 0);\n+      int64_t num_complete_tiles = loop.dim_size / loop.tile_size;\n+      bool has_partial_tile = (loop.dim_size % loop.tile_size != 0);\n \n       // If there is a trailing partial tile as well as complete tiles, handle\n       // it as a trailer on the loop over complete tiles.\n       bool has_trailing_plan_node = false;\n       if (num_complete_tiles > 0 && has_partial_tile &&\n-          task_id == loop_parallelism_[agendum.loop_id] - 1) {\n+          task_id == loop.parallelism - 1) {\n         Agendum new_agendum;\n         new_agendum.loop_id = agendum.loop_id + 1;\n         new_agendum.parent_node_id = node_id;\n@@ -864,17 +854,6 @@ void TransposePlan::BuildPlanNodes(\n         agenda.push(std::move(new_agendum));\n         has_trailing_plan_node = true;\n       }\n-      Node node;\n-      node.lda = lda_[a_dim] * tile_size / a_tiling_[a_dim];\n-      node.ldb = ldb_[b_dim] * tile_size / b_tiling_[b_dim];\n-      node.inc = 1;\n-      node.is_inner_dim_in_a = (tile_size == 1 && a_dim == ndim - 1);\n-      node.is_inner_dim_in_b = (tile_size == 1 && a_dim == pos_stride1b_in_a);\n-      if (node.is_inner_dim_in_a) {\n-        node.inc = inner_block_elems_ * outer_block_elems_a_;\n-      } else if (node.is_inner_dim_in_b) {\n-        node.inc = inner_block_elems_ * outer_block_elems_b_;\n-      }\n \n       // If this tiled dimension consists only of a single partial tile, handle\n       // it here; there's no point emitting a degenerate loop and a separate\n@@ -884,8 +863,8 @@ void TransposePlan::BuildPlanNodes(\n       // Evenly divide the loop iterations amongst the threads.\n       int64_t num_tiles = partial ? 1 : num_complete_tiles;\n       int64_t num_iterations = CeilOfRatio(num_tiles, node.inc);\n-      int64_t num_iterations_per_task = CeilOfRatio<int64_t>(\n-          num_iterations, loop_parallelism_[agendum.loop_id]);\n+      int64_t num_iterations_per_task =\n+          CeilOfRatio<int64_t>(num_iterations, loop.parallelism);\n       node.start =\n           std::min(num_tiles, task_id * num_iterations_per_task * node.inc);\n       node.end = std::min(num_tiles,\n@@ -1123,11 +1102,45 @@ void TransposePlan::Initialize() {\n   const int pos_stride1b_in_a = permutation_.back();\n   inner_kernel_is_memcpy_ = (pos_stride1b_in_a == pos_stride1a);\n \n+  // Calculate sentinel strides.\n+  if (!inner_kernel_is_memcpy_) {\n+    int pos_stride1a_in_b = inverse_permutation[ndim - 1];\n+    sentinel_lda_ = a_tiling_[pos_stride1b_in_a] > 1\n+                        ? lda_tile_[pos_stride1b_in_a]\n+                        : lda_[pos_stride1b_in_a];\n+    sentinel_ldb_ = b_tiling_[pos_stride1a_in_b] > 1\n+                        ? ldb_tile_[pos_stride1a_in_b]\n+                        : ldb_[pos_stride1a_in_b];\n+  }\n+\n   loop_order_.reserve(ndim);\n   for (int i = 0; i < ndim; ++i) {\n-    loop_order_.push_back(Loop{i, /*tile_interior=*/false});\n-    if (a_tiling_[i] != 1 || b_tiling_[inverse_permutation[i]] != 1) {\n-      loop_order_.push_back(Loop{i, /*tile_interior=*/true});\n+    Loop loop;\n+    loop.dim_in_a = i;\n+    loop.tile_interior = false;\n+    loop.dim_size = a_dims_[i];\n+    loop.tile_size = std::max(a_tiling_[i], b_tiling_[inverse_permutation[i]]);\n+\n+    loop.lda = lda_[i];\n+    if (a_tiling_[i] == 1) {\n+      loop.lda *= loop.tile_size;\n+    }\n+    loop.ldb = ldb_[inverse_permutation[i]];\n+    if (b_tiling_[inverse_permutation[i]] == 1) {\n+      loop.ldb *= loop.tile_size;\n+    }\n+    loop.is_inner_dim_in_a = (loop.tile_size == 1) && (i == pos_stride1a);\n+    loop.is_inner_dim_in_b = (loop.tile_size == 1) && (i == pos_stride1b_in_a);\n+    loop_order_.push_back(loop);\n+\n+    if (loop.tile_size > 1) {\n+      loop.tile_interior = true;\n+      loop.lda = a_is_tiled_ ? lda_tile_[i] : lda_[i];\n+      loop.ldb = b_is_tiled_ ? ldb_tile_[inverse_permutation[i]]\n+                             : ldb_[inverse_permutation[i]];\n+      loop.is_inner_dim_in_a = (i == pos_stride1a);\n+      loop.is_inner_dim_in_b = (i == pos_stride1b_in_a);\n+      loop_order_.push_back(loop);\n     }\n   }\n \n@@ -1196,21 +1209,12 @@ void TransposePlan::Initialize() {\n \n   // Loop order heuristic: try to make loops with small strides innermost.\n   auto cost = [&](const Loop& l) {\n-    int64_t a_stride =\n-        std::abs((l.tile_interior && a_is_tiled_) ? lda_tile_[l.dim_in_a]\n-                                                  : lda_[l.dim_in_a]);\n-    bool is_inner_dim_in_a =\n-        (!a_is_tiled_ || l.tile_interior) && (l.dim_in_a == pos_stride1a);\n-\n-    if (!inner_kernel_is_memcpy_ && is_inner_dim_in_a) {\n+    int64_t a_stride = std::abs(l.lda);\n+    if (!inner_kernel_is_memcpy_ && l.is_inner_dim_in_a) {\n       a_stride *= inner_block_elems_ * outer_block_elems_a_;\n     }\n-    int b_dim = inverse_permutation[l.dim_in_a];\n-    int64_t b_stride =\n-        (l.tile_interior && b_is_tiled_) ? ldb_tile_[b_dim] : ldb_[b_dim];\n-    bool is_inner_dim_in_b =\n-        (!b_is_tiled_ || l.tile_interior) && (l.dim_in_a == pos_stride1b_in_a);\n-    if (!inner_kernel_is_memcpy_ && is_inner_dim_in_b) {\n+    int64_t b_stride = std::abs(l.ldb);\n+    if (!inner_kernel_is_memcpy_ && l.is_inner_dim_in_b) {\n       b_stride *= inner_block_elems_ * outer_block_elems_b_;\n     }\n     // Add a small penalty to the input strides: given the choice between\n@@ -1220,10 +1224,7 @@ void TransposePlan::Initialize() {\n \n     // If the inner kernel is a memcpy make sure the innermost loop is the\n     // stride-1 dimension. This is a requirement of the memcpy kernel.\n-    bool dim_must_go_last =\n-        inner_kernel_is_memcpy_ && l.dim_in_a == pos_stride1a &&\n-        (l.tile_interior ||\n-         (a_tiling_[l.dim_in_a] == 1 && b_tiling_[b_dim] == 1));\n+    bool dim_must_go_last = inner_kernel_is_memcpy_ && l.is_inner_dim_in_a;\n     return std::make_tuple(dim_must_go_last,\n                            inner_kernel_is_memcpy_ && l.tile_interior,\n                            -std::min<double>(a_stride * penalty, b_stride));\n@@ -1237,15 +1238,13 @@ void TransposePlan::Initialize() {\n   // both input and output.\n \n   // The stride-1 loop must be innermost for a memcpy loop.\n-  DCHECK(!inner_kernel_is_memcpy_ || loop_order_.back().dim_in_a == ndim - 1)\n+  DCHECK(!inner_kernel_is_memcpy_ || loop_order_.back().is_inner_dim_in_a)\n       << ToString();\n \n-  loop_parallelism_ = ChooseParallelizationStrategy(inverse_permutation);\n-  int num_threads =\n-      absl::c_accumulate(loop_parallelism_, int{1}, std::multiplies<int>());\n+  int num_threads = ChooseParallelizationStrategy();\n   nodes_.resize(num_threads);\n   for (int thread_id = 0; thread_id < num_threads; ++thread_id) {\n-    BuildPlanNodes(inverse_permutation, thread_id, nodes_[thread_id]);\n+    BuildPlanNodes(thread_id, nodes_[thread_id]);\n   }\n \n   switch (transformation_) {\n@@ -1260,28 +1259,20 @@ void TransposePlan::Initialize() {\n   }\n }\n \n-std::vector<int> TransposePlan::ChooseParallelizationStrategy(\n-    absl::Span<int64_t const> inverse_permutation) {\n-  std::vector<int> parallelism;\n+int TransposePlan::ChooseParallelizationStrategy() {\n   int available_parallelism = num_threads_requested_;\n-  parallelism.reserve(loop_order_.size());\n \n-  int ndim = permutation_.size();\n-  const int pos_stride1a = ndim - 1;\n-  const int pos_stride1b_in_a = permutation_.back();\n   // Compute the number of iterations in `loop`.\n   auto loop_iterations = [&](const Loop& loop) {\n-    int a_dim = loop.dim_in_a;\n-    int b_dim = inverse_permutation[a_dim];\n-    int64_t tile_size = std::max(a_tiling_[a_dim], b_tiling_[b_dim]);\n     int64_t size = loop.tile_interior\n-                       ? tile_size\n-                       : (CeilOfRatio(a_dims_[loop.dim_in_a], tile_size));\n-    if (!inner_kernel_is_memcpy_ && (loop.tile_interior || tile_size == 1)) {\n-      if (loop.dim_in_a == pos_stride1a) {\n+                       ? loop.tile_size\n+                       : (CeilOfRatio(loop.dim_size, loop.tile_size));\n+    if (!inner_kernel_is_memcpy_ &&\n+        (loop.tile_interior || loop.tile_size == 1)) {\n+      if (loop.is_inner_dim_in_a) {\n         size = CeilOfRatio<int64_t>(size,\n                                     inner_block_elems_ * outer_block_elems_a_);\n-      } else if (loop.dim_in_a == pos_stride1b_in_a) {\n+      } else if (loop.is_inner_dim_in_b) {\n         size = CeilOfRatio<int64_t>(size,\n                                     inner_block_elems_ * outer_block_elems_b_);\n       }\n@@ -1306,8 +1297,9 @@ std::vector<int> TransposePlan::ChooseParallelizationStrategy(\n \n   // Heuristic that attempts to parallelize the outermost loops, down to a\n   // minimum per-thread number of bytes processed.\n+  int num_threads = 1;\n   for (size_t i = 0; i < loop_order_.size(); ++i) {\n-    const Loop& loop = loop_order_[i];\n+    Loop& loop = loop_order_[i];\n     CHECK_GE(available_parallelism, 1);\n     int64_t iterations = loop_iterations(loop);\n     int kMinBytesPerThread = inner_kernel_is_memcpy_ ? (1 << 20) : (1 << 26);\n@@ -1318,14 +1310,15 @@ std::vector<int> TransposePlan::ChooseParallelizationStrategy(\n     VLOG(8) << \"iterations=\" << iterations << \" parallel_work=\" << parallel_work\n             << \" available_parallelism=\" << available_parallelism;\n     if (parallel_work >= available_parallelism) {\n-      parallelism.push_back(available_parallelism);\n+      loop.parallelism = available_parallelism;\n       available_parallelism = 1;\n     } else {\n-      parallelism.push_back(parallel_work);\n+      loop.parallelism = parallel_work;\n       available_parallelism /= parallel_work;\n     }\n+    num_threads *= loop.parallelism;\n   }\n-  return parallelism;\n+  return num_threads;\n }\n \n std::string TransposePlan::ToString() const {\n@@ -1348,7 +1341,8 @@ std::string TransposePlan::ToString() const {\n       });\n   auto format_loop_order = [](std::string* out, const Loop& loop) {\n     return absl::StrAppend(out, loop.dim_in_a,\n-                           loop.tile_interior ? \"[tile]\" : \"\");\n+                           loop.tile_interior ? \"[tile]\" : \"\", \"(\",\n+                           loop.parallelism, \")\");\n   };\n   std::string transformation_str;\n   switch (transformation_) {\n@@ -1362,7 +1356,7 @@ std::string TransposePlan::ToString() const {\n   return absl::StrFormat(\n       \"elem_size=%d a_dims=%s b_dims=%s permutation=%s a_tiling=%s b_tiling=%s \"\n       \"lda=%s lda_tile=%s ldb=%s ldb_tile=%s loop_order=%s \"\n-      \"loop_parallelism=%s outer_bs=[%d,%d] inner_bs=%d \"\n+      \"outer_bs=[%d,%d] inner_bs=%d \"\n       \"transformation=%s scratch_size=%d\\n\"\n       \"nodes:\\n%s\",\n       elem_size_in_bytes_, absl::StrJoin(a_dims_, \",\"),\n@@ -1371,8 +1365,7 @@ std::string TransposePlan::ToString() const {\n       absl::StrJoin(b_tiling_, \",\"), absl::StrJoin(lda_, \",\"),\n       absl::StrJoin(lda_tile_, \",\"), absl::StrJoin(ldb_, \",\"),\n       absl::StrJoin(ldb_tile_, \",\"),\n-      absl::StrJoin(loop_order_, \",\", format_loop_order),\n-      absl::StrJoin(loop_parallelism_, \",\"), outer_block_elems_a_,\n+      absl::StrJoin(loop_order_, \",\", format_loop_order), outer_block_elems_a_,\n       outer_block_elems_b_, inner_block_elems_, transformation_str,\n       scratch_size_, nodes_str);\n }"
        },
        {
            "sha": "c428d2df0f7f9d5aa875e6a29c211df7bfdfe1ea",
            "filename": "third_party/xla/xla/pjrt/transpose.h",
            "status": "modified",
            "additions": 31,
            "deletions": 6,
            "changes": 37,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7585d543b0837c2f6a05087d3ba44d741fda92fe/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7585d543b0837c2f6a05087d3ba44d741fda92fe/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fpjrt%2Ftranspose.h?ref=7585d543b0837c2f6a05087d3ba44d741fda92fe",
            "patch": "@@ -169,11 +169,11 @@ class TransposePlan {\n   // Performs plan initialization that cannot fail.\n   void Initialize();\n \n-  void BuildPlanNodes(absl::Span<int64_t const> inverse_permutation,\n-                      int thread_id, std::vector<Node>& output_nodes);\n+  void BuildPlanNodes(int thread_id, std::vector<Node>& output_nodes);\n \n-  std::vector<int> ChooseParallelizationStrategy(\n-      absl::Span<int64_t const> inverse_permutation);\n+  // Chooses a parallelism for each loop. Returns the total number of parallel\n+  // work units.\n+  int ChooseParallelizationStrategy();\n \n   // The signature of ExecuteTyped uses char* pointers because we perform\n   // address calculations with strides in bytes; the strides need not be\n@@ -222,13 +222,34 @@ class TransposePlan {\n \n   // Order to traverse dimensions, from slowest-varying to fastest-varying.\n   struct Loop {\n-    // The integers are dimension numbers in A.\n+    // Dimension number in A from which this loop originated. This is mostly\n+    // for debugging the plan.\n     int dim_in_a;\n+\n     // If true, the loop iterates over the interior of a tile.\n+    // For an untiled dimension, this is always false. For a tiled dimension,\n+    // we will have two loops: one over the tile exteriors and one over the tile\n+    // interiors.\n     bool tile_interior;\n+\n+    // Size of the iteration space.\n+    int64_t dim_size;\n+\n+    // Size of the tiles, if this a tiled dimension.\n+    int64_t tile_size;\n+\n+    int64_t lda;  // Stride in A for this loop.\n+    int64_t ldb;  // Stride in B for this loop.\n+\n+    // Is this the innermost (stride 1) dimension in A or B? These dimensions\n+    // are special for the kernels.\n+    bool is_inner_dim_in_a;\n+    bool is_inner_dim_in_b;\n+\n+    // Number of parallel threads to use for this loop.\n+    int64_t parallelism;\n   };\n   std::vector<Loop> loop_order_;\n-  std::vector<int> loop_parallelism_;\n \n   // Root nodes of the plan, i.e., pointing to the outermost loops in the loop\n   // nest. The outer vector is indexed on the thread ID.\n@@ -246,6 +267,10 @@ class TransposePlan {\n   int outer_block_elems_a_ = 4;\n   int outer_block_elems_b_ = 4;\n \n+  // Strides used by an inner transpose kernel. Unused for memcpy kernels.\n+  int64_t sentinel_lda_ = -1;\n+  int64_t sentinel_ldb_ = -1;\n+\n   // Transformations to apply to the input before transposition.\n   // Currently the only supported transformation is EF57 conversion, which is\n   // a pair-of-floats extended precision representation used on TPU. We"
        }
    ],
    "stats": {
        "total": 232,
        "additions": 125,
        "deletions": 107
    }
}