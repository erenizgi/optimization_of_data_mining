{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Prevent multi-process usage of collective metadata.\n\nPiperOrigin-RevId: 840185180",
    "sha": "b13024dcdd0bbe0b9403dff90c3257755efe3198",
    "files": [
        {
            "sha": "e6bc973d5b8df9a94c22c499f75c3a11350c1e48",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=b13024dcdd0bbe0b9403dff90c3257755efe3198",
            "patch": "@@ -1330,6 +1330,7 @@ xla_test(\n         \"//xla/tsl/platform:errors\",\n         \"//xla/tsl/platform:statusor\",\n         \"@com_google_absl//absl/log\",\n+        \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings:string_view\",\n         \"@com_google_absl//absl/synchronization\",\n@@ -1982,12 +1983,12 @@ cc_library(\n         \":thunk\",\n         \"//xla:shape_util\",\n         \"//xla:status_macros\",\n+        \"//xla:util\",\n         \"//xla/backends/gpu/collectives:gpu_clique_key\",\n         \"//xla/core/collectives:rank_id\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/runtime:device_id\",\n         \"//xla/service:buffer_assignment\",\n-        \"//xla/service:collective_ops_utils\",\n         \"//xla/service:rendezvous\",\n         \"//xla/service/gpu:backend_configs_cc\",\n         \"//xla/stream_executor:device_memory\",\n@@ -2001,6 +2002,7 @@ cc_library(\n         \"@com_google_absl//absl/container:flat_hash_map\",\n         \"@com_google_absl//absl/status\",\n         \"@com_google_absl//absl/status:statusor\",\n+        \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/types:span\",\n         \"@com_google_protobuf//:protobuf_lite\","
        },
        {
            "sha": "910ab53a1eb8f3715d42754116f63769ac324bd7",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk_test.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 4,
            "changes": 33,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk_test.cc?ref=b13024dcdd0bbe0b9403dff90c3257755efe3198",
            "patch": "@@ -23,6 +23,7 @@ limitations under the License.\n \n #include <gtest/gtest.h>\n #include \"absl/log/log.h\"\n+#include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/string_view.h\"\n #include \"xla/backends/gpu/runtime/collective_params.h\"\n@@ -59,6 +60,7 @@ limitations under the License.\n \n namespace xla::gpu {\n namespace {\n+using ::absl_testing::StatusIs;\n \n static constexpr absl::string_view kProfileName = \"test_kernel_profiler\";\n static constexpr absl::string_view kKernelName = \"six_argument_kernel\";\n@@ -227,7 +229,7 @@ absl::StatusOr<std::vector<uint8_t>> CompilePtxToCubin(\n \n absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n     CollectiveKernelThunkMetadata& metadata, se::StreamExecutor* executor,\n-    std::vector<uint64_t> input_data) {\n+    std::vector<uint64_t> input_data, bool emulate_multiprocess = false) {\n   BufferAllocation buffer_allocation(\n       /*index=*/0, /*size=*/metadata.total_buffer_size, /*color=*/0);\n   GpuExecutableRunOptions gpu_options;\n@@ -279,6 +281,13 @@ absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n   initialize_params.collective_params = &collective_params;\n   initialize_params.src = {kKernelSource};\n \n+  GpuExecutableRunOptions::DeviceIdMap global_device_id_map = {\n+      {LocalDeviceId(0), GlobalDeviceId(0)}};\n+  if (emulate_multiprocess) {\n+    initialize_params.collective_params->global_device_id_map =\n+        &global_device_id_map;\n+  }\n+\n   std::vector<uint8_t> cubin;\n   if (!metadata.use_ptx) {\n     TF_ASSIGN_OR_RETURN(\n@@ -298,16 +307,19 @@ absl::StatusOr<se::DeviceMemoryBase> RunCollectiveKernelThunk(\n }\n \n std::vector<absl::StatusOr<se::DeviceMemoryBase>>\n-RunCollectiveKernelThunkOnDevices(CollectiveKernelThunkMetadata& metadata) {\n+RunCollectiveKernelThunkOnDevices(CollectiveKernelThunkMetadata& metadata,\n+                                  bool emulate_multiprocess = false) {\n   tsl::thread::ThreadPool thread_pool(tsl::Env::Default(), \"device_threads\",\n                                       metadata.num_devices);\n   std::vector<tsl::Future<se::DeviceMemoryBase>> futures;\n   for (int device_number = 0; device_number < metadata.num_devices;\n        ++device_number) {\n     futures.push_back(tsl::Future<se::DeviceMemoryBase>::MakeOn(\n-        *thread_pool.AsExecutor(), [&metadata, device_number] {\n+        *thread_pool.AsExecutor(),\n+        [&metadata, device_number, emulate_multiprocess] {\n           return RunCollectiveKernelThunk(metadata,\n-                                          GetGpuExecutor(device_number), {});\n+                                          GetGpuExecutor(device_number), {},\n+                                          emulate_multiprocess);\n         }));\n   }\n \n@@ -373,5 +385,18 @@ TEST(CollectiveKernelThunkTest, MultimemSetupTest) {\n   }\n }\n \n+TEST(CollectiveKernelThunkTest, MultiprocessTest) {\n+  static constexpr int kDevicesCount = 2;\n+\n+  CollectiveKernelThunkMetadata metadata = CreateCollectiveKernelThunk(\n+      /*num_devices=*/kDevicesCount, /*num_elements=*/kNumElements,\n+      /*is_multimem_enabled=*/false, /*use_ptx=*/true);\n+  for (absl::StatusOr<se::DeviceMemoryBase> result :\n+       RunCollectiveKernelThunkOnDevices(metadata,\n+                                         /*emulate_multiprocess=*/true)) {\n+    EXPECT_THAT(result, StatusIs(absl::StatusCode::kUnimplemented));\n+  }\n+}\n+\n }  // namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "1a6b4c567857f992966b66c34529908c8b9817d3",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_metadata_thunk.cc",
            "status": "modified",
            "additions": 68,
            "deletions": 33,
            "changes": 101,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/b13024dcdd0bbe0b9403dff90c3257755efe3198/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_metadata_thunk.cc?ref=b13024dcdd0bbe0b9403dff90c3257755efe3198",
            "patch": "@@ -25,15 +25,16 @@ limitations under the License.\n #include \"absl/algorithm/container.h\"\n #include \"absl/status/status.h\"\n #include \"absl/status/statusor.h\"\n+#include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n #include \"absl/types/span.h\"\n #include \"google/protobuf/repeated_ptr_field.h\"\n #include \"xla/backends/gpu/collectives/gpu_clique_key.h\"\n+#include \"xla/backends/gpu/runtime/collective_thunk.h\"\n #include \"xla/core/collectives/rank_id.h\"\n #include \"xla/hlo/ir/hlo_instruction.h\"\n #include \"xla/layout.h\"\n #include \"xla/runtime/device_id.h\"\n-#include \"xla/service/collective_ops_utils.h\"\n #include \"xla/service/gpu/backend_configs.pb.h\"\n #include \"xla/service/rendezvous.h\"\n #include \"xla/status_macros.h\"\n@@ -44,6 +45,7 @@ limitations under the License.\n #include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n+#include \"xla/util.h\"\n \n namespace xla {\n namespace gpu {\n@@ -76,47 +78,69 @@ CollectiveConfig CollectiveMetadataThunk::GetCollectiveConfig(\n   return config;\n }\n \n-struct CollectiveMetadataRendezvousValue {\n+struct DeviceParameters {\n   RankId rank;\n   std::vector<se::DeviceMemoryBase> parameters;\n \n-  bool operator<(const CollectiveMetadataRendezvousValue& other) const {\n+  bool operator<(const DeviceParameters& other) const {\n     return rank < other.rank;\n   }\n };\n \n-absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n-    std::vector<se::DeviceMemoryBase> parameters, se::Stream* stream,\n-    const GpuCliqueKey& clique_key, void* multimem_address_space,\n-    int device_ordinal, se::DeviceMemoryBase destination) {\n-  auto rendezvous_fn =\n-      [](absl::Span<const CollectiveMetadataRendezvousValue* const> values) {\n-        std::vector<CollectiveMetadataRendezvousValue> values_copy;\n-        for (const auto& value : values) {\n-          values_copy.push_back(*value);\n-        }\n-        // Sort to make sure that values are in the same order as the\n-        // devices are ordered in the communicator.\n-        absl::c_sort(values_copy);\n-        return values_copy;\n-      };\n+absl::StatusOr<std::vector<DeviceParameters>> SyncLocalDeviceParameters(\n+    const GpuCliqueKey& clique_key, int device_ordinal,\n+    const std::vector<se::DeviceMemoryBase>& parameters) {\n+  std::vector<DeviceParameters> device_parameters;\n+  auto rendezvous_fn = [](absl::Span<const DeviceParameters* const> values) {\n+    std::vector<DeviceParameters> values_copy;\n+    for (const auto& value : values) {\n+      values_copy.push_back(*value);\n+    }\n+    // Sort to make sure that values are in the same order as the\n+    // devices are ordered in the communicator.\n+    absl::c_sort(values_copy);\n+    return values_copy;\n+  };\n \n   std::string start_rendezvous_key =\n       absl::StrFormat(\"[%d] Initializing collective metadata for clique %s\",\n                       device_ordinal, clique_key.ToString());\n \n-  CollectiveMetadataRendezvousValue rendezvous_value;\n-  rendezvous_value.rank = device_ordinal;\n-  rendezvous_value.parameters = std::move(parameters);\n+  DeviceParameters params;\n+  params.rank = device_ordinal;\n+  params.parameters = std::move(parameters);\n \n   TF_ASSIGN_OR_RETURN(\n-      std::shared_ptr<std::vector<CollectiveMetadataRendezvousValue>>\n-          rendezvous_values,\n-      Rendezvous<std::vector<CollectiveMetadataRendezvousValue>>(\n+      std::shared_ptr<std::vector<DeviceParameters>> local_ranks_parameters,\n+      Rendezvous<std::vector<DeviceParameters>>(\n           /*name=*/start_rendezvous_key, /*key=*/clique_key,\n-          /*value=*/rendezvous_value, /*num_threads=*/clique_key.num_devices(),\n-          rendezvous_fn));\n+          /*value=*/params,\n+          /*num_threads=*/clique_key.num_local_participants(), rendezvous_fn));\n+  return std::vector<DeviceParameters>(local_ranks_parameters->begin(),\n+                                       local_ranks_parameters->end());\n+}\n+\n+absl::StatusOr<std::vector<DeviceParameters>> SyncGlobalDeviceParameters(\n+    const GpuCliqueKey& clique_key, int device_ordinal,\n+    const std::vector<se::DeviceMemoryBase>& parameters) {\n+  if (!clique_key.is_local()) {\n+    return absl::UnimplementedError(absl::StrCat(\n+        XlaFormatDevice(device_ordinal),\n+        \"Multiprocess collective metadata is not supported yet in clique \",\n+        clique_key.ToString()));\n+  }\n+\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<DeviceParameters> local_ranks_parameters,\n+      SyncLocalDeviceParameters(clique_key, device_ordinal, parameters));\n \n+  return local_ranks_parameters;\n+}\n+\n+absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n+    std::vector<se::DeviceMemoryBase> parameters, se::Stream* stream,\n+    const GpuCliqueKey& clique_key, void* multimem_address_space,\n+    int device_ordinal, se::DeviceMemoryBase destination) {\n   CollectiveKernelMetadata metadata;\n   metadata.rank = clique_key.rank(GlobalDeviceId(device_ordinal))\n                       .value_or(RankId(-1))\n@@ -127,19 +151,22 @@ absl::Status CollectiveMetadataThunk::ConstructCollectiveMetadata(\n                         clique_key.ToString()));\n   }\n   metadata.multicast_buffer_ptr = multimem_address_space;\n-  TF_RET_CHECK(!rendezvous_values->empty())\n+  TF_ASSIGN_OR_RETURN(\n+      std::vector<DeviceParameters> device_parameters,\n+      SyncGlobalDeviceParameters(clique_key, device_ordinal, parameters));\n+  TF_RET_CHECK(!device_parameters.empty())\n       << \"Not enough devices in the clique.\";\n-  const size_t num_parameters = (*rendezvous_values)[0].parameters.size();\n-  for (const auto& value : *rendezvous_values) {\n+  const size_t num_parameters = device_parameters[0].parameters.size();\n+  for (const auto& value : device_parameters) {\n     TF_RET_CHECK(value.parameters.size() == num_parameters);\n   }\n \n   std::vector<void*> param_to_peers_ptrs;\n-  param_to_peers_ptrs.reserve(rendezvous_values->size() * num_parameters);\n-  for (int param = 0; param < num_parameters; ++param) {\n-    for (int peer = 0; peer < clique_key.num_devices(); ++peer) {\n+  param_to_peers_ptrs.reserve(device_parameters.size() * num_parameters);\n+  for (int peer = 0; peer < device_parameters.size(); ++peer) {\n+    for (int param = 0; param < num_parameters; ++param) {\n       param_to_peers_ptrs.push_back(\n-          (*rendezvous_values)[peer].parameters[param].opaque());\n+          device_parameters[peer].parameters[param].opaque());\n     }\n   }\n \n@@ -228,6 +255,14 @@ absl::StatusOr<void*> CollectiveMetadataThunk::SetupMultimem(\n   if (memory_range.is_null()) {\n     return nullptr;\n   }\n+\n+  if (!clique_key.is_local()) {\n+    return absl::UnimplementedError(absl::StrCat(\n+        XlaFormatDevice(params.executor->device_ordinal()),\n+        \"Multimem is not supported in multi-process mode in clique \",\n+        clique_key.ToString()));\n+  }\n+\n   return address_space_provider_.SetupMultimemAddressSpace(\n       clique_key, params.executor, memory_range);\n }"
        }
    ],
    "stats": {
        "total": 138,
        "additions": 100,
        "deletions": 38
    }
}