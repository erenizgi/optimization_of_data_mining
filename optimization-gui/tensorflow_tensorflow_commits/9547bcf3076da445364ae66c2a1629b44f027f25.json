{
    "author": "derdrdirk",
    "message": "[XLA:GPU] Remove convolution vectorization pass.\n\nThe pass is not used anymore for Hopper and newer GPU generations and when benchmarked does not yield performance improvements on Ampere.\n\nPiperOrigin-RevId: 813658344",
    "sha": "9547bcf3076da445364ae66c2a1629b44f027f25",
    "files": [
        {
            "sha": "825682602734fc290f52d4e0f943f7a3900be653",
            "filename": "third_party/xla/xla/service/gpu/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2FBUILD?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -1933,7 +1933,6 @@ cc_library(\n         \"//xla/service/gpu/transforms:cudnn_norm_rewriter\",\n         \"//xla/service/gpu/transforms:cudnn_pad_for_convolutions\",\n         \"//xla/service/gpu/transforms:cudnn_simplify_padding\",\n-        \"//xla/service/gpu/transforms:cudnn_vectorize_convolutions\",\n         \"//xla/service/gpu/transforms:gpusolver_rewriter\",\n         \"//xla/service/gpu/transforms:triangular_solve_rewriter\",\n         \"//xla/service/llvm_ir:llvm_util\","
        },
        {
            "sha": "8e519b7a0950f3dc862774001d72e2c8829596fa",
            "filename": "third_party/xla/xla/service/gpu/nvptx_compiler.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fnvptx_compiler.cc?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -57,7 +57,6 @@ limitations under the License.\n #include \"xla/hlo/transforms/simplifiers/dot_dimension_merger.h\"\n #include \"xla/hlo/transforms/simplifiers/float_normalization.h\"\n #include \"xla/hlo/transforms/simplifiers/hlo_constant_folding.h\"\n-#include \"xla/hlo/transforms/simplifiers/reshape_mover.h\"\n #include \"xla/hlo/transforms/simplifiers/tuple_simplifier.h\"\n #include \"xla/pjrt/distributed/key_value_store_interface.h\"\n #include \"xla/service/call_inliner.h\"\n@@ -90,7 +89,6 @@ limitations under the License.\n #include \"xla/service/gpu/transforms/cudnn_norm_rewriter.h\"\n #include \"xla/service/gpu/transforms/cudnn_pad_for_convolutions.h\"\n #include \"xla/service/gpu/transforms/cudnn_simplify_padding.h\"\n-#include \"xla/service/gpu/transforms/cudnn_vectorize_convolutions.h\"\n #include \"xla/service/gpu/transforms/gpusolver_rewriter.h\"\n #include \"xla/service/gpu/transforms/triangular_solve_rewriter.h\"\n #include \"xla/service/hlo_cost_analysis.h\"\n@@ -209,14 +207,6 @@ absl::Status NVPTXCompiler::OptimizeHloConvolutionCanonicalization(\n                                              dnn_version, toolkit_version);\n     pipeline.AddPass<ConvPaddingLegalization>();\n     pipeline.AddPass<CudnnPadForConvolutions>(cuda_compute_capability);\n-    if (!cuda_compute_capability.IsAtLeast(\n-            se::CudaComputeCapability::CudaComputeCapabilities::kHopper)) {\n-      // CUDNN vectorization is not performant on Hopper and later.\n-      // The official guidance is not to use the vectorized layouts anymore on\n-      // these newer architectures.\n-      pipeline.AddPass<CudnnVectorizeConvolutions>(cuda_compute_capability,\n-                                                   dnn_version);\n-    }\n   }\n   // The conv padding/vectorization passes which we need to get rid of.  They\n   // also leave behind unnecessary tuple/get-tuple-element pairs that"
        },
        {
            "sha": "ae510cafb52a23ffc6e7d4d6b6af17c2c75e2156",
            "filename": "third_party/xla/xla/service/gpu/transforms/BUILD",
            "status": "modified",
            "additions": 0,
            "deletions": 59,
            "changes": 59,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2FBUILD?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -913,7 +913,6 @@ xla_cc_test(\n     deps = [\n         \":cudnn_pad_for_convolutions\",\n         \":cudnn_simplify_padding\",\n-        \":cudnn_vectorize_convolutions\",\n         \"//xla:literal\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n@@ -940,64 +939,6 @@ xla_cc_test(\n     ],\n )\n \n-cc_library(\n-    name = \"cudnn_vectorize_convolutions\",\n-    srcs = [\"cudnn_vectorize_convolutions.cc\"],\n-    hdrs = [\"cudnn_vectorize_convolutions.h\"],\n-    deps = [\n-        \"//xla:shape_util\",\n-        \"//xla:util\",\n-        \"//xla:xla_data_proto_cc\",\n-        \"//xla/hlo/builder:xla_builder\",\n-        \"//xla/hlo/builder:xla_computation\",\n-        \"//xla/hlo/ir:hlo\",\n-        \"//xla/hlo/pass:hlo_pass\",\n-        \"//xla/service:hlo_creation_utils\",\n-        \"//xla/service:hlo_module_config\",\n-        \"//xla/service/gpu:backend_configs_cc\",\n-        \"//xla/service/gpu:cublas_cudnn\",\n-        \"//xla/service/gpu:cudnn_support_utils\",\n-        \"//xla/service/gpu:stream_executor_util\",\n-        \"//xla/stream_executor:dnn\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/container:flat_hash_set\",\n-        \"@com_google_absl//absl/container:inlined_vector\",\n-        \"@com_google_absl//absl/log\",\n-        \"@com_google_absl//absl/log:check\",\n-        \"@com_google_absl//absl/status\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_absl//absl/strings\",\n-        \"@com_google_absl//absl/strings:string_view\",\n-    ],\n-)\n-\n-xla_cc_test(\n-    name = \"cudnn_vectorize_convolutions_test\",\n-    srcs = [\"cudnn_vectorize_convolutions_test.cc\"],\n-    deps = [\n-        \":cudnn_vectorize_convolutions\",\n-        \"//xla:util\",\n-        \"//xla:xla_data_proto_cc\",\n-        \"//xla/hlo/parser:hlo_parser\",\n-        \"//xla/hlo/testlib:hlo_hardware_independent_test_base\",\n-        \"//xla/hlo/testlib:pattern_matcher_gmock\",\n-        \"//xla/service:call_inliner\",\n-        \"//xla/service:pattern_matcher\",\n-        \"//xla/service/gpu:backend_configs_cc\",\n-        \"//xla/service/gpu:cublas_cudnn\",\n-        \"//xla/stream_executor:dnn\",\n-        \"//xla/stream_executor/cuda:cuda_compute_capability\",\n-        \"//xla/tsl/platform:errors\",\n-        \"//xla/tsl/platform:statusor\",\n-        \"@com_google_absl//absl/algorithm:container\",\n-        \"@com_google_absl//absl/status:statusor\",\n-        \"@com_google_googletest//:gtest_main\",\n-    ],\n-)\n-\n # TODO(b/358278858): Currently lacking test coverage.\n cc_library(\n     name = \"cudnn_custom_call_compiler\","
        },
        {
            "sha": "b25d11293f0ff364c180b3c071c701dc4e54a845",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_simplify_padding.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 237,
            "changes": 240,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.cc?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -47,55 +47,6 @@ namespace xla::gpu {\n namespace {\n namespace m = ::xla::match;\n \n-// If exactly one index of `dims` is false, returns that index.  If 0 or more\n-// than one index is false, returns nullopt.\n-std::optional<int64_t> FindFalseIndex(absl::Span<const bool> vals) {\n-  std::optional<int64_t> missing_dim;\n-  for (int i = 0; i < vals.size(); i++) {\n-    if (vals[i]) {\n-      continue;\n-    }\n-    if (missing_dim.has_value()) {\n-      VLOG(2) << \"Multiple dimensions are missing from conv dnums; can't \"\n-                 \"determine which is vect_c dimension\";\n-      return std::nullopt;\n-    }\n-    missing_dim = i;\n-  }\n-  return missing_dim;\n-}\n-\n-// Finds the vect_c dimension in the convolution's output.\n-//\n-// The vect_c dimension in dnums is the dimension that's not mentioned in\n-// `dnums`.  If there's zero or more than one such dimension, returns nullopt.\n-std::optional<int64_t> FindOutputVectCDim(HloInstruction* conv) {\n-  const ConvolutionDimensionNumbers& dnums =\n-      conv->convolution_dimension_numbers();\n-  int64_t num_dims = conv->shape().tuple_shapes(0).dimensions().size();\n-  absl::InlinedVector<bool, 5> seen_dims(num_dims);\n-  seen_dims[dnums.output_batch_dimension()] = true;\n-  seen_dims[dnums.output_feature_dimension()] = true;\n-  for (int64_t d : dnums.output_spatial_dimensions()) {\n-    seen_dims[d] = true;\n-  }\n-  return FindFalseIndex(seen_dims);\n-}\n-\n-// Finds the vect_c dimension in the convolution's kernel.\n-std::optional<int64_t> FindKernelVectCDim(HloInstruction* conv) {\n-  const ConvolutionDimensionNumbers& dnums =\n-      conv->convolution_dimension_numbers();\n-  int64_t num_dims = conv->operand(1)->shape().dimensions().size();\n-  absl::InlinedVector<bool, 5> seen_dims(num_dims);\n-  seen_dims[dnums.kernel_input_feature_dimension()] = true;\n-  seen_dims[dnums.kernel_output_feature_dimension()] = true;\n-  for (int64_t d : dnums.kernel_spatial_dimensions()) {\n-    seen_dims[d] = true;\n-  }\n-  return FindFalseIndex(seen_dims);\n-}\n-\n // Attempts to count the number of output features at the end of conv that are\n // guaranteed to be 0.\n //\n@@ -107,66 +58,6 @@ std::optional<int64_t> NumTrailingZeroOutputFeatures(HloInstruction* conv) {\n   int64_t feature_dim = dnums.kernel_output_feature_dimension();\n   const HloInstruction* weights = conv->operand(1);\n \n-  // If the filter is reordered for an int8x32 NCHW_VECT_C convolution, find the\n-  // original, un-reordered filter and check *it* for trailing zero output\n-  // features.\n-  auto backend_config = conv->backend_config<GpuBackendConfig>();\n-  if (backend_config.ok() &&\n-      backend_config->cudnn_conv_backend_config().reordered_int8_nchw_vect()) {\n-    VLOG(2) << \"Matched int8x32 convolution with filter reordering\";\n-\n-    // Try to set weights to the original, un-reordered value.\n-    const HloInstruction *reshape, *transpose;\n-    bool matched =\n-        Match(weights, m::Reshape(m::Transpose(\n-                           &transpose, m::Reshape(&reshape, m::Op(&weights)))));\n-\n-    // Verify some properties of the reshape-transpose-reshape pattern.\n-    // If these don't hold, it means that some pass (e.g. constant folding)\n-    // has modified the filter, making making it infeasible to get the original,\n-    // un-reordered value.\n-    if (!matched || feature_dim != 0 ||\n-        transpose->shape().dimensions().size() != 8) {\n-      VLOG(2) << \"The filter output feature dimension cannot be determined, as \"\n-                 \"the reordering sequence is modified\";\n-      return std::nullopt;\n-    }\n-\n-    // Calculate the actual output feature dimension before the transpose.\n-    // For example: the input filter [I, O, H, W] will get reshaped to\n-    // [I/32, 8, 4, O/8, 4, 2, H, W], transposed in a way that is compatible\n-    // with cuDNN INT8x32_CONFIG convolutions (see 'cudnn_support_utils.h') and\n-    // reshaped again to [O, I/32, H, W, 32]. While the output features\n-    // dimension is zero, we need to get the dimension in the original shape\n-    // (equals to one in this example).\n-    const auto& transpose_dimensions =\n-        Cast<HloTransposeInstruction>(transpose)->dimensions();\n-\n-    // Calculate combined dimensions size before the first appearing output\n-    // component [O/8], which appears in position 3 of the transpose.\n-    int64_t preceding_size = 1;\n-    for (int64_t i = transpose_dimensions.at(3) - 1; i >= 0; --i) {\n-      preceding_size *= reshape->shape().dimensions(i);\n-    }\n-\n-    // Skip dimensions in front until the output features dimension is found.\n-    int64_t accumulated_size = 1;\n-    for (int64_t size : weights->shape().dimensions()) {\n-      if (accumulated_size < preceding_size) {\n-        accumulated_size *= size;\n-        ++feature_dim;\n-      } else {\n-        break;\n-      }\n-    }\n-    // Sanity check; if this condition doesn't hold, something is off.\n-    if (accumulated_size != preceding_size) {\n-      VLOG(2) << \"Something is really wrong here, I give up\";\n-      return std::nullopt;\n-    }\n-    VLOG(2) << \"Computed output feature dimension: \" << feature_dim;\n-  }\n-\n   VLOG(2) << \"Computing NumTrailingZeroOutputFeatures of \" << conv->ToString()\n           << \"\\nwith weights \" << weights->ToString();\n   if (Match(weights, m::Pad(m::Op(), m::ConstantEffectiveScalar(0)))) {\n@@ -177,56 +68,6 @@ std::optional<int64_t> NumTrailingZeroOutputFeatures(HloInstruction* conv) {\n             << padding_config.edge_padding_high();\n     return padding_config.edge_padding_high();\n   }\n-  if (const HloInstruction* pad;\n-      Match(weights,\n-            m::Reshape(m::Pad(&pad, m::Op(), m::ConstantEffectiveScalar(0))))) {\n-    // Check that the reshape merely adds a VECT_C to the kernel input features.\n-    // That is, we reshape from [I,O,H,W] (in some order) to [I/k,k,O,H,W] (in\n-    // the same order) for some constant k (probably 32).  Then check how much\n-    // the pad adds to the O dimension.\n-    std::optional<int64_t> vect_c_dim = FindKernelVectCDim(conv);\n-    if (!vect_c_dim.has_value()) {\n-      VLOG(2) << \"fail: Can't find vect_c dimension in conv.\";\n-      return std::nullopt;\n-    }\n-    if (*vect_c_dim != dnums.kernel_input_feature_dimension() + 1) {\n-      VLOG(2) << \"fail: vect_c dim is in the wrong place; should be right \"\n-                 \"after kernel input feature dims in conv.\";\n-      return std::nullopt;\n-    }\n-    absl::InlinedVector<int64_t, 5> expected_pad_dim_sizes(\n-        weights->shape().dimensions().begin(),\n-        weights->shape().dimensions().end());\n-    expected_pad_dim_sizes[dnums.kernel_input_feature_dimension()] *=\n-        weights->shape().dimensions(*vect_c_dim);\n-    expected_pad_dim_sizes.erase(expected_pad_dim_sizes.begin() + *vect_c_dim);\n-    if (pad->shape().dimensions() != expected_pad_dim_sizes) {\n-      VLOG(2) << \"fail: Reshape doesn't simply merge vect_c dimension into \"\n-                 \"input features dim \"\n-              << weights->ToString() << \" but expected dims \"\n-              << absl::StrJoin(expected_pad_dim_sizes, \",\");\n-      return std::nullopt;\n-    }\n-\n-    // If the filter dnums are e.g. [I,O,H,W] then after reshape they are\n-    // [I/k,k,O,H,W] and the new index of O is greater less than before the\n-    // reshape (which we know only adds the I/k and k dims, which we also know\n-    // are contiguous).  OTOH if the O comes before the I in the original, then\n-    // the index of O doesn't change after the reshape.\n-    int64_t feature_dim_before_reshape = feature_dim;\n-    if (dnums.kernel_output_feature_dimension() >\n-        dnums.kernel_input_feature_dimension()) {\n-      feature_dim_before_reshape--;\n-    }\n-    const PaddingConfig::PaddingConfigDimension& padding_config =\n-        pad->padding_config().dimensions(feature_dim_before_reshape);\n-\n-    // The last N output feature weights are all 0.\n-    VLOG(2) << \"Success: Weights is a reshape of a pad; padding on output \"\n-               \"feature dim is \"\n-            << padding_config.edge_padding_high();\n-    return padding_config.edge_padding_high();\n-  }\n   if (Match(weights, m::Constant())) {\n     // Iterate backwards over `weights` to find the index of the first nonzero\n     // value.\n@@ -288,15 +129,9 @@ std::optional<int64_t> NumTrailingZeroOutputFeatures(HloInstruction* conv) {\n }\n \n absl::StatusOr<bool> TrySimplifyPadding(HloInstruction* instr) {\n-  // Match one of the following patterns.\n-  //   conv -> slice -> pad\n-  //   conv -> reshape -> slice-> pad\n-  //   conv -> transpose -> reshape -> slice -> pad\n-  //\n+  // Match pattern: conv -> slice -> pad\n   // where `pad` (the root of the pattern) is `instr`.\n   HloInstruction* conv;\n-  HloInstruction* transpose = nullptr;  // optional\n-  HloInstruction* reshape = nullptr;    // optional\n   HloInstruction* slice;\n   HloInstruction* pad;\n   auto conv_matcher = m::GetTupleElement(\n@@ -310,29 +145,12 @@ absl::StatusOr<bool> TrySimplifyPadding(HloInstruction* instr) {\n   if (!MatchAndLogIfFailed(instr, \"conv-slice-pad\",\n                            m::Pad(&pad, m::Slice(&slice, conv_matcher),\n                                   m::ConstantEffectiveScalar(0)),\n-                           VLOG_IS_ON(3), pad_matcher) &&\n-      !MatchAndLogIfFailed(\n-          instr, \"conv-reshape-slice-pad\",\n-          m::Pad(&pad, m::Slice(&slice, m::Reshape(&reshape, conv_matcher)),\n-                 m::ConstantEffectiveScalar(0)),\n-          VLOG_IS_ON(3), pad_matcher) &&\n-      !MatchAndLogIfFailed(\n-          instr, \"conv-transpose-reshape-slice-pad\",\n-          m::Pad(&pad,\n-                 m::Slice(&slice,\n-                          m::Reshape(&reshape,\n-                                     m::Transpose(&transpose, conv_matcher))),\n-                 m::ConstantEffectiveScalar(0)),\n-          VLOG_IS_ON(3), pad_matcher)) {\n+                           VLOG_IS_ON(3), pad_matcher)) {\n     return false;\n   }\n \n   VLOG(2) << \"Found pattern to attempt to simplify:\\n\"\n           << \"conv: \" << conv->ToString()  //\n-          << \"\\ntranspose: \"\n-          << (transpose != nullptr ? transpose->ToString() : \"(null)\")\n-          << \"\\nreshape: \"\n-          << (reshape != nullptr ? reshape->ToString() : \"(null)\")\n           << \"\\nslice: \" << slice->ToString()  //\n           << \"\\npad: \" << pad->ToString();\n \n@@ -355,59 +173,7 @@ absl::StatusOr<bool> TrySimplifyPadding(HloInstruction* instr) {\n   // optional-reshape + optional-transpose + slice + pad combination is setting\n   // all of these features to 0.  If so, we can merge the slice into the pad.\n   const auto& dnums = conv->convolution_dimension_numbers();\n-  int64_t output_feature_dim;\n-  if (reshape == nullptr) {\n-    CHECK_EQ(transpose, nullptr);\n-    output_feature_dim = dnums.output_feature_dimension();\n-  } else {\n-    std::optional<int64_t> vect_c_dim_before_transpose =\n-        FindOutputVectCDim(conv);\n-    if (!vect_c_dim_before_transpose.has_value()) {\n-      VLOG(2) << \"Couldn't find vect_c output dim in conv.\";\n-      return false;\n-    }\n-\n-    // If there's no transpose, check that the vect_c dim is immediately after\n-    // the feature dim.  OTOH if there is a transpose, check that the transpose\n-    // moves the vect_c dim immediately after the feature dim.\n-    int64_t feature_dim_after_transpose;\n-    int64_t vect_c_dim_after_transpose;\n-    if (transpose == nullptr) {\n-      feature_dim_after_transpose = dnums.output_feature_dimension();\n-      vect_c_dim_after_transpose = *vect_c_dim_before_transpose;\n-    } else {\n-      const auto& transpose_dims = transpose->dimensions();\n-      feature_dim_after_transpose = std::distance(\n-          transpose->dimensions().begin(),\n-          absl::c_find(transpose_dims, dnums.output_feature_dimension()));\n-      vect_c_dim_after_transpose = std::distance(\n-          transpose->dimensions().begin(),\n-          absl::c_find(transpose_dims, *vect_c_dim_before_transpose));\n-    }\n-    if (vect_c_dim_after_transpose != feature_dim_after_transpose + 1) {\n-      VLOG(2) << \"fail: after transpose (if present), vect_c dim must appear \"\n-                 \"immediately after output feature dim: Computed \"\n-                 \"vect_d_dim_after_transpose to be \"\n-              << vect_c_dim_after_transpose;\n-      return false;\n-    }\n-\n-    // Now check that the reshape merges the feature + vect_c dims and\n-    // doesn't do anything else.\n-    absl::InlinedVector<int64_t, 5> expected_reshape_dim_sizes(\n-        reshape->operand(0)->shape().dimensions().begin(),\n-        reshape->operand(0)->shape().dimensions().end());\n-    expected_reshape_dim_sizes[feature_dim_after_transpose] *=\n-        expected_reshape_dim_sizes[vect_c_dim_after_transpose];\n-    expected_reshape_dim_sizes.erase(expected_reshape_dim_sizes.begin() +\n-                                     vect_c_dim_after_transpose);\n-    if (reshape->shape().dimensions() != expected_reshape_dim_sizes) {\n-      VLOG(2) << \"fail: Reshape doesn't merge vect_c with feature dimension.\";\n-      return false;\n-    }\n-\n-    output_feature_dim = feature_dim_after_transpose;\n-  }\n+  int64_t output_feature_dim = dnums.output_feature_dimension();\n \n   // Check that `slice` slices only the output feature dimension.\n   if (!absl::c_all_of(slice->slice_starts(), [](auto v) { return v == 0; }) ||"
        },
        {
            "sha": "147379561eb3d862f7282a0da6b654cdcd2639c4",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_simplify_padding.h",
            "status": "modified",
            "additions": 7,
            "deletions": 25,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding.h?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -24,32 +24,14 @@ limitations under the License.\n \n namespace xla::gpu {\n \n-// Simplifies or eliminates padding introduced by CudnnPadForConvolutions and\n-// CudnnVectorizeConvolutions.\n+// Simplifies or eliminates padding introduced by CudnnPadForConvolutions.\n //\n-// CudnnVectorizeConvolutions will generate code that does the following.\n-//  - pad input and output features to a multiple of 32 (or 4),\n-//  - reshape input from [N,C,H,W] to [N,C/32,H,W,32] and reshape kernel from\n-//    [I,O,H,W] to [I/32,32,O,H,W],\n-//  - run the conv,\n-//  - reshape output from [N,C/32,H,W,32] to [N,C,H,W], and finally\n-//  - slice off the padding on the C channel.\n-//\n-// But if this is followed by another convolution (very common), then the slice\n-// is immediately followed by another pad. This may be redundant; we know that\n-// the trailing channels sliced off from the first conv are 0.\n-//\n-// Ideally we can eliminate the whole reshape+slice+pad+reshape sequence between\n-// the two convolutions.\n-//\n-// Specifically, this pass tries to merge the slice at the end of the sequence\n-// above into the pad from the next convolution (when we can prove that the\n-// sliced-off elements are all 0). We then rely on algsimp to remove the pad if\n-// it's a nop and then to merge and eliminate the remaining reshapes.\n-//\n-// This pass should run after CudnnVectorizeConvolutions and there should be no\n-// simplification passes in between that modify the reshape-transpose-reshape\n-// introduced by int8x32 convolution filter reordering.\n+// If a convolution's weights are padded with 0s in the output feature\n+// dimension, then the convolution output will contain 0s in corresponding\n+// features. If these zero features are sliced off, and then padded back with 0s\n+// (e.g. as input to another convolution), this slice+pad sequence may be\n+// redundant. This pass simplifies such slice+pad sequences by merging the slice\n+// into the pad. We then rely on algsimp to remove the pad if it's a nop.\n class CudnnSimplifyPadding : public HloModulePass {\n  public:\n   CudnnSimplifyPadding() = default;"
        },
        {
            "sha": "1700105262e766d0f5fb8635f274815f1eceed98",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_simplify_padding_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 323,
            "changes": 323,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9547bcf3076da445364ae66c2a1629b44f027f25/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_simplify_padding_test.cc?ref=9547bcf3076da445364ae66c2a1629b44f027f25",
            "patch": "@@ -27,16 +27,10 @@ limitations under the License.\n #include \"absl/strings/str_cat.h\"\n #include \"absl/types/span.h\"\n #include \"xla/hlo/pass/hlo_pass_fix.h\"\n-#include \"xla/hlo/pass/hlo_pass_pipeline.h\"\n #include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n #include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n #include \"xla/hlo/transforms/simplifiers/algebraic_simplifier.h\"\n-#include \"xla/hlo/transforms/simplifiers/reshape_mover.h\"\n-#include \"xla/hlo/transforms/simplifiers/tuple_simplifier.h\"\n #include \"xla/literal.h\"\n-#include \"xla/service/call_inliner.h\"\n-#include \"xla/service/gpu/transforms/cudnn_pad_for_convolutions.h\"\n-#include \"xla/service/gpu/transforms/cudnn_vectorize_convolutions.h\"\n #include \"xla/service/pattern_matcher.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/dnn.h\"\n@@ -53,46 +47,6 @@ namespace m = ::xla::match;\n \n class CudnnSimplifyPaddingTest : public HloHardwareIndependentTestBase {\n  protected:\n-  // Runs the whole relevant pass pipeline starting at CudnnPadForConvolutions.\n-  // This lets us test that we're matching the patterns that actually get\n-  // generated by padding+vectorization.\n-  absl::StatusOr<bool> RunEndToEnd(std::pair<int, int> compute_capability,\n-                                   HloModule* module) {\n-    se::CudaComputeCapability cc{compute_capability.first,\n-                                 compute_capability.second};\n-\n-    TF_RETURN_IF_ERROR(\n-        RunHloPass(CudnnPadForConvolutions(cc), module).status());\n-\n-    TF_RETURN_IF_ERROR(\n-        RunHloPass(CudnnVectorizeConvolutions(\n-                       cc, /*cudnn_version=*/se::dnn::VersionInfo{8, 9, 0}),\n-                   module)\n-            .status());\n-    VLOG(1) << \"after vectorizing convs:\\n\" << module->ToString();\n-\n-    TF_RETURN_IF_ERROR(RunHloPass(CallInliner(), module).status());\n-    VLOG(1) << \"after inliner:\\n\" << module->ToString();\n-\n-    TF_RETURN_IF_ERROR(RunHloPass(TupleSimplifier(), module).status());\n-    VLOG(1) << \"after tuple simplifier:\\n\" << module->ToString();\n-\n-    TF_ASSIGN_OR_RETURN(bool changed,\n-                        RunHloPass(CudnnSimplifyPadding(), module));\n-    VLOG(1) << \"after simplify_padding:\\n\" << module->ToString();\n-\n-    {\n-      // reshape-mover expects to be run alongside algsimp.\n-      HloPassFix<HloPassPipeline> pipeline(\"reshape-mover and algsimp\");\n-      pipeline.AddPass<ReshapeMover>();\n-      pipeline.AddPass<AlgebraicSimplifier>(AlgebraicSimplifierOptions());\n-      TF_RETURN_IF_ERROR(RunHloPass(pipeline, module).status());\n-    }\n-    VLOG(1) << \"after reshape mover + algsimp:\\n\" << module->ToString();\n-\n-    return changed;\n-  }\n-\n   absl::StatusOr<bool> RunJustThisPass(HloModule* module) {\n     TF_ASSIGN_OR_RETURN(bool changed,\n                         RunHloPass(CudnnSimplifyPadding(), module));\n@@ -132,72 +86,6 @@ void SetConstantValue(\n       instr, HloInstruction::CreateConstant(std::move(new_literal))));\n }\n \n-TEST_F(CudnnSimplifyPaddingTest, EndToEnd) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    conv1 = (s8[10,20,30,190], u8[0]) custom-call(\n-        s8[10,20,30,63] parameter(0), s8[3,5,63,190] parameter(1),\n-        f32[10] parameter(2), s8[10,20,30,190] parameter(3)),\n-      window={size=3x5}, dim_labels=b01f_01io->b01f,\n-      custom_call_target=\"__cudnn$convBiasActivationForward\"\n-    conv1_result = get-tuple-element(conv1), index=0\n-    ROOT conv2 = (s8[10,20,30,29], u8[0]) custom-call(\n-        conv1_result, s8[3,5,190,29] parameter(4),\n-        f32[10] parameter(5), s8[10,20,30,29] parameter(6)),\n-      window={size=3x5}, dim_labels=b01f_01io->b01f,\n-      custom_call_target=\"__cudnn$convBiasActivationForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunEndToEnd({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  // conv2 should be fed directly from conv1, without any intervening\n-  // reshapes/pads.\n-  EXPECT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Slice(m::Reshape(m::GetTupleElement(m::CustomCall(\n-              {\"__cudnn$convBiasActivationForward\"},\n-              m::GetTupleElement(\n-                  m::CustomCall({\"__cudnn$convBiasActivationForward\"}), 0),\n-              m::Op(), m::Op(), m::Op())))),\n-          m::Op())));\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, EndToEndNCHW) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    conv1 = (s8[1,64,480,400], u8[0]) custom-call(\n-        s8[1,112,480,400] parameter(0), s8[3,3,112,64] parameter(1),\n-        f32[64] parameter(2)),\n-      window={size=3x3}, dim_labels=bf01_01io->bf01,\n-      custom_call_target=\"__cudnn$convBiasActivationForward\"\n-    conv1_result = get-tuple-element(conv1), index=0\n-    convert = f32[1,64,480,400] convert(conv1_result)\n-    constant = f32[] constant(0.349002093)\n-    broadcast = f32[1,64,480,400] broadcast(constant)\n-    ROOT multiply = f32[1,64,480,400] multiply(convert, broadcast)\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunEndToEnd({7, 5}, module.get()));\n-  // The SimplifyPadding pass itself does not do anything.\n-  EXPECT_FALSE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  // The reshape introduced by CudnnVectorizeConvolutions should have been moved\n-  // to the root.\n-  EXPECT_THAT(root, GmockMatch(m::Reshape(m::Multiply())));\n-}\n-\n TEST_F(CudnnSimplifyPaddingTest, PaddedWeights) {\n   auto module = ParseAndReturnVerifiedModule(R\"(\n     HloModule TestModule\n@@ -255,108 +143,6 @@ TEST_F(CudnnSimplifyPaddingTest, PaddedWeightsNotPaddedEnough) {\n   EXPECT_FALSE(changed);\n }\n \n-TEST_F(CudnnSimplifyPaddingTest, PaddedAndReshapedWeightsNCHW) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[64,60,3,3] parameter(0), s8[] constant(0)), padding=0_0x0_4x0_0x0_0\n-      weights = s8[2,32,64,3,3] reshape(weights_p)\n-      conv = (s8[10,2,32,10,10], u8[0]) custom-call(\n-          s8[10,2,32,10,10] parameter(1),\n-          weights\n-        ), window={size=3x3}, dim_labels=bf?01_i?o01->bf?01,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      slice = s8[10,60,10,10] slice(s8[10,64,10,10] reshape(conv_result)), slice={[0:10], [0:60], [0:10], [0:10]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_5x0_0x0_0\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-  const HloInstruction* pad = nullptr;\n-  ASSERT_THAT(\n-      root, GmockMatch(\n-                m::Pad(&pad, m::Reshape(m::GetTupleElement(m::CustomCall(), 0)),\n-                       m::ConstantScalar(0))));\n-\n-  ExpectOnlyPadsOneDim(/*dim=*/1, /*padding_high=*/1, pad->padding_config());\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, PaddedAndReshapedWeightsNHWC) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[3,3,64,60] parameter(0), s8[] constant(0)), padding=0_0x0_0x0_0x0_4\n-      weights = s8[3,3,2,32,64] reshape(weights_p)\n-      conv = (s8[10,10,10,2,32], u8[0]) custom-call(\n-          s8[10,10,10,2,32] parameter(1),\n-          weights\n-        ), window={size=3x3}, dim_labels=b01f?_01i?o->b01f?,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      slice = s8[10,10,10,60] slice(s8[10,10,10,64] reshape(conv_result)), slice={[0:10], [0:10], [0:10], [0:60]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_0x0_0x0_5\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-  const HloInstruction* pad = nullptr;\n-  ASSERT_THAT(\n-      root, GmockMatch(\n-                m::Pad(&pad, m::Reshape(m::GetTupleElement(m::CustomCall(), 0)),\n-                       m::ConstantScalar(0))));\n-\n-  ExpectOnlyPadsOneDim(/*dim=*/3, /*padding_high=*/1, pad->padding_config());\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, PaddedTransposedAndReshapedOutput) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[64,60,3,3] parameter(0), s8[] constant(0)), padding=0_0x0_4x0_0x0_0\n-      weights = s8[2,32,64,3,3] reshape(weights_p)\n-      conv = (s8[10,2,10,10,32], u8[0]) custom-call(\n-          s8[10,2,10,10,32] parameter(1),\n-          weights\n-        ), window={size=3x3}, dim_labels=bf01?_i?o01->bf01?,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      conv_transposed = s8[10,2,32,10,10] transpose(conv_result), dimensions={0,1,4,2,3}\n-      slice = s8[10,60,10,10] slice(s8[10,64,10,10] reshape(conv_transposed)), slice={[0:10], [0:60], [0:10], [0:10]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_6x0_0x0_0\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-  const HloInstruction* pad = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Pad(\n-          &pad,\n-          m::Reshape(m::Transpose(m::GetTupleElement(m::CustomCall(), 0))),\n-          m::ConstantScalar(0))));\n-\n-  ExpectOnlyPadsOneDim(/*dim=*/1, /*padding_high=*/2, pad->padding_config());\n-}\n-\n TEST_F(CudnnSimplifyPaddingTest, PaddedConstantWeight) {\n   auto module = ParseAndReturnVerifiedModule(R\"(\n     HloModule TestModule\n@@ -441,77 +227,6 @@ TEST_F(CudnnSimplifyPaddingTest, PaddedConstantWeightIsNotLargeEnough) {\n   EXPECT_FALSE(changed);\n }\n \n-TEST_F(CudnnSimplifyPaddingTest, ReshapeDoesntMergeVectCDim) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[64,60,3,3] parameter(0), s8[] constant(0)), padding=0_0x0_4x0_0x0_0\n-      weights = s8[2,64,3,3,32] reshape(weights_p)\n-      conv = (s8[10,2,10,10,32], u8[0]) custom-call(\n-          s8[10,2,10,10,32] parameter(1),\n-          weights_p\n-        ), window={size=3x3}, dim_labels=bf01?_io01?->bf01?,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      slice = s8[10,60,10,10] slice(s8[10,64,10,10] reshape(conv_result)), slice={[0:10], [0:60], [0:10], [0:10]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_6x0_0x0_0\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_FALSE(changed);\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, TwoVectCDimsInOutput) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[64,60,3,3] parameter(0), s8[] constant(0)), padding=0_0x0_4x0_0x0_0\n-      weights = s8[2,64,3,3,32] reshape(weights_p)\n-      conv = (s8[10,2,10,10,4,8], u8[0]) custom-call(\n-          s8[10,2,10,10,32] parameter(1),\n-          weights\n-        ), window={size=3x3}, dim_labels=bf01?_io01?->bf01??,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      conv_transposed = s8[10,2,4,8,10,10] transpose(conv_result), dimensions={0,1,4,5,2,3}\n-      slice = s8[10,60,10,10] slice(s8[10,64,10,10] reshape(conv_transposed)), slice={[0:10], [0:60], [0:10], [0:10]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_6x0_0x0_0\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_FALSE(changed);\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, TwoVectCDimsInKernel) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-    HloModule TestModule\n-\n-    ENTRY TestComputation {\n-      weights_p = pad(s8[64,60,3,3] parameter(0), s8[] constant(0)), padding=0_0x0_4x0_0x0_0\n-      weights = s8[2,64,3,3,4,8] reshape(weights_p)\n-      conv = (s8[10,2,10,10,32], u8[0]) custom-call(\n-          s8[10,2,10,10,32] parameter(1),\n-          weights\n-        ), window={size=3x3}, dim_labels=bf01?_io01??->bf01?,\n-        custom_call_target=\"__cudnn$convForward\"\n-      conv_result = get-tuple-element(conv), index=0\n-      conv_transposed = s8[10,2,32,10,10] transpose(conv_result), dimensions={0,1,4,2,3}\n-      slice = s8[10,60,10,10] slice(s8[10,64,10,10] reshape(conv_transposed)), slice={[0:10], [0:60], [0:10], [0:10]}\n-      ROOT pad = pad(slice, s8[] constant(0)), padding=0_0x0_6x0_0x0_0\n-    }\n-  )\")\n-                    .value();\n-\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunJustThisPass(module.get()));\n-  EXPECT_FALSE(changed);\n-}\n-\n TEST_F(CudnnSimplifyPaddingTest, SliceDoesntStartAtBeginning) {\n   auto module = ParseAndReturnVerifiedModule(R\"(\n     HloModule TestModule\n@@ -733,43 +448,5 @@ ENTRY main.26 {\n   EXPECT_FALSE(changed);\n }\n \n-TEST_F(CudnnSimplifyPaddingTest, Int8FilterReorderedOutputFirst) {\n-  // Test feature dimension calculation from reordering transpose (oi01)\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    conv.1 = (s8[1,63,80,80], u8[0]) custom-call(\n-        s8[1,112,80,80] parameter(0), s8[63,112,3,3] parameter(1)),\n-      window={size=3x3}, dim_labels=bf01_oi01->bf01,\n-      custom_call_target=\"__cudnn$convForward\"\n-    gte.1 = s8[1,63,80,80] get-tuple-element(conv.1), index=0\n-    const.0 = s8[] constant(0)\n-    ROOT pad.1 = s8[1,64,80,80] pad(gte.1, const.0), padding=0_0x0_1x0_0x0_0\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunEndToEnd({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-}\n-\n-TEST_F(CudnnSimplifyPaddingTest, Int8FilterReorderedOutputLast) {\n-  // Test feature dimension calculation from reordering transpose (01io)\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    conv.1 = (s8[1,63,80,80], u8[0]) custom-call(\n-        s8[1,112,80,80] parameter(0), s8[3,3,112,63] parameter(1)),\n-      window={size=3x3}, dim_labels=bf01_01io->bf01,\n-      custom_call_target=\"__cudnn$convForward\"\n-    gte.1 = s8[1,63,80,80] get-tuple-element(conv.1), index=0\n-    const.0 = s8[] constant(0)\n-    ROOT pad.1 = s8[1,64,80,80] pad(gte.1, const.0), padding=0_0x0_1x0_0x0_0\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, RunEndToEnd({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-}\n-\n }  // anonymous namespace\n }  // namespace xla::gpu"
        },
        {
            "sha": "737773686aba183dff0413c7715e4cb343e26095",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_vectorize_convolutions.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 631,
            "changes": 631,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.cc?ref=0073ee20686c1f52b9ab8e01468303f585da7cd7",
            "patch": "@@ -1,631 +0,0 @@\n-/* Copyright 2021 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/transforms/cudnn_vectorize_convolutions.h\"\n-\n-#include <cstdint>\n-#include <optional>\n-#include <tuple>\n-#include <vector>\n-\n-#include \"absl/algorithm/container.h\"\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"absl/container/inlined_vector.h\"\n-#include \"absl/log/check.h\"\n-#include \"absl/log/log.h\"\n-#include \"absl/status/status.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/str_cat.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/hlo/builder/xla_builder.h\"\n-#include \"xla/hlo/builder/xla_computation.h\"\n-#include \"xla/hlo/ir/hlo_casting_utils.h\"\n-#include \"xla/hlo/ir/hlo_clone_context.h\"\n-#include \"xla/hlo/ir/hlo_computation.h\"\n-#include \"xla/hlo/ir/hlo_instruction.h\"\n-#include \"xla/hlo/ir/hlo_instructions.h\"\n-#include \"xla/hlo/ir/hlo_opcode.h\"\n-#include \"xla/primitive_util.h\"\n-#include \"xla/service/gpu/backend_configs.pb.h\"\n-#include \"xla/service/gpu/cublas_cudnn.h\"\n-#include \"xla/service/gpu/cudnn_support_utils.h\"\n-#include \"xla/service/gpu/stream_executor_util.h\"\n-#include \"xla/service/hlo_creation_utils.h\"\n-#include \"xla/service/hlo_module_config.h\"\n-#include \"xla/shape.h\"\n-#include \"xla/shape_util.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/dnn.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/util.h\"\n-#include \"xla/xla_data.pb.h\"\n-\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-// Finds convolutions that this pass may be able to transform, namely int8_t\n-// cudnn forward or forward-bias-activation convolutions\n-//\n-// cudnn as of v8.2 supports the following data type combinations for forward\n-// and forward-bias-activation convolutions.  We have to make sure we only\n-// vectorize to one of these supported configs.\n-//\n-//   in       out\n-//   int8x1   int8x1\n-//   int8x1   float\n-//   int8x1   int32_t\n-//\n-//   int8x4   int8x4\n-//   int8x4   float\n-//\n-//   int8x32  int8x32\n-//\n-// https://docs.nvidia.com/deeplearning/cudnn/api/index.html#cudnnConvolutionForward\n-//\n-// For now we restrict ourselves to only the int8xN -> int8xN cases.  We could\n-// allow the int8x4 -> float case in the future if desirable.\n-static std::vector<HloCustomCallInstruction*> GetRelevantConvs(\n-    HloComputation* comp) {\n-  std::vector<HloCustomCallInstruction*> convs;\n-  for (HloInstruction* instr : comp->instructions()) {\n-    if (HloPredicateIsNotOp<HloOpcode::kCustomCall>(instr) ||\n-        (instr->custom_call_target() != kCudnnConvForwardCallTarget &&\n-         instr->custom_call_target() !=\n-             kCudnnConvBiasActivationForwardCallTarget) ||\n-        instr->operand_count() < 2) {\n-      continue;\n-    }\n-\n-    PrimitiveType input_ty = instr->operand(0)->shape().element_type();\n-    PrimitiveType output_ty = instr->shape().tuple_shapes(0).element_type();\n-    if (input_ty == output_ty && (input_ty == S8 || input_ty == U8)) {\n-      convs.push_back(Cast<HloCustomCallInstruction>(instr));\n-    }\n-  }\n-  return convs;\n-}\n-\n-// Reshapes `instr` so that it has an extra dimension of size `vect_size` right\n-// after `dim`.\n-static XlaOp SplitAtDim(XlaOp instr, int64_t dim, int64_t vect_size) {\n-  XlaBuilder& b = *instr.builder();\n-  Shape shape = b.GetShape(instr).value();\n-  DimensionVector new_dims(shape.dimensions().begin(),\n-                           shape.dimensions().end());\n-  CHECK_EQ(new_dims[dim] % vect_size, 0);\n-  new_dims[dim] /= vect_size;\n-  new_dims.insert(new_dims.begin() + dim + 1, vect_size);\n-  return Reshape(instr, new_dims);\n-}\n-\n-// Reshapes `shape` so that there's an extra dimension of size `vect_size` right\n-// after `dim`.\n-//\n-// For example given shape=s8[10, 32, 20], dim=1, vect_size=4, returns\n-// s8[10, 8, 4, 20].\n-static Shape SplitShapeAtDim(Shape shape, int64_t dim, int64_t vect_size) {\n-  DimensionVector new_dims(shape.dimensions().begin(),\n-                           shape.dimensions().end());\n-  CHECK_EQ(new_dims[dim] % vect_size, 0);\n-  new_dims[dim] /= vect_size;\n-  new_dims.insert(new_dims.begin() + dim + 1, vect_size);\n-  return ShapeUtil::MakeShape(shape.element_type(), new_dims);\n-}\n-\n-// Transposes dimension `src` to right before `dst`.\n-static XlaOp MoveDim(XlaOp instr, int64_t src, int64_t dst) {\n-  XlaBuilder& b = *instr.builder();\n-  int64_t rank = b.GetShape(instr)->dimensions().size();\n-\n-  DimensionVector idxs(rank);\n-  absl::c_iota(idxs, 0);\n-  if (src < dst) {\n-    idxs.insert(idxs.begin() + dst, src);\n-    idxs.erase(idxs.begin() + src);\n-  } else {\n-    idxs.erase(idxs.begin() + src);\n-    idxs.insert(idxs.begin() + dst, src);\n-  }\n-  return Transpose(instr, idxs);\n-}\n-\n-// Reshapes instr so that dimension `vect_dim` has size `vect_size`, by stealing\n-// elements from `dim`.\n-//\n-// Requires that this is possible without merging and re-splitting the two\n-// dimensions.  I.e. there should be some amount of dim that we can \"split off\"\n-// and add to vect_dim to get it to have size vect_size.\n-static XlaOp RevectorizeInstr(XlaOp instr, int64_t dim, int64_t vect_dim,\n-                              int64_t vect_size) {\n-  XlaBuilder& b = *instr.builder();\n-  Shape shape = b.GetShape(instr).value();\n-  auto size = [&](int64_t d) { return shape.dimensions(d); };\n-\n-  CHECK_LE(size(vect_dim), vect_size);\n-  CHECK_EQ(vect_size % size(vect_dim), 0);\n-\n-  int64_t split_factor = vect_size / size(vect_dim);\n-  CHECK_EQ(size(dim) % split_factor, 0);\n-\n-  // Split dim into [C, split_factor].\n-  instr = SplitAtDim(instr, dim, split_factor);\n-\n-  // SplitAtDim may have added a dimension before vect_dim.\n-  if (vect_dim > dim) {\n-    vect_dim++;\n-  }\n-\n-  // Move the split_factor dimension to right before vect_dim.\n-  instr = MoveDim(instr, dim + 1, vect_dim);\n-\n-  // Moving the split_factor dimension may have *removed* a dimension before\n-  // vect_dim.\n-  if (vect_dim > dim) {\n-    vect_dim--;\n-  }\n-\n-  // Collapse the split_factor dimension into vect_dim.\n-  return Collapse(instr, {vect_dim, vect_dim + 1});\n-}\n-\n-// Inverse of RevectorizeInstr.  Reshapes instr so that dimension `vect_dim` has\n-// size `vect_size`, moving excess elements into `dim`.\n-static XlaOp UnrevectorizeInstr(XlaOp instr, int64_t dim, int64_t vect_dim,\n-                                int64_t orig_vect_size) {\n-  XlaBuilder& b = *instr.builder();\n-  Shape shape = b.GetShape(instr).value();\n-  auto size = [&](int64_t d) { return shape.dimensions(d); };\n-\n-  CHECK_GE(size(vect_dim), orig_vect_size);\n-  CHECK_EQ(size(vect_dim) % orig_vect_size, 0);\n-\n-  // Split vect_dim into [C, orig_vect_size].\n-  instr = SplitAtDim(instr, vect_dim, orig_vect_size);\n-\n-  // SplitAtDim may have added a dimension before dim.\n-  if (dim > vect_dim) {\n-    dim++;\n-  }\n-\n-  // Move the `C` dimension to right after `dim`.  Take into account that\n-  // SplitAtDim may have added a dimension before dim.\n-  instr = MoveDim(instr, vect_dim, dim + 1);\n-\n-  // MoveDim may have *removed* a dimension before dim.\n-  if (dim > vect_dim) {\n-    dim--;\n-  }\n-\n-  // Collapse the `C` and `dim` dimensions.\n-  return Collapse(instr, {dim, dim + 1});\n-}\n-\n-// Adds a vectorized-feature dimension to dnums right after the current feature\n-// dimension.\n-//\n-// ConvolutionDimensionNumbers doesn't represent the vectorized-feature\n-// dimension explicitly, because the whole concept of a vectorized-feature\n-// dimension is specific to cudnn.  Rather, the vectorized-feature dimension is\n-// implicit; it's the first dimension that *doesn't* appear in the dnums.\n-//\n-// This function \"makes room\" in dnums for the new vectorized dimension by\n-// incrementing any dimensions which appear after the feature dim.  The implicit\n-// vector dim is then in this \"empty\" spot.\n-static ConvolutionDimensionNumbers VectorizeDnums(\n-    ConvolutionDimensionNumbers dnums, bool reordered_filter) {\n-  int64_t input_vect_dim = dnums.input_feature_dimension();\n-  if (dnums.input_batch_dimension() > input_vect_dim) {\n-    dnums.set_input_batch_dimension(dnums.input_batch_dimension() + 1);\n-  }\n-  for (int64_t& d : *dnums.mutable_input_spatial_dimensions()) {\n-    if (d > input_vect_dim) {\n-      ++d;\n-    }\n-  }\n-\n-  if (!reordered_filter) {\n-    int64_t kernel_vect_dim = dnums.kernel_input_feature_dimension();\n-    if (dnums.kernel_output_feature_dimension() > kernel_vect_dim) {\n-      dnums.set_kernel_output_feature_dimension(\n-          dnums.kernel_output_feature_dimension() + 1);\n-    }\n-    for (int64_t& d : *dnums.mutable_kernel_spatial_dimensions()) {\n-      if (d > kernel_vect_dim) {\n-        ++d;\n-      }\n-    }\n-  }\n-\n-  int64_t output_vect_dim = dnums.output_feature_dimension();\n-  if (dnums.output_batch_dimension() > output_vect_dim) {\n-    dnums.set_output_batch_dimension(dnums.output_batch_dimension() + 1);\n-  }\n-  for (int64_t& d : *dnums.mutable_output_spatial_dimensions()) {\n-    if (d > output_vect_dim) {\n-      ++d;\n-    }\n-  }\n-\n-  return dnums;\n-}\n-\n-// Reorders the convolution's filter and bias (if present) according to\n-// cudnnReorderFilterAndBias.  Also marks that the filter + bias are reordered\n-// in the conv's backend-config.\n-absl::Status ReorderInt8NchwVect(HloCustomCallInstruction* conv,\n-                                 XlaOp* operands) {\n-  bool has_bias = conv->operand_count() > 2;\n-  VLOG(1) << \"Reordering filter\" << (has_bias ? \" and bias\" : \"\")\n-          << \" (replacement for cudnnReorderFilterAndBias)\";\n-\n-  auto builder = operands->builder();\n-  ConvolutionDimensionNumbers dnums = conv->convolution_dimension_numbers();\n-\n-  // Update convolution backend config.\n-  TF_ASSIGN_OR_RETURN(GpuBackendConfig gpu_config,\n-                      conv->backend_config<GpuBackendConfig>());\n-  CudnnConvBackendConfig& config =\n-      *gpu_config.mutable_cudnn_conv_backend_config();\n-  config.set_reordered_int8_nchw_vect(true);\n-  TF_RETURN_IF_ERROR(conv->set_backend_config(gpu_config));\n-\n-  // Reorder the filter.\n-  TF_ASSIGN_OR_RETURN(Shape filter_shape, builder->GetShape(operands[1]));\n-  TF_ASSIGN_OR_RETURN(auto reorder, CudnnInferTransposeForFilterReordering(\n-                                        filter_shape, dnums));\n-  XlaOp reshape = Reshape(reorder.transpose_shape, operands[1]);\n-  XlaOp transpose = Transpose(reshape, reorder.permutation);\n-  operands[1] = Reshape(reorder.result_shape, transpose);\n-\n-  // The reshape-transpose-reshape we did above makes sure the resulting filter\n-  // has dimension numbers corresponding to \"oihw?\", so update them.\n-  dnums.set_kernel_output_feature_dimension(0);\n-  dnums.set_kernel_input_feature_dimension(1);\n-  dnums.set_kernel_spatial_dimensions(0, 2);\n-  dnums.set_kernel_spatial_dimensions(1, 3);\n-  conv->set_convolution_dimension_numbers(dnums);\n-\n-  if (has_bias) {\n-    // Reorder the bias.\n-    TF_ASSIGN_OR_RETURN(Shape bias_shape, builder->GetShape(operands[2]));\n-    TF_ASSIGN_OR_RETURN(reorder,\n-                        CudnnInferTransposeForBiasReordering(bias_shape));\n-    reshape = Reshape(reorder.transpose_shape, operands[2]);\n-    transpose = Transpose(reshape, reorder.permutation);\n-    operands[2] = Reshape(reorder.result_shape, transpose);\n-  }\n-  return absl::OkStatus();\n-}\n-\n-// Tries to vectorize an already-vectorized convolution.\n-//\n-// That is, given a convolution of shape [N, C/k, H, W, k], changes it to have\n-// shape [N, C/vect_size, H, W, vect_size].  Similarly changes the filter from\n-// [H, W, I/k, O] to [H, W, I/vect_size, vect_size, O].\n-//\n-// (The dimensions can appear in any order; which is N/C/etc is determined by\n-// the convolutions' dnums.)\n-static absl::StatusOr<bool> TryRevectorizeConv(\n-    const se::CudaComputeCapability& compute_capability,\n-    const se::dnn::VersionInfo& cudnn_version, HloCustomCallInstruction* conv,\n-    int vect_size) {\n-  const Shape& input_shape = conv->operand(0)->shape();\n-  const Shape& kernel_shape = conv->operand(1)->shape();\n-  const Shape& output_shape = conv->shape().tuple_shapes(0);\n-  const ConvolutionDimensionNumbers* dnums =\n-      &conv->convolution_dimension_numbers();\n-\n-  // Find the vectorized-features dim in the input/kernel/output.\n-  std::optional<int64_t> input_vect_dim;\n-  std::optional<int64_t> kernel_vect_dim;\n-  std::optional<int64_t> output_vect_dim;\n-  std::tie(input_vect_dim, kernel_vect_dim, output_vect_dim) =\n-      FindVectorizedFeatureDims(*dnums, input_shape, kernel_shape,\n-                                output_shape);\n-\n-  if (!input_vect_dim.has_value() || !kernel_vect_dim.has_value() ||\n-      !output_vect_dim.has_value()) {\n-    return false;\n-  }\n-\n-  int64_t input_feat_size =\n-      input_shape.dimensions(dnums->input_feature_dimension());\n-  int64_t output_feat_size =\n-      output_shape.dimensions(dnums->output_feature_dimension());\n-  int64_t input_vect_size = input_shape.dimensions(*input_vect_dim);\n-  int64_t output_vect_size = output_shape.dimensions(*output_vect_dim);\n-  if (vect_size % input_vect_size != 0 || vect_size % output_vect_size != 0 ||\n-      input_feat_size % (vect_size / input_vect_size) != 0 ||\n-      output_feat_size % (vect_size / output_vect_size) != 0) {\n-    return false;\n-  }\n-\n-  // If this is an integer convolution check that we only vectorize when cuDNN\n-  // supports the vectorized implementation.\n-  if (primitive_util::IsIntegralType(input_shape.element_type())) {\n-    TF_ASSIGN_OR_RETURN(bool supported_target_vectorization,\n-                        CudnnSupportsOptimizedIntegerConvolution(\n-                            compute_capability, *conv, vect_size));\n-    if (!supported_target_vectorization) {\n-      VLOG(3) << \"Skipping re-vectorization of conv to vector size: \"\n-              << vect_size << \": \" << conv->ToString();\n-      return false;\n-    }\n-  }\n-\n-  VLOG(1) << \"Re-vectorizing conv channels from \"\n-          << input_shape.dimensions(*input_vect_dim) << \" to \" << vect_size\n-          << \": \" << conv->ToString();\n-\n-  // We use XlaBuilder because it's a lot easier to get these tricky\n-  // reshape/transposes correct using that API.\n-  XlaBuilder b(absl::StrCat(conv->name(), \".revectorized\"));\n-  b.SetOpMetadata(conv->metadata());\n-\n-  XlaOp filter = Parameter(&b, 1, conv->operand(1)->shape(), \"filter\");\n-  absl::InlinedVector<XlaOp, 4> new_operands = {\n-      RevectorizeInstr(Parameter(&b, 0, conv->operand(0)->shape(), \"input\"),\n-                       dnums->input_feature_dimension(), *input_vect_dim,\n-                       vect_size),\n-      RevectorizeInstr(filter, dnums->kernel_input_feature_dimension(),\n-                       *kernel_vect_dim, vect_size),\n-  };\n-  if (conv->operand_count() > 2) {\n-    // Bias, if present.  This is passed through unmodified.\n-    new_operands.push_back(Parameter(&b, 2, conv->operand(2)->shape(), \"bias\"));\n-  }\n-  if (conv->operand_count() > 3) {\n-    new_operands.push_back(RevectorizeInstr(\n-        Parameter(&b, 3, conv->operand(3)->shape(), \"side_input\"),\n-        dnums->input_feature_dimension(), *input_vect_dim, vect_size));\n-  }\n-\n-  if (conv->operand_count() > 4) {\n-    return InvalidArgument(\n-        \"Don't understand a conv with more than 4 arguments: %s\",\n-        conv->ToString());\n-  }\n-\n-  // Reorder filter and bias for the int8x32 convolutions.  This requires cudnn\n-  // >= 8.3.0.\n-  //\n-  // TODO(jlebar): Remove this guard once JAX no longer supports cudnn 8.3.\n-  const auto& debug_options = conv->GetModule()->config().debug_options();\n-  bool use_reordering =\n-      input_shape.element_type() == xla::S8 && vect_size == 32 &&\n-      debug_options.xla_gpu_enable_cudnn_int8x32_convolution_reordering();\n-  if (use_reordering) {\n-    // Reordering helper supports vector sizes of 4 and 32, so an additional\n-    // reshape-transpose-reshape is not necessary in these cases.\n-    int64_t kernel_vect_size = kernel_shape.dimensions(*kernel_vect_dim);\n-    if (kernel_vect_size == 4 || kernel_vect_size == 32) {\n-      new_operands[1] = filter;\n-    }\n-    TF_RETURN_IF_ERROR(ReorderInt8NchwVect(conv, new_operands.data()));\n-    dnums = &conv->convolution_dimension_numbers();\n-  }\n-\n-  // The custom-call returns a tuple (new_output_shape, u8[0]), where the second\n-  // value in the tuple represents the convolution's scratch memory.\n-  DimensionVector new_output_dims(output_shape.dimensions().begin(),\n-                                  output_shape.dimensions().end());\n-  new_output_dims[dnums->output_feature_dimension()] /=\n-      (vect_size / output_vect_size);\n-  new_output_dims[*output_vect_dim] = vect_size;\n-  XlaOp new_conv = CustomCallWithConvDnums(\n-      &b, conv->custom_call_target(), new_operands,\n-      ShapeUtil::MakeTupleShape(\n-          {ShapeUtil::MakeShape(output_shape.element_type(), new_output_dims),\n-           ShapeUtil::MakeShape(U8, {0})}),\n-      /*operand_shapes_with_layout=*/{},\n-      /*opaque=*/conv->raw_backend_config_string(), /*has_side_effect=*/false,\n-      /*output_operand_aliasing=*/{}, /*literal=*/nullptr,\n-      /*window=*/conv->window(),\n-      /*dnums=*/*dnums);\n-\n-  XlaOp new_conv_result = GetTupleElement(new_conv, 0);\n-  XlaOp new_conv_scratch = GetTupleElement(new_conv, 1);\n-\n-  XlaOp new_conv_result_unrevectorized = UnrevectorizeInstr(\n-      new_conv_result, dnums->output_feature_dimension(), *output_vect_dim,\n-      /*orig_vect_size=*/output_shape.dimensions(*output_vect_dim));\n-\n-  XlaOp root = Tuple(&b, {new_conv_result_unrevectorized, new_conv_scratch});\n-  TF_ASSIGN_OR_RETURN(XlaComputation comp, b.Build(root));\n-  TF_ASSIGN_OR_RETURN(\n-      HloComputation * new_conv_comp,\n-      XlaComputationToHloComputation(comp, conv->parent()->parent()));\n-\n-  // Set the name on the new conv.  This is purely cosmetic, but we attempt to\n-  // preserve e.g. \"cudnn-conv.42\" instead of \"custom-call.42\".\n-  auto new_conv_comp_instrs = new_conv_comp->instructions();\n-  auto new_conv_it = absl::c_find_if(new_conv_comp_instrs,\n-                                     HloPredicateIsOp<HloOpcode::kCustomCall>);\n-  if (new_conv_it != new_conv_comp_instrs.end()) {\n-    new_conv_comp->parent()->SetAndUniquifyInstrName(*new_conv_it,\n-                                                     conv->name());\n-  }\n-\n-  // Replace the old conv with a call to the computation we just created.\n-  VLOG(1) << \"Re-vectorized conv to \" << new_conv_comp->ToString();\n-  TF_RETURN_IF_ERROR(conv->parent()->ReplaceWithNewInstruction(\n-      conv, HloInstruction::CreateCall(conv->shape(), conv->operands(),\n-                                       new_conv_comp)));\n-\n-  return true;\n-}\n-\n-// Tries to vectorize a convolution.\n-//\n-// Given a convolution of dimensions [N, C, H, W], tries to convert it to have\n-// shape [N, C/vect_size, H, W, vect_size].  Similarly, given a kernel of shape\n-// [H, W, I, O], tries to conver it to [H, W, I/vect_size, vect_size, O].\n-//\n-// This requires that C be a multiple of vect_size.  CudnnPadForConvolutions can\n-// add padding to make this true.\n-static absl::StatusOr<bool> TryVectorizeConv(\n-    const se::CudaComputeCapability& compute_capability,\n-    const se::dnn::VersionInfo& cudnn_version, HloCustomCallInstruction* conv,\n-    int64_t vect_size) {\n-  const Shape& input_shape = conv->operand(0)->shape();\n-  const Shape& output_shape = conv->shape().tuple_shapes(0);\n-  const ConvolutionDimensionNumbers* dnums =\n-      &conv->convolution_dimension_numbers();\n-  int64_t in_channels =\n-      input_shape.dimensions(dnums->input_feature_dimension());\n-  int64_t out_channels =\n-      output_shape.dimensions(dnums->output_feature_dimension());\n-\n-  if (in_channels % vect_size != 0 || out_channels % vect_size != 0) {\n-    return false;\n-  }\n-\n-  if (input_shape.dimensions().size() >\n-      2 + dnums->input_spatial_dimensions_size()) {\n-    // Conv already has an extra dimension, which we assume is the vectorized\n-    // features dim.\n-    return false;\n-  }\n-\n-  // If this is an integer convolution check that we only vectorize when cuDNN\n-  // supports the vectorized implementation.\n-  if (primitive_util::IsIntegralType(input_shape.element_type())) {\n-    TF_ASSIGN_OR_RETURN(bool supported_target_vectorization,\n-                        CudnnSupportsOptimizedIntegerConvolution(\n-                            compute_capability, *conv, vect_size));\n-    if (!supported_target_vectorization) {\n-      VLOG(3) << \"Skipping vectorization of conv to vector size: \" << vect_size\n-              << \": \" << conv->ToString();\n-      return false;\n-    }\n-  }\n-\n-  VLOG(1) << \"Vectorizing conv channels by \" << vect_size << \": \"\n-          << conv->ToString();\n-\n-  // We use XlaBuilder because it's a lot easier to get these tricky\n-  // reshape/transposes correct using that API.\n-  XlaBuilder b(absl::StrCat(conv->name(), \".revectorized\"));\n-  b.SetOpMetadata(conv->metadata());\n-\n-  XlaOp filter = Parameter(&b, 1, conv->operand(1)->shape(), \"filter\");\n-  absl::InlinedVector<XlaOp, 4> new_operands = {\n-      SplitAtDim(Parameter(&b, 0, conv->operand(0)->shape(), \"input\"),\n-                 dnums->input_feature_dimension(), vect_size),\n-      SplitAtDim(filter, dnums->kernel_input_feature_dimension(), vect_size),\n-  };\n-  if (conv->operand_count() > 2) {\n-    // Bias, if present.  This is passed through unmodified.\n-    new_operands.push_back(Parameter(&b, 2, conv->operand(2)->shape(), \"bias\"));\n-  }\n-  if (conv->operand_count() > 3) {\n-    // Handle side input, which has same shape as the output.\n-    new_operands.push_back(\n-        SplitAtDim(Parameter(&b, 3, conv->operand(3)->shape(), \"side_input\"),\n-                   dnums->output_feature_dimension(), vect_size));\n-  }\n-  if (conv->operand_count() > 4) {\n-    return InvalidArgument(\n-        \"Don't understand a conv with more than 4 arguments: %s\",\n-        conv->ToString());\n-  }\n-\n-  // Reorder filter and bias for the int8x32 convolutions.  This requires cudnn\n-  // >= 8.3.0.\n-  //\n-  // TODO(jlebar): Remove this guard once JAX no longer supports cudnn 8.3.\n-  const auto& debug_options = conv->GetModule()->config().debug_options();\n-  bool use_reordering =\n-      input_shape.element_type() == xla::S8 && vect_size == 32 &&\n-      debug_options.xla_gpu_enable_cudnn_int8x32_convolution_reordering();\n-  if (use_reordering) {\n-    new_operands[1] = filter;\n-    TF_RETURN_IF_ERROR(ReorderInt8NchwVect(conv, new_operands.data()));\n-    dnums = &conv->convolution_dimension_numbers();\n-  }\n-\n-  // The custom-call returns a tuple (new_output_shape, u8[0]), where the second\n-  // value in the tuple represents the convolution's scratch memory.\n-  Shape new_output_shape = SplitShapeAtDim(\n-      output_shape, dnums->output_feature_dimension(), vect_size);\n-  XlaOp new_conv = CustomCallWithConvDnums(\n-      &b, conv->custom_call_target(), new_operands,\n-      ShapeUtil::MakeTupleShape(\n-          {new_output_shape, ShapeUtil::MakeShape(U8, {0})}),\n-      /*operand_shapes_with_layout=*/{},\n-      /*opaque=*/conv->raw_backend_config_string(), /*has_side_effect=*/false,\n-      /*output_operand_aliasing=*/{}, /*literal=*/nullptr,\n-      /*window=*/conv->window(),\n-      /*dnums=*/VectorizeDnums(*dnums, use_reordering));\n-\n-  XlaOp new_conv_result = GetTupleElement(new_conv, 0);\n-  XlaOp new_conv_scratch = GetTupleElement(new_conv, 1);\n-\n-  // Reshape back to the original shape.\n-  XlaOp conv_result_collapsed =\n-      Collapse(new_conv_result, {dnums->output_feature_dimension(),\n-                                 dnums->output_feature_dimension() + 1});\n-\n-  XlaOp root = Tuple(&b, {conv_result_collapsed, new_conv_scratch});\n-  TF_ASSIGN_OR_RETURN(XlaComputation comp, b.Build(root));\n-  TF_ASSIGN_OR_RETURN(\n-      HloComputation * new_conv_comp,\n-      XlaComputationToHloComputation(comp, conv->parent()->parent()));\n-\n-  // Create a tuple and replace the old conv with it!\n-  VLOG(1) << \"Vectorized conv to: \" << new_conv_comp->ToString();\n-  TF_RETURN_IF_ERROR(conv->parent()->ReplaceWithNewInstruction(\n-      conv, HloInstruction::CreateCall(conv->shape(), conv->operands(),\n-                                       new_conv_comp)));\n-  return true;\n-}\n-\n-}  // namespace\n-\n-absl::StatusOr<bool> CudnnVectorizeConvolutions::Run(\n-    HloModule* module,\n-    const absl::flat_hash_set<absl::string_view>& execution_threads) {\n-  bool changed = false;\n-  for (HloComputation* comp :\n-       module->MakeNonfusionComputations(execution_threads)) {\n-    for (HloCustomCallInstruction* conv : GetRelevantConvs(comp)) {\n-      // Try to (re)vectorize to int8x32 if this is an sm75+ GPU.  If we can't,\n-      // fall back to int8x4.\n-      bool local_changed = false;\n-      if (compute_capability_.IsAtLeast(7, 5)) {\n-        TF_ASSIGN_OR_RETURN(\n-            local_changed,\n-            TryRevectorizeConv(compute_capability_, cudnn_version_, conv, 32));\n-        if (!local_changed) {\n-          TF_ASSIGN_OR_RETURN(\n-              local_changed,\n-              TryVectorizeConv(compute_capability_, cudnn_version_, conv, 32));\n-        }\n-      }\n-      if (!local_changed) {\n-        TF_ASSIGN_OR_RETURN(\n-            local_changed,\n-            TryVectorizeConv(compute_capability_, cudnn_version_, conv, 4));\n-      }\n-      changed |= local_changed;\n-    }\n-  }\n-  return changed;\n-}\n-\n-}  // namespace gpu\n-}  // namespace xla"
        },
        {
            "sha": "9d5856d482626b456abd9a17d86b5d977fbcbed1",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_vectorize_convolutions.h",
            "status": "removed",
            "additions": 0,
            "deletions": 73,
            "changes": 73,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions.h?ref=0073ee20686c1f52b9ab8e01468303f585da7cd7",
            "patch": "@@ -1,73 +0,0 @@\n-/* Copyright 2021 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#ifndef XLA_SERVICE_GPU_TRANSFORMS_CUDNN_VECTORIZE_CONVOLUTIONS_H_\n-#define XLA_SERVICE_GPU_TRANSFORMS_CUDNN_VECTORIZE_CONVOLUTIONS_H_\n-\n-#include \"absl/container/flat_hash_set.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"absl/strings/string_view.h\"\n-#include \"xla/hlo/ir/hlo_module.h\"\n-#include \"xla/hlo/pass/hlo_pass_interface.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/dnn.h\"\n-\n-namespace xla {\n-namespace gpu {\n-\n-// Changes the shape of cudnn convolutions to allow faster \"vectorized\"\n-// algorithms.\n-//\n-// On sm61+ will convert int8_t convolutions from\n-//\n-//   - [N, C, H, W] to [N, C/4, H, W, 4],\n-//\n-// assuming C is divisible by 4.\n-//\n-// On sm75+ will convert int8_t convolutions from\n-//\n-//   - [N, C, H, W]      to [N, C/32, H, W, 32],\n-//   - [N, C/4, H, W, 4] to [N, C/32, H, W, 32], and\n-//   - [N, C, H, W]      to [N,  C/4, H, W,  4] (same as sm61+),\n-//\n-// assuming C is divisible by 4 or 32.\n-//\n-// This pass will not pad the channel dim to a multiple of 4 or 32, so you\n-// should run CudnnPadForConvolutions before this.\n-class CudnnVectorizeConvolutions : public HloModulePass {\n- public:\n-  explicit CudnnVectorizeConvolutions(\n-      se::CudaComputeCapability compute_capability,\n-      se::dnn::VersionInfo cudnn_version)\n-      : compute_capability_(compute_capability),\n-        cudnn_version_(cudnn_version) {}\n-\n-  absl::string_view name() const override {\n-    return \"cudnn_vectorize_convolutions\";\n-  }\n-  using HloPassInterface::Run;\n-  absl::StatusOr<bool> Run(\n-      HloModule* module,\n-      const absl::flat_hash_set<absl::string_view>& execution_threads) override;\n-\n- private:\n-  const se::CudaComputeCapability compute_capability_;\n-  const se::dnn::VersionInfo cudnn_version_;\n-};\n-\n-}  // namespace gpu\n-}  // namespace xla\n-\n-#endif  // XLA_SERVICE_GPU_TRANSFORMS_CUDNN_VECTORIZE_CONVOLUTIONS_H_"
        },
        {
            "sha": "675477c2bd2e9fb4db3e44b6d34d76d0c7f0671a",
            "filename": "third_party/xla/xla/service/gpu/transforms/cudnn_vectorize_convolutions_test.cc",
            "status": "removed",
            "additions": 0,
            "deletions": 758,
            "changes": 758,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/0073ee20686c1f52b9ab8e01468303f585da7cd7/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftransforms%2Fcudnn_vectorize_convolutions_test.cc?ref=0073ee20686c1f52b9ab8e01468303f585da7cd7",
            "patch": "@@ -1,758 +0,0 @@\n-/* Copyright 2021 The OpenXLA Authors.\n-\n-Licensed under the Apache License, Version 2.0 (the \"License\");\n-you may not use this file except in compliance with the License.\n-You may obtain a copy of the License at\n-\n-    http://www.apache.org/licenses/LICENSE-2.0\n-\n-Unless required by applicable law or agreed to in writing, software\n-distributed under the License is distributed on an \"AS IS\" BASIS,\n-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n-See the License for the specific language governing permissions and\n-limitations under the License.\n-==============================================================================*/\n-\n-#include \"xla/service/gpu/transforms/cudnn_vectorize_convolutions.h\"\n-\n-#include <cstdint>\n-#include <utility>\n-#include <vector>\n-\n-#include <gmock/gmock.h>\n-#include <gtest/gtest.h>\n-#include \"absl/algorithm/container.h\"\n-#include \"absl/status/statusor.h\"\n-#include \"xla/hlo/parser/hlo_parser.h\"\n-#include \"xla/hlo/testlib/hlo_hardware_independent_test_base.h\"\n-#include \"xla/hlo/testlib/pattern_matcher_gmock.h\"\n-#include \"xla/service/call_inliner.h\"\n-#include \"xla/service/gpu/backend_configs.pb.h\"\n-#include \"xla/service/gpu/cublas_cudnn.h\"\n-#include \"xla/service/pattern_matcher.h\"\n-#include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n-#include \"xla/stream_executor/dnn.h\"\n-#include \"xla/tsl/platform/errors.h\"\n-#include \"xla/tsl/platform/statusor.h\"\n-#include \"xla/util.h\"\n-#include \"xla/xla_data.pb.h\"\n-namespace xla {\n-namespace gpu {\n-namespace {\n-\n-namespace m = ::xla::match;\n-\n-class CudnnVectorizeConvolutionsTest : public HloHardwareIndependentTestBase {\n- protected:\n-  // Runs this pass and some cleanup to make pattern-matching easier.\n-  absl::StatusOr<bool> Run(std::pair<int, int> compute_capability,\n-                           HloModule* module) {\n-    CudnnVectorizeConvolutions pass(\n-        se::CudaComputeCapability{compute_capability.first,\n-                                  compute_capability.second},\n-        se::dnn::VersionInfo(8, 9, 0));\n-    TF_ASSIGN_OR_RETURN(bool changed, RunHloPass(&pass, module));\n-\n-    CallInliner inliner;\n-    TF_RETURN_IF_ERROR(RunHloPass(&inliner, module).status());\n-\n-    return changed;\n-  }\n-};\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, VectorizeTo4) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,40] parameter(0)\n-    filter = s8[2,2,40,44] parameter(1)\n-    ROOT result = (s8[10,20,30,44], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\",\n-                  backend_config=\"{bar: 0}\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(m::GetTupleElement(\n-                         m::CustomCall(&conv, {kCudnnConvForwardCallTarget},\n-                                       m::Reshape(m::Parameter(0))\n-                                           .WithShape(S8, {10, 20, 30, 10, 4}),\n-                                       m::Reshape(m::Parameter(1))\n-                                           .WithShape(S8, {2, 2, 10, 4, 44}))\n-                             .WithConvDnums(\"b01f?_01i?o->b01f?\"))\n-                         .WithShape(S8, {10, 20, 30, 11, 4})),\n-          m::Op())));\n-\n-  EXPECT_EQ(conv->raw_backend_config_string(), \"{bar: 0}\");\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorizeTo4UnsupportedFilterType) {\n-  // This test checks that the vectorize pass correctly calls\n-  // CudnnSupportsOptimizedIntegerConvolution() which should reject this\n-  // convolution because its filter type is f32.\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,40] parameter(0)\n-    filter = f32[2,2,40,44] parameter(1)\n-    ROOT result = (s8[10,20,30,44], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\",\n-                  backend_config=\"{bar: 0}\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_FALSE(changed);\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, VectorizeTo4NCHW) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,48,20,30] parameter(0)\n-    filter = s8[48,44,2,2] parameter(1)\n-    ROOT result = (s8[10,44,20,30], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=bf01_io01->bf01,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(m::GetTupleElement(\n-                         m::CustomCall(&conv, {kCudnnConvForwardCallTarget},\n-                                       m::Reshape(m::Parameter(0))\n-                                           .WithShape(S8, {10, 12, 4, 20, 30}),\n-                                       m::Reshape(m::Parameter(1))\n-                                           .WithShape(S8, {12, 4, 44, 2, 2}))\n-                             .WithConvDnums(\"bf?01_i?o01->bf?01\"))\n-                         .WithShape(S8, {10, 11, 4, 20, 30})),\n-          m::Op())));\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, IncrementAllDnums) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[16,16,16,16] parameter(0)\n-    filter = s8[16,16,3,3] parameter(1)\n-    ROOT result = (s8[16,16,16,16], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=fb01_i01o->fb01,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(m::GetTupleElement(\n-                         m::CustomCall(&conv, {kCudnnConvForwardCallTarget},\n-                                       m::Reshape(m::Parameter(0))\n-                                           .WithShape(S8, {4, 4, 16, 16, 16}),\n-                                       m::Reshape(m::Parameter(1))\n-                                           .WithShape(S8, {4, 4, 16, 3, 3}))\n-                             .WithConvDnums(\"f?b01_i?01o->f?b01\"))\n-                         .WithShape(S8, {4, 4, 16, 16, 16})),\n-          m::Op())));\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, FilterDnums) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[1,20,9,9] parameter(0)\n-    filter = s8[3,3,20,32] parameter(1)\n-    ROOT result = (s8[1,32,9,9], u8[0]) custom-call(s8[1,20,9,9] input, s8[3,3,20,32] filter),\n-                  window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_01io->bf01,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(m::GetTupleElement(\n-                         m::CustomCall(&conv, {kCudnnConvForwardCallTarget},\n-                                       m::Reshape(m::Parameter(0))\n-                                           .WithShape(S8, {1, 5, 4, 9, 9}),\n-                                       m::Reshape(m::Parameter(1))\n-                                           .WithShape(S8, {3, 3, 5, 4, 32}))\n-                             .WithConvDnums(\"bf?01_01i?o->bf?01\"))\n-                         .WithShape(S8, {1, 8, 4, 9, 9})),\n-          m::Op())));\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorizeTo4) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,41] parameter(0)\n-    filter = s8[2,2,41,44] parameter(1)\n-    ROOT result = (s8[10,20,30,44], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  CudnnVectorizeConvolutions pass(\n-      /*compute_capability=*/{7, 5},\n-      /*cudnn_version=*/se::dnn::VersionInfo{8, 9, 0});\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-\n-  SCOPED_TRACE(module->ToString());\n-  EXPECT_FALSE(changed);\n-}\n-\n-// Don't vectorize int8_t -> int32_t into int8x4 or int8x32; this is not\n-// supported in cudnn.\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorizeTo4IfOutputIsS32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,41] parameter(0)\n-    filter = s8[2,2,41,44] parameter(1)\n-    ROOT result = (s32[10,20,30,44], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  SCOPED_TRACE(module->ToString());\n-  EXPECT_FALSE(changed);\n-}\n-\n-// Don't vectorize int8_t -> float into int8x4 or int8x32.  Vectorizing to\n-// int8x4 *is* allowed by cudnn, but we don't do it at the moment.\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorizeTo4IfOutputIsF32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,41] parameter(0)\n-    filter = s8[2,2,41,44] parameter(1)\n-    ROOT result = (f32[10,20,30,44], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  SCOPED_TRACE(module->ToString());\n-  EXPECT_FALSE(changed);\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, VectorizeTo32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,64] parameter(0)\n-    filter = s8[2,2,64,128] parameter(1)\n-    ROOT result = (s8[10,20,30,128], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(\n-              m::GetTupleElement(\n-                  m::CustomCall(\n-                      &conv, {kCudnnConvForwardCallTarget},\n-                      m::Reshape(m::Parameter(0))\n-                          .WithShape(S8, {10, 20, 30, 2, 32}),\n-                      m::Reshape(\n-                          m::Transpose(\n-                              m::Reshape(m::Parameter(1))\n-                                  .WithShape(S8, {2, 2, 2, 8, 4, 16, 4, 2}))\n-                              .WithShape(S8, {2, 2, 2, 16, 2, 8, 4, 4})\n-                              .WithPredicate([](const HloInstruction* instr) {\n-                                return absl::c_equal(\n-                                    instr->dimensions(),\n-                                    std::vector<int64_t>{2, 0, 1, 5, 7, 3, 6,\n-                                                         4});\n-                              }))\n-                          .WithShape(S8, {128, 2, 2, 2, 32})))\n-                  .WithShape(S8, {10, 20, 30, 4, 32})),\n-          m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, BiasAndSideInput) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,64] parameter(0)\n-    filter = s8[2,2,64,128] parameter(1)\n-    bias = f32[128] parameter(2)\n-    side_input = s8[10,20,30,64] parameter(3)\n-\n-    ROOT result = (s8[10,20,30,128], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(\n-              m::GetTupleElement(\n-                  m::CustomCall(\n-                      &conv, {kCudnnConvForwardCallTarget},\n-                      m::Reshape(m::Parameter(0))\n-                          .WithShape(S8, {10, 20, 30, 2, 32}),\n-                      m::Reshape(m::Transpose(m::Reshape(m::Parameter(1))))\n-                          .WithShape(S8, {128, 2, 2, 2, 32}),\n-                      m::Reshape(\n-                          m::Transpose(m::Reshape(m::Parameter(2))\n-                                           .WithShape(F32, {4, 4, 2, 4}))\n-                              .WithShape(F32, {4, 2, 4, 4})\n-                              .WithPredicate([](const HloInstruction* instr) {\n-                                return absl::c_equal(\n-                                    instr->dimensions(),\n-                                    std::vector<int64_t>{0, 2, 1, 3});\n-                              }))\n-                          .WithShape(F32, {128}),\n-                      m::Reshape(m::Parameter(3))\n-                          .WithShape(S8, {10, 20, 30, 2, 32})))\n-                  .WithShape(S8, {10, 20, 30, 4, 32})),\n-          m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, InputNHWC_OutputNCHW) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,64] parameter(0)\n-    filter = s8[2,2,64,128] parameter(1)\n-    bias = f32[128] parameter(2)\n-    side_input = s8[10,128,20,30] parameter(3)\n-\n-    ROOT result = (s8[10,128,20,30], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=2x2}, dim_labels=b01f_01io->bf01,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(\n-              m::GetTupleElement(\n-                  m::CustomCall(\n-                      &conv, {kCudnnConvForwardCallTarget},\n-                      m::Reshape(m::Parameter(0))\n-                          .WithShape(S8, {10, 20, 30, 2, 32}),\n-                      m::Reshape(m::Transpose(m::Reshape(m::Parameter(1))))\n-                          .WithShape(S8, {128, 2, 2, 2, 32}),\n-                      m::Reshape(\n-                          m::Transpose(m::Reshape(m::Parameter(2))\n-                                           .WithShape(F32, {4, 4, 2, 4}))\n-                              .WithShape(F32, {4, 2, 4, 4})\n-                              .WithPredicate([](const HloInstruction* instr) {\n-                                return absl::c_equal(\n-                                    instr->dimensions(),\n-                                    std::vector<int64_t>{0, 2, 1, 3});\n-                              }))\n-                          .WithShape(F32, {128}),\n-                      m::Reshape(m::Parameter(3))\n-                          .WithShape(S8, {10, 4, 32, 20, 30})))\n-                  .WithShape(S8, {10, 4, 32, 20, 30})),\n-          m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorizeTo32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,64] parameter(0)\n-    filter = s8[2,2,64,128] parameter(1)\n-    ROOT result = (s8[10,20,30,128], u8[0]) custom-call(input, filter),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 0}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  ASSERT_THAT(\n-      root,\n-      GmockMatch(m::Tuple(\n-          m::Reshape(m::GetTupleElement(\n-                         m::CustomCall(&conv, {kCudnnConvForwardCallTarget},\n-                                       m::Reshape(m::Parameter(0))\n-                                           .WithShape(S8, {10, 20, 30, 16, 4}),\n-                                       m::Reshape(m::Parameter(1))\n-                                           .WithShape(S8, {2, 2, 16, 4, 128})))\n-                         .WithShape(S8, {10, 20, 30, 32, 4})),\n-          m::Op())));\n-\n-  EXPECT_FALSE(conv->backend_config<GpuBackendConfig>()\n-                   ->cudnn_conv_backend_config()\n-                   .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, Vectorize4To32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,16,4] parameter(0)\n-    filter = s8[3,5,16,192,4] parameter(1)\n-    bias = f32[64] parameter(2)\n-    side_input = s8[10,20,30,16,4] parameter(3)\n-    ROOT result = (s8[10,20,30,48,4], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=3x5}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  auto conv_pat =\n-      m::GetTupleElement(\n-          m::CustomCall(\n-              &conv, {kCudnnConvForwardCallTarget},\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(0))\n-                                          .WithShape(S8, {10, 20, 30, 2, 8, 4}))\n-                             .WithShape(S8, {10, 20, 30, 2, 8, 4}))\n-                  .WithShape(S8, {10, 20, 30, 2, 32}),\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(m::Parameter(1))\n-                                   .WithShape(S8, {3, 5, 2, 8, 24, 4, 2, 4}))\n-                      .WithShape(S8, {2, 3, 5, 24, 2, 8, 4, 4})\n-                      .WithPredicate([](const HloInstruction* instr) {\n-                        return absl::c_equal(\n-                            instr->dimensions(),\n-                            std::vector<int64_t>{2, 0, 1, 4, 6, 3, 5, 7});\n-                      }))\n-                  .WithShape(S8, {192, 2, 3, 5, 32}),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(2)))),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(3))\n-                                          .WithShape(S8, {10, 20, 30, 2, 8, 4}))\n-                             .WithShape(S8, {10, 20, 30, 2, 8, 4}))\n-                  .WithShape(S8, {10, 20, 30, 2, 32}))\n-              .WithConvDnums(\"b01f?_oi01?->b01f?\"))\n-          .WithShape(S8, {10, 20, 30, 6, 32});\n-  ASSERT_THAT(root, GmockMatch(m::Tuple(\n-                        m::Reshape(m::Transpose(m::Reshape(conv_pat).WithShape(\n-                                                    S8, {10, 20, 30, 6, 8, 4}))\n-                                       .WithShape(S8, {10, 20, 30, 6, 8, 4}))\n-                            .WithShape(S8, {10, 20, 30, 48, 4}),\n-                        m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, Vectorize4To32NCHW) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,16,20,30,4] parameter(0)\n-    filter = s8[16,128,2,2,4] parameter(1)\n-    bias = f32[64] parameter(2)\n-    side_input = s8[10,16,20,30,4] parameter(3)\n-    ROOT result = (s8[10,32,20,30,4], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=2x2}, dim_labels=bf01_io01->bf01,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  auto conv_pat =\n-      m::GetTupleElement(\n-          m::CustomCall(\n-              &conv, {kCudnnConvForwardCallTarget},\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(0))\n-                                          .WithShape(S8, {10, 2, 8, 20, 30, 4}))\n-                             .WithShape(S8, {10, 2, 20, 30, 8, 4}))\n-                  .WithShape(S8, {10, 2, 20, 30, 32}),\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(m::Parameter(1))\n-                                   .WithShape(S8, {2, 8, 16, 4, 2, 2, 2, 4}))\n-                      .WithShape(S8, {2, 2, 2, 16, 2, 8, 4, 4})\n-                      .WithPredicate([](const HloInstruction* instr) {\n-                        return absl::c_equal(\n-                            instr->dimensions(),\n-                            std::vector<int64_t>{0, 5, 6, 2, 4, 1, 3, 7});\n-                      }))\n-                  .WithShape(S8, {128, 2, 2, 2, 32}),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(2)))),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(3))\n-                                          .WithShape(S8, {10, 2, 8, 20, 30, 4}))\n-                             .WithShape(S8, {10, 2, 20, 30, 8, 4}))\n-                  .WithShape(S8, {10, 2, 20, 30, 32}))\n-              .WithConvDnums(\"bf01_oi01->bf01\"))\n-          .WithShape(S8, {10, 4, 20, 30, 32});\n-  ASSERT_THAT(root, GmockMatch(m::Tuple(\n-                        m::Reshape(m::Transpose(m::Reshape(conv_pat).WithShape(\n-                                                    S8, {10, 4, 20, 30, 8, 4}))\n-                                       .WithShape(S8, {10, 4, 8, 20, 30, 4}))\n-                            .WithShape(S8, {10, 32, 20, 30, 4}),\n-                        m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, Vectorize4To32VectorDimFirst) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[4,10,20,30,16] parameter(0)\n-    filter = s8[4,3,5,16,192] parameter(1)\n-    bias = f32[64] parameter(2)\n-    side_input = s8[4,10,20,30,16] parameter(3)\n-    ROOT result = (s8[4,10,20,30,48], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=3x5}, dim_labels=?b01f_?01io->?b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  auto conv_pat =\n-      m::GetTupleElement(\n-          m::CustomCall(\n-              &conv, {kCudnnConvForwardCallTarget},\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(0))\n-                                          .WithShape(S8, {4, 10, 20, 30, 2, 8}))\n-                             .WithShape(S8, {8, 4, 10, 20, 30, 2}))\n-                  .WithShape(S8, {32, 10, 20, 30, 2}),\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(m::Parameter(1))\n-                                   .WithShape(S8, {4, 3, 5, 2, 8, 24, 4, 2}))\n-                      .WithShape(S8, {2, 3, 5, 24, 2, 8, 4, 4})\n-                      .WithPredicate([](const HloInstruction* instr) {\n-                        return absl::c_equal(\n-                            instr->dimensions(),\n-                            std::vector<int64_t>{3, 1, 2, 5, 7, 4, 6, 0});\n-                      }))\n-                  .WithShape(S8, {192, 2, 3, 5, 32}),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(2)))),\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(3))\n-                                          .WithShape(S8, {4, 10, 20, 30, 2, 8}))\n-                             .WithShape(S8, {8, 4, 10, 20, 30, 2}))\n-                  .WithShape(S8, {32, 10, 20, 30, 2}))\n-              .WithConvDnums(\"?b01f_oi01->?b01f\"))\n-          .WithShape(S8, {32, 10, 20, 30, 6});\n-  ASSERT_THAT(root, GmockMatch(m::Tuple(\n-                        m::Reshape(m::Transpose(m::Reshape(conv_pat).WithShape(\n-                                                    S8, {8, 4, 10, 20, 30, 6}))\n-                                       .WithShape(S8, {4, 10, 20, 30, 6, 8}))\n-                            .WithShape(S8, {4, 10, 20, 30, 48}),\n-                        m::Op())));\n-\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, NoVectorize4To32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,16,4] parameter(0)\n-    filter = s8[2,2,16,128,4] parameter(1)\n-    bias = f32[10] parameter(2)\n-    side_input = s8[10,20,30,16,4] parameter(3)\n-    ROOT result = (s8[10,20,30,32,4], u8[0]) custom-call(input, filter, bias, side_input),\n-                  window={size=2x2}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 0}, module.get()));\n-  EXPECT_FALSE(changed);\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, Vectorize16To32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,4,16] parameter(0)\n-    filter = s8[3,5,4,192,16] parameter(1)\n-    ROOT result = (s8[10,20,30,12,16], u8[0]) custom-call(input, filter),\n-                  window={size=3x5}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  auto filter_pat =\n-      m::Reshape(\n-          m::Transpose(\n-              m::Reshape(m::Parameter(1)).WithShape(S8, {3, 5, 2, 2, 192, 16}))\n-              .WithShape(S8, {3, 5, 2, 192, 2, 16}))\n-          .WithShape(S8, {3, 5, 2, 192, 32});\n-  auto conv_pat =\n-      m::GetTupleElement(\n-          m::CustomCall(\n-              &conv, {kCudnnConvForwardCallTarget},\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(m::Parameter(0))\n-                                   .WithShape(S8, {10, 20, 30, 2, 2, 16}))\n-                      .WithShape(S8, {10, 20, 30, 2, 2, 16}))\n-                  .WithShape(S8, {10, 20, 30, 2, 32}),\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(filter_pat)\n-                                   .WithShape(S8, {3, 5, 2, 24, 4, 2, 8, 4}))\n-                      .WithShape(S8, {2, 3, 5, 24, 2, 8, 4, 4}))\n-                  .WithShape(S8, {192, 2, 3, 5, 32}))\n-              .WithConvDnums(\"b01f_oi01->b01f\"))\n-          .WithShape(S8, {10, 20, 30, 6, 32});\n-  ASSERT_THAT(root, GmockMatch(m::Tuple(\n-                        m::Reshape(m::Transpose(m::Reshape(conv_pat).WithShape(\n-                                                    S8, {10, 20, 30, 6, 2, 16}))\n-                                       .WithShape(S8, {10, 20, 30, 6, 2, 16}))\n-                            .WithShape(S8, {10, 20, 30, 12, 16}),\n-                        m::Op())));\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-TEST_F(CudnnVectorizeConvolutionsTest, VectorizeMixedTo32) {\n-  auto module = ParseAndReturnVerifiedModule(R\"(\n-  HloModule TestModule\n-\n-  ENTRY TestComputation {\n-    input = s8[10,20,30,8,8] parameter(0)\n-    filter = s8[3,5,2,192,32] parameter(1)\n-    ROOT result = (s8[10,20,30,96,2], u8[0]) custom-call(input, filter),\n-                  window={size=3x5}, dim_labels=b01f_01io->b01f,\n-                  custom_call_target=\"__cudnn$convForward\"\n-  })\")\n-                    .value();\n-  TF_ASSERT_OK_AND_ASSIGN(bool changed, Run({7, 5}, module.get()));\n-  EXPECT_TRUE(changed);\n-\n-  SCOPED_TRACE(module->ToString());\n-  auto* root = module->entry_computation()->root_instruction();\n-\n-  const HloInstruction* conv = nullptr;\n-  auto conv_pat =\n-      m::GetTupleElement(\n-          m::CustomCall(\n-              &conv, {kCudnnConvForwardCallTarget},\n-              m::Reshape(m::Transpose(m::Reshape(m::Parameter(0))\n-                                          .WithShape(S8, {10, 20, 30, 2, 4, 8}))\n-                             .WithShape(S8, {10, 20, 30, 2, 4, 8}))\n-                  .WithShape(S8, {10, 20, 30, 2, 32}),\n-              m::Reshape(\n-                  m::Transpose(m::Reshape(m::Parameter(1))\n-                                   .WithShape(S8, {3, 5, 2, 24, 4, 2, 8, 4}))\n-                      .WithShape(S8, {2, 3, 5, 24, 2, 8, 4, 4}))\n-                  .WithShape(S8, {192, 2, 3, 5, 32}))\n-              .WithConvDnums(\"b01f_oi01->b01f\"))\n-          .WithShape(S8, {10, 20, 30, 6, 32});\n-  ASSERT_THAT(root, GmockMatch(m::Tuple(\n-                        m::Reshape(m::Transpose(m::Reshape(conv_pat).WithShape(\n-                                                    S8, {10, 20, 30, 6, 16, 2}))\n-                                       .WithShape(S8, {10, 20, 30, 6, 16, 2}))\n-                            .WithShape(S8, {10, 20, 30, 96, 2}),\n-                        m::Op())));\n-  EXPECT_TRUE(conv->backend_config<GpuBackendConfig>()\n-                  ->cudnn_conv_backend_config()\n-                  .reordered_int8_nchw_vect());\n-}\n-\n-}  // namespace\n-}  // namespace gpu\n-}  // namespace xla"
        }
    ],
    "stats": {
        "total": 2127,
        "additions": 10,
        "deletions": 2117
    }
}