{
    "author": "WillFroom",
    "message": "[XLA:CPU] Remove xla_cpu_use_thunk_runtime flag.\n\nPiperOrigin-RevId: 801723396",
    "sha": "48581a319c6ad81c4176ac8b9546353159362b76",
    "files": [
        {
            "sha": "61a7b8fd4d77dafb204af7bf378859e7cdca54ed",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/hlo_benchmark_runner.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -326,12 +326,6 @@ absl::Status CompileHloBenchmark(benchmark::State& state,\n     compile_options.executable_build_options.mutable_debug_options()\n         ->add_xla_disable_hlo_passes(\"cpu-parallel-task-assigner\");\n   }\n-  // TODO(intel-tf): Remove this if-block once oneDNN custom calls are enabled\n-  // with thunk runtime\n-  if (!benchmark_options.use_thunk_runtime) {\n-    compile_options.executable_build_options.mutable_debug_options()\n-        ->set_xla_cpu_use_thunk_runtime(false);\n-  }\n \n   for (auto _ : state) {\n     TF_ASSIGN_OR_RETURN(std::unique_ptr<PjRtLoadedExecutable> executable,"
        },
        {
            "sha": "87fac7b2cbb1cbeff1dc0b2d00a054b83afe6fbd",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/hlo_benchmark_runner.h",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fhlo_benchmark_runner.h?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -40,7 +40,6 @@ using StrToStrMapping =\n struct HloBenchmarkOptions {\n   int32_t num_executions = 1;\n   bool disable_parallel_task_assigner = false;\n-  bool use_thunk_runtime = true;\n   // If not null, AOT compilation will be used.\n   std::unique_ptr<AotCompilationOptions> aot_options;\n };"
        },
        {
            "sha": "c354818455c6569e7f987008a5cccd96beb55813",
            "filename": "third_party/xla/xla/backends/cpu/benchmarks/onednn_matmul_benchmark_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fonednn_matmul_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fonednn_matmul_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fbenchmarks%2Fonednn_matmul_benchmark_test.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -74,7 +74,6 @@ static void BM_oneDNN_MM(benchmark::State& state) {\n \n   std::vector<const Literal*> args = {&p0, &p1};\n   HloBenchmarkOptions benchmark_options;\n-  benchmark_options.use_thunk_runtime = false;\n   CHECK_OK(RunHloBenchmark(\n       state, hlo, args,\n       {{\"$dtype\", primitive_util::LowercasePrimitiveTypeName(dtype)},"
        },
        {
            "sha": "6d7d125035d158f42dfe052ae4d3bc75d7d9256c",
            "filename": "third_party/xla/xla/backends/cpu/codegen/emitters/cpu_fusion_emitter_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fcpu_fusion_emitter_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fcpu_fusion_emitter_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fcpu%2Fcodegen%2Femitters%2Fcpu_fusion_emitter_test.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -124,7 +124,6 @@ TEST_F(CpuFusionEmitterTest, ScatterMlir) {\n   TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n                           ParseAndReturnVerifiedModule(kScatterHlo));\n   auto& debug_options = hlo_module->mutable_config().mutable_debug_options();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n   debug_options.set_xla_cpu_use_fusion_emitters(true);\n   TF_ASSERT_OK_AND_ASSIGN(auto buffer_assignment,\n                           RunBufferAssignment(*hlo_module));\n@@ -152,7 +151,6 @@ TEST_F(CpuFusionEmitterTest, ScatterLlvm) {\n   TF_ASSERT_OK_AND_ASSIGN(auto hlo_module,\n                           ParseAndReturnVerifiedModule(kScatterHlo));\n   auto& debug_options = hlo_module->mutable_config().mutable_debug_options();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n   debug_options.set_xla_cpu_use_fusion_emitters(true);\n   debug_options.set_xla_cpu_prefer_vector_width(512);\n   TF_ASSERT_OK_AND_ASSIGN(auto buffer_assignment,"
        },
        {
            "sha": "ac099e728b7915c79e538163f42bdefe1c266df0",
            "filename": "third_party/xla/xla/debug_options_flags.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 8,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fdebug_options_flags.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -208,7 +208,6 @@ DebugOptions DefaultDebugOptionsIgnoringFlags() {\n   opts.set_xla_cpu_use_acl(true);\n #endif\n   opts.set_xla_cpu_use_fusion_emitters(true);\n-  opts.set_xla_cpu_use_thunk_runtime(true);\n   opts.set_xla_cpu_use_xnnpack(true);\n   opts.set_xla_cpu_experimental_xnn_graph_fusion_mode(\n       DebugOptions::XNN_GRAPH_FUSION_MODE_DISABLED);\n@@ -1086,13 +1085,15 @@ void MakeDebugOptionsFlags(std::vector<tsl::Flag>* flag_list,\n       tsl::Flag(\"xla_cpu_use_fusion_emitters\",\n                 bool_setter_for(&DebugOptions::set_xla_cpu_use_fusion_emitters),\n                 debug_options->xla_cpu_use_fusion_emitters(),\n-                \"Use fusion emitters for code generation in the CPU backend. \"\n-                \"Note: only works with --xla_cpu_use_thunk_runtime=true.\"));\n-  flag_list->push_back(\n-      tsl::Flag(\"xla_cpu_use_thunk_runtime\",\n-                bool_setter_for(&DebugOptions::set_xla_cpu_use_thunk_runtime),\n-                debug_options->xla_cpu_use_thunk_runtime(),\n-                \"Use Thunk-based runtime for the CPU backend.\"));\n+                \"Use fusion emitters for code generation in the CPU backend.\"));\n+  flag_list->push_back(tsl::Flag(\n+      \"xla_cpu_use_thunk_runtime\",\n+      [](bool) {\n+        LOG(WARNING) << \"\\\"xla_cpu_use_thunk_runtime\\\" is no longer supported \"\n+                        \"and will be removed in a future release.\";\n+        return true;\n+      },\n+      true, \"Deprecated.\"));\n   flag_list->push_back(\n       tsl::Flag(\"xla_cpu_use_xnnpack\",\n                 bool_setter_for(&DebugOptions::set_xla_cpu_use_xnnpack),"
        },
        {
            "sha": "7779629bf57b56caef4266512aa456caca8315af",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 12,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -530,10 +530,7 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n     HloModule* module, bool is_aot_compile,\n     TargetMachineFeatures* target_machine_features) {\n   const int64_t num_partitions = module->config().num_partitions();\n-  const bool is_thunk_runtime =\n-      module->config().debug_options().xla_cpu_use_thunk_runtime();\n   const bool is_fusion_emitters =\n-      is_thunk_runtime &&\n       module->config().debug_options().xla_cpu_use_fusion_emitters();\n   bool use_shardy_partitioner = module->config().use_shardy_partitioner();\n   bool is_onednn_compatible = false;\n@@ -660,6 +657,7 @@ absl::Status CpuCompiler::RunHloPassesThroughLayoutAssn(\n   // Rewrite to custom calls with target as oneDNN library calls.\n #if defined(INTEL_MKL)\n   // AOT compiled code runs in single thread.\n+  bool is_thunk_runtime = true;\n   is_onednn_compatible = !is_aot_compile && !is_thunk_runtime;\n   if (is_onednn_compatible) {\n     // Placing OneDnnOpsRewriter here to match the flax patterns\n@@ -852,9 +850,7 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n     TargetMachineFeatures* target_machine_features,\n     const CompileOptions& compile_options) {\n   const auto& debug_options = module->config().debug_options();\n-  const bool is_thunk_runtime = debug_options.xla_cpu_use_thunk_runtime();\n-  const bool is_fusion_emitters =\n-      is_thunk_runtime && debug_options.xla_cpu_use_fusion_emitters();\n+  const bool is_fusion_emitters = debug_options.xla_cpu_use_fusion_emitters();\n   bool is_onednn_compatible = false;\n   bool flatten_after_fusion = options::FlattenAfterFusion(module->config());\n   HloPassPipeline pipeline(\"HLO passes after layout assignment\");\n@@ -881,6 +877,7 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n \n #if defined(INTEL_MKL)\n   // AOT compiled code runs in single thread.\n+  bool is_thunk_runtime = true;\n   is_onednn_compatible = !is_aot_compile && !is_thunk_runtime;\n   if (is_onednn_compatible) {\n     // Run SimplifyFPConversions pass to simplify the BF16 pattern and make it\n@@ -1009,7 +1006,7 @@ absl::Status CpuCompiler::RunHloPassesAfterLayoutAssn(\n \n   // The hoisting of small while loops is only useful in the context of the\n   // thunk runtime.\n-  if (module->config().debug_options().xla_cpu_use_thunk_runtime()) {\n+  {\n     TF_ASSIGN_OR_RETURN(\n         int64_t byte_threshold,\n         xla::cpu::options::SmallWhileLoopByteThreshold(module->config()));\n@@ -1959,11 +1956,6 @@ CpuCompiler::CompileAheadOfTime(std::unique_ptr<HloModuleGroup> module_group,\n                                     target_machine.get(),\n                                     /*dummy*/ CompileOptions{}));\n \n-    if (!hlo_module->config().debug_options().xla_cpu_use_thunk_runtime()) {\n-      return InvalidArgument(\n-          \"xla_cpu_use_thunk_runtime must be true for AOT compilation.\");\n-    }\n-\n     TF_ASSIGN_OR_RETURN(\n         results.emplace_back(),\n         CompileAheadOfTimeThunks(std::move(hlo_module), target_machine_builder,"
        },
        {
            "sha": "38e27955521f90d566f7ae4a307775497a8ac52c",
            "filename": "third_party/xla/xla/service/cpu/cpu_compiler_internals_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler_internals_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler_internals_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_compiler_internals_test.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -105,7 +105,6 @@ TEST_F(CpuCompilerInternalsTest, DylibWithThunks) {\n                           ParseAndReturnVerifiedModule(kAddScatterHlo));\n   DebugOptions& debug_options =\n       hlo_module->mutable_config().mutable_debug_options();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n   debug_options.set_xla_cpu_use_fusion_emitters(false);\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> optimized_module,\n                           GetOptimizedModule(std::move(hlo_module)));\n@@ -136,7 +135,6 @@ TEST_F(CpuCompilerInternalsTest, JustOneDylibWithThunks) {\n                           ParseAndReturnVerifiedModule(kAddScatterHlo));\n   DebugOptions& debug_options =\n       hlo_module->mutable_config().mutable_debug_options();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n   debug_options.set_xla_cpu_use_fusion_emitters(false);\n   debug_options.set_xla_cpu_parallel_codegen_split_count(1);\n   TF_ASSERT_OK_AND_ASSIGN(std::unique_ptr<HloModule> optimized_module,"
        },
        {
            "sha": "eb5dc2e99d1456f6b632b93b2d5d835c1d4fc142",
            "filename": "third_party/xla/xla/service/cpu/cpu_instruction_fusion.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -85,7 +85,6 @@ bool BlockSubcomputationFusion(const HloInstruction* instruction,\n                                const HloModuleConfig& config) {\n   HloOpcode opcode = instruction->opcode();\n   const bool is_fusion_emitters =\n-      config.debug_options().xla_cpu_use_thunk_runtime() &&\n       config.debug_options().xla_cpu_use_fusion_emitters();\n \n   if (is_fusion_emitters && opcode == HloOpcode::kScatter) {"
        },
        {
            "sha": "f0159f209deb33dfde07bb235856e0ac7b828c48",
            "filename": "third_party/xla/xla/service/cpu/cpu_instruction_fusion_test.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Fcpu_instruction_fusion_test.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -1098,7 +1098,6 @@ ENTRY %main (arg0: f32[13,5,10,62], arg1: s32[3,1], arg2: f32[3,1,5,10,62])\n TEST_F(InstructionFusionTest, SkipScatterComputationsIfFusionEmitters) {\n   auto mod_config = GetModuleConfigForTest();\n   auto debug_options = GetDebugOptionsForTest();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n   debug_options.set_xla_cpu_use_fusion_emitters(true);\n   mod_config.set_debug_options(debug_options);\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnVerifiedModule("
        },
        {
            "sha": "5b5878138b78bd6b617a1ca4b98492df57d457d5",
            "filename": "third_party/xla/xla/service/cpu/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2FBUILD?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -153,6 +153,7 @@ xla_cc_test(\n         \"//xla/tests:pjrt_cpu_client_registry\",\n         \"//xla/tests:xla_internal_test_main\",\n         \"//xla/tsl/lib/core:status_test_util\",\n+        \"//xla/tsl/platform:test\",\n         \"@com_google_absl//absl/status\",\n     ],\n )"
        },
        {
            "sha": "c95fcee3cb2f2816ded301095637c94d54814ba9",
            "filename": "third_party/xla/xla/service/cpu/tests/cpu_ffi_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 14,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_ffi_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_ffi_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fcpu%2Ftests%2Fcpu_ffi_test.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -26,6 +26,7 @@ limitations under the License.\n #include \"xla/shape_util.h\"\n #include \"xla/tests/hlo_pjrt_test_base.h\"\n #include \"xla/tsl/lib/core/status_test_util.h\"\n+#include \"xla/tsl/platform/test.h\"\n \n namespace xla {\n namespace {\n@@ -42,21 +43,15 @@ XLA_FFI_DEFINE_HANDLER(\n XLA_FFI_REGISTER_HANDLER(ffi::GetXlaFfiApi(), \"__xla_test$$io_callback\", \"Host\",\n                          kIOCallback);\n \n-class CpuFFITest : public HloPjRtTestBase,\n-                   public ::testing::WithParamInterface<bool> {\n+class CpuFFITest : public HloPjRtTestBase {\n  protected:\n-  bool thunk_rt_val_;\n-\n-  CpuFFITest() { thunk_rt_val_ = GetParam(); }\n-\n   DebugOptions GetDebugOptionsForTest() const override {\n     DebugOptions debug_options = GetDebugOptionsFromFlags();\n-    debug_options.set_xla_cpu_use_thunk_runtime(thunk_rt_val_);\n     return debug_options;\n   }\n };\n \n-TEST_P(CpuFFITest, EmulateImpureCallbackWithTokens) {\n+TEST_F(CpuFFITest, EmulateImpureCallbackWithTokens) {\n   auto module = CreateNewVerifiedModule();\n   auto builder = HloComputation::Builder(TestName());\n \n@@ -74,11 +69,5 @@ TEST_P(CpuFFITest, EmulateImpureCallbackWithTokens) {\n   TF_EXPECT_OK(Execute(std::move(module), {}).status());\n }\n \n-INSTANTIATE_TEST_SUITE_P(\n-    FFITest, CpuFFITest, ::testing::Values(true),\n-    [](const ::testing::TestParamInfo<CpuFFITest::ParamType>& info) {\n-      return info.param ? \"ThunkRuntime\" : \"LegacyRuntime\";\n-    });\n-\n }  // namespace\n }  // namespace xla"
        },
        {
            "sha": "7749b3afdc8959f97f78ca22ef45a03d63e548a6",
            "filename": "third_party/xla/xla/tools/run_hlo_module.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -167,12 +167,6 @@ absl::StatusOr<Literal> ExecuteWithRunner(\n   return std::move(result_status).value();\n }\n \n-void UseCpuThunkRuntime(HloModule& module) {\n-  auto debug_options = module.config().debug_options();\n-  debug_options.set_xla_cpu_use_thunk_runtime(true);\n-  module.mutable_config().set_debug_options(debug_options);\n-}\n-\n absl::Status RunAndCompareInternal(\n     std::unique_ptr<HloModule> test_module,\n     const BufferAssignmentProto* buffer_assignment_proto,\n@@ -278,12 +272,6 @@ absl::Status RunAndCompareInternal(\n             ModuleResult::kCompilationError, reference_run_result));\n   }\n \n-  // Now when reference_module is ready, we can modify test_module without\n-  // impacting the reference run.\n-  if (options.force_use_cpu_thunk_runtime_for_test) {\n-    UseCpuThunkRuntime(*test_module);\n-  }\n-\n   TF_ASSIGN_OR_RETURN(\n       auto test_result,\n       copy_result_on_failure("
        },
        {
            "sha": "3300f1b1b8671df7f5fe9b6b3c58e205f10d104a",
            "filename": "third_party/xla/xla/tools/run_hlo_module.h",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module.h?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -40,7 +40,6 @@ struct RunHloModuleOptions {\n   bool flatten_control_flow{false};\n   bool run_test_hlo_passes{true};\n   bool run_reference_hlo_passes{true};\n-  bool force_use_cpu_thunk_runtime_for_test{false};\n   // Using small float range by default, as otherwise all reductions\n   // miscompare vs. the interpreter with inf/nan.\n   bool use_large_float_range{false};"
        },
        {
            "sha": "3ea05bc0fc513fb89447be9694068463c43958ea",
            "filename": "third_party/xla/xla/tools/run_hlo_module_main.cc",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module_main.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module_main.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Ftools%2Frun_hlo_module_main.cc?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -152,13 +152,6 @@ int main(int argc, char** argv) {\n           \"other \"\n           \"than the reference this is necessary because some HLO passes are \"\n           \"legalization passes which must be run prior to code generation.\"),\n-      tsl::Flag(\n-          \"force_use_cpu_thunk_runtime_for_test\",\n-          &opts.force_use_cpu_thunk_runtime_for_test,\n-          \"Use thunk runtime for the test platform. If true, thunks runtime \"\n-          \"will be used for the test run regardless of the \"\n-          \"xla_cpu_use_thunk_runtime flag in XLA_FLAGS. This option doesn't \"\n-          \"impact reference run. It is ignored for platforms other than CPU.\"),\n       tsl::Flag(\"random_init_input_literals\", &opts.random_init_input_literals,\n                 \"Initialize input literals with random numbers.\"\n                 \"Leave them uninitialized otherwise.\"),"
        },
        {
            "sha": "56bd30069d7e5ab62627d61e23412d84d335e836",
            "filename": "third_party/xla/xla/xla.proto",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fxla.proto",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/48581a319c6ad81c4176ac8b9546353159362b76/third_party%2Fxla%2Fxla%2Fxla.proto",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fxla.proto?ref=48581a319c6ad81c4176ac8b9546353159362b76",
            "patch": "@@ -244,9 +244,6 @@ message DebugOptions {\n   // If set, XLA:CPU uses \"fusion emitters\" for codegen.\n   optional bool xla_cpu_use_fusion_emitters = 376;\n \n-  // When true, XLA:CPU uses the thunk runtime to execute compiled program.\n-  optional bool xla_cpu_use_thunk_runtime = 298;\n-\n   // When true, XLA:CPU uses XNNPACK to execute supported operations.\n   optional bool xla_cpu_use_xnnpack = 359;\n \n@@ -255,6 +252,8 @@ message DebugOptions {\n \n   // go/keep-sorted end\n \n+  reserved 298;  // Was xla_cpu_use_thunk_runtime\n+\n   //--------------------------------------------------------------------------//\n   // XLA:GPU options.\n   //--------------------------------------------------------------------------//"
        }
    ],
    "stats": {
        "total": 90,
        "additions": 19,
        "deletions": 71
    }
}