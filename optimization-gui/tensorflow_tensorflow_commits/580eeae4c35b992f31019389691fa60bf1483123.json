{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 847190483",
    "sha": "580eeae4c35b992f31019389691fa60bf1483123",
    "files": [
        {
            "sha": "e485fb8c7d31b0cf5da3d43601f510902ef269f0",
            "filename": "tensorflow/core/common_runtime/device/device_event_mgr_test.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/580eeae4c35b992f31019389691fa60bf1483123/tensorflow%2Fcore%2Fcommon_runtime%2Fdevice%2Fdevice_event_mgr_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/580eeae4c35b992f31019389691fa60bf1483123/tensorflow%2Fcore%2Fcommon_runtime%2Fdevice%2Fdevice_event_mgr_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fcommon_runtime%2Fdevice%2Fdevice_event_mgr_test.cc?ref=580eeae4c35b992f31019389691fa60bf1483123",
            "patch": "@@ -184,12 +184,12 @@ class EMBenchmarkHelper {\n   // The rest of these are one per chain.\n   NodeDef add_node_def_;\n   NodeDef id_node_def_;\n-  gtl::InlinedVector<TensorValue, 4> add_inputs_;\n+  absl::InlinedVector<TensorValue, 4UL> add_inputs_;\n   std::vector<AllocatorAttributes> allocator_attrs_;\n-  gtl::InlinedVector<Tensor, 4> gpu_inputs_;\n-  gtl::InlinedVector<Tensor, 4> gpu_outputs_;\n-  gtl::InlinedVector<Tensor, 4> host_inputs_;\n-  gtl::InlinedVector<Tensor, 4> host_outputs_;\n+  absl::InlinedVector<Tensor, 4UL> gpu_inputs_;\n+  absl::InlinedVector<Tensor, 4UL> gpu_outputs_;\n+  absl::InlinedVector<Tensor, 4UL> host_inputs_;\n+  absl::InlinedVector<Tensor, 4UL> host_outputs_;\n \n  public:\n   // Length of tensors.  TODO(tucker): make this a variable parameter.\n@@ -242,7 +242,7 @@ class EMBenchmarkHelper {\n   }\n \n   std::unique_ptr<OpKernel> GetOpKernel(const NodeDef& node_def,\n-                                        Status* status) {\n+                                        absl::Status* status) {\n     return CreateOpKernel(\"GPU\", gpu_helper_->gpu(),\n                           gpu_helper_->gpu_allocator(), node_def,\n                           TF_GRAPH_DEF_VERSION, status);\n@@ -256,7 +256,7 @@ class EMBenchmarkHelper {\n                        .Device(\"/job:a/replica:0/task:0/GPU:0\")\n                        .Finalize(&add_node_def_));\n     }\n-    Status status;\n+    absl::Status status;\n     add_kernels_.emplace_back(GetOpKernel(add_node_def_, &status));\n     TF_ASSERT_OK(status);\n     add_params_.push_back(new OpKernelContext::Params);\n@@ -385,12 +385,12 @@ class EMBenchmarkHelper {\n           gpu_helper_->h2d_stream()->WaitFor(gpu_helper_->compute_stream()));\n       // Begin by copying the input values from CPU to GPU.\n       const int64_t src_bytes = host_inputs_[0].TotalBytes();\n-      se::DeviceMemoryBase gpu_dst_ptr0(DMAHelper::base(&gpu_inputs_[0]),\n-                                        src_bytes);\n+      stream_executor::DeviceAddressBase gpu_dst_ptr0(\n+          DMAHelper::base(&gpu_inputs_[0]), src_bytes);\n       TF_ASSERT_OK(gpu_helper_->h2d_stream()->Memcpy(\n           &gpu_dst_ptr0, DMAHelper::base(&host_inputs_[0]), src_bytes));\n-      se::DeviceMemoryBase gpu_dst_ptr1(DMAHelper::base(&gpu_inputs_[1]),\n-                                        src_bytes);\n+      stream_executor::DeviceAddressBase gpu_dst_ptr1(\n+          DMAHelper::base(&gpu_inputs_[1]), src_bytes);\n       TF_ASSERT_OK(gpu_helper_->h2d_stream()->Memcpy(\n           &gpu_dst_ptr1, DMAHelper::base(&host_inputs_[1]), src_bytes));\n       TF_ASSERT_OK(\n@@ -421,8 +421,8 @@ class EMBenchmarkHelper {\n       TF_ASSERT_OK(\n           gpu_helper_->d2h_stream()->WaitFor(gpu_helper_->compute_stream()));\n       const int64_t return_bytes = ctx->mutable_output(0)->TotalBytes();\n-      se::DeviceMemoryBase gpu_src_ptr(DMAHelper::base(ctx->mutable_output(0)),\n-                                       return_bytes);\n+      stream_executor::DeviceAddressBase gpu_src_ptr(\n+          DMAHelper::base(ctx->mutable_output(0)), return_bytes);\n       TF_ASSERT_OK(gpu_helper_->d2h_stream()->Memcpy(\n           DMAHelper::base(&host_outputs_[0]), gpu_src_ptr, return_bytes));\n       gpu_helper_->event_mgr()->ThenExecute(gpu_helper_->d2h_stream(),"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 13,
        "deletions": 13
    }
}