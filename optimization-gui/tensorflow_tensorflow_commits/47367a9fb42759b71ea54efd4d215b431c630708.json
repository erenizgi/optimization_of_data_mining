{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 828881451",
    "sha": "47367a9fb42759b71ea54efd4d215b431c630708",
    "files": [
        {
            "sha": "340cdbe8032c63b006da58520d196808284ecb1d",
            "filename": "tensorflow/compiler/jit/mark_for_compilation_pass.cc",
            "status": "modified",
            "additions": 47,
            "deletions": 43,
            "changes": 90,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -151,7 +151,7 @@ class MarkForCompilationPassImpl {\n             std::optional<DeviceId> resource_op_device,\n             std::optional<int> resource_var_operation_node_id,\n             std::optional<DeadnessPredicate> deadness_predicate,\n-            bool is_xla_compile_attr_true, std::optional<string> xla_scope)\n+            bool is_xla_compile_attr_true, std::optional<std::string> xla_scope)\n         : cycles_graph_node_id_(tf_graph_node_id),\n           effective_cluster_size_(effective_cluster_size),\n           has_functional_control_flow_(has_functional_control_flow),\n@@ -220,15 +220,15 @@ class MarkForCompilationPassImpl {\n \n     // If not nullopt then the all nodes in the cluster either do not have the\n     // XlaScope attribute set or have it set to the value returned.\n-    const std::optional<string>& xla_scope() const { return xla_scope_; }\n+    const std::optional<std::string>& xla_scope() const { return xla_scope_; }\n \n     // Returns the TF graph node IDs for the resource variable operations in\n     // this cluster.\n     absl::Span<const int> resource_var_operation_node_ids() const {\n       return resource_var_operation_node_ids_;\n     }\n \n-    string DebugString(const Graph& graph) const {\n+    std::string DebugString(const Graph& graph) const {\n       Node* node = graph.FindNodeId(cycles_graph_node_id());\n       if (!node) {\n         // This should never happen but we try to be resilient because this is a\n@@ -254,7 +254,7 @@ class MarkForCompilationPassImpl {\n     std::optional<DeviceId> resource_op_device_;\n     std::optional<DeadnessPredicate> deadness_predicate_;\n     bool is_xla_compile_attr_true_;\n-    std::optional<string> xla_scope_;\n+    std::optional<std::string> xla_scope_;\n     std::vector<int> resource_var_operation_node_ids_;\n \n     Cluster(const Cluster&) = delete;\n@@ -365,7 +365,7 @@ class MarkForCompilationPassImpl {\n                           std::optional<int> resource_var_operation_node_id,\n                           std::optional<DeadnessPredicate> deadness_predicate,\n                           bool is_xla_compile_attr_true,\n-                          std::optional<string> xla_scope) {\n+                          std::optional<std::string> xla_scope) {\n     cluster_storage_.push_back(std::make_unique<Cluster>(\n         cycles_graph_node_id, effective_cluster_size,\n         has_functional_control_flow, device_set, resource_op_device,\n@@ -374,7 +374,7 @@ class MarkForCompilationPassImpl {\n     return cluster_storage_.back().get();\n   }\n \n-  std::optional<string> GetXlaScope(Node* n);\n+  std::optional<std::string> GetXlaScope(Node* n);\n \n   // Returns the cluster for node `n`.  If two nodes, N1 and N2, are placed in\n   // the same cluster by the clustering algorithm then this function will return\n@@ -417,7 +417,8 @@ class MarkForCompilationPassImpl {\n   // Returns a string representing `cycles_graph_node_id`.  If the node is\n   // unclusterable (either it is a phatom \"frame\" node or is not a compilation\n   // candidate) then set `*found_unclustered` to true.\n-  string DebugStringForCyclesGraphNode(int node_id, bool* found_unclustered);\n+  std::string DebugStringForCyclesGraphNode(int node_id,\n+                                            bool* found_unclustered);\n \n   // We could not contract the edge from `from` to `to`.  Return a string\n   // describing an alternate path from `from` to `to` (besides the direct edge\n@@ -429,7 +430,7 @@ class MarkForCompilationPassImpl {\n   // contracted because of the path [P,Q,R]\" where P, Q and R are all clusters\n   // since in that case a natural question is why we could not form a {A, P, Q,\n   // R, B} cluster.\n-  string DescribePotentialCycle(int from, int to);\n+  std::string DescribePotentialCycle(int from, int to);\n \n   // Merge the clusters `cluster_from` and `cluster_to`. After this step the\n   // larger combined cluster is represented by `cluster_from`, but can have\n@@ -459,16 +460,16 @@ class MarkForCompilationPassImpl {\n     return true;\n   }\n \n-  string EdgeContractionFailureMsg(Cluster* from, Cluster* to,\n-                                   absl::string_view reason) {\n+  std::string EdgeContractionFailureMsg(Cluster* from, Cluster* to,\n+                                        absl::string_view reason) {\n     return absl::StrCat(\"Could not contract \", from->DebugString(*graph_),\n                         \" -> \", to->DebugString(*graph_), \" because \", reason,\n                         \".\");\n   }\n \n   DebugOptions debug_options_;\n   Graph* graph_;\n-  uint64 graph_fingerprint_;\n+  uint64_t graph_fingerprint_;\n   FunctionLibraryDefinition* flib_def_;\n   Env* env_;\n   OptimizerOptions::GlobalJitLevel global_jit_level_;\n@@ -547,7 +548,7 @@ std::vector<int> MarkForCompilationPassImpl::FindAlternatePathForDebugging(\n   return path;\n }\n \n-string MarkForCompilationPassImpl::DebugStringForCyclesGraphNode(\n+std::string MarkForCompilationPassImpl::DebugStringForCyclesGraphNode(\n     int cycles_graph_node_id, bool* found_unclustered) {\n   Cluster* cluster = GetClusterForCyclesGraphNode(cycles_graph_node_id);\n   if (cluster) {\n@@ -567,8 +568,9 @@ string MarkForCompilationPassImpl::DebugStringForCyclesGraphNode(\n   return node->name();\n }\n \n-string MarkForCompilationPassImpl::DescribePotentialCycle(int from, int to) {\n-  std::vector<string> path_str;\n+std::string MarkForCompilationPassImpl::DescribePotentialCycle(int from,\n+                                                               int to) {\n+  std::vector<std::string> path_str;\n   bool found_unclustered = false;\n   absl::c_transform(FindAlternatePathForDebugging(from, to),\n                     std::back_inserter(path_str), [&](int node_id) {\n@@ -701,7 +703,7 @@ absl::StatusOr<bool> MarkForCompilationPassImpl::ForEachEdgeInPostOrder(\n \n     // Make a copy of the set of successors because we may modify the graph in\n     // TryToContractEdge.\n-    std::vector<int32> successors_copy =\n+    std::vector<int32_t> successors_copy =\n         cycles_graph_.SuccessorsCopy(cluster_from->cycles_graph_node_id());\n \n     for (int to : successors_copy) {\n@@ -974,7 +976,7 @@ class ClusterSequenceNumberGenerator {\n     sequence_numbers_.clear();\n   }\n \n-  int64 GetNext(uint64 key) {\n+  int64_t GetNext(uint64_t key) {\n     mutex_lock lock(mu_);\n     return sequence_numbers_[key]++;\n   }\n@@ -987,13 +989,13 @@ class ClusterSequenceNumberGenerator {\n \n  private:\n   mutex mu_;\n-  absl::flat_hash_map<uint64, int64> sequence_numbers_;\n+  absl::flat_hash_map<uint64_t, int64_t> sequence_numbers_;\n };\n \n // Get a monotonic sequence numbers for a graph identified by its `fingerprint`.\n // The sequence number is necessary to disambiguate clusters extracted from the\n // same graph and when duplicate graphs exist within the same process.\n-int64_t GetNextClusterSequenceNumber(uint64 fingerprint) {\n+int64_t GetNextClusterSequenceNumber(uint64_t fingerprint) {\n   return ClusterSequenceNumberGenerator::Global().GetNext(fingerprint);\n }\n \n@@ -1002,7 +1004,7 @@ absl::Status MarkForCompilationPassImpl::CreateClusters() {\n   clusters_created_ = true;\n \n   // Names for each cluster.\n-  std::unordered_map<int, string> cluster_names;\n+  std::unordered_map<int, std::string> cluster_names;\n \n   if (debug_options_.dump_graphs) {\n     DumpGraphToFile(\"before_mark_for_compilation\", *graph_, flib_def_);\n@@ -1030,7 +1032,7 @@ absl::Status MarkForCompilationPassImpl::CreateClusters() {\n     if (cluster->effective_cluster_size() >= debug_options_.min_cluster_size ||\n         cluster->has_functional_control_flow() ||\n         cluster->is_xla_compile_attr_true()) {\n-      string& name = cluster_names[cluster->cycles_graph_node_id()];\n+      std::string& name = cluster_names[cluster->cycles_graph_node_id()];\n \n       if (name.empty()) {\n         if (!cluster_name_prefix_.empty()) {\n@@ -1099,7 +1101,7 @@ MarkForCompilationPassImpl::ClusteringWillIntroduceInterDeviceDependency(\n   return false;\n }\n \n-std::optional<string> MarkForCompilationPassImpl::GetXlaScope(Node* node) {\n+std::optional<std::string> MarkForCompilationPassImpl::GetXlaScope(Node* node) {\n   // Look for either _XlaScope or _XlaInternalScope on both nodes to guide\n   // clustering.  If both nodes have a scope and the scopes do not match, do\n   // not cluster along this edge.  If even one of the nodes lacks a scope\n@@ -1118,14 +1120,14 @@ std::optional<string> MarkForCompilationPassImpl::GetXlaScope(Node* node) {\n \n   if (global_jit_level_ != OptimizerOptions::OFF) {\n     // If global_jit_level_ is ON, respect only _XlaInternalScope.\n-    const string& scope =\n+    const std::string& scope =\n         GetNodeAttrString(node->attrs(), kXlaInternalScopeAttr);\n     if (!scope.empty()) {\n       return scope;\n     }\n   } else {\n     // If global_jit_level_ is OFF, respect only _XlaScope.\n-    const string& scope = GetNodeAttrString(node->attrs(), kXlaScopeAttr);\n+    const std::string& scope = GetNodeAttrString(node->attrs(), kXlaScopeAttr);\n     if (!scope.empty()) {\n       return scope;\n     }\n@@ -1186,9 +1188,9 @@ absl::Status MarkForCompilationPassImpl::BuildInitialClusterSet() {\n           deadness_analysis_->GetPredicateFor(node, Graph::kControlSlot));\n     }\n \n-    const string& device_name_str = !node->assigned_device_name().empty()\n-                                        ? node->assigned_device_name()\n-                                        : node->requested_device();\n+    const std::string& device_name_str = !node->assigned_device_name().empty()\n+                                             ? node->assigned_device_name()\n+                                             : node->requested_device();\n     TF_ASSIGN_OR_RETURN(DeviceId device,\n                         device_info_cache_.GetIdFor(device_name_str));\n \n@@ -1258,16 +1260,17 @@ absl::StatusOr<bool> IsIdentityDrivingConstsInLoop(Node* node) {\n   return true;\n }\n \n-absl::flat_hash_set<string> CreateClusterExcludeList() {\n+absl::flat_hash_set<std::string> CreateClusterExcludeList() {\n   MarkForCompilationPassFlags* flags = GetMarkForCompilationPassFlags();\n-  absl::flat_hash_set<string> excludelist;\n+  absl::flat_hash_set<std::string> excludelist;\n   for (auto s : absl::StrSplit(flags->tf_xla_cluster_exclude_ops, ',')) {\n     if (!s.empty()) {\n-      excludelist.insert(string(s));\n+      excludelist.insert(std::string(s));\n     }\n   }\n   if (VLOG_IS_ON(2) && !excludelist.empty()) {\n-    std::vector<string> vexcludelist(excludelist.begin(), excludelist.end());\n+    std::vector<std::string> vexcludelist(excludelist.begin(),\n+                                          excludelist.end());\n     absl::c_sort(vexcludelist);\n     VLOG(2) << \"XLA clustering will exclude following TF operations from auto \"\n                \"clustering: \"\n@@ -1276,11 +1279,11 @@ absl::flat_hash_set<string> CreateClusterExcludeList() {\n   return excludelist;\n }\n \n-absl::flat_hash_set<string> GetOrCreateAllowlist() {\n-  absl::flat_hash_map<string, std::vector<string>>* allowlist_table =\n+absl::flat_hash_set<std::string> GetOrCreateAllowlist() {\n+  absl::flat_hash_map<std::string, std::vector<std::string>>* allowlist_table =\n       tensorflow::GetAllowlistTable();\n   MarkForCompilationPassFlags* flags = GetMarkForCompilationPassFlags();\n-  absl::flat_hash_set<string> allowlist;\n+  absl::flat_hash_set<std::string> allowlist;\n \n   for (auto s : absl::StrSplit(flags->tf_xla_ops_to_cluster, ',')) {\n     if (s == \"FUSIBLE\") {\n@@ -1292,12 +1295,12 @@ absl::flat_hash_set<string> GetOrCreateAllowlist() {\n       allowlist.insert(v.begin(), v.end());\n     } else if (!s.empty()) {\n       // Should be a user provided TF operation.\n-      allowlist.insert(string(s));\n+      allowlist.insert(std::string(s));\n     }\n   }\n \n   if (VLOG_IS_ON(2) && !allowlist.empty()) {\n-    std::vector<string> vallowlist(allowlist.begin(), allowlist.end());\n+    std::vector<std::string> vallowlist(allowlist.begin(), allowlist.end());\n     absl::c_sort(vallowlist);\n     VLOG(2) << \"XLA clustering will only consider the following TF operations: \"\n             << absl::StrJoin(vallowlist, \" \");\n@@ -1338,8 +1341,8 @@ absl::Status MarkForCompilationPassImpl::FindCompilationCandidates() {\n \n   auto allowlist = GetOrCreateAllowlist();\n \n-  std::vector<string> vall_ops = XlaOpRegistry::GetAllRegisteredOps();\n-  absl::flat_hash_set<string> all_ops(vall_ops.begin(), vall_ops.end());\n+  std::vector<std::string> vall_ops = XlaOpRegistry::GetAllRegisteredOps();\n+  absl::flat_hash_set<std::string> all_ops(vall_ops.begin(), vall_ops.end());\n   // Check that user's provided TF operation really exists.\n   for (const auto& s : allowlist) {\n     if (!all_ops.contains(s)) {\n@@ -1674,7 +1677,7 @@ void MarkForCompilationPassImpl::DumpPostClusteringGraphs() {\n   DumpGraphToFile(\"mark_for_compilation_annotated\", new_graph, flib_def_);\n }\n \n-string RatioToString(int numerator, int denominator) {\n+std::string RatioToString(int numerator, int denominator) {\n   return absl::StrFormat(\"%d / %d (%.2f%%)\", numerator, denominator,\n                          (100.0 * numerator) / denominator);\n }\n@@ -1985,10 +1988,11 @@ absl::Status MarkForCompilationPass::RunForTest(\n   return MarkForCompilation(options, debug_options);\n }\n \n-absl::flat_hash_map<string, std::vector<string>>* GetAllowlistTable() {\n+absl::flat_hash_map<std::string, std::vector<std::string>>*\n+GetAllowlistTable() {\n   // Table format: category name: {list of TF operations in that category}\n-  static absl::flat_hash_map<string, std::vector<string>>* result =\n-      new absl::flat_hash_map<string, std::vector<string>>{\n+  static absl::flat_hash_map<std::string, std::vector<std::string>>* result =\n+      new absl::flat_hash_map<std::string, std::vector<std::string>>{\n           // Unary\n           {\"PW\",\n            {\"ComplexAbs\", \"Angle\", \"Conj\", \"Abs\", \"Acos\", \"Acosh\", \"Asin\",\n@@ -2056,8 +2060,8 @@ void ResetClusterSequenceNumber() {\n   ClusterSequenceNumberGenerator::Global().Reset();\n }\n \n-absl::flat_hash_set<string> GetKnownXLAAllowlistOp() {\n-  absl::flat_hash_set<string> result{\n+absl::flat_hash_set<std::string> GetKnownXLAAllowlistOp() {\n+  absl::flat_hash_set<std::string> result{\n       \"AdjustContrastv2\",\n       \"AdjustHue\",\n       \"AdjustSaturation\","
        },
        {
            "sha": "d6a2814ed339821a7482e62c7a4c464d00a0226b",
            "filename": "tensorflow/compiler/jit/mark_for_compilation_pass.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass.h?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -47,7 +47,7 @@ class MarkForCompilationPass : public GraphOptimizationPass {\n   friend class MarkForCompilationPassTestHelper;\n };\n \n-absl::flat_hash_map<string, std::vector<string>>* GetAllowlistTable();\n+absl::flat_hash_map<std::string, std::vector<std::string>>* GetAllowlistTable();\n \n namespace testing {\n // DO NOT USE IN PRODUCTION.\n@@ -56,7 +56,7 @@ namespace testing {\n void ResetClusterSequenceNumber();\n \n // Return a list of operation that we choose not to put into the allowlist.\n-absl::flat_hash_set<string> GetKnownXLAAllowlistOp();\n+absl::flat_hash_set<std::string> GetKnownXLAAllowlistOp();\n }  // namespace testing\n }  // namespace tensorflow\n "
        },
        {
            "sha": "1d4031a4ffc926f5dd2c5f433e065f24986d1404",
            "filename": "tensorflow/compiler/jit/mark_for_compilation_pass_test.cc",
            "status": "modified",
            "additions": 80,
            "deletions": 80,
            "changes": 160,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fmark_for_compilation_pass_test.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -67,10 +67,10 @@ static bool Initialized = [] {\n REGISTER_OP(\"UncompilableNullary\").Output(\"o: float\");\n REGISTER_OP(\"UncompilableUnary\").Input(\"a: float\").Output(\"o: float\");\n \n-std::unordered_map<string, string> GetClusters(const Graph& graph) {\n-  std::unordered_map<string, string> ids;\n+std::unordered_map<std::string, std::string> GetClusters(const Graph& graph) {\n+  std::unordered_map<std::string, std::string> ids;\n   for (Node* node : graph.nodes()) {\n-    string cluster;\n+    std::string cluster;\n     if (TryGetNodeAttr(node->attrs(), kXlaClusterAttr, &cluster)) {\n       CHECK(!cluster.empty());\n       ids[node->name()] = cluster;\n@@ -86,10 +86,10 @@ std::unordered_map<string, string> GetClusters(const Graph& graph) {\n   return ids;\n }\n \n-std::set<string> GetClusterNames(const Graph& graph) {\n-  std::set<string> names;\n+std::set<std::string> GetClusterNames(const Graph& graph) {\n+  std::set<std::string> names;\n   for (Node* node : graph.nodes()) {\n-    string cluster;\n+    std::string cluster;\n     if (TryGetNodeAttr(node->attrs(), kXlaClusterAttr, &cluster)) {\n       CHECK(!cluster.empty());\n       names.insert(cluster);\n@@ -98,10 +98,10 @@ std::set<string> GetClusterNames(const Graph& graph) {\n   return names;\n }\n \n-absl::flat_hash_map<string, std::vector<string>> GetClusterSets(\n-    const Graph& g, std::vector<string>* cluster_names = nullptr) {\n+absl::flat_hash_map<std::string, std::vector<std::string>> GetClusterSets(\n+    const Graph& g, std::vector<std::string>* cluster_names = nullptr) {\n   CHECK(cluster_names == nullptr || cluster_names->empty());\n-  absl::flat_hash_map<string, std::vector<string>> cluster_sets;\n+  absl::flat_hash_map<std::string, std::vector<std::string>> cluster_sets;\n   for (const auto& p : GetClusters(g)) {\n     cluster_sets[p.second].push_back(p.first);\n   }\n@@ -357,7 +357,7 @@ TEST(XlaCompilationTest, CallXlaDeviceFuncWithResourceOp) {\n     TF_EXPECT_OK(GraphDefBuilderToGraph(builder, graph.get()));\n   }\n \n-  string xla_cpu_device = \"/job:worker/replica:0/task:0/device:XLA_CPU:0\";\n+  std::string xla_cpu_device = \"/job:worker/replica:0/task:0/device:XLA_CPU:0\";\n   testing::FindNodeByName(graph.get(), \"A\")\n       ->set_assigned_device_name(xla_cpu_device);\n   testing::FindNodeByName(graph.get(), \"tanh0\")\n@@ -694,7 +694,7 @@ TEST(XlaCompilationTest, ClusterNodesWithMismatchingInputDeadness) {\n }\n \n namespace {\n-Node* MakeRead(const Scope& scope, const string& id,\n+Node* MakeRead(const Scope& scope, const std::string& id,\n                Node** var_handle_op = nullptr) {\n   Output var_handle =\n       ops::VarHandleOp(scope.WithOpName(\"Var\" + id), DT_FLOAT, TensorShape({}));\n@@ -706,7 +706,7 @@ Node* MakeRead(const Scope& scope, const string& id,\n   return read.node();\n }\n \n-Node* MakeWrite(const Scope& scope, const string& id) {\n+Node* MakeWrite(const Scope& scope, const std::string& id) {\n   Output var_handle =\n       ops::VarHandleOp(scope.WithOpName(\"Var\" + id), DT_FLOAT, TensorShape({}));\n   Output value_to_write =\n@@ -716,7 +716,7 @@ Node* MakeWrite(const Scope& scope, const string& id) {\n   return assign_op.operation.node();\n }\n \n-Node* MakeNeutral(const Scope& scope, const string& id) {\n+Node* MakeNeutral(const Scope& scope, const std::string& id) {\n   return ops::Const(scope.WithOpName(\"Const\" + id), 42.0f).node();\n }\n }  // namespace\n@@ -733,11 +733,11 @@ TEST(XlaCompilationTest, ResourcesClusteringAllowed) {\n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   TF_EXPECT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n-  absl::flat_hash_map<string, std::vector<string>> cluster_sets =\n+  absl::flat_hash_map<std::string, std::vector<std::string>> cluster_sets =\n       GetClusterSets(*graph);\n   ASSERT_EQ(cluster_sets.size(), 1);\n-  std::vector<string> expected_clustered_nodes = {\"AssignmentW\", \"ReadR\",\n-                                                  \"ValueToAssignW\"};\n+  std::vector<std::string> expected_clustered_nodes = {\"AssignmentW\", \"ReadR\",\n+                                                       \"ValueToAssignW\"};\n   ASSERT_EQ(cluster_sets.begin()->second, expected_clustered_nodes);\n }\n \n@@ -753,7 +753,7 @@ TEST(XlaCompilationTest, ResourcesClusteringDisallowed) {\n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   TF_EXPECT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n-  absl::flat_hash_map<string, std::vector<string>> cluster_sets =\n+  absl::flat_hash_map<std::string, std::vector<std::string>> cluster_sets =\n       GetClusterSets(*graph);\n   ASSERT_EQ(cluster_sets.size(), 0);\n }\n@@ -779,13 +779,13 @@ TEST(XlaCompilationTest, ChainOfOps) {\n   TF_EXPECT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::vector<string> cluster_names;\n-  absl::flat_hash_map<string, std::vector<string>> cluster_sets =\n+  std::vector<std::string> cluster_names;\n+  absl::flat_hash_map<std::string, std::vector<std::string>> cluster_sets =\n       GetClusterSets(*graph, &cluster_names);\n \n   ASSERT_EQ(cluster_sets.size(), 1);\n \n-  std::vector<string> expected_clustered_nodes_a = {\n+  std::vector<std::string> expected_clustered_nodes_a = {\n       \"AssignmentW1\", \"ConstN0\", \"ReadR0\", \"ValueToAssignW1\"};\n   ASSERT_EQ(cluster_sets[cluster_names[0]], expected_clustered_nodes_a);\n }\n@@ -881,7 +881,7 @@ TEST(XlaCompilationTest, ConstOp) {\n   {\n     std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n     Scope root = Scope::NewRootScope().ExitOnError();\n-    auto c = ops::Const(root.WithOpName(\"const\"), string(\"string\"));\n+    auto c = ops::Const(root.WithOpName(\"const\"), std::string(\"string\"));\n     c.node()->AddAttr(kXlaCompileAttr, true);\n     TF_ASSERT_OK(root.ToGraph(graph.get()));\n     TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n@@ -901,12 +901,12 @@ TEST(XlaCompilationTest, DontClusterIdentityWithRefInput) {\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   ASSERT_FALSE(clusters.empty());\n-  string cluster_name = clusters.begin()->second;\n+  std::string cluster_name = clusters.begin()->second;\n \n-  std::unordered_map<string, string> expected_clusters(\n+  std::unordered_map<std::string, std::string> expected_clusters(\n       {{\"negate\", cluster_name}, {\"add\", cluster_name}});\n   EXPECT_EQ(clusters, expected_clusters);\n }\n@@ -924,12 +924,12 @@ TEST(XlaCompilationTest, ClusterIdentityWithNonRefInput) {\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   ASSERT_FALSE(clusters.empty());\n-  string cluster_name = clusters.begin()->second;\n+  std::string cluster_name = clusters.begin()->second;\n \n-  std::unordered_map<string, string> expected_clusters(\n+  std::unordered_map<std::string, std::string> expected_clusters(\n       {{\"negate\", cluster_name},\n        {\"identity\", cluster_name},\n        {\"add\", cluster_name}});\n@@ -956,7 +956,7 @@ TEST(XlaCompilationTest, ClusterControlTrigger) {\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   // TODO(b/118970344): ctrl_trigger_a has inputs with mismatching deadness so\n   // it won't be clustered.  ctrl_trigger_b is okay to cluster but we don't\n@@ -982,7 +982,7 @@ TEST(XlaCompilationTest, RandomShape) {\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"shape\"], \"\");\n }\n \n@@ -1028,7 +1028,7 @@ TEST(XlaCompilationTest, RandomShapeWithFunc) {\n   TF_ASSERT_OK(\n       MarkForCompilationPassTestHelper::MarkForCompilation(&graph, fld.get()));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"fn_call\"], \"\");\n }\n \n@@ -1054,12 +1054,12 @@ TEST(XlaCompilationTest, RandomShapeOnXlaDevice) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::StartsWith(n->name(), /*prefix=*/\"test/\")) {\n-      n->set_assigned_device_name(string(xla_gpu_device));\n+      n->set_assigned_device_name(std::string(xla_gpu_device));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"test/shape_rng\"], \"\");\n   EXPECT_EQ(clusters[\"test/reshape\"], \"\");\n }\n@@ -1087,12 +1087,12 @@ TEST(XlaCompilationTest, TensorArrayShapeOnXlaDevice) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::StartsWith(n->name(), /*prefix=*/\"test/\")) {\n-      n->set_assigned_device_name(string(xla_gpu_device));\n+      n->set_assigned_device_name(std::string(xla_gpu_device));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"test/read\"], \"\");\n   EXPECT_EQ(clusters[\"test/read\"], clusters[\"test/reshape\"]);\n }\n@@ -1133,15 +1133,15 @@ TEST(XlaCompilationTest, DontClusterMergingNodes) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::EndsWith(n->name(), /*suffix=*/\"dev0\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev0));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev0));\n     } else if (absl::EndsWith(n->name(), /*suffix=*/\"dev1\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev1));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev1));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n   // Each of the MatMuls should be in a separate cluster.\n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"MatMul0_dev0\"], clusters[\"MatMul1_dev1\"]);\n   EXPECT_NE(clusters[\"MatMulCombined_dev1\"], clusters[\"MatMul0_dev0\"]);\n   EXPECT_NE(clusters[\"MatMulCombined_dev1\"], clusters[\"MatMul1_dev1\"]);\n@@ -1170,17 +1170,17 @@ TEST(XlaCompilationTest, DontClusterMergingNodesOnCPU) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::EndsWith(n->name(), /*suffix=*/\"cpu\")) {\n-      n->set_assigned_device_name(string(xla_cpu_dev0));\n+      n->set_assigned_device_name(std::string(xla_cpu_dev0));\n     } else if (absl::EndsWith(n->name(), /*suffix=*/\"dev0\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev0));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev0));\n     } else if (absl::EndsWith(n->name(), /*suffix=*/\"dev1\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev1));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev1));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n   // Each of the MatMuls should be in a separate cluster.\n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"MatMul0_dev0\"], clusters[\"MatMul1_dev1\"]);\n   EXPECT_NE(clusters[\"MatMulCombined_cpu\"], clusters[\"MatMul0_dev0\"]);\n   EXPECT_NE(clusters[\"MatMulCombined_cpu\"], clusters[\"MatMul1_dev1\"]);\n@@ -1223,14 +1223,14 @@ TEST(XlaCompilationTest, NOT_DontClusterSpreadingNodes) {\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n   for (Node* n : graph->nodes()) {\n     if (absl::EndsWith(n->name(), /*suffix=*/\"dev0\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev0));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev0));\n     } else if (absl::EndsWith(n->name(), /*suffix=*/\"dev1\")) {\n-      n->set_assigned_device_name(string(xla_gpu_dev1));\n+      n->set_assigned_device_name(std::string(xla_gpu_dev1));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"A_dev0\"], clusters[\"MatMulSource_dev0\"]);\n   EXPECT_NE(clusters[\"MatMul0_dev0\"], clusters[\"MatMul1_dev1\"]);\n   EXPECT_NE(clusters[\"MatMulSource_dev0\"], clusters[\"MatMul1_dev1\"]);\n@@ -1254,12 +1254,12 @@ TEST(XlaCompilationTest, ClusterStatefulRandomOpOnXlaDevice) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::StartsWith(n->name(), /*prefix=*/\"test/\")) {\n-      n->set_assigned_device_name(string(xla_cpu_device));\n+      n->set_assigned_device_name(std::string(xla_cpu_device));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"test/a\"], \"\");\n   EXPECT_NE(clusters[\"test/b\"], \"\");\n   EXPECT_NE(clusters[\"test/c\"], \"\");\n@@ -1277,7 +1277,7 @@ TEST(XlaCompilationTest, DontAutoClusterStatefulRandomOp) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"test/a\"], \"\");\n   EXPECT_EQ(clusters[\"test/b\"], \"\");\n }\n@@ -1299,12 +1299,12 @@ TEST(XlaCompilationTest, ClusterDummyOpsOnXlaDevice) {\n \n   for (Node* n : graph->nodes()) {\n     if (absl::StartsWith(n->name(), /*prefix=*/\"test/\")) {\n-      n->set_assigned_device_name(string(xla_cpu_device));\n+      n->set_assigned_device_name(std::string(xla_cpu_device));\n     }\n   }\n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"test/check\"], \"\");\n   EXPECT_NE(clusters[\"test/greaterequal\"], \"\");\n   EXPECT_NE(clusters[\"test/assert\"], \"\");\n@@ -1324,7 +1324,7 @@ TEST(XlaCompilationTest, DontAutoClusterDummyOps) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"test/assert\"], \"\");\n   EXPECT_EQ(clusters[\"test/check\"], \"\");\n }\n@@ -1345,7 +1345,7 @@ TEST(XlaCompilationTest, DontAutoClusterOpsProducingVariant) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"test/tensor_list_reserve\"], \"\");\n }\n \n@@ -1373,7 +1373,7 @@ TEST(XlaCompilationTest, DontAutoClusterOpsConsumingVariant) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_EQ(clusters[\"test/tensor_list_element_shape\"], \"\");\n }\n \n@@ -1391,7 +1391,7 @@ TEST(XlaCompilationTest, ClusterOpsProducingVariantIfOnXlaDevice) {\n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n \n-  string xla_cpu_device = \"/job:worker/replica:0/task:0/device:XLA_CPU:0\";\n+  std::string xla_cpu_device = \"/job:worker/replica:0/task:0/device:XLA_CPU:0\";\n   for (Node* n : graph->nodes()) {\n     if (absl::StartsWith(n->name(), /*prefix=*/\"test/\")) {\n       n->set_assigned_device_name(xla_cpu_device);\n@@ -1400,7 +1400,7 @@ TEST(XlaCompilationTest, ClusterOpsProducingVariantIfOnXlaDevice) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n   EXPECT_NE(clusters[\"test/tensor_list_reserve\"], \"\");\n }\n \n@@ -1427,7 +1427,7 @@ TEST(XlaCompilationTest, CreateCombinedCpuGpuClusters) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_NE(clusters[\"test/x\"], \"\");\n \n@@ -1451,7 +1451,7 @@ TEST(XlaCompilationTest, DontCreateGpu0AndGpu1Clusters) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_EQ(clusters[\"test/x\"], \"\");\n   EXPECT_EQ(clusters[\"test/y\"], \"\");\n@@ -1473,7 +1473,7 @@ TEST(XlaCompilationTest, DontCreateCombinedCpuUnknownClusters) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_EQ(clusters[\"test/x\"], \"\");\n   EXPECT_EQ(clusters[\"test/y\"], \"\");\n@@ -1486,8 +1486,8 @@ TEST(XlaCompilationTest, ClusterResourceOpsWhenSafe) {\n   Node* resource_read = MakeRead(root, \"read\", &var_handle);\n   Output b = ops::Add(root.WithOpName(\"test/b\"), Output(resource_read, 0), a);\n \n-  string resource_read_name = resource_read->name();\n-  string var_handle_name = var_handle->name();\n+  std::string resource_read_name = resource_read->name();\n+  std::string var_handle_name = var_handle->name();\n \n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n@@ -1499,7 +1499,7 @@ TEST(XlaCompilationTest, ClusterResourceOpsWhenSafe) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_NE(clusters[\"test/b\"], \"\");\n   EXPECT_EQ(clusters[\"test/b\"], clusters[resource_read_name]);\n@@ -1512,8 +1512,8 @@ TEST(XlaCompilationTest, DontClusterResourceOpsWhenUnsafe) {\n   Node* resource_read = MakeRead(root, \"read\", &var_handle);\n   Output b = ops::Add(root.WithOpName(\"test/b\"), Output(resource_read, 0), a);\n \n-  string resource_read_name = resource_read->name();\n-  string var_handle_name = var_handle->name();\n+  std::string resource_read_name = resource_read->name();\n+  std::string var_handle_name = var_handle->name();\n \n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   TF_ASSERT_OK(root.ToGraph(graph.get()));\n@@ -1525,7 +1525,7 @@ TEST(XlaCompilationTest, DontClusterResourceOpsWhenUnsafe) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_EQ(clusters[\"test/b\"], \"\");\n   EXPECT_EQ(clusters[resource_read_name], \"\");\n@@ -1555,7 +1555,7 @@ TEST(XlaCompilationTest, DontClusterNodesWithScopedAllocatorAttr) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_EQ(clusters[\"test/z\"], \"\");\n }\n@@ -1580,7 +1580,7 @@ TEST(XlaCompilationTest, DontClusterNodesWithForwardFromAttr) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_EQ(clusters[\"test/z\"], \"\");\n }\n@@ -1610,7 +1610,7 @@ TEST(XlaCompilationTest, ClusterShapeConsumerWithProducer) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_NE(clusters[\"test/y\"], \"\");\n   EXPECT_EQ(clusters[\"test/x\"], clusters[\"test/y\"]);\n@@ -1632,7 +1632,7 @@ TEST(XlaCompilationTest, ClusterShapeConsumerWithProducerAndConsumer) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_NE(clusters[\"test/y\"], \"\");\n   EXPECT_EQ(clusters[\"test/y\"], clusters[\"test/x\"]);\n@@ -1705,7 +1705,7 @@ TEST(XlaCompilationTest, IterationIncrementAndGroupDeps) {\n \n   TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   EXPECT_NE(clusters[\"some_ctrl_input\"], \"\");\n   EXPECT_EQ(clusters[\"some_ctrl_input\"], clusters[\"weights_0_update\"]);\n@@ -1875,19 +1875,19 @@ TEST(XlaCompilationTest, ClusterSessionName) {\n   TF_ASSERT_OK(\n       MarkForCompilationPassTestHelper::MarkForCompilation(&graph, options));\n \n-  std::unordered_map<string, string> clusters = GetClusters(*graph);\n+  std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n \n   ASSERT_FALSE(clusters.empty());\n-  string cluster_name = clusters.begin()->second;\n+  std::string cluster_name = clusters.begin()->second;\n \n-  std::unordered_map<string, string> expected_clusters(\n+  std::unordered_map<std::string, std::string> expected_clusters(\n       {{\"negate\", cluster_name}, {\"add\", cluster_name}});\n   EXPECT_EQ(clusters, expected_clusters);\n   EXPECT_THAT(cluster_name, ::testing::StartsWith(\"test_session_name\"));\n }\n \n namespace {\n-Node* MakeStageNode(GraphDefBuilder& builder, string name,\n+Node* MakeStageNode(GraphDefBuilder& builder, std::string name,\n                     std::initializer_list<DataType> dtypes,\n                     absl::Span<const ops::NodeOut> values) {\n   auto opts = builder.opts()\n@@ -1949,7 +1949,7 @@ TEST(XlaCompilationTest, StagePipelinePreservedByClusterScopingPass) {\n         &graph,\n         MarkForCompilationPassTestHelper::Options().WithNoClusterScoping()));\n \n-    std::unordered_map<string, string> clusters = GetClusters(*graph);\n+    std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n     EXPECT_EQ(clusters[\"add0\"], clusters[\"add1\"]);\n     EXPECT_EQ(clusters[\"add0\"], clusters[\"relu1\"]);\n     EXPECT_EQ(clusters[\"relu0\"], clusters[\"add1\"]);\n@@ -1964,7 +1964,7 @@ TEST(XlaCompilationTest, StagePipelinePreservedByClusterScopingPass) {\n \n     TF_ASSERT_OK(MarkForCompilationPassTestHelper::MarkForCompilation(&graph));\n \n-    std::unordered_map<string, string> clusters = GetClusters(*graph);\n+    std::unordered_map<std::string, std::string> clusters = GetClusters(*graph);\n     EXPECT_NE(clusters[\"add0\"], clusters[\"add1\"]);\n     EXPECT_NE(clusters[\"add0\"], clusters[\"relu1\"]);\n     EXPECT_NE(clusters[\"relu0\"], clusters[\"add1\"]);\n@@ -1973,9 +1973,9 @@ TEST(XlaCompilationTest, StagePipelinePreservedByClusterScopingPass) {\n }\n TEST(XlaCompilationTest, XLALiteAllowlist) {\n   auto* allowlist_table = tensorflow::GetAllowlistTable();\n-  absl::flat_hash_set<string> hallowlist;\n-  std::vector<string> vall_ops = XlaOpRegistry::GetAllRegisteredOps();\n-  absl::flat_hash_set<string> all_ops(vall_ops.begin(), vall_ops.end());\n+  absl::flat_hash_set<std::string> hallowlist;\n+  std::vector<std::string> vall_ops = XlaOpRegistry::GetAllRegisteredOps();\n+  absl::flat_hash_set<std::string> all_ops(vall_ops.begin(), vall_ops.end());\n \n   // Check that all the operations in the table are existing TF operations\n   for (auto pair : *allowlist_table) {\n@@ -1988,10 +1988,10 @@ TEST(XlaCompilationTest, XLALiteAllowlist) {\n   // Check that all registered XLA operation are in the allowlist\n   // table or are known to not be in it.\n \n-  absl::flat_hash_set<string> known_not_in_list =\n+  absl::flat_hash_set<std::string> known_not_in_list =\n       tensorflow::testing::GetKnownXLAAllowlistOp();\n-  std::vector<string> unknow_op;\n-  for (string op : vall_ops) {\n+  std::vector<std::string> unknow_op;\n+  for (std::string op : vall_ops) {\n     if (!hallowlist.contains(op) && !known_not_in_list.contains(op)) {\n       unknow_op.push_back(op);\n     }"
        },
        {
            "sha": "db158fc84a0173c5e069934374cd0289a63af0b7",
            "filename": "tensorflow/compiler/jit/node_matchers.cc",
            "status": "modified",
            "additions": 32,
            "deletions": 30,
            "changes": 62,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -35,7 +35,7 @@ namespace {\n using impl::NodeMatcherProperties;\n using impl::OutEdge;\n \n-string IndentAllButFirstLine(absl::string_view text) {\n+std::string IndentAllButFirstLine(absl::string_view text) {\n   std::vector<std::string> lines = absl::StrSplit(text, '\\n');\n   for (int i = 1; i < lines.size(); i++) {\n     lines[i].insert(0, \"  \");\n@@ -86,21 +86,21 @@ bool MatchAndExplainTensor(const Tensor& tensor, const Tensor& expected_tensor,\n     case DT_DOUBLE:\n       return CompareTensor<double>(tensor, expected_tensor, listener);\n     case DT_INT8:\n-      return CompareTensor<int8>(tensor, expected_tensor, listener);\n+      return CompareTensor<int8_t>(tensor, expected_tensor, listener);\n     case DT_INT16:\n-      return CompareTensor<int16>(tensor, expected_tensor, listener);\n+      return CompareTensor<int16_t>(tensor, expected_tensor, listener);\n     case DT_INT32:\n-      return CompareTensor<int32>(tensor, expected_tensor, listener);\n+      return CompareTensor<int32_t>(tensor, expected_tensor, listener);\n     case DT_INT64:\n       return CompareTensor<int64_t>(tensor, expected_tensor, listener);\n     case DT_UINT8:\n-      return CompareTensor<uint8>(tensor, expected_tensor, listener);\n+      return CompareTensor<uint8_t>(tensor, expected_tensor, listener);\n     case DT_UINT16:\n-      return CompareTensor<uint16>(tensor, expected_tensor, listener);\n+      return CompareTensor<uint16_t>(tensor, expected_tensor, listener);\n     case DT_UINT32:\n-      return CompareTensor<uint32>(tensor, expected_tensor, listener);\n+      return CompareTensor<uint32_t>(tensor, expected_tensor, listener);\n     case DT_UINT64:\n-      return CompareTensor<uint64>(tensor, expected_tensor, listener);\n+      return CompareTensor<uint64_t>(tensor, expected_tensor, listener);\n     default:\n       LOG(FATAL) << \"Unsupported dtype \"  // Crash ok: testonly.\n                  << DataType_Name(tensor.dtype());\n@@ -188,7 +188,7 @@ struct NodeMatcher : public ::testing::MatcherInterface<const Node*> {\n     if (control_dep_set &&\n         !control_dep_set->MatchAndExplain(control_deps, &inner_listener)) {\n       if (listener->IsInterested()) {\n-        string explanation = inner_listener.str();\n+        std::string explanation = inner_listener.str();\n         if (!explanation.empty()) {\n           explanation = absl::StrCat(\", \", explanation, \",\");\n         }\n@@ -225,7 +225,7 @@ struct NodeMatcher : public ::testing::MatcherInterface<const Node*> {\n   }\n \n   void DescribeTo(::std::ostream* os) const override {\n-    std::vector<string> predicates;\n+    std::vector<std::string> predicates;\n \n     if (name) {\n       predicates.push_back(absl::StrCat(\"name: \", *name));\n@@ -282,10 +282,11 @@ struct NodeMatcher : public ::testing::MatcherInterface<const Node*> {\n \n     if (!attrs.empty()) {\n       printed_something = true;\n-      std::vector<string> attrs_str;\n+      std::vector<std::string> attrs_str;\n       absl::c_transform(\n           attrs, std::back_inserter(attrs_str),\n-          [](const std::pair<string, std::optional<AttrValue>>& attr_kv_pair) {\n+          [](const std::pair<std::string, std::optional<AttrValue>>&\n+                 attr_kv_pair) {\n             return absl::StrCat(attr_kv_pair.first, \"->\",\n                                 attr_kv_pair.second\n                                     ? SummarizeAttrValue(*attr_kv_pair.second)\n@@ -319,22 +320,22 @@ struct NodeMatcher : public ::testing::MatcherInterface<const Node*> {\n     if (listener->IsInterested()) {\n       *listener << \"\\ninput \" << input_idx << \" does not match expected:\\n\";\n       (*input_matchers)[input_idx].DescribeTo(listener->stream());\n-      string explanation = inner_listener.str();\n+      std::string explanation = inner_listener.str();\n       if (!explanation.empty()) {\n         *listener << \", \" << explanation;\n       }\n     }\n     return false;\n   }\n \n-  std::optional<string> op;\n-  std::optional<string> name;\n-  std::optional<string> assigned_device;\n+  std::optional<std::string> op;\n+  std::optional<std::string> name;\n+  std::optional<std::string> assigned_device;\n   std::optional<Tensor> constant_value;\n   std::optional<std::vector<::testing::Matcher<OutEdge>>> input_matchers;\n   std::optional<::testing::Matcher<absl::Span<const Node* const>>>\n       control_dep_set;\n-  std::map<string, std::optional<AttrValue>> attrs;\n+  std::map<std::string, std::optional<AttrValue>> attrs;\n };\n \n // Matches a dst and dst_output on an input edge.  Today we only use this with\n@@ -352,7 +353,7 @@ class OutEdgeMatcher : public ::testing::MatcherInterface<OutEdge> {\n       if (listener->IsInterested()) {\n         *listener << \"\\nsource does not match expected \";\n         src_matcher_.DescribeTo(listener->stream());\n-        string explanation = inner_listener.str();\n+        std::string explanation = inner_listener.str();\n         if (!explanation.empty()) {\n           *listener << \"\\n\\t\" << explanation;\n         }\n@@ -432,21 +433,21 @@ ::testing::Matcher<const Node*> impl::NodeWith(\n   return ::testing::MakeMatcher(matcher);\n }\n \n-impl::NodeMatcherProperties Name(string name) {\n+impl::NodeMatcherProperties Name(std::string name) {\n   impl::NodeMatcherProperties props;\n   props.set_name(std::move(name));\n   return props;\n }\n \n // Matches a node with op `op`.\n-impl::NodeMatcherProperties Op(string op) {\n+impl::NodeMatcherProperties Op(std::string op) {\n   impl::NodeMatcherProperties props;\n   props.set_op(std::move(op));\n   return props;\n }\n \n // Matches a node with assigned device `assigned_device`.\n-impl::NodeMatcherProperties AssignedDevice(string assigned_device) {\n+impl::NodeMatcherProperties AssignedDevice(std::string assigned_device) {\n   impl::NodeMatcherProperties props;\n   props.set_assigned_device(std::move(assigned_device));\n   return props;\n@@ -472,15 +473,15 @@ impl::NodeMatcherProperties impl::CtrlDeps(\n   return props;\n }\n \n-std::pair<string, AttrValue> impl::AttrLiteralHelper(\n-    const std::pair<string, bool>& bool_attr) {\n+std::pair<std::string, AttrValue> impl::AttrLiteralHelper(\n+    const std::pair<std::string, bool>& bool_attr) {\n   AttrValue attr_value;\n   attr_value.set_b(bool_attr.second);\n   return {bool_attr.first, attr_value};\n }\n \n-std::pair<string, AttrValue> impl::AttrLiteralHelper(\n-    const std::pair<string, absl::Span<const int>>& int_list_attr) {\n+std::pair<std::string, AttrValue> impl::AttrLiteralHelper(\n+    const std::pair<std::string, absl::Span<const int>>& int_list_attr) {\n   AttrValue attr_value;\n   AttrValue::ListValue* list = attr_value.mutable_list();\n   for (int i : int_list_attr.second) {\n@@ -489,23 +490,24 @@ std::pair<string, AttrValue> impl::AttrLiteralHelper(\n   return {int_list_attr.first, attr_value};\n }\n \n-std::pair<string, AttrValue> impl::AttrLiteralHelper(\n-    const std::pair<string, absl::Span<const string>>& string_list_attr) {\n+std::pair<std::string, AttrValue> impl::AttrLiteralHelper(\n+    const std::pair<std::string, absl::Span<const std::string>>&\n+        string_list_attr) {\n   AttrValue attr_value;\n   AttrValue::ListValue* list = attr_value.mutable_list();\n-  for (const string& s : string_list_attr.second) {\n+  for (const std::string& s : string_list_attr.second) {\n     list->add_s(s);\n   }\n   return {string_list_attr.first, attr_value};\n }\n \n-impl::NodeMatcherProperties impl::Attr(std::pair<string, AttrValue> attr) {\n+impl::NodeMatcherProperties impl::Attr(std::pair<std::string, AttrValue> attr) {\n   impl::NodeMatcherProperties props;\n   props.set_attr(std::move(attr));\n   return props;\n }\n \n-impl::NodeMatcherProperties impl::Attr(string name) {\n+impl::NodeMatcherProperties impl::Attr(std::string name) {\n   impl::NodeMatcherProperties props;\n   props.set_attr({std::move(name), std::nullopt});\n   return props;"
        },
        {
            "sha": "1391df3743bd4c6a96fbe77b0a7ea1573ec17cdc",
            "filename": "tensorflow/compiler/jit/node_matchers.h",
            "status": "modified",
            "additions": 24,
            "deletions": 23,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers.h?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -84,11 +84,11 @@ class NodeMatcherProperties {\n  public:\n   using NodeSeqMatcher = std::vector<::testing::Matcher<const Node*>>;\n   using InputSeqMatcher = std::vector<::testing::Matcher<OutEdge>>;\n-  using AttrKeyValuePair = std::pair<string, std::optional<AttrValue>>;\n+  using AttrKeyValuePair = std::pair<std::string, std::optional<AttrValue>>;\n \n-  const std::optional<string>& name() const { return name_; }\n-  const std::optional<string>& op() const { return op_; }\n-  const std::optional<string>& assigned_device() const {\n+  const std::optional<std::string>& name() const { return name_; }\n+  const std::optional<std::string>& op() const { return op_; }\n+  const std::optional<std::string>& assigned_device() const {\n     return assigned_device_;\n   }\n   const std::optional<Tensor>& constant_value() const {\n@@ -102,17 +102,17 @@ class NodeMatcherProperties {\n   }\n   const std::optional<AttrKeyValuePair>& attr() const { return attr_; }\n \n-  void set_name(string name) {\n+  void set_name(std::string name) {\n     DCHECK(IsEmpty());\n     name_ = std::move(name);\n   }\n \n-  void set_op(string op) {\n+  void set_op(std::string op) {\n     DCHECK(IsEmpty());\n     op_ = std::move(op);\n   }\n \n-  void set_assigned_device(string assigned_device) {\n+  void set_assigned_device(std::string assigned_device) {\n     DCHECK(IsEmpty());\n     assigned_device_ = std::move(assigned_device);\n   }\n@@ -144,9 +144,9 @@ class NodeMatcherProperties {\n   }\n \n  private:\n-  std::optional<string> name_;\n-  std::optional<string> op_;\n-  std::optional<string> assigned_device_;\n+  std::optional<std::string> name_;\n+  std::optional<std::string> op_;\n+  std::optional<std::string> assigned_device_;\n   std::optional<Tensor> constant_value_;\n   std::optional<InputSeqMatcher> input_matchers_;\n   std::optional<NodeSeqMatcher> control_deps_;\n@@ -162,39 +162,40 @@ impl::NodeMatcherProperties Inputs(\n impl::NodeMatcherProperties CtrlDeps(\n     absl::Span<const ::testing::Matcher<const Node*>> control_deps);\n \n-impl::NodeMatcherProperties Attr(std::pair<string, AttrValue> attrs);\n-impl::NodeMatcherProperties Attr(string name);\n+impl::NodeMatcherProperties Attr(std::pair<std::string, AttrValue> attrs);\n+impl::NodeMatcherProperties Attr(std::string name);\n \n-std::pair<string, AttrValue> AttrLiteralHelper(\n-    const std::pair<string, bool>& bool_attr);\n+std::pair<std::string, AttrValue> AttrLiteralHelper(\n+    const std::pair<std::string, bool>& bool_attr);\n \n-std::pair<string, AttrValue> AttrLiteralHelper(\n-    const std::pair<string, absl::Span<const int>>& int_list_attr);\n+std::pair<std::string, AttrValue> AttrLiteralHelper(\n+    const std::pair<std::string, absl::Span<const int>>& int_list_attr);\n \n-std::pair<string, AttrValue> AttrLiteralHelper(\n-    const std::pair<string, absl::Span<const string>>& string_list_attr);\n+std::pair<std::string, AttrValue> AttrLiteralHelper(\n+    const std::pair<std::string, absl::Span<const std::string>>&\n+        string_list_attr);\n }  // namespace impl\n \n // -----------------------------------------------------------------------------\n // Public interface.\n \n // Matches a node with name `name`.\n-impl::NodeMatcherProperties Name(string name);\n+impl::NodeMatcherProperties Name(std::string name);\n \n // Matches a node with op `op`.\n-impl::NodeMatcherProperties Op(string op);\n+impl::NodeMatcherProperties Op(std::string op);\n \n // Matches a node with assigned device `assigned_device`.\n-impl::NodeMatcherProperties AssignedDevice(string assigned_device);\n+impl::NodeMatcherProperties AssignedDevice(std::string assigned_device);\n \n // Matches a node with a boolean typed attribute named `name` and with value\n // `value`.\n template <typename ValueTy>\n-impl::NodeMatcherProperties Attr(const string& name, ValueTy value) {\n+impl::NodeMatcherProperties Attr(const std::string& name, ValueTy value) {\n   return impl::Attr({impl::AttrLiteralHelper({name, value})});\n }\n \n-inline impl::NodeMatcherProperties Attr(const string& name) {\n+inline impl::NodeMatcherProperties Attr(const std::string& name) {\n   return impl::Attr(name);\n }\n "
        },
        {
            "sha": "ac1d9ce3468df10917044d5270f7fe3096fa16a0",
            "filename": "tensorflow/compiler/jit/node_matchers_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fnode_matchers_test.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -41,7 +41,7 @@ using testing::matchers::Op;\n using testing::matchers::Out;\n \n template <typename M, typename T>\n-string Explain(const T& t, const M& m) {\n+std::string Explain(const T& t, const M& m) {\n   ::testing::StringMatchResultListener listener;\n   EXPECT_THAT(t, ::testing::Not(m));  // For the error message.\n   EXPECT_FALSE(m.MatchAndExplain(t, &listener));"
        },
        {
            "sha": "9539a14d060f4280ca664eca95b13e18f3ff9773",
            "filename": "tensorflow/compiler/jit/partially_decluster_pass_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fpartially_decluster_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fpartially_decluster_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fpartially_decluster_pass_test.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -100,7 +100,7 @@ absl::Status PartiallyDecluster(std::unique_ptr<Graph>* graph) {\n   return pass.Run(opt_options);\n }\n \n-Node* FindNodeByName(const Graph& graph, const string& name) {\n+Node* FindNodeByName(const Graph& graph, const std::string& name) {\n   for (Node* node : graph.nodes()) {\n     if (node->name() == name) {\n       return node;\n@@ -109,7 +109,7 @@ Node* FindNodeByName(const Graph& graph, const string& name) {\n   return nullptr;\n }\n \n-bool GetInputsForNode(const Graph& graph, const string& node_name,\n+bool GetInputsForNode(const Graph& graph, const std::string& node_name,\n                       std::vector<Node*>* inputs) {\n   const Node* node = FindNodeByName(graph, node_name);\n   if (node == nullptr) {\n@@ -292,7 +292,7 @@ TEST(PartiallyDeclusterPassTest, DeclusterDependentNodes) {\n void AddToCluster(absl::Span<Node* const> nodes,\n                   absl::string_view cluster_name) {\n   for (Node* n : nodes) {\n-    n->AddAttr(kXlaClusterAttr, string(cluster_name));\n+    n->AddAttr(kXlaClusterAttr, std::string(cluster_name));\n   }\n }\n "
        },
        {
            "sha": "d25d77d6cff22b7735092d4e581a7adebc17fec8",
            "filename": "tensorflow/compiler/jit/pjrt_base_device.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fpjrt_base_device.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fpjrt_base_device.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fpjrt_base_device.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -17,8 +17,8 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-DeviceAttributes BuildPjRtBaseDeviceAttributes(const string& name_prefix,\n-                                               const string& device_name,\n+DeviceAttributes BuildPjRtBaseDeviceAttributes(const std::string& name_prefix,\n+                                               const std::string& device_name,\n                                                int device_ordinal) {\n   return Device::BuildDeviceAttributes(\n       absl::StrCat(name_prefix, \"/device:\", device_name, \":\", device_ordinal),"
        },
        {
            "sha": "33f09704d7c72b4bd5609366671e6ec4402347c1",
            "filename": "tensorflow/compiler/jit/resource_operation_safety_analysis.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -143,7 +143,7 @@ bool IsEdgeSafe(XlaResourceOpKind from, XlaResourceOpKind to) {\n \n using ResourceOp = std::pair<int, XlaResourceOpKind>;\n \n-string ResourceOpToString(const ResourceOp& resource_op) {\n+std::string ResourceOpToString(const ResourceOp& resource_op) {\n   return absl::StrCat(\n       resource_op.first, \": \",\n       XlaResourceOpInfo::XlaResourceOpKindToString(resource_op.second));\n@@ -233,14 +233,14 @@ class ResourceOpSet {\n   void operator=(const ResourceOpSet&) = delete;\n };\n \n-string ResourceOpSetToString(const ResourceOpSet& resource_op_set) {\n-  std::vector<string> elements_debug_string;\n+std::string ResourceOpSetToString(const ResourceOpSet& resource_op_set) {\n+  std::vector<std::string> elements_debug_string;\n   std::transform(resource_op_set.begin(), resource_op_set.end(),\n                  std::back_inserter(elements_debug_string), ResourceOpToString);\n   return absl::StrCat(\"{\", absl::StrJoin(elements_debug_string, \",\"), \"}\");\n }\n \n-string NodeToString(const Node& n, XlaResourceOpKind resource_op_kind) {\n+std::string NodeToString(const Node& n, XlaResourceOpKind resource_op_kind) {\n   return absl::StrCat(\n       \"[\", n.name(), \": \", n.type_string(), \"(\",\n       XlaResourceOpInfo::XlaResourceOpKindToString(resource_op_kind), \")\", \"]\");"
        },
        {
            "sha": "6b038c992f171589f3bdcc286dfe6724864765af",
            "filename": "tensorflow/compiler/jit/resource_operation_safety_analysis_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 7,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fresource_operation_safety_analysis_test.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -38,15 +38,15 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-Node* MakeRead(const Scope& scope, const string& id) {\n+Node* MakeRead(const Scope& scope, const std::string& id) {\n   Output var_handle =\n       ops::VarHandleOp(scope.WithOpName(\"Var\" + id), DT_FLOAT, TensorShape({}));\n   Output read =\n       ops::ReadVariableOp(scope.WithOpName(\"Read\" + id), var_handle, DT_FLOAT);\n   return read.node();\n }\n \n-Node* MakeWrite(const Scope& scope, const string& id) {\n+Node* MakeWrite(const Scope& scope, const std::string& id) {\n   Output var_handle =\n       ops::VarHandleOp(scope.WithOpName(\"Var\" + id), DT_FLOAT, TensorShape({}));\n   Output value_to_write =\n@@ -56,7 +56,7 @@ Node* MakeWrite(const Scope& scope, const string& id) {\n   return assign_op.operation.node();\n }\n \n-Node* MakeModify(const Scope& scope, const string& id) {\n+Node* MakeModify(const Scope& scope, const std::string& id) {\n   Output var_handle =\n       ops::VarHandleOp(scope.WithOpName(\"Var\" + id), DT_FLOAT, TensorShape({}));\n   Output value_to_write = ops::Const(scope.WithOpName(\"Increment\" + id), 1.0f);\n@@ -65,7 +65,7 @@ Node* MakeModify(const Scope& scope, const string& id) {\n   return assign_add_op.operation.node();\n }\n \n-Node* MakeNeutral(const Scope& scope, const string& id) {\n+Node* MakeNeutral(const Scope& scope, const std::string& id) {\n   return ops::Const(scope.WithOpName(\"Const\" + id), 42.0f).node();\n }\n \n@@ -238,7 +238,8 @@ TEST(ResourceOperationSafetyAnalysisTest, WriteReadModify) {\n   EXPECT_EQ(incompatible_pairs[1], write_modify_pair);\n }\n \n-FunctionDefLibrary CreateFunctionDefLibWithConstFunction(const string& name) {\n+FunctionDefLibrary CreateFunctionDefLibWithConstFunction(\n+    const std::string& name) {\n   FunctionDefLibrary flib_def;\n   FunctionDef func = FunctionDefHelper::Create(\n       /*function_name=*/name, /*in_def=*/{}, /*out_def=*/{\"out: float\"},\n@@ -249,8 +250,8 @@ FunctionDefLibrary CreateFunctionDefLibWithConstFunction(const string& name) {\n   return flib_def;\n }\n \n-Node* MakeCall(Graph* graph, const string& callee_name, const string& node_name,\n-               absl::Status* status) {\n+Node* MakeCall(Graph* graph, const std::string& callee_name,\n+               const std::string& node_name, absl::Status* status) {\n   NodeDef call_node;\n   call_node.set_name(node_name);\n   call_node.set_op(callee_name);"
        },
        {
            "sha": "b1469d2d699bf1c7af569689bc010730b55e9af0",
            "filename": "tensorflow/compiler/jit/shape_inference.h",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fshape_inference.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fshape_inference.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fshape_inference.h?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -35,7 +35,8 @@ struct InferredShape {\n   DataType handle_type = DT_INVALID;\n   PartialTensorShape handle_shape;\n };\n-typedef std::unordered_map<string, std::vector<InferredShape>> GraphShapeInfo;\n+typedef std::unordered_map<std::string, std::vector<InferredShape>>\n+    GraphShapeInfo;\n \n // Infer shapes for all Tensors in a graph, and save them in a map.  The vector\n // for a Node contains the information about each of its outputs."
        },
        {
            "sha": "599d442de4b092010b0dc10660e66b2c0ba2284c",
            "filename": "tensorflow/compiler/jit/shape_inference_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fshape_inference_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Fshape_inference_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fshape_inference_test.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -61,7 +61,7 @@ TEST(ShapeInferenceTest, Basics) {\n   TF_ASSERT_OK(InferShapes(graph.get(), /*arg_shapes=*/{},\n                            /*fnlib_def=*/nullptr, &shape_info));\n \n-  std::map<string, std::vector<PartialTensorShape>> expected = {\n+  std::map<std::string, std::vector<PartialTensorShape>> expected = {\n       {\"A\", {PartialTensorShape({2, 3})}}, {\"B\", {PartialTensorShape({3})}},\n       {\"C\", {PartialTensorShape()}},       {\"D\", {PartialTensorShape({2, 3})}},\n       {\"E\", {PartialTensorShape()}},       {\"F\", {PartialTensorShape()}},\n@@ -94,7 +94,7 @@ TEST(ShapeInferenceTest, UseArgShapesForVariableBatchSize) {\n   TF_ASSERT_OK(InferShapes(graph.get(), arg_shapes,\n                            /*fnlib_def=*/nullptr, &shape_info));\n \n-  std::map<string, std::vector<PartialTensorShape>> expected = {\n+  std::map<std::string, std::vector<PartialTensorShape>> expected = {\n       {\"A\", {PartialTensorShape({2, 3})}},\n       {\"B\", {PartialTensorShape({2, 3})}},\n       {\"C\", {PartialTensorShape({2, 3})}},\n@@ -127,7 +127,7 @@ TEST(ShapeInferenceTest, UseArgShapesForVariableBatchSizeIncompleteUserArgs) {\n   TF_ASSERT_OK(InferShapes(graph.get(), arg_shapes,\n                            /*fnlib_def=*/nullptr, &shape_info));\n \n-  std::map<string, std::vector<PartialTensorShape>> expected = {\n+  std::map<std::string, std::vector<PartialTensorShape>> expected = {\n       {\"A\", {PartialTensorShape({2, 3})}},\n       {\"B\", {PartialTensorShape({2, 3})}},\n       {\"C\", {PartialTensorShape({2, 3})}},\n@@ -156,7 +156,7 @@ TEST(ShapeInferenceTest, WhileLoop) {\n         ops::internal::Enter(scope.WithOpName(\"while/Enter2\"), source, \"aloop\");\n     auto merge = ops::Merge(scope.WithOpName(\"while/Merge\"),\n                             std::initializer_list<Input>{enter, dummy});\n-    auto ten = ops::Const<int32>(\n+    auto ten = ops::Const<int32_t>(\n         scope.WithOpName(\"while/Less/y\").WithControlDependencies(merge.output),\n         10);\n     auto less = ops::Less(scope.WithOpName(\"while/Less\"), merge.output, ten);\n@@ -168,11 +168,11 @@ TEST(ShapeInferenceTest, WhileLoop) {\n     auto identity = ops::Identity(scope.WithOpName(\"while/Identity\"),\n                                   switch_node.output_true);\n     auto identity_shape =\n-        ops::Const<int32>(scope.WithOpName(\"while/Identity/shape\"), {});\n+        ops::Const<int32_t>(scope.WithOpName(\"while/Identity/shape\"), {});\n     auto identity_reshaped = ops::Reshape(\n         scope.WithOpName(\"while/Identity/reshaped\"), identity, identity_shape);\n \n-    auto one = ops::Const<int32>(\n+    auto one = ops::Const<int32_t>(\n         scope.WithOpName(\"while/add/y\").WithControlDependencies(identity), 1);\n     auto add = ops::Add(scope.WithOpName(\"while/add\"), identity_reshaped, one);\n     auto next_iteration =\n@@ -190,7 +190,7 @@ TEST(ShapeInferenceTest, WhileLoop) {\n   GraphShapeInfo shape_info;\n   TF_ASSERT_OK(InferShapes(&graph, /*arg_shapes=*/{}, /*fnlib_def=*/nullptr,\n                            &shape_info));\n-  std::map<string, std::vector<PartialTensorShape>> expected = {\n+  std::map<std::string, std::vector<PartialTensorShape>> expected = {\n       {\"while/Identity\", {PartialTensorShape()}},\n       {\"while/add\", {PartialTensorShape({})}},\n   };"
        },
        {
            "sha": "30a9ab51faf105525c42f3f2712b06de018acdd9",
            "filename": "tensorflow/compiler/jit/test_util.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Ftest_util.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Ftest_util.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Ftest_util.cc?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -29,7 +29,7 @@ namespace tensorflow {\n \n absl::Status ShapeAnnotationsMatch(\n     const Graph& graph, const GraphShapeInfo& shape_info,\n-    std::map<string, std::vector<PartialTensorShape>> expected_shapes) {\n+    std::map<std::string, std::vector<PartialTensorShape>> expected_shapes) {\n   for (Node* node : graph.op_nodes()) {\n     auto sit = shape_info.find(node->name());\n     TF_RET_CHECK(sit != shape_info.end())\n@@ -50,7 +50,7 @@ absl::Status ShapeAnnotationsMatch(\n     }\n   }\n   if (!expected_shapes.empty()) {\n-    std::vector<string> missing;\n+    std::vector<std::string> missing;\n     missing.reserve(expected_shapes.size());\n     for (const auto& entry : expected_shapes) {\n       missing.push_back(entry.first);\n@@ -88,12 +88,12 @@ void DeviceSetup::AddDevicesAndSetUp(\n   flr_ = pflr_->GetFLR(\"/job:localhost/replica:0/task:0/cpu:0\");\n }\n \n-Device* DeviceSetup::GetDevice(const string& device_name) {\n+Device* DeviceSetup::GetDevice(const std::string& device_name) {\n   if (device_mgr_ == nullptr) {\n     return nullptr;\n   }\n \n-  string full_device_name = absl::StrCat(\n+  std::string full_device_name = absl::StrCat(\n       \"/job:localhost/replica:0/task:0/device:\", device_name, \":0\");\n   Device* device;\n   TF_CHECK_OK(device_mgr_->LookupDevice(full_device_name, &device));"
        },
        {
            "sha": "ba7d2533ef7c74e7584f999a3d8ed688cd3c8580",
            "filename": "tensorflow/compiler/jit/test_util.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Ftest_util.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/47367a9fb42759b71ea54efd4d215b431c630708/tensorflow%2Fcompiler%2Fjit%2Ftest_util.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Ftest_util.h?ref=47367a9fb42759b71ea54efd4d215b431c630708",
            "patch": "@@ -44,7 +44,7 @@ namespace tensorflow {\n // `expected_shapes` entries.\n absl::Status ShapeAnnotationsMatch(\n     const Graph& graph, const GraphShapeInfo& shape_info,\n-    std::map<string, std::vector<PartialTensorShape>> expected_shapes);\n+    std::map<std::string, std::vector<PartialTensorShape>> expected_shapes);\n \n // A helper object to create GraphOptimizationPassOptions.\n struct GraphOptimizationPassWrapper {\n@@ -74,7 +74,7 @@ class DeviceSetup {\n   void AddDevicesAndSetUp(\n       const std::vector<std::string>& device_names,\n       const std::optional<FunctionDef>& fdef = std::nullopt);\n-  Device* GetDevice(const string& device_name);\n+  Device* GetDevice(const std::string& device_name);\n   FunctionLibraryRuntime* flr() { return flr_; }\n \n  private:"
        }
    ],
    "stats": {
        "total": 427,
        "additions": 218,
        "deletions": 209
    }
}