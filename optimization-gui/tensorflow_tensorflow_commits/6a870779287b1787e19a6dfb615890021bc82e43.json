{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 848079114",
    "sha": "6a870779287b1787e19a6dfb615890021bc82e43",
    "files": [
        {
            "sha": "a9de19492d1aff51db3a44c02c8f8bcb69f57b81",
            "filename": "tensorflow/core/kernels/maxpooling_op.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 24,
            "changes": 48,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fmaxpooling_op.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -366,7 +366,7 @@ class MaxPoolingGradOp<Eigen::GpuDevice, T> : public OpKernel {\n   typedef Eigen::GpuDevice Device;\n \n   explicit MaxPoolingGradOp(OpKernelConstruction* context) : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -412,16 +412,16 @@ class MaxPoolingGradOp<Eigen::GpuDevice, T> : public OpKernel {\n \n     TensorShape output_shape = tensor_in.shape();\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n     if (context->num_inputs() == 5) {\n       const Tensor& tensor_ksize = context->input(3);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(4);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -452,8 +452,8 @@ class MaxPoolingGradOp<Eigen::GpuDevice, T> : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   std::vector<int64_t> explicit_paddings_;\n   TensorFormat data_format_;\n@@ -698,7 +698,7 @@ class MaxPoolingGradGradOp<Eigen::GpuDevice, T> : public OpKernel {\n \n   explicit MaxPoolingGradGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -739,16 +739,16 @@ class MaxPoolingGradGradOp<Eigen::GpuDevice, T> : public OpKernel {\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, tensor_out.shape(), &output));\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n     if (context->num_inputs() == 5) {\n       const Tensor& tensor_ksize = context->input(3);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(4);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -798,8 +798,8 @@ class MaxPoolingGradGradOp<Eigen::GpuDevice, T> : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   TensorFormat data_format_;\n   bool use_dnn_;\n@@ -1270,7 +1270,7 @@ class MaxPoolingNoMaskOp<GPUDevice, T> : public OpKernel {\n   typedef GPUDevice Device;\n   explicit MaxPoolingNoMaskOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -1372,8 +1372,8 @@ class MaxPoolingNoMaskOp<GPUDevice, T> : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   std::vector<int64_t> explicit_paddings_;\n   TensorFormat data_format_;\n@@ -1386,7 +1386,7 @@ class MaxPoolingNoMaskV2Op<GPUDevice, T> : public OpKernel {\n   typedef GPUDevice Device;\n   explicit MaxPoolingNoMaskV2Op(OpKernelConstruction* context)\n       : OpKernel(context) {\n-    string data_format;\n+    std::string data_format;\n     OP_REQUIRES_OK(context, context->GetAttr(\"data_format\", &data_format));\n     OP_REQUIRES(context, FormatFromString(data_format, &data_format_),\n                 errors::InvalidArgument(\"Invalid data format\"));\n@@ -1413,17 +1413,17 @@ class MaxPoolingNoMaskV2Op<GPUDevice, T> : public OpKernel {\n   void Compute(OpKernelContext* context) override {\n     const Tensor& tensor_in = context->input(0);\n \n-    std::vector<int32> ksize = ksize_;\n-    std::vector<int32> stride = stride_;\n+    std::vector<int32_t> ksize = ksize_;\n+    std::vector<int32_t> stride = stride_;\n \n     if (context->num_inputs() != 1) {\n       const Tensor& tensor_ksize = context->input(1);\n-      auto value_ksize = tensor_ksize.flat<int32>();\n+      auto value_ksize = tensor_ksize.flat<int32_t>();\n       ksize.resize(tensor_ksize.shape().num_elements());\n       std::copy_n(&value_ksize(0), ksize.size(), ksize.begin());\n \n       const Tensor& tensor_stride = context->input(2);\n-      auto value_stride = tensor_stride.flat<int32>();\n+      auto value_stride = tensor_stride.flat<int32_t>();\n       stride.resize(tensor_stride.shape().num_elements());\n       std::copy_n(&value_stride(0), stride.size(), stride.begin());\n     }\n@@ -1471,8 +1471,8 @@ class MaxPoolingNoMaskV2Op<GPUDevice, T> : public OpKernel {\n   }\n \n  private:\n-  std::vector<int32> ksize_;\n-  std::vector<int32> stride_;\n+  std::vector<int32_t> ksize_;\n+  std::vector<int32_t> stride_;\n   Padding padding_;\n   std::vector<int64_t> explicit_paddings_;\n   TensorFormat data_format_;"
        },
        {
            "sha": "a63a176032f95395f923bb1dc108303f4d40f8c2",
            "filename": "tensorflow/core/kernels/pooling_ops_3d.cc",
            "status": "modified",
            "additions": 14,
            "deletions": 14,
            "changes": 28,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_3d.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -816,9 +816,9 @@ TF_CALL_bfloat16(REGISTER_CPU_KERNELS);\n template <typename T>\n struct LaunchPoolingOp<GPUDevice, T, AVG> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Padding padding_type,\n                      Tensor* output) {\n     DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kAverage, window,\n@@ -829,9 +829,9 @@ struct LaunchPoolingOp<GPUDevice, T, AVG> {\n template <typename T>\n struct LaunchPoolingOp<GPUDevice, T, MAX> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Padding padding_type,\n                      Tensor* output) {\n     DnnPooling3dOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum, window,\n@@ -843,10 +843,10 @@ template <typename T>\n struct LaunchMaxPooling3dGradOp<GPUDevice, T> {\n   static void launch(OpKernelContext* context, const Tensor& tensor_in,\n                      const Tensor& tensor_out, const Tensor& out_backprop,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& out,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& out,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Tensor* input_backprop) {\n     const TensorShape output_shape = tensor_in.shape();\n     DnnPooling3dGradOp<T>::Compute(context, se::dnn::PoolingMode::kMaximum,\n@@ -861,10 +861,10 @@ struct LaunchAvgPooling3dGradOp<GPUDevice, T> {\n   static void launch(OpKernelContext* context,\n                      const TensorShape& tensor_in_shape,\n                      const Tensor& out_backprop,\n-                     const std::array<int64, 3>& window,\n-                     const std::array<int64, 3>& stride,\n-                     const std::array<int64, 3>& out,\n-                     const std::array<int64, 3>& padding,\n+                     const std::array<int64_t, 3>& window,\n+                     const std::array<int64_t, 3>& stride,\n+                     const std::array<int64_t, 3>& out,\n+                     const std::array<int64_t, 3>& padding,\n                      TensorFormat data_format, Tensor* output) {\n     DnnPooling3dGradOp<T>::Compute(\n         context, se::dnn::PoolingMode::kAverage, window, stride, padding, out,"
        },
        {
            "sha": "24ed53d027442e0a3caf4617c19fe0718b26307d",
            "filename": "tensorflow/core/kernels/pooling_ops_common.cc",
            "status": "modified",
            "additions": 27,
            "deletions": 28,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -56,27 +56,28 @@ struct RawType<qint8> {\n \n template <typename T>\n struct PadInputWithNegativeInf {\n-  Status operator()(const GPUDevice& d,\n-                    typename TTypes<T, 4, int>::ConstTensor in,\n-                    int input_pad_top, int input_pad_bottom, int input_pad_left,\n-                    int input_pad_right, typename TTypes<T, 4, int>::Tensor out,\n-                    TensorFormat format) {\n+  absl::Status operator()(const GPUDevice& d,\n+                          typename TTypes<T, 4, int>::ConstTensor in,\n+                          int input_pad_top, int input_pad_bottom,\n+                          int input_pad_left, int input_pad_right,\n+                          typename TTypes<T, 4, int>::Tensor out,\n+                          TensorFormat format) {\n     T padding_value = -std::numeric_limits<T>::infinity();\n     functor::PadInput<GPUDevice, T, int, 4>()(\n         d, in, {{input_pad_top, input_pad_left}},\n         {{input_pad_bottom, input_pad_right}}, out, format, padding_value);\n-    return OkStatus();\n+    return absl::OkStatus();\n   }\n };\n \n template <>\n struct PadInputWithNegativeInf<qint8> {\n-  Status operator()(const GPUDevice& d,\n-                    typename TTypes<qint8, 4, int>::ConstTensor in,\n-                    int input_pad_top, int input_pad_bottom, int input_pad_left,\n-                    int input_pad_right,\n-                    typename TTypes<qint8, 4, int>::Tensor out,\n-                    TensorFormat format) {\n+  absl::Status operator()(const GPUDevice& d,\n+                          typename TTypes<qint8, 4, int>::ConstTensor in,\n+                          int input_pad_top, int input_pad_bottom,\n+                          int input_pad_left, int input_pad_right,\n+                          typename TTypes<qint8, 4, int>::Tensor out,\n+                          TensorFormat format) {\n     return errors::InvalidArgument(\n         \"Explicit padding not yet supported with qint8\");\n   }\n@@ -227,8 +228,8 @@ absl::Status PoolParameters::forward_output_shape(TensorShape* shape) {\n \n template <typename T>\n void DnnPoolingImpl(OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n-                    const std::vector<int32>& size,\n-                    const std::vector<int32>& stride, Padding padding,\n+                    const std::vector<int32_t>& size,\n+                    const std::vector<int32_t>& stride, Padding padding,\n                     std::vector<int64_t> explicit_paddings,\n                     TensorFormat data_format, const Tensor& tensor_in,\n                     const TensorShape& tensor_out_shape, bool propagate_nans,\n@@ -438,14 +439,12 @@ void DnnPoolingImpl(OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n }\n \n template <typename T>\n-void DnnPoolingOp<T>::Compute(OpKernelContext* context,\n-                              se::dnn::PoolingMode pooling_mode,\n-                              const std::vector<int32>& size,\n-                              const std::vector<int32>& stride, Padding padding,\n-                              std::vector<int64_t> explicit_paddings,\n-                              TensorFormat data_format, const Tensor& tensor_in,\n-                              const TensorShape& tensor_out_shape,\n-                              bool propagate_nans) {\n+void DnnPoolingOp<T>::Compute(\n+    OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n+    const std::vector<int32_t>& size, const std::vector<int32_t>& stride,\n+    Padding padding, std::vector<int64_t> explicit_paddings,\n+    TensorFormat data_format, const Tensor& tensor_in,\n+    const TensorShape& tensor_out_shape, bool propagate_nans) {\n   Tensor* tensor_out = nullptr;\n   OP_REQUIRES_OK(context,\n                  context->allocate_output(0, tensor_out_shape, &tensor_out));\n@@ -457,7 +456,7 @@ void DnnPoolingOp<T>::Compute(OpKernelContext* context,\n template <>\n void DnnPoolingOp<Eigen::bfloat16>::Compute(\n     OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n-    const std::vector<int32>& size, const std::vector<int32>& stride,\n+    const std::vector<int32_t>& size, const std::vector<int32_t>& stride,\n     Padding padding, std::vector<int64_t> explicit_paddings,\n     TensorFormat data_format, const Tensor& tensor_in,\n     const TensorShape& tensor_out_shape, bool propagate_nans) {\n@@ -511,14 +510,14 @@ DECLARE_GPU_SPEC(float);\n DECLARE_GPU_SPEC(Eigen::half);\n DECLARE_GPU_SPEC(Eigen::bfloat16);\n DECLARE_GPU_SPEC(double);\n-DECLARE_GPU_SPEC(int32);\n+DECLARE_GPU_SPEC(int32_t);\n }  // namespace functor\n \n template <typename T>\n void DnnPoolingGradImpl(OpKernelContext* context,\n                         se::dnn::PoolingMode pooling_mode,\n-                        const std::vector<int32>& size,\n-                        const std::vector<int32>& stride, Padding padding,\n+                        const std::vector<int32_t>& size,\n+                        const std::vector<int32_t>& stride, Padding padding,\n                         std::vector<int64_t> explicit_paddings,\n                         TensorFormat data_format, const Tensor* tensor_in,\n                         const Tensor* tensor_out, const Tensor& out_backprop,\n@@ -856,7 +855,7 @@ void DnnPoolingGradImpl(OpKernelContext* context,\n template <typename T>\n void DnnPoolingGradOp<T>::Compute(\n     OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n-    const std::vector<int32>& size, const std::vector<int32>& stride,\n+    const std::vector<int32_t>& size, const std::vector<int32_t>& stride,\n     Padding padding, std::vector<int64_t> explicit_paddings,\n     TensorFormat data_format, const Tensor* tensor_in, const Tensor* tensor_out,\n     const Tensor& out_backprop, const TensorShape& tensor_in_shape,\n@@ -873,7 +872,7 @@ void DnnPoolingGradOp<T>::Compute(\n template <>\n void DnnPoolingGradOp<Eigen::bfloat16>::Compute(\n     OpKernelContext* context, se::dnn::PoolingMode pooling_mode,\n-    const std::vector<int32>& size, const std::vector<int32>& stride,\n+    const std::vector<int32_t>& size, const std::vector<int32_t>& stride,\n     Padding padding, std::vector<int64_t> explicit_paddings,\n     TensorFormat data_format, const Tensor* tensor_in, const Tensor* tensor_out,\n     const Tensor& out_backprop, const TensorShape& tensor_in_shape,"
        },
        {
            "sha": "cced70b25d4a39d3a5d9170cf002c2e5ec634480",
            "filename": "tensorflow/core/kernels/pooling_ops_common.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fpooling_ops_common.h?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -314,12 +314,12 @@ struct LaunchMaxPoolingNoMask_NCHW_VECT_C<Eigen::GpuDevice> {\n                      const Tensor& input, Tensor* output) {\n #if GOOGLE_CUDA\n     bool status = functor::MaxPoolForwardNoMask_NCHW_VECT_C()(\n-        reinterpret_cast<const int32*>(input.flat<qint8>().data()),\n+        reinterpret_cast<const int32_t*>(input.flat<qint8>().data()),\n         params.tensor_in_batch, params.tensor_in_rows, params.tensor_in_cols,\n         params.depth, params.out_height, params.out_width, params.window_rows,\n         params.window_cols, params.row_stride, params.col_stride,\n         params.pad_top, params.pad_left,\n-        reinterpret_cast<int32*>(output->flat<qint8>().data()),\n+        reinterpret_cast<int32_t*>(output->flat<qint8>().data()),\n         context->eigen_gpu_device());\n     if (!status) {\n       context->SetStatus(errors::Internal("
        },
        {
            "sha": "cef648707d34222d962929949c38a185be83205f",
            "filename": "tensorflow/core/kernels/random_op.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Frandom_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Frandom_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Frandom_op.h?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -51,8 +51,8 @@ typedef Eigen::GpuDevice GPUDevice;\n // Declares the partially GPU-specialized functor struct.\n template <class Distribution>\n struct FillPhiloxRandom<GPUDevice, Distribution> {\n-  void operator()(OpKernelContext* ctx, const GPUDevice& d, const uint64* key,\n-                  const uint64* counter, random::PhiloxRandom gen,\n+  void operator()(OpKernelContext* ctx, const GPUDevice& d, const uint64_t* key,\n+                  const uint64_t* counter, random::PhiloxRandom gen,\n                   typename Distribution::ResultElementType* data, int64_t size,\n                   Distribution dist);\n };"
        },
        {
            "sha": "23be3bd76534fde76985b17acdc69516d2a4f76e",
            "filename": "tensorflow/core/kernels/regex_full_match_op.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fregex_full_match_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fregex_full_match_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fregex_full_match_op.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -41,7 +41,7 @@ class RegexFullMatchOp : public OpKernel {\n     OP_REQUIRES(ctx, TensorShapeUtils::IsScalar(pattern_tensor->shape()),\n                 errors::InvalidArgument(\"Pattern must be scalar, but received \",\n                                         pattern_tensor->shape().DebugString()));\n-    const string pattern = pattern_tensor->flat<tstring>()(0);\n+    const std::string pattern = pattern_tensor->flat<tstring>()(0);\n     std::shared_ptr<RE2> regex = CachedRE2(pattern);\n     OP_REQUIRES(ctx, regex->ok(),\n                 errors::InvalidArgument(\"Invalid pattern: \", pattern,\n@@ -57,7 +57,7 @@ class RegexFullMatchOp : public OpKernel {\n   }\n \n  private:\n-  std::shared_ptr<RE2> CachedRE2(const string& pattern) {\n+  std::shared_ptr<RE2> CachedRE2(const std::string& pattern) {\n     {\n       tf_shared_lock l(mu_);\n       if (regex_ != nullptr && regex_->pattern() == pattern) {\n@@ -88,7 +88,7 @@ REGISTER_KERNEL_BUILDER(Name(\"RegexFullMatch\").Device(DEVICE_CPU),\n class StaticRegexFullMatchOp : public OpKernel {\n  public:\n   explicit StaticRegexFullMatchOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n-    string pattern;\n+    std::string pattern;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"pattern\", &pattern));\n     re_ = std::make_unique<RE2>(pattern);\n     OP_REQUIRES(ctx, re_->ok(),"
        },
        {
            "sha": "41ee85d7e4b02b23e5995cc4156b8994355b091f",
            "filename": "tensorflow/core/kernels/regex_replace_op_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 4,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fregex_replace_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fregex_replace_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fregex_replace_op_test.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -67,8 +67,9 @@ Tensor GetTestTensor(int batch) {\n   return t;\n }\n \n-Graph* SetupRegexReplaceGraph(const Tensor& input, const string& input_pattern,\n-                              const string& input_rewrite) {\n+Graph* SetupRegexReplaceGraph(const Tensor& input,\n+                              const std::string& input_pattern,\n+                              const std::string& input_rewrite) {\n   Graph* g = new Graph(OpRegistry::Global());\n   Tensor pattern(DT_STRING, TensorShape({}));\n   pattern.flat<tstring>().setConstant(input_pattern);\n@@ -103,8 +104,8 @@ BENCHMARK(BM_RegexReplace)\n     ->Arg(128)\n     ->Arg(256);\n \n-Graph* SetupStaticGraph(const Tensor& input, const string& input_pattern,\n-                        const string& rewrite) {\n+Graph* SetupStaticGraph(const Tensor& input, const std::string& input_pattern,\n+                        const std::string& rewrite) {\n   Graph* g = new Graph(OpRegistry::Global());\n \n   TF_CHECK_OK(NodeBuilder(\"static_regex_replace_op\", \"StaticRegexReplace\")"
        },
        {
            "sha": "127381c00034f7e312fa51a7fce1b55f214ad65a",
            "filename": "tensorflow/core/kernels/reshape_op.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freshape_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freshape_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Freshape_op.h?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -61,8 +61,8 @@ class ReshapeOp : public OpKernel {\n     switch (sizes.dtype()) {\n       case DT_INT32:\n         OP_REQUIRES_OK(context,\n-                       ValidateSizes<int32>(sizes, &product, &unknown_index,\n-                                            &shape, &sizes_has_zero_dim));\n+                       ValidateSizes<int32_t>(sizes, &product, &unknown_index,\n+                                              &shape, &sizes_has_zero_dim));\n         break;\n       case DT_INT64:\n         OP_REQUIRES_OK(context,\n@@ -145,7 +145,7 @@ class ReshapeOp : public OpKernel {\n         *has_zero_dim = true;\n       } else {\n         if (MultiplyWithoutOverflow(shape->num_elements(), size) < 0) {\n-          string msg;\n+          std::string msg;\n           for (int ii = 0; ii < num_dims; ++ii) {\n             if (ii != 0) {\n               absl::StrAppend(&msg, \", \");"
        },
        {
            "sha": "43df25dc056eb58c278dfd1b1aa37c92d2aba759",
            "filename": "tensorflow/core/kernels/resource_ops_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fresource_ops_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fresource_ops_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fresource_ops_test.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -42,7 +42,7 @@ class MockResource : public ResourceBase {\n       *alive_ = false;\n     }\n   }\n-  string DebugString() const override { return \"\"; }\n+  std::string DebugString() const override { return \"\"; }\n   bool* alive_;\n   int payload_;\n };\n@@ -103,7 +103,7 @@ TEST_F(MockHandleCreationOpTest, RefCounting) {\n   // Feed and run\n   AddInputFromArray<int64_t>(TensorShape({}),\n                              {reinterpret_cast<int64_t>(&alive)});\n-  AddInputFromArray<int32>(TensorShape({}), {payload});\n+  AddInputFromArray<int32_t>(TensorShape({}), {payload});\n   TF_ASSERT_OK(RunOpKernel());\n   EXPECT_TRUE(alive);\n "
        },
        {
            "sha": "53a52e6cda430390bcd473d61eaadf7fdca7bed5",
            "filename": "tensorflow/core/kernels/resource_variable_ops.h",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fresource_variable_ops.h?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -32,9 +32,9 @@ class VarHandleOp : public OpKernel {\n  private:\n   // Same fields as in ResourceHandleOp.\n   bool is_anonymous_;\n-  string container_;\n-  string name_;\n-  string debug_name_;\n+  std::string container_;\n+  std::string name_;\n+  std::string debug_name_;\n   Tensor const_tensor_;\n \n   DtypeAndPartialTensorShape dtype_and_shape_;"
        },
        {
            "sha": "16bfd01ab4f335be9e3439399b4954e466a52074",
            "filename": "tensorflow/core/kernels/restore_op_test.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 23,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Frestore_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Frestore_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Frestore_op_test.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -62,8 +62,8 @@ Tensor MakeInput(const TensorShape& shape,\n }\n \n TEST_F(RestoreOpTest, RestoreSimple) {\n-  const string filename = io::JoinPath(testing::TmpDir(), \"tensor_simple\");\n-  const std::vector<string> tensor_names = {\n+  const std::string filename = io::JoinPath(testing::TmpDir(), \"tensor_simple\");\n+  const std::vector<std::string> tensor_names = {\n       \"tensor_bool\",  \"tensor_int\",        \"tensor_float\",  \"tensor_double\",\n       \"tensor_qint8\", \"tensor_qint32\",     \"tensor_uint8\",  \"tensor_int8\",\n       \"tensor_int16\", \"tensor_int64\",      \"tensor_string\", \"tensor_complex64\",\n@@ -103,16 +103,16 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n     // Input #1 is the tensor names\n     Tensor input_1 = MakeInput<tstring>(\n         TensorShape({static_cast<int>(tensor_names.size())}),\n-        [&tensor_names](int x) -> string { return tensor_names[x]; });\n+        [&tensor_names](int x) -> std::string { return tensor_names[x]; });\n     inputs.push_back({nullptr, &input_1});\n \n     // Input #2 is a 1-d bool tensor\n     Tensor input_2 =\n         MakeInput<bool>(TensorShape({2}), [](int x) -> bool { return x != 0; });\n     inputs.push_back({nullptr, &input_2});\n     // Input #3 is a 1-d integer tensor\n-    Tensor input_3 = MakeInput<int32>(TensorShape({10}),\n-                                      [](int x) -> int32 { return x + 1; });\n+    Tensor input_3 = MakeInput<int32_t>(TensorShape({10}),\n+                                        [](int x) -> int32_t { return x + 1; });\n     inputs.push_back({nullptr, &input_3});\n     // Input #4 is a 2-d float tensor\n     Tensor input_4 = MakeInput<float>(TensorShape({2, 4}), [](int x) -> float {\n@@ -136,24 +136,25 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n         });\n     inputs.push_back({nullptr, &input_7});\n     // Input #8 is a 1-d uint8 tensor\n-    Tensor input_8 = MakeInput<uint8>(TensorShape({11}),\n-                                      [](int x) -> uint8 { return x + 1; });\n+    Tensor input_8 = MakeInput<uint8_t>(TensorShape({11}),\n+                                        [](int x) -> uint8_t { return x + 1; });\n     inputs.push_back({nullptr, &input_8});\n     // Input #9 is a 1-d int8 tensor\n-    Tensor input_9 =\n-        MakeInput<int8>(TensorShape({7}), [](int x) -> int8 { return x - 7; });\n+    Tensor input_9 = MakeInput<int8_t>(TensorShape({7}),\n+                                       [](int x) -> int8_t { return x - 7; });\n     inputs.push_back({nullptr, &input_9});\n     // Input #10 is a 1-d int16 tensor\n-    Tensor input_10 = MakeInput<int16>(TensorShape({7}),\n-                                       [](int x) -> int16 { return x - 8; });\n+    Tensor input_10 = MakeInput<int16_t>(\n+        TensorShape({7}), [](int x) -> int16_t { return x - 8; });\n     inputs.push_back({nullptr, &input_10});\n     // Input #11 is a 1-d int64 tensor\n-    Tensor input_11 = MakeInput<int64_t>(TensorShape({9}),\n-                                         [](int x) -> int64 { return x - 9; });\n+    Tensor input_11 = MakeInput<int64_t>(\n+        TensorShape({9}), [](int x) -> int64_t { return x - 9; });\n     inputs.push_back({nullptr, &input_11});\n     // Input #12 is a 1-d string tensor\n     Tensor input_12 = MakeInput<tstring>(\n-        TensorShape({2}), [](int x) -> string { return x ? \"yes\" : \"no\"; });\n+        TensorShape({2}),\n+        [](int x) -> std::string { return x ? \"yes\" : \"no\"; });\n     inputs.push_back({nullptr, &input_12});\n     // Input #13 is a 1-d complex64 tensor\n     Tensor input_13 = MakeInput<complex64>(\n@@ -212,7 +213,7 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n     TensorShape expected({10});\n     EXPECT_TRUE(output->shape().IsSameSize(expected));\n     for (int i = 0; i < 10; ++i) {\n-      EXPECT_EQ(i + 1, output->flat<int32>()(i));\n+      EXPECT_EQ(i + 1, output->flat<int32_t>()(i));\n     }\n   }\n   // The 2-d float tensor\n@@ -273,7 +274,7 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n     TensorShape expected({11});\n     EXPECT_TRUE(output->shape().IsSameSize(expected));\n     for (int i = 0; i < 11; ++i) {\n-      EXPECT_EQ(i + 1, output->flat<uint8>()(i));\n+      EXPECT_EQ(i + 1, output->flat<uint8_t>()(i));\n     }\n   }\n   // The 1-d int8 tensor\n@@ -285,7 +286,7 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n     TensorShape expected({7});\n     EXPECT_TRUE(output->shape().IsSameSize(expected));\n     for (int i = 0; i < 7; ++i) {\n-      EXPECT_EQ(i - 7, output->flat<int8>()(i));\n+      EXPECT_EQ(i - 7, output->flat<int8_t>()(i));\n     }\n   }\n   // The 1-d int16 tensor\n@@ -297,7 +298,7 @@ TEST_F(RestoreOpTest, RestoreSimple) {\n     TensorShape expected({7});\n     EXPECT_TRUE(output->shape().IsSameSize(expected));\n     for (int i = 0; i < 7; ++i) {\n-      EXPECT_EQ(i - 8, output->flat<int16>()(i));\n+      EXPECT_EQ(i - 8, output->flat<int16_t>()(i));\n     }\n   }\n   // The 1-d int64 tensor\n@@ -373,8 +374,8 @@ class RestoreSliceOpTest : public OpsTestBase {\n };\n \n TEST_F(RestoreSliceOpTest, RestoreInt) {\n-  const string filename = io::JoinPath(testing::TmpDir(), \"tensor_int\");\n-  const string tensor_name = \"tensor_int\";\n+  const std::string filename = io::JoinPath(testing::TmpDir(), \"tensor_int\");\n+  const std::string tensor_name = \"tensor_int\";\n \n   // We first need to write a tensor using the save_op\n   {\n@@ -412,7 +413,7 @@ TEST_F(RestoreSliceOpTest, RestoreInt) {\n     // Input #2 is a 4x16 integer tensor.\n     Tensor input_2(DT_INT32, TensorShape({4, 16}));\n     for (int64_t i = 0; i < input_2.NumElements(); ++i) {\n-      input_2.flat<int32>()(i) = i + 1;\n+      input_2.flat<int32_t>()(i) = i + 1;\n     }\n     inputs.push_back({nullptr, &input_2});\n \n@@ -433,7 +434,7 @@ TEST_F(RestoreSliceOpTest, RestoreInt) {\n \n   // Now we restore\n   MakeRestoreSliceOp(DT_INT32);\n-  string shape_and_slice = \"4 16 0,2:-\";\n+  std::string shape_and_slice = \"4 16 0,2:-\";\n   // Add a file name\n   AddInput<tstring>(TensorShape({}),\n                     [&filename](int x) -> tstring { return filename; });\n@@ -452,7 +453,7 @@ TEST_F(RestoreSliceOpTest, RestoreInt) {\n   TensorShape expected({2, 16});\n   EXPECT_TRUE(output->shape().IsSameSize(expected));\n   for (int64_t i = 0; i < expected.num_elements(); ++i) {\n-    EXPECT_EQ(i + 1, output->flat<int32>()(i));\n+    EXPECT_EQ(i + 1, output->flat<int32_t>()(i));\n   }\n }\n "
        },
        {
            "sha": "632a5136db8280666fe410f74df5f4efc5fda047",
            "filename": "tensorflow/core/kernels/reverse_op_test.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 28,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Freverse_op_test.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -115,17 +115,17 @@ class ReverseOpTest : public OpsTestBase {\n   }\n };\n \n-TEST_F(ReverseOpTest, Reverse_0_uint8) { Reverse_0<uint8>(); }\n+TEST_F(ReverseOpTest, Reverse_0_uint8) { Reverse_0<uint8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_0_int8) { Reverse_0<int8>(); }\n+TEST_F(ReverseOpTest, Reverse_0_int8) { Reverse_0<int8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_0_uint16) { Reverse_0<uint16>(); }\n+TEST_F(ReverseOpTest, Reverse_0_uint16) { Reverse_0<uint16_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_0_int16) { Reverse_0<int16>(); }\n+TEST_F(ReverseOpTest, Reverse_0_int16) { Reverse_0<int16_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_0_float) { Reverse_0<float>(); }\n \n-TEST_F(ReverseOpTest, Reverse_0_int32) { Reverse_0<int32>(); }\n+TEST_F(ReverseOpTest, Reverse_0_int32) { Reverse_0<int32_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_0_int64) { Reverse_0<int64_t>(); }\n \n@@ -135,17 +135,17 @@ TEST_F(ReverseOpTest, Reverse_0_complex64) { Reverse_0<complex64>(); }\n \n TEST_F(ReverseOpTest, Reverse_0_complex128) { Reverse_0<complex128>(); }\n \n-TEST_F(ReverseOpTest, Reverse_234_uint8) { Reverse_234<uint8>(); }\n+TEST_F(ReverseOpTest, Reverse_234_uint8) { Reverse_234<uint8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_234_int8) { Reverse_234<int8>(); }\n+TEST_F(ReverseOpTest, Reverse_234_int8) { Reverse_234<int8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_234_uint16) { Reverse_234<uint16>(); }\n+TEST_F(ReverseOpTest, Reverse_234_uint16) { Reverse_234<uint16_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_234_int16) { Reverse_234<int16>(); }\n+TEST_F(ReverseOpTest, Reverse_234_int16) { Reverse_234<int16_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_234_float) { Reverse_234<float>(); }\n \n-TEST_F(ReverseOpTest, Reverse_234_int32) { Reverse_234<int32>(); }\n+TEST_F(ReverseOpTest, Reverse_234_int32) { Reverse_234<int32_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_234_int64) { Reverse_234<int64_t>(); }\n \n@@ -155,17 +155,17 @@ TEST_F(ReverseOpTest, Reverse_234_complex64) { Reverse_234<complex64>(); }\n \n TEST_F(ReverseOpTest, Reverse_234_complex128) { Reverse_234<complex128>(); }\n \n-TEST_F(ReverseOpTest, Reverse_1234_uint8) { Reverse_1234<uint8>(); }\n+TEST_F(ReverseOpTest, Reverse_1234_uint8) { Reverse_1234<uint8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_1234_int8) { Reverse_1234<int8>(); }\n+TEST_F(ReverseOpTest, Reverse_1234_int8) { Reverse_1234<int8_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_1234_uint16) { Reverse_1234<uint16>(); }\n+TEST_F(ReverseOpTest, Reverse_1234_uint16) { Reverse_1234<uint16_t>(); }\n \n-TEST_F(ReverseOpTest, Reverse_1234_int16) { Reverse_1234<int16>(); }\n+TEST_F(ReverseOpTest, Reverse_1234_int16) { Reverse_1234<int16_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_1234_float) { Reverse_1234<float>(); }\n \n-TEST_F(ReverseOpTest, Reverse_1234_int32) { Reverse_1234<int32>(); }\n+TEST_F(ReverseOpTest, Reverse_1234_int32) { Reverse_1234<int32_t>(); }\n \n TEST_F(ReverseOpTest, Reverse_1234_int64) { Reverse_1234<int64_t>(); }\n \n@@ -190,7 +190,7 @@ static Graph* Reverse(const TensorShape& shape, int reverse_axis) {\n   Tensor data(DataTypeToEnum<T>::value, shape);\n   data.flat<T>().setRandom();\n   Tensor axes(DT_INT32, TensorShape({1}));\n-  axes.flat<int32>()(0) = reverse_axis;\n+  axes.flat<int32_t>()(0) = reverse_axis;\n   test::graph::Reverse(g, test::graph::Constant(g, data),\n                        test::graph::Constant(g, axes));\n   return g;\n@@ -229,8 +229,8 @@ void BM_ReverseRowsOf1Channel_1T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 1 /* intra_threads */, 1 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   1 /* intra_threads */, 1 /* channels */);\n }\n \n BENCHMARK(BM_ReverseRowsOf1Channel_1T_uint8)\n@@ -257,8 +257,8 @@ void BM_ReverseRowsOf1Channel_4T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 4 /* intra_threads */, 1 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   4 /* intra_threads */, 1 /* channels */);\n }\n \n BENCHMARK(BM_ReverseRowsOf1Channel_4T_uint8)\n@@ -286,8 +286,8 @@ void BM_ReverseRowsOf3Channels_1T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 1 /* intra_threads */, 3 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   1 /* intra_threads */, 3 /* channels */);\n }\n \n BENCHMARK(BM_ReverseRowsOf3Channels_1T_uint8)\n@@ -316,8 +316,8 @@ void BM_ReverseRowsOf3Channels_4T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 4 /* intra_threads */, 3 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   4 /* intra_threads */, 3 /* channels */);\n }\n BENCHMARK(BM_ReverseRowsOf3Channels_4T_uint8)\n     ->UseRealTime()\n@@ -344,8 +344,8 @@ void BM_ReverseRowsOf4Channels_1T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 1 /* intra_threads */, 4 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   1 /* intra_threads */, 4 /* channels */);\n }\n \n BENCHMARK(BM_ReverseRowsOf4Channels_1T_uint8)\n@@ -372,8 +372,8 @@ void BM_ReverseRowsOf4Channels_4T_uint8(::testing::benchmark::State& state) {\n   const int outer_dim = state.range(0);\n   const int middle_dim = state.range(1);\n \n-  RunReverseRowsBenchmark<uint8>(state, outer_dim, middle_dim,\n-                                 4 /* intra_threads */, 4 /* channels */);\n+  RunReverseRowsBenchmark<uint8_t>(state, outer_dim, middle_dim,\n+                                   4 /* intra_threads */, 4 /* channels */);\n }\n \n BENCHMARK(BM_ReverseRowsOf4Channels_4T_uint8)"
        },
        {
            "sha": "7d33356a169ccf7aed67146e3034dc3fee1014a6",
            "filename": "tensorflow/core/kernels/reverse_sequence_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.cc?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -98,8 +98,8 @@ void CheckErrorsGPU(OpKernelContext* context, int batch_dim, int seq_dim) {\n }\n \n template <>\n-void CheckErrors<GPUDevice, int32>(OpKernelContext* context, int batch_dim,\n-                                   int seq_dim) {\n+void CheckErrors<GPUDevice, int32_t>(OpKernelContext* context, int batch_dim,\n+                                     int seq_dim) {\n   CheckErrorsGPU(context, batch_dim, seq_dim);\n }\n \n@@ -164,8 +164,8 @@ class ReverseSequenceOp : public OpKernel {\n   }\n \n  private:\n-  int32 batch_dim_;\n-  int32 seq_dim_;\n+  int32_t batch_dim_;\n+  int32_t seq_dim_;\n \n   ReverseSequenceOp(const ReverseSequenceOp&) = delete;\n   void operator=(const ReverseSequenceOp&) = delete;"
        },
        {
            "sha": "7db47a4b8bbce392cef250b3ef48781ddce33b35",
            "filename": "tensorflow/core/kernels/reverse_sequence_op.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/6a870779287b1787e19a6dfb615890021bc82e43/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Freverse_sequence_op.h?ref=6a870779287b1787e19a6dfb615890021bc82e43",
            "patch": "@@ -49,8 +49,8 @@ class ReverseGenerator {\n \n  private:\n   typename TTypes<T, Dims>::ConstTensor input_;\n-  int32 batch_dim_;\n-  int32 seq_dim_;\n+  int32_t batch_dim_;\n+  int32_t seq_dim_;\n   typename TTypes<Tlen>::ConstVec seq_lengths_;\n };\n "
        }
    ],
    "stats": {
        "total": 285,
        "additions": 143,
        "deletions": 142
    }
}