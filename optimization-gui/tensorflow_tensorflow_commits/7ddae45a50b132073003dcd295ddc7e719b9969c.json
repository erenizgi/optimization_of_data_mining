{
    "author": "akuegel",
    "message": "[XLA:GPU] Bring hlo_op_profiler_run in sync with hlo_op_profiler_test.\n\nAlso add missing dependencies and set flags to make it actually run as test\ndespite being not a gtest based test.\n\nPiperOrigin-RevId: 836666319",
    "sha": "7ddae45a50b132073003dcd295ddc7e719b9969c",
    "files": [
        {
            "sha": "5f07de699e9576d147668006be9ced6a7efe1872",
            "filename": "third_party/xla/xla/service/gpu/model/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ddae45a50b132073003dcd295ddc7e719b9969c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ddae45a50b132073003dcd295ddc7e719b9969c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2FBUILD?ref=7ddae45a50b132073003dcd295ddc7e719b9969c",
            "patch": "@@ -809,6 +809,9 @@ xla_test(\n     # expressions like integer add and multiply.\n     args = [\"--xla_backend_optimization_level=0\"],\n     backends = [\"gpu\"],\n+    fail_if_no_test_linked = False,  # NOLINT=not based on gtest and thus doesn't support --gunit_fail_if_no_test_linked.\n+    fail_if_no_test_selected = False,  # NOLINT=not based on gtest and thus doesn't support --gunit_fail_if_no_test_selected.\n+    shuffle_tests = False,  # CANNOT_SHUFFLE_TESTS=This test is not based on gtest and thus doesn't support shuffling.\n     # This is a development tool, not a normal test, and thus should only be run\n     # manually with --config=cuda.\n     tags = [\n@@ -826,6 +829,8 @@ xla_test(\n         \"//xla/service:hlo_runner\",\n         \"//xla/service:platform_util\",\n         \"//xla/stream_executor:device_description\",\n+        \"//xla/tsl/platform:env\",\n+        \"//xla/tsl/platform:status\",\n         \"//xla/tsl/util:command_line_flags\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/strings\","
        },
        {
            "sha": "4008a8ccdae200ea328e026df89c5c8ae1d40735",
            "filename": "third_party/xla/xla/service/gpu/model/hlo_op_profiler_run.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 27,
            "changes": 31,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/7ddae45a50b132073003dcd295ddc7e719b9969c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler_run.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/7ddae45a50b132073003dcd295ddc7e719b9969c/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler_run.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fhlo_op_profiler_run.cc?ref=7ddae45a50b132073003dcd295ddc7e719b9969c",
            "patch": "@@ -84,37 +84,14 @@ int RunProfiler(int argc, char** argv) {\n       runner.backend().stream_executors()[0]->GetDeviceDescription();\n   VLOG(0) << dev_info.name() << \" @ \" << dev_info.clock_rate_ghz() << \" GHz\";\n \n-  const std::vector<PrimitiveType> dtypes = {\n-      S8, S16, S32, S64, U8, U16, U32, U64, F16, F32, F64, C64, C128,\n-  };\n-  const std::vector<HloOpcode> ops = {\n-      // Unary\n-      HloOpcode::kCbrt,\n-      HloOpcode::kCos,\n-      HloOpcode::kErf,\n-      HloOpcode::kExp,\n-      HloOpcode::kExpm1,\n-      HloOpcode::kLog,\n-      HloOpcode::kLog1p,\n-      HloOpcode::kLogistic,\n-      HloOpcode::kRsqrt,\n-      HloOpcode::kSin,\n-      HloOpcode::kSinh,\n-      HloOpcode::kSqrt,\n-      HloOpcode::kTanh,\n-      // Binary\n-      HloOpcode::kAdd,\n-      HloOpcode::kAtan2,\n-      HloOpcode::kDivide,\n-      HloOpcode::kMultiply,\n-      HloOpcode::kPower,\n-      HloOpcode::kSubtract,\n-  };\n-\n   HloInstructionProfileList instr_profiles;\n \n   for (const PrimitiveType data_type : HloOpProfiler::AllSupportedDtypes()) {\n     for (const HloOpcode op : HloOpProfiler::AllSupportedOps()) {\n+      if (HloOpProfiler::TooFastToMeasure().count(op) ||\n+          HloOpProfiler::Unsupported().count(op)) {\n+        continue;\n+      }\n       auto result = profiler.MeasureClockCyclesPerOp(op, data_type);\n       if (result.ok()) {\n         instr_profiles.add_entries()->Swap(&*result);"
        }
    ],
    "stats": {
        "total": 36,
        "additions": 9,
        "deletions": 27
    }
}