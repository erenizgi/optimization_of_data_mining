{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 832630323",
    "sha": "07c6ae663f75c904a78d9dbc65489231fd6b1179",
    "files": [
        {
            "sha": "0890d444ed55385671d5b2aec96d7b0c57a8f433",
            "filename": "tensorflow/core/kernels/image/adjust_contrast_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_contrast_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_contrast_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fadjust_contrast_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -99,10 +99,10 @@ class AdjustContrastOp : public OpKernel {\n       Name(\"AdjustContrast\").Device(DEVICE_CPU).TypeConstraint<T>(\"T\"), \\\n       AdjustContrastOp<CPUDevice, T>);\n \n-REGISTER_KERNEL(uint8);\n-REGISTER_KERNEL(int8);\n-REGISTER_KERNEL(int16);\n-REGISTER_KERNEL(int32);\n+REGISTER_KERNEL(uint8_t);\n+REGISTER_KERNEL(int8_t);\n+REGISTER_KERNEL(int16_t);\n+REGISTER_KERNEL(int32_t);\n REGISTER_KERNEL(float);\n REGISTER_KERNEL(double);\n #undef REGISTER_KERNEL"
        },
        {
            "sha": "99b1b246629852b0bd980b9ba1f196aabf3ac7e2",
            "filename": "tensorflow/core/kernels/image/attention_ops.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fattention_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fattention_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fattention_ops.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -33,12 +33,12 @@ namespace tensorflow {\n class ExtractGlimpseOp : public OpKernel {\n  public:\n   explicit ExtractGlimpseOp(OpKernelConstruction* context) : OpKernel(context) {\n-    const string& op = context->def().op();\n+    const std::string& op = context->def().op();\n     version_ = (op == \"ExtractGlimpse\") ? 1 : 2;\n     OP_REQUIRES_OK(context, context->GetAttr(\"normalized\", &normalized_));\n     OP_REQUIRES_OK(context, context->GetAttr(\"centered\", &centered_));\n     bool uniform_noise = false;\n-    string noise;\n+    std::string noise;\n     OP_REQUIRES_OK(context, context->GetAttr(\"uniform_noise\", &uniform_noise));\n     OP_REQUIRES_OK(context, context->GetAttr(\"noise\", &noise));\n     OP_REQUIRES(context,\n@@ -132,7 +132,7 @@ class ExtractGlimpseOp : public OpKernel {\n   bool normalized_;\n   bool centered_;\n   Eigen::ExtractGlimpsesNoiseMode noise_;\n-  int32 version_;\n+  int32_t version_;\n };\n \n REGISTER_KERNEL_BUILDER(Name(\"ExtractGlimpse\").Device(DEVICE_CPU),"
        },
        {
            "sha": "a667e2752ba0139098b6b35c29695432ff9fd495",
            "filename": "tensorflow/core/kernels/image/crop_and_resize_op.cc",
            "status": "modified",
            "additions": 22,
            "deletions": 20,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -83,14 +83,16 @@ static inline absl::Status ParseAndCheckBoxSizes(const Tensor& boxes,\n // [0, batch_size) then calls done.\n template <typename Device>\n inline void RunIfBoxIndexIsValid(\n-    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n-    int batch_size, const Callback& compute, const Callback& done);\n+    OpKernelContext* context,\n+    typename TTypes<int32_t, 1>::ConstTensor box_index, int batch_size,\n+    const Callback& compute, const Callback& done);\n \n // Specialization of CheckValidBoxIndex for a CPUDevice.\n template <>\n inline void RunIfBoxIndexIsValid<CPUDevice>(\n-    OpKernelContext* context, typename TTypes<int32, 1>::ConstTensor box_index,\n-    int batch_size, const Callback& compute, const Callback& done) {\n+    OpKernelContext* context,\n+    typename TTypes<int32_t, 1>::ConstTensor box_index, int batch_size,\n+    const Callback& compute, const Callback& done) {\n   const int num_boxes = box_index.dimension(0);\n   for (int b = 0; b < num_boxes; ++b) {\n     OP_REQUIRES_ASYNC(\n@@ -169,7 +171,7 @@ class CropAndResizeOp : public AsyncOpKernel {\n         done);\n \n     // Copy and validate crop sizes.\n-    auto crop_size_vec = crop_size.vec<int32>();\n+    auto crop_size_vec = crop_size.vec<int32_t>();\n     const int crop_height = internal::SubtleMustCopy(crop_size_vec(0));\n     const int crop_width = internal::SubtleMustCopy(crop_size_vec(1));\n     OP_REQUIRES_ASYNC(\n@@ -192,7 +194,7 @@ class CropAndResizeOp : public AsyncOpKernel {\n       const Tensor& box_index = context->input(2);\n       const bool status = functor::CropAndResize<Device, T>()(\n           context, image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n-          box_index.tensor<int32, 1>(), method_, extrapolation_value_,\n+          box_index.tensor<int32_t, 1>(), method_, extrapolation_value_,\n           output->tensor<float, 4>());\n \n       if (!status) {\n@@ -201,14 +203,14 @@ class CropAndResizeOp : public AsyncOpKernel {\n       }\n     };\n \n-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n+    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32_t, 1>(),\n                                  batch_size, std::move(compute_callback),\n                                  std::move(done));\n   }\n \n  private:\n   float extrapolation_value_;\n-  string method_;\n+  std::string method_;\n };\n \n // Partial specialization of CropAndResize functor for a CPUDevice.\n@@ -218,8 +220,8 @@ struct CropAndResize<CPUDevice, T> {\n   bool operator()(OpKernelContext* context,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_index,\n-                  const string& method_name, float extrapolation_value,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_index,\n+                  const std::string& method_name, float extrapolation_value,\n                   typename TTypes<float, 4>::Tensor crops) {\n     const int batch_size = image.dimension(0);\n     const int image_height = image.dimension(1);\n@@ -403,7 +405,7 @@ class CropAndResizeGradImageOp : public AsyncOpKernel {\n                       errors::InvalidArgument(\"image_size must have 4 elements\",\n                                               image_size.shape().DebugString()),\n                       done);\n-    auto image_size_vec = image_size.vec<int32>();\n+    auto image_size_vec = image_size.vec<int32_t>();\n     const int batch_size = internal::SubtleMustCopy(image_size_vec(0));\n     const int image_height = internal::SubtleMustCopy(image_size_vec(1));\n     const int image_width = internal::SubtleMustCopy(image_size_vec(2));\n@@ -440,21 +442,21 @@ class CropAndResizeGradImageOp : public AsyncOpKernel {\n       const Tensor& box_index = context->input(2);\n       const bool status = functor::CropAndResizeBackpropImage<Device, T>()(\n           context, grads.tensor<float, 4>(), boxes.tensor<float, 2>(),\n-          box_index.tensor<int32, 1>(), output->tensor<T, 4>(), method_);\n+          box_index.tensor<int32_t, 1>(), output->tensor<T, 4>(), method_);\n \n       if (!status) {\n         context->SetStatus(errors::Internal(\n             \"Failed to launch CropAndResizeBackpropImage kernel.\"));\n       }\n     };\n \n-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n+    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32_t, 1>(),\n                                  batch_size, std::move(compute_callback),\n                                  std::move(done));\n   }\n \n  private:\n-  string method_;\n+  std::string method_;\n };\n \n // Partial specialization of CropAndResizeBackpropImage functor for a CPUDevice.\n@@ -464,9 +466,9 @@ struct CropAndResizeBackpropImage<CPUDevice, T> {\n   bool operator()(const OpKernelContext* context,\n                   typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_index,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_index,\n                   typename TTypes<T, 4>::Tensor grads_image,\n-                  const string& method_name) {\n+                  const std::string& method_name) {\n     const int batch_size = grads_image.dimension(0);\n     const int image_height = grads_image.dimension(1);\n     const int image_width = grads_image.dimension(2);\n@@ -583,7 +585,7 @@ class CropAndResizeGradBoxesOp : public AsyncOpKernel {\n  public:\n   explicit CropAndResizeGradBoxesOp(OpKernelConstruction* context)\n       : AsyncOpKernel(context) {\n-    string method;\n+    std::string method;\n     OP_REQUIRES_OK(context, context->GetAttr(\"method\", &method));\n     OP_REQUIRES(context, method == \"bilinear\",\n                 errors::InvalidArgument(\"method must be 'bilinear'\", method));\n@@ -658,14 +660,14 @@ class CropAndResizeGradBoxesOp : public AsyncOpKernel {\n       const bool status = functor::CropAndResizeBackpropBoxes<Device, T>()(\n           context->eigen_device<Device>(), grads.tensor<float, 4>(),\n           image.tensor<T, 4>(), boxes.tensor<float, 2>(),\n-          box_index.tensor<int32, 1>(), output->tensor<float, 2>());\n+          box_index.tensor<int32_t, 1>(), output->tensor<float, 2>());\n       if (!status) {\n         context->SetStatus(errors::Internal(\n             \"Failed to launch CropAndResizeBackpropBoxes kernel.\"));\n       }\n     };\n \n-    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32, 1>(),\n+    RunIfBoxIndexIsValid<Device>(context, box_index.tensor<int32_t, 1>(),\n                                  batch_size, std::move(compute_callback),\n                                  std::move(done));\n   }\n@@ -679,7 +681,7 @@ struct CropAndResizeBackpropBoxes<CPUDevice, T> {\n                   typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_index,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_index,\n                   typename TTypes<float, 2>::Tensor grads_boxes) {\n     const int batch_size = image.dimension(0);\n     const int image_height = image.dimension(1);"
        },
        {
            "sha": "0e61fdb9b8bd4110039af0322302946af5b73805",
            "filename": "tensorflow/core/kernels/image/crop_and_resize_op.h",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op.h?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -30,7 +30,7 @@ struct CropAndResize {\n   bool operator()(const OpKernelContext* context,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   const std::string& method_name, float extrapolation_value,\n                   typename TTypes<float, 4>::Tensor crops);\n };\n@@ -41,7 +41,7 @@ struct CropAndResizeBackpropImage {\n   bool operator()(const OpKernelContext* context,\n                   typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   typename TTypes<T, 4>::Tensor grads_image,\n                   const std::string& method_name);\n };\n@@ -52,15 +52,15 @@ struct CropAndResizeBackpropBoxes {\n   bool operator()(const Device& d, typename TTypes<float, 4>::ConstTensor grads,\n                   typename TTypes<T, 4>::ConstTensor image,\n                   typename TTypes<float, 2>::ConstTensor boxes,\n-                  typename TTypes<int32, 1>::ConstTensor box_ind,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_ind,\n                   typename TTypes<float, 2>::Tensor grads_boxes);\n };\n \n template <typename Device>\n struct CheckValidBoxIndexHelper {\n   // Checks if all values in box_index are in [0, batch).\n   void operator()(const Device& d,\n-                  typename TTypes<int32, 1>::ConstTensor box_index, int batch,\n+                  typename TTypes<int32_t, 1>::ConstTensor box_index, int batch,\n                   typename TTypes<bool, 0>::Tensor isvalid) {\n     isvalid.device(d) = ((box_index >= 0) && (box_index < batch)).all();\n   }"
        },
        {
            "sha": "8f73a552812d7eb8aa15701704332e5092299b6f",
            "filename": "tensorflow/core/kernels/image/crop_and_resize_op_benchmark_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_benchmark_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -29,7 +29,7 @@ static Graph* CropAndResize(int batches, int width, int height, int depth,\n   Tensor boxes(DT_FLOAT, TensorShape({batches, 4}));\n   auto boxes_tensor = boxes.matrix<float>();\n   Tensor box_ind(DT_INT32, TensorShape({batches}));\n-  auto box_ind_flat = box_ind.flat<int32>();\n+  auto box_ind_flat = box_ind.flat<int32_t>();\n   for (int i = 0; i < batches; ++i) {\n     boxes_tensor(i, 0) = 0.2;\n     boxes_tensor(i, 1) = 0.2;\n@@ -38,7 +38,7 @@ static Graph* CropAndResize(int batches, int width, int height, int depth,\n     box_ind_flat(i) = i;\n   }\n   Tensor crop_size(DT_INT32, TensorShape({2}));\n-  auto crop_size_flat = crop_size.flat<int32>();\n+  auto crop_size_flat = crop_size.flat<int32_t>();\n   crop_size_flat(0) = crop_height;\n   crop_size_flat(1) = crop_width;\n   Node* ret;"
        },
        {
            "sha": "ac00c2d45245e45840623067ad407f5be76c167f",
            "filename": "tensorflow/core/kernels/image/crop_and_resize_op_test.cc",
            "status": "modified",
            "additions": 46,
            "deletions": 46,
            "changes": 92,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fcrop_and_resize_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -34,7 +34,7 @@ namespace tensorflow {\n class CropAndResizeOpTest : public OpsTestBase {\n  protected:\n   template <typename T>\n-  void MakeOp(float extrapolation_value, const string& method) {\n+  void MakeOp(float extrapolation_value, const std::string& method) {\n     TF_EXPECT_OK(NodeDefBuilder(\"crop_and_resize_op\", \"CropAndResize\")\n                      .Input(FakeInput(DataTypeToEnum<T>::value))\n                      .Input(FakeInput(DT_FLOAT))\n@@ -76,24 +76,24 @@ class CropAndResizeOpTest : public OpsTestBase {\n \n REGISTER_TEST(float)\n REGISTER_TEST(double)\n-REGISTER_TEST(uint8)\n-REGISTER_TEST(uint16)\n-REGISTER_TEST(int8)\n-REGISTER_TEST(int16)\n-REGISTER_TEST(int32)\n+REGISTER_TEST(uint8_t)\n+REGISTER_TEST(uint16_t)\n+REGISTER_TEST(int8_t)\n+REGISTER_TEST(int16_t)\n+REGISTER_TEST(int32_t)\n REGISTER_TEST(int64_t)\n \n #undef REGISTER_TEST\n \n TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To1x1Uint8) {\n-  MakeOp<uint8>(0, \"bilinear\");\n+  MakeOp<uint8_t>(0, \"bilinear\");\n   // Input:\n   //  1, 2\n   //  3, 4\n-  AddInputFromArray<uint8>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n+  AddInputFromArray<uint8_t>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -102,14 +102,14 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To1x1Uint8) {\n }\n \n TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To1x1Uint8NearestNeibor) {\n-  MakeOp<uint8>(0, \"nearest\");\n+  MakeOp<uint8_t>(0, \"nearest\");\n   // Input:\n   //  1, 2\n   //  3, 4\n-  AddInputFromArray<uint8>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n+  AddInputFromArray<uint8_t>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -124,8 +124,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To1x1Flipped) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {1, 1, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -140,8 +140,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To1x1FlippedNearestNeighbor) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {1, 1, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -156,8 +156,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -177,8 +177,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3NearestNeighbor) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -198,8 +198,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3Flipped) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {1, 1, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -219,8 +219,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3FlippedNearestNeighbor) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {1, 1, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -242,8 +242,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize3x3To2x2) {\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n   AddInputFromArray<float>(TensorShape({2, 4}), {0, 0, 1, 1, 0, 0, 0.5, 0.5});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 2, 1}));\n@@ -267,8 +267,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize3x3To2x2NearestNeighbor) {\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n   AddInputFromArray<float>(TensorShape({2, 4}), {0, 0, 1, 1, 0, 0, 0.5, 0.5});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 2, 1}));\n@@ -292,8 +292,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize3x3To2x2Flipped) {\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n   AddInputFromArray<float>(TensorShape({2, 4}), {1, 1, 0, 0, 0.5, 0.5, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 2, 1}));\n@@ -317,8 +317,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize3x3To2x2FlippedNearestNeighbor) {\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n   AddInputFromArray<float>(TensorShape({2, 4}), {1, 1, 0, 0, 0.5, 0.5, 0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 2, 2, 1}));\n@@ -341,8 +341,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3Extrapolated) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {-1, -1, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -362,8 +362,8 @@ TEST_F(CropAndResizeOpTest, TestCropAndResize2x2To3x3NoCrop) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({0, 4}), {});\n-  AddInputFromArray<int32>(TensorShape({0}), {});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({0}), {});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({0, 3, 3, 1}));\n@@ -377,8 +377,8 @@ TEST_F(CropAndResizeOpTest, TestInvalidInputShape) {\n   MakeOp<float>(0, \"bilinear\");\n   AddInputFromArray<float>(TensorShape({2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {0});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   absl::Status s = RunOpKernel();\n   ASSERT_FALSE(s.ok());\n   EXPECT_TRUE(absl::StrContains(s.ToString(), \"input image must be 4-D\")) << s;\n@@ -388,8 +388,8 @@ TEST_F(CropAndResizeOpTest, TestInvalidBoxIndexShape) {\n   MakeOp<float>(0, \"bilinear\");\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   absl::Status s = RunOpKernel();\n   ASSERT_FALSE(s.ok());\n   EXPECT_TRUE(\n@@ -401,8 +401,8 @@ TEST_F(CropAndResizeOpTest, TestInvalidBoxIndex) {\n   MakeOp<float>(0, \"bilinear\");\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n   AddInputFromArray<float>(TensorShape({1, 4}), {0, 0, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({1}), {1});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({1}), {1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   absl::Status s = RunOpKernel();\n   ASSERT_FALSE(s.ok());\n   EXPECT_TRUE(absl::StrContains(s.ToString(),\n@@ -425,8 +425,8 @@ TEST_F(CropAndResizeOpTest, TestWithSharding) {\n                   [=](int i) -> float { return i % kLength; });\n   AddInputFromArray<float>(TensorShape({2, 4}),\n                            {0, 0, 0.5, 0.5, 0.5, 0.5, 1, 1});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n-  AddInputFromArray<int32>(TensorShape({2}), {kHalf, kHalf});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {kHalf, kHalf});\n \n   TF_ASSERT_OK(RunOpKernel());\n "
        },
        {
            "sha": "a73d6f1ad660cb901250146adc32bd69d73456ed",
            "filename": "tensorflow/core/kernels/image/decode_image_op.cc",
            "status": "modified",
            "additions": 62,
            "deletions": 60,
            "changes": 122,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdecode_image_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdecode_image_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fdecode_image_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -129,7 +129,7 @@ class DecodeImageV2Op : public OpKernel {\n       OP_REQUIRES_OK(context,\n                      context->GetAttr(\"acceptable_fraction\",\n                                       &flags_.min_acceptable_fraction));\n-      string dct_method;\n+      std::string dct_method;\n       OP_REQUIRES_OK(context, context->GetAttr(\"dct_method\", &dct_method));\n       OP_REQUIRES(\n           context,\n@@ -189,7 +189,7 @@ class DecodeImageV2Op : public OpKernel {\n   }\n \n   // Helper for decoding BMP.\n-  inline int32 ByteSwapInt32ForBigEndian(int32_t x) {\n+  inline int32_t ByteSwapInt32ForBigEndian(int32_t x) {\n     if (!port::kLittleEndian) {\n       return BYTE_SWAP_32(x);\n     } else {\n@@ -198,7 +198,7 @@ class DecodeImageV2Op : public OpKernel {\n   }\n \n   // Helper for decoding BMP.\n-  inline int16 ByteSwapInt16ForBigEndian(int16_t x) {\n+  inline int16_t ByteSwapInt16ForBigEndian(int16_t x) {\n     if (!port::kLittleEndian) {\n       return BYTE_SWAP_16(x);\n     } else {\n@@ -264,7 +264,7 @@ class DecodeImageV2Op : public OpKernel {\n       OP_REQUIRES(context, crop_window.dim_size(0) == 4,\n                   errors::InvalidArgument(\"crop_size must have four elements \",\n                                           crop_window.shape().DebugString()));\n-      auto crop_window_vec = crop_window.vec<int32>();\n+      auto crop_window_vec = crop_window.vec<int32_t>();\n       flags.crop_y = crop_window_vec(0);\n       flags.crop_x = crop_window_vec(1);\n       flags.crop_height = crop_window_vec(2);\n@@ -288,9 +288,9 @@ class DecodeImageV2Op : public OpKernel {\n     // Decode JPEG. Directly allocate to the output buffer if data type is\n     // uint8 (to save extra copying). Otherwise, allocate a new uint8 buffer\n     // with buffer size. `jpeg::Uncompress` supports unit8 only.\n-    uint8* buffer = jpeg::Uncompress(\n+    uint8_t* buffer = jpeg::Uncompress(\n         input.data(), input.size(), flags, nullptr /* nwarn */,\n-        [&](int width, int height, int channels) -> uint8* {\n+        [&](int width, int height, int channels) -> uint8_t* {\n           buffer_size = height * width * channels;\n           absl::Status status;\n           // By the existing API, we support decoding JPEG with `DecodeGif`\n@@ -310,9 +310,9 @@ class DecodeImageV2Op : public OpKernel {\n           }\n \n           if (data_type_ == DataType::DT_UINT8) {\n-            return output->flat<uint8>().data();\n+            return output->flat<uint8_t>().data();\n           } else {\n-            return new uint8[buffer_size];\n+            return new uint8_t[buffer_size];\n           }\n         });\n \n@@ -327,20 +327,20 @@ class DecodeImageV2Op : public OpKernel {\n       return;\n     }\n     // Make sure we don't forget to deallocate `buffer`.\n-    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n+    std::unique_ptr<uint8_t[]> buffer_unique_ptr(buffer);\n \n     // Convert uint8 image data to desired data type.\n     // Use eigen threadpooling to speed up the copy operation.\n     const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n-    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n+    TTypes<uint8_t>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n     if (data_type_ == DataType::DT_UINT16) {\n-      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n-                           (std::numeric_limits<uint8>::max() + 1));\n+      uint16_t scale = floor((std::numeric_limits<uint16_t>::max() + 1) /\n+                             (std::numeric_limits<uint8_t>::max() + 1));\n       // Fill output tensor with desired dtype.\n-      output->flat<uint16>().device(device) =\n-          buffer_view.cast<uint16>() * scale;\n+      output->flat<uint16_t>().device(device) =\n+          buffer_view.cast<uint16_t>() * scale;\n     } else if (data_type_ == DataType::DT_FLOAT) {\n-      float scale = 1. / std::numeric_limits<uint8>::max();\n+      float scale = 1. / std::numeric_limits<uint8_t>::max();\n       // Fill output tensor with desired dtype.\n       output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n     }\n@@ -415,35 +415,35 @@ class DecodeImageV2Op : public OpKernel {\n       OP_REQUIRES(\n           context,\n           png::CommonFinishDecode(\n-              reinterpret_cast<png_bytep>(output->flat<uint8>().data()),\n-              decode.channels * width * sizeof(uint8), &decode),\n+              reinterpret_cast<png_bytep>(output->flat<uint8_t>().data()),\n+              decode.channels * width * sizeof(uint8_t), &decode),\n           errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n     } else if (data_type_ == DataType::DT_UINT16) {\n       OP_REQUIRES(\n           context,\n           png::CommonFinishDecode(\n-              reinterpret_cast<png_bytep>(output->flat<uint16>().data()),\n-              decode.channels * width * sizeof(uint16), &decode),\n+              reinterpret_cast<png_bytep>(output->flat<uint16_t>().data()),\n+              decode.channels * width * sizeof(uint16_t), &decode),\n           errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n     } else if (data_type_ == DataType::DT_FLOAT) {\n       // `png::CommonFinishDecode` does not support `float`. First allocate\n       // uint16 buffer for the image and decode in uint16 (lossless). Wrap the\n       // buffer in `unique_ptr` so that we don't forget to delete the buffer.\n-      std::unique_ptr<uint16[]> buffer(\n-          new uint16[height * width * decode.channels]);\n+      std::unique_ptr<uint16_t[]> buffer(\n+          new uint16_t[height * width * decode.channels]);\n       OP_REQUIRES(\n           context,\n           png::CommonFinishDecode(reinterpret_cast<png_bytep>(buffer.get()),\n-                                  decode.channels * width * sizeof(uint16),\n+                                  decode.channels * width * sizeof(uint16_t),\n                                   &decode),\n           errors::InvalidArgument(\"Invalid PNG data, size \", input.size()));\n \n       // Convert uint16 image data to desired data type.\n       // Use eigen threadpooling to speed up the copy operation.\n       const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n-      TTypes<uint16, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n-                                                  decode.channels);\n-      float scale = 1. / std::numeric_limits<uint16>::max();\n+      TTypes<uint16_t, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n+                                                    decode.channels);\n+      float scale = 1. / std::numeric_limits<uint16_t>::max();\n       // Fill output tensor with desired dtype.\n       output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n     }\n@@ -477,10 +477,10 @@ class DecodeImageV2Op : public OpKernel {\n     // uint8 only.\n     Tensor* output = nullptr;\n     int64_t buffer_size = 0;\n-    string error_string;\n-    uint8* buffer = gif::Decode(\n+    std::string error_string;\n+    uint8_t* buffer = gif::Decode(\n         input.data(), input.size(),\n-        [&](int num_frames, int width, int height, int channels) -> uint8* {\n+        [&](int num_frames, int width, int height, int channels) -> uint8_t* {\n           buffer_size =\n               static_cast<int64_t>(num_frames) * height * width * channels;\n \n@@ -515,9 +515,9 @@ class DecodeImageV2Op : public OpKernel {\n           }\n \n           if (data_type_ == DataType::DT_UINT8) {\n-            return output->flat<uint8>().data();\n+            return output->flat<uint8_t>().data();\n           } else {\n-            return new uint8[buffer_size];\n+            return new uint8_t[buffer_size];\n           }\n         },\n         &error_string, expand_animations_);\n@@ -532,20 +532,20 @@ class DecodeImageV2Op : public OpKernel {\n       return;\n     }\n     // Make sure we don't forget to deallocate `buffer`.\n-    std::unique_ptr<uint8[]> buffer_unique_ptr(buffer);\n+    std::unique_ptr<uint8_t[]> buffer_unique_ptr(buffer);\n \n     // Convert the raw uint8 buffer to desired dtype.\n     // Use eigen threadpooling to speed up the copy operation.\n-    TTypes<uint8>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n+    TTypes<uint8_t>::UnalignedConstFlat buffer_view(buffer, buffer_size);\n     const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n     if (data_type_ == DataType::DT_UINT16) {\n-      uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n-                           (std::numeric_limits<uint8>::max() + 1));\n+      uint16_t scale = floor((std::numeric_limits<uint16_t>::max() + 1) /\n+                             (std::numeric_limits<uint8_t>::max() + 1));\n       // Fill output tensor with desired dtype.\n-      output->flat<uint16>().device(device) =\n-          buffer_view.cast<uint16>() * scale;\n+      output->flat<uint16_t>().device(device) =\n+          buffer_view.cast<uint16_t>() * scale;\n     } else if (data_type_ == DataType::DT_FLOAT) {\n-      float scale = 1. / std::numeric_limits<uint8>::max();\n+      float scale = 1. / std::numeric_limits<uint8_t>::max();\n       // Fill output tensor with desired dtype.\n       output->flat<float>().device(device) = buffer_view.cast<float>() * scale;\n     }\n@@ -578,18 +578,18 @@ class DecodeImageV2Op : public OpKernel {\n                                         \"size, width, height, and bpp, got \",\n                                         input.size(), \" bytes\"));\n \n-    const uint8* img_bytes = reinterpret_cast<const uint8*>(input.data());\n+    const uint8_t* img_bytes = reinterpret_cast<const uint8_t*>(input.data());\n     int32_t header_size_ = internal::SubtleMustCopy(\n-        *(reinterpret_cast<const int32*>(img_bytes + 10)));\n+        *(reinterpret_cast<const int32_t*>(img_bytes + 10)));\n     const int32_t header_size = ByteSwapInt32ForBigEndian(header_size_);\n     int32_t width_ = internal::SubtleMustCopy(\n-        *(reinterpret_cast<const int32*>(img_bytes + 18)));\n+        *(reinterpret_cast<const int32_t*>(img_bytes + 18)));\n     const int32_t width = ByteSwapInt32ForBigEndian(width_);\n     int32_t height_ = internal::SubtleMustCopy(\n-        *(reinterpret_cast<const int32*>(img_bytes + 22)));\n+        *(reinterpret_cast<const int32_t*>(img_bytes + 22)));\n     const int32_t height = ByteSwapInt32ForBigEndian(height_);\n     int16_t bpp_ = internal::SubtleMustCopy(\n-        *(reinterpret_cast<const int16*>(img_bytes + 28)));\n+        *(reinterpret_cast<const int16_t*>(img_bytes + 28)));\n     const int16_t bpp = ByteSwapInt16ForBigEndian(bpp_);\n \n     // `channels_` is desired number of channels. `img_channels` is number of\n@@ -657,28 +657,29 @@ class DecodeImageV2Op : public OpKernel {\n         context->allocate_output(\n             0, TensorShape({abs_height, width, requested_channels}), &output));\n \n-    const uint8* bmp_pixels = &img_bytes[header_size];\n+    const uint8_t* bmp_pixels = &img_bytes[header_size];\n \n     if (data_type_ == DataType::DT_UINT8) {\n-      DecodeBMP(bmp_pixels, row_size, output->flat<uint8>().data(), width,\n+      DecodeBMP(bmp_pixels, row_size, output->flat<uint8_t>().data(), width,\n                 abs_height, requested_channels, img_channels, top_down);\n     } else {\n-      std::unique_ptr<uint8[]> buffer(\n-          new uint8[height * width * requested_channels]);\n+      std::unique_ptr<uint8_t[]> buffer(\n+          new uint8_t[height * width * requested_channels]);\n       DecodeBMP(bmp_pixels, row_size, buffer.get(), width, abs_height,\n                 requested_channels, img_channels, top_down);\n-      TTypes<uint8, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n-                                                 requested_channels);\n+      TTypes<uint8_t, 3>::UnalignedConstTensor buf(buffer.get(), height, width,\n+                                                   requested_channels);\n       // Convert the raw uint8 buffer to desired dtype.\n       // Use eigen threadpooling to speed up the copy operation.\n       const auto& device = context->eigen_device<Eigen::ThreadPoolDevice>();\n       if (data_type_ == DataType::DT_UINT16) {\n-        uint16 scale = floor((std::numeric_limits<uint16>::max() + 1) /\n-                             (std::numeric_limits<uint8>::max() + 1));\n+        uint16_t scale = floor((std::numeric_limits<uint16_t>::max() + 1) /\n+                               (std::numeric_limits<uint8_t>::max() + 1));\n         // Fill output tensor with desired dtype.\n-        output->tensor<uint16, 3>().device(device) = buf.cast<uint16>() * scale;\n+        output->tensor<uint16_t, 3>().device(device) =\n+            buf.cast<uint16_t>() * scale;\n       } else if (data_type_ == DataType::DT_FLOAT) {\n-        float scale = 1. / std::numeric_limits<uint8>::max();\n+        float scale = 1. / std::numeric_limits<uint8_t>::max();\n         // Fill output tensor with desired dtype.\n         output->tensor<float, 3>().device(device) = buf.cast<float>() * scale;\n       }\n@@ -724,7 +725,7 @@ class DecodeImageV2Op : public OpKernel {\n \n       // Actually decode the image into the output buffer.\n       OP_REQUIRES(context,\n-                  webp::DecodeWebPImage(input, output->flat<uint8>().data(),\n+                  webp::DecodeWebPImage(input, output->flat<uint8_t>().data(),\n                                         width, height, channels),\n                   errors::InvalidArgument(\"Failed to decode WebP image.\"));\n       // Note: Here we could also perform casting to other dtypes, but users can\n@@ -762,7 +763,7 @@ class DecodeImageV2Op : public OpKernel {\n             return nullptr;\n           }\n \n-          return output->flat<uint8>().data();\n+          return output->flat<uint8_t>().data();\n         },\n         &error_string, expand_animations_);\n \n@@ -773,15 +774,16 @@ class DecodeImageV2Op : public OpKernel {\n   }\n \n  private:\n-  void DecodeBMP(const uint8* input, const int row_size, uint8* const output,\n-                 const int width, const int height, const int output_channels,\n-                 const int input_channels, bool top_down);\n+  void DecodeBMP(const uint8_t* input, const int row_size,\n+                 uint8_t* const output, const int width, const int height,\n+                 const int output_channels, const int input_channels,\n+                 bool top_down);\n \n   int channels_ = 0;\n   DataType data_type_ = DataType::DT_UINT8;\n   bool expand_animations_ = true;\n   jpeg::UncompressFlags flags_;\n-  string op_type_;\n+  std::string op_type_;\n };\n \n REGISTER_KERNEL_BUILDER(Name(\"DecodeJpeg\").Device(DEVICE_CPU), DecodeImageV2Op);\n@@ -794,8 +796,8 @@ REGISTER_KERNEL_BUILDER(Name(\"DecodeImage\").Device(DEVICE_CPU),\n REGISTER_KERNEL_BUILDER(Name(\"DecodeBmp\").Device(DEVICE_CPU), DecodeImageV2Op);\n REGISTER_KERNEL_BUILDER(Name(\"DecodeWebP\").Device(DEVICE_CPU), DecodeImageV2Op);\n \n-void DecodeImageV2Op::DecodeBMP(const uint8* input, const int row_size,\n-                                uint8* const output, const int width,\n+void DecodeImageV2Op::DecodeBMP(const uint8_t* input, const int row_size,\n+                                uint8_t* const output, const int width,\n                                 const int height, const int output_channels,\n                                 const int input_channels, bool top_down) {\n   for (int i = 0; i < height; i++) {"
        },
        {
            "sha": "3ef479b9154bdd11ba0518fe712c155bed9a0f1e",
            "filename": "tensorflow/core/kernels/image/encode_jpeg_op.cc",
            "status": "modified",
            "additions": 29,
            "deletions": 27,
            "changes": 56,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -56,7 +56,7 @@ class EncodeJpegOp : public OpKernel {\n     OP_REQUIRES_OK(context, context->GetAttr(\"chroma_downsampling\",\n                                              &flags_.chroma_downsampling));\n \n-    string density_unit;\n+    std::string density_unit;\n     OP_REQUIRES_OK(context, context->GetAttr(\"density_unit\", &density_unit));\n     if (density_unit == \"in\") {\n       flags_.density_unit = 1;\n@@ -80,15 +80,15 @@ class EncodeJpegOp : public OpKernel {\n                 errors::InvalidArgument(\"image must be 3-dimensional\",\n                                         image.shape().DebugString()));\n \n-    OP_REQUIRES(\n-        context,\n-        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n-        errors::InvalidArgument(\n-            \"Cannot encode images with >= max int32 elements\"));\n+    OP_REQUIRES(context,\n+                FastBoundsCheck(image.NumElements(),\n+                                std::numeric_limits<int32_t>::max()),\n+                errors::InvalidArgument(\n+                    \"Cannot encode images with >= max int32 elements\"));\n \n-    const int32_t dim_size0 = static_cast<int32>(image.dim_size(0));\n-    const int32_t dim_size1 = static_cast<int32>(image.dim_size(1));\n-    const int32_t dim_size2 = static_cast<int32>(image.dim_size(2));\n+    const int32_t dim_size0 = static_cast<int32_t>(image.dim_size(0));\n+    const int32_t dim_size1 = static_cast<int32_t>(image.dim_size(1));\n+    const int32_t dim_size2 = static_cast<int32_t>(image.dim_size(2));\n \n     // Autodetect format if desired, otherwise make sure format and\n     // image channels are consistent.\n@@ -122,15 +122,16 @@ class EncodeJpegOp : public OpKernel {\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, TensorShape({}), &output));\n-    OP_REQUIRES(context,\n-                jpeg::Compress(image.flat<uint8>().data(), dim_size1, dim_size0,\n-                               adjusted_flags, &output->scalar<tstring>()()),\n-                errors::Internal(\"JPEG encoding failed\"));\n+    OP_REQUIRES(\n+        context,\n+        jpeg::Compress(image.flat<uint8_t>().data(), dim_size1, dim_size0,\n+                       adjusted_flags, &output->scalar<tstring>()()),\n+        errors::Internal(\"JPEG encoding failed\"));\n   }\n \n  private:\n-  string format_;\n-  string xmp_metadata_;  // Owns data referenced by flags_\n+  std::string format_;\n+  std::string xmp_metadata_;  // Owns data referenced by flags_\n   jpeg::CompressFlags flags_;\n };\n REGISTER_KERNEL_BUILDER(Name(\"EncodeJpeg\").Device(DEVICE_CPU), EncodeJpegOp);\n@@ -146,15 +147,15 @@ class EncodeJpegVariableQualityOp : public OpKernel {\n                 errors::InvalidArgument(\"image must be 3-dimensional\",\n                                         image.shape().DebugString()));\n \n-    OP_REQUIRES(\n-        context,\n-        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n-        errors::InvalidArgument(\n-            \"Cannot encode images with >= max int32 elements\"));\n+    OP_REQUIRES(context,\n+                FastBoundsCheck(image.NumElements(),\n+                                std::numeric_limits<int32_t>::max()),\n+                errors::InvalidArgument(\n+                    \"Cannot encode images with >= max int32 elements\"));\n \n-    const int32_t dim_size0 = static_cast<int32>(image.dim_size(0));\n-    const int32_t dim_size1 = static_cast<int32>(image.dim_size(1));\n-    const int32_t dim_size2 = static_cast<int32>(image.dim_size(2));\n+    const int32_t dim_size0 = static_cast<int32_t>(image.dim_size(0));\n+    const int32_t dim_size1 = static_cast<int32_t>(image.dim_size(1));\n+    const int32_t dim_size2 = static_cast<int32_t>(image.dim_size(2));\n \n     // Use default jpeg compression flags except for format and quality.\n     jpeg::CompressFlags adjusted_flags;\n@@ -188,10 +189,11 @@ class EncodeJpegVariableQualityOp : public OpKernel {\n     Tensor* output = nullptr;\n     OP_REQUIRES_OK(context,\n                    context->allocate_output(0, TensorShape({}), &output));\n-    OP_REQUIRES(context,\n-                jpeg::Compress(image.flat<uint8>().data(), dim_size1, dim_size0,\n-                               adjusted_flags, &output->scalar<tstring>()()),\n-                errors::Internal(\"JPEG encoding failed\"));\n+    OP_REQUIRES(\n+        context,\n+        jpeg::Compress(image.flat<uint8_t>().data(), dim_size1, dim_size0,\n+                       adjusted_flags, &output->scalar<tstring>()()),\n+        errors::Internal(\"JPEG encoding failed\"));\n   }\n };\n REGISTER_KERNEL_BUILDER(Name(\"EncodeJpegVariableQuality\").Device(DEVICE_CPU),"
        },
        {
            "sha": "c52685ccea043ac9eb7ca05d9752c993eb93aa65",
            "filename": "tensorflow/core/kernels/image/encode_jpeg_op_test.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_jpeg_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -35,9 +35,9 @@ TEST_F(EncodeJpegWithVariableQualityTest, FailsForInvalidQuality) {\n                    .Finalize(node_def()));\n   TF_ASSERT_OK(InitOp());\n \n-  AddInputFromArray<uint8>(TensorShape({2, 2, 3}),\n-                           {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n-  AddInputFromArray<int32>(TensorShape({}), {200});\n+  AddInputFromArray<uint8_t>(TensorShape({2, 2, 3}),\n+                             {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11});\n+  AddInputFromArray<int32_t>(TensorShape({}), {200});\n   absl::Status status = RunOpKernel();\n   EXPECT_TRUE(absl::IsInvalidArgument(status));\n   EXPECT_TRUE(absl::StartsWith(status.message(), \"quality must be in [0,100]\"));"
        },
        {
            "sha": "ebf7527302ac9a9eaab7d468e068718b3ce761a0",
            "filename": "tensorflow/core/kernels/image/encode_png_op.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_png_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_png_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fencode_png_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -67,16 +67,18 @@ class EncodePngOp : public OpKernel {\n                 errors::Internal(\"Invalid image provided.\"));\n     OP_REQUIRES(\n         context,\n-        FastBoundsCheck(image.NumElements(), std::numeric_limits<int32>::max()),\n+        FastBoundsCheck(image.NumElements(),\n+                        std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\"image cannot have >= int32 max elements\"));\n \n     const int batch_dims = image.dims() - 3;\n-    const int32_t height = static_cast<int32>(image.dim_size(batch_dims));\n-    const int32_t width = static_cast<int32>(image.dim_size(batch_dims + 1));\n-    const int32_t channels = static_cast<int32>(image.dim_size(batch_dims + 2));\n+    const int32_t height = static_cast<int32_t>(image.dim_size(batch_dims));\n+    const int32_t width = static_cast<int32_t>(image.dim_size(batch_dims + 1));\n+    const int32_t channels =\n+        static_cast<int32_t>(image.dim_size(batch_dims + 2));\n \n     // In some cases, we pass width*channels*2 to png.\n-    const int32_t max_row_width = std::numeric_limits<int32>::max() / 2;\n+    const int32_t max_row_width = std::numeric_limits<int32_t>::max() / 2;\n \n     OP_REQUIRES(context, FastBoundsCheck(width * channels, max_row_width),\n                 errors::InvalidArgument(\"image too wide to encode\"));"
        },
        {
            "sha": "dc9739123ca1f867ffcde91020205d0215712f90",
            "filename": "tensorflow/core/kernels/image/extract_image_patches_op.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_image_patches_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_image_patches_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_image_patches_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -41,8 +41,8 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n typedef Eigen::GpuDevice GPUDevice;\n \n static inline void ParseAttributeVec4(OpKernelConstruction* context,\n-                                      const string& attr_name,\n-                                      std::vector<int32>* attr) {\n+                                      const std::string& attr_name,\n+                                      std::vector<int32_t>* attr) {\n   OP_REQUIRES_OK(context, context->GetAttr(attr_name, attr));\n   OP_REQUIRES(\n       context, (*attr)[0] == 1 && (*attr)[3] == 1,\n@@ -115,9 +115,9 @@ class ExtractImagePatchesOp : public UnaryOp<T> {\n   }\n \n  private:\n-  std::vector<int32> ksizes_;\n-  std::vector<int32> strides_;\n-  std::vector<int32> rates_;\n+  std::vector<int32_t> ksizes_;\n+  std::vector<int32_t> strides_;\n+  std::vector<int32_t> rates_;\n \n   Padding padding_;\n "
        },
        {
            "sha": "0db3ca43ad36d8795d546c8ae35a458652870360",
            "filename": "tensorflow/core/kernels/image/extract_volume_patches_op.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_volume_patches_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_volume_patches_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fextract_volume_patches_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -46,8 +46,8 @@ typedef Eigen::ThreadPoolDevice CPUDevice;\n typedef Eigen::GpuDevice GPUDevice;\n \n static inline void ParseAttributeVec5(OpKernelConstruction* context,\n-                                      const string& attr_name,\n-                                      std::vector<int32>* attr) {\n+                                      const std::string& attr_name,\n+                                      std::vector<int32_t>* attr) {\n   OP_REQUIRES_OK(context, context->GetAttr(attr_name, attr));\n   OP_REQUIRES(\n       context, (*attr)[0] == 1 && (*attr)[4] == 1,\n@@ -143,8 +143,8 @@ class ExtractVolumePatchesOp : public UnaryOp<T> {\n   }\n \n  private:\n-  std::vector<int32> ksizes_;\n-  std::vector<int32> strides_;\n+  std::vector<int32_t> ksizes_;\n+  std::vector<int32_t> strides_;\n   // std::vector<int32> rates_;\n \n   Padding padding_;"
        },
        {
            "sha": "9dd1e907e94cde2afc089be281d7dd6aba888469",
            "filename": "tensorflow/core/kernels/image/image_ops.cc",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fimage_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fimage_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fimage_ops.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -75,7 +75,7 @@ void DoImageProjectiveTransformOp(OpKernelContext* ctx,\n     OP_REQUIRES(ctx, shape_t.NumElements() == 2,\n                 errors::InvalidArgument(\"output shape must have two elements\",\n                                         shape_t.shape().DebugString()));\n-    auto shape_vec = shape_t.vec<int32>();\n+    auto shape_vec = shape_t.vec<int32_t>();\n     out_height = shape_vec(0);\n     out_width = shape_vec(1);\n     OP_REQUIRES(ctx, out_height > 0 && out_width > 0,\n@@ -121,7 +121,7 @@ class ImageProjectiveTransformV2 : public OpKernel {\n  public:\n   explicit ImageProjectiveTransformV2(OpKernelConstruction* ctx)\n       : OpKernel(ctx) {\n-    string interpolation_str;\n+    std::string interpolation_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"interpolation\", &interpolation_str));\n     if (interpolation_str == \"NEAREST\") {\n       interpolation_ = Interpolation::NEAREST;\n@@ -131,7 +131,7 @@ class ImageProjectiveTransformV2 : public OpKernel {\n       LOG(ERROR) << \"Invalid interpolation \" << interpolation_str\n                  << \". Supported types: NEAREST, BILINEAR\";\n     }\n-    string mode_str;\n+    std::string mode_str;\n     OP_REQUIRES_OK(ctx, ctx->GetAttr(\"fill_mode\", &mode_str));\n     if (mode_str == \"REFLECT\") {\n       fill_mode_ = Mode::FILL_REFLECT;"
        },
        {
            "sha": "0bdf9ad6961b70250c3c54728dd8f2852d1c98c7",
            "filename": "tensorflow/core/kernels/image/mirror_pad_op.h",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op.h?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -343,13 +343,13 @@ namespace functor {\n template <typename Device, typename T, typename Tpaddings, int Dims>\n struct MirrorPad {\n   void operator()(const Device& device,\n-                  typename TTypes<T, Dims, int32>::Tensor output,\n-                  typename TTypes<T, Dims, int32>::ConstTensor input,\n+                  typename TTypes<T, Dims, int32_t>::Tensor output,\n+                  typename TTypes<T, Dims, int32_t>::ConstTensor input,\n                   typename TTypes<Tpaddings>::ConstMatrix padding, int offset) {\n-    Eigen::array<Eigen::IndexPair<int32>, Dims> padding_dims;\n+    Eigen::array<Eigen::IndexPair<int32_t>, Dims> padding_dims;\n \n     for (int i = 0; i < Dims; ++i) {\n-      padding_dims[i] = Eigen::IndexPair<int32>(padding(i, 0), padding(i, 1));\n+      padding_dims[i] = Eigen::IndexPair<int32_t>(padding(i, 0), padding(i, 1));\n     }\n \n     output.device(device) = MirrorPadOp(input, padding_dims, offset);\n@@ -370,16 +370,16 @@ struct MirrorPad {\n template <typename Device, typename T, typename Tpaddings, int Dims>\n struct MirrorPadGrad {\n   void operator()(const Device& device,\n-                  typename TTypes<T, Dims, int32>::Tensor output,\n-                  typename TTypes<T, Dims, int32>::ConstTensor input,\n+                  typename TTypes<T, Dims, int32_t>::Tensor output,\n+                  typename TTypes<T, Dims, int32_t>::ConstTensor input,\n                   typename TTypes<Tpaddings>::ConstMatrix paddings, int offset,\n-                  typename TTypes<T, Dims, int32>::Tensor scratch) {\n+                  typename TTypes<T, Dims, int32_t>::Tensor scratch) {\n     // Copy the gradient input into the scratch buffer.\n     scratch.device(device) = input;\n \n-    Eigen::array<int32, Dims> lhs_offsets;\n-    Eigen::array<int32, Dims> rhs_offsets;\n-    Eigen::array<int32, Dims> extents;\n+    Eigen::array<int32_t, Dims> lhs_offsets;\n+    Eigen::array<int32_t, Dims> rhs_offsets;\n+    Eigen::array<int32_t, Dims> extents;\n     Eigen::array<bool, Dims> reverses;\n \n     for (int i = 0; i < Dims; ++i) {"
        },
        {
            "sha": "94b8dc0697b6e6cd2b47b452cce2e456da8871d3",
            "filename": "tensorflow/core/kernels/image/mirror_pad_op_test.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 16,
            "changes": 32,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fmirror_pad_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -34,7 +34,7 @@ namespace tensorflow {\n class MirrorPadOpTest : public OpsTestBase {\n  protected:\n   template <typename T>\n-  void MakeOp(const string& mode) {\n+  void MakeOp(const std::string& mode) {\n     TF_EXPECT_OK(NodeDefBuilder(\"mirror_pad_op\", \"MirrorPad\")\n                      .Input(FakeInput(DataTypeToEnum<T>::value))\n                      .Input(FakeInput(DT_INT32))\n@@ -79,11 +79,11 @@ REGISTER_TEST(double)\n REGISTER_TEST(quint8)\n REGISTER_TEST(qint8)\n REGISTER_TEST(qint32)\n-REGISTER_TEST(uint8)\n-REGISTER_TEST(uint16)\n-REGISTER_TEST(int8)\n-REGISTER_TEST(int16)\n-REGISTER_TEST(int32)\n+REGISTER_TEST(uint8_t)\n+REGISTER_TEST(uint16_t)\n+REGISTER_TEST(int8_t)\n+REGISTER_TEST(int16_t)\n+REGISTER_TEST(int32_t)\n REGISTER_TEST(int64_t)\n \n #undef REGISTER_TEST\n@@ -102,8 +102,8 @@ TEST_F(MirrorPadOpTest, TestMirrorPadReflectLargeInput) {\n   //  0, 1, 2, ..., 999\n   AddInput<float>(TensorShape({1, kInput, kInput, 1}),\n                   [=](int i) -> float { return i % kInput; });\n-  AddInputFromArray<int32>(TensorShape({4, 2}),\n-                           {0, 0, kPad, kPad, kPad, kPad, 0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({4, 2}),\n+                             {0, 0, kPad, kPad, kPad, kPad, 0, 0});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, kOutput, kOutput, 1}));\n@@ -136,8 +136,8 @@ TEST_F(MirrorPadOpTest, TestMirrorPadSymmetricLargeInput) {\n   //  0, 1, 2, ..., 999\n   AddInput<float>(TensorShape({1, kInput, kInput, 1}),\n                   [=](int i) -> float { return i % kInput; });\n-  AddInputFromArray<int32>(TensorShape({4, 2}),\n-                           {0, 0, kPad, kPad, kPad, kPad, 0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({4, 2}),\n+                             {0, 0, kPad, kPad, kPad, kPad, 0, 0});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, kOutput, kOutput, 1}));\n@@ -159,7 +159,7 @@ TEST_F(MirrorPadOpTest, TestMirrorPadSymmetricLargeInput) {\n class MirrorPadGradOpTest : public OpsTestBase {\n  protected:\n   template <typename T>\n-  void MakeOp(const string& mode) {\n+  void MakeOp(const std::string& mode) {\n     TF_EXPECT_OK(NodeDefBuilder(\"mirror_pad_grad_op\", \"MirrorPadGrad\")\n                      .Input(FakeInput(DataTypeToEnum<T>::value))\n                      .Input(FakeInput(DT_INT32))\n@@ -196,11 +196,11 @@ class MirrorPadGradOpTest : public OpsTestBase {\n \n REGISTER_TEST(float)\n REGISTER_TEST(double)\n-REGISTER_TEST(uint8)\n-REGISTER_TEST(uint16)\n-REGISTER_TEST(int8)\n-REGISTER_TEST(int16)\n-REGISTER_TEST(int32)\n+REGISTER_TEST(uint8_t)\n+REGISTER_TEST(uint16_t)\n+REGISTER_TEST(int8_t)\n+REGISTER_TEST(int16_t)\n+REGISTER_TEST(int32_t)\n REGISTER_TEST(int64_t)\n \n #undef REGISTER_TEST"
        },
        {
            "sha": "012c9bf0f8f926346577cbee9ca254453fa0da7e",
            "filename": "tensorflow/core/kernels/image/non_max_suppression_op.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fnon_max_suppression_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -822,7 +822,7 @@ class NonMaxSuppressionV4Op : public OpKernel {\n     Tensor* num_outputs_t = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(\n                                 1, tensorflow::TensorShape{}, &num_outputs_t));\n-    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);\n+    num_outputs_t->scalar<int32_t>().setConstant(num_valid_outputs);\n   }\n \n  private:\n@@ -902,7 +902,7 @@ class NonMaxSuppressionV5Op : public OpKernel {\n     Tensor* num_outputs_t = nullptr;\n     OP_REQUIRES_OK(context, context->allocate_output(\n                                 2, tensorflow::TensorShape{}, &num_outputs_t));\n-    num_outputs_t->scalar<int32>().setConstant(num_valid_outputs);\n+    num_outputs_t->scalar<int32_t>().setConstant(num_valid_outputs);\n   }\n \n  private:"
        },
        {
            "sha": "af4db8cd3c18d8f3f2a2736c25b4365264a6de8e",
            "filename": "tensorflow/core/kernels/image/resize_area_op_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_area_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_area_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_area_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -152,7 +152,7 @@ class ResizeAreaOpTest : public OpsTestBase {\n                      int target_width, int channels) {\n     const Tensor* input =\n         SetRandomImageInput(TensorShape({1, in_height, in_width, channels}));\n-    AddInputFromArray<int32>(TensorShape({2}), {target_height, target_width});\n+    AddInputFromArray<int32_t>(TensorShape({2}), {target_height, target_width});\n \n     TF_ASSERT_OK(RunOpKernel());\n     std::unique_ptr<Tensor> expected("
        },
        {
            "sha": "366f7e284fd27920cc4ac7fd3b96be2c5d5457b7",
            "filename": "tensorflow/core/kernels/image/resize_bicubic_op_test.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bicubic_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bicubic_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bicubic_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -173,7 +173,7 @@ class ResizeBicubicOpTest : public OpsTestBase {\n               << \"x\" << channels;\n     const Tensor* input = SetRandomImageInput(\n         TensorShape({batch_size, in_height, in_width, channels}));\n-    AddInputFromArray<int32>(TensorShape({2}), {target_height, target_width});\n+    AddInputFromArray<int32_t>(TensorShape({2}), {target_height, target_width});\n \n     TF_ASSERT_OK(RunOpKernel());\n \n@@ -213,7 +213,7 @@ TEST_F(ResizeBicubicOpTest, TestBicubic2x2To1x1) {\n   // 1, 2\n   // 3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // When scaling down, we have to arbitrarily pick a pixel from the\n@@ -225,7 +225,7 @@ TEST_F(ResizeBicubicOpTest, TestBicubic2x2To1x1) {\n \n TEST_F(ResizeBicubicOpTest, TestBicubic2x2To0x0) {\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n \n   absl::Status s = RunOpKernel();\n   EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n@@ -267,7 +267,7 @@ static Graph* ResizeBicubic(int batch_size, int size, int channels,\n   Tensor input(DT_FLOAT, TensorShape({batch_size, size, size, channels}));\n   input.flat<float>().setRandom();\n   Tensor shape(DT_INT32, TensorShape({2}));\n-  auto shape_t = shape.flat<int32>();\n+  auto shape_t = shape.flat<int32_t>();\n   shape_t(0) = scale_y * size;\n   shape_t(1) = scale_x * size;\n   test::graph::Binary(g, \"ResizeBicubic\", test::graph::Constant(g, input),"
        },
        {
            "sha": "87da8432435aae8a94a181236cc437adfd17544c",
            "filename": "tensorflow/core/kernels/image/resize_bilinear_op_test.cc",
            "status": "modified",
            "additions": 19,
            "deletions": 19,
            "changes": 38,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_bilinear_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -137,7 +137,7 @@ class ResizeBilinearOpTestBase\n                   int channels, int output_width, int output_height) {\n     const TensorShape shape({batch_size, input_width, input_height, channels});\n     const Tensor* input = SetRandomImageInput(shape);\n-    AddInputFromArray<int32>(TensorShape({2}), {output_width, output_height});\n+    AddInputFromArray<int32_t>(TensorShape({2}), {output_width, output_height});\n     TF_ASSERT_OK(RunOpKernel());\n \n     std::unique_ptr<Tensor> expected(new Tensor(\n@@ -199,7 +199,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To1x1) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // When scaling down, we have to arbitrarily pick a pixel from the\n@@ -211,7 +211,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To1x1) {\n \n TEST_P(ResizeBilinearOpTest, TestBilinearRandom2x2To1x1) {\n   const Tensor* input = SetRandomImageInput(TensorShape({1, 2, 2, 1}));\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // When scaling down, we have to arbitrarily pick a pixel from the\n@@ -230,7 +230,7 @@ TEST_P(ResizeBilinearOpAlignCornersTest, TestBilinearAlignCorners2x2To1x1) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   // When scaling down, we have to arbitrarily pick a pixel from the\n@@ -245,7 +245,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To3x3) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -265,7 +265,7 @@ TEST_P(ResizeBilinearOpAlignCornersTest, TestBilinearAlignCorners2x2To3x3) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -290,7 +290,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear3x3To2x2) {\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -311,7 +311,7 @@ TEST_P(ResizeBilinearOpAlignCornersTest, TestBilinearAlignCorners3x3To2x2) {\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -332,7 +332,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear3x3To4x4) {\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 4, 4, 1}));\n@@ -356,7 +356,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear4x4To3x3) {\n   AddInputFromArray<float>(\n       TensorShape({1, 4, 4, 1}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -388,7 +388,7 @@ TEST_P(ResizeBilinearOpAlignCornersTest, TestBilinearAlignCorners4x4To3x3) {\n   AddInputFromArray<float>(\n       TensorShape({1, 4, 4, 1}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -410,7 +410,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To3x3Batch2) {\n   //\n   // repeated twice\n   AddInputFromArray<float>(TensorShape({2, 2, 2, 1}), {1, 2, 3, 4, 1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 3, 3, 1}));\n@@ -426,7 +426,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To3x3Batch2) {\n TEST_P(ResizeBilinearOpTest, TestBilinear2x2x2To3x3x2) {\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 2}),\n                            {1, -1, 2, -2, 3, -3, 4, -4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 2}));\n@@ -452,7 +452,7 @@ TEST_P(ResizeBilinearOpTest, TestBilinear2x2To4x4) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 4, 4, 1}));\n@@ -492,7 +492,7 @@ TEST_P(ResizeBilinearOpTest, Test6_3c) { TestResize(1, 304, 303, 3, 299, 299); }\n \n TEST_P(ResizeBilinearOpTest, TestInvalidOutputSize) {\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {0, 0});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {0, 0});\n   absl::Status s = RunOpKernel();\n   EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n   EXPECT_TRUE(\n@@ -502,7 +502,7 @@ TEST_P(ResizeBilinearOpTest, TestInvalidOutputSize) {\n \n TEST_P(ResizeBilinearOpTest, TestInvalidInputShape) {\n   AddInputFromArray<float>(TensorShape({2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   absl::Status s = RunOpKernel();\n   EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n   EXPECT_TRUE(absl::StrContains(s.message(), \"input must be 4-dimensional\"))\n@@ -511,7 +511,7 @@ TEST_P(ResizeBilinearOpTest, TestInvalidInputShape) {\n \n TEST_P(ResizeBilinearOpTest, TestInvalidSizeDim) {\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2, 1}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2, 1}), {4, 4});\n   absl::Status s = RunOpKernel();\n   EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n   EXPECT_TRUE(absl::StrContains(s.message(), \"shape_t must be 1-dimensional\"))\n@@ -520,7 +520,7 @@ TEST_P(ResizeBilinearOpTest, TestInvalidSizeDim) {\n \n TEST_P(ResizeBilinearOpTest, TestInvalidSizeElements) {\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({3}), {4, 4, 1});\n+  AddInputFromArray<int32_t>(TensorShape({3}), {4, 4, 1});\n   absl::Status s = RunOpKernel();\n   EXPECT_EQ(s.code(), error::INVALID_ARGUMENT);\n   EXPECT_TRUE(absl::StrContains(s.message(), \"shape_t must have two elements\"))\n@@ -562,7 +562,7 @@ class ResizeBM : public ResizeBilinearOpTest {\n     const TensorShape shape(\n         {/*batch_size*/ 1, input_width, input_height, num_channels});\n     SetRandomImageInput(shape);\n-    AddInputFromArray<int32>(TensorShape({2}), {output_width, output_height});\n+    AddInputFromArray<int32_t>(TensorShape({2}), {output_width, output_height});\n   }\n \n   using ResizeBilinearOpTest::RunOpKernel;"
        },
        {
            "sha": "7dfe9f2cefd2e205a52ba02057ed328e9d7eeca0",
            "filename": "tensorflow/core/kernels/image/resize_nearest_neighbor_op.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -236,7 +236,7 @@ class ResizeNearestNeighborOpGrad : public OpKernel {\n                 errors::InvalidArgument(\"shape_t must have two elements\",\n                                         shape_t.shape().DebugString()));\n \n-    auto sizes = shape_t.vec<int32>();\n+    auto sizes = shape_t.vec<int32_t>();\n     OP_REQUIRES(context, sizes(0) > 0 && sizes(1) > 0,\n                 errors::InvalidArgument(\"shape_t's elements must be positive\"));\n "
        },
        {
            "sha": "9367253f356707a6a0f11c55ca046c9d931a31e9",
            "filename": "tensorflow/core/kernels/image/resize_nearest_neighbor_op_test.cc",
            "status": "modified",
            "additions": 21,
            "deletions": 21,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_nearest_neighbor_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -101,7 +101,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2To1x1) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -119,7 +119,7 @@ TEST_P(ResizeNearestNeighborOpAlignCornersTest,\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -136,7 +136,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2To3x3) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -157,7 +157,7 @@ TEST_P(ResizeNearestNeighborOpAlignCornersTest,\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -179,7 +179,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest3x3To2x2) {\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -201,7 +201,7 @@ TEST_P(ResizeNearestNeighborOpAlignCornersTest,\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -220,7 +220,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2To2x5) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 5});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 5});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 5, 1}));\n@@ -243,7 +243,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearestNeighbor4x4To3x3) {\n   AddInputFromArray<float>(\n       TensorShape({1, 4, 4, 1}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -268,7 +268,7 @@ TEST_P(ResizeNearestNeighborOpAlignCornersTest,\n   AddInputFromArray<float>(\n       TensorShape({1, 4, 4, 1}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -288,7 +288,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2To5x2) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {5, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {5, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 5, 2, 1}));\n@@ -310,7 +310,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2To4x4) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 4, 4, 1}));\n@@ -334,7 +334,7 @@ TEST_P(ResizeNearestNeighborOpTest, TestNearest2x2x2x2To2x3x3x2) {\n   //    [ 7, 7 ], [ 8, 8] ]\n   AddInputFromArray<float>(TensorShape({2, 2, 2, 2}),\n                            {1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 3, 3, 2}));\n@@ -364,7 +364,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest5x2To2x2) {\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 5, 1}),\n                            {1, 2, 3, 4, 5, 1, 2, 3, 4, 5});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -381,7 +381,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest2x2To1x1) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {1, 1});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {1, 1});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 1, 1, 1}));\n@@ -398,7 +398,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest2x2To3x3) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -420,7 +420,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest3x3To2x2) {\n   //  7, 8, 9\n   AddInputFromArray<float>(TensorShape({1, 3, 3, 1}),\n                            {1, 2, 3, 4, 5, 6, 7, 8, 9});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 2, 1}));\n@@ -439,7 +439,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest2x2To2x5) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {2, 5});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {2, 5});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 2, 5, 1}));\n@@ -463,7 +463,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest,\n   AddInputFromArray<float>(\n       TensorShape({1, 4, 4, 1}),\n       {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 3, 3, 1}));\n@@ -483,7 +483,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest2x2To5x2) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {5, 2});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {5, 2});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 5, 2, 1}));\n@@ -505,7 +505,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest, TestNearest2x2To4x4) {\n   //  1, 2\n   //  3, 4\n   AddInputFromArray<float>(TensorShape({1, 2, 2, 1}), {1, 2, 3, 4});\n-  AddInputFromArray<int32>(TensorShape({2}), {4, 4});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {4, 4});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({1, 4, 4, 1}));\n@@ -530,7 +530,7 @@ TEST_P(ResizeNearestNeighborHalfPixelCentersOpTest,\n   //    [ 7, 7 ], [ 8, 8] ]\n   AddInputFromArray<float>(TensorShape({2, 2, 2, 2}),\n                            {1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8});\n-  AddInputFromArray<int32>(TensorShape({2}), {3, 3});\n+  AddInputFromArray<int32_t>(TensorShape({2}), {3, 3});\n   TF_ASSERT_OK(RunOpKernel());\n \n   Tensor expected(allocator(), DT_FLOAT, TensorShape({2, 3, 3, 2}));"
        },
        {
            "sha": "852d31f96f7ca6c5a7c8ae8d71c7e7b7aca89444",
            "filename": "tensorflow/core/kernels/image/resize_op_benchmark_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_op_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_op_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fresize_op_benchmark_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -28,7 +28,7 @@ static Graph* Resize(const char* algorithm, int batches, int width,\n   in.flat<float>().setRandom();\n \n   Tensor out_size(DT_INT32, TensorShape({2}));\n-  auto out_size_flat = out_size.flat<int32>();\n+  auto out_size_flat = out_size.flat<int32_t>();\n   out_size_flat(0) = width * 2;\n   out_size_flat(1) = height * 2;\n "
        },
        {
            "sha": "42804ea06e129f1d7da5b32619b65d8863423cfe",
            "filename": "tensorflow/core/kernels/image/sample_distorted_bounding_box_op.cc",
            "status": "modified",
            "additions": 16,
            "deletions": 13,
            "changes": 29,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsample_distorted_bounding_box_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsample_distorted_bounding_box_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsample_distorted_bounding_box_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -270,16 +270,19 @@ class SampleDistortedBoundingBoxBaseOp : public OpKernel {\n                                         image_size.shape().DebugString()));\n \n     // Note image_size_data(2) is the depth and unused.\n-    const uint64 height_raw = internal::SubtleMustCopy(image_size.flat<T>()(0));\n-    const uint64 width_raw = internal::SubtleMustCopy(image_size.flat<T>()(1));\n-    OP_REQUIRES(context,\n-                FastBoundsCheck(height_raw, std::numeric_limits<int32>::max()),\n-                errors::InvalidArgument(\"image height cannot be >= int32 max\"));\n+    const uint64_t height_raw =\n+        internal::SubtleMustCopy(image_size.flat<T>()(0));\n+    const uint64_t width_raw =\n+        internal::SubtleMustCopy(image_size.flat<T>()(1));\n+    OP_REQUIRES(\n+        context,\n+        FastBoundsCheck(height_raw, std::numeric_limits<int32_t>::max()),\n+        errors::InvalidArgument(\"image height cannot be >= int32 max\"));\n     OP_REQUIRES(context,\n-                FastBoundsCheck(width_raw, std::numeric_limits<int32>::max()),\n+                FastBoundsCheck(width_raw, std::numeric_limits<int32_t>::max()),\n                 errors::InvalidArgument(\"image width cannot be >= int32 max\"));\n-    const int32_t height = static_cast<int32>(height_raw);\n-    const int32_t width = static_cast<int32>(width_raw);\n+    const int32_t height = static_cast<int32_t>(height_raw);\n+    const int32_t width = static_cast<int32_t>(width_raw);\n \n     // Ensure that the supplied bounding boxes are sane and convert them to\n     // Rectangles.\n@@ -328,10 +331,10 @@ class SampleDistortedBoundingBoxBaseOp : public OpKernel {\n                                       boxes(b, i)));\n         }\n \n-        const int32_t x_min = static_cast<int32>(boxes(b, 1) * width);\n-        const int32_t y_min = static_cast<int32>(boxes(b, 0) * height);\n-        const int32_t x_max = static_cast<int32>(boxes(b, 3) * width);\n-        const int32_t y_max = static_cast<int32>(boxes(b, 2) * height);\n+        const int32_t x_min = static_cast<int32_t>(boxes(b, 1) * width);\n+        const int32_t y_min = static_cast<int32_t>(boxes(b, 0) * height);\n+        const int32_t x_max = static_cast<int32_t>(boxes(b, 3) * width);\n+        const int32_t y_max = static_cast<int32_t>(boxes(b, 2) * height);\n \n         bounding_boxes.push_back(Rectangle(x_min, y_min, x_max, y_max));\n       }\n@@ -432,7 +435,7 @@ class SampleDistortedBoundingBoxBaseOp : public OpKernel {\n   }\n \n  protected:\n-  int32 max_attempts_;\n+  int32_t max_attempts_;\n   std::vector<float> area_range_;\n   std::vector<float> aspect_ratio_range_;\n   float min_object_covered_;"
        },
        {
            "sha": "c72e206f4e424c8960092edf2a1a68e4b0a8af6c",
            "filename": "tensorflow/core/kernels/image/sampling_kernels.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsampling_kernels.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsampling_kernels.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fsampling_kernels.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -24,7 +24,7 @@ namespace tensorflow {\n namespace functor {\n \n SamplingKernelType SamplingKernelTypeFromString(const absl::string_view str) {\n-  const string lower_case = absl::AsciiStrToLower(str);\n+  const std::string lower_case = absl::AsciiStrToLower(str);\n   if (lower_case == \"lanczos1\") return Lanczos1Kernel;\n   if (lower_case == \"lanczos3\") return Lanczos3Kernel;\n   if (lower_case == \"lanczos5\") return Lanczos5Kernel;"
        },
        {
            "sha": "edd6ef09b3a8f4723c1518bb276d3c06b6655488",
            "filename": "tensorflow/core/kernels/image/scale_and_translate_op.cc",
            "status": "modified",
            "additions": 24,
            "deletions": 23,
            "changes": 47,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -70,7 +70,7 @@ absl::Status ComputeSpansCore(OpKernelContext* context, const Kernel& kernel,\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n       tensorflow::DT_INT32, tensorflow::TensorShape({output_size}),\n       &spans->starts, alloc_attr));\n-  auto starts_vec = spans->starts.vec<int32>();\n+  auto starts_vec = spans->starts.vec<int32_t>();\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n       tensorflow::DT_FLOAT,\n       tensorflow::TensorShape({spans->span_size * output_size}),\n@@ -135,7 +135,7 @@ absl::Status ComputeGradSpansCore(OpKernelContext* context, const Spans& spans,\n   };\n   std::vector<std::vector<GradComponent>> grad_components(forward_input_size);\n   auto weights_vec = spans.weights.vec<float>();\n-  auto starts_vec = spans.starts.vec<int32>();\n+  auto starts_vec = spans.starts.vec<int32_t>();\n   for (int output_index = 0; output_index < forward_output_size;\n        ++output_index) {\n     int input_index = starts_vec(output_index);\n@@ -163,7 +163,7 @@ absl::Status ComputeGradSpansCore(OpKernelContext* context, const Spans& spans,\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n       tensorflow::DT_INT32, tensorflow::TensorShape({forward_input_size}),\n       &grad_spans->starts, alloc_attr));\n-  auto grad_starts_vec = grad_spans->starts.vec<int32>();\n+  auto grad_starts_vec = grad_spans->starts.vec<int32_t>();\n   TF_RETURN_IF_ERROR(context->allocate_temp(\n       tensorflow::DT_FLOAT,\n       tensorflow::TensorShape({grad_spans->span_size * forward_input_size}),\n@@ -273,7 +273,7 @@ class ScaleAndTranslateOp : public OpKernel {\n   explicit ScaleAndTranslateOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"antialias\", &antialias_));\n-    string kernel_type_str;\n+    std::string kernel_type_str;\n     OP_REQUIRES_OK(context, context->GetAttr(\"kernel_type\", &kernel_type_str));\n     kernel_type_ = functor::SamplingKernelTypeFromString(kernel_type_str);\n     OP_REQUIRES(context, kernel_type_ != functor::SamplingKernelTypeEnd,\n@@ -293,15 +293,16 @@ class ScaleAndTranslateOp : public OpKernel {\n     OP_REQUIRES(context, output_shape_t.NumElements() == 2,\n                 errors::InvalidArgument(\"output_shape_t must have two elements\",\n                                         output_shape_t.shape().DebugString()));\n-    auto output_shape_vec = output_shape_t.vec<int32>();\n+    auto output_shape_vec = output_shape_t.vec<int32_t>();\n     const int64_t output_height = internal::SubtleMustCopy(output_shape_vec(0));\n     const int64_t output_width = internal::SubtleMustCopy(output_shape_vec(1));\n \n     OP_REQUIRES(\n         context,\n-        FastBoundsCheck(input.dim_size(1), std::numeric_limits<int32>::max()) &&\n+        FastBoundsCheck(input.dim_size(1),\n+                        std::numeric_limits<int32_t>::max()) &&\n             FastBoundsCheck(input.dim_size(2),\n-                            std::numeric_limits<int32>::max()),\n+                            std::numeric_limits<int32_t>::max()),\n         errors::InvalidArgument(\"input sizes must be between 0 and max int32\"));\n \n     const int64_t batch_size = input.dim_size(0);\n@@ -359,13 +360,13 @@ class ScaleAndTranslateOp : public OpKernel {\n         intermediate_t.tensor<float, 4>();\n \n     const functor::Spans& const_row_spans = row_spans;\n-    typename TTypes<int32, 1>::ConstTensor row_starts(\n-        const_row_spans.starts.tensor<int32, 1>());\n+    typename TTypes<int32_t, 1>::ConstTensor row_starts(\n+        const_row_spans.starts.tensor<int32_t, 1>());\n     typename TTypes<float, 1>::ConstTensor row_weights(\n         const_row_spans.weights.tensor<float, 1>());\n     const functor::Spans& const_col_spans = col_spans;\n-    typename TTypes<int32, 1>::ConstTensor col_starts(\n-        const_col_spans.starts.tensor<int32, 1>());\n+    typename TTypes<int32_t, 1>::ConstTensor col_starts(\n+        const_col_spans.starts.tensor<int32_t, 1>());\n     typename TTypes<float, 1>::ConstTensor col_weights(\n         const_col_spans.weights.tensor<float, 1>());\n \n@@ -384,7 +385,7 @@ class ScaleAndTranslateGradOp : public OpKernel {\n   explicit ScaleAndTranslateGradOp(OpKernelConstruction* context)\n       : OpKernel(context) {\n     OP_REQUIRES_OK(context, context->GetAttr(\"antialias\", &antialias_));\n-    string kernel_type_str;\n+    std::string kernel_type_str;\n     OP_REQUIRES_OK(context, context->GetAttr(\"kernel_type\", &kernel_type_str));\n     kernel_type_ = functor::SamplingKernelTypeFromString(kernel_type_str);\n     OP_REQUIRES(context, kernel_type_ != functor::SamplingKernelTypeEnd,\n@@ -417,9 +418,9 @@ class ScaleAndTranslateGradOp : public OpKernel {\n \n     OP_REQUIRES(context,\n                 FastBoundsCheck(forward_input_height,\n-                                std::numeric_limits<int32>::max()) &&\n+                                std::numeric_limits<int32_t>::max()) &&\n                     FastBoundsCheck(forward_input_width,\n-                                    std::numeric_limits<int32>::max()),\n+                                    std::numeric_limits<int32_t>::max()),\n                 errors::InvalidArgument(\n                     \"original sizes must be between 0 and max int32\"));\n     Tensor* output = nullptr;\n@@ -464,13 +465,13 @@ class ScaleAndTranslateGradOp : public OpKernel {\n         intermediate_t.tensor<float, 4>();\n \n     const functor::Spans& const_row_spans = row_spans;\n-    typename TTypes<int32, 1>::ConstTensor row_starts =\n-        const_row_spans.starts.tensor<int32, 1>();\n+    typename TTypes<int32_t, 1>::ConstTensor row_starts =\n+        const_row_spans.starts.tensor<int32_t, 1>();\n     typename TTypes<float, 1>::ConstTensor row_weights(\n         const_row_spans.weights.tensor<float, 1>());\n     const functor::Spans& const_col_spans = col_spans;\n-    typename TTypes<int32, 1>::ConstTensor col_starts(\n-        const_col_spans.starts.tensor<int32, 1>());\n+    typename TTypes<int32_t, 1>::ConstTensor col_starts(\n+        const_col_spans.starts.tensor<int32_t, 1>());\n     typename TTypes<float, 1>::ConstTensor col_weights(\n         const_col_spans.weights.tensor<float, 1>());\n \n@@ -485,8 +486,8 @@ class ScaleAndTranslateGradOp : public OpKernel {\n };\n \n template <typename T>\n-void GatherColumns(OpKernelContext* context, int span_size, const int32* starts,\n-                   const float* weights, const T* image,\n+void GatherColumns(OpKernelContext* context, int span_size,\n+                   const int32_t* starts, const float* weights, const T* image,\n                    const int64_t input_height, const int64_t input_width,\n                    const int64_t output_height, const int64_t output_width,\n                    const int channels, float* output) {\n@@ -538,7 +539,7 @@ inline void AddScaledVector(const T* in_vec, int vec_len, float weight,\n }\n \n template <typename T>\n-void GatherRows(OpKernelContext* context, int span_size, const int32* starts,\n+void GatherRows(OpKernelContext* context, int span_size, const int32_t* starts,\n                 const float* weights, const T* image,\n                 const int64_t input_height, const int64_t input_width,\n                 const int64_t output_height, const int64_t output_width,\n@@ -581,10 +582,10 @@ template <typename T>\n struct GatherSpans<CPUDevice, T> {\n   void operator()(OpKernelContext* context, const CPUDevice& d,\n                   int row_span_size,\n-                  typename TTypes<int32, 1>::ConstTensor row_starts,\n+                  typename TTypes<int32_t, 1>::ConstTensor row_starts,\n                   typename TTypes<float, 1>::ConstTensor row_weights,\n                   int col_span_size,\n-                  typename TTypes<int32, 1>::ConstTensor col_starts,\n+                  typename TTypes<int32_t, 1>::ConstTensor col_starts,\n                   typename TTypes<float, 1>::ConstTensor col_weights,\n                   typename TTypes<T, 4>::ConstTensor images,\n                   typename TTypes<float, 4>::Tensor intermediate_buffer,"
        },
        {
            "sha": "e2387a41ae381c19c12ce3d2eaa14431a0d4bf1c",
            "filename": "tensorflow/core/kernels/image/scale_and_translate_op.h",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op.h?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -60,10 +60,10 @@ struct Spans {\n template <typename Device, typename T>\n struct GatherSpans {\n   void operator()(OpKernelContext* context, const Device& d, int row_span_size,\n-                  typename TTypes<int32, 1>::ConstTensor row_starts,\n+                  typename TTypes<int32_t, 1>::ConstTensor row_starts,\n                   typename TTypes<float, 1>::ConstTensor row_weights,\n                   int col_span_size,\n-                  typename TTypes<int32, 1>::ConstTensor col_starts,\n+                  typename TTypes<int32_t, 1>::ConstTensor col_starts,\n                   typename TTypes<float, 1>::ConstTensor col_weights,\n                   typename TTypes<T, 4>::ConstTensor input_images,\n                   typename TTypes<float, 4>::Tensor intermediate_buffer,"
        },
        {
            "sha": "9b69dae48790cb25e965c8d232cc6c3c7b7ffed6",
            "filename": "tensorflow/core/kernels/image/scale_and_translate_op_benchmark_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_benchmark_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_benchmark_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_benchmark_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -26,8 +26,8 @@ void BM_ScaleAndTranslateOp(benchmark::State& state) {\n   Tensor in(DT_FLOAT, TensorShape({1, 768, 768, 3}));\n   in.flat<float>().setRandom();\n   Tensor size(DT_INT32, TensorShape({2}));\n-  size.flat<int32>()(0) = 772;\n-  size.flat<int32>()(1) = 772;\n+  size.flat<int32_t>()(0) = 772;\n+  size.flat<int32_t>()(1) = 772;\n   Tensor scale(DT_FLOAT, TensorShape({2}));\n   scale.flat<float>()(0) = 1.0052;\n   scale.flat<float>()(1) = 1.0052;"
        },
        {
            "sha": "0def4456696781edad534f92362c3a7844061216",
            "filename": "tensorflow/core/kernels/image/scale_and_translate_op_test.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/07c6ae663f75c904a78d9dbc65489231fd6b1179/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcore%2Fkernels%2Fimage%2Fscale_and_translate_op_test.cc?ref=07c6ae663f75c904a78d9dbc65489231fd6b1179",
            "patch": "@@ -193,7 +193,7 @@ void ScaleAndTranslateBaseline(const DynamicKernel& kernel,\n \n class ScaleAndTranslateOpTest : public OpsTestBase {\n  protected:\n-  void CreateOp(const string& kernel_type_str, const bool antialias) {\n+  void CreateOp(const std::string& kernel_type_str, const bool antialias) {\n     TF_EXPECT_OK(NodeDefBuilder(\"scale_and_translate_op\", \"ScaleAndTranslate\")\n                      .Input(FakeInput(DT_FLOAT))\n                      .Input(FakeInput(DT_INT32))\n@@ -244,8 +244,8 @@ class ScaleAndTranslateOpTest : public OpsTestBase {\n \n   void RunTest(int output_image_height, int output_image_width,\n                const Vector2f& scale, const Vector2f& translate) {\n-    AddInputFromArray<int32>(TensorShape({2}),\n-                             {output_image_height, output_image_width});\n+    AddInputFromArray<int32_t>(TensorShape({2}),\n+                               {output_image_height, output_image_width});\n     AddInputFromArray<float>(TensorShape({2}), {scale[1], scale[0]});\n     AddInputFromArray<float>(TensorShape({2}), {translate[1], translate[0]});\n     absl::Status s = RunOpKernel();\n@@ -417,10 +417,10 @@ TEST_F(ScaleAndTranslateOpTest, NonAntialiasedScaleAndTranslationTest) {\n }\n \n TEST_F(ScaleAndTranslateOpTest, TestKernelTypes) {\n-  const std::vector<string> kKernelTypes = {\n+  const std::vector<std::string> kKernelTypes = {\n       \"lanczos1\", \"lanczos3\",  \"lanczos5\",     \"box\",\n       \"triangle\", \"keyscubic\", \"mitchellcubic\"};\n-  for (const string& kernel_type : kKernelTypes) {\n+  for (const std::string& kernel_type : kKernelTypes) {\n     CreateOp(kernel_type, true);\n     constexpr int64_t kBatchSize = 2;\n     constexpr int64_t kNumRowSquares = 10;"
        }
    ],
    "stats": {
        "total": 626,
        "additions": 319,
        "deletions": 307
    }
}