{
    "author": "chsigg",
    "message": "[xla:gpu] Fix indexing analysis for bitcasts with trailing ones in the shape.\n\nThose unit dimensions should not be simplified away.\n\nPiperOrigin-RevId: 811264419",
    "sha": "810e70c52baea208dda16b441c24d2637d9898e3",
    "files": [
        {
            "sha": "23032c7bf73bdaa8f3247d65cb9d24181a6ab373",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 12,
            "changes": 22,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter.cc?ref=810e70c52baea208dda16b441c24d2637d9898e3",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"absl/status/statusor.h\"\n #include \"absl/strings/str_cat.h\"\n #include \"absl/strings/str_format.h\"\n+#include \"absl/strings/str_join.h\"\n #include \"absl/strings/string_view.h\"\n #include \"absl/types/span.h\"\n #include \"llvm/ADT/ArrayRef.h\"\n@@ -216,17 +217,6 @@ absl::StatusOr<SmallVector<Value>> ComputeOffsetsForTile(\n                                  /*symbols=*/{}, b);\n }\n \n-SmallVector<Value> CreateIndexValues(EmitterLocOpBuilder builder,\n-                                     const ArrayRef<int64_t>& values) {\n-  SmallVector<Value> result;\n-  result.reserve(values.size());\n-  for (int64_t value : values) {\n-    result.push_back(\n-        CreateConst(builder, builder.getIndexType(), value).UnwrapScalar());\n-  }\n-  return result;\n-}\n-\n // Constructs and holds information needed to construct a tile. This information\n // is propagated to Extract/Insert ops to use them to load and store the correct\n // tiles.\n@@ -641,9 +631,17 @@ absl::StatusOr<ScalarOrTensor> EmitTiledReshape(EmitterLocOpBuilder b,\n   }\n \n   // At this point we know that neither the input nor the output are 0D tensors.\n-  Type output_tensor_type = mlir::RankedTensorType::get(\n+  auto output_tensor_type = mlir::RankedTensorType::get(\n       padded_tile_sizes, input_shaped_type.getElementType());\n \n+  if (input_shaped_type.getNumElements() !=\n+      output_tensor_type.getNumElements()) {\n+    return absl::InvalidArgumentError(\n+        absl::StrCat(\"Reshape input and output shapes must be the same, got \",\n+                     absl::StrJoin(input_shaped_type.getShape(), \"x\"), \" -> \",\n+                     absl::StrJoin(output_tensor_type.getShape(), \"x\")));\n+  }\n+\n   // Conservatively prevent Triton from reordering elements within the tile.\n   // TODO(b/353637689): see if this restriction can be lifted.\n   bool allow_reorder = false;"
        },
        {
            "sha": "5700382a5debf8e5e6b8484953c2bdf1d9e201fe",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/fusion_emitter_device_test.cc",
            "status": "modified",
            "additions": 67,
            "deletions": 0,
            "changes": 67,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ffusion_emitter_device_test.cc?ref=810e70c52baea208dda16b441c24d2637d9898e3",
            "patch": "@@ -3798,6 +3798,73 @@ TEST_F(TritonEmitterTest, RocmWarpSizeIsSetCorrectly) {\n   EXPECT_THAT(RunFileCheck(triton_passes_log, kPattern_n), true);\n }\n \n+TEST_F(TritonEmitterTest, EmitsCorrectlyForReshapeOfPad) {\n+  // Note: this test needs a dot for ShouldDerivationSimplifyPointDimensions()\n+  // to return false. Otherwise the tile will still be simplified.\n+  const std::string kHloText = R\"(\n+lhs {\n+  ROOT p0 = bf16[16,32,67,133] parameter(0)\n+}\n+\n+rhs {\n+  p0 = bf16[16,2128,1] parameter(0)\n+  zero = bf16[] constant(0)\n+  pad = bf16[16,2144,1] pad(p0, zero), padding=0_0x0_16x0_0\n+  ROOT bitcast = bf16[16,32,67,1] bitcast(pad)\n+}\n+\n+fusion {\n+  p0 = bf16[16,32,67,133] parameter(0)\n+  p1 = bf16[16,2128,1] parameter(1)\n+  lhs = bf16[16,32,67,133] fusion(p0), kind=kCustom, calls=lhs, backend_config={\n+      \"fusion_backend_config\":{\n+          \"kind\":\"__triton_nested_gemm_fusion\",\n+          \"block_level_fusion_config\":{\n+              \"num_warps\":\"2\",\n+              \"output_tiles\":[{\"sizes\":[\"1\",\"1\",\"16\",\"256\"]}],\n+              \"num_ctas\":1,\n+              \"num_stages\":1,\n+              \"is_tma_allowed\":false\n+          }\n+      }\n+  }\n+  rhs = bf16[16,32,67,1] fusion(p1), kind=kCustom, calls=rhs, backend_config={\n+      \"fusion_backend_config\":{\n+          \"kind\":\"__triton_nested_gemm_fusion\",\n+          \"block_level_fusion_config\":{\n+              \"num_warps\":\"2\",\n+              \"output_tiles\":[{\"sizes\":[\"1\",\"1\",\"16\",\"16\"]}],\n+              \"num_ctas\":1,\n+              \"num_stages\":1,\n+              \"is_tma_allowed\":false\n+          }\n+      }\n+  }\n+  ROOT dot = f32[32,16,133,1] dot(lhs, rhs),\n+      lhs_batch_dims={1,0}, lhs_contracting_dims={2},\n+      rhs_batch_dims={1,0}, rhs_contracting_dims={2}\n+}\n+\n+ENTRY entry {\n+  p0 = bf16[16,32,67,133] parameter(0)\n+  p1 = bf16[16,2128,1] parameter(1)\n+  ROOT micro_kernel = f32[32,16,133,1] fusion(p0, p1), kind=kCustom, calls=fusion, backend_config={\n+      \"fusion_backend_config\":{\n+          \"kind\":\"__triton_nested_gemm_fusion\",\n+          \"block_level_fusion_config\":{\n+              \"num_warps\":\"2\",\n+              \"output_tiles\":[{\"sizes\":[\"1\",\"1\",\"256\",\"16\"]}],\n+              \"num_ctas\":1,\n+              \"num_stages\":1,\n+              \"is_tma_allowed\":false\n+          }\n+      }\n+  }\n+})\";\n+  EXPECT_TRUE(RunAndCompareNoHloPasses(\n+      kHloText, ErrorSpec{/*aabs=*/1e-4, /*arel=*/1e-6}));\n+}\n+\n }  // namespace\n }  // namespace gpu\n }  // namespace xla"
        },
        {
            "sha": "b6be74fba177e12ae2a10f09e32a19bfeb6ba8f7",
            "filename": "third_party/xla/xla/hlo/analysis/indexing_analysis.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fhlo%2Fanalysis%2Findexing_analysis.cc?ref=810e70c52baea208dda16b441c24d2637d9898e3",
            "patch": "@@ -1100,16 +1100,14 @@ AffineMap ComputeReshapeIndexingMap(const Shape& input, const Shape& output,\n          output_dim_id < output.dimensions().size() ||\n          !input_subshape.empty()) {\n     if (input_dim_id < input.dimensions().size() &&\n-        (input_subshape.empty() || input_num_elements < output_num_elements ||\n-         input_dims[input_dim_id] == 1)) {\n+        (input_subshape.empty() || input_num_elements < output_num_elements)) {\n       input_num_elements *= input_dims[input_dim_id];\n       input_subshape.push_back(input_dims[input_dim_id]);\n       ++input_dim_id;\n       continue;\n     }\n     if (output_dim_id < output.dimensions().size() &&\n-        (output_subshape.empty() || output_num_elements < input_num_elements ||\n-         output_dims[output_dim_id] == 1)) {\n+        (output_subshape.empty() || output_num_elements < input_num_elements)) {\n       output_num_elements *= output_dims[output_dim_id];\n       output_subshape.push_back(output_dims[output_dim_id]);\n       output_dims_exprs.push_back(\n@@ -1137,7 +1135,8 @@ HloInstructionIndexing ComputeOutputToInputReshapeOpIndexing(\n   IndexingMap reshape_indexing_map = IndexingMap::FromTensorSizes(\n       ComputeReshapeIndexingMap(input, output, mlir_context),\n       output.dimensions(), {});\n-  reshape_indexing_map.Simplify();\n+  reshape_indexing_map.Simplify(\n+      IndexingMap::SimplifyPointDimensions::kPreserve);\n   return HloInstructionIndexing::FromIndexingMaps({reshape_indexing_map});\n }\n HloInstructionIndexing ComputeInputToOutputReshapeOpIndexing(\n@@ -1148,7 +1147,8 @@ HloInstructionIndexing ComputeInputToOutputReshapeOpIndexing(\n   IndexingMap reshape_indexing_map = IndexingMap::FromTensorSizes(\n       ComputeReshapeIndexingMap(output, input, mlir_context),\n       input.dimensions(), {});\n-  reshape_indexing_map.Simplify();\n+  reshape_indexing_map.Simplify(\n+      IndexingMap::SimplifyPointDimensions::kPreserve);\n   return HloInstructionIndexing::FromIndexingMaps({reshape_indexing_map});\n }\n \n@@ -1310,15 +1310,15 @@ HloInstructionIndexing ComputeOutputToInputBitcastOpIndexing(\n     const HloInstruction* bitcast, MLIRContext* mlir_context) {\n   auto bitcast_map = GetBitcastMap(bitcast->shape(),\n                                    bitcast->operand(0)->shape(), mlir_context);\n-  bitcast_map.Simplify();\n+  bitcast_map.Simplify(IndexingMap::SimplifyPointDimensions::kPreserve);\n   return HloInstructionIndexing::FromIndexingMaps({bitcast_map});\n }\n \n HloInstructionIndexing ComputeInputToOutputBitcastOpIndexing(\n     const HloInstruction* bitcast, MLIRContext* mlir_context) {\n   auto bitcast_map = GetBitcastMap(bitcast->operand(0)->shape(),\n                                    bitcast->shape(), mlir_context);\n-  bitcast_map.Simplify();\n+  bitcast_map.Simplify(IndexingMap::SimplifyPointDimensions::kPreserve);\n   return HloInstructionIndexing::FromIndexingMaps({bitcast_map});\n }\n "
        },
        {
            "sha": "96598481387f357ff350c4627e57f0fa2bd001ec",
            "filename": "third_party/xla/xla/service/gpu/model/symbolic_tile_analysis_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_analysis_test.cc?ref=810e70c52baea208dda16b441c24d2637d9898e3",
            "patch": "@@ -1630,8 +1630,8 @@ ENTRY e {\n   EXPECT_EQ(dynamic_slice->hlo()->opcode(), HloOpcode::kDynamicSlice);\n   const TiledHloInstruction* p0 = dynamic_slice->operand(0);\n   EXPECT_THAT(*p0, MatchTiledHloInstruction(\n-                       /*tile_sizes=*/{1, 8, 2},\n-                       /*tile_strides=*/{0, 1, 1},\n+                       /*tile_sizes=*/{2, 8, 2},\n+                       /*tile_strides=*/{1, 1, 1},\n                        /*tile_offsets_indexing=*/R\"(\n     (pid_0){rt0} -> (rt0, 0, 0), domain: pid_0 in [0, 0], rt0 in [0, 3]\n   )\"));"
        },
        {
            "sha": "ab98cbe37fb7bc089dca79344c7ed98f3864571f",
            "filename": "third_party/xla/xla/service/gpu/model/symbolic_tile_test.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 6,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/810e70c52baea208dda16b441c24d2637d9898e3/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fsymbolic_tile_test.cc?ref=810e70c52baea208dda16b441c24d2637d9898e3",
            "patch": "@@ -79,8 +79,9 @@ TEST_F(SymbolicTileTest, CanPropagateTileThroughTrivialReshape) {\n               Optional(MatchSymbolicTileString(R\"(\n       Symbolic tile with\n         offset_map: (d0, d1, d2, d3) -> (0, 0, 0)\n-        size_map: (d0, d1, d2, d3) -> (d1, d2, d3)\n-        stride_map: (d0, d1, d2, d3) -> (1, 1, 1)\n+        size_map: (d0, d1, d2, d3) -> (d0 * d1, d2, d3)\n+        stride_map: (d0, d1, d2, d3) -> (((-d1 + 12) floordiv 11) * ((-(-d0 + 2) + 1) * 11) + -((-d1 + 12) floordiv 11) + 1, 1, 1)\n+        constraints: d0 in [1, 1] || d1 in [1, 1] || d1 in [11, 11]\n       )\")));\n }\n \n@@ -101,8 +102,8 @@ TEST_F(SymbolicTileTest,\n               Optional(MatchSymbolicTileString(R\"(\n       Symbolic tile with\n         offset_map: (d0, d1) -> (0, 0, 0, 0)\n-        size_map: (d0, d1) -> (1, (d0 + 5) floordiv 6, d0 - ((d0 - 1) floordiv 6) * 6, d1)\n-        stride_map: (d0, d1) -> (0, 1, 1, 1)\n+        size_map: (d0, d1) -> ((d0 + 47) floordiv 48, (d0 + 5) floordiv 6, d0 - ((d0 - 1) floordiv 6) * 6, d1)\n+        stride_map: (d0, d1) -> (1, 1, 1, 1)\n         constraints:\n           6 mod d0 in [0, 0] || d0 mod 6 in [0, 0]\n       )\")));\n@@ -767,8 +768,8 @@ TEST_F(SymbolicTileTest, CanCombineCompatibleConstraints) {\n               Optional(MatchSymbolicTileString(R\"(\n       Symbolic tile with\n         offset_map: (d0, d1) -> (0, 0, 0, 0, 0)\n-        size_map: (d0, d1) -> (1, (d0 + 5) floordiv 6, d0 - ((d0 - 1) floordiv 6) * 6, (d1 + 7) floordiv 8, d1 - ((d1 - 1) floordiv 8) * 8)\n-        stride_map: (d0, d1) -> (0, 1, 1, 1, 1)\n+        size_map: (d0, d1) -> ((d0 + 47) floordiv 48, (d0 + 5) floordiv 6, d0 - ((d0 - 1) floordiv 6) * 6, (d1 + 7) floordiv 8, d1 - ((d1 - 1) floordiv 8) * 8)\n+        stride_map: (d0, d1) -> (1, 1, 1, 1, 1)\n         constraints:\n           6 mod d0 in [0, 0] && 8 mod d1 in [0, 0] ||\n           6 mod d0 in [0, 0] && d1 mod 8 in [0, 0] ||"
        }
    ],
    "stats": {
        "total": 122,
        "additions": 94,
        "deletions": 28
    }
}