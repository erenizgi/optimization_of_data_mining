{
    "author": "WillFroom",
    "message": "[XLA][XTile] Add xtile lowering passes for triton.\n\nThis enables migrating the triton emitter to use emit xtile entry, insert & extract in the child PR.\n\nThe main difference is the memref args in the entry function for which `MemrefToPtr` & `PtrToMemref` were introduced which closely resemble `UnrealizedConversionCastOp` with additional verification and will enable special folding of `memref::TransposeOp`.\n\nPiperOrigin-RevId: 821593545",
    "sha": "beb48d90e2ea588a85dc5491abd2a1c53b19f942",
    "files": [
        {
            "sha": "34c88f93e903def7f7b440ac9f299822c26397a2",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/BUILD",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2FBUILD?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -239,6 +239,7 @@ cc_library(\n         \"//xla/codegen/tiling:tiled_hlo_computation\",\n         \"//xla/codegen/tiling:tiled_hlo_fusion_instruction\",\n         \"//xla/codegen/tiling:tiled_hlo_instruction\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/service:hlo_module_config\",\n         \"//xla/service/gpu/model:block_level_parameters\",\n@@ -353,8 +354,9 @@ cc_library(\n         \"//xla:status_macros\",\n         \"//xla:util\",\n         \"//xla:xla_data_proto_cc\",\n+        \"//xla/backends/gpu/codegen/triton/ir:triton_xla\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n-        \"//xla/codegen/tiling:tiled_hlo_computation\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_query\",\n         \"//xla/hlo/utils:hlo_traversal\",\n@@ -392,6 +394,7 @@ cc_library(\n         \"@llvm-project//mlir:FunctionInterfaces\",\n         \"@llvm-project//mlir:IR\",\n         \"@llvm-project//mlir:MathDialect\",\n+        \"@llvm-project//mlir:NVVMDialect\",\n         \"@llvm-project//mlir:SCFDialect\",\n         \"@llvm-project//mlir:Support\",\n         \"@triton//:TritonDialects\",\n@@ -443,6 +446,7 @@ cc_library(\n         \"//xla:autotuning_proto_cc\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/codegen/tiling:symbolic_tile_analysis\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n         \"//xla/hlo/ir:hlo\",\n         \"//xla/hlo/utils:hlo_traversal\",\n         \"//xla/service:hlo_module_config\","
        },
        {
            "sha": "650b9226c0c931b0590be3c008f7e634a52f2482",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.cc",
            "status": "modified",
            "additions": 18,
            "deletions": 0,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.cc?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -33,6 +33,7 @@ limitations under the License.\n #include \"llvm/Support/MathExtras.h\"\n #include \"llvm/TargetParser/Triple.h\"\n #include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/LLVMIR/LLVMAttrs.h\"\n #include \"mlir/Dialect/LLVMIR/LLVMDialect.h\"\n #include \"mlir/Dialect/Math/IR/Math.h\"\n #include \"mlir/IR/Builders.h\"\n@@ -66,6 +67,7 @@ limitations under the License.\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n #include \"triton/Dialect/Triton/IR/Dialect.h\"\n+#include \"triton/Dialect/Triton/IR/Types.h\"\n \n namespace xla::gpu::triton {\n \n@@ -616,4 +618,20 @@ absl::StatusOr<stream_executor::gpu::TmaMetadata> ExtractTmaMetadata(\n   return tma_metadata;\n }\n \n+::mlir::triton::PointerType GetPointerType(mlir::MemRefType memref_type) {\n+  int address_space = 0;\n+\n+  mlir::Attribute memory_space_attr = memref_type.getMemorySpace();\n+  if (auto int_memory_space_attr =\n+          mlir::dyn_cast_if_present<mlir::IntegerAttr>(memory_space_attr)) {\n+    address_space = int_memory_space_attr.getInt();\n+  } else if (auto llvm_memory_space_attr = mlir::dyn_cast_if_present<\n+                 mlir::LLVM::LLVMAddrSpaceAttrInterface>(memory_space_attr)) {\n+    address_space = llvm_memory_space_attr.getAddressSpace();\n+  }\n+\n+  return ::mlir::triton::PointerType::get(memref_type.getElementType(),\n+                                          address_space);\n+}\n+\n }  // namespace xla::gpu::triton"
        },
        {
            "sha": "b2b65bb95b3f226ea16241b949a803d37374a59a",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/emitter_helpers.h",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Femitter_helpers.h?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -50,6 +50,7 @@ limitations under the License.\n #include \"xla/tsl/platform/status.h\"\n #include \"xla/xla.pb.h\"\n #include \"xla/xla_data.pb.h\"\n+#include \"triton/Dialect/Triton/IR/Types.h\"\n \n namespace xla::gpu::triton {\n \n@@ -230,6 +231,10 @@ absl::StatusOr<stream_executor::gpu::TmaMetadata> ExtractTmaMetadata(\n absl::StatusOr<stream_executor::ThreadDim> ExtractThreadDims(\n     mlir::ModuleOp triton_module, mlir::LLVM::LLVMFuncOp func_op);\n \n+// Returns the triton pointer type that corresponds to the given memref type,\n+// i.e. has the same element type and address space.\n+::mlir::triton::PointerType GetPointerType(mlir::MemRefType memref_type);\n+\n }  // namespace xla::gpu::triton\n \n #endif  // XLA_BACKENDS_GPU_CODEGEN_TRITON_EMITTER_HELPERS_H_"
        },
        {
            "sha": "8512fbb549a67b9509d8ba5ac228c01411a7cc82",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/tests/canonicalize.mlir",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftests%2Fcanonicalize.mlir?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -17,3 +17,12 @@ tt.func @xla_triton_extract_insert(%arg0: !tt.ptr<bf16>, %arg1: index) {\n       [%c0, %arg1][16, 64][1, 1] {noinline = false} : tensor<16x64xbf16>\n   tt.return\n }\n+\n+// CHECK-LABEL: @fold_ptr_memref_ptr(\n+// CHECK-SAME: %[[SRC:.*]]: !tt.ptr<f32>\n+func.func @fold_ptr_memref_ptr(%src: !tt.ptr<f32>) -> !tt.ptr<f32> {\n+  // CHECK: return %[[SRC]] : !tt.ptr<f32>\n+  %src_ptr = triton_xla.ptr_to_memref %src from !tt.ptr<f32> to memref<256xf32>\n+  %dst = triton_xla.memref_to_ptr %src_ptr from memref<256xf32> to !tt.ptr<f32>\n+  func.return %dst : !tt.ptr<f32>\n+}"
        },
        {
            "sha": "9e6ad7f1e535dc3981e7fc81aeb8c8458e70e0e1",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_ops.cc",
            "status": "modified",
            "additions": 58,
            "deletions": 0,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.cc?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -254,6 +254,64 @@ void InsertOp::getCanonicalizationPatterns(RewritePatternSet &results,\n   results.add<InsertOpOffsetsSizesStridesFolder>(context);\n }\n \n+OpFoldResult MemrefToPtrOp::fold(FoldAdaptor adaptor) {\n+  if (auto ptr_to_memref = getOperand().getDefiningOp<PtrToMemrefOp>()) {\n+    // memref_to_ptr(ptr_to_memref(x)) -> x\n+    return ptr_to_memref.getOperand();\n+  }\n+\n+  return {};\n+}\n+\n+LogicalResult MemrefToPtrOp::verify() {\n+  mlir::MemRefType src_type = getSrc().getType();\n+  if (src_type.getElementType() != getType().getPointeeType()) {\n+    getOperation()->emitError(\n+        \"source element type does not match result pointee type\");\n+    return failure();\n+  }\n+\n+  // It is only safe to directly convert a pointer to a memref if the memref\n+  // has no offset.\n+  llvm::SmallVector<int64_t> strides;\n+  int64_t offset = 0;\n+  if (src_type.getStridesAndOffset(strides, offset).failed()) {\n+    getOperation()->emitError(\"failed to get strides and offset\") << src_type;\n+    return failure();\n+  }\n+  if (offset != 0) {\n+    getOperation()->emitError(\"memref has non-zero offset\");\n+    return failure();\n+  }\n+\n+  return success();\n+}\n+\n+LogicalResult PtrToMemrefOp::verify() {\n+  mlir::MemRefType result_type = getType();\n+  if (getSrc().getType().getPointeeType() != result_type.getElementType()) {\n+    getOperation()->emitError(\n+        \"source pointee type does not match result element type\");\n+    return failure();\n+  }\n+\n+  // It is only safe to directly convert a pointer to a memref if the memref\n+  // has no offset.\n+  llvm::SmallVector<int64_t> strides;\n+  int64_t offset = 0;\n+  if (result_type.getStridesAndOffset(strides, offset).failed()) {\n+    getOperation()->emitError(\"failed to get strides and offset\")\n+        << result_type;\n+    return failure();\n+  }\n+  if (offset != 0) {\n+    getOperation()->emitError(\"memref has non-zero offset\");\n+    return failure();\n+  }\n+\n+  return success();\n+}\n+\n }  // namespace mlir::triton::xla\n \n #define GET_OP_CLASSES"
        },
        {
            "sha": "8ca4f7eec5d61a31003489b877aaa73f9e35749c",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/ir/triton_xla_ops.td",
            "status": "modified",
            "additions": 35,
            "deletions": 0,
            "changes": 35,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Fir%2Ftriton_xla_ops.td?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -421,6 +421,41 @@ def TTXLA_GetPeerPtrOp : TTXLA_Op<\"get_peer_ptr\", [Pure]> {\n   }];\n }\n \n+def TTXLA_MemrefToPtrOp : TTXLA_Op<\"memref_to_ptr\", [Pure]> {\n+  let summary = [{\n+    A specialized version of unrealized_conversion_cast that converts a\n+    memref to a pointer.\n+  }];\n+\n+  let arguments = (ins AnyMemRef:$src);\n+\n+  let results = (outs TT_Ptr:$result);\n+\n+  let assemblyFormat = [{\n+    $src `from` type($src) `to` type($result) attr-dict\n+  }];\n+\n+  let hasFolder = 1;\n+  let hasVerifier = 1;\n+}\n+\n+def TTXLA_PtrToMemrefOp : TTXLA_Op<\"ptr_to_memref\", [Pure]> {\n+  let summary = [{\n+    A specialized version of unrealized_conversion_cast that converts a\n+    pointer to a memref.\n+  }];\n+\n+  let arguments = (ins TT_Ptr:$src);\n+\n+  let results = (outs AnyMemRef:$result);\n+\n+  let assemblyFormat = [{\n+    $src `from` type($src) `to` type($result) attr-dict\n+  }];\n+\n+  let hasVerifier = 1;\n+}\n+\n \n #endif // XLA_BACKENDS_GPU_CODEGEN_TRITON_IR_TRITON_XLA_OPS_TD_\n "
        },
        {
            "sha": "0da459d5fac61222071ef840c3f9c4e4742e7573",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/BUILD",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2FBUILD?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -44,6 +44,7 @@ cc_library(\n         \"triton_xla_lower_block_barrier_pass.cc\",\n         \"triton_xla_lower_get_tid_pass.cc\",\n         \"triton_xla_lower_remote_access_pass.cc\",\n+        \"triton_xla_lower_xtile_pass.cc\",\n         \"triton_xla_squeeze_dims_pass.cc\",\n         \"triton_xla_unswitch_loops_pass.cc\",\n     ],\n@@ -56,13 +57,16 @@ cc_library(\n         \"//xla/backends/gpu/codegen/triton/ir:triton_xla\",\n         \"//xla/codegen:emitter_loc_op_builder\",\n         \"//xla/codegen/emitters/ir:xla\",\n+        \"//xla/codegen/xtile/ir:xtile\",\n+        \"//xla/service/gpu:ir_emission_utils\",\n         \"//xla/service/llvm_ir:llvm_util\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n         \"//xla/stream_executor/gpu:tma_metadata\",\n         \"@com_google_absl//absl/algorithm:container\",\n         \"@com_google_absl//absl/log\",\n         \"@com_google_absl//absl/log:check\",\n         \"@com_google_absl//absl/status\",\n+        \"@com_google_absl//absl/status:statusor\",\n         \"@com_google_absl//absl/strings\",\n         \"@com_google_absl//absl/strings:str_format\",\n         \"@com_google_absl//absl/strings:string_view\",\n@@ -73,7 +77,10 @@ cc_library(\n         \"@llvm-project//mlir:FuncDialect\",\n         \"@llvm-project//mlir:FunctionInterfaces\",\n         \"@llvm-project//mlir:IR\",\n+        \"@llvm-project//mlir:InliningUtils\",\n+        \"@llvm-project//mlir:LLVMCommonConversion\",\n         \"@llvm-project//mlir:LLVMDialect\",\n+        \"@llvm-project//mlir:MemRefDialect\",\n         \"@llvm-project//mlir:NVVMDialect\",\n         \"@llvm-project//mlir:Pass\",\n         \"@llvm-project//mlir:Rewrite\","
        },
        {
            "sha": "3637c2c580e05a7d7aff12c6911ae594fa05ded3",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.h",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.h?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -22,6 +22,7 @@ limitations under the License.\n #include \"mlir/IR/Operation.h\"\n #include \"mlir/Pass/Pass.h\"\n #include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"  // IWYU pragma: keep\n+#include \"xla/codegen/xtile/ir/xtile_dialect.h\"  // IWYU pragma: keep\n \n namespace mlir::triton::xla {\n \n@@ -45,6 +46,7 @@ std::unique_ptr<mlir::Pass> CreateTritonXLALowerAtomicsPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerBlockBarrierPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLAConvertUnsupportedTypesPass();\n std::unique_ptr<mlir::Pass> CreateTritonXLALowerRemoteAccessPass();\n+std::unique_ptr<mlir::Pass> CreateTritonXLALowerXTilePass();\n std::unique_ptr<mlir::Pass> CreateStableHLOLowerToTritonPass();\n std::unique_ptr<mlir::Pass> CreateTensorLowerToTritonPass();\n "
        },
        {
            "sha": "25a7e536ac7a0366d537e2d902926783a28da8ae",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/passes.td",
            "status": "modified",
            "additions": 14,
            "deletions": 0,
            "changes": 14,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Fpasses.td?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -190,6 +190,20 @@ def TritonXLAUnswitchLoopsPass :\n   let constructor = \"CreateTritonXLAUnswitchLoopsPass()\";\n }\n \n+def TritonXLALowerXTilePass :\n+   Pass<\"triton-xla-lower-xtile\", \"mlir::ModuleOp\"> {\n+  let summary = \"Lowers xtile ops to Triton ops.\";\n+\n+  let dependentDialects = [\n+    \"mlir::func::FuncDialect\",\n+    \"mlir::memref::MemRefDialect\",\n+    \"mlir::triton::xla::XlaTritonDialect\",\n+    \"triton::TritonDialect\",\n+  ];\n+\n+  let constructor = \"CreateTritonXLALowerXTilePass()\";\n+}\n+\n def StableHLOLowerToTritonPass\n     : Pass<\"stablehlo-lower-to-triton\", \"mlir::ModuleOp\"> {\n   let summary = \"Lowers StableHLO operations to their Triton equivalent.\";"
        },
        {
            "sha": "60dc9ca6df4a6fc466c843085f3aa4875182bb83",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/tests/triton_xla_lower_xtile.mlir",
            "status": "added",
            "additions": 39,
            "deletions": 0,
            "changes": 39,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_lower_xtile.mlir",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_lower_xtile.mlir",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftests%2Ftriton_xla_lower_xtile.mlir?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -0,0 +1,39 @@\n+// RUN: xla-opt %s -split-input-file -triton-xla-lower-xtile | FileCheck %s\n+\n+xtile.entry_func @extract_insert_no_layout(%input: memref<1024xf32, #nvvm.memory_space<global>>,\n+                         %output: memref<32xf32, #nvvm.memory_space<global>>,\n+                         %tile_id: index) {\n+  %tile = xtile.extract %input[%tile_id][1][1] : memref<1024xf32, #nvvm.memory_space<global>> -> tensor<1xf32>\n+  xtile.insert %tile into %output[%tile_id][1][1] : tensor<1xf32> -> memref<32xf32, #nvvm.memory_space<global>>\n+  xtile.return\n+}\n+\n+// CHECK: func.func @extract_insert_no_layout(%[[ARG0:.*]]: !tt.ptr<f32>, %[[ARG1:.*]]: !tt.ptr<f32>) {\n+// CHECK:   %[[PID:.*]] = tt.get_program_id x : i32\n+// CHECK:   %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n+// CHECK:   %[[PID_IDX:.*]] = arith.index_cast %[[PID_I64]] : i64 to index\n+// CHECK:   %[[TILE:.*]] = triton_xla.extract from %[[ARG0]] as memref<1024xf32, #triton_xla.layout<[0]>> [%[[PID_IDX]]] [1] [1] : tensor<1xf32>\n+// CHECK:   triton_xla.insert %[[TILE]] into %[[ARG1]] as memref<32xf32, #triton_xla.layout<[0]>> [%[[PID_IDX]]] [1] [1] : tensor<1xf32>\n+// CHECK:   return\n+// CHECK: }\n+\n+// -----\n+\n+!arg_type = memref<1024x32x1x1xbf16, #triton_xla.layout<[2, 3, 0, 1]>, #nvvm.memory_space<global>>\n+xtile.entry_func @layout_preserved(%input: !arg_type,\n+                                   %tile_id: index) {\n+  %c_0 = arith.constant 0 : index\n+  %tile = xtile.extract %input[%tile_id, %c_0, %c_0, %c_0][1, 1, 1, 1][1, 1, 1, 1] : !arg_type -> tensor<1x1x1x1xbf16>\n+  xtile.return\n+}\n+\n+// CHECK: func.func @layout_preserved(%[[ARG0:.*]]: !tt.ptr<bf16>) {\n+// CHECK:   %[[PID:.*]] = tt.get_program_id x : i32\n+// CHECK:   %[[PID_I64:.*]] = arith.extsi %[[PID]] : i32 to i64\n+// CHECK:   %[[PID_IDX:.*]] = arith.index_cast %[[PID_I64]] : i64 to index\n+// CHECK:   %[[TILE:.*]] = triton_xla.extract from %[[ARG0]]\n+// CHECK-SAME: as memref<1024x32x1x1xbf16, #triton_xla.layout<[3, 2, 0, 1]>>\n+// CHECK-SAME: [%[[PID_IDX]], 0, 0, 0]\n+// CHECK-SAME: [1, 1, 1, 1] [1, 1, 1, 1] : tensor<1x1x1x1xbf16>\n+// CHECK:   return\n+// CHECK: }"
        },
        {
            "sha": "7c6eacabb7efbae839bbce25334efa59d2bfebdf",
            "filename": "third_party/xla/xla/backends/gpu/codegen/triton/transforms/triton_xla_lower_xtile_pass.cc",
            "status": "added",
            "additions": 291,
            "deletions": 0,
            "changes": 291,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fcodegen%2Ftriton%2Ftransforms%2Ftriton_xla_lower_xtile_pass.cc?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -0,0 +1,291 @@\n+/* Copyright 2025 The OpenXLA Authors.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+    http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+==============================================================================*/\n+\n+#include <cstdint>\n+#include <memory>\n+#include <utility>\n+\n+#include \"absl/algorithm/container.h\"\n+#include \"absl/status/status.h\"\n+#include \"absl/status/statusor.h\"\n+#include \"absl/strings/string_view.h\"\n+#include \"llvm/ADT/STLExtras.h\"\n+#include \"mlir/Conversion/LLVMCommon/MemRefBuilder.h\"\n+#include \"mlir/Dialect/Arith/IR/Arith.h\"\n+#include \"mlir/Dialect/Func/IR/FuncOps.h\"\n+#include \"mlir/Dialect/MemRef/IR/MemRef.h\"\n+#include \"mlir/IR/Builders.h\"\n+#include \"mlir/IR/BuiltinAttributes.h\"\n+#include \"mlir/IR/BuiltinOps.h\"\n+#include \"mlir/IR/BuiltinTypeInterfaces.h\"\n+#include \"mlir/IR/BuiltinTypes.h\"\n+#include \"mlir/IR/Operation.h\"\n+#include \"mlir/IR/OperationSupport.h\"\n+#include \"mlir/IR/PatternMatch.h\"\n+#include \"mlir/IR/Types.h\"\n+#include \"mlir/IR/Value.h\"\n+#include \"mlir/IR/ValueRange.h\"\n+#include \"mlir/Pass/Pass.h\"\n+#include \"mlir/Support/LLVM.h\"\n+#include \"mlir/Support/LogicalResult.h\"\n+#include \"mlir/Transforms/DialectConversion.h\"\n+#include \"mlir/Transforms/GreedyPatternRewriteDriver.h\"\n+#include \"mlir/Transforms/Inliner.h\"\n+#include \"mlir/Transforms/InliningUtils.h\"\n+#include \"xla/backends/gpu/codegen/triton/emitter_helpers.h\"\n+#include \"xla/backends/gpu/codegen/triton/ir/triton_xla_ops.h\"\n+#include \"xla/codegen/xtile/ir/xtile_ops.h\"\n+#include \"triton/Dialect/Triton/IR/Dialect.h\"\n+\n+namespace mlir::triton::xla {\n+\n+#define GEN_PASS_DEF_TRITONXLALOWERXTILEPASS\n+#include \"xla/backends/gpu/codegen/triton/transforms/passes.h.inc\"\n+\n+namespace {\n+\n+namespace ttir = ::mlir::triton;\n+namespace ma = ::mlir::arith;\n+\n+// Get the new arg types of the lowered function by translating memrefs to the\n+// corresponding pointer types.\n+llvm::SmallVector<mlir::Type> GetPtrArgTypes(mlir::ValueRange args) {\n+  llvm::SmallVector<mlir::Type> arg_types;\n+  arg_types.reserve(args.size());\n+  for (auto arg : args) {\n+    mlir::MemRefType memref_type = mlir::cast<mlir::MemRefType>(arg.getType());\n+    arg_types.push_back(::xla::gpu::triton::GetPointerType(memref_type));\n+  }\n+  return arg_types;\n+}\n+\n+// Function to get the permutation vector from a MemRefType.\n+// The motivation for extracting it from getStridesAndOffset vs directly from\n+// triton_xla.layout is that when we fold memrefs (such as in a transpose) it\n+// will have a generic strided layout that does not directly encode the\n+// permutation.\n+absl::StatusOr<llvm::SmallVector<int64_t>> getPermutationMinorToMajor(\n+    mlir::MemRefType memref) {\n+  llvm::SmallVector<int64_t> strides;\n+  int64_t offset;\n+  if (memref.getStridesAndOffset(strides, offset).failed()) {\n+    // This can fail if the layout is not strided (e.g., has dynamic strides).\n+    return absl::InvalidArgumentError(\"Failed to get strides and offset\");\n+  }\n+\n+  llvm::SmallVector<int64_t> permutation;\n+  permutation.resize(strides.size());\n+  absl::c_iota(permutation, 0);\n+\n+  absl::c_sort(permutation, [&](int64_t lhs_dim, int64_t rhs_dim) {\n+    int64_t lhs_stride = strides[lhs_dim];\n+    int64_t rhs_stride = strides[rhs_dim];\n+    if (lhs_stride != rhs_stride) {\n+      return lhs_stride < rhs_stride;\n+    }\n+\n+    // If the strides are the same, we need to ensure that the unit dimension is\n+    // the more minor.\n+    int64_t lhs_size = memref.getDimSize(lhs_dim);\n+    int64_t rhs_size = memref.getDimSize(rhs_dim);\n+    if (lhs_size != rhs_size) {\n+      return lhs_size < rhs_size;\n+    }\n+\n+    // If all else fails just sort in the canonical order.\n+    return lhs_dim > rhs_dim;\n+  });\n+\n+  // Check that the strides actually represent a permutation,\n+  // this could happen for example with padded buffers.\n+  int64_t size_product = 1;\n+  for (int64_t dim : permutation) {\n+    if (strides[dim] != size_product) {\n+      return absl::InvalidArgumentError(\"Layout is not a valid permutation\");\n+    }\n+    size_product *= memref.getDimSize(dim);\n+  }\n+\n+  return permutation;\n+}\n+\n+MemrefToPtrOp CreateMemrefToPtr(mlir::OpBuilder& builder,\n+                                mlir::TypedValue<mlir::MemRefType> memref) {\n+  mlir::MemRefType memref_type = memref.getType();\n+  return builder.create<MemrefToPtrOp>(\n+      memref.getLoc(), ::xla::gpu::triton::GetPointerType(memref_type), memref);\n+}\n+\n+// Rewrite a xtile entry to a func.func with the same body, but with memref\n+// arguments replaced by pointers.\n+class XTileEntryToTriton\n+    : public mlir::OpRewritePattern<::xla::xtile::EntryFuncOp> {\n+ public:\n+  XTileEntryToTriton(mlir::MLIRContext* context, mlir::ModuleOp& module)\n+      : OpRewritePattern(context), module_(module) {}\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      ::xla::xtile::EntryFuncOp entry_op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    mlir::ImplicitLocOpBuilder builder(module_->getLoc(), module_);\n+    builder.setInsertionPointToStart(module_.getBody());\n+\n+    auto new_arg_types = GetPtrArgTypes(entry_op.getBufferArgs());\n+    auto new_func_op = builder.create<mlir::func::FuncOp>(\n+        entry_op.getName(), builder.getFunctionType(new_arg_types, {}));\n+\n+    // Move the old function's body to the new function\n+    rewriter.inlineRegionBefore(\n+        entry_op.getBody(), new_func_op.getFunctionBody(), new_func_op.end());\n+\n+    Block& entry_block = new_func_op.front();\n+    builder.setInsertionPointToStart(&entry_block);\n+\n+    SmallVector<BlockArgument> old_args(entry_block.getArguments());\n+    SmallVector<BlockArgument> new_args(entry_block.addArguments(\n+        new_arg_types,\n+        SmallVector<Location>(new_arg_types.size(), entry_op.getLoc())));\n+\n+    BlockArgument tile_id_arg = old_args.back();\n+\n+    // TODO(b/389955087): we can decide whether to sign extend by\n+    // understanding if we need 64 bits to encode indices or if 32 bits are\n+    // enough. For now, just use 64 bits to avoid issues.\n+    auto pid = builder.create<ttir::GetProgramIdOp>(ttir::ProgramIDDim::X);\n+    Value pid_i64 = builder.create<ma::ExtSIOp>(builder.getI64Type(), pid);\n+    Value pid_idx =\n+        builder.create<ma::IndexCastOp>(builder.getIndexType(), pid_i64);\n+    rewriter.replaceAllUsesWith(tile_id_arg, pid_idx);\n+\n+    // Handle memeref arguments.\n+    for (auto [old_arg, new_arg] : llvm::zip(old_args, new_args)) {\n+      mlir::MemRefType memref_type =\n+          mlir::cast<mlir::MemRefType>(old_arg.getType());\n+\n+      mlir::Value memref_cast =\n+          builder.create<PtrToMemrefOp>(memref_type, new_arg);\n+\n+      // Replace all uses of the old argument with the result of the cast.\n+      rewriter.replaceAllUsesWith(old_arg, memref_cast);\n+    }\n+\n+    entry_block.eraseArguments(0, old_args.size());\n+\n+    rewriter.setInsertionPointToEnd(&entry_block);\n+\n+    rewriter.replaceOpWithNewOp<mlir::func::ReturnOp>(\n+        entry_block.getTerminator());\n+\n+    rewriter.eraseOp(entry_op);\n+    return success();\n+  }\n+\n+ private:\n+  mlir::ModuleOp& module_;\n+};\n+\n+// Rewrite a xtile extract to a triton_xla extract.\n+class XTileExtractToTriton\n+    : public mlir::OpRewritePattern<::xla::xtile::ExtractTileOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      ::xla::xtile::ExtractTileOp extract_op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    mlir::MemRefType source_type = extract_op.getSource().getType();\n+    mlir::RankedTensorType result_type = extract_op.getType();\n+\n+    mlir::Value memref_to_ptr =\n+        CreateMemrefToPtr(rewriter, extract_op.getSource());\n+\n+    absl::StatusOr<SmallVector<int64_t>> minor_to_major_or =\n+        getPermutationMinorToMajor(source_type);\n+    if (!minor_to_major_or.ok()) {\n+      return rewriter.notifyMatchFailure(extract_op,\n+                                         minor_to_major_or.status().ToString());\n+    }\n+    const SmallVector<int64_t>& minor_to_major = *minor_to_major_or;\n+    auto triton_extract_op = rewriter.create<ExtractOp>(\n+        extract_op.getLoc(), result_type, memref_to_ptr,\n+        extract_op.getOffsets(), extract_op.getFullTileShape(),\n+        extract_op.getStrides(), source_type.getShape(), minor_to_major);\n+\n+    rewriter.replaceOp(extract_op, triton_extract_op);\n+\n+    return mlir::success();\n+  }\n+};\n+\n+// Rewrite a xtile insert to a triton_xla insert.\n+class XTileInsertToTriton\n+    : public mlir::OpRewritePattern<::xla::xtile::InsertTileOp> {\n+ public:\n+  using OpRewritePattern::OpRewritePattern;\n+\n+  mlir::LogicalResult matchAndRewrite(\n+      ::xla::xtile::InsertTileOp insert_op,\n+      mlir::PatternRewriter& rewriter) const override {\n+    mlir::MemRefType destination_type = insert_op.getDestination().getType();\n+\n+    mlir::Value memref_to_ptr =\n+        CreateMemrefToPtr(rewriter, insert_op.getDestination());\n+\n+    absl::StatusOr<SmallVector<int64_t>> minor_to_major_or =\n+        getPermutationMinorToMajor(destination_type);\n+    if (!minor_to_major_or.ok()) {\n+      return rewriter.notifyMatchFailure(insert_op,\n+                                         minor_to_major_or.status().ToString());\n+    }\n+    const SmallVector<int64_t>& minor_to_major = *minor_to_major_or;\n+    auto triton_insert_op = rewriter.create<InsertOp>(\n+        insert_op.getLoc(), insert_op.getSource(), memref_to_ptr,\n+        insert_op.getOffsets(), insert_op.getFullTileShape(),\n+        insert_op.getStrides(), destination_type.getShape(), minor_to_major);\n+\n+    rewriter.replaceOp(insert_op, triton_insert_op);\n+\n+    return mlir::success();\n+  }\n+};\n+\n+class TritonXLALowerXTilePass\n+    : public impl::TritonXLALowerXTilePassBase<TritonXLALowerXTilePass> {\n+ public:\n+  using TritonXLALowerXTilePassBase::TritonXLALowerXTilePassBase;\n+\n+  void runOnOperation() override {\n+    mlir::ModuleOp module = getOperation();\n+    mlir::MLIRContext* context = &getContext();\n+\n+    mlir::RewritePatternSet patterns(context);\n+\n+    patterns.add<XTileEntryToTriton>(context, module);\n+    patterns.add<XTileExtractToTriton, XTileInsertToTriton>(context);\n+    if (mlir::failed(\n+            mlir::applyPatternsGreedily(module, std::move(patterns)))) {\n+      signalPassFailure();\n+      return;\n+    }\n+  }\n+};\n+\n+}  // namespace\n+\n+std::unique_ptr<Pass> CreateTritonXLALowerXTilePass() {\n+  return std::make_unique<TritonXLALowerXTilePass>();\n+}\n+\n+}  // namespace mlir::triton::xla"
        },
        {
            "sha": "302063d751f5d8ed8dd5a974f46149ea2aa9928c",
            "filename": "third_party/xla/xla/service/gpu/tests/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2FBUILD?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -699,6 +699,7 @@ lit_test_suite_for_gpus(\n #         \"//xla/backends/gpu/codegen/triton/transforms:passes\",\n #         \"//xla/codegen/emitters/ir:xla\",\n #         \"//xla/codegen/emitters/transforms:passes\",\n+#         \"//xla/codegen/xtile/ir:xtile\",\n #         \"//xla/stream_executor:device_description\",\n #         \"//xla/stream_executor/cuda:cuda_compute_capability\",\n #         \"@triton//:AllPassesAndDialects\","
        },
        {
            "sha": "ee783721b7eae49843c53ac4fc4602758d668ff0",
            "filename": "third_party/xla/xla/service/gpu/tests/xla-opt.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fxla-opt.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/beb48d90e2ea588a85dc5491abd2a1c53b19f942/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fxla-opt.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Ftests%2Fxla-opt.cc?ref=beb48d90e2ea588a85dc5491abd2a1c53b19f942",
            "patch": "@@ -34,6 +34,7 @@ limitations under the License.\n #include \"xla/backends/gpu/codegen/triton/transforms/passes.h\"\n #include \"xla/codegen/emitters/ir/xla_dialect.h\"\n #include \"xla/codegen/emitters/transforms/passes.h\"\n+#include \"xla/codegen/xtile/ir/xtile_dialect.h\"\n #include \"xla/stream_executor/cuda/cuda_compute_capability.h\"\n #include \"xla/stream_executor/device_description.h\"\n #include \"third_party/triton/bin/RegisterTritonDialects.h\"\n@@ -86,9 +87,10 @@ int main(int argc, char** argv) {\n   mlir::LLVM::registerInlinerInterface(registry);\n   mlir::func::registerInlinerExtension(registry);\n   registerTritonDialects(registry);  // This registers all passes as well.\n-  registry.insert<mlir::func::FuncDialect, mlir::tensor::TensorDialect,\n-                  mlir::triton::xla::XlaTritonDialect, xla::XlaDialect,\n-                  mlir::stablehlo::StablehloDialect>();\n+  registry\n+      .insert<mlir::func::FuncDialect, mlir::tensor::TensorDialect,\n+              mlir::triton::xla::XlaTritonDialect, xla::XlaDialect,\n+              xla::xtile::XTileDialect, mlir::stablehlo::StablehloDialect>();\n   mlir::triton::xla::registerTritonXlaTransformsPasses();\n   xla::emitters::registerTransformsPasses();\n   xla::gpu::registerGpuFusionTransformsPasses();"
        }
    ],
    "stats": {
        "total": 493,
        "additions": 489,
        "deletions": 4
    }
}