{
    "author": "tensorflower-gardener",
    "message": "Automated Code Change\n\nPiperOrigin-RevId: 850619607",
    "sha": "8ce699b6372f5452f6005713f301b5e29587c08c",
    "files": [
        {
            "sha": "13df41fb8ab5297f21ee01dd802f48225405f724",
            "filename": "tensorflow/compiler/jit/build_xla_ops_pass_test.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fbuild_xla_ops_pass_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fbuild_xla_ops_pass_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fbuild_xla_ops_pass_test.cc?ref=8ce699b6372f5452f6005713f301b5e29587c08c",
            "patch": "@@ -262,7 +262,7 @@ TEST_F(BuildXlaOpsTest, NoExtraMergeForEdgeToSink) {\n }\n \n #ifdef GOOGLE_CUDA\n-FunctionDefLibrary CreateFunctionDefLibWithInt32Input(const string& name) {\n+FunctionDefLibrary CreateFunctionDefLibWithInt32Input(const std::string& name) {\n   FunctionDefLibrary fdef_lib;\n   FunctionDef func = FunctionDefHelper::Create(\n       /*function_name=*/name, /*in_def=*/{\"in: int32\"},"
        },
        {
            "sha": "ea5f247417e243af27c3c799e09bba3634cafdcf",
            "filename": "tensorflow/compiler/jit/pjrt_compile_util_test.cc",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fpjrt_compile_util_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fpjrt_compile_util_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fpjrt_compile_util_test.cc?ref=8ce699b6372f5452f6005713f301b5e29587c08c",
            "patch": "@@ -34,7 +34,7 @@ limitations under the License.\n namespace tensorflow {\n namespace {\n \n-StatusOr<std::unique_ptr<Graph>> SampleGraphAddXY() {\n+absl::StatusOr<std::unique_ptr<Graph>> SampleGraphAddXY() {\n   std::unique_ptr<Graph> graph(new Graph(OpRegistry::Global()));\n   Scope scope = Scope::NewRootScope().ExitOnError();\n   auto a = ops::_Arg(scope.WithOpName(\"A\"), DT_INT32, 0);\n@@ -45,7 +45,7 @@ StatusOr<std::unique_ptr<Graph>> SampleGraphAddXY() {\n   return graph;\n }\n \n-StatusOr<FunctionDef> SampleFuntionAddXY(const std::string& name) {\n+absl::StatusOr<FunctionDef> SampleFuntionAddXY(const std::string& name) {\n   TF_ASSIGN_OR_RETURN(auto graph, SampleGraphAddXY());\n   FunctionDef fdef;\n   TF_RETURN_IF_ERROR(GraphToFunctionDef(*graph, name, &fdef));"
        },
        {
            "sha": "ca74add480f77df5c88f11bddbc02fd40fe82bba",
            "filename": "tensorflow/compiler/jit/xla_host_send_recv_device_context_test.cc",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fxla_host_send_recv_device_context_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/8ce699b6372f5452f6005713f301b5e29587c08c/tensorflow%2Fcompiler%2Fjit%2Fxla_host_send_recv_device_context_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/tensorflow%2Fcompiler%2Fjit%2Fxla_host_send_recv_device_context_test.cc?ref=8ce699b6372f5452f6005713f301b5e29587c08c",
            "patch": "@@ -34,15 +34,15 @@ namespace {\n \n class XlaHostSendRecvDeviceContextTest : public ::testing::Test {\n  public:\n-  absl::Status SetDevice(const string& device_type) {\n+  absl::Status SetDevice(const std::string& device_type) {\n     auto device_factory = DeviceFactory::GetFactory(device_type);\n     if (device_factory == nullptr) {\n       return absl::NotFoundError(\n           \"Failed to get DeviceFactory for device_type: \" + device_type);\n     }\n     SessionOptions options;\n     std::vector<std::unique_ptr<Device>> devices;\n-    Status s = device_factory->CreateDevices(\n+    absl::Status s = device_factory->CreateDevices(\n         options, \"/job:worker/replica:0/task:0\", &devices);\n     device_ = std::move(devices[0]);\n \n@@ -75,7 +75,8 @@ TEST_F(XlaHostSendRecvDeviceContextTest, CopyDeviceTensorToCPU) {\n       platform->ExecutorForDevice(0).value();\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n \n-  se::DeviceMemoryBase gpu_dst{device_tensor.data(), 4 * sizeof(float)};\n+  stream_executor::DeviceAddressBase gpu_dst{device_tensor.data(),\n+                                             4 * sizeof(float)};\n   xla::Shape shape;\n   TF_ASSERT_OK(TensorShapeToXLAShape(DT_FLOAT, TensorShape({2, 2}), &shape));\n \n@@ -110,7 +111,8 @@ TEST_F(XlaHostSendRecvDeviceContextTest, CopyCPUTensorToDevice) {\n       platform->ExecutorForDevice(0).value();\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n \n-  se::DeviceMemoryBase gpu_dst{device_tensor.data(), 4 * sizeof(float)};\n+  stream_executor::DeviceAddressBase gpu_dst{device_tensor.data(),\n+                                             4 * sizeof(float)};\n   xla::Shape shape;\n   TF_ASSERT_OK(TensorShapeToXLAShape(DT_FLOAT, TensorShape({2, 2}), &shape));\n \n@@ -144,7 +146,8 @@ TEST_F(XlaHostSendRecvDeviceContextTest, RoundTrip) {\n       platform->ExecutorForDevice(0).value();\n   TF_ASSERT_OK_AND_ASSIGN(auto stream, executor->CreateStream());\n \n-  se::DeviceMemoryBase gpu_dst{device_tensor.data(), 4 * sizeof(float)};\n+  stream_executor::DeviceAddressBase gpu_dst{device_tensor.data(),\n+                                             4 * sizeof(float)};\n   xla::Shape shape;\n   TF_ASSERT_OK(TensorShapeToXLAShape(DT_FLOAT, TensorShape({2, 2}), &shape));\n "
        }
    ],
    "stats": {
        "total": 19,
        "additions": 11,
        "deletions": 8
    }
}