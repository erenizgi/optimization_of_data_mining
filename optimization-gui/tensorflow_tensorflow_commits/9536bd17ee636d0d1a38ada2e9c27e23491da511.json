{
    "author": "tensorflower-gardener",
    "message": "Add flag to prioritize aggressive flex annotation scheduling over memory pressure\n\nPiperOrigin-RevId: 798631247",
    "sha": "9536bd17ee636d0d1a38ada2e9c27e23491da511",
    "files": [
        {
            "sha": "e38716f5f0df417238d2d72faadc33ba14903f24",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.cc",
            "status": "modified",
            "additions": 28,
            "deletions": 14,
            "changes": 42,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9536bd17ee636d0d1a38ada2e9c27e23491da511/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9536bd17ee636d0d1a38ada2e9c27e23491da511/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.cc?ref=9536bd17ee636d0d1a38ada2e9c27e23491da511",
            "patch": "@@ -1256,10 +1256,24 @@ class ReadySetLt {\n     // the heuristic algorithm.\n     CMP_PROPERTY(GetPreference(), \"kPreference\");\n \n+    const SchedulerConfig& config = sched_state_.config;\n+    if (config.force_delay_over_memory_pressure) {\n+      if (ABSL_PREDICT_FALSE(has_early_target_scheduling_rule_)) {\n+        if (auto value = InvokeTargetSchedulingFunction(\n+                early_target_scheduling_rule_, a, b, reason)) {\n+          return *value;\n+        }\n+      }\n+\n+      // Schedule according to ForceDelayAfterTarget when we executed the\n+      // early target scheduling rule.\n+      CMP_EXPLICIT(!an->GetForceDelayAfterTarget(),\n+                   !bn->GetForceDelayAfterTarget(), \"kForceDelayAfterTarget\");\n+    }\n+\n     std::pair<int64_t, int64_t> a_increase = {0, 0};\n     std::pair<int64_t, int64_t> b_increase = {0, 0};\n     bool computed_memory_increases = true;\n-\n     if (config_has_memory_limit_ &&\n         sched_state_.memory_pressure_tracker->memory_usage() >\n             (config_memory_limit_ / 2)) {\n@@ -1273,21 +1287,20 @@ class ReadySetLt {\n       }\n     }\n \n-    const SchedulerConfig& config = sched_state_.config;\n-    const bool aggressive_scheduling_policies =\n-        config.aggressive_scheduling_policies;\n-\n-    if (ABSL_PREDICT_FALSE(has_early_target_scheduling_rule_)) {\n-      if (auto value = InvokeTargetSchedulingFunction(\n-              early_target_scheduling_rule_, a, b, reason)) {\n-        return *value;\n+    if (!config.force_delay_over_memory_pressure) {\n+      if (ABSL_PREDICT_FALSE(has_early_target_scheduling_rule_)) {\n+        if (auto value = InvokeTargetSchedulingFunction(\n+                early_target_scheduling_rule_, a, b, reason)) {\n+          return *value;\n+        }\n       }\n+\n+      // Schedule according to ForceDelayAfterTarget when we executed the\n+      // early target scheduling rule.\n+      CMP_EXPLICIT(!an->GetForceDelayAfterTarget(),\n+                   !bn->GetForceDelayAfterTarget(), \"kForceDelayAfterTarget\");\n     }\n \n-    // Schedule according to ForceDelayAfterTarget when we executed the\n-    // early target scheduling rule.\n-    CMP_EXPLICIT(!an->GetForceDelayAfterTarget(),\n-                 !bn->GetForceDelayAfterTarget(), \"kForceDelayAfterTarget\");\n     // Some heuristic that try to prioritize unlocking \"done\" instructions\n     // so that we can perform overlap. More fancy heuristics can be used by\n     // discovering the closest \"done\" to every instruction and prioritize\n@@ -1312,7 +1325,8 @@ class ReadySetLt {\n         return *value;\n       }\n     }\n-\n+    const bool aggressive_scheduling_policies =\n+        config.aggressive_scheduling_policies;\n     if (aggressive_scheduling_policies &&\n         config.prioritize_async_depth_over_stall) {\n       // If an instruction releasing a resource is not resource constrained and"
        },
        {
            "sha": "34a243c9d81833769ae757b9632950ac7a4b080f",
            "filename": "third_party/xla/xla/service/latency_hiding_scheduler.h",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/9536bd17ee636d0d1a38ada2e9c27e23491da511/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/9536bd17ee636d0d1a38ada2e9c27e23491da511/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Flatency_hiding_scheduler.h?ref=9536bd17ee636d0d1a38ada2e9c27e23491da511",
            "patch": "@@ -160,6 +160,10 @@ struct SchedulerConfig {\n   // If the above flag is also set, force the scheduler to provide maximum delay\n   // to nodes at the stat of a scheduling group.\n   bool aggressive_flexible_annotation_scheduling = false;\n+  // Prioritize  flexible annotation scheduling over memory pressure; this is\n+  // useful when the memory pressure is high. Without this, under high memory\n+  // pressure, aggressive_flexible_annotation_scheduling is not respected.\n+  bool force_delay_over_memory_pressure = false;\n   // If true, estimate the fragmentation size of the module by running the heap\n   // simulator.\n   bool estimate_fragmentation_size = false;"
        }
    ],
    "stats": {
        "total": 46,
        "additions": 32,
        "deletions": 14
    }
}