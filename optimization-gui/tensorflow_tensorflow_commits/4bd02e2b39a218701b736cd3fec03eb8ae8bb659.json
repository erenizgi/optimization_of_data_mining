{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Add device ordinal to the runtime logs.\n\nThis will simplify logs analysis for a given device.\n\nPiperOrigin-RevId: 800891193",
    "sha": "4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
    "files": [
        {
            "sha": "37d1e561f20ae46aa2d287aeff548f1510a7990b",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_gather_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_gather_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -109,7 +109,8 @@ absl::Status RunAllGather(std::vector<DeviceBufferPair>& buffers,\n                           se::Stream& stream, Communicator* comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing all-gather from device ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing all-gather from device ordinal: \" << device_ordinal;\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n   auto* gpu_comm = tsl::down_cast<GpuCommunicator*>(comm);\n@@ -125,7 +126,8 @@ absl::Status RunAllGather(std::vector<DeviceBufferPair>& buffers,\n       });\n \n   tsl::BlockUntilReady(event);\n-  VLOG(3) << \"Done performing all-gather for ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Done performing all-gather for ordinal: \" << device_ordinal;\n   if (event.IsError()) {\n     return event.GetError();\n   }"
        },
        {
            "sha": "f5c7541a6d9e355bd9b33921e5b2a8913f829c18",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_reduce_thunk.cc",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_reduce_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -87,7 +87,8 @@ absl::Status RunAllReduce(ReductionKind reduction_kind,\n                           se::Stream& stream, Communicator* comm,\n                           bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing all-reduce from device ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing all-reduce from device ordinal: \" << device_ordinal;\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n \n@@ -104,7 +105,8 @@ absl::Status RunAllReduce(ReductionKind reduction_kind,\n         return absl::OkStatus();\n       });\n   tsl::BlockUntilReady(event);\n-  VLOG(3) << \"Done performing all-reduce for ordinal: \" << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Done performing all-reduce for ordinal: \" << device_ordinal;\n   if (event.IsError()) {\n     return event.GetError();\n   }"
        },
        {
            "sha": "efd734cc04a145960aa4fb15290df6362b76e41a",
            "filename": "third_party/xla/xla/backends/gpu/runtime/all_to_all_thunk.cc",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fall_to_all_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -118,7 +118,8 @@ absl::Status AllToAllStartThunk::Initialize(const InitializeParams& params) {\n   TF_RETURN_IF_ERROR(CollectiveThunk::Initialize(params));\n   device_count_ = params.local_device_count;\n   CHECK_GT(device_count_, 0);\n-  VLOG(5) << \"Local device count: \" << device_count_;\n+  VLOG(5) << \"[\" << params.executor->device_ordinal()\n+          << \"] Local device count : \" << device_count_;\n \n   if (is_local() && p2p_memcpy_enabled_) {\n     TF_ASSIGN_OR_RETURN(GpuCollectives * collectives,\n@@ -270,8 +271,9 @@ absl::Status RunAllToAll(bool has_split_dimension,\n                          se::Stream& stream, Communicator* comm,\n                          bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing all-to-all from device ordinal: \" << device_ordinal\n-          << \", has_split_dimension: \" << has_split_dimension;\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing all-to-all, has_split_dimension: \"\n+          << has_split_dimension;\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm,\n                                           use_symmetric_buffer));\n \n@@ -394,8 +396,7 @@ absl::Status RunMemCpyAllToAll(bool has_split_dimension,\n                                se::Event* event,\n                                std::vector<se::Event*>& events) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing mem-copy-all-to-all from device ordinal: \"\n-          << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing mem-copy-all-to-all\";\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm));\n   TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n   TF_RETURN_IF_ERROR(SyncProgress(\"before memcpy all-to-all\", clique_key, rank,"
        },
        {
            "sha": "292593a790730aa0d5563c6c4f16562ab430a448",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_thunk.cc",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -380,15 +380,16 @@ absl::Status RegisterBufferOnce(se::StreamExecutor* executor,\n                                           buffer.opaque()})) {\n       need_reg = true;\n     } else {\n-      VLOG(5) << \"Buffer: \" << buffer.opaque()\n+      VLOG(5) << \"[\" << executor->device_ordinal()\n+              << \"] Buffer: \" << buffer.opaque()\n               << \" with size: \" << buffer.size()\n               << \" and base pointer: \" << base_buffer.opaque()\n               << \" is already registered.\";\n     }\n   }\n   if (need_reg) {\n-    VLOG(5) << \"Registering \" << buffer.opaque()\n-            << \" with size: \" << buffer.size()\n+    VLOG(5) << \"[\" << executor->device_ordinal() << \"] Registering \"\n+            << buffer.opaque() << \" with size: \" << buffer.size()\n             << \" and base pointer: \" << base_buffer.opaque()\n             << \", is symmetric: \" << (use_symmetric_buffer ? \"true\" : \"false\");\n     // Symmetric buffer registration is a collective operation,\n@@ -463,8 +464,9 @@ absl::Status CollectiveThunk::Initialize(const InitializeParams& params) {\n }\n \n absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n-  VLOG(1) << absl::StreamFormat(\"Starting %s %s.\", IsAsync() ? \"async\" : \"sync\",\n-                                Thunk::KindToString(kind()));\n+  VLOG(1) << absl::StreamFormat(\n+      \"[%d] Starting %s %s.\", params.stream->parent()->device_ordinal(),\n+      IsAsync() ? \"async\" : \"sync\", Thunk::KindToString(kind()));\n   AsyncStreamKind stream_kind = GetAsyncStreamKind();\n   TF_ASSIGN_OR_RETURN(GpuCollectives * collectives, GetGpuCollectives(params));\n   TF_ASSIGN_OR_RETURN(\n@@ -508,7 +510,8 @@ absl::Status CollectiveThunk::ExecuteOnStream(const ExecuteParams& params) {\n \n     auto global_device_id = params.collective_params->global_device_id;\n     RankId rank = clique_key.rank(global_device_id).value_or(RankId(-1));\n-    VLOG(1) << \"Do a rendezvous after a first call to \"\n+    VLOG(1) << \"[\" << global_device_id.value()\n+            << \"] Do a rendezvous after a first call to \"\n             << Thunk::KindToString(kind())\n             << \"; run_id=\" << params.collective_params->run_id.ToInt()\n             << \"; op_id=\" << config().op_id"
        },
        {
            "sha": "157fa72f3b0a85592230207d967dc2256c52b0ba",
            "filename": "third_party/xla/xla/backends/gpu/runtime/command_buffer_cmd.cc",
            "status": "modified",
            "additions": 34,
            "deletions": 21,
            "changes": 55,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcommand_buffer_cmd.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -1943,12 +1943,15 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllReduceCmd::Record(\n       ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n                              config().operand_element_type));\n \n-  VLOG(5) << \"AllReduceCmd: reduction=\" << ReductionKindString(reduction_kind_);\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal << \"] AllReduceCmd: reduction=\"\n+          << ReductionKindString(reduction_kind_);\n \n   for (size_t i = 0; i < device_buffers.size(); ++i) {\n-    VLOG(5) << \"  Src: \" << buffers_[i].source_buffer << \" (\"\n-            << device_buffers[i].source_buffer.opaque() << \")\";\n-    VLOG(5) << \"  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n             << device_buffers[i].destination_buffer.opaque() << \")\";\n   }\n \n@@ -2005,13 +2008,15 @@ absl::StatusOr<const se::CommandBuffer::Command*> ReduceScatterCmd::Record(\n       ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n                              config().operand_element_type));\n \n-  VLOG(5) << \"ReduceScatterCmd: reduction=\"\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal << \"] ReduceScatterCmd: reduction=\"\n           << ReductionKindString(reduction_kind_);\n \n   for (size_t i = 0; i < device_buffers.size(); ++i) {\n-    VLOG(5) << \"  Src: \" << buffers_[i].source_buffer << \" (\"\n-            << device_buffers[i].source_buffer.opaque() << \")\";\n-    VLOG(5) << \"  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n             << device_buffers[i].destination_buffer.opaque() << \")\";\n   }\n \n@@ -2069,12 +2074,15 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllToAllCmd::Record(\n       ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n                              config().operand_element_type));\n \n-  VLOG(5) << \"AllToAllCmd, has_split_dimension=\" << has_split_dimension_;\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal\n+          << \"] AllToAllCmd, has_split_dimension=\" << has_split_dimension_;\n \n   for (size_t i = 0; i < device_buffers.size(); ++i) {\n-    VLOG(5) << \"  Src: \" << buffers_[i].source_buffer << \" (\"\n-            << device_buffers[i].source_buffer.opaque() << \")\";\n-    VLOG(5) << \"  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n             << device_buffers[i].destination_buffer.opaque() << \")\";\n   }\n \n@@ -2128,12 +2136,14 @@ absl::StatusOr<const se::CommandBuffer::Command*> AllGatherCmd::Record(\n       ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n                              config().operand_element_type));\n \n-  VLOG(5) << \"AllGatherCmd:\";\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal << \"] AllGatherCmd:\";\n \n   for (size_t i = 0; i < device_buffers.size(); ++i) {\n-    VLOG(5) << \"  Src: \" << buffers_[i].source_buffer << \" (\"\n-            << device_buffers[i].source_buffer.opaque() << \")\";\n-    VLOG(5) << \"  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n             << device_buffers[i].destination_buffer.opaque() << \")\";\n   }\n \n@@ -2189,12 +2199,14 @@ CollectiveBroadcastCmd::Record(const Thunk::ExecuteParams& execute_params,\n       ConvertToDeviceBuffers(execute_params.buffer_allocations, buffers_,\n                              config().operand_element_type));\n \n-  VLOG(5) << \"CollectiveBroadcastCmd:\";\n+  int device_ordinal = execute_params.stream->parent()->device_ordinal();\n+  VLOG(5) << \"[\" << device_ordinal << \"] CollectiveBroadcastCmd:\";\n \n   for (size_t i = 0; i < device_buffers.size(); ++i) {\n-    VLOG(5) << \"  Src: \" << buffers_[i].source_buffer << \" (\"\n-            << device_buffers[i].source_buffer.opaque() << \")\";\n-    VLOG(5) << \"  Dst: \" << buffers_[i].destination_buffer << \" (\"\n+    VLOG(5) << \"[\" << device_ordinal << \"]  Src: \" << buffers_[i].source_buffer\n+            << \" (\" << device_buffers[i].source_buffer.opaque() << \")\";\n+    VLOG(5) << \"[\" << device_ordinal\n+            << \"]  Dst: \" << buffers_[i].destination_buffer << \" (\"\n             << device_buffers[i].destination_buffer.opaque() << \")\";\n   }\n \n@@ -2296,7 +2308,8 @@ absl::Status DynamicSliceFusionCmd::Initialize(\n     return absl::OkStatus();\n   }\n \n-  VLOG(2) << \"Allocate \" << offsets_allocs_size_\n+  VLOG(2) << \"[\" << params.executor->device_ordinal() << \"] Allocate \"\n+          << offsets_allocs_size_\n           << \" bytes for transferring offsets on executor: \" << params.executor;\n   TF_ASSIGN_OR_RETURN(\n       std::unique_ptr<se::MemoryAllocation> allocation,"
        },
        {
            "sha": "2c3e8e7d49d198918035c9c7d5d9a796d9faf8dd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/kernel_thunk.cc",
            "status": "modified",
            "additions": 13,
            "deletions": 8,
            "changes": 21,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fkernel_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -212,25 +212,27 @@ absl::Status KernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n     kernel = it->second.get();\n   }\n \n-  VLOG(3) << \"Launching \" << kernel->name();\n+  int device_ordinal = executor->device_ordinal();\n+  VLOG(3) << \"[\" << device_ordinal << \"] Launching \" << kernel->name();\n   absl::InlinedVector<std::variant<se::DeviceMemoryBase, se::TensorMap>, 4>\n       kernel_args;\n   stream_executor::gpu::TmaMetadata tma_metadata =\n       tma_metadata_.value_or(stream_executor::gpu::TmaMetadata{});\n   for (int idx = 0; idx < args_.size(); ++idx) {\n     const BufferAllocation::Slice& arg = args_[idx];\n     se::DeviceMemoryBase buf = params.buffer_allocations->GetDeviceAddress(arg);\n-    VLOG(3) << \"  Arg: alloc #\" << arg.index() << \", offset: \" << arg.offset()\n-            << \": \" << buf.opaque() << \" (\" << buf.size() << \"B)\";\n+    VLOG(3) << \"[\" << device_ordinal << \"] Arg: alloc #\" << arg.index()\n+            << \", offset: \" << arg.offset() << \": \" << buf.opaque() << \" (\"\n+            << buf.size() << \"B)\";\n \n     if (auto it = tma_metadata.arg_index_to_tma_info.find(idx);\n         it != tma_metadata.arg_index_to_tma_info.end()) {\n       // TMA descriptor argument.\n       stream_executor::gpu::TmaDescriptor tma_desc = it->second;\n       TF_ASSIGN_OR_RETURN(se::TensorMap tensor_map,\n                           executor->CreateTensorMap(tma_desc, buf.opaque()));\n-      VLOG(3) << \"  Using TensorMap for arg #\" << idx << \": \"\n-              << tma_desc.ToString();\n+      VLOG(3) << \"[\" << device_ordinal << \"]  Using TensorMap for arg #\" << idx\n+              << \": \" << tma_desc.ToString();\n       kernel_args.push_back(std::move(tensor_map));\n     } else {\n       // Buffer argument.\n@@ -287,14 +289,17 @@ absl::Status CustomKernelThunk::ExecuteOnStream(const ExecuteParams& params) {\n     return kernel_cache_[executor].get();\n   }();\n \n-  VLOG(3) << \"Launching \" << custom_kernel_.ToString() << \" as device kernel \"\n+  int device_ordinal = executor->device_ordinal();\n+  VLOG(3) << \"[\" << device_ordinal << \"] Launching \"\n+          << custom_kernel_.ToString() << \" as device kernel \"\n           << kernel->name();\n \n   absl::InlinedVector<se::DeviceMemoryBase, 4> buffer_args;\n   for (const BufferAllocation::Slice& arg : args_) {\n     se::DeviceMemoryBase buf = params.buffer_allocations->GetDeviceAddress(arg);\n-    VLOG(3) << \"  Arg: alloc #\" << arg.index() << \", offset: \" << arg.offset()\n-            << \": \" << buf.opaque() << \" (\" << buf.size() << \"B)\";\n+    VLOG(3) << \"[\" << device_ordinal << \"]  Arg: alloc #\" << arg.index()\n+            << \", offset: \" << arg.offset() << \": \" << buf.opaque() << \" (\"\n+            << buf.size() << \"B)\";\n     buffer_args.push_back(buf);\n   }\n "
        },
        {
            "sha": "890ef29772ac5f915ff4bcc7dfd915206fef9afe",
            "filename": "third_party/xla/xla/backends/gpu/runtime/ragged_all_to_all_thunk.cc",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fragged_all_to_all_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -150,7 +150,8 @@ absl::Status RunRaggedAllToAll(\n     const se::DeviceMemoryBase& output_offsets_device_buffer,\n     bool use_symmetric_buffer) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing ragged-all-to-all from device ordinal: \"\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing ragged-all-to-all from device ordinal: \"\n           << device_ordinal;\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), original_buffers,\n                                           comm, use_symmetric_buffer));\n@@ -323,8 +324,7 @@ absl::Status RunMemCpyRaggedAllToAll(\n     Communicator* comm, const std::vector<int64_t*>& ragged_metadata_allocs,\n     se::Event* start_event, se::Event* end_event) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing mem-copy-ragged-all-to-all from device ordinal: \"\n-          << device_ordinal;\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing mem-copy-ragged-all-to-all\";\n   TF_RETURN_IF_ERROR(MaybeRegisterBuffers(stream.parent(), buffers, comm));\n \n   TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n@@ -380,8 +380,8 @@ absl::Status RunOneShotRaggedAllToAll(\n     RankId rank, Communicator* comm, se::Event* start_event,\n     se::Event* end_event) {\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing one-shot ragged-all-to-all from device ordinal: \"\n-          << device_ordinal << \", rank: \" << rank.value();\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing one-shot ragged-all-to-all rank: \" << rank.value();\n \n   TF_ASSIGN_OR_RETURN(int32_t num_ranks, comm->NumRanks());\n "
        },
        {
            "sha": "6dcde53c21ae42ac743dba88a4e5f575b7f2eecd",
            "filename": "third_party/xla/xla/backends/gpu/runtime/recv_thunk.cc",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Frecv_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -94,8 +94,8 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n   // the peer that will copy its data to this instance. If there is no\n   // source, just memzero() the destination buffer.\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing Recv from device ordinal: \" << device_ordinal\n-          << \", current_id: \" << current_id << \", group mode: \"\n+  VLOG(3) << \"[\" << device_ordinal\n+          << \"] Performing Recv, current_id: \" << current_id << \", group mode: \"\n           << CollectiveOpGroupModeToString(config_.config.group_mode) << \" (\"\n           << hlo_name_ << \")\";\n \n@@ -105,8 +105,9 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n   const std::optional<int64_t> source_id = source_target.source;\n   se::DeviceMemoryBase dest_addr = buffer.destination_buffer;\n \n-  VLOG(3) << absl::StreamFormat(\"%s : id = %d, source_id = %d\", device_string,\n-                                current_id, source_id.value_or(-1));\n+  VLOG(3) << absl::StreamFormat(\"[%d] %s : id = %d, source_id = %d\",\n+                                device_ordinal, device_string, current_id,\n+                                source_id.value_or(-1));\n \n   // Receive data from the source peer to the destination buffer.\n   if (source_id) {\n@@ -126,7 +127,8 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n       if (*counter < it->second.first || *counter > it->second.second) {\n         should_run = false;\n       }\n-      VLOG(3) << \"RunCollective counter \" << *counter << \" \" << should_run;\n+      VLOG(3) << \"[\" << device_ordinal << \"] RunCollective counter \" << *counter\n+              << \" \" << should_run;\n       ++(*counter);\n     }\n     if (should_run) {\n@@ -139,13 +141,14 @@ absl::StatusOr<bool> RecvThunk::RunCollective(const ExecuteParams& params,\n         return event.GetError();\n       }\n     } else {\n-      VLOG(3) << \"Skipping Recv\";\n+      VLOG(3) << \"[\" << device_ordinal << \"] Skipping Recv\";\n     }\n \n   } else {\n     // If there is no source peer, i.e. no sender to this instance, zero out\n     // the destination buffer.\n-    VLOG(3) << absl::StreamFormat(\"%s : Recv: Issuing MemZero\", device_string);\n+    VLOG(3) << absl::StreamFormat(\"[%d] %s : Recv: Issuing MemZero\",\n+                                  device_ordinal, device_string);\n     TF_RETURN_IF_ERROR(stream.MemZero(&dest_addr, dest_addr.size()));\n   }\n   return false;"
        },
        {
            "sha": "77d8f353178b0bf78b1dc5c736a7f38e809e6456",
            "filename": "third_party/xla/xla/backends/gpu/runtime/send_thunk.cc",
            "status": "modified",
            "additions": 7,
            "deletions": 5,
            "changes": 12,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fsend_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -94,7 +94,7 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n   // Determine the target IDs for this instance. The target ID is the ID\n   // to which this instance will copy its data.\n   int device_ordinal = stream.parent()->device_ordinal();\n-  VLOG(3) << \"Performing Send from device ordinal: \" << device_ordinal\n+  VLOG(3) << \"[\" << device_ordinal << \"] Performing Send \"\n           << \", current_id: \" << current_id << \", group mode: \"\n           << CollectiveOpGroupModeToString(config_.config.group_mode) << \" (\"\n           << hlo_name_ << \")\";\n@@ -105,8 +105,9 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n   const std::optional<int64_t> target_id = source_target.target;\n   se::DeviceMemoryBase src_addr = buffer.source_buffer;\n \n-  VLOG(3) << absl::StreamFormat(\"%s : id = %d, target_id = %d\", device_string,\n-                                current_id, target_id.value_or(-1));\n+  VLOG(3) << absl::StreamFormat(\"[%d] %s : id = %d, target_id = %d\",\n+                                device_ordinal, device_string, current_id,\n+                                target_id.value_or(-1));\n \n   // Send source buffer to target peer if needed.\n   if (target_id) {\n@@ -126,7 +127,8 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n       if (*counter < it->second.first || *counter > it->second.second) {\n         should_run = false;\n       }\n-      VLOG(3) << \"RunCollective counter \" << *counter << \" \" << should_run;\n+      VLOG(3) << \"[\" << device_ordinal << \"] RunCollective counter \" << *counter\n+              << \" \" << should_run;\n       ++(*counter);\n     }\n \n@@ -140,7 +142,7 @@ absl::StatusOr<bool> SendThunk::RunCollective(const ExecuteParams& params,\n         return event.GetError();\n       }\n     } else {\n-      VLOG(3) << \"Skipping Send\";\n+      VLOG(3) << \"[\" << device_ordinal << \"] Skipping Send\";\n     }\n   }\n "
        },
        {
            "sha": "848dfd5a990dc40057c8970a756645e911543a2f",
            "filename": "third_party/xla/xla/backends/gpu/runtime/while_thunk.cc",
            "status": "modified",
            "additions": 12,
            "deletions": 6,
            "changes": 18,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/4bd02e2b39a218701b736cd3fec03eb8ae8bb659/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fwhile_thunk.cc?ref=4bd02e2b39a218701b736cd3fec03eb8ae8bb659",
            "patch": "@@ -128,10 +128,12 @@ absl::Status WhileThunk::ExecuteOnStream(const ExecuteParams& params) {\n   int64_t& iter = loop.counter;\n   absl::Cleanup cleanup = [&] { RunningLoops().pop_front(); };\n \n+  int device_ordinal = stream.parent()->device_ordinal();\n   if (trip_count_.has_value()) {\n-    VLOG(2) << \"Executing WhileThunk for \" << *trip_count_ << \" iterations\";\n+    VLOG(2) << \"[\" << device_ordinal << \"] Executing WhileThunk for \"\n+            << *trip_count_ << \" iterations\";\n     for (iter = 0; iter < trip_count_; ++iter) {\n-      VLOG(3) << \"Executing iteration # \" << iter\n+      VLOG(3) << \"[\" << device_ordinal << \"] Executing iteration # \" << iter\n               << \" (Device: \" << stream.parent()->device_ordinal() << \")\";\n       TF_RETURN_IF_ERROR(body_thunk_sequence_->ExecuteOnStream(params));\n     }\n@@ -152,7 +154,8 @@ absl::Status WhileThunk::ExecuteOnStream(const ExecuteParams& params) {\n   while (true) {\n     TraceMe trace(\n         [&] { return TraceMeEncode(\"While\", {{\"iteration:\", iter}}); });\n-    VLOG(3) << \"Executing WhileThunk condition computation; iter=\" << iter;\n+    VLOG(3) << \"[\" << device_ordinal\n+            << \"] Executing WhileThunk condition computation; iter=\" << iter;\n     TF_RETURN_IF_ERROR(condition_thunk_sequence_->ExecuteOnStream(params));\n \n     // Copy the result of condition computation and break the loop if 'false'.\n@@ -165,13 +168,16 @@ absl::Status WhileThunk::ExecuteOnStream(const ExecuteParams& params) {\n           blocked.message()));\n     }\n \n-    VLOG(3) << \"condition_result = \" << *condition_result;\n+    VLOG(3) << \"[\" << device_ordinal\n+            << \"] condition_result = \" << *condition_result;\n     if (!*condition_result) {\n-      VLOG(3) << \"Break WhileThunk loop; iter=\" << iter;\n+      VLOG(3) << \"[\" << device_ordinal\n+              << \"] Break WhileThunk loop; iter=\" << iter;\n       break;\n     }\n \n-    VLOG(3) << \"Executing WhileThunk body computation; iter=\" << iter\n+    VLOG(3) << \"[\" << device_ordinal\n+            << \"] Executing WhileThunk body computation; iter=\" << iter\n             << \" (Device: \" << stream.parent()->device_ordinal() << \")\";\n     TF_RETURN_IF_ERROR(body_thunk_sequence_->ExecuteOnStream(params));\n     ++iter;"
        }
    ],
    "stats": {
        "total": 171,
        "additions": 104,
        "deletions": 67
    }
}