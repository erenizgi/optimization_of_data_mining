{
    "author": "frgossen",
    "message": "[XLA:GPU] Update ICI collectives perf table for B200\n\nPiperOrigin-RevId: 801093043",
    "sha": "adddbdb26520b6ade029a1641050cf634b36e34f",
    "files": [
        {
            "sha": "edb3434177f701caccbc45cf73bb967c304b81dd",
            "filename": "third_party/xla/xla/service/gpu/model/collective_interpolator_data.h",
            "status": "modified",
            "additions": 7925,
            "deletions": 0,
            "changes": 7925,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adddbdb26520b6ade029a1641050cf634b36e34f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_data.h",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adddbdb26520b6ade029a1641050cf634b36e34f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_data.h",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_data.h?ref=adddbdb26520b6ade029a1641050cf634b36e34f"
        },
        {
            "sha": "91e83a802b07af43c02272fbeacca8b57d556ff9",
            "filename": "third_party/xla/xla/service/gpu/model/collective_interpolator_test.cc",
            "status": "modified",
            "additions": 43,
            "deletions": 15,
            "changes": 58,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/adddbdb26520b6ade029a1641050cf634b36e34f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_test.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/adddbdb26520b6ade029a1641050cf634b36e34f/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_test.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fservice%2Fgpu%2Fmodel%2Fcollective_interpolator_test.cc?ref=adddbdb26520b6ade029a1641050cf634b36e34f",
            "patch": "@@ -80,8 +80,7 @@ class CollectiveInterpolationTest : public TestWithParam<ParametrizedTestCase> {\n           space_spec.network_througput_bytes);\n       *profiles.add_entries() = entry;\n     }\n-    device_info_ = TestGpuDeviceInfo::RTXA6000DeviceInfo(\n-        stream_executor::CudaComputeCapability::Hopper());\n+    device_info_ = TestGpuDeviceInfo::RTXA6000DeviceInfo();\n     interpolator_ = *CollectiveInterpolator::Create(kNumGpusPerHost, profiles,\n                                                     device_info_);\n   }\n@@ -1020,36 +1019,65 @@ INSTANTIATE_TEST_SUITE_P(\n       return info.param.test_name;\n     });\n \n-TEST(CollectiveInterpolatorTest, LoadsDefaultProfile) {\n-  auto device_info = TestGpuDeviceInfo::RTXA6000DeviceInfo(\n-      stream_executor::CudaComputeCapability::Hopper());\n+struct CollectiveInterpolationWithDefaultProfileTestCase {\n+  std::string test_name;\n+  stream_executor::GpuComputeCapability cc;\n+  absl::Duration expected_duration;\n+};\n+\n+class CollectiveInterpolationWithDefaultProfileTest\n+    : public TestWithParam<CollectiveInterpolationWithDefaultProfileTestCase> {\n+};\n+\n+TEST_P(CollectiveInterpolationWithDefaultProfileTest, LoadsDefaultProfile) {\n+  const auto& [test_name, cc, expected_duration] = GetParam();\n+  auto device_info = TestGpuDeviceInfo::RTXA6000DeviceInfo(cc);\n   TF_ASSERT_OK_AND_ASSIGN(\n       std::unique_ptr<CollectiveInterpolator> interpolator,\n       CollectiveInterpolator::Create(kNumGpusPerHost, device_info));\n   absl::string_view kHlo = R\"(\n     HloModule m, num_partitions=8\n \n     wrapped_add {\n-        a = f32[] parameter(0)\n-        b = f32[] parameter(1)\n-        ROOT _ = f32[] add(a,b)\n+      a = f32[] parameter(0)\n+      b = f32[] parameter(1)\n+      ROOT _ = f32[] add(a,b)\n     }\n \n     ENTRY main {\n-        p = f32[256] parameter(0)\n-        ROOT _ = f32[256] all-reduce(p),\n-        to_apply=wrapped_add,\n-        replica_groups=[1,8]<=[8],\n-        use_global_device_ids=true,\n-        channel_id=1\n+      p = f32[256] parameter(0)\n+      ROOT _ = f32[256] all-reduce(p), to_apply=wrapped_add,\n+          replica_groups=[1,8]<=[8], use_global_device_ids=true, channel_id=1\n     }\n )\";\n   TF_ASSERT_OK_AND_ASSIGN(auto module, ParseAndReturnUnverifiedModule(kHlo));\n   HloCollectiveInstruction* instr = Cast<HloCollectiveInstruction>(\n       module->entry_computation()->root_instruction());\n \n-  EXPECT_TRUE(interpolator->EstimatedRuntime(*instr).ok());\n+  absl::StatusOr<absl::Duration> runtime =\n+      interpolator->EstimatedRuntime(*instr);\n+  EXPECT_TRUE(runtime.ok());\n+  EXPECT_EQ(runtime.value(), expected_duration);\n }\n \n+INSTANTIATE_TEST_SUITE_P(\n+    CollectiveInterpolationWithDefaultProfileTestInstantiation,\n+    CollectiveInterpolationWithDefaultProfileTest,\n+    ValuesIn<CollectiveInterpolationWithDefaultProfileTestCase>(\n+        {{\n+             \"H100\",\n+             se::CudaComputeCapability(9, 0),\n+             absl::Microseconds(49.312),\n+         },\n+         {\n+             \"B200\",\n+             se::CudaComputeCapability(10, 0),\n+             absl::Microseconds(45.024),\n+         }}),\n+    [](const TestParamInfo<\n+        CollectiveInterpolationWithDefaultProfileTest::ParamType>& info) {\n+      return info.param.test_name;\n+    });\n+\n }  // namespace\n }  // namespace xla::gpu"
        }
    ],
    "stats": {
        "total": 7983,
        "additions": 7968,
        "deletions": 15
    }
}