{
    "author": "tensorflower-gardener",
    "message": "[XLA:GPU] Fix usage of P2P memory type by cuda executor.\n\nPiperOrigin-RevId: 810805623",
    "sha": "d6c5da4f4b7e464fc303acd515e3441492f80c83",
    "files": [
        {
            "sha": "36d5a951263485b78543408be3745459aaac06f0",
            "filename": "third_party/xla/xla/backends/gpu/runtime/BUILD",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2FBUILD?ref=d6c5da4f4b7e464fc303acd515e3441492f80c83",
            "patch": "@@ -1105,6 +1105,7 @@ cc_library(\n         \"//xla/stream_executor:device_memory\",\n         \"//xla/stream_executor:device_memory_handle\",\n         \"//xla/stream_executor:stream\",\n+        \"//xla/stream_executor:stream_executor_h\",\n         \"//xla/stream_executor/gpu:all_reduce_kernel\",\n         \"//xla/stream_executor/gpu:collective_kernel_metadata\",\n         \"//xla/tsl/platform:errors\","
        },
        {
            "sha": "1d92c9eebf20b5d94b545a49f5eb4f08b892742e",
            "filename": "third_party/xla/xla/backends/gpu/runtime/collective_kernel_thunk.cc",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fbackends%2Fgpu%2Fruntime%2Fcollective_kernel_thunk.cc?ref=d6c5da4f4b7e464fc303acd515e3441492f80c83",
            "patch": "@@ -45,6 +45,7 @@ limitations under the License.*/\n #include \"xla/stream_executor/gpu/all_reduce_kernel.h\"\n #include \"xla/stream_executor/gpu/collective_kernel_metadata.h\"\n #include \"xla/stream_executor/stream.h\"\n+#include \"xla/stream_executor/stream_executor.h\"\n #include \"xla/tsl/platform/errors.h\"\n #include \"xla/tsl/platform/statusor.h\"\n #include \"xla/util.h\""
        },
        {
            "sha": "a5ed51f64a6391eee42b9d035f1df559f63ef700",
            "filename": "third_party/xla/xla/stream_executor/cuda/cuda_executor.cc",
            "status": "modified",
            "additions": 15,
            "deletions": 5,
            "changes": 20,
            "blob_url": "https://github.com/tensorflow/tensorflow/blob/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "raw_url": "https://github.com/tensorflow/tensorflow/raw/d6c5da4f4b7e464fc303acd515e3441492f80c83/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc",
            "contents_url": "https://api.github.com/repos/tensorflow/tensorflow/contents/third_party%2Fxla%2Fxla%2Fstream_executor%2Fcuda%2Fcuda_executor.cc?ref=d6c5da4f4b7e464fc303acd515e3441492f80c83",
            "patch": "@@ -717,7 +717,9 @@ CudaExecutor::CreateMemoryAllocator(MemoryType type) {\n                 }\n               });\n         });\n-  } else if (type == MemoryType::kCollective) {\n+  }\n+\n+  if (type == MemoryType::kCollective) {\n     return std::make_unique<GenericMemoryAllocator>(\n         [this](uint64_t size)\n             -> absl::StatusOr<std::unique_ptr<MemoryAllocation>> {\n@@ -739,11 +741,14 @@ CudaExecutor::CreateMemoryAllocator(MemoryType type) {\n                 }\n               });\n         });\n-  } else if (type == MemoryType::kHost) {\n+  }\n+\n+  if (type == MemoryType::kHost) {\n     return std::make_unique<GenericMemoryAllocator>([this](uint64_t size) {\n       return AllocateHostMemory(cuda_context_, numa_node_, size);\n     });\n   }\n+\n   return absl::UnimplementedError(\n       absl::StrFormat(\"Unsupported memory type %d\", type));\n }\n@@ -1058,8 +1063,10 @@ DeviceMemoryBase CudaExecutor::Allocate(uint64_t size, int64_t memory_space) {\n     VLOG(1) << \"[\" << device_ordinal() << \"] CudaExecutor::Allocate returns \"\n             << result.value();\n     return DeviceMemoryBase(result.value(), size);\n-  } else if (memory_space ==\n-             static_cast<int64_t>(stream_executor::MemoryType::kHost)) {\n+  }\n+\n+  if (memory_space ==\n+      static_cast<int64_t>(stream_executor::MemoryType::kHost)) {\n     auto result = HostAllocate(cuda_context_, numa_node_, size);\n     if (!result.ok()) {\n       LOG(ERROR) << \"[\" << device_ordinal()\n@@ -1070,7 +1077,10 @@ DeviceMemoryBase CudaExecutor::Allocate(uint64_t size, int64_t memory_space) {\n             << result.value();\n     return DeviceMemoryBase(result.value(), size);\n   }\n-  CHECK_EQ(memory_space, 0);\n+\n+  CHECK(memory_space == static_cast<int64_t>(MemoryType::kDevice) ||\n+        memory_space == static_cast<int64_t>(MemoryType::kP2P));\n+\n   auto device_buf_base = DeviceAllocate(cuda_context_, size);\n   VLOG(1) << \"[\" << device_ordinal() << \"] CudaExecutor::Allocate returns \"\n           << device_buf_base;"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 17,
        "deletions": 5
    }
}