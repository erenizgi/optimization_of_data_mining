{
    "author": "vercel-release-bot",
    "message": "Upgrade React from `fa3feba6-20250623` to `cee7939b-20250625` (#80904)\n\n\n\nCo-authored-by: Sebastian Sebbie Silbermann <sebastian.silbermann@vercel.com>",
    "sha": "d93f940a50b810621c0fed839566897a1c375022",
    "files": [
        {
            "sha": "11f67aa0adb783456a6418a3b5ebd8662931edd4",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -35,9 +35,9 @@ checksum = \"512761e0bb2578dd7380c6baaa0f4ce03e84f95e960231d1dec8bf4d7d6e2627\"\n \n [[package]]\n name = \"afl\"\n-version = \"0.15.18\"\n+version = \"0.15.19\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"eda81c043843d2eeb489c3f30774953326fa043b7a6470d4c2ad7c3cdfd9847b\"\n+checksum = \"a2e868a49dcc54f7edcec970721ba68c4b5cc5f1e478393ae2dd2d475efd752e\"\n dependencies = [\n  \"home\",\n  \"libc\",\n@@ -11532,9 +11532,9 @@ dependencies = [\n \n [[package]]\n name = \"xdg\"\n-version = \"2.5.2\"\n+version = \"3.0.0\"\n source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"213b7324336b53d2414b2db8537e56544d981803139155afa84f76eeebb7a546\"\n+checksum = \"2fb433233f2df9344722454bc7e96465c9d03bff9d77c248f9e7523fe79585b5\"\n \n [[package]]\n name = \"xtask\""
        },
        {
            "sha": "7c85e33de0ff2584b2e69f32392db353ae08d2a0",
            "filename": "package.json",
            "status": "modified",
            "additions": 15,
            "deletions": 15,
            "changes": 30,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/package.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/package.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/package.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -233,16 +233,16 @@\n     \"pretty-ms\": \"7.0.0\",\n     \"random-seed\": \"0.3.0\",\n     \"react\": \"19.0.0\",\n-    \"react-builtin\": \"npm:react@19.2.0-canary-fa3feba6-20250623\",\n+    \"react-builtin\": \"npm:react@19.2.0-canary-cee7939b-20250625\",\n     \"react-dom\": \"19.0.0\",\n-    \"react-dom-builtin\": \"npm:react-dom@19.2.0-canary-fa3feba6-20250623\",\n-    \"react-dom-experimental-builtin\": \"npm:react-dom@0.0.0-experimental-fa3feba6-20250623\",\n-    \"react-experimental-builtin\": \"npm:react@0.0.0-experimental-fa3feba6-20250623\",\n-    \"react-is-builtin\": \"npm:react-is@19.2.0-canary-fa3feba6-20250623\",\n-    \"react-server-dom-turbopack\": \"19.2.0-canary-fa3feba6-20250623\",\n-    \"react-server-dom-turbopack-experimental\": \"npm:react-server-dom-turbopack@0.0.0-experimental-fa3feba6-20250623\",\n-    \"react-server-dom-webpack\": \"19.2.0-canary-fa3feba6-20250623\",\n-    \"react-server-dom-webpack-experimental\": \"npm:react-server-dom-webpack@0.0.0-experimental-fa3feba6-20250623\",\n+    \"react-dom-builtin\": \"npm:react-dom@19.2.0-canary-cee7939b-20250625\",\n+    \"react-dom-experimental-builtin\": \"npm:react-dom@0.0.0-experimental-cee7939b-20250625\",\n+    \"react-experimental-builtin\": \"npm:react@0.0.0-experimental-cee7939b-20250625\",\n+    \"react-is-builtin\": \"npm:react-is@19.2.0-canary-cee7939b-20250625\",\n+    \"react-server-dom-turbopack\": \"19.2.0-canary-cee7939b-20250625\",\n+    \"react-server-dom-turbopack-experimental\": \"npm:react-server-dom-turbopack@0.0.0-experimental-cee7939b-20250625\",\n+    \"react-server-dom-webpack\": \"19.2.0-canary-cee7939b-20250625\",\n+    \"react-server-dom-webpack-experimental\": \"npm:react-server-dom-webpack@0.0.0-experimental-cee7939b-20250625\",\n     \"react-ssr-prepass\": \"1.0.8\",\n     \"react-virtualized\": \"9.22.3\",\n     \"relay-compiler\": \"13.0.2\",\n@@ -252,8 +252,8 @@\n     \"resolve-from\": \"5.0.0\",\n     \"sass\": \"1.54.0\",\n     \"satori\": \"0.12.2\",\n-    \"scheduler-builtin\": \"npm:scheduler@0.27.0-canary-fa3feba6-20250623\",\n-    \"scheduler-experimental-builtin\": \"npm:scheduler@0.0.0-experimental-fa3feba6-20250623\",\n+    \"scheduler-builtin\": \"npm:scheduler@0.27.0-canary-cee7939b-20250625\",\n+    \"scheduler-experimental-builtin\": \"npm:scheduler@0.0.0-experimental-cee7939b-20250625\",\n     \"seedrandom\": \"3.0.5\",\n     \"semver\": \"7.3.7\",\n     \"shell-quote\": \"1.7.3\",\n@@ -296,10 +296,10 @@\n       \"@types/react-dom\": \"19.1.2\",\n       \"@types/retry\": \"0.12.0\",\n       \"jest-snapshot\": \"30.0.0-alpha.6\",\n-      \"react\": \"19.2.0-canary-fa3feba6-20250623\",\n-      \"react-dom\": \"19.2.0-canary-fa3feba6-20250623\",\n-      \"react-is\": \"19.2.0-canary-fa3feba6-20250623\",\n-      \"scheduler\": \"0.27.0-canary-fa3feba6-20250623\"\n+      \"react\": \"19.2.0-canary-cee7939b-20250625\",\n+      \"react-dom\": \"19.2.0-canary-cee7939b-20250625\",\n+      \"react-is\": \"19.2.0-canary-cee7939b-20250625\",\n+      \"scheduler\": \"0.27.0-canary-cee7939b-20250625\"\n     },\n     \"patchedDependencies\": {\n       \"webpack-sources@3.2.3\": \"patches/webpack-sources@3.2.3.patch\","
        },
        {
            "sha": "0d894cdff8192b95517b2b2922a40e8d29e117e4",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-client.development.js",
            "status": "modified",
            "additions": 144,
            "deletions": 130,
            "changes": 274,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -648,6 +648,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -820,27 +841,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeFiber(fiber) {\n       switch (fiber.tag) {\n         case 26:\n@@ -878,11 +878,25 @@\n             for (var i = debugInfo.length - 1; 0 <= i; i--) {\n               var entry = debugInfo[i];\n               if (\"string\" === typeof entry.name) {\n-                var JSCompiler_temp_const = info,\n-                  env = entry.env;\n-                var JSCompiler_inline_result = describeBuiltInComponentFrame(\n-                  entry.name + (env ? \" [\" + env + \"]\" : \"\")\n-                );\n+                var JSCompiler_temp_const = info;\n+                a: {\n+                  var name = entry.name,\n+                    env = entry.env,\n+                    location = entry.debugLocation;\n+                  if (null != location) {\n+                    var childStack = formatOwnerStack(location),\n+                      idx = childStack.lastIndexOf(\"\\n\"),\n+                      lastLine =\n+                        -1 === idx ? childStack : childStack.slice(idx + 1);\n+                    if (-1 !== lastLine.indexOf(name)) {\n+                      var JSCompiler_inline_result = \"\\n\" + lastLine;\n+                      break a;\n+                    }\n+                  }\n+                  JSCompiler_inline_result = describeBuiltInComponentFrame(\n+                    name + (env ? \" [\" + env + \"]\" : \"\")\n+                  );\n+                }\n                 info = JSCompiler_temp_const + JSCompiler_inline_result;\n               }\n             }\n@@ -10480,25 +10494,25 @@\n       return current;\n     }\n     function updateSuspenseComponent(current, workInProgress, renderLanes) {\n-      var JSCompiler_object_inline_componentStack_3148;\n-      var JSCompiler_object_inline_stack_3147 = workInProgress.pendingProps;\n+      var JSCompiler_object_inline_componentStack_3152;\n+      var JSCompiler_object_inline_stack_3151 = workInProgress.pendingProps;\n       shouldSuspendImpl(workInProgress) && (workInProgress.flags |= 128);\n-      var JSCompiler_object_inline_digest_3146 = !1;\n+      var JSCompiler_object_inline_digest_3150 = !1;\n       var didSuspend = 0 !== (workInProgress.flags & 128);\n-      (JSCompiler_object_inline_componentStack_3148 = didSuspend) ||\n-        (JSCompiler_object_inline_componentStack_3148 =\n+      (JSCompiler_object_inline_componentStack_3152 = didSuspend) ||\n+        (JSCompiler_object_inline_componentStack_3152 =\n           null !== current && null === current.memoizedState\n             ? !1\n             : 0 !== (suspenseStackCursor.current & ForceSuspenseFallback));\n-      JSCompiler_object_inline_componentStack_3148 &&\n-        ((JSCompiler_object_inline_digest_3146 = !0),\n+      JSCompiler_object_inline_componentStack_3152 &&\n+        ((JSCompiler_object_inline_digest_3150 = !0),\n         (workInProgress.flags &= -129));\n-      JSCompiler_object_inline_componentStack_3148 =\n+      JSCompiler_object_inline_componentStack_3152 =\n         0 !== (workInProgress.flags & 32);\n       workInProgress.flags &= -33;\n       if (null === current) {\n         if (isHydrating) {\n-          JSCompiler_object_inline_digest_3146\n+          JSCompiler_object_inline_digest_3150\n             ? pushPrimaryTreeSuspenseHandler(workInProgress)\n             : reuseSuspenseHandlerOnStack(workInProgress);\n           (current = nextHydratableInstance)\n@@ -10511,20 +10525,20 @@\n                   ? renderLanes\n                   : null),\n               null !== renderLanes &&\n-                ((JSCompiler_object_inline_componentStack_3148 = {\n+                ((JSCompiler_object_inline_componentStack_3152 = {\n                   dehydrated: renderLanes,\n                   treeContext: getSuspendedTreeContext(),\n                   retryLane: 536870912,\n                   hydrationErrors: null\n                 }),\n                 (workInProgress.memoizedState =\n-                  JSCompiler_object_inline_componentStack_3148),\n-                (JSCompiler_object_inline_componentStack_3148 =\n+                  JSCompiler_object_inline_componentStack_3152),\n+                (JSCompiler_object_inline_componentStack_3152 =\n                   createFiberFromDehydratedFragment(renderLanes)),\n-                (JSCompiler_object_inline_componentStack_3148.return =\n+                (JSCompiler_object_inline_componentStack_3152.return =\n                   workInProgress),\n                 (workInProgress.child =\n-                  JSCompiler_object_inline_componentStack_3148),\n+                  JSCompiler_object_inline_componentStack_3152),\n                 (hydrationParentFiber = workInProgress),\n                 (nextHydratableInstance = null)))\n             : (renderLanes = null);\n@@ -10538,12 +10552,12 @@\n             : (workInProgress.lanes = 536870912);\n           return null;\n         }\n-        var nextPrimaryChildren = JSCompiler_object_inline_stack_3147.children,\n-          nextFallbackChildren = JSCompiler_object_inline_stack_3147.fallback;\n-        if (JSCompiler_object_inline_digest_3146)\n+        var nextPrimaryChildren = JSCompiler_object_inline_stack_3151.children,\n+          nextFallbackChildren = JSCompiler_object_inline_stack_3151.fallback;\n+        if (JSCompiler_object_inline_digest_3150)\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3147 =\n+            (JSCompiler_object_inline_stack_3151 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10555,19 +10569,19 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3148,\n+              JSCompiler_object_inline_componentStack_3152,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n-            JSCompiler_object_inline_stack_3147\n+            JSCompiler_object_inline_stack_3151\n           );\n         if (\n           \"number\" ===\n-          typeof JSCompiler_object_inline_stack_3147.unstable_expectedLoadTime\n+          typeof JSCompiler_object_inline_stack_3151.unstable_expectedLoadTime\n         )\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3147 =\n+            (JSCompiler_object_inline_stack_3151 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10579,12 +10593,12 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3148,\n+              JSCompiler_object_inline_componentStack_3152,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n             (workInProgress.lanes = 4194304),\n-            JSCompiler_object_inline_stack_3147\n+            JSCompiler_object_inline_stack_3151\n           );\n         pushPrimaryTreeSuspenseHandler(workInProgress);\n         return mountSuspensePrimaryChildren(\n@@ -10594,8 +10608,8 @@\n       }\n       var prevState = current.memoizedState;\n       if (null !== prevState) {\n-        var JSCompiler_object_inline_message_3145 = prevState.dehydrated;\n-        if (null !== JSCompiler_object_inline_message_3145) {\n+        var JSCompiler_object_inline_message_3149 = prevState.dehydrated;\n+        if (null !== JSCompiler_object_inline_message_3149) {\n           if (didSuspend)\n             workInProgress.flags & 256\n               ? (pushPrimaryTreeSuspenseHandler(workInProgress),\n@@ -10612,13 +10626,13 @@\n                   (workInProgress = null))\n                 : (reuseSuspenseHandlerOnStack(workInProgress),\n                   (nextPrimaryChildren =\n-                    JSCompiler_object_inline_stack_3147.fallback),\n+                    JSCompiler_object_inline_stack_3151.fallback),\n                   (nextFallbackChildren = workInProgress.mode),\n-                  (JSCompiler_object_inline_stack_3147 =\n+                  (JSCompiler_object_inline_stack_3151 =\n                     mountWorkInProgressOffscreenFiber(\n                       {\n                         mode: \"visible\",\n-                        children: JSCompiler_object_inline_stack_3147.children\n+                        children: JSCompiler_object_inline_stack_3151.children\n                       },\n                       nextFallbackChildren\n                     )),\n@@ -10629,73 +10643,73 @@\n                     null\n                   )),\n                   (nextPrimaryChildren.flags |= 2),\n-                  (JSCompiler_object_inline_stack_3147.return = workInProgress),\n+                  (JSCompiler_object_inline_stack_3151.return = workInProgress),\n                   (nextPrimaryChildren.return = workInProgress),\n-                  (JSCompiler_object_inline_stack_3147.sibling =\n+                  (JSCompiler_object_inline_stack_3151.sibling =\n                     nextPrimaryChildren),\n-                  (workInProgress.child = JSCompiler_object_inline_stack_3147),\n+                  (workInProgress.child = JSCompiler_object_inline_stack_3151),\n                   reconcileChildFibers(\n                     workInProgress,\n                     current.child,\n                     null,\n                     renderLanes\n                   ),\n-                  (JSCompiler_object_inline_stack_3147 = workInProgress.child),\n-                  (JSCompiler_object_inline_stack_3147.memoizedState =\n+                  (JSCompiler_object_inline_stack_3151 = workInProgress.child),\n+                  (JSCompiler_object_inline_stack_3151.memoizedState =\n                     mountSuspenseOffscreenState(renderLanes)),\n-                  (JSCompiler_object_inline_stack_3147.childLanes =\n+                  (JSCompiler_object_inline_stack_3151.childLanes =\n                     getRemainingWorkInPrimaryTree(\n                       current,\n-                      JSCompiler_object_inline_componentStack_3148,\n+                      JSCompiler_object_inline_componentStack_3152,\n                       renderLanes\n                     )),\n                   (workInProgress.memoizedState = SUSPENDED_MARKER),\n                   (workInProgress = nextPrimaryChildren));\n           else if (\n             (pushPrimaryTreeSuspenseHandler(workInProgress),\n             warnIfHydrating(),\n-            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3145))\n+            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3149))\n           ) {\n-            JSCompiler_object_inline_componentStack_3148 =\n-              JSCompiler_object_inline_message_3145.nextSibling &&\n-              JSCompiler_object_inline_message_3145.nextSibling.dataset;\n-            if (JSCompiler_object_inline_componentStack_3148) {\n+            JSCompiler_object_inline_componentStack_3152 =\n+              JSCompiler_object_inline_message_3149.nextSibling &&\n+              JSCompiler_object_inline_message_3149.nextSibling.dataset;\n+            if (JSCompiler_object_inline_componentStack_3152) {\n               nextPrimaryChildren =\n-                JSCompiler_object_inline_componentStack_3148.dgst;\n-              var message = JSCompiler_object_inline_componentStack_3148.msg;\n+                JSCompiler_object_inline_componentStack_3152.dgst;\n+              var message = JSCompiler_object_inline_componentStack_3152.msg;\n               nextFallbackChildren =\n-                JSCompiler_object_inline_componentStack_3148.stck;\n+                JSCompiler_object_inline_componentStack_3152.stck;\n               var componentStack =\n-                JSCompiler_object_inline_componentStack_3148.cstck;\n+                JSCompiler_object_inline_componentStack_3152.cstck;\n             }\n-            JSCompiler_object_inline_message_3145 = message;\n-            JSCompiler_object_inline_digest_3146 = nextPrimaryChildren;\n-            JSCompiler_object_inline_stack_3147 = nextFallbackChildren;\n-            JSCompiler_object_inline_componentStack_3148 = componentStack;\n-            nextPrimaryChildren = JSCompiler_object_inline_digest_3146;\n-            nextFallbackChildren = JSCompiler_object_inline_message_3145;\n-            componentStack = JSCompiler_object_inline_componentStack_3148;\n+            JSCompiler_object_inline_message_3149 = message;\n+            JSCompiler_object_inline_digest_3150 = nextPrimaryChildren;\n+            JSCompiler_object_inline_stack_3151 = nextFallbackChildren;\n+            JSCompiler_object_inline_componentStack_3152 = componentStack;\n+            nextPrimaryChildren = JSCompiler_object_inline_digest_3150;\n+            nextFallbackChildren = JSCompiler_object_inline_message_3149;\n+            componentStack = JSCompiler_object_inline_componentStack_3152;\n             \"POSTPONE\" !== nextPrimaryChildren &&\n-              ((JSCompiler_object_inline_componentStack_3148 =\n+              ((JSCompiler_object_inline_componentStack_3152 =\n                 nextFallbackChildren\n                   ? Error(nextFallbackChildren)\n                   : Error(\n                       \"The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.\"\n                     )),\n-              (JSCompiler_object_inline_componentStack_3148.stack =\n-                JSCompiler_object_inline_stack_3147 || \"\"),\n-              (JSCompiler_object_inline_componentStack_3148.digest =\n+              (JSCompiler_object_inline_componentStack_3152.stack =\n+                JSCompiler_object_inline_stack_3151 || \"\"),\n+              (JSCompiler_object_inline_componentStack_3152.digest =\n                 nextPrimaryChildren),\n-              (JSCompiler_object_inline_stack_3147 =\n+              (JSCompiler_object_inline_stack_3151 =\n                 void 0 === componentStack ? null : componentStack),\n               (nextPrimaryChildren = {\n-                value: JSCompiler_object_inline_componentStack_3148,\n+                value: JSCompiler_object_inline_componentStack_3152,\n                 source: null,\n-                stack: JSCompiler_object_inline_stack_3147\n+                stack: JSCompiler_object_inline_stack_3151\n               }),\n-              \"string\" === typeof JSCompiler_object_inline_stack_3147 &&\n+              \"string\" === typeof JSCompiler_object_inline_stack_3151 &&\n                 CapturedStacks.set(\n-                  JSCompiler_object_inline_componentStack_3148,\n+                  JSCompiler_object_inline_componentStack_3152,\n                   nextPrimaryChildren\n                 ),\n               queueHydrationError(nextPrimaryChildren));\n@@ -10712,48 +10726,48 @@\n                 renderLanes,\n                 !1\n               ),\n-            (JSCompiler_object_inline_componentStack_3148 =\n+            (JSCompiler_object_inline_componentStack_3152 =\n               0 !== (renderLanes & current.childLanes)),\n-            didReceiveUpdate || JSCompiler_object_inline_componentStack_3148)\n+            didReceiveUpdate || JSCompiler_object_inline_componentStack_3152)\n           ) {\n-            JSCompiler_object_inline_componentStack_3148 = workInProgressRoot;\n+            JSCompiler_object_inline_componentStack_3152 = workInProgressRoot;\n             if (\n-              null !== JSCompiler_object_inline_componentStack_3148 &&\n-              ((JSCompiler_object_inline_stack_3147 = getBumpedLaneForHydration(\n-                JSCompiler_object_inline_componentStack_3148,\n+              null !== JSCompiler_object_inline_componentStack_3152 &&\n+              ((JSCompiler_object_inline_stack_3151 = getBumpedLaneForHydration(\n+                JSCompiler_object_inline_componentStack_3152,\n                 renderLanes\n               )),\n-              0 !== JSCompiler_object_inline_stack_3147 &&\n-                JSCompiler_object_inline_stack_3147 !== prevState.retryLane)\n+              0 !== JSCompiler_object_inline_stack_3151 &&\n+                JSCompiler_object_inline_stack_3151 !== prevState.retryLane)\n             )\n               throw (\n-                ((prevState.retryLane = JSCompiler_object_inline_stack_3147),\n+                ((prevState.retryLane = JSCompiler_object_inline_stack_3151),\n                 enqueueConcurrentRenderForLane(\n                   current,\n-                  JSCompiler_object_inline_stack_3147\n+                  JSCompiler_object_inline_stack_3151\n                 ),\n                 scheduleUpdateOnFiber(\n-                  JSCompiler_object_inline_componentStack_3148,\n+                  JSCompiler_object_inline_componentStack_3152,\n                   current,\n-                  JSCompiler_object_inline_stack_3147\n+                  JSCompiler_object_inline_stack_3151\n                 ),\n                 SelectiveHydrationException)\n               );\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3145) ||\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3149) ||\n               renderDidSuspendDelayIfPossible();\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n               workInProgress,\n               renderLanes\n             );\n           } else\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3145)\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3149)\n               ? ((workInProgress.flags |= 192),\n                 (workInProgress.child = current.child),\n                 (workInProgress = null))\n               : ((current = prevState.treeContext),\n                 (nextHydratableInstance = getNextHydratable(\n-                  JSCompiler_object_inline_message_3145.nextSibling\n+                  JSCompiler_object_inline_message_3149.nextSibling\n                 )),\n                 (hydrationParentFiber = workInProgress),\n                 (isHydrating = !0),\n@@ -10765,31 +10779,31 @@\n                   restoreSuspendedTreeContext(workInProgress, current),\n                 (workInProgress = mountSuspensePrimaryChildren(\n                   workInProgress,\n-                  JSCompiler_object_inline_stack_3147.children\n+                  JSCompiler_object_inline_stack_3151.children\n                 )),\n                 (workInProgress.flags |= 4096));\n           return workInProgress;\n         }\n       }\n-      if (JSCompiler_object_inline_digest_3146)\n+      if (JSCompiler_object_inline_digest_3150)\n         return (\n           reuseSuspenseHandlerOnStack(workInProgress),\n-          (nextPrimaryChildren = JSCompiler_object_inline_stack_3147.fallback),\n+          (nextPrimaryChildren = JSCompiler_object_inline_stack_3151.fallback),\n           (nextFallbackChildren = workInProgress.mode),\n           (componentStack = current.child),\n-          (JSCompiler_object_inline_message_3145 = componentStack.sibling),\n-          (JSCompiler_object_inline_stack_3147 = createWorkInProgress(\n+          (JSCompiler_object_inline_message_3149 = componentStack.sibling),\n+          (JSCompiler_object_inline_stack_3151 = createWorkInProgress(\n             componentStack,\n             {\n               mode: \"hidden\",\n-              children: JSCompiler_object_inline_stack_3147.children\n+              children: JSCompiler_object_inline_stack_3151.children\n             }\n           )),\n-          (JSCompiler_object_inline_stack_3147.subtreeFlags =\n+          (JSCompiler_object_inline_stack_3151.subtreeFlags =\n             componentStack.subtreeFlags & 65011712),\n-          null !== JSCompiler_object_inline_message_3145\n+          null !== JSCompiler_object_inline_message_3149\n             ? (nextPrimaryChildren = createWorkInProgress(\n-                JSCompiler_object_inline_message_3145,\n+                JSCompiler_object_inline_message_3149,\n                 nextPrimaryChildren\n               ))\n             : ((nextPrimaryChildren = createFiberFromFragment(\n@@ -10800,24 +10814,24 @@\n               )),\n               (nextPrimaryChildren.flags |= 2)),\n           (nextPrimaryChildren.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3147.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3147.sibling = nextPrimaryChildren),\n-          (workInProgress.child = JSCompiler_object_inline_stack_3147),\n-          (JSCompiler_object_inline_stack_3147 = nextPrimaryChildren),\n+          (JSCompiler_object_inline_stack_3151.return = workInProgress),\n+          (JSCompiler_object_inline_stack_3151.sibling = nextPrimaryChildren),\n+          (workInProgress.child = JSCompiler_object_inline_stack_3151),\n+          (JSCompiler_object_inline_stack_3151 = nextPrimaryChildren),\n           (nextPrimaryChildren = workInProgress.child),\n           (nextFallbackChildren = current.child.memoizedState),\n           null === nextFallbackChildren\n             ? (nextFallbackChildren = mountSuspenseOffscreenState(renderLanes))\n             : ((componentStack = nextFallbackChildren.cachePool),\n               null !== componentStack\n-                ? ((JSCompiler_object_inline_message_3145 =\n+                ? ((JSCompiler_object_inline_message_3149 =\n                     CacheContext._currentValue),\n                   (componentStack =\n                     componentStack.parent !==\n-                    JSCompiler_object_inline_message_3145\n+                    JSCompiler_object_inline_message_3149\n                       ? {\n-                          parent: JSCompiler_object_inline_message_3145,\n-                          pool: JSCompiler_object_inline_message_3145\n+                          parent: JSCompiler_object_inline_message_3149,\n+                          pool: JSCompiler_object_inline_message_3149\n                         }\n                       : componentStack))\n                 : (componentStack = getSuspendedCache()),\n@@ -10828,28 +10842,28 @@\n           (nextPrimaryChildren.memoizedState = nextFallbackChildren),\n           (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_componentStack_3148,\n+            JSCompiler_object_inline_componentStack_3152,\n             renderLanes\n           )),\n           (workInProgress.memoizedState = SUSPENDED_MARKER),\n-          JSCompiler_object_inline_stack_3147\n+          JSCompiler_object_inline_stack_3151\n         );\n       pushPrimaryTreeSuspenseHandler(workInProgress);\n       renderLanes = current.child;\n       current = renderLanes.sibling;\n       renderLanes = createWorkInProgress(renderLanes, {\n         mode: \"visible\",\n-        children: JSCompiler_object_inline_stack_3147.children\n+        children: JSCompiler_object_inline_stack_3151.children\n       });\n       renderLanes.return = workInProgress;\n       renderLanes.sibling = null;\n       null !== current &&\n-        ((JSCompiler_object_inline_componentStack_3148 =\n+        ((JSCompiler_object_inline_componentStack_3152 =\n           workInProgress.deletions),\n-        null === JSCompiler_object_inline_componentStack_3148\n+        null === JSCompiler_object_inline_componentStack_3152\n           ? ((workInProgress.deletions = [current]),\n             (workInProgress.flags |= 16))\n-          : JSCompiler_object_inline_componentStack_3148.push(current));\n+          : JSCompiler_object_inline_componentStack_3152.push(current));\n       workInProgress.child = renderLanes;\n       workInProgress.memoizedState = null;\n       return renderLanes;\n@@ -30640,11 +30654,11 @@\n     };\n     (function () {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     })();\n     (\"function\" === typeof Map &&\n@@ -30681,10 +30695,10 @@\n       !(function () {\n         var internals = {\n           bundleType: 1,\n-          version: \"19.2.0-experimental-fa3feba6-20250623\",\n+          version: \"19.2.0-experimental-cee7939b-20250625\",\n           rendererPackageName: \"react-dom\",\n           currentDispatcherRef: ReactSharedInternals,\n-          reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+          reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n         };\n         internals.overrideHookState = overrideHookState;\n         internals.overrideHookStateDeletePath = overrideHookStateDeletePath;\n@@ -30830,7 +30844,7 @@\n       listenToAllSupportedEvents(container);\n       return new ReactDOMHydrationRoot(initialChildren);\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "453726a48ff6c1b0251ab072d9ce05d32d516cb8",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-client.production.js",
            "status": "modified",
            "additions": 27,
            "deletions": 27,
            "changes": 54,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-client.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -14482,20 +14482,20 @@ function debounceScrollEnd(targetInst, nativeEvent, nativeEventTarget) {\n     (nativeEventTarget[internalScrollTimer] = targetInst));\n }\n for (\n-  var i$jscomp$inline_1792 = 0;\n-  i$jscomp$inline_1792 < simpleEventPluginEvents.length;\n-  i$jscomp$inline_1792++\n+  var i$jscomp$inline_1798 = 0;\n+  i$jscomp$inline_1798 < simpleEventPluginEvents.length;\n+  i$jscomp$inline_1798++\n ) {\n-  var eventName$jscomp$inline_1793 =\n-      simpleEventPluginEvents[i$jscomp$inline_1792],\n-    domEventName$jscomp$inline_1794 =\n-      eventName$jscomp$inline_1793.toLowerCase(),\n-    capitalizedEvent$jscomp$inline_1795 =\n-      eventName$jscomp$inline_1793[0].toUpperCase() +\n-      eventName$jscomp$inline_1793.slice(1);\n+  var eventName$jscomp$inline_1799 =\n+      simpleEventPluginEvents[i$jscomp$inline_1798],\n+    domEventName$jscomp$inline_1800 =\n+      eventName$jscomp$inline_1799.toLowerCase(),\n+    capitalizedEvent$jscomp$inline_1801 =\n+      eventName$jscomp$inline_1799[0].toUpperCase() +\n+      eventName$jscomp$inline_1799.slice(1);\n   registerSimpleEvent(\n-    domEventName$jscomp$inline_1794,\n-    \"on\" + capitalizedEvent$jscomp$inline_1795\n+    domEventName$jscomp$inline_1800,\n+    \"on\" + capitalizedEvent$jscomp$inline_1801\n   );\n }\n registerSimpleEvent(ANIMATION_END, \"onAnimationEnd\");\n@@ -19157,16 +19157,16 @@ ReactDOMHydrationRoot.prototype.unstable_scheduleHydration = function (target) {\n     0 === i && attemptExplicitHydrationTarget(target);\n   }\n };\n-var isomorphicReactPackageVersion$jscomp$inline_2180 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_2186 = React.version;\n if (\n-  \"19.2.0-experimental-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_2180\n+  \"19.2.0-experimental-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_2186\n )\n   throw Error(\n     formatProdErrorMessage(\n       527,\n-      isomorphicReactPackageVersion$jscomp$inline_2180,\n-      \"19.2.0-experimental-fa3feba6-20250623\"\n+      isomorphicReactPackageVersion$jscomp$inline_2186,\n+      \"19.2.0-experimental-cee7939b-20250625\"\n     )\n   );\n ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n@@ -19186,24 +19186,24 @@ ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n     null === componentOrElement ? null : componentOrElement.stateNode;\n   return componentOrElement;\n };\n-var internals$jscomp$inline_2865 = {\n+var internals$jscomp$inline_2871 = {\n   bundleType: 0,\n-  version: \"19.2.0-experimental-fa3feba6-20250623\",\n+  version: \"19.2.0-experimental-cee7939b-20250625\",\n   rendererPackageName: \"react-dom\",\n   currentDispatcherRef: ReactSharedInternals,\n-  reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+  reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n };\n if (\"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__) {\n-  var hook$jscomp$inline_2866 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n+  var hook$jscomp$inline_2872 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n   if (\n-    !hook$jscomp$inline_2866.isDisabled &&\n-    hook$jscomp$inline_2866.supportsFiber\n+    !hook$jscomp$inline_2872.isDisabled &&\n+    hook$jscomp$inline_2872.supportsFiber\n   )\n     try {\n-      (rendererID = hook$jscomp$inline_2866.inject(\n-        internals$jscomp$inline_2865\n+      (rendererID = hook$jscomp$inline_2872.inject(\n+        internals$jscomp$inline_2871\n       )),\n-        (injectedHook = hook$jscomp$inline_2866);\n+        (injectedHook = hook$jscomp$inline_2872);\n     } catch (err) {}\n }\n exports.createRoot = function (container, options) {\n@@ -19298,4 +19298,4 @@ exports.hydrateRoot = function (container, initialChildren, options) {\n   listenToAllSupportedEvents(container);\n   return new ReactDOMHydrationRoot(initialChildren);\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "0726f1cdc7433319cd6017cbca3f5defe95292bd",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-profiling.development.js",
            "status": "modified",
            "additions": 144,
            "deletions": 130,
            "changes": 274,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -656,6 +656,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -828,27 +849,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeFiber(fiber) {\n       switch (fiber.tag) {\n         case 26:\n@@ -886,11 +886,25 @@\n             for (var i = debugInfo.length - 1; 0 <= i; i--) {\n               var entry = debugInfo[i];\n               if (\"string\" === typeof entry.name) {\n-                var JSCompiler_temp_const = info,\n-                  env = entry.env;\n-                var JSCompiler_inline_result = describeBuiltInComponentFrame(\n-                  entry.name + (env ? \" [\" + env + \"]\" : \"\")\n-                );\n+                var JSCompiler_temp_const = info;\n+                a: {\n+                  var name = entry.name,\n+                    env = entry.env,\n+                    location = entry.debugLocation;\n+                  if (null != location) {\n+                    var childStack = formatOwnerStack(location),\n+                      idx = childStack.lastIndexOf(\"\\n\"),\n+                      lastLine =\n+                        -1 === idx ? childStack : childStack.slice(idx + 1);\n+                    if (-1 !== lastLine.indexOf(name)) {\n+                      var JSCompiler_inline_result = \"\\n\" + lastLine;\n+                      break a;\n+                    }\n+                  }\n+                  JSCompiler_inline_result = describeBuiltInComponentFrame(\n+                    name + (env ? \" [\" + env + \"]\" : \"\")\n+                  );\n+                }\n                 info = JSCompiler_temp_const + JSCompiler_inline_result;\n               }\n             }\n@@ -10488,25 +10502,25 @@\n       return current;\n     }\n     function updateSuspenseComponent(current, workInProgress, renderLanes) {\n-      var JSCompiler_object_inline_componentStack_3153;\n-      var JSCompiler_object_inline_stack_3152 = workInProgress.pendingProps;\n+      var JSCompiler_object_inline_componentStack_3157;\n+      var JSCompiler_object_inline_stack_3156 = workInProgress.pendingProps;\n       shouldSuspendImpl(workInProgress) && (workInProgress.flags |= 128);\n-      var JSCompiler_object_inline_digest_3151 = !1;\n+      var JSCompiler_object_inline_digest_3155 = !1;\n       var didSuspend = 0 !== (workInProgress.flags & 128);\n-      (JSCompiler_object_inline_componentStack_3153 = didSuspend) ||\n-        (JSCompiler_object_inline_componentStack_3153 =\n+      (JSCompiler_object_inline_componentStack_3157 = didSuspend) ||\n+        (JSCompiler_object_inline_componentStack_3157 =\n           null !== current && null === current.memoizedState\n             ? !1\n             : 0 !== (suspenseStackCursor.current & ForceSuspenseFallback));\n-      JSCompiler_object_inline_componentStack_3153 &&\n-        ((JSCompiler_object_inline_digest_3151 = !0),\n+      JSCompiler_object_inline_componentStack_3157 &&\n+        ((JSCompiler_object_inline_digest_3155 = !0),\n         (workInProgress.flags &= -129));\n-      JSCompiler_object_inline_componentStack_3153 =\n+      JSCompiler_object_inline_componentStack_3157 =\n         0 !== (workInProgress.flags & 32);\n       workInProgress.flags &= -33;\n       if (null === current) {\n         if (isHydrating) {\n-          JSCompiler_object_inline_digest_3151\n+          JSCompiler_object_inline_digest_3155\n             ? pushPrimaryTreeSuspenseHandler(workInProgress)\n             : reuseSuspenseHandlerOnStack(workInProgress);\n           (current = nextHydratableInstance)\n@@ -10519,20 +10533,20 @@\n                   ? renderLanes\n                   : null),\n               null !== renderLanes &&\n-                ((JSCompiler_object_inline_componentStack_3153 = {\n+                ((JSCompiler_object_inline_componentStack_3157 = {\n                   dehydrated: renderLanes,\n                   treeContext: getSuspendedTreeContext(),\n                   retryLane: 536870912,\n                   hydrationErrors: null\n                 }),\n                 (workInProgress.memoizedState =\n-                  JSCompiler_object_inline_componentStack_3153),\n-                (JSCompiler_object_inline_componentStack_3153 =\n+                  JSCompiler_object_inline_componentStack_3157),\n+                (JSCompiler_object_inline_componentStack_3157 =\n                   createFiberFromDehydratedFragment(renderLanes)),\n-                (JSCompiler_object_inline_componentStack_3153.return =\n+                (JSCompiler_object_inline_componentStack_3157.return =\n                   workInProgress),\n                 (workInProgress.child =\n-                  JSCompiler_object_inline_componentStack_3153),\n+                  JSCompiler_object_inline_componentStack_3157),\n                 (hydrationParentFiber = workInProgress),\n                 (nextHydratableInstance = null)))\n             : (renderLanes = null);\n@@ -10546,12 +10560,12 @@\n             : (workInProgress.lanes = 536870912);\n           return null;\n         }\n-        var nextPrimaryChildren = JSCompiler_object_inline_stack_3152.children,\n-          nextFallbackChildren = JSCompiler_object_inline_stack_3152.fallback;\n-        if (JSCompiler_object_inline_digest_3151)\n+        var nextPrimaryChildren = JSCompiler_object_inline_stack_3156.children,\n+          nextFallbackChildren = JSCompiler_object_inline_stack_3156.fallback;\n+        if (JSCompiler_object_inline_digest_3155)\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3152 =\n+            (JSCompiler_object_inline_stack_3156 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10563,19 +10577,19 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3153,\n+              JSCompiler_object_inline_componentStack_3157,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n-            JSCompiler_object_inline_stack_3152\n+            JSCompiler_object_inline_stack_3156\n           );\n         if (\n           \"number\" ===\n-          typeof JSCompiler_object_inline_stack_3152.unstable_expectedLoadTime\n+          typeof JSCompiler_object_inline_stack_3156.unstable_expectedLoadTime\n         )\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3152 =\n+            (JSCompiler_object_inline_stack_3156 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10587,12 +10601,12 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3153,\n+              JSCompiler_object_inline_componentStack_3157,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n             (workInProgress.lanes = 4194304),\n-            JSCompiler_object_inline_stack_3152\n+            JSCompiler_object_inline_stack_3156\n           );\n         pushPrimaryTreeSuspenseHandler(workInProgress);\n         return mountSuspensePrimaryChildren(\n@@ -10602,8 +10616,8 @@\n       }\n       var prevState = current.memoizedState;\n       if (null !== prevState) {\n-        var JSCompiler_object_inline_message_3150 = prevState.dehydrated;\n-        if (null !== JSCompiler_object_inline_message_3150) {\n+        var JSCompiler_object_inline_message_3154 = prevState.dehydrated;\n+        if (null !== JSCompiler_object_inline_message_3154) {\n           if (didSuspend)\n             workInProgress.flags & 256\n               ? (pushPrimaryTreeSuspenseHandler(workInProgress),\n@@ -10620,13 +10634,13 @@\n                   (workInProgress = null))\n                 : (reuseSuspenseHandlerOnStack(workInProgress),\n                   (nextPrimaryChildren =\n-                    JSCompiler_object_inline_stack_3152.fallback),\n+                    JSCompiler_object_inline_stack_3156.fallback),\n                   (nextFallbackChildren = workInProgress.mode),\n-                  (JSCompiler_object_inline_stack_3152 =\n+                  (JSCompiler_object_inline_stack_3156 =\n                     mountWorkInProgressOffscreenFiber(\n                       {\n                         mode: \"visible\",\n-                        children: JSCompiler_object_inline_stack_3152.children\n+                        children: JSCompiler_object_inline_stack_3156.children\n                       },\n                       nextFallbackChildren\n                     )),\n@@ -10637,73 +10651,73 @@\n                     null\n                   )),\n                   (nextPrimaryChildren.flags |= 2),\n-                  (JSCompiler_object_inline_stack_3152.return = workInProgress),\n+                  (JSCompiler_object_inline_stack_3156.return = workInProgress),\n                   (nextPrimaryChildren.return = workInProgress),\n-                  (JSCompiler_object_inline_stack_3152.sibling =\n+                  (JSCompiler_object_inline_stack_3156.sibling =\n                     nextPrimaryChildren),\n-                  (workInProgress.child = JSCompiler_object_inline_stack_3152),\n+                  (workInProgress.child = JSCompiler_object_inline_stack_3156),\n                   reconcileChildFibers(\n                     workInProgress,\n                     current.child,\n                     null,\n                     renderLanes\n                   ),\n-                  (JSCompiler_object_inline_stack_3152 = workInProgress.child),\n-                  (JSCompiler_object_inline_stack_3152.memoizedState =\n+                  (JSCompiler_object_inline_stack_3156 = workInProgress.child),\n+                  (JSCompiler_object_inline_stack_3156.memoizedState =\n                     mountSuspenseOffscreenState(renderLanes)),\n-                  (JSCompiler_object_inline_stack_3152.childLanes =\n+                  (JSCompiler_object_inline_stack_3156.childLanes =\n                     getRemainingWorkInPrimaryTree(\n                       current,\n-                      JSCompiler_object_inline_componentStack_3153,\n+                      JSCompiler_object_inline_componentStack_3157,\n                       renderLanes\n                     )),\n                   (workInProgress.memoizedState = SUSPENDED_MARKER),\n                   (workInProgress = nextPrimaryChildren));\n           else if (\n             (pushPrimaryTreeSuspenseHandler(workInProgress),\n             warnIfHydrating(),\n-            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3150))\n+            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3154))\n           ) {\n-            JSCompiler_object_inline_componentStack_3153 =\n-              JSCompiler_object_inline_message_3150.nextSibling &&\n-              JSCompiler_object_inline_message_3150.nextSibling.dataset;\n-            if (JSCompiler_object_inline_componentStack_3153) {\n+            JSCompiler_object_inline_componentStack_3157 =\n+              JSCompiler_object_inline_message_3154.nextSibling &&\n+              JSCompiler_object_inline_message_3154.nextSibling.dataset;\n+            if (JSCompiler_object_inline_componentStack_3157) {\n               nextPrimaryChildren =\n-                JSCompiler_object_inline_componentStack_3153.dgst;\n-              var message = JSCompiler_object_inline_componentStack_3153.msg;\n+                JSCompiler_object_inline_componentStack_3157.dgst;\n+              var message = JSCompiler_object_inline_componentStack_3157.msg;\n               nextFallbackChildren =\n-                JSCompiler_object_inline_componentStack_3153.stck;\n+                JSCompiler_object_inline_componentStack_3157.stck;\n               var componentStack =\n-                JSCompiler_object_inline_componentStack_3153.cstck;\n+                JSCompiler_object_inline_componentStack_3157.cstck;\n             }\n-            JSCompiler_object_inline_message_3150 = message;\n-            JSCompiler_object_inline_digest_3151 = nextPrimaryChildren;\n-            JSCompiler_object_inline_stack_3152 = nextFallbackChildren;\n-            JSCompiler_object_inline_componentStack_3153 = componentStack;\n-            nextPrimaryChildren = JSCompiler_object_inline_digest_3151;\n-            nextFallbackChildren = JSCompiler_object_inline_message_3150;\n-            componentStack = JSCompiler_object_inline_componentStack_3153;\n+            JSCompiler_object_inline_message_3154 = message;\n+            JSCompiler_object_inline_digest_3155 = nextPrimaryChildren;\n+            JSCompiler_object_inline_stack_3156 = nextFallbackChildren;\n+            JSCompiler_object_inline_componentStack_3157 = componentStack;\n+            nextPrimaryChildren = JSCompiler_object_inline_digest_3155;\n+            nextFallbackChildren = JSCompiler_object_inline_message_3154;\n+            componentStack = JSCompiler_object_inline_componentStack_3157;\n             \"POSTPONE\" !== nextPrimaryChildren &&\n-              ((JSCompiler_object_inline_componentStack_3153 =\n+              ((JSCompiler_object_inline_componentStack_3157 =\n                 nextFallbackChildren\n                   ? Error(nextFallbackChildren)\n                   : Error(\n                       \"The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.\"\n                     )),\n-              (JSCompiler_object_inline_componentStack_3153.stack =\n-                JSCompiler_object_inline_stack_3152 || \"\"),\n-              (JSCompiler_object_inline_componentStack_3153.digest =\n+              (JSCompiler_object_inline_componentStack_3157.stack =\n+                JSCompiler_object_inline_stack_3156 || \"\"),\n+              (JSCompiler_object_inline_componentStack_3157.digest =\n                 nextPrimaryChildren),\n-              (JSCompiler_object_inline_stack_3152 =\n+              (JSCompiler_object_inline_stack_3156 =\n                 void 0 === componentStack ? null : componentStack),\n               (nextPrimaryChildren = {\n-                value: JSCompiler_object_inline_componentStack_3153,\n+                value: JSCompiler_object_inline_componentStack_3157,\n                 source: null,\n-                stack: JSCompiler_object_inline_stack_3152\n+                stack: JSCompiler_object_inline_stack_3156\n               }),\n-              \"string\" === typeof JSCompiler_object_inline_stack_3152 &&\n+              \"string\" === typeof JSCompiler_object_inline_stack_3156 &&\n                 CapturedStacks.set(\n-                  JSCompiler_object_inline_componentStack_3153,\n+                  JSCompiler_object_inline_componentStack_3157,\n                   nextPrimaryChildren\n                 ),\n               queueHydrationError(nextPrimaryChildren));\n@@ -10720,48 +10734,48 @@\n                 renderLanes,\n                 !1\n               ),\n-            (JSCompiler_object_inline_componentStack_3153 =\n+            (JSCompiler_object_inline_componentStack_3157 =\n               0 !== (renderLanes & current.childLanes)),\n-            didReceiveUpdate || JSCompiler_object_inline_componentStack_3153)\n+            didReceiveUpdate || JSCompiler_object_inline_componentStack_3157)\n           ) {\n-            JSCompiler_object_inline_componentStack_3153 = workInProgressRoot;\n+            JSCompiler_object_inline_componentStack_3157 = workInProgressRoot;\n             if (\n-              null !== JSCompiler_object_inline_componentStack_3153 &&\n-              ((JSCompiler_object_inline_stack_3152 = getBumpedLaneForHydration(\n-                JSCompiler_object_inline_componentStack_3153,\n+              null !== JSCompiler_object_inline_componentStack_3157 &&\n+              ((JSCompiler_object_inline_stack_3156 = getBumpedLaneForHydration(\n+                JSCompiler_object_inline_componentStack_3157,\n                 renderLanes\n               )),\n-              0 !== JSCompiler_object_inline_stack_3152 &&\n-                JSCompiler_object_inline_stack_3152 !== prevState.retryLane)\n+              0 !== JSCompiler_object_inline_stack_3156 &&\n+                JSCompiler_object_inline_stack_3156 !== prevState.retryLane)\n             )\n               throw (\n-                ((prevState.retryLane = JSCompiler_object_inline_stack_3152),\n+                ((prevState.retryLane = JSCompiler_object_inline_stack_3156),\n                 enqueueConcurrentRenderForLane(\n                   current,\n-                  JSCompiler_object_inline_stack_3152\n+                  JSCompiler_object_inline_stack_3156\n                 ),\n                 scheduleUpdateOnFiber(\n-                  JSCompiler_object_inline_componentStack_3153,\n+                  JSCompiler_object_inline_componentStack_3157,\n                   current,\n-                  JSCompiler_object_inline_stack_3152\n+                  JSCompiler_object_inline_stack_3156\n                 ),\n                 SelectiveHydrationException)\n               );\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3150) ||\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3154) ||\n               renderDidSuspendDelayIfPossible();\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n               workInProgress,\n               renderLanes\n             );\n           } else\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3150)\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3154)\n               ? ((workInProgress.flags |= 192),\n                 (workInProgress.child = current.child),\n                 (workInProgress = null))\n               : ((current = prevState.treeContext),\n                 (nextHydratableInstance = getNextHydratable(\n-                  JSCompiler_object_inline_message_3150.nextSibling\n+                  JSCompiler_object_inline_message_3154.nextSibling\n                 )),\n                 (hydrationParentFiber = workInProgress),\n                 (isHydrating = !0),\n@@ -10773,31 +10787,31 @@\n                   restoreSuspendedTreeContext(workInProgress, current),\n                 (workInProgress = mountSuspensePrimaryChildren(\n                   workInProgress,\n-                  JSCompiler_object_inline_stack_3152.children\n+                  JSCompiler_object_inline_stack_3156.children\n                 )),\n                 (workInProgress.flags |= 4096));\n           return workInProgress;\n         }\n       }\n-      if (JSCompiler_object_inline_digest_3151)\n+      if (JSCompiler_object_inline_digest_3155)\n         return (\n           reuseSuspenseHandlerOnStack(workInProgress),\n-          (nextPrimaryChildren = JSCompiler_object_inline_stack_3152.fallback),\n+          (nextPrimaryChildren = JSCompiler_object_inline_stack_3156.fallback),\n           (nextFallbackChildren = workInProgress.mode),\n           (componentStack = current.child),\n-          (JSCompiler_object_inline_message_3150 = componentStack.sibling),\n-          (JSCompiler_object_inline_stack_3152 = createWorkInProgress(\n+          (JSCompiler_object_inline_message_3154 = componentStack.sibling),\n+          (JSCompiler_object_inline_stack_3156 = createWorkInProgress(\n             componentStack,\n             {\n               mode: \"hidden\",\n-              children: JSCompiler_object_inline_stack_3152.children\n+              children: JSCompiler_object_inline_stack_3156.children\n             }\n           )),\n-          (JSCompiler_object_inline_stack_3152.subtreeFlags =\n+          (JSCompiler_object_inline_stack_3156.subtreeFlags =\n             componentStack.subtreeFlags & 65011712),\n-          null !== JSCompiler_object_inline_message_3150\n+          null !== JSCompiler_object_inline_message_3154\n             ? (nextPrimaryChildren = createWorkInProgress(\n-                JSCompiler_object_inline_message_3150,\n+                JSCompiler_object_inline_message_3154,\n                 nextPrimaryChildren\n               ))\n             : ((nextPrimaryChildren = createFiberFromFragment(\n@@ -10808,24 +10822,24 @@\n               )),\n               (nextPrimaryChildren.flags |= 2)),\n           (nextPrimaryChildren.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3152.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3152.sibling = nextPrimaryChildren),\n-          (workInProgress.child = JSCompiler_object_inline_stack_3152),\n-          (JSCompiler_object_inline_stack_3152 = nextPrimaryChildren),\n+          (JSCompiler_object_inline_stack_3156.return = workInProgress),\n+          (JSCompiler_object_inline_stack_3156.sibling = nextPrimaryChildren),\n+          (workInProgress.child = JSCompiler_object_inline_stack_3156),\n+          (JSCompiler_object_inline_stack_3156 = nextPrimaryChildren),\n           (nextPrimaryChildren = workInProgress.child),\n           (nextFallbackChildren = current.child.memoizedState),\n           null === nextFallbackChildren\n             ? (nextFallbackChildren = mountSuspenseOffscreenState(renderLanes))\n             : ((componentStack = nextFallbackChildren.cachePool),\n               null !== componentStack\n-                ? ((JSCompiler_object_inline_message_3150 =\n+                ? ((JSCompiler_object_inline_message_3154 =\n                     CacheContext._currentValue),\n                   (componentStack =\n                     componentStack.parent !==\n-                    JSCompiler_object_inline_message_3150\n+                    JSCompiler_object_inline_message_3154\n                       ? {\n-                          parent: JSCompiler_object_inline_message_3150,\n-                          pool: JSCompiler_object_inline_message_3150\n+                          parent: JSCompiler_object_inline_message_3154,\n+                          pool: JSCompiler_object_inline_message_3154\n                         }\n                       : componentStack))\n                 : (componentStack = getSuspendedCache()),\n@@ -10836,28 +10850,28 @@\n           (nextPrimaryChildren.memoizedState = nextFallbackChildren),\n           (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_componentStack_3153,\n+            JSCompiler_object_inline_componentStack_3157,\n             renderLanes\n           )),\n           (workInProgress.memoizedState = SUSPENDED_MARKER),\n-          JSCompiler_object_inline_stack_3152\n+          JSCompiler_object_inline_stack_3156\n         );\n       pushPrimaryTreeSuspenseHandler(workInProgress);\n       renderLanes = current.child;\n       current = renderLanes.sibling;\n       renderLanes = createWorkInProgress(renderLanes, {\n         mode: \"visible\",\n-        children: JSCompiler_object_inline_stack_3152.children\n+        children: JSCompiler_object_inline_stack_3156.children\n       });\n       renderLanes.return = workInProgress;\n       renderLanes.sibling = null;\n       null !== current &&\n-        ((JSCompiler_object_inline_componentStack_3153 =\n+        ((JSCompiler_object_inline_componentStack_3157 =\n           workInProgress.deletions),\n-        null === JSCompiler_object_inline_componentStack_3153\n+        null === JSCompiler_object_inline_componentStack_3157\n           ? ((workInProgress.deletions = [current]),\n             (workInProgress.flags |= 16))\n-          : JSCompiler_object_inline_componentStack_3153.push(current));\n+          : JSCompiler_object_inline_componentStack_3157.push(current));\n       workInProgress.child = renderLanes;\n       workInProgress.memoizedState = null;\n       return renderLanes;\n@@ -30692,11 +30706,11 @@\n     };\n     (function () {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     })();\n     (\"function\" === typeof Map &&\n@@ -30733,10 +30747,10 @@\n       !(function () {\n         var internals = {\n           bundleType: 1,\n-          version: \"19.2.0-experimental-fa3feba6-20250623\",\n+          version: \"19.2.0-experimental-cee7939b-20250625\",\n           rendererPackageName: \"react-dom\",\n           currentDispatcherRef: ReactSharedInternals,\n-          reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+          reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n         };\n         internals.overrideHookState = overrideHookState;\n         internals.overrideHookStateDeletePath = overrideHookStateDeletePath;\n@@ -31212,7 +31226,7 @@\n     exports.useFormStatus = function () {\n       return resolveDispatcher().useHostTransitionStatus();\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "0ee662236154d1f9183b7d2cc31b44a71487d877",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-profiling.profiling.js",
            "status": "modified",
            "additions": 27,
            "deletions": 27,
            "changes": 54,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.profiling.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.profiling.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-profiling.profiling.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -16111,20 +16111,20 @@ function debounceScrollEnd(targetInst, nativeEvent, nativeEventTarget) {\n     (nativeEventTarget[internalScrollTimer] = targetInst));\n }\n for (\n-  var i$jscomp$inline_2012 = 0;\n-  i$jscomp$inline_2012 < simpleEventPluginEvents.length;\n-  i$jscomp$inline_2012++\n+  var i$jscomp$inline_2018 = 0;\n+  i$jscomp$inline_2018 < simpleEventPluginEvents.length;\n+  i$jscomp$inline_2018++\n ) {\n-  var eventName$jscomp$inline_2013 =\n-      simpleEventPluginEvents[i$jscomp$inline_2012],\n-    domEventName$jscomp$inline_2014 =\n-      eventName$jscomp$inline_2013.toLowerCase(),\n-    capitalizedEvent$jscomp$inline_2015 =\n-      eventName$jscomp$inline_2013[0].toUpperCase() +\n-      eventName$jscomp$inline_2013.slice(1);\n+  var eventName$jscomp$inline_2019 =\n+      simpleEventPluginEvents[i$jscomp$inline_2018],\n+    domEventName$jscomp$inline_2020 =\n+      eventName$jscomp$inline_2019.toLowerCase(),\n+    capitalizedEvent$jscomp$inline_2021 =\n+      eventName$jscomp$inline_2019[0].toUpperCase() +\n+      eventName$jscomp$inline_2019.slice(1);\n   registerSimpleEvent(\n-    domEventName$jscomp$inline_2014,\n-    \"on\" + capitalizedEvent$jscomp$inline_2015\n+    domEventName$jscomp$inline_2020,\n+    \"on\" + capitalizedEvent$jscomp$inline_2021\n   );\n }\n registerSimpleEvent(ANIMATION_END, \"onAnimationEnd\");\n@@ -20812,16 +20812,16 @@ ReactDOMHydrationRoot.prototype.unstable_scheduleHydration = function (target) {\n     0 === i && attemptExplicitHydrationTarget(target);\n   }\n };\n-var isomorphicReactPackageVersion$jscomp$inline_2400 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_2406 = React.version;\n if (\n-  \"19.2.0-experimental-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_2400\n+  \"19.2.0-experimental-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_2406\n )\n   throw Error(\n     formatProdErrorMessage(\n       527,\n-      isomorphicReactPackageVersion$jscomp$inline_2400,\n-      \"19.2.0-experimental-fa3feba6-20250623\"\n+      isomorphicReactPackageVersion$jscomp$inline_2406,\n+      \"19.2.0-experimental-cee7939b-20250625\"\n     )\n   );\n ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n@@ -20841,24 +20841,24 @@ ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n     null === componentOrElement ? null : componentOrElement.stateNode;\n   return componentOrElement;\n };\n-var internals$jscomp$inline_3087 = {\n+var internals$jscomp$inline_3093 = {\n   bundleType: 0,\n-  version: \"19.2.0-experimental-fa3feba6-20250623\",\n+  version: \"19.2.0-experimental-cee7939b-20250625\",\n   rendererPackageName: \"react-dom\",\n   currentDispatcherRef: ReactSharedInternals,\n-  reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+  reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n };\n if (\"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__) {\n-  var hook$jscomp$inline_3088 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n+  var hook$jscomp$inline_3094 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n   if (\n-    !hook$jscomp$inline_3088.isDisabled &&\n-    hook$jscomp$inline_3088.supportsFiber\n+    !hook$jscomp$inline_3094.isDisabled &&\n+    hook$jscomp$inline_3094.supportsFiber\n   )\n     try {\n-      (rendererID = hook$jscomp$inline_3088.inject(\n-        internals$jscomp$inline_3087\n+      (rendererID = hook$jscomp$inline_3094.inject(\n+        internals$jscomp$inline_3093\n       )),\n-        (injectedHook = hook$jscomp$inline_3088);\n+        (injectedHook = hook$jscomp$inline_3094);\n     } catch (err) {}\n }\n function getCrossOriginStringAs(as, input) {\n@@ -21113,7 +21113,7 @@ exports.useFormState = function (action, initialState, permalink) {\n exports.useFormStatus = function () {\n   return ReactSharedInternals.H.useHostTransitionStatus();\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n   \"function\" ===\n     typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "93bfd38aee9600ebf3cd02e3b2bd7bdc94d562ca",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server-legacy.browser.development.js",
            "status": "modified",
            "additions": 112,
            "deletions": 45,
            "changes": 157,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4366,6 +4366,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4538,27 +4559,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4582,13 +4582,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -4934,6 +4947,25 @@\n       }\n       return JSCompiler_inline_result$jscomp$0;\n     }\n+    function pushHaltedAwaitOnComponentStack(task, debugInfo) {\n+      if (null != debugInfo)\n+        for (var i = debugInfo.length - 1; 0 <= i; i--) {\n+          var info = debugInfo[i];\n+          if (\"string\" === typeof info.name) break;\n+          if (\"number\" === typeof info.time) break;\n+          if (null != info.awaited) {\n+            var bestStack = null == info.debugStack ? info.awaited : info;\n+            void 0 !== bestStack.debugStack &&\n+              ((task.componentStack = {\n+                parent: task.componentStack,\n+                type: info,\n+                owner: bestStack.owner,\n+                stack: bestStack.debugStack\n+              }),\n+              (task.debugTask = bestStack.debugTask));\n+          }\n+        }\n+    }\n     function pushServerComponentStack(task, debugInfo) {\n       if (null != debugInfo)\n         for (var i = 0; i < debugInfo.length; i++) {\n@@ -7397,7 +7429,11 @@\n         if (6 === segment.status) return;\n         segment.status = ABORTED;\n       }\n-      var errorInfo = getThrownInfo(task.componentStack);\n+      var errorInfo = getThrownInfo(task.componentStack),\n+        node = task.node;\n+      null !== node &&\n+        \"object\" === typeof node &&\n+        pushHaltedAwaitOnComponentStack(task, node._debugInfo);\n       if (null === boundary) {\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n@@ -7407,22 +7443,42 @@\n             error.$$typeof === REACT_POSTPONE_TYPE\n               ? ((boundary = request.trackedPostpones),\n                 null !== boundary && null !== segment\n-                  ? (logPostpone(request, error.message, errorInfo, null),\n+                  ? (logPostpone(\n+                      request,\n+                      error.message,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n                     trackPostpone(request, boundary, task, segment),\n                     finishedTask(request, null, task.row, segment))\n-                  : ((task = Error(\n+                  : ((segment = Error(\n                       \"The render was aborted with postpone when the shell is incomplete. Reason: \" +\n                         error.message\n                     )),\n-                    logRecoverableError(request, task, errorInfo, null),\n-                    fatalError(request, task, errorInfo, null)))\n+                    logRecoverableError(\n+                      request,\n+                      segment,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n+                    fatalError(request, segment, errorInfo, task.debugTask)))\n               : null !== request.trackedPostpones && null !== segment\n                 ? ((boundary = request.trackedPostpones),\n-                  logRecoverableError(request, error, errorInfo, null),\n+                  logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n                   trackPostpone(request, boundary, task, segment),\n                   finishedTask(request, null, task.row, segment))\n-                : (logRecoverableError(request, error, errorInfo, null),\n-                  fatalError(request, error, errorInfo, null));\n+                : (logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+                  fatalError(request, error, errorInfo, task.debugTask));\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7431,7 +7487,7 @@\n             (\"object\" === typeof error &&\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n-              ? (logPostpone(request, error.message, errorInfo, null),\n+              ? (logPostpone(request, error.message, errorInfo, task.debugTask),\n                 (segment = \"POSTPONE\"))\n               : (segment = logRecoverableError(\n                   request,\n@@ -7453,16 +7509,21 @@\n           0 === request.pendingRootTasks && completeShell(request);\n         }\n       } else {\n-        var _trackedPostpones2 = request.trackedPostpones;\n+        node = request.trackedPostpones;\n         if (boundary.status !== CLIENT_RENDERED) {\n-          if (null !== _trackedPostpones2 && null !== segment)\n+          if (null !== node && null !== segment)\n             return (\n               \"object\" === typeof error &&\n               null !== error &&\n               error.$$typeof === REACT_POSTPONE_TYPE\n-                ? logPostpone(request, error.message, errorInfo, null)\n-                : logRecoverableError(request, error, errorInfo, null),\n-              trackPostpone(request, _trackedPostpones2, task, segment),\n+                ? logPostpone(request, error.message, errorInfo, task.debugTask)\n+                : logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+              trackPostpone(request, node, task, segment),\n               boundary.fallbackAbortableTasks.forEach(function (fallbackTask) {\n                 return abortTask(fallbackTask, request, error);\n               }),\n@@ -7475,7 +7536,7 @@\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n           ) {\n-            logPostpone(request, error.message, errorInfo, null);\n+            logPostpone(request, error.message, errorInfo, task.debugTask);\n             if (null !== request.trackedPostpones && null !== segment) {\n               trackPostpone(request, request.trackedPostpones, task, segment);\n               finishedTask(request, task.blockedBoundary, task.row, segment);\n@@ -7486,7 +7547,13 @@\n               return;\n             }\n             segment = \"POSTPONE\";\n-          } else segment = logRecoverableError(request, error, errorInfo, null);\n+          } else\n+            segment = logRecoverableError(\n+              request,\n+              error,\n+              errorInfo,\n+              task.debugTask\n+            );\n           boundary.status = CLIENT_RENDERED;\n           encodeErrorForBoundary(boundary, segment, error, errorInfo, !0);\n           untrackBoundary(request, boundary);\n@@ -10415,5 +10482,5 @@\n         'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToReadableStream\" which supports Suspense on the server'\n       );\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "01cf755a40de63710b5899e28ee9f03f134f328f",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server-legacy.browser.production.js",
            "status": "modified",
            "additions": 52,
            "deletions": 28,
            "changes": 80,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2943,16 +2943,16 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       \"\\x3c/script>\"\n     ));\n   bootstrapScriptContent = idPrefix + \"P:\";\n-  var JSCompiler_object_inline_segmentPrefix_1865 = idPrefix + \"S:\";\n+  var JSCompiler_object_inline_segmentPrefix_1875 = idPrefix + \"S:\";\n   idPrefix += \"B:\";\n-  var JSCompiler_object_inline_preconnects_1879 = new Set(),\n-    JSCompiler_object_inline_fontPreloads_1880 = new Set(),\n-    JSCompiler_object_inline_highImagePreloads_1881 = new Set(),\n-    JSCompiler_object_inline_styles_1882 = new Map(),\n-    JSCompiler_object_inline_bootstrapScripts_1883 = new Set(),\n-    JSCompiler_object_inline_scripts_1884 = new Set(),\n-    JSCompiler_object_inline_bulkPreloads_1885 = new Set(),\n-    JSCompiler_object_inline_preloads_1886 = {\n+  var JSCompiler_object_inline_preconnects_1889 = new Set(),\n+    JSCompiler_object_inline_fontPreloads_1890 = new Set(),\n+    JSCompiler_object_inline_highImagePreloads_1891 = new Set(),\n+    JSCompiler_object_inline_styles_1892 = new Map(),\n+    JSCompiler_object_inline_bootstrapScripts_1893 = new Set(),\n+    JSCompiler_object_inline_scripts_1894 = new Set(),\n+    JSCompiler_object_inline_bulkPreloads_1895 = new Set(),\n+    JSCompiler_object_inline_preloads_1896 = {\n       images: new Map(),\n       stylesheets: new Map(),\n       scripts: new Map(),\n@@ -2989,7 +2989,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       scriptConfig.moduleScriptResources[href] = null;\n       scriptConfig = [];\n       pushLinkImpl(scriptConfig, props);\n-      JSCompiler_object_inline_bootstrapScripts_1883.add(scriptConfig);\n+      JSCompiler_object_inline_bootstrapScripts_1893.add(scriptConfig);\n       bootstrapChunks.push('<script src=\"', escapeTextForBrowser(src), '\"');\n       \"string\" === typeof integrity &&\n         bootstrapChunks.push(\n@@ -3036,7 +3036,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         (props.moduleScriptResources[scriptConfig] = null),\n         (props = []),\n         pushLinkImpl(props, integrity),\n-        JSCompiler_object_inline_bootstrapScripts_1883.add(props),\n+        JSCompiler_object_inline_bootstrapScripts_1893.add(props),\n         bootstrapChunks.push(\n           '<script type=\"module\" src=\"',\n           escapeTextForBrowser(i),\n@@ -3058,7 +3058,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         bootstrapChunks.push(' async=\"\">\\x3c/script>');\n   return {\n     placeholderPrefix: bootstrapScriptContent,\n-    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1865,\n+    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1875,\n     boundaryPrefix: idPrefix,\n     startInlineScript: \"<script\",\n     startInlineStyle: \"<style\",\n@@ -3078,14 +3078,14 @@ function createRenderState(resumableState, generateStaticMarkup) {\n     charsetChunks: [],\n     viewportChunks: [],\n     hoistableChunks: [],\n-    preconnects: JSCompiler_object_inline_preconnects_1879,\n-    fontPreloads: JSCompiler_object_inline_fontPreloads_1880,\n-    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1881,\n-    styles: JSCompiler_object_inline_styles_1882,\n-    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1883,\n-    scripts: JSCompiler_object_inline_scripts_1884,\n-    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1885,\n-    preloads: JSCompiler_object_inline_preloads_1886,\n+    preconnects: JSCompiler_object_inline_preconnects_1889,\n+    fontPreloads: JSCompiler_object_inline_fontPreloads_1890,\n+    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1891,\n+    styles: JSCompiler_object_inline_styles_1892,\n+    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1893,\n+    scripts: JSCompiler_object_inline_scripts_1894,\n+    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1895,\n+    preloads: JSCompiler_object_inline_preloads_1896,\n     nonce: { script: void 0, style: void 0 },\n     stylesToHoist: !1,\n     generateStaticMarkup: generateStaticMarkup\n@@ -3811,13 +3811,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7083,4 +7107,4 @@ exports.renderToString = function (children, options) {\n     'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToReadableStream\" which supports Suspense on the server'\n   );\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "e36974d0854ecde608097ee30c9ff6f708e493db",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server-legacy.node.development.js",
            "status": "modified",
            "additions": 112,
            "deletions": 45,
            "changes": 157,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4366,6 +4366,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4538,27 +4559,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4582,13 +4582,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -4934,6 +4947,25 @@\n       }\n       return JSCompiler_inline_result$jscomp$0;\n     }\n+    function pushHaltedAwaitOnComponentStack(task, debugInfo) {\n+      if (null != debugInfo)\n+        for (var i = debugInfo.length - 1; 0 <= i; i--) {\n+          var info = debugInfo[i];\n+          if (\"string\" === typeof info.name) break;\n+          if (\"number\" === typeof info.time) break;\n+          if (null != info.awaited) {\n+            var bestStack = null == info.debugStack ? info.awaited : info;\n+            void 0 !== bestStack.debugStack &&\n+              ((task.componentStack = {\n+                parent: task.componentStack,\n+                type: info,\n+                owner: bestStack.owner,\n+                stack: bestStack.debugStack\n+              }),\n+              (task.debugTask = bestStack.debugTask));\n+          }\n+        }\n+    }\n     function pushServerComponentStack(task, debugInfo) {\n       if (null != debugInfo)\n         for (var i = 0; i < debugInfo.length; i++) {\n@@ -7397,7 +7429,11 @@\n         if (6 === segment.status) return;\n         segment.status = ABORTED;\n       }\n-      var errorInfo = getThrownInfo(task.componentStack);\n+      var errorInfo = getThrownInfo(task.componentStack),\n+        node = task.node;\n+      null !== node &&\n+        \"object\" === typeof node &&\n+        pushHaltedAwaitOnComponentStack(task, node._debugInfo);\n       if (null === boundary) {\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n@@ -7407,22 +7443,42 @@\n             error.$$typeof === REACT_POSTPONE_TYPE\n               ? ((boundary = request.trackedPostpones),\n                 null !== boundary && null !== segment\n-                  ? (logPostpone(request, error.message, errorInfo, null),\n+                  ? (logPostpone(\n+                      request,\n+                      error.message,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n                     trackPostpone(request, boundary, task, segment),\n                     finishedTask(request, null, task.row, segment))\n-                  : ((task = Error(\n+                  : ((segment = Error(\n                       \"The render was aborted with postpone when the shell is incomplete. Reason: \" +\n                         error.message\n                     )),\n-                    logRecoverableError(request, task, errorInfo, null),\n-                    fatalError(request, task, errorInfo, null)))\n+                    logRecoverableError(\n+                      request,\n+                      segment,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n+                    fatalError(request, segment, errorInfo, task.debugTask)))\n               : null !== request.trackedPostpones && null !== segment\n                 ? ((boundary = request.trackedPostpones),\n-                  logRecoverableError(request, error, errorInfo, null),\n+                  logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n                   trackPostpone(request, boundary, task, segment),\n                   finishedTask(request, null, task.row, segment))\n-                : (logRecoverableError(request, error, errorInfo, null),\n-                  fatalError(request, error, errorInfo, null));\n+                : (logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+                  fatalError(request, error, errorInfo, task.debugTask));\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7431,7 +7487,7 @@\n             (\"object\" === typeof error &&\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n-              ? (logPostpone(request, error.message, errorInfo, null),\n+              ? (logPostpone(request, error.message, errorInfo, task.debugTask),\n                 (segment = \"POSTPONE\"))\n               : (segment = logRecoverableError(\n                   request,\n@@ -7453,16 +7509,21 @@\n           0 === request.pendingRootTasks && completeShell(request);\n         }\n       } else {\n-        var _trackedPostpones2 = request.trackedPostpones;\n+        node = request.trackedPostpones;\n         if (boundary.status !== CLIENT_RENDERED) {\n-          if (null !== _trackedPostpones2 && null !== segment)\n+          if (null !== node && null !== segment)\n             return (\n               \"object\" === typeof error &&\n               null !== error &&\n               error.$$typeof === REACT_POSTPONE_TYPE\n-                ? logPostpone(request, error.message, errorInfo, null)\n-                : logRecoverableError(request, error, errorInfo, null),\n-              trackPostpone(request, _trackedPostpones2, task, segment),\n+                ? logPostpone(request, error.message, errorInfo, task.debugTask)\n+                : logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+              trackPostpone(request, node, task, segment),\n               boundary.fallbackAbortableTasks.forEach(function (fallbackTask) {\n                 return abortTask(fallbackTask, request, error);\n               }),\n@@ -7475,7 +7536,7 @@\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n           ) {\n-            logPostpone(request, error.message, errorInfo, null);\n+            logPostpone(request, error.message, errorInfo, task.debugTask);\n             if (null !== request.trackedPostpones && null !== segment) {\n               trackPostpone(request, request.trackedPostpones, task, segment);\n               finishedTask(request, task.blockedBoundary, task.row, segment);\n@@ -7486,7 +7547,13 @@\n               return;\n             }\n             segment = \"POSTPONE\";\n-          } else segment = logRecoverableError(request, error, errorInfo, null);\n+          } else\n+            segment = logRecoverableError(\n+              request,\n+              error,\n+              errorInfo,\n+              task.debugTask\n+            );\n           boundary.status = CLIENT_RENDERED;\n           encodeErrorForBoundary(boundary, segment, error, errorInfo, !0);\n           untrackBoundary(request, boundary);\n@@ -10415,5 +10482,5 @@\n         'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToPipeableStream\" which supports Suspense on the server'\n       );\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "d7f41ebb353775e03c3792a0be5747bdf42d7d6d",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server-legacy.node.production.js",
            "status": "modified",
            "additions": 52,
            "deletions": 28,
            "changes": 80,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server-legacy.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2964,16 +2964,16 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       \"\\x3c/script>\"\n     ));\n   bootstrapScriptContent = idPrefix + \"P:\";\n-  var JSCompiler_object_inline_segmentPrefix_1865 = idPrefix + \"S:\";\n+  var JSCompiler_object_inline_segmentPrefix_1875 = idPrefix + \"S:\";\n   idPrefix += \"B:\";\n-  var JSCompiler_object_inline_preconnects_1879 = new Set(),\n-    JSCompiler_object_inline_fontPreloads_1880 = new Set(),\n-    JSCompiler_object_inline_highImagePreloads_1881 = new Set(),\n-    JSCompiler_object_inline_styles_1882 = new Map(),\n-    JSCompiler_object_inline_bootstrapScripts_1883 = new Set(),\n-    JSCompiler_object_inline_scripts_1884 = new Set(),\n-    JSCompiler_object_inline_bulkPreloads_1885 = new Set(),\n-    JSCompiler_object_inline_preloads_1886 = {\n+  var JSCompiler_object_inline_preconnects_1889 = new Set(),\n+    JSCompiler_object_inline_fontPreloads_1890 = new Set(),\n+    JSCompiler_object_inline_highImagePreloads_1891 = new Set(),\n+    JSCompiler_object_inline_styles_1892 = new Map(),\n+    JSCompiler_object_inline_bootstrapScripts_1893 = new Set(),\n+    JSCompiler_object_inline_scripts_1894 = new Set(),\n+    JSCompiler_object_inline_bulkPreloads_1895 = new Set(),\n+    JSCompiler_object_inline_preloads_1896 = {\n       images: new Map(),\n       stylesheets: new Map(),\n       scripts: new Map(),\n@@ -3010,7 +3010,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       scriptConfig.moduleScriptResources[href] = null;\n       scriptConfig = [];\n       pushLinkImpl(scriptConfig, props);\n-      JSCompiler_object_inline_bootstrapScripts_1883.add(scriptConfig);\n+      JSCompiler_object_inline_bootstrapScripts_1893.add(scriptConfig);\n       bootstrapChunks.push('<script src=\"', escapeTextForBrowser(src), '\"');\n       \"string\" === typeof integrity &&\n         bootstrapChunks.push(\n@@ -3057,7 +3057,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         (props.moduleScriptResources[scriptConfig] = null),\n         (props = []),\n         pushLinkImpl(props, integrity),\n-        JSCompiler_object_inline_bootstrapScripts_1883.add(props),\n+        JSCompiler_object_inline_bootstrapScripts_1893.add(props),\n         bootstrapChunks.push(\n           '<script type=\"module\" src=\"',\n           escapeTextForBrowser(i),\n@@ -3079,7 +3079,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         bootstrapChunks.push(' async=\"\">\\x3c/script>');\n   return {\n     placeholderPrefix: bootstrapScriptContent,\n-    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1865,\n+    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1875,\n     boundaryPrefix: idPrefix,\n     startInlineScript: \"<script\",\n     startInlineStyle: \"<style\",\n@@ -3099,14 +3099,14 @@ function createRenderState(resumableState, generateStaticMarkup) {\n     charsetChunks: [],\n     viewportChunks: [],\n     hoistableChunks: [],\n-    preconnects: JSCompiler_object_inline_preconnects_1879,\n-    fontPreloads: JSCompiler_object_inline_fontPreloads_1880,\n-    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1881,\n-    styles: JSCompiler_object_inline_styles_1882,\n-    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1883,\n-    scripts: JSCompiler_object_inline_scripts_1884,\n-    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1885,\n-    preloads: JSCompiler_object_inline_preloads_1886,\n+    preconnects: JSCompiler_object_inline_preconnects_1889,\n+    fontPreloads: JSCompiler_object_inline_fontPreloads_1890,\n+    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1891,\n+    styles: JSCompiler_object_inline_styles_1892,\n+    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1893,\n+    scripts: JSCompiler_object_inline_scripts_1894,\n+    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1895,\n+    preloads: JSCompiler_object_inline_preloads_1896,\n     nonce: { script: void 0, style: void 0 },\n     stylesToHoist: !1,\n     generateStaticMarkup: generateStaticMarkup\n@@ -3862,13 +3862,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7186,4 +7210,4 @@ exports.renderToString = function (children, options) {\n     'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToPipeableStream\" which supports Suspense on the server'\n   );\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "8afc5c381514088568a4bf7bade93ef991c4b8d2",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.browser.development.js",
            "status": "modified",
            "additions": 114,
            "deletions": 47,
            "changes": 161,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4554,6 +4554,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4726,27 +4747,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4770,13 +4770,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -5308,6 +5321,25 @@\n       }\n       return JSCompiler_inline_result$jscomp$0;\n     }\n+    function pushHaltedAwaitOnComponentStack(task, debugInfo) {\n+      if (null != debugInfo)\n+        for (var i = debugInfo.length - 1; 0 <= i; i--) {\n+          var info = debugInfo[i];\n+          if (\"string\" === typeof info.name) break;\n+          if (\"number\" === typeof info.time) break;\n+          if (null != info.awaited) {\n+            var bestStack = null == info.debugStack ? info.awaited : info;\n+            void 0 !== bestStack.debugStack &&\n+              ((task.componentStack = {\n+                parent: task.componentStack,\n+                type: info,\n+                owner: bestStack.owner,\n+                stack: bestStack.debugStack\n+              }),\n+              (task.debugTask = bestStack.debugTask));\n+          }\n+        }\n+    }\n     function pushServerComponentStack(task, debugInfo) {\n       if (null != debugInfo)\n         for (var i = 0; i < debugInfo.length; i++) {\n@@ -7832,7 +7864,11 @@\n         if (6 === segment.status) return;\n         segment.status = ABORTED;\n       }\n-      var errorInfo = getThrownInfo(task.componentStack);\n+      var errorInfo = getThrownInfo(task.componentStack),\n+        node = task.node;\n+      null !== node &&\n+        \"object\" === typeof node &&\n+        pushHaltedAwaitOnComponentStack(task, node._debugInfo);\n       if (null === boundary) {\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n@@ -7842,22 +7878,42 @@\n             error.$$typeof === REACT_POSTPONE_TYPE\n               ? ((boundary = request.trackedPostpones),\n                 null !== boundary && null !== segment\n-                  ? (logPostpone(request, error.message, errorInfo, null),\n+                  ? (logPostpone(\n+                      request,\n+                      error.message,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n                     trackPostpone(request, boundary, task, segment),\n                     finishedTask(request, null, task.row, segment))\n-                  : ((task = Error(\n+                  : ((segment = Error(\n                       \"The render was aborted with postpone when the shell is incomplete. Reason: \" +\n                         error.message\n                     )),\n-                    logRecoverableError(request, task, errorInfo, null),\n-                    fatalError(request, task, errorInfo, null)))\n+                    logRecoverableError(\n+                      request,\n+                      segment,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n+                    fatalError(request, segment, errorInfo, task.debugTask)))\n               : null !== request.trackedPostpones && null !== segment\n                 ? ((boundary = request.trackedPostpones),\n-                  logRecoverableError(request, error, errorInfo, null),\n+                  logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n                   trackPostpone(request, boundary, task, segment),\n                   finishedTask(request, null, task.row, segment))\n-                : (logRecoverableError(request, error, errorInfo, null),\n-                  fatalError(request, error, errorInfo, null));\n+                : (logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+                  fatalError(request, error, errorInfo, task.debugTask));\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7866,7 +7922,7 @@\n             (\"object\" === typeof error &&\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n-              ? (logPostpone(request, error.message, errorInfo, null),\n+              ? (logPostpone(request, error.message, errorInfo, task.debugTask),\n                 (segment = \"POSTPONE\"))\n               : (segment = logRecoverableError(\n                   request,\n@@ -7888,16 +7944,21 @@\n           0 === request.pendingRootTasks && completeShell(request);\n         }\n       } else {\n-        var _trackedPostpones2 = request.trackedPostpones;\n+        node = request.trackedPostpones;\n         if (boundary.status !== CLIENT_RENDERED) {\n-          if (null !== _trackedPostpones2 && null !== segment)\n+          if (null !== node && null !== segment)\n             return (\n               \"object\" === typeof error &&\n               null !== error &&\n               error.$$typeof === REACT_POSTPONE_TYPE\n-                ? logPostpone(request, error.message, errorInfo, null)\n-                : logRecoverableError(request, error, errorInfo, null),\n-              trackPostpone(request, _trackedPostpones2, task, segment),\n+                ? logPostpone(request, error.message, errorInfo, task.debugTask)\n+                : logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+              trackPostpone(request, node, task, segment),\n               boundary.fallbackAbortableTasks.forEach(function (fallbackTask) {\n                 return abortTask(fallbackTask, request, error);\n               }),\n@@ -7910,7 +7971,7 @@\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n           ) {\n-            logPostpone(request, error.message, errorInfo, null);\n+            logPostpone(request, error.message, errorInfo, task.debugTask);\n             if (null !== request.trackedPostpones && null !== segment) {\n               trackPostpone(request, request.trackedPostpones, task, segment);\n               finishedTask(request, task.blockedBoundary, task.row, segment);\n@@ -7921,7 +7982,13 @@\n               return;\n             }\n             segment = \"POSTPONE\";\n-          } else segment = logRecoverableError(request, error, errorInfo, null);\n+          } else\n+            segment = logRecoverableError(\n+              request,\n+              error,\n+              errorInfo,\n+              task.debugTask\n+            );\n           boundary.status = CLIENT_RENDERED;\n           encodeErrorForBoundary(boundary, segment, error, errorInfo, !0);\n           untrackBoundary(request, boundary);\n@@ -9406,11 +9473,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     var React = require(\"next/dist/compiled/react-experimental\"),\n@@ -11229,5 +11296,5 @@\n         startWork(request);\n       });\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "c08832b5f34d69618baf89d27d4c50c97586f496",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.browser.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4240,13 +4240,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7748,12 +7772,12 @@ function getPostponedState(request) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       formatProdErrorMessage(\n         527,\n         isomorphicReactPackageVersion,\n-        \"19.2.0-experimental-fa3feba6-20250623\"\n+        \"19.2.0-experimental-cee7939b-20250625\"\n       )\n     );\n }\n@@ -8008,4 +8032,4 @@ exports.resumeAndPrerender = function (children, postponedState, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "acbc8664259fc756b34165c44a545952ae0cc2f3",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.bun.production.js",
            "status": "modified",
            "additions": 37,
            "deletions": 13,
            "changes": 50,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.bun.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.bun.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.bun.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -3863,13 +3863,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7231,15 +7255,15 @@ function addToReplayParent(node, parentKeyPath, trackedPostpones) {\n     parentNode[2].push(node);\n   }\n }\n-var isomorphicReactPackageVersion$jscomp$inline_866 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_870 = React.version;\n if (\n-  \"19.2.0-experimental-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_866\n+  \"19.2.0-experimental-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_870\n )\n   throw Error(\n     'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n-      (isomorphicReactPackageVersion$jscomp$inline_866 +\n-        \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+      (isomorphicReactPackageVersion$jscomp$inline_870 +\n+        \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n   );\n exports.renderToReadableStream = function (children, options) {\n   return new Promise(function (resolve, reject) {\n@@ -7330,4 +7354,4 @@ exports.renderToReadableStream = function (children, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "f9d35051908029e319aeffe26f0844e14c5a34e8",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.edge.development.js",
            "status": "modified",
            "additions": 114,
            "deletions": 47,
            "changes": 161,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4571,6 +4571,27 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = prepareStackTrace;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4743,27 +4764,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = prepareStackTrace;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4787,13 +4787,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -5333,6 +5346,25 @@\n       }\n       return JSCompiler_inline_result$jscomp$0;\n     }\n+    function pushHaltedAwaitOnComponentStack(task, debugInfo) {\n+      if (null != debugInfo)\n+        for (var i = debugInfo.length - 1; 0 <= i; i--) {\n+          var info = debugInfo[i];\n+          if (\"string\" === typeof info.name) break;\n+          if (\"number\" === typeof info.time) break;\n+          if (null != info.awaited) {\n+            var bestStack = null == info.debugStack ? info.awaited : info;\n+            void 0 !== bestStack.debugStack &&\n+              ((task.componentStack = {\n+                parent: task.componentStack,\n+                type: info,\n+                owner: bestStack.owner,\n+                stack: bestStack.debugStack\n+              }),\n+              (task.debugTask = bestStack.debugTask));\n+          }\n+        }\n+    }\n     function pushServerComponentStack(task, debugInfo) {\n       if (null != debugInfo)\n         for (var i = 0; i < debugInfo.length; i++) {\n@@ -7857,7 +7889,11 @@\n         if (6 === segment.status) return;\n         segment.status = ABORTED;\n       }\n-      var errorInfo = getThrownInfo(task.componentStack);\n+      var errorInfo = getThrownInfo(task.componentStack),\n+        node = task.node;\n+      null !== node &&\n+        \"object\" === typeof node &&\n+        pushHaltedAwaitOnComponentStack(task, node._debugInfo);\n       if (null === boundary) {\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n@@ -7867,22 +7903,42 @@\n             error.$$typeof === REACT_POSTPONE_TYPE\n               ? ((boundary = request.trackedPostpones),\n                 null !== boundary && null !== segment\n-                  ? (logPostpone(request, error.message, errorInfo, null),\n+                  ? (logPostpone(\n+                      request,\n+                      error.message,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n                     trackPostpone(request, boundary, task, segment),\n                     finishedTask(request, null, task.row, segment))\n-                  : ((task = Error(\n+                  : ((segment = Error(\n                       \"The render was aborted with postpone when the shell is incomplete. Reason: \" +\n                         error.message\n                     )),\n-                    logRecoverableError(request, task, errorInfo, null),\n-                    fatalError(request, task, errorInfo, null)))\n+                    logRecoverableError(\n+                      request,\n+                      segment,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n+                    fatalError(request, segment, errorInfo, task.debugTask)))\n               : null !== request.trackedPostpones && null !== segment\n                 ? ((boundary = request.trackedPostpones),\n-                  logRecoverableError(request, error, errorInfo, null),\n+                  logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n                   trackPostpone(request, boundary, task, segment),\n                   finishedTask(request, null, task.row, segment))\n-                : (logRecoverableError(request, error, errorInfo, null),\n-                  fatalError(request, error, errorInfo, null));\n+                : (logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+                  fatalError(request, error, errorInfo, task.debugTask));\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7891,7 +7947,7 @@\n             (\"object\" === typeof error &&\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n-              ? (logPostpone(request, error.message, errorInfo, null),\n+              ? (logPostpone(request, error.message, errorInfo, task.debugTask),\n                 (segment = \"POSTPONE\"))\n               : (segment = logRecoverableError(\n                   request,\n@@ -7913,16 +7969,21 @@\n           0 === request.pendingRootTasks && completeShell(request);\n         }\n       } else {\n-        var _trackedPostpones2 = request.trackedPostpones;\n+        node = request.trackedPostpones;\n         if (boundary.status !== CLIENT_RENDERED) {\n-          if (null !== _trackedPostpones2 && null !== segment)\n+          if (null !== node && null !== segment)\n             return (\n               \"object\" === typeof error &&\n               null !== error &&\n               error.$$typeof === REACT_POSTPONE_TYPE\n-                ? logPostpone(request, error.message, errorInfo, null)\n-                : logRecoverableError(request, error, errorInfo, null),\n-              trackPostpone(request, _trackedPostpones2, task, segment),\n+                ? logPostpone(request, error.message, errorInfo, task.debugTask)\n+                : logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+              trackPostpone(request, node, task, segment),\n               boundary.fallbackAbortableTasks.forEach(function (fallbackTask) {\n                 return abortTask(fallbackTask, request, error);\n               }),\n@@ -7935,7 +7996,7 @@\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n           ) {\n-            logPostpone(request, error.message, errorInfo, null);\n+            logPostpone(request, error.message, errorInfo, task.debugTask);\n             if (null !== request.trackedPostpones && null !== segment) {\n               trackPostpone(request, request.trackedPostpones, task, segment);\n               finishedTask(request, task.blockedBoundary, task.row, segment);\n@@ -7946,7 +8007,13 @@\n               return;\n             }\n             segment = \"POSTPONE\";\n-          } else segment = logRecoverableError(request, error, errorInfo, null);\n+          } else\n+            segment = logRecoverableError(\n+              request,\n+              error,\n+              errorInfo,\n+              task.debugTask\n+            );\n           boundary.status = CLIENT_RENDERED;\n           encodeErrorForBoundary(boundary, segment, error, errorInfo, !0);\n           untrackBoundary(request, boundary);\n@@ -9444,11 +9511,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     var React = require(\"next/dist/compiled/react-experimental\"),\n@@ -11263,5 +11330,5 @@\n         startWork(request);\n       });\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "7da725a257baa5cb1775c93254976a725587d84a",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.edge.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4301,13 +4301,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = prepareStackTrace),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7875,11 +7899,11 @@ function getPostponedState(request) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n         (isomorphicReactPackageVersion +\n-          \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+          \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n     );\n }\n ensureCorrectIsomorphicReactVersion();\n@@ -8133,4 +8157,4 @@ exports.resumeAndPrerender = function (children, postponedState, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "2b025a8ffdc69571eba03d1fe641032b7b0316a7",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.node.development.js",
            "status": "modified",
            "additions": 114,
            "deletions": 47,
            "changes": 161,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4451,6 +4451,27 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = prepareStackTrace;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4623,27 +4644,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = prepareStackTrace;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4667,13 +4667,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -5210,6 +5223,25 @@\n       }\n       return JSCompiler_inline_result$jscomp$0;\n     }\n+    function pushHaltedAwaitOnComponentStack(task, debugInfo) {\n+      if (null != debugInfo)\n+        for (var i = debugInfo.length - 1; 0 <= i; i--) {\n+          var info = debugInfo[i];\n+          if (\"string\" === typeof info.name) break;\n+          if (\"number\" === typeof info.time) break;\n+          if (null != info.awaited) {\n+            var bestStack = null == info.debugStack ? info.awaited : info;\n+            void 0 !== bestStack.debugStack &&\n+              ((task.componentStack = {\n+                parent: task.componentStack,\n+                type: info,\n+                owner: bestStack.owner,\n+                stack: bestStack.debugStack\n+              }),\n+              (task.debugTask = bestStack.debugTask));\n+          }\n+        }\n+    }\n     function pushServerComponentStack(task, debugInfo) {\n       if (null != debugInfo)\n         for (var i = 0; i < debugInfo.length; i++) {\n@@ -7733,7 +7765,11 @@\n         if (6 === segment.status) return;\n         segment.status = ABORTED;\n       }\n-      var errorInfo = getThrownInfo(task.componentStack);\n+      var errorInfo = getThrownInfo(task.componentStack),\n+        node = task.node;\n+      null !== node &&\n+        \"object\" === typeof node &&\n+        pushHaltedAwaitOnComponentStack(task, node._debugInfo);\n       if (null === boundary) {\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n@@ -7743,22 +7779,42 @@\n             error.$$typeof === REACT_POSTPONE_TYPE\n               ? ((boundary = request.trackedPostpones),\n                 null !== boundary && null !== segment\n-                  ? (logPostpone(request, error.message, errorInfo, null),\n+                  ? (logPostpone(\n+                      request,\n+                      error.message,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n                     trackPostpone(request, boundary, task, segment),\n                     finishedTask(request, null, task.row, segment))\n-                  : ((task = Error(\n+                  : ((segment = Error(\n                       \"The render was aborted with postpone when the shell is incomplete. Reason: \" +\n                         error.message\n                     )),\n-                    logRecoverableError(request, task, errorInfo, null),\n-                    fatalError(request, task, errorInfo, null)))\n+                    logRecoverableError(\n+                      request,\n+                      segment,\n+                      errorInfo,\n+                      task.debugTask\n+                    ),\n+                    fatalError(request, segment, errorInfo, task.debugTask)))\n               : null !== request.trackedPostpones && null !== segment\n                 ? ((boundary = request.trackedPostpones),\n-                  logRecoverableError(request, error, errorInfo, null),\n+                  logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n                   trackPostpone(request, boundary, task, segment),\n                   finishedTask(request, null, task.row, segment))\n-                : (logRecoverableError(request, error, errorInfo, null),\n-                  fatalError(request, error, errorInfo, null));\n+                : (logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+                  fatalError(request, error, errorInfo, task.debugTask));\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7767,7 +7823,7 @@\n             (\"object\" === typeof error &&\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n-              ? (logPostpone(request, error.message, errorInfo, null),\n+              ? (logPostpone(request, error.message, errorInfo, task.debugTask),\n                 (segment = \"POSTPONE\"))\n               : (segment = logRecoverableError(\n                   request,\n@@ -7789,16 +7845,21 @@\n           0 === request.pendingRootTasks && completeShell(request);\n         }\n       } else {\n-        var _trackedPostpones2 = request.trackedPostpones;\n+        node = request.trackedPostpones;\n         if (boundary.status !== CLIENT_RENDERED) {\n-          if (null !== _trackedPostpones2 && null !== segment)\n+          if (null !== node && null !== segment)\n             return (\n               \"object\" === typeof error &&\n               null !== error &&\n               error.$$typeof === REACT_POSTPONE_TYPE\n-                ? logPostpone(request, error.message, errorInfo, null)\n-                : logRecoverableError(request, error, errorInfo, null),\n-              trackPostpone(request, _trackedPostpones2, task, segment),\n+                ? logPostpone(request, error.message, errorInfo, task.debugTask)\n+                : logRecoverableError(\n+                    request,\n+                    error,\n+                    errorInfo,\n+                    task.debugTask\n+                  ),\n+              trackPostpone(request, node, task, segment),\n               boundary.fallbackAbortableTasks.forEach(function (fallbackTask) {\n                 return abortTask(fallbackTask, request, error);\n               }),\n@@ -7811,7 +7872,7 @@\n             null !== error &&\n             error.$$typeof === REACT_POSTPONE_TYPE\n           ) {\n-            logPostpone(request, error.message, errorInfo, null);\n+            logPostpone(request, error.message, errorInfo, task.debugTask);\n             if (null !== request.trackedPostpones && null !== segment) {\n               trackPostpone(request, request.trackedPostpones, task, segment);\n               finishedTask(request, task.blockedBoundary, task.row, segment);\n@@ -7822,7 +7883,13 @@\n               return;\n             }\n             segment = \"POSTPONE\";\n-          } else segment = logRecoverableError(request, error, errorInfo, null);\n+          } else\n+            segment = logRecoverableError(\n+              request,\n+              error,\n+              errorInfo,\n+              task.debugTask\n+            );\n           boundary.status = CLIENT_RENDERED;\n           encodeErrorForBoundary(boundary, segment, error, errorInfo, !0);\n           untrackBoundary(request, boundary);\n@@ -9296,11 +9363,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     function createDrainHandler(destination, request) {\n@@ -11425,5 +11492,5 @@\n         }\n       };\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "1e59c568c74afb925e53f5e56e72ae5b7f54a65e",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-server.node.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4180,13 +4180,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = prepareStackTrace),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -7746,11 +7770,11 @@ function getPostponedState(request) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n         (isomorphicReactPackageVersion +\n-          \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+          \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n     );\n }\n ensureCorrectIsomorphicReactVersion();\n@@ -8308,4 +8332,4 @@ exports.resumeToPipeableStream = function (children, postponedState, options) {\n     }\n   };\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "a7d666cbb5921e9243e09bf5559975f729682f22",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-unstable_testing.development.js",
            "status": "modified",
            "additions": 144,
            "deletions": 130,
            "changes": 274,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -648,6 +648,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -820,27 +841,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeFiber(fiber) {\n       switch (fiber.tag) {\n         case 26:\n@@ -878,11 +878,25 @@\n             for (var i = debugInfo.length - 1; 0 <= i; i--) {\n               var entry = debugInfo[i];\n               if (\"string\" === typeof entry.name) {\n-                var JSCompiler_temp_const = info,\n-                  env = entry.env;\n-                var JSCompiler_inline_result = describeBuiltInComponentFrame(\n-                  entry.name + (env ? \" [\" + env + \"]\" : \"\")\n-                );\n+                var JSCompiler_temp_const = info;\n+                a: {\n+                  var name = entry.name,\n+                    env = entry.env,\n+                    location = entry.debugLocation;\n+                  if (null != location) {\n+                    var childStack = formatOwnerStack(location),\n+                      idx = childStack.lastIndexOf(\"\\n\"),\n+                      lastLine =\n+                        -1 === idx ? childStack : childStack.slice(idx + 1);\n+                    if (-1 !== lastLine.indexOf(name)) {\n+                      var JSCompiler_inline_result = \"\\n\" + lastLine;\n+                      break a;\n+                    }\n+                  }\n+                  JSCompiler_inline_result = describeBuiltInComponentFrame(\n+                    name + (env ? \" [\" + env + \"]\" : \"\")\n+                  );\n+                }\n                 info = JSCompiler_temp_const + JSCompiler_inline_result;\n               }\n             }\n@@ -10521,25 +10535,25 @@\n       return current;\n     }\n     function updateSuspenseComponent(current, workInProgress, renderLanes) {\n-      var JSCompiler_object_inline_componentStack_3182;\n-      var JSCompiler_object_inline_stack_3181 = workInProgress.pendingProps;\n+      var JSCompiler_object_inline_componentStack_3186;\n+      var JSCompiler_object_inline_stack_3185 = workInProgress.pendingProps;\n       shouldSuspendImpl(workInProgress) && (workInProgress.flags |= 128);\n-      var JSCompiler_object_inline_digest_3180 = !1;\n+      var JSCompiler_object_inline_digest_3184 = !1;\n       var didSuspend = 0 !== (workInProgress.flags & 128);\n-      (JSCompiler_object_inline_componentStack_3182 = didSuspend) ||\n-        (JSCompiler_object_inline_componentStack_3182 =\n+      (JSCompiler_object_inline_componentStack_3186 = didSuspend) ||\n+        (JSCompiler_object_inline_componentStack_3186 =\n           null !== current && null === current.memoizedState\n             ? !1\n             : 0 !== (suspenseStackCursor.current & ForceSuspenseFallback));\n-      JSCompiler_object_inline_componentStack_3182 &&\n-        ((JSCompiler_object_inline_digest_3180 = !0),\n+      JSCompiler_object_inline_componentStack_3186 &&\n+        ((JSCompiler_object_inline_digest_3184 = !0),\n         (workInProgress.flags &= -129));\n-      JSCompiler_object_inline_componentStack_3182 =\n+      JSCompiler_object_inline_componentStack_3186 =\n         0 !== (workInProgress.flags & 32);\n       workInProgress.flags &= -33;\n       if (null === current) {\n         if (isHydrating) {\n-          JSCompiler_object_inline_digest_3180\n+          JSCompiler_object_inline_digest_3184\n             ? pushPrimaryTreeSuspenseHandler(workInProgress)\n             : reuseSuspenseHandlerOnStack(workInProgress);\n           (current = nextHydratableInstance)\n@@ -10552,20 +10566,20 @@\n                   ? renderLanes\n                   : null),\n               null !== renderLanes &&\n-                ((JSCompiler_object_inline_componentStack_3182 = {\n+                ((JSCompiler_object_inline_componentStack_3186 = {\n                   dehydrated: renderLanes,\n                   treeContext: getSuspendedTreeContext(),\n                   retryLane: 536870912,\n                   hydrationErrors: null\n                 }),\n                 (workInProgress.memoizedState =\n-                  JSCompiler_object_inline_componentStack_3182),\n-                (JSCompiler_object_inline_componentStack_3182 =\n+                  JSCompiler_object_inline_componentStack_3186),\n+                (JSCompiler_object_inline_componentStack_3186 =\n                   createFiberFromDehydratedFragment(renderLanes)),\n-                (JSCompiler_object_inline_componentStack_3182.return =\n+                (JSCompiler_object_inline_componentStack_3186.return =\n                   workInProgress),\n                 (workInProgress.child =\n-                  JSCompiler_object_inline_componentStack_3182),\n+                  JSCompiler_object_inline_componentStack_3186),\n                 (hydrationParentFiber = workInProgress),\n                 (nextHydratableInstance = null)))\n             : (renderLanes = null);\n@@ -10579,12 +10593,12 @@\n             : (workInProgress.lanes = 536870912);\n           return null;\n         }\n-        var nextPrimaryChildren = JSCompiler_object_inline_stack_3181.children,\n-          nextFallbackChildren = JSCompiler_object_inline_stack_3181.fallback;\n-        if (JSCompiler_object_inline_digest_3180)\n+        var nextPrimaryChildren = JSCompiler_object_inline_stack_3185.children,\n+          nextFallbackChildren = JSCompiler_object_inline_stack_3185.fallback;\n+        if (JSCompiler_object_inline_digest_3184)\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3181 =\n+            (JSCompiler_object_inline_stack_3185 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10596,19 +10610,19 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3182,\n+              JSCompiler_object_inline_componentStack_3186,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n-            JSCompiler_object_inline_stack_3181\n+            JSCompiler_object_inline_stack_3185\n           );\n         if (\n           \"number\" ===\n-          typeof JSCompiler_object_inline_stack_3181.unstable_expectedLoadTime\n+          typeof JSCompiler_object_inline_stack_3185.unstable_expectedLoadTime\n         )\n           return (\n             reuseSuspenseHandlerOnStack(workInProgress),\n-            (JSCompiler_object_inline_stack_3181 =\n+            (JSCompiler_object_inline_stack_3185 =\n               mountSuspenseFallbackChildren(\n                 workInProgress,\n                 nextPrimaryChildren,\n@@ -10620,12 +10634,12 @@\n               mountSuspenseOffscreenState(renderLanes)),\n             (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n               current,\n-              JSCompiler_object_inline_componentStack_3182,\n+              JSCompiler_object_inline_componentStack_3186,\n               renderLanes\n             )),\n             (workInProgress.memoizedState = SUSPENDED_MARKER),\n             (workInProgress.lanes = 4194304),\n-            JSCompiler_object_inline_stack_3181\n+            JSCompiler_object_inline_stack_3185\n           );\n         pushPrimaryTreeSuspenseHandler(workInProgress);\n         return mountSuspensePrimaryChildren(\n@@ -10635,8 +10649,8 @@\n       }\n       var prevState = current.memoizedState;\n       if (null !== prevState) {\n-        var JSCompiler_object_inline_message_3179 = prevState.dehydrated;\n-        if (null !== JSCompiler_object_inline_message_3179) {\n+        var JSCompiler_object_inline_message_3183 = prevState.dehydrated;\n+        if (null !== JSCompiler_object_inline_message_3183) {\n           if (didSuspend)\n             workInProgress.flags & 256\n               ? (pushPrimaryTreeSuspenseHandler(workInProgress),\n@@ -10653,13 +10667,13 @@\n                   (workInProgress = null))\n                 : (reuseSuspenseHandlerOnStack(workInProgress),\n                   (nextPrimaryChildren =\n-                    JSCompiler_object_inline_stack_3181.fallback),\n+                    JSCompiler_object_inline_stack_3185.fallback),\n                   (nextFallbackChildren = workInProgress.mode),\n-                  (JSCompiler_object_inline_stack_3181 =\n+                  (JSCompiler_object_inline_stack_3185 =\n                     mountWorkInProgressOffscreenFiber(\n                       {\n                         mode: \"visible\",\n-                        children: JSCompiler_object_inline_stack_3181.children\n+                        children: JSCompiler_object_inline_stack_3185.children\n                       },\n                       nextFallbackChildren\n                     )),\n@@ -10670,73 +10684,73 @@\n                     null\n                   )),\n                   (nextPrimaryChildren.flags |= 2),\n-                  (JSCompiler_object_inline_stack_3181.return = workInProgress),\n+                  (JSCompiler_object_inline_stack_3185.return = workInProgress),\n                   (nextPrimaryChildren.return = workInProgress),\n-                  (JSCompiler_object_inline_stack_3181.sibling =\n+                  (JSCompiler_object_inline_stack_3185.sibling =\n                     nextPrimaryChildren),\n-                  (workInProgress.child = JSCompiler_object_inline_stack_3181),\n+                  (workInProgress.child = JSCompiler_object_inline_stack_3185),\n                   reconcileChildFibers(\n                     workInProgress,\n                     current.child,\n                     null,\n                     renderLanes\n                   ),\n-                  (JSCompiler_object_inline_stack_3181 = workInProgress.child),\n-                  (JSCompiler_object_inline_stack_3181.memoizedState =\n+                  (JSCompiler_object_inline_stack_3185 = workInProgress.child),\n+                  (JSCompiler_object_inline_stack_3185.memoizedState =\n                     mountSuspenseOffscreenState(renderLanes)),\n-                  (JSCompiler_object_inline_stack_3181.childLanes =\n+                  (JSCompiler_object_inline_stack_3185.childLanes =\n                     getRemainingWorkInPrimaryTree(\n                       current,\n-                      JSCompiler_object_inline_componentStack_3182,\n+                      JSCompiler_object_inline_componentStack_3186,\n                       renderLanes\n                     )),\n                   (workInProgress.memoizedState = SUSPENDED_MARKER),\n                   (workInProgress = nextPrimaryChildren));\n           else if (\n             (pushPrimaryTreeSuspenseHandler(workInProgress),\n             warnIfHydrating(),\n-            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3179))\n+            isSuspenseInstanceFallback(JSCompiler_object_inline_message_3183))\n           ) {\n-            JSCompiler_object_inline_componentStack_3182 =\n-              JSCompiler_object_inline_message_3179.nextSibling &&\n-              JSCompiler_object_inline_message_3179.nextSibling.dataset;\n-            if (JSCompiler_object_inline_componentStack_3182) {\n+            JSCompiler_object_inline_componentStack_3186 =\n+              JSCompiler_object_inline_message_3183.nextSibling &&\n+              JSCompiler_object_inline_message_3183.nextSibling.dataset;\n+            if (JSCompiler_object_inline_componentStack_3186) {\n               nextPrimaryChildren =\n-                JSCompiler_object_inline_componentStack_3182.dgst;\n-              var message = JSCompiler_object_inline_componentStack_3182.msg;\n+                JSCompiler_object_inline_componentStack_3186.dgst;\n+              var message = JSCompiler_object_inline_componentStack_3186.msg;\n               nextFallbackChildren =\n-                JSCompiler_object_inline_componentStack_3182.stck;\n+                JSCompiler_object_inline_componentStack_3186.stck;\n               var componentStack =\n-                JSCompiler_object_inline_componentStack_3182.cstck;\n+                JSCompiler_object_inline_componentStack_3186.cstck;\n             }\n-            JSCompiler_object_inline_message_3179 = message;\n-            JSCompiler_object_inline_digest_3180 = nextPrimaryChildren;\n-            JSCompiler_object_inline_stack_3181 = nextFallbackChildren;\n-            JSCompiler_object_inline_componentStack_3182 = componentStack;\n-            nextPrimaryChildren = JSCompiler_object_inline_digest_3180;\n-            nextFallbackChildren = JSCompiler_object_inline_message_3179;\n-            componentStack = JSCompiler_object_inline_componentStack_3182;\n+            JSCompiler_object_inline_message_3183 = message;\n+            JSCompiler_object_inline_digest_3184 = nextPrimaryChildren;\n+            JSCompiler_object_inline_stack_3185 = nextFallbackChildren;\n+            JSCompiler_object_inline_componentStack_3186 = componentStack;\n+            nextPrimaryChildren = JSCompiler_object_inline_digest_3184;\n+            nextFallbackChildren = JSCompiler_object_inline_message_3183;\n+            componentStack = JSCompiler_object_inline_componentStack_3186;\n             \"POSTPONE\" !== nextPrimaryChildren &&\n-              ((JSCompiler_object_inline_componentStack_3182 =\n+              ((JSCompiler_object_inline_componentStack_3186 =\n                 nextFallbackChildren\n                   ? Error(nextFallbackChildren)\n                   : Error(\n                       \"The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.\"\n                     )),\n-              (JSCompiler_object_inline_componentStack_3182.stack =\n-                JSCompiler_object_inline_stack_3181 || \"\"),\n-              (JSCompiler_object_inline_componentStack_3182.digest =\n+              (JSCompiler_object_inline_componentStack_3186.stack =\n+                JSCompiler_object_inline_stack_3185 || \"\"),\n+              (JSCompiler_object_inline_componentStack_3186.digest =\n                 nextPrimaryChildren),\n-              (JSCompiler_object_inline_stack_3181 =\n+              (JSCompiler_object_inline_stack_3185 =\n                 void 0 === componentStack ? null : componentStack),\n               (nextPrimaryChildren = {\n-                value: JSCompiler_object_inline_componentStack_3182,\n+                value: JSCompiler_object_inline_componentStack_3186,\n                 source: null,\n-                stack: JSCompiler_object_inline_stack_3181\n+                stack: JSCompiler_object_inline_stack_3185\n               }),\n-              \"string\" === typeof JSCompiler_object_inline_stack_3181 &&\n+              \"string\" === typeof JSCompiler_object_inline_stack_3185 &&\n                 CapturedStacks.set(\n-                  JSCompiler_object_inline_componentStack_3182,\n+                  JSCompiler_object_inline_componentStack_3186,\n                   nextPrimaryChildren\n                 ),\n               queueHydrationError(nextPrimaryChildren));\n@@ -10753,48 +10767,48 @@\n                 renderLanes,\n                 !1\n               ),\n-            (JSCompiler_object_inline_componentStack_3182 =\n+            (JSCompiler_object_inline_componentStack_3186 =\n               0 !== (renderLanes & current.childLanes)),\n-            didReceiveUpdate || JSCompiler_object_inline_componentStack_3182)\n+            didReceiveUpdate || JSCompiler_object_inline_componentStack_3186)\n           ) {\n-            JSCompiler_object_inline_componentStack_3182 = workInProgressRoot;\n+            JSCompiler_object_inline_componentStack_3186 = workInProgressRoot;\n             if (\n-              null !== JSCompiler_object_inline_componentStack_3182 &&\n-              ((JSCompiler_object_inline_stack_3181 = getBumpedLaneForHydration(\n-                JSCompiler_object_inline_componentStack_3182,\n+              null !== JSCompiler_object_inline_componentStack_3186 &&\n+              ((JSCompiler_object_inline_stack_3185 = getBumpedLaneForHydration(\n+                JSCompiler_object_inline_componentStack_3186,\n                 renderLanes\n               )),\n-              0 !== JSCompiler_object_inline_stack_3181 &&\n-                JSCompiler_object_inline_stack_3181 !== prevState.retryLane)\n+              0 !== JSCompiler_object_inline_stack_3185 &&\n+                JSCompiler_object_inline_stack_3185 !== prevState.retryLane)\n             )\n               throw (\n-                ((prevState.retryLane = JSCompiler_object_inline_stack_3181),\n+                ((prevState.retryLane = JSCompiler_object_inline_stack_3185),\n                 enqueueConcurrentRenderForLane(\n                   current,\n-                  JSCompiler_object_inline_stack_3181\n+                  JSCompiler_object_inline_stack_3185\n                 ),\n                 scheduleUpdateOnFiber(\n-                  JSCompiler_object_inline_componentStack_3182,\n+                  JSCompiler_object_inline_componentStack_3186,\n                   current,\n-                  JSCompiler_object_inline_stack_3181\n+                  JSCompiler_object_inline_stack_3185\n                 ),\n                 SelectiveHydrationException)\n               );\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3179) ||\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3183) ||\n               renderDidSuspendDelayIfPossible();\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n               workInProgress,\n               renderLanes\n             );\n           } else\n-            isSuspenseInstancePending(JSCompiler_object_inline_message_3179)\n+            isSuspenseInstancePending(JSCompiler_object_inline_message_3183)\n               ? ((workInProgress.flags |= 192),\n                 (workInProgress.child = current.child),\n                 (workInProgress = null))\n               : ((current = prevState.treeContext),\n                 (nextHydratableInstance = getNextHydratable(\n-                  JSCompiler_object_inline_message_3179.nextSibling\n+                  JSCompiler_object_inline_message_3183.nextSibling\n                 )),\n                 (hydrationParentFiber = workInProgress),\n                 (isHydrating = !0),\n@@ -10806,31 +10820,31 @@\n                   restoreSuspendedTreeContext(workInProgress, current),\n                 (workInProgress = mountSuspensePrimaryChildren(\n                   workInProgress,\n-                  JSCompiler_object_inline_stack_3181.children\n+                  JSCompiler_object_inline_stack_3185.children\n                 )),\n                 (workInProgress.flags |= 4096));\n           return workInProgress;\n         }\n       }\n-      if (JSCompiler_object_inline_digest_3180)\n+      if (JSCompiler_object_inline_digest_3184)\n         return (\n           reuseSuspenseHandlerOnStack(workInProgress),\n-          (nextPrimaryChildren = JSCompiler_object_inline_stack_3181.fallback),\n+          (nextPrimaryChildren = JSCompiler_object_inline_stack_3185.fallback),\n           (nextFallbackChildren = workInProgress.mode),\n           (componentStack = current.child),\n-          (JSCompiler_object_inline_message_3179 = componentStack.sibling),\n-          (JSCompiler_object_inline_stack_3181 = createWorkInProgress(\n+          (JSCompiler_object_inline_message_3183 = componentStack.sibling),\n+          (JSCompiler_object_inline_stack_3185 = createWorkInProgress(\n             componentStack,\n             {\n               mode: \"hidden\",\n-              children: JSCompiler_object_inline_stack_3181.children\n+              children: JSCompiler_object_inline_stack_3185.children\n             }\n           )),\n-          (JSCompiler_object_inline_stack_3181.subtreeFlags =\n+          (JSCompiler_object_inline_stack_3185.subtreeFlags =\n             componentStack.subtreeFlags & 65011712),\n-          null !== JSCompiler_object_inline_message_3179\n+          null !== JSCompiler_object_inline_message_3183\n             ? (nextPrimaryChildren = createWorkInProgress(\n-                JSCompiler_object_inline_message_3179,\n+                JSCompiler_object_inline_message_3183,\n                 nextPrimaryChildren\n               ))\n             : ((nextPrimaryChildren = createFiberFromFragment(\n@@ -10841,24 +10855,24 @@\n               )),\n               (nextPrimaryChildren.flags |= 2)),\n           (nextPrimaryChildren.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3181.return = workInProgress),\n-          (JSCompiler_object_inline_stack_3181.sibling = nextPrimaryChildren),\n-          (workInProgress.child = JSCompiler_object_inline_stack_3181),\n-          (JSCompiler_object_inline_stack_3181 = nextPrimaryChildren),\n+          (JSCompiler_object_inline_stack_3185.return = workInProgress),\n+          (JSCompiler_object_inline_stack_3185.sibling = nextPrimaryChildren),\n+          (workInProgress.child = JSCompiler_object_inline_stack_3185),\n+          (JSCompiler_object_inline_stack_3185 = nextPrimaryChildren),\n           (nextPrimaryChildren = workInProgress.child),\n           (nextFallbackChildren = current.child.memoizedState),\n           null === nextFallbackChildren\n             ? (nextFallbackChildren = mountSuspenseOffscreenState(renderLanes))\n             : ((componentStack = nextFallbackChildren.cachePool),\n               null !== componentStack\n-                ? ((JSCompiler_object_inline_message_3179 =\n+                ? ((JSCompiler_object_inline_message_3183 =\n                     CacheContext._currentValue),\n                   (componentStack =\n                     componentStack.parent !==\n-                    JSCompiler_object_inline_message_3179\n+                    JSCompiler_object_inline_message_3183\n                       ? {\n-                          parent: JSCompiler_object_inline_message_3179,\n-                          pool: JSCompiler_object_inline_message_3179\n+                          parent: JSCompiler_object_inline_message_3183,\n+                          pool: JSCompiler_object_inline_message_3183\n                         }\n                       : componentStack))\n                 : (componentStack = getSuspendedCache()),\n@@ -10869,28 +10883,28 @@\n           (nextPrimaryChildren.memoizedState = nextFallbackChildren),\n           (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_componentStack_3182,\n+            JSCompiler_object_inline_componentStack_3186,\n             renderLanes\n           )),\n           (workInProgress.memoizedState = SUSPENDED_MARKER),\n-          JSCompiler_object_inline_stack_3181\n+          JSCompiler_object_inline_stack_3185\n         );\n       pushPrimaryTreeSuspenseHandler(workInProgress);\n       renderLanes = current.child;\n       current = renderLanes.sibling;\n       renderLanes = createWorkInProgress(renderLanes, {\n         mode: \"visible\",\n-        children: JSCompiler_object_inline_stack_3181.children\n+        children: JSCompiler_object_inline_stack_3185.children\n       });\n       renderLanes.return = workInProgress;\n       renderLanes.sibling = null;\n       null !== current &&\n-        ((JSCompiler_object_inline_componentStack_3182 =\n+        ((JSCompiler_object_inline_componentStack_3186 =\n           workInProgress.deletions),\n-        null === JSCompiler_object_inline_componentStack_3182\n+        null === JSCompiler_object_inline_componentStack_3186\n           ? ((workInProgress.deletions = [current]),\n             (workInProgress.flags |= 16))\n-          : JSCompiler_object_inline_componentStack_3182.push(current));\n+          : JSCompiler_object_inline_componentStack_3186.push(current));\n       workInProgress.child = renderLanes;\n       workInProgress.memoizedState = null;\n       return renderLanes;\n@@ -30961,11 +30975,11 @@\n     };\n     (function () {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-experimental-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-experimental-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-experimental-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-experimental-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     })();\n     (\"function\" === typeof Map &&\n@@ -31002,10 +31016,10 @@\n       !(function () {\n         var internals = {\n           bundleType: 1,\n-          version: \"19.2.0-experimental-fa3feba6-20250623\",\n+          version: \"19.2.0-experimental-cee7939b-20250625\",\n           rendererPackageName: \"react-dom\",\n           currentDispatcherRef: ReactSharedInternals,\n-          reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+          reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n         };\n         internals.overrideHookState = overrideHookState;\n         internals.overrideHookStateDeletePath = overrideHookStateDeletePath;\n@@ -31317,5 +31331,5 @@\n         }\n       };\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "67c89526539245a4b6796a08287206841f57482a",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom-unstable_testing.production.js",
            "status": "modified",
            "additions": 27,
            "deletions": 27,
            "changes": 54,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom-unstable_testing.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -14754,20 +14754,20 @@ function debounceScrollEnd(targetInst, nativeEvent, nativeEventTarget) {\n     (nativeEventTarget[internalScrollTimer] = targetInst));\n }\n for (\n-  var i$jscomp$inline_1821 = 0;\n-  i$jscomp$inline_1821 < simpleEventPluginEvents.length;\n-  i$jscomp$inline_1821++\n+  var i$jscomp$inline_1827 = 0;\n+  i$jscomp$inline_1827 < simpleEventPluginEvents.length;\n+  i$jscomp$inline_1827++\n ) {\n-  var eventName$jscomp$inline_1822 =\n-      simpleEventPluginEvents[i$jscomp$inline_1821],\n-    domEventName$jscomp$inline_1823 =\n-      eventName$jscomp$inline_1822.toLowerCase(),\n-    capitalizedEvent$jscomp$inline_1824 =\n-      eventName$jscomp$inline_1822[0].toUpperCase() +\n-      eventName$jscomp$inline_1822.slice(1);\n+  var eventName$jscomp$inline_1828 =\n+      simpleEventPluginEvents[i$jscomp$inline_1827],\n+    domEventName$jscomp$inline_1829 =\n+      eventName$jscomp$inline_1828.toLowerCase(),\n+    capitalizedEvent$jscomp$inline_1830 =\n+      eventName$jscomp$inline_1828[0].toUpperCase() +\n+      eventName$jscomp$inline_1828.slice(1);\n   registerSimpleEvent(\n-    domEventName$jscomp$inline_1823,\n-    \"on\" + capitalizedEvent$jscomp$inline_1824\n+    domEventName$jscomp$inline_1829,\n+    \"on\" + capitalizedEvent$jscomp$inline_1830\n   );\n }\n registerSimpleEvent(ANIMATION_END, \"onAnimationEnd\");\n@@ -19473,16 +19473,16 @@ ReactDOMHydrationRoot.prototype.unstable_scheduleHydration = function (target) {\n     0 === i && attemptExplicitHydrationTarget(target);\n   }\n };\n-var isomorphicReactPackageVersion$jscomp$inline_2209 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_2215 = React.version;\n if (\n-  \"19.2.0-experimental-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_2209\n+  \"19.2.0-experimental-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_2215\n )\n   throw Error(\n     formatProdErrorMessage(\n       527,\n-      isomorphicReactPackageVersion$jscomp$inline_2209,\n-      \"19.2.0-experimental-fa3feba6-20250623\"\n+      isomorphicReactPackageVersion$jscomp$inline_2215,\n+      \"19.2.0-experimental-cee7939b-20250625\"\n     )\n   );\n ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n@@ -19502,24 +19502,24 @@ ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n     null === componentOrElement ? null : componentOrElement.stateNode;\n   return componentOrElement;\n };\n-var internals$jscomp$inline_2899 = {\n+var internals$jscomp$inline_2905 = {\n   bundleType: 0,\n-  version: \"19.2.0-experimental-fa3feba6-20250623\",\n+  version: \"19.2.0-experimental-cee7939b-20250625\",\n   rendererPackageName: \"react-dom\",\n   currentDispatcherRef: ReactSharedInternals,\n-  reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\"\n+  reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\"\n };\n if (\"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__) {\n-  var hook$jscomp$inline_2900 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n+  var hook$jscomp$inline_2906 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n   if (\n-    !hook$jscomp$inline_2900.isDisabled &&\n-    hook$jscomp$inline_2900.supportsFiber\n+    !hook$jscomp$inline_2906.isDisabled &&\n+    hook$jscomp$inline_2906.supportsFiber\n   )\n     try {\n-      (rendererID = hook$jscomp$inline_2900.inject(\n-        internals$jscomp$inline_2899\n+      (rendererID = hook$jscomp$inline_2906.inject(\n+        internals$jscomp$inline_2905\n       )),\n-        (injectedHook = hook$jscomp$inline_2900);\n+        (injectedHook = hook$jscomp$inline_2906);\n     } catch (err) {}\n }\n exports.createComponentSelector = function (component) {\n@@ -19765,4 +19765,4 @@ exports.observeVisibleRects = function (\n     }\n   };\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "11990e764746f154adc6087cb952bb4deffbce5b",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -416,7 +416,7 @@\n     exports.useFormStatus = function () {\n       return resolveDispatcher().useHostTransitionStatus();\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "30b5b9bfb48728b32469284b8e184f938fb1f905",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -207,4 +207,4 @@ exports.useFormState = function (action, initialState, permalink) {\n exports.useFormStatus = function () {\n   return ReactSharedInternals.H.useHostTransitionStatus();\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "3e3c4b64f02229d33b99ce8f1f1cc85637693c77",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom.react-server.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -336,5 +336,5 @@\n             }))\n           : Internals.d.m(href));\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "d07196a146bcc0c546eb4f7edbdd01fdd2538331",
            "filename": "packages/next/src/compiled/react-dom-experimental/cjs/react-dom.react-server.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fcjs%2Freact-dom.react-server.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -149,4 +149,4 @@ exports.preloadModule = function (href, options) {\n       });\n     } else Internals.d.m(href);\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "8922928e793012121e2fa6345dce209ddbddbe81",
            "filename": "packages/next/src/compiled/react-dom-experimental/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom-experimental%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -72,10 +72,10 @@\n     \"./package.json\": \"./package.json\"\n   },\n   \"dependencies\": {\n-    \"scheduler\": \"0.0.0-experimental-fa3feba6-20250623\"\n+    \"scheduler\": \"0.0.0-experimental-cee7939b-20250625\"\n   },\n   \"peerDependencies\": {\n-    \"react\": \"0.0.0-experimental-fa3feba6-20250623\"\n+    \"react\": \"0.0.0-experimental-cee7939b-20250625\"\n   },\n   \"browser\": {\n     \"./server.js\": \"./server.browser.js\","
        },
        {
            "sha": "2d5d339cf8897108efa7891e52d3b9eb23e96bcb",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-client.development.js",
            "status": "modified",
            "additions": 142,
            "deletions": 128,
            "changes": 270,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -532,6 +532,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -704,27 +725,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeFiber(fiber) {\n       switch (fiber.tag) {\n         case 26:\n@@ -760,11 +760,25 @@\n             for (var i = debugInfo.length - 1; 0 <= i; i--) {\n               var entry = debugInfo[i];\n               if (\"string\" === typeof entry.name) {\n-                var JSCompiler_temp_const = info,\n-                  env = entry.env;\n-                var JSCompiler_inline_result = describeBuiltInComponentFrame(\n-                  entry.name + (env ? \" [\" + env + \"]\" : \"\")\n-                );\n+                var JSCompiler_temp_const = info;\n+                a: {\n+                  var name = entry.name,\n+                    env = entry.env,\n+                    location = entry.debugLocation;\n+                  if (null != location) {\n+                    var childStack = formatOwnerStack(location),\n+                      idx = childStack.lastIndexOf(\"\\n\"),\n+                      lastLine =\n+                        -1 === idx ? childStack : childStack.slice(idx + 1);\n+                    if (-1 !== lastLine.indexOf(name)) {\n+                      var JSCompiler_inline_result = \"\\n\" + lastLine;\n+                      break a;\n+                    }\n+                  }\n+                  JSCompiler_inline_result = describeBuiltInComponentFrame(\n+                    name + (env ? \" [\" + env + \"]\" : \"\")\n+                  );\n+                }\n                 info = JSCompiler_temp_const + JSCompiler_inline_result;\n               }\n             }\n@@ -9700,24 +9714,24 @@\n       return current;\n     }\n     function updateSuspenseComponent(current, workInProgress, renderLanes) {\n-      var JSCompiler_object_inline_digest_2550;\n-      var JSCompiler_object_inline_stack_2551 = workInProgress.pendingProps;\n+      var JSCompiler_object_inline_digest_2554;\n+      var JSCompiler_object_inline_stack_2555 = workInProgress.pendingProps;\n       shouldSuspendImpl(workInProgress) && (workInProgress.flags |= 128);\n-      var JSCompiler_object_inline_message_2549 = !1;\n+      var JSCompiler_object_inline_message_2553 = !1;\n       var didSuspend = 0 !== (workInProgress.flags & 128);\n-      (JSCompiler_object_inline_digest_2550 = didSuspend) ||\n-        (JSCompiler_object_inline_digest_2550 =\n+      (JSCompiler_object_inline_digest_2554 = didSuspend) ||\n+        (JSCompiler_object_inline_digest_2554 =\n           null !== current && null === current.memoizedState\n             ? !1\n             : 0 !== (suspenseStackCursor.current & ForceSuspenseFallback));\n-      JSCompiler_object_inline_digest_2550 &&\n-        ((JSCompiler_object_inline_message_2549 = !0),\n+      JSCompiler_object_inline_digest_2554 &&\n+        ((JSCompiler_object_inline_message_2553 = !0),\n         (workInProgress.flags &= -129));\n-      JSCompiler_object_inline_digest_2550 = 0 !== (workInProgress.flags & 32);\n+      JSCompiler_object_inline_digest_2554 = 0 !== (workInProgress.flags & 32);\n       workInProgress.flags &= -33;\n       if (null === current) {\n         if (isHydrating) {\n-          JSCompiler_object_inline_message_2549\n+          JSCompiler_object_inline_message_2553\n             ? pushPrimaryTreeSuspenseHandler(workInProgress)\n             : reuseSuspenseHandlerOnStack(workInProgress);\n           (current = nextHydratableInstance)\n@@ -9730,18 +9744,18 @@\n                   ? renderLanes\n                   : null),\n               null !== renderLanes &&\n-                ((JSCompiler_object_inline_digest_2550 = {\n+                ((JSCompiler_object_inline_digest_2554 = {\n                   dehydrated: renderLanes,\n                   treeContext: getSuspendedTreeContext(),\n                   retryLane: 536870912,\n                   hydrationErrors: null\n                 }),\n                 (workInProgress.memoizedState =\n-                  JSCompiler_object_inline_digest_2550),\n-                (JSCompiler_object_inline_digest_2550 =\n+                  JSCompiler_object_inline_digest_2554),\n+                (JSCompiler_object_inline_digest_2554 =\n                   createFiberFromDehydratedFragment(renderLanes)),\n-                (JSCompiler_object_inline_digest_2550.return = workInProgress),\n-                (workInProgress.child = JSCompiler_object_inline_digest_2550),\n+                (JSCompiler_object_inline_digest_2554.return = workInProgress),\n+                (workInProgress.child = JSCompiler_object_inline_digest_2554),\n                 (hydrationParentFiber = workInProgress),\n                 (nextHydratableInstance = null)))\n             : (renderLanes = null);\n@@ -9755,36 +9769,36 @@\n             : (workInProgress.lanes = 536870912);\n           return null;\n         }\n-        var nextPrimaryChildren = JSCompiler_object_inline_stack_2551.children;\n-        JSCompiler_object_inline_stack_2551 =\n-          JSCompiler_object_inline_stack_2551.fallback;\n-        if (JSCompiler_object_inline_message_2549) {\n+        var nextPrimaryChildren = JSCompiler_object_inline_stack_2555.children;\n+        JSCompiler_object_inline_stack_2555 =\n+          JSCompiler_object_inline_stack_2555.fallback;\n+        if (JSCompiler_object_inline_message_2553) {\n           reuseSuspenseHandlerOnStack(workInProgress);\n           var mode = workInProgress.mode;\n           nextPrimaryChildren = mountWorkInProgressOffscreenFiber(\n             { mode: \"hidden\", children: nextPrimaryChildren },\n             mode\n           );\n-          JSCompiler_object_inline_stack_2551 = createFiberFromFragment(\n-            JSCompiler_object_inline_stack_2551,\n+          JSCompiler_object_inline_stack_2555 = createFiberFromFragment(\n+            JSCompiler_object_inline_stack_2555,\n             mode,\n             renderLanes,\n             null\n           );\n           nextPrimaryChildren.return = workInProgress;\n-          JSCompiler_object_inline_stack_2551.return = workInProgress;\n-          nextPrimaryChildren.sibling = JSCompiler_object_inline_stack_2551;\n+          JSCompiler_object_inline_stack_2555.return = workInProgress;\n+          nextPrimaryChildren.sibling = JSCompiler_object_inline_stack_2555;\n           workInProgress.child = nextPrimaryChildren;\n           nextPrimaryChildren = workInProgress.child;\n           nextPrimaryChildren.memoizedState =\n             mountSuspenseOffscreenState(renderLanes);\n           nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_digest_2550,\n+            JSCompiler_object_inline_digest_2554,\n             renderLanes\n           );\n           workInProgress.memoizedState = SUSPENDED_MARKER;\n-          return JSCompiler_object_inline_stack_2551;\n+          return JSCompiler_object_inline_stack_2555;\n         }\n         pushPrimaryTreeSuspenseHandler(workInProgress);\n         return mountSuspensePrimaryChildren(\n@@ -9794,8 +9808,8 @@\n       }\n       var prevState = current.memoizedState;\n       if (null !== prevState) {\n-        var JSCompiler_object_inline_componentStack_2552 = prevState.dehydrated;\n-        if (null !== JSCompiler_object_inline_componentStack_2552) {\n+        var JSCompiler_object_inline_componentStack_2556 = prevState.dehydrated;\n+        if (null !== JSCompiler_object_inline_componentStack_2556) {\n           if (didSuspend)\n             workInProgress.flags & 256\n               ? (pushPrimaryTreeSuspenseHandler(workInProgress),\n@@ -9812,13 +9826,13 @@\n                   (workInProgress = null))\n                 : (reuseSuspenseHandlerOnStack(workInProgress),\n                   (nextPrimaryChildren =\n-                    JSCompiler_object_inline_stack_2551.fallback),\n+                    JSCompiler_object_inline_stack_2555.fallback),\n                   (mode = workInProgress.mode),\n-                  (JSCompiler_object_inline_stack_2551 =\n+                  (JSCompiler_object_inline_stack_2555 =\n                     mountWorkInProgressOffscreenFiber(\n                       {\n                         mode: \"visible\",\n-                        children: JSCompiler_object_inline_stack_2551.children\n+                        children: JSCompiler_object_inline_stack_2555.children\n                       },\n                       mode\n                     )),\n@@ -9829,24 +9843,24 @@\n                     null\n                   )),\n                   (nextPrimaryChildren.flags |= 2),\n-                  (JSCompiler_object_inline_stack_2551.return = workInProgress),\n+                  (JSCompiler_object_inline_stack_2555.return = workInProgress),\n                   (nextPrimaryChildren.return = workInProgress),\n-                  (JSCompiler_object_inline_stack_2551.sibling =\n+                  (JSCompiler_object_inline_stack_2555.sibling =\n                     nextPrimaryChildren),\n-                  (workInProgress.child = JSCompiler_object_inline_stack_2551),\n+                  (workInProgress.child = JSCompiler_object_inline_stack_2555),\n                   reconcileChildFibers(\n                     workInProgress,\n                     current.child,\n                     null,\n                     renderLanes\n                   ),\n-                  (JSCompiler_object_inline_stack_2551 = workInProgress.child),\n-                  (JSCompiler_object_inline_stack_2551.memoizedState =\n+                  (JSCompiler_object_inline_stack_2555 = workInProgress.child),\n+                  (JSCompiler_object_inline_stack_2555.memoizedState =\n                     mountSuspenseOffscreenState(renderLanes)),\n-                  (JSCompiler_object_inline_stack_2551.childLanes =\n+                  (JSCompiler_object_inline_stack_2555.childLanes =\n                     getRemainingWorkInPrimaryTree(\n                       current,\n-                      JSCompiler_object_inline_digest_2550,\n+                      JSCompiler_object_inline_digest_2554,\n                       renderLanes\n                     )),\n                   (workInProgress.memoizedState = SUSPENDED_MARKER),\n@@ -9855,45 +9869,45 @@\n             (pushPrimaryTreeSuspenseHandler(workInProgress),\n             warnIfHydrating(),\n             isSuspenseInstanceFallback(\n-              JSCompiler_object_inline_componentStack_2552\n+              JSCompiler_object_inline_componentStack_2556\n             ))\n           ) {\n-            JSCompiler_object_inline_digest_2550 =\n-              JSCompiler_object_inline_componentStack_2552.nextSibling &&\n-              JSCompiler_object_inline_componentStack_2552.nextSibling.dataset;\n-            if (JSCompiler_object_inline_digest_2550) {\n-              nextPrimaryChildren = JSCompiler_object_inline_digest_2550.dgst;\n-              var message = JSCompiler_object_inline_digest_2550.msg;\n-              mode = JSCompiler_object_inline_digest_2550.stck;\n-              var componentStack = JSCompiler_object_inline_digest_2550.cstck;\n+            JSCompiler_object_inline_digest_2554 =\n+              JSCompiler_object_inline_componentStack_2556.nextSibling &&\n+              JSCompiler_object_inline_componentStack_2556.nextSibling.dataset;\n+            if (JSCompiler_object_inline_digest_2554) {\n+              nextPrimaryChildren = JSCompiler_object_inline_digest_2554.dgst;\n+              var message = JSCompiler_object_inline_digest_2554.msg;\n+              mode = JSCompiler_object_inline_digest_2554.stck;\n+              var componentStack = JSCompiler_object_inline_digest_2554.cstck;\n             }\n-            JSCompiler_object_inline_message_2549 = message;\n-            JSCompiler_object_inline_digest_2550 = nextPrimaryChildren;\n-            JSCompiler_object_inline_stack_2551 = mode;\n-            JSCompiler_object_inline_componentStack_2552 = componentStack;\n-            nextPrimaryChildren = JSCompiler_object_inline_message_2549;\n-            mode = JSCompiler_object_inline_componentStack_2552;\n+            JSCompiler_object_inline_message_2553 = message;\n+            JSCompiler_object_inline_digest_2554 = nextPrimaryChildren;\n+            JSCompiler_object_inline_stack_2555 = mode;\n+            JSCompiler_object_inline_componentStack_2556 = componentStack;\n+            nextPrimaryChildren = JSCompiler_object_inline_message_2553;\n+            mode = JSCompiler_object_inline_componentStack_2556;\n             nextPrimaryChildren = nextPrimaryChildren\n               ? Error(nextPrimaryChildren)\n               : Error(\n                   \"The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.\"\n                 );\n             nextPrimaryChildren.stack =\n-              JSCompiler_object_inline_stack_2551 || \"\";\n-            nextPrimaryChildren.digest = JSCompiler_object_inline_digest_2550;\n-            JSCompiler_object_inline_digest_2550 =\n+              JSCompiler_object_inline_stack_2555 || \"\";\n+            nextPrimaryChildren.digest = JSCompiler_object_inline_digest_2554;\n+            JSCompiler_object_inline_digest_2554 =\n               void 0 === mode ? null : mode;\n-            JSCompiler_object_inline_stack_2551 = {\n+            JSCompiler_object_inline_stack_2555 = {\n               value: nextPrimaryChildren,\n               source: null,\n-              stack: JSCompiler_object_inline_digest_2550\n+              stack: JSCompiler_object_inline_digest_2554\n             };\n-            \"string\" === typeof JSCompiler_object_inline_digest_2550 &&\n+            \"string\" === typeof JSCompiler_object_inline_digest_2554 &&\n               CapturedStacks.set(\n                 nextPrimaryChildren,\n-                JSCompiler_object_inline_stack_2551\n+                JSCompiler_object_inline_stack_2555\n               );\n-            queueHydrationError(JSCompiler_object_inline_stack_2551);\n+            queueHydrationError(JSCompiler_object_inline_stack_2555);\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n               workInProgress,\n@@ -9907,35 +9921,35 @@\n                 renderLanes,\n                 !1\n               ),\n-            (JSCompiler_object_inline_digest_2550 =\n+            (JSCompiler_object_inline_digest_2554 =\n               0 !== (renderLanes & current.childLanes)),\n-            didReceiveUpdate || JSCompiler_object_inline_digest_2550)\n+            didReceiveUpdate || JSCompiler_object_inline_digest_2554)\n           ) {\n-            JSCompiler_object_inline_digest_2550 = workInProgressRoot;\n+            JSCompiler_object_inline_digest_2554 = workInProgressRoot;\n             if (\n-              null !== JSCompiler_object_inline_digest_2550 &&\n-              ((JSCompiler_object_inline_stack_2551 = getBumpedLaneForHydration(\n-                JSCompiler_object_inline_digest_2550,\n+              null !== JSCompiler_object_inline_digest_2554 &&\n+              ((JSCompiler_object_inline_stack_2555 = getBumpedLaneForHydration(\n+                JSCompiler_object_inline_digest_2554,\n                 renderLanes\n               )),\n-              0 !== JSCompiler_object_inline_stack_2551 &&\n-                JSCompiler_object_inline_stack_2551 !== prevState.retryLane)\n+              0 !== JSCompiler_object_inline_stack_2555 &&\n+                JSCompiler_object_inline_stack_2555 !== prevState.retryLane)\n             )\n               throw (\n-                ((prevState.retryLane = JSCompiler_object_inline_stack_2551),\n+                ((prevState.retryLane = JSCompiler_object_inline_stack_2555),\n                 enqueueConcurrentRenderForLane(\n                   current,\n-                  JSCompiler_object_inline_stack_2551\n+                  JSCompiler_object_inline_stack_2555\n                 ),\n                 scheduleUpdateOnFiber(\n-                  JSCompiler_object_inline_digest_2550,\n+                  JSCompiler_object_inline_digest_2554,\n                   current,\n-                  JSCompiler_object_inline_stack_2551\n+                  JSCompiler_object_inline_stack_2555\n                 ),\n                 SelectiveHydrationException)\n               );\n             isSuspenseInstancePending(\n-              JSCompiler_object_inline_componentStack_2552\n+              JSCompiler_object_inline_componentStack_2556\n             ) || renderDidSuspendDelayIfPossible();\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n@@ -9944,14 +9958,14 @@\n             );\n           } else\n             isSuspenseInstancePending(\n-              JSCompiler_object_inline_componentStack_2552\n+              JSCompiler_object_inline_componentStack_2556\n             )\n               ? ((workInProgress.flags |= 192),\n                 (workInProgress.child = current.child),\n                 (workInProgress = null))\n               : ((current = prevState.treeContext),\n                 (nextHydratableInstance = getNextHydratable(\n-                  JSCompiler_object_inline_componentStack_2552.nextSibling\n+                  JSCompiler_object_inline_componentStack_2556.nextSibling\n                 )),\n                 (hydrationParentFiber = workInProgress),\n                 (isHydrating = !0),\n@@ -9963,32 +9977,32 @@\n                   restoreSuspendedTreeContext(workInProgress, current),\n                 (workInProgress = mountSuspensePrimaryChildren(\n                   workInProgress,\n-                  JSCompiler_object_inline_stack_2551.children\n+                  JSCompiler_object_inline_stack_2555.children\n                 )),\n                 (workInProgress.flags |= 4096));\n           return workInProgress;\n         }\n       }\n-      if (JSCompiler_object_inline_message_2549)\n+      if (JSCompiler_object_inline_message_2553)\n         return (\n           reuseSuspenseHandlerOnStack(workInProgress),\n-          (nextPrimaryChildren = JSCompiler_object_inline_stack_2551.fallback),\n+          (nextPrimaryChildren = JSCompiler_object_inline_stack_2555.fallback),\n           (mode = workInProgress.mode),\n           (componentStack = current.child),\n-          (JSCompiler_object_inline_componentStack_2552 =\n+          (JSCompiler_object_inline_componentStack_2556 =\n             componentStack.sibling),\n-          (JSCompiler_object_inline_stack_2551 = createWorkInProgress(\n+          (JSCompiler_object_inline_stack_2555 = createWorkInProgress(\n             componentStack,\n             {\n               mode: \"hidden\",\n-              children: JSCompiler_object_inline_stack_2551.children\n+              children: JSCompiler_object_inline_stack_2555.children\n             }\n           )),\n-          (JSCompiler_object_inline_stack_2551.subtreeFlags =\n+          (JSCompiler_object_inline_stack_2555.subtreeFlags =\n             componentStack.subtreeFlags & 65011712),\n-          null !== JSCompiler_object_inline_componentStack_2552\n+          null !== JSCompiler_object_inline_componentStack_2556\n             ? (nextPrimaryChildren = createWorkInProgress(\n-                JSCompiler_object_inline_componentStack_2552,\n+                JSCompiler_object_inline_componentStack_2556,\n                 nextPrimaryChildren\n               ))\n             : ((nextPrimaryChildren = createFiberFromFragment(\n@@ -9999,24 +10013,24 @@\n               )),\n               (nextPrimaryChildren.flags |= 2)),\n           (nextPrimaryChildren.return = workInProgress),\n-          (JSCompiler_object_inline_stack_2551.return = workInProgress),\n-          (JSCompiler_object_inline_stack_2551.sibling = nextPrimaryChildren),\n-          (workInProgress.child = JSCompiler_object_inline_stack_2551),\n-          (JSCompiler_object_inline_stack_2551 = nextPrimaryChildren),\n+          (JSCompiler_object_inline_stack_2555.return = workInProgress),\n+          (JSCompiler_object_inline_stack_2555.sibling = nextPrimaryChildren),\n+          (workInProgress.child = JSCompiler_object_inline_stack_2555),\n+          (JSCompiler_object_inline_stack_2555 = nextPrimaryChildren),\n           (nextPrimaryChildren = workInProgress.child),\n           (mode = current.child.memoizedState),\n           null === mode\n             ? (mode = mountSuspenseOffscreenState(renderLanes))\n             : ((componentStack = mode.cachePool),\n               null !== componentStack\n-                ? ((JSCompiler_object_inline_componentStack_2552 =\n+                ? ((JSCompiler_object_inline_componentStack_2556 =\n                     CacheContext._currentValue),\n                   (componentStack =\n                     componentStack.parent !==\n-                    JSCompiler_object_inline_componentStack_2552\n+                    JSCompiler_object_inline_componentStack_2556\n                       ? {\n-                          parent: JSCompiler_object_inline_componentStack_2552,\n-                          pool: JSCompiler_object_inline_componentStack_2552\n+                          parent: JSCompiler_object_inline_componentStack_2556,\n+                          pool: JSCompiler_object_inline_componentStack_2556\n                         }\n                       : componentStack))\n                 : (componentStack = getSuspendedCache()),\n@@ -10027,27 +10041,27 @@\n           (nextPrimaryChildren.memoizedState = mode),\n           (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_digest_2550,\n+            JSCompiler_object_inline_digest_2554,\n             renderLanes\n           )),\n           (workInProgress.memoizedState = SUSPENDED_MARKER),\n-          JSCompiler_object_inline_stack_2551\n+          JSCompiler_object_inline_stack_2555\n         );\n       pushPrimaryTreeSuspenseHandler(workInProgress);\n       renderLanes = current.child;\n       current = renderLanes.sibling;\n       renderLanes = createWorkInProgress(renderLanes, {\n         mode: \"visible\",\n-        children: JSCompiler_object_inline_stack_2551.children\n+        children: JSCompiler_object_inline_stack_2555.children\n       });\n       renderLanes.return = workInProgress;\n       renderLanes.sibling = null;\n       null !== current &&\n-        ((JSCompiler_object_inline_digest_2550 = workInProgress.deletions),\n-        null === JSCompiler_object_inline_digest_2550\n+        ((JSCompiler_object_inline_digest_2554 = workInProgress.deletions),\n+        null === JSCompiler_object_inline_digest_2554\n           ? ((workInProgress.deletions = [current]),\n             (workInProgress.flags |= 16))\n-          : JSCompiler_object_inline_digest_2550.push(current));\n+          : JSCompiler_object_inline_digest_2554.push(current));\n       workInProgress.child = renderLanes;\n       workInProgress.memoizedState = null;\n       return renderLanes;\n@@ -25487,11 +25501,11 @@\n     };\n     (function () {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     })();\n     (\"function\" === typeof Map &&\n@@ -25528,10 +25542,10 @@\n       !(function () {\n         var internals = {\n           bundleType: 1,\n-          version: \"19.2.0-canary-fa3feba6-20250623\",\n+          version: \"19.2.0-canary-cee7939b-20250625\",\n           rendererPackageName: \"react-dom\",\n           currentDispatcherRef: ReactSharedInternals,\n-          reconcilerVersion: \"19.2.0-canary-fa3feba6-20250623\"\n+          reconcilerVersion: \"19.2.0-canary-cee7939b-20250625\"\n         };\n         internals.overrideHookState = overrideHookState;\n         internals.overrideHookStateDeletePath = overrideHookStateDeletePath;\n@@ -25669,7 +25683,7 @@\n       listenToAllSupportedEvents(container);\n       return new ReactDOMHydrationRoot(initialChildren);\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "0cfb9269318d08a3978699b5504b859426876a29",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-client.production.js",
            "status": "modified",
            "additions": 37,
            "deletions": 37,
            "changes": 74,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-client.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2044,19 +2044,19 @@ function getTargetInstForChangeEvent(domEventName, targetInst) {\n }\n var isInputEventSupported = !1;\n if (canUseDOM) {\n-  var JSCompiler_inline_result$jscomp$294;\n+  var JSCompiler_inline_result$jscomp$295;\n   if (canUseDOM) {\n-    var isSupported$jscomp$inline_434 = \"oninput\" in document;\n-    if (!isSupported$jscomp$inline_434) {\n-      var element$jscomp$inline_435 = document.createElement(\"div\");\n-      element$jscomp$inline_435.setAttribute(\"oninput\", \"return;\");\n-      isSupported$jscomp$inline_434 =\n-        \"function\" === typeof element$jscomp$inline_435.oninput;\n+    var isSupported$jscomp$inline_440 = \"oninput\" in document;\n+    if (!isSupported$jscomp$inline_440) {\n+      var element$jscomp$inline_441 = document.createElement(\"div\");\n+      element$jscomp$inline_441.setAttribute(\"oninput\", \"return;\");\n+      isSupported$jscomp$inline_440 =\n+        \"function\" === typeof element$jscomp$inline_441.oninput;\n     }\n-    JSCompiler_inline_result$jscomp$294 = isSupported$jscomp$inline_434;\n-  } else JSCompiler_inline_result$jscomp$294 = !1;\n+    JSCompiler_inline_result$jscomp$295 = isSupported$jscomp$inline_440;\n+  } else JSCompiler_inline_result$jscomp$295 = !1;\n   isInputEventSupported =\n-    JSCompiler_inline_result$jscomp$294 &&\n+    JSCompiler_inline_result$jscomp$295 &&\n     (!document.documentMode || 9 < document.documentMode);\n }\n function stopWatchingForValueChange() {\n@@ -12082,20 +12082,20 @@ function extractEvents$1(\n   }\n }\n for (\n-  var i$jscomp$inline_1591 = 0;\n-  i$jscomp$inline_1591 < simpleEventPluginEvents.length;\n-  i$jscomp$inline_1591++\n+  var i$jscomp$inline_1597 = 0;\n+  i$jscomp$inline_1597 < simpleEventPluginEvents.length;\n+  i$jscomp$inline_1597++\n ) {\n-  var eventName$jscomp$inline_1592 =\n-      simpleEventPluginEvents[i$jscomp$inline_1591],\n-    domEventName$jscomp$inline_1593 =\n-      eventName$jscomp$inline_1592.toLowerCase(),\n-    capitalizedEvent$jscomp$inline_1594 =\n-      eventName$jscomp$inline_1592[0].toUpperCase() +\n-      eventName$jscomp$inline_1592.slice(1);\n+  var eventName$jscomp$inline_1598 =\n+      simpleEventPluginEvents[i$jscomp$inline_1597],\n+    domEventName$jscomp$inline_1599 =\n+      eventName$jscomp$inline_1598.toLowerCase(),\n+    capitalizedEvent$jscomp$inline_1600 =\n+      eventName$jscomp$inline_1598[0].toUpperCase() +\n+      eventName$jscomp$inline_1598.slice(1);\n   registerSimpleEvent(\n-    domEventName$jscomp$inline_1593,\n-    \"on\" + capitalizedEvent$jscomp$inline_1594\n+    domEventName$jscomp$inline_1599,\n+    \"on\" + capitalizedEvent$jscomp$inline_1600\n   );\n }\n registerSimpleEvent(ANIMATION_END, \"onAnimationEnd\");\n@@ -15711,16 +15711,16 @@ ReactDOMHydrationRoot.prototype.unstable_scheduleHydration = function (target) {\n     0 === i && attemptExplicitHydrationTarget(target);\n   }\n };\n-var isomorphicReactPackageVersion$jscomp$inline_1851 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_1857 = React.version;\n if (\n-  \"19.2.0-canary-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_1851\n+  \"19.2.0-canary-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_1857\n )\n   throw Error(\n     formatProdErrorMessage(\n       527,\n-      isomorphicReactPackageVersion$jscomp$inline_1851,\n-      \"19.2.0-canary-fa3feba6-20250623\"\n+      isomorphicReactPackageVersion$jscomp$inline_1857,\n+      \"19.2.0-canary-cee7939b-20250625\"\n     )\n   );\n ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n@@ -15740,24 +15740,24 @@ ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n     null === componentOrElement ? null : componentOrElement.stateNode;\n   return componentOrElement;\n };\n-var internals$jscomp$inline_2344 = {\n+var internals$jscomp$inline_2350 = {\n   bundleType: 0,\n-  version: \"19.2.0-canary-fa3feba6-20250623\",\n+  version: \"19.2.0-canary-cee7939b-20250625\",\n   rendererPackageName: \"react-dom\",\n   currentDispatcherRef: ReactSharedInternals,\n-  reconcilerVersion: \"19.2.0-canary-fa3feba6-20250623\"\n+  reconcilerVersion: \"19.2.0-canary-cee7939b-20250625\"\n };\n if (\"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__) {\n-  var hook$jscomp$inline_2345 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n+  var hook$jscomp$inline_2351 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n   if (\n-    !hook$jscomp$inline_2345.isDisabled &&\n-    hook$jscomp$inline_2345.supportsFiber\n+    !hook$jscomp$inline_2351.isDisabled &&\n+    hook$jscomp$inline_2351.supportsFiber\n   )\n     try {\n-      (rendererID = hook$jscomp$inline_2345.inject(\n-        internals$jscomp$inline_2344\n+      (rendererID = hook$jscomp$inline_2351.inject(\n+        internals$jscomp$inline_2350\n       )),\n-        (injectedHook = hook$jscomp$inline_2345);\n+        (injectedHook = hook$jscomp$inline_2351);\n     } catch (err) {}\n }\n exports.createRoot = function (container, options) {\n@@ -15843,4 +15843,4 @@ exports.hydrateRoot = function (container, initialChildren, options) {\n   listenToAllSupportedEvents(container);\n   return new ReactDOMHydrationRoot(initialChildren);\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "43b0b2dd6dd72d1709c938a4e900b7442d68c61a",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-profiling.development.js",
            "status": "modified",
            "additions": 142,
            "deletions": 128,
            "changes": 270,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -540,6 +540,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -712,27 +733,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeFiber(fiber) {\n       switch (fiber.tag) {\n         case 26:\n@@ -768,11 +768,25 @@\n             for (var i = debugInfo.length - 1; 0 <= i; i--) {\n               var entry = debugInfo[i];\n               if (\"string\" === typeof entry.name) {\n-                var JSCompiler_temp_const = info,\n-                  env = entry.env;\n-                var JSCompiler_inline_result = describeBuiltInComponentFrame(\n-                  entry.name + (env ? \" [\" + env + \"]\" : \"\")\n-                );\n+                var JSCompiler_temp_const = info;\n+                a: {\n+                  var name = entry.name,\n+                    env = entry.env,\n+                    location = entry.debugLocation;\n+                  if (null != location) {\n+                    var childStack = formatOwnerStack(location),\n+                      idx = childStack.lastIndexOf(\"\\n\"),\n+                      lastLine =\n+                        -1 === idx ? childStack : childStack.slice(idx + 1);\n+                    if (-1 !== lastLine.indexOf(name)) {\n+                      var JSCompiler_inline_result = \"\\n\" + lastLine;\n+                      break a;\n+                    }\n+                  }\n+                  JSCompiler_inline_result = describeBuiltInComponentFrame(\n+                    name + (env ? \" [\" + env + \"]\" : \"\")\n+                  );\n+                }\n                 info = JSCompiler_temp_const + JSCompiler_inline_result;\n               }\n             }\n@@ -9708,24 +9722,24 @@\n       return current;\n     }\n     function updateSuspenseComponent(current, workInProgress, renderLanes) {\n-      var JSCompiler_object_inline_digest_2555;\n-      var JSCompiler_object_inline_stack_2556 = workInProgress.pendingProps;\n+      var JSCompiler_object_inline_digest_2559;\n+      var JSCompiler_object_inline_stack_2560 = workInProgress.pendingProps;\n       shouldSuspendImpl(workInProgress) && (workInProgress.flags |= 128);\n-      var JSCompiler_object_inline_message_2554 = !1;\n+      var JSCompiler_object_inline_message_2558 = !1;\n       var didSuspend = 0 !== (workInProgress.flags & 128);\n-      (JSCompiler_object_inline_digest_2555 = didSuspend) ||\n-        (JSCompiler_object_inline_digest_2555 =\n+      (JSCompiler_object_inline_digest_2559 = didSuspend) ||\n+        (JSCompiler_object_inline_digest_2559 =\n           null !== current && null === current.memoizedState\n             ? !1\n             : 0 !== (suspenseStackCursor.current & ForceSuspenseFallback));\n-      JSCompiler_object_inline_digest_2555 &&\n-        ((JSCompiler_object_inline_message_2554 = !0),\n+      JSCompiler_object_inline_digest_2559 &&\n+        ((JSCompiler_object_inline_message_2558 = !0),\n         (workInProgress.flags &= -129));\n-      JSCompiler_object_inline_digest_2555 = 0 !== (workInProgress.flags & 32);\n+      JSCompiler_object_inline_digest_2559 = 0 !== (workInProgress.flags & 32);\n       workInProgress.flags &= -33;\n       if (null === current) {\n         if (isHydrating) {\n-          JSCompiler_object_inline_message_2554\n+          JSCompiler_object_inline_message_2558\n             ? pushPrimaryTreeSuspenseHandler(workInProgress)\n             : reuseSuspenseHandlerOnStack(workInProgress);\n           (current = nextHydratableInstance)\n@@ -9738,18 +9752,18 @@\n                   ? renderLanes\n                   : null),\n               null !== renderLanes &&\n-                ((JSCompiler_object_inline_digest_2555 = {\n+                ((JSCompiler_object_inline_digest_2559 = {\n                   dehydrated: renderLanes,\n                   treeContext: getSuspendedTreeContext(),\n                   retryLane: 536870912,\n                   hydrationErrors: null\n                 }),\n                 (workInProgress.memoizedState =\n-                  JSCompiler_object_inline_digest_2555),\n-                (JSCompiler_object_inline_digest_2555 =\n+                  JSCompiler_object_inline_digest_2559),\n+                (JSCompiler_object_inline_digest_2559 =\n                   createFiberFromDehydratedFragment(renderLanes)),\n-                (JSCompiler_object_inline_digest_2555.return = workInProgress),\n-                (workInProgress.child = JSCompiler_object_inline_digest_2555),\n+                (JSCompiler_object_inline_digest_2559.return = workInProgress),\n+                (workInProgress.child = JSCompiler_object_inline_digest_2559),\n                 (hydrationParentFiber = workInProgress),\n                 (nextHydratableInstance = null)))\n             : (renderLanes = null);\n@@ -9763,36 +9777,36 @@\n             : (workInProgress.lanes = 536870912);\n           return null;\n         }\n-        var nextPrimaryChildren = JSCompiler_object_inline_stack_2556.children;\n-        JSCompiler_object_inline_stack_2556 =\n-          JSCompiler_object_inline_stack_2556.fallback;\n-        if (JSCompiler_object_inline_message_2554) {\n+        var nextPrimaryChildren = JSCompiler_object_inline_stack_2560.children;\n+        JSCompiler_object_inline_stack_2560 =\n+          JSCompiler_object_inline_stack_2560.fallback;\n+        if (JSCompiler_object_inline_message_2558) {\n           reuseSuspenseHandlerOnStack(workInProgress);\n           var mode = workInProgress.mode;\n           nextPrimaryChildren = mountWorkInProgressOffscreenFiber(\n             { mode: \"hidden\", children: nextPrimaryChildren },\n             mode\n           );\n-          JSCompiler_object_inline_stack_2556 = createFiberFromFragment(\n-            JSCompiler_object_inline_stack_2556,\n+          JSCompiler_object_inline_stack_2560 = createFiberFromFragment(\n+            JSCompiler_object_inline_stack_2560,\n             mode,\n             renderLanes,\n             null\n           );\n           nextPrimaryChildren.return = workInProgress;\n-          JSCompiler_object_inline_stack_2556.return = workInProgress;\n-          nextPrimaryChildren.sibling = JSCompiler_object_inline_stack_2556;\n+          JSCompiler_object_inline_stack_2560.return = workInProgress;\n+          nextPrimaryChildren.sibling = JSCompiler_object_inline_stack_2560;\n           workInProgress.child = nextPrimaryChildren;\n           nextPrimaryChildren = workInProgress.child;\n           nextPrimaryChildren.memoizedState =\n             mountSuspenseOffscreenState(renderLanes);\n           nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_digest_2555,\n+            JSCompiler_object_inline_digest_2559,\n             renderLanes\n           );\n           workInProgress.memoizedState = SUSPENDED_MARKER;\n-          return JSCompiler_object_inline_stack_2556;\n+          return JSCompiler_object_inline_stack_2560;\n         }\n         pushPrimaryTreeSuspenseHandler(workInProgress);\n         return mountSuspensePrimaryChildren(\n@@ -9802,8 +9816,8 @@\n       }\n       var prevState = current.memoizedState;\n       if (null !== prevState) {\n-        var JSCompiler_object_inline_componentStack_2557 = prevState.dehydrated;\n-        if (null !== JSCompiler_object_inline_componentStack_2557) {\n+        var JSCompiler_object_inline_componentStack_2561 = prevState.dehydrated;\n+        if (null !== JSCompiler_object_inline_componentStack_2561) {\n           if (didSuspend)\n             workInProgress.flags & 256\n               ? (pushPrimaryTreeSuspenseHandler(workInProgress),\n@@ -9820,13 +9834,13 @@\n                   (workInProgress = null))\n                 : (reuseSuspenseHandlerOnStack(workInProgress),\n                   (nextPrimaryChildren =\n-                    JSCompiler_object_inline_stack_2556.fallback),\n+                    JSCompiler_object_inline_stack_2560.fallback),\n                   (mode = workInProgress.mode),\n-                  (JSCompiler_object_inline_stack_2556 =\n+                  (JSCompiler_object_inline_stack_2560 =\n                     mountWorkInProgressOffscreenFiber(\n                       {\n                         mode: \"visible\",\n-                        children: JSCompiler_object_inline_stack_2556.children\n+                        children: JSCompiler_object_inline_stack_2560.children\n                       },\n                       mode\n                     )),\n@@ -9837,24 +9851,24 @@\n                     null\n                   )),\n                   (nextPrimaryChildren.flags |= 2),\n-                  (JSCompiler_object_inline_stack_2556.return = workInProgress),\n+                  (JSCompiler_object_inline_stack_2560.return = workInProgress),\n                   (nextPrimaryChildren.return = workInProgress),\n-                  (JSCompiler_object_inline_stack_2556.sibling =\n+                  (JSCompiler_object_inline_stack_2560.sibling =\n                     nextPrimaryChildren),\n-                  (workInProgress.child = JSCompiler_object_inline_stack_2556),\n+                  (workInProgress.child = JSCompiler_object_inline_stack_2560),\n                   reconcileChildFibers(\n                     workInProgress,\n                     current.child,\n                     null,\n                     renderLanes\n                   ),\n-                  (JSCompiler_object_inline_stack_2556 = workInProgress.child),\n-                  (JSCompiler_object_inline_stack_2556.memoizedState =\n+                  (JSCompiler_object_inline_stack_2560 = workInProgress.child),\n+                  (JSCompiler_object_inline_stack_2560.memoizedState =\n                     mountSuspenseOffscreenState(renderLanes)),\n-                  (JSCompiler_object_inline_stack_2556.childLanes =\n+                  (JSCompiler_object_inline_stack_2560.childLanes =\n                     getRemainingWorkInPrimaryTree(\n                       current,\n-                      JSCompiler_object_inline_digest_2555,\n+                      JSCompiler_object_inline_digest_2559,\n                       renderLanes\n                     )),\n                   (workInProgress.memoizedState = SUSPENDED_MARKER),\n@@ -9863,45 +9877,45 @@\n             (pushPrimaryTreeSuspenseHandler(workInProgress),\n             warnIfHydrating(),\n             isSuspenseInstanceFallback(\n-              JSCompiler_object_inline_componentStack_2557\n+              JSCompiler_object_inline_componentStack_2561\n             ))\n           ) {\n-            JSCompiler_object_inline_digest_2555 =\n-              JSCompiler_object_inline_componentStack_2557.nextSibling &&\n-              JSCompiler_object_inline_componentStack_2557.nextSibling.dataset;\n-            if (JSCompiler_object_inline_digest_2555) {\n-              nextPrimaryChildren = JSCompiler_object_inline_digest_2555.dgst;\n-              var message = JSCompiler_object_inline_digest_2555.msg;\n-              mode = JSCompiler_object_inline_digest_2555.stck;\n-              var componentStack = JSCompiler_object_inline_digest_2555.cstck;\n+            JSCompiler_object_inline_digest_2559 =\n+              JSCompiler_object_inline_componentStack_2561.nextSibling &&\n+              JSCompiler_object_inline_componentStack_2561.nextSibling.dataset;\n+            if (JSCompiler_object_inline_digest_2559) {\n+              nextPrimaryChildren = JSCompiler_object_inline_digest_2559.dgst;\n+              var message = JSCompiler_object_inline_digest_2559.msg;\n+              mode = JSCompiler_object_inline_digest_2559.stck;\n+              var componentStack = JSCompiler_object_inline_digest_2559.cstck;\n             }\n-            JSCompiler_object_inline_message_2554 = message;\n-            JSCompiler_object_inline_digest_2555 = nextPrimaryChildren;\n-            JSCompiler_object_inline_stack_2556 = mode;\n-            JSCompiler_object_inline_componentStack_2557 = componentStack;\n-            nextPrimaryChildren = JSCompiler_object_inline_message_2554;\n-            mode = JSCompiler_object_inline_componentStack_2557;\n+            JSCompiler_object_inline_message_2558 = message;\n+            JSCompiler_object_inline_digest_2559 = nextPrimaryChildren;\n+            JSCompiler_object_inline_stack_2560 = mode;\n+            JSCompiler_object_inline_componentStack_2561 = componentStack;\n+            nextPrimaryChildren = JSCompiler_object_inline_message_2558;\n+            mode = JSCompiler_object_inline_componentStack_2561;\n             nextPrimaryChildren = nextPrimaryChildren\n               ? Error(nextPrimaryChildren)\n               : Error(\n                   \"The server could not finish this Suspense boundary, likely due to an error during server rendering. Switched to client rendering.\"\n                 );\n             nextPrimaryChildren.stack =\n-              JSCompiler_object_inline_stack_2556 || \"\";\n-            nextPrimaryChildren.digest = JSCompiler_object_inline_digest_2555;\n-            JSCompiler_object_inline_digest_2555 =\n+              JSCompiler_object_inline_stack_2560 || \"\";\n+            nextPrimaryChildren.digest = JSCompiler_object_inline_digest_2559;\n+            JSCompiler_object_inline_digest_2559 =\n               void 0 === mode ? null : mode;\n-            JSCompiler_object_inline_stack_2556 = {\n+            JSCompiler_object_inline_stack_2560 = {\n               value: nextPrimaryChildren,\n               source: null,\n-              stack: JSCompiler_object_inline_digest_2555\n+              stack: JSCompiler_object_inline_digest_2559\n             };\n-            \"string\" === typeof JSCompiler_object_inline_digest_2555 &&\n+            \"string\" === typeof JSCompiler_object_inline_digest_2559 &&\n               CapturedStacks.set(\n                 nextPrimaryChildren,\n-                JSCompiler_object_inline_stack_2556\n+                JSCompiler_object_inline_stack_2560\n               );\n-            queueHydrationError(JSCompiler_object_inline_stack_2556);\n+            queueHydrationError(JSCompiler_object_inline_stack_2560);\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n               workInProgress,\n@@ -9915,35 +9929,35 @@\n                 renderLanes,\n                 !1\n               ),\n-            (JSCompiler_object_inline_digest_2555 =\n+            (JSCompiler_object_inline_digest_2559 =\n               0 !== (renderLanes & current.childLanes)),\n-            didReceiveUpdate || JSCompiler_object_inline_digest_2555)\n+            didReceiveUpdate || JSCompiler_object_inline_digest_2559)\n           ) {\n-            JSCompiler_object_inline_digest_2555 = workInProgressRoot;\n+            JSCompiler_object_inline_digest_2559 = workInProgressRoot;\n             if (\n-              null !== JSCompiler_object_inline_digest_2555 &&\n-              ((JSCompiler_object_inline_stack_2556 = getBumpedLaneForHydration(\n-                JSCompiler_object_inline_digest_2555,\n+              null !== JSCompiler_object_inline_digest_2559 &&\n+              ((JSCompiler_object_inline_stack_2560 = getBumpedLaneForHydration(\n+                JSCompiler_object_inline_digest_2559,\n                 renderLanes\n               )),\n-              0 !== JSCompiler_object_inline_stack_2556 &&\n-                JSCompiler_object_inline_stack_2556 !== prevState.retryLane)\n+              0 !== JSCompiler_object_inline_stack_2560 &&\n+                JSCompiler_object_inline_stack_2560 !== prevState.retryLane)\n             )\n               throw (\n-                ((prevState.retryLane = JSCompiler_object_inline_stack_2556),\n+                ((prevState.retryLane = JSCompiler_object_inline_stack_2560),\n                 enqueueConcurrentRenderForLane(\n                   current,\n-                  JSCompiler_object_inline_stack_2556\n+                  JSCompiler_object_inline_stack_2560\n                 ),\n                 scheduleUpdateOnFiber(\n-                  JSCompiler_object_inline_digest_2555,\n+                  JSCompiler_object_inline_digest_2559,\n                   current,\n-                  JSCompiler_object_inline_stack_2556\n+                  JSCompiler_object_inline_stack_2560\n                 ),\n                 SelectiveHydrationException)\n               );\n             isSuspenseInstancePending(\n-              JSCompiler_object_inline_componentStack_2557\n+              JSCompiler_object_inline_componentStack_2561\n             ) || renderDidSuspendDelayIfPossible();\n             workInProgress = retrySuspenseComponentWithoutHydrating(\n               current,\n@@ -9952,14 +9966,14 @@\n             );\n           } else\n             isSuspenseInstancePending(\n-              JSCompiler_object_inline_componentStack_2557\n+              JSCompiler_object_inline_componentStack_2561\n             )\n               ? ((workInProgress.flags |= 192),\n                 (workInProgress.child = current.child),\n                 (workInProgress = null))\n               : ((current = prevState.treeContext),\n                 (nextHydratableInstance = getNextHydratable(\n-                  JSCompiler_object_inline_componentStack_2557.nextSibling\n+                  JSCompiler_object_inline_componentStack_2561.nextSibling\n                 )),\n                 (hydrationParentFiber = workInProgress),\n                 (isHydrating = !0),\n@@ -9971,32 +9985,32 @@\n                   restoreSuspendedTreeContext(workInProgress, current),\n                 (workInProgress = mountSuspensePrimaryChildren(\n                   workInProgress,\n-                  JSCompiler_object_inline_stack_2556.children\n+                  JSCompiler_object_inline_stack_2560.children\n                 )),\n                 (workInProgress.flags |= 4096));\n           return workInProgress;\n         }\n       }\n-      if (JSCompiler_object_inline_message_2554)\n+      if (JSCompiler_object_inline_message_2558)\n         return (\n           reuseSuspenseHandlerOnStack(workInProgress),\n-          (nextPrimaryChildren = JSCompiler_object_inline_stack_2556.fallback),\n+          (nextPrimaryChildren = JSCompiler_object_inline_stack_2560.fallback),\n           (mode = workInProgress.mode),\n           (componentStack = current.child),\n-          (JSCompiler_object_inline_componentStack_2557 =\n+          (JSCompiler_object_inline_componentStack_2561 =\n             componentStack.sibling),\n-          (JSCompiler_object_inline_stack_2556 = createWorkInProgress(\n+          (JSCompiler_object_inline_stack_2560 = createWorkInProgress(\n             componentStack,\n             {\n               mode: \"hidden\",\n-              children: JSCompiler_object_inline_stack_2556.children\n+              children: JSCompiler_object_inline_stack_2560.children\n             }\n           )),\n-          (JSCompiler_object_inline_stack_2556.subtreeFlags =\n+          (JSCompiler_object_inline_stack_2560.subtreeFlags =\n             componentStack.subtreeFlags & 65011712),\n-          null !== JSCompiler_object_inline_componentStack_2557\n+          null !== JSCompiler_object_inline_componentStack_2561\n             ? (nextPrimaryChildren = createWorkInProgress(\n-                JSCompiler_object_inline_componentStack_2557,\n+                JSCompiler_object_inline_componentStack_2561,\n                 nextPrimaryChildren\n               ))\n             : ((nextPrimaryChildren = createFiberFromFragment(\n@@ -10007,24 +10021,24 @@\n               )),\n               (nextPrimaryChildren.flags |= 2)),\n           (nextPrimaryChildren.return = workInProgress),\n-          (JSCompiler_object_inline_stack_2556.return = workInProgress),\n-          (JSCompiler_object_inline_stack_2556.sibling = nextPrimaryChildren),\n-          (workInProgress.child = JSCompiler_object_inline_stack_2556),\n-          (JSCompiler_object_inline_stack_2556 = nextPrimaryChildren),\n+          (JSCompiler_object_inline_stack_2560.return = workInProgress),\n+          (JSCompiler_object_inline_stack_2560.sibling = nextPrimaryChildren),\n+          (workInProgress.child = JSCompiler_object_inline_stack_2560),\n+          (JSCompiler_object_inline_stack_2560 = nextPrimaryChildren),\n           (nextPrimaryChildren = workInProgress.child),\n           (mode = current.child.memoizedState),\n           null === mode\n             ? (mode = mountSuspenseOffscreenState(renderLanes))\n             : ((componentStack = mode.cachePool),\n               null !== componentStack\n-                ? ((JSCompiler_object_inline_componentStack_2557 =\n+                ? ((JSCompiler_object_inline_componentStack_2561 =\n                     CacheContext._currentValue),\n                   (componentStack =\n                     componentStack.parent !==\n-                    JSCompiler_object_inline_componentStack_2557\n+                    JSCompiler_object_inline_componentStack_2561\n                       ? {\n-                          parent: JSCompiler_object_inline_componentStack_2557,\n-                          pool: JSCompiler_object_inline_componentStack_2557\n+                          parent: JSCompiler_object_inline_componentStack_2561,\n+                          pool: JSCompiler_object_inline_componentStack_2561\n                         }\n                       : componentStack))\n                 : (componentStack = getSuspendedCache()),\n@@ -10035,27 +10049,27 @@\n           (nextPrimaryChildren.memoizedState = mode),\n           (nextPrimaryChildren.childLanes = getRemainingWorkInPrimaryTree(\n             current,\n-            JSCompiler_object_inline_digest_2555,\n+            JSCompiler_object_inline_digest_2559,\n             renderLanes\n           )),\n           (workInProgress.memoizedState = SUSPENDED_MARKER),\n-          JSCompiler_object_inline_stack_2556\n+          JSCompiler_object_inline_stack_2560\n         );\n       pushPrimaryTreeSuspenseHandler(workInProgress);\n       renderLanes = current.child;\n       current = renderLanes.sibling;\n       renderLanes = createWorkInProgress(renderLanes, {\n         mode: \"visible\",\n-        children: JSCompiler_object_inline_stack_2556.children\n+        children: JSCompiler_object_inline_stack_2560.children\n       });\n       renderLanes.return = workInProgress;\n       renderLanes.sibling = null;\n       null !== current &&\n-        ((JSCompiler_object_inline_digest_2555 = workInProgress.deletions),\n-        null === JSCompiler_object_inline_digest_2555\n+        ((JSCompiler_object_inline_digest_2559 = workInProgress.deletions),\n+        null === JSCompiler_object_inline_digest_2559\n           ? ((workInProgress.deletions = [current]),\n             (workInProgress.flags |= 16))\n-          : JSCompiler_object_inline_digest_2555.push(current));\n+          : JSCompiler_object_inline_digest_2559.push(current));\n       workInProgress.child = renderLanes;\n       workInProgress.memoizedState = null;\n       return renderLanes;\n@@ -25539,11 +25553,11 @@\n     };\n     (function () {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     })();\n     (\"function\" === typeof Map &&\n@@ -25580,10 +25594,10 @@\n       !(function () {\n         var internals = {\n           bundleType: 1,\n-          version: \"19.2.0-canary-fa3feba6-20250623\",\n+          version: \"19.2.0-canary-cee7939b-20250625\",\n           rendererPackageName: \"react-dom\",\n           currentDispatcherRef: ReactSharedInternals,\n-          reconcilerVersion: \"19.2.0-canary-fa3feba6-20250623\"\n+          reconcilerVersion: \"19.2.0-canary-cee7939b-20250625\"\n         };\n         internals.overrideHookState = overrideHookState;\n         internals.overrideHookStateDeletePath = overrideHookStateDeletePath;\n@@ -26051,7 +26065,7 @@\n     exports.useFormStatus = function () {\n       return resolveDispatcher().useHostTransitionStatus();\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "df9d1c31f61c1ee3405d79b94dbe4a3fc5b1225c",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-profiling.profiling.js",
            "status": "modified",
            "additions": 37,
            "deletions": 37,
            "changes": 74,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.profiling.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.profiling.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-profiling.profiling.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2126,19 +2126,19 @@ function getTargetInstForChangeEvent(domEventName, targetInst) {\n }\n var isInputEventSupported = !1;\n if (canUseDOM) {\n-  var JSCompiler_inline_result$jscomp$312;\n+  var JSCompiler_inline_result$jscomp$313;\n   if (canUseDOM) {\n-    var isSupported$jscomp$inline_453 = \"oninput\" in document;\n-    if (!isSupported$jscomp$inline_453) {\n-      var element$jscomp$inline_454 = document.createElement(\"div\");\n-      element$jscomp$inline_454.setAttribute(\"oninput\", \"return;\");\n-      isSupported$jscomp$inline_453 =\n-        \"function\" === typeof element$jscomp$inline_454.oninput;\n+    var isSupported$jscomp$inline_459 = \"oninput\" in document;\n+    if (!isSupported$jscomp$inline_459) {\n+      var element$jscomp$inline_460 = document.createElement(\"div\");\n+      element$jscomp$inline_460.setAttribute(\"oninput\", \"return;\");\n+      isSupported$jscomp$inline_459 =\n+        \"function\" === typeof element$jscomp$inline_460.oninput;\n     }\n-    JSCompiler_inline_result$jscomp$312 = isSupported$jscomp$inline_453;\n-  } else JSCompiler_inline_result$jscomp$312 = !1;\n+    JSCompiler_inline_result$jscomp$313 = isSupported$jscomp$inline_459;\n+  } else JSCompiler_inline_result$jscomp$313 = !1;\n   isInputEventSupported =\n-    JSCompiler_inline_result$jscomp$312 &&\n+    JSCompiler_inline_result$jscomp$313 &&\n     (!document.documentMode || 9 < document.documentMode);\n }\n function stopWatchingForValueChange() {\n@@ -12764,20 +12764,20 @@ function extractEvents$1(\n   }\n }\n for (\n-  var i$jscomp$inline_1693 = 0;\n-  i$jscomp$inline_1693 < simpleEventPluginEvents.length;\n-  i$jscomp$inline_1693++\n+  var i$jscomp$inline_1699 = 0;\n+  i$jscomp$inline_1699 < simpleEventPluginEvents.length;\n+  i$jscomp$inline_1699++\n ) {\n-  var eventName$jscomp$inline_1694 =\n-      simpleEventPluginEvents[i$jscomp$inline_1693],\n-    domEventName$jscomp$inline_1695 =\n-      eventName$jscomp$inline_1694.toLowerCase(),\n-    capitalizedEvent$jscomp$inline_1696 =\n-      eventName$jscomp$inline_1694[0].toUpperCase() +\n-      eventName$jscomp$inline_1694.slice(1);\n+  var eventName$jscomp$inline_1700 =\n+      simpleEventPluginEvents[i$jscomp$inline_1699],\n+    domEventName$jscomp$inline_1701 =\n+      eventName$jscomp$inline_1700.toLowerCase(),\n+    capitalizedEvent$jscomp$inline_1702 =\n+      eventName$jscomp$inline_1700[0].toUpperCase() +\n+      eventName$jscomp$inline_1700.slice(1);\n   registerSimpleEvent(\n-    domEventName$jscomp$inline_1695,\n-    \"on\" + capitalizedEvent$jscomp$inline_1696\n+    domEventName$jscomp$inline_1701,\n+    \"on\" + capitalizedEvent$jscomp$inline_1702\n   );\n }\n registerSimpleEvent(ANIMATION_END, \"onAnimationEnd\");\n@@ -16412,16 +16412,16 @@ ReactDOMHydrationRoot.prototype.unstable_scheduleHydration = function (target) {\n     0 === i && attemptExplicitHydrationTarget(target);\n   }\n };\n-var isomorphicReactPackageVersion$jscomp$inline_1955 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_1961 = React.version;\n if (\n-  \"19.2.0-canary-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_1955\n+  \"19.2.0-canary-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_1961\n )\n   throw Error(\n     formatProdErrorMessage(\n       527,\n-      isomorphicReactPackageVersion$jscomp$inline_1955,\n-      \"19.2.0-canary-fa3feba6-20250623\"\n+      isomorphicReactPackageVersion$jscomp$inline_1961,\n+      \"19.2.0-canary-cee7939b-20250625\"\n     )\n   );\n ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n@@ -16441,12 +16441,12 @@ ReactDOMSharedInternals.findDOMNode = function (componentOrElement) {\n     null === componentOrElement ? null : componentOrElement.stateNode;\n   return componentOrElement;\n };\n-var internals$jscomp$inline_1962 = {\n+var internals$jscomp$inline_1968 = {\n   bundleType: 0,\n-  version: \"19.2.0-canary-fa3feba6-20250623\",\n+  version: \"19.2.0-canary-cee7939b-20250625\",\n   rendererPackageName: \"react-dom\",\n   currentDispatcherRef: ReactSharedInternals,\n-  reconcilerVersion: \"19.2.0-canary-fa3feba6-20250623\",\n+  reconcilerVersion: \"19.2.0-canary-cee7939b-20250625\",\n   getLaneLabelMap: function () {\n     for (\n       var map = new Map(), lane = 1, index$293 = 0;\n@@ -16464,16 +16464,16 @@ var internals$jscomp$inline_1962 = {\n   }\n };\n if (\"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__) {\n-  var hook$jscomp$inline_2416 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n+  var hook$jscomp$inline_2422 = __REACT_DEVTOOLS_GLOBAL_HOOK__;\n   if (\n-    !hook$jscomp$inline_2416.isDisabled &&\n-    hook$jscomp$inline_2416.supportsFiber\n+    !hook$jscomp$inline_2422.isDisabled &&\n+    hook$jscomp$inline_2422.supportsFiber\n   )\n     try {\n-      (rendererID = hook$jscomp$inline_2416.inject(\n-        internals$jscomp$inline_1962\n+      (rendererID = hook$jscomp$inline_2422.inject(\n+        internals$jscomp$inline_1968\n       )),\n-        (injectedHook = hook$jscomp$inline_2416);\n+        (injectedHook = hook$jscomp$inline_2422);\n     } catch (err) {}\n }\n function getCrossOriginStringAs(as, input) {\n@@ -16719,7 +16719,7 @@ exports.useFormState = function (action, initialState, permalink) {\n exports.useFormStatus = function () {\n   return ReactSharedInternals.H.useHostTransitionStatus();\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";\n \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n   \"function\" ===\n     typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "624d72544abe0904d147231cae74f07e01c18c0f",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server-legacy.browser.development.js",
            "status": "modified",
            "additions": 50,
            "deletions": 32,
            "changes": 82,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4108,6 +4108,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4280,27 +4301,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4324,13 +4324,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -6866,8 +6879,8 @@\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n           if (null === boundary) {\n-            logRecoverableError(request, error, segment, null);\n-            fatalError(request, error, segment, null);\n+            logRecoverableError(request, error, segment, task.debugTask);\n+            fatalError(request, error, segment, task.debugTask);\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -6895,7 +6908,12 @@\n       } else\n         boundary.status !== CLIENT_RENDERED &&\n           ((boundary.status = CLIENT_RENDERED),\n-          (errorDigest = logRecoverableError(request, error, segment, null)),\n+          (errorDigest = logRecoverableError(\n+            request,\n+            error,\n+            segment,\n+            task.debugTask\n+          )),\n           (boundary.status = CLIENT_RENDERED),\n           encodeErrorForBoundary(boundary, errorDigest, error, segment, !0),\n           untrackBoundary(request, boundary),\n@@ -9665,5 +9683,5 @@\n         'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToReadableStream\" which supports Suspense on the server'\n       );\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "dcc5f7c33798cdf1878298a3466b5f0568fe57d2",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server-legacy.browser.production.js",
            "status": "modified",
            "additions": 52,
            "deletions": 28,
            "changes": 80,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2724,16 +2724,16 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       \"\\x3c/script>\"\n     ));\n   bootstrapScriptContent = idPrefix + \"P:\";\n-  var JSCompiler_object_inline_segmentPrefix_1667 = idPrefix + \"S:\";\n+  var JSCompiler_object_inline_segmentPrefix_1677 = idPrefix + \"S:\";\n   idPrefix += \"B:\";\n-  var JSCompiler_object_inline_preconnects_1681 = new Set(),\n-    JSCompiler_object_inline_fontPreloads_1682 = new Set(),\n-    JSCompiler_object_inline_highImagePreloads_1683 = new Set(),\n-    JSCompiler_object_inline_styles_1684 = new Map(),\n-    JSCompiler_object_inline_bootstrapScripts_1685 = new Set(),\n-    JSCompiler_object_inline_scripts_1686 = new Set(),\n-    JSCompiler_object_inline_bulkPreloads_1687 = new Set(),\n-    JSCompiler_object_inline_preloads_1688 = {\n+  var JSCompiler_object_inline_preconnects_1691 = new Set(),\n+    JSCompiler_object_inline_fontPreloads_1692 = new Set(),\n+    JSCompiler_object_inline_highImagePreloads_1693 = new Set(),\n+    JSCompiler_object_inline_styles_1694 = new Map(),\n+    JSCompiler_object_inline_bootstrapScripts_1695 = new Set(),\n+    JSCompiler_object_inline_scripts_1696 = new Set(),\n+    JSCompiler_object_inline_bulkPreloads_1697 = new Set(),\n+    JSCompiler_object_inline_preloads_1698 = {\n       images: new Map(),\n       stylesheets: new Map(),\n       scripts: new Map(),\n@@ -2770,7 +2770,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       scriptConfig.moduleScriptResources[href] = null;\n       scriptConfig = [];\n       pushLinkImpl(scriptConfig, props);\n-      JSCompiler_object_inline_bootstrapScripts_1685.add(scriptConfig);\n+      JSCompiler_object_inline_bootstrapScripts_1695.add(scriptConfig);\n       bootstrapChunks.push('<script src=\"', escapeTextForBrowser(src), '\"');\n       \"string\" === typeof integrity &&\n         bootstrapChunks.push(\n@@ -2817,7 +2817,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         (props.moduleScriptResources[scriptConfig] = null),\n         (props = []),\n         pushLinkImpl(props, integrity),\n-        JSCompiler_object_inline_bootstrapScripts_1685.add(props),\n+        JSCompiler_object_inline_bootstrapScripts_1695.add(props),\n         bootstrapChunks.push(\n           '<script type=\"module\" src=\"',\n           escapeTextForBrowser(i),\n@@ -2839,7 +2839,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         bootstrapChunks.push(' async=\"\">\\x3c/script>');\n   return {\n     placeholderPrefix: bootstrapScriptContent,\n-    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1667,\n+    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1677,\n     boundaryPrefix: idPrefix,\n     startInlineScript: \"<script\",\n     startInlineStyle: \"<style\",\n@@ -2859,14 +2859,14 @@ function createRenderState(resumableState, generateStaticMarkup) {\n     charsetChunks: [],\n     viewportChunks: [],\n     hoistableChunks: [],\n-    preconnects: JSCompiler_object_inline_preconnects_1681,\n-    fontPreloads: JSCompiler_object_inline_fontPreloads_1682,\n-    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1683,\n-    styles: JSCompiler_object_inline_styles_1684,\n-    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1685,\n-    scripts: JSCompiler_object_inline_scripts_1686,\n-    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1687,\n-    preloads: JSCompiler_object_inline_preloads_1688,\n+    preconnects: JSCompiler_object_inline_preconnects_1691,\n+    fontPreloads: JSCompiler_object_inline_fontPreloads_1692,\n+    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1693,\n+    styles: JSCompiler_object_inline_styles_1694,\n+    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1695,\n+    scripts: JSCompiler_object_inline_scripts_1696,\n+    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1697,\n+    preloads: JSCompiler_object_inline_preloads_1698,\n     nonce: { script: void 0, style: void 0 },\n     stylesToHoist: !1,\n     generateStaticMarkup: generateStaticMarkup\n@@ -3579,13 +3579,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6432,4 +6456,4 @@ exports.renderToString = function (children, options) {\n     'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToReadableStream\" which supports Suspense on the server'\n   );\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "606f12bd633392b7741792d9490880798b1e974d",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server-legacy.node.development.js",
            "status": "modified",
            "additions": 50,
            "deletions": 32,
            "changes": 82,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4108,6 +4108,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4280,27 +4301,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4324,13 +4324,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -6866,8 +6879,8 @@\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n           if (null === boundary) {\n-            logRecoverableError(request, error, segment, null);\n-            fatalError(request, error, segment, null);\n+            logRecoverableError(request, error, segment, task.debugTask);\n+            fatalError(request, error, segment, task.debugTask);\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -6895,7 +6908,12 @@\n       } else\n         boundary.status !== CLIENT_RENDERED &&\n           ((boundary.status = CLIENT_RENDERED),\n-          (errorDigest = logRecoverableError(request, error, segment, null)),\n+          (errorDigest = logRecoverableError(\n+            request,\n+            error,\n+            segment,\n+            task.debugTask\n+          )),\n           (boundary.status = CLIENT_RENDERED),\n           encodeErrorForBoundary(boundary, errorDigest, error, segment, !0),\n           untrackBoundary(request, boundary),\n@@ -9665,5 +9683,5 @@\n         'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToPipeableStream\" which supports Suspense on the server'\n       );\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "a21da9d0e178babc6b6b3a79f94ab251dc614c6d",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server-legacy.node.production.js",
            "status": "modified",
            "additions": 52,
            "deletions": 28,
            "changes": 80,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server-legacy.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -2743,16 +2743,16 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       \"\\x3c/script>\"\n     ));\n   bootstrapScriptContent = idPrefix + \"P:\";\n-  var JSCompiler_object_inline_segmentPrefix_1667 = idPrefix + \"S:\";\n+  var JSCompiler_object_inline_segmentPrefix_1677 = idPrefix + \"S:\";\n   idPrefix += \"B:\";\n-  var JSCompiler_object_inline_preconnects_1681 = new Set(),\n-    JSCompiler_object_inline_fontPreloads_1682 = new Set(),\n-    JSCompiler_object_inline_highImagePreloads_1683 = new Set(),\n-    JSCompiler_object_inline_styles_1684 = new Map(),\n-    JSCompiler_object_inline_bootstrapScripts_1685 = new Set(),\n-    JSCompiler_object_inline_scripts_1686 = new Set(),\n-    JSCompiler_object_inline_bulkPreloads_1687 = new Set(),\n-    JSCompiler_object_inline_preloads_1688 = {\n+  var JSCompiler_object_inline_preconnects_1691 = new Set(),\n+    JSCompiler_object_inline_fontPreloads_1692 = new Set(),\n+    JSCompiler_object_inline_highImagePreloads_1693 = new Set(),\n+    JSCompiler_object_inline_styles_1694 = new Map(),\n+    JSCompiler_object_inline_bootstrapScripts_1695 = new Set(),\n+    JSCompiler_object_inline_scripts_1696 = new Set(),\n+    JSCompiler_object_inline_bulkPreloads_1697 = new Set(),\n+    JSCompiler_object_inline_preloads_1698 = {\n       images: new Map(),\n       stylesheets: new Map(),\n       scripts: new Map(),\n@@ -2789,7 +2789,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n       scriptConfig.moduleScriptResources[href] = null;\n       scriptConfig = [];\n       pushLinkImpl(scriptConfig, props);\n-      JSCompiler_object_inline_bootstrapScripts_1685.add(scriptConfig);\n+      JSCompiler_object_inline_bootstrapScripts_1695.add(scriptConfig);\n       bootstrapChunks.push('<script src=\"', escapeTextForBrowser(src), '\"');\n       \"string\" === typeof integrity &&\n         bootstrapChunks.push(\n@@ -2836,7 +2836,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         (props.moduleScriptResources[scriptConfig] = null),\n         (props = []),\n         pushLinkImpl(props, integrity),\n-        JSCompiler_object_inline_bootstrapScripts_1685.add(props),\n+        JSCompiler_object_inline_bootstrapScripts_1695.add(props),\n         bootstrapChunks.push(\n           '<script type=\"module\" src=\"',\n           escapeTextForBrowser(i),\n@@ -2858,7 +2858,7 @@ function createRenderState(resumableState, generateStaticMarkup) {\n         bootstrapChunks.push(' async=\"\">\\x3c/script>');\n   return {\n     placeholderPrefix: bootstrapScriptContent,\n-    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1667,\n+    segmentPrefix: JSCompiler_object_inline_segmentPrefix_1677,\n     boundaryPrefix: idPrefix,\n     startInlineScript: \"<script\",\n     startInlineStyle: \"<style\",\n@@ -2878,14 +2878,14 @@ function createRenderState(resumableState, generateStaticMarkup) {\n     charsetChunks: [],\n     viewportChunks: [],\n     hoistableChunks: [],\n-    preconnects: JSCompiler_object_inline_preconnects_1681,\n-    fontPreloads: JSCompiler_object_inline_fontPreloads_1682,\n-    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1683,\n-    styles: JSCompiler_object_inline_styles_1684,\n-    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1685,\n-    scripts: JSCompiler_object_inline_scripts_1686,\n-    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1687,\n-    preloads: JSCompiler_object_inline_preloads_1688,\n+    preconnects: JSCompiler_object_inline_preconnects_1691,\n+    fontPreloads: JSCompiler_object_inline_fontPreloads_1692,\n+    highImagePreloads: JSCompiler_object_inline_highImagePreloads_1693,\n+    styles: JSCompiler_object_inline_styles_1694,\n+    bootstrapScripts: JSCompiler_object_inline_bootstrapScripts_1695,\n+    scripts: JSCompiler_object_inline_scripts_1696,\n+    bulkPreloads: JSCompiler_object_inline_bulkPreloads_1697,\n+    preloads: JSCompiler_object_inline_preloads_1698,\n     nonce: { script: void 0, style: void 0 },\n     stylesToHoist: !1,\n     generateStaticMarkup: generateStaticMarkup\n@@ -3626,13 +3626,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6515,4 +6539,4 @@ exports.renderToString = function (children, options) {\n     'The server used \"renderToString\" which does not support Suspense. If you intended for this Suspense boundary to render the fallback content on the server consider throwing an Error somewhere within the Suspense boundary. If you intended to have the server wait for the suspended component please switch to \"renderToPipeableStream\" which supports Suspense on the server'\n   );\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "ceb3374c8d0a05d89e7c44f1c44cb57df2853c31",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.browser.development.js",
            "status": "modified",
            "additions": 52,
            "deletions": 34,
            "changes": 86,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4262,6 +4262,27 @@\n           \"disabledDepth fell below zero. This is a bug in React. Please file an issue.\"\n         );\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = void 0;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4434,27 +4455,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = void 0;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4478,13 +4478,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -7081,8 +7094,8 @@\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n           if (null === boundary) {\n-            logRecoverableError(request, error, segment, null);\n-            fatalError(request, error, segment, null);\n+            logRecoverableError(request, error, segment, task.debugTask);\n+            fatalError(request, error, segment, task.debugTask);\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7110,7 +7123,12 @@\n       } else\n         boundary.status !== CLIENT_RENDERED &&\n           ((boundary.status = CLIENT_RENDERED),\n-          (errorDigest = logRecoverableError(request, error, segment, null)),\n+          (errorDigest = logRecoverableError(\n+            request,\n+            error,\n+            segment,\n+            task.debugTask\n+          )),\n           (boundary.status = CLIENT_RENDERED),\n           encodeErrorForBoundary(boundary, errorDigest, error, segment, !0),\n           untrackBoundary(request, boundary),\n@@ -8414,11 +8432,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     var React = require(\"next/dist/compiled/react\"),\n@@ -10108,5 +10126,5 @@\n         startWork(request);\n       });\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "d23b8d8be929665d7f1e67cf5533e9541866c8c3",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.browser.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -3962,13 +3962,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6818,12 +6842,12 @@ function addToReplayParent(node, parentKeyPath, trackedPostpones) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       formatProdErrorMessage(\n         527,\n         isomorphicReactPackageVersion,\n-        \"19.2.0-canary-fa3feba6-20250623\"\n+        \"19.2.0-canary-cee7939b-20250625\"\n       )\n     );\n }\n@@ -6970,4 +6994,4 @@ exports.renderToReadableStream = function (children, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "d706dfa1eaab83ca00de2229df9aea67361cd323",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.bun.production.js",
            "status": "modified",
            "additions": 37,
            "deletions": 13,
            "changes": 50,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.bun.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.bun.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.bun.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -3606,13 +3606,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = void 0),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6461,15 +6485,15 @@ function addToReplayParent(node, parentKeyPath, trackedPostpones) {\n     parentNode[2].push(node);\n   }\n }\n-var isomorphicReactPackageVersion$jscomp$inline_813 = React.version;\n+var isomorphicReactPackageVersion$jscomp$inline_817 = React.version;\n if (\n-  \"19.2.0-canary-fa3feba6-20250623\" !==\n-  isomorphicReactPackageVersion$jscomp$inline_813\n+  \"19.2.0-canary-cee7939b-20250625\" !==\n+  isomorphicReactPackageVersion$jscomp$inline_817\n )\n   throw Error(\n     'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n-      (isomorphicReactPackageVersion$jscomp$inline_813 +\n-        \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+      (isomorphicReactPackageVersion$jscomp$inline_817 +\n+        \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n   );\n exports.renderToReadableStream = function (children, options) {\n   return new Promise(function (resolve, reject) {\n@@ -6560,4 +6584,4 @@ exports.renderToReadableStream = function (children, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "e1a8f2c2494a3a44cefcf7d3a6fd94f18d3a60a7",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.edge.development.js",
            "status": "modified",
            "additions": 52,
            "deletions": 34,
            "changes": 86,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4273,6 +4273,27 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = prepareStackTrace;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4445,27 +4466,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = prepareStackTrace;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4489,13 +4489,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -7100,8 +7113,8 @@\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n           if (null === boundary) {\n-            logRecoverableError(request, error, segment, null);\n-            fatalError(request, error, segment, null);\n+            logRecoverableError(request, error, segment, task.debugTask);\n+            fatalError(request, error, segment, task.debugTask);\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7129,7 +7142,12 @@\n       } else\n         boundary.status !== CLIENT_RENDERED &&\n           ((boundary.status = CLIENT_RENDERED),\n-          (errorDigest = logRecoverableError(request, error, segment, null)),\n+          (errorDigest = logRecoverableError(\n+            request,\n+            error,\n+            segment,\n+            task.debugTask\n+          )),\n           (boundary.status = CLIENT_RENDERED),\n           encodeErrorForBoundary(boundary, errorDigest, error, segment, !0),\n           untrackBoundary(request, boundary),\n@@ -8446,11 +8464,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     var React = require(\"next/dist/compiled/react\"),\n@@ -10136,5 +10154,5 @@\n         startWork(request);\n       });\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "4157e8476d552f81343e7b292fb3ca3363fa510e",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.edge.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4015,13 +4015,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = prepareStackTrace),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6925,11 +6949,11 @@ function addToReplayParent(node, parentKeyPath, trackedPostpones) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n         (isomorphicReactPackageVersion +\n-          \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+          \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n     );\n }\n ensureCorrectIsomorphicReactVersion();\n@@ -7075,4 +7099,4 @@ exports.renderToReadableStream = function (children, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "5b2a9c32319de97c13f7c883d42e61c7d2faba5e",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.node.development.js",
            "status": "modified",
            "additions": 52,
            "deletions": 34,
            "changes": 86,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -4167,6 +4167,27 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n+    function formatOwnerStack(error) {\n+      var prevPrepareStackTrace = Error.prepareStackTrace;\n+      Error.prepareStackTrace = prepareStackTrace;\n+      error = error.stack;\n+      Error.prepareStackTrace = prevPrepareStackTrace;\n+      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+        (error = error.slice(29));\n+      prevPrepareStackTrace = error.indexOf(\"\\n\");\n+      -1 !== prevPrepareStackTrace &&\n+        (error = error.slice(prevPrepareStackTrace + 1));\n+      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n+      -1 !== prevPrepareStackTrace &&\n+        (prevPrepareStackTrace = error.lastIndexOf(\n+          \"\\n\",\n+          prevPrepareStackTrace\n+        ));\n+      if (-1 !== prevPrepareStackTrace)\n+        error = error.slice(0, prevPrepareStackTrace);\n+      else return \"\";\n+      return error;\n+    }\n     function describeBuiltInComponentFrame(name) {\n       if (void 0 === prefix)\n         try {\n@@ -4339,27 +4360,6 @@\n       \"function\" === typeof fn && componentFrameCache.set(fn, sampleLines);\n       return sampleLines;\n     }\n-    function formatOwnerStack(error) {\n-      var prevPrepareStackTrace = Error.prepareStackTrace;\n-      Error.prepareStackTrace = prepareStackTrace;\n-      error = error.stack;\n-      Error.prepareStackTrace = prevPrepareStackTrace;\n-      error.startsWith(\"Error: react-stack-top-frame\\n\") &&\n-        (error = error.slice(29));\n-      prevPrepareStackTrace = error.indexOf(\"\\n\");\n-      -1 !== prevPrepareStackTrace &&\n-        (error = error.slice(prevPrepareStackTrace + 1));\n-      prevPrepareStackTrace = error.indexOf(\"react-stack-bottom-frame\");\n-      -1 !== prevPrepareStackTrace &&\n-        (prevPrepareStackTrace = error.lastIndexOf(\n-          \"\\n\",\n-          prevPrepareStackTrace\n-        ));\n-      if (-1 !== prevPrepareStackTrace)\n-        error = error.slice(0, prevPrepareStackTrace);\n-      else return \"\";\n-      return error;\n-    }\n     function describeComponentStackByType(type) {\n       if (\"string\" === typeof type) return describeBuiltInComponentFrame(type);\n       if (\"function\" === typeof type)\n@@ -4383,13 +4383,26 @@\n             }\n             return describeComponentStackByType(type);\n         }\n-        if (\"string\" === typeof type.name)\n-          return (\n-            (payload = type.env),\n-            describeBuiltInComponentFrame(\n-              type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-            )\n-          );\n+        if (\"string\" === typeof type.name) {\n+          a: {\n+            payload = type.name;\n+            lazyComponent = type.env;\n+            type = type.debugLocation;\n+            if (null != type) {\n+              type = formatOwnerStack(type);\n+              var idx = type.lastIndexOf(\"\\n\");\n+              type = -1 === idx ? type : type.slice(idx + 1);\n+              if (-1 !== type.indexOf(payload)) {\n+                payload = \"\\n\" + type;\n+                break a;\n+              }\n+            }\n+            payload = describeBuiltInComponentFrame(\n+              payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+            );\n+          }\n+          return payload;\n+        }\n       }\n       switch (type) {\n         case REACT_SUSPENSE_LIST_TYPE:\n@@ -6990,8 +7003,8 @@\n         if (13 !== request.status && request.status !== CLOSED) {\n           boundary = task.replay;\n           if (null === boundary) {\n-            logRecoverableError(request, error, segment, null);\n-            fatalError(request, error, segment, null);\n+            logRecoverableError(request, error, segment, task.debugTask);\n+            fatalError(request, error, segment, task.debugTask);\n             return;\n           }\n           boundary.pendingTasks--;\n@@ -7019,7 +7032,12 @@\n       } else\n         boundary.status !== CLIENT_RENDERED &&\n           ((boundary.status = CLIENT_RENDERED),\n-          (errorDigest = logRecoverableError(request, error, segment, null)),\n+          (errorDigest = logRecoverableError(\n+            request,\n+            error,\n+            segment,\n+            task.debugTask\n+          )),\n           (boundary.status = CLIENT_RENDERED),\n           encodeErrorForBoundary(boundary, errorDigest, error, segment, !0),\n           untrackBoundary(request, boundary),\n@@ -8312,11 +8330,11 @@\n     }\n     function ensureCorrectIsomorphicReactVersion() {\n       var isomorphicReactPackageVersion = React.version;\n-      if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+      if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n         throw Error(\n           'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n             (isomorphicReactPackageVersion +\n-              \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+              \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n         );\n     }\n     function createDrainHandler(destination, request) {\n@@ -10187,5 +10205,5 @@\n         startWork(request);\n       });\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "b8dc286ce52f94e566d271dbbaa885cfd36e662d",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom-server.node.production.js",
            "status": "modified",
            "additions": 34,
            "deletions": 10,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -3909,13 +3909,37 @@ function describeComponentStackByType(type) {\n         }\n         return describeComponentStackByType(type);\n     }\n-    if (\"string\" === typeof type.name)\n-      return (\n-        (payload = type.env),\n-        describeBuiltInComponentFrame(\n-          type.name + (payload ? \" [\" + payload + \"]\" : \"\")\n-        )\n-      );\n+    if (\"string\" === typeof type.name) {\n+      a: {\n+        payload = type.name;\n+        lazyComponent = type.env;\n+        var location = type.debugLocation;\n+        if (\n+          null != location &&\n+          ((type = Error.prepareStackTrace),\n+          (Error.prepareStackTrace = prepareStackTrace),\n+          (location = location.stack),\n+          (Error.prepareStackTrace = type),\n+          location.startsWith(\"Error: react-stack-top-frame\\n\") &&\n+            (location = location.slice(29)),\n+          (type = location.indexOf(\"\\n\")),\n+          -1 !== type && (location = location.slice(type + 1)),\n+          (type = location.indexOf(\"react-stack-bottom-frame\")),\n+          -1 !== type && (type = location.lastIndexOf(\"\\n\", type)),\n+          (type = -1 !== type ? (location = location.slice(0, type)) : \"\"),\n+          (location = type.lastIndexOf(\"\\n\")),\n+          (type = -1 === location ? type : type.slice(location + 1)),\n+          -1 !== type.indexOf(payload))\n+        ) {\n+          payload = \"\\n\" + type;\n+          break a;\n+        }\n+        payload = describeBuiltInComponentFrame(\n+          payload + (lazyComponent ? \" [\" + lazyComponent + \"]\" : \"\")\n+        );\n+      }\n+      return payload;\n+    }\n   }\n   switch (type) {\n     case REACT_SUSPENSE_LIST_TYPE:\n@@ -6808,11 +6832,11 @@ function addToReplayParent(node, parentKeyPath, trackedPostpones) {\n }\n function ensureCorrectIsomorphicReactVersion() {\n   var isomorphicReactPackageVersion = React.version;\n-  if (\"19.2.0-canary-fa3feba6-20250623\" !== isomorphicReactPackageVersion)\n+  if (\"19.2.0-canary-cee7939b-20250625\" !== isomorphicReactPackageVersion)\n     throw Error(\n       'Incompatible React versions: The \"react\" and \"react-dom\" packages must have the exact same version. Instead got:\\n  - react:      ' +\n         (isomorphicReactPackageVersion +\n-          \"\\n  - react-dom:  19.2.0-canary-fa3feba6-20250623\\nLearn more: https://react.dev/warnings/version-mismatch\")\n+          \"\\n  - react-dom:  19.2.0-canary-cee7939b-20250625\\nLearn more: https://react.dev/warnings/version-mismatch\")\n     );\n }\n ensureCorrectIsomorphicReactVersion();\n@@ -7150,4 +7174,4 @@ exports.renderToReadableStream = function (children, options) {\n     startWork(request);\n   });\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "5a7201918caad07e45342299fdc49ead8b4c4284",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -416,7 +416,7 @@\n     exports.useFormStatus = function () {\n       return resolveDispatcher().useHostTransitionStatus();\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "65b93509c9c1df0bc09259b905a1eaa7e0f49266",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -207,4 +207,4 @@ exports.useFormState = function (action, initialState, permalink) {\n exports.useFormStatus = function () {\n   return ReactSharedInternals.H.useHostTransitionStatus();\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "9cec6127e1ad4963297f50aed2a5289f663352e7",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom.react-server.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -336,5 +336,5 @@\n             }))\n           : Internals.d.m(href));\n     };\n-    exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-canary-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "cc59ee517725c9edccaafb6da5bb6624632469a7",
            "filename": "packages/next/src/compiled/react-dom/cjs/react-dom.react-server.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fcjs%2Freact-dom.react-server.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -149,4 +149,4 @@ exports.preloadModule = function (href, options) {\n       });\n     } else Internals.d.m(href);\n };\n-exports.version = \"19.2.0-canary-fa3feba6-20250623\";\n+exports.version = \"19.2.0-canary-cee7939b-20250625\";"
        },
        {
            "sha": "993fd029b947e029f3e663f41135b98d4eb0e0e6",
            "filename": "packages/next/src/compiled/react-dom/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-dom%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -67,10 +67,10 @@\n     \"./package.json\": \"./package.json\"\n   },\n   \"dependencies\": {\n-    \"scheduler\": \"0.27.0-canary-fa3feba6-20250623\"\n+    \"scheduler\": \"0.27.0-canary-cee7939b-20250625\"\n   },\n   \"peerDependencies\": {\n-    \"react\": \"19.2.0-canary-fa3feba6-20250623\"\n+    \"react\": \"19.2.0-canary-cee7939b-20250625\"\n   },\n   \"browser\": {\n     \"./server.js\": \"./server.browser.js\","
        },
        {
            "sha": "124c08d95a7a1dcee619f62604ccfedb8913745d",
            "filename": "packages/next/src/compiled/react-experimental/cjs/react.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1327,7 +1327,7 @@\n     exports.useTransition = function () {\n       return resolveDispatcher().useTransition();\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n     \"undefined\" !== typeof __REACT_DEVTOOLS_GLOBAL_HOOK__ &&\n       \"function\" ===\n         typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.registerInternalModuleStop &&"
        },
        {
            "sha": "894b65c087eb1afa95ee6f849846a7d22bbc158f",
            "filename": "packages/next/src/compiled/react-experimental/cjs/react.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -605,4 +605,4 @@ exports.useSyncExternalStore = function (\n exports.useTransition = function () {\n   return ReactSharedInternals.H.useTransition();\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "33c5f10ae319dada8b2812de1977ea054b2a0351",
            "filename": "packages/next/src/compiled/react-experimental/cjs/react.react-server.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -994,5 +994,5 @@\n     exports.useMemo = function (create, deps) {\n       return resolveDispatcher().useMemo(create, deps);\n     };\n-    exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+    exports.version = \"19.2.0-experimental-cee7939b-20250625\";\n   })();"
        },
        {
            "sha": "33968f18130561b30a5f5d89a8b7d2944dcafa8b",
            "filename": "packages/next/src/compiled/react-experimental/cjs/react.react-server.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-experimental%2Fcjs%2Freact.react-server.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -572,4 +572,4 @@ exports.useId = function () {\n exports.useMemo = function (create, deps) {\n   return ReactSharedInternals.H.useMemo(create, deps);\n };\n-exports.version = \"19.2.0-experimental-fa3feba6-20250623\";\n+exports.version = \"19.2.0-experimental-cee7939b-20250625\";"
        },
        {
            "sha": "3dd754583617ca54c171d6878707a44dbd861e90",
            "filename": "packages/next/src/compiled/react-is/package.json",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-is%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-is%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-is%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1,6 +1,6 @@\n {\n   \"name\": \"react-is\",\n-  \"version\": \"19.2.0-canary-fa3feba6-20250623\",\n+  \"version\": \"19.2.0-canary-cee7939b-20250625\",\n   \"description\": \"Brand checking of React Elements.\",\n   \"main\": \"index.js\",\n   \"sideEffects\": false,"
        },
        {
            "sha": "cf68fa1fe77cc803e834837a2756ea9a22d04def",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.browser.development.js",
            "status": "modified",
            "additions": 105,
            "deletions": 80,
            "changes": 185,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1142,11 +1142,10 @@\n         }\n       return null;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1169,11 +1168,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1219,25 +1218,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1258,13 +1258,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1301,6 +1302,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1361,7 +1365,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -1822,6 +1826,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -1855,7 +1862,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -1886,43 +1894,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -1932,14 +1938,14 @@\n         response._bundlerConfig,\n         model\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -1952,28 +1958,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -1994,12 +1992,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2014,7 +2007,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2026,7 +2019,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2077,10 +2070,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2095,8 +2087,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2120,7 +2111,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2131,9 +2127,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2143,7 +2145,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2433,15 +2435,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2559,9 +2566,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3010,7 +3017,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3141,7 +3148,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3154,7 +3161,24 @@\n         return value;\n       };\n     }\n+    function createDebugCallbackFromWritableStream(debugWritable) {\n+      var textEncoder = new TextEncoder(),\n+        writer = debugWritable.getWriter();\n+      return function (message) {\n+        \"\" === message\n+          ? writer.close()\n+          : writer\n+              .write(textEncoder.encode(message + \"\\n\"))\n+              .catch(console.error);\n+      };\n+    }\n     function createResponseFromOptions(options) {\n+      var debugChannel =\n+        options &&\n+        void 0 !== options.debugChannel &&\n+        void 0 !== options.debugChannel.writable\n+          ? createDebugCallbackFromWritableStream(options.debugChannel.writable)\n+          : void 0;\n       return new ResponseInstance(\n         null,\n         null,\n@@ -3167,7 +3191,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !1 !== options.replayConsoleLogs : !0,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        debugChannel\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -3479,10 +3504,10 @@\n       return hook.checkDCE ? !0 : !1;\n     })({\n       bundleType: 1,\n-      version: \"19.2.0-experimental-fa3feba6-20250623\",\n+      version: \"19.2.0-experimental-cee7939b-20250625\",\n       rendererPackageName: \"react-server-dom-turbopack\",\n       currentDispatcherRef: ReactSharedInternals,\n-      reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\",\n+      reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\",\n       getCurrentComponentInfo: function () {\n         return currentOwnerInDEV;\n       }"
        },
        {
            "sha": "9d3f1d392ed3ed09d73e964e402f54deb6ecfd51",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.browser.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -519,11 +519,10 @@ function createBoundServerReference(metaData, callServer) {\n   registerBoundServerReference(action, id, bound);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -570,11 +569,8 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function createErrorChunk(response, error) {\n-  return new ReactPromise(\"rejected\", null, error, response);\n+  return new ReactPromise(\"rejected\", null, error);\n }\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -618,23 +614,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -655,12 +652,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -707,7 +705,7 @@ function getChunk(response, id) {\n   chunk ||\n     ((chunk = response._closed\n       ? createErrorChunk(response, response._closedReason)\n-      : createPendingChunk(response)),\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1051,25 +1049,25 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n     chunk = chunks.get(id);\n   model = JSON.parse(model, response._fromJSON);\n   var clientReference = resolveClientReference(response._bundlerConfig, model);\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1082,23 +1080,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1119,7 +1114,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1134,7 +1129,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1146,7 +1141,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1197,10 +1192,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1215,8 +1209,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1236,7 +1229,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1247,9 +1245,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1259,7 +1263,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1419,10 +1423,10 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n         : tag.set(id, createErrorChunk(response, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1462,11 +1466,8 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1493,12 +1494,7 @@ function createFromJSONCallback(response) {\n             (key = createErrorChunk(response, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "a55c45d15d39206ac85124817eda156413a6dae2",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.edge.development.js",
            "status": "modified",
            "additions": 86,
            "deletions": 78,
            "changes": 164,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1354,11 +1354,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1381,11 +1380,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1431,25 +1430,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1470,13 +1470,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1513,6 +1514,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1573,7 +1577,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -2041,6 +2045,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -2074,7 +2081,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -2105,43 +2113,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -2156,14 +2162,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -2176,28 +2182,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -2218,12 +2216,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2238,7 +2231,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2250,7 +2243,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2301,10 +2294,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2319,8 +2311,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2344,7 +2335,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2355,9 +2351,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2367,7 +2369,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2657,15 +2659,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2783,9 +2790,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3234,7 +3241,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3365,7 +3372,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3396,7 +3403,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {"
        },
        {
            "sha": "798e8646814f546475aabdd568eefe4e6dd51d40",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.edge.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -689,11 +689,10 @@ function createServerReference$1(id, callServer, encodeFormAction) {\n   registerBoundServerReference(action, id, null, encodeFormAction);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -740,11 +739,8 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function createErrorChunk(response, error) {\n-  return new ReactPromise(\"rejected\", null, error, response);\n+  return new ReactPromise(\"rejected\", null, error);\n }\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -788,23 +784,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -825,12 +822,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -877,7 +875,7 @@ function getChunk(response, id) {\n   chunk ||\n     ((chunk = response._closed\n       ? createErrorChunk(response, response._closedReason)\n-      : createPendingChunk(response)),\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1236,11 +1234,11 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n@@ -1252,14 +1250,14 @@ function resolveModule(response, id, model) {\n     model[1],\n     response._nonce\n   );\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1272,23 +1270,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1309,7 +1304,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1324,7 +1319,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1336,7 +1331,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1387,10 +1382,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1405,8 +1399,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1426,7 +1419,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1437,9 +1435,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1449,7 +1453,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1609,10 +1613,10 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n         : tag.set(id, createErrorChunk(response, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1652,11 +1656,8 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1683,12 +1684,7 @@ function createFromJSONCallback(response) {\n             (key = createErrorChunk(response, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "b92da53855d3574198358a4e99e18a1ec6f59a02",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.node.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 79,
            "changes": 167,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1354,11 +1354,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1381,11 +1380,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1431,25 +1430,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1470,13 +1470,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1513,6 +1514,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1573,7 +1577,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -2041,6 +2045,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -2074,7 +2081,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -2105,43 +2113,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -2156,14 +2162,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -2176,28 +2182,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -2218,12 +2216,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2238,7 +2231,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2250,7 +2243,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2301,10 +2294,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2319,8 +2311,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2344,7 +2335,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2355,9 +2351,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2367,7 +2369,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2657,15 +2659,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2783,9 +2790,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3234,7 +3241,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3444,7 +3451,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3478,7 +3485,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -3733,7 +3741,8 @@\n         void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n       stream.on(\"data\", function (chunk) {\n         processBinaryChunk(response, chunk);"
        },
        {
            "sha": "c4346186a99aa399a8ebc7214264e779326b1d29",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-client.node.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -690,11 +690,10 @@ function createServerReference$1(id, callServer, encodeFormAction) {\n   registerBoundServerReference(action, id, null, encodeFormAction);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -741,11 +740,8 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function createErrorChunk(response, error) {\n-  return new ReactPromise(\"rejected\", null, error, response);\n+  return new ReactPromise(\"rejected\", null, error);\n }\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -789,23 +785,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -826,12 +823,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -878,7 +876,7 @@ function getChunk(response, id) {\n   chunk ||\n     ((chunk = response._closed\n       ? createErrorChunk(response, response._closedReason)\n-      : createPendingChunk(response)),\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1237,11 +1235,11 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n@@ -1253,14 +1251,14 @@ function resolveModule(response, id, model) {\n     model[1],\n     response._nonce\n   );\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1273,23 +1271,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1310,7 +1305,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1325,7 +1320,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1337,7 +1332,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1388,10 +1383,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1406,8 +1400,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1427,7 +1420,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1438,9 +1436,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1450,7 +1454,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1610,10 +1614,10 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n         : tag.set(id, createErrorChunk(response, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1653,11 +1657,8 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function processBinaryChunk(response, chunk) {\n@@ -1762,12 +1763,7 @@ function createFromJSONCallback(response) {\n             (key = createErrorChunk(response, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "85d05c2c5dbc483eaf3b2957c1b1d0bec4b94d72",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.browser.development.js",
            "status": "modified",
            "additions": 281,
            "deletions": 132,
            "changes": 413,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -756,13 +756,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -787,7 +788,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -823,6 +823,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = this.timeOrigin = performance.now();\n       emitTimeOriginChunk(this, type + performance.timeOrigin);\n       model = createTask(\n@@ -846,21 +849,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -873,21 +878,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -915,6 +922,8 @@\n             ref\n           );\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -950,7 +959,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -989,11 +998,9 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n               request.type === PRERENDER\n-                ? request.pendingChunks--\n-                : ((task = stringify(serializeByValueID(request.fatalError))),\n-                  emitModelChunk(request, newTask.id, task)),\n+                ? haltTask(newTask, request)\n+                : abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -1027,14 +1034,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(stringToChunk(entry)),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -1047,21 +1058,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1082,20 +1098,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1111,10 +1126,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1127,23 +1145,29 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal.reason),\n+              enqueueFlush(request));\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1157,14 +1181,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1684,6 +1706,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -1835,32 +1867,38 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? haltTask(newTask, request)\n+            : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -1874,9 +1912,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2543,8 +2580,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2656,15 +2711,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -2870,6 +2930,24 @@\n       (thenable = thenable._debugInfo) &&\n         forwardDebugInfo(request, task, thenable);\n     }\n+    function forwardDebugInfoFromAbortedTask(request, task) {\n+      var model = task.model;\n+      if (\"object\" === typeof model && null !== model) {\n+        var debugInfo;\n+        (debugInfo = model._debugInfo) &&\n+          forwardDebugInfo(request, task, debugInfo);\n+        if (\n+          \"function\" !== typeof model.then &&\n+          model.$$typeof === REACT_LAZY_TYPE\n+        ) {\n+          request = model._payload;\n+          model = model._init;\n+          try {\n+            model(request);\n+          } catch (x) {}\n+        }\n+      }\n+    }\n     function emitTimingChunk(request, id, timestamp) {\n       request.pendingChunks++;\n       timestamp -= request.timeOrigin;\n@@ -2974,16 +3052,11 @@\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n           if (request.status === ABORTING)\n-            if (\n-              (request.abortableTasks.delete(task),\n-              (task.status = ABORTED),\n-              request.type === PRERENDER)\n-            )\n-              request.pendingChunks--;\n-            else {\n-              var model = stringify(serializeByValueID(request.fatalError));\n-              emitModelChunk(request, task.id, model);\n-            }\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              request.type === PRERENDER\n+                ? haltTask(task, request)\n+                : abortTask(task, request, request.fatalError);\n           else {\n             var x =\n               thrownValue === SuspenseException\n@@ -3040,11 +3113,18 @@\n     function abortTask(task, request, errorId) {\n       task.status !== RENDERING &&\n         ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n         task.timed && markOperationEndTime(request, task, performance.now()),\n         (errorId = serializeByValueID(errorId)),\n         (task = encodeReferenceChunk(request, task.id, errorId)),\n         request.completedErrorChunks.push(task));\n     }\n+    function haltTask(task, request) {\n+      task.status !== RENDERING &&\n+        ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n+        request.pendingChunks--);\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -3136,11 +3216,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -3158,13 +3235,14 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           if (request.type === PRERENDER)\n             abortableTasks.forEach(function (task) {\n-              task.status !== RENDERING &&\n-                ((task.status = ABORTED), request.pendingChunks--);\n+              return haltTask(task, request);\n             });\n           else if (\n             \"object\" === typeof reason &&\n@@ -3204,37 +3282,29 @@\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            \"object\" === typeof reason &&\n-            null !== reason &&\n-            reason.$$typeof === REACT_POSTPONE_TYPE\n-              ? Error(\"The render was aborted due to being postponed.\")\n-              : void 0 === reason\n-                ? Error(\n-                    \"The render was aborted by the server without a reason.\"\n-                  )\n-                : \"object\" === typeof reason &&\n-                    null !== reason &&\n-                    \"function\" === typeof reason.then\n-                  ? Error(\n-                      \"The render was aborted by the server with a promise.\"\n-                    )\n-                  : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -3976,6 +4046,76 @@\n       if (\"fulfilled\" !== body.status) throw body.reason;\n       return body.value;\n     }\n+    function startReadingFromDebugChannelReadableStream(\n+      request$jscomp$0,\n+      stream\n+    ) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++) {\n+          var request = request$jscomp$0,\n+            message = _ref[buffer],\n+            deferredDebugObjects = request.deferredDebugObjects;\n+          if (null === deferredDebugObjects)\n+            throw Error(\n+              \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+            );\n+          var command = message.charCodeAt(0);\n+          message = message.slice(2).split(\",\").map(fromHex);\n+          switch (command) {\n+            case 82:\n+              for (command = 0; command < message.length; command++) {\n+                var id = message[command],\n+                  retainedValue = deferredDebugObjects.retained.get(id);\n+                void 0 !== retainedValue &&\n+                  (request.pendingChunks--,\n+                  deferredDebugObjects.retained.delete(id),\n+                  deferredDebugObjects.existing.delete(retainedValue),\n+                  enqueueFlush(request));\n+              }\n+              break;\n+            case 81:\n+              for (command = 0; command < message.length; command++)\n+                (id = message[command]),\n+                  (retainedValue = deferredDebugObjects.retained.get(id)),\n+                  void 0 !== retainedValue &&\n+                    (emitOutlinedDebugModelChunk(\n+                      request,\n+                      id,\n+                      { objectLimit: 10 },\n+                      retainedValue\n+                    ),\n+                    enqueueFlush(request));\n+              break;\n+            default:\n+              throw Error(\n+                \"Unknown command. The debugChannel was not wired up properly.\"\n+              );\n+          }\n+        }\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request$jscomp$0);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request$jscomp$0,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     var ReactDOM = require(\"react-dom\"),\n       React = require(\"react\"),\n       channel = new MessageChannel(),\n@@ -4449,6 +4589,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -4564,16 +4705,21 @@\n       });\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -4585,6 +4731,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       return new ReadableStream(\n         {\n           type: \"bytes\",\n@@ -4611,9 +4762,6 @@\n             var stream = new ReadableStream(\n               {\n                 type: \"bytes\",\n-                start: function () {\n-                  startWork(request);\n-                },\n                 pull: function (controller) {\n                   startFlowing(request, controller);\n                 },\n@@ -4632,7 +4780,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "6385289016272ff5bf1b667635ff99aafac2a5dd",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.browser.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 122,
            "changes": 223,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -751,23 +751,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var cleanupQueue = [];\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    cleanupQueue = [];\n   TaintRegistryPendingRequests.add(cleanupQueue);\n   var hints = new Set();\n   this.type = type;\n@@ -779,9 +777,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -798,14 +795,14 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -821,11 +818,9 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n           21 === request.type\n-            ? request.pendingChunks--\n-            : ((task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task)),\n+            ? haltTask(newTask, request)\n+            : abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -856,14 +851,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(stringToChunk(entry)),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -876,21 +875,23 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -907,19 +908,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -935,10 +935,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -951,23 +954,29 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal.reason),\n+          enqueueFlush(request));\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -977,12 +986,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1344,38 +1351,37 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? haltTask(newTask, request)\n+        : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1860,16 +1866,11 @@ function retryTask(request, task) {\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n       if (12 === request.status)\n-        if (\n-          (request.abortableTasks.delete(task),\n-          (task.status = 3),\n-          21 === request.type)\n-        )\n-          request.pendingChunks--;\n-        else {\n-          var model = stringify(serializeByValueID(request.fatalError));\n-          emitModelChunk(request, task.id, model);\n-        }\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          21 === request.type\n+            ? haltTask(task, request)\n+            : abortTask(task, request, request.fatalError);\n       else {\n         var x =\n           thrownValue === SuspenseException\n@@ -1926,6 +1927,9 @@ function abortTask(task, request, errorId) {\n     (task = encodeReferenceChunk(request, task.id, errorId)),\n     request.completedErrorChunks.push(task));\n }\n+function haltTask(task, request) {\n+  5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -1994,8 +1998,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -2012,12 +2016,14 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       if (21 === request.type)\n         abortableTasks.forEach(function (task) {\n-          5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+          return haltTask(task, request);\n         });\n       else if (\n         \"object\" === typeof reason &&\n@@ -2053,30 +2059,10 @@ function abort(request, reason) {\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$28 =\n-        \"object\" === typeof reason &&\n-        null !== reason &&\n-        reason.$$typeof === REACT_POSTPONE_TYPE\n-          ? Error(\"The render was aborted due to being postponed.\")\n-          : void 0 === reason\n-            ? Error(\"The render was aborted by the server without a reason.\")\n-            : \"object\" === typeof reason &&\n-                null !== reason &&\n-                \"function\" === typeof reason.then\n-              ? Error(\"The render was aborted by the server with a promise.\")\n-              : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$28);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$29) {\n-    logRecoverableError(request, error$29, null), fatalError(request, error$29);\n+  } catch (error$28) {\n+    logRecoverableError(request, error$28, null), fatalError(request, error$28);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2521,19 +2507,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$32 = createPendingChunk(response);\n-        chunk$32.then(\n+        var chunk$31 = createPendingChunk(response);\n+        chunk$31.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$32;\n+        previousBlockedChunk = chunk$31;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$32 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$32, json, -1);\n+          previousBlockedChunk === chunk$31 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$31, json, -1);\n         });\n       }\n     },\n@@ -2881,13 +2867,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -2924,18 +2908,11 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var stream = new ReadableStream(\n           {\n             type: \"bytes\",\n-            start: function () {\n-              startWork(request);\n-            },\n             pull: function (controller) {\n               startFlowing(request, controller);\n             },\n@@ -2948,7 +2925,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n         );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "7e8c8bdd433d81999aa44a646ad354e66d0a8ae7",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.edge.development.js",
            "status": "modified",
            "additions": 281,
            "deletions": 132,
            "changes": 413,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -772,13 +772,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -803,7 +804,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -839,6 +839,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = this.timeOrigin = performance.now();\n       emitTimeOriginChunk(this, type + performance.timeOrigin);\n       model = createTask(\n@@ -862,21 +865,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -889,21 +894,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -936,6 +943,8 @@\n             ref\n           );\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -971,7 +980,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -1010,11 +1019,9 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n               request.type === PRERENDER\n-                ? request.pendingChunks--\n-                : ((task = stringify(serializeByValueID(request.fatalError))),\n-                  emitModelChunk(request, newTask.id, task)),\n+                ? haltTask(newTask, request)\n+                : abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -1048,14 +1055,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(stringToChunk(entry)),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -1068,21 +1079,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1103,20 +1119,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1132,10 +1147,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1148,23 +1166,29 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal.reason),\n+              enqueueFlush(request));\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1178,14 +1202,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1753,6 +1775,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -1904,32 +1936,38 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? haltTask(newTask, request)\n+            : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -1943,9 +1981,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2634,8 +2671,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2747,15 +2802,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -2961,6 +3021,24 @@\n       (thenable = thenable._debugInfo) &&\n         forwardDebugInfo(request, task, thenable);\n     }\n+    function forwardDebugInfoFromAbortedTask(request, task) {\n+      var model = task.model;\n+      if (\"object\" === typeof model && null !== model) {\n+        var debugInfo;\n+        (debugInfo = model._debugInfo) &&\n+          forwardDebugInfo(request, task, debugInfo);\n+        if (\n+          \"function\" !== typeof model.then &&\n+          model.$$typeof === REACT_LAZY_TYPE\n+        ) {\n+          request = model._payload;\n+          model = model._init;\n+          try {\n+            model(request);\n+          } catch (x) {}\n+        }\n+      }\n+    }\n     function emitTimingChunk(request, id, timestamp) {\n       request.pendingChunks++;\n       timestamp -= request.timeOrigin;\n@@ -3065,16 +3143,11 @@\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n           if (request.status === ABORTING)\n-            if (\n-              (request.abortableTasks.delete(task),\n-              (task.status = ABORTED),\n-              request.type === PRERENDER)\n-            )\n-              request.pendingChunks--;\n-            else {\n-              var model = stringify(serializeByValueID(request.fatalError));\n-              emitModelChunk(request, task.id, model);\n-            }\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              request.type === PRERENDER\n+                ? haltTask(task, request)\n+                : abortTask(task, request, request.fatalError);\n           else {\n             var x =\n               thrownValue === SuspenseException\n@@ -3131,11 +3204,18 @@\n     function abortTask(task, request, errorId) {\n       task.status !== RENDERING &&\n         ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n         task.timed && markOperationEndTime(request, task, performance.now()),\n         (errorId = serializeByValueID(errorId)),\n         (task = encodeReferenceChunk(request, task.id, errorId)),\n         request.completedErrorChunks.push(task));\n     }\n+    function haltTask(task, request) {\n+      task.status !== RENDERING &&\n+        ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n+        request.pendingChunks--);\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -3231,11 +3311,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -3253,13 +3330,14 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           if (request.type === PRERENDER)\n             abortableTasks.forEach(function (task) {\n-              task.status !== RENDERING &&\n-                ((task.status = ABORTED), request.pendingChunks--);\n+              return haltTask(task, request);\n             });\n           else if (\n             \"object\" === typeof reason &&\n@@ -3299,37 +3377,29 @@\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            \"object\" === typeof reason &&\n-            null !== reason &&\n-            reason.$$typeof === REACT_POSTPONE_TYPE\n-              ? Error(\"The render was aborted due to being postponed.\")\n-              : void 0 === reason\n-                ? Error(\n-                    \"The render was aborted by the server without a reason.\"\n-                  )\n-                : \"object\" === typeof reason &&\n-                    null !== reason &&\n-                    \"function\" === typeof reason.then\n-                  ? Error(\n-                      \"The render was aborted by the server with a promise.\"\n-                    )\n-                  : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -4071,6 +4141,76 @@\n       if (\"fulfilled\" !== body.status) throw body.reason;\n       return body.value;\n     }\n+    function startReadingFromDebugChannelReadableStream(\n+      request$jscomp$0,\n+      stream\n+    ) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++) {\n+          var request = request$jscomp$0,\n+            message = _ref[buffer],\n+            deferredDebugObjects = request.deferredDebugObjects;\n+          if (null === deferredDebugObjects)\n+            throw Error(\n+              \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+            );\n+          var command = message.charCodeAt(0);\n+          message = message.slice(2).split(\",\").map(fromHex);\n+          switch (command) {\n+            case 82:\n+              for (command = 0; command < message.length; command++) {\n+                var id = message[command],\n+                  retainedValue = deferredDebugObjects.retained.get(id);\n+                void 0 !== retainedValue &&\n+                  (request.pendingChunks--,\n+                  deferredDebugObjects.retained.delete(id),\n+                  deferredDebugObjects.existing.delete(retainedValue),\n+                  enqueueFlush(request));\n+              }\n+              break;\n+            case 81:\n+              for (command = 0; command < message.length; command++)\n+                (id = message[command]),\n+                  (retainedValue = deferredDebugObjects.retained.get(id)),\n+                  void 0 !== retainedValue &&\n+                    (emitOutlinedDebugModelChunk(\n+                      request,\n+                      id,\n+                      { objectLimit: 10 },\n+                      retainedValue\n+                    ),\n+                    enqueueFlush(request));\n+              break;\n+            default:\n+              throw Error(\n+                \"Unknown command. The debugChannel was not wired up properly.\"\n+              );\n+          }\n+        }\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request$jscomp$0);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request$jscomp$0,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     var ReactDOM = require(\"react-dom\"),\n       React = require(\"react\"),\n       REACT_LEGACY_ELEMENT_TYPE = Symbol.for(\"react.element\"),\n@@ -4544,6 +4684,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -4697,16 +4838,21 @@\n       });\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -4718,6 +4864,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       return new ReadableStream(\n         {\n           type: \"bytes\",\n@@ -4744,9 +4895,6 @@\n             var stream = new ReadableStream(\n               {\n                 type: \"bytes\",\n-                start: function () {\n-                  startWork(request);\n-                },\n                 pull: function (controller) {\n                   startFlowing(request, controller);\n                 },\n@@ -4765,7 +4913,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "086d51c01381266afefccde850e8754276db6445",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.edge.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 122,
            "changes": 223,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -751,23 +751,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var cleanupQueue = [];\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    cleanupQueue = [];\n   TaintRegistryPendingRequests.add(cleanupQueue);\n   var hints = new Set();\n   this.type = type;\n@@ -779,9 +777,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -798,8 +795,8 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function resolveRequest() {\n@@ -813,7 +810,7 @@ function resolveRequest() {\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -829,11 +826,9 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n           21 === request.type\n-            ? request.pendingChunks--\n-            : ((task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task)),\n+            ? haltTask(newTask, request)\n+            : abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -864,14 +859,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(stringToChunk(entry)),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -884,21 +883,23 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -915,19 +916,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -943,10 +943,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -959,23 +962,29 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal.reason),\n+          enqueueFlush(request));\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -985,12 +994,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1352,38 +1359,37 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? haltTask(newTask, request)\n+        : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1872,16 +1878,11 @@ function retryTask(request, task) {\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n       if (12 === request.status)\n-        if (\n-          (request.abortableTasks.delete(task),\n-          (task.status = 3),\n-          21 === request.type)\n-        )\n-          request.pendingChunks--;\n-        else {\n-          var model = stringify(serializeByValueID(request.fatalError));\n-          emitModelChunk(request, task.id, model);\n-        }\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          21 === request.type\n+            ? haltTask(task, request)\n+            : abortTask(task, request, request.fatalError);\n       else {\n         var x =\n           thrownValue === SuspenseException\n@@ -1938,6 +1939,9 @@ function abortTask(task, request, errorId) {\n     (task = encodeReferenceChunk(request, task.id, errorId)),\n     request.completedErrorChunks.push(task));\n }\n+function haltTask(task, request) {\n+  5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -2010,8 +2014,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -2028,12 +2032,14 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       if (21 === request.type)\n         abortableTasks.forEach(function (task) {\n-          5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+          return haltTask(task, request);\n         });\n       else if (\n         \"object\" === typeof reason &&\n@@ -2069,30 +2075,10 @@ function abort(request, reason) {\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$28 =\n-        \"object\" === typeof reason &&\n-        null !== reason &&\n-        reason.$$typeof === REACT_POSTPONE_TYPE\n-          ? Error(\"The render was aborted due to being postponed.\")\n-          : void 0 === reason\n-            ? Error(\"The render was aborted by the server without a reason.\")\n-            : \"object\" === typeof reason &&\n-                null !== reason &&\n-                \"function\" === typeof reason.then\n-              ? Error(\"The render was aborted by the server with a promise.\")\n-              : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$28);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$29) {\n-    logRecoverableError(request, error$29, null), fatalError(request, error$29);\n+  } catch (error$28) {\n+    logRecoverableError(request, error$28, null), fatalError(request, error$28);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2537,19 +2523,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$32 = createPendingChunk(response);\n-        chunk$32.then(\n+        var chunk$31 = createPendingChunk(response);\n+        chunk$31.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$32;\n+        previousBlockedChunk = chunk$31;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$32 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$32, json, -1);\n+          previousBlockedChunk === chunk$31 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$31, json, -1);\n         });\n       }\n     },\n@@ -2934,13 +2920,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -2977,18 +2961,11 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var stream = new ReadableStream(\n           {\n             type: \"bytes\",\n-            start: function () {\n-              startWork(request);\n-            },\n             pull: function (controller) {\n               startFlowing(request, controller);\n             },\n@@ -3001,7 +2978,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n         );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "017065039da3fa3e5f2c565d1f4be6028d1260d8",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.node.development.js",
            "status": "modified",
            "additions": 395,
            "deletions": 159,
            "changes": 554,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -240,6 +240,14 @@\n       unresolvedNode.end = endTime;\n       return unresolvedNode;\n     }\n+    function getAsyncSequenceFromPromise(promise) {\n+      try {\n+        var asyncId = getAsyncId.call(promise);\n+      } catch (x) {}\n+      if (void 0 === asyncId) return null;\n+      promise = pendingOperations.get(asyncId);\n+      return void 0 === promise ? null : promise;\n+    }\n     function collectStackTrace(error, structuredStackTrace) {\n       for (\n         var result = [], i = framesToSkip;\n@@ -793,13 +801,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -824,7 +833,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -860,6 +868,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = this.timeOrigin = performance.now();\n       emitTimeOriginChunk(this, type + performance.timeOrigin);\n       model = createTask(\n@@ -883,21 +894,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -910,21 +923,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -954,6 +969,8 @@\n             ref\n           );\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -989,7 +1006,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -1028,11 +1045,9 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n               request.type === PRERENDER\n-                ? request.pendingChunks--\n-                : ((task = stringify(serializeByValueID(request.fatalError))),\n-                  emitModelChunk(request, newTask.id, task)),\n+                ? haltTask(newTask, request)\n+                : abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -1066,14 +1081,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(entry),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -1086,21 +1105,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1121,20 +1145,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(task);\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1150,10 +1173,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(endStreamRow);\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1166,23 +1192,29 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+            ? (haltTask(streamTask, request),\n+              request.abortableTasks.delete(streamTask))\n+            : (erroredTask(request, streamTask, signal.reason),\n+              enqueueFlush(request));\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1196,14 +1228,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(task);\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1737,7 +1767,8 @@\n                     owner: node.owner,\n                     stack: filterStackTrace(request, node.stack)\n                   }),\n-                  markOperationEndTime(request, task, endTime))\n+                  request.status !== ABORTING &&\n+                    markOperationEndTime(request, task, endTime))\n                 : (match = awaited);\n             }\n           }\n@@ -1778,7 +1809,8 @@\n             parseStackTrace(stack, 1)\n           )),\n         emitDebugChunk(request, task.id, alreadyForwardedDebugInfo),\n-        markOperationEndTime(request, task, node.end));\n+        request.status !== ABORTING &&\n+          markOperationEndTime(request, task, node.end));\n     }\n     function pingTask(request, task) {\n       task.timed = !0;\n@@ -1864,6 +1896,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -2013,32 +2055,38 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n           request.type === PRERENDER\n-            ? request.pendingChunks--\n-            : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-          reader.cancel(reason).then(error, error));\n+            ? haltTask(newTask, request)\n+            : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -2052,9 +2100,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2582,10 +2629,6 @@\n       id = encodeReferenceChunk(request, id, \"$S\" + name);\n       request.completedImportChunks.push(id);\n     }\n-    function emitModelChunk(request, id, json) {\n-      id = id.toString(16) + \":\" + json + \"\\n\";\n-      request.completedRegularChunks.push(id);\n-    }\n     function emitDebugHaltChunk(request, id) {\n       id = id.toString(16) + \":\\n\";\n       request.completedRegularChunks.push(id);\n@@ -2697,20 +2740,21 @@\n       filterStackFrame = void 0;\n       null !== promiseRef && (filterStackFrame = promiseRef.deref());\n       promiseRef = (0, request.environmentName)();\n+      i = 3 === ioNode.tag ? performance.now() : ioNode.end;\n       request.pendingChunks++;\n-      i = request.nextChunkId++;\n+      functionName = request.nextChunkId++;\n       emitIOInfoChunk(\n         request,\n-        i,\n+        functionName,\n         name,\n         ioNode.start,\n-        ioNode.end,\n+        i,\n         filterStackFrame,\n         promiseRef,\n         bestMatch,\n         existingRef\n       );\n-      existingRef = serializeByValueID(i);\n+      existingRef = serializeByValueID(functionName);\n       request.writtenDebugObjects.set(ioNode, existingRef);\n       return existingRef;\n     }\n@@ -2810,8 +2854,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2923,15 +2985,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -3125,13 +3192,7 @@\n       var debugInfo;\n       (debugInfo = thenable._debugInfo) &&\n         forwardDebugInfo(request, task, debugInfo);\n-      try {\n-        var asyncId = getAsyncId.call(thenable);\n-      } catch (x) {}\n-      void 0 === asyncId\n-        ? (thenable = null)\n-        : ((thenable = pendingOperations.get(asyncId)),\n-          (thenable = void 0 === thenable ? null : thenable));\n+      thenable = getAsyncSequenceFromPromise(thenable);\n       null !== thenable &&\n         emitAsyncSequence(request, task, thenable, debugInfo, owner, stack);\n     }\n@@ -3143,6 +3204,48 @@\n       null !== sequence &&\n         emitAsyncSequence(request, task, sequence, thenable, null, null);\n     }\n+    function forwardDebugInfoFromAbortedTask(request, task) {\n+      var model = task.model;\n+      if (\"object\" === typeof model && null !== model) {\n+        var debugInfo;\n+        (debugInfo = model._debugInfo) &&\n+          forwardDebugInfo(request, task, debugInfo);\n+        var thenable = null;\n+        if (\"function\" === typeof model.then) thenable = model;\n+        else if (model.$$typeof === REACT_LAZY_TYPE) {\n+          var payload = model._payload;\n+          model = model._init;\n+          try {\n+            model(payload);\n+          } catch (x) {\n+            \"object\" === typeof x &&\n+              null !== x &&\n+              \"function\" === typeof x.then &&\n+              (thenable = x);\n+          }\n+        }\n+        if (\n+          null !== thenable &&\n+          ((payload = getAsyncSequenceFromPromise(thenable)), null !== payload)\n+        ) {\n+          for (\n+            thenable = payload;\n+            4 === thenable.tag && null !== thenable.awaited;\n+\n+          )\n+            thenable = thenable.awaited;\n+          3 === thenable.tag\n+            ? (serializeIONode(request, thenable, null),\n+              request.pendingChunks++,\n+              (debugInfo = (0, request.environmentName)()),\n+              emitDebugChunk(request, task.id, {\n+                awaited: thenable,\n+                env: debugInfo\n+              }))\n+            : emitAsyncSequence(request, task, payload, debugInfo, null, null);\n+        }\n+      }\n+    }\n     function emitTimingChunk(request, id, timestamp) {\n       request.pendingChunks++;\n       timestamp -= request.timeOrigin;\n@@ -3195,7 +3298,12 @@\n                                 : value instanceof DataView\n                                   ? emitTypedArrayChunk(request, id, \"V\", value)\n                                   : ((value = stringify(value, task.toJSON)),\n-                                    emitModelChunk(request, task.id, value));\n+                                    (task =\n+                                      task.id.toString(16) +\n+                                      \":\" +\n+                                      value +\n+                                      \"\\n\"),\n+                                    request.completedRegularChunks.push(task));\n     }\n     function erroredTask(request, task, error) {\n       task.timed && markOperationEndTime(request, task, performance.now());\n@@ -3245,24 +3353,20 @@\n             ),\n               emitChunk(request, task, resolvedModel);\n           else {\n-            var json = stringify(resolvedModel);\n-            emitModelChunk(request, task.id, json);\n+            var json = stringify(resolvedModel),\n+              processedChunk = task.id.toString(16) + \":\" + json + \"\\n\";\n+            request.completedRegularChunks.push(processedChunk);\n           }\n           task.status = COMPLETED;\n           request.abortableTasks.delete(task);\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n           if (request.status === ABORTING)\n-            if (\n-              (request.abortableTasks.delete(task),\n-              (task.status = ABORTED),\n-              request.type === PRERENDER)\n-            )\n-              request.pendingChunks--;\n-            else {\n-              var model = stringify(serializeByValueID(request.fatalError));\n-              emitModelChunk(request, task.id, model);\n-            }\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              request.type === PRERENDER\n+                ? haltTask(task, request)\n+                : abortTask(task, request, request.fatalError);\n           else {\n             var x =\n               thrownValue === SuspenseException\n@@ -3320,11 +3424,18 @@\n     function abortTask(task, request, errorId) {\n       task.status !== RENDERING &&\n         ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n         task.timed && markOperationEndTime(request, task, performance.now()),\n         (errorId = serializeByValueID(errorId)),\n         (task = encodeReferenceChunk(request, task.id, errorId)),\n         request.completedErrorChunks.push(task));\n     }\n+    function haltTask(task, request) {\n+      task.status !== RENDERING &&\n+        ((task.status = ABORTED),\n+        forwardDebugInfoFromAbortedTask(request, task),\n+        request.pendingChunks--);\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -3417,11 +3528,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -3438,13 +3546,14 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           if (request.type === PRERENDER)\n             abortableTasks.forEach(function (task) {\n-              task.status !== RENDERING &&\n-                ((task.status = ABORTED), request.pendingChunks--);\n+              return haltTask(task, request);\n             });\n           else if (\n             \"object\" === typeof reason &&\n@@ -3484,37 +3593,68 @@\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            \"object\" === typeof reason &&\n-            null !== reason &&\n-            reason.$$typeof === REACT_POSTPONE_TYPE\n-              ? Error(\"The render was aborted due to being postponed.\")\n-              : void 0 === reason\n-                ? Error(\n-                    \"The render was aborted by the server without a reason.\"\n-                  )\n-                : \"object\" === typeof reason &&\n-                    null !== reason &&\n-                    \"function\" === typeof reason.then\n-                  ? Error(\n-                      \"The render was aborted by the server with a promise.\"\n-                    )\n-                  : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function resolveDebugMessage(request, message) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      var command = message.charCodeAt(0);\n+      message = message.slice(2).split(\",\").map(fromHex);\n+      switch (command) {\n+        case 82:\n+          for (command = 0; command < message.length; command++) {\n+            var id = message[command],\n+              retainedValue = deferredDebugObjects.retained.get(id);\n+            void 0 !== retainedValue &&\n+              (request.pendingChunks--,\n+              deferredDebugObjects.retained.delete(id),\n+              deferredDebugObjects.existing.delete(retainedValue),\n+              enqueueFlush(request));\n+          }\n+          break;\n+        case 81:\n+          for (command = 0; command < message.length; command++)\n+            (id = message[command]),\n+              (retainedValue = deferredDebugObjects.retained.get(id)),\n+              void 0 !== retainedValue &&\n+                (emitOutlinedDebugModelChunk(\n+                  request,\n+                  id,\n+                  { objectLimit: 10 },\n+                  retainedValue\n+                ),\n+                enqueueFlush(request));\n+          break;\n+        default:\n+          throw Error(\n+            \"Unknown command. The debugChannel was not wired up properly.\"\n+          );\n+      }\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -4275,6 +4415,57 @@\n         abort(request, Error(reason));\n       };\n     }\n+    function startReadingFromDebugChannelReadable(request, stream) {\n+      function onData(chunk) {\n+        if (\"string\" === typeof chunk) {\n+          if (lastWasPartial) {\n+            var JSCompiler_temp_const = stringBuffer;\n+            var JSCompiler_inline_result = new Uint8Array(0);\n+            JSCompiler_inline_result = stringDecoder.decode(\n+              JSCompiler_inline_result\n+            );\n+            stringBuffer = JSCompiler_temp_const + JSCompiler_inline_result;\n+            lastWasPartial = !1;\n+          }\n+          stringBuffer += chunk;\n+        } else\n+          (stringBuffer += stringDecoder.decode(chunk, decoderOptions)),\n+            (lastWasPartial = !0);\n+        chunk = stringBuffer.split(\"\\n\");\n+        for (\n+          JSCompiler_temp_const = 0;\n+          JSCompiler_temp_const < chunk.length - 1;\n+          JSCompiler_temp_const++\n+        )\n+          resolveDebugMessage(request, chunk[JSCompiler_temp_const]);\n+        stringBuffer = chunk[chunk.length - 1];\n+      }\n+      function onError(error) {\n+        abort(\n+          request,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: error })\n+        );\n+      }\n+      function onClose() {\n+        closeDebugChannel(request);\n+      }\n+      var stringDecoder = new util.TextDecoder(),\n+        lastWasPartial = !1,\n+        stringBuffer = \"\";\n+      \"function\" === typeof stream.addEventListener &&\n+      \"string\" === typeof stream.binaryType\n+        ? ((stream.binaryType = \"arraybuffer\"),\n+          stream.addEventListener(\"message\", function (event) {\n+            onData(event.data);\n+          }),\n+          stream.addEventListener(\"error\", function (event) {\n+            onError(event.error);\n+          }),\n+          stream.addEventListener(\"close\", onClose))\n+        : (stream.on(\"data\", onData),\n+          stream.on(\"error\", onError),\n+          stream.on(\"end\", onClose));\n+    }\n     function createFakeWritableFromReadableStreamController(controller) {\n       return {\n         write: function (chunk) {\n@@ -4292,6 +4483,34 @@\n         }\n       };\n     }\n+    function startReadingFromDebugChannelReadableStream(request, stream) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++)\n+          resolveDebugMessage(request, _ref[buffer]);\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new util.TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     function createFakeWritableFromNodeReadable(readable) {\n       return {\n         write: function (chunk) {\n@@ -4908,6 +5127,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -5047,20 +5267,20 @@\n           ? queuedFields.push(name, value)\n           : resolveField(response, name, value);\n       });\n-      busboyStream.on(\"file\", function (name, value, _ref) {\n-        var filename = _ref.filename,\n-          mimeType = _ref.mimeType;\n-        if (\"base64\" === _ref.encoding.toLowerCase())\n+      busboyStream.on(\"file\", function (name, value, _ref2) {\n+        var filename = _ref2.filename,\n+          mimeType = _ref2.mimeType;\n+        if (\"base64\" === _ref2.encoding.toLowerCase())\n           throw Error(\n             \"React doesn't accept base64 encoded file uploads because we don't expect form data passed from a browser to ever encode data that way. If that's the wrong assumption, we can easily fix it.\"\n           );\n         pendingFiles++;\n-        var JSCompiler_object_inline_chunks_201 = [];\n+        var JSCompiler_object_inline_chunks_202 = [];\n         value.on(\"data\", function (chunk) {\n-          JSCompiler_object_inline_chunks_201.push(chunk);\n+          JSCompiler_object_inline_chunks_202.push(chunk);\n         });\n         value.on(\"end\", function () {\n-          var blob = new Blob(JSCompiler_object_inline_chunks_201, {\n+          var blob = new Blob(JSCompiler_object_inline_chunks_202, {\n             type: mimeType\n           });\n           response._formData.append(name, blob, filename);\n@@ -5108,18 +5328,22 @@\n       });\n     };\n     exports.renderToPipeableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n+      var debugChannel = options ? options.debugChannel : void 0,\n+        request = createRequest(\n           model,\n           turbopackMap,\n           options ? options.onError : void 0,\n           options ? options.identifierPrefix : void 0,\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannel\n         ),\n         hasStartedFlowing = !1;\n       startWork(request);\n+      void 0 !== debugChannel &&\n+        startReadingFromDebugChannelReadable(request, debugChannel);\n       return {\n         pipe: function (destination) {\n           if (hasStartedFlowing)\n@@ -5148,16 +5372,21 @@\n       };\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -5169,6 +5398,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       var writable;\n       return new ReadableStream(\n         {\n@@ -5223,7 +5457,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;\n@@ -5263,7 +5498,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "7ac89049515c947080c5f0f124bfb0fdce84313e",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/cjs/react-server-dom-turbopack-server.node.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 143,
            "changes": 263,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -768,23 +768,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var cleanupQueue = [];\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    cleanupQueue = [];\n   TaintRegistryPendingRequests.add(cleanupQueue);\n   var hints = new Set();\n   this.type = type;\n@@ -796,9 +794,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -815,8 +812,8 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function resolveRequest() {\n@@ -827,7 +824,7 @@ function resolveRequest() {\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -843,11 +840,9 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n           21 === request.type\n-            ? request.pendingChunks--\n-            : ((task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task)),\n+            ? haltTask(newTask, request)\n+            : abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -878,14 +873,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(entry),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -898,21 +897,23 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -929,19 +930,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(task);\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -957,10 +957,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(endStreamRow);\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -973,23 +976,29 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, streamTask, reason), enqueueFlush(request)),\n+        ? (haltTask(streamTask, request),\n+          request.abortableTasks.delete(streamTask))\n+        : (erroredTask(request, streamTask, signal.reason),\n+          enqueueFlush(request));\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -999,12 +1008,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(task);\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1363,38 +1370,37 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n       21 === request.type\n-        ? request.pendingChunks--\n-        : (erroredTask(request, newTask, reason), enqueueFlush(request)),\n-      reader.cancel(reason).then(error, error));\n+        ? haltTask(newTask, request)\n+        : (erroredTask(request, newTask, signal), enqueueFlush(request));\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1756,10 +1762,6 @@ function emitErrorChunk(request, id, digest) {\n   id = id.toString(16) + \":E\" + stringify(digest) + \"\\n\";\n   request.completedErrorChunks.push(id);\n }\n-function emitModelChunk(request, id, json) {\n-  id = id.toString(16) + \":\" + json + \"\\n\";\n-  request.completedRegularChunks.push(id);\n-}\n function emitTypedArrayChunk(request, id, tag, typedArray) {\n   if (TaintRegistryByteLengths.has(typedArray.byteLength)) {\n     var tainted = TaintRegistryValues.get(\n@@ -1827,7 +1829,9 @@ function emitChunk(request, task, value) {\n                             : value instanceof DataView\n                               ? emitTypedArrayChunk(request, id, \"V\", value)\n                               : ((value = stringify(value, task.toJSON)),\n-                                emitModelChunk(request, task.id, value));\n+                                (task =\n+                                  task.id.toString(16) + \":\" + value + \"\\n\"),\n+                                request.completedRegularChunks.push(task));\n }\n function erroredTask(request, task, error) {\n   task.status = 4;\n@@ -1862,24 +1866,20 @@ function retryTask(request, task) {\n         request.writtenObjects.set(resolvedModel, serializeByValueID(task.id)),\n           emitChunk(request, task, resolvedModel);\n       else {\n-        var json = stringify(resolvedModel);\n-        emitModelChunk(request, task.id, json);\n+        var json = stringify(resolvedModel),\n+          processedChunk = task.id.toString(16) + \":\" + json + \"\\n\";\n+        request.completedRegularChunks.push(processedChunk);\n       }\n       task.status = 1;\n       request.abortableTasks.delete(task);\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n       if (12 === request.status)\n-        if (\n-          (request.abortableTasks.delete(task),\n-          (task.status = 3),\n-          21 === request.type)\n-        )\n-          request.pendingChunks--;\n-        else {\n-          var model = stringify(serializeByValueID(request.fatalError));\n-          emitModelChunk(request, task.id, model);\n-        }\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          21 === request.type\n+            ? haltTask(task, request)\n+            : abortTask(task, request, request.fatalError);\n       else {\n         var x =\n           thrownValue === SuspenseException\n@@ -1936,6 +1936,9 @@ function abortTask(task, request, errorId) {\n     (task = encodeReferenceChunk(request, task.id, errorId)),\n     request.completedErrorChunks.push(task));\n }\n+function haltTask(task, request) {\n+  5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -2028,8 +2031,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -2046,12 +2049,14 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       if (21 === request.type)\n         abortableTasks.forEach(function (task) {\n-          5 !== task.status && ((task.status = 3), request.pendingChunks--);\n+          return haltTask(task, request);\n         });\n       else if (\n         \"object\" === typeof reason &&\n@@ -2087,30 +2092,10 @@ function abort(request, reason) {\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$28 =\n-        \"object\" === typeof reason &&\n-        null !== reason &&\n-        reason.$$typeof === REACT_POSTPONE_TYPE\n-          ? Error(\"The render was aborted due to being postponed.\")\n-          : void 0 === reason\n-            ? Error(\"The render was aborted by the server without a reason.\")\n-            : \"object\" === typeof reason &&\n-                null !== reason &&\n-                \"function\" === typeof reason.then\n-              ? Error(\"The render was aborted by the server with a promise.\")\n-              : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$28);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$29) {\n-    logRecoverableError(request, error$29, null), fatalError(request, error$29);\n+  } catch (error$28) {\n+    logRecoverableError(request, error$28, null), fatalError(request, error$28);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2555,19 +2540,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$32 = createPendingChunk(response);\n-        chunk$32.then(\n+        var chunk$31 = createPendingChunk(response);\n+        chunk$31.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$32;\n+        previousBlockedChunk = chunk$31;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$32 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$32, json, -1);\n+          previousBlockedChunk === chunk$31 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$31, json, -1);\n         });\n       }\n     },\n@@ -2980,20 +2965,20 @@ exports.decodeReplyFromBusboy = function (busboyStream, turbopackMap, options) {\n       ? queuedFields.push(name, value)\n       : resolveField(response, name, value);\n   });\n-  busboyStream.on(\"file\", function (name, value, _ref) {\n-    var filename = _ref.filename,\n-      mimeType = _ref.mimeType;\n-    if (\"base64\" === _ref.encoding.toLowerCase())\n+  busboyStream.on(\"file\", function (name, value, _ref2) {\n+    var filename = _ref2.filename,\n+      mimeType = _ref2.mimeType;\n+    if (\"base64\" === _ref2.encoding.toLowerCase())\n       throw Error(\n         \"React doesn't accept base64 encoded file uploads because we don't expect form data passed from a browser to ever encode data that way. If that's the wrong assumption, we can easily fix it.\"\n       );\n     pendingFiles++;\n-    var JSCompiler_object_inline_chunks_259 = [];\n+    var JSCompiler_object_inline_chunks_254 = [];\n     value.on(\"data\", function (chunk) {\n-      JSCompiler_object_inline_chunks_259.push(chunk);\n+      JSCompiler_object_inline_chunks_254.push(chunk);\n     });\n     value.on(\"end\", function () {\n-      var blob = new Blob(JSCompiler_object_inline_chunks_259, {\n+      var blob = new Blob(JSCompiler_object_inline_chunks_254, {\n         type: mimeType\n       });\n       response._formData.append(name, blob, filename);\n@@ -3041,13 +3026,11 @@ exports.renderToPipeableStream = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       noop,\n-      noop\n+      noop,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     ),\n     hasStartedFlowing = !1;\n   startWork(request);\n@@ -3084,13 +3067,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -3129,11 +3110,7 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var writable,\n           stream = new ReadableStream(\n@@ -3155,7 +3132,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n           );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;\n@@ -3182,11 +3161,7 @@ exports.unstable_prerenderToNodeStream = function (\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var readable = new stream.Readable({\n             read: function () {\n@@ -3196,7 +3171,9 @@ exports.unstable_prerenderToNodeStream = function (\n           writable = createFakeWritableFromNodeReadable(readable);\n         resolve({ prelude: readable });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "87c8bc997b0071a348cbb7ce34e0176905a74807",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack-experimental/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack-experimental%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -48,7 +48,7 @@\n     \"neo-async\": \"^2.6.1\"\n   },\n   \"peerDependencies\": {\n-    \"react\": \"0.0.0-experimental-fa3feba6-20250623\",\n-    \"react-dom\": \"0.0.0-experimental-fa3feba6-20250623\"\n+    \"react\": \"0.0.0-experimental-cee7939b-20250625\",\n+    \"react-dom\": \"0.0.0-experimental-cee7939b-20250625\"\n   }\n }\n\\ No newline at end of file"
        },
        {
            "sha": "8a450de48c47f72d4d83d4d09a2dc36887a05dbe",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.browser.development.js",
            "status": "modified",
            "additions": 105,
            "deletions": 85,
            "changes": 190,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -905,11 +905,10 @@\n         }\n       return null;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._debugInfo = null;\n     }\n     function readChunk(chunk) {\n@@ -931,8 +930,8 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -978,25 +977,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1016,12 +1016,13 @@\n     function initializeModelChunk(chunk) {\n       var prevHandler = initializingHandler;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1058,6 +1059,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n     }\n     function nullRefGetter() {\n       return null;\n@@ -1093,8 +1097,8 @@\n         chunk = chunks.get(id);\n       chunk ||\n         ((chunk = response._closed\n-          ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-          : createPendingChunk(response)),\n+          ? new ReactPromise(\"rejected\", null, response._closedReason)\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -1544,6 +1548,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -1577,7 +1584,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -1607,43 +1615,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -1653,14 +1659,14 @@\n         response._bundlerConfig,\n         model\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -1673,28 +1679,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -1715,12 +1713,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -1735,7 +1728,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -1747,7 +1740,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -1798,10 +1791,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -1816,8 +1808,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -1841,7 +1832,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -1852,9 +1848,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -1864,7 +1866,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2138,15 +2140,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2339,14 +2346,14 @@\n           var chunk = row.get(id);\n           chunk\n             ? triggerErrorOnChunk(chunk, tag)\n-            : row.set(id, new ReactPromise(\"rejected\", null, tag, response));\n+            : row.set(id, new ReactPromise(\"rejected\", null, tag));\n           break;\n         case 84:\n           resolveText(response, id, row);\n           break;\n         case 78:\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -2461,12 +2468,7 @@\n               ? ((stack = initializingHandler),\n                 (initializingHandler = stack.parent),\n                 stack.errored\n-                  ? ((key = new ReactPromise(\n-                      \"rejected\",\n-                      null,\n-                      stack.value,\n-                      response\n-                    )),\n+                  ? ((key = new ReactPromise(\"rejected\", null, stack.value)),\n                     (stack = {\n                       name: getComponentNameFromType(value.type) || \"\",\n                       owner: value._owner\n@@ -2476,7 +2478,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -2489,7 +2491,24 @@\n         return value;\n       };\n     }\n+    function createDebugCallbackFromWritableStream(debugWritable) {\n+      var textEncoder = new TextEncoder(),\n+        writer = debugWritable.getWriter();\n+      return function (message) {\n+        \"\" === message\n+          ? writer.close()\n+          : writer\n+              .write(textEncoder.encode(message + \"\\n\"))\n+              .catch(console.error);\n+      };\n+    }\n     function createResponseFromOptions(options) {\n+      var debugChannel =\n+        options &&\n+        void 0 !== options.debugChannel &&\n+        void 0 !== options.debugChannel.writable\n+          ? createDebugCallbackFromWritableStream(options.debugChannel.writable)\n+          : void 0;\n       return new ResponseInstance(\n         null,\n         null,\n@@ -2502,7 +2521,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !1 !== options.replayConsoleLogs : !0,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        debugChannel\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -2785,10 +2805,10 @@\n       return hook.checkDCE ? !0 : !1;\n     })({\n       bundleType: 1,\n-      version: \"19.2.0-canary-fa3feba6-20250623\",\n+      version: \"19.2.0-canary-cee7939b-20250625\",\n       rendererPackageName: \"react-server-dom-turbopack\",\n       currentDispatcherRef: ReactSharedInternals,\n-      reconcilerVersion: \"19.2.0-canary-fa3feba6-20250623\",\n+      reconcilerVersion: \"19.2.0-canary-cee7939b-20250625\",\n       getCurrentComponentInfo: function () {\n         return currentOwnerInDEV;\n       }"
        },
        {
            "sha": "a7077d519fdff18d2794b9b94dabd00717c591b2",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.browser.production.js",
            "status": "modified",
            "additions": 62,
            "deletions": 66,
            "changes": 128,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -518,11 +518,10 @@ function createBoundServerReference(metaData, callServer) {\n   registerBoundServerReference(action, id, bound);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -569,9 +568,6 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n }\n@@ -614,23 +610,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -651,12 +648,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -702,8 +700,8 @@ function getChunk(response, id) {\n     chunk = chunks.get(id);\n   chunk ||\n     ((chunk = response._closed\n-      ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-      : createPendingChunk(response)),\n+      ? new ReactPromise(\"rejected\", null, response._closedReason)\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1047,25 +1045,25 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n     chunk = chunks.get(id);\n   model = JSON.parse(model, response._fromJSON);\n   var clientReference = resolveClientReference(response._bundlerConfig, model);\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1078,23 +1076,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1115,7 +1110,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1130,7 +1125,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1142,7 +1137,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1193,10 +1188,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1211,8 +1205,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1232,7 +1225,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1243,9 +1241,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1255,7 +1259,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1409,16 +1413,16 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       tag = JSON.parse(buffer);\n       buffer = resolveErrorProd();\n       buffer.digest = tag.digest;\n-      tag = response._chunks;\n-      (chunk = tag.get(id))\n-        ? triggerErrorOnChunk(chunk, buffer)\n-        : tag.set(id, new ReactPromise(\"rejected\", null, buffer, response));\n+      response = response._chunks;\n+      (tag = response.get(id))\n+        ? triggerErrorOnChunk(tag, buffer)\n+        : response.set(id, new ReactPromise(\"rejected\", null, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1440,18 +1444,15 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       startAsyncIterable(response, id, !0);\n       break;\n     case 67:\n-      (response = response._chunks.get(id)) &&\n-        \"fulfilled\" === response.status &&\n-        response.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n+      (id = response._chunks.get(id)) &&\n+        \"fulfilled\" === id.status &&\n+        id.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n       break;\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1475,15 +1476,10 @@ function createFromJSONCallback(response) {\n             (initializingHandler = value.parent),\n             value.errored)\n           )\n-            (key = new ReactPromise(\"rejected\", null, value.value, response)),\n+            (key = new ReactPromise(\"rejected\", null, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "56bb5c9957a0ac921c90dbbbe82dfa76700cb4c2",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.edge.development.js",
            "status": "modified",
            "additions": 86,
            "deletions": 83,
            "changes": 169,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1117,11 +1117,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._debugInfo = null;\n     }\n     function readChunk(chunk) {\n@@ -1143,8 +1142,8 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1190,25 +1189,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1228,12 +1228,13 @@\n     function initializeModelChunk(chunk) {\n       var prevHandler = initializingHandler;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1270,6 +1271,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n     }\n     function nullRefGetter() {\n       return null;\n@@ -1305,8 +1309,8 @@\n         chunk = chunks.get(id);\n       chunk ||\n         ((chunk = response._closed\n-          ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-          : createPendingChunk(response)),\n+          ? new ReactPromise(\"rejected\", null, response._closedReason)\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -1763,6 +1767,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -1796,7 +1803,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -1826,43 +1834,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -1877,14 +1883,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -1897,28 +1903,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -1939,12 +1937,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -1959,7 +1952,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -1971,7 +1964,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2022,10 +2015,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2040,8 +2032,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2065,7 +2056,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2076,9 +2072,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2088,7 +2090,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2362,15 +2364,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2563,14 +2570,14 @@\n           var chunk = row.get(id);\n           chunk\n             ? triggerErrorOnChunk(chunk, tag)\n-            : row.set(id, new ReactPromise(\"rejected\", null, tag, response));\n+            : row.set(id, new ReactPromise(\"rejected\", null, tag));\n           break;\n         case 84:\n           resolveText(response, id, row);\n           break;\n         case 78:\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -2685,12 +2692,7 @@\n               ? ((stack = initializingHandler),\n                 (initializingHandler = stack.parent),\n                 stack.errored\n-                  ? ((key = new ReactPromise(\n-                      \"rejected\",\n-                      null,\n-                      stack.value,\n-                      response\n-                    )),\n+                  ? ((key = new ReactPromise(\"rejected\", null, stack.value)),\n                     (stack = {\n                       name: getComponentNameFromType(value.type) || \"\",\n                       owner: value._owner\n@@ -2700,7 +2702,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -2731,7 +2733,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {"
        },
        {
            "sha": "66fd9041294a372812f2a08436a9c6a847b6680c",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.edge.production.js",
            "status": "modified",
            "additions": 62,
            "deletions": 66,
            "changes": 128,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -688,11 +688,10 @@ function createServerReference$1(id, callServer, encodeFormAction) {\n   registerBoundServerReference(action, id, null, encodeFormAction);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -739,9 +738,6 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n }\n@@ -784,23 +780,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -821,12 +818,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -872,8 +870,8 @@ function getChunk(response, id) {\n     chunk = chunks.get(id);\n   chunk ||\n     ((chunk = response._closed\n-      ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-      : createPendingChunk(response)),\n+      ? new ReactPromise(\"rejected\", null, response._closedReason)\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1232,11 +1230,11 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n@@ -1248,14 +1246,14 @@ function resolveModule(response, id, model) {\n     model[1],\n     response._nonce\n   );\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1268,23 +1266,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1305,7 +1300,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1320,7 +1315,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1332,7 +1327,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1383,10 +1378,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1401,8 +1395,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1422,7 +1415,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1433,9 +1431,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1445,7 +1449,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1599,16 +1603,16 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       tag = JSON.parse(buffer);\n       buffer = resolveErrorProd();\n       buffer.digest = tag.digest;\n-      tag = response._chunks;\n-      (chunk = tag.get(id))\n-        ? triggerErrorOnChunk(chunk, buffer)\n-        : tag.set(id, new ReactPromise(\"rejected\", null, buffer, response));\n+      response = response._chunks;\n+      (tag = response.get(id))\n+        ? triggerErrorOnChunk(tag, buffer)\n+        : response.set(id, new ReactPromise(\"rejected\", null, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1630,18 +1634,15 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       startAsyncIterable(response, id, !0);\n       break;\n     case 67:\n-      (response = response._chunks.get(id)) &&\n-        \"fulfilled\" === response.status &&\n-        response.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n+      (id = response._chunks.get(id)) &&\n+        \"fulfilled\" === id.status &&\n+        id.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n       break;\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1665,15 +1666,10 @@ function createFromJSONCallback(response) {\n             (initializingHandler = value.parent),\n             value.errored)\n           )\n-            (key = new ReactPromise(\"rejected\", null, value.value, response)),\n+            (key = new ReactPromise(\"rejected\", null, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "1460a0aaa60c2bee59089c43f4d1569e350d997d",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.node.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 84,
            "changes": 172,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1117,11 +1117,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._debugInfo = null;\n     }\n     function readChunk(chunk) {\n@@ -1143,8 +1142,8 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1190,25 +1189,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1228,12 +1228,13 @@\n     function initializeModelChunk(chunk) {\n       var prevHandler = initializingHandler;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1270,6 +1271,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n     }\n     function nullRefGetter() {\n       return null;\n@@ -1305,8 +1309,8 @@\n         chunk = chunks.get(id);\n       chunk ||\n         ((chunk = response._closed\n-          ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-          : createPendingChunk(response)),\n+          ? new ReactPromise(\"rejected\", null, response._closedReason)\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -1763,6 +1767,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -1796,7 +1803,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -1826,43 +1834,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -1877,14 +1883,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -1897,28 +1903,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -1939,12 +1937,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -1959,7 +1952,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -1971,7 +1964,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2022,10 +2015,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2040,8 +2032,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2065,7 +2056,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2076,9 +2072,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2088,7 +2090,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2362,15 +2364,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2563,14 +2570,14 @@\n           var chunk = row.get(id);\n           chunk\n             ? triggerErrorOnChunk(chunk, tag)\n-            : row.set(id, new ReactPromise(\"rejected\", null, tag, response));\n+            : row.set(id, new ReactPromise(\"rejected\", null, tag));\n           break;\n         case 84:\n           resolveText(response, id, row);\n           break;\n         case 78:\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -2764,12 +2771,7 @@\n               ? ((stack = initializingHandler),\n                 (initializingHandler = stack.parent),\n                 stack.errored\n-                  ? ((key = new ReactPromise(\n-                      \"rejected\",\n-                      null,\n-                      stack.value,\n-                      response\n-                    )),\n+                  ? ((key = new ReactPromise(\"rejected\", null, stack.value)),\n                     (stack = {\n                       name: getComponentNameFromType(value.type) || \"\",\n                       owner: value._owner\n@@ -2779,7 +2781,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -2813,7 +2815,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -3039,7 +3042,8 @@\n         void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n       stream.on(\"data\", function (chunk) {\n         processBinaryChunk(response, chunk);"
        },
        {
            "sha": "e53bd49e858ac4014319481e4dd21ffec3f7c478",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-client.node.production.js",
            "status": "modified",
            "additions": 62,
            "deletions": 66,
            "changes": 128,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-client.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -689,11 +689,10 @@ function createServerReference$1(id, callServer, encodeFormAction) {\n   registerBoundServerReference(action, id, null, encodeFormAction);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -740,9 +739,6 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n }\n@@ -785,23 +781,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -822,12 +819,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -873,8 +871,8 @@ function getChunk(response, id) {\n     chunk = chunks.get(id);\n   chunk ||\n     ((chunk = response._closed\n-      ? new ReactPromise(\"rejected\", null, response._closedReason, response)\n-      : createPendingChunk(response)),\n+      ? new ReactPromise(\"rejected\", null, response._closedReason)\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1233,11 +1231,11 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n@@ -1249,14 +1247,14 @@ function resolveModule(response, id, model) {\n     model[1],\n     response._nonce\n   );\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1269,23 +1267,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1306,7 +1301,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1321,7 +1316,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1333,7 +1328,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1384,10 +1379,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1402,8 +1396,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1423,7 +1416,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1434,9 +1432,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1446,7 +1450,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1600,16 +1604,16 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       tag = JSON.parse(buffer);\n       buffer = resolveErrorProd();\n       buffer.digest = tag.digest;\n-      tag = response._chunks;\n-      (chunk = tag.get(id))\n-        ? triggerErrorOnChunk(chunk, buffer)\n-        : tag.set(id, new ReactPromise(\"rejected\", null, buffer, response));\n+      response = response._chunks;\n+      (tag = response.get(id))\n+        ? triggerErrorOnChunk(tag, buffer)\n+        : response.set(id, new ReactPromise(\"rejected\", null, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1631,18 +1635,15 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n       startAsyncIterable(response, id, !0);\n       break;\n     case 67:\n-      (response = response._chunks.get(id)) &&\n-        \"fulfilled\" === response.status &&\n-        response.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n+      (id = response._chunks.get(id)) &&\n+        \"fulfilled\" === id.status &&\n+        id.reason.close(\"\" === buffer ? '\"$undefined\"' : buffer);\n       break;\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function processBinaryChunk(response, chunk) {\n@@ -1744,15 +1745,10 @@ function createFromJSONCallback(response) {\n             (initializingHandler = value.parent),\n             value.errored)\n           )\n-            (key = new ReactPromise(\"rejected\", null, value.value, response)),\n+            (key = new ReactPromise(\"rejected\", null, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "f64b98b0dcac3382fb5d5aae048cde6b307c5fa4",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.browser.development.js",
            "status": "modified",
            "additions": 265,
            "deletions": 123,
            "changes": 388,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -737,13 +737,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -766,7 +767,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -802,6 +802,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = createTask(this, model, null, !1, abortSet, 0, null, null, null);\n       pingedTasks.push(type);\n     }\n@@ -813,21 +816,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -840,21 +845,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -874,6 +881,8 @@\n         case \"rejected\":\n           return emitErrorChunk(request, id, \"\", thenable.reason), ref;\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -905,7 +914,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -932,9 +941,7 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n-              (task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task),\n+              abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -966,14 +973,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(stringToChunk(entry)),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -986,20 +997,24 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n+          erroredTask(request, streamTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1020,20 +1035,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1049,10 +1063,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1065,22 +1082,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n+          erroredTask(request, streamTask, signal.reason);\n+          enqueueFlush(request);\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1094,14 +1115,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1609,6 +1628,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -1760,31 +1789,37 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n-          erroredTask(request, newTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n+          erroredTask(request, newTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -1798,9 +1833,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2398,8 +2432,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2511,15 +2563,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -2797,12 +2854,11 @@\n           request.abortableTasks.delete(task);\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n-          if (request.status === ABORTING) {\n-            request.abortableTasks.delete(task);\n-            task.status = ABORTED;\n-            var model = stringify(serializeByValueID(request.fatalError));\n-            emitModelChunk(request, task.id, model);\n-          } else {\n+          if (request.status === ABORTING)\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              abortTask(task, request, request.fatalError);\n+          else {\n             var x =\n               thrownValue === SuspenseException\n                 ? getSuspendedThenable()\n@@ -2855,6 +2911,19 @@\n           (currentRequest = prevRequest);\n       }\n     }\n+    function abortTask(task, request, errorId) {\n+      if (task.status !== RENDERING) {\n+        task.status = ABORTED;\n+        var model = task.model;\n+        \"object\" === typeof model &&\n+          null !== model &&\n+          (model = model._debugInfo) &&\n+          forwardDebugInfo(request, task, model);\n+        errorId = serializeByValueID(errorId);\n+        task = encodeReferenceChunk(request, task.id, errorId);\n+        request.completedErrorChunks.push(task);\n+      }\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -2945,11 +3014,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -2967,7 +3033,9 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           var error =\n@@ -2988,39 +3056,34 @@\n           request.pendingChunks++;\n           emitErrorChunk(request, _errorId2, digest, error);\n           abortableTasks.forEach(function (task) {\n-            if (task.status !== RENDERING) {\n-              task.status = ABORTED;\n-              var ref = serializeByValueID(_errorId2);\n-              task = encodeReferenceChunk(request, task.id, ref);\n-              request.completedErrorChunks.push(task);\n-            }\n+            return abortTask(task, request, _errorId2);\n           });\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            void 0 === reason\n-              ? Error(\"The render was aborted by the server without a reason.\")\n-              : \"object\" === typeof reason &&\n-                  null !== reason &&\n-                  \"function\" === typeof reason.then\n-                ? Error(\"The render was aborted by the server with a promise.\")\n-                : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -3762,6 +3825,76 @@\n       if (\"fulfilled\" !== body.status) throw body.reason;\n       return body.value;\n     }\n+    function startReadingFromDebugChannelReadableStream(\n+      request$jscomp$0,\n+      stream\n+    ) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++) {\n+          var request = request$jscomp$0,\n+            message = _ref[buffer],\n+            deferredDebugObjects = request.deferredDebugObjects;\n+          if (null === deferredDebugObjects)\n+            throw Error(\n+              \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+            );\n+          var command = message.charCodeAt(0);\n+          message = message.slice(2).split(\",\").map(fromHex);\n+          switch (command) {\n+            case 82:\n+              for (command = 0; command < message.length; command++) {\n+                var id = message[command],\n+                  retainedValue = deferredDebugObjects.retained.get(id);\n+                void 0 !== retainedValue &&\n+                  (request.pendingChunks--,\n+                  deferredDebugObjects.retained.delete(id),\n+                  deferredDebugObjects.existing.delete(retainedValue),\n+                  enqueueFlush(request));\n+              }\n+              break;\n+            case 81:\n+              for (command = 0; command < message.length; command++)\n+                (id = message[command]),\n+                  (retainedValue = deferredDebugObjects.retained.get(id)),\n+                  void 0 !== retainedValue &&\n+                    (emitOutlinedDebugModelChunk(\n+                      request,\n+                      id,\n+                      { objectLimit: 10 },\n+                      retainedValue\n+                    ),\n+                    enqueueFlush(request));\n+              break;\n+            default:\n+              throw Error(\n+                \"Unknown command. The debugChannel was not wired up properly.\"\n+              );\n+          }\n+        }\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request$jscomp$0);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request$jscomp$0,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     var ReactDOM = require(\"react-dom\"),\n       React = require(\"react\"),\n       channel = new MessageChannel(),\n@@ -4227,6 +4360,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -4342,16 +4476,21 @@\n       });\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -4363,6 +4502,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       return new ReadableStream(\n         {\n           type: \"bytes\",\n@@ -4389,9 +4533,6 @@\n             var stream = new ReadableStream(\n               {\n                 type: \"bytes\",\n-                start: function () {\n-                  startWork(request);\n-                },\n                 pull: function (controller) {\n                   startFlowing(request, controller);\n                 },\n@@ -4410,7 +4551,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "815850dc2660880ad13be4052fef7af0fff4e48e",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.browser.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 118,
            "changes": 219,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -725,23 +725,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var hints = new Set();\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    hints = new Set();\n   this.type = type;\n   this.status = 10;\n   this.flushScheduled = !1;\n@@ -751,9 +749,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -770,14 +767,14 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -793,9 +790,7 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n-          (task = stringify(serializeByValueID(request.fatalError))),\n-          emitModelChunk(request, newTask.id, task),\n+          abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -826,14 +821,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(stringToChunk(entry)),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -846,20 +845,21 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n+      erroredTask(request, streamTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -876,19 +876,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -904,10 +903,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -920,22 +922,26 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n+      erroredTask(request, streamTask, signal.reason);\n+      enqueueFlush(request);\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -945,12 +951,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1298,37 +1302,36 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n-      erroredTask(request, newTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n+      erroredTask(request, newTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1765,12 +1768,11 @@ function retryTask(request, task) {\n       request.abortableTasks.delete(task);\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n-      if (12 === request.status) {\n-        request.abortableTasks.delete(task);\n-        task.status = 3;\n-        var model = stringify(serializeByValueID(request.fatalError));\n-        emitModelChunk(request, task.id, model);\n-      } else {\n+      if (12 === request.status)\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          abortTask(task, request, request.fatalError);\n+      else {\n         var x =\n           thrownValue === SuspenseException\n             ? getSuspendedThenable()\n@@ -1819,6 +1821,13 @@ function performWork(request) {\n       (currentRequest = prevRequest);\n   }\n }\n+function abortTask(task, request, errorId) {\n+  5 !== task.status &&\n+    ((task.status = 3),\n+    (errorId = serializeByValueID(errorId)),\n+    (task = encodeReferenceChunk(request, task.id, errorId)),\n+    request.completedErrorChunks.push(task));\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -1886,8 +1895,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -1904,7 +1913,9 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       var error =\n@@ -1921,36 +1932,15 @@ function abort(request, reason) {\n       request.pendingChunks++;\n       emitErrorChunk(request, errorId, digest, error);\n       abortableTasks.forEach(function (task) {\n-        if (5 !== task.status) {\n-          task.status = 3;\n-          var ref = serializeByValueID(errorId);\n-          task = encodeReferenceChunk(request, task.id, ref);\n-          request.completedErrorChunks.push(task);\n-        }\n+        return abortTask(task, request, errorId);\n       });\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$24 =\n-        void 0 === reason\n-          ? Error(\"The render was aborted by the server without a reason.\")\n-          : \"object\" === typeof reason &&\n-              null !== reason &&\n-              \"function\" === typeof reason.then\n-            ? Error(\"The render was aborted by the server with a promise.\")\n-            : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$24);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$25) {\n-    logRecoverableError(request, error$25, null), fatalError(request, error$25);\n+  } catch (error$24) {\n+    logRecoverableError(request, error$24, null), fatalError(request, error$24);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2395,19 +2385,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$28 = createPendingChunk(response);\n-        chunk$28.then(\n+        var chunk$27 = createPendingChunk(response);\n+        chunk$27.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$28;\n+        previousBlockedChunk = chunk$27;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$28 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$28, json, -1);\n+          previousBlockedChunk === chunk$27 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$27, json, -1);\n         });\n       }\n     },\n@@ -2755,13 +2745,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -2798,18 +2786,11 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var stream = new ReadableStream(\n           {\n             type: \"bytes\",\n-            start: function () {\n-              startWork(request);\n-            },\n             pull: function (controller) {\n               startFlowing(request, controller);\n             },\n@@ -2822,7 +2803,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n         );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "1d98086862ddcca2fabbdaede0801da641d3ea90",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.edge.development.js",
            "status": "modified",
            "additions": 265,
            "deletions": 123,
            "changes": 388,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -753,13 +753,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -782,7 +783,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -818,6 +818,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = createTask(this, model, null, !1, abortSet, 0, null, null, null);\n       pingedTasks.push(type);\n     }\n@@ -829,21 +832,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -856,21 +861,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -895,6 +902,8 @@\n         case \"rejected\":\n           return emitErrorChunk(request, id, \"\", thenable.reason), ref;\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -926,7 +935,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -953,9 +962,7 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n-              (task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task),\n+              abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -987,14 +994,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(stringToChunk(entry)),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -1007,20 +1018,24 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n+          erroredTask(request, streamTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1041,20 +1056,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1070,10 +1084,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1086,22 +1103,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n+          erroredTask(request, streamTask, signal.reason);\n+          enqueueFlush(request);\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1115,14 +1136,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(stringToChunk(task));\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1678,6 +1697,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -1829,31 +1858,37 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n-          erroredTask(request, newTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n+          erroredTask(request, newTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -1867,9 +1902,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2478,8 +2512,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2591,15 +2643,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -2877,12 +2934,11 @@\n           request.abortableTasks.delete(task);\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n-          if (request.status === ABORTING) {\n-            request.abortableTasks.delete(task);\n-            task.status = ABORTED;\n-            var model = stringify(serializeByValueID(request.fatalError));\n-            emitModelChunk(request, task.id, model);\n-          } else {\n+          if (request.status === ABORTING)\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              abortTask(task, request, request.fatalError);\n+          else {\n             var x =\n               thrownValue === SuspenseException\n                 ? getSuspendedThenable()\n@@ -2935,6 +2991,19 @@\n           (currentRequest = prevRequest);\n       }\n     }\n+    function abortTask(task, request, errorId) {\n+      if (task.status !== RENDERING) {\n+        task.status = ABORTED;\n+        var model = task.model;\n+        \"object\" === typeof model &&\n+          null !== model &&\n+          (model = model._debugInfo) &&\n+          forwardDebugInfo(request, task, model);\n+        errorId = serializeByValueID(errorId);\n+        task = encodeReferenceChunk(request, task.id, errorId);\n+        request.completedErrorChunks.push(task);\n+      }\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -3029,11 +3098,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -3051,7 +3117,9 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           var error =\n@@ -3072,39 +3140,34 @@\n           request.pendingChunks++;\n           emitErrorChunk(request, _errorId2, digest, error);\n           abortableTasks.forEach(function (task) {\n-            if (task.status !== RENDERING) {\n-              task.status = ABORTED;\n-              var ref = serializeByValueID(_errorId2);\n-              task = encodeReferenceChunk(request, task.id, ref);\n-              request.completedErrorChunks.push(task);\n-            }\n+            return abortTask(task, request, _errorId2);\n           });\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            void 0 === reason\n-              ? Error(\"The render was aborted by the server without a reason.\")\n-              : \"object\" === typeof reason &&\n-                  null !== reason &&\n-                  \"function\" === typeof reason.then\n-                ? Error(\"The render was aborted by the server with a promise.\")\n-                : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -3846,6 +3909,76 @@\n       if (\"fulfilled\" !== body.status) throw body.reason;\n       return body.value;\n     }\n+    function startReadingFromDebugChannelReadableStream(\n+      request$jscomp$0,\n+      stream\n+    ) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++) {\n+          var request = request$jscomp$0,\n+            message = _ref[buffer],\n+            deferredDebugObjects = request.deferredDebugObjects;\n+          if (null === deferredDebugObjects)\n+            throw Error(\n+              \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+            );\n+          var command = message.charCodeAt(0);\n+          message = message.slice(2).split(\",\").map(fromHex);\n+          switch (command) {\n+            case 82:\n+              for (command = 0; command < message.length; command++) {\n+                var id = message[command],\n+                  retainedValue = deferredDebugObjects.retained.get(id);\n+                void 0 !== retainedValue &&\n+                  (request.pendingChunks--,\n+                  deferredDebugObjects.retained.delete(id),\n+                  deferredDebugObjects.existing.delete(retainedValue),\n+                  enqueueFlush(request));\n+              }\n+              break;\n+            case 81:\n+              for (command = 0; command < message.length; command++)\n+                (id = message[command]),\n+                  (retainedValue = deferredDebugObjects.retained.get(id)),\n+                  void 0 !== retainedValue &&\n+                    (emitOutlinedDebugModelChunk(\n+                      request,\n+                      id,\n+                      { objectLimit: 10 },\n+                      retainedValue\n+                    ),\n+                    enqueueFlush(request));\n+              break;\n+            default:\n+              throw Error(\n+                \"Unknown command. The debugChannel was not wired up properly.\"\n+              );\n+          }\n+        }\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request$jscomp$0);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request$jscomp$0,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     var ReactDOM = require(\"react-dom\"),\n       React = require(\"react\"),\n       REACT_LEGACY_ELEMENT_TYPE = Symbol.for(\"react.element\"),\n@@ -4311,6 +4444,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -4464,16 +4598,21 @@\n       });\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -4485,6 +4624,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       return new ReadableStream(\n         {\n           type: \"bytes\",\n@@ -4511,9 +4655,6 @@\n             var stream = new ReadableStream(\n               {\n                 type: \"bytes\",\n-                start: function () {\n-                  startWork(request);\n-                },\n                 pull: function (controller) {\n                   startFlowing(request, controller);\n                 },\n@@ -4532,7 +4673,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "d0b71fb22f41fb75d8fedcb549549b747a8d657d",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.edge.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 118,
            "changes": 219,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -725,23 +725,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var hints = new Set();\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    hints = new Set();\n   this.type = type;\n   this.status = 10;\n   this.flushScheduled = !1;\n@@ -751,9 +749,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -770,8 +767,8 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function resolveRequest() {\n@@ -785,7 +782,7 @@ function resolveRequest() {\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -801,9 +798,7 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n-          (task = stringify(serializeByValueID(request.fatalError))),\n-          emitModelChunk(request, newTask.id, task),\n+          abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -834,14 +829,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(stringToChunk(entry)),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -854,20 +853,21 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n+      erroredTask(request, streamTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -884,19 +884,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -912,10 +911,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(stringToChunk(endStreamRow));\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -928,22 +930,26 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n+      erroredTask(request, streamTask, signal.reason);\n+      enqueueFlush(request);\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -953,12 +959,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(stringToChunk(task));\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1306,37 +1310,36 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n-      erroredTask(request, newTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n+      erroredTask(request, newTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1775,12 +1778,11 @@ function retryTask(request, task) {\n       request.abortableTasks.delete(task);\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n-      if (12 === request.status) {\n-        request.abortableTasks.delete(task);\n-        task.status = 3;\n-        var model = stringify(serializeByValueID(request.fatalError));\n-        emitModelChunk(request, task.id, model);\n-      } else {\n+      if (12 === request.status)\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          abortTask(task, request, request.fatalError);\n+      else {\n         var x =\n           thrownValue === SuspenseException\n             ? getSuspendedThenable()\n@@ -1829,6 +1831,13 @@ function performWork(request) {\n       (currentRequest = prevRequest);\n   }\n }\n+function abortTask(task, request, errorId) {\n+  5 !== task.status &&\n+    ((task.status = 3),\n+    (errorId = serializeByValueID(errorId)),\n+    (task = encodeReferenceChunk(request, task.id, errorId)),\n+    request.completedErrorChunks.push(task));\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -1900,8 +1909,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -1918,7 +1927,9 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       var error =\n@@ -1935,36 +1946,15 @@ function abort(request, reason) {\n       request.pendingChunks++;\n       emitErrorChunk(request, errorId, digest, error);\n       abortableTasks.forEach(function (task) {\n-        if (5 !== task.status) {\n-          task.status = 3;\n-          var ref = serializeByValueID(errorId);\n-          task = encodeReferenceChunk(request, task.id, ref);\n-          request.completedErrorChunks.push(task);\n-        }\n+        return abortTask(task, request, errorId);\n       });\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$24 =\n-        void 0 === reason\n-          ? Error(\"The render was aborted by the server without a reason.\")\n-          : \"object\" === typeof reason &&\n-              null !== reason &&\n-              \"function\" === typeof reason.then\n-            ? Error(\"The render was aborted by the server with a promise.\")\n-            : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$24);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$25) {\n-    logRecoverableError(request, error$25, null), fatalError(request, error$25);\n+  } catch (error$24) {\n+    logRecoverableError(request, error$24, null), fatalError(request, error$24);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2409,19 +2399,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$28 = createPendingChunk(response);\n-        chunk$28.then(\n+        var chunk$27 = createPendingChunk(response);\n+        chunk$27.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$28;\n+        previousBlockedChunk = chunk$27;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$28 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$28, json, -1);\n+          previousBlockedChunk === chunk$27 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$27, json, -1);\n         });\n       }\n     },\n@@ -2806,13 +2796,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -2849,18 +2837,11 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var stream = new ReadableStream(\n           {\n             type: \"bytes\",\n-            start: function () {\n-              startWork(request);\n-            },\n             pull: function (controller) {\n               startFlowing(request, controller);\n             },\n@@ -2873,7 +2854,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n         );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "da88a82434a8af32d8322d55b7b03b55c63f0366",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.node.development.js",
            "status": "modified",
            "additions": 337,
            "deletions": 137,
            "changes": 474,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -767,13 +767,14 @@\n       model,\n       bundlerConfig,\n       onError,\n-      identifierPrefix,\n       onPostpone,\n+      onAllReady,\n+      onFatalError,\n+      identifierPrefix,\n       temporaryReferences,\n       environmentName,\n       filterStackFrame,\n-      onAllReady,\n-      onFatalError\n+      keepDebugAlive\n     ) {\n       if (\n         null !== ReactSharedInternalsServer.A &&\n@@ -796,7 +797,6 @@\n       this.cacheController = new AbortController();\n       this.pendingChunks = this.nextChunkId = 0;\n       this.hints = hints;\n-      this.abortListeners = new Set();\n       this.abortableTasks = abortSet;\n       this.pingedTasks = pingedTasks;\n       this.completedImportChunks = [];\n@@ -832,6 +832,9 @@\n           : filterStackFrame;\n       this.didWarnForKey = null;\n       this.writtenDebugObjects = new WeakMap();\n+      this.deferredDebugObjects = keepDebugAlive\n+        ? { retained: new Map(), existing: new Map() }\n+        : null;\n       type = createTask(this, model, null, !1, abortSet, 0, null, null, null);\n       pingedTasks.push(type);\n     }\n@@ -843,21 +846,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         20,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        noop,\n+        noop,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        noop,\n-        noop\n+        keepDebugAlive\n       );\n     }\n     function createPrerenderRequest(\n@@ -870,21 +875,23 @@\n       onPostpone,\n       temporaryReferences,\n       environmentName,\n-      filterStackFrame\n+      filterStackFrame,\n+      keepDebugAlive\n     ) {\n       resetOwnerStackLimit();\n       return new RequestInstance(\n         PRERENDER,\n         model,\n         bundlerConfig,\n         onError,\n-        identifierPrefix,\n         onPostpone,\n+        onAllReady,\n+        onFatalError,\n+        identifierPrefix,\n         temporaryReferences,\n         environmentName,\n         filterStackFrame,\n-        onAllReady,\n-        onFatalError\n+        keepDebugAlive\n       );\n     }\n     function resolveRequest() {\n@@ -906,6 +913,8 @@\n         case \"rejected\":\n           return emitErrorChunk(request, id, \"\", thenable.reason), ref;\n       }\n+      if (request.status === ABORTING)\n+        return emitDebugHaltChunk(request, id), ref;\n       var cancelled = !1;\n       thenable.then(\n         function (value) {\n@@ -937,7 +946,7 @@\n     function serializeThenable(request, task, thenable) {\n       var newTask = createTask(\n         request,\n-        null,\n+        thenable,\n         task.keyPath,\n         task.implicitSlot,\n         request.abortableTasks,\n@@ -964,9 +973,7 @@\n           if (request.status === ABORTING)\n             return (\n               request.abortableTasks.delete(newTask),\n-              (newTask.status = ABORTED),\n-              (task = stringify(serializeByValueID(request.fatalError))),\n-              emitModelChunk(request, newTask.id, task),\n+              abortTask(newTask, request, request.fatalError),\n               newTask.id\n             );\n           \"string\" !== typeof thenable.status &&\n@@ -998,14 +1005,18 @@\n     }\n     function serializeReadableStream(request, task, stream) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done)\n-            (entry = streamTask.id.toString(16) + \":C\\n\"),\n+            (streamTask.status = COMPLETED),\n+              (entry = streamTask.id.toString(16) + \":C\\n\"),\n               request.completedRegularChunks.push(entry),\n+              request.abortableTasks.delete(streamTask),\n+              request.cacheController.signal.removeEventListener(\n+                \"abort\",\n+                abortStream\n+              ),\n               enqueueFlush(request),\n-              request.abortListeners.delete(abortStream),\n-              callOnAllReadyIfReady(request),\n-              (aborted = !0);\n+              callOnAllReadyIfReady(request);\n           else\n             try {\n               (streamTask.model = entry.value),\n@@ -1018,20 +1029,24 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortStream(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortStream),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortStream() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortStream);\n+          signal = signal.reason;\n+          erroredTask(request, streamTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var supportsBYOB = stream.supportsBYOB;\n       if (void 0 === supportsBYOB)\n@@ -1052,20 +1067,19 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task =\n         streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n       request.completedRegularChunks.push(task);\n-      var aborted = !1;\n-      request.abortListeners.add(abortStream);\n+      request.cacheController.signal.addEventListener(\"abort\", abortStream);\n       reader.read().then(progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n     function serializeAsyncIterable(request, task, iterable, iterator) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (streamTask.status === PENDING$1)\n           if (entry.done) {\n+            streamTask.status = COMPLETED;\n             if (void 0 === entry.value)\n               var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n             else\n@@ -1081,10 +1095,13 @@\n                 return;\n               }\n             request.completedRegularChunks.push(endStreamRow);\n+            request.abortableTasks.delete(streamTask);\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortIterable\n+            );\n             enqueueFlush(request);\n-            request.abortListeners.delete(abortIterable);\n             callOnAllReadyIfReady(request);\n-            aborted = !0;\n           } else\n             try {\n               (streamTask.model = entry.value),\n@@ -1097,22 +1114,26 @@\n             }\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n+        streamTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortIterable\n+          ),\n           erroredTask(request, streamTask, reason),\n           enqueueFlush(request),\n           \"function\" === typeof iterator.throw &&\n             iterator.throw(reason).then(error, error));\n       }\n-      function abortIterable(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortIterable),\n-          erroredTask(request, streamTask, reason),\n-          enqueueFlush(request),\n+      function abortIterable() {\n+        if (streamTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortIterable);\n+          var reason = signal.reason;\n+          erroredTask(request, streamTask, signal.reason);\n+          enqueueFlush(request);\n           \"function\" === typeof iterator.throw &&\n-            iterator.throw(reason).then(error, error));\n+            iterator.throw(reason).then(error, error);\n+        }\n       }\n       var isIterator = iterable === iterator,\n         streamTask = createTask(\n@@ -1126,14 +1147,12 @@\n           task.debugStack,\n           task.debugTask\n         );\n-      request.abortableTasks.delete(streamTask);\n       request.pendingChunks++;\n       task = streamTask.id.toString(16) + \":\" + (isIterator ? \"x\" : \"X\") + \"\\n\";\n       request.completedRegularChunks.push(task);\n       (iterable = iterable._debugInfo) &&\n         forwardDebugInfo(request, streamTask, iterable);\n-      var aborted = !1;\n-      request.abortListeners.add(abortIterable);\n+      request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n       callIteratorInDEV(iterator, progress, error);\n       return serializeByValueID(streamTask.id);\n     }\n@@ -1666,6 +1685,16 @@\n     function serializeLazyID(id) {\n       return \"$L\" + id.toString(16);\n     }\n+    function serializeDeferredObject(request, value) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      return null !== deferredDebugObjects\n+        ? (request.pendingChunks++,\n+          (request = request.nextChunkId++),\n+          deferredDebugObjects.existing.set(value, request),\n+          deferredDebugObjects.retained.set(request, value),\n+          \"$Y\" + request.toString(16))\n+        : \"$Y\";\n+    }\n     function serializeNumber(number) {\n       return Number.isFinite(number)\n         ? 0 === number && -Infinity === 1 / number\n@@ -1815,31 +1844,37 @@\n     }\n     function serializeBlob(request, blob) {\n       function progress(entry) {\n-        if (!aborted)\n+        if (newTask.status === PENDING$1)\n           if (entry.done)\n-            request.abortListeners.delete(abortBlob),\n-              (aborted = !0),\n+            request.cacheController.signal.removeEventListener(\n+              \"abort\",\n+              abortBlob\n+            ),\n               pingTask(request, newTask);\n           else\n             return (\n               model.push(entry.value), reader.read().then(progress).catch(error)\n             );\n       }\n       function error(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n+        newTask.status === PENDING$1 &&\n+          (request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortBlob\n+          ),\n           erroredTask(request, newTask, reason),\n           enqueueFlush(request),\n           reader.cancel(reason).then(error, error));\n       }\n-      function abortBlob(reason) {\n-        aborted ||\n-          ((aborted = !0),\n-          request.abortListeners.delete(abortBlob),\n-          erroredTask(request, newTask, reason),\n-          enqueueFlush(request),\n-          reader.cancel(reason).then(error, error));\n+      function abortBlob() {\n+        if (newTask.status === PENDING$1) {\n+          var signal = request.cacheController.signal;\n+          signal.removeEventListener(\"abort\", abortBlob);\n+          signal = signal.reason;\n+          erroredTask(request, newTask, signal);\n+          enqueueFlush(request);\n+          reader.cancel(signal).then(error, error);\n+        }\n       }\n       var model = [blob.type],\n         newTask = createTask(\n@@ -1853,9 +1888,8 @@\n           null,\n           null\n         ),\n-        reader = blob.stream().getReader(),\n-        aborted = !1;\n-      request.abortListeners.add(abortBlob);\n+        reader = blob.stream().getReader();\n+      request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n       reader.read().then(progress).catch(error);\n       return \"$B\" + newTask.id.toString(16);\n     }\n@@ -2321,10 +2355,6 @@\n       id = encodeReferenceChunk(request, id, \"$S\" + name);\n       request.completedImportChunks.push(id);\n     }\n-    function emitModelChunk(request, id, json) {\n-      id = id.toString(16) + \":\" + json + \"\\n\";\n-      request.completedRegularChunks.push(id);\n-    }\n     function emitDebugHaltChunk(request, id) {\n       id = id.toString(16) + \":\\n\";\n       request.completedRegularChunks.push(id);\n@@ -2451,8 +2481,26 @@\n             );\n         parent = request.writtenObjects.get(value);\n         if (void 0 !== parent) return parent;\n-        if (0 >= counter.objectLimit && !doNotLimit.has(value)) return \"$Y\";\n+        if (0 >= counter.objectLimit && !doNotLimit.has(value))\n+          return serializeDeferredObject(request, value);\n         counter.objectLimit--;\n+        parent = request.deferredDebugObjects;\n+        if (\n+          null !== parent &&\n+          ((parentPropertyName = parent.existing.get(value)),\n+          void 0 !== parentPropertyName)\n+        )\n+          return (\n+            parent.existing.delete(value),\n+            parent.retained.delete(parentPropertyName),\n+            emitOutlinedDebugModelChunk(\n+              request,\n+              parentPropertyName,\n+              counter,\n+              value\n+            ),\n+            serializeByValueID(parentPropertyName)\n+          );\n         switch (value.$$typeof) {\n           case REACT_ELEMENT_TYPE:\n             null != value._owner && outlineComponentInfo(request, value._owner);\n@@ -2564,15 +2612,20 @@\n         }\n         return value;\n       }\n-      if (\"string\" === typeof value)\n-        return \"Z\" === value[value.length - 1] &&\n+      if (\"string\" === typeof value) {\n+        if (\n+          \"Z\" === value[value.length - 1] &&\n           parent[parentPropertyName] instanceof Date\n-          ? \"$D\" + value\n-          : 1024 <= value.length\n-            ? serializeLargeTextString(request, value)\n-            : \"$\" === value[0]\n-              ? \"$\" + value\n-              : value;\n+        )\n+          return \"$D\" + value;\n+        if (1024 <= value.length) {\n+          if (0 >= counter.objectLimit)\n+            return serializeDeferredObject(request, value);\n+          counter.objectLimit--;\n+          return serializeLargeTextString(request, value);\n+        }\n+        return \"$\" === value[0] ? \"$\" + value : value;\n+      }\n       if (\"boolean\" === typeof value) return value;\n       if (\"number\" === typeof value) return serializeNumber(value);\n       if (\"undefined\" === typeof value) return \"$undefined\";\n@@ -2802,7 +2855,12 @@\n                                 : value instanceof DataView\n                                   ? emitTypedArrayChunk(request, id, \"V\", value)\n                                   : ((value = stringify(value, task.toJSON)),\n-                                    emitModelChunk(request, task.id, value));\n+                                    (task =\n+                                      task.id.toString(16) +\n+                                      \":\" +\n+                                      value +\n+                                      \"\\n\"),\n+                                    request.completedRegularChunks.push(task));\n     }\n     function erroredTask(request, task, error) {\n       task.status = ERRORED$1;\n@@ -2841,19 +2899,19 @@\n             ),\n               emitChunk(request, task, resolvedModel);\n           else {\n-            var json = stringify(resolvedModel);\n-            emitModelChunk(request, task.id, json);\n+            var json = stringify(resolvedModel),\n+              processedChunk = task.id.toString(16) + \":\" + json + \"\\n\";\n+            request.completedRegularChunks.push(processedChunk);\n           }\n           task.status = COMPLETED;\n           request.abortableTasks.delete(task);\n           callOnAllReadyIfReady(request);\n         } catch (thrownValue) {\n-          if (request.status === ABORTING) {\n-            request.abortableTasks.delete(task);\n-            task.status = ABORTED;\n-            var model = stringify(serializeByValueID(request.fatalError));\n-            emitModelChunk(request, task.id, model);\n-          } else {\n+          if (request.status === ABORTING)\n+            request.abortableTasks.delete(task),\n+              (task.status = PENDING$1),\n+              abortTask(task, request, request.fatalError);\n+          else {\n             var x =\n               thrownValue === SuspenseException\n                 ? getSuspendedThenable()\n@@ -2906,6 +2964,19 @@\n           (currentRequest = prevRequest);\n       }\n     }\n+    function abortTask(task, request, errorId) {\n+      if (task.status !== RENDERING) {\n+        task.status = ABORTED;\n+        var model = task.model;\n+        \"object\" === typeof model &&\n+          null !== model &&\n+          (model = model._debugInfo) &&\n+          forwardDebugInfo(request, task, model);\n+        errorId = serializeByValueID(errorId);\n+        task = encodeReferenceChunk(request, task.id, errorId);\n+        request.completedErrorChunks.push(task);\n+      }\n+    }\n     function flushCompletedChunks(request, destination) {\n       currentView = new Uint8Array(2048);\n       writtenBytes = 0;\n@@ -2997,11 +3068,8 @@\n         }));\n     }\n     function callOnAllReadyIfReady(request) {\n-      if (\n-        0 === request.abortableTasks.size &&\n-        0 === request.abortListeners.size\n-      )\n-        request.onAllReady();\n+      0 === request.abortableTasks.size &&\n+        ((request = request.onAllReady), request());\n     }\n     function startFlowing(request, destination) {\n       if (request.status === CLOSING)\n@@ -3018,7 +3086,9 @@\n     function abort(request, reason) {\n       try {\n         11 >= request.status &&\n-          ((request.status = ABORTING), request.cacheController.abort(reason));\n+          ((request.status = ABORTING),\n+          request.cacheController.abort(reason),\n+          callOnAllReadyIfReady(request));\n         var abortableTasks = request.abortableTasks;\n         if (0 < abortableTasks.size) {\n           var error =\n@@ -3039,39 +3109,73 @@\n           request.pendingChunks++;\n           emitErrorChunk(request, _errorId2, digest, error);\n           abortableTasks.forEach(function (task) {\n-            if (task.status !== RENDERING) {\n-              task.status = ABORTED;\n-              var ref = serializeByValueID(_errorId2);\n-              task = encodeReferenceChunk(request, task.id, ref);\n-              request.completedErrorChunks.push(task);\n-            }\n+            return abortTask(task, request, _errorId2);\n           });\n           abortableTasks.clear();\n           callOnAllReadyIfReady(request);\n         }\n-        var abortListeners = request.abortListeners;\n-        if (0 < abortListeners.size) {\n-          var _error =\n-            void 0 === reason\n-              ? Error(\"The render was aborted by the server without a reason.\")\n-              : \"object\" === typeof reason &&\n-                  null !== reason &&\n-                  \"function\" === typeof reason.then\n-                ? Error(\"The render was aborted by the server with a promise.\")\n-                : reason;\n-          abortListeners.forEach(function (callback) {\n-            return callback(_error);\n-          });\n-          abortListeners.clear();\n-          callOnAllReadyIfReady(request);\n-        }\n         null !== request.destination &&\n           flushCompletedChunks(request, request.destination);\n       } catch (error$2) {\n         logRecoverableError(request, error$2, null),\n           fatalError(request, error$2);\n       }\n     }\n+    function fromHex(str) {\n+      return parseInt(str, 16);\n+    }\n+    function resolveDebugMessage(request, message) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      var command = message.charCodeAt(0);\n+      message = message.slice(2).split(\",\").map(fromHex);\n+      switch (command) {\n+        case 82:\n+          for (command = 0; command < message.length; command++) {\n+            var id = message[command],\n+              retainedValue = deferredDebugObjects.retained.get(id);\n+            void 0 !== retainedValue &&\n+              (request.pendingChunks--,\n+              deferredDebugObjects.retained.delete(id),\n+              deferredDebugObjects.existing.delete(retainedValue),\n+              enqueueFlush(request));\n+          }\n+          break;\n+        case 81:\n+          for (command = 0; command < message.length; command++)\n+            (id = message[command]),\n+              (retainedValue = deferredDebugObjects.retained.get(id)),\n+              void 0 !== retainedValue &&\n+                (emitOutlinedDebugModelChunk(\n+                  request,\n+                  id,\n+                  { objectLimit: 10 },\n+                  retainedValue\n+                ),\n+                enqueueFlush(request));\n+          break;\n+        default:\n+          throw Error(\n+            \"Unknown command. The debugChannel was not wired up properly.\"\n+          );\n+      }\n+    }\n+    function closeDebugChannel(request) {\n+      var deferredDebugObjects = request.deferredDebugObjects;\n+      if (null === deferredDebugObjects)\n+        throw Error(\n+          \"resolveDebugMessage/closeDebugChannel should not be called for a Request that wasn't kept alive. This is a bug in React.\"\n+        );\n+      deferredDebugObjects.retained.forEach(function (value, id) {\n+        request.pendingChunks--;\n+        deferredDebugObjects.retained.delete(id);\n+        deferredDebugObjects.existing.delete(value);\n+      });\n+      enqueueFlush(request);\n+    }\n     function resolveServerReference(bundlerConfig, id) {\n       var name = \"\",\n         resolvedModuleData = bundlerConfig[id];\n@@ -3832,6 +3936,57 @@\n         abort(request, Error(reason));\n       };\n     }\n+    function startReadingFromDebugChannelReadable(request, stream) {\n+      function onData(chunk) {\n+        if (\"string\" === typeof chunk) {\n+          if (lastWasPartial) {\n+            var JSCompiler_temp_const = stringBuffer;\n+            var JSCompiler_inline_result = new Uint8Array(0);\n+            JSCompiler_inline_result = stringDecoder.decode(\n+              JSCompiler_inline_result\n+            );\n+            stringBuffer = JSCompiler_temp_const + JSCompiler_inline_result;\n+            lastWasPartial = !1;\n+          }\n+          stringBuffer += chunk;\n+        } else\n+          (stringBuffer += stringDecoder.decode(chunk, decoderOptions)),\n+            (lastWasPartial = !0);\n+        chunk = stringBuffer.split(\"\\n\");\n+        for (\n+          JSCompiler_temp_const = 0;\n+          JSCompiler_temp_const < chunk.length - 1;\n+          JSCompiler_temp_const++\n+        )\n+          resolveDebugMessage(request, chunk[JSCompiler_temp_const]);\n+        stringBuffer = chunk[chunk.length - 1];\n+      }\n+      function onError(error) {\n+        abort(\n+          request,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: error })\n+        );\n+      }\n+      function onClose() {\n+        closeDebugChannel(request);\n+      }\n+      var stringDecoder = new util.TextDecoder(),\n+        lastWasPartial = !1,\n+        stringBuffer = \"\";\n+      \"function\" === typeof stream.addEventListener &&\n+      \"string\" === typeof stream.binaryType\n+        ? ((stream.binaryType = \"arraybuffer\"),\n+          stream.addEventListener(\"message\", function (event) {\n+            onData(event.data);\n+          }),\n+          stream.addEventListener(\"error\", function (event) {\n+            onError(event.error);\n+          }),\n+          stream.addEventListener(\"close\", onClose))\n+        : (stream.on(\"data\", onData),\n+          stream.on(\"error\", onError),\n+          stream.on(\"end\", onClose));\n+    }\n     function createFakeWritableFromReadableStreamController(controller) {\n       return {\n         write: function (chunk) {\n@@ -3849,6 +4004,34 @@\n         }\n       };\n     }\n+    function startReadingFromDebugChannelReadableStream(request, stream) {\n+      function progress(_ref) {\n+        var done = _ref.done,\n+          buffer = _ref.value;\n+        _ref = stringBuffer;\n+        done\n+          ? ((buffer = new Uint8Array(0)),\n+            (buffer = stringDecoder.decode(buffer)))\n+          : (buffer = stringDecoder.decode(buffer, decoderOptions));\n+        stringBuffer = _ref + buffer;\n+        _ref = stringBuffer.split(\"\\n\");\n+        for (buffer = 0; buffer < _ref.length - 1; buffer++)\n+          resolveDebugMessage(request, _ref[buffer]);\n+        stringBuffer = _ref[_ref.length - 1];\n+        if (done) closeDebugChannel(request);\n+        else return reader.read().then(progress).catch(error);\n+      }\n+      function error(e) {\n+        abort(\n+          request,\n+          Error(\"Lost connection to the Debug Channel.\", { cause: e })\n+        );\n+      }\n+      var reader = stream.getReader(),\n+        stringDecoder = new util.TextDecoder(),\n+        stringBuffer = \"\";\n+      reader.read().then(progress).catch(error);\n+    }\n     function createFakeWritableFromNodeReadable(readable) {\n       return {\n         write: function (chunk) {\n@@ -4320,6 +4503,7 @@\n       debugModelRoot = null,\n       debugNoOutline = null,\n       emptyRoot = {},\n+      decoderOptions = { stream: !0 },\n       chunkCache = new Map();\n     Chunk.prototype = Object.create(Promise.prototype);\n     Chunk.prototype.then = function (resolve, reject) {\n@@ -4459,20 +4643,20 @@\n           ? queuedFields.push(name, value)\n           : resolveField(response, name, value);\n       });\n-      busboyStream.on(\"file\", function (name, value, _ref) {\n-        var filename = _ref.filename,\n-          mimeType = _ref.mimeType;\n-        if (\"base64\" === _ref.encoding.toLowerCase())\n+      busboyStream.on(\"file\", function (name, value, _ref2) {\n+        var filename = _ref2.filename,\n+          mimeType = _ref2.mimeType;\n+        if (\"base64\" === _ref2.encoding.toLowerCase())\n           throw Error(\n             \"React doesn't accept base64 encoded file uploads because we don't expect form data passed from a browser to ever encode data that way. If that's the wrong assumption, we can easily fix it.\"\n           );\n         pendingFiles++;\n-        var JSCompiler_object_inline_chunks_185 = [];\n+        var JSCompiler_object_inline_chunks_188 = [];\n         value.on(\"data\", function (chunk) {\n-          JSCompiler_object_inline_chunks_185.push(chunk);\n+          JSCompiler_object_inline_chunks_188.push(chunk);\n         });\n         value.on(\"end\", function () {\n-          var blob = new Blob(JSCompiler_object_inline_chunks_185, {\n+          var blob = new Blob(JSCompiler_object_inline_chunks_188, {\n             type: mimeType\n           });\n           response._formData.append(name, blob, filename);\n@@ -4520,18 +4704,22 @@\n       });\n     };\n     exports.renderToPipeableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n+      var debugChannel = options ? options.debugChannel : void 0,\n+        request = createRequest(\n           model,\n           turbopackMap,\n           options ? options.onError : void 0,\n           options ? options.identifierPrefix : void 0,\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannel\n         ),\n         hasStartedFlowing = !1;\n       startWork(request);\n+      void 0 !== debugChannel &&\n+        startReadingFromDebugChannelReadable(request, debugChannel);\n       return {\n         pipe: function (destination) {\n           if (hasStartedFlowing)\n@@ -4560,16 +4748,21 @@\n       };\n     };\n     exports.renderToReadableStream = function (model, turbopackMap, options) {\n-      var request = createRequest(\n-        model,\n-        turbopackMap,\n-        options ? options.onError : void 0,\n-        options ? options.identifierPrefix : void 0,\n-        options ? options.onPostpone : void 0,\n-        options ? options.temporaryReferences : void 0,\n-        options ? options.environmentName : void 0,\n-        options ? options.filterStackFrame : void 0\n-      );\n+      var debugChannelReadable =\n+          options && options.debugChannel\n+            ? options.debugChannel.readable\n+            : void 0,\n+        request = createRequest(\n+          model,\n+          turbopackMap,\n+          options ? options.onError : void 0,\n+          options ? options.identifierPrefix : void 0,\n+          options ? options.onPostpone : void 0,\n+          options ? options.temporaryReferences : void 0,\n+          options ? options.environmentName : void 0,\n+          options ? options.filterStackFrame : void 0,\n+          void 0 !== debugChannelReadable\n+        );\n       if (options && options.signal) {\n         var signal = options.signal;\n         if (signal.aborted) abort(request, signal.reason);\n@@ -4581,6 +4774,11 @@\n           signal.addEventListener(\"abort\", listener);\n         }\n       }\n+      void 0 !== debugChannelReadable &&\n+        startReadingFromDebugChannelReadableStream(\n+          request,\n+          debugChannelReadable\n+        );\n       var writable;\n       return new ReadableStream(\n         {\n@@ -4635,7 +4833,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;\n@@ -4675,7 +4874,8 @@\n           options ? options.onPostpone : void 0,\n           options ? options.temporaryReferences : void 0,\n           options ? options.environmentName : void 0,\n-          options ? options.filterStackFrame : void 0\n+          options ? options.filterStackFrame : void 0,\n+          !1\n         );\n         if (options && options.signal) {\n           var signal = options.signal;"
        },
        {
            "sha": "b6012c830800d9ed22e33f967ec4378ab69c1004",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/cjs/react-server-dom-turbopack-server.node.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 139,
            "changes": 259,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fcjs%2Freact-server-dom-turbopack-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -742,23 +742,21 @@ function RequestInstance(\n   model,\n   bundlerConfig,\n   onError,\n-  identifierPrefix,\n   onPostpone,\n-  temporaryReferences,\n-  environmentName,\n-  filterStackFrame,\n   onAllReady,\n-  onFatalError\n+  onFatalError,\n+  identifierPrefix,\n+  temporaryReferences\n ) {\n   if (\n     null !== ReactSharedInternalsServer.A &&\n     ReactSharedInternalsServer.A !== DefaultAsyncDispatcher\n   )\n     throw Error(\"Currently React only supports one RSC renderer at a time.\");\n   ReactSharedInternalsServer.A = DefaultAsyncDispatcher;\n-  filterStackFrame = new Set();\n-  environmentName = [];\n-  var hints = new Set();\n+  var abortSet = new Set(),\n+    pingedTasks = [],\n+    hints = new Set();\n   this.type = type;\n   this.status = 10;\n   this.flushScheduled = !1;\n@@ -768,9 +766,8 @@ function RequestInstance(\n   this.cacheController = new AbortController();\n   this.pendingChunks = this.nextChunkId = 0;\n   this.hints = hints;\n-  this.abortListeners = new Set();\n-  this.abortableTasks = filterStackFrame;\n-  this.pingedTasks = environmentName;\n+  this.abortableTasks = abortSet;\n+  this.pingedTasks = pingedTasks;\n   this.completedImportChunks = [];\n   this.completedHintChunks = [];\n   this.completedRegularChunks = [];\n@@ -787,8 +784,8 @@ function RequestInstance(\n   this.onPostpone = void 0 === onPostpone ? noop : onPostpone;\n   this.onAllReady = onAllReady;\n   this.onFatalError = onFatalError;\n-  type = createTask(this, model, null, !1, filterStackFrame);\n-  environmentName.push(type);\n+  type = createTask(this, model, null, !1, abortSet);\n+  pingedTasks.push(type);\n }\n var currentRequest = null;\n function resolveRequest() {\n@@ -799,7 +796,7 @@ function resolveRequest() {\n function serializeThenable(request, task, thenable) {\n   var newTask = createTask(\n     request,\n-    null,\n+    thenable,\n     task.keyPath,\n     task.implicitSlot,\n     request.abortableTasks\n@@ -815,9 +812,7 @@ function serializeThenable(request, task, thenable) {\n       if (12 === request.status)\n         return (\n           request.abortableTasks.delete(newTask),\n-          (newTask.status = 3),\n-          (task = stringify(serializeByValueID(request.fatalError))),\n-          emitModelChunk(request, newTask.id, task),\n+          abortTask(newTask, request, request.fatalError),\n           newTask.id\n         );\n       \"string\" !== typeof thenable.status &&\n@@ -848,14 +843,18 @@ function serializeThenable(request, task, thenable) {\n }\n function serializeReadableStream(request, task, stream) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done)\n-        (entry = streamTask.id.toString(16) + \":C\\n\"),\n+        (streamTask.status = 1),\n+          (entry = streamTask.id.toString(16) + \":C\\n\"),\n           request.completedRegularChunks.push(entry),\n+          request.abortableTasks.delete(streamTask),\n+          request.cacheController.signal.removeEventListener(\n+            \"abort\",\n+            abortStream\n+          ),\n           enqueueFlush(request),\n-          request.abortListeners.delete(abortStream),\n-          callOnAllReadyIfReady(request),\n-          (aborted = !0);\n+          callOnAllReadyIfReady(request);\n       else\n         try {\n           (streamTask.model = entry.value),\n@@ -868,20 +867,21 @@ function serializeReadableStream(request, task, stream) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortStream),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortStream(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortStream),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortStream() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortStream);\n+      signal = signal.reason;\n+      erroredTask(request, streamTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var supportsBYOB = stream.supportsBYOB;\n   if (void 0 === supportsBYOB)\n@@ -898,19 +898,18 @@ function serializeReadableStream(request, task, stream) {\n       task.implicitSlot,\n       request.abortableTasks\n     );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (supportsBYOB ? \"r\" : \"R\") + \"\\n\";\n   request.completedRegularChunks.push(task);\n-  var aborted = !1;\n-  request.abortListeners.add(abortStream);\n+  request.cacheController.signal.addEventListener(\"abort\", abortStream);\n   reader.read().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n function serializeAsyncIterable(request, task, iterable, iterator) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === streamTask.status)\n       if (entry.done) {\n+        streamTask.status = 1;\n         if (void 0 === entry.value)\n           var endStreamRow = streamTask.id.toString(16) + \":C\\n\";\n         else\n@@ -926,10 +925,13 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n             return;\n           }\n         request.completedRegularChunks.push(endStreamRow);\n+        request.abortableTasks.delete(streamTask);\n+        request.cacheController.signal.removeEventListener(\n+          \"abort\",\n+          abortIterable\n+        );\n         enqueueFlush(request);\n-        request.abortListeners.delete(abortIterable);\n         callOnAllReadyIfReady(request);\n-        aborted = !0;\n       } else\n         try {\n           (streamTask.model = entry.value),\n@@ -942,22 +944,26 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n         }\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n+    0 === streamTask.status &&\n+      (request.cacheController.signal.removeEventListener(\n+        \"abort\",\n+        abortIterable\n+      ),\n       erroredTask(request, streamTask, reason),\n       enqueueFlush(request),\n       \"function\" === typeof iterator.throw &&\n         iterator.throw(reason).then(error, error));\n   }\n-  function abortIterable(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortIterable),\n-      erroredTask(request, streamTask, reason),\n-      enqueueFlush(request),\n+  function abortIterable() {\n+    if (0 === streamTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortIterable);\n+      var reason = signal.reason;\n+      erroredTask(request, streamTask, signal.reason);\n+      enqueueFlush(request);\n       \"function\" === typeof iterator.throw &&\n-        iterator.throw(reason).then(error, error));\n+        iterator.throw(reason).then(error, error);\n+    }\n   }\n   iterable = iterable === iterator;\n   var streamTask = createTask(\n@@ -967,12 +973,10 @@ function serializeAsyncIterable(request, task, iterable, iterator) {\n     task.implicitSlot,\n     request.abortableTasks\n   );\n-  request.abortableTasks.delete(streamTask);\n   request.pendingChunks++;\n   task = streamTask.id.toString(16) + \":\" + (iterable ? \"x\" : \"X\") + \"\\n\";\n   request.completedRegularChunks.push(task);\n-  var aborted = !1;\n-  request.abortListeners.add(abortIterable);\n+  request.cacheController.signal.addEventListener(\"abort\", abortIterable);\n   iterator.next().then(progress, error);\n   return serializeByValueID(streamTask.id);\n }\n@@ -1317,37 +1321,36 @@ function serializeTypedArray(request, tag, typedArray) {\n }\n function serializeBlob(request, blob) {\n   function progress(entry) {\n-    if (!aborted)\n+    if (0 === newTask.status)\n       if (entry.done)\n-        request.abortListeners.delete(abortBlob),\n-          (aborted = !0),\n+        request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n           pingTask(request, newTask);\n       else\n         return (\n           model.push(entry.value), reader.read().then(progress).catch(error)\n         );\n   }\n   function error(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n+    0 === newTask.status &&\n+      (request.cacheController.signal.removeEventListener(\"abort\", abortBlob),\n       erroredTask(request, newTask, reason),\n       enqueueFlush(request),\n       reader.cancel(reason).then(error, error));\n   }\n-  function abortBlob(reason) {\n-    aborted ||\n-      ((aborted = !0),\n-      request.abortListeners.delete(abortBlob),\n-      erroredTask(request, newTask, reason),\n-      enqueueFlush(request),\n-      reader.cancel(reason).then(error, error));\n+  function abortBlob() {\n+    if (0 === newTask.status) {\n+      var signal = request.cacheController.signal;\n+      signal.removeEventListener(\"abort\", abortBlob);\n+      signal = signal.reason;\n+      erroredTask(request, newTask, signal);\n+      enqueueFlush(request);\n+      reader.cancel(signal).then(error, error);\n+    }\n   }\n   var model = [blob.type],\n     newTask = createTask(request, model, null, !1, request.abortableTasks),\n-    reader = blob.stream().getReader(),\n-    aborted = !1;\n-  request.abortListeners.add(abortBlob);\n+    reader = blob.stream().getReader();\n+  request.cacheController.signal.addEventListener(\"abort\", abortBlob);\n   reader.read().then(progress).catch(error);\n   return \"$B\" + newTask.id.toString(16);\n }\n@@ -1684,10 +1687,6 @@ function emitErrorChunk(request, id, digest) {\n   id = id.toString(16) + \":E\" + stringify(digest) + \"\\n\";\n   request.completedErrorChunks.push(id);\n }\n-function emitModelChunk(request, id, json) {\n-  id = id.toString(16) + \":\" + json + \"\\n\";\n-  request.completedRegularChunks.push(id);\n-}\n function emitTypedArrayChunk(request, id, tag, typedArray) {\n   request.pendingChunks++;\n   typedArray = new Uint8Array(\n@@ -1740,7 +1739,9 @@ function emitChunk(request, task, value) {\n                             : value instanceof DataView\n                               ? emitTypedArrayChunk(request, id, \"V\", value)\n                               : ((value = stringify(value, task.toJSON)),\n-                                emitModelChunk(request, task.id, value));\n+                                (task =\n+                                  task.id.toString(16) + \":\" + value + \"\\n\"),\n+                                request.completedRegularChunks.push(task));\n }\n function erroredTask(request, task, error) {\n   task.status = 4;\n@@ -1770,19 +1771,19 @@ function retryTask(request, task) {\n         request.writtenObjects.set(resolvedModel, serializeByValueID(task.id)),\n           emitChunk(request, task, resolvedModel);\n       else {\n-        var json = stringify(resolvedModel);\n-        emitModelChunk(request, task.id, json);\n+        var json = stringify(resolvedModel),\n+          processedChunk = task.id.toString(16) + \":\" + json + \"\\n\";\n+        request.completedRegularChunks.push(processedChunk);\n       }\n       task.status = 1;\n       request.abortableTasks.delete(task);\n       callOnAllReadyIfReady(request);\n     } catch (thrownValue) {\n-      if (12 === request.status) {\n-        request.abortableTasks.delete(task);\n-        task.status = 3;\n-        var model = stringify(serializeByValueID(request.fatalError));\n-        emitModelChunk(request, task.id, model);\n-      } else {\n+      if (12 === request.status)\n+        request.abortableTasks.delete(task),\n+          (task.status = 0),\n+          abortTask(task, request, request.fatalError);\n+      else {\n         var x =\n           thrownValue === SuspenseException\n             ? getSuspendedThenable()\n@@ -1831,6 +1832,13 @@ function performWork(request) {\n       (currentRequest = prevRequest);\n   }\n }\n+function abortTask(task, request, errorId) {\n+  5 !== task.status &&\n+    ((task.status = 3),\n+    (errorId = serializeByValueID(errorId)),\n+    (task = encodeReferenceChunk(request, task.id, errorId)),\n+    request.completedErrorChunks.push(task));\n+}\n function flushCompletedChunks(request, destination) {\n   currentView = new Uint8Array(2048);\n   writtenBytes = 0;\n@@ -1922,8 +1930,8 @@ function enqueueFlush(request) {\n     }));\n }\n function callOnAllReadyIfReady(request) {\n-  if (0 === request.abortableTasks.size && 0 === request.abortListeners.size)\n-    request.onAllReady();\n+  0 === request.abortableTasks.size &&\n+    ((request = request.onAllReady), request());\n }\n function startFlowing(request, destination) {\n   if (13 === request.status)\n@@ -1940,7 +1948,9 @@ function startFlowing(request, destination) {\n function abort(request, reason) {\n   try {\n     11 >= request.status &&\n-      ((request.status = 12), request.cacheController.abort(reason));\n+      ((request.status = 12),\n+      request.cacheController.abort(reason),\n+      callOnAllReadyIfReady(request));\n     var abortableTasks = request.abortableTasks;\n     if (0 < abortableTasks.size) {\n       var error =\n@@ -1957,36 +1967,15 @@ function abort(request, reason) {\n       request.pendingChunks++;\n       emitErrorChunk(request, errorId, digest, error);\n       abortableTasks.forEach(function (task) {\n-        if (5 !== task.status) {\n-          task.status = 3;\n-          var ref = serializeByValueID(errorId);\n-          task = encodeReferenceChunk(request, task.id, ref);\n-          request.completedErrorChunks.push(task);\n-        }\n+        return abortTask(task, request, errorId);\n       });\n       abortableTasks.clear();\n       callOnAllReadyIfReady(request);\n     }\n-    var abortListeners = request.abortListeners;\n-    if (0 < abortListeners.size) {\n-      var error$24 =\n-        void 0 === reason\n-          ? Error(\"The render was aborted by the server without a reason.\")\n-          : \"object\" === typeof reason &&\n-              null !== reason &&\n-              \"function\" === typeof reason.then\n-            ? Error(\"The render was aborted by the server with a promise.\")\n-            : reason;\n-      abortListeners.forEach(function (callback) {\n-        return callback(error$24);\n-      });\n-      abortListeners.clear();\n-      callOnAllReadyIfReady(request);\n-    }\n     null !== request.destination &&\n       flushCompletedChunks(request, request.destination);\n-  } catch (error$25) {\n-    logRecoverableError(request, error$25, null), fatalError(request, error$25);\n+  } catch (error$24) {\n+    logRecoverableError(request, error$24, null), fatalError(request, error$24);\n   }\n }\n function resolveServerReference(bundlerConfig, id) {\n@@ -2431,19 +2420,19 @@ function parseReadableStream(response, reference, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$28 = createPendingChunk(response);\n-        chunk$28.then(\n+        var chunk$27 = createPendingChunk(response);\n+        chunk$27.then(\n           function (v) {\n             return controller.enqueue(v);\n           },\n           function (e) {\n             return controller.error(e);\n           }\n         );\n-        previousBlockedChunk = chunk$28;\n+        previousBlockedChunk = chunk$27;\n         chunk.then(function () {\n-          previousBlockedChunk === chunk$28 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$28, json, -1);\n+          previousBlockedChunk === chunk$27 && (previousBlockedChunk = null);\n+          resolveModelChunk(chunk$27, json, -1);\n         });\n       }\n     },\n@@ -2856,20 +2845,20 @@ exports.decodeReplyFromBusboy = function (busboyStream, turbopackMap, options) {\n       ? queuedFields.push(name, value)\n       : resolveField(response, name, value);\n   });\n-  busboyStream.on(\"file\", function (name, value, _ref) {\n-    var filename = _ref.filename,\n-      mimeType = _ref.mimeType;\n-    if (\"base64\" === _ref.encoding.toLowerCase())\n+  busboyStream.on(\"file\", function (name, value, _ref2) {\n+    var filename = _ref2.filename,\n+      mimeType = _ref2.mimeType;\n+    if (\"base64\" === _ref2.encoding.toLowerCase())\n       throw Error(\n         \"React doesn't accept base64 encoded file uploads because we don't expect form data passed from a browser to ever encode data that way. If that's the wrong assumption, we can easily fix it.\"\n       );\n     pendingFiles++;\n-    var JSCompiler_object_inline_chunks_252 = [];\n+    var JSCompiler_object_inline_chunks_244 = [];\n     value.on(\"data\", function (chunk) {\n-      JSCompiler_object_inline_chunks_252.push(chunk);\n+      JSCompiler_object_inline_chunks_244.push(chunk);\n     });\n     value.on(\"end\", function () {\n-      var blob = new Blob(JSCompiler_object_inline_chunks_252, {\n+      var blob = new Blob(JSCompiler_object_inline_chunks_244, {\n         type: mimeType\n       });\n       response._formData.append(name, blob, filename);\n@@ -2917,13 +2906,11 @@ exports.renderToPipeableStream = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       noop,\n-      noop\n+      noop,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     ),\n     hasStartedFlowing = !1;\n   startWork(request);\n@@ -2960,13 +2947,11 @@ exports.renderToReadableStream = function (model, turbopackMap, options) {\n     model,\n     turbopackMap,\n     options ? options.onError : void 0,\n-    options ? options.identifierPrefix : void 0,\n     options ? options.onPostpone : void 0,\n-    options ? options.temporaryReferences : void 0,\n-    void 0,\n-    void 0,\n     noop,\n-    noop\n+    noop,\n+    options ? options.identifierPrefix : void 0,\n+    options ? options.temporaryReferences : void 0\n   );\n   if (options && options.signal) {\n     var signal = options.signal;\n@@ -3005,11 +2990,7 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var writable,\n           stream = new ReadableStream(\n@@ -3031,7 +3012,9 @@ exports.unstable_prerender = function (model, turbopackMap, options) {\n           );\n         resolve({ prelude: stream });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;\n@@ -3058,11 +3041,7 @@ exports.unstable_prerenderToNodeStream = function (\n       model,\n       turbopackMap,\n       options ? options.onError : void 0,\n-      options ? options.identifierPrefix : void 0,\n       options ? options.onPostpone : void 0,\n-      options ? options.temporaryReferences : void 0,\n-      void 0,\n-      void 0,\n       function () {\n         var readable = new stream.Readable({\n             read: function () {\n@@ -3072,7 +3051,9 @@ exports.unstable_prerenderToNodeStream = function (\n           writable = createFakeWritableFromNodeReadable(readable);\n         resolve({ prelude: readable });\n       },\n-      reject\n+      reject,\n+      options ? options.identifierPrefix : void 0,\n+      options ? options.temporaryReferences : void 0\n     );\n     if (options && options.signal) {\n       var signal = options.signal;"
        },
        {
            "sha": "8816a40dcb1a16568e9c81a987e2f56632725b9f",
            "filename": "packages/next/src/compiled/react-server-dom-turbopack/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-turbopack%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -48,7 +48,7 @@\n     \"neo-async\": \"^2.6.1\"\n   },\n   \"peerDependencies\": {\n-    \"react\": \"19.2.0-canary-fa3feba6-20250623\",\n-    \"react-dom\": \"19.2.0-canary-fa3feba6-20250623\"\n+    \"react\": \"19.2.0-canary-cee7939b-20250625\",\n+    \"react-dom\": \"19.2.0-canary-cee7939b-20250625\"\n   }\n }\n\\ No newline at end of file"
        },
        {
            "sha": "ffedbcb5c060f5de7821ede79a1e296c90a7c593",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.browser.development.js",
            "status": "modified",
            "additions": 105,
            "deletions": 80,
            "changes": 185,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1149,11 +1149,10 @@\n         }\n       return null;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1176,11 +1175,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1226,25 +1225,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1265,13 +1265,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1308,6 +1309,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1368,7 +1372,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -1829,6 +1833,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -1862,7 +1869,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -1893,43 +1901,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -1939,14 +1945,14 @@\n         response._bundlerConfig,\n         model\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -1959,28 +1965,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -2001,12 +1999,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2021,7 +2014,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2033,7 +2026,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2084,10 +2077,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2102,8 +2094,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2127,7 +2118,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2138,9 +2134,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2150,7 +2152,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2440,15 +2442,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2566,9 +2573,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3017,7 +3024,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3148,7 +3155,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3161,7 +3168,24 @@\n         return value;\n       };\n     }\n+    function createDebugCallbackFromWritableStream(debugWritable) {\n+      var textEncoder = new TextEncoder(),\n+        writer = debugWritable.getWriter();\n+      return function (message) {\n+        \"\" === message\n+          ? writer.close()\n+          : writer\n+              .write(textEncoder.encode(message + \"\\n\"))\n+              .catch(console.error);\n+      };\n+    }\n     function createResponseFromOptions(options) {\n+      var debugChannel =\n+        options &&\n+        void 0 !== options.debugChannel &&\n+        void 0 !== options.debugChannel.writable\n+          ? createDebugCallbackFromWritableStream(options.debugChannel.writable)\n+          : void 0;\n       return new ResponseInstance(\n         null,\n         null,\n@@ -3174,7 +3198,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !1 !== options.replayConsoleLogs : !0,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        debugChannel\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -3494,10 +3519,10 @@\n       return hook.checkDCE ? !0 : !1;\n     })({\n       bundleType: 1,\n-      version: \"19.2.0-experimental-fa3feba6-20250623\",\n+      version: \"19.2.0-experimental-cee7939b-20250625\",\n       rendererPackageName: \"react-server-dom-webpack\",\n       currentDispatcherRef: ReactSharedInternals,\n-      reconcilerVersion: \"19.2.0-experimental-fa3feba6-20250623\",\n+      reconcilerVersion: \"19.2.0-experimental-cee7939b-20250625\",\n       getCurrentComponentInfo: function () {\n         return currentOwnerInDEV;\n       }"
        },
        {
            "sha": "f9c8d4f2785cdf6a79802abd8d5467ba3d86cf26",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.browser.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -531,11 +531,10 @@ function createBoundServerReference(metaData, callServer) {\n   registerBoundServerReference(action, id, bound);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -582,11 +581,8 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function createErrorChunk(response, error) {\n-  return new ReactPromise(\"rejected\", null, error, response);\n+  return new ReactPromise(\"rejected\", null, error);\n }\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -630,23 +626,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -667,12 +664,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -719,7 +717,7 @@ function getChunk(response, id) {\n   chunk ||\n     ((chunk = response._closed\n       ? createErrorChunk(response, response._closedReason)\n-      : createPendingChunk(response)),\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1063,25 +1061,25 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n     chunk = chunks.get(id);\n   model = JSON.parse(model, response._fromJSON);\n   var clientReference = resolveClientReference(response._bundlerConfig, model);\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1094,23 +1092,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1131,7 +1126,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1146,7 +1141,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1158,7 +1153,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1209,10 +1204,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1227,8 +1221,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1248,7 +1241,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1259,9 +1257,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1271,7 +1275,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1431,10 +1435,10 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n         : tag.set(id, createErrorChunk(response, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1474,11 +1478,8 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1505,12 +1506,7 @@ function createFromJSONCallback(response) {\n             (key = createErrorChunk(response, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "87cf2bdf6c5f1714aaed05fae9f53a5abeebb88b",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.edge.development.js",
            "status": "modified",
            "additions": 86,
            "deletions": 78,
            "changes": 164,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1357,11 +1357,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1384,11 +1383,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1434,25 +1433,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1473,13 +1473,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1516,6 +1517,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1576,7 +1580,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -2044,6 +2048,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -2077,7 +2084,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -2108,43 +2116,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -2159,14 +2165,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -2179,28 +2185,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -2221,12 +2219,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2241,7 +2234,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2253,7 +2246,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2304,10 +2297,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2322,8 +2314,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2347,7 +2338,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2358,9 +2354,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2370,7 +2372,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2660,15 +2662,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2786,9 +2793,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3237,7 +3244,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3368,7 +3375,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3399,7 +3406,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {"
        },
        {
            "sha": "0ce99bb46951330b7cab048c796e06fdcc349646",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.edge.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -692,11 +692,10 @@ function createServerReference$1(id, callServer, encodeFormAction) {\n   registerBoundServerReference(action, id, null, encodeFormAction);\n   return action;\n }\n-function ReactPromise(status, value, reason, response) {\n+function ReactPromise(status, value, reason) {\n   this.status = status;\n   this.value = value;\n   this.reason = reason;\n-  this._response = response;\n }\n ReactPromise.prototype = Object.create(Promise.prototype);\n ReactPromise.prototype.then = function (resolve, reject) {\n@@ -743,11 +742,8 @@ function readChunk(chunk) {\n       throw chunk.reason;\n   }\n }\n-function createPendingChunk(response) {\n-  return new ReactPromise(\"pending\", null, null, response);\n-}\n function createErrorChunk(response, error) {\n-  return new ReactPromise(\"rejected\", null, error, response);\n+  return new ReactPromise(\"rejected\", null, error);\n }\n function wakeChunk(listeners, value) {\n   for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -791,23 +787,24 @@ function createResolvedIteratorResultChunk(response, value, done) {\n   return new ReactPromise(\n     \"resolved_model\",\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\",\n-    null,\n     response\n   );\n }\n-function resolveIteratorResultChunk(chunk, value, done) {\n+function resolveIteratorResultChunk(response, chunk, value, done) {\n   resolveModelChunk(\n+    response,\n     chunk,\n     (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') + value + \"}\"\n   );\n }\n-function resolveModelChunk(chunk, value) {\n+function resolveModelChunk(response, chunk, value) {\n   if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n   else {\n     var resolveListeners = chunk.value,\n       rejectListeners = chunk.reason;\n     chunk.status = \"resolved_model\";\n     chunk.value = value;\n+    chunk.reason = response;\n     null !== resolveListeners &&\n       (initializeModelChunk(chunk),\n       wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -828,12 +825,13 @@ var initializingHandler = null;\n function initializeModelChunk(chunk) {\n   var prevHandler = initializingHandler;\n   initializingHandler = null;\n-  var resolvedModel = chunk.value;\n+  var resolvedModel = chunk.value,\n+    response = chunk.reason;\n   chunk.status = \"blocked\";\n   chunk.value = null;\n   chunk.reason = null;\n   try {\n-    var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+    var value = JSON.parse(resolvedModel, response._fromJSON),\n       resolveListeners = chunk.value;\n     null !== resolveListeners &&\n       ((chunk.value = null),\n@@ -880,7 +878,7 @@ function getChunk(response, id) {\n   chunk ||\n     ((chunk = response._closed\n       ? createErrorChunk(response, response._closedReason)\n-      : createPendingChunk(response)),\n+      : new ReactPromise(\"pending\", null, null)),\n     chunks.set(id, chunk));\n   return chunk;\n }\n@@ -1239,11 +1237,11 @@ function ResponseInstance(\n   this._fromJSON = createFromJSONCallback(this);\n }\n function resolveBuffer(response, id, buffer) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n+  response = response._chunks;\n+  var chunk = response.get(id);\n   chunk && \"pending\" !== chunk.status\n     ? chunk.reason.enqueueValue(buffer)\n-    : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+    : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n }\n function resolveModule(response, id, model) {\n   var chunks = response._chunks,\n@@ -1255,14 +1253,14 @@ function resolveModule(response, id, model) {\n     model[1],\n     response._nonce\n   );\n-  if ((model = preloadModule(clientReference))) {\n+  if ((response = preloadModule(clientReference))) {\n     if (chunk) {\n       var blockedChunk = chunk;\n       blockedChunk.status = \"blocked\";\n     } else\n-      (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+      (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n         chunks.set(id, blockedChunk);\n-    model.then(\n+    response.then(\n       function () {\n         return resolveModuleChunk(blockedChunk, clientReference);\n       },\n@@ -1275,23 +1273,20 @@ function resolveModule(response, id, model) {\n       ? resolveModuleChunk(chunk, clientReference)\n       : chunks.set(\n           id,\n-          new ReactPromise(\"resolved_module\", clientReference, null, response)\n+          new ReactPromise(\"resolved_module\", clientReference, null)\n         );\n }\n function resolveStream(response, id, stream, controller) {\n-  var chunks = response._chunks,\n-    chunk = chunks.get(id);\n-  chunk\n-    ? \"pending\" === chunk.status &&\n-      ((response = chunk.value),\n-      (chunk.status = \"fulfilled\"),\n-      (chunk.value = stream),\n-      (chunk.reason = controller),\n-      null !== response && wakeChunk(response, chunk.value))\n-    : chunks.set(\n-        id,\n-        new ReactPromise(\"fulfilled\", stream, controller, response)\n-      );\n+  var chunks = response._chunks;\n+  response = chunks.get(id);\n+  response\n+    ? \"pending\" === response.status &&\n+      ((id = response.value),\n+      (response.status = \"fulfilled\"),\n+      (response.value = stream),\n+      (response.reason = controller),\n+      null !== id && wakeChunk(id, response.value))\n+    : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n }\n function startReadableStream(response, id, type) {\n   var controller = null;\n@@ -1312,7 +1307,7 @@ function startReadableStream(response, id, type) {\n     },\n     enqueueModel: function (json) {\n       if (null === previousBlockedChunk) {\n-        var chunk = new ReactPromise(\"resolved_model\", json, null, response);\n+        var chunk = new ReactPromise(\"resolved_model\", json, response);\n         initializeModelChunk(chunk);\n         \"fulfilled\" === chunk.status\n           ? controller.enqueue(chunk.value)\n@@ -1327,7 +1322,7 @@ function startReadableStream(response, id, type) {\n             (previousBlockedChunk = chunk));\n       } else {\n         chunk = previousBlockedChunk;\n-        var chunk$51 = createPendingChunk(response);\n+        var chunk$51 = new ReactPromise(\"pending\", null, null);\n         chunk$51.then(\n           function (v) {\n             return controller.enqueue(v);\n@@ -1339,7 +1334,7 @@ function startReadableStream(response, id, type) {\n         previousBlockedChunk = chunk$51;\n         chunk.then(function () {\n           previousBlockedChunk === chunk$51 && (previousBlockedChunk = null);\n-          resolveModelChunk(chunk$51, json);\n+          resolveModelChunk(response, chunk$51, json);\n         });\n       }\n     },\n@@ -1390,10 +1385,9 @@ function startAsyncIterable(response, id, iterator) {\n           return new ReactPromise(\n             \"fulfilled\",\n             { done: !0, value: void 0 },\n-            null,\n-            response\n+            null\n           );\n-        buffer[nextReadIndex] = createPendingChunk(response);\n+        buffer[nextReadIndex] = new ReactPromise(\"pending\", null, null);\n       }\n       return buffer[nextReadIndex++];\n     });\n@@ -1408,8 +1402,7 @@ function startAsyncIterable(response, id, iterator) {\n           buffer[nextWriteIndex] = new ReactPromise(\n             \"fulfilled\",\n             { done: !1, value: value },\n-            null,\n-            response\n+            null\n           );\n         else {\n           var chunk = buffer[nextWriteIndex],\n@@ -1429,7 +1422,12 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !1\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !1\n+            );\n         nextWriteIndex++;\n       },\n       close: function (value) {\n@@ -1440,9 +1438,15 @@ function startAsyncIterable(response, id, iterator) {\n               value,\n               !0\n             ))\n-          : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+          : resolveIteratorResultChunk(\n+              response,\n+              buffer[nextWriteIndex],\n+              value,\n+              !0\n+            );\n         for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n           resolveIteratorResultChunk(\n+            response,\n             buffer[nextWriteIndex++],\n             '\"$undefined\"',\n             !0\n@@ -1452,7 +1456,7 @@ function startAsyncIterable(response, id, iterator) {\n         closed = !0;\n         for (\n           nextWriteIndex === buffer.length &&\n-          (buffer[nextWriteIndex] = createPendingChunk(response));\n+          (buffer[nextWriteIndex] = new ReactPromise(\"pending\", null, null));\n           nextWriteIndex < buffer.length;\n \n         )\n@@ -1612,10 +1616,10 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n         : tag.set(id, createErrorChunk(response, buffer));\n       break;\n     case 84:\n-      tag = response._chunks;\n-      (chunk = tag.get(id)) && \"pending\" !== chunk.status\n-        ? chunk.reason.enqueueValue(buffer)\n-        : tag.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+      response = response._chunks;\n+      (tag = response.get(id)) && \"pending\" !== tag.status\n+        ? tag.reason.enqueueValue(buffer)\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n       break;\n     case 78:\n     case 68:\n@@ -1655,11 +1659,8 @@ function processFullBinaryRow(response, id, tag, buffer, chunk) {\n     default:\n       (tag = response._chunks),\n         (chunk = tag.get(id))\n-          ? resolveModelChunk(chunk, buffer)\n-          : tag.set(\n-              id,\n-              new ReactPromise(\"resolved_model\", buffer, null, response)\n-            );\n+          ? resolveModelChunk(response, chunk, buffer)\n+          : tag.set(id, new ReactPromise(\"resolved_model\", buffer, response));\n   }\n }\n function createFromJSONCallback(response) {\n@@ -1686,12 +1687,7 @@ function createFromJSONCallback(response) {\n             (key = createErrorChunk(response, value.value)),\n               (key = createLazyChunkWrapper(key));\n           else if (0 < value.deps) {\n-            var blockedChunk = new ReactPromise(\n-              \"blocked\",\n-              null,\n-              null,\n-              response\n-            );\n+            var blockedChunk = new ReactPromise(\"blocked\", null, null);\n             value.value = key;\n             value.chunk = blockedChunk;\n             key = createLazyChunkWrapper(blockedChunk);"
        },
        {
            "sha": "df6c32633f5fb511b72a5a48b5513c37175de171",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.node.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 79,
            "changes": 167,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022",
            "patch": "@@ -1357,11 +1357,10 @@\n         error += \"\\n    at \" + structuredStackTrace[i].toString();\n       return error;\n     }\n-    function ReactPromise(status, value, reason, response) {\n+    function ReactPromise(status, value, reason) {\n       this.status = status;\n       this.value = value;\n       this.reason = reason;\n-      this._response = response;\n       this._children = [];\n       this._debugInfo = null;\n     }\n@@ -1384,11 +1383,11 @@\n           throw chunk.reason;\n       }\n     }\n-    function createPendingChunk(response) {\n-      return new ReactPromise(\"pending\", null, null, response);\n+    function createPendingChunk() {\n+      return new ReactPromise(\"pending\", null, null);\n     }\n     function createErrorChunk(response, error) {\n-      return new ReactPromise(\"rejected\", null, error, response);\n+      return new ReactPromise(\"rejected\", null, error);\n     }\n     function wakeChunk(listeners, value) {\n       for (var i = 0; i < listeners.length; i++) (0, listeners[i])(value);\n@@ -1434,25 +1433,26 @@\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\",\n-        null,\n         response\n       );\n     }\n-    function resolveIteratorResultChunk(chunk, value, done) {\n+    function resolveIteratorResultChunk(response, chunk, value, done) {\n       resolveModelChunk(\n+        response,\n         chunk,\n         (done ? '{\"done\":true,\"value\":' : '{\"done\":false,\"value\":') +\n           value +\n           \"}\"\n       );\n     }\n-    function resolveModelChunk(chunk, value) {\n+    function resolveModelChunk(response, chunk, value) {\n       if (\"pending\" !== chunk.status) chunk.reason.enqueueModel(value);\n       else {\n         var resolveListeners = chunk.value,\n           rejectListeners = chunk.reason;\n         chunk.status = \"resolved_model\";\n         chunk.value = value;\n+        chunk.reason = response;\n         null !== resolveListeners &&\n           (initializeModelChunk(chunk),\n           wakeChunkIfInitialized(chunk, resolveListeners, rejectListeners));\n@@ -1473,13 +1473,14 @@\n       var prevHandler = initializingHandler,\n         prevChunk = initializingChunk;\n       initializingHandler = null;\n-      var resolvedModel = chunk.value;\n+      var resolvedModel = chunk.value,\n+        response = chunk.reason;\n       chunk.status = \"blocked\";\n       chunk.value = null;\n       chunk.reason = null;\n       initializingChunk = chunk;\n       try {\n-        var value = JSON.parse(resolvedModel, chunk._response._fromJSON),\n+        var value = JSON.parse(resolvedModel, response._fromJSON),\n           resolveListeners = chunk.value;\n         null !== resolveListeners &&\n           ((chunk.value = null),\n@@ -1516,6 +1517,9 @@\n       response._chunks.forEach(function (chunk) {\n         \"pending\" === chunk.status && triggerErrorOnChunk(chunk, error);\n       });\n+      var debugChannel = response._debugChannel;\n+      void 0 !== debugChannel &&\n+        (debugChannel(\"\"), (response._debugChannel = void 0));\n       supportsUserTiming &&\n         (console.timeStamp(\n           \"Server Requests Track\",\n@@ -1576,7 +1580,7 @@\n       chunk ||\n         ((chunk = response._closed\n           ? createErrorChunk(response, response._closedReason)\n-          : createPendingChunk(response)),\n+          : createPendingChunk()),\n         chunks.set(id, chunk));\n       return chunk;\n     }\n@@ -2044,6 +2048,9 @@\n             }\n           case \"Y\":\n             return (\n+              2 < value.length &&\n+                (response = response._debugChannel) &&\n+                ((value = value.slice(2)), response(\"R:\" + value)),\n               Object.defineProperty(parentObject, key, {\n                 get: function () {\n                   return \"This object has been omitted by React in the console log to avoid sending too much data from the server. Try logging smaller or more specific objects.\";\n@@ -2077,7 +2084,8 @@\n       temporaryReferences,\n       findSourceMapURL,\n       replayConsole,\n-      environmentName\n+      environmentName,\n+      debugChannel\n     ) {\n       var chunks = new Map();\n       this._bundlerConfig = bundlerConfig;\n@@ -2108,43 +2116,41 @@\n           '\"use ' + environmentName.toLowerCase() + '\"'\n         ));\n       this._debugFindSourceMapURL = findSourceMapURL;\n+      this._debugChannel = debugChannel;\n       this._replayConsole = replayConsole;\n       this._rootEnvironmentName = environmentName;\n       this._fromJSON = createFromJSONCallback(this);\n     }\n     function resolveDebugHalt(response, id) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk || chunks.set(id, (chunk = createPendingChunk(response)));\n+      response = response._chunks;\n+      var chunk = response.get(id);\n+      chunk || response.set(id, (chunk = createPendingChunk()));\n       if (\"pending\" === chunk.status || \"blocked\" === chunk.status)\n-        (response = chunk),\n-          (response.status = \"halted\"),\n-          (response.value = null),\n-          (response.reason = null);\n+        (id = chunk),\n+          (id.status = \"halted\"),\n+          (id.value = null),\n+          (id.reason = null);\n     }\n     function resolveModel(response, id, model) {\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? resolveModelChunk(chunk, model)\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"resolved_model\", model, null, response)\n-          );\n+        ? resolveModelChunk(response, chunk, model)\n+        : chunks.set(id, new ReactPromise(\"resolved_model\", model, response));\n     }\n     function resolveText(response, id, text) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(text)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", text, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", text, null));\n     }\n     function resolveBuffer(response, id, buffer) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n+      response = response._chunks;\n+      var chunk = response.get(id);\n       chunk && \"pending\" !== chunk.status\n         ? chunk.reason.enqueueValue(buffer)\n-        : chunks.set(id, new ReactPromise(\"fulfilled\", buffer, null, response));\n+        : response.set(id, new ReactPromise(\"fulfilled\", buffer, null));\n     }\n     function resolveModule(response, id, model) {\n       var chunks = response._chunks,\n@@ -2159,14 +2165,14 @@\n         model[1],\n         response._nonce\n       );\n-      if ((model = preloadModule(clientReference))) {\n+      if ((response = preloadModule(clientReference))) {\n         if (chunk) {\n           var blockedChunk = chunk;\n           blockedChunk.status = \"blocked\";\n         } else\n-          (blockedChunk = new ReactPromise(\"blocked\", null, null, response)),\n+          (blockedChunk = new ReactPromise(\"blocked\", null, null)),\n             chunks.set(id, blockedChunk);\n-        model.then(\n+        response.then(\n           function () {\n             return resolveModuleChunk(blockedChunk, clientReference);\n           },\n@@ -2179,28 +2185,20 @@\n           ? resolveModuleChunk(chunk, clientReference)\n           : chunks.set(\n               id,\n-              new ReactPromise(\n-                \"resolved_module\",\n-                clientReference,\n-                null,\n-                response\n-              )\n+              new ReactPromise(\"resolved_module\", clientReference, null)\n             );\n     }\n     function resolveStream(response, id, stream, controller) {\n-      var chunks = response._chunks,\n-        chunk = chunks.get(id);\n-      chunk\n-        ? \"pending\" === chunk.status &&\n-          ((response = chunk.value),\n-          (chunk.status = \"fulfilled\"),\n-          (chunk.value = stream),\n-          (chunk.reason = controller),\n-          null !== response && wakeChunk(response, chunk.value))\n-        : chunks.set(\n-            id,\n-            new ReactPromise(\"fulfilled\", stream, controller, response)\n-          );\n+      var chunks = response._chunks;\n+      response = chunks.get(id);\n+      response\n+        ? \"pending\" === response.status &&\n+          ((id = response.value),\n+          (response.status = \"fulfilled\"),\n+          (response.value = stream),\n+          (response.reason = controller),\n+          null !== id && wakeChunk(id, response.value))\n+        : chunks.set(id, new ReactPromise(\"fulfilled\", stream, controller));\n     }\n     function startReadableStream(response, id, type) {\n       var controller = null;\n@@ -2221,12 +2219,7 @@\n         },\n         enqueueModel: function (json) {\n           if (null === previousBlockedChunk) {\n-            var chunk = new ReactPromise(\n-              \"resolved_model\",\n-              json,\n-              null,\n-              response\n-            );\n+            var chunk = new ReactPromise(\"resolved_model\", json, response);\n             initializeModelChunk(chunk);\n             \"fulfilled\" === chunk.status\n               ? controller.enqueue(chunk.value)\n@@ -2241,7 +2234,7 @@\n                 (previousBlockedChunk = chunk));\n           } else {\n             chunk = previousBlockedChunk;\n-            var _chunk3 = createPendingChunk(response);\n+            var _chunk3 = createPendingChunk();\n             _chunk3.then(\n               function (v) {\n                 return controller.enqueue(v);\n@@ -2253,7 +2246,7 @@\n             previousBlockedChunk = _chunk3;\n             chunk.then(function () {\n               previousBlockedChunk === _chunk3 && (previousBlockedChunk = null);\n-              resolveModelChunk(_chunk3, json);\n+              resolveModelChunk(response, _chunk3, json);\n             });\n           }\n         },\n@@ -2304,10 +2297,9 @@\n               return new ReactPromise(\n                 \"fulfilled\",\n                 { done: !0, value: void 0 },\n-                null,\n-                response\n+                null\n               );\n-            buffer[nextReadIndex] = createPendingChunk(response);\n+            buffer[nextReadIndex] = createPendingChunk();\n           }\n           return buffer[nextReadIndex++];\n         });\n@@ -2322,8 +2314,7 @@\n               buffer[nextWriteIndex] = new ReactPromise(\n                 \"fulfilled\",\n                 { done: !1, value: value },\n-                null,\n-                response\n+                null\n               );\n             else {\n               var chunk = buffer[nextWriteIndex],\n@@ -2347,7 +2338,12 @@\n                   value,\n                   !1\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !1);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !1\n+                );\n             nextWriteIndex++;\n           },\n           close: function (value) {\n@@ -2358,9 +2354,15 @@\n                   value,\n                   !0\n                 ))\n-              : resolveIteratorResultChunk(buffer[nextWriteIndex], value, !0);\n+              : resolveIteratorResultChunk(\n+                  response,\n+                  buffer[nextWriteIndex],\n+                  value,\n+                  !0\n+                );\n             for (nextWriteIndex++; nextWriteIndex < buffer.length; )\n               resolveIteratorResultChunk(\n+                response,\n                 buffer[nextWriteIndex++],\n                 '\"$undefined\"',\n                 !0\n@@ -2370,7 +2372,7 @@\n             closed = !0;\n             for (\n               nextWriteIndex === buffer.length &&\n-              (buffer[nextWriteIndex] = createPendingChunk(response));\n+              (buffer[nextWriteIndex] = createPendingChunk());\n               nextWriteIndex < buffer.length;\n \n             )\n@@ -2660,15 +2662,20 @@\n       return Error(\"react-stack-top-frame\");\n     }\n     function initializeFakeStack(response, debugInfo) {\n-      void 0 === debugInfo.debugStack &&\n-        (null != debugInfo.stack &&\n+      if (void 0 === debugInfo.debugStack) {\n+        null != debugInfo.stack &&\n           (debugInfo.debugStack = createFakeJSXCallStackInDEV(\n             response,\n             debugInfo.stack,\n             null == debugInfo.env ? \"\" : debugInfo.env\n-          )),\n-        null != debugInfo.owner &&\n-          initializeFakeStack(response, debugInfo.owner));\n+          ));\n+        var owner = debugInfo.owner;\n+        null != owner &&\n+          (initializeFakeStack(response, owner),\n+          void 0 === owner.debugLocation &&\n+            null != debugInfo.debugStack &&\n+            (owner.debugLocation = debugInfo.debugStack));\n+      }\n     }\n     function resolveDebugInfo(response, id, debugInfo) {\n       void 0 !== debugInfo.stack && initializeFakeTask(response, debugInfo);\n@@ -2786,9 +2793,9 @@\n       var chunks = response._chunks,\n         chunk = chunks.get(id);\n       chunk\n-        ? (resolveModelChunk(chunk, model),\n+        ? (resolveModelChunk(response, chunk, model),\n           \"resolved_model\" === chunk.status && initializeModelChunk(chunk))\n-        : ((chunk = new ReactPromise(\"resolved_model\", model, null, response)),\n+        : ((chunk = new ReactPromise(\"resolved_model\", model, response)),\n           chunks.set(id, chunk),\n           initializeModelChunk(chunk));\n       \"fulfilled\" === chunk.status\n@@ -3237,7 +3244,7 @@\n           response._timeOrigin = +row - performance.timeOrigin;\n           break;\n         case 68:\n-          tag = new ReactPromise(\"resolved_model\", row, null, response);\n+          tag = new ReactPromise(\"resolved_model\", row, response);\n           initializeModelChunk(tag);\n           \"fulfilled\" === tag.status\n             ? resolveDebugInfo(response, id, tag.value)\n@@ -3447,7 +3454,7 @@\n                     (key._debugInfo = [stack]),\n                     (value = createLazyChunkWrapper(key)))\n                   : 0 < stack.deps &&\n-                    ((key = new ReactPromise(\"blocked\", null, null, response)),\n+                    ((key = new ReactPromise(\"blocked\", null, null)),\n                     (stack.value = value),\n                     (stack.chunk = key),\n                     (value = Object.freeze.bind(Object, value.props)),\n@@ -3481,7 +3488,8 @@\n           : void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n     }\n     function startReadingFromStream(response, stream) {\n@@ -3736,7 +3744,8 @@\n         void 0,\n         options && options.findSourceMapURL ? options.findSourceMapURL : void 0,\n         options ? !0 === options.replayConsoleLogs : !1,\n-        options && options.environmentName ? options.environmentName : void 0\n+        options && options.environmentName ? options.environmentName : void 0,\n+        void 0\n       );\n       stream.on(\"data\", function (chunk) {\n         if (\"string\" === typeof chunk) {"
        },
        {
            "sha": "cd7d9315f0665f6a56134d300bc2c7868f95e260",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.node.production.js",
            "status": "modified",
            "additions": 0,
            "deletions": 0,
            "changes": 0,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "fb2d154fb995e8b2603baf966d2b0b3056c91972",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.node.unbundled.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 79,
            "changes": 167,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "6f4fd89b47ff60931c93e9e3371a35117be29c58",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-client.node.unbundled.production.js",
            "status": "modified",
            "additions": 54,
            "deletions": 58,
            "changes": 112,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "ac413eccb95de2e500ac6c96c1a0bcc9ffe0385e",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.browser.development.js",
            "status": "modified",
            "additions": 281,
            "deletions": 132,
            "changes": 413,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "4a68b9e126fad2a04dfbdaf3c7b90d985c4c2b7b",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.browser.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 122,
            "changes": 223,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "e1b4d6f70dbc6df8b8f790348c5fbd7cc19ba175",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.edge.development.js",
            "status": "modified",
            "additions": 281,
            "deletions": 129,
            "changes": 410,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "ce98a66b3cf08ee8cd751a1a3d53578c747be159",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.edge.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 119,
            "changes": 220,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "8c16eaa0fb3a1d79e5e155903c08884f2c85d9ba",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.node.development.js",
            "status": "modified",
            "additions": 395,
            "deletions": 159,
            "changes": 554,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "5ba936c071b6045d82e1989abd23fb2f41997fe6",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.node.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 143,
            "changes": 263,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "955cedb6dea619d4cfd210abc2317012520b6b80",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.node.unbundled.development.js",
            "status": "modified",
            "additions": 395,
            "deletions": 159,
            "changes": 554,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "bf23cb7014af04abac3a116e9524e52eef7081bf",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/cjs/react-server-dom-webpack-server.node.unbundled.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 143,
            "changes": 263,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "e0c30854c3e2a8341b3ac4218250975a59fc4c4f",
            "filename": "packages/next/src/compiled/react-server-dom-webpack-experimental/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack-experimental%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "9ca270c9990636023d2f3d30820e0bfd5eb5fe3c",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.browser.development.js",
            "status": "modified",
            "additions": 105,
            "deletions": 85,
            "changes": 190,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "4274b46c7cb9b23406044931d0bf2cce8a018138",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.browser.production.js",
            "status": "modified",
            "additions": 62,
            "deletions": 66,
            "changes": 128,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "94055f16973f9c87aa35c76719a5bd5556b6c87f",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.edge.development.js",
            "status": "modified",
            "additions": 86,
            "deletions": 83,
            "changes": 169,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "ed3edf4ccf05144335f73001d4e9ae674113cf1f",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.edge.production.js",
            "status": "modified",
            "additions": 62,
            "deletions": 66,
            "changes": 128,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "b3b0832f745d2c4b4ad129760451ef5b18279a7e",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.node.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 84,
            "changes": 172,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "8dc059a269ff7f0c2990d2b1b59cf540d81a9f2c",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.node.production.js",
            "status": "modified",
            "additions": 65,
            "deletions": 69,
            "changes": 134,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "e1ce7e48bf069e5b98f917d0925d10c55fbfa3ec",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.node.unbundled.development.js",
            "status": "modified",
            "additions": 88,
            "deletions": 84,
            "changes": 172,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "09dcb3c31416b0aa17d78411b1934ced7905ae9b",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-client.node.unbundled.production.js",
            "status": "modified",
            "additions": 65,
            "deletions": 69,
            "changes": 134,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-client.node.unbundled.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "9abb7d008f6c30ddad62356a2c5a61b5d4a317ea",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.browser.development.js",
            "status": "modified",
            "additions": 265,
            "deletions": 123,
            "changes": 388,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "96babc2bbb873e22937f41f22bb86ec0d66cb0a5",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.browser.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 118,
            "changes": 219,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.browser.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "160d7db8da8b265bf56b2ad88ba0d3a3b96f96e7",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.edge.development.js",
            "status": "modified",
            "additions": 265,
            "deletions": 120,
            "changes": 385,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "46b4f5ea707eab5c83b8261dd03be0416cccce4f",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.edge.production.js",
            "status": "modified",
            "additions": 101,
            "deletions": 115,
            "changes": 216,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.edge.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "fd942c3d2ab44d12f5820a399118a51919866157",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.node.development.js",
            "status": "modified",
            "additions": 337,
            "deletions": 137,
            "changes": 474,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "3fd735752cb2cb82b773e72d274be316b30ffc8a",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.node.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 139,
            "changes": 259,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "e97fd21dad296b3521063f6bfb03f15098fe8e3d",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.node.unbundled.development.js",
            "status": "modified",
            "additions": 337,
            "deletions": 137,
            "changes": 474,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "71609d30e18ccf4a645c68ad9f06d51aa24317ad",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.node.unbundled.production.js",
            "status": "modified",
            "additions": 120,
            "deletions": 139,
            "changes": 259,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fcjs%2Freact-server-dom-webpack-server.node.unbundled.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "9dcc62ee0c4d5fc2ef01450a3ab20cf86c280e76",
            "filename": "packages/next/src/compiled/react-server-dom-webpack/package.json",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fpackage.json",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fpackage.json",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact-server-dom-webpack%2Fpackage.json?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "46f4cf639ca245c60bc2549553d1f77ec848131b",
            "filename": "packages/next/src/compiled/react/cjs/react.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "f39acca6a69e6898df2e0bb56dbab50d3818e75a",
            "filename": "packages/next/src/compiled/react/cjs/react.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "83e167f32ccc2b585a92f72342e4a5cf5b928497",
            "filename": "packages/next/src/compiled/react/cjs/react.react-server.development.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.development.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.development.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.development.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "5f41e08322489dacaf0cbad856aef7f861607419",
            "filename": "packages/next/src/compiled/react/cjs/react.react-server.production.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.production.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.production.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Freact%2Fcjs%2Freact.react-server.production.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "2a807c4d9a1f4a599d1c42e9f15657ab2a039ad4",
            "filename": "packages/next/src/compiled/unistore/unistore.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Funistore%2Funistore.js",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/packages%2Fnext%2Fsrc%2Fcompiled%2Funistore%2Funistore.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcompiled%2Funistore%2Funistore.js?ref=d93f940a50b810621c0fed839566897a1c375022"
        },
        {
            "sha": "ca7a7d2d870a37abf8ae0b7d6fa76e478299c419",
            "filename": "pnpm-lock.yaml",
            "status": "modified",
            "additions": 236,
            "deletions": 209,
            "changes": 445,
            "blob_url": "https://github.com/vercel/next.js/blob/d93f940a50b810621c0fed839566897a1c375022/pnpm-lock.yaml",
            "raw_url": "https://github.com/vercel/next.js/raw/d93f940a50b810621c0fed839566897a1c375022/pnpm-lock.yaml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/pnpm-lock.yaml?ref=d93f940a50b810621c0fed839566897a1c375022"
        }
    ],
    "stats": {
        "total": 17853,
        "additions": 10482,
        "deletions": 7371
    }
}