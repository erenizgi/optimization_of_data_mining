{
    "author": "sokra",
    "message": "Turbopack: improve overhead benchmarks (#83231)\n\n### What?\r\n\r\n* add tokio\r\n* add parallel benchmark\r\n* configure worker_threads\r\n* configure malloc",
    "sha": "10f5495fca99ab43a4235986c6a1406159a4021d",
    "files": [
        {
            "sha": "2330e205f4b3527b6746c1837c488ab5694f9475",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/10f5495fca99ab43a4235986c6a1406159a4021d/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/10f5495fca99ab43a4235986c6a1406159a4021d/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=10f5495fca99ab43a4235986c6a1406159a4021d",
            "patch": "@@ -9246,6 +9246,7 @@ dependencies = [\n  \"codspeed-criterion-compat\",\n  \"dashmap 6.1.0\",\n  \"either\",\n+ \"futures\",\n  \"hashbrown 0.14.5\",\n  \"indexmap 2.9.0\",\n  \"lmdb-rkv\",\n@@ -9269,6 +9270,7 @@ dependencies = [\n  \"turbo-rcstr\",\n  \"turbo-tasks\",\n  \"turbo-tasks-build\",\n+ \"turbo-tasks-malloc\",\n  \"turbo-tasks-testing\",\n ]\n "
        },
        {
            "sha": "3861169f5e265cdbd455242b3b283e6f0b24af38",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/10f5495fca99ab43a4235986c6a1406159a4021d/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/10f5495fca99ab43a4235986c6a1406159a4021d/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=10f5495fca99ab43a4235986c6a1406159a4021d",
            "patch": "@@ -56,8 +56,10 @@ turbo-tasks-testing = { workspace = true }\n \n [dev-dependencies]\n criterion = { workspace = true, features = [\"async_tokio\"] }\n+futures = { workspace = true }\n regex = { workspace = true }\n tempfile = { workspace = true }\n+turbo-tasks-malloc = { workspace = true }\n rstest = { workspace = true }\n \n [build-dependencies]"
        },
        {
            "sha": "329b171ad4d1a50ae6ac571614e6bd721a255c80",
            "filename": "turbopack/crates/turbo-tasks-backend/benches/overhead.rs",
            "status": "modified",
            "additions": 89,
            "deletions": 9,
            "changes": 98,
            "blob_url": "https://github.com/vercel/next.js/blob/10f5495fca99ab43a4235986c6a1406159a4021d/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/10f5495fca99ab43a4235986c6a1406159a4021d/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs?ref=10f5495fca99ab43a4235986c6a1406159a4021d",
            "patch": "@@ -1,11 +1,16 @@\n use std::time::{Duration, Instant};\n \n use criterion::{BenchmarkId, Criterion, black_box};\n+use futures::{FutureExt, StreamExt, stream::FuturesUnordered};\n+use tokio::spawn;\n use turbo_tasks::TurboTasks;\n use turbo_tasks_backend::{BackendOptions, TurboTasksBackend, noop_backing_storage};\n \n use super::register;\n \n+#[global_allocator]\n+static ALLOC: turbo_tasks_malloc::TurboMalloc = turbo_tasks_malloc::TurboMalloc;\n+\n // Tunable task: busy-wait for a given duration\n #[inline(never)]\n fn busy_task(duration: Duration) {\n@@ -18,7 +23,7 @@ fn busy_task(duration: Duration) {\n // Simulate running the task inside turbo-tasks (replace with actual turbo-tasks API)\n #[turbo_tasks::function]\n fn busy_turbo(key: u64, duration: Duration) {\n-    busy_task(duration);\n+    busy_task(black_box(duration));\n     black_box(key); // consume the key, we need it to be part of the cache key.\n }\n \n@@ -27,7 +32,18 @@ pub fn overhead(c: &mut Criterion) {\n \n     let mut group = c.benchmark_group(\"task_overhead\");\n     group.sample_size(100);\n-    let rt: tokio::runtime::Runtime = tokio::runtime::Builder::new_multi_thread()\n+\n+    let rt = tokio::runtime::Builder::new_multi_thread()\n+        .disable_lifo_slot()\n+        .worker_threads(1)\n+        .thread_name(\"tokio-thread\")\n+        .enable_all()\n+        .build()\n+        .unwrap();\n+\n+    let rt_parallel = tokio::runtime::Builder::new_multi_thread()\n+        .disable_lifo_slot()\n+        .thread_name(\"tokio-parallel-thread\")\n         .enable_all()\n         .build()\n         .unwrap();\n@@ -43,27 +59,74 @@ pub fn overhead(c: &mut Criterion) {\n             b.iter(|| busy_task(black_box(d)))\n         });\n \n+        group.bench_with_input(BenchmarkId::new(\"tokio\", micros), &duration, |b, &d| {\n+            b.to_async(&rt).iter_custom(move |iters| {\n+                spawn(async move {\n+                    let start = Instant::now();\n+                    for _ in 0..iters {\n+                        spawn(async move {\n+                            busy_task(black_box(d));\n+                        })\n+                        .await\n+                        .unwrap();\n+                    }\n+                    start.elapsed()\n+                })\n+                .then(|r| async { r.unwrap() })\n+            });\n+        });\n+\n         group.bench_with_input(\n             BenchmarkId::new(\"turbo-uncached\", micros),\n             &duration,\n             |b, &d| {\n-                run_turbo::<Uncached>(&rt, b, d);\n+                run_turbo::<Uncached>(&rt, b, d, false);\n             },\n         );\n \n         group.bench_with_input(\n             BenchmarkId::new(\"turbo-cached-same-keys\", micros),\n             &duration,\n             |b, &d| {\n-                run_turbo::<CachedSame>(&rt, b, d);\n+                run_turbo::<CachedSame>(&rt, b, d, false);\n             },\n         );\n \n         group.bench_with_input(\n             BenchmarkId::new(\"turbo-cached-different-keys\", micros),\n             &duration,\n             |b, &d| {\n-                run_turbo::<CachedDifferent>(&rt, b, d);\n+                run_turbo::<CachedDifferent>(&rt, b, d, false);\n+            },\n+        );\n+\n+        group.bench_with_input(\n+            BenchmarkId::new(\"tokio-parallel\", micros),\n+            &duration,\n+            |b, &d| {\n+                b.to_async(&rt_parallel).iter_custom(move |iters| {\n+                    spawn(async move {\n+                        let start = Instant::now();\n+                        let mut futures = (0..iters)\n+                            .map(|_| {\n+                                spawn(async move {\n+                                    busy_task(black_box(d));\n+                                })\n+                            })\n+                            .collect::<FuturesUnordered<_>>();\n+                        while futures.next().await.is_some() {}\n+                        start.elapsed()\n+                    })\n+                    .then(|r| async { r.unwrap() })\n+                });\n+            },\n+        );\n+\n+        group.bench_with_input(\n+            BenchmarkId::new(\"turbo-uncached-parallel\", micros),\n+            &duration,\n+            |b, &d| {\n+                run_turbo::<Uncached>(&rt_parallel, b, d, true);\n             },\n         );\n     }\n@@ -104,10 +167,12 @@ impl TurboMode for CachedDifferent {\n         true\n     }\n }\n+\n fn run_turbo<Mode: TurboMode>(\n     rt: &tokio::runtime::Runtime,\n     b: &mut criterion::Bencher<'_>,\n     d: Duration,\n+    is_parallel: bool,\n ) {\n     b.to_async(rt).iter_custom(|iters| {\n         // It is important to create the tt instance here to ensure the cache is not shared across\n@@ -125,14 +190,29 @@ fn run_turbo<Mode: TurboMode>(\n                 // If cached run once outside the loop to ensure the tasks are cached.\n                 if Mode::is_cached() {\n                     for i in 0..iters {\n+                        // Precache all possible tasks even if we might only check a few below.\n+                        // This ensures we are testing a large cache\n+                        // Do not use Mode::key here, to create a large task set\n                         black_box(busy_turbo(i, black_box(d)).await?);\n                     }\n                 }\n-                let start = Instant::now();\n-                for i in 0..iters {\n-                    black_box(busy_turbo(Mode::key(i), black_box(d)).await?);\n+                if is_parallel {\n+                    let mut vcs = Vec::with_capacity(iters as usize);\n+                    let start = Instant::now();\n+                    vcs.extend(\n+                        (0..iters).map(|i| black_box(busy_turbo(Mode::key(i), black_box(d)))),\n+                    );\n+                    for vc in vcs {\n+                        vc.await?;\n+                    }\n+                    Ok(start.elapsed())\n+                } else {\n+                    let start = Instant::now();\n+                    for i in 0..iters {\n+                        black_box(busy_turbo(Mode::key(i), black_box(d)).await?);\n+                    }\n+                    Ok(start.elapsed())\n                 }\n-                Ok(start.elapsed())\n             })\n             .await\n             .unwrap()"
        }
    ],
    "stats": {
        "total": 102,
        "additions": 93,
        "deletions": 9
    }
}