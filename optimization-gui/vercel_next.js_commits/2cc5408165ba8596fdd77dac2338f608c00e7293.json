{
    "author": "sokra",
    "message": "Turbopack: refactor backend jobs (#83019)\n\n### What?\n\nUse associated types to avoid Box and Any.\n\n* avoids any casting\n* avoid extra vec collecting\n* avoid cloning lists for parallelization",
    "sha": "2cc5408165ba8596fdd77dac2338f608c00e7293",
    "files": [
        {
            "sha": "9f677fa10334a36ec747a80e394aae1c7d47f304",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 115,
            "deletions": 106,
            "changes": 221,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -3,12 +3,13 @@ mod operation;\n mod storage;\n \n use std::{\n-    any::Any,\n     borrow::Cow,\n+    cmp::min,\n     fmt::{self, Write},\n     future::Future,\n     hash::BuildHasherDefault,\n     mem::take,\n+    ops::Range,\n     pin::Pin,\n     sync::{\n         Arc,\n@@ -26,11 +27,11 @@ use smallvec::{SmallVec, smallvec};\n use tokio::time::{Duration, Instant};\n use tracing::{field::Empty, info_span};\n use turbo_tasks::{\n-    CellId, FxDashMap, KeyValuePair, RawVc, ReadCellOptions, ReadConsistency, SessionId,\n-    TRANSIENT_TASK_BIT, TaskExecutionReason, TaskId, TraitTypeId, TurboTasksBackendApi,\n+    CellId, FxDashMap, FxIndexMap, KeyValuePair, RawVc, ReadCellOptions, ReadConsistency,\n+    SessionId, TRANSIENT_TASK_BIT, TaskExecutionReason, TaskId, TraitTypeId, TurboTasksBackendApi,\n     ValueTypeId,\n     backend::{\n-        Backend, BackendJobId, CachedTaskType, CellContent, TaskExecutionSpec, TransientTaskRoot,\n+        Backend, CachedTaskType, CellContent, TaskExecutionSpec, TransientTaskRoot,\n         TransientTaskType, TurboTasksExecutionError, TypedCellContent,\n     },\n     event::{Event, EventListener},\n@@ -39,7 +40,7 @@ use turbo_tasks::{\n     task_statistics::TaskStatisticsApi,\n     trace::TraceRawVcs,\n     turbo_tasks,\n-    util::{IdFactoryWithReuse, good_chunk_size, into_chunks},\n+    util::{IdFactoryWithReuse, good_chunk_size},\n };\n \n pub use self::{operation::AnyOperation, storage::TaskDataCategory};\n@@ -70,11 +71,6 @@ use crate::{\n     },\n };\n \n-const BACKEND_JOB_INITIAL_SNAPSHOT: BackendJobId = unsafe { BackendJobId::new_unchecked(1) };\n-const BACKEND_JOB_FOLLOW_UP_SNAPSHOT: BackendJobId = unsafe { BackendJobId::new_unchecked(2) };\n-const BACKEND_JOB_PREFETCH_TASK: BackendJobId = unsafe { BackendJobId::new_unchecked(3) };\n-const BACKEND_JOB_PREFETCH_CHUNK_TASK: BackendJobId = unsafe { BackendJobId::new_unchecked(4) };\n-\n const SNAPSHOT_REQUESTED_BIT: usize = 1 << (usize::BITS - 1);\n \n struct SnapshotRequest {\n@@ -160,6 +156,15 @@ impl Default for BackendOptions {\n     }\n }\n \n+pub enum TurboTasksBackendJob {\n+    InitialSnapshot,\n+    FollowUpSnapshot,\n+    Prefetch {\n+        data: Arc<FxIndexMap<TaskId, bool>>,\n+        range: Option<Range<usize>>,\n+    },\n+}\n+\n pub struct TurboTasksBackend<B: BackingStorage>(Arc<TurboTasksBackendInner<B>>);\n \n type TaskCacheLog = Sharded<ChunkedVec<(Arc<CachedTaskType>, TaskId)>>;\n@@ -1210,7 +1215,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n \n         if self.should_persist() {\n             // Schedule the snapshot job\n-            turbo_tasks.schedule_backend_background_job(BACKEND_JOB_INITIAL_SNAPSHOT, None);\n+            turbo_tasks.schedule_backend_background_job(TurboTasksBackendJob::InitialSnapshot);\n         }\n     }\n \n@@ -2135,115 +2140,118 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n \n     fn run_backend_job<'a>(\n         self: &'a Arc<Self>,\n-        id: BackendJobId,\n-        data: Option<Box<dyn Any + Send>>,\n+        job: TurboTasksBackendJob,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<TurboTasksBackend<B>>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>> {\n         Box::pin(async move {\n-            if id == BACKEND_JOB_INITIAL_SNAPSHOT || id == BACKEND_JOB_FOLLOW_UP_SNAPSHOT {\n-                debug_assert!(self.should_persist());\n-\n-                let last_snapshot = self.last_snapshot.load(Ordering::Relaxed);\n-                let mut last_snapshot = self.start_time + Duration::from_millis(last_snapshot);\n-                loop {\n-                    const FIRST_SNAPSHOT_WAIT: Duration = Duration::from_secs(300);\n-                    const SNAPSHOT_INTERVAL: Duration = Duration::from_secs(120);\n-                    const IDLE_TIMEOUT: Duration = Duration::from_secs(2);\n-\n-                    let time = if id == BACKEND_JOB_INITIAL_SNAPSHOT {\n-                        FIRST_SNAPSHOT_WAIT\n-                    } else {\n-                        SNAPSHOT_INTERVAL\n-                    };\n-\n-                    let until = last_snapshot + time;\n-                    if until > Instant::now() {\n-                        let mut stop_listener = self.stopping_event.listen();\n-                        if self.stopping.load(Ordering::Acquire) {\n-                            return;\n-                        }\n-                        let mut idle_start_listener = self.idle_start_event.listen();\n-                        let mut idle_end_listener = self.idle_end_event.listen();\n-                        let mut idle_time = if turbo_tasks.is_idle() {\n-                            Instant::now() + IDLE_TIMEOUT\n+            match job {\n+                TurboTasksBackendJob::InitialSnapshot | TurboTasksBackendJob::FollowUpSnapshot => {\n+                    debug_assert!(self.should_persist());\n+\n+                    let last_snapshot = self.last_snapshot.load(Ordering::Relaxed);\n+                    let mut last_snapshot = self.start_time + Duration::from_millis(last_snapshot);\n+                    loop {\n+                        const FIRST_SNAPSHOT_WAIT: Duration = Duration::from_secs(300);\n+                        const SNAPSHOT_INTERVAL: Duration = Duration::from_secs(120);\n+                        const IDLE_TIMEOUT: Duration = Duration::from_secs(2);\n+\n+                        let time = if matches!(job, TurboTasksBackendJob::InitialSnapshot) {\n+                            FIRST_SNAPSHOT_WAIT\n                         } else {\n-                            far_future()\n+                            SNAPSHOT_INTERVAL\n                         };\n-                        loop {\n-                            tokio::select! {\n-                                _ = &mut stop_listener => {\n-                                    return;\n-                                },\n-                                _ = &mut idle_start_listener => {\n-                                    idle_time = Instant::now() + IDLE_TIMEOUT;\n-                                    idle_start_listener = self.idle_start_event.listen()\n-                                },\n-                                _ = &mut idle_end_listener => {\n-                                    idle_time = until + IDLE_TIMEOUT;\n-                                    idle_end_listener = self.idle_end_event.listen()\n-                                },\n-                                _ = tokio::time::sleep_until(until) => {\n-                                    break;\n-                                },\n-                                _ = tokio::time::sleep_until(idle_time) => {\n-                                    if turbo_tasks.is_idle() {\n+\n+                        let until = last_snapshot + time;\n+                        if until > Instant::now() {\n+                            let mut stop_listener = self.stopping_event.listen();\n+                            if self.stopping.load(Ordering::Acquire) {\n+                                return;\n+                            }\n+                            let mut idle_start_listener = self.idle_start_event.listen();\n+                            let mut idle_end_listener = self.idle_end_event.listen();\n+                            let mut idle_time = if turbo_tasks.is_idle() {\n+                                Instant::now() + IDLE_TIMEOUT\n+                            } else {\n+                                far_future()\n+                            };\n+                            loop {\n+                                tokio::select! {\n+                                    _ = &mut stop_listener => {\n+                                        return;\n+                                    },\n+                                    _ = &mut idle_start_listener => {\n+                                        idle_time = Instant::now() + IDLE_TIMEOUT;\n+                                        idle_start_listener = self.idle_start_event.listen()\n+                                    },\n+                                    _ = &mut idle_end_listener => {\n+                                        idle_time = until + IDLE_TIMEOUT;\n+                                        idle_end_listener = self.idle_end_event.listen()\n+                                    },\n+                                    _ = tokio::time::sleep_until(until) => {\n                                         break;\n-                                    }\n-                                },\n+                                    },\n+                                    _ = tokio::time::sleep_until(idle_time) => {\n+                                        if turbo_tasks.is_idle() {\n+                                            break;\n+                                        }\n+                                    },\n+                                }\n                             }\n                         }\n-                    }\n \n-                    let this = self.clone();\n-                    let snapshot = this.snapshot();\n-                    if let Some((snapshot_start, new_data)) = snapshot {\n-                        last_snapshot = snapshot_start;\n-                        if new_data {\n-                            continue;\n-                        }\n-                        let last_snapshot = last_snapshot.duration_since(self.start_time);\n-                        self.last_snapshot.store(\n-                            last_snapshot.as_millis().try_into().unwrap(),\n-                            Ordering::Relaxed,\n-                        );\n+                        let this = self.clone();\n+                        let snapshot = this.snapshot();\n+                        if let Some((snapshot_start, new_data)) = snapshot {\n+                            last_snapshot = snapshot_start;\n+                            if new_data {\n+                                continue;\n+                            }\n+                            let last_snapshot = last_snapshot.duration_since(self.start_time);\n+                            self.last_snapshot.store(\n+                                last_snapshot.as_millis().try_into().unwrap(),\n+                                Ordering::Relaxed,\n+                            );\n \n-                        turbo_tasks\n-                            .schedule_backend_background_job(BACKEND_JOB_FOLLOW_UP_SNAPSHOT, None);\n-                        return;\n+                            turbo_tasks.schedule_backend_background_job(\n+                                TurboTasksBackendJob::FollowUpSnapshot,\n+                            );\n+                            return;\n+                        }\n                     }\n                 }\n-            } else if id == BACKEND_JOB_PREFETCH_TASK || id == BACKEND_JOB_PREFETCH_CHUNK_TASK {\n-                const DATA_EXPECTATION: &str =\n-                    \"Expected data to be a FxHashMap<TaskId, bool> for BACKEND_JOB_PREFETCH_TASK\";\n-                let data = Box::<dyn Any + Send>::downcast::<Vec<(TaskId, bool)>>(\n-                    data.expect(DATA_EXPECTATION),\n-                )\n-                .expect(DATA_EXPECTATION);\n-\n-                fn prefetch_task(ctx: &mut impl ExecuteContext<'_>, task: TaskId, with_data: bool) {\n-                    let category = if with_data {\n-                        TaskDataCategory::All\n+                TurboTasksBackendJob::Prefetch { data, range } => {\n+                    let range = if let Some(range) = range {\n+                        range\n                     } else {\n-                        TaskDataCategory::Meta\n+                        if data.len() > 128 {\n+                            let chunk_size = good_chunk_size(data.len());\n+                            let chunks = data.len().div_ceil(chunk_size);\n+                            for i in 0..chunks {\n+                                turbo_tasks.schedule_backend_foreground_job(\n+                                    TurboTasksBackendJob::Prefetch {\n+                                        data: data.clone(),\n+                                        range: Some(\n+                                            (i * chunk_size)..min(data.len(), (i + 1) * chunk_size),\n+                                        ),\n+                                    },\n+                                );\n+                            }\n+                            return;\n+                        }\n+                        0..data.len()\n                     };\n-                    // Prefetch the task\n-                    drop(ctx.task(task, category));\n-                }\n \n-                if id == BACKEND_JOB_PREFETCH_TASK && data.len() > 128 {\n-                    let chunk_size = good_chunk_size(data.len());\n-                    for chunk in into_chunks(*data, chunk_size) {\n-                        let data: Box<Vec<(TaskId, bool)>> = Box::new(chunk.collect::<Vec<_>>());\n-                        turbo_tasks.schedule_backend_foreground_job(\n-                            BACKEND_JOB_PREFETCH_CHUNK_TASK,\n-                            Some(data),\n-                        );\n-                    }\n-                } else {\n                     let _span = info_span!(\"prefetching\").entered();\n                     let mut ctx = self.execute_context(turbo_tasks);\n-                    for (task, with_data) in data.into_iter() {\n-                        prefetch_task(&mut ctx, task, with_data);\n+                    for i in range {\n+                        let (&task, &with_data) = data.get_index(i).unwrap();\n+                        let category = if with_data {\n+                            TaskDataCategory::All\n+                        } else {\n+                            TaskDataCategory::Meta\n+                        };\n+                        // Prefetch the task\n+                        drop(ctx.task(task, category));\n                     }\n                 }\n             }\n@@ -2934,13 +2942,14 @@ impl<B: BackingStorage> Backend for TurboTasksBackend<B> {\n         )\n     }\n \n+    type BackendJob = TurboTasksBackendJob;\n+\n     fn run_backend_job<'a>(\n         &'a self,\n-        id: BackendJobId,\n-        data: Option<Box<dyn Any + Send>>,\n+        job: Self::BackendJob,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<Self>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>> {\n-        self.0.run_backend_job(id, data, turbo_tasks)\n+        self.0.run_backend_job(job, turbo_tasks)\n     }\n \n     fn try_read_task_output("
        },
        {
            "sha": "cbbf96973114a86ef07517019afe25723a918e85",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/mod.rs",
            "status": "modified",
            "additions": 13,
            "deletions": 13,
            "changes": 26,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -11,17 +11,16 @@ mod update_output;\n use std::{\n     fmt::{Debug, Formatter},\n     mem::transmute,\n-    sync::atomic::Ordering,\n+    sync::{Arc, atomic::Ordering},\n };\n \n-use rustc_hash::FxHashMap;\n use serde::{Deserialize, Serialize};\n-use turbo_tasks::{KeyValuePair, SessionId, TaskId, TurboTasksBackendApi};\n+use turbo_tasks::{FxIndexMap, KeyValuePair, SessionId, TaskId, TurboTasksBackendApi};\n \n use crate::{\n     backend::{\n-        BACKEND_JOB_PREFETCH_TASK, OperationGuard, TaskDataCategory, TransientTask,\n-        TurboTasksBackend, TurboTasksBackendInner,\n+        OperationGuard, TaskDataCategory, TransientTask, TurboTasksBackend, TurboTasksBackendInner,\n+        TurboTasksBackendJob,\n         storage::{SpecificTaskDataCategory, StorageWriteGuard, iter_many},\n     },\n     backing_storage::BackingStorage,\n@@ -265,10 +264,11 @@ where\n \n     fn schedule_task(&self, mut task: impl TaskGuard + '_) {\n         if let Some(tasks_to_prefetch) = task.prefetch() {\n-            self.turbo_tasks.schedule_backend_foreground_job(\n-                BACKEND_JOB_PREFETCH_TASK,\n-                Some(Box::new(tasks_to_prefetch)),\n-            );\n+            self.turbo_tasks\n+                .schedule_backend_foreground_job(TurboTasksBackendJob::Prefetch {\n+                    data: Arc::new(tasks_to_prefetch),\n+                    range: None,\n+                });\n         }\n         self.turbo_tasks.schedule(task.id());\n     }\n@@ -336,7 +336,7 @@ pub trait TaskGuard: Debug {\n     where\n         F: for<'a> FnMut(CachedDataItemKey, CachedDataItemValueRef<'a>) -> bool + 'l;\n     fn invalidate_serialization(&mut self);\n-    fn prefetch(&mut self) -> Option<Vec<(TaskId, bool)>>;\n+    fn prefetch(&mut self) -> Option<FxIndexMap<TaskId, bool>>;\n     fn is_immutable(&self) -> bool;\n }\n \n@@ -526,15 +526,15 @@ impl<B: BackingStorage> TaskGuard for TaskGuardImpl<'_, B> {\n         }\n     }\n \n-    fn prefetch(&mut self) -> Option<Vec<(TaskId, bool)>> {\n+    fn prefetch(&mut self) -> Option<FxIndexMap<TaskId, bool>> {\n         if !self.task.state().prefetched() {\n             self.task.state_mut().set_prefetched(true);\n             let map = iter_many!(self, OutputDependency { target } => (target, false))\n                 .chain(iter_many!(self, CellDependency { target } => (target.task, true)))\n                 .chain(iter_many!(self, CollectiblesDependency { target } => (target.task, true)))\n-                .collect::<FxHashMap<_, _>>();\n+                .collect::<FxIndexMap<_, _>>();\n             if map.len() > 16 {\n-                return Some(map.into_iter().collect());\n+                return Some(map);\n             }\n         }\n         None"
        },
        {
            "sha": "70cf5fc95a2a84ce71d706d75214acb55ba6b276",
            "filename": "turbopack/crates/turbo-tasks/src/backend.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -1,5 +1,4 @@\n use std::{\n-    any::Any,\n     borrow::Cow,\n     error::Error,\n     fmt::{self, Debug, Display},\n@@ -17,7 +16,6 @@ use serde::{Deserialize, Serialize};\n use tracing::Span;\n use turbo_rcstr::RcStr;\n \n-pub use crate::id::BackendJobId;\n use crate::{\n     RawVc, ReadCellOptions, ReadRef, SharedReference, TaskId, TaskIdSet, TraitRef, TraitTypeId,\n     TurboTasksPanic, ValueTypeId, VcRead, VcValueTrait, VcValueType,\n@@ -583,10 +581,11 @@ pub trait Backend: Sync + Send {\n         turbo_tasks: &dyn TurboTasksBackendApi<Self>,\n     ) -> bool;\n \n+    type BackendJob: Send + 'static;\n+\n     fn run_backend_job<'a>(\n         &'a self,\n-        id: BackendJobId,\n-        data: Option<Box<dyn Any + Send>>,\n+        job: Self::BackendJob,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<Self>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>>;\n "
        },
        {
            "sha": "58969b228dd37540dbc64a84836fc9a7337f1de9",
            "filename": "turbopack/crates/turbo-tasks/src/id.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -115,7 +115,6 @@ macro_rules! define_id {\n define_id!(TaskId: u32, derive(Serialize, Deserialize), serde(transparent));\n define_id!(ValueTypeId: u32);\n define_id!(TraitTypeId: u32);\n-define_id!(BackendJobId: u32);\n define_id!(SessionId: u32, derive(Debug, Serialize, Deserialize), serde(transparent));\n define_id!(\n     LocalTaskId: u32,"
        },
        {
            "sha": "0651538b185509590b0737e0b178e6c8ecfe641a",
            "filename": "turbopack/crates/turbo-tasks/src/id_factory.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid_factory.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid_factory.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid_factory.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -121,8 +121,7 @@ where\n     }\n }\n \n-/// An [`IdFactory`], but extended with a free list to allow for id reuse for ids such as\n-/// [`BackendJobId`][crate::backend::BackendJobId].\n+/// An [`IdFactory`], but extended with a free list to allow for id reuse.\n ///\n /// If silent untracked re-use of ids is okay, consider using the cheaper\n /// [`IdFactory::wrapping_get`] method."
        },
        {
            "sha": "fcc67f5e8595c35721a9a204413fb7f19b9fd347",
            "filename": "turbopack/crates/turbo-tasks/src/manager.rs",
            "status": "modified",
            "additions": 7,
            "deletions": 7,
            "changes": 14,
            "blob_url": "https://github.com/vercel/next.js/blob/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2cc5408165ba8596fdd77dac2338f608c00e7293/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs?ref=2cc5408165ba8596fdd77dac2338f608c00e7293",
            "patch": "@@ -30,7 +30,7 @@ use crate::{\n     },\n     capture_future::CaptureFuture,\n     event::{Event, EventListener},\n-    id::{BackendJobId, ExecutionId, LocalTaskId, TRANSIENT_TASK_BIT, TraitTypeId},\n+    id::{ExecutionId, LocalTaskId, TRANSIENT_TASK_BIT, TraitTypeId},\n     id_factory::IdFactoryWithReuse,\n     macro_helpers::NativeFunction,\n     magic_any::MagicAny,\n@@ -250,8 +250,8 @@ pub trait TurboTasksBackendApi<B: Backend + 'static>: TurboTasksCallApi + Sync +\n     unsafe fn reuse_transient_task_id(&self, id: Unused<TaskId>);\n \n     fn schedule(&self, task: TaskId);\n-    fn schedule_backend_background_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>);\n-    fn schedule_backend_foreground_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>);\n+    fn schedule_backend_background_job(&self, job: B::BackendJob);\n+    fn schedule_backend_foreground_job(&self, job: B::BackendJob);\n \n     fn try_foreground_done(&self) -> Result<(), EventListener>;\n     fn wait_foreground_done_excluding_own<'a>(\n@@ -1478,16 +1478,16 @@ impl<B: Backend + 'static> TurboTasksBackendApi<B> for TurboTasks<B> {\n     }\n \n     #[track_caller]\n-    fn schedule_backend_background_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>) {\n+    fn schedule_backend_background_job(&self, job: B::BackendJob) {\n         self.schedule_background_job(move |this| async move {\n-            this.backend.run_backend_job(id, data, &*this).await;\n+            this.backend.run_backend_job(job, &*this).await;\n         })\n     }\n \n     #[track_caller]\n-    fn schedule_backend_foreground_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>) {\n+    fn schedule_backend_foreground_job(&self, job: B::BackendJob) {\n         self.schedule_foreground_job(move |this| async move {\n-            this.backend.run_backend_job(id, data, &*this).await;\n+            this.backend.run_backend_job(job, &*this).await;\n         })\n     }\n "
        }
    ],
    "stats": {
        "total": 272,
        "additions": 139,
        "deletions": 133
    }
}