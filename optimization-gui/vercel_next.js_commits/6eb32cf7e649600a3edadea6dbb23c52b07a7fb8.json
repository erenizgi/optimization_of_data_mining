{
    "author": "snyamathi",
    "message": "fix: memory leak from cloneResponse (#82678)\n\nrepro info here: https://github.com/snyamathi/nextjs-mem-leak\n\n## Background\n\n> The Fetch Standard allows users to skip consuming the response body by\nrelying on garbage collection to release connection resources.\n\nUndici added support for this in\nhttps://github.com/nodejs/undici/pull/3199 and later for the body of\ncloned responses in https://github.com/nodejs/undici/pull/3458 which\nfirst landed in [Undici version\n6.19.8](https://github.com/nodejs/undici/commits/v6.19.8) in August\n2024. In September 2024, this issue\nhttps://github.com/vercel/next.js/discussions/69635 was raised for the\nerror, `TypeError: Response.clone: Body has already been consumed`\n\nIn NextJS's\n[dedupe-fetch](https://github.com/vercel/next.js/blame/ab59e37a66f1a70b1172af9149d8aa3ba1509330/packages/next/src/server/lib/dedupe-fetch.ts#L92)\nthe cloned response is returned to userland, while the original response\nis stored in a react cache\n\n```js\n// match was pulled from react cache, a clone is returned to the user\nreturn match.then((response: Response) => response.clone());\n```\n\n## Undici Bug\n\nI'm omitting some details in the code snippet below (see full changes at\nhttps://github.com/nodejs/undici/pull/3458/files), but the Undici change\nto `use FinalizationRegistry for cloned response body` seems to have\nmixed up the response pointer and stream bodies when registering with\nthe finalization registry, resulting in the wrong stream being\ncancelled.\n\nThe original response, (the `match` above) stored in the react cache is\ncloned, and then **its** stream is registered with the finalization\nregistry when the cloned response `newRequest` is reclaimed.\n\n**I believe this is the true underlying cause of the errors:** `Body has\nalready been consumed`\n\n```js\nfunction cloneBody(instance, body) {\n  const [out1, out2] = body.stream.tee();\n\n  // Erroneously registering newRequest + old body with finalization registry\n  streamRegistry.register(instance, new WeakRef(out1));\n\n  // Original request + out1 is used in Next's dedupe-request cache\n  body.stream = out1;\n\n  // Clone request + out2 is returned to userland\n  return {\n    stream: out2,\n  };\n}\n\n// When newRequest is reclaimed, the original request.body is cancelled by mistake!\nnewRequest.body = cloneBody(newRequest, request.body);\n\n// This is what the registry looks like\nstreamRegistry = new FinalizationRegistry((weakRef) => {\n  const stream = weakRef.deref();\n  if (stream && !stream.locked && !isDisturbed(stream) && !isErrored(stream)) {\n    stream.cancel(\"Response object has been garbage collected\").catch(noop);\n  }\n});\n```\n\nhttps://github.com/snyamathi/nextjs-mem-leak/blob/main/index.mjs has a\nsimple reproduction of this issue which shows that when the clone is\nreclaimed, the original stream is cancelled, leading to issues\n\n## Memory Leak\n\nThis lead to https://github.com/vercel/next.js/pull/73274 which fixed\nthe problem by adding a custom `cloneResponse` function.\n\n\nhttps://github.com/vercel/next.js/blob/7ef0a2b2767b4159f8db8e1884bac98370528a25/packages/next/src/server/lib/clone-response.ts\n\nHowever, this in turn has lead to a memory leak because now there is no\none to garbage collect the tee'd stream.\n\nhttps://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/tee\n\n> To cancel the stream you then need to cancel both resulting branches.\nTeeing a stream will generally lock it for the duration, preventing\nother readers from locking it.\n\nUndici was incorrectly cancelling the stream (leading to a bug), and\nNext is simply not cancelling the stream (leading to a memory leak).\nThis can be observed with a Docker setup which shows a current version\nof NextJS, the last version prior to the custom `cloneResponse`\nfunction, as well as the effects of the proposed fix here.\n\n<img width=\"2400\" height=\"1200\" alt=\"plot\"\nsrc=\"https://github.com/user-attachments/assets/a1df0afd-cc8a-4a89-8c92-381ee71fff59\"\n/>\n\nI have a reproduction available here\nhttps://github.com/snyamathi/nextjs-mem-leak/tree/main - you'll notice\nthe memory for NextJS climb until it runs out of memory and crashes,\nwhereas the version prior to this change (`15.0.4-canary`) is\nunaffected.\n\nSimilarly, if we forego the dedupe cache by passing in a signal\n(https://github.com/vercel/next.js/blob/102f233a170e9df0b30c24a58c3953dc678ec330/packages/next/src/server/lib/dedupe-fetch.ts#L45)\nthere is no memory leak either.\n\nThe PR changes here are applied as a patch and also fix the memory leak\n:)\n\n```bash\ndocker compose pull\ndocker compose build\ndocker compose up -d\ndocker container stats\n```\n\n```\nCONTAINER ID   NAME                          CPU %     MEM USAGE / LIMIT    MEM %     NET I/O           BLOCK I/O   PIDS\n1b2f217c4d03   mem-next-og-1                 28.50%    124MiB / 1GiB        12.11%    993MB / 7.45MB    0B / 0B     23\n7e76622a4a3e   mem-next-15.4.1-1             49.03%    1021MiB / 1GiB       99.69%    993MB / 7.5MB     0B / 0B     23\n1bacb1a9b1cc   mem-next-15.0.4-canary.39-1   21.22%    115.6MiB / 1GiB      11.29%    991MB / 7.44MB    0B / 0B     23\ndf2a8ba5800e   mem-siege-1                   5.59%     12.56MiB / 31.2GiB   0.04%     9.73MB / 10.5MB   0B / 0B     102\n46fab210c911   mem-next-patched-1            2.46%     91.34MiB / 1GiB      8.92%     2.38MB / 1.97MB   0B / 0B     23\n365987089d03   mem-upstream-1                15.16%    137.2MiB / 31.2GiB   0.43%     16.8MB / 2.97GB   0B / 0B     23\n```\n\nEach container outputs the request number and current memory usage which\nare then plotted in order to observe the memory leak due to the custom\n`cloneResponse`.\n\nBecause the fix associates the correct response and stream, the previous\nregression does not happen again. We can confirm this by making requests\nto the page for each of the docker containers. The container using the\nversion prior to the custom `cloneResponse` will error out, while the\nrest will not\n\n```\n$ curl -s localhost:3002 | htmlq --text '#error'\nResponse.clone: Body has already been consumed.\n```\n\ncc @wyattjoh @gnoff \n\n## Reproduction\n\nhttps://github.com/snyamathi/nextjs-mem-leak/tree/main contains a number\nof reproductions\n\n- https://github.com/snyamathi/nextjs-mem-leak/blob/main/index.mjs shows\na pure javascript reproduction of the original undici bug\n- https://github.com/snyamathi/nextjs-mem-leak/blob/main/page.js shows\nhow that bug manifested itself in Next for the `Body has already been\nconsumed` error\n- https://github.com/snyamathi/nextjs-mem-leak/blob/main/route.js shows\nthe memory leak due to the custom `cloneResponse` function\n\nThe rest of the files are supporting infrastructure to start docker\ncontainers of various versions and various patches showing how versions\nprior to the `cloneResponse` do not have the same memory leak, and how\nthe patch (PR'd here) fixes the issue without regressing on the Undici\nissue.",
    "sha": "6eb32cf7e649600a3edadea6dbb23c52b07a7fb8",
    "files": [
        {
            "sha": "5913d8ee7dd1ad3a61a0a3560a90558ca4db58ee",
            "filename": "packages/next/src/server/lib/clone-response.ts",
            "status": "modified",
            "additions": 31,
            "deletions": 0,
            "changes": 31,
            "blob_url": "https://github.com/vercel/next.js/blob/6eb32cf7e649600a3edadea6dbb23c52b07a7fb8/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fclone-response.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/6eb32cf7e649600a3edadea6dbb23c52b07a7fb8/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fclone-response.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fclone-response.ts?ref=6eb32cf7e649600a3edadea6dbb23c52b07a7fb8",
            "patch": "@@ -1,3 +1,16 @@\n+const noop = () => {}\n+\n+let registry: FinalizationRegistry<WeakRef<ReadableStream>> | undefined\n+\n+if (globalThis.FinalizationRegistry) {\n+  registry = new FinalizationRegistry((weakRef: WeakRef<ReadableStream>) => {\n+    const stream = weakRef.deref()\n+    if (stream && !stream.locked) {\n+      stream.cancel('Response object has been garbage collected').then(noop)\n+    }\n+  })\n+}\n+\n /**\n  * Clones a response by teeing the body so we can return two independent\n  * ReadableStreams from it. This avoids the bug in the undici library around\n@@ -33,6 +46,24 @@ export function cloneResponse(original: Response): [Response, Response] {\n     writable: false,\n   })\n \n+  // The Fetch Standard allows users to skip consuming the response body by\n+  // relying on garbage collection to release connection resources.\n+  // https://github.com/nodejs/undici?tab=readme-ov-file#garbage-collection\n+  //\n+  // To cancel the stream you then need to cancel both resulting branches.\n+  // Teeing a stream will generally lock it for the duration, preventing other\n+  // readers from locking it.\n+  // https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream/tee\n+\n+  // cloned2 is stored in a react cache and cloned for subsequent requests.\n+  // It is the original request, and is is garbage collected by a\n+  // FinalizationRegistry in Undici, but since we're tee-ing the stream\n+  // ourselves, we need to cancel clone1's stream (the response returned from\n+  // our dedupe fetch) when clone1 is reclaimed, otherwise we leak memory.\n+  if (registry && cloned1.body) {\n+    registry.register(cloned1, new WeakRef(cloned1.body))\n+  }\n+\n   const cloned2 = new Response(body2, {\n     status: original.status,\n     statusText: original.statusText,"
        }
    ],
    "stats": {
        "total": 31,
        "additions": 31,
        "deletions": 0
    }
}