{
    "author": "sokra",
    "message": "Turbopack: use parallel execution helpers (#82667)\n\n<!-- Thanks for opening a PR! Your contribution is much appreciated.\nTo make sure your PR is handled as smoothly as possible we request that you follow the checklist sections below.\nChoose the right checklist for the change(s) that you're making:\n\n## For Contributors\n\n### Improving Documentation\n\n- Run `pnpm prettier-fix` to fix formatting issues before opening the PR.\n- Read the Docs Contribution Guide to ensure your contribution follows the docs guidelines: https://nextjs.org/docs/community/contribution-guide\n\n### Adding or Updating Examples\n\n- The \"examples guidelines\" are followed from our contributing doc https://github.com/vercel/next.js/blob/canary/contributing/examples/adding-examples.md\n- Make sure the linting passes by running `pnpm build && pnpm lint`. See https://github.com/vercel/next.js/blob/canary/contributing/repository/linting.md\n\n### Fixing a bug\n\n- Related issues linked using `fixes #number`\n- Tests added. See: https://github.com/vercel/next.js/blob/canary/contributing/core/testing.md#writing-tests-for-nextjs\n- Errors have a helpful link attached, see https://github.com/vercel/next.js/blob/canary/contributing.md\n\n### Adding a feature\n\n- Implements an existing feature request or RFC. Make sure the feature request has been accepted for implementation before opening a PR. (A discussion must be opened, see https://github.com/vercel/next.js/discussions/new?category=ideas)\n- Related issues/discussions are linked using `fixes #number`\n- e2e tests added (https://github.com/vercel/next.js/blob/canary/contributing/core/testing.md#writing-tests-for-nextjs)\n- Documentation added\n- Telemetry added. In case of a feature if it's used or not.\n- Errors have a helpful link attached, see https://github.com/vercel/next.js/blob/canary/contributing.md\n\n\n## For Maintainers\n\n- Minimal description (aim for explaining to someone not on the team to understand the PR)\n- When linking to a Slack thread, you might want to share details of the conclusion\n- Link both the Linear (Fixes NEXT-xxx) and the GitHub issues\n- Add review comments if necessary to explain to the reviewer the logic behind a change\n\n### What?\n\n### Why?\n\n### How?\n\nCloses NEXT-\nFixes #\n\n-->",
    "sha": "e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
    "files": [
        {
            "sha": "903b89bb07e12355fd7885dc8bbf5466f77505de",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -9253,7 +9253,6 @@ dependencies = [\n  \"parking_lot\",\n  \"pot\",\n  \"rand 0.9.0\",\n- \"rayon\",\n  \"regex\",\n  \"ringmap\",\n  \"rstest\",\n@@ -9367,7 +9366,6 @@ dependencies = [\n  \"mime\",\n  \"notify\",\n  \"parking_lot\",\n- \"rayon\",\n  \"regex\",\n  \"rstest\",\n  \"rustc-hash 2.1.1\","
        },
        {
            "sha": "3554ce1f31b20b6ec207e43b07a76982c023b7b2",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -40,7 +40,6 @@ once_cell = { workspace = true }\n parking_lot = { workspace = true }\n pot = \"3.0.0\"\n rand = { workspace = true }\n-rayon = { workspace = true }\n ringmap = { workspace = true, features = [\"serde\"] }\n rustc-hash = { workspace = true }\n serde = { workspace = true }"
        },
        {
            "sha": "ba83f1da5a209dc0a78cc9dbc985ddc290a6bb1b",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/storage.rs",
            "status": "modified",
            "additions": 33,
            "deletions": 39,
            "changes": 72,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -6,9 +6,8 @@ use std::{\n };\n \n use bitfield::bitfield;\n-use rayon::iter::{IndexedParallelIterator, IntoParallelRefIterator, ParallelIterator};\n use smallvec::SmallVec;\n-use turbo_tasks::{FxDashMap, TaskId};\n+use turbo_tasks::{FxDashMap, TaskId, parallel};\n \n use crate::{\n     backend::dynamic_storage::DynamicStorage,\n@@ -664,48 +663,43 @@ impl Storage {\n \n         // The number of shards is much larger than the number of threads, so the effect of the\n         // locks held is negligible.\n-        self.modified\n-            .shards()\n-            .par_iter()\n-            .with_max_len(1)\n-            .map(|shard| {\n-                let mut direct_snapshots: Vec<(TaskId, Box<InnerStorageSnapshot>)> = Vec::new();\n-                let mut modified: SmallVec<[TaskId; 4]> = SmallVec::new();\n-                {\n-                    // Take the snapshots from the modified map\n-                    let guard = shard.write();\n-                    // Safety: guard must outlive the iterator.\n-                    for bucket in unsafe { guard.iter() } {\n-                        // Safety: the guard guarantees that the bucket is not removed and the ptr\n-                        // is valid.\n-                        let (key, shared_value) = unsafe { bucket.as_mut() };\n-                        let modified_state = shared_value.get_mut();\n-                        match modified_state {\n-                            ModifiedState::Modified => {\n-                                modified.push(*key);\n-                            }\n-                            ModifiedState::Snapshot(snapshot) => {\n-                                if let Some(snapshot) = snapshot.take() {\n-                                    direct_snapshots.push((*key, snapshot));\n-                                }\n+        parallel::map_collect::<_, _, Vec<_>>(self.modified.shards(), |shard| {\n+            let mut direct_snapshots: Vec<(TaskId, Box<InnerStorageSnapshot>)> = Vec::new();\n+            let mut modified: SmallVec<[TaskId; 4]> = SmallVec::new();\n+            {\n+                // Take the snapshots from the modified map\n+                let guard = shard.write();\n+                // Safety: guard must outlive the iterator.\n+                for bucket in unsafe { guard.iter() } {\n+                    // Safety: the guard guarantees that the bucket is not removed and the ptr\n+                    // is valid.\n+                    let (key, shared_value) = unsafe { bucket.as_mut() };\n+                    let modified_state = shared_value.get_mut();\n+                    match modified_state {\n+                        ModifiedState::Modified => {\n+                            modified.push(*key);\n+                        }\n+                        ModifiedState::Snapshot(snapshot) => {\n+                            if let Some(snapshot) = snapshot.take() {\n+                                direct_snapshots.push((*key, snapshot));\n                             }\n                         }\n                     }\n-                    // Safety: guard must outlive the iterator.\n-                    drop(guard);\n                 }\n+                // Safety: guard must outlive the iterator.\n+                drop(guard);\n+            }\n \n-                SnapshotShard {\n-                    direct_snapshots,\n-                    modified,\n-                    storage: self,\n-                    guard: Some(guard.clone()),\n-                    process,\n-                    preprocess,\n-                    process_snapshot,\n-                }\n-            })\n-            .collect::<Vec<_>>()\n+            SnapshotShard {\n+                direct_snapshots,\n+                modified,\n+                storage: self,\n+                guard: Some(guard.clone()),\n+                process,\n+                preprocess,\n+                process_snapshot,\n+            }\n+        })\n     }\n \n     /// Start snapshot mode."
        },
        {
            "sha": "3127a15ab70667c46cb4d9e4743e0038e176e1ed",
            "filename": "turbopack/crates/turbo-tasks-backend/src/kv_backing_storage.rs",
            "status": "modified",
            "additions": 44,
            "deletions": 61,
            "changes": 105,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -1,21 +1,18 @@\n use std::{\n     borrow::Borrow,\n-    cmp::max,\n     env,\n     path::PathBuf,\n     sync::{Arc, LazyLock, Mutex, PoisonError, Weak},\n };\n \n use anyhow::{Context, Result, anyhow};\n-use rayon::iter::{IndexedParallelIterator, IntoParallelIterator, ParallelIterator};\n use serde::{Deserialize, Serialize};\n use smallvec::SmallVec;\n-use tracing::Span;\n use turbo_tasks::{\n     SessionId, TaskId,\n     backend::CachedTaskType,\n     panic_hooks::{PanicHookGuard, register_panic_hook},\n-    turbo_tasks_scope,\n+    parallel,\n };\n \n use crate::{\n@@ -331,14 +328,15 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                     let _span = tracing::trace_span!(\"update task data\").entered();\n                     process_task_data(snapshots, Some(batch))?;\n                     let span = tracing::trace_span!(\"flush task data\").entered();\n-                    [KeySpace::TaskMeta, KeySpace::TaskData]\n-                        .into_par_iter()\n-                        .try_for_each(|key_space| {\n+                    parallel::try_for_each(\n+                        &[KeySpace::TaskMeta, KeySpace::TaskData],\n+                        |&key_space| {\n                             let _span = span.clone().entered();\n                             // Safety: We already finished all processing of the task data and task\n                             // meta\n                             unsafe { batch.flush(key_space) }\n-                        })?;\n+                        },\n+                    )?;\n                 }\n \n                 let mut next_task_id = get_next_free_task_id::<\n@@ -352,10 +350,9 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                         items = task_cache_updates.iter().map(|m| m.len()).sum::<usize>()\n                     )\n                     .entered();\n-                    let result = task_cache_updates\n-                        .into_par_iter()\n-                        .with_max_len(1)\n-                        .map(|updates| {\n+                    let result = parallel::map_collect_owned::<_, _, Result<Vec<_>>>(\n+                        task_cache_updates,\n+                        |updates| {\n                             let _span = _span.clone().entered();\n                             let mut max_task_id = 0;\n \n@@ -390,15 +387,11 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                             }\n \n                             Ok(max_task_id)\n-                        })\n-                        .reduce(\n-                            || Ok(0),\n-                            |a, b| -> anyhow::Result<_> {\n-                                let a_max = a?;\n-                                let b_max = b?;\n-                                Ok(max(a_max, b_max))\n-                            },\n-                        )?;\n+                        },\n+                    )?\n+                    .into_iter()\n+                    .max()\n+                    .unwrap_or(0);\n                     next_task_id = next_task_id.max(result);\n                 }\n \n@@ -697,48 +690,38 @@ where\n         > + Send\n         + Sync,\n {\n-    let span = Span::current();\n-    let turbo_tasks = turbo_tasks::turbo_tasks();\n-    let handle = tokio::runtime::Handle::current();\n-    tasks\n-        .into_par_iter()\n-        .map(|tasks| {\n-            let _span = span.clone().entered();\n-            let _guard = handle.clone().enter();\n-            turbo_tasks_scope(turbo_tasks.clone(), || {\n-                let mut result = Vec::new();\n-                for (task_id, meta, data) in tasks {\n-                    if let Some(batch) = batch {\n-                        let key = IntKey::new(*task_id);\n-                        let key = key.as_ref();\n-                        if let Some(meta) = meta {\n-                            batch.put(\n-                                KeySpace::TaskMeta,\n-                                WriteBuffer::Borrowed(key),\n-                                WriteBuffer::SmallVec(meta),\n-                            )?;\n-                        }\n-                        if let Some(data) = data {\n-                            batch.put(\n-                                KeySpace::TaskData,\n-                                WriteBuffer::Borrowed(key),\n-                                WriteBuffer::SmallVec(data),\n-                            )?;\n-                        }\n-                    } else {\n-                        // Store the new task data\n-                        result.push((\n-                            task_id,\n-                            meta.map(WriteBuffer::SmallVec),\n-                            data.map(WriteBuffer::SmallVec),\n-                        ));\n-                    }\n+    parallel::map_collect_owned::<_, _, Result<Vec<_>>>(tasks, |tasks| {\n+        let mut result = Vec::new();\n+        for (task_id, meta, data) in tasks {\n+            if let Some(batch) = batch {\n+                let key = IntKey::new(*task_id);\n+                let key = key.as_ref();\n+                if let Some(meta) = meta {\n+                    batch.put(\n+                        KeySpace::TaskMeta,\n+                        WriteBuffer::Borrowed(key),\n+                        WriteBuffer::SmallVec(meta),\n+                    )?;\n+                }\n+                if let Some(data) = data {\n+                    batch.put(\n+                        KeySpace::TaskData,\n+                        WriteBuffer::Borrowed(key),\n+                        WriteBuffer::SmallVec(data),\n+                    )?;\n                 }\n+            } else {\n+                // Store the new task data\n+                result.push((\n+                    task_id,\n+                    meta.map(WriteBuffer::SmallVec),\n+                    data.map(WriteBuffer::SmallVec),\n+                ));\n+            }\n+        }\n \n-                Ok(result)\n-            })\n-        })\n-        .collect::<Result<Vec<_>>>()\n+        Ok(result)\n+    })\n }\n \n fn serialize(task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>> {"
        },
        {
            "sha": "e3320823ee76f6ccc06fdd3207864a3e21becc8e",
            "filename": "turbopack/crates/turbo-tasks-fs/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -37,7 +37,6 @@ jsonc-parser = { version = \"0.26.3\", features = [\"serde\"] }\n mime = { workspace = true }\n notify = { workspace = true }\n parking_lot = { workspace = true }\n-rayon = { workspace = true }\n regex = { workspace = true }\n rustc-hash = { workspace = true }\n serde = { workspace = true, features = [\"rc\"] }"
        },
        {
            "sha": "2ae2dc3036f0c7752938051bac37cf68d56c1843",
            "filename": "turbopack/crates/turbo-tasks-fs/src/lib.rs",
            "status": "modified",
            "additions": 14,
            "deletions": 24,
            "changes": 38,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -46,7 +46,6 @@ use dunce::simplified;\n use indexmap::IndexSet;\n use jsonc_parser::{ParseOptions, parse_to_serde_value};\n use mime::Mime;\n-use rayon::iter::{IntoParallelIterator, ParallelIterator};\n use rustc_hash::FxHashSet;\n use serde::{Deserialize, Serialize};\n use serde_json::Value;\n@@ -56,7 +55,7 @@ use turbo_rcstr::{RcStr, rcstr};\n use turbo_tasks::{\n     ApplyEffectsContext, Completion, InvalidationReason, Invalidator, NonLocalValue, ReadRef,\n     ResolvedVc, TaskInput, ValueToString, Vc, debug::ValueDebugFormat, effect,\n-    mark_session_dependent, mark_stateful, trace::TraceRawVcs,\n+    mark_session_dependent, mark_stateful, parallel, trace::TraceRawVcs,\n };\n use turbo_tasks_hash::{DeterministicHash, DeterministicHasher, hash_xxh3_hash64};\n use turbo_unix_path::{\n@@ -309,19 +308,14 @@ impl DiskFileSystemInner {\n \n     fn invalidate(&self) {\n         let _span = tracing::info_span!(\"invalidate filesystem\", name = &*self.root).entered();\n-        let span = tracing::Span::current();\n-        let handle = tokio::runtime::Handle::current();\n         let invalidator_map = take(&mut *self.invalidator_map.lock().unwrap());\n         let dir_invalidator_map = take(&mut *self.dir_invalidator_map.lock().unwrap());\n-        let iter = invalidator_map\n-            .into_par_iter()\n-            .chain(dir_invalidator_map.into_par_iter())\n-            .flat_map(|(_, invalidators)| invalidators.into_par_iter());\n-        iter.for_each(|(i, _)| {\n-            let _span = span.clone().entered();\n-            let _guard = handle.enter();\n-            i.invalidate()\n-        });\n+        let invalidators = invalidator_map\n+            .into_iter()\n+            .chain(dir_invalidator_map)\n+            .flat_map(|(_, invalidators)| invalidators.into_keys())\n+            .collect::<Vec<_>>();\n+        parallel::for_each_owned(invalidators, |invalidator| invalidator.invalidate());\n     }\n \n     /// Invalidates every tracked file in the filesystem.\n@@ -332,23 +326,19 @@ impl DiskFileSystemInner {\n         reason: impl Fn(&Path) -> R + Sync,\n     ) {\n         let _span = tracing::info_span!(\"invalidate filesystem\", name = &*self.root).entered();\n-        let span = tracing::Span::current();\n-        let handle = tokio::runtime::Handle::current();\n         let invalidator_map = take(&mut *self.invalidator_map.lock().unwrap());\n         let dir_invalidator_map = take(&mut *self.dir_invalidator_map.lock().unwrap());\n-        let iter = invalidator_map\n-            .into_par_iter()\n-            .chain(dir_invalidator_map.into_par_iter())\n+        let invalidators = invalidator_map\n+            .into_iter()\n+            .chain(dir_invalidator_map)\n             .flat_map(|(path, invalidators)| {\n-                let _span = span.clone().entered();\n                 let reason_for_path = reason(&path);\n                 invalidators\n-                    .into_par_iter()\n+                    .into_keys()\n                     .map(move |i| (reason_for_path.clone(), i))\n-            });\n-        iter.for_each(|(reason, (invalidator, _))| {\n-            let _span = span.clone().entered();\n-            let _guard = handle.enter();\n+            })\n+            .collect::<Vec<_>>();\n+        parallel::for_each_owned(invalidators, |(reason, invalidator)| {\n             invalidator.invalidate_with_reason(reason)\n         });\n     }"
        },
        {
            "sha": "a9f58e0f2d6ca2eb47afa756a5ca67520c5dd0b7",
            "filename": "turbopack/crates/turbo-tasks-fs/src/watcher.rs",
            "status": "modified",
            "additions": 20,
            "deletions": 31,
            "changes": 51,
            "blob_url": "https://github.com/vercel/next.js/blob/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Fwatcher.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e21ac64cd01485c4951c305ae9654bf6fca3f7a7/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Fwatcher.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Fwatcher.rs?ref=e21ac64cd01485c4951c305ae9654bf6fca3f7a7",
            "patch": "@@ -16,13 +16,12 @@ use notify::{\n     Config, EventKind, PollWatcher, RecommendedWatcher, RecursiveMode, Watcher,\n     event::{MetadataKind, ModifyKind, RenameMode},\n };\n-use rayon::iter::{IntoParallelIterator, ParallelIterator};\n use rustc_hash::FxHashSet;\n use serde::{Deserialize, Serialize};\n use tracing::instrument;\n use turbo_rcstr::RcStr;\n use turbo_tasks::{\n-    FxIndexSet, InvalidationReason, InvalidationReasonKind, Invalidator, spawn_thread,\n+    FxIndexSet, InvalidationReason, InvalidationReasonKind, Invalidator, parallel, spawn_thread,\n     util::StaticOrArc,\n };\n \n@@ -397,40 +396,30 @@ impl DiskWatcher {\n         //\n         // Best is to start_watching before starting to read\n         {\n-            let span = tracing::info_span!(\"invalidate filesystem\");\n-            let _span = span.clone().entered();\n+            let _span = tracing::info_span!(\"invalidate filesystem\").entered();\n             let invalidator_map = take(&mut *fs_inner.invalidator_map.lock().unwrap());\n             let dir_invalidator_map = take(&mut *fs_inner.dir_invalidator_map.lock().unwrap());\n-            let iter = invalidator_map\n-                .into_par_iter()\n-                .chain(dir_invalidator_map.into_par_iter());\n-            let handle = tokio::runtime::Handle::current();\n+            let iter = invalidator_map.into_iter().chain(dir_invalidator_map);\n             if report_invalidation_reason {\n-                iter.flat_map(|(path, invalidators)| {\n-                    let _span = span.clone().entered();\n-                    let reason = WatchStart {\n-                        name: fs_inner.name.clone(),\n-                        // this path is just used for display purposes\n-                        path: RcStr::from(path.to_string_lossy()),\n-                    };\n-                    invalidators\n-                        .into_par_iter()\n-                        .map(move |i| (reason.clone(), i))\n-                })\n-                .for_each(|(reason, (invalidator, _))| {\n-                    let _span = span.clone().entered();\n-                    let _guard = handle.enter();\n-                    invalidator.invalidate_with_reason(reason)\n+                let invalidators = iter\n+                    .flat_map(|(path, invalidators)| {\n+                        let reason = WatchStart {\n+                            name: fs_inner.name.clone(),\n+                            // this path is just used for display purposes\n+                            path: RcStr::from(path.to_string_lossy()),\n+                        };\n+                        invalidators.into_iter().map(move |i| (reason.clone(), i))\n+                    })\n+                    .collect::<Vec<_>>();\n+                parallel::for_each_owned(invalidators, |(reason, (invalidator, _))| {\n+                    invalidator.invalidate_with_reason(reason);\n                 });\n             } else {\n-                iter.flat_map(|(_, invalidators)| {\n-                    let _span = span.clone().entered();\n-                    invalidators.into_par_iter().map(move |i| i)\n-                })\n-                .for_each(|(invalidator, _)| {\n-                    let _span = span.clone().entered();\n-                    let _guard = handle.enter();\n-                    invalidator.invalidate()\n+                let invalidators = iter\n+                    .flat_map(|(_, invalidators)| invalidators.into_keys())\n+                    .collect::<Vec<_>>();\n+                parallel::for_each_owned(invalidators, |invalidator| {\n+                    invalidator.invalidate();\n                 });\n             }\n         }"
        }
    ],
    "stats": {
        "total": 270,
        "additions": 111,
        "deletions": 159
    }
}