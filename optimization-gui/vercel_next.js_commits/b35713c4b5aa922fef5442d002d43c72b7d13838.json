{
    "author": "bgw",
    "message": "Turbopack: bincode: Use bincode to store the contents of value cells (#86338)\n\nThis PR switches `turbo-tasks-backend` to use `bincode` instead of serde for cell contents. To keep PR size manageable, `TaskInput`s are still serialized using serde and a compatibility shim. The next PR fixes that.\n\nSee https://github.com/vercel/next.js/pull/86631 for benchmark numbers.",
    "sha": "b35713c4b5aa922fef5442d002d43c72b7d13838",
    "files": [
        {
            "sha": "a20e20d2971eee31ae368d524371d315c98a2bbd",
            "filename": ".cargo/config.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/.cargo%2Fconfig.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/.cargo%2Fconfig.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.cargo%2Fconfig.toml?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -73,4 +73,4 @@ rustflags = [\n linker = \"arm-linux-gnueabihf-gcc\"\n \n [target.wasm32-unknown-unknown]\n-rustflags = [\"-Zshare-generics=y\", \"--cfg\", 'getrandom_backend=\"wasm_js\"']\n\\ No newline at end of file\n+rustflags = [\"-Zshare-generics=y\", \"--cfg\", 'getrandom_backend=\"wasm_js\"']"
        },
        {
            "sha": "6dc53a67fa519f64ea06e6e4496e3504a1592a11",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -9218,6 +9218,7 @@ dependencies = [\n  \"once_cell\",\n  \"parking_lot\",\n  \"pin-project-lite\",\n+ \"pot\",\n  \"rayon\",\n  \"regex\",\n  \"rustc-hash 2.1.1\",\n@@ -9237,6 +9238,7 @@ dependencies = [\n  \"turbo-tasks-macros\",\n  \"turbo-tasks-malloc\",\n  \"unsize\",\n+ \"unty\",\n ]\n \n [[package]]\n@@ -9258,7 +9260,6 @@ dependencies = [\n  \"lmdb-rkv\",\n  \"once_cell\",\n  \"parking_lot\",\n- \"pot\",\n  \"rand 0.9.0\",\n  \"regex\",\n  \"ringmap\",\n@@ -9272,6 +9273,7 @@ dependencies = [\n  \"thread_local\",\n  \"tokio\",\n  \"tracing\",\n+ \"turbo-bincode\",\n  \"turbo-persistence\",\n  \"turbo-rcstr\",\n  \"turbo-tasks\","
        },
        {
            "sha": "857020e0b32b6d21aab684be1fdf4e4f21fd0110",
            "filename": "Cargo.toml",
            "status": "modified",
            "additions": 8,
            "deletions": 8,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/Cargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/Cargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.toml?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -360,7 +360,6 @@ preset_env_base = \"6.0.0\"\n \n \n # General Deps\n-bincode = { version = \"2.0.1\", features = [\"serde\"] }\n chromiumoxide = { version = \"0.5.4\", features = [\n   \"tokio-runtime\",\n ], default-features = false }\n@@ -374,6 +373,7 @@ allsorts = { version = \"0.14.0\", default-features = false, features = [\n ] }\n anyhow = \"1.0.100\"\n async-trait = \"0.1.64\"\n+bincode = { version = \"2.0.1\", features = [\"serde\"] }\n bitfield = \"0.18.0\"\n byteorder = \"1.5.0\"\n bytes = \"1.1.0\"\n@@ -393,12 +393,13 @@ either = \"1.9.0\"\n erased-serde = \"0.4.5\"\n flate2 = \"1.0.28\"\n futures = \"0.3.31\"\n-futures-util = \"0.3.31\"\n futures-retry = \"0.6.0\"\n+futures-util = \"0.3.31\"\n hashbrown = \"0.14.5\"\n image = { version = \"0.25.8\", default-features = false }\n indexmap = \"2.7.1\"\n indoc = \"2.0.0\"\n+inventory = \"0.3.21\"\n itertools = \"0.10.5\"\n lightningcss = { version = \"1.0.0-alpha.68\", features = [\n   \"serde\",\n@@ -443,11 +444,10 @@ ringmap = \"0.1.3\"\n roaring = \"0.10.10\"\n rstest = \"0.16.0\"\n rustc-hash = \"2.1.1\"\n-twox-hash = { version = \"2.1.0\", features = [\"xxhash64\", \"xxhash3_128\"] }\n semver = \"1.0.16\"\n serde = { version = \"1.0.217\", features = [\"derive\"] }\n-serde_json = \"1.0.138\"\n serde_bytes = \"0.11.15\"\n+serde_json = \"1.0.138\"\n serde_path_to_error = \"0.1.16\"\n serde_qs = \"0.13.0\"\n serde_with = \"3.12.0\"\n@@ -458,18 +458,19 @@ smallvec = { version = \"1.15.1\", features = [\n   \"const_new\",\n   \"impl_bincode\",\n ] }\n-swc_sourcemap = \"9.3.4\"\n-strsim = \"0.11.1\"\n shrink-to-fit = \"0.2.10\"\n+strsim = \"0.11.1\"\n+swc_sourcemap = \"9.3.4\"\n syn = \"2.0.100\"\n tempfile = \"3.20.0\"\n-thread_local = \"1.1.8\"\n thiserror = \"1.0.48\"\n+thread_local = \"1.1.8\"\n tokio = \"1.43.0\"\n tokio-util = { version = \"0.7.13\", features = [\"io\", \"rt\"] }\n tracing = \"0.1.37\"\n tracing-subscriber = \"0.3.16\"\n triomphe = { git = \"https://github.com/sokra/triomphe\", branch = \"sokra/unstable\" }\n+twox-hash = { version = \"2.1.0\", features = [\"xxhash64\", \"xxhash3_128\"] }\n unsize = \"1.1.0\"\n unty = \"0.0.4\"\n url = \"2.2.2\"\n@@ -478,7 +479,6 @@ uuid = \"1.18.1\"\n vergen = { version = \"9.0.6\", features = [\"cargo\"] }\n vergen-gitcl = { version = \"1.0.8\", features = [\"cargo\"] }\n webbrowser = \"1.0.6\"\n-inventory = \"0.3.21\"\n \n [patch.crates-io]\n bincode = { git = \"https://github.com/bgw/bincode.git\", branch = \"bgw/patches\" }"
        },
        {
            "sha": "4b6a14e7d108b79cecc1701089b9f282e2a55929",
            "filename": "crates/next-core/src/next_config.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/crates%2Fnext-core%2Fsrc%2Fnext_config.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/crates%2Fnext-core%2Fsrc%2Fnext_config.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-core%2Fsrc%2Fnext_config.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -2204,9 +2204,10 @@ impl NextConfig {\n /// A subset of ts/jsconfig that next.js implicitly\n /// interops with.\n #[turbo_tasks::value(serialization = \"custom\", eq = \"manual\")]\n-#[derive(Clone, Debug, Default, PartialEq, Serialize, Deserialize)]\n+#[derive(Clone, Debug, Default, PartialEq, Serialize, Deserialize, Encode, Decode)]\n #[serde(rename_all = \"camelCase\")]\n pub struct JsConfig {\n+    #[bincode(with = \"turbo_bincode::serde_json\")]\n     compiler_options: Option<serde_json::Value>,\n }\n "
        },
        {
            "sha": "7404fcb2d9b8b69c13c769cb97af2e0acc9538c5",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -42,7 +42,6 @@ indexmap = { workspace = true }\n lmdb-rkv = { version = \"0.14.0\", optional = true }\n once_cell = { workspace = true }\n parking_lot = { workspace = true }\n-pot = \"3.0.0\"\n rand = { workspace = true }\n ringmap = { workspace = true, features = [\"serde\"] }\n rustc-hash = { workspace = true }\n@@ -53,6 +52,7 @@ smallvec = { workspace = true }\n tokio = { workspace = true }\n tracing = { workspace = true }\n thread_local = { workspace = true }\n+turbo-bincode = { workspace = true }\n turbo-persistence = { workspace = true }\n turbo-rcstr = { workspace = true }\n turbo-tasks = { workspace = true }"
        },
        {
            "sha": "37bb7c036a35f3de4323ef80636e465e738cf441",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1057,6 +1057,9 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n             (meta, data)\n         };\n         let process = |task_id: TaskId, (meta, data): (Option<Vec<_>>, Option<Vec<_>>)| {\n+            // TODO: perf: Instead of returning a `Vec` of individually allocated `SmallVec`s, it'd\n+            // be better to append everything to a flat per-task or per-shard `Vec<u8>`, and have\n+            // each `serialize` call return `(start_idx, end_idx)`.\n             (\n                 task_id,\n                 meta.map(|d| self.backing_storage.serialize(task_id, &d)),"
        },
        {
            "sha": "0fe60ff56cb98a0b1f60f07fa64eedf096cd0326",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/aggregation_update.rs",
            "status": "modified",
            "additions": 100,
            "deletions": 50,
            "changes": 150,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -10,10 +10,10 @@ use std::{\n };\n \n use anyhow::Result;\n+use bincode::{Decode, Encode};\n use indexmap::map::Entry;\n use ringmap::RingSet;\n use rustc_hash::{FxBuildHasher, FxHashMap};\n-use serde::{Deserialize, Serialize, Serializer, ser::SerializeSeq};\n use smallvec::{SmallVec, smallvec};\n #[cfg(any(\n     feature = \"trace_aggregation_update\",\n@@ -166,9 +166,11 @@ impl ComputeDirtyAndCleanUpdateResult {\n     }\n }\n \n-#[derive(Serialize, Deserialize, Clone, Debug)]\n+#[derive(Encode, Decode, Clone, Debug)]\n pub struct InnerOfUppersHasNewFollowersJob {\n+    #[bincode(with = \"turbo_bincode::smallvec\")]\n     pub upper_ids: TaskIdVec,\n+    #[bincode(with = \"turbo_bincode::smallvec\")]\n     pub new_follower_ids: TaskIdVec,\n }\n \n@@ -178,9 +180,11 @@ impl From<InnerOfUppersHasNewFollowersJob> for AggregationUpdateJob {\n     }\n }\n \n-#[derive(Serialize, Deserialize, Clone, Debug)]\n+#[derive(Encode, Decode, Clone, Debug)]\n pub struct InnerOfUppersLostFollowersJob {\n+    #[bincode(with = \"turbo_bincode::smallvec\")]\n     pub upper_ids: TaskIdVec,\n+    #[bincode(with = \"turbo_bincode::smallvec\")]\n     pub lost_follower_ids: TaskIdVec,\n }\n \n@@ -190,7 +194,7 @@ impl From<InnerOfUppersLostFollowersJob> for AggregationUpdateJob {\n     }\n }\n \n-#[derive(Serialize, Deserialize, Clone, Debug)]\n+#[derive(Encode, Decode, Clone, Debug)]\n pub struct AggregatedDataUpdateJob {\n     pub upper_ids: TaskIdVec,\n     pub update: AggregatedDataUpdate,\n@@ -203,7 +207,7 @@ impl From<AggregatedDataUpdateJob> for AggregationUpdateJob {\n }\n \n /// A job in the job queue for updating something in the aggregated graph.\n-#[derive(Serialize, Deserialize, Clone, Debug)]\n+#[derive(Encode, Decode, Clone, Debug)]\n pub enum AggregationUpdateJob {\n     /// Update the aggregation number of a task. This might result in balancing needed to update\n     /// \"upper\" and \"follower\" edges.\n@@ -252,17 +256,27 @@ pub enum AggregationUpdateJob {\n         collectible_type: turbo_tasks::TraitTypeId,\n     },\n     /// Increases the active counter of the task\n-    #[serde(skip)]\n-    IncreaseActiveCount { task: TaskId },\n+    IncreaseActiveCount {\n+        // TODO: bgw: Add a way to skip the entire enum variant in bincode (generating an error\n+        // upon attempted serialization) similar to #[serde(skip)] on variants\n+        #[bincode(skip, default = \"unreachable_decode\")]\n+        task: TaskId,\n+    },\n     /// Increases the active counters of the tasks\n-    #[serde(skip)]\n-    IncreaseActiveCounts { task_ids: TaskIdVec },\n+    IncreaseActiveCounts {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n+        task_ids: TaskIdVec,\n+    },\n     /// Decreases the active counter of the task\n-    #[serde(skip)]\n-    DecreaseActiveCount { task: TaskId },\n+    DecreaseActiveCount {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n+        task: TaskId,\n+    },\n     /// Decreases the active counters of the tasks\n-    #[serde(skip)]\n-    DecreaseActiveCounts { task_ids: TaskIdVec },\n+    DecreaseActiveCounts {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n+        task_ids: TaskIdVec,\n+    },\n     /// Balances the edges of the graph. This checks if the graph invariant is still met for this\n     /// edge and coverts a upper edge to a follower edge or vice versa. Balancing might triggers\n     /// more changes to the structure.\n@@ -271,6 +285,10 @@ pub enum AggregationUpdateJob {\n     Noop,\n }\n \n+fn unreachable_decode<T>() -> T {\n+    unreachable!(\"AggregatedDataUpdateJob variant should not have been encoded, cannot decode\")\n+}\n+\n impl AggregationUpdateJob {\n     pub fn data_update(\n         task: &mut impl TaskGuard,\n@@ -291,9 +309,10 @@ impl AggregationUpdateJob {\n     }\n }\n \n-#[derive(Default, Serialize, Deserialize, Clone, Copy, Debug)]\n+#[derive(Default, Encode, Decode, Clone, Copy, Debug)]\n+#[bincode(decode_bounds = \"T: Default\", borrow_decode_bounds = \"T: Default\")]\n pub struct SessionDependent<T> {\n-    #[serde(skip, default)]\n+    #[bincode(skip)]\n     pub value: T,\n }\n \n@@ -312,7 +331,7 @@ impl<T> Deref for SessionDependent<T> {\n }\n \n /// Aggregated data update.\n-#[derive(Default, Serialize, Deserialize, Clone, Debug)]\n+#[derive(Default, Encode, Decode, Clone, Debug)]\n pub struct AggregatedDataUpdate {\n     /// One of the inner tasks has changed its dirty state or aggregated dirty state.\n     /// (task id, dirty update, current session clean update)\n@@ -649,21 +668,21 @@ impl AggregatedDataUpdate {\n }\n \n /// An aggregation number update job that is enqueued.\n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n struct AggregationNumberUpdate {\n     base_aggregation_number: u32,\n     distance: Option<NonZeroU32>,\n     #[cfg(feature = \"trace_aggregation_update\")]\n-    #[serde(skip, default)]\n+    #[bincode(skip, default)]\n     span: Option<Span>,\n }\n \n /// An aggregated data update job that is enqueued. See `AggregatedDataUpdate`.\n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n struct AggregationUpdateJobItem {\n     job: AggregationUpdateJob,\n     #[cfg(feature = \"trace_aggregation_update\")]\n-    #[serde(skip, default)]\n+    #[bincode(skip, default)]\n     span: Option<Span>,\n }\n \n@@ -692,12 +711,12 @@ struct AggregationUpdateJobGuard {\n }\n \n /// A balancing job that is enqueued. See `balance_edge`.\n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n struct BalanceJob {\n     upper_id: TaskId,\n     task_id: TaskId,\n     #[cfg(feature = \"trace_aggregation_update\")]\n-    #[serde(skip, default)]\n+    #[bincode(skip, default)]\n     span: Option<Span>,\n }\n \n@@ -728,11 +747,11 @@ impl PartialEq for BalanceJob {\n impl Eq for BalanceJob {}\n \n /// An optimization job that is enqueued. See `optimize_task`.\n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n struct OptimizeJob {\n     task_id: TaskId,\n     #[cfg(feature = \"trace_aggregation_update\")]\n-    #[serde(skip, default)]\n+    #[bincode(skip, default)]\n     span: Option<Span>,\n }\n \n@@ -761,11 +780,11 @@ impl PartialEq for OptimizeJob {\n impl Eq for OptimizeJob {}\n \n /// A job to find and schedule dirty tasks that is enqueued. See `find_and_schedule_dirty`.\n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n struct FindAndScheduleJob {\n     task_id: TaskId,\n     #[cfg(feature = \"trace_find_and_schedule\")]\n-    #[serde(skip, default)]\n+    #[bincode(skip, default)]\n     span: Option<Span>,\n }\n \n@@ -793,42 +812,73 @@ impl PartialEq for FindAndScheduleJob {\n \n impl Eq for FindAndScheduleJob {}\n \n-/// Serializes the jobs in the queue. This is used to filter out transient jobs during\n-/// serialization.\n-fn serialize_jobs<S: Serializer>(\n-    jobs: &VecDeque<AggregationUpdateJobItem>,\n-    serializer: S,\n-) -> Result<S::Ok, S::Error> {\n-    let mut seq = serializer.serialize_seq(Some(jobs.len()))?;\n-    for job in jobs {\n-        match job.job {\n-            AggregationUpdateJob::IncreaseActiveCount { .. }\n-            | AggregationUpdateJob::IncreaseActiveCounts { .. }\n-            | AggregationUpdateJob::DecreaseActiveCount { .. }\n-            | AggregationUpdateJob::DecreaseActiveCounts { .. } => {\n-                seq.serialize_element(&AggregationUpdateJobItem {\n-                    job: AggregationUpdateJob::Noop,\n-                    #[cfg(feature = \"trace_aggregation_update\")]\n-                    span: None,\n-                })?;\n-            }\n-            _ => {\n-                seq.serialize_element(job)?;\n+/// Encodes the jobs in the queue. This is used to filter out transient jobs during encoding.\n+mod encode_jobs {\n+    use bincode::{\n+        de::{BorrowDecoder, Decoder},\n+        enc::Encoder,\n+        error::{DecodeError, EncodeError},\n+    };\n+\n+    use super::*;\n+\n+    pub fn encode<E: Encoder>(\n+        jobs: &VecDeque<AggregationUpdateJobItem>,\n+        encoder: &mut E,\n+    ) -> Result<(), EncodeError> {\n+        usize::encode(&jobs.len(), encoder)?;\n+        for job in jobs {\n+            match job.job {\n+                AggregationUpdateJob::IncreaseActiveCount { .. }\n+                | AggregationUpdateJob::IncreaseActiveCounts { .. }\n+                | AggregationUpdateJob::DecreaseActiveCount { .. }\n+                | AggregationUpdateJob::DecreaseActiveCounts { .. } => {\n+                    AggregationUpdateJobItem {\n+                        job: AggregationUpdateJob::Noop,\n+                        #[cfg(feature = \"trace_aggregation_update\")]\n+                        span: None,\n+                    }\n+                    .encode(encoder)?;\n+                }\n+                _ => {\n+                    job.encode(encoder)?;\n+                }\n             }\n         }\n+        Ok(())\n+    }\n+\n+    pub fn decode<Context, D: Decoder<Context = Context>>(\n+        decoder: &mut D,\n+    ) -> Result<VecDeque<AggregationUpdateJobItem>, DecodeError> {\n+        let len = usize::decode(decoder)?;\n+        let mut jobs = VecDeque::with_capacity(len);\n+        for _ in 0..len {\n+            jobs.push_back(Decode::decode(decoder)?);\n+        }\n+        Ok(jobs)\n+    }\n+\n+    pub fn borrow_decode<'de, Context, D: BorrowDecoder<'de, Context = Context>>(\n+        decoder: &mut D,\n+    ) -> Result<VecDeque<AggregationUpdateJobItem>, DecodeError> {\n+        decode(decoder)\n     }\n-    seq.end()\n }\n \n /// A queue for aggregation update jobs.\n-#[derive(Default, Serialize, Deserialize, Clone)]\n+#[derive(Default, Encode, Decode, Clone)]\n pub struct AggregationUpdateQueue {\n-    #[serde(serialize_with = \"serialize_jobs\")]\n+    #[bincode(with = \"encode_jobs\")]\n     jobs: VecDeque<AggregationUpdateJobItem>,\n+    #[bincode(with = \"turbo_bincode::indexmap\")]\n     number_updates: FxIndexMap<TaskId, AggregationNumberUpdate>,\n     done_number_updates: FxHashMap<TaskId, AggregationNumberUpdate>,\n+    #[bincode(with = \"turbo_bincode::ringset\")]\n     find_and_schedule: FxRingSet<FindAndScheduleJob>,\n+    #[bincode(with = \"turbo_bincode::ringset\")]\n     balance_queue: FxRingSet<BalanceJob>,\n+    #[bincode(with = \"turbo_bincode::ringset\")]\n     optimize_queue: FxRingSet<OptimizeJob>,\n }\n "
        },
        {
            "sha": "e18873d38280c4e330758fd5dd005b10ded7cf89",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/cleanup_old_edges.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,7 +1,7 @@\n use std::mem::take;\n \n+use bincode::{Decode, Encode};\n use rustc_hash::FxHashSet;\n-use serde::{Deserialize, Serialize};\n use smallvec::SmallVec;\n use turbo_tasks::TaskId;\n \n@@ -23,7 +23,7 @@ use crate::{\n     data::{CachedDataItemKey, CellRef, CollectibleRef, CollectiblesRef},\n };\n \n-#[derive(Serialize, Deserialize, Clone, Default)]\n+#[derive(Encode, Decode, Clone, Default)]\n pub enum CleanupOldEdgesOperation {\n     RemoveEdges {\n         task_id: TaskId,\n@@ -38,7 +38,7 @@ pub enum CleanupOldEdgesOperation {\n     // TODO Add aggregated edge\n }\n \n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n pub enum OutdatedEdge {\n     Child(TaskId),\n     Collectible(CollectibleRef, i32),"
        },
        {
            "sha": "cbfc93a6d5f6ca197bdadbd91c8ad63f588a70c8",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/connect_child.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,4 +1,4 @@\n-use serde::{Deserialize, Serialize};\n+use bincode::{Decode, Encode};\n use turbo_tasks::{TaskExecutionReason, TaskId};\n \n use crate::{\n@@ -12,7 +12,7 @@ use crate::{\n     data::{CachedDataItem, CachedDataItemKey, InProgressState, InProgressStateInner},\n };\n \n-#[derive(Serialize, Deserialize, Clone, Default)]\n+#[derive(Encode, Decode, Clone, Default)]\n #[allow(clippy::large_enum_variant)]\n pub enum ConnectChildOperation {\n     UpdateAggregation {"
        },
        {
            "sha": "2383da6ee3914f5980a072e60a3361f2697d1d2c",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/invalidate.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,4 +1,4 @@\n-use serde::{Deserialize, Serialize};\n+use bincode::{Decode, Encode};\n use smallvec::SmallVec;\n use turbo_tasks::{TaskExecutionReason, TaskId};\n \n@@ -19,7 +19,7 @@ use crate::{\n     },\n };\n \n-#[derive(Serialize, Deserialize, Clone, Default)]\n+#[derive(Encode, Decode, Clone, Default)]\n #[allow(clippy::large_enum_variant)]\n pub enum InvalidateOperation {\n     MakeDirty {"
        },
        {
            "sha": "75d4d4265e8b77908e1d3f78489108d3f97e557a",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/mod.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -13,7 +13,7 @@ use std::{\n     sync::{Arc, atomic::Ordering},\n };\n \n-use serde::{Deserialize, Serialize};\n+use bincode::{Decode, Encode};\n use turbo_tasks::{\n     CellId, FxIndexMap, KeyValuePair, TaskId, TurboTasksBackendApi, TypedSharedReference,\n };\n@@ -32,11 +32,7 @@ use crate::{\n };\n \n pub trait Operation:\n-    Serialize\n-    + for<'de> Deserialize<'de>\n-    + Default\n-    + TryFrom<AnyOperation, Error = ()>\n-    + Into<AnyOperation>\n+    Encode + Decode<()> + Default + TryFrom<AnyOperation, Error = ()> + Into<AnyOperation>\n {\n     fn execute(self, ctx: &mut impl ExecuteContext);\n }\n@@ -786,7 +782,7 @@ macro_rules! impl_operation {\n     };\n }\n \n-#[derive(Serialize, Deserialize, Clone)]\n+#[derive(Encode, Decode, Clone)]\n pub enum AnyOperation {\n     ConnectChild(connect_child::ConnectChildOperation),\n     Invalidate(invalidate::InvalidateOperation),"
        },
        {
            "sha": "fbdf9e2ff294ff96d0bb38b4c10b32debdc1b076",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/update_cell.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_cell.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_cell.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_cell.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,6 +1,6 @@\n use std::mem::take;\n \n-use serde::{Deserialize, Serialize};\n+use bincode::{Decode, Encode};\n use smallvec::SmallVec;\n #[cfg(not(feature = \"verify_determinism\"))]\n use turbo_tasks::backend::VerificationMode;\n@@ -20,7 +20,7 @@ use crate::{\n     data::{CachedDataItem, CachedDataItemKey, CellRef},\n };\n \n-#[derive(Serialize, Deserialize, Clone, Default)]\n+#[derive(Encode, Decode, Clone, Default)]\n #[allow(clippy::large_enum_variant)]\n pub enum UpdateCellOperation {\n     InvalidateWhenCellDependency {"
        },
        {
            "sha": "a88854f0b26a46723eb896a1b1ed2ae074821e3d",
            "filename": "turbopack/crates/turbo-tasks-backend/src/data.rs",
            "status": "modified",
            "additions": 32,
            "deletions": 18,
            "changes": 50,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,3 +1,4 @@\n+use bincode::{Decode, Encode};\n use rustc_hash::FxHashSet;\n use serde::{Deserialize, Serialize};\n use turbo_tasks::{\n@@ -32,25 +33,25 @@ macro_rules! transient_traits {\n     };\n }\n \n-#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Serialize, Deserialize)]\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Encode, Decode)]\n pub struct CellRef {\n     pub task: TaskId,\n     pub cell: CellId,\n }\n \n-#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Serialize, Deserialize)]\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Encode, Decode)]\n pub struct CollectibleRef {\n     pub collectible_type: TraitTypeId,\n     pub cell: CellRef,\n }\n \n-#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Serialize, Deserialize)]\n+#[derive(Debug, Copy, Clone, Hash, PartialEq, Eq, Encode, Decode)]\n pub struct CollectiblesRef {\n     pub task: TaskId,\n     pub collectible_type: TraitTypeId,\n }\n \n-#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\n+#[derive(Debug, Clone, PartialEq, Eq, Encode, Decode)]\n pub enum OutputValue {\n     Cell(CellRef),\n     Output(TaskId),\n@@ -140,7 +141,7 @@ transient_traits!(ActivenessState);\n \n impl Eq for ActivenessState {}\n \n-#[derive(Debug, Clone, Copy, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Debug, Clone, Copy, Encode, Decode, PartialEq, Eq)]\n pub enum Dirtyness {\n     Dirty,\n     SessionDependent,\n@@ -205,14 +206,14 @@ impl InProgressCellState {\n     }\n }\n \n-#[derive(Debug, Clone, Copy, Default, PartialEq, Eq, Serialize, Deserialize)]\n+#[derive(Debug, Clone, Copy, Default, PartialEq, Eq, Serialize, Deserialize, Encode, Decode)]\n pub struct AggregationNumber {\n     pub base: u32,\n     pub distance: u32,\n     pub effective: u32,\n }\n \n-#[derive(Debug, Clone, KeyValuePair, Serialize, Deserialize)]\n+#[derive(Debug, Clone, KeyValuePair, Encode, Decode)]\n pub enum CachedDataItem {\n     // Output\n     Output {\n@@ -227,8 +228,10 @@ pub enum CachedDataItem {\n     Dirty {\n         value: Dirtyness,\n     },\n-    #[serde(skip)]\n     CurrentSessionClean {\n+        // TODO: bgw: Add a way to skip the entire enum variant in bincode (generating an error\n+        // upon attempted serialization) similar to #[serde(skip)] on variants\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: (),\n     },\n \n@@ -243,9 +246,10 @@ pub enum CachedDataItem {\n         cell: CellId,\n         value: TypedSharedReference,\n     },\n-    #[serde(skip)]\n     TransientCellData {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         cell: CellId,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: SharedReference,\n     },\n     CellTypeMaxIndex {\n@@ -301,9 +305,10 @@ pub enum CachedDataItem {\n         task: TaskId,\n         value: i32,\n     },\n-    #[serde(skip)]\n     AggregatedCurrentSessionCleanContainer {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         task: TaskId,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: i32,\n     },\n     AggregatedCollectible {\n@@ -313,8 +318,8 @@ pub enum CachedDataItem {\n     AggregatedDirtyContainerCount {\n         value: i32,\n     },\n-    #[serde(skip)]\n     AggregatedCurrentSessionCleanContainerCount {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: i32,\n     },\n \n@@ -330,43 +335,52 @@ pub enum CachedDataItem {\n     },\n \n     // Transient Root Type\n-    #[serde(skip)]\n     Activeness {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: ActivenessState,\n     },\n \n     // Transient In Progress state\n-    #[serde(skip)]\n     InProgress {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: InProgressState,\n     },\n-    #[serde(skip)]\n     InProgressCell {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         cell: CellId,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: InProgressCellState,\n     },\n-    #[serde(skip)]\n     OutdatedCollectible {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         collectible: CollectibleRef,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: i32,\n     },\n-    #[serde(skip)]\n     OutdatedOutputDependency {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         target: TaskId,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: (),\n     },\n-    #[serde(skip)]\n     OutdatedCellDependency {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         target: CellRef,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: (),\n     },\n-    #[serde(skip)]\n     OutdatedCollectiblesDependency {\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         target: CollectiblesRef,\n+        #[bincode(skip, default = \"unreachable_decode\")]\n         value: (),\n     },\n }\n \n+fn unreachable_decode<T>() -> T {\n+    unreachable!(\"CachedDataItem variant should not have been encoded, cannot decode\")\n+}\n+\n impl CachedDataItem {\n     pub fn cell_data(\n         is_serializable_cell_content: bool,"
        },
        {
            "sha": "6966a70d66b8ad522fb0362d14baeeabab6930b1",
            "filename": "turbopack/crates/turbo-tasks-backend/src/kv_backing_storage.rs",
            "status": "modified",
            "additions": 123,
            "deletions": 169,
            "changes": 292,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -6,8 +6,9 @@ use std::{\n };\n \n use anyhow::{Context, Result, anyhow};\n-use serde::{Deserialize, Serialize};\n-use smallvec::SmallVec;\n+use turbo_bincode::{\n+    TurboBincodeBuffer, turbo_bincode_decode, turbo_bincode_encode, turbo_bincode_encode_into,\n+};\n use turbo_tasks::{\n     TaskId,\n     backend::CachedTaskType,\n@@ -33,42 +34,6 @@ use crate::{\n     utils::chunked_vec::ChunkedVec,\n };\n \n-const POT_CONFIG: pot::Config = pot::Config::new().compatibility(pot::Compatibility::V4);\n-\n-fn pot_serialize_small_vec<T: Serialize>(value: &T) -> pot::Result<SmallVec<[u8; 16]>> {\n-    struct SmallVecWrite<'l>(&'l mut SmallVec<[u8; 16]>);\n-    impl std::io::Write for SmallVecWrite<'_> {\n-        #[inline]\n-        fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {\n-            self.0.extend_from_slice(buf);\n-            Ok(buf.len())\n-        }\n-\n-        #[inline]\n-        fn write_all(&mut self, buf: &[u8]) -> std::io::Result<()> {\n-            self.0.extend_from_slice(buf);\n-            Ok(())\n-        }\n-\n-        #[inline]\n-        fn flush(&mut self) -> std::io::Result<()> {\n-            Ok(())\n-        }\n-    }\n-\n-    let mut output = SmallVec::new();\n-    POT_CONFIG.serialize_into(value, SmallVecWrite(&mut output))?;\n-    Ok(output)\n-}\n-\n-fn pot_ser_symbol_map() -> pot::ser::SymbolMap {\n-    pot::ser::SymbolMap::new().with_compatibility(pot::Compatibility::V4)\n-}\n-\n-fn pot_de_symbol_list<'l>() -> pot::de::SymbolList<'l> {\n-    pot::de::SymbolList::new()\n-}\n-\n const META_KEY_OPERATIONS: u32 = 0;\n const META_KEY_NEXT_FREE_TASK_ID: u32 = 1;\n \n@@ -279,14 +244,14 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(Vec::new());\n             };\n-            let operations = deserialize_with_good_error(operations.borrow())?;\n+            let operations = turbo_bincode_decode(operations.borrow())?;\n             Ok(operations)\n         }\n         get(&self.inner.database).context(\"Unable to read uncompleted operations from database\")\n     }\n \n-    fn serialize(&self, task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>> {\n-        serialize(task, data)\n+    fn serialize(&self, task: TaskId, data: &Vec<CachedDataItem>) -> Result<TurboBincodeBuffer> {\n+        encode_task_data(task, data)\n     }\n \n     fn save_snapshot<I>(\n@@ -299,15 +264,18 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n         I: Iterator<\n                 Item = (\n                     TaskId,\n-                    Option<SmallVec<[u8; 16]>>,\n-                    Option<SmallVec<[u8; 16]>>,\n+                    Option<TurboBincodeBuffer>,\n+                    Option<TurboBincodeBuffer>,\n                 ),\n             > + Send\n             + Sync,\n     {\n         let _span = tracing::info_span!(\"save snapshot\", operations = operations.len()).entered();\n         let mut batch = self.inner.database.write_batch()?;\n \n+        // these buffers should be large, because they're temporary and re-used.\n+        const INITIAL_ENCODE_BUFFER_CAPACITY: usize = 1024;\n+\n         // Start organizing the updates in parallel\n         match &mut batch {\n             &mut WriteBatch::Concurrent(ref batch, _) => {\n@@ -337,19 +305,20 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                         items = task_cache_updates.iter().map(|m| m.len()).sum::<usize>()\n                     )\n                     .entered();\n-                    let result = parallel::map_collect_owned::<_, _, Result<Vec<_>>>(\n+                    let max_task_id = parallel::map_collect_owned::<_, _, Result<Vec<_>>>(\n                         task_cache_updates,\n                         |updates| {\n                             let _span = _span.clone().entered();\n                             let mut max_task_id = 0;\n \n-                            let mut task_type_bytes = Vec::new();\n+                            // Re-use the same buffer across every `serialize_task_type` call in\n+                            // this chunk. `ConcurrentWriteBatch::put` will copy the data out of\n+                            // this buffer into smaller exact-sized vecs.\n+                            let mut task_type_bytes =\n+                                TurboBincodeBuffer::with_capacity(INITIAL_ENCODE_BUFFER_CAPACITY);\n                             for (task_type, task_id) in updates {\n-                                serialize_task_type(\n-                                    &task_type,\n-                                    &mut task_type_bytes,\n-                                    Some(task_id),\n-                                )?;\n+                                task_type_bytes.clear();\n+                                encode_task_type(&task_type, &mut task_type_bytes, Some(task_id))?;\n                                 let task_id: u32 = *task_id;\n \n                                 batch\n@@ -374,7 +343,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                                             \"Unable to write task cache {task_id} => {task_type:?}\"\n                                         )\n                                     })?;\n-                                max_task_id = max_task_id.max(task_id + 1);\n+                                max_task_id = max_task_id.max(task_id);\n                             }\n \n                             Ok(max_task_id)\n@@ -383,7 +352,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                     .into_iter()\n                     .max()\n                     .unwrap_or(0);\n-                    next_task_id = next_task_id.max(result);\n+                    next_task_id = next_task_id.max(max_task_id + 1);\n                 }\n \n                 save_infra::<T::SerialWriteBatch<'_>, T::ConcurrentWriteBatch<'_>>(\n@@ -430,9 +399,13 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                         items = task_cache_updates.iter().map(|m| m.len()).sum::<usize>()\n                     )\n                     .entered();\n-                    let mut task_type_bytes = Vec::new();\n+                    // Re-use the same buffer across every `serialize_task_type` call.\n+                    // `ConcurrentWriteBatch::put` will copy the data out of this buffer into\n+                    // smaller exact-sized vecs.\n+                    let mut task_type_bytes =\n+                        TurboBincodeBuffer::with_capacity(INITIAL_ENCODE_BUFFER_CAPACITY);\n                     for (task_type, task_id) in task_cache_updates.into_iter().flatten() {\n-                        serialize_task_type(&task_type, &mut task_type_bytes, Some(task_id))?;\n+                        encode_task_type(&task_type, &mut task_type_bytes, Some(task_id))?;\n                         let task_id = *task_id;\n \n                         batch\n@@ -489,8 +462,8 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             tx: &D::ReadTransaction<'_>,\n             task_type: &CachedTaskType,\n         ) -> Result<Option<TaskId>> {\n-            let mut task_type_bytes = Vec::new();\n-            serialize_task_type(task_type, &mut task_type_bytes, None)?;\n+            let mut task_type_bytes = TurboBincodeBuffer::new();\n+            encode_task_type(task_type, &mut task_type_bytes, None)?;\n             let Some(bytes) = database.get(tx, KeySpace::ForwardTaskCache, &task_type_bytes)?\n             else {\n                 return Ok(None);\n@@ -528,7 +501,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(None);\n             };\n-            Ok(Some(deserialize_with_good_error(bytes.borrow())?))\n+            Ok(Some(turbo_bincode_decode(bytes.borrow())?))\n         }\n         inner\n             .with_tx(tx, |tx| lookup(&inner.database, tx, task_id))\n@@ -560,7 +533,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(Vec::new());\n             };\n-            let result: Vec<CachedDataItem> = deserialize_with_good_error(bytes.borrow())?;\n+            let result: Vec<CachedDataItem> = turbo_bincode_decode(bytes.borrow())?;\n             Ok(result)\n         }\n         inner\n@@ -607,102 +580,99 @@ where\n                 WriteBuffer::Borrowed(IntKey::new(META_KEY_NEXT_FREE_TASK_ID).as_ref()),\n                 WriteBuffer::Borrowed(&next_task_id.to_le_bytes()),\n             )\n-            .with_context(|| anyhow!(\"Unable to write next free task id\"))?;\n+            .context(\"Unable to write next free task id\")?;\n     }\n     {\n         let _span =\n             tracing::trace_span!(\"update operations\", operations = operations.len()).entered();\n-        let operations = pot_serialize_small_vec(&operations)\n-            .with_context(|| anyhow!(\"Unable to serialize operations\"))?;\n+        let operations =\n+            turbo_bincode_encode(&operations).context(\"Unable to serialize operations\")?;\n         batch\n             .put(\n                 KeySpace::Infra,\n                 WriteBuffer::Borrowed(IntKey::new(META_KEY_OPERATIONS).as_ref()),\n                 WriteBuffer::SmallVec(operations),\n             )\n-            .with_context(|| anyhow!(\"Unable to write operations\"))?;\n+            .context(\"Unable to write operations\")?;\n     }\n     batch.flush(KeySpace::Infra)?;\n     Ok(())\n }\n \n-// DO NOT REMOVE THE `inline(never)` ATTRIBUTE!\n-// `pot` uses the pointer address of `&'static str` to deduplicate Symbols.\n-// If this function is inlined into multiple different callsites it might inline the Serialize\n-// implementation too, which can pull a `&'static str` from another crate into this crate.\n-// Since string deduplication between crates is not guaranteed, it can lead to behavior changes due\n-// to the pointer addresses. This can lead to lookup path and store path creating different\n-// serialization of the same task type, which breaks task cache lookups.\n-#[inline(never)]\n-fn serialize_task_type(\n+fn encode_task_type(\n     task_type: &CachedTaskType,\n-    mut task_type_bytes: &mut Vec<u8>,\n+    buffer: &mut TurboBincodeBuffer,\n     task_id: Option<TaskId>,\n ) -> Result<()> {\n-    task_type_bytes.clear();\n-    POT_CONFIG\n-        .serialize_into(task_type, &mut task_type_bytes)\n-        .with_context(|| {\n+    // DO NOT REMOVE THE `inline(never)` ATTRIBUTE!\n+    // CachedTaskType's `Encode`/`Decode` implementations use `pot` internally for `TaskInput`s.\n+    // TODO: remove `serde` and `pot`, make `TaskInput: Encode + Decode`.\n+    //\n+    // `pot` uses the pointer address of `&'static str` to deduplicate Symbols.\n+    // If this function is inlined into multiple different callsites it might inline the Serialize\n+    // implementation too, which can pull a `&'static str` from another crate into this crate.\n+    // Since string deduplication between crates is not guaranteed, it can lead to behavior changes\n+    // due to the pointer addresses. This can lead to lookup path and store path creating different\n+    // serialization of the same task type, which breaks task cache lookups.\n+    #[inline(never)]\n+    fn encode_once_into(\n+        task_type: &CachedTaskType,\n+        buffer: &mut TurboBincodeBuffer,\n+        task_id: Option<TaskId>,\n+    ) -> Result<()> {\n+        turbo_bincode_encode_into(task_type, buffer).with_context(|| {\n             if let Some(task_id) = task_id {\n-                anyhow!(\"Unable to serialize task {task_id} cache key {task_type:?}\")\n+                format!(\"Unable to serialize task {task_id} cache key {task_type:?}\")\n             } else {\n-                anyhow!(\"Unable to serialize task cache key {task_type:?}\")\n+                format!(\"Unable to serialize task cache key {task_type:?}\")\n             }\n-        })?;\n-    #[cfg(feature = \"verify_serialization\")]\n-    {\n-        let deserialize: Result<CachedTaskType, _> = serde_path_to_error::deserialize(\n-            &mut pot_de_symbol_list().deserializer_for_slice(&*task_type_bytes)?,\n-        );\n+        })\n+    }\n+\n+    debug_assert!(buffer.is_empty());\n+    encode_once_into(task_type, buffer, task_id)?;\n+\n+    if cfg!(feature = \"verify_serialization\") {\n+        macro_rules! println_and_panic {\n+            ($($tt:tt)*) => {\n+                println!($($tt)*);\n+                panic!($($tt)*);\n+            };\n+        }\n+        let deserialize: Result<CachedTaskType, _> = turbo_bincode_decode(buffer);\n         match deserialize {\n             Err(err) => {\n-                println!(\n-                    \"Task type would not be deserializable {task_id:?}: {err:?}\\n{task_type:#?}\"\n-                );\n-                panic!(\"Task type would not be deserializable {task_id:?}: {err:?}\");\n+                println_and_panic!(\"Task type would not be deserializable:\\n{err:?}\");\n             }\n             Ok(task_type2) => {\n                 if &task_type2 != task_type {\n-                    println!(\n-                        \"Task type would not round-trip {task_id:?}:\\noriginal: \\\n-                         {task_type:#?}\\nround-tripped: {task_type2:#?}\"\n-                    );\n-                    panic!(\n+                    println_and_panic!(\n                         \"Task type would not round-trip {task_id:?}:\\noriginal: \\\n                          {task_type:#?}\\nround-tripped: {task_type2:#?}\"\n                     );\n                 }\n-                let mut bytes2 = Vec::new();\n-                let result2 = POT_CONFIG.serialize_into(&task_type2, &mut bytes2);\n-                match result2 {\n+                let mut buffer2 = TurboBincodeBuffer::new();\n+                match encode_once_into(&task_type2, &mut buffer2, task_id) {\n                     Err(err) => {\n-                        println!(\n-                            \"Task type would not be serializable the second time {task_id:?}: \\\n-                             {err:?}\\n{task_type2:#?}\"\n-                        );\n-                        panic!(\n-                            \"Task type would not be serializable the second time {task_id:?}: \\\n-                             {err:?}\\n{task_type2:#?}\"\n+                        println_and_panic!(\n+                            \"Task type would not be serializable the second time:\\n{err:?}\"\n                         );\n                     }\n                     Ok(()) => {\n-                        if bytes2 != *task_type_bytes {\n-                            println!(\n+                        if buffer2 != *buffer {\n+                            println_and_panic!(\n                                 \"Task type would not serialize to the same bytes the second time \\\n                                  {task_id:?}:\\noriginal: {:x?}\\nsecond: {:x?}\\n{task_type2:#?}\",\n-                                task_type_bytes, bytes2\n-                            );\n-                            panic!(\n-                                \"Task type would not serialize to the same bytes the second time \\\n-                                 {task_id:?}:\\noriginal: {:x?}\\nsecond: {:x?}\\n{task_type2:#?}\",\n-                                task_type_bytes, bytes2\n+                                buffer,\n+                                buffer2\n                             );\n                         }\n                     }\n                 }\n             }\n         }\n     }\n+\n     Ok(())\n }\n \n@@ -722,8 +692,8 @@ where\n     I: Iterator<\n             Item = (\n                 TaskId,\n-                Option<SmallVec<[u8; 16]>>,\n-                Option<SmallVec<[u8; 16]>>,\n+                Option<TurboBincodeBuffer>,\n+                Option<TurboBincodeBuffer>,\n             ),\n         > + Send\n         + Sync,\n@@ -762,63 +732,47 @@ where\n     })\n }\n \n-fn serialize(task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>> {\n-    Ok(match pot_serialize_small_vec(data) {\n-        #[cfg(not(feature = \"verify_serialization\"))]\n-        Ok(value) => value,\n-        _ => {\n-            let mut error = Ok(());\n-            let mut data = data.clone();\n-            data.retain(|item| {\n-                let mut buf = Vec::<u8>::new();\n-                let mut symbol_map = pot_ser_symbol_map();\n-                let mut serializer = symbol_map.serializer_for(&mut buf).unwrap();\n-                if let Err(err) = serde_path_to_error::serialize(&item, &mut serializer) {\n-                    if item.is_optional() {\n-                        #[cfg(feature = \"verify_serialization\")]\n-                        println!(\n-                            \"Skipping non-serializable optional item for {task}: {item:?} due to \\\n-                             {err}\"\n-                        );\n-                    } else {\n-                        error = Err(err).context({\n-                            anyhow!(\"Unable to serialize data item for {task}: {item:?}\")\n-                        });\n-                    }\n-                    false\n-                } else {\n-                    #[cfg(feature = \"verify_serialization\")]\n-                    {\n-                        let deserialize: Result<CachedDataItem, _> =\n-                            serde_path_to_error::deserialize(\n-                                &mut pot_de_symbol_list().deserializer_for_slice(&buf).unwrap(),\n-                            );\n-                        if let Err(err) = deserialize {\n-                            println!(\n-                                \"Data item would not be deserializable {task}: {err:?}\\n{item:?}\"\n-                            );\n-                            return false;\n-                        }\n-                    }\n-                    true\n-                }\n-            });\n-            error?;\n+fn encode_task_data(task: TaskId, data: &Vec<CachedDataItem>) -> Result<TurboBincodeBuffer> {\n+    let orig_result = turbo_bincode_encode(data);\n+    if !cfg!(feature = \"verify_serialization\")\n+        && let Ok(value) = orig_result\n+    {\n+        return Ok(value);\n+    }\n \n-            pot_serialize_small_vec(&data)\n-                .with_context(|| anyhow!(\"Unable to serialize data items for {task}: {data:#?}\"))?\n+    let mut error = Ok(());\n+    let mut filtered_data = data.clone();\n+    filtered_data.retain(|item| match turbo_bincode_encode(&item) {\n+        Ok(buf) => {\n+            if cfg!(feature = \"verify_serialization\") {\n+                let deserialized = turbo_bincode_decode::<CachedDataItem>(&buf);\n+                if let Err(err) = deserialized {\n+                    println!(\"Data item would not be deserializable {task}: {err:?}\\n{item:?}\");\n+                    return false;\n+                }\n+            }\n+            true\n         }\n-    })\n-}\n+        Err(err) => {\n+            if item.is_optional() {\n+                if cfg!(feature = \"verify_serialization\") {\n+                    println!(\n+                        \"Skipping non-encodable optional item for {task}: {item:?} due to {err}\"\n+                    );\n+                }\n+            } else {\n+                error =\n+                    Err(err).context(format!(\"Unable to encode data item for {task}: {item:?}\"));\n+            }\n+            false\n+        }\n+    });\n+    error?;\n \n-fn deserialize_with_good_error<'de, T: Deserialize<'de>>(data: &'de [u8]) -> Result<T> {\n-    match POT_CONFIG.deserialize(data) {\n-        Ok(value) => Ok(value),\n-        Err(error) => serde_path_to_error::deserialize::<'_, _, T>(\n-            &mut pot_de_symbol_list().deserializer_for_slice(data)?,\n-        )\n-        .map_err(anyhow::Error::from)\n-        .and(Err(error.into()))\n-        .context(\"Deserialization failed\"),\n-    }\n+    (if filtered_data.len() == data.len() {\n+        orig_result\n+    } else {\n+        turbo_bincode_encode(&filtered_data)\n+    })\n+    .with_context(|| format!(\"Unable to serialize data items for {task}: {filtered_data:#?}\"))\n }"
        },
        {
            "sha": "97aed767f2ac77ce3ba7f62fad65950ea0518859",
            "filename": "turbopack/crates/turbo-tasks-macros/src/derive/key_value_pair_macro.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fderive%2Fkey_value_pair_macro.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fderive%2Fkey_value_pair_macro.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fderive%2Fkey_value_pair_macro.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -591,9 +591,9 @@ fn field_declarations(fields: &[Vec<&syn::Field>]) -> Vec<proc_macro2::TokenStre\n                 .map(|field| {\n                     let ty = &field.ty;\n                     let ident = field.ident.as_ref().unwrap();\n-                    let attrs = &field.attrs;\n+                    // we don't preserve attrs here because we don't copy over the derives, so the\n+                    // attributes are likely irrelevant to the generated type\n                     quote! {\n-                        #(#attrs)*\n                         #ident: #ty\n                     }\n                 })\n@@ -614,9 +614,8 @@ fn ref_field_declarations(fields: &[Vec<&syn::Field>]) -> Vec<proc_macro2::Token\n                 .map(|field| {\n                     let ty = &field.ty;\n                     let ident = field.ident.as_ref().unwrap();\n-                    let attrs = &field.attrs;\n+                    // don't preserve attrs because we don't copy over the derives either\n                     quote! {\n-                        #(#attrs)*\n                         #ident: &'l #ty\n                     }\n                 })\n@@ -637,9 +636,8 @@ fn mut_ref_field_declarations(fields: &[Vec<&syn::Field>]) -> Vec<proc_macro2::T\n                 .map(|field| {\n                     let ty = &field.ty;\n                     let ident = field.ident.as_ref().unwrap();\n-                    let attrs = &field.attrs;\n+                    // don't preserve attrs because we don't copy over the derives either\n                     quote! {\n-                        #(#attrs)*\n                         #ident: &'l mut #ty\n                     }\n                 })"
        },
        {
            "sha": "83b91e5b306542afda91b465e1fb1c5cc4d9bd64",
            "filename": "turbopack/crates/turbo-tasks-macros/src/primitive_input.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_input.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_input.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_input.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -53,8 +53,6 @@ impl Parse for PrimitiveInput {\n     }\n }\n \n-// TODO: wire this up in https://github.com/vercel/next.js/pull/86338\n-#[allow(dead_code)]\n pub struct BincodeWrappers {\n     pub encode_ty: Type,\n     pub decode_ty: Type,"
        },
        {
            "sha": "c6bbcde3ae3933c1ded24837a32441c264b66e34",
            "filename": "turbopack/crates/turbo-tasks-macros/src/primitive_macro.rs",
            "status": "modified",
            "additions": 16,
            "deletions": 5,
            "changes": 21,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_macro.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_macro.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fprimitive_macro.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -3,14 +3,16 @@ use quote::quote;\n use syn::parse_macro_input;\n \n use crate::{\n-    global_name::global_name, ident::get_type_ident, primitive_input::PrimitiveInput,\n+    global_name::global_name,\n+    ident::get_type_ident,\n+    primitive_input::{BincodeWrappers, PrimitiveInput},\n     value_macro::value_type_and_register,\n };\n \n pub fn primitive(input: TokenStream) -> TokenStream {\n     let PrimitiveInput {\n         ty,\n-        bincode_wrappers: _,\n+        bincode_wrappers,\n     } = parse_macro_input!(input as PrimitiveInput);\n \n     let Some(ident) = get_type_ident(&ty) else {\n@@ -38,9 +40,18 @@ pub fn primitive(input: TokenStream) -> TokenStream {\n     };\n \n     let name = global_name(quote!(stringify!(#ty)));\n-    // TODO: https://github.com/vercel/next.js/pull/86338 -- switch to bincode, use bincode wrapper\n-    let new_value_type = quote! {\n-        turbo_tasks::ValueType::new_with_any_serialization::<#ty>(#name);\n+    let new_value_type = if let Some(bincode_wrappers) = bincode_wrappers {\n+        let BincodeWrappers {\n+            encode_ty,\n+            decode_ty,\n+        } = bincode_wrappers;\n+        quote! {\n+            turbo_tasks::ValueType::new_with_bincode_wrappers::<#ty, #encode_ty, #decode_ty>(#name)\n+        }\n+    } else {\n+        quote! {\n+            turbo_tasks::ValueType::new_with_bincode::<#ty>(#name)\n+        }\n     };\n \n     let value_type_and_register = value_type_and_register("
        },
        {
            "sha": "82c725a500f21e803dcde3411d0597837684ab6f",
            "filename": "turbopack/crates/turbo-tasks-macros/src/value_macro.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fvalue_macro.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fvalue_macro.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros%2Fsrc%2Fvalue_macro.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -348,7 +348,7 @@ pub fn value(args: TokenStream, input: TokenStream) -> TokenStream {\n         },\n         SerializationMode::Auto | SerializationMode::Custom => {\n             quote! {\n-                turbo_tasks::ValueType::new_with_any_serialization::<#ident>(#name)\n+                turbo_tasks::ValueType::new_with_bincode::<#ident>(#name)\n             }\n         }\n     };"
        },
        {
            "sha": "74f5641bd7abee37b661990dc01dd0d921fcace0",
            "filename": "turbopack/crates/turbo-tasks/Cargo.toml",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -33,6 +33,7 @@ erased-serde = { workspace = true }\n event-listener = \"5.4.0\"\n futures = { workspace = true }\n indexmap = { workspace = true, features = [\"serde\"] }\n+inventory = { workspace = true }\n once_cell = { workspace = true }\n parking_lot = { workspace = true, features = [\"serde\"]}\n pin-project-lite = { workspace = true }\n@@ -41,7 +42,7 @@ regex = { workspace = true }\n rustc-hash = { workspace = true }\n serde = { workspace = true, features = [\"rc\", \"derive\"] }\n serde_json = { workspace = true }\n-shrink-to-fit = { workspace=true,features = [\"indexmap\", \"serde_json\", \"smallvec\", \"nightly\"] }\n+shrink-to-fit = { workspace = true, features = [\"indexmap\", \"serde_json\", \"smallvec\", \"nightly\"] }\n smallvec = { workspace = true }\n thiserror = { workspace = true }\n tokio = { workspace = true, features = [\"full\"] }\n@@ -55,7 +56,8 @@ turbo-tasks-hash = { workspace = true }\n turbo-tasks-macros = { workspace = true }\n turbo-tasks-malloc = { workspace = true }\n unsize = { workspace = true }\n-inventory = { workspace = true }\n+unty = { workspace = true }\n+pot = \"3.0.0\"\n \n [dev-dependencies]\n criterion = { workspace = true, features = [\"async_tokio\"] }"
        },
        {
            "sha": "0b800d2a9b8c080fbc6a50ced60f0d5365bebbd8",
            "filename": "turbopack/crates/turbo-tasks/src/backend.rs",
            "status": "modified",
            "additions": 106,
            "deletions": 149,
            "changes": 255,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -10,9 +10,13 @@ use std::{\n \n use anyhow::{Result, anyhow};\n use auto_hash_map::AutoMap;\n+use bincode::{\n+    Decode, Encode,\n+    error::{DecodeError, EncodeError},\n+};\n use rustc_hash::FxHasher;\n-use serde::{Deserialize, Serialize};\n use tracing::Span;\n+use turbo_bincode::{TurboBincodeDecoder, TurboBincodeEncoder};\n use turbo_rcstr::RcStr;\n \n use crate::{\n@@ -99,110 +103,31 @@ impl Display for CachedTaskType {\n }\n \n mod ser {\n-    use std::any::Any;\n-\n-    use serde::{\n-        Deserialize, Deserializer, Serialize, Serializer,\n-        de::{self},\n-        ser::{SerializeSeq, SerializeTuple},\n+    use bincode::{\n+        de::{Decoder, read::Reader},\n+        enc::Encoder,\n     };\n+    use serde::{Deserialize, Deserializer, Serialize, Serializer, ser::SerializeSeq};\n \n     use super::*;\n \n-    impl Serialize for TypedCellContent {\n-        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>\n-        where\n-            S: Serializer,\n-        {\n-            let value_type = registry::get_value_type(self.0);\n-            let serializable = if let Some(value) = &self.1.0 {\n-                value_type.any_as_serializable(&value.0)\n-            } else {\n-                None\n-            };\n-            let mut state = serializer.serialize_tuple(3)?;\n-            state.serialize_element(&self.0)?;\n-            if let Some(serializable) = serializable {\n-                state.serialize_element(&true)?;\n-                state.serialize_element(serializable)?;\n-            } else {\n-                state.serialize_element(&false)?;\n-                state.serialize_element(&())?;\n-            }\n-            state.end()\n-        }\n-    }\n-\n-    impl<'de> Deserialize<'de> for TypedCellContent {\n-        fn deserialize<D>(deserializer: D) -> std::result::Result<Self, D::Error>\n-        where\n-            D: Deserializer<'de>,\n-        {\n-            struct Visitor;\n+    const POT_CONFIG: pot::Config = pot::Config::new().compatibility(pot::Compatibility::V4);\n \n-            impl<'de> serde::de::Visitor<'de> for Visitor {\n-                type Value = TypedCellContent;\n-\n-                fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n-                    write!(formatter, \"a valid TypedCellContent\")\n-                }\n-\n-                fn visit_seq<A>(self, mut seq: A) -> std::result::Result<Self::Value, A::Error>\n-                where\n-                    A: de::SeqAccess<'de>,\n-                {\n-                    let value_type: ValueTypeId = seq\n-                        .next_element()?\n-                        .ok_or_else(|| de::Error::invalid_length(0, &self))?;\n-                    let has_value: bool = seq\n-                        .next_element()?\n-                        .ok_or_else(|| de::Error::invalid_length(1, &self))?;\n-                    if has_value {\n-                        let seed = registry::get_value_type(value_type)\n-                            .get_any_deserialize_seed()\n-                            .ok_or_else(|| {\n-                                de::Error::custom(\"Value type doesn't support deserialization\")\n-                            })?;\n-                        let value = seq\n-                            .next_element_seed(seed)?\n-                            .ok_or_else(|| de::Error::invalid_length(2, &self))?;\n-                        let arc = triomphe::Arc::<dyn Any + Send + Sync>::from(value);\n-                        Ok(TypedCellContent(\n-                            value_type,\n-                            CellContent(Some(SharedReference(arc))),\n-                        ))\n-                    } else {\n-                        let () = seq\n-                            .next_element()?\n-                            .ok_or_else(|| de::Error::invalid_length(2, &self))?;\n-                        Ok(TypedCellContent(value_type, CellContent(None)))\n-                    }\n-                }\n-            }\n-\n-            deserializer.deserialize_tuple(2, Visitor)\n-        }\n+    struct FunctionAndArgBorrowed<'a> {\n+        native_fn: &'static NativeFunction,\n+        arg: &'a dyn MagicAny,\n     }\n-\n-    enum FunctionAndArg<'a> {\n-        Owned {\n-            native_fn: &'static NativeFunction,\n-            arg: Box<dyn MagicAny>,\n-        },\n-        Borrowed {\n-            native_fn: &'static NativeFunction,\n-            arg: &'a dyn MagicAny,\n-        },\n+    struct FunctionAndArgOwned {\n+        native_fn: &'static NativeFunction,\n+        arg: Box<dyn MagicAny>,\n     }\n \n-    impl Serialize for FunctionAndArg<'_> {\n-        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>\n+    impl Serialize for FunctionAndArgBorrowed<'_> {\n+        fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n         where\n             S: Serializer,\n         {\n-            let FunctionAndArg::Borrowed { native_fn, arg } = self else {\n-                unreachable!();\n-            };\n+            let Self { native_fn, arg } = self;\n             let mut state = serializer.serialize_seq(Some(2))?;\n             state.serialize_element(&registry::get_function_id(native_fn))?;\n             let arg = *arg;\n@@ -212,17 +137,17 @@ mod ser {\n         }\n     }\n \n-    impl<'de> Deserialize<'de> for FunctionAndArg<'de> {\n+    impl<'de> Deserialize<'de> for FunctionAndArgOwned {\n         fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n             struct Visitor;\n             impl<'de> serde::de::Visitor<'de> for Visitor {\n-                type Value = FunctionAndArg<'de>;\n+                type Value = FunctionAndArgOwned;\n \n                 fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n-                    write!(formatter, \"a valid FunctionAndArg\")\n+                    write!(formatter, \"a valid FunctionAndArgOwned\")\n                 }\n \n-                fn visit_seq<A>(self, mut seq: A) -> std::result::Result<Self::Value, A::Error>\n+                fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>\n                 where\n                     A: serde::de::SeqAccess<'de>,\n                 {\n@@ -234,64 +159,65 @@ mod ser {\n                     let arg = seq\n                         .next_element_seed(seed)?\n                         .ok_or_else(|| serde::de::Error::invalid_length(1, &self))?;\n-                    Ok(FunctionAndArg::Owned { native_fn, arg })\n+                    Ok(FunctionAndArgOwned { native_fn, arg })\n                 }\n             }\n             deserializer.deserialize_seq(Visitor)\n         }\n     }\n \n-    impl Serialize for CachedTaskType {\n-        fn serialize<S>(&self, serializer: S) -> std::result::Result<S::Ok, S::Error>\n-        where\n-            S: ser::Serializer,\n-        {\n-            let CachedTaskType {\n-                native_fn,\n-                this,\n-                arg,\n-            } = self;\n-            let mut s = serializer.serialize_tuple(2)?;\n-            s.serialize_element(&FunctionAndArg::Borrowed {\n-                native_fn,\n-                arg: &**arg,\n-            })?;\n-            s.serialize_element(this)?;\n-            s.end()\n+    // HACK: We don't yet require `TaskInput: Encode + Decode`, so use a pot serializer for the\n+    // function arguments, and bincode for everything else.\n+    impl Encode for CachedTaskType {\n+        fn encode<E: Encoder>(&self, encoder: &mut E) -> Result<(), EncodeError> {\n+            struct BincodeWriterWrapper<W: bincode::enc::write::Writer>(W);\n+            impl<W: bincode::enc::write::Writer> std::io::Write for BincodeWriterWrapper<W> {\n+                fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {\n+                    self.write_all(buf)?;\n+                    Ok(buf.len())\n+                }\n+                fn write_all(&mut self, buf: &[u8]) -> std::io::Result<()> {\n+                    self.0.write(buf).map_err(std::io::Error::other)\n+                }\n+                fn flush(&mut self) -> std::io::Result<()> {\n+                    Ok(())\n+                }\n+            }\n+            let function_and_arg = FunctionAndArgBorrowed {\n+                native_fn: self.native_fn,\n+                arg: &*self.arg,\n+            };\n+            POT_CONFIG\n+                .serialize_into(\n+                    &function_and_arg,\n+                    &mut BincodeWriterWrapper(encoder.writer()),\n+                )\n+                .map_err(|e| EncodeError::OtherString(e.to_string()))?;\n+            Encode::encode(&self.this, encoder)\n         }\n     }\n \n-    impl<'de> Deserialize<'de> for CachedTaskType {\n-        fn deserialize<D: ser::Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n-            struct Visitor;\n-            impl<'de> serde::de::Visitor<'de> for Visitor {\n-                type Value = CachedTaskType;\n-\n-                fn expecting(&self, formatter: &mut fmt::Formatter) -> fmt::Result {\n-                    write!(formatter, \"a valid PersistentTaskType\")\n+    impl<Context> Decode<Context> for CachedTaskType {\n+        fn decode<D: Decoder<Context = Context>>(decoder: &mut D) -> Result<Self, DecodeError> {\n+            struct BincodeReaderWrapper<R: Reader>(R);\n+            impl<R: Reader> std::io::Read for BincodeReaderWrapper<R> {\n+                fn read(&mut self, buf: &mut [u8]) -> std::io::Result<usize> {\n+                    self.read_exact(buf)?;\n+                    Ok(buf.len())\n                 }\n-\n-                fn visit_seq<A>(self, mut seq: A) -> std::result::Result<Self::Value, A::Error>\n-                where\n-                    A: serde::de::SeqAccess<'de>,\n-                {\n-                    let FunctionAndArg::Owned { native_fn, arg } = seq\n-                        .next_element()?\n-                        .ok_or_else(|| serde::de::Error::invalid_length(0, &self))?\n-                    else {\n-                        unreachable!();\n-                    };\n-                    let this = seq\n-                        .next_element()?\n-                        .ok_or_else(|| serde::de::Error::invalid_length(1, &self))?;\n-                    Ok(CachedTaskType {\n-                        native_fn,\n-                        this,\n-                        arg,\n-                    })\n+                fn read_exact(&mut self, buf: &mut [u8]) -> std::io::Result<()> {\n+                    self.0.read(buf).map_err(std::io::Error::other)\n                 }\n             }\n-            deserializer.deserialize_tuple(2, Visitor)\n+            let FunctionAndArgOwned { native_fn, arg } = POT_CONFIG\n+                .deserialize_from(BincodeReaderWrapper(decoder.reader()))\n+                .map_err(|e| DecodeError::OtherString(e.to_string()))?;\n+            let this: Option<RawVc> = Decode::decode(decoder)?;\n+            Ok(CachedTaskType {\n+                native_fn,\n+                this,\n+                arg,\n+            })\n         }\n     }\n }\n@@ -349,6 +275,37 @@ impl TypedCellContent {\n     pub fn into_untyped(self) -> CellContent {\n         self.1\n     }\n+\n+    pub fn encode(&self, enc: &mut TurboBincodeEncoder) -> Result<(), EncodeError> {\n+        let Self(type_id, content) = self;\n+        let value_type = registry::get_value_type(*type_id);\n+        type_id.encode(enc)?;\n+        if let Some(bincode) = value_type.bincode {\n+            if let Some(reference) = &content.0 {\n+                true.encode(enc)?;\n+                bincode.0(&*reference.0, enc)?;\n+                Ok(())\n+            } else {\n+                false.encode(enc)?;\n+                Ok(())\n+            }\n+        } else {\n+            Ok(())\n+        }\n+    }\n+\n+    pub fn decode(dec: &mut TurboBincodeDecoder) -> Result<Self, DecodeError> {\n+        let type_id = ValueTypeId::decode(dec)?;\n+        let value_type = registry::get_value_type(type_id);\n+        if let Some(bincode) = value_type.bincode {\n+            let is_some = bool::decode(dec)?;\n+            if is_some {\n+                let reference = bincode.1(dec)?;\n+                return Ok(TypedCellContent(type_id, CellContent(Some(reference))));\n+            }\n+        }\n+        Ok(TypedCellContent(type_id, CellContent(None)))\n+    }\n }\n \n impl From<TypedSharedReference> for TypedCellContent {\n@@ -403,9 +360,9 @@ pub type TaskCollectiblesMap = AutoMap<RawVc, i32, BuildHasherDefault<FxHasher>,\n \n // Structurally and functionally similar to Cow<&'static, str> but explicitly notes the importance\n // of non-static strings potentially containing PII (Personal Identifiable Information).\n-#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Clone, Debug, Encode, Decode, PartialEq, Eq)]\n pub enum TurboTasksExecutionErrorMessage {\n-    PIISafe(Cow<'static, str>),\n+    PIISafe(#[bincode(with = \"turbo_bincode::owned_cow\")] Cow<'static, str>),\n     NonPIISafe(String),\n }\n \n@@ -418,21 +375,21 @@ impl Display for TurboTasksExecutionErrorMessage {\n     }\n }\n \n-#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Debug, Clone, Encode, Decode, PartialEq, Eq)]\n pub struct TurboTasksError {\n     pub message: TurboTasksExecutionErrorMessage,\n     pub source: Option<TurboTasksExecutionError>,\n }\n \n-#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Debug, Clone, Encode, Decode, PartialEq, Eq)]\n pub struct TurboTaskContextError {\n     pub task: RcStr,\n     #[cfg(feature = \"task_id_details\")]\n     pub task_id: Option<TaskId>,\n     pub source: Option<TurboTasksExecutionError>,\n }\n \n-#[derive(Clone, Debug, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Clone, Debug, Encode, Decode, PartialEq, Eq)]\n pub enum TurboTasksExecutionError {\n     Panic(Arc<TurboTasksPanic>),\n     Error(Arc<TurboTasksError>),"
        },
        {
            "sha": "2396caa4710be64c6e5160d18536029c6c65a93f",
            "filename": "turbopack/crates/turbo-tasks/src/capture_future.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -8,8 +8,8 @@ use std::{\n };\n \n use anyhow::Result;\n+use bincode::{Decode, Encode};\n use pin_project_lite::pin_project;\n-use serde::{Deserialize, Serialize};\n \n use crate::{backend::TurboTasksExecutionErrorMessage, panic_hooks::LAST_ERROR_LOCATION};\n \n@@ -26,7 +26,7 @@ impl<T, F: Future<Output = T>> CaptureFuture<T, F> {\n     }\n }\n \n-#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\n+#[derive(Debug, Clone, Encode, Decode, PartialEq, Eq)]\n pub struct TurboTasksPanic {\n     pub message: TurboTasksExecutionErrorMessage,\n     pub location: Option<String>,"
        },
        {
            "sha": "777f43ddc440eafeb9cd193480dccef9f068999c",
            "filename": "turbopack/crates/turbo-tasks/src/id.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -73,6 +73,7 @@ macro_rules! define_id {\n             type Target = $primitive;\n \n             fn deref(&self) -> &Self::Target {\n+                // SAFETY: `NonZero<T>` is guaranteed to have the same layout as `T`\n                 unsafe { transmute_copy(&&self.id) }\n             }\n         }"
        },
        {
            "sha": "316fd1201d201cb232b3afdf1580c5ad69979634",
            "filename": "turbopack/crates/turbo-tasks/src/magic_any.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 38,
            "changes": 38,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmagic_any.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmagic_any.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmagic_any.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -108,41 +108,3 @@ impl<'de> DeserializeSeed<'de> for MagicAnyDeserializeSeed {\n         (self.functor)(&mut deserializer).map_err(serde::de::Error::custom)\n     }\n }\n-\n-type AnyDeserializeSeedFunctor = fn(\n-    &mut dyn erased_serde::Deserializer<'_>,\n-) -> Result<Box<dyn Any + Sync + Send>, erased_serde::Error>;\n-\n-#[derive(Clone, Copy)]\n-pub struct AnyDeserializeSeed {\n-    functor: AnyDeserializeSeedFunctor,\n-}\n-\n-impl AnyDeserializeSeed {\n-    pub fn new<T>() -> Self\n-    where\n-        T: for<'de> Deserialize<'de> + Any + Send + Sync + 'static,\n-    {\n-        fn deserialize<T: Any + for<'de> Deserialize<'de> + Send + Sync + 'static>(\n-            deserializer: &mut dyn erased_serde::Deserializer<'_>,\n-        ) -> Result<Box<dyn Any + Sync + Send>, erased_serde::Error> {\n-            let value: T = erased_serde::deserialize(deserializer)?;\n-            Ok(Box::new(value))\n-        }\n-        Self {\n-            functor: deserialize::<T>,\n-        }\n-    }\n-}\n-\n-impl<'de> DeserializeSeed<'de> for AnyDeserializeSeed {\n-    type Value = Box<dyn Any + Sync + Send>;\n-\n-    fn deserialize<D>(self, deserializer: D) -> Result<Self::Value, D::Error>\n-    where\n-        D: serde::Deserializer<'de>,\n-    {\n-        let mut deserializer = <dyn erased_serde::Deserializer>::erase(deserializer);\n-        (self.functor)(&mut deserializer).map_err(serde::de::Error::custom)\n-    }\n-}"
        },
        {
            "sha": "9557d20efaacf10c4c0228bf54dfcaccc51756ea",
            "filename": "turbopack/crates/turbo-tasks/src/primitives.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fprimitives.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fprimitives.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fprimitives.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -44,8 +44,6 @@ __turbo_tasks_internal_primitive!(Duration);\n __turbo_tasks_internal_primitive!(Vec<u8>);\n __turbo_tasks_internal_primitive!(Vec<bool>);\n \n-// TODO: use this in https://github.com/vercel/next.js/pull/86338\n-#[allow(dead_code)]\n struct JsonValueEncodeWrapper<'a>(&'a serde_json::Value);\n \n impl ManualEncodeWrapper for JsonValueEncodeWrapper<'_> {\n@@ -62,8 +60,6 @@ impl Encode for JsonValueEncodeWrapper<'_> {\n     }\n }\n \n-// TODO: use this in https://github.com/vercel/next.js/pull/86338\n-#[allow(dead_code)]\n struct JsonValueDecodeWrapper(serde_json::Value);\n \n impl ManualDecodeWrapper for JsonValueDecodeWrapper {"
        },
        {
            "sha": "2b8553eb135f3d788785fe4f8ad07cd4b7770c17",
            "filename": "turbopack/crates/turbo-tasks/src/raw_vc.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fraw_vc.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fraw_vc.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fraw_vc.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -211,7 +211,7 @@ impl RawVc {\n                         task,\n                         index,\n                         ReadCellOptions {\n-                            is_serializable_cell_content: value_type.is_serializable(),\n+                            is_serializable_cell_content: value_type.bincode.is_some(),\n                             final_read_hint: false,\n                             tracking: ReadTracking::default(),\n                         },\n@@ -467,7 +467,7 @@ impl Future for ReadRawVcFuture {\n                         if this.is_serializable_cell_content_unknown {\n                             let value_type = registry::get_value_type(index.type_id);\n                             this.read_cell_options.is_serializable_cell_content =\n-                                value_type.is_serializable();\n+                                value_type.bincode.is_some();\n                         }\n                         let read_result =\n                             tt.try_read_task_cell(task, index, this.read_cell_options);"
        },
        {
            "sha": "76575845246a5e57fb4afd39cbd2df11eff3b244",
            "filename": "turbopack/crates/turbo-tasks/src/task/shared_reference.rs",
            "status": "modified",
            "additions": 104,
            "deletions": 77,
            "changes": 181,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask%2Fshared_reference.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask%2Fshared_reference.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask%2Fshared_reference.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -6,11 +6,20 @@ use std::{\n };\n \n use anyhow::Result;\n-use serde::{Deserialize, Serialize, ser::SerializeTuple};\n+use bincode::{\n+    Decode, Encode,\n+    de::Decoder,\n+    enc::Encoder,\n+    error::{DecodeError, EncodeError},\n+    impl_borrow_decode,\n+};\n+use turbo_bincode::{\n+    TurboBincodeDecoder, TurboBincodeEncoder, turbo_bincode_decode, turbo_bincode_encode,\n+};\n use unsize::CoerceUnsize;\n \n use crate::{\n-    ValueTypeId, registry,\n+    ValueType, ValueTypeId, registry,\n     triomphe_utils::{coerce_to_any_send_sync, downcast_triomphe_arc},\n };\n \n@@ -55,8 +64,101 @@ impl TypedSharedReference {\n     pub fn into_untyped(self) -> SharedReference {\n         self.reference\n     }\n+\n+    fn encode(&self, enc: &mut TurboBincodeEncoder) -> Result<(), EncodeError> {\n+        let Self { type_id, reference } = self;\n+        let value_type = registry::get_value_type(*type_id);\n+        if let Some(bincode) = value_type.bincode {\n+            type_id.encode(enc)?;\n+            bincode.0(&*reference.0, enc)?;\n+            Ok(())\n+        } else {\n+            Err(EncodeError::OtherString(format!(\n+                \"{:?} is not serializable\",\n+                value_type.global_name\n+            )))\n+        }\n+    }\n+\n+    fn decode(dec: &mut TurboBincodeDecoder) -> Result<Self, DecodeError> {\n+        let type_id = ValueTypeId::decode(dec)?;\n+        let value_type = registry::get_value_type(type_id);\n+        if let Some(bincode) = value_type.bincode {\n+            let reference = bincode.1(dec)?;\n+            Ok(Self { type_id, reference })\n+        } else {\n+            #[cold]\n+            fn not_deserializable(value_type: &ValueType) -> DecodeError {\n+                DecodeError::OtherString(format!(\"{value_type} is not deserializable\"))\n+            }\n+            Err(not_deserializable(value_type))\n+        }\n+    }\n }\n \n+impl Encode for TypedSharedReference {\n+    fn encode<'a, E: Encoder>(&self, encoder: &'a mut E) -> Result<(), EncodeError> {\n+        let maybe_turbo_encoder = if unty::type_equal::<E, TurboBincodeEncoder>() {\n+            // SAFETY: Transmute is safe because `&mut E` is `&mut TurboBincodeEncoder`:\n+            // - `unty::type_equal::<E, TurboBincodeEncoder>()` does not check lifetimes, but does\n+            //   check the type and layout, so we know those are correct.\n+            // - The transmuted encoder cannot escape this function, and we know that the lifetime\n+            //   of `'f` is at least as long as the function.\n+            // - Lifetimes don't change layout. This is not guaranteed, but if this assumption is\n+            //   broken, we'd have a different type id, `type_equal` would return `false` and we'd\n+            //   fall back to a slower codepath, and wouldn't violate memory safety.\n+            // - Two mutable references have the same layout and alignment when they reference\n+            //   exactly the same type.\n+            // - The explicit lifetime ('a) avoids creating an implitly unbounded lifetime.\n+            Ok(unsafe { std::mem::transmute::<&'a mut E, &'a mut TurboBincodeEncoder>(encoder) })\n+        } else {\n+            Err(encoder)\n+        };\n+        match maybe_turbo_encoder {\n+            Ok(turbo_encoder) => TypedSharedReference::encode(self, turbo_encoder),\n+            Err(generic_encoder) => {\n+                // The underlying `SharedReference` can only be serialized using\n+                // `TurboBincodeEncoder` because the encoder function pointer cannot take type\n+                // parameters. This is okay, because we expect any hot codepaths to use\n+                // `TurboBincodeEncoder`.\n+                //\n+                // Create a `TurboBincodeEncoder` and encode this as a nested byte array. We must\n+                // redundantly store a size here, otherwise we won't be able to determine what size\n+                // buffer to use for `TurboBincodeReader`.\n+                let buffer = turbo_bincode_encode(self)?;\n+                buffer.encode(generic_encoder)\n+            }\n+        }\n+    }\n+}\n+\n+impl<Context> Decode<Context> for TypedSharedReference {\n+    fn decode<'a, D: Decoder<Context = Context>>(decoder: &mut D) -> Result<Self, DecodeError> {\n+        let maybe_turbo_decoder = if unty::type_equal::<D, TurboBincodeDecoder>() {\n+            // SAFETY: See notes on the `Encode::encode` implementation above.\n+            Ok(unsafe { std::mem::transmute::<&mut D, &mut TurboBincodeDecoder<'a>>(decoder) })\n+        } else {\n+            Err(decoder)\n+        };\n+        match maybe_turbo_decoder {\n+            Ok(turbo_decoder) => TypedSharedReference::decode(turbo_decoder),\n+            Err(generic_decoder) => {\n+                // The underlying `SharedReference` can only be deserialized using\n+                // `TurboBincodeDecoder` because the decoder function pointer cannot take type\n+                // parameters. This is okay, because we expect any hot codepaths to use\n+                // `TurboBincodeDecoder`.\n+                //\n+                // Decode the nested byte array that was created during encoding, then use a\n+                // `TurboBincodeDecoder` to decode the contents.\n+                let buffer: Vec<u8> = Decode::decode(generic_decoder)?;\n+                turbo_bincode_decode(&buffer)\n+            }\n+        }\n+    }\n+}\n+\n+impl_borrow_decode!(TypedSharedReference);\n+\n impl Deref for TypedSharedReference {\n     type Target = SharedReference;\n \n@@ -98,30 +200,6 @@ impl Debug for SharedReference {\n     }\n }\n \n-impl Serialize for TypedSharedReference {\n-    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>\n-    where\n-        S: serde::Serializer,\n-    {\n-        let TypedSharedReference {\n-            type_id: ty,\n-            reference: SharedReference(arc),\n-        } = self;\n-        let value_type = registry::get_value_type(*ty);\n-        if let Some(serializable) = value_type.any_as_serializable(arc) {\n-            let mut t = serializer.serialize_tuple(2)?;\n-            t.serialize_element(ty)?;\n-            t.serialize_element(serializable)?;\n-            t.end()\n-        } else {\n-            Err(serde::ser::Error::custom(format!(\n-                \"{:?} is not serializable\",\n-                registry::get_value_type(*ty).global_name\n-            )))\n-        }\n-    }\n-}\n-\n impl Display for SharedReference {\n     fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n         write!(f, \"untyped value\")\n@@ -137,54 +215,3 @@ impl Display for TypedSharedReference {\n         )\n     }\n }\n-\n-impl<'de> Deserialize<'de> for TypedSharedReference {\n-    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n-    where\n-        D: serde::Deserializer<'de>,\n-    {\n-        struct Visitor;\n-\n-        impl<'de> serde::de::Visitor<'de> for Visitor {\n-            type Value = TypedSharedReference;\n-\n-            fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {\n-                formatter.write_str(\"a serializable shared reference\")\n-            }\n-\n-            fn visit_seq<A>(self, mut seq: A) -> Result<Self::Value, A::Error>\n-            where\n-                A: serde::de::SeqAccess<'de>,\n-            {\n-                if let Some(type_id) = seq.next_element()? {\n-                    let value_type = registry::get_value_type(type_id);\n-                    if let Some(seed) = value_type.get_any_deserialize_seed() {\n-                        if let Some(value) = seq.next_element_seed(seed)? {\n-                            let arc = triomphe::Arc::<dyn Any + Send + Sync>::from(value);\n-                            Ok(TypedSharedReference {\n-                                type_id,\n-                                reference: SharedReference(arc),\n-                            })\n-                        } else {\n-                            Err(serde::de::Error::invalid_length(\n-                                1,\n-                                &\"tuple with type and value\",\n-                            ))\n-                        }\n-                    } else {\n-                        Err(serde::de::Error::custom(format!(\n-                            \"{value_type} is not deserializable\"\n-                        )))\n-                    }\n-                } else {\n-                    Err(serde::de::Error::invalid_length(\n-                        0,\n-                        &\"tuple with type and value\",\n-                    ))\n-                }\n-            }\n-        }\n-\n-        deserializer.deserialize_tuple(2, Visitor)\n-    }\n-}"
        },
        {
            "sha": "1d921c05841839d9c1f401a25bd32d3f6a6b27dc",
            "filename": "turbopack/crates/turbo-tasks/src/trait_ref.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftrait_ref.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftrait_ref.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftrait_ref.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -1,7 +1,6 @@\n use std::{fmt::Debug, future::Future, marker::PhantomData};\n \n use anyhow::Result;\n-use serde::{Deserialize, Serialize};\n \n use crate::{\n     Vc, VcValueTrait,\n@@ -57,21 +56,6 @@ impl<T> std::hash::Hash for TraitRef<T> {\n     }\n }\n \n-impl<T> Serialize for TraitRef<T> {\n-    fn serialize<S: serde::Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n-        self.shared_reference.serialize(serializer)\n-    }\n-}\n-\n-impl<'de, T> Deserialize<'de> for TraitRef<T> {\n-    fn deserialize<D: serde::Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n-        Ok(Self {\n-            shared_reference: TypedSharedReference::deserialize(deserializer)?,\n-            _t: PhantomData,\n-        })\n-    }\n-}\n-\n impl<U> std::ops::Deref for TraitRef<Box<U>>\n where\n     Box<U>: VcValueTrait<ValueTrait = U>,"
        },
        {
            "sha": "38e560bd74721926808108d7647f06aa2ad6b128",
            "filename": "turbopack/crates/turbo-tasks/src/value_type.rs",
            "status": "modified",
            "additions": 73,
            "deletions": 52,
            "changes": 125,
            "blob_url": "https://github.com/vercel/next.js/blob/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fvalue_type.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b35713c4b5aa922fef5442d002d43c72b7d13838/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fvalue_type.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fvalue_type.rs?ref=b35713c4b5aa922fef5442d002d43c72b7d13838",
            "patch": "@@ -5,19 +5,23 @@ use std::{\n };\n \n use auto_hash_map::{AutoMap, AutoSet};\n-use bincode::{Decode, Encode};\n-use serde::{Deserialize, Serialize};\n+use bincode::{\n+    Decode, Encode,\n+    error::{DecodeError, EncodeError},\n+};\n use tracing::Span;\n+use turbo_bincode::{TurboBincodeDecoder, TurboBincodeEncoder};\n \n use crate::{\n-    RawVc, VcValueType, id::TraitTypeId, macro_helpers::NativeFunction,\n-    magic_any::AnyDeserializeSeed, registry, task::shared_reference::TypedSharedReference,\n-    vc::VcCellMode,\n+    RawVc, SharedReference, VcValueType, id::TraitTypeId, macro_helpers::NativeFunction, registry,\n+    task::shared_reference::TypedSharedReference, vc::VcCellMode,\n };\n \n-type AnySerializationFn = fn(&(dyn Any + Sync + Send)) -> &dyn erased_serde::Serialize;\n type RawCellFactoryFn = fn(TypedSharedReference) -> RawVc;\n \n+type AnyEncodeFn = fn(&dyn Any, &mut TurboBincodeEncoder<'_>) -> Result<(), EncodeError>;\n+type AnyDecodeFn = fn(&mut TurboBincodeDecoder<'_>) -> Result<SharedReference, DecodeError>;\n+\n // TODO this type need some refactoring when multiple languages are added to\n // turbo-task In this case a trait_method might be of a different function type.\n // It probably need to be a Vc<Function>.\n@@ -37,14 +41,14 @@ pub struct ValueType {\n     /// List of trait methods available\n     trait_methods: AutoMap<&'static TraitMethod, &'static NativeFunction>,\n \n-    /// Functors for serialization\n-    any_serialization: Option<(AnySerializationFn, AnyDeserializeSeed)>,\n+    /// Functions to convert to write the type to a buffer or read it from a buffer.\n+    pub bincode: Option<(AnyEncodeFn, AnyDecodeFn)>,\n \n     /// An implementation of\n-    /// [`VcCellMode::raw_cell`][crate::vc::cell_mode::VcCellMode::raw_cell].\n+    /// [`VcCellMode::raw_cell`][crate::vc::VcCellMode::raw_cell].\n     ///\n     /// Allows dynamically constructing a cell using the type id. Used inside of\n-    /// [`RawVc`] where we have a type id, but not the concrete type `T` of\n+    /// [`TraitRef`][crate::TraitRef] where we have a type id, but not the concrete type `T` of\n     /// `Vc<T>`.\n     ///\n     /// Because we allow resolving `Vc<dyn Trait>`, it's otherwise not possible\n@@ -87,81 +91,98 @@ impl Display for ValueType {\n     }\n }\n \n-pub fn any_as_serialize<T: Any + Serialize + Send + Sync + 'static>(\n-    this: &(dyn Any + Send + Sync),\n-) -> &dyn erased_serde::Serialize {\n-    if let Some(r) = this.downcast_ref::<T>() {\n-        return r;\n+pub fn any_as_encode<T: Any>(this: &dyn Any) -> &T {\n+    if let Some(enc) = this.downcast_ref::<T>() {\n+        return enc;\n     }\n-    panic!(\n-        \"any_as_serialize::<{}> called with invalid type\",\n+    unreachable!(\n+        \"any_as_encode::<{}> called with invalid type\",\n         type_name::<T>()\n     );\n }\n \n-// TODO: use this in https://github.com/vercel/next.js/pull/86338\n-#[allow(dead_code)]\n pub trait ManualEncodeWrapper: Encode {\n     type Value;\n+\n     // this uses RPIT to avoid some lifetime problems\n     fn new<'a>(value: &'a Self::Value) -> impl Encode + 'a;\n }\n \n-// TODO: use this in https://github.com/vercel/next.js/pull/86338\n-#[allow(dead_code)]\n pub trait ManualDecodeWrapper: Decode<()> {\n     type Value;\n+\n     fn inner(self) -> Self::Value;\n }\n \n impl ValueType {\n-    /// This is internally used by `#[turbo_tasks::value]`\n+    /// This is internally used by [`#[turbo_tasks::value]`][crate::value].\n     pub fn new<T: VcValueType>(global_name: &'static str) -> Self {\n-        Self {\n-            name: std::any::type_name::<T>(),\n+        Self::new_inner::<T>(global_name, None)\n+    }\n+\n+    /// This is internally used by [`#[turbo_tasks::value]`][crate::value].\n+    pub fn new_with_bincode<T: VcValueType + Encode + Decode<()>>(\n+        global_name: &'static str,\n+    ) -> Self {\n+        Self::new_inner::<T>(\n             global_name,\n-            traits: AutoSet::new(),\n-            trait_methods: AutoMap::new(),\n-            any_serialization: None,\n-            raw_cell: <T::CellMode as VcCellMode<T>>::raw_cell,\n-        }\n+            Some((\n+                |this, enc| {\n+                    T::encode(any_as_encode::<T>(this), enc)?;\n+                    Ok(())\n+                },\n+                |dec| {\n+                    let val = T::decode(dec)?;\n+                    Ok(SharedReference::new(triomphe::Arc::new(val)))\n+                },\n+            )),\n+        )\n     }\n \n-    /// This is internally used by `#[turbo_tasks::value]`\n-    pub fn new_with_any_serialization<\n-        T: VcValueType + Any + Serialize + for<'de> Deserialize<'de>,\n+    /// This is used internally by [`turbo_tasks_macros::primitive`] to encode/decode foreign types\n+    /// that cannot implement the [`bincode`] traits due to the [orphan rules].\n+    ///\n+    /// This is done by constructing wrapper types that implement the bincode traits on behalf of\n+    /// the wrapped type.\n+    ///\n+    /// [orphan rules]: https://doc.rust-lang.org/reference/items/implementations.html#orphan-rules\n+    pub fn new_with_bincode_wrappers<\n+        T: VcValueType,\n+        E: ManualEncodeWrapper<Value = T>,\n+        D: ManualDecodeWrapper<Value = T>,\n     >(\n         global_name: &'static str,\n+    ) -> Self {\n+        Self::new_inner::<T>(\n+            global_name,\n+            Some((\n+                |this, enc| {\n+                    E::new(any_as_encode::<T>(this)).encode(enc)?;\n+                    Ok(())\n+                },\n+                |dec| {\n+                    let val = D::inner(D::decode(dec)?);\n+                    Ok(SharedReference::new(triomphe::Arc::new(val)))\n+                },\n+            )),\n+        )\n+    }\n+\n+    // Helper for other constructor functions\n+    fn new_inner<T: VcValueType>(\n+        global_name: &'static str,\n+        bincode: Option<(AnyEncodeFn, AnyDecodeFn)>,\n     ) -> Self {\n         Self {\n             name: std::any::type_name::<T>(),\n             global_name,\n             traits: AutoSet::new(),\n             trait_methods: AutoMap::new(),\n-            any_serialization: Some((any_as_serialize::<T>, AnyDeserializeSeed::new::<T>())),\n+            bincode,\n             raw_cell: <T::CellMode as VcCellMode<T>>::raw_cell,\n         }\n     }\n \n-    pub fn any_as_serializable<'a>(\n-        &self,\n-        arc: &'a triomphe::Arc<dyn Any + Sync + Send>,\n-    ) -> Option<&'a dyn erased_serde::Serialize> {\n-        if let Some(s) = self.any_serialization {\n-            Some((s.0)(&**arc))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    pub fn is_serializable(&self) -> bool {\n-        self.any_serialization.is_some()\n-    }\n-\n-    pub fn get_any_deserialize_seed(&self) -> Option<AnyDeserializeSeed> {\n-        self.any_serialization.map(|s| s.1)\n-    }\n-\n     pub(crate) fn register_trait_method(\n         &mut self,\n         trait_method: &'static TraitMethod,"
        }
    ],
    "stats": {
        "total": 1219,
        "additions": 598,
        "deletions": 621
    }
}