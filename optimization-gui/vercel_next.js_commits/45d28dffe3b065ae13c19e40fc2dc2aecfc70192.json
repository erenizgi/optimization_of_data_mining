{
    "author": "sokra",
    "message": "Turbopack Persistent Caching: Use SmallVec to avoid allocations for small values written to DB (#78136)\n\n### What?\r\n\r\nUse SmallVec to avoid allocations for small values written to DB",
    "sha": "45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
    "files": [
        {
            "sha": "feb80afde4e894045836f6386029d01dbe8610dc",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -9204,6 +9204,7 @@ dependencies = [\n  \"rayon\",\n  \"rustc-hash 2.1.0\",\n  \"serde\",\n+ \"smallvec\",\n  \"tempfile\",\n  \"thread_local\",\n  \"twox-hash 2.1.0\","
        },
        {
            "sha": "2efd376c8e14f28cfd45e983c0f463f6eea39c45",
            "filename": "turbopack/crates/turbo-persistence/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -22,6 +22,7 @@ quick_cache = { version = \"0.6.9\" }\n rayon = { workspace = true }\n rustc-hash = { workspace = true }\n serde = { workspace = true }\n+smallvec = { workspace = true}\n thread_local = { workspace = true }\n twox-hash = { version = \"2.0.1\", features = [\"xxhash64\"] }\n zstd = { version = \"0.13.2\", features = [\"zdict_builder\"] }"
        },
        {
            "sha": "82e82b9cf920137be68d5274c9ae09c68e34701e",
            "filename": "turbopack/crates/turbo-persistence/src/collector.rs",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -4,6 +4,7 @@ use crate::{\n         DATA_THRESHOLD_PER_INITIAL_FILE, MAX_ENTRIES_PER_INITIAL_FILE, MAX_SMALL_VALUE_SIZE,\n     },\n     key::{hash_key, StoreKey},\n+    ValueBuffer,\n };\n \n /// A collector accumulates entries that should be eventually written to a file. It keeps track of\n@@ -36,15 +37,19 @@ impl<K: StoreKey> Collector<K> {\n     }\n \n     /// Adds a normal key-value pair to the collector.\n-    pub fn put(&mut self, key: K, value: Vec<u8>) {\n+    pub fn put(&mut self, key: K, value: ValueBuffer) {\n         let key = EntryKey {\n             hash: hash_key(&key),\n             data: key,\n         };\n         let value = if value.len() > MAX_SMALL_VALUE_SIZE {\n-            CollectorEntryValue::Medium { value }\n+            CollectorEntryValue::Medium {\n+                value: value.into_vec(),\n+            }\n         } else {\n-            CollectorEntryValue::Small { value }\n+            CollectorEntryValue::Small {\n+                value: value.into_small_vec(),\n+            }\n         };\n         self.total_key_size += key.len();\n         self.total_value_size += value.len();"
        },
        {
            "sha": "88f49821d3c38835ded87a76c20d483b754d5651",
            "filename": "turbopack/crates/turbo-persistence/src/collector_entry.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector_entry.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector_entry.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcollector_entry.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,5 +1,7 @@\n use std::cmp::Ordering;\n \n+use smallvec::SmallVec;\n+\n use crate::{\n     key::StoreKey,\n     static_sorted_file_builder::{Entry, EntryValue},\n@@ -11,7 +13,7 @@ pub struct CollectorEntry<K: StoreKey> {\n }\n \n pub enum CollectorEntryValue {\n-    Small { value: Vec<u8> },\n+    Small { value: SmallVec<[u8; 16]> },\n     Medium { value: Vec<u8> },\n     Large { blob: u32 },\n     Deleted,"
        },
        {
            "sha": "f10a6ff8ac5c27df40ec2fea380aa1467d426e34",
            "filename": "turbopack/crates/turbo-persistence/src/key.rs",
            "status": "modified",
            "additions": 29,
            "deletions": 1,
            "changes": 30,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fkey.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fkey.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fkey.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -4,6 +4,9 @@ use std::{cmp::min, hash::Hasher};\n pub trait KeyBase {\n     /// Returns the length of the key in bytes.\n     fn len(&self) -> usize;\n+    fn is_empty(&self) -> bool {\n+        self.len() == 0\n+    }\n     /// Hashes the key. It should not include the structure of the key, only the data. E.g. `([1,\n     /// 2], [3, 4])` should hash the same as `[1, 2, 3, 4]`.\n     fn hash<H: Hasher>(&self, state: &mut H);\n@@ -14,6 +17,10 @@ impl KeyBase for &'_ [u8] {\n         <[u8]>::len(self)\n     }\n \n+    fn is_empty(&self) -> bool {\n+        <[u8]>::is_empty(self)\n+    }\n+\n     fn hash<H: Hasher>(&self, state: &mut H) {\n         for item in *self {\n             state.write_u8(*item);\n@@ -23,7 +30,11 @@ impl KeyBase for &'_ [u8] {\n \n impl<const N: usize> KeyBase for [u8; N] {\n     fn len(&self) -> usize {\n-        self[..].len()\n+        N\n+    }\n+\n+    fn is_empty(&self) -> bool {\n+        N > 0\n     }\n \n     fn hash<H: Hasher>(&self, state: &mut H) {\n@@ -38,6 +49,10 @@ impl KeyBase for Vec<u8> {\n         self.len()\n     }\n \n+    fn is_empty(&self) -> bool {\n+        self.is_empty()\n+    }\n+\n     fn hash<H: Hasher>(&self, state: &mut H) {\n         for item in self {\n             state.write_u8(*item);\n@@ -50,6 +65,10 @@ impl KeyBase for u8 {\n         1\n     }\n \n+    fn is_empty(&self) -> bool {\n+        false\n+    }\n+\n     fn hash<H: Hasher>(&self, state: &mut H) {\n         state.write_u8(*self);\n     }\n@@ -61,6 +80,11 @@ impl<A: KeyBase, B: KeyBase> KeyBase for (A, B) {\n         a.len() + b.len()\n     }\n \n+    fn is_empty(&self) -> bool {\n+        let (a, b) = self;\n+        a.is_empty() && b.is_empty()\n+    }\n+\n     fn hash<H: Hasher>(&self, state: &mut H) {\n         let (a, b) = self;\n         KeyBase::hash(a, state);\n@@ -73,6 +97,10 @@ impl<T: KeyBase> KeyBase for &'_ T {\n         (*self).len()\n     }\n \n+    fn is_empty(&self) -> bool {\n+        (*self).is_empty()\n+    }\n+\n     fn hash<H: Hasher>(&self, state: &mut H) {\n         (*self).hash(state)\n     }"
        },
        {
            "sha": "fd4473e6102f8e07939ad67fffa7ea195a4795d2",
            "filename": "turbopack/crates/turbo-persistence/src/lib.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -17,8 +17,10 @@ mod write_batch;\n \n #[cfg(test)]\n mod tests;\n+mod value_buf;\n \n pub use arc_slice::ArcSlice;\n pub use db::TurboPersistence;\n-pub use key::{QueryKey, StoreKey};\n+pub use key::{KeyBase, QueryKey, StoreKey};\n+pub use value_buf::ValueBuffer;\n pub use write_batch::WriteBatch;"
        },
        {
            "sha": "8e961a60c596d7639ab12e24ac864ecad4a66631",
            "filename": "turbopack/crates/turbo-persistence/src/value_buf.rs",
            "status": "added",
            "additions": 66,
            "deletions": 0,
            "changes": 66,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fvalue_buf.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fvalue_buf.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fvalue_buf.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -0,0 +1,66 @@\n+use std::{borrow::Cow, ops::Deref};\n+\n+use smallvec::SmallVec;\n+\n+pub enum ValueBuffer<'l> {\n+    Borrowed(&'l [u8]),\n+    Vec(Vec<u8>),\n+    SmallVec(SmallVec<[u8; 16]>),\n+}\n+\n+impl ValueBuffer<'_> {\n+    pub fn into_vec(self) -> Vec<u8> {\n+        match self {\n+            ValueBuffer::Borrowed(b) => b.to_vec(),\n+            ValueBuffer::Vec(v) => v,\n+            ValueBuffer::SmallVec(sv) => sv.into_vec(),\n+        }\n+    }\n+\n+    pub fn into_small_vec(self) -> SmallVec<[u8; 16]> {\n+        match self {\n+            ValueBuffer::Borrowed(b) => SmallVec::from_slice(b),\n+            ValueBuffer::Vec(v) => SmallVec::from_vec(v),\n+            ValueBuffer::SmallVec(sv) => sv,\n+        }\n+    }\n+}\n+\n+impl<'l> From<&'l [u8]> for ValueBuffer<'l> {\n+    fn from(b: &'l [u8]) -> Self {\n+        ValueBuffer::Borrowed(b)\n+    }\n+}\n+\n+impl From<Vec<u8>> for ValueBuffer<'_> {\n+    fn from(v: Vec<u8>) -> Self {\n+        ValueBuffer::Vec(v)\n+    }\n+}\n+\n+impl From<SmallVec<[u8; 16]>> for ValueBuffer<'_> {\n+    fn from(sv: SmallVec<[u8; 16]>) -> Self {\n+        ValueBuffer::SmallVec(sv)\n+    }\n+}\n+\n+impl<'l> From<Cow<'l, [u8]>> for ValueBuffer<'l> {\n+    fn from(c: Cow<'l, [u8]>) -> Self {\n+        match c {\n+            Cow::Borrowed(b) => ValueBuffer::Borrowed(b),\n+            Cow::Owned(o) => ValueBuffer::Vec(o),\n+        }\n+    }\n+}\n+\n+impl Deref for ValueBuffer<'_> {\n+    type Target = [u8];\n+\n+    fn deref(&self) -> &Self::Target {\n+        match self {\n+            ValueBuffer::Borrowed(b) => b,\n+            ValueBuffer::Vec(v) => v,\n+            ValueBuffer::SmallVec(sv) => sv,\n+        }\n+    }\n+}"
        },
        {
            "sha": "6eb97c3742b7e4e353c26898a2a8aee41ec05762",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 4,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,5 +1,4 @@\n use std::{\n-    borrow::Cow,\n     cell::UnsafeCell,\n     fs::File,\n     io::Write,\n@@ -20,7 +19,7 @@ use thread_local::ThreadLocal;\n \n use crate::{\n     collector::Collector, collector_entry::CollectorEntry, constants::MAX_MEDIUM_VALUE_SIZE,\n-    key::StoreKey, static_sorted_file_builder::StaticSortedFileBuilder,\n+    key::StoreKey, static_sorted_file_builder::StaticSortedFileBuilder, ValueBuffer,\n };\n \n /// The thread local state of a `WriteBatch`.\n@@ -107,11 +106,11 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n     }\n \n     /// Puts a key-value pair into the write batch.\n-    pub fn put(&self, family: usize, key: K, value: Cow<'_, [u8]>) -> Result<()> {\n+    pub fn put(&self, family: usize, key: K, value: ValueBuffer<'_>) -> Result<()> {\n         let state = self.thread_local_state();\n         let collector = self.collector_mut(state, family)?;\n         if value.len() <= MAX_MEDIUM_VALUE_SIZE {\n-            collector.put(key, value.into_owned());\n+            collector.put(key, value);\n         } else {\n             let (blob, file) = self.create_blob(&value)?;\n             collector.put_blob(key, blob);"
        },
        {
            "sha": "3013091f1a480db0c877feb379dab0f868023091",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/fresh_db_optimization.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 6,
            "changes": 18,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Ffresh_db_optimization.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Ffresh_db_optimization.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Ffresh_db_optimization.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,5 +1,4 @@\n use std::{\n-    borrow::Cow,\n     fs,\n     path::Path,\n     sync::atomic::{AtomicBool, Ordering},\n@@ -9,7 +8,9 @@ use anyhow::Result;\n \n use crate::database::{\n     key_value_database::{KeySpace, KeyValueDatabase},\n-    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch},\n+    write_batch::{\n+        BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch, WriteBuffer,\n+    },\n };\n \n pub fn is_fresh(path: &Path) -> bool {\n@@ -124,23 +125,28 @@ impl<'a, B: BaseWriteBatch<'a>> BaseWriteBatch<'a> for FreshDbOptimizationWriteB\n }\n \n impl<'a, B: SerialWriteBatch<'a>> SerialWriteBatch<'a> for FreshDbOptimizationWriteBatch<'a, B> {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         self.write_batch.put(key_space, key, value)\n     }\n \n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         self.write_batch.delete(key_space, key)\n     }\n }\n \n impl<'a, B: ConcurrentWriteBatch<'a>> ConcurrentWriteBatch<'a>\n     for FreshDbOptimizationWriteBatch<'a, B>\n {\n-    fn put(&self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(&self, key_space: KeySpace, key: WriteBuffer<'_>, value: WriteBuffer<'_>) -> Result<()> {\n         self.write_batch.put(key_space, key, value)\n     }\n \n-    fn delete(&self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         self.write_batch.delete(key_space, key)\n     }\n }"
        },
        {
            "sha": "2a986ce121985a67b6732f7093eff373091cdf5f",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/lmdb/mod.rs",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Flmdb%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Flmdb%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Flmdb%2Fmod.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,4 +1,4 @@\n-use std::{borrow::Cow, fs::create_dir_all, path::Path, thread::available_parallelism};\n+use std::{fs::create_dir_all, path::Path, thread::available_parallelism};\n \n use anyhow::{Context, Result};\n use lmdb::{\n@@ -8,7 +8,7 @@ use lmdb::{\n \n use crate::database::{\n     key_value_database::{KeySpace, KeyValueDatabase},\n-    write_batch::{BaseWriteBatch, SerialWriteBatch, WriteBatch},\n+    write_batch::{BaseWriteBatch, SerialWriteBatch, WriteBatch, WriteBuffer},\n };\n \n mod extended_key;\n@@ -164,7 +164,12 @@ impl<'a> BaseWriteBatch<'a> for LmbdWriteBatch<'a> {\n }\n \n impl<'a> SerialWriteBatch<'a> for LmbdWriteBatch<'a> {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         extended_key::put(\n             &mut self.tx,\n             self.this.db(key_space),\n@@ -175,7 +180,7 @@ impl<'a> SerialWriteBatch<'a> for LmbdWriteBatch<'a> {\n         Ok(())\n     }\n \n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         extended_key::delete(\n             &mut self.tx,\n             self.this.db(key_space),"
        },
        {
            "sha": "050140198e59cda94a4a6aba61bfaf91c1207338",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/noop_kv.rs",
            "status": "modified",
            "additions": 17,
            "deletions": 7,
            "changes": 24,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fnoop_kv.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fnoop_kv.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fnoop_kv.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,10 +1,10 @@\n-use std::borrow::Cow;\n-\n use anyhow::Result;\n \n use crate::database::{\n     key_value_database::{KeySpace, KeyValueDatabase},\n-    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch},\n+    write_batch::{\n+        BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch, WriteBuffer,\n+    },\n };\n \n pub struct NoopKvDb;\n@@ -78,21 +78,31 @@ impl<'a> BaseWriteBatch<'a> for NoopWriteBatch {\n }\n \n impl SerialWriteBatch<'_> for NoopWriteBatch {\n-    fn put(&mut self, _key_space: KeySpace, _key: Cow<[u8]>, _value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        _key_space: KeySpace,\n+        _key: WriteBuffer<'_>,\n+        _value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         Ok(())\n     }\n \n-    fn delete(&mut self, _key_space: KeySpace, _key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, _key_space: KeySpace, _key: WriteBuffer<'_>) -> Result<()> {\n         Ok(())\n     }\n }\n \n impl ConcurrentWriteBatch<'_> for NoopWriteBatch {\n-    fn put(&self, _key_space: KeySpace, _key: Cow<[u8]>, _value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &self,\n+        _key_space: KeySpace,\n+        _key: WriteBuffer<'_>,\n+        _value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         Ok(())\n     }\n \n-    fn delete(&self, _key_space: KeySpace, _key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&self, _key_space: KeySpace, _key: WriteBuffer<'_>) -> Result<()> {\n         Ok(())\n     }\n }"
        },
        {
            "sha": "2296b7ca265e59fd09ad42a372b1650a7f79c600",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/read_transaction_cache.rs",
            "status": "modified",
            "additions": 9,
            "deletions": 7,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fread_transaction_cache.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fread_transaction_cache.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fread_transaction_cache.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -7,7 +7,9 @@ use thread_local::ThreadLocal;\n \n use crate::database::{\n     key_value_database::KeyValueDatabase,\n-    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch},\n+    write_batch::{\n+        BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch, WriteBuffer,\n+    },\n };\n \n struct ThreadLocalReadTransactionsContainer<T: KeyValueDatabase + 'static>(\n@@ -184,15 +186,15 @@ impl<'a, T: KeyValueDatabase, B: SerialWriteBatch<'a>> SerialWriteBatch<'a>\n     fn put(\n         &mut self,\n         key_space: super::key_value_database::KeySpace,\n-        key: std::borrow::Cow<[u8]>,\n-        value: std::borrow::Cow<[u8]>,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n     ) -> Result<()> {\n         self.write_batch.put(key_space, key, value)\n     }\n     fn delete(\n         &mut self,\n         key_space: super::key_value_database::KeySpace,\n-        key: std::borrow::Cow<[u8]>,\n+        key: WriteBuffer<'_>,\n     ) -> Result<()> {\n         self.write_batch.delete(key_space, key)\n     }\n@@ -204,15 +206,15 @@ impl<'a, T: KeyValueDatabase, B: ConcurrentWriteBatch<'a>> ConcurrentWriteBatch<\n     fn put(\n         &self,\n         key_space: super::key_value_database::KeySpace,\n-        key: std::borrow::Cow<[u8]>,\n-        value: std::borrow::Cow<[u8]>,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n     ) -> Result<()> {\n         self.write_batch.put(key_space, key, value)\n     }\n     fn delete(\n         &self,\n         key_space: super::key_value_database::KeySpace,\n-        key: std::borrow::Cow<[u8]>,\n+        key: WriteBuffer<'_>,\n     ) -> Result<()> {\n         self.write_batch.delete(key_space, key)\n     }"
        },
        {
            "sha": "583733760490c9e42041222b6ba8b8b39788ed7c",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/startup_cache.rs",
            "status": "modified",
            "additions": 13,
            "deletions": 6,
            "changes": 19,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fstartup_cache.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fstartup_cache.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fstartup_cache.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,5 +1,5 @@\n use std::{\n-    borrow::{Borrow, Cow},\n+    borrow::Borrow,\n     fs::{self, File},\n     hash::BuildHasherDefault,\n     io::{BufWriter, Read, Write},\n@@ -16,7 +16,9 @@ use turbo_tasks::FxDashMap;\n use crate::database::{\n     by_key_space::ByKeySpace,\n     key_value_database::{KeySpace, KeyValueDatabase},\n-    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch},\n+    write_batch::{\n+        BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch, WriteBuffer,\n+    },\n };\n \n const CACHE_SIZE_LIMIT: usize = 100 * 1024 * 1024;\n@@ -268,15 +270,20 @@ impl<'a, B: BaseWriteBatch<'a>> BaseWriteBatch<'a> for StartupCacheWriteBatch<'a\n }\n \n impl<'a, B: SerialWriteBatch<'a>> SerialWriteBatch<'a> for StartupCacheWriteBatch<'a, B> {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         if !self.fresh_db {\n             let cache = self.cache.get(key_space);\n             cache.insert(key.to_vec(), Some(value.to_vec()));\n         }\n         self.batch.put(key_space, key, value)\n     }\n \n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         if !self.fresh_db {\n             let cache = self.cache.get(key_space);\n             cache.insert(key.to_vec(), None);\n@@ -286,15 +293,15 @@ impl<'a, B: SerialWriteBatch<'a>> SerialWriteBatch<'a> for StartupCacheWriteBatc\n }\n \n impl<'a, B: ConcurrentWriteBatch<'a>> ConcurrentWriteBatch<'a> for StartupCacheWriteBatch<'a, B> {\n-    fn put(&self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(&self, key_space: KeySpace, key: WriteBuffer<'_>, value: WriteBuffer<'_>) -> Result<()> {\n         if !self.fresh_db {\n             let cache = self.cache.get(key_space);\n             cache.insert(key.to_vec(), Some(value.to_vec()));\n         }\n         self.batch.put(key_space, key, value)\n     }\n \n-    fn delete(&self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         if !self.fresh_db {\n             let cache = self.cache.get(key_space);\n             cache.insert(key.to_vec(), None);"
        },
        {
            "sha": "9a4e418bd81ef2df5fd0c5ffd00e270b6fbff289",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/turbo.rs",
            "status": "modified",
            "additions": 56,
            "deletions": 8,
            "changes": 64,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,17 +1,16 @@\n use std::{\n-    borrow::Cow,\n     path::PathBuf,\n     sync::Arc,\n     thread::{spawn, JoinHandle},\n };\n \n use anyhow::Result;\n use parking_lot::Mutex;\n-use turbo_persistence::{ArcSlice, TurboPersistence};\n+use turbo_persistence::{ArcSlice, KeyBase, StoreKey, TurboPersistence, ValueBuffer};\n \n use crate::database::{\n     key_value_database::{KeySpace, KeyValueDatabase},\n-    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, WriteBatch},\n+    write_batch::{BaseWriteBatch, ConcurrentWriteBatch, WriteBatch, WriteBuffer},\n };\n \n const COMPACT_MAX_COVERAGE: f32 = 20.0;\n@@ -104,7 +103,7 @@ impl KeyValueDatabase for TurboKeyValueDatabase {\n }\n \n pub struct TurboWriteBatch<'a> {\n-    batch: turbo_persistence::WriteBatch<Vec<u8>, 5>,\n+    batch: turbo_persistence::WriteBatch<WriteBuffer<'static>, 5>,\n     db: &'a Arc<TurboPersistence>,\n     compact_join_handle: &'a Mutex<Option<JoinHandle<Result<()>>>>,\n }\n@@ -137,11 +136,60 @@ impl<'a> BaseWriteBatch<'a> for TurboWriteBatch<'a> {\n }\n \n impl<'a> ConcurrentWriteBatch<'a> for TurboWriteBatch<'a> {\n-    fn put(&self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n-        self.batch.put(key_space as usize, key.into_owned(), value)\n+    fn put(&self, key_space: KeySpace, key: WriteBuffer<'_>, value: WriteBuffer<'_>) -> Result<()> {\n+        self.batch\n+            .put(key_space as usize, key.into_static(), value.into())\n     }\n \n-    fn delete(&self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n-        self.batch.delete(key_space as usize, key.into_owned())\n+    fn delete(&self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n+        self.batch.delete(key_space as usize, key.into_static())\n+    }\n+}\n+\n+impl KeyBase for WriteBuffer<'_> {\n+    fn len(&self) -> usize {\n+        (**self).len()\n+    }\n+\n+    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n+        for item in &**self {\n+            state.write_u8(*item);\n+        }\n+    }\n+}\n+\n+impl StoreKey for WriteBuffer<'_> {\n+    fn write_to(&self, buf: &mut Vec<u8>) {\n+        buf.extend_from_slice(self);\n+    }\n+}\n+\n+impl PartialEq for WriteBuffer<'_> {\n+    fn eq(&self, other: &Self) -> bool {\n+        **self == **other\n+    }\n+}\n+\n+impl Eq for WriteBuffer<'_> {}\n+\n+impl Ord for WriteBuffer<'_> {\n+    fn cmp(&self, other: &Self) -> std::cmp::Ordering {\n+        (**self).cmp(&**other)\n+    }\n+}\n+\n+impl PartialOrd for WriteBuffer<'_> {\n+    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {\n+        Some(self.cmp(other))\n+    }\n+}\n+\n+impl<'l> From<WriteBuffer<'l>> for ValueBuffer<'l> {\n+    fn from(val: WriteBuffer<'l>) -> Self {\n+        match val {\n+            WriteBuffer::Borrowed(b) => ValueBuffer::Borrowed(b),\n+            WriteBuffer::Vec(v) => ValueBuffer::Vec(v),\n+            WriteBuffer::SmallVec(sv) => ValueBuffer::SmallVec(sv),\n+        }\n     }\n }"
        },
        {
            "sha": "6754a4ebb69a3521259aeb9532bab97132d7a5a4",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/write_batch.rs",
            "status": "modified",
            "additions": 76,
            "deletions": 12,
            "changes": 88,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fwrite_batch.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,9 +1,11 @@\n use std::{\n     borrow::{Borrow, Cow},\n     marker::PhantomData,\n+    ops::Deref,\n };\n \n use anyhow::Result;\n+use smallvec::SmallVec;\n \n use crate::database::key_value_database::KeySpace;\n \n@@ -19,14 +21,56 @@ pub trait BaseWriteBatch<'a> {\n     fn commit(self) -> Result<()>;\n }\n \n+pub enum WriteBuffer<'a> {\n+    Borrowed(&'a [u8]),\n+    Vec(Vec<u8>),\n+    SmallVec(smallvec::SmallVec<[u8; 16]>),\n+}\n+\n+impl WriteBuffer<'_> {\n+    pub fn into_static(self) -> WriteBuffer<'static> {\n+        match self {\n+            WriteBuffer::Borrowed(b) => WriteBuffer::SmallVec(SmallVec::from_slice(b)),\n+            WriteBuffer::Vec(v) => WriteBuffer::Vec(v),\n+            WriteBuffer::SmallVec(sv) => WriteBuffer::Vec(sv.into_vec()),\n+        }\n+    }\n+}\n+\n+impl Deref for WriteBuffer<'_> {\n+    type Target = [u8];\n+\n+    fn deref(&self) -> &Self::Target {\n+        match self {\n+            WriteBuffer::Borrowed(b) => b,\n+            WriteBuffer::Vec(v) => v,\n+            WriteBuffer::SmallVec(sv) => sv,\n+        }\n+    }\n+}\n+\n+impl<'l> From<Cow<'l, [u8]>> for WriteBuffer<'l> {\n+    fn from(c: Cow<'l, [u8]>) -> Self {\n+        match c {\n+            Cow::Borrowed(b) => WriteBuffer::Borrowed(b),\n+            Cow::Owned(o) => WriteBuffer::Vec(o),\n+        }\n+    }\n+}\n+\n pub trait SerialWriteBatch<'a>: BaseWriteBatch<'a> {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()>;\n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()>;\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()>;\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()>;\n }\n \n pub trait ConcurrentWriteBatch<'a>: BaseWriteBatch<'a> + Sync + Send {\n-    fn put(&self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()>;\n-    fn delete(&self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()>;\n+    fn put(&self, key_space: KeySpace, key: WriteBuffer<'_>, value: WriteBuffer<'_>) -> Result<()>;\n+    fn delete(&self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()>;\n }\n \n pub enum WriteBatch<'a, S, C>\n@@ -102,14 +146,19 @@ where\n     S: SerialWriteBatch<'a>,\n     C: ConcurrentWriteBatch<'a>,\n {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         match self {\n             WriteBatch::Serial(s) => s.put(key_space, key, value),\n             WriteBatch::Concurrent(c, _) => c.put(key_space, key, value),\n         }\n     }\n \n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         match self {\n             WriteBatch::Serial(s) => s.delete(key_space, key),\n             WriteBatch::Concurrent(c, _) => c.delete(key_space, key),\n@@ -174,14 +223,19 @@ where\n     S: SerialWriteBatch<'a>,\n     C: ConcurrentWriteBatch<'a>,\n {\n-    fn put(&mut self, key_space: KeySpace, key: Cow<[u8]>, value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        key_space: KeySpace,\n+        key: WriteBuffer<'_>,\n+        value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         match self {\n             WriteBatchRef::Serial(s) => s.put(key_space, key, value),\n             WriteBatchRef::Concurrent(c, _) => c.put(key_space, key, value),\n         }\n     }\n \n-    fn delete(&mut self, key_space: KeySpace, key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, key_space: KeySpace, key: WriteBuffer<'_>) -> Result<()> {\n         match self {\n             WriteBatchRef::Serial(s) => s.delete(key_space, key),\n             WriteBatchRef::Concurrent(c, _) => c.delete(key_space, key),\n@@ -210,19 +264,29 @@ impl<'a> BaseWriteBatch<'a> for UnimplementedWriteBatch {\n }\n \n impl SerialWriteBatch<'_> for UnimplementedWriteBatch {\n-    fn put(&mut self, _key_space: KeySpace, _key: Cow<[u8]>, _value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &mut self,\n+        _key_space: KeySpace,\n+        _key: WriteBuffer<'_>,\n+        _value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         todo!()\n     }\n-    fn delete(&mut self, _key_space: KeySpace, _key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&mut self, _key_space: KeySpace, _key: WriteBuffer<'_>) -> Result<()> {\n         todo!()\n     }\n }\n \n impl ConcurrentWriteBatch<'_> for UnimplementedWriteBatch {\n-    fn put(&self, _key_space: KeySpace, _key: Cow<[u8]>, _value: Cow<[u8]>) -> Result<()> {\n+    fn put(\n+        &self,\n+        _key_space: KeySpace,\n+        _key: WriteBuffer<'_>,\n+        _value: WriteBuffer<'_>,\n+    ) -> Result<()> {\n         todo!()\n     }\n-    fn delete(&self, _key_space: KeySpace, _key: Cow<[u8]>) -> Result<()> {\n+    fn delete(&self, _key_space: KeySpace, _key: WriteBuffer<'_>) -> Result<()> {\n         todo!()\n     }\n }"
        },
        {
            "sha": "3d0465220e075ae89292681b1daadc4a2e417156",
            "filename": "turbopack/crates/turbo-tasks-backend/src/kv_backing_storage.rs",
            "status": "modified",
            "additions": 55,
            "deletions": 35,
            "changes": 90,
            "blob_url": "https://github.com/vercel/next.js/blob/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/45d28dffe3b065ae13c19e40fc2dc2aecfc70192/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs?ref=45d28dffe3b065ae13c19e40fc2dc2aecfc70192",
            "patch": "@@ -1,14 +1,10 @@\n-use std::{\n-    borrow::{Borrow, Cow},\n-    cmp::max,\n-    collections::hash_map::Entry,\n-    sync::Arc,\n-};\n+use std::{borrow::Borrow, cmp::max, collections::hash_map::Entry, sync::Arc};\n \n use anyhow::{anyhow, Context, Result};\n use rayon::iter::{IndexedParallelIterator, IntoParallelIterator, ParallelIterator};\n use rustc_hash::FxHashMap;\n use serde::{ser::SerializeSeq, Serialize};\n+use smallvec::SmallVec;\n use tracing::Span;\n use turbo_tasks::{backend::CachedTaskType, turbo_tasks_scope, KeyValuePair, SessionId, TaskId};\n \n@@ -20,13 +16,40 @@ use crate::{\n         key_value_database::{KeySpace, KeyValueDatabase},\n         write_batch::{\n             BaseWriteBatch, ConcurrentWriteBatch, SerialWriteBatch, WriteBatch, WriteBatchRef,\n+            WriteBuffer,\n         },\n     },\n     utils::chunked_vec::ChunkedVec,\n };\n \n const POT_CONFIG: pot::Config = pot::Config::new().compatibility(pot::Compatibility::V4);\n \n+fn pot_serialize_small_vec<T: Serialize>(value: &T) -> pot::Result<SmallVec<[u8; 16]>> {\n+    struct SmallVecWrite<'l>(&'l mut SmallVec<[u8; 16]>);\n+    impl std::io::Write for SmallVecWrite<'_> {\n+        #[inline]\n+        fn write(&mut self, buf: &[u8]) -> std::io::Result<usize> {\n+            self.0.extend_from_slice(buf);\n+            Ok(buf.len())\n+        }\n+\n+        #[inline]\n+        fn write_all(&mut self, buf: &[u8]) -> std::io::Result<()> {\n+            self.0.extend_from_slice(buf);\n+            Ok(())\n+        }\n+\n+        #[inline]\n+        fn flush(&mut self) -> std::io::Result<()> {\n+            Ok(())\n+        }\n+    }\n+\n+    let mut output = SmallVec::new();\n+    POT_CONFIG.serialize_into(value, SmallVecWrite(&mut output))?;\n+    Ok(output)\n+}\n+\n fn pot_ser_symbol_map() -> pot::ser::SymbolMap {\n     pot::ser::SymbolMap::new().with_compatibility(pot::Compatibility::V4)\n }\n@@ -191,8 +214,8 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorage\n                                     batch\n                                         .put(\n                                             KeySpace::ForwardTaskCache,\n-                                            Cow::Borrowed(&task_type_bytes),\n-                                            Cow::Borrowed(&task_id.to_le_bytes()),\n+                                            WriteBuffer::Borrowed(&task_type_bytes),\n+                                            WriteBuffer::Borrowed(&task_id.to_le_bytes()),\n                                         )\n                                         .with_context(|| {\n                                             anyhow!(\n@@ -203,8 +226,8 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorage\n                                     batch\n                                         .put(\n                                             KeySpace::ReverseTaskCache,\n-                                            Cow::Borrowed(IntKey::new(task_id).as_ref()),\n-                                            Cow::Borrowed(&task_type_bytes),\n+                                            WriteBuffer::Borrowed(IntKey::new(task_id).as_ref()),\n+                                            WriteBuffer::Borrowed(&task_type_bytes),\n                                         )\n                                         .with_context(|| {\n                                             anyhow!(\n@@ -279,17 +302,17 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorage\n                             batch\n                                 .put(\n                                     KeySpace::ForwardTaskCache,\n-                                    Cow::Borrowed(&task_type_bytes),\n-                                    Cow::Borrowed(&task_id.to_le_bytes()),\n+                                    WriteBuffer::Borrowed(&task_type_bytes),\n+                                    WriteBuffer::Borrowed(&task_id.to_le_bytes()),\n                                 )\n                                 .with_context(|| {\n                                     anyhow!(\"Unable to write task cache {task_type:?} => {task_id}\")\n                                 })?;\n                             batch\n                                 .put(\n                                     KeySpace::ReverseTaskCache,\n-                                    Cow::Borrowed(IntKey::new(task_id).as_ref()),\n-                                    Cow::Borrowed(&task_type_bytes),\n+                                    WriteBuffer::Borrowed(IntKey::new(task_id).as_ref()),\n+                                    WriteBuffer::Borrowed(&task_type_bytes),\n                                 )\n                                 .with_context(|| {\n                                     anyhow!(\"Unable to write task cache {task_id} => {task_type:?}\")\n@@ -325,8 +348,8 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorage\n                         batch\n                             .put(\n                                 key_space,\n-                                Cow::Borrowed(IntKey::new(*task_id).as_ref()),\n-                                value.into(),\n+                                WriteBuffer::Borrowed(IntKey::new(*task_id).as_ref()),\n+                                value,\n                             )\n                             .with_context(|| anyhow!(\"Unable to write data items for {task_id}\"))?;\n                     }\n@@ -473,8 +496,8 @@ where\n         batch\n             .put(\n                 KeySpace::Infra,\n-                Cow::Borrowed(IntKey::new(META_KEY_NEXT_FREE_TASK_ID).as_ref()),\n-                Cow::Borrowed(&next_task_id.to_le_bytes()),\n+                WriteBuffer::Borrowed(IntKey::new(META_KEY_NEXT_FREE_TASK_ID).as_ref()),\n+                WriteBuffer::Borrowed(&next_task_id.to_le_bytes()),\n             )\n             .with_context(|| anyhow!(\"Unable to write next free task id\"))?;\n     }\n@@ -483,22 +506,21 @@ where\n         batch\n             .put(\n                 KeySpace::Infra,\n-                Cow::Borrowed(IntKey::new(META_KEY_SESSION_ID).as_ref()),\n-                Cow::Borrowed(&session_id.to_le_bytes()),\n+                WriteBuffer::Borrowed(IntKey::new(META_KEY_SESSION_ID).as_ref()),\n+                WriteBuffer::Borrowed(&session_id.to_le_bytes()),\n             )\n             .with_context(|| anyhow!(\"Unable to write next session id\"))?;\n     }\n     {\n         let _span =\n             tracing::trace_span!(\"update operations\", operations = operations.len()).entered();\n-        let operations = POT_CONFIG\n-            .serialize(&operations)\n+        let operations = pot_serialize_small_vec(&operations)\n             .with_context(|| anyhow!(\"Unable to serialize operations\"))?;\n         batch\n             .put(\n                 KeySpace::Infra,\n-                Cow::Borrowed(IntKey::new(META_KEY_OPERATIONS).as_ref()),\n-                operations.into(),\n+                WriteBuffer::Borrowed(IntKey::new(META_KEY_OPERATIONS).as_ref()),\n+                WriteBuffer::SmallVec(operations),\n             )\n             .with_context(|| anyhow!(\"Unable to write operations\"))?;\n     }\n@@ -527,7 +549,7 @@ fn serialize_task_type(\n     Ok(())\n }\n \n-type SerializedTasks = Vec<Vec<(TaskId, Vec<u8>)>>;\n+type SerializedTasks = Vec<Vec<(TaskId, WriteBuffer<'static>)>>;\n type TaskUpdates =\n     FxHashMap<CachedDataItemKey, (Option<CachedDataItemValue>, Option<CachedDataItemValue>)>;\n \n@@ -712,12 +734,12 @@ fn process_task_data<'a, B: ConcurrentWriteBatch<'a> + Send + Sync>(\n                     if let Some(batch) = batch {\n                         batch.put(\n                             key_space,\n-                            Cow::Borrowed(IntKey::new(*task).as_ref()),\n-                            Cow::Owned(value),\n+                            WriteBuffer::Borrowed(IntKey::new(*task).as_ref()),\n+                            WriteBuffer::SmallVec(value),\n                         )?;\n                     } else {\n                         // Store the new task data\n-                        tasks.push((task, value));\n+                        tasks.push((task, WriteBuffer::SmallVec(value)));\n                     }\n                 }\n \n@@ -728,9 +750,9 @@ fn process_task_data<'a, B: ConcurrentWriteBatch<'a> + Send + Sync>(\n         .collect::<Result<Vec<_>>>()\n }\n \n-fn serialize(task: TaskId, data: &mut TaskUpdates) -> Result<Vec<u8>> {\n+fn serialize(task: TaskId, data: &mut TaskUpdates) -> Result<SmallVec<[u8; 16]>> {\n     Ok(\n-        match POT_CONFIG.serialize(&SerializeLikeVecOfCachedDataItem(data)) {\n+        match pot_serialize_small_vec(&SerializeLikeVecOfCachedDataItem(data)) {\n             #[cfg(not(feature = \"verify_serialization\"))]\n             Ok(value) => value,\n             _ => {\n@@ -782,11 +804,9 @@ fn serialize(task: TaskId, data: &mut TaskUpdates) -> Result<Vec<u8>> {\n                 });\n                 error?;\n \n-                POT_CONFIG\n-                    .serialize(&SerializeLikeVecOfCachedDataItem(data))\n-                    .with_context(|| {\n-                        anyhow!(\"Unable to serialize data items for {task}: {data:#?}\")\n-                    })?\n+                pot_serialize_small_vec(&SerializeLikeVecOfCachedDataItem(data)).with_context(\n+                    || anyhow!(\"Unable to serialize data items for {task}: {data:#?}\"),\n+                )?\n             }\n         },\n     )"
        }
    ],
    "stats": {
        "total": 456,
        "additions": 361,
        "deletions": 95
    }
}