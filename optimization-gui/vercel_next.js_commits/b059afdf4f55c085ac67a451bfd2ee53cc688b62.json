{
    "author": "sokra",
    "message": "Revert \"perf(turbopack/rcstr): Add serialization-time optimization (#78645)\" (#81112)\n\nThis reverts commit 2689a741014f57c3fbda32cb488f67607fbc6fe6.\n\nReverts https://github.com/vercel/next.js/pull/78645 as it causes an\nincremental build regression",
    "sha": "b059afdf4f55c085ac67a451bfd2ee53cc688b62",
    "files": [
        {
            "sha": "0bf3ef7701d84b568fa09864cf59645be0a4de10",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -9159,11 +9159,9 @@ version = \"0.1.0\"\n dependencies = [\n  \"bytes-str\",\n  \"codspeed-criterion-compat\",\n- \"indexmap 2.9.0\",\n  \"napi\",\n  \"new_debug_unreachable\",\n  \"rustc-hash 2.1.1\",\n- \"scoped-tls\",\n  \"serde\",\n  \"shrink-to-fit\",\n  \"triomphe 0.1.12\",\n@@ -9255,7 +9253,6 @@ dependencies = [\n  \"rstest\",\n  \"rustc-hash 2.1.1\",\n  \"serde\",\n- \"serde_bytes\",\n  \"serde_json\",\n  \"serde_path_to_error\",\n  \"smallvec\","
        },
        {
            "sha": "70c87199f396c21baca31641b1a85431aa7df4bd",
            "filename": "turbopack/crates/turbo-persistence/src/lib.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 3,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -13,15 +13,16 @@ mod db;\n mod key;\n mod lookup_entry;\n mod merge_iter;\n+mod static_sorted_file;\n+mod static_sorted_file_builder;\n+mod write_batch;\n+\n mod meta_file;\n mod meta_file_builder;\n mod sst_filter;\n-mod static_sorted_file;\n-mod static_sorted_file_builder;\n #[cfg(test)]\n mod tests;\n mod value_buf;\n-mod write_batch;\n \n pub use arc_slice::ArcSlice;\n pub use db::{CompactConfig, MetaFileEntryInfo, MetaFileInfo, TurboPersistence};"
        },
        {
            "sha": "3ab1b82b70aa505d55b21132fbe58a5512337641",
            "filename": "turbopack/crates/turbo-rcstr/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-rcstr%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-rcstr%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-rcstr%2FCargo.toml?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -15,15 +15,11 @@ turbo-tasks-hash = { workspace = true }\n serde = { workspace = true }\n new_debug_unreachable = \"1.0.6\"\n shrink-to-fit = { workspace = true }\n-bytes-str = { workspace = true }\n-indexmap = { workspace = true }\n rustc-hash = { workspace = true }\n-scoped-tls = \"1.0.1\"\n+bytes-str = { workspace = true }\n \n [target.'cfg(not(target_family = \"wasm\"))'.dependencies]\n napi = { workspace = true, optional = true }\n-scoped-tls = \"1.0.1\"\n-indexmap = { workspace = true }\n \n [dev-dependencies]\n criterion = { workspace = true }"
        },
        {
            "sha": "e4be84916fc1c74db756d301d91e093824432209",
            "filename": "turbopack/crates/turbo-rcstr/src/lib.rs",
            "status": "modified",
            "additions": 14,
            "deletions": 2,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Flib.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -11,18 +11,17 @@ use std::{\n \n use bytes_str::BytesStr;\n use debug_unreachable::debug_unreachable;\n+use serde::{Deserialize, Deserializer, Serialize, Serializer};\n use shrink_to_fit::ShrinkToFit;\n use triomphe::Arc;\n use turbo_tasks_hash::{DeterministicHash, DeterministicHasher};\n \n-pub use crate::serde::{set_de_map, set_ser_map};\n use crate::{\n     dynamic::{deref_from, new_atom},\n     tagged_value::TaggedValue,\n };\n \n mod dynamic;\n-mod serde;\n mod tagged_value;\n \n /// An immutable reference counted [`String`], similar to [`Arc<String>`][std::sync::Arc].\n@@ -319,6 +318,19 @@ impl Hash for RcStr {\n     }\n }\n \n+impl Serialize for RcStr {\n+    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n+        serializer.serialize_str(self.as_str())\n+    }\n+}\n+\n+impl<'de> Deserialize<'de> for RcStr {\n+    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n+        let s = String::deserialize(deserializer)?;\n+        Ok(RcStr::from(s))\n+    }\n+}\n+\n impl Drop for RcStr {\n     fn drop(&mut self) {\n         if self.tag() == DYNAMIC_TAG {"
        },
        {
            "sha": "ebac2688f6cb4cd19855eb8460dfa2269bea2e02",
            "filename": "turbopack/crates/turbo-rcstr/src/serde.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 99,
            "changes": 99,
            "blob_url": "https://github.com/vercel/next.js/blob/dde872d7e5432df98bf287a5f1c4c2f183927f96/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Fserde.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/dde872d7e5432df98bf287a5f1c4c2f183927f96/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Fserde.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-rcstr%2Fsrc%2Fserde.rs?ref=dde872d7e5432df98bf287a5f1c4c2f183927f96",
            "patch": "@@ -1,99 +0,0 @@\n-use std::{cell::RefCell, hash::BuildHasherDefault};\n-\n-use indexmap::IndexSet;\n-use rustc_hash::FxHasher;\n-use scoped_tls::scoped_thread_local;\n-use serde::{Deserialize, Deserializer, Serialize, Serializer};\n-\n-use crate::RcStr;\n-\n-scoped_thread_local!(\n-    /// Map of strings to their interned ids.\n-    ///\n-    /// This is used to serialize strings to their interned ids.\n-    static SER_MAP: RefCell<IndexSet<RcStr, BuildHasherDefault<FxHasher>>>\n-);\n-\n-scoped_thread_local!(\n-    /// Read-only map interned ids to their strings\n-    static DE_MAP: Vec<RcStr>\n-);\n-\n-pub fn set_ser_map<F, R>(f: F) -> (R, IndexSet<RcStr, BuildHasherDefault<FxHasher>>)\n-where\n-    F: FnOnce() -> R,\n-{\n-    let map = Default::default();\n-\n-    let r = { SER_MAP.set(&map, f) };\n-\n-    (r, map.into_inner())\n-}\n-\n-pub fn set_de_map<F, R>(map: &Vec<RcStr>, f: F) -> R\n-where\n-    F: FnOnce() -> R,\n-{\n-    DE_MAP.set(map, f)\n-}\n-\n-/// Intern a string for serialization.\n-///\n-/// This function exists to move the logic for accessing the SER_MAP out of the hot path of\n-/// `Serialize::serialize`.\n-#[inline(never)]\n-fn intern_for_serialize(str: &RcStr) -> Option<u32> {\n-    if !SER_MAP.is_set() {\n-        return None;\n-    }\n-\n-    Some(SER_MAP.with(|ser| {\n-        let mut borrow = ser.borrow_mut();\n-        if let Some(id) = borrow.get_index_of(str) {\n-            id as u32\n-        } else {\n-            let id = borrow.len();\n-            borrow.insert(str.clone());\n-            id as u32\n-        }\n-    }))\n-}\n-\n-impl Serialize for RcStr {\n-    fn serialize<S: Serializer>(&self, serializer: S) -> Result<S::Ok, S::Error> {\n-        // If it's too short, it's not worth interning.\n-        // If it's too long, it's unlikely to be repeated.\n-        if self.len() >= 3 && self.len() < 512 {\n-            let id = intern_for_serialize(self);\n-            if let Some(id) = id {\n-                return serializer.serialize_u32(id);\n-            }\n-        }\n-\n-        serializer.serialize_str(self.as_str())\n-    }\n-}\n-\n-impl<'de> Deserialize<'de> for RcStr {\n-    fn deserialize<D: Deserializer<'de>>(deserializer: D) -> Result<Self, D::Error> {\n-        use serde::de::Error;\n-        #[derive(Deserialize)]\n-        #[serde(untagged)]\n-        enum Repr {\n-            Id(u32),\n-            String(String),\n-        }\n-\n-        let repr = Repr::deserialize(deserializer)?;\n-\n-        match repr {\n-            Repr::String(s) => Ok(RcStr::from(s)),\n-            Repr::Id(id) => DE_MAP.with(|map| {\n-                let s = map\n-                    .get(id as usize)\n-                    .ok_or_else(|| D::Error::custom(format!(\"failed to find id: {id}\")))?;\n-                Ok(s.clone())\n-            }),\n-        }\n-    }\n-}"
        },
        {
            "sha": "8c878414b23e3e075dbc4c9ccec8a03e5d7c592a",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -42,10 +42,9 @@ rayon = { workspace = true }\n ringmap = { workspace = true, features = [\"serde\"] }\n rustc-hash = { workspace = true }\n serde = { workspace = true }\n-serde_bytes = { workspace = true }\n serde_json = { workspace = true }\n serde_path_to_error = { workspace = true }\n-smallvec = { workspace = true, features = [\"write\"] }\n+smallvec = { workspace = true }\n tokio = { workspace = true }\n tracing = { workspace = true }\n thread_local = { workspace = true }"
        },
        {
            "sha": "f95626ee299f2a3228360fd768d1d973043a1c43",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -62,7 +62,6 @@ use crate::{\n         CachedDataItemValueRef, CellRef, CollectibleRef, CollectiblesRef, DirtyState,\n         InProgressCellState, InProgressState, InProgressStateInner, OutputValue, RootType,\n     },\n-    interning_serde::RcStrToLocalId,\n     utils::{\n         bi_map::BiMap, chunked_vec::ChunkedVec, ptr_eq_arc::PtrEqArc, sharded::Sharded, swap_retain,\n     },\n@@ -963,14 +962,12 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let task_snapshots = snapshot\n             .into_iter()\n             .filter_map(|iter| {\n-                type SerializedData = (SmallVec<[u8; 16]>, RcStrToLocalId);\n-\n                 let mut iter = iter\n                     .filter_map(\n                         |(task_id, meta, data): (\n                             _,\n-                            Option<Result<SerializedData>>,\n-                            Option<Result<SerializedData>>,\n+                            Option<Result<SmallVec<_>>>,\n+                            Option<Result<SmallVec<_>>>,\n                         )| {\n                             let meta = match meta {\n                                 Some(Ok(meta)) => {\n@@ -1172,8 +1169,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n             .flatten();\n         let task_id = {\n             // Safety: `tx` is a valid transaction from `self.backend.backing_storage`.\n-            if let Some((task_id, _rcstr_map)) = unsafe {\n-                // We can ignore rcstr_map because those are all already stored in the database.\n+            if let Some(task_id) = unsafe {\n                 self.backing_storage\n                     .forward_lookup_task_cache(tx.as_ref(), &task_type)\n                     .expect(\"Failed to lookup task id\")"
        },
        {
            "sha": "cf33d978e364dcba4e0dd62ef2138e30ff4bb371",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backing_storage.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 8,
            "changes": 12,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -7,7 +7,6 @@ use turbo_tasks::{SessionId, TaskId, backend::CachedTaskType};\n use crate::{\n     backend::{AnyOperation, TaskDataCategory},\n     data::CachedDataItem,\n-    interning_serde::RcStrToLocalId,\n     utils::chunked_vec::ChunkedVec,\n };\n \n@@ -49,10 +48,7 @@ pub trait BackingStorageSealed: 'static + Send + Sync {\n     fn next_session_id(&self) -> Result<SessionId>;\n     fn uncompleted_operations(&self) -> Result<Vec<AnyOperation>>;\n     #[allow(clippy::ptr_arg)]\n-    fn serialize(\n-        task: TaskId,\n-        data: &Vec<CachedDataItem>,\n-    ) -> Result<(SmallVec<[u8; 16]>, RcStrToLocalId)>;\n+    fn serialize(task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>>;\n     fn save_snapshot<I>(\n         &self,\n         session_id: SessionId,\n@@ -64,8 +60,8 @@ pub trait BackingStorageSealed: 'static + Send + Sync {\n         I: Iterator<\n                 Item = (\n                     TaskId,\n-                    Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n-                    Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n+                    Option<SmallVec<[u8; 16]>>,\n+                    Option<SmallVec<[u8; 16]>>,\n                 ),\n             > + Send\n             + Sync;\n@@ -77,7 +73,7 @@ pub trait BackingStorageSealed: 'static + Send + Sync {\n         &self,\n         tx: Option<&Self::ReadTransaction<'_>>,\n         key: &CachedTaskType,\n-    ) -> Result<Option<(TaskId, RcStrToLocalId)>>;\n+    ) -> Result<Option<TaskId>>;\n     /// # Safety\n     ///\n     /// `tx` must be a transaction from this BackingStorage instance."
        },
        {
            "sha": "449a1ba7a5fac12b16cf04ccf3b2da3d53324516",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/key_value_database.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fkey_value_database.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fkey_value_database.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fkey_value_database.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -11,8 +11,6 @@ pub enum KeySpace {\n     TaskData = 2,\n     ForwardTaskCache = 3,\n     ReverseTaskCache = 4,\n-    StringInternMap = 5,\n-    ReverseStringInternMap = 6,\n }\n \n pub trait KeyValueDatabase {"
        },
        {
            "sha": "52ee105dfcea0d81264d24a9507b156ebec8a3a3",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/turbo.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -122,7 +122,7 @@ impl KeyValueDatabase for TurboKeyValueDatabase {\n }\n \n pub struct TurboWriteBatch<'a> {\n-    batch: turbo_persistence::WriteBatch<WriteBuffer<'static>, 7>,\n+    batch: turbo_persistence::WriteBatch<WriteBuffer<'static>, 5>,\n     db: &'a Arc<TurboPersistence>,\n     compact_join_handle: &'a Mutex<Option<JoinHandle<Result<()>>>>,\n     initial_write: bool,"
        },
        {
            "sha": "fa9f3e83761638a4e92b4e09c6af28f44fdc108c",
            "filename": "turbopack/crates/turbo-tasks-backend/src/interning_serde/mod.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 104,
            "changes": 104,
            "blob_url": "https://github.com/vercel/next.js/blob/dde872d7e5432df98bf287a5f1c4c2f183927f96/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Finterning_serde%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/dde872d7e5432df98bf287a5f1c4c2f183927f96/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Finterning_serde%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Finterning_serde%2Fmod.rs?ref=dde872d7e5432df98bf287a5f1c4c2f183927f96",
            "patch": "@@ -1,104 +0,0 @@\n-//! Exposed for usage in `turbo-tasks-backend`\n-\n-use std::io::Write;\n-\n-use serde::{Deserialize, Serialize};\n-use turbo_rcstr::RcStr;\n-use turbo_tasks::FxIndexSet;\n-\n-pub fn to_vec<T>(config: &pot::Config, value: &T) -> anyhow::Result<(Vec<u8>, RcStrToLocalId)>\n-where\n-    T: Serialize,\n-{\n-    let mut vec = Vec::new();\n-    let ser_map = to_writer(config, value, &mut vec)?;\n-    Ok((vec, ser_map))\n-}\n-\n-pub struct LocalIdToRcStr(Vec<RcStr>);\n-\n-impl From<Vec<RcStr>> for LocalIdToRcStr {\n-    fn from(value: Vec<RcStr>) -> Self {\n-        Self(value)\n-    }\n-}\n-\n-#[derive(Default)]\n-pub struct RcStrToLocalId(FxIndexSet<RcStr>);\n-\n-impl RcStrToLocalId {\n-    pub fn iter(&self) -> impl Iterator<Item = &RcStr> {\n-        self.0.iter()\n-    }\n-}\n-\n-#[derive(Default)]\n-pub struct LocalIdToGlobalId(Vec<u32>);\n-\n-impl From<Vec<u32>> for LocalIdToGlobalId {\n-    fn from(value: Vec<u32>) -> Self {\n-        Self(value)\n-    }\n-}\n-\n-impl LocalIdToGlobalId {\n-    pub fn len(&self) -> usize {\n-        self.0.len()\n-    }\n-\n-    pub fn iter(&self) -> impl '_ + Iterator<Item = u32> {\n-        self.0.iter().copied()\n-    }\n-\n-    pub fn write_to(&self, writer: &mut impl Write) -> anyhow::Result<()> {\n-        let len = self.0.len() as u32;\n-        for id in self.0.iter().rev() {\n-            writer.write_all(&id.to_le_bytes())?;\n-        }\n-\n-        writer.write_all(&len.to_le_bytes())?;\n-\n-        Ok(())\n-    }\n-\n-    pub fn read_from_slice(mut bytes: &[u8]) -> anyhow::Result<(Self, &[u8])> {\n-        let mut global_ids = Vec::new();\n-\n-        // Length is the last 4 bytes\n-        let len = u32::from_le_bytes(bytes[bytes.len() - 4..].try_into().unwrap());\n-        global_ids.reserve(len as usize);\n-\n-        bytes = &bytes[..bytes.len() - 4];\n-\n-        // Read the ids in reverse order\n-        for _ in 0..len {\n-            let id = u32::from_le_bytes(bytes[bytes.len() - 4..].try_into().unwrap());\n-            global_ids.push(id);\n-            bytes = &bytes[..bytes.len() - 4];\n-        }\n-\n-        Ok((Self(global_ids), bytes))\n-    }\n-}\n-\n-pub fn to_writer<T, W>(config: &pot::Config, value: &T, writer: W) -> anyhow::Result<RcStrToLocalId>\n-where\n-    T: Serialize,\n-    W: Write,\n-{\n-    let (result, ser_map) = turbo_rcstr::set_ser_map(|| config.serialize_into(value, writer));\n-    result?;\n-\n-    Ok(RcStrToLocalId(ser_map))\n-}\n-\n-pub fn from_slice<'de, T>(\n-    config: &pot::Config,\n-    bytes: &'de [u8],\n-    de_map: &LocalIdToRcStr,\n-) -> anyhow::Result<T>\n-where\n-    T: Deserialize<'de>,\n-{\n-    turbo_rcstr::set_de_map(&de_map.0, || Ok(config.deserialize(bytes)?))\n-}"
        },
        {
            "sha": "915f3570a12b30af9d495cd5a806f4b8bb0726ab",
            "filename": "turbopack/crates/turbo-tasks-backend/src/kv_backing_storage.rs",
            "status": "modified",
            "additions": 43,
            "deletions": 274,
            "changes": 317,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -3,21 +3,16 @@ use std::{\n     cmp::max,\n     env,\n     path::PathBuf,\n-    sync::{\n-        Arc, LazyLock, Mutex, OnceLock, PoisonError, Weak,\n-        atomic::{AtomicU32, Ordering},\n-    },\n+    sync::{Arc, LazyLock, Mutex, PoisonError, Weak},\n };\n \n-use anyhow::{Context, Result, anyhow, bail};\n+use anyhow::{Context, Result, anyhow};\n use rayon::iter::{IndexedParallelIterator, IntoParallelIterator, ParallelIterator};\n-use rustc_hash::FxHashMap;\n use serde::{Deserialize, Serialize};\n use smallvec::SmallVec;\n use tracing::Span;\n-use turbo_rcstr::RcStr;\n use turbo_tasks::{\n-    FxDashMap, SessionId, TaskId,\n+    SessionId, TaskId,\n     backend::CachedTaskType,\n     panic_hooks::{PanicHookGuard, register_panic_hook},\n     turbo_tasks_scope,\n@@ -38,16 +33,12 @@ use crate::{\n         },\n     },\n     db_invalidation::invalidation_reasons,\n-    interning_serde,\n-    interning_serde::{LocalIdToGlobalId, LocalIdToRcStr, RcStrToLocalId},\n     utils::chunked_vec::ChunkedVec,\n };\n \n const POT_CONFIG: pot::Config = pot::Config::new().compatibility(pot::Compatibility::V4);\n \n-fn pot_serialize_small_vec<T: Serialize>(\n-    value: &T,\n-) -> Result<(SmallVec<[u8; 16]>, RcStrToLocalId)> {\n+fn pot_serialize_small_vec<T: Serialize>(value: &T) -> pot::Result<SmallVec<[u8; 16]>> {\n     struct SmallVecWrite<'l>(&'l mut SmallVec<[u8; 16]>);\n     impl std::io::Write for SmallVecWrite<'_> {\n         #[inline]\n@@ -69,8 +60,8 @@ fn pot_serialize_small_vec<T: Serialize>(\n     }\n \n     let mut output = SmallVec::new();\n-    let ser_map = interning_serde::to_writer(&POT_CONFIG, value, SmallVecWrite(&mut output))?;\n-    Ok((output, ser_map))\n+    POT_CONFIG.serialize_into(value, SmallVecWrite(&mut output))?;\n+    Ok(output)\n }\n \n fn pot_ser_symbol_map() -> pot::ser::SymbolMap {\n@@ -84,7 +75,6 @@ fn pot_de_symbol_list<'l>() -> pot::de::SymbolList<'l> {\n const META_KEY_OPERATIONS: u32 = 0;\n const META_KEY_NEXT_FREE_TASK_ID: u32 = 1;\n const META_KEY_SESSION_ID: u32 = 2;\n-const META_KEY_NEXT_STRING_ID: u32 = 3;\n \n struct IntKey([u8; 4]);\n \n@@ -308,16 +298,13 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(Vec::new());\n             };\n-            let operations = deserialize_with_good_error(database, &tx, operations.borrow())?;\n+            let operations = deserialize_with_good_error(operations.borrow())?;\n             Ok(operations)\n         }\n         get(&self.inner.database).context(\"Unable to read uncompleted operations from database\")\n     }\n \n-    fn serialize(\n-        task: TaskId,\n-        data: &Vec<CachedDataItem>,\n-    ) -> Result<(SmallVec<[u8; 16]>, RcStrToLocalId)> {\n+    fn serialize(task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>> {\n         serialize(task, data)\n     }\n \n@@ -332,8 +319,8 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n         I: Iterator<\n                 Item = (\n                     TaskId,\n-                    Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n-                    Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n+                    Option<SmallVec<[u8; 16]>>,\n+                    Option<SmallVec<[u8; 16]>>,\n                 ),\n             > + Send\n             + Sync,\n@@ -379,11 +366,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                             let mut task_type_bytes = Vec::new();\n                             for (task_type, task_id) in updates {\n                                 let task_id: u32 = *task_id;\n-                                let rcstr_map =\n-                                    serialize_task_type(&task_type, &mut task_type_bytes, task_id)?;\n-\n-                                let global_ids = save_strings_concurrent(batch, &rcstr_map)?;\n-                                global_ids.write_to(&mut task_type_bytes)?;\n+                                serialize_task_type(&task_type, &mut task_type_bytes, task_id)?;\n \n                                 batch\n                                     .put(\n@@ -453,11 +436,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                         let mut task_type_bytes = Vec::new();\n                         for (task_type, task_id) in task_cache_updates.into_iter().flatten() {\n                             let task_id = *task_id;\n-                            let rcstr_map =\n-                                serialize_task_type(&task_type, &mut task_type_bytes, task_id)?;\n-\n-                            let global_ids = save_strings_serial(batch, &rcstr_map)?;\n-                            global_ids.write_to(&mut task_type_bytes)?;\n+                            serialize_task_type(&task_type, &mut task_type_bytes, task_id)?;\n \n                             batch\n                                 .put(\n@@ -495,30 +474,16 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                     for (task_id, meta, data) in task_items_result?.into_iter().flatten() {\n                         let key = IntKey::new(*task_id);\n                         let key = key.as_ref();\n-                        if let Some((mut meta, rcstr_map)) = meta {\n-                            let global_ids = save_strings_serial(batch, &rcstr_map)?;\n-                            global_ids.write_to(&mut meta)?;\n-\n+                        if let Some(meta) = meta {\n                             batch\n-                                .put(\n-                                    KeySpace::TaskMeta,\n-                                    WriteBuffer::Borrowed(key),\n-                                    WriteBuffer::SmallVec(meta),\n-                                )\n+                                .put(KeySpace::TaskMeta, WriteBuffer::Borrowed(key), meta)\n                                 .with_context(|| {\n                                     anyhow!(\"Unable to write meta items for {task_id}\")\n                                 })?;\n                         }\n-                        if let Some((mut data, rcstr_map)) = data {\n-                            let global_ids = save_strings_serial(batch, &rcstr_map)?;\n-                            global_ids.write_to(&mut data)?;\n-\n+                        if let Some(data) = data {\n                             batch\n-                                .put(\n-                                    KeySpace::TaskData,\n-                                    WriteBuffer::Borrowed(key),\n-                                    WriteBuffer::SmallVec(data),\n-                                )\n+                                .put(KeySpace::TaskData, WriteBuffer::Borrowed(key), data)\n                                 .with_context(|| {\n                                     anyhow!(\"Unable to write data items for {task_id}\")\n                                 })?;\n@@ -545,22 +510,21 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n         &self,\n         tx: Option<&T::ReadTransaction<'_>>,\n         task_type: &CachedTaskType,\n-    ) -> Result<Option<(TaskId, RcStrToLocalId)>> {\n+    ) -> Result<Option<TaskId>> {\n+        let inner = &*self.inner;\n         fn lookup<D: KeyValueDatabase>(\n             database: &D,\n             tx: &D::ReadTransaction<'_>,\n             task_type: &CachedTaskType,\n-        ) -> Result<Option<(TaskId, RcStrToLocalId)>> {\n-            let (task_type, map) = interning_serde::to_vec(&POT_CONFIG, task_type)?;\n+        ) -> Result<Option<TaskId>> {\n+            let task_type = POT_CONFIG.serialize(task_type)?;\n             let Some(bytes) = database.get(tx, KeySpace::ForwardTaskCache, &task_type)? else {\n                 return Ok(None);\n             };\n             let bytes = bytes.borrow().try_into()?;\n             let id = TaskId::try_from(u32::from_le_bytes(bytes)).unwrap();\n-            Ok(Some((id, map)))\n+            Ok(Some(id))\n         }\n-\n-        let inner = &*self.inner;\n         if inner.database.is_empty() {\n             // Checking if the database is empty is a performance optimization\n             // to avoid serializing the task type.\n@@ -590,11 +554,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(None);\n             };\n-            Ok(Some(deserialize_with_good_error(\n-                database,\n-                tx,\n-                bytes.borrow(),\n-            )?))\n+            Ok(Some(deserialize_with_good_error(bytes.borrow())?))\n         }\n         inner\n             .with_tx(tx, |tx| lookup(&inner.database, tx, task_id))\n@@ -626,8 +586,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             else {\n                 return Ok(Vec::new());\n             };\n-            let result: Vec<CachedDataItem> =\n-                deserialize_with_good_error(database, tx, bytes.borrow())?;\n+            let result: Vec<CachedDataItem> = deserialize_with_good_error(bytes.borrow())?;\n             Ok(result)\n         }\n         inner\n@@ -640,55 +599,6 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n     }\n }\n \n-fn restore_strings<D: KeyValueDatabase>(\n-    database: &D,\n-    tx: &D::ReadTransaction<'_>,\n-    global_ids: &LocalIdToGlobalId,\n-) -> Result<LocalIdToRcStr> {\n-    let mut map = Vec::with_capacity(global_ids.len());\n-\n-    for global_id in global_ids.iter() {\n-        // First, check the in-memory cache\n-        let rcstr = {\n-            let cache = STRING_CACHE.lock().unwrap_or_else(PoisonError::into_inner);\n-            cache.get(&global_id).cloned()\n-        };\n-\n-        let rcstr = if let Some(rcstr) = rcstr {\n-            // Cache hit\n-            rcstr\n-        } else {\n-            // Cache miss, fetch from database\n-            let Some(value) = database.get(\n-                tx,\n-                KeySpace::ReverseStringInternMap,\n-                IntKey::new(global_id).as_ref(),\n-            )?\n-            else {\n-                bail!(\"Unable to find string for {global_id}\")\n-            };\n-\n-            let mut rcstr = unsafe {\n-                // Safety: We interned a rust string, so it is valid utf-8\n-                RcStr::from(str::from_utf8_unchecked(value.borrow()))\n-            };\n-\n-            // Update both caches\n-            {\n-                let mut cache = STRING_CACHE.lock().unwrap_or_else(PoisonError::into_inner);\n-                rcstr = cache.entry(global_id).or_insert(rcstr).clone();\n-            }\n-            STRING_TO_ID_CACHE.insert(rcstr.clone(), global_id);\n-\n-            rcstr\n-        };\n-\n-        map.push(rcstr);\n-    }\n-\n-    Ok(map.into())\n-}\n-\n fn get_next_free_task_id<'a, S, C>(\n     batch: &mut WriteBatchRef<'_, 'a, S, C>,\n ) -> Result<u32, anyhow::Error>\n@@ -739,15 +649,8 @@ where\n     {\n         let _span =\n             tracing::trace_span!(\"update operations\", operations = operations.len()).entered();\n-        let (mut operations, rcstr_map) = pot_serialize_small_vec(&operations)\n+        let operations = pot_serialize_small_vec(&operations)\n             .with_context(|| anyhow!(\"Unable to serialize operations\"))?;\n-        let global_ids = match batch {\n-            WriteBatchRef::Serial(_) => save_strings_serial(batch, &rcstr_map)?,\n-            WriteBatchRef::Concurrent(batch, _) => save_strings_concurrent(&**batch, &rcstr_map)?,\n-        };\n-        // Prepend the global ids to the operations\n-        global_ids.write_to(&mut operations)?;\n-\n         batch\n             .put(\n                 KeySpace::Infra,\n@@ -756,33 +659,18 @@ where\n             )\n             .with_context(|| anyhow!(\"Unable to write operations\"))?;\n     }\n-\n-    if let Some(next_string_id) = STRING_INTERN_ID.get() {\n-        let _span = tracing::trace_span!(\"update next string id\").entered();\n-\n-        let next_string_id = next_string_id.load(Ordering::SeqCst);\n-\n-        batch\n-            .put(\n-                KeySpace::Infra,\n-                WriteBuffer::Borrowed(IntKey::new(META_KEY_NEXT_STRING_ID).as_ref()),\n-                WriteBuffer::Borrowed(&next_string_id.to_le_bytes()),\n-            )\n-            .with_context(|| anyhow!(\"Unable to write next string id\"))?;\n-    }\n-\n     batch.flush(KeySpace::Infra)?;\n-\n     Ok(())\n }\n \n fn serialize_task_type(\n     task_type: &Arc<CachedTaskType>,\n     mut task_type_bytes: &mut Vec<u8>,\n     task_id: u32,\n-) -> Result<RcStrToLocalId> {\n+) -> Result<()> {\n     task_type_bytes.clear();\n-    let result = interning_serde::to_writer(&POT_CONFIG, task_type, &mut task_type_bytes)\n+    POT_CONFIG\n+        .serialize_into(&**task_type, &mut task_type_bytes)\n         .with_context(|| anyhow!(\"Unable to serialize task {task_id} cache key {task_type:?}\"))?;\n     #[cfg(feature = \"verify_serialization\")]\n     {\n@@ -794,14 +682,14 @@ fn serialize_task_type(\n             panic!(\"Task type would not be deserializable {task_id}: {err:?}\");\n         }\n     }\n-    Ok(result)\n+    Ok(())\n }\n \n type SerializedTasks = Vec<\n     Vec<(\n         TaskId,\n-        Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n-        Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n+        Option<WriteBuffer<'static>>,\n+        Option<WriteBuffer<'static>>,\n     )>,\n >;\n \n@@ -813,8 +701,8 @@ where\n     I: Iterator<\n             Item = (\n                 TaskId,\n-                Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n-                Option<(SmallVec<[u8; 16]>, RcStrToLocalId)>,\n+                Option<SmallVec<[u8; 16]>>,\n+                Option<SmallVec<[u8; 16]>>,\n             ),\n         > + Send\n         + Sync,\n@@ -833,20 +721,14 @@ where\n                     if let Some(batch) = batch {\n                         let key = IntKey::new(*task_id);\n                         let key = key.as_ref();\n-                        if let Some((mut meta, rcstr_map)) = meta {\n-                            let global_ids = save_strings_concurrent(batch, &rcstr_map)?;\n-                            global_ids.write_to(&mut meta)?;\n-\n+                        if let Some(meta) = meta {\n                             batch.put(\n                                 KeySpace::TaskMeta,\n                                 WriteBuffer::Borrowed(key),\n                                 WriteBuffer::SmallVec(meta),\n                             )?;\n                         }\n-                        if let Some((mut data, rcstr_map)) = data {\n-                            let global_ids = save_strings_concurrent(batch, &rcstr_map)?;\n-                            global_ids.write_to(&mut data)?;\n-\n+                        if let Some(data) = data {\n                             batch.put(\n                                 KeySpace::TaskData,\n                                 WriteBuffer::Borrowed(key),\n@@ -855,7 +737,11 @@ where\n                         }\n                     } else {\n                         // Store the new task data\n-                        result.push((task_id, meta, data));\n+                        result.push((\n+                            task_id,\n+                            meta.map(WriteBuffer::SmallVec),\n+                            data.map(WriteBuffer::SmallVec),\n+                        ));\n                     }\n                 }\n \n@@ -865,10 +751,7 @@ where\n         .collect::<Result<Vec<_>>>()\n }\n \n-fn serialize(\n-    task: TaskId,\n-    data: &Vec<CachedDataItem>,\n-) -> Result<(SmallVec<[u8; 16]>, RcStrToLocalId)> {\n+fn serialize(task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>> {\n     Ok(match pot_serialize_small_vec(data) {\n         #[cfg(not(feature = \"verify_serialization\"))]\n         Ok(value) => value,\n@@ -914,128 +797,14 @@ fn serialize(\n     })\n }\n \n-fn deserialize_with_good_error<'de, D: KeyValueDatabase, T: Deserialize<'de>>(\n-    database: &D,\n-    tx: &D::ReadTransaction<'_>,\n-    data: &'de [u8],\n-) -> Result<T> {\n-    let (global_ids, data) = LocalIdToGlobalId::read_from_slice(data)?;\n-    let map = restore_strings(database, tx, &global_ids)?;\n-\n-    match interning_serde::from_slice::<T>(&POT_CONFIG, data, &map) {\n+fn deserialize_with_good_error<'de, T: Deserialize<'de>>(data: &'de [u8]) -> Result<T> {\n+    match POT_CONFIG.deserialize(data) {\n         Ok(value) => Ok(value),\n         Err(error) => serde_path_to_error::deserialize::<'_, _, T>(\n             &mut pot_de_symbol_list().deserializer_for_slice(data)?,\n         )\n         .map_err(anyhow::Error::from)\n-        .and(Err(error))\n+        .and(Err(error.into()))\n         .context(\"Deserialization failed\"),\n     }\n }\n-\n-/// Store the strings in the database and return the global ids.\n-fn save_strings_serial<'a>(\n-    batch: &mut impl SerialWriteBatch<'a>,\n-    strings: &RcStrToLocalId,\n-) -> Result<LocalIdToGlobalId> {\n-    let mut global_ids = Vec::new();\n-    for s in strings.iter() {\n-        let (global_id, is_new) = get_string_id(batch, s)?;\n-        if is_new {\n-            batch.put(\n-                KeySpace::StringInternMap,\n-                WriteBuffer::Borrowed(s.as_bytes()),\n-                WriteBuffer::Borrowed(&global_id.to_le_bytes()),\n-            )?;\n-            batch.put(\n-                KeySpace::ReverseStringInternMap,\n-                WriteBuffer::Borrowed(IntKey::new(global_id).as_ref()),\n-                WriteBuffer::Borrowed(s.as_bytes()),\n-            )?;\n-        }\n-\n-        global_ids.push(global_id);\n-    }\n-\n-    Ok(LocalIdToGlobalId::from(global_ids))\n-}\n-/// Store the strings in the database and return the global ids.\n-fn save_strings_concurrent<'a>(\n-    batch: &impl ConcurrentWriteBatch<'a>,\n-    strings: &RcStrToLocalId,\n-) -> Result<LocalIdToGlobalId> {\n-    let mut global_ids = Vec::new();\n-    for s in strings.iter() {\n-        let (global_id, is_new) = get_string_id(batch, s)?;\n-        if is_new {\n-            batch.put(\n-                KeySpace::StringInternMap,\n-                WriteBuffer::Borrowed(s.as_bytes()),\n-                WriteBuffer::Borrowed(&global_id.to_le_bytes()),\n-            )?;\n-            batch.put(\n-                KeySpace::ReverseStringInternMap,\n-                WriteBuffer::Borrowed(IntKey::new(global_id).as_ref()),\n-                WriteBuffer::Borrowed(s.as_bytes()),\n-            )?;\n-        }\n-\n-        global_ids.push(global_id);\n-    }\n-\n-    Ok(LocalIdToGlobalId::from(global_ids))\n-}\n-\n-static STRING_INTERN_ID: OnceLock<AtomicU32> = OnceLock::new();\n-static STRING_CACHE: LazyLock<Mutex<FxHashMap<u32, RcStr>>> =\n-    LazyLock::new(|| Mutex::new(FxHashMap::default()));\n-static STRING_TO_ID_CACHE: LazyLock<FxDashMap<RcStr, u32>> = LazyLock::new(FxDashMap::default);\n-\n-/// Returns `(global_id, is_new)`\n-fn get_string_id<'a>(batch: &impl BaseWriteBatch<'a>, s: &RcStr) -> Result<(u32, bool)> {\n-    // First check the synchronization cache\n-    if let Some(global_id) = STRING_TO_ID_CACHE.get(s) {\n-        return Ok((*global_id, false));\n-    }\n-\n-    // Check the database\n-    let original = batch.get(KeySpace::StringInternMap, s.as_bytes())?;\n-\n-    if let Some(bytes) = original {\n-        let global_id = as_u32(bytes)?;\n-        // Cache the result for future lookups\n-        STRING_TO_ID_CACHE.insert(s.clone(), global_id);\n-        STRING_CACHE.lock().unwrap().insert(global_id, s.clone());\n-        return Ok((global_id, false));\n-    }\n-\n-    // Allocate a new ID\n-    let global_id = STRING_INTERN_ID\n-        .get_or_try_init(|| {\n-            let Some(bytes) = batch.get(\n-                KeySpace::Infra,\n-                IntKey::new(META_KEY_NEXT_STRING_ID).as_ref(),\n-            )?\n-            else {\n-                return anyhow::Ok(AtomicU32::new(0));\n-            };\n-\n-            let latest_id = as_u32(bytes)?;\n-\n-            Ok(AtomicU32::new(latest_id))\n-        })?\n-        .fetch_add(1, Ordering::Relaxed);\n-\n-    // Cache the new assignment to prevent duplicates within the same batch\n-    match STRING_TO_ID_CACHE.entry(s.clone()) {\n-        dashmap::Entry::Occupied(occupied_entry) => {\n-            return Ok((*occupied_entry.get(), false));\n-        }\n-        dashmap::Entry::Vacant(vacant_entry) => {\n-            vacant_entry.insert(global_id);\n-        }\n-    }\n-    STRING_CACHE.lock().unwrap().insert(global_id, s.clone());\n-\n-    Ok((global_id, true))\n-}"
        },
        {
            "sha": "c900c3a2b86a8b4637fa385f69104453f3ec7e2a",
            "filename": "turbopack/crates/turbo-tasks-backend/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b059afdf4f55c085ac67a451bfd2ee53cc688b62/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Flib.rs?ref=b059afdf4f55c085ac67a451bfd2ee53cc688b62",
            "patch": "@@ -2,13 +2,12 @@\n #![feature(associated_type_defaults)]\n #![feature(iter_collect_into)]\n #![feature(box_patterns)]\n-#![feature(once_cell_try)]\n+\n mod backend;\n mod backing_storage;\n mod data;\n mod data_storage;\n mod database;\n-mod interning_serde;\n mod kv_backing_storage;\n mod utils;\n "
        }
    ],
    "stats": {
        "total": 584,
        "additions": 72,
        "deletions": 512
    }
}