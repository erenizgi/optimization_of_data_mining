{
    "author": "sokra",
    "message": "Turbopack: refactor idle process queue and fix bugs and race conditions (#82630)\n\n### What?\n\nFixes a bug that breaks the pool after scaling down\n\nCloses PACK-5249",
    "sha": "36458f9002dffb620b040958f5832477ac107dfe",
    "files": [
        {
            "sha": "90ae1f0fe2d80870c266e22839f97543f5393989",
            "filename": "turbopack/crates/turbopack-node/src/heap_queue.rs",
            "status": "added",
            "additions": 87,
            "deletions": 0,
            "changes": 87,
            "blob_url": "https://github.com/vercel/next.js/blob/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fheap_queue.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fheap_queue.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fheap_queue.rs?ref=36458f9002dffb620b040958f5832477ac107dfe",
            "patch": "@@ -0,0 +1,87 @@\n+use std::{collections::BinaryHeap, sync::Arc};\n+\n+use parking_lot::Mutex;\n+use tokio::sync::{AcquireError, Semaphore};\n+\n+pub struct HeapQueue<T> {\n+    heap: Mutex<BinaryHeap<T>>,\n+    semaphore: Semaphore,\n+}\n+\n+impl<T: Ord> HeapQueue<T> {\n+    pub fn new() -> Self {\n+        Self {\n+            heap: Mutex::new(BinaryHeap::new()),\n+            semaphore: Semaphore::new(0),\n+        }\n+    }\n+\n+    pub fn push(self: &Arc<Self>, item: T, active_queues: &Mutex<Vec<Arc<Self>>>) {\n+        {\n+            let mut heap = self.heap.lock();\n+            if heap.is_empty() {\n+                // If the heap was empty, add this queue to the active queues\n+                let mut queues = active_queues.lock();\n+                queues.push(self.clone());\n+            }\n+            heap.push(item);\n+        }\n+        self.semaphore.add_permits(1);\n+    }\n+\n+    pub async fn pop(\n+        self: &Arc<Self>,\n+        active_queues: &Mutex<Vec<Arc<Self>>>,\n+    ) -> Result<T, AcquireError> {\n+        self.semaphore.acquire().await?.forget();\n+        let mut heap = self.heap.lock();\n+        let item = heap.pop().unwrap();\n+        if heap.is_empty() {\n+            // If the heap is empty, remove this queue from the active queues\n+            let mut queues = active_queues.lock();\n+            if let Some(pos) = queues.iter().position(|q| Arc::ptr_eq(q, self)) {\n+                queues.remove(pos);\n+            }\n+        }\n+        Ok(item)\n+    }\n+\n+    pub fn reduce_to_one(&self) {\n+        // Drain the semaphore permits\n+        let mut n = self.semaphore.forget_permits(usize::MAX);\n+        if n <= 1 {\n+            self.semaphore.add_permits(n);\n+            return;\n+        }\n+        let mut heap: parking_lot::lock_api::MutexGuard<'_, parking_lot::RawMutex, BinaryHeap<T>> =\n+            self.heap.lock();\n+        // We must only pop n items even if there are more since we only have n permits\n+        let top = heap.pop().unwrap();\n+        n -= 1;\n+        for _ in 0..n {\n+            heap.pop();\n+        }\n+        heap.push(top);\n+        self.semaphore.add_permits(1);\n+    }\n+\n+    pub fn reduce_to_zero(self: &Arc<Self>, active_queues: &Mutex<Vec<Arc<Self>>>) {\n+        // Drain the semaphore permits\n+        let n = self.semaphore.forget_permits(usize::MAX);\n+        if n == 0 {\n+            return;\n+        }\n+        let mut heap = self.heap.lock();\n+        // We must only pop n items even if there are more since we only have n permits\n+        for _ in 0..n {\n+            heap.pop();\n+        }\n+        if heap.is_empty() {\n+            // If the heap is empty, remove this queue from the active queues\n+            let mut queues = active_queues.lock();\n+            if let Some(pos) = queues.iter().position(|q| Arc::ptr_eq(q, self)) {\n+                queues.remove(pos);\n+            }\n+        }\n+    }\n+}"
        },
        {
            "sha": "bc3910e92f6490530d7a354b961123bfddb84fb8",
            "filename": "turbopack/crates/turbopack-node/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Flib.rs?ref=36458f9002dffb620b040958f5832477ac107dfe",
            "patch": "@@ -31,6 +31,7 @@ pub mod debug;\n pub mod embed_js;\n pub mod evaluate;\n pub mod execution_context;\n+mod heap_queue;\n mod node_entry;\n mod pool;\n pub mod render;"
        },
        {
            "sha": "a048276d9707250896233ab2dbda2f7584ee84cc",
            "filename": "turbopack/crates/turbopack-node/src/pool.rs",
            "status": "modified",
            "additions": 14,
            "deletions": 46,
            "changes": 60,
            "blob_url": "https://github.com/vercel/next.js/blob/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fpool.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/36458f9002dffb620b040958f5832477ac107dfe/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fpool.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-node%2Fsrc%2Fpool.rs?ref=36458f9002dffb620b040958f5832477ac107dfe",
            "patch": "@@ -1,7 +1,6 @@\n use std::{\n     borrow::Cow,\n     cmp::max,\n-    collections::BinaryHeap,\n     fmt::{Debug, Display},\n     future::Future,\n     mem::take,\n@@ -34,7 +33,7 @@ use turbo_tasks::{FxIndexSet, ResolvedVc, Vc, duration_span};\n use turbo_tasks_fs::{FileSystemPath, json::parse_json_with_source_context};\n use turbopack_ecmascript::magic_identifier::unmangle_identifiers;\n \n-use crate::{AssetsForSourceMapping, source_map::apply_source_mapping};\n+use crate::{AssetsForSourceMapping, heap_queue::HeapQueue, source_map::apply_source_mapping};\n \n #[derive(Clone, Copy)]\n pub enum FormattingMode {\n@@ -706,11 +705,11 @@ enum AcquiredPermits {\n     },\n }\n \n-type IdleProcessesList = Arc<Mutex<BinaryHeap<NodeJsPoolProcess>>>;\n+type IdleProcessQueues = Mutex<Vec<Arc<HeapQueue<NodeJsPoolProcess>>>>;\n \n-/// All non-empty `IdleProcessesList`s of the whole application.\n+/// All non-empty `IdleProcessQueues`s of the whole application.\n /// This is used to scale down processes globally.\n-static ACTIVE_POOLS: Lazy<Mutex<Vec<IdleProcessesList>>> = Lazy::new(Default::default);\n+static ACTIVE_POOLS: Lazy<IdleProcessQueues> = Lazy::new(Default::default);\n \n /// A pool of Node.js workers operating on [entrypoint] with specific [cwd] and\n /// [env].\n@@ -730,17 +729,14 @@ pub struct NodeJsPool {\n     pub assets_root: FileSystemPath,\n     pub project_dir: FileSystemPath,\n     #[turbo_tasks(trace_ignore, debug_ignore)]\n-    processes: Arc<Mutex<BinaryHeap<NodeJsPoolProcess>>>,\n+    idle_processes: Arc<HeapQueue<NodeJsPoolProcess>>,\n     /// Semaphore to limit the number of concurrent operations in general\n     #[turbo_tasks(trace_ignore, debug_ignore)]\n     concurrency_semaphore: Arc<Semaphore>,\n     /// Semaphore to limit the number of concurrently booting up processes\n     /// (excludes one-off processes)\n     #[turbo_tasks(trace_ignore, debug_ignore)]\n     bootup_semaphore: Arc<Semaphore>,\n-    /// Semaphore to wait for an idle process to become available\n-    #[turbo_tasks(trace_ignore, debug_ignore)]\n-    idle_process_semaphore: Arc<Semaphore>,\n     #[turbo_tasks(trace_ignore, debug_ignore)]\n     shared_stdout: SharedOutputSet,\n     #[turbo_tasks(trace_ignore, debug_ignore)]\n@@ -770,10 +766,9 @@ impl NodeJsPool {\n             assets_for_source_mapping,\n             assets_root,\n             project_dir,\n-            processes: Arc::new(Mutex::new(BinaryHeap::new())),\n             concurrency_semaphore: Arc::new(Semaphore::new(if debug { 1 } else { concurrency })),\n             bootup_semaphore: Arc::new(Semaphore::new(1)),\n-            idle_process_semaphore: Arc::new(Semaphore::new(0)),\n+            idle_processes: Arc::new(HeapQueue::new()),\n             shared_stdout: Arc::new(Mutex::new(FxIndexSet::default())),\n             shared_stderr: Arc::new(Mutex::new(FxIndexSet::default())),\n             debug,\n@@ -796,20 +791,8 @@ impl NodeJsPool {\n         };\n \n         select! {\n-            idle_process_permit = self.idle_process_semaphore.clone().acquire_owned() => {\n-                let idle_process_permit = idle_process_permit.context(\"acquiring idle process permit\")?;\n-                let process = {\n-                    let mut processes = self.processes.lock();\n-                    let process = processes.pop().unwrap();\n-                    if processes.is_empty() {\n-                        let mut pools = ACTIVE_POOLS.lock();\n-                        if let Some(idx) = pools.iter().position(|p| Arc::ptr_eq(p, &self.processes)) {\n-                            pools.swap_remove(idx);\n-                        }\n-                    }\n-                    process\n-                };\n-                idle_process_permit.forget();\n+            idle_process_result = self.idle_processes.pop(&ACTIVE_POOLS) => {\n+                let process = idle_process_result.context(\"acquiring idle process permit\")?;\n                 Ok((process, AcquiredPermits::Idle { concurrency_permit }))\n             },\n             bootup_permit = bootup => {\n@@ -856,8 +839,7 @@ impl NodeJsPool {\n         Ok(NodeJsOperation {\n             process: Some(process),\n             permits,\n-            processes: self.processes.clone(),\n-            idle_process_semaphore: self.idle_process_semaphore.clone(),\n+            idle_processes: self.idle_processes.clone(),\n             start: Instant::now(),\n             stats: self.stats.clone(),\n             allow_process_reuse: true,\n@@ -867,20 +849,14 @@ impl NodeJsPool {\n     pub fn scale_down() {\n         let pools = ACTIVE_POOLS.lock().clone();\n         for pool in pools {\n-            let mut pool = pool.lock();\n-            let best = pool.pop().unwrap();\n-            pool.clear();\n-            pool.push(best);\n-            pool.shrink_to_fit();\n+            pool.reduce_to_one();\n         }\n     }\n \n     pub fn scale_zero() {\n-        let pools = take(&mut *ACTIVE_POOLS.lock());\n+        let pools = ACTIVE_POOLS.lock().clone();\n         for pool in pools {\n-            let mut pool = pool.lock();\n-            pool.clear();\n-            pool.shrink_to_fit();\n+            pool.reduce_to_zero(&ACTIVE_POOLS);\n         }\n     }\n }\n@@ -890,8 +866,7 @@ pub struct NodeJsOperation {\n     // This is used for drop\n     #[allow(dead_code)]\n     permits: AcquiredPermits,\n-    processes: Arc<Mutex<BinaryHeap<NodeJsPoolProcess>>>,\n-    idle_process_semaphore: Arc<Semaphore>,\n+    idle_processes: Arc<HeapQueue<NodeJsPoolProcess>>,\n     start: Instant,\n     stats: Arc<Mutex<NodeJsPoolStats>>,\n     allow_process_reuse: bool,\n@@ -1005,14 +980,7 @@ impl Drop for NodeJsOperation {\n             }\n             if self.allow_process_reuse {\n                 process.cpu_time_invested += elapsed;\n-                {\n-                    let mut processes = self.processes.lock();\n-                    if processes.is_empty() {\n-                        ACTIVE_POOLS.lock().push(self.processes.clone());\n-                    }\n-                    processes.push(process);\n-                }\n-                self.idle_process_semaphore.add_permits(1);\n+                self.idle_processes.push(process, &ACTIVE_POOLS);\n             }\n         }\n     }"
        }
    ],
    "stats": {
        "total": 148,
        "additions": 102,
        "deletions": 46
    }
}