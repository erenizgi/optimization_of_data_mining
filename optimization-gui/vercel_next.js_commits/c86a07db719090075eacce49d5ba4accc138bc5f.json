{
    "author": "sokra",
    "message": "Turbopack: Streaming write of SST files (#82048)\n\n### What?\n\nWrite SST while processing blocks to avoid keeping all blocks in memory. Reduces temporary memory used by persisting.",
    "sha": "c86a07db719090075eacce49d5ba4accc138bc5f",
    "files": [
        {
            "sha": "25fbe6d31201b799d46c5aa4d18d3409b8cf6e29",
            "filename": "turbopack/crates/turbo-persistence-tools/src/main.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -31,8 +31,8 @@ fn main() -> Result<()> {\n             sequence_number,\n             min_hash,\n             max_hash,\n-            aqmf_size,\n-            aqmf_entries,\n+            amqf_size,\n+            amqf_entries,\n             sst_size,\n             key_compression_dictionary_size,\n             value_compression_dictionary_size,\n@@ -43,7 +43,7 @@ fn main() -> Result<()> {\n                 \"  SST {sequence_number:08}.sst: {min_hash:016x} - {max_hash:016x} (p = 1/{})\",\n                 u64::MAX / (max_hash - min_hash + 1)\n             );\n-            println!(\"    AQMF {aqmf_entries} entries = {} KiB\", aqmf_size / 1024);\n+            println!(\"    AMQF {amqf_entries} entries = {} KiB\", amqf_size / 1024);\n             println!(\n                 \"    {} KiB = {} kiB key compression dict + {} KiB value compression dict + \\\n                  {block_count} blocks (avg {} bytes/block)\","
        },
        {
            "sha": "93d97ab052ad680710b84cdeabfaf780b64bea51",
            "filename": "turbopack/crates/turbo-persistence/README.md",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -21,7 +21,7 @@ There are four different file types:\n - Static Sorted Table (SST, `*.sst`): These files contain key value pairs.\n - Blob files (`*.blob`): These files contain large values.\n - Delete files (`*.del`): These files contain a list of sequence numbers of files that should be considered as deleted.\n-- Meta files (`*.meta`): These files contain metadata about the SST files. They contains the hash range and a AQMF for quick filtering.\n+- Meta files (`*.meta`): These files contain metadata about the SST files. They contains the hash range and a AMQF for quick filtering.\n \n Therefore there are there value types:\n \n@@ -50,9 +50,9 @@ A meta file can contain metadata about multiple SST files. The metadata is store\n     - 8 bytes min hash\n     - 8 bytes max hash\n     - 8 bytes SST file size\n-    - 4 bytes end of AQMF offset relative to start of all AQMF data\n+    - 4 bytes end of AMQF offset relative to start of all AMQF data\n - foreach described SST file\n-  - serialized AQMF\n+  - serialized AMQF\n \n ### SST file\n \n@@ -139,7 +139,7 @@ Reading start from the current sequence number and goes downwards.\n \n - We have all SST files memory mapped\n - for i = CURRENT sequence number .. 0\n-  - Check AQMF from SST file for key existance -> if not continue\n+  - Check AMQF from SST file for key existance -> if not continue\n   - let block = 0\n   - loop\n     - Index Block: find key range that contains the key by binary search"
        },
        {
            "sha": "7fb697bdff6642b4d529a11d7a302c3d5f9092d3",
            "filename": "turbopack/crates/turbo-persistence/src/constants.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fconstants.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fconstants.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fconstants.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -21,9 +21,9 @@ pub const DATA_THRESHOLD_PER_COMPACTED_FILE: usize = 256 * 1024 * 1024;\n /// MAX_ENTRIES_PER_INITIAL_FILE and DATA_THRESHOLD_PER_INITIAL_FILE.\n pub const THREAD_LOCAL_SIZE_SHIFT: usize = 7;\n \n-/// Maximum RAM bytes for AQMF cache\n-pub const AQMF_CACHE_SIZE: u64 = 300 * 1024 * 1024;\n-pub const AQMF_AVG_SIZE: usize = 37399;\n+/// Maximum RAM bytes for AMQF cache\n+pub const AMQF_CACHE_SIZE: u64 = 300 * 1024 * 1024;\n+pub const AMQF_AVG_SIZE: usize = 37399;\n \n /// Maximum RAM bytes for key block cache\n pub const KEY_BLOCK_CACHE_SIZE: u64 = 400 * 1024 * 1024;"
        },
        {
            "sha": "4ba703fa75ea59f67cc0d0c3af8fadc90b076b99",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 24,
            "deletions": 25,
            "changes": 49,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -27,18 +27,18 @@ use crate::{\n     arc_slice::ArcSlice,\n     compaction::selector::{Compactable, compute_metrics, get_merge_segments},\n     constants::{\n-        AQMF_AVG_SIZE, AQMF_CACHE_SIZE, DATA_THRESHOLD_PER_COMPACTED_FILE, KEY_BLOCK_AVG_SIZE,\n+        AMQF_AVG_SIZE, AMQF_CACHE_SIZE, DATA_THRESHOLD_PER_COMPACTED_FILE, KEY_BLOCK_AVG_SIZE,\n         KEY_BLOCK_CACHE_SIZE, MAX_ENTRIES_PER_COMPACTED_FILE, VALUE_BLOCK_AVG_SIZE,\n         VALUE_BLOCK_CACHE_SIZE,\n     },\n     key::{StoreKey, hash_key},\n     lookup_entry::{LookupEntry, LookupValue},\n     merge_iter::MergeIter,\n-    meta_file::{AqmfCache, MetaFile, MetaLookupResult, StaticSortedFileRange},\n+    meta_file::{AmqfCache, MetaFile, MetaLookupResult, StaticSortedFileRange},\n     meta_file_builder::MetaFileBuilder,\n     sst_filter::SstFilter,\n     static_sorted_file::{BlockCache, SstLookupResult},\n-    static_sorted_file_builder::{StaticSortedFileBuilder, StaticSortedFileBuilderMeta},\n+    static_sorted_file_builder::{StaticSortedFileBuilderMeta, write_static_stored_file},\n     write_batch::{FinishResult, WriteBatch},\n };\n \n@@ -84,12 +84,12 @@ pub struct Statistics {\n     pub sst_files: usize,\n     pub key_block_cache: CacheStatistics,\n     pub value_block_cache: CacheStatistics,\n-    pub aqmf_cache: CacheStatistics,\n+    pub amqf_cache: CacheStatistics,\n     pub hits: u64,\n     pub misses: u64,\n     pub miss_family: u64,\n     pub miss_range: u64,\n-    pub miss_aqmf: u64,\n+    pub miss_amqf: u64,\n     pub miss_key: u64,\n }\n \n@@ -101,7 +101,7 @@ struct TrackedStats {\n     hits_blob: std::sync::atomic::AtomicU64,\n     miss_family: std::sync::atomic::AtomicU64,\n     miss_range: std::sync::atomic::AtomicU64,\n-    miss_aqmf: std::sync::atomic::AtomicU64,\n+    miss_amqf: std::sync::atomic::AtomicU64,\n     miss_key: std::sync::atomic::AtomicU64,\n     miss_global: std::sync::atomic::AtomicU64,\n }\n@@ -119,8 +119,8 @@ pub struct TurboPersistence {\n     /// A flag to indicate if a write operation is currently active. Prevents multiple concurrent\n     /// write operations.\n     active_write_operation: AtomicBool,\n-    /// A cache for deserialized AQMF filters.\n-    aqmf_cache: AqmfCache,\n+    /// A cache for deserialized AMQF filters.\n+    amqf_cache: AmqfCache,\n     /// A cache for decompressed key blocks.\n     key_block_cache: BlockCache,\n     /// A cache for decompressed value blocks.\n@@ -158,9 +158,9 @@ impl TurboPersistence {\n                 current_sequence_number: 0,\n             }),\n             active_write_operation: AtomicBool::new(false),\n-            aqmf_cache: AqmfCache::with(\n-                AQMF_CACHE_SIZE as usize / AQMF_AVG_SIZE,\n-                AQMF_CACHE_SIZE,\n+            amqf_cache: AmqfCache::with(\n+                AMQF_CACHE_SIZE as usize / AMQF_AVG_SIZE,\n+                AMQF_CACHE_SIZE,\n                 Default::default(),\n                 Default::default(),\n                 Default::default(),\n@@ -876,11 +876,11 @@ impl TurboPersistence {\n                             let index_in_meta = ssts_with_ranges[index].index_in_meta;\n                             let meta_file = &meta_files[meta_index];\n                             let entry = meta_file.entry(index_in_meta);\n-                            let aqmf = Cow::Borrowed(entry.raw_aqmf(meta_file.aqmf_data()));\n+                            let amqf = Cow::Borrowed(entry.raw_amqf(meta_file.amqf_data()));\n                             let meta = StaticSortedFileBuilderMeta {\n                                 min_hash: entry.min_hash(),\n                                 max_hash: entry.max_hash(),\n-                                aqmf,\n+                                amqf,\n                                 key_compression_dictionary_length: entry\n                                     .key_compression_dictionary_length(),\n                                 value_compression_dictionary_length: entry\n@@ -904,13 +904,12 @@ impl TurboPersistence {\n                         ) -> Result<(u32, File, StaticSortedFileBuilderMeta<'static>)>\n                         {\n                             let _span = tracing::trace_span!(\"write merged sst file\").entered();\n-                            let builder = StaticSortedFileBuilder::new(\n+                            let (meta, file) = write_static_stored_file(\n                                 entries,\n                                 total_key_size,\n                                 total_value_size,\n+                                &path.join(format!(\"{seq:08}.sst\")),\n                             )?;\n-                            let (meta, file) =\n-                                builder.write(&path.join(format!(\"{seq:08}.sst\")))?;\n                             Ok((seq, file, meta))\n                         }\n \n@@ -1148,7 +1147,7 @@ impl TurboPersistence {\n                 family as u32,\n                 hash,\n                 key,\n-                &self.aqmf_cache,\n+                &self.amqf_cache,\n                 &self.key_block_cache,\n                 &self.value_block_cache,\n             )? {\n@@ -1162,7 +1161,7 @@ impl TurboPersistence {\n                 }\n                 MetaLookupResult::QuickFilterMiss => {\n                     #[cfg(feature = \"stats\")]\n-                    self.stats.miss_aqmf.fetch_add(1, Ordering::Relaxed);\n+                    self.stats.miss_amqf.fetch_add(1, Ordering::Relaxed);\n                 }\n                 MetaLookupResult::SstLookup(result) => match result {\n                     SstLookupResult::Found(result) => match result {\n@@ -1204,14 +1203,14 @@ impl TurboPersistence {\n             sst_files: inner.meta_files.iter().map(|m| m.entries().len()).sum(),\n             key_block_cache: CacheStatistics::new(&self.key_block_cache),\n             value_block_cache: CacheStatistics::new(&self.value_block_cache),\n-            aqmf_cache: CacheStatistics::new(&self.aqmf_cache),\n+            amqf_cache: CacheStatistics::new(&self.amqf_cache),\n             hits: self.stats.hits_deleted.load(Ordering::Relaxed)\n                 + self.stats.hits_small.load(Ordering::Relaxed)\n                 + self.stats.hits_blob.load(Ordering::Relaxed),\n             misses: self.stats.miss_global.load(Ordering::Relaxed),\n             miss_family: self.stats.miss_family.load(Ordering::Relaxed),\n             miss_range: self.stats.miss_range.load(Ordering::Relaxed),\n-            miss_aqmf: self.stats.miss_aqmf.load(Ordering::Relaxed),\n+            miss_amqf: self.stats.miss_amqf.load(Ordering::Relaxed),\n             miss_key: self.stats.miss_key.load(Ordering::Relaxed),\n         }\n     }\n@@ -1228,14 +1227,14 @@ impl TurboPersistence {\n                     .entries()\n                     .iter()\n                     .map(|entry| {\n-                        let aqmf = entry.raw_aqmf(meta_file.aqmf_data());\n+                        let amqf = entry.raw_amqf(meta_file.amqf_data());\n                         MetaFileEntryInfo {\n                             sequence_number: entry.sequence_number(),\n                             min_hash: entry.min_hash(),\n                             max_hash: entry.max_hash(),\n                             sst_size: entry.size(),\n-                            aqmf_size: entry.aqmf_size(),\n-                            aqmf_entries: aqmf.len(),\n+                            amqf_size: entry.amqf_size(),\n+                            amqf_entries: amqf.len(),\n                             key_compression_dictionary_size: entry\n                                 .key_compression_dictionary_length(),\n                             value_compression_dictionary_size: entry\n@@ -1273,8 +1272,8 @@ pub struct MetaFileEntryInfo {\n     pub sequence_number: u32,\n     pub min_hash: u64,\n     pub max_hash: u64,\n-    pub aqmf_size: u32,\n-    pub aqmf_entries: usize,\n+    pub amqf_size: u32,\n+    pub amqf_entries: usize,\n     pub sst_size: u64,\n     pub key_compression_dictionary_size: u16,\n     pub value_compression_dictionary_size: u16,"
        },
        {
            "sha": "871cccd3cd512553fed62ff036d625570c5001c0",
            "filename": "turbopack/crates/turbo-persistence/src/meta_file.rs",
            "status": "modified",
            "additions": 47,
            "deletions": 47,
            "changes": 94,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -20,16 +20,16 @@ use crate::{\n };\n \n #[derive(Clone, Default)]\n-pub struct AqmfWeighter;\n+pub struct AmqfWeighter;\n \n-impl quick_cache::Weighter<u32, Arc<qfilter::Filter>> for AqmfWeighter {\n+impl quick_cache::Weighter<u32, Arc<qfilter::Filter>> for AmqfWeighter {\n     fn weight(&self, _key: &u32, filter: &Arc<qfilter::Filter>) -> u64 {\n         filter.capacity() + 1\n     }\n }\n \n-pub type AqmfCache =\n-    quick_cache::sync::Cache<u32, Arc<qfilter::Filter>, AqmfWeighter, BuildHasherDefault<FxHasher>>;\n+pub type AmqfCache =\n+    quick_cache::sync::Cache<u32, Arc<qfilter::Filter>, AmqfWeighter, BuildHasherDefault<FxHasher>>;\n \n pub struct MetaEntry {\n     /// The metadata for the static sorted file.\n@@ -42,15 +42,15 @@ pub struct MetaEntry {\n     max_hash: u64,\n     /// The size of the SST file in bytes.\n     size: u64,\n-    /// The offset of the start of the AQMF data in the meta file relative to the end of the\n+    /// The offset of the start of the AMQF data in the meta file relative to the end of the\n     /// header.\n-    start_of_aqmf_data_offset: u32,\n-    /// The offset of the end of the AQMF data in the the meta file relative to the end of the\n+    start_of_amqf_data_offset: u32,\n+    /// The offset of the end of the AMQF data in the the meta file relative to the end of the\n     /// header.\n-    end_of_aqmf_data_offset: u32,\n-    /// The AQMF filter of this file. This is only used if the range is very large. Smaller ranges\n-    /// use the AQMF cache instead.\n-    aqmf: OnceLock<qfilter::Filter>,\n+    end_of_amqf_data_offset: u32,\n+    /// The AMQF filter of this file. This is only used if the range is very large. Smaller ranges\n+    /// use the AMQF cache instead.\n+    amqf: OnceLock<qfilter::Filter>,\n     /// The static sorted file that is lazily loaded\n     sst: OnceLock<StaticSortedFile>,\n }\n@@ -64,51 +64,51 @@ impl MetaEntry {\n         self.size\n     }\n \n-    pub fn aqmf_size(&self) -> u32 {\n-        self.end_of_aqmf_data_offset - self.start_of_aqmf_data_offset\n+    pub fn amqf_size(&self) -> u32 {\n+        self.end_of_amqf_data_offset - self.start_of_amqf_data_offset\n     }\n \n-    pub fn raw_aqmf<'l>(&self, aqmf_data: &'l [u8]) -> &'l [u8] {\n-        aqmf_data\n-            .get(self.start_of_aqmf_data_offset as usize..self.end_of_aqmf_data_offset as usize)\n-            .expect(\"AQMF data out of bounds\")\n+    pub fn raw_amqf<'l>(&self, amqf_data: &'l [u8]) -> &'l [u8] {\n+        amqf_data\n+            .get(self.start_of_amqf_data_offset as usize..self.end_of_amqf_data_offset as usize)\n+            .expect(\"AMQF data out of bounds\")\n     }\n \n-    pub fn deserialize_aqmf(&self, meta: &MetaFile) -> Result<qfilter::Filter> {\n-        let aqmf = self.raw_aqmf(meta.aqmf_data());\n-        pot::from_slice(aqmf).with_context(|| {\n+    pub fn deserialize_amqf(&self, meta: &MetaFile) -> Result<qfilter::Filter> {\n+        let amqf = self.raw_amqf(meta.amqf_data());\n+        pot::from_slice(amqf).with_context(|| {\n             format!(\n-                \"Failed to deserialize AQMF from {:08}.meta for {:08}.sst\",\n+                \"Failed to deserialize AMQF from {:08}.meta for {:08}.sst\",\n                 meta.sequence_number,\n                 self.sequence_number()\n             )\n         })\n     }\n \n-    pub fn aqmf(\n+    pub fn amqf(\n         &self,\n         meta: &MetaFile,\n-        aqmf_cache: &AqmfCache,\n+        amqf_cache: &AmqfCache,\n     ) -> Result<impl Deref<Target = qfilter::Filter>> {\n-        let use_aqmf_cache = self.max_hash - self.min_hash < 1 << 60;\n-        Ok(if use_aqmf_cache {\n-            let aqmf = match aqmf_cache.get_value_or_guard(&self.sequence_number(), None) {\n-                GuardResult::Value(aqmf) => aqmf,\n+        let use_amqf_cache = self.max_hash - self.min_hash < 1 << 60;\n+        Ok(if use_amqf_cache {\n+            let amqf = match amqf_cache.get_value_or_guard(&self.sequence_number(), None) {\n+                GuardResult::Value(amqf) => amqf,\n                 GuardResult::Guard(guard) => {\n-                    let aqmf = self.deserialize_aqmf(meta)?;\n-                    let aqmf: Arc<qfilter::Filter> = Arc::new(aqmf);\n-                    let _ = guard.insert(aqmf.clone());\n-                    aqmf\n+                    let amqf = self.deserialize_amqf(meta)?;\n+                    let amqf: Arc<qfilter::Filter> = Arc::new(amqf);\n+                    let _ = guard.insert(amqf.clone());\n+                    amqf\n                 }\n                 GuardResult::Timeout => unreachable!(),\n             };\n-            Either::Left(aqmf)\n+            Either::Left(amqf)\n         } else {\n-            let aqmf = self.aqmf.get_or_try_init(|| {\n-                let aqmf = self.deserialize_aqmf(meta)?;\n-                anyhow::Ok(aqmf)\n+            let amqf = self.amqf.get_or_try_init(|| {\n+                let amqf = self.deserialize_amqf(meta)?;\n+                anyhow::Ok(amqf)\n             })?;\n-            Either::Right(aqmf)\n+            Either::Right(amqf)\n         })\n     }\n \n@@ -160,9 +160,9 @@ pub enum MetaLookupResult {\n     /// The key was not found because it is out of the range of this SST file. But it was the\n     /// correct key family.\n     RangeMiss,\n-    /// The key was not found because it was not in the AQMF filter. But it was in the range.\n+    /// The key was not found because it was not in the AMQF filter. But it was in the range.\n     QuickFilterMiss,\n-    /// The key was looked up in the SST file. It was in the AQMF filter.\n+    /// The key was looked up in the SST file. It was in the AMQF filter.\n     SstLookup(SstLookupResult),\n }\n \n@@ -216,7 +216,7 @@ impl MetaFile {\n         }\n         let count = file.read_u32::<BE>()?;\n         let mut entries = Vec::with_capacity(count as usize);\n-        let mut start_of_aqmf_data_offset = 0;\n+        let mut start_of_amqf_data_offset = 0;\n         for _ in 0..count {\n             let entry = MetaEntry {\n                 sst_data: StaticSortedFileMetaData {\n@@ -229,12 +229,12 @@ impl MetaFile {\n                 min_hash: file.read_u64::<BE>()?,\n                 max_hash: file.read_u64::<BE>()?,\n                 size: file.read_u64::<BE>()?,\n-                start_of_aqmf_data_offset,\n-                end_of_aqmf_data_offset: file.read_u32::<BE>()?,\n-                aqmf: OnceLock::new(),\n+                start_of_amqf_data_offset,\n+                end_of_amqf_data_offset: file.read_u32::<BE>()?,\n+                amqf: OnceLock::new(),\n                 sst: OnceLock::new(),\n             };\n-            start_of_aqmf_data_offset = entry.end_of_aqmf_data_offset;\n+            start_of_amqf_data_offset = entry.end_of_amqf_data_offset;\n             entries.push(entry);\n         }\n         let offset = file.stream_position()?;\n@@ -273,7 +273,7 @@ impl MetaFile {\n         &self.entries[index]\n     }\n \n-    pub fn aqmf_data(&self) -> &[u8] {\n+    pub fn amqf_data(&self) -> &[u8] {\n         &self.mmap\n     }\n \n@@ -307,7 +307,7 @@ impl MetaFile {\n         key_family: u32,\n         key_hash: u64,\n         key: &K,\n-        aqmf_cache: &AqmfCache,\n+        amqf_cache: &AmqfCache,\n         key_block_cache: &BlockCache,\n         value_block_cache: &BlockCache,\n     ) -> Result<MetaLookupResult> {\n@@ -320,8 +320,8 @@ impl MetaFile {\n                 continue;\n             }\n             {\n-                let aqmf = entry.aqmf(self, aqmf_cache)?;\n-                if !aqmf.contains_fingerprint(key_hash) {\n+                let amqf = entry.amqf(self, amqf_cache)?;\n+                if !amqf.contains_fingerprint(key_hash) {\n                     miss_result = MetaLookupResult::QuickFilterMiss;\n                     continue;\n                 }"
        },
        {
            "sha": "afa402ac684735fe032f06247c47bffa06465d59",
            "filename": "turbopack/crates/turbo-persistence/src/meta_file_builder.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -54,7 +54,7 @@ impl<'a> MetaFileBuilder<'a> {\n \n         file.write_u32::<BE>(self.entries.len() as u32)?;\n \n-        let mut aqmf_offset = 0;\n+        let mut amqf_offset = 0;\n         for (sequence_number, sst) in &self.entries {\n             file.write_u32::<BE>(*sequence_number)?;\n             file.write_u16::<BE>(sst.key_compression_dictionary_length)?;\n@@ -63,12 +63,12 @@ impl<'a> MetaFileBuilder<'a> {\n             file.write_u64::<BE>(sst.min_hash)?;\n             file.write_u64::<BE>(sst.max_hash)?;\n             file.write_u64::<BE>(sst.size)?;\n-            aqmf_offset += sst.aqmf.len();\n-            file.write_u32::<BE>(aqmf_offset as u32)?;\n+            amqf_offset += sst.amqf.len();\n+            file.write_u32::<BE>(amqf_offset as u32)?;\n         }\n \n         for (_, sst) in &self.entries {\n-            file.write_all(&sst.aqmf)?;\n+            file.write_all(&sst.amqf)?;\n         }\n         Ok(file.into_inner()?)\n     }"
        },
        {
            "sha": "74f3776797263bedad3ab14bf6d53ed5561860b3",
            "filename": "turbopack/crates/turbo-persistence/src/static_sorted_file_builder.rs",
            "status": "modified",
            "additions": 440,
            "deletions": 359,
            "changes": 799,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -1,8 +1,8 @@\n use std::{\n     borrow::Cow,\n-    cmp::{max, min},\n+    cmp::min,\n     fs::File,\n-    io::{self, BufWriter, Seek, Write},\n+    io::{BufWriter, Seek, Write},\n     path::Path,\n };\n \n@@ -26,8 +26,8 @@ const KEY_BLOCK_ENTRY_META_OVERHEAD: usize = 8;\n const MAX_SMALL_VALUE_BLOCK_ENTRIES: usize = 100 * 1024;\n /// The maximum bytes that should go into a single small value block\n const MAX_SMALL_VALUE_BLOCK_SIZE: usize = 16 * 1024;\n-/// The aimed false positive rate for the AQMF\n-const AQMF_FALSE_POSITIVE_RATE: f64 = 0.01;\n+/// The aimed false positive rate for the AMQF\n+const AMQF_FALSE_POSITIVE_RATE: f64 = 0.01;\n \n /// The maximum compression dictionary size for value blocks\n const VALUE_COMPRESSION_DICTIONARY_SIZE: usize = 64 * 1024 - 1;\n@@ -80,8 +80,8 @@ pub struct StaticSortedFileBuilderMeta<'a> {\n     pub min_hash: u64,\n     /// The maximum hash of the keys in the SST file\n     pub max_hash: u64,\n-    /// The AQMF data\n-    pub aqmf: Cow<'a, [u8]>,\n+    /// The AMQF data\n+    pub amqf: Cow<'a, [u8]>,\n     /// The key compression dictionary\n     pub key_compression_dictionary_length: u16,\n     /// The value compression dictionary\n@@ -94,387 +94,464 @@ pub struct StaticSortedFileBuilderMeta<'a> {\n     pub entries: u64,\n }\n \n-#[derive(Debug, Default)]\n-pub struct StaticSortedFileBuilder<'a> {\n-    aqmf: Cow<'a, [u8]>,\n-    key_compression_dictionary: Vec<u8>,\n-    value_compression_dictionary: Vec<u8>,\n-    blocks: Vec<(u32, Vec<u8>)>,\n-    min_hash: u64,\n-    max_hash: u64,\n-    entries: u64,\n-}\n-\n-impl<'a> StaticSortedFileBuilder<'a> {\n-    pub fn new<E: Entry>(\n-        entries: &[E],\n-        total_key_size: usize,\n-        total_value_size: usize,\n-    ) -> Result<Self> {\n-        debug_assert!(entries.iter().map(|e| e.key_hash()).is_sorted());\n-        let mut builder = Self {\n-            min_hash: entries.first().map(|e| e.key_hash()).unwrap_or(u64::MAX),\n-            max_hash: entries.last().map(|e| e.key_hash()).unwrap_or(0),\n-            entries: entries.len() as u64,\n-            ..Default::default()\n-        };\n-        builder.compute_aqmf(entries);\n-        builder.compute_compression_dictionary(entries, total_key_size, total_value_size)?;\n-        builder.compute_blocks(entries);\n-        Ok(builder)\n+pub fn write_static_stored_file<E: Entry>(\n+    entries: &[E],\n+    total_key_size: usize,\n+    total_value_size: usize,\n+    file: &Path,\n+) -> Result<(StaticSortedFileBuilderMeta<'static>, File)> {\n+    debug_assert!(entries.iter().map(|e| e.key_hash()).is_sorted());\n+\n+    let mut file = BufWriter::new(File::create(file)?);\n+\n+    let capacity = get_compression_buffer_capacity(total_key_size, total_value_size);\n+    // We use a shared buffer for all operations to avoid excessive allocations\n+    let mut buffer = Vec::with_capacity(capacity);\n+\n+    let key_dict = compute_key_compression_dictionary(entries, total_key_size, &mut buffer)?;\n+    let value_dict = compute_value_compression_dictionary(entries, total_value_size, &mut buffer)?;\n+    file.write_all(&key_dict)?;\n+    file.write_all(&value_dict)?;\n+\n+    let mut block_writer = BlockWriter::new(&mut file, &mut buffer);\n+\n+    // Another shared buffer for the uncompressed blocks\n+    // The existing shared buffer will be used for compressed blocks\n+    // So we need both\n+    let mut buffer = Vec::new();\n+\n+    let min_hash = entries.first().map_or(u64::MAX, |e| e.key_hash());\n+    let value_locations = write_value_blocks(entries, &value_dict, &mut block_writer, &mut buffer)\n+        .context(\"Failed to write value blocks\")?;\n+    let amqf = write_key_blocks_and_compute_amqf(\n+        entries,\n+        &value_locations,\n+        &key_dict,\n+        &mut block_writer,\n+        &mut buffer,\n+    )\n+    .context(\"Failed to write key blocks\")?;\n+    let max_hash = entries.last().map_or(0, |e| e.key_hash());\n+\n+    let block_count = block_writer.block_count();\n+    for offset in &block_writer.block_offsets {\n+        file.write_u32::<BE>(*offset)\n+            .context(\"Failed to write block offset\")?;\n     }\n \n-    /// Computes a AQMF from the keys of all entries.\n-    #[tracing::instrument(level = \"trace\", skip_all)]\n-    fn compute_aqmf<E: Entry>(&mut self, entries: &[E]) {\n-        let mut filter = qfilter::Filter::new(entries.len() as u64, AQMF_FALSE_POSITIVE_RATE)\n-            // This won't fail as we limit the number of entries per SST file\n-            .expect(\"Filter can't be constructed\");\n-        for entry in entries {\n-            filter\n-                .insert_fingerprint(false, entry.key_hash())\n-                // This can't fail as we allocated enough capacity\n-                .expect(\"AQMF insert failed\");\n-        }\n-        for entry in entries {\n-            debug_assert!(filter.contains_fingerprint(entry.key_hash()));\n-        }\n-        self.aqmf = Cow::Owned(pot::to_vec(&filter).expect(\"AQMF serialization failed\"));\n-    }\n+    let meta = StaticSortedFileBuilderMeta {\n+        min_hash,\n+        max_hash,\n+        amqf: Cow::Owned(amqf),\n+        key_compression_dictionary_length: key_dict.len().try_into().unwrap(),\n+        value_compression_dictionary_length: value_dict.len().try_into().unwrap(),\n+        block_count,\n+        size: file.stream_position()?,\n+        entries: entries.len() as u64,\n+    };\n+    Ok((meta, file.into_inner()?))\n+}\n \n-    /// Computes compression dictionaries from keys and values of all entries\n-    #[tracing::instrument(level = \"trace\", skip_all)]\n-    fn compute_compression_dictionary<E: Entry>(\n-        &mut self,\n-        entries: &[E],\n-        total_key_size: usize,\n-        total_value_size: usize,\n-    ) -> Result<()> {\n-        if total_key_size < MIN_KEY_COMPRESSION_SAMPLES_SIZE\n-            && total_value_size < MIN_VALUE_COMPRESSION_SAMPLES_SIZE\n-        {\n-            return Ok(());\n-        }\n+fn get_compression_buffer_capacity(total_key_size: usize, total_value_size: usize) -> usize {\n+    let mut size = 0;\n+    if total_key_size >= MIN_KEY_COMPRESSION_SAMPLES_SIZE {\n         let key_compression_samples_size = min(KEY_COMPRESSION_SAMPLES_SIZE, total_key_size / 16);\n+        size = key_compression_samples_size;\n+    }\n+    if total_value_size >= MIN_VALUE_COMPRESSION_SAMPLES_SIZE {\n         let value_compression_samples_size =\n             min(VALUE_COMPRESSION_SAMPLES_SIZE, total_value_size / 16);\n-        let mut value_samples = Vec::with_capacity(value_compression_samples_size);\n-        let mut value_sample_sizes = Vec::new();\n-        let mut key_samples = Vec::with_capacity(key_compression_samples_size);\n-        let mut key_sample_sizes = Vec::new();\n-\n-        // Limit the number of iterations to avoid infinite loops\n-        let max_iterations =\n-            max(total_key_size, total_value_size) / COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY * 2;\n-        for i in 0..max_iterations {\n-            let entry = &entries[i % entries.len()];\n-            let value_remaining = value_compression_samples_size - value_samples.len();\n-            if value_remaining < MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n-                break;\n-            }\n-            if let EntryValue::Small { value } | EntryValue::Medium { value } = entry.value() {\n-                let len = value.len();\n-                if len >= MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n-                    let used_len = min(value_remaining, COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY);\n-                    if len <= used_len {\n-                        value_sample_sizes.push(len);\n-                        value_samples.extend_from_slice(value);\n-                    } else {\n-                        value_sample_sizes.push(used_len);\n-                        let p = value_samples.len() % (len - used_len);\n-                        value_samples.extend_from_slice(&value[p..p + used_len]);\n-                    };\n-                }\n-            }\n+        size = size.max(value_compression_samples_size);\n+    }\n+    size\n+}\n+\n+/// Computes compression dictionaries from keys of all entries\n+#[tracing::instrument(level = \"trace\", skip(entries))]\n+fn compute_key_compression_dictionary<E: Entry>(\n+    entries: &[E],\n+    total_key_size: usize,\n+    buffer: &mut Vec<u8>,\n+) -> Result<Vec<u8>> {\n+    if total_key_size < MIN_KEY_COMPRESSION_SAMPLES_SIZE {\n+        return Ok(Vec::new());\n+    }\n+    let key_compression_samples_size = min(KEY_COMPRESSION_SAMPLES_SIZE, total_key_size / 16);\n+    let mut sample_sizes = Vec::new();\n+\n+    // Limit the number of iterations to avoid infinite loops\n+    let max_iterations = total_key_size / COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY * 2;\n+    for i in 0..max_iterations {\n+        let entry = &entries[i % entries.len()];\n+        let key_remaining = key_compression_samples_size - buffer.len();\n+        if key_remaining < MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n+            break;\n         }\n-        assert!(value_samples.len() == value_sample_sizes.iter().sum::<usize>());\n-        if value_samples.len() > MIN_VALUE_COMPRESSION_SAMPLES_SIZE && value_sample_sizes.len() > 5\n-        {\n-            self.value_compression_dictionary = zstd::dict::from_continuous(\n-                &value_samples,\n-                &value_sample_sizes,\n-                VALUE_COMPRESSION_DICTIONARY_SIZE,\n-            )\n-            .context(\"Value dictionary creation failed\")?;\n-        } else {\n-            self.value_compression_dictionary = Vec::new();\n+        let len = entry.key_len();\n+        if len >= MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n+            let used_len = min(key_remaining, COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY);\n+            if len <= used_len {\n+                sample_sizes.push(len);\n+                entry.write_key_to(buffer);\n+            } else {\n+                let mut temp = Vec::with_capacity(len);\n+                entry.write_key_to(&mut temp);\n+                debug_assert!(temp.len() == len);\n+\n+                let p = buffer.len() % (len - used_len);\n+                sample_sizes.push(used_len);\n+                buffer.extend_from_slice(&temp[p..p + used_len]);\n+            }\n         }\n+    }\n+    debug_assert!(buffer.len() == sample_sizes.iter().sum::<usize>());\n+    let result = if buffer.len() > MIN_KEY_COMPRESSION_SAMPLES_SIZE && sample_sizes.len() > 5 {\n+        zstd::dict::from_continuous(buffer, &sample_sizes, KEY_COMPRESSION_DICTIONARY_SIZE)\n+            .context(\"Key dictionary creation failed\")?\n+    } else {\n+        Vec::new()\n+    };\n+    buffer.clear();\n+    Ok(result)\n+}\n \n-        for i in 0..max_iterations {\n-            let entry = &entries[i % entries.len()];\n-            let key_remaining = key_compression_samples_size - key_samples.len();\n-            if key_remaining < MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n-                break;\n-            }\n-            let len = entry.key_len();\n+/// Computes compression dictionaries from values of all entries\n+#[tracing::instrument(level = \"trace\", skip(entries))]\n+fn compute_value_compression_dictionary<E: Entry>(\n+    entries: &[E],\n+    total_value_size: usize,\n+    buffer: &mut Vec<u8>,\n+) -> Result<Vec<u8>> {\n+    if total_value_size < MIN_VALUE_COMPRESSION_SAMPLES_SIZE {\n+        return Ok(Vec::new());\n+    }\n+    let value_compression_samples_size = min(VALUE_COMPRESSION_SAMPLES_SIZE, total_value_size / 16);\n+    let mut sample_sizes = Vec::new();\n+\n+    // Limit the number of iterations to avoid infinite loops\n+    let max_iterations = total_value_size / COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY * 2;\n+    for i in 0..max_iterations {\n+        let entry = &entries[i % entries.len()];\n+        let remaining = value_compression_samples_size - buffer.len();\n+        if remaining < MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n+            break;\n+        }\n+        if let EntryValue::Small { value } | EntryValue::Medium { value } = entry.value() {\n+            let len = value.len();\n             if len >= MIN_COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY {\n-                let used_len = min(key_remaining, COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY);\n+                let used_len = min(remaining, COMPRESSION_DICTIONARY_SAMPLE_PER_ENTRY);\n                 if len <= used_len {\n-                    key_sample_sizes.push(len);\n-                    entry.write_key_to(&mut key_samples);\n+                    sample_sizes.push(len);\n+                    buffer.extend_from_slice(value);\n                 } else {\n-                    let mut temp = Vec::with_capacity(len);\n-                    entry.write_key_to(&mut temp);\n-                    debug_assert!(temp.len() == len);\n-\n-                    let p = key_samples.len() % (len - used_len);\n-                    key_sample_sizes.push(used_len);\n-                    key_samples.extend_from_slice(&temp[p..p + used_len]);\n-                }\n+                    sample_sizes.push(used_len);\n+                    let p = buffer.len() % (len - used_len);\n+                    buffer.extend_from_slice(&value[p..p + used_len]);\n+                };\n             }\n         }\n-        assert!(key_samples.len() == key_sample_sizes.iter().sum::<usize>());\n-        if key_samples.len() > MIN_KEY_COMPRESSION_SAMPLES_SIZE && key_sample_sizes.len() > 5 {\n-            self.key_compression_dictionary = zstd::dict::from_continuous(\n-                &key_samples,\n-                &key_sample_sizes,\n-                KEY_COMPRESSION_DICTIONARY_SIZE,\n-            )\n-            .context(\"Key dictionary creation failed\")?;\n+    }\n+    debug_assert!(buffer.len() == sample_sizes.iter().sum::<usize>());\n+    let result = if buffer.len() > MIN_VALUE_COMPRESSION_SAMPLES_SIZE && sample_sizes.len() > 5 {\n+        zstd::dict::from_continuous(buffer, &sample_sizes, VALUE_COMPRESSION_DICTIONARY_SIZE)\n+            .context(\"Value dictionary creation failed\")?\n+    } else {\n+        Vec::new()\n+    };\n+    buffer.clear();\n+    Ok(result)\n+}\n+\n+struct BlockWriter<'l> {\n+    buffer: &'l mut Vec<u8>,\n+    block_offsets: Vec<u32>,\n+    writer: &'l mut BufWriter<File>,\n+}\n+\n+impl<'l> BlockWriter<'l> {\n+    fn new(writer: &'l mut BufWriter<File>, buffer: &'l mut Vec<u8>) -> Self {\n+        Self {\n+            buffer,\n+            block_offsets: Vec::new(),\n+            writer,\n         }\n+    }\n+\n+    fn next_block_index(&mut self) -> u16 {\n+        self.block_offsets\n+            .len()\n+            .try_into()\n+            .expect(\"Block index overflow\")\n+    }\n+\n+    fn block_count(&self) -> u16 {\n+        self.block_offsets\n+            .len()\n+            .try_into()\n+            .expect(\"Block count overflow\")\n+    }\n+\n+    #[tracing::instrument(level = \"trace\", skip_all)]\n+    fn write_key_block(&mut self, block: &[u8], dict: &[u8]) -> Result<()> {\n+        self.write_block(block, dict)\n+            .context(\"Failed to write key block\")\n+    }\n+\n+    #[tracing::instrument(level = \"trace\", skip_all)]\n+    fn write_index_block(&mut self, block: &[u8], dict: &[u8]) -> Result<()> {\n+        self.write_block(block, dict)\n+            .context(\"Failed to write index block\")\n+    }\n+\n+    #[tracing::instrument(level = \"trace\", skip_all)]\n+    fn write_value_block(&mut self, block: &[u8], dict: &[u8]) -> Result<()> {\n+        self.write_block(block, dict)\n+            .context(\"Failed to write value block\")\n+    }\n+\n+    fn write_block(&mut self, block: &[u8], dict: &[u8]) -> Result<()> {\n+        let uncompressed_size = block.len().try_into().unwrap();\n+        self.compress_block_into_buffer(block, dict);\n+        let len = (self.buffer.len() + 4).try_into().unwrap();\n+        let offset = self\n+            .block_offsets\n+            .last()\n+            .copied()\n+            .unwrap_or_default()\n+            .checked_add(len)\n+            .expect(\"Block offset overflow\");\n+        self.block_offsets.push(offset);\n+\n+        self.writer\n+            .write_u32::<BE>(uncompressed_size)\n+            .context(\"Failed to write uncompressed size\")?;\n+        self.writer\n+            .write_all(self.buffer)\n+            .context(\"Failed to write compressed block\")?;\n+        self.buffer.clear();\n         Ok(())\n     }\n \n-    /// Compute index, key and value blocks.\n+    /// Compresses a block with a compression dictionary.\n     #[tracing::instrument(level = \"trace\", skip_all)]\n-    fn compute_blocks<E: Entry>(&mut self, entries: &[E]) {\n-        // TODO implement multi level index\n-        // TODO place key and value block near to each other\n-\n-        // For now we use something simple to implement:\n-        // Start with Value blocks\n-        // And then Key blocks\n-        // Last block is Index block\n-\n-        // Store the locations of the values\n-        let mut value_locations: Vec<(u16, u32)> = Vec::with_capacity(entries.len());\n-\n-        // Split the values into blocks\n-        let mut current_block_start = 0;\n-        let mut current_block_count = 0;\n-        let mut current_block_size = 0;\n-        for (i, entry) in entries.iter().enumerate() {\n-            match entry.value() {\n-                EntryValue::Small { value } => {\n-                    if current_block_size + value.len() > MAX_SMALL_VALUE_BLOCK_SIZE\n-                        || current_block_count + 1 >= MAX_SMALL_VALUE_BLOCK_ENTRIES\n-                    {\n-                        let block_index = self.blocks.len().try_into().unwrap();\n-                        let mut block = Vec::with_capacity(current_block_size);\n-                        for j in current_block_start..i {\n-                            if let EntryValue::Small { value } = &entries[j].value() {\n-                                block.extend_from_slice(value);\n-                                value_locations[j].0 = block_index;\n-                            }\n+    fn compress_block_into_buffer(&mut self, block: &[u8], dict: &[u8]) {\n+        let mut compressor =\n+            lzzzz::lz4::Compressor::with_dict(dict).expect(\"LZ4 compressor creation failed\");\n+        self.buffer.reserve(max_compressed_size(block.len()));\n+        compressor\n+            .next_to_vec(block, self.buffer, ACC_LEVEL_DEFAULT)\n+            .expect(\"Compression failed\");\n+    }\n+}\n+\n+/// Splits the values of the entries into blocks and writes them to the writer.\n+#[tracing::instrument(level = \"trace\", skip_all)]\n+fn write_value_blocks(\n+    entries: &[impl Entry],\n+    value_compression_dictionary: &[u8],\n+    writer: &mut BlockWriter<'_>,\n+    buffer: &mut Vec<u8>,\n+) -> Result<Vec<(u16, u32)>> {\n+    let mut value_locations: Vec<(u16, u32)> = Vec::with_capacity(entries.len());\n+\n+    let mut current_block_start = 0;\n+    let mut current_block_count = 0;\n+    let mut current_block_size = 0;\n+    for (i, entry) in entries.iter().enumerate() {\n+        match entry.value() {\n+            EntryValue::Small { value } => {\n+                if current_block_size + value.len() > MAX_SMALL_VALUE_BLOCK_SIZE\n+                    || current_block_count + 1 >= MAX_SMALL_VALUE_BLOCK_ENTRIES\n+                {\n+                    let block_index = writer.next_block_index();\n+                    buffer.reserve(current_block_size);\n+                    for j in current_block_start..i {\n+                        if let EntryValue::Small { value } = &entries[j].value() {\n+                            buffer.extend_from_slice(value);\n+                            value_locations[j].0 = block_index;\n                         }\n-                        self.blocks.push(self.compress_value_block(&block));\n-                        current_block_start = i;\n-                        current_block_size = 0;\n-                        current_block_count = 0;\n                     }\n-                    value_locations.push((0, current_block_size.try_into().unwrap()));\n-                    current_block_size += value.len();\n-                    current_block_count += 1;\n-                }\n-                EntryValue::Medium { value } => {\n-                    let block_index = self.blocks.len().try_into().unwrap();\n-                    value_locations.push((block_index, 0));\n-                    self.blocks.push(self.compress_value_block(value));\n-                }\n-                _ => {\n-                    value_locations.push((0, 0));\n+                    writer.write_value_block(buffer, value_compression_dictionary)?;\n+                    buffer.clear();\n+                    current_block_start = i;\n+                    current_block_size = 0;\n+                    current_block_count = 0;\n                 }\n+                value_locations.push((0, current_block_size.try_into().unwrap()));\n+                current_block_size += value.len();\n+                current_block_count += 1;\n+            }\n+            EntryValue::Medium { value } => {\n+                let block_index = writer.next_block_index();\n+                value_locations.push((block_index, 0));\n+                writer.write_value_block(value, value_compression_dictionary)?;\n+            }\n+            _ => {\n+                value_locations.push((0, 0));\n             }\n         }\n-        if current_block_count > 0 {\n-            let block_index = self.blocks.len().try_into().unwrap();\n-            let mut block = Vec::with_capacity(current_block_size);\n-            for j in current_block_start..entries.len() {\n-                if let EntryValue::Small { value } = &entries[j].value() {\n-                    block.extend_from_slice(value);\n-                    value_locations[j].0 = block_index;\n-                }\n+    }\n+    if current_block_count > 0 {\n+        let block_index = writer.next_block_index();\n+        buffer.reserve(current_block_size);\n+        for j in current_block_start..entries.len() {\n+            if let EntryValue::Small { value } = &entries[j].value() {\n+                buffer.extend_from_slice(value);\n+                value_locations[j].0 = block_index;\n             }\n-            self.blocks.push(self.compress_value_block(&block));\n         }\n+        writer.write_value_block(buffer, value_compression_dictionary)?;\n+        buffer.clear();\n+    }\n \n-        let mut key_block_boundaries = Vec::new();\n-\n-        // Split the keys into blocks\n-        fn add_entry_to_block<E: Entry>(\n-            entry: &E,\n-            value_location: &(u16, u32),\n-            block: &mut KeyBlockBuilder,\n-        ) {\n-            match entry.value() {\n-                EntryValue::Small { value } => {\n-                    block.put_small(\n-                        entry,\n-                        value_location.0,\n-                        value_location.1,\n-                        value.len().try_into().unwrap(),\n-                    );\n-                }\n-                EntryValue::Medium { .. } => {\n-                    block.put_medium(entry, value_location.0);\n-                }\n-                EntryValue::Large { blob } => {\n-                    block.put_blob(entry, blob);\n-                }\n-                EntryValue::Deleted => {\n-                    block.delete(entry);\n-                }\n+    Ok(value_locations)\n+}\n+\n+/// Splits the keys of the entries into blocks and writes them to the writer. Also writes an index\n+/// block.\n+#[tracing::instrument(level = \"trace\", skip_all)]\n+fn write_key_blocks_and_compute_amqf(\n+    entries: &[impl Entry],\n+    value_locations: &[(u16, u32)],\n+    key_compression_dictionary: &[u8],\n+    writer: &mut BlockWriter<'_>,\n+    buffer: &mut Vec<u8>,\n+) -> Result<Vec<u8>> {\n+    let mut filter = qfilter::Filter::new(entries.len() as u64, AMQF_FALSE_POSITIVE_RATE)\n+        // This won't fail as we limit the number of entries per SST file\n+        .expect(\"Filter can't be constructed\");\n+\n+    let mut key_block_boundaries = Vec::new();\n+\n+    // Split the keys into blocks\n+    fn add_entry_to_block<E: Entry>(\n+        entry: &E,\n+        value_location: &(u16, u32),\n+        block: &mut KeyBlockBuilder,\n+    ) {\n+        match entry.value() {\n+            EntryValue::Small { value } => {\n+                block.put_small(\n+                    entry,\n+                    value_location.0,\n+                    value_location.1,\n+                    value.len().try_into().unwrap(),\n+                );\n+            }\n+            EntryValue::Medium { .. } => {\n+                block.put_medium(entry, value_location.0);\n+            }\n+            EntryValue::Large { blob } => {\n+                block.put_blob(entry, blob);\n+            }\n+            EntryValue::Deleted => {\n+                block.delete(entry);\n             }\n         }\n-        let mut current_block_start = 0;\n-        let mut current_block_size = 0;\n-        for (i, entry) in entries.iter().enumerate() {\n-            if current_block_size > 0\n+    }\n+    let mut current_block_start = 0;\n+    let mut current_block_size = 0;\n+    let mut last_hash = 0;\n+    for (i, entry) in entries.iter().enumerate() {\n+        let key_hash = entry.key_hash();\n+\n+        // Add to AMQF\n+        filter\n+            .insert_fingerprint(false, key_hash)\n+            // This can't fail as we allocated enough capacity\n+            .expect(\"AMQF insert failed\");\n+\n+        // Accumulate until the block is full\n+        if current_block_size > 0\n                 && (current_block_size + entry.key_len() + KEY_BLOCK_ENTRY_META_OVERHEAD\n                     > MAX_KEY_BLOCK_SIZE\n                     || i - current_block_start >= MAX_KEY_BLOCK_ENTRIES) &&\n                     // avoid breaking the block in the middle of a hash conflict\n-                    entries[i - 1].key_hash() != entry.key_hash()\n-            {\n-                let mut block = KeyBlockBuilder::new((i - current_block_start) as u32);\n-                for j in current_block_start..i {\n-                    let entry = &entries[j];\n-                    let value_location = &value_locations[j];\n-                    add_entry_to_block(entry, value_location, &mut block);\n-                }\n-                key_block_boundaries\n-                    .push((entries[current_block_start].key_hash(), self.blocks.len()));\n-                self.blocks.push(self.compress_key_block(&block.finish()));\n-                current_block_size = 0;\n-                current_block_start = i;\n-            }\n-            current_block_size += entry.key_len() + KEY_BLOCK_ENTRY_META_OVERHEAD;\n-        }\n-        if current_block_size > 0 {\n-            let mut block = KeyBlockBuilder::new((entries.len() - current_block_start) as u32);\n-            for j in current_block_start..entries.len() {\n+                    last_hash != key_hash\n+        {\n+            let mut block = KeyBlockBuilder::new(buffer, (i - current_block_start) as u32);\n+            for j in current_block_start..i {\n                 let entry = &entries[j];\n                 let value_location = &value_locations[j];\n                 add_entry_to_block(entry, value_location, &mut block);\n             }\n-            key_block_boundaries.push((entries[current_block_start].key_hash(), self.blocks.len()));\n-            self.blocks.push(self.compress_key_block(&block.finish()));\n+            key_block_boundaries.push((\n+                entries[current_block_start].key_hash(),\n+                writer.next_block_index(),\n+            ));\n+            block.finish();\n+            writer.write_key_block(buffer, key_compression_dictionary)?;\n+            buffer.clear();\n+            current_block_size = 0;\n+            current_block_start = i;\n         }\n-\n-        // Compute the index\n-        let mut index_block = IndexBlockBuilder::new(\n-            key_block_boundaries.len() as u16,\n-            key_block_boundaries[0].1 as u16,\n-        );\n-        for (hash, block) in &key_block_boundaries[1..] {\n-            index_block.put(*hash, *block as u16);\n-        }\n-        self.blocks\n-            .push(self.compress_key_block(&index_block.finish()));\n+        current_block_size += entry.key_len() + KEY_BLOCK_ENTRY_META_OVERHEAD;\n+        last_hash = key_hash;\n     }\n \n-    /// Compresses a block with a compression dictionary.\n-    fn compress_block(&self, block: &[u8], dict: &[u8]) -> (u32, Vec<u8>) {\n-        let mut compressor =\n-            lzzzz::lz4::Compressor::with_dict(dict).expect(\"LZ4 compressor creation failed\");\n-        let mut compressed = Vec::with_capacity(max_compressed_size(block.len()));\n-        compressor\n-            .next_to_vec(block, &mut compressed, ACC_LEVEL_DEFAULT)\n-            .expect(\"Compression failed\");\n-        if compressed.capacity() > compressed.len() * 2 {\n-            compressed.shrink_to_fit();\n+    // Finish the last block\n+    if current_block_size > 0 {\n+        let mut block = KeyBlockBuilder::new(buffer, (entries.len() - current_block_start) as u32);\n+        for j in current_block_start..entries.len() {\n+            let entry = &entries[j];\n+            let value_location = &value_locations[j];\n+            add_entry_to_block(entry, value_location, &mut block);\n         }\n-        (block.len().try_into().unwrap(), compressed)\n-    }\n-\n-    /// Compresses an index or key block.\n-    #[tracing::instrument(level = \"trace\", skip_all)]\n-    fn compress_key_block(&self, block: &[u8]) -> (u32, Vec<u8>) {\n-        self.compress_block(block, &self.key_compression_dictionary)\n+        key_block_boundaries.push((\n+            entries[current_block_start].key_hash(),\n+            writer.next_block_index(),\n+        ));\n+        block.finish();\n+        writer.write_key_block(buffer, key_compression_dictionary)?;\n+        buffer.clear();\n     }\n \n-    /// Compresses a value block.\n-    #[tracing::instrument(level = \"trace\", skip_all)]\n-    fn compress_value_block(&self, block: &[u8]) -> (u32, Vec<u8>) {\n-        self.compress_block(block, &self.value_compression_dictionary)\n+    // Compute the index\n+    let mut index_block = IndexBlockBuilder::new(\n+        buffer,\n+        key_block_boundaries\n+            .len()\n+            .try_into()\n+            .expect(\"Index entries count overflow\"),\n+        key_block_boundaries[0].1,\n+    );\n+    for (hash, block) in &key_block_boundaries[1..] {\n+        index_block.put(*hash, *block);\n     }\n+    let _ = writer.next_block_index();\n+    index_block.finish();\n+    writer.write_index_block(buffer, key_compression_dictionary)?;\n+    buffer.clear();\n \n-    /// Writes the SST file.\n-    #[tracing::instrument(level = \"trace\", skip_all)]\n-    pub fn write(self, file: &Path) -> io::Result<(StaticSortedFileBuilderMeta<'a>, File)> {\n-        let mut file = BufWriter::new(File::create(file)?);\n-        // Write the key compression dictionary\n-        file.write_all(&self.key_compression_dictionary)?;\n-        // Write the value compression dictionary\n-        file.write_all(&self.value_compression_dictionary)?;\n-\n-        // Write the blocks\n-        let block_count = self.blocks.len().try_into().unwrap();\n-        let mut block_offsets = Vec::with_capacity(self.blocks.len());\n-        let mut offset = 0;\n-        for (uncompressed_size, block) in self.blocks {\n-            // Block length (including the uncompressed length field)\n-            let len = block.len() + 4;\n-            offset += len;\n-            block_offsets.push(offset.try_into().unwrap());\n-            // Uncompressed size\n-            file.write_u32::<BE>(uncompressed_size)?;\n-            // Compressed block\n-            file.write_all(&block)?;\n-        }\n-        // Write the block offsets\n-        for offset in block_offsets {\n-            file.write_u32::<BE>(offset)?;\n-        }\n-\n-        let meta = StaticSortedFileBuilderMeta {\n-            min_hash: self.min_hash,\n-            max_hash: self.max_hash,\n-            aqmf: self.aqmf,\n-            key_compression_dictionary_length: self\n-                .key_compression_dictionary\n-                .len()\n-                .try_into()\n-                .unwrap(),\n-            value_compression_dictionary_length: self\n-                .value_compression_dictionary\n-                .len()\n-                .try_into()\n-                .unwrap(),\n-            block_count,\n-            size: file.stream_position()?,\n-            entries: self.entries,\n-        };\n-        Ok((meta, file.into_inner()?))\n-    }\n+    Ok(pot::to_vec(&filter).expect(\"AMQF serialization failed\"))\n }\n \n /// Builder for a single key block\n-pub struct KeyBlockBuilder {\n+pub struct KeyBlockBuilder<'l> {\n     current_entry: usize,\n     header_size: usize,\n-    data: Vec<u8>,\n+    buffer: &'l mut Vec<u8>,\n }\n \n /// The size of the key block header.\n const KEY_BLOCK_HEADER_SIZE: usize = 4;\n \n-impl KeyBlockBuilder {\n+impl<'l> KeyBlockBuilder<'l> {\n     /// Creates a new key block builder for the number of entries.\n-    pub fn new(entry_count: u32) -> Self {\n+    pub fn new(buffer: &'l mut Vec<u8>, entry_count: u32) -> Self {\n         debug_assert!(entry_count < (1 << 24));\n \n         const ESTIMATED_KEY_SIZE: usize = 16;\n-        let mut data = Vec::with_capacity(entry_count as usize * ESTIMATED_KEY_SIZE);\n-        data.write_u8(BLOCK_TYPE_KEY).unwrap();\n-        data.write_u24::<BE>(entry_count).unwrap();\n+        buffer.reserve(entry_count as usize * ESTIMATED_KEY_SIZE);\n+        buffer.write_u8(BLOCK_TYPE_KEY).unwrap();\n+        buffer.write_u24::<BE>(entry_count).unwrap();\n         for _ in 0..entry_count {\n-            data.write_u32::<BE>(0).unwrap();\n+            buffer.write_u32::<BE>(0).unwrap();\n         }\n         Self {\n             current_entry: 0,\n-            header_size: data.len(),\n-            data,\n+            header_size: buffer.len(),\n+            buffer,\n         }\n     }\n \n@@ -486,90 +563,94 @@ impl KeyBlockBuilder {\n         value_offset: u32,\n         value_size: u16,\n     ) {\n-        let pos = self.data.len() - self.header_size;\n+        let pos = self.buffer.len() - self.header_size;\n         let header_offset = KEY_BLOCK_HEADER_SIZE + self.current_entry * 4;\n         let header = (pos as u32) | ((KEY_BLOCK_ENTRY_TYPE_SMALL as u32) << 24);\n-        BE::write_u32(&mut self.data[header_offset..header_offset + 4], header);\n+        BE::write_u32(&mut self.buffer[header_offset..header_offset + 4], header);\n \n-        self.data.write_u64::<BE>(entry.key_hash()).unwrap();\n-        entry.write_key_to(&mut self.data);\n-        self.data.write_u16::<BE>(value_block).unwrap();\n-        self.data.write_u16::<BE>(value_size).unwrap();\n-        self.data.write_u32::<BE>(value_offset).unwrap();\n+        self.buffer.write_u64::<BE>(entry.key_hash()).unwrap();\n+        entry.write_key_to(self.buffer);\n+        self.buffer.write_u16::<BE>(value_block).unwrap();\n+        self.buffer.write_u16::<BE>(value_size).unwrap();\n+        self.buffer.write_u32::<BE>(value_offset).unwrap();\n \n         self.current_entry += 1;\n     }\n \n     /// Writes a medium-sized value to the buffer.\n     pub fn put_medium<E: Entry>(&mut self, entry: &E, value_block: u16) {\n-        let pos = self.data.len() - self.header_size;\n+        let pos = self.buffer.len() - self.header_size;\n         let header_offset = KEY_BLOCK_HEADER_SIZE + self.current_entry * 4;\n         let header = (pos as u32) | ((KEY_BLOCK_ENTRY_TYPE_MEDIUM as u32) << 24);\n-        BE::write_u32(&mut self.data[header_offset..header_offset + 4], header);\n+        BE::write_u32(&mut self.buffer[header_offset..header_offset + 4], header);\n \n-        self.data.write_u64::<BE>(entry.key_hash()).unwrap();\n-        entry.write_key_to(&mut self.data);\n-        self.data.write_u16::<BE>(value_block).unwrap();\n+        self.buffer.write_u64::<BE>(entry.key_hash()).unwrap();\n+        entry.write_key_to(self.buffer);\n+        self.buffer.write_u16::<BE>(value_block).unwrap();\n \n         self.current_entry += 1;\n     }\n \n     /// Writes a tombstone to the buffer.\n     pub fn delete<E: Entry>(&mut self, entry: &E) {\n-        let pos = self.data.len() - self.header_size;\n+        let pos = self.buffer.len() - self.header_size;\n         let header_offset = KEY_BLOCK_HEADER_SIZE + self.current_entry * 4;\n         let header = (pos as u32) | ((KEY_BLOCK_ENTRY_TYPE_DELETED as u32) << 24);\n-        BE::write_u32(&mut self.data[header_offset..header_offset + 4], header);\n+        BE::write_u32(&mut self.buffer[header_offset..header_offset + 4], header);\n \n-        self.data.write_u64::<BE>(entry.key_hash()).unwrap();\n-        entry.write_key_to(&mut self.data);\n+        self.buffer.write_u64::<BE>(entry.key_hash()).unwrap();\n+        entry.write_key_to(self.buffer);\n \n         self.current_entry += 1;\n     }\n \n     /// Writes a blob value to the buffer.\n     pub fn put_blob<E: Entry>(&mut self, entry: &E, blob: u32) {\n-        let pos = self.data.len() - self.header_size;\n+        let pos = self.buffer.len() - self.header_size;\n         let header_offset = KEY_BLOCK_HEADER_SIZE + self.current_entry * 4;\n         let header = (pos as u32) | ((KEY_BLOCK_ENTRY_TYPE_BLOB as u32) << 24);\n-        BE::write_u32(&mut self.data[header_offset..header_offset + 4], header);\n+        BE::write_u32(&mut self.buffer[header_offset..header_offset + 4], header);\n \n-        self.data.write_u64::<BE>(entry.key_hash()).unwrap();\n-        entry.write_key_to(&mut self.data);\n-        self.data.write_u32::<BE>(blob).unwrap();\n+        self.buffer.write_u64::<BE>(entry.key_hash()).unwrap();\n+        entry.write_key_to(self.buffer);\n+        self.buffer.write_u32::<BE>(blob).unwrap();\n \n         self.current_entry += 1;\n     }\n \n     /// Returns the key block buffer\n-    pub fn finish(self) -> Vec<u8> {\n-        self.data\n+    pub fn finish(self) -> &'l mut Vec<u8> {\n+        self.buffer\n     }\n }\n \n /// Builder for a single index block.\n-pub struct IndexBlockBuilder {\n-    data: Vec<u8>,\n+pub struct IndexBlockBuilder<'l> {\n+    buffer: &'l mut Vec<u8>,\n }\n \n-impl IndexBlockBuilder {\n+impl<'l> IndexBlockBuilder<'l> {\n     /// Creates a new builder for an index block with the specified number of entries and a pointer\n     /// to the first block.\n-    pub fn new(entry_count: u16, first_block: u16) -> Self {\n-        let mut data = Vec::with_capacity(entry_count as usize * 10 + 3);\n-        data.write_u8(BLOCK_TYPE_INDEX).unwrap();\n-        data.write_u16::<BE>(first_block).unwrap();\n-        Self { data }\n+    pub fn new(buffer: &'l mut Vec<u8>, entry_count: u16, first_block: u16) -> Self {\n+        buffer.reserve(\n+            entry_count as usize * (size_of::<u64>() + size_of::<u16>())\n+                + size_of::<u8>()\n+                + size_of::<u16>(),\n+        );\n+        buffer.write_u8(BLOCK_TYPE_INDEX).unwrap();\n+        buffer.write_u16::<BE>(first_block).unwrap();\n+        Self { buffer }\n     }\n \n     /// Adds a hash boundary to the index block.\n     pub fn put(&mut self, hash: u64, block: u16) {\n-        self.data.write_u64::<BE>(hash).unwrap();\n-        self.data.write_u16::<BE>(block).unwrap();\n+        self.buffer.write_u64::<BE>(hash).unwrap();\n+        self.buffer.write_u16::<BE>(block).unwrap();\n     }\n \n     /// Returns the index block buffer\n-    fn finish(self) -> Vec<u8> {\n-        self.data\n+    fn finish(self) -> &'l mut Vec<u8> {\n+        self.buffer\n     }\n }"
        },
        {
            "sha": "490cf38e88a90b3ab957ee06ab7a9f4534326dca",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 6,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/c86a07db719090075eacce49d5ba4accc138bc5f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=c86a07db719090075eacce49d5ba4accc138bc5f",
            "patch": "@@ -26,7 +26,7 @@ use crate::{\n     constants::{MAX_MEDIUM_VALUE_SIZE, THREAD_LOCAL_SIZE_SHIFT},\n     key::StoreKey,\n     meta_file_builder::MetaFileBuilder,\n-    static_sorted_file_builder::{StaticSortedFileBuilder, StaticSortedFileBuilderMeta},\n+    static_sorted_file_builder::{StaticSortedFileBuilderMeta, write_static_stored_file},\n };\n \n /// The thread local state of a `WriteBatch`. `FAMILIES` should fit within a `u32`.\n@@ -408,12 +408,10 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         let (entries, total_key_size, total_value_size) = collector_data;\n         let seq = self.current_sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n \n-        let builder = StaticSortedFileBuilder::new(entries, total_key_size, total_value_size)?;\n-\n         let path = self.db_path.join(format!(\"{seq:08}.sst\"));\n-        let (meta, file) = builder\n-            .write(&path)\n-            .with_context(|| format!(\"Unable to write SST file {seq:08}.sst\"))?;\n+        let (meta, file) =\n+            write_static_stored_file(entries, total_key_size, total_value_size, &path)\n+                .with_context(|| format!(\"Unable to write SST file {seq:08}.sst\"))?;\n \n         #[cfg(feature = \"verify_sst_content\")]\n         {"
        }
    ],
    "stats": {
        "total": 980,
        "additions": 529,
        "deletions": 451
    }
}