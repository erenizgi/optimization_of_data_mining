{
    "author": "bgw",
    "message": "Turbopack: perf: Avoid clones in RopeReader (#86708)\n\nWe (unsurprisingly) spend a lot of time encoding `Rope`s. Most of this is in `memcpy`ing the data out of the rope (not easy to optimize), but there's some cloning of refcounted `Bytes` containers here that can be easily avoided.\n\nYes, `Bytes`â€‹ is refcounted, but updating refcounts isn't free, and it matters because this is a hot codepath.\n\nThis is too small to show up on any top-line measurement (<1%) of total time, but should still be an improvement.",
    "sha": "e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
    "files": [
        {
            "sha": "8cfaeed73fdab1317dad37d6a4dad8f537a20b26",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 1,
            "deletions": 14,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -328,19 +328,6 @@ dependencies = [\n  \"syn 2.0.104\",\n ]\n \n-[[package]]\n-name = \"async-compression\"\n-version = \"0.3.15\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"942c7cd7ae39e91bde4820d74132e9862e62c2f386c3aa90ccf55949f5bad63a\"\n-dependencies = [\n- \"flate2\",\n- \"futures-core\",\n- \"memchr\",\n- \"pin-project-lite\",\n- \"tokio\",\n-]\n-\n [[package]]\n name = \"async-stream\"\n version = \"0.3.4\"\n@@ -9694,8 +9681,8 @@ name = \"turbopack-dev-server\"\n version = \"0.1.0\"\n dependencies = [\n  \"anyhow\",\n- \"async-compression\",\n  \"auto-hash-map\",\n+ \"flate2\",\n  \"futures\",\n  \"hyper 0.14.32\",\n  \"hyper-tungstenite\","
        },
        {
            "sha": "aa08933e9e5d7d8284ba576f1ad19d29d1a0b8eb",
            "filename": "Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/Cargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/Cargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.toml?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -373,10 +373,6 @@ allsorts = { version = \"0.14.0\", default-features = false, features = [\n   \"flate2_rust\",\n ] }\n anyhow = \"1.0.100\"\n-async-compression = { version = \"0.3.13\", default-features = false, features = [\n-  \"gzip\",\n-  \"tokio\",\n-] }\n async-trait = \"0.1.64\"\n bitfield = \"0.18.0\"\n byteorder = \"1.5.0\""
        },
        {
            "sha": "2caf3dcf0a2a3a1ecc1afdc5fd1351437b658402",
            "filename": "turbopack/crates/turbo-tasks-fs/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -1912,7 +1912,7 @@ impl File {\n     }\n \n     /// Returns a Read/AsyncRead/Stream/Iterator to access the File's contents.\n-    pub fn read(&self) -> RopeReader {\n+    pub fn read(&self) -> RopeReader<'_> {\n         self.content.read()\n     }\n }"
        },
        {
            "sha": "617d50ca5a104a28db9f727b9917e61cf903376d",
            "filename": "turbopack/crates/turbo-tasks-fs/src/rope.rs",
            "status": "modified",
            "additions": 60,
            "deletions": 42,
            "changes": 102,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -11,7 +11,7 @@ use std::{\n \n use RopeElem::{Local, Shared};\n use anyhow::{Context, Result};\n-use bytes::{Buf, Bytes};\n+use bytes::Bytes;\n use futures::Stream;\n use serde::{Deserialize, Deserializer, Serialize, Serializer};\n use serde_bytes::ByteBuf;\n@@ -103,7 +103,7 @@ impl Rope {\n     }\n \n     /// Returns a [Read]/[AsyncRead]/[Iterator] instance over all bytes.\n-    pub fn read(&self) -> RopeReader {\n+    pub fn read(&self) -> RopeReader<'_> {\n         RopeReader::new(&self.data, 0)\n     }\n \n@@ -688,28 +688,30 @@ impl DeterministicHash for RopeElem {\n \n #[derive(Debug, Default)]\n /// Implements the [Read]/[AsyncRead]/[Iterator] trait over a [Rope].\n-pub struct RopeReader {\n-    /// The Rope's tree is kept as a cloned stack, allowing us to accomplish\n-    /// incremental yielding.\n-    stack: Vec<StackElem>,\n+pub struct RopeReader<'a> {\n+    /// The Rope's tree is kept as a stack, allowing us to accomplish incremental yielding.\n+    stack: Vec<StackElem<'a>>,\n+    /// An offset in the current buffer, used by the `read` implementation.\n+    offset: usize,\n }\n \n /// A StackElem holds the current index into either a Bytes or a shared Rope.\n /// When the index reaches the end of the associated data, it is removed and we\n /// continue onto the next item in the stack.\n #[derive(Debug)]\n-enum StackElem {\n-    Local(Bytes),\n-    Shared(InnerRope, usize),\n+enum StackElem<'a> {\n+    Local(&'a Bytes),\n+    Shared(&'a InnerRope, usize),\n }\n \n-impl RopeReader {\n-    fn new(inner: &InnerRope, index: usize) -> Self {\n+impl<'a> RopeReader<'a> {\n+    fn new(inner: &'a InnerRope, index: usize) -> Self {\n         if index >= inner.len() {\n             Default::default()\n         } else {\n             RopeReader {\n-                stack: vec![StackElem::Shared(inner.clone(), index)],\n+                stack: vec![StackElem::Shared(inner, index)],\n+                offset: 0,\n             }\n         }\n     }\n@@ -720,30 +722,30 @@ impl RopeReader {\n         let mut remaining = want;\n \n         while remaining > 0 {\n-            let mut bytes = match self.next() {\n+            let bytes = match self.next_internal() {\n                 None => break,\n                 Some(b) => b,\n             };\n \n-            let amount = min(bytes.len(), remaining);\n+            let lower = self.offset;\n+            let upper = min(bytes.len(), lower + remaining);\n \n-            buf.put_slice(&bytes[0..amount]);\n+            buf.put_slice(&bytes[self.offset..upper]);\n \n-            if amount < bytes.len() {\n-                bytes.advance(amount);\n+            if upper < bytes.len() {\n+                self.offset = upper;\n                 self.stack.push(StackElem::Local(bytes))\n+            } else {\n+                self.offset = 0;\n             }\n-            remaining -= amount;\n+            remaining -= upper - lower;\n         }\n \n         want - remaining\n     }\n-}\n \n-impl Iterator for RopeReader {\n-    type Item = Bytes;\n-\n-    fn next(&mut self) -> Option<Self::Item> {\n+    /// Returns the next item in the iterator without modifying `self.offset`.\n+    fn next_internal(&mut self) -> Option<&'a Bytes> {\n         // Iterates the rope's elements recursively until we find the next Local\n         // section, returning its Bytes.\n         loop {\n@@ -756,7 +758,7 @@ impl Iterator for RopeReader {\n                 Some(StackElem::Shared(r, i)) => (r, i),\n             };\n \n-            let el = inner[index].clone();\n+            let el = &inner[index];\n             index += 1;\n             if index < inner.len() {\n                 self.stack.push(StackElem::Shared(inner, index));\n@@ -767,13 +769,22 @@ impl Iterator for RopeReader {\n     }\n }\n \n-impl Read for RopeReader {\n+impl<'a> Iterator for RopeReader<'a> {\n+    type Item = &'a Bytes;\n+\n+    fn next(&mut self) -> Option<Self::Item> {\n+        self.offset = 0;\n+        self.next_internal()\n+    }\n+}\n+\n+impl Read for RopeReader<'_> {\n     fn read(&mut self, buf: &mut [u8]) -> IoResult<usize> {\n         Ok(self.read_internal(buf.len(), &mut ReadBuf::new(buf)))\n     }\n }\n \n-impl AsyncRead for RopeReader {\n+impl AsyncRead for RopeReader<'_> {\n     fn poll_read(\n         self: Pin<&mut Self>,\n         _cx: &mut TaskContext<'_>,\n@@ -785,12 +796,12 @@ impl AsyncRead for RopeReader {\n     }\n }\n \n-impl BufRead for RopeReader {\n+impl BufRead for RopeReader<'_> {\n     /// Never returns an error.\n     fn fill_buf(&mut self) -> IoResult<&[u8]> {\n         // Returns the full buffer without coping any data. The same bytes will\n         // continue to be returned until [consume] is called.\n-        let bytes = match self.next() {\n+        let bytes = match self.next_internal() {\n             None => return Ok(EMPTY_BUF),\n             Some(b) => b,\n         };\n@@ -803,37 +814,44 @@ impl BufRead for RopeReader {\n             unreachable!()\n         };\n \n-        Ok(bytes)\n+        Ok(&bytes[self.offset..])\n     }\n \n     fn consume(&mut self, amt: usize) {\n         if let Some(StackElem::Local(b)) = self.stack.last_mut() {\n-            if amt == b.len() {\n+            // https://doc.rust-lang.org/std/io/trait.BufRead.html#tymethod.consume\n+            debug_assert!(\n+                self.offset + amt <= b.len(),\n+                \"It is a logic error if `amount` exceeds the number of unread bytes in the \\\n+                 internal buffer, which is returned by `fill_buf`.\"\n+            );\n+            // Consume some amount of bytes from the current Bytes instance, ensuring those bytes\n+            // are not returned on the next call to `fill_buf`.\n+            self.offset += amt;\n+            if self.offset == b.len() {\n+                // whole Bytes instance was consumed\n                 self.stack.pop();\n-            } else {\n-                // Consume some amount of bytes from the current Bytes instance, ensuring\n-                // those bytes are not returned on the next call to [fill_buf].\n-                b.advance(amt);\n+                self.offset = 0;\n             }\n         }\n     }\n }\n \n-impl Stream for RopeReader {\n-    // The Result<Bytes> item type is required for this to be streamable into a\n-    // [Hyper::Body].\n-    type Item = Result<Bytes>;\n+impl<'a> Stream for RopeReader<'a> {\n+    /// This is efficiently streamable into a [`Hyper::Body`] if each item is cloned into an owned\n+    /// `Bytes` instance.\n+    type Item = Result<&'a Bytes>;\n \n-    // Returns a \"result\" of reading the next shared bytes reference. This\n-    // differs from [Read::read] by not copying any memory.\n+    /// Returns a \"result\" of reading the next shared bytes reference. This\n+    /// differs from [`Read::read`] by not copying any memory.\n     fn poll_next(self: Pin<&mut Self>, _cx: &mut TaskContext<'_>) -> Poll<Option<Self::Item>> {\n         let this = self.get_mut();\n         Poll::Ready(this.next().map(Ok))\n     }\n }\n \n-impl From<RopeElem> for StackElem {\n-    fn from(el: RopeElem) -> Self {\n+impl<'a> From<&'a RopeElem> for StackElem<'a> {\n+    fn from(el: &'a RopeElem) -> Self {\n         match el {\n             Local(bytes) => Self::Local(bytes),\n             Shared(inner) => Self::Shared(inner, 0),"
        },
        {
            "sha": "e9aeda6f3fefd80ce96699678dcea3a38acbd753",
            "filename": "turbopack/crates/turbopack-dev-server/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbopack-dev-server%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbopack-dev-server%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-dev-server%2FCargo.toml?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -17,8 +17,8 @@ workspace = true\n \n [dependencies]\n anyhow = { workspace = true }\n-async-compression = { workspace = true }\n auto-hash-map = { workspace = true }\n+flate2 = { workspace = true }\n futures = { workspace = true }\n hyper = { version = \"0.14\", features = [\"full\"] }\n hyper-tungstenite = \"0.9.0\""
        },
        {
            "sha": "e8b31c08dd2a3bedc4e9a3b304648f91ac0255fa",
            "filename": "turbopack/crates/turbopack-dev-server/src/http.rs",
            "status": "modified",
            "additions": 23,
            "deletions": 13,
            "changes": 36,
            "blob_url": "https://github.com/vercel/next.js/blob/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbopack-dev-server%2Fsrc%2Fhttp.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/e01d3f2e7c06fe814a07c28d8e41d6913fe63445/turbopack%2Fcrates%2Fturbopack-dev-server%2Fsrc%2Fhttp.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-dev-server%2Fsrc%2Fhttp.rs?ref=e01d3f2e7c06fe814a07c28d8e41d6913fe63445",
            "patch": "@@ -1,13 +1,15 @@\n+use std::{io::Read, iter};\n+\n use anyhow::{Result, anyhow};\n use auto_hash_map::AutoSet;\n-use futures::{StreamExt, TryStreamExt};\n+use flate2::{Compression, bufread::GzEncoder};\n+use futures::{StreamExt, TryStreamExt, stream};\n use hyper::{\n     Request, Response,\n     header::{CONTENT_ENCODING, CONTENT_LENGTH, HeaderName},\n     http::HeaderValue,\n };\n use mime::Mime;\n-use tokio_util::io::{ReaderStream, StreamReader};\n use turbo_tasks::{\n     CollectiblesSource, OperationVc, ReadRef, ResolvedVc, TransientInstance, Vc, apply_effects,\n     util::SharedError,\n@@ -175,22 +177,30 @@ pub async fn process_request_with_content_source(\n                 let response = if should_compress {\n                     header_map.insert(CONTENT_ENCODING, HeaderValue::from_static(\"gzip\"));\n \n-                    // Grab ropereader stream, coerce anyhow::Error to std::io::Error\n-                    let stream_ext = content.read().into_stream().map_err(std::io::Error::other);\n-\n-                    let gzipped_stream =\n-                        ReaderStream::new(async_compression::tokio::bufread::GzipEncoder::new(\n-                            StreamReader::new(stream_ext),\n-                        ));\n-\n-                    response.body(hyper::Body::wrap_stream(gzipped_stream))?\n+                    // Hyper requires an owned reader... We could do this with streaming by cloning\n+                    // each `Bytes` and implementing `BufRead` for `Iterator<bytes::Bytes>`, but\n+                    // it's not really worth it, just compressing the whole thing up-front is fine.\n+                    //\n+                    // Use fast compression, since we're likely just tranferring data over\n+                    // localhost.\n+                    let mut gz_bytes = Vec::new();\n+                    GzEncoder::new(content.read(), Compression::fast())\n+                        .read_to_end(&mut gz_bytes)\n+                        .expect(\"read of Rope should never fail\");\n+                    response.body(hyper::Body::wrap_stream(stream::iter(iter::once(\n+                        hyper::Result::Ok(gz_bytes),\n+                    ))))?\n                 } else {\n+                    // hyper requires an owned stream, so we must clone the iterator items\n+                    // this is relatively cheap: each chunk is a `Bytes`, so `Clone` updates a\n+                    // refcount\n+                    let owned_chunks: Vec<_> =\n+                        content.read().cloned().map(hyper::Result::Ok).collect();\n                     header_map.insert(\n                         CONTENT_LENGTH,\n                         hyper::header::HeaderValue::try_from(content.len().to_string())?,\n                     );\n-\n-                    response.body(hyper::Body::wrap_stream(content.read()))?\n+                    response.body(hyper::Body::wrap_stream(stream::iter(owned_chunks)))?\n                 };\n \n                 return Ok((response, side_effects));"
        }
    ],
    "stats": {
        "total": 161,
        "additions": 86,
        "deletions": 75
    }
}