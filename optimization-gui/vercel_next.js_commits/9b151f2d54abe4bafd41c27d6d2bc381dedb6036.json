{
    "author": "sokra",
    "message": "Turbopack: Improve compaction in Persistent Caching (#80860)\n\n### What?\r\n\r\nRefactors the compaction algorithm with the following improvements.\r\n\r\n* Multiple ranges can be compacted in parallel\r\n* Instead of going for the largest merge it looks for an \"optimal\" size and runs multiple in parallel\r\n* Compaction considers duplicated size and tries to reduce it\r\n* Compaction works on recent SST files first as they tend to be less compacted yet and potentially contains more duplication.\r\n* Limits the parallel compactions to CPUs / 4 during the build and CPUs / 2 after the build",
    "sha": "9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
    "files": [
        {
            "sha": "1fb89739e712fe1c0011281163fe0e8c19aafbc4",
            "filename": "turbopack/crates/turbo-persistence-tools/src/main.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -22,8 +22,10 @@ fn main() -> Result<()> {\n         .context(\"Failed to retrieve meta information\")?;\n     for meta_file in meta_info {\n         println!(\n-            \"META {:08}.meta: family = {}, \",\n-            meta_file.sequence_number, meta_file.family\n+            \"META {:08}.meta: family = {}, sst_size = {} MiB\",\n+            meta_file.sequence_number,\n+            meta_file.family,\n+            meta_file.entries.iter().map(|e| e.sst_size).sum::<u64>() / 1024 / 1024,\n         );\n         for MetaFileEntryInfo {\n             sequence_number,"
        },
        {
            "sha": "396f8046db7489765f53f69c4129f763ff03cb11",
            "filename": "turbopack/crates/turbo-persistence/src/compaction/interval_map.rs",
            "status": "added",
            "additions": 183,
            "deletions": 0,
            "changes": 183,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Finterval_map.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Finterval_map.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Finterval_map.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -0,0 +1,183 @@\n+struct IntervalPoint<T> {\n+    start: u64,\n+    value: Option<T>,\n+}\n+\n+pub struct IntervalMap<T> {\n+    intervals: Vec<IntervalPoint<T>>,\n+}\n+\n+impl<T> Default for IntervalMap<T> {\n+    fn default() -> Self {\n+        Self {\n+            intervals: Vec::new(),\n+        }\n+    }\n+}\n+\n+impl<T> IntervalMap<T> {\n+    pub fn new() -> Self {\n+        Default::default()\n+    }\n+\n+    /// Ensures that there is an interval point at the specified location.\n+    fn ensure_point(&mut self, location: u64) -> usize\n+    where\n+        T: Clone,\n+    {\n+        match self\n+            .intervals\n+            .binary_search_by_key(&location, |point| point.start)\n+        {\n+            Ok(index) => index,\n+            Err(index) => {\n+                // If the location does not exist, we need to insert a new interval\n+                let value = if index > 0 {\n+                    self.intervals[index - 1].value.clone()\n+                } else {\n+                    None\n+                };\n+                self.intervals.insert(\n+                    index,\n+                    IntervalPoint {\n+                        start: location,\n+                        value,\n+                    },\n+                );\n+                index\n+            }\n+        }\n+    }\n+\n+    /// Applies the update function to all values in the specified range.\n+    pub fn update(&mut self, range: &(u64, u64), mut update: impl FnMut(&mut T))\n+    where\n+        T: Default + Clone,\n+    {\n+        let start = range.0;\n+        let end = range.1;\n+        if start > end {\n+            return;\n+        }\n+\n+        let start = self.ensure_point(start);\n+        if end == u64::MAX {\n+            for i in start..self.intervals.len() {\n+                update(self.intervals[i].value.get_or_insert_default());\n+            }\n+        } else {\n+            let end = self.ensure_point(end + 1);\n+\n+            for i in start..end {\n+                update(self.intervals[i].value.get_or_insert_default());\n+            }\n+        }\n+    }\n+\n+    /// Tests if any values in the specified range satisfy the predicate.\n+    pub fn test(&self, range: &(u64, u64), mut predicate: impl FnMut(&T) -> bool) -> bool {\n+        let start = range.0;\n+        let end = range.1;\n+        if start > end {\n+            return false;\n+        }\n+\n+        let start_index = match self\n+            .intervals\n+            .binary_search_by_key(&start, |point| point.start)\n+        {\n+            Ok(index) => index,\n+            Err(0) => 0,\n+            Err(index) => index - 1,\n+        };\n+\n+        let end_index = match self\n+            .intervals\n+            .binary_search_by_key(&end, |point| point.start)\n+        {\n+            Ok(index) => index + 1,\n+            Err(index) => index,\n+        };\n+\n+        for i in start_index..end_index {\n+            if let Some(value) = &self.intervals[i].value\n+                && predicate(value)\n+            {\n+                return true;\n+            }\n+        }\n+        false\n+    }\n+\n+    /// Returns an iterator over the ranges and their associated values.\n+    pub fn ranges(&self) -> impl Iterator<Item = ((u64, u64), &T)> {\n+        (0..self.intervals.len()).filter_map(move |i| {\n+            let start = self.intervals[i].start;\n+            let end = if i + 1 < self.intervals.len() {\n+                self.intervals[i + 1].start - 1\n+            } else {\n+                u64::MAX\n+            };\n+            self.intervals[i]\n+                .value\n+                .as_ref()\n+                .map(|value| ((start, end), value))\n+        })\n+    }\n+}\n+\n+#[cfg(test)]\n+mod tests {\n+    use super::*;\n+\n+    #[test]\n+    fn test_interval_map() {\n+        let mut map = IntervalMap::new();\n+        map.update(&(5, 15), |v| *v |= 1);\n+        map.update(&(10, 15), |v| *v |= 2);\n+        map.update(&(10, 20), |v| *v |= 4);\n+        map.update(&(0, u64::MAX), |v| *v |= 8);\n+        map.update(&(15, 20), |v| *v |= 16);\n+\n+        let expected = vec![\n+            ((0, 4), &8),\n+            ((5, 9), &(1 | 8)),\n+            ((10, 14), &(1 | 2 | 4 | 8)),\n+            ((15, 15), &(1 | 2 | 4 | 8 | 16)),\n+            ((16, 20), &(4 | 8 | 16)),\n+            ((21, u64::MAX), &8),\n+        ];\n+        let result: Vec<_> = map.ranges().collect();\n+        assert_eq!(result, expected);\n+\n+        // test the `test` method\n+        assert!(map.test(&(0, 10), |v| *v & 1 != 0));\n+        assert!(map.test(&(0, 10), |v| *v & 2 != 0));\n+        assert!(map.test(&(0, 50), |v| *v & 4 != 0));\n+        assert!(map.test(&(15, 15), |v| *v & 16 != 0));\n+        assert!(map.test(&(0, 15), |v| *v & 16 != 0));\n+        assert!(map.test(&(20, 20), |v| *v & 16 != 0));\n+        assert!(map.test(&(20, u64::MAX), |v| *v & 16 != 0));\n+        assert!(map.test(&(0, u64::MAX), |v| *v & 8 != 0));\n+        assert!(map.test(&(0, 0), |v| *v & 8 != 0));\n+        assert!(map.test(&(u64::MAX, u64::MAX), |v| *v & 8 != 0));\n+        assert!(map.test(&(123, 1234), |v| *v & 8 != 0));\n+    }\n+\n+    #[test]\n+    fn test_interval_map_empty() {\n+        let map: IntervalMap<u32> = IntervalMap::new();\n+        let result: Vec<_> = map.ranges().collect();\n+        assert!(result.is_empty());\n+    }\n+\n+    #[test]\n+    fn test_interval_map_single_point() {\n+        let mut map: IntervalMap<u32> = IntervalMap::new();\n+        map.update(&(10, 10), |v| *v += 1);\n+\n+        let result: Vec<_> = map.ranges().collect();\n+        assert_eq!(result.len(), 1);\n+        assert_eq!(result[0], ((10, 10), &1));\n+    }\n+}"
        },
        {
            "sha": "abef2dd322e4d4941cce84e042930c566ce63629",
            "filename": "turbopack/crates/turbo-persistence/src/compaction/mod.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fmod.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -1 +1,2 @@\n+mod interval_map;\n pub mod selector;"
        },
        {
            "sha": "bd6ea2d2f61a10ebeabd0a384aa6633f41608035",
            "filename": "turbopack/crates/turbo-persistence/src/compaction/selector.rs",
            "status": "modified",
            "additions": 504,
            "deletions": 224,
            "changes": 728,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -1,17 +1,6 @@\n-/// The merge and move jobs that the compaction algorithm has computed. It's expected that all move\n-/// jobs are executed in parallel and when that has finished the move jobs are executed in parallel.\n-#[derive(Debug)]\n-pub struct CompactionJobs {\n-    pub merge_jobs: Vec<Vec<usize>>,\n-    pub move_jobs: Vec<usize>,\n-}\n+use smallvec::{SmallVec, smallvec};\n \n-impl CompactionJobs {\n-    #[cfg(test)]\n-    pub(self) fn is_empty(&self) -> bool {\n-        self.merge_jobs.is_empty() && self.move_jobs.is_empty()\n-    }\n-}\n+use crate::compaction::interval_map::IntervalMap;\n \n type Range = (u64, u64);\n \n@@ -29,7 +18,7 @@ fn is_overlapping(a: &Range, b: &Range) -> bool {\n }\n \n fn spread(range: &Range) -> u64 {\n-    range.1 - range.0\n+    (range.1 - range.0).saturating_add(1)\n }\n \n /// Extends the range `a` to include the range `b`, returns `true` if the range was extended.\n@@ -46,183 +35,324 @@ fn extend_range(a: &mut Range, b: &Range) -> bool {\n     extended\n }\n \n-/// Computes the total coverage of the compactables.\n-pub fn total_coverage<T: Compactable>(compactables: &[T], full_range: Range) -> f32 {\n+#[derive(Debug)]\n+pub struct CompactableMetrics {\n+    /// The total coverage of the compactables.\n+    pub coverage: f32,\n+\n+    /// The maximum overlap of the compactables.\n+    pub overlap: f32,\n+\n+    /// The possible duplication of the compactables.\n+    pub duplicated_size: u64,\n+\n+    /// The possible duplication of the compactables as factor to total size.\n+    pub duplication: f32,\n+}\n+\n+/// Computes metrics about the compactables.\n+pub fn compute_metrics<T: Compactable>(\n+    compactables: &[T],\n+    full_range: Range,\n+) -> CompactableMetrics {\n+    let mut interval_map: IntervalMap<(DuplicationInfo, usize)> = IntervalMap::new();\n     let mut coverage = 0.0f32;\n     for c in compactables {\n         let range = c.range();\n         coverage += spread(&range) as f32;\n+        interval_map.update(&range, |(dup_info, count)| {\n+            dup_info.add(c.size(), &range);\n+            *count += 1;\n+        });\n+    }\n+    let full_spread = spread(&full_range) as f32;\n+\n+    let (duplicated_size, duplication, overlap) = interval_map\n+        .ranges()\n+        .map(|(range, (dup_info, count))| {\n+            let duplicated_size = dup_info.duplication(&range);\n+            let total_size = dup_info.size(&range);\n+            let overlap = spread(&range) as f32 * count.saturating_sub(1) as f32;\n+            (duplicated_size, total_size, overlap)\n+        })\n+        .reduce(|(dup1, total1, overlap1), (dup2, total2, overlap2)| {\n+            (dup1 + dup2, total1 + total2, overlap1 + overlap2)\n+        })\n+        .map(|(duplicated_size, total_size, overlap)| {\n+            (\n+                duplicated_size,\n+                if total_size > 0 {\n+                    duplicated_size as f32 / total_size as f32\n+                } else {\n+                    0.0\n+                },\n+                overlap,\n+            )\n+        })\n+        .unwrap_or((0, 0.0, 0.0));\n+\n+    CompactableMetrics {\n+        coverage: coverage / full_spread,\n+        overlap: overlap / full_spread,\n+        duplicated_size,\n+        duplication,\n     }\n-    coverage / spread(&full_range) as f32\n }\n \n /// Configuration for the compaction algorithm.\n pub struct CompactConfig {\n     /// The minimum number of files to merge at once.\n-    pub min_merge: usize,\n+    pub min_merge_count: usize,\n+\n+    /// The optimal number of files to merge at once.\n+    pub optimal_merge_count: usize,\n \n     /// The maximum number of files to merge at once.\n-    pub max_merge: usize,\n+    pub max_merge_count: usize,\n \n     /// The maximum size of all files to merge at once.\n-    pub max_merge_size: u64,\n+    pub max_merge_bytes: u64,\n+\n+    /// The amount of duplication that need to be in a merge job to be considered for merging.\n+    pub min_merge_duplication_bytes: u64,\n+\n+    /// The optimal duplication size for merging.\n+    pub optimal_merge_duplication_bytes: u64,\n+\n+    /// The maximum number of merge segments to determine.\n+    pub max_merge_segment_count: usize,\n }\n \n-/// For a list of compactables, computes merge and move jobs that are expected to perform best.\n-pub fn get_compaction_jobs<T: Compactable>(\n-    compactables: &[T],\n-    config: &CompactConfig,\n-) -> CompactionJobs {\n-    let (jobs, _) = get_compaction_jobs_internal(compactables, config, 0);\n-    jobs\n+impl Default for CompactConfig {\n+    fn default() -> Self {\n+        const MB: u64 = 1024 * 1024;\n+        Self {\n+            min_merge_count: 2,\n+            optimal_merge_count: 8,\n+            max_merge_count: 32,\n+            max_merge_bytes: 500 * MB,\n+            min_merge_duplication_bytes: MB,\n+            optimal_merge_duplication_bytes: 10 * MB,\n+            max_merge_segment_count: 8,\n+        }\n+    }\n+}\n+\n+#[derive(Clone, Default)]\n+struct DuplicationInfo {\n+    total_size: u64,\n+    max_size: u64,\n }\n \n-fn get_compaction_jobs_internal<T: Compactable>(\n+impl DuplicationInfo {\n+    fn duplication(&self, range: &Range) -> u64 {\n+        if self.total_size == 0 {\n+            return 0;\n+        }\n+        ((self.total_size - self.max_size) as u128 * spread(range) as u128 / (u64::MAX as u128 + 1))\n+            as u64\n+    }\n+\n+    fn size(&self, range: &Range) -> u64 {\n+        if self.total_size == 0 {\n+            return 0;\n+        }\n+        (self.total_size as u128 * spread(range) as u128 / (u64::MAX as u128 + 1)) as u64\n+    }\n+\n+    fn add(&mut self, size: u64, range: &Range) {\n+        // Scale size to full range:\n+        let scaled_size = (size as u128 * (u64::MAX as u128 + 1) / spread(range) as u128) as u64;\n+        self.total_size = self.total_size.saturating_add(scaled_size);\n+        self.max_size = self.max_size.max(scaled_size);\n+    }\n+}\n+\n+fn total_duplication_size(duplication: &IntervalMap<DuplicationInfo>) -> u64 {\n+    duplication\n+        .ranges()\n+        .map(|(range, info)| info.duplication(&range))\n+        .sum()\n+}\n+\n+type MergeSegments = Vec<SmallVec<[usize; 1]>>;\n+\n+pub fn get_merge_segments<T: Compactable>(\n     compactables: &[T],\n     config: &CompactConfig,\n-    start_index: usize,\n-) -> (CompactionJobs, f32) {\n-    let len = compactables.len();\n-    let mut used_compactables = vec![false; len];\n-    let mut need_move = vec![false; len];\n-    let mut merge_jobs = Vec::new();\n-    let mut merge_jobs_reducation = 0.0f32;\n-    let mut move_jobs = Vec::new();\n-\n-    let age = |i| (len - 1 - i) as f32;\n-\n-    loop {\n-        // Find the first unused compactable.\n-        let Some(start) = used_compactables\n-            .iter()\n-            .skip(start_index)\n-            .position(|&used| !used)\n-            .map(|i| i + start_index)\n-        else {\n-            break;\n-        };\n-        if start >= len - 1 {\n+) -> MergeSegments {\n+    // Process all compactables in reverse order.\n+    // For each compactable, find the smallest set of compactables that overlaps with it and matches\n+    // the conditions.\n+    // To find the set:\n+    // - Set the current range to the range of the first unused compactable.\n+    // - When the set matches the conditions, add the set as merge job, mark all used compactables\n+    //   and continue.\n+    // - Find the next unused compactable that overlaps with the current range.\n+    // - If the range need to be extended, restart the search with the new range.\n+    // - If the compactable is within the range, add it to the current set.\n+    // - If the set is too large, mark the starting compactable as used and continue with the next\n+\n+    let mut unused_compactables = compactables.iter().collect::<Vec<_>>();\n+    let mut used_compactables = vec![false; compactables.len()];\n+\n+    let mut merge_segments: MergeSegments = Vec::new();\n+    let mut real_merge_segments = 0;\n+\n+    // Iterate in reverse order to process the compactables from the end.\n+    // That's the order in which compactables are read, so we need to keep that order.\n+    'outer: while let Some(start_compactable) = unused_compactables.pop() {\n+        let start_index = unused_compactables.len();\n+        if used_compactables[start_index] {\n+            continue;\n+        }\n+        if real_merge_segments >= config.max_merge_segment_count {\n+            // We have reached the maximum number of merge jobs, so we stop here.\n             break;\n         }\n-        used_compactables[start] = true;\n-        let start_range = compactables[start].range();\n-        let mut range = start_range;\n-\n-        let mut merge_job_size = compactables[start].size();\n-        let mut merge_job = Vec::new();\n-        merge_job.push(start);\n-        let mut merge_job_input_spread = spread(&start_range) as f32;\n-\n-        'outer: loop {\n-            // Find the next overlapping unused compactable and extend the range to cover it.\n-            // If it already covers it, add this to the current set.\n-            let mut i = start + 1;\n+        let mut current_range = start_compactable.range();\n+\n+        // We might need to restart the search if we need to extend the range.\n+        'search: loop {\n+            let mut current_set = smallvec![start_index];\n+            let mut current_size = start_compactable.size();\n+            let mut duplication: IntervalMap<DuplicationInfo> = IntervalMap::new();\n+            let mut current_skip = 0;\n+\n+            // We will capture compactables in the current_range until we find a optimal merge\n+            // segment or are limited by size or count.\n             loop {\n-                if !used_compactables[i] {\n-                    let range_for_i = compactables[i].range();\n-                    if is_overlapping(&range, &range_for_i) {\n-                        let mut extended_range = range;\n-                        if !extend_range(&mut extended_range, &range_for_i) {\n-                            let size = compactables[i].size();\n-                            if merge_job_size + size > config.max_merge_size {\n-                                break 'outer;\n+                // Early exit if we have found an optimal merge segment.\n+                let duplication_size = total_duplication_size(&duplication);\n+                let optimal_merge_job = current_set.len() >= config.optimal_merge_count\n+                    && duplication_size >= config.optimal_merge_duplication_bytes;\n+                if optimal_merge_job {\n+                    for &i in current_set.iter() {\n+                        used_compactables[i] = true;\n+                    }\n+                    current_set.reverse();\n+                    merge_segments.push(current_set);\n+                    real_merge_segments += 1;\n+                    continue 'outer;\n+                }\n+\n+                // If we are limited by size or count, we might also crate a merge segment if it's\n+                // within the limits.\n+                let valid_merge_job = current_set.len() >= config.min_merge_count\n+                    && duplication_size >= config.min_merge_duplication_bytes;\n+                let mut end_job =\n+                    |mut current_set: SmallVec<[usize; 1]>, used_compactables: &mut Vec<bool>| {\n+                        if valid_merge_job {\n+                            for &i in current_set.iter() {\n+                                used_compactables[i] = true;\n                             }\n-                            used_compactables[i] = true;\n-                            merge_job.push(i);\n-                            merge_job_size += compactables[i].size();\n-                            merge_job_input_spread += spread(&range_for_i) as f32;\n+                            current_set.reverse();\n+                            merge_segments.push(current_set);\n+                            real_merge_segments += 1;\n                         } else {\n-                            let s = spread(&range);\n-                            // Disallow doubling the range spread\n-                            if merge_job.len() >= config.min_merge\n-                                && spread(&extended_range) - s > s\n-                            {\n-                                break 'outer;\n-                            }\n-                            range = extended_range;\n-                            // Need to restart the search from the beginning as the extended range\n-                            // may overlap with compactables that were\n-                            // already processed.\n-                            break;\n+                            merge_segments.push(smallvec![start_index]);\n                         }\n-                    }\n-                }\n-                i += 1;\n-                if i >= compactables.len() {\n-                    break 'outer;\n-                }\n-                if merge_job.len() >= config.max_merge {\n-                    break 'outer;\n+                    };\n+\n+                // Check if we run into the count or size limit.\n+                if current_set.len() >= config.max_merge_count\n+                    || current_size >= config.max_merge_bytes\n+                {\n+                    // The set is so large so we can't add more compactables to it.\n+                    end_job(current_set, &mut used_compactables);\n+                    continue 'outer;\n                 }\n-            }\n-        }\n \n-        if merge_job.len() < config.min_merge {\n-            continue;\n-        }\n-        let mut merge_range = compactables[start].range();\n-        if !merge_job\n-            .iter()\n-            .skip(1)\n-            .any(|&i| is_overlapping(&merge_range, &compactables[i].range()))\n-        {\n-            // No overlapping ranges, skip that merge job.\n-            continue;\n-        }\n+                // Find the next compactable that overlaps with the current range.\n+                let Some((next_index, compactable)) = unused_compactables\n+                    .iter()\n+                    .enumerate()\n+                    .rev()\n+                    .skip(current_skip)\n+                    .find(|(i, compactable)| {\n+                        if used_compactables[*i] {\n+                            return false;\n+                        }\n+                        let range = compactable.range();\n+                        is_overlapping(&current_range, &range)\n+                    })\n+                else {\n+                    // There are no more compactables that overlap with the current range.\n+                    end_job(current_set, &mut used_compactables);\n+                    continue 'outer;\n+                };\n+                current_skip = unused_compactables.len() - next_index;\n+\n+                // Check if we run into the size limit.\n+                let size = compactable.size();\n+                if current_size + size > config.max_merge_bytes {\n+                    // The next compactable is too large to be added to the current set.\n+                    end_job(current_set, &mut used_compactables);\n+                    continue 'outer;\n+                }\n \n-        for &i in merge_job.iter().skip(1) {\n-            extend_range(&mut merge_range, &compactables[i].range());\n-        }\n-        merge_jobs_reducation = (merge_job_input_spread - spread(&merge_range) as f32) * age(start);\n+                // Check if the next compactable is larger than the current range. We need to\n+                // restart from beginning here as there could be previously skipped compactables\n+                // that are within the larger range.\n+                let range = compactable.range();\n+                if extend_range(&mut current_range, &range) {\n+                    // The range was extended, so we need to restart the search.\n+                    continue 'search;\n+                }\n \n-        for (i, compactable) in compactables\n-            .iter()\n-            .enumerate()\n-            .skip(merge_job.last().unwrap() + 1)\n-        {\n-            if used_compactables[i] {\n-                continue;\n-            }\n-            let range = compactable.range();\n-            if is_overlapping(&merge_range, &range) && !need_move[i] {\n-                need_move[i] = true;\n-                used_compactables[i] = true;\n-                move_jobs.push(i);\n+                // The next compactable is within the current range, so we can add it to the current\n+                // set.\n+                current_set.push(next_index);\n+                current_size += size;\n+                duplication.update(&range, |dup_info| {\n+                    dup_info.add(size, &range);\n+                });\n             }\n         }\n-\n-        merge_jobs.push(merge_job);\n     }\n \n-    // Check if there is an alternative with better reduction.\n-    if !move_jobs.is_empty() {\n-        let offset = move_jobs[0];\n-        let (result, estimated_reduction) =\n-            get_compaction_jobs_internal(compactables, config, offset);\n-        if estimated_reduction > merge_jobs_reducation {\n-            return (result, estimated_reduction);\n-        }\n+    while merge_segments.last().is_some_and(|s| s.len() == 1) {\n+        // Remove segments that only contain a single compactable.\n+        merge_segments.pop();\n     }\n \n-    move_jobs.sort_unstable();\n+    // Reverse it since we processed in reverse order.\n+    merge_segments.reverse();\n+\n+    // Remove single compectable segments that don't overlap with previous segments. We don't need\n+    // to touch them.\n+    // TODO: Technically it's a bit inefficient to use an IntervalMap here, but\n+    // it's not very hot code anyway.\n+    let mut used_ranges: IntervalMap<bool> = IntervalMap::new();\n+    merge_segments.retain(|segment| {\n+        // Remove a single element segments which doesn't overlap with previous used ranges.\n+        if segment.len() == 1 {\n+            let range = compactables[segment[0]].range();\n+            if !used_ranges.test(&range, |in_use| *in_use) {\n+                return false;\n+            }\n+        }\n+        // Mark the ranges of the segment as used.\n+        for i in segment {\n+            let range = compactables[*i].range();\n+            used_ranges.update(&range, |in_use| {\n+                *in_use = true;\n+            });\n+        }\n+        true\n+    });\n \n-    (\n-        CompactionJobs {\n-            merge_jobs,\n-            move_jobs,\n-        },\n-        merge_jobs_reducation,\n-    )\n+    merge_segments\n }\n \n #[cfg(test)]\n mod tests {\n     use std::{\n         fmt::Debug,\n-        mem::{swap, take},\n+        mem::{replace, swap},\n     };\n \n-    use rand::{Rng, SeedableRng};\n+    use rand::{Rng, SeedableRng, seq::SliceRandom};\n \n     use super::*;\n \n@@ -241,30 +371,20 @@ mod tests {\n         }\n     }\n \n-    fn compact<const N: usize>(\n-        ranges: [(u64, u64); N],\n-        max_merge: usize,\n-        max_merge_size: u64,\n-    ) -> CompactionJobs {\n+    fn compact<const N: usize>(ranges: [(u64, u64); N], config: &CompactConfig) -> Vec<Vec<usize>> {\n         let compactables = ranges\n             .iter()\n             .map(|&range| TestCompactable { range, size: 100 })\n             .collect::<Vec<_>>();\n-        let config = CompactConfig {\n-            max_merge,\n-            min_merge: 2,\n-            max_merge_size,\n-        };\n-        get_compaction_jobs(&compactables, &config)\n+        let jobs = get_merge_segments(&compactables, config);\n+        jobs.into_iter()\n+            .map(|job| job.into_iter().collect())\n+            .collect()\n     }\n \n     #[test]\n-    fn test_compaction_jobs() {\n-        let CompactionJobs {\n-            merge_jobs,\n-            move_jobs,\n-            ..\n-        } = compact(\n+    fn test_compaction_jobs_by_count() {\n+        let merge_jobs = compact(\n             [\n                 (0, 10),\n                 (10, 30),\n@@ -276,20 +396,49 @@ mod tests {\n                 (90, 100),\n                 (30, 40),\n             ],\n-            3,\n-            u64::MAX,\n+            &CompactConfig {\n+                min_merge_count: 2,\n+                optimal_merge_count: 3,\n+                max_merge_count: 4,\n+                max_merge_bytes: u64::MAX,\n+                min_merge_duplication_bytes: 0,\n+                optimal_merge_duplication_bytes: 0,\n+                max_merge_segment_count: usize::MAX,\n+            },\n         );\n-        assert_eq!(merge_jobs, vec![vec![0, 1, 2], vec![4, 5, 6]]);\n-        assert_eq!(move_jobs, vec![3, 8]);\n+        assert_eq!(merge_jobs, vec![vec![1, 2, 3], vec![5, 6, 8]]);\n     }\n \n     #[test]\n     fn test_compaction_jobs_by_size() {\n-        let CompactionJobs {\n-            merge_jobs,\n-            move_jobs,\n-            ..\n-        } = compact(\n+        let merge_jobs = compact(\n+            [\n+                (0, 10),\n+                (10, 30),\n+                (9, 13),\n+                (0, 30),\n+                (40, 44),\n+                (41, 42),\n+                (41, 47),\n+                (90, 100),\n+                (30, 40),\n+            ],\n+            &CompactConfig {\n+                min_merge_count: 2,\n+                optimal_merge_count: 2,\n+                max_merge_count: usize::MAX,\n+                max_merge_bytes: 300,\n+                min_merge_duplication_bytes: 0,\n+                optimal_merge_duplication_bytes: u64::MAX,\n+                max_merge_segment_count: usize::MAX,\n+            },\n+        );\n+        assert_eq!(merge_jobs, vec![vec![1, 2, 3], vec![5, 6, 8]]);\n+    }\n+\n+    #[test]\n+    fn test_compaction_jobs_full() {\n+        let merge_jobs = compact(\n             [\n                 (0, 10),\n                 (10, 30),\n@@ -301,26 +450,114 @@ mod tests {\n                 (90, 100),\n                 (30, 40),\n             ],\n-            usize::MAX,\n-            300,\n+            &CompactConfig {\n+                min_merge_count: 2,\n+                optimal_merge_count: usize::MAX,\n+                max_merge_count: usize::MAX,\n+                max_merge_bytes: u64::MAX,\n+                min_merge_duplication_bytes: 0,\n+                optimal_merge_duplication_bytes: u64::MAX,\n+                max_merge_segment_count: usize::MAX,\n+            },\n         );\n-        assert_eq!(merge_jobs, vec![vec![0, 1, 2], vec![4, 5, 6]]);\n-        assert_eq!(move_jobs, vec![3, 8]);\n+        assert_eq!(merge_jobs, vec![vec![0, 1, 2, 3, 4, 5, 6, 8]]);\n+    }\n+\n+    #[test]\n+    fn test_compaction_jobs_big() {\n+        let merge_jobs = compact(\n+            [\n+                (0, 10),\n+                (10, 30),\n+                (9, 13),\n+                (0, 30),\n+                (40, 44),\n+                (41, 42),\n+                (41, 47),\n+                (90, 100),\n+                (30, 40),\n+            ],\n+            &CompactConfig {\n+                min_merge_count: 2,\n+                optimal_merge_count: 7,\n+                max_merge_count: usize::MAX,\n+                max_merge_bytes: u64::MAX,\n+                min_merge_duplication_bytes: 0,\n+                optimal_merge_duplication_bytes: 0,\n+                max_merge_segment_count: usize::MAX,\n+            },\n+        );\n+        assert_eq!(merge_jobs, vec![vec![1, 2, 3, 4, 5, 6, 8]]);\n+    }\n+\n+    #[test]\n+    fn test_compaction_jobs_small() {\n+        let merge_jobs = compact(\n+            [\n+                (0, 10),\n+                (10, 30),\n+                (9, 13),\n+                (0, 30),\n+                (40, 44),\n+                (41, 42),\n+                (41, 47),\n+                (90, 100),\n+                (30, 40),\n+            ],\n+            &CompactConfig {\n+                min_merge_count: 2,\n+                optimal_merge_count: 2,\n+                max_merge_count: usize::MAX,\n+                max_merge_bytes: u64::MAX,\n+                min_merge_duplication_bytes: 0,\n+                optimal_merge_duplication_bytes: 0,\n+                max_merge_segment_count: usize::MAX,\n+            },\n+        );\n+        assert_eq!(\n+            merge_jobs,\n+            vec![vec![0, 1], vec![2, 3], vec![4, 5], vec![6, 8]]\n+        );\n+    }\n+\n+    pub fn debug_print_compactables<T: Compactable>(compactables: &[T], max_key: u64) {\n+        const WIDTH: usize = 128;\n+        let char_width: u64 = max_key / WIDTH as u64;\n+        for (i, c) in compactables.iter().enumerate() {\n+            let range = c.range();\n+            let size = c.size();\n+            let start = (range.0 / char_width) as usize;\n+            let end = (range.1 / char_width) as usize;\n+            let mut line = format!(\"{i:>3} | \");\n+            for j in 0..WIDTH {\n+                if j >= start && j <= end {\n+                    line.push('â–ˆ');\n+                } else {\n+                    line.push(' ');\n+                }\n+            }\n+            println!(\"{line} | {size:>6}\");\n+        }\n     }\n \n     #[test]\n     fn simulate_compactions() {\n+        const KEY_RANGE: u64 = 10000;\n+        const WARM_KEY_COUNT: usize = 100;\n+        const INITIAL_CHUNK_SIZE: usize = 100;\n+        const ITERATIONS: usize = 100;\n+\n         let mut rnd = rand::rngs::SmallRng::from_seed([0; 32]);\n-        let mut keys = (0..1000)\n-            .map(|_| rnd.random_range(0..10000))\n-            .collect::<Vec<_>>();\n+        let mut keys = (0..KEY_RANGE).collect::<Vec<_>>();\n+        keys.shuffle(&mut rnd);\n \n+        let mut batch_index = 0;\n         let mut containers = keys\n-            .chunks(100)\n-            .map(|keys| Container::new(keys.to_vec()))\n+            .chunks(INITIAL_CHUNK_SIZE)\n+            .map(|keys| Container::new(batch_index, keys.to_vec()))\n             .collect::<Vec<_>>();\n \n-        let mut warm_keys = (0..100)\n+        let mut warm_keys = (0..WARM_KEY_COUNT)\n             .map(|_| {\n                 let i = rnd.random_range(0..keys.len());\n                 keys.swap_remove(i)\n@@ -329,56 +566,85 @@ mod tests {\n \n         let mut number_of_compactions = 0;\n \n-        for _ in 0..100 {\n-            let coverage = total_coverage(&containers, (0, 10000));\n+        for _ in 0..ITERATIONS {\n+            let total_size = containers.iter().map(|c| c.keys.len()).sum::<usize>();\n+            let metrics = compute_metrics(&containers, (0, KEY_RANGE));\n+            debug_print_compactables(&containers, KEY_RANGE);\n             println!(\n-                \"{containers:#?} coverage: {}, items: {}\",\n-                coverage,\n+                \"size: {}, coverage: {}, overlap: {}, duplication: {}, items: {}\",\n+                total_size,\n+                metrics.coverage,\n+                metrics.overlap,\n+                metrics.duplication,\n                 containers.len()\n             );\n \n-            if coverage > 10.0 {\n-                let config = CompactConfig {\n-                    max_merge: 4,\n-                    min_merge: 2,\n-                    max_merge_size: u64::MAX,\n-                };\n-                let jobs = get_compaction_jobs(&containers, &config);\n-                if !jobs.is_empty() {\n-                    println!(\"{jobs:?}\");\n-\n-                    do_compact(&mut containers, jobs);\n-                    number_of_compactions += 1;\n-                }\n+            assert!(containers.len() < 400);\n+            // assert!(metrics.duplication < 4.0);\n+\n+            let config = CompactConfig {\n+                max_merge_count: 16,\n+                min_merge_count: 2,\n+                optimal_merge_count: 4,\n+                max_merge_bytes: 5000,\n+                min_merge_duplication_bytes: 200,\n+                optimal_merge_duplication_bytes: 500,\n+                max_merge_segment_count: 4,\n+            };\n+            let jobs = get_merge_segments(&containers, &config);\n+            if !jobs.is_empty() {\n+                println!(\"{jobs:?}\");\n+\n+                batch_index += 1;\n+                do_compact(&mut containers, jobs, batch_index);\n+                number_of_compactions += 1;\n+\n+                let new_metrics = compute_metrics(&containers, (0, KEY_RANGE));\n+                println!(\n+                    \"Compaction done: coverage: {} ({}), overlap: {} ({}), duplication: {} ({})\",\n+                    new_metrics.coverage,\n+                    new_metrics.coverage - metrics.coverage,\n+                    new_metrics.overlap,\n+                    new_metrics.overlap - metrics.overlap,\n+                    new_metrics.duplication,\n+                    new_metrics.duplication - metrics.duplication\n+                );\n             } else {\n                 println!(\"No compaction needed\");\n             }\n \n             // Modify warm keys\n-            containers.push(Container::new(warm_keys.clone()));\n+            batch_index += 1;\n+            let pieces = rnd.random_range(1..4);\n+            for chunk in warm_keys.chunks(warm_keys.len().div_ceil(pieces)) {\n+                containers.push(Container::new(batch_index, chunk.to_vec()));\n+            }\n \n             // Change some warm keys\n-            for _ in 0..10 {\n+            let changes = rnd.random_range(0..100);\n+            for _ in 0..changes {\n                 let i = rnd.random_range(0..warm_keys.len());\n                 let j = rnd.random_range(0..keys.len());\n                 swap(&mut warm_keys[i], &mut keys[j]);\n             }\n         }\n         println!(\"Number of compactions: {number_of_compactions}\");\n \n-        assert!(containers.len() < 40);\n-        let coverage = total_coverage(&containers, (0, 10000));\n-        assert!(coverage < 12.0);\n+        let metrics = compute_metrics(&containers, (0, KEY_RANGE));\n+        assert!(number_of_compactions < 40);\n+        assert!(containers.len() < 30);\n+        assert!(metrics.duplication < 0.5);\n     }\n \n     struct Container {\n+        batch_index: usize,\n         keys: Vec<u64>,\n     }\n \n     impl Container {\n-        fn new(mut keys: Vec<u64>) -> Self {\n+        fn new(batch_index: usize, mut keys: Vec<u64>) -> Self {\n             keys.sort_unstable();\n-            Self { keys }\n+            Self { batch_index, keys }\n         }\n     }\n \n@@ -395,30 +661,44 @@ mod tests {\n     impl Debug for Container {\n         fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n             let (l, r) = self.range();\n-            write!(f, \"{} {l} - {r} ({})\", self.keys.len(), r - l)\n+            write!(\n+                f,\n+                \"#{} {}b {l} - {r} ({})\",\n+                self.batch_index,\n+                self.keys.len(),\n+                r - l\n+            )\n         }\n     }\n \n-    fn do_compact(containers: &mut Vec<Container>, jobs: CompactionJobs) {\n-        for merge_job in jobs.merge_jobs {\n-            let mut keys = Vec::new();\n-            for i in merge_job {\n-                keys.append(&mut containers[i].keys);\n+    fn do_compact(containers: &mut Vec<Container>, segments: MergeSegments, batch_index: usize) {\n+        let total_size = containers.iter().map(|c| c.keys.len()).sum::<usize>();\n+        for merge_job in segments {\n+            if merge_job.len() < 2 {\n+                let container = replace(\n+                    &mut containers[merge_job[0]],\n+                    Container {\n+                        batch_index: 0,\n+                        keys: Default::default(),\n+                    },\n+                );\n+                containers.push(container);\n+            } else {\n+                let mut keys = Vec::new();\n+                for i in merge_job {\n+                    keys.append(&mut containers[i].keys);\n+                }\n+                keys.sort_unstable();\n+                keys.dedup();\n+                containers.extend(keys.chunks(1000).map(|keys| Container {\n+                    batch_index,\n+                    keys: keys.to_vec(),\n+                }));\n             }\n-            keys.sort_unstable();\n-            keys.dedup();\n-            containers.extend(keys.chunks(100).map(|keys| Container {\n-                keys: keys.to_vec(),\n-            }));\n-        }\n-\n-        for i in jobs.move_jobs {\n-            let moved_container = Container {\n-                keys: take(&mut containers[i].keys),\n-            };\n-            containers.push(moved_container);\n         }\n \n         containers.retain(|c| !c.keys.is_empty());\n+        let total_size2 = containers.iter().map(|c| c.keys.len()).sum::<usize>();\n+        println!(\"Compaction done: {total_size} -> {total_size2}\",);\n     }\n }"
        },
        {
            "sha": "d1c2de1db43e79fae5c1bb3b1c8c93e5ae12e99b",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 116,
            "deletions": 111,
            "changes": 227,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -21,12 +21,11 @@ use parking_lot::{Mutex, RwLock};\n use rayon::iter::{IndexedParallelIterator, IntoParallelIterator, ParallelIterator};\n use tracing::Span;\n \n+pub use crate::compaction::selector::CompactConfig;\n use crate::{\n     QueryKey,\n     arc_slice::ArcSlice,\n-    compaction::selector::{\n-        CompactConfig, Compactable, CompactionJobs, get_compaction_jobs, total_coverage,\n-    },\n+    compaction::selector::{Compactable, compute_metrics, get_merge_segments},\n     constants::{\n         AQMF_AVG_SIZE, AQMF_CACHE_SIZE, DATA_THRESHOLD_PER_COMPACTED_FILE, KEY_BLOCK_AVG_SIZE,\n         KEY_BLOCK_CACHE_SIZE, MAX_ENTRIES_PER_COMPACTED_FILE, VALUE_BLOCK_AVG_SIZE,\n@@ -650,20 +649,23 @@ impl TurboPersistence {\n     /// Runs a full compaction on the database. This will rewrite all SST files, removing all\n     /// duplicate keys and separating all key ranges into unique files.\n     pub fn full_compact(&self) -> Result<()> {\n-        self.compact(0.0, usize::MAX, u64::MAX)?;\n+        self.compact(&CompactConfig {\n+            min_merge_count: 2,\n+            optimal_merge_count: usize::MAX,\n+            max_merge_count: usize::MAX,\n+            max_merge_bytes: u64::MAX,\n+            min_merge_duplication_bytes: 0,\n+            optimal_merge_duplication_bytes: u64::MAX,\n+            max_merge_segment_count: usize::MAX,\n+        })?;\n         Ok(())\n     }\n \n     /// Runs a (partial) compaction. Compaction will only be performed if the coverage of the SST\n     /// files is above the given threshold. The coverage is the average number of SST files that\n     /// need to be read to find a key. It also limits the maximum number of SST files that are\n     /// merged at once, which is the main factor for the runtime of the compaction.\n-    pub fn compact(\n-        &self,\n-        max_coverage: f32,\n-        max_merge_sequence: usize,\n-        max_merge_size: u64,\n-    ) -> Result<()> {\n+    pub fn compact(&self, compact_config: &CompactConfig) -> Result<()> {\n         if self.read_only {\n             bail!(\"Compaction is not allowed on a read only database\");\n         }\n@@ -697,9 +699,7 @@ impl TurboPersistence {\n                 &mut sst_seq_numbers_to_delete,\n                 &mut blob_seq_numbers_to_delete,\n                 &mut keys_written,\n-                max_coverage,\n-                max_merge_sequence,\n-                max_merge_size,\n+                compact_config,\n             )\n             .context(\"Failed to compact database\")?;\n         }\n@@ -732,9 +732,7 @@ impl TurboPersistence {\n         sst_seq_numbers_to_delete: &mut Vec<u32>,\n         blob_seq_numbers_to_delete: &mut Vec<u32>,\n         keys_written: &mut u64,\n-        max_coverage: f32,\n-        max_merge_sequence: usize,\n-        max_merge_size: u64,\n+        compact_config: &CompactConfig,\n     ) -> Result<()> {\n         if meta_files.is_empty() {\n             return Ok(());\n@@ -811,8 +809,10 @@ impl TurboPersistence {\n             .map(|(family, ssts_with_ranges)| {\n                 let family = family as u32;\n                 let _span = span.clone().entered();\n-                let coverage = total_coverage(&ssts_with_ranges, (0, u64::MAX));\n-                if coverage <= max_coverage {\n+\n+                let merge_jobs = get_merge_segments(&ssts_with_ranges, compact_config);\n+\n+                if merge_jobs.is_empty() {\n                     return Ok(PartialResultPerFamily {\n                         new_meta_file: None,\n                         new_sst_files: Vec::new(),\n@@ -822,24 +822,18 @@ impl TurboPersistence {\n                     });\n                 }\n \n-                let CompactionJobs {\n-                    merge_jobs,\n-                    move_jobs,\n-                } = get_compaction_jobs(\n-                    &ssts_with_ranges,\n-                    &CompactConfig {\n-                        min_merge: 2,\n-                        max_merge: max_merge_sequence,\n-                        max_merge_size,\n-                    },\n-                );\n-\n-                if !merge_jobs.is_empty() {\n+                {\n+                    let metrics = compute_metrics(&ssts_with_ranges, (0, u64::MAX));\n                     let guard = log_mutex.lock();\n                     let mut log = self.open_log()?;\n                     writeln!(\n                         log,\n-                        \"Compaction for family {family} (coverage: {coverage}):\"\n+                        \"Compaction for family {family} (coverage: {}, overlap: {}, duplication: \\\n+                         {} / {} MiB):\",\n+                        metrics.coverage,\n+                        metrics.overlap,\n+                        metrics.duplication,\n+                        metrics.duplicated_size / 1024 / 1024\n                     )?;\n                     for job in merge_jobs.iter() {\n                         writeln!(log, \"  merge\")?;\n@@ -855,32 +849,63 @@ impl TurboPersistence {\n                 // Later we will remove the merged files\n                 let sst_seq_numbers_to_delete = merge_jobs\n                     .iter()\n+                    .filter(|l| l.len() > 1)\n                     .flat_map(|l| l.iter().copied())\n                     .map(|index| ssts_with_ranges[index].seq)\n                     .collect::<Vec<_>>();\n \n-                let meta_file_builder = Mutex::new(MetaFileBuilder::new(family));\n-\n                 // Merge SST files\n                 let span = tracing::trace_span!(\"merge files\");\n-                struct PartialMergeResult {\n-                    new_sst_files: Vec<(u32, File)>,\n-                    blob_seq_numbers_to_delete: Vec<u32>,\n-                    keys_written: u64,\n+                enum PartialMergeResult<'l> {\n+                    Merged {\n+                        new_sst_files: Vec<(u32, File, StaticSortedFileBuilderMeta<'static>)>,\n+                        blob_seq_numbers_to_delete: Vec<u32>,\n+                        keys_written: u64,\n+                    },\n+                    Move {\n+                        seq: u32,\n+                        meta: StaticSortedFileBuilderMeta<'l>,\n+                    },\n                 }\n                 let merge_result = merge_jobs\n                     .into_par_iter()\n                     .with_min_len(1)\n                     .map(|indicies| {\n                         let _span = span.clone().entered();\n+                        if indicies.len() == 1 {\n+                            // If we only have one file, we can just move it\n+                            let index = indicies[0];\n+                            let meta_index = ssts_with_ranges[index].meta_index;\n+                            let index_in_meta = ssts_with_ranges[index].index_in_meta;\n+                            let meta_file = &meta_files[meta_index];\n+                            let entry = meta_file.entry(index_in_meta);\n+                            let aqmf = Cow::Borrowed(entry.raw_aqmf(meta_file.aqmf_data()));\n+                            let meta = StaticSortedFileBuilderMeta {\n+                                min_hash: entry.min_hash(),\n+                                max_hash: entry.max_hash(),\n+                                aqmf,\n+                                key_compression_dictionary_length: entry\n+                                    .key_compression_dictionary_length(),\n+                                value_compression_dictionary_length: entry\n+                                    .value_compression_dictionary_length(),\n+                                block_count: entry.block_count(),\n+                                size: entry.size(),\n+                                entries: 0,\n+                            };\n+                            return Ok(PartialMergeResult::Move {\n+                                seq: entry.sequence_number(),\n+                                meta,\n+                            });\n+                        }\n+\n                         fn create_sst_file(\n                             entries: &[LookupEntry],\n                             total_key_size: usize,\n                             total_value_size: usize,\n                             path: &Path,\n                             seq: u32,\n-                            meta_file_builder: &Mutex<MetaFileBuilder>,\n-                        ) -> Result<(u32, File)> {\n+                        ) -> Result<(u32, File, StaticSortedFileBuilderMeta<'static>)>\n+                        {\n                             let _span = tracing::trace_span!(\"write merged sst file\").entered();\n                             let builder = StaticSortedFileBuilder::new(\n                                 entries,\n@@ -889,8 +914,7 @@ impl TurboPersistence {\n                             )?;\n                             let (meta, file) =\n                                 builder.write(&path.join(format!(\"{seq:08}.sst\")))?;\n-                            meta_file_builder.lock().add(seq, meta);\n-                            Ok((seq, file))\n+                            Ok((seq, file, meta))\n                         }\n \n                         let mut new_sst_files = Vec::new();\n@@ -958,7 +982,6 @@ impl TurboPersistence {\n                                                 selected_total_value_size,\n                                                 path,\n                                                 seq,\n-                                                &meta_file_builder,\n                                             )?);\n \n                                             entries.clear();\n@@ -989,7 +1012,6 @@ impl TurboPersistence {\n                                 total_value_size,\n                                 path,\n                                 seq,\n-                                &meta_file_builder,\n                             )?);\n                         } else\n                         // If we have two sets of entries left, merge them and\n@@ -1014,7 +1036,6 @@ impl TurboPersistence {\n                                 last_entries_total_sizes.1 / 2,\n                                 path,\n                                 seq1,\n-                                &meta_file_builder,\n                             )?);\n \n                             keys_written += part2.len() as u64;\n@@ -1024,10 +1045,9 @@ impl TurboPersistence {\n                                 last_entries_total_sizes.1 / 2,\n                                 path,\n                                 seq2,\n-                                &meta_file_builder,\n                             )?);\n                         }\n-                        Ok(PartialMergeResult {\n+                        Ok(PartialMergeResult::Merged {\n                             new_sst_files,\n                             blob_seq_numbers_to_delete,\n                             keys_written,\n@@ -1038,76 +1058,61 @@ impl TurboPersistence {\n                         format!(\"Failed to merge database files for family {family}\")\n                     })?;\n \n-                let mut meta_file_builder = meta_file_builder.into_inner();\n+                let Some((sst_files_len, blob_delete_len)) = merge_result\n+                    .iter()\n+                    .map(|r| {\n+                        if let PartialMergeResult::Merged {\n+                            new_sst_files,\n+                            blob_seq_numbers_to_delete,\n+                            keys_written: _,\n+                        } = r\n+                        {\n+                            (new_sst_files.len(), blob_seq_numbers_to_delete.len())\n+                        } else {\n+                            (0, 0)\n+                        }\n+                    })\n+                    .reduce(|(a1, a2), (b1, b2)| (a1 + b1, a2 + b2))\n+                else {\n+                    unreachable!()\n+                };\n \n-                for &seq in sst_seq_numbers_to_delete.iter() {\n-                    meta_file_builder.add_obsolete_sst_file(seq);\n+                let mut new_sst_files = Vec::with_capacity(sst_files_len);\n+                let mut blob_seq_numbers_to_delete = Vec::with_capacity(blob_delete_len);\n+\n+                let mut meta_file_builder = MetaFileBuilder::new(family);\n+\n+                let mut keys_written = 0;\n+                for result in merge_result {\n+                    match result {\n+                        PartialMergeResult::Merged {\n+                            new_sst_files: merged_new_sst_files,\n+                            blob_seq_numbers_to_delete: merged_blob_seq_numbers_to_delete,\n+                            keys_written: merged_keys_written,\n+                        } => {\n+                            for (seq, file, meta) in merged_new_sst_files {\n+                                meta_file_builder.add(seq, meta);\n+                                new_sst_files.push((seq, file));\n+                            }\n+                            blob_seq_numbers_to_delete.extend(merged_blob_seq_numbers_to_delete);\n+                            keys_written += merged_keys_written;\n+                        }\n+                        PartialMergeResult::Move { seq, meta } => {\n+                            meta_file_builder.add(seq, meta);\n+                        }\n+                    }\n                 }\n \n-                // Move SST files\n-                let span = tracing::trace_span!(\"query moved sst files\").entered();\n-                for index in move_jobs {\n-                    let meta_index = ssts_with_ranges[index].meta_index;\n-                    let index_in_meta = ssts_with_ranges[index].index_in_meta;\n-                    let meta_file = &meta_files[meta_index];\n-                    let entry = meta_file.entry(index_in_meta);\n-                    let aqmf = Cow::Borrowed(entry.raw_aqmf(meta_file.aqmf_data()));\n-                    let meta = StaticSortedFileBuilderMeta {\n-                        min_hash: entry.min_hash(),\n-                        max_hash: entry.max_hash(),\n-                        aqmf,\n-                        key_compression_dictionary_length: entry\n-                            .key_compression_dictionary_length(),\n-                        value_compression_dictionary_length: entry\n-                            .value_compression_dictionary_length(),\n-                        block_count: entry.block_count(),\n-                        size: entry.size(),\n-                        entries: 0,\n-                    };\n-                    meta_file_builder.add(entry.sequence_number(), meta);\n+                for &seq in sst_seq_numbers_to_delete.iter() {\n+                    meta_file_builder.add_obsolete_sst_file(seq);\n                 }\n-                drop(span);\n \n-                let span = tracing::trace_span!(\"write meta file\").entered();\n                 let seq = sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n-                let meta_file = meta_file_builder.write(&self.path, seq)?;\n-                drop(span);\n-\n-                let mut new_sst_files = Vec::with_capacity(\n-                    merge_result\n-                        .iter()\n-                        .map(\n-                            |PartialMergeResult {\n-                                 new_sst_files: v,\n-                                 blob_seq_numbers_to_delete: _,\n-                                 keys_written: _,\n-                             }| v.len(),\n-                        )\n-                        .sum(),\n-                );\n-                let mut blob_seq_numbers_to_delete = Vec::with_capacity(\n-                    merge_result\n-                        .iter()\n-                        .map(\n-                            |PartialMergeResult {\n-                                 new_sst_files: _,\n-                                 blob_seq_numbers_to_delete: v,\n-                                 keys_written: _,\n-                             }| v.len(),\n-                        )\n-                        .sum(),\n-                );\n-                let mut keys_written = 0;\n-                for PartialMergeResult {\n-                    new_sst_files: merged_new_sst_files,\n-                    blob_seq_numbers_to_delete: merged_blob_seq_numbers_to_delete,\n-                    keys_written: merged_keys_written,\n-                } in merge_result\n-                {\n-                    new_sst_files.extend(merged_new_sst_files);\n-                    blob_seq_numbers_to_delete.extend(merged_blob_seq_numbers_to_delete);\n-                    keys_written += merged_keys_written;\n-                }\n+                let meta_file = {\n+                    let _span = tracing::trace_span!(\"write meta file\").entered();\n+                    meta_file_builder.write(&self.path, seq)?\n+                };\n+\n                 Ok(PartialResultPerFamily {\n                     new_meta_file: Some((seq, meta_file)),\n                     new_sst_files,"
        },
        {
            "sha": "866d2e910464ffc7e21391d3050fda80d6de66b9",
            "filename": "turbopack/crates/turbo-persistence/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -24,7 +24,7 @@ mod value_buf;\n mod write_batch;\n \n pub use arc_slice::ArcSlice;\n-pub use db::{MetaFileEntryInfo, MetaFileInfo, TurboPersistence};\n+pub use db::{CompactConfig, MetaFileEntryInfo, MetaFileInfo, TurboPersistence};\n pub use key::{KeyBase, QueryKey, StoreKey};\n pub use value_buf::ValueBuffer;\n pub use write_batch::WriteBatch;"
        },
        {
            "sha": "5c123611d8759e0045710f0e2f7945884b6ee401",
            "filename": "turbopack/crates/turbo-persistence/src/tests.rs",
            "status": "modified",
            "additions": 23,
            "deletions": 4,
            "changes": 27,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -3,7 +3,11 @@ use std::{fs, time::Instant};\n use anyhow::Result;\n use rayon::iter::{IntoParallelIterator, ParallelIterator};\n \n-use crate::{constants::MAX_MEDIUM_VALUE_SIZE, db::TurboPersistence, write_batch::WriteBatch};\n+use crate::{\n+    constants::MAX_MEDIUM_VALUE_SIZE,\n+    db::{CompactConfig, TurboPersistence},\n+    write_batch::WriteBatch,\n+};\n \n #[test]\n fn full_cycle() -> Result<()> {\n@@ -455,7 +459,12 @@ fn persist_changes() -> Result<()> {\n     {\n         let db = TurboPersistence::open(path.to_path_buf())?;\n \n-        db.compact(1.0, 3, u64::MAX)?;\n+        db.compact(&CompactConfig {\n+            optimal_merge_count: 4,\n+            min_merge_duplication_bytes: 1,\n+            optimal_merge_duplication_bytes: 1,\n+            ..Default::default()\n+        })?;\n \n         check(&db, 1, 13)?;\n         check(&db, 2, 22)?;\n@@ -528,7 +537,12 @@ fn partial_compaction() -> Result<()> {\n         {\n             let db = TurboPersistence::open(path.to_path_buf())?;\n \n-            db.compact(3.0, 3, u64::MAX)?;\n+            db.compact(&CompactConfig {\n+                optimal_merge_count: 4,\n+                min_merge_duplication_bytes: 1,\n+                optimal_merge_duplication_bytes: 1,\n+                ..Default::default()\n+            })?;\n \n             for j in 0..i {\n                 check(&db, j, j)?;\n@@ -630,7 +644,12 @@ fn merge_file_removal() -> Result<()> {\n         {\n             let db = TurboPersistence::open(path.to_path_buf())?;\n \n-            db.compact(3.0, 3, u64::MAX)?;\n+            db.compact(&CompactConfig {\n+                optimal_merge_count: 4,\n+                min_merge_duplication_bytes: 1,\n+                optimal_merge_duplication_bytes: 1,\n+                ..Default::default()\n+            })?;\n \n             for j in 0..32 {\n                 check(&db, j, expected_values[j as usize])?;"
        },
        {
            "sha": "e8accef018d1664aa1154078b5b7073fc9411163",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/turbo.rs",
            "status": "modified",
            "additions": 25,
            "deletions": 15,
            "changes": 40,
            "blob_url": "https://github.com/vercel/next.js/blob/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/9b151f2d54abe4bafd41c27d6d2bc381dedb6036/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo.rs?ref=9b151f2d54abe4bafd41c27d6d2bc381dedb6036",
            "patch": "@@ -1,21 +1,31 @@\n use std::{\n+    cmp::max,\n     path::PathBuf,\n     sync::Arc,\n-    thread::{JoinHandle, spawn},\n+    thread::{JoinHandle, available_parallelism, spawn},\n };\n \n use anyhow::Result;\n use parking_lot::Mutex;\n-use turbo_persistence::{ArcSlice, KeyBase, StoreKey, TurboPersistence, ValueBuffer};\n+use turbo_persistence::{\n+    ArcSlice, CompactConfig, KeyBase, StoreKey, TurboPersistence, ValueBuffer,\n+};\n \n use crate::database::{\n     key_value_database::{KeySpace, KeyValueDatabase},\n     write_batch::{BaseWriteBatch, ConcurrentWriteBatch, WriteBatch, WriteBuffer},\n };\n \n-const COMPACT_MAX_COVERAGE: f32 = 20.0;\n-const COMPACT_MAX_MERGE_SEQUENCE: usize = 64;\n-const COMPACT_MAX_MERGE_SIZE: u64 = 512 * 1024 * 1024; // 512 MiB\n+const MB: u64 = 1024 * 1024;\n+const COMPACT_CONFIG: CompactConfig = CompactConfig {\n+    min_merge_count: 3,\n+    optimal_merge_count: 8,\n+    max_merge_count: 64,\n+    max_merge_bytes: 512 * MB,\n+    min_merge_duplication_bytes: MB,\n+    optimal_merge_duplication_bytes: 100 * MB,\n+    max_merge_segment_count: 16,\n+};\n \n pub struct TurboKeyValueDatabase {\n     db: Arc<TurboPersistence>,\n@@ -32,11 +42,11 @@ impl TurboKeyValueDatabase {\n         // start compaction in background if the database is not empty\n         if !db.is_empty() {\n             let handle = spawn(move || {\n-                db.compact(\n-                    COMPACT_MAX_COVERAGE,\n-                    COMPACT_MAX_MERGE_SEQUENCE,\n-                    COMPACT_MAX_MERGE_SIZE,\n-                )\n+                db.compact(&CompactConfig {\n+                    max_merge_segment_count: available_parallelism()\n+                        .map_or(4, |c| max(4, c.get() / 4)),\n+                    ..COMPACT_CONFIG\n+                })\n             });\n             this.compact_join_handle.get_mut().replace(handle);\n         }\n@@ -140,11 +150,11 @@ impl<'a> BaseWriteBatch<'a> for TurboWriteBatch<'a> {\n             // Start a new compaction in the background\n             let db = self.db.clone();\n             let handle = spawn(move || {\n-                db.compact(\n-                    COMPACT_MAX_COVERAGE,\n-                    COMPACT_MAX_MERGE_SEQUENCE,\n-                    COMPACT_MAX_MERGE_SIZE,\n-                )\n+                db.compact(&CompactConfig {\n+                    max_merge_segment_count: available_parallelism()\n+                        .map_or(4, |c| max(4, c.get() / 2)),\n+                    ..COMPACT_CONFIG\n+                })\n             });\n             self.compact_join_handle.lock().replace(handle);\n         }"
        }
    ],
    "stats": {
        "total": 1214,
        "additions": 857,
        "deletions": 357
    }
}