{
    "author": "wyattjoh",
    "message": "Use cacheMaxMemorySize config in default cache handler (#85153)\n\n### What?\n\nThis refactoring enables the `cacheMaxMemorySize` configuration option\nto control the memory limits of the default \"use cache\" handler.\n\n### Why?\n\nPreviously, the default cache handler was hardcoded to use 50MB of\nmemory, ignoring the user's `cacheMaxMemorySize` configuration. This\nmeant users couldn't:\n- Disable internal caching when using external CDNs (by setting size to\n0)\n- Customize memory limits based on their deployment environment\n- Control memory usage for the \"use cache\" handler\n\n### How?\n\n- Extracted cache handler creation into `createDefaultCacheHandler()`\nfactory function\n- Threaded `cacheMaxMemorySize` through `initializeCacheHandlers()`\ncalls\n- Harmonized parameter naming (`maxMemoryCacheSize` â†’\n`cacheMaxMemorySize`) for consistency with the config\n- Made `cacheMaxMemorySize` required in type signatures\n- Added zero-size optimization (returns no-op handler when size=0)",
    "sha": "d58f7aa0d1d78341573ba67af797f618ddd84060",
    "files": [
        {
            "sha": "1aacdf0f0169a805266e76eb79770118cb778c60",
            "filename": "packages/next/src/build/index.ts",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -2012,6 +2012,7 @@ export default async function build(\n               cacheLifeProfiles: config.cacheLife,\n               buildId,\n               sriEnabled,\n+              cacheMaxMemorySize: config.cacheMaxMemorySize,\n             })\n         )\n \n@@ -2227,7 +2228,7 @@ export default async function build(\n                             isrFlushToDisk: ciEnvironment.hasNextSupport\n                               ? false\n                               : config.experimental.isrFlushToDisk,\n-                            maxMemoryCacheSize: config.cacheMaxMemorySize,\n+                            cacheMaxMemorySize: config.cacheMaxMemorySize,\n                             nextConfigOutput: config.output,\n                             pprConfig: config.experimental.ppr,\n                             cacheLifeProfiles: config.cacheLife,"
        },
        {
            "sha": "c7feadd24cccfb4e39007bc282a309d0593ac849",
            "filename": "packages/next/src/build/static-paths/app.ts",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Fstatic-paths%2Fapp.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Fstatic-paths%2Fapp.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fstatic-paths%2Fapp.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -730,7 +730,7 @@ export async function buildAppStaticPaths({\n   cacheLifeProfiles,\n   requestHeaders,\n   cacheHandlers,\n-  maxMemoryCacheSize,\n+  cacheMaxMemorySize,\n   fetchCacheKeyPrefix,\n   nextConfigOutput,\n   ComponentMod,\n@@ -751,7 +751,7 @@ export async function buildAppStaticPaths({\n   cacheLifeProfiles?: {\n     [profile: string]: import('../../server/use-cache/cache-life').CacheLife\n   }\n-  maxMemoryCacheSize?: number\n+  cacheMaxMemorySize: number\n   requestHeaders: IncrementalCache['requestHeaders']\n   nextConfigOutput: 'standalone' | 'export' | undefined\n   ComponentMod: AppPageModule\n@@ -778,7 +778,7 @@ export async function buildAppStaticPaths({\n     requestHeaders,\n     fetchCacheKeyPrefix,\n     flushToDisk: isrFlushToDisk,\n-    cacheMaxMemorySize: maxMemoryCacheSize,\n+    cacheMaxMemorySize,\n   })\n \n   const childrenRouteParamSegments: Array<{"
        },
        {
            "sha": "65322faff9e348e455f4b2b9d24882b7108c3031",
            "filename": "packages/next/src/build/templates/edge-ssr-app.ts",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr-app.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr-app.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr-app.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -27,14 +27,12 @@ import { checkIsOnDemandRevalidate } from '../../server/api-utils'\n import { CloseController } from '../../server/web/web-on-close'\n \n declare const incrementalCacheHandler: any\n+declare const nextConfig: NextConfigComplete\n // OPTIONAL_IMPORT:incrementalCacheHandler\n+// INJECT:nextConfig\n \n // Initialize the cache handlers interface.\n-initializeCacheHandlers()\n-\n-// injected by the loader afterwards.\n-declare const nextConfig: NextConfigComplete\n-// INJECT:nextConfig\n+initializeCacheHandlers(nextConfig.cacheMaxMemorySize)\n \n const maybeJSONParse = (str?: string) => (str ? JSON.parse(str) : undefined)\n "
        },
        {
            "sha": "5431190f5906a895015b5d364d1cd7547274077e",
            "filename": "packages/next/src/build/templates/edge-ssr.ts",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Ftemplates%2Fedge-ssr.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -38,7 +38,7 @@ declare const user500RouteModuleOptions: any\n // INJECT:user500RouteModuleOptions\n \n // Initialize the cache handlers interface.\n-initializeCacheHandlers()\n+initializeCacheHandlers(nextConfig.cacheMaxMemorySize)\n \n // expose this for the route-module\n ;(globalThis as any).nextConfig = nextConfig"
        },
        {
            "sha": "78fedfee3a1ff2162b8dae2f6ced0ed03dbae7b4",
            "filename": "packages/next/src/build/utils.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Futils.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fbuild%2Futils.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Futils.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -684,7 +684,7 @@ export async function isPageStatic({\n   authInterrupts,\n   originalAppPath,\n   isrFlushToDisk,\n-  maxMemoryCacheSize,\n+  cacheMaxMemorySize,\n   nextConfigOutput,\n   cacheHandler,\n   cacheHandlers,\n@@ -708,7 +708,7 @@ export async function isPageStatic({\n   pageRuntime?: ServerRuntime\n   originalAppPath?: string\n   isrFlushToDisk?: boolean\n-  maxMemoryCacheSize?: number\n+  cacheMaxMemorySize: number\n   cacheHandler?: string\n   cacheHandlers?: Record<string, string | undefined>\n   cacheLifeProfiles?: {\n@@ -740,7 +740,7 @@ export async function isPageStatic({\n     distDir,\n     dir,\n     flushToDisk: isrFlushToDisk,\n-    cacheMaxMemorySize: maxMemoryCacheSize,\n+    cacheMaxMemorySize,\n   })\n \n   const isPageStaticSpan = trace('is-page-static-utils', parentId)\n@@ -866,7 +866,7 @@ export async function isPageStatic({\n               distDir,\n               requestHeaders: {},\n               isrFlushToDisk,\n-              maxMemoryCacheSize,\n+              cacheMaxMemorySize,\n               cacheHandler,\n               cacheLifeProfiles,\n               ComponentMod,"
        },
        {
            "sha": "7f13c795178e67215bf6d1cf5d838c3e06a42ef3",
            "filename": "packages/next/src/export/helpers/create-incremental-cache.ts",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fexport%2Fhelpers%2Fcreate-incremental-cache.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fexport%2Fhelpers%2Fcreate-incremental-cache.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fexport%2Fhelpers%2Fcreate-incremental-cache.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -20,7 +20,7 @@ export async function createIncrementalCache({\n   requestHeaders,\n }: {\n   cacheHandler?: string\n-  cacheMaxMemorySize?: number\n+  cacheMaxMemorySize: number\n   fetchCacheKeyPrefix?: string\n   distDir: string\n   dir: string\n@@ -38,7 +38,7 @@ export async function createIncrementalCache({\n     )\n   }\n \n-  if (cacheHandlers && initializeCacheHandlers()) {\n+  if (cacheHandlers && initializeCacheHandlers(cacheMaxMemorySize)) {\n     for (const [kind, handler] of Object.entries(cacheHandlers)) {\n       if (!handler) continue\n "
        },
        {
            "sha": "441c0eb366fd9d2a429b75a778927c3edbdd3d1c",
            "filename": "packages/next/src/export/types.ts",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fexport%2Ftypes.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fexport%2Ftypes.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fexport%2Ftypes.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -27,7 +27,7 @@ export interface ExportPagesInput {\n   pagesDataDir: string\n   renderOpts: WorkerRenderOptsPartial\n   nextConfig: NextConfigComplete\n-  cacheMaxMemorySize: NextConfigComplete['cacheMaxMemorySize'] | undefined\n+  cacheMaxMemorySize: NextConfigComplete['cacheMaxMemorySize']\n   fetchCache: boolean | undefined\n   cacheHandler: string | undefined\n   fetchCacheKeyPrefix: string | undefined"
        },
        {
            "sha": "c9618b05f27d9e06a416368a1df3c26b15606894",
            "filename": "packages/next/src/server/dev/next-dev-server.ts",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fnext-dev-server.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fnext-dev-server.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fnext-dev-server.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -765,7 +765,7 @@ export default class DevServer extends Server {\n           cacheLifeProfiles: this.nextConfig.cacheLife,\n           fetchCacheKeyPrefix: this.nextConfig.experimental.fetchCacheKeyPrefix,\n           isrFlushToDisk: this.nextConfig.experimental.isrFlushToDisk,\n-          maxMemoryCacheSize: this.nextConfig.cacheMaxMemorySize,\n+          cacheMaxMemorySize: this.nextConfig.cacheMaxMemorySize,\n           nextConfigOutput: this.nextConfig.output,\n           buildId: this.buildId,\n           authInterrupts: Boolean(this.nextConfig.experimental.authInterrupts),"
        },
        {
            "sha": "7b3a52d59adf42de3affe55def49da43decdf722",
            "filename": "packages/next/src/server/dev/static-paths-worker.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fstatic-paths-worker.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fstatic-paths-worker.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fdev%2Fstatic-paths-worker.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -42,7 +42,7 @@ export async function loadStaticPaths({\n   page,\n   isrFlushToDisk,\n   fetchCacheKeyPrefix,\n-  maxMemoryCacheSize,\n+  cacheMaxMemorySize,\n   requestHeaders,\n   cacheHandler,\n   cacheHandlers,\n@@ -63,7 +63,7 @@ export async function loadStaticPaths({\n   page: string\n   isrFlushToDisk?: boolean\n   fetchCacheKeyPrefix?: string\n-  maxMemoryCacheSize?: number\n+  cacheMaxMemorySize: number\n   requestHeaders: IncrementalCache['requestHeaders']\n   cacheHandler?: string\n   cacheHandlers?: NextConfigComplete['experimental']['cacheHandlers']\n@@ -85,7 +85,7 @@ export async function loadStaticPaths({\n     requestHeaders,\n     fetchCacheKeyPrefix,\n     flushToDisk: isrFlushToDisk,\n-    cacheMaxMemorySize: maxMemoryCacheSize,\n+    cacheMaxMemorySize,\n   })\n \n   // update work memory runtime-config\n@@ -128,7 +128,7 @@ export async function loadStaticPaths({\n       cacheLifeProfiles,\n       isrFlushToDisk,\n       fetchCacheKeyPrefix,\n-      maxMemoryCacheSize,\n+      cacheMaxMemorySize,\n       ComponentMod: components.ComponentMod,\n       nextConfigOutput,\n       isRoutePPREnabled,"
        },
        {
            "sha": "f88934fc89b7bf1a4045fa70622a44751e5ffe2f",
            "filename": "packages/next/src/server/lib/cache-handlers/default.external.ts",
            "status": "modified",
            "additions": 6,
            "deletions": 192,
            "changes": 198,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.external.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.external.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.external.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -1,194 +1,8 @@\n+import { createDefaultCacheHandler } from './default'\n+\n /**\n- * This is the default \"use cache\" handler it defaults to an in-memory store.\n- * In-memory caches are fragile and should not use stale-while-revalidate\n- * semantics on the caches because it's not worth warming up an entry that's\n- * likely going to get evicted before we get to use it anyway. However, we also\n- * don't want to reuse a stale entry for too long so stale entries should be\n- * considered expired/missing in such cache handlers.\n+ * Used for edge runtime compatibility.\n+ *\n+ * @deprecated Use createDefaultCacheHandler instead.\n  */\n-\n-import { LRUCache } from '../lru-cache'\n-import type { CacheEntry, CacheHandler } from './types'\n-import {\n-  areTagsExpired,\n-  areTagsStale,\n-  tagsManifest,\n-  type TagManifestEntry,\n-} from '../incremental-cache/tags-manifest.external'\n-\n-type PrivateCacheEntry = {\n-  entry: CacheEntry\n-\n-  // For the default cache we store errored cache\n-  // entries and allow them to be used up to 3 times\n-  // after that we want to dispose it and try for fresh\n-\n-  // If an entry is errored we return no entry\n-  // three times so that we retry hitting origin (MISS)\n-  // and then if it still fails to set after the third we\n-  // return the errored content and use expiration of\n-  // Math.min(30, entry.expiration)\n-  isErrored: boolean\n-  errorRetryCount: number\n-\n-  // compute size on set since we need to read size\n-  // of the ReadableStream for LRU evicting\n-  size: number\n-}\n-\n-// LRU cache default to max 50 MB but in future track\n-const memoryCache = new LRUCache<PrivateCacheEntry>(\n-  50 * 1024 * 1024,\n-  (entry) => entry.size\n-)\n-const pendingSets = new Map<string, Promise<void>>()\n-\n-const debug = process.env.NEXT_PRIVATE_DEBUG_CACHE\n-  ? console.debug.bind(console, 'DefaultCacheHandler:')\n-  : undefined\n-\n-const DefaultCacheHandler: CacheHandler = {\n-  async get(cacheKey) {\n-    const pendingPromise = pendingSets.get(cacheKey)\n-\n-    if (pendingPromise) {\n-      debug?.('get', cacheKey, 'pending')\n-      await pendingPromise\n-    }\n-\n-    const privateEntry = memoryCache.get(cacheKey)\n-\n-    if (!privateEntry) {\n-      debug?.('get', cacheKey, 'not found')\n-      return undefined\n-    }\n-\n-    const entry = privateEntry.entry\n-    if (\n-      performance.timeOrigin + performance.now() >\n-      entry.timestamp + entry.revalidate * 1000\n-    ) {\n-      // In-memory caches should expire after revalidate time because it is\n-      // unlikely that a new entry will be able to be used before it is dropped\n-      // from the cache.\n-      debug?.('get', cacheKey, 'expired')\n-\n-      return undefined\n-    }\n-\n-    let revalidate = entry.revalidate\n-\n-    if (areTagsExpired(entry.tags, entry.timestamp)) {\n-      debug?.('get', cacheKey, 'had expired tag')\n-      return undefined\n-    }\n-\n-    if (areTagsStale(entry.tags, entry.timestamp)) {\n-      debug?.('get', cacheKey, 'had stale tag')\n-      revalidate = -1\n-    }\n-\n-    const [returnStream, newSaved] = entry.value.tee()\n-    entry.value = newSaved\n-\n-    debug?.('get', cacheKey, 'found', {\n-      tags: entry.tags,\n-      timestamp: entry.timestamp,\n-      expire: entry.expire,\n-      revalidate,\n-    })\n-\n-    return {\n-      ...entry,\n-      revalidate,\n-      value: returnStream,\n-    }\n-  },\n-\n-  async set(cacheKey, pendingEntry) {\n-    debug?.('set', cacheKey, 'start')\n-\n-    let resolvePending: () => void = () => {}\n-    const pendingPromise = new Promise<void>((resolve) => {\n-      resolvePending = resolve\n-    })\n-    pendingSets.set(cacheKey, pendingPromise)\n-\n-    const entry = await pendingEntry\n-\n-    let size = 0\n-\n-    try {\n-      const [value, clonedValue] = entry.value.tee()\n-      entry.value = value\n-      const reader = clonedValue.getReader()\n-\n-      for (let chunk; !(chunk = await reader.read()).done; ) {\n-        size += Buffer.from(chunk.value).byteLength\n-      }\n-\n-      memoryCache.set(cacheKey, {\n-        entry,\n-        isErrored: false,\n-        errorRetryCount: 0,\n-        size,\n-      })\n-\n-      debug?.('set', cacheKey, 'done')\n-    } catch (err) {\n-      // TODO: store partial buffer with error after we retry 3 times\n-      debug?.('set', cacheKey, 'failed', err)\n-    } finally {\n-      resolvePending()\n-      pendingSets.delete(cacheKey)\n-    }\n-  },\n-\n-  async refreshTags() {\n-    // Nothing to do for an in-memory cache handler.\n-  },\n-\n-  async getExpiration(tags) {\n-    const expirations = tags.map((tag) => {\n-      const entry = tagsManifest.get(tag)\n-      if (!entry) return 0\n-      // Return the most recent timestamp (either expired or stale)\n-      return entry.expired || 0\n-    })\n-\n-    const expiration = Math.max(...expirations, 0)\n-\n-    debug?.('getExpiration', { tags, expiration })\n-\n-    return expiration\n-  },\n-\n-  async updateTags(tags, durations) {\n-    const now = Math.round(performance.timeOrigin + performance.now())\n-    debug?.('updateTags', { tags, timestamp: now })\n-\n-    for (const tag of tags) {\n-      // TODO: update file-system-cache?\n-      const existingEntry = tagsManifest.get(tag) || {}\n-\n-      if (durations) {\n-        // Use provided durations directly\n-        const updates: TagManifestEntry = { ...existingEntry }\n-\n-        // mark as stale immediately\n-        updates.stale = now\n-\n-        if (durations.expire !== undefined) {\n-          updates.expired = now + durations.expire * 1000 // Convert seconds to ms\n-        }\n-\n-        tagsManifest.set(tag, updates)\n-      } else {\n-        // Update expired field for immediate expiration (default behavior when no durations provided)\n-        tagsManifest.set(tag, { ...existingEntry, expired: now })\n-      }\n-    }\n-  },\n-}\n-\n-export default DefaultCacheHandler\n+export default createDefaultCacheHandler(50 * 1024 * 1024)"
        },
        {
            "sha": "1f936e41da1ac73c865e489ddba8178fe9965f55",
            "filename": "packages/next/src/server/lib/cache-handlers/default.ts",
            "status": "added",
            "additions": 206,
            "deletions": 0,
            "changes": 206,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Flib%2Fcache-handlers%2Fdefault.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -0,0 +1,206 @@\n+/**\n+ * This is the default \"use cache\" handler it defaults to an in-memory store.\n+ * In-memory caches are fragile and should not use stale-while-revalidate\n+ * semantics on the caches because it's not worth warming up an entry that's\n+ * likely going to get evicted before we get to use it anyway. However, we also\n+ * don't want to reuse a stale entry for too long so stale entries should be\n+ * considered expired/missing in such cache handlers.\n+ */\n+\n+import { LRUCache } from '../lru-cache'\n+import type { CacheEntry, CacheHandler } from './types'\n+import {\n+  areTagsExpired,\n+  areTagsStale,\n+  tagsManifest,\n+  type TagManifestEntry,\n+} from '../incremental-cache/tags-manifest.external'\n+\n+type PrivateCacheEntry = {\n+  entry: CacheEntry\n+\n+  // For the default cache we store errored cache\n+  // entries and allow them to be used up to 3 times\n+  // after that we want to dispose it and try for fresh\n+\n+  // If an entry is errored we return no entry\n+  // three times so that we retry hitting origin (MISS)\n+  // and then if it still fails to set after the third we\n+  // return the errored content and use expiration of\n+  // Math.min(30, entry.expiration)\n+  isErrored: boolean\n+  errorRetryCount: number\n+\n+  // compute size on set since we need to read size\n+  // of the ReadableStream for LRU evicting\n+  size: number\n+}\n+\n+export function createDefaultCacheHandler(maxSize: number): CacheHandler {\n+  // If the max size is 0, return a cache handler that doesn't cache anything,\n+  // this avoids an unnecessary LRUCache instance and potential memory\n+  // allocation.\n+  if (maxSize === 0) {\n+    return {\n+      get: () => Promise.resolve(undefined),\n+      set: () => Promise.resolve(),\n+      refreshTags: () => Promise.resolve(),\n+      getExpiration: () => Promise.resolve(0),\n+      updateTags: () => Promise.resolve(),\n+    }\n+  }\n+\n+  const memoryCache = new LRUCache<PrivateCacheEntry>(\n+    maxSize,\n+    (entry) => entry.size\n+  )\n+  const pendingSets = new Map<string, Promise<void>>()\n+\n+  const debug = process.env.NEXT_PRIVATE_DEBUG_CACHE\n+    ? console.debug.bind(console, 'DefaultCacheHandler:')\n+    : undefined\n+\n+  return {\n+    async get(cacheKey) {\n+      const pendingPromise = pendingSets.get(cacheKey)\n+\n+      if (pendingPromise) {\n+        debug?.('get', cacheKey, 'pending')\n+        await pendingPromise\n+      }\n+\n+      const privateEntry = memoryCache.get(cacheKey)\n+\n+      if (!privateEntry) {\n+        debug?.('get', cacheKey, 'not found')\n+        return undefined\n+      }\n+\n+      const entry = privateEntry.entry\n+      if (\n+        performance.timeOrigin + performance.now() >\n+        entry.timestamp + entry.revalidate * 1000\n+      ) {\n+        // In-memory caches should expire after revalidate time because it is\n+        // unlikely that a new entry will be able to be used before it is dropped\n+        // from the cache.\n+        debug?.('get', cacheKey, 'expired')\n+\n+        return undefined\n+      }\n+\n+      let revalidate = entry.revalidate\n+\n+      if (areTagsExpired(entry.tags, entry.timestamp)) {\n+        debug?.('get', cacheKey, 'had expired tag')\n+        return undefined\n+      }\n+\n+      if (areTagsStale(entry.tags, entry.timestamp)) {\n+        debug?.('get', cacheKey, 'had stale tag')\n+        revalidate = -1\n+      }\n+\n+      const [returnStream, newSaved] = entry.value.tee()\n+      entry.value = newSaved\n+\n+      debug?.('get', cacheKey, 'found', {\n+        tags: entry.tags,\n+        timestamp: entry.timestamp,\n+        expire: entry.expire,\n+        revalidate,\n+      })\n+\n+      return {\n+        ...entry,\n+        revalidate,\n+        value: returnStream,\n+      }\n+    },\n+\n+    async set(cacheKey, pendingEntry) {\n+      debug?.('set', cacheKey, 'start')\n+\n+      let resolvePending: () => void = () => {}\n+      const pendingPromise = new Promise<void>((resolve) => {\n+        resolvePending = resolve\n+      })\n+      pendingSets.set(cacheKey, pendingPromise)\n+\n+      const entry = await pendingEntry\n+\n+      let size = 0\n+\n+      try {\n+        const [value, clonedValue] = entry.value.tee()\n+        entry.value = value\n+        const reader = clonedValue.getReader()\n+\n+        for (let chunk; !(chunk = await reader.read()).done; ) {\n+          size += Buffer.from(chunk.value).byteLength\n+        }\n+\n+        memoryCache.set(cacheKey, {\n+          entry,\n+          isErrored: false,\n+          errorRetryCount: 0,\n+          size,\n+        })\n+\n+        debug?.('set', cacheKey, 'done')\n+      } catch (err) {\n+        // TODO: store partial buffer with error after we retry 3 times\n+        debug?.('set', cacheKey, 'failed', err)\n+      } finally {\n+        resolvePending()\n+        pendingSets.delete(cacheKey)\n+      }\n+    },\n+\n+    async refreshTags() {\n+      // Nothing to do for an in-memory cache handler.\n+    },\n+\n+    async getExpiration(tags) {\n+      const expirations = tags.map((tag) => {\n+        const entry = tagsManifest.get(tag)\n+        if (!entry) return 0\n+        // Return the most recent timestamp (either expired or stale)\n+        return entry.expired || 0\n+      })\n+\n+      const expiration = Math.max(...expirations, 0)\n+\n+      debug?.('getExpiration', { tags, expiration })\n+\n+      return expiration\n+    },\n+\n+    async updateTags(tags, durations) {\n+      const now = Math.round(performance.timeOrigin + performance.now())\n+      debug?.('updateTags', { tags, timestamp: now })\n+\n+      for (const tag of tags) {\n+        // TODO: update file-system-cache?\n+        const existingEntry = tagsManifest.get(tag) || {}\n+\n+        if (durations) {\n+          // Use provided durations directly\n+          const updates: TagManifestEntry = { ...existingEntry }\n+\n+          // mark as stale immediately\n+          updates.stale = now\n+\n+          if (durations.expire !== undefined) {\n+            updates.expired = now + durations.expire * 1000 // Convert seconds to ms\n+          }\n+\n+          tagsManifest.set(tag, updates)\n+        } else {\n+          // Update expired field for immediate expiration (default behavior when no durations provided)\n+          tagsManifest.set(tag, { ...existingEntry, expired: now })\n+        }\n+      }\n+    },\n+  }\n+}"
        },
        {
            "sha": "485ece8bc9e7f8b962c8009ee0b7d059918ce5e5",
            "filename": "packages/next/src/server/next-server.ts",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fnext-server.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fnext-server.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fnext-server.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -459,12 +459,15 @@ export default class NextNodeServer extends BaseServer<\n   }\n \n   private async loadCustomCacheHandlers() {\n-    const { cacheHandlers } = this.nextConfig.experimental\n+    const {\n+      cacheMaxMemorySize,\n+      experimental: { cacheHandlers },\n+    } = this.nextConfig\n     if (!cacheHandlers) return\n \n     // If we've already initialized the cache handlers interface, don't do it\n     // again.\n-    if (!initializeCacheHandlers()) return\n+    if (!initializeCacheHandlers(cacheMaxMemorySize)) return\n \n     for (const [kind, handler] of Object.entries(cacheHandlers)) {\n       if (!handler) continue"
        },
        {
            "sha": "4b1546249c77e1ee0217ce0043b4d15c0541a670",
            "filename": "packages/next/src/server/route-modules/route-module.ts",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Froute-modules%2Froute-module.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Froute-modules%2Froute-module.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Froute-modules%2Froute-module.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -381,12 +381,15 @@ export abstract class RouteModule<\n     nextConfig: NextConfigComplete\n   ) {\n     if (process.env.NEXT_RUNTIME !== 'edge') {\n-      const { cacheHandlers } = nextConfig.experimental\n+      const {\n+        cacheMaxMemorySize,\n+        experimental: { cacheHandlers },\n+      } = nextConfig\n       if (!cacheHandlers) return\n \n       // If we've already initialized the cache handlers interface, don't do it\n       // again.\n-      if (!initializeCacheHandlers()) return\n+      if (!initializeCacheHandlers(cacheMaxMemorySize)) return\n \n       for (const [kind, handler] of Object.entries(cacheHandlers)) {\n         if (!handler) continue"
        },
        {
            "sha": "3a8b5bdf978e096100ee499da23ded0f0bd7aaba",
            "filename": "packages/next/src/server/use-cache/handlers.ts",
            "status": "modified",
            "additions": 9,
            "deletions": 5,
            "changes": 14,
            "blob_url": "https://github.com/vercel/next.js/blob/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fhandlers.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/d58f7aa0d1d78341573ba67af797f618ddd84060/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fhandlers.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fhandlers.ts?ref=d58f7aa0d1d78341573ba67af797f618ddd84060",
            "patch": "@@ -1,4 +1,4 @@\n-import DefaultCacheHandler from '../lib/cache-handlers/default.external'\n+import { createDefaultCacheHandler } from '../lib/cache-handlers/default'\n import type { CacheHandler } from '../lib/cache-handlers/types'\n \n const debug = process.env.NEXT_PRIVATE_DEBUG_CACHE\n@@ -27,9 +27,11 @@ const reference: typeof globalThis & {\n \n /**\n  * Initialize the cache handlers.\n+ * @param cacheMaxMemorySize - The maximum memory size of the cache in bytes, if\n+ *  not provided, the default memory size will be used.\n  * @returns `true` if the cache handlers were initialized, `false` if they were already initialized.\n  */\n-export function initializeCacheHandlers(): boolean {\n+export function initializeCacheHandlers(cacheMaxMemorySize: number): boolean {\n   // If the cache handlers have already been initialized, don't do it again.\n   if (reference[handlersMapSymbol]) {\n     debug?.('cache handlers already initialized')\n@@ -47,7 +49,7 @@ export function initializeCacheHandlers(): boolean {\n       fallback = reference[handlersSymbol].DefaultCache\n     } else {\n       debug?.('setting \"default\" cache handler from default')\n-      fallback = DefaultCacheHandler\n+      fallback = createDefaultCacheHandler(cacheMaxMemorySize)\n     }\n \n     reference[handlersMapSymbol].set('default', fallback)\n@@ -63,10 +65,12 @@ export function initializeCacheHandlers(): boolean {\n       reference[handlersMapSymbol].set('remote', fallback)\n     }\n   } else {\n+    const handler = createDefaultCacheHandler(cacheMaxMemorySize)\n+\n     debug?.('setting \"default\" cache handler from default')\n-    reference[handlersMapSymbol].set('default', DefaultCacheHandler)\n+    reference[handlersMapSymbol].set('default', handler)\n     debug?.('setting \"remote\" cache handler from default')\n-    reference[handlersMapSymbol].set('remote', DefaultCacheHandler)\n+    reference[handlersMapSymbol].set('remote', handler)\n   }\n \n   // Create a set of the cache handlers."
        }
    ],
    "stats": {
        "total": 475,
        "additions": 252,
        "deletions": 223
    }
}