{
    "author": "sokra",
    "message": "Turbopack: Avoid that session-dependent tasks write to DB on every build (#86068)\n\n### What?\n\nRefactor session-dependent tasks to avoid session ids. This way session-dependent tasks no longer \"change\" on very run and dump duplicate data into the database.",
    "sha": "78a802cb1ed4730992855d7df88652a4727d5f71",
    "files": [
        {
            "sha": "bc0141f0f1b49afef68997728ef3890284f7acde",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 33,
            "deletions": 58,
            "changes": 91,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -27,8 +27,8 @@ use tokio::time::{Duration, Instant};\n use tracing::{Span, trace_span};\n use turbo_tasks::{\n     CellId, FxDashMap, FxIndexMap, KeyValuePair, RawVc, ReadCellOptions, ReadConsistency,\n-    ReadOutputOptions, ReadTracking, SessionId, TRANSIENT_TASK_BIT, TaskExecutionReason, TaskId,\n-    TraitTypeId, TurboTasksBackendApi, ValueTypeId,\n+    ReadOutputOptions, ReadTracking, TRANSIENT_TASK_BIT, TaskExecutionReason, TaskId, TraitTypeId,\n+    TurboTasksBackendApi, ValueTypeId,\n     backend::{\n         Backend, CachedTaskType, CellContent, TaskExecutionSpec, TransientTaskRoot,\n         TransientTaskType, TurboTasksExecutionError, TypedCellContent, VerificationMode,\n@@ -180,7 +180,6 @@ struct TurboTasksBackendInner<B: BackingStorage> {\n     options: BackendOptions,\n \n     start_time: Instant,\n-    session_id: SessionId,\n \n     persisted_task_id_factory: IdFactoryWithReuse<TaskId>,\n     transient_task_id_factory: IdFactoryWithReuse<TaskId>,\n@@ -254,9 +253,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         Self {\n             options,\n             start_time: Instant::now(),\n-            session_id: backing_storage\n-                .next_session_id()\n-                .expect(\"Failed get session id\"),\n             persisted_task_id_factory: IdFactoryWithReuse::new(\n                 next_task_id,\n                 TaskId::try_from(TRANSIENT_TASK_BIT - 1).unwrap(),\n@@ -295,10 +291,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         ExecuteContextImpl::new(self, turbo_tasks)\n     }\n \n-    fn session_id(&self) -> SessionId {\n-        self.session_id\n-    }\n-\n     /// # Safety\n     ///\n     /// `tx` must be a transaction from this TurboTasksBackendInner instance.\n@@ -567,10 +559,10 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                 }\n             }\n \n-            let is_dirty = task.is_dirty(self.session_id);\n+            let is_dirty = task.is_dirty();\n \n             // Check the dirty count of the root node\n-            let has_dirty_containers = task.has_dirty_containers(self.session_id);\n+            let has_dirty_containers = task.has_dirty_containers();\n             if has_dirty_containers || is_dirty {\n                 let activeness = get_mut!(task, Activeness);\n                 let mut task_ids_to_schedule: Vec<_> = Vec::new();\n@@ -589,7 +581,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                         .set_active_until_clean();\n                     if ctx.should_track_activeness() {\n                         // A newly added Activeness need to make sure to schedule the tasks\n-                        task_ids_to_schedule = task.dirty_containers(self.session_id).collect();\n+                        task_ids_to_schedule = task.dirty_containers().collect();\n                         task_ids_to_schedule.push(task_id);\n                     }\n                     get!(task, Activeness).unwrap()\n@@ -613,7 +605,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                             visited: &mut FxHashSet<TaskId>,\n                         ) -> String {\n                             let task = ctx.task(task_id, TaskDataCategory::All);\n-                            let is_dirty = task.is_dirty(ctx.session_id());\n+                            let is_dirty = task.is_dirty();\n                             let in_progress =\n                                 get!(task, InProgress).map_or(\"not in progress\", |p| match p {\n                                     InProgressState::InProgress(_) => \"in progress\",\n@@ -634,7 +626,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                             };\n \n                             // Check the dirty count of the root node\n-                            let has_dirty_containers = task.has_dirty_containers(ctx.session_id());\n+                            let has_dirty_containers = task.has_dirty_containers();\n \n                             let task_description = ctx.get_task_description(task_id);\n                             let is_dirty_label = if is_dirty { \", dirty\" } else { \"\" };\n@@ -653,8 +645,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                                  {in_progress}, \\\n                                  {activeness}{is_dirty_label}{has_dirty_containers_label})\",\n                             );\n-                            let children: Vec<_> =\n-                                task.dirty_containers_with_count(ctx.session_id()).collect();\n+                            let children: Vec<_> = task.dirty_containers_with_count().collect();\n                             drop(task);\n \n                             if missing_upper {\n@@ -1197,7 +1188,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let _span = tracing::info_span!(parent: parent_span, \"persist\", reason = reason).entered();\n         {\n             if let Err(err) = self.backing_storage.save_snapshot(\n-                self.session_id,\n                 suspended_operations,\n                 persisted_task_cache_log,\n                 task_snapshots,\n@@ -2365,32 +2355,21 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n \n         // Grab the old dirty state\n         let old_dirtyness = get!(task, Dirty).cloned();\n-        let (old_self_dirty, old_current_session_self_clean, old_clean_in_session) =\n-            match old_dirtyness {\n-                None => (false, false, None),\n-                Some(Dirtyness::Dirty) => (true, false, None),\n-                Some(Dirtyness::SessionDependent) => {\n-                    let clean_in_session = get!(task, CleanInSession).copied();\n-                    (\n-                        true,\n-                        clean_in_session == Some(self.session_id),\n-                        clean_in_session,\n-                    )\n-                }\n-            };\n+        let (old_self_dirty, old_current_session_self_clean) = match old_dirtyness {\n+            None => (false, false),\n+            Some(Dirtyness::Dirty) => (true, false),\n+            Some(Dirtyness::SessionDependent) => {\n+                let clean_in_current_session = get!(task, CurrentSessionClean).is_some();\n+                (true, clean_in_current_session)\n+            }\n+        };\n \n         // Compute the new dirty state\n-        let (new_dirtyness, new_clean_in_session, new_self_dirty, new_current_session_self_clean) =\n-            if session_dependent {\n-                (\n-                    Some(Dirtyness::SessionDependent),\n-                    Some(self.session_id),\n-                    true,\n-                    true,\n-                )\n-            } else {\n-                (None, None, false, false)\n-            };\n+        let (new_dirtyness, new_self_dirty, new_current_session_self_clean) = if session_dependent {\n+            (Some(Dirtyness::SessionDependent), true, true)\n+        } else {\n+            (None, false, false)\n+        };\n \n         // Update the dirty state\n         if old_dirtyness != new_dirtyness {\n@@ -2400,11 +2379,11 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                 task.remove(&CachedDataItemKey::Dirty {});\n             }\n         }\n-        if old_clean_in_session != new_clean_in_session {\n-            if let Some(session_id) = new_clean_in_session {\n-                task.insert(CachedDataItem::CleanInSession { value: session_id });\n-            } else if old_clean_in_session.is_some() {\n-                task.remove(&CachedDataItemKey::CleanInSession {});\n+        if old_current_session_self_clean != new_current_session_self_clean {\n+            if new_current_session_self_clean {\n+                task.insert(CachedDataItem::CurrentSessionClean { value: () });\n+            } else if old_current_session_self_clean {\n+                task.remove(&CachedDataItemKey::CurrentSessionClean {});\n             }\n         }\n \n@@ -2415,14 +2394,10 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n             let dirty_container_count = get!(task, AggregatedDirtyContainerCount)\n                 .cloned()\n                 .unwrap_or_default();\n-            let current_session_clean_container_count = get!(\n-                task,\n-                AggregatedSessionDependentCleanContainerCount {\n-                    session_id: self.session_id\n-                }\n-            )\n-            .copied()\n-            .unwrap_or_default();\n+            let current_session_clean_container_count =\n+                get!(task, AggregatedCurrentSessionCleanContainerCount)\n+                    .copied()\n+                    .unwrap_or_default();\n             let result = ComputeDirtyAndCleanUpdate {\n                 old_dirty_container_count: dirty_container_count,\n                 new_dirty_container_count: dirty_container_count,\n@@ -2914,8 +2889,8 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n \n         let mut ctx = self.execute_context(turbo_tasks);\n         let mut task = ctx.task(task_id, TaskDataCategory::All);\n-        let is_dirty = task.is_dirty(self.session_id);\n-        let has_dirty_containers = task.has_dirty_containers(self.session_id);\n+        let is_dirty = task.is_dirty();\n+        let has_dirty_containers = task.has_dirty_containers();\n         if is_dirty || has_dirty_containers {\n             if let Some(activeness_state) = get_mut!(task, Activeness) {\n                 // We will finish the task, but it would be removed after the task is done\n@@ -3005,7 +2980,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                 }\n \n                 let is_dirty = get!(task, Dirty).is_some();\n-                let has_dirty_container = task.has_dirty_containers(self.session_id);\n+                let has_dirty_container = task.has_dirty_containers();\n                 let should_be_in_upper = is_dirty || has_dirty_container;\n \n                 let aggregation_number = get_aggregation_number(&task);"
        },
        {
            "sha": "2a61df315cf1dd6d641ebfba897afa890ca889b1",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/aggregation_update.rs",
            "status": "modified",
            "additions": 31,
            "deletions": 89,
            "changes": 120,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -20,7 +20,7 @@ use smallvec::{SmallVec, smallvec};\n     feature = \"trace_find_and_schedule\"\n ))]\n use tracing::{span::Span, trace_span};\n-use turbo_tasks::{FxIndexMap, SessionId, TaskExecutionReason, TaskId};\n+use turbo_tasks::{FxIndexMap, TaskExecutionReason, TaskId};\n \n #[cfg(feature = \"trace_task_dirty\")]\n use crate::backend::operation::invalidate::TaskDirtyCause;\n@@ -325,7 +325,7 @@ pub struct AggregatedDataUpdate {\n impl AggregatedDataUpdate {\n     /// Derives an `AggregatedDataUpdate` from a task. This is used when a task is connected to an\n     /// upper task.\n-    fn from_task(task: &mut impl TaskGuard, current_session_id: SessionId) -> Self {\n+    fn from_task(task: &mut impl TaskGuard) -> Self {\n         let aggregation = get_aggregation_number(task);\n         let mut dirty_count = 0;\n         let mut current_session_clean_count = 0;\n@@ -335,14 +335,9 @@ impl AggregatedDataUpdate {\n             dirty_count = get!(task, AggregatedDirtyContainerCount)\n                 .copied()\n                 .unwrap_or_default();\n-            current_session_clean_count = get!(\n-                task,\n-                AggregatedSessionDependentCleanContainerCount {\n-                    session_id: current_session_id\n-                }\n-            )\n-            .copied()\n-            .unwrap_or_default();\n+            current_session_clean_count = get!(task, AggregatedCurrentSessionCleanContainerCount)\n+                .copied()\n+                .unwrap_or_default();\n             let collectibles = iter_many!(\n                 task,\n                 AggregatedCollectible {\n@@ -355,7 +350,7 @@ impl AggregatedDataUpdate {\n                 collectibles_update.push((collectible, 1));\n             }\n         }\n-        let (dirty, current_session_clean) = task.dirty(current_session_id);\n+        let (dirty, current_session_clean) = task.dirty();\n         if dirty {\n             dirty_count += 1;\n         }\n@@ -399,7 +394,6 @@ impl AggregatedDataUpdate {\n     fn apply(\n         &self,\n         task: &mut impl TaskGuard,\n-        current_session_id: SessionId,\n         should_track_activeness: bool,\n         queue: &mut AggregationUpdateQueue,\n     ) -> AggregatedDataUpdate {\n@@ -463,9 +457,8 @@ impl AggregatedDataUpdate {\n             if *current_session_clean_update != 0 {\n                 new_single_container_current_session_clean_count = update_count_and_get!(\n                     task,\n-                    AggregatedSessionDependentCleanContainer {\n+                    AggregatedCurrentSessionCleanContainer {\n                         task: dirty_container_id,\n-                        session_id: current_session_id\n                     },\n                     *current_session_clean_update\n                 );\n@@ -475,9 +468,8 @@ impl AggregatedDataUpdate {\n             } else {\n                 new_single_container_current_session_clean_count = get!(\n                     task,\n-                    AggregatedSessionDependentCleanContainer {\n+                    AggregatedCurrentSessionCleanContainer {\n                         task: dirty_container_id,\n-                        session_id: current_session_id\n                     }\n                 )\n                 .copied()\n@@ -497,7 +489,7 @@ impl AggregatedDataUpdate {\n                 before_after_to_diff_value(was_single_container_clean, is_single_container_clean);\n \n             if dirty_container_count_update != 0 || current_session_clean_update != 0 {\n-                let (is_self_dirty, current_session_self_clean) = task.dirty(current_session_id);\n+                let (is_self_dirty, current_session_self_clean) = task.dirty();\n \n                 let task_id = task.id();\n \n@@ -525,22 +517,16 @@ impl AggregatedDataUpdate {\n                 if current_session_clean_update != 0 {\n                     new_current_session_clean_container_count = update_count_and_get!(\n                         task,\n-                        AggregatedSessionDependentCleanContainerCount {\n-                            session_id: current_session_id\n-                        },\n+                        AggregatedCurrentSessionCleanContainerCount,\n                         current_session_clean_update\n                     );\n                     old_current_session_clean_container_count =\n                         new_current_session_clean_container_count - current_session_clean_update;\n                 } else {\n-                    new_current_session_clean_container_count = get!(\n-                        task,\n-                        AggregatedSessionDependentCleanContainerCount {\n-                            session_id: current_session_id\n-                        }\n-                    )\n-                    .copied()\n-                    .unwrap_or_default();\n+                    new_current_session_clean_container_count =\n+                        get!(task, AggregatedCurrentSessionCleanContainerCount)\n+                            .copied()\n+                            .unwrap_or_default();\n                     old_current_session_clean_container_count =\n                         new_current_session_clean_container_count;\n                 };\n@@ -1270,14 +1256,9 @@ impl AggregationUpdateQueue {\n                         }\n                         // When this is a new inner node, update aggregated data and\n                         // followers\n-                        let data = AggregatedDataUpdate::from_task(&mut task, ctx.session_id());\n+                        let data = AggregatedDataUpdate::from_task(&mut task);\n                         let followers = get_followers(&task);\n-                        let diff = data.apply(\n-                            &mut upper,\n-                            ctx.session_id(),\n-                            ctx.should_track_activeness(),\n-                            self,\n-                        );\n+                        let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n \n                         if !upper_ids.is_empty() && !diff.is_empty() {\n                             // Notify uppers about changed aggregated data\n@@ -1367,15 +1348,9 @@ impl AggregationUpdateQueue {\n \n                     // Since this is no longer an inner node, update the aggregated data and\n                     // followers\n-                    let data =\n-                        AggregatedDataUpdate::from_task(&mut task, ctx.session_id()).invert();\n+                    let data = AggregatedDataUpdate::from_task(&mut task).invert();\n                     let followers = get_followers(&task);\n-                    let diff = data.apply(\n-                        &mut upper,\n-                        ctx.session_id(),\n-                        ctx.should_track_activeness(),\n-                        self,\n-                    );\n+                    let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                     if !upper_ids.is_empty() && !diff.is_empty() {\n                         self.push(\n                             AggregatedDataUpdateJob {\n@@ -1437,9 +1412,8 @@ impl AggregationUpdateQueue {\n         mut task: impl TaskGuard,\n         ctx: &mut impl ExecuteContext<'_>,\n     ) {\n-        let session_id = ctx.session_id();\n         // Task need to be scheduled if it's dirty or doesn't have output\n-        let dirty = task.is_dirty(session_id);\n+        let dirty = task.is_dirty();\n         let should_schedule = if dirty {\n             Some(TaskExecutionReason::ActivateDirty)\n         } else if !task.has_key(&CachedDataItemKey::Output {}) {\n@@ -1452,7 +1426,7 @@ impl AggregationUpdateQueue {\n         // this would already be scheduled by the `Activeness`\n         let is_active_until_clean = get!(task, Activeness).is_some_and(|a| a.active_until_clean);\n         if !is_active_until_clean {\n-            let mut dirty_containers = task.dirty_containers(session_id).peekable();\n+            let mut dirty_containers = task.dirty_containers().peekable();\n             let is_empty = dirty_containers.peek().is_none();\n             if !is_empty || dirty {\n                 self.extend_find_and_schedule_dirty(dirty_containers);\n@@ -1483,12 +1457,7 @@ impl AggregationUpdateQueue {\n                 // For performance reasons this should stay `Meta` and not `All`\n                 TaskDataCategory::Meta,\n             );\n-            let diff = update.apply(\n-                &mut upper,\n-                ctx.session_id(),\n-                ctx.should_track_activeness(),\n-                self,\n-            );\n+            let diff = update.apply(&mut upper, ctx.should_track_activeness(), self);\n             if !diff.is_empty() {\n                 let upper_ids = get_uppers(&upper);\n                 if !upper_ids.is_empty() {\n@@ -1541,8 +1510,7 @@ impl AggregationUpdateQueue {\n                 follower_in_upper\n             });\n             if !removed_uppers.is_empty() {\n-                let data =\n-                    AggregatedDataUpdate::from_task(&mut follower, ctx.session_id()).invert();\n+                let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n                 let followers = get_followers(&follower);\n                 drop(follower);\n \n@@ -1554,12 +1522,7 @@ impl AggregationUpdateQueue {\n                             // For performance reasons this should stay `Meta` and not `All`\n                             TaskDataCategory::Meta,\n                         );\n-                        let diff = data.apply(\n-                            &mut upper,\n-                            ctx.session_id(),\n-                            ctx.should_track_activeness(),\n-                            self,\n-                        );\n+                        let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                         if !diff.is_empty() {\n                             let upper_ids = get_uppers(&upper);\n                             self.push(\n@@ -1704,8 +1667,7 @@ impl AggregationUpdateQueue {\n                     Some(old - 1)\n                 });\n                 if remove_upper {\n-                    let data =\n-                        AggregatedDataUpdate::from_task(&mut follower, ctx.session_id()).invert();\n+                    let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n                     let followers = get_followers(&follower);\n                     drop(follower);\n \n@@ -1716,12 +1678,7 @@ impl AggregationUpdateQueue {\n                             // For performance reasons this should stay `Meta` and not `All`\n                             TaskDataCategory::Meta,\n                         );\n-                        let diff = data.apply(\n-                            &mut upper,\n-                            ctx.session_id(),\n-                            ctx.should_track_activeness(),\n-                            self,\n-                        );\n+                        let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                         if !diff.is_empty() {\n                             let upper_ids = get_uppers(&upper);\n                             self.push(\n@@ -1943,7 +1900,7 @@ impl AggregationUpdateQueue {\n                     self.push_optimize_task(new_follower_id);\n                 }\n \n-                let data = AggregatedDataUpdate::from_task(&mut follower, ctx.session_id());\n+                let data = AggregatedDataUpdate::from_task(&mut follower);\n                 let children = get_followers(&follower);\n                 drop(follower);\n \n@@ -1957,12 +1914,7 @@ impl AggregationUpdateQueue {\n                             TaskDataCategory::Meta,\n                         );\n                         if has_data {\n-                            let diff = data.apply(\n-                                &mut upper,\n-                                ctx.session_id(),\n-                                ctx.should_track_activeness(),\n-                                self,\n-                            );\n+                            let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                             if !diff.is_empty() {\n                                 let upper_ids = get_uppers(&upper);\n                                 self.push(\n@@ -2114,7 +2066,7 @@ impl AggregationUpdateQueue {\n                         }\n \n                         // It's a new upper\n-                        let data = AggregatedDataUpdate::from_task(&mut inner, ctx.session_id());\n+                        let data = AggregatedDataUpdate::from_task(&mut inner);\n                         let children = get_followers(&inner);\n                         let follower_aggregation_number = get_aggregation_number(&inner);\n                         drop(inner);\n@@ -2159,12 +2111,7 @@ impl AggregationUpdateQueue {\n                 let diffs = upper_data_updates\n                     .into_iter()\n                     .filter_map(|data| {\n-                        let diff = data.apply(\n-                            &mut upper,\n-                            ctx.session_id(),\n-                            ctx.should_track_activeness(),\n-                            self,\n-                        );\n+                        let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                         (!diff.is_empty()).then_some(diff)\n                     })\n                     .collect::<Vec<_>>();\n@@ -2326,7 +2273,7 @@ impl AggregationUpdateQueue {\n                     self.push_optimize_task(new_follower_id);\n                 }\n                 // It's a new upper\n-                let data = AggregatedDataUpdate::from_task(&mut inner, ctx.session_id());\n+                let data = AggregatedDataUpdate::from_task(&mut inner);\n                 let followers = get_followers(&inner);\n                 drop(inner);\n \n@@ -2337,12 +2284,7 @@ impl AggregationUpdateQueue {\n                         // For performance reasons this should stay `Meta` and not `All`\n                         TaskDataCategory::Meta,\n                     );\n-                    let diff = data.apply(\n-                        &mut upper,\n-                        ctx.session_id(),\n-                        ctx.should_track_activeness(),\n-                        self,\n-                    );\n+                    let diff = data.apply(&mut upper, ctx.should_track_activeness(), self);\n                     if !diff.is_empty() {\n                         let upper_ids = get_uppers(&upper);\n                         self.push("
        },
        {
            "sha": "b1541b509cf362e5b233b4ca81fc3cbd7861756d",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/invalidate.rs",
            "status": "modified",
            "additions": 6,
            "deletions": 12,
            "changes": 18,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -253,10 +253,8 @@ pub fn make_task_dirty_internal(\n             value: Dirtyness::SessionDependent,\n         }) => {\n             // It was a session-dependent dirty before, so we need to remove that clean count\n-            let old = remove!(task, CleanInSession);\n-            if let Some(session_id) = old\n-                && session_id == ctx.session_id()\n-            {\n+            let was_current_session_clean = remove!(task, CurrentSessionClean).is_some();\n+            if was_current_session_clean {\n                 // There was a clean count for a session. If it was the current session, we need to\n                 // propagate that change.\n                 (true, true)\n@@ -285,14 +283,10 @@ pub fn make_task_dirty_internal(\n     let dirty_container_count = get!(task, AggregatedDirtyContainerCount)\n         .copied()\n         .unwrap_or_default();\n-    let current_session_clean_container_count = get!(\n-        task,\n-        AggregatedSessionDependentCleanContainerCount {\n-            session_id: ctx.session_id(),\n-        }\n-    )\n-    .copied()\n-    .unwrap_or_default();\n+    let current_session_clean_container_count =\n+        get!(task, AggregatedCurrentSessionCleanContainerCount)\n+            .copied()\n+            .unwrap_or_default();\n \n     #[cfg(feature = \"trace_task_dirty\")]\n     let _span = tracing::trace_span!("
        },
        {
            "sha": "57d28b626375c8790d705cf754ebc54f449dffb5",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/mod.rs",
            "status": "modified",
            "additions": 16,
            "deletions": 33,
            "changes": 49,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -14,7 +14,7 @@ use std::{\n };\n \n use serde::{Deserialize, Serialize};\n-use turbo_tasks::{FxIndexMap, KeyValuePair, SessionId, TaskId, TurboTasksBackendApi};\n+use turbo_tasks::{FxIndexMap, KeyValuePair, TaskId, TurboTasksBackendApi};\n \n use crate::{\n     backend::{\n@@ -51,7 +51,6 @@ pub trait ExecuteContext<'e>: Sized {\n     fn child_context<'l, 'r>(&'r self) -> impl ChildExecuteContext<'l> + use<'e, 'l, Self>\n     where\n         'e: 'l;\n-    fn session_id(&self) -> SessionId;\n     fn task(&mut self, task_id: TaskId, category: TaskDataCategory) -> Self::TaskGuardImpl;\n     fn is_once_task(&self, task_id: TaskId) -> bool;\n     fn task_pair(\n@@ -181,10 +180,6 @@ where\n         }\n     }\n \n-    fn session_id(&self) -> SessionId {\n-        self.backend.session_id()\n-    }\n-\n     fn task(&mut self, task_id: TaskId, category: TaskDataCategory) -> Self::TaskGuardImpl {\n         #[cfg(debug_assertions)]\n         if self.active_task_locks.fetch_add(1, Ordering::AcqRel) != 0 {\n@@ -415,49 +410,40 @@ pub trait TaskGuard: Debug {\n     fn invalidate_serialization(&mut self);\n     fn prefetch(&mut self) -> Option<FxIndexMap<TaskId, bool>>;\n     fn is_immutable(&self) -> bool;\n-    fn is_dirty(&self, session_id: SessionId) -> bool {\n+    fn is_dirty(&self) -> bool {\n         get!(self, Dirty).is_some_and(|dirtyness| match dirtyness {\n             Dirtyness::Dirty => true,\n-            Dirtyness::SessionDependent => get!(self, CleanInSession).copied() != Some(session_id),\n+            Dirtyness::SessionDependent => get!(self, CurrentSessionClean).is_none(),\n         })\n     }\n-    fn dirtyness_and_session(&self) -> Option<(Dirtyness, Option<SessionId>)> {\n+    fn dirtyness_and_session(&self) -> Option<(Dirtyness, bool)> {\n         match get!(self, Dirty)? {\n-            Dirtyness::Dirty => Some((Dirtyness::Dirty, None)),\n+            Dirtyness::Dirty => Some((Dirtyness::Dirty, false)),\n             Dirtyness::SessionDependent => Some((\n                 Dirtyness::SessionDependent,\n-                get!(self, CleanInSession).copied(),\n+                get!(self, CurrentSessionClean).is_some(),\n             )),\n         }\n     }\n     /// Returns (is_dirty, is_clean_in_current_session)\n-    fn dirty(&self, session_id: SessionId) -> (bool, bool) {\n+    fn dirty(&self) -> (bool, bool) {\n         match get!(self, Dirty) {\n             None => (false, false),\n             Some(Dirtyness::Dirty) => (true, false),\n-            Some(Dirtyness::SessionDependent) => (\n-                true,\n-                get!(self, CleanInSession).copied() == Some(session_id),\n-            ),\n+            Some(Dirtyness::SessionDependent) => (true, get!(self, CurrentSessionClean).is_some()),\n         }\n     }\n-    fn dirty_containers(&self, session_id: SessionId) -> impl Iterator<Item = TaskId> {\n-        self.dirty_containers_with_count(session_id)\n+    fn dirty_containers(&self) -> impl Iterator<Item = TaskId> {\n+        self.dirty_containers_with_count()\n             .map(|(task_id, _)| task_id)\n     }\n-    fn dirty_containers_with_count(\n-        &self,\n-        session_id: SessionId,\n-    ) -> impl Iterator<Item = (TaskId, i32)> {\n+    fn dirty_containers_with_count(&self) -> impl Iterator<Item = (TaskId, i32)> {\n         iter_many!(self, AggregatedDirtyContainer { task } count => (task, *count)).filter(\n             move |&(task_id, count)| {\n                 if count > 0 {\n                     let clean_count = get!(\n                         self,\n-                        AggregatedSessionDependentCleanContainer {\n-                            task: task_id,\n-                            session_id\n-                        }\n+                        AggregatedCurrentSessionCleanContainer { task: task_id }\n                     )\n                     .copied()\n                     .unwrap_or_default();\n@@ -469,19 +455,16 @@ pub trait TaskGuard: Debug {\n         )\n     }\n \n-    fn has_dirty_containers(&self, session_id: SessionId) -> bool {\n+    fn has_dirty_containers(&self) -> bool {\n         let dirty_count = get!(self, AggregatedDirtyContainerCount)\n             .copied()\n             .unwrap_or_default();\n         if dirty_count <= 0 {\n             return false;\n         }\n-        let clean_count = get!(\n-            self,\n-            AggregatedSessionDependentCleanContainerCount { session_id }\n-        )\n-        .copied()\n-        .unwrap_or_default();\n+        let clean_count = get!(self, AggregatedCurrentSessionCleanContainerCount)\n+            .copied()\n+            .unwrap_or_default();\n         dirty_count > clean_count\n     }\n }"
        },
        {
            "sha": "b5df76f3a832f5cfd6268f6a04a02578cb7faeb3",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backing_storage.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 9,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbacking_storage.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -3,7 +3,7 @@ use std::{any::type_name, sync::Arc};\n use anyhow::Result;\n use either::Either;\n use smallvec::SmallVec;\n-use turbo_tasks::{SessionId, TaskId, backend::CachedTaskType};\n+use turbo_tasks::{TaskId, backend::CachedTaskType};\n \n use crate::{\n     backend::{AnyOperation, TaskDataCategory},\n@@ -43,13 +43,11 @@ pub trait BackingStorage: BackingStorageSealed {\n pub trait BackingStorageSealed: 'static + Send + Sync {\n     type ReadTransaction<'l>;\n     fn next_free_task_id(&self) -> Result<TaskId>;\n-    fn next_session_id(&self) -> Result<SessionId>;\n     fn uncompleted_operations(&self) -> Result<Vec<AnyOperation>>;\n     #[allow(clippy::ptr_arg)]\n     fn serialize(&self, task: TaskId, data: &Vec<CachedDataItem>) -> Result<SmallVec<[u8; 16]>>;\n     fn save_snapshot<I>(\n         &self,\n-        session_id: SessionId,\n         operations: Vec<Arc<AnyOperation>>,\n         task_cache_updates: Vec<ChunkedVec<(Arc<CachedTaskType>, TaskId)>>,\n         snapshots: Vec<I>,\n@@ -116,10 +114,6 @@ where\n         either::for_both!(self, this => this.next_free_task_id())\n     }\n \n-    fn next_session_id(&self) -> Result<SessionId> {\n-        either::for_both!(self, this => this.next_session_id())\n-    }\n-\n     fn uncompleted_operations(&self) -> Result<Vec<AnyOperation>> {\n         either::for_both!(self, this => this.uncompleted_operations())\n     }\n@@ -130,7 +124,6 @@ where\n \n     fn save_snapshot<I>(\n         &self,\n-        session_id: SessionId,\n         operations: Vec<Arc<AnyOperation>>,\n         task_cache_updates: Vec<ChunkedVec<(Arc<CachedTaskType>, TaskId)>>,\n         snapshots: Vec<I>,\n@@ -146,7 +139,6 @@ where\n             + Sync,\n     {\n         either::for_both!(self, this => this.save_snapshot(\n-            session_id,\n             operations,\n             task_cache_updates,\n             snapshots,"
        },
        {
            "sha": "197b9c7a30329cea95923e6561537e22c7b24e76",
            "filename": "turbopack/crates/turbo-tasks-backend/src/data.rs",
            "status": "modified",
            "additions": 24,
            "deletions": 27,
            "changes": 51,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdata.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -1,8 +1,8 @@\n use rustc_hash::FxHashSet;\n use serde::{Deserialize, Serialize};\n use turbo_tasks::{\n-    CellId, KeyValuePair, SessionId, TaskExecutionReason, TaskId, TraitTypeId,\n-    TypedSharedReference, ValueTypeId,\n+    CellId, KeyValuePair, TaskExecutionReason, TaskId, TraitTypeId, TypedSharedReference,\n+    ValueTypeId,\n     backend::TurboTasksExecutionError,\n     event::{Event, EventListener},\n     registry,\n@@ -228,8 +228,9 @@ pub enum CachedDataItem {\n     Dirty {\n         value: Dirtyness,\n     },\n-    CleanInSession {\n-        value: SessionId,\n+    #[serde(skip)]\n+    CurrentSessionClean {\n+        value: (),\n     },\n \n     // Children\n@@ -296,9 +297,9 @@ pub enum CachedDataItem {\n         task: TaskId,\n         value: i32,\n     },\n-    AggregatedSessionDependentCleanContainer {\n+    #[serde(skip)]\n+    AggregatedCurrentSessionCleanContainer {\n         task: TaskId,\n-        session_id: SessionId,\n         value: i32,\n     },\n     AggregatedCollectible {\n@@ -308,8 +309,8 @@ pub enum CachedDataItem {\n     AggregatedDirtyContainerCount {\n         value: i32,\n     },\n-    AggregatedSessionDependentCleanContainerCount {\n-        session_id: SessionId,\n+    #[serde(skip)]\n+    AggregatedCurrentSessionCleanContainerCount {\n         value: i32,\n     },\n \n@@ -370,7 +371,7 @@ impl CachedDataItem {\n                 !collectible.cell.task.is_transient()\n             }\n             CachedDataItem::Dirty { .. } => true,\n-            CachedDataItem::CleanInSession { .. } => true,\n+            CachedDataItem::CurrentSessionClean { .. } => false,\n             CachedDataItem::Child { task, .. } => !task.is_transient(),\n             CachedDataItem::CellData { .. } => true,\n             CachedDataItem::CellTypeMaxIndex { .. } => true,\n@@ -384,14 +385,12 @@ impl CachedDataItem {\n             CachedDataItem::Follower { task, .. } => !task.is_transient(),\n             CachedDataItem::Upper { task, .. } => !task.is_transient(),\n             CachedDataItem::AggregatedDirtyContainer { task, .. } => !task.is_transient(),\n-            CachedDataItem::AggregatedSessionDependentCleanContainer { task, .. } => {\n-                !task.is_transient()\n-            }\n+            CachedDataItem::AggregatedCurrentSessionCleanContainer { .. } => false,\n             CachedDataItem::AggregatedCollectible { collectible, .. } => {\n                 !collectible.cell.task.is_transient()\n             }\n             CachedDataItem::AggregatedDirtyContainerCount { .. } => true,\n-            CachedDataItem::AggregatedSessionDependentCleanContainerCount { .. } => true,\n+            CachedDataItem::AggregatedCurrentSessionCleanContainerCount { .. } => false,\n             CachedDataItem::Stateful { .. } => true,\n             CachedDataItem::HasInvalidator { .. } => true,\n             CachedDataItem::Immutable { .. } => true,\n@@ -457,15 +456,12 @@ impl CachedDataItem {\n             | Self::Output { .. }\n             | Self::AggregationNumber { .. }\n             | Self::Dirty { .. }\n-            | Self::CleanInSession { .. }\n             | Self::Follower { .. }\n             | Self::Child { .. }\n             | Self::Upper { .. }\n             | Self::AggregatedDirtyContainer { .. }\n-            | Self::AggregatedSessionDependentCleanContainer { .. }\n             | Self::AggregatedCollectible { .. }\n             | Self::AggregatedDirtyContainerCount { .. }\n-            | Self::AggregatedSessionDependentCleanContainerCount { .. }\n             | Self::Stateful { .. }\n             | Self::HasInvalidator { .. }\n             | Self::Immutable { .. }\n@@ -475,6 +471,9 @@ impl CachedDataItem {\n             | Self::OutdatedOutputDependency { .. }\n             | Self::OutdatedCellDependency { .. }\n             | Self::OutdatedCollectiblesDependency { .. }\n+            | Self::CurrentSessionClean { .. }\n+            | Self::AggregatedCurrentSessionCleanContainer { .. }\n+            | Self::AggregatedCurrentSessionCleanContainerCount { .. }\n             | Self::InProgressCell { .. }\n             | Self::InProgress { .. }\n             | Self::Activeness { .. } => TaskDataCategory::All,\n@@ -494,7 +493,7 @@ impl CachedDataItemKey {\n                 !collectible.cell.task.is_transient()\n             }\n             CachedDataItemKey::Dirty { .. } => true,\n-            CachedDataItemKey::CleanInSession { .. } => true,\n+            CachedDataItemKey::CurrentSessionClean { .. } => false,\n             CachedDataItemKey::Child { task, .. } => !task.is_transient(),\n             CachedDataItemKey::CellData { .. } => true,\n             CachedDataItemKey::CellTypeMaxIndex { .. } => true,\n@@ -508,14 +507,12 @@ impl CachedDataItemKey {\n             CachedDataItemKey::Follower { task, .. } => !task.is_transient(),\n             CachedDataItemKey::Upper { task, .. } => !task.is_transient(),\n             CachedDataItemKey::AggregatedDirtyContainer { task, .. } => !task.is_transient(),\n-            CachedDataItemKey::AggregatedSessionDependentCleanContainer { task, .. } => {\n-                !task.is_transient()\n-            }\n+            CachedDataItemKey::AggregatedCurrentSessionCleanContainer { .. } => false,\n             CachedDataItemKey::AggregatedCollectible { collectible, .. } => {\n                 !collectible.cell.task.is_transient()\n             }\n             CachedDataItemKey::AggregatedDirtyContainerCount { .. } => true,\n-            CachedDataItemKey::AggregatedSessionDependentCleanContainerCount { .. } => true,\n+            CachedDataItemKey::AggregatedCurrentSessionCleanContainerCount { .. } => false,\n             CachedDataItemKey::Stateful { .. } => true,\n             CachedDataItemKey::HasInvalidator { .. } => true,\n             CachedDataItemKey::Immutable { .. } => true,\n@@ -549,15 +546,12 @@ impl CachedDataItemType {\n             | Self::Output { .. }\n             | Self::AggregationNumber { .. }\n             | Self::Dirty { .. }\n-            | Self::CleanInSession { .. }\n             | Self::Follower { .. }\n             | Self::Child { .. }\n             | Self::Upper { .. }\n             | Self::AggregatedDirtyContainer { .. }\n-            | Self::AggregatedSessionDependentCleanContainer { .. }\n             | Self::AggregatedCollectible { .. }\n             | Self::AggregatedDirtyContainerCount { .. }\n-            | Self::AggregatedSessionDependentCleanContainerCount { .. }\n             | Self::Stateful { .. }\n             | Self::HasInvalidator { .. }\n             | Self::Immutable { .. }\n@@ -567,6 +561,9 @@ impl CachedDataItemType {\n             | Self::OutdatedOutputDependency { .. }\n             | Self::OutdatedCellDependency { .. }\n             | Self::OutdatedCollectiblesDependency { .. }\n+            | Self::CurrentSessionClean { .. }\n+            | Self::AggregatedCurrentSessionCleanContainer { .. }\n+            | Self::AggregatedCurrentSessionCleanContainerCount { .. }\n             | Self::InProgressCell { .. }\n             | Self::InProgress { .. }\n             | Self::Activeness { .. } => TaskDataCategory::All,\n@@ -578,7 +575,6 @@ impl CachedDataItemType {\n             Self::Output\n             | Self::Collectible\n             | Self::Dirty\n-            | Self::CleanInSession\n             | Self::Child\n             | Self::CellData\n             | Self::CellTypeMaxIndex\n@@ -592,17 +588,18 @@ impl CachedDataItemType {\n             | Self::Follower\n             | Self::Upper\n             | Self::AggregatedDirtyContainer\n-            | Self::AggregatedSessionDependentCleanContainer\n             | Self::AggregatedCollectible\n             | Self::AggregatedDirtyContainerCount\n-            | Self::AggregatedSessionDependentCleanContainerCount\n             | Self::Stateful\n             | Self::HasInvalidator\n             | Self::Immutable => true,\n \n             Self::Activeness\n             | Self::InProgress\n             | Self::InProgressCell\n+            | Self::CurrentSessionClean\n+            | Self::AggregatedCurrentSessionCleanContainer\n+            | Self::AggregatedCurrentSessionCleanContainerCount\n             | Self::OutdatedCollectible\n             | Self::OutdatedOutputDependency\n             | Self::OutdatedCellDependency"
        },
        {
            "sha": "09601bf3fc235786e216a5e23a1a2980837d1aff",
            "filename": "turbopack/crates/turbo-tasks-backend/src/kv_backing_storage.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 28,
            "changes": 31,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fkv_backing_storage.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -9,7 +9,7 @@ use anyhow::{Context, Result, anyhow};\n use serde::{Deserialize, Serialize};\n use smallvec::SmallVec;\n use turbo_tasks::{\n-    SessionId, TaskId,\n+    TaskId,\n     backend::CachedTaskType,\n     panic_hooks::{PanicHookGuard, register_panic_hook},\n     parallel,\n@@ -71,7 +71,6 @@ fn pot_de_symbol_list<'l>() -> pot::de::SymbolList<'l> {\n \n const META_KEY_OPERATIONS: u32 = 0;\n const META_KEY_NEXT_FREE_TASK_ID: u32 = 1;\n-const META_KEY_SESSION_ID: u32 = 2;\n \n struct IntKey([u8; 4]);\n \n@@ -238,7 +237,7 @@ impl<T: KeyValueDatabase> KeyValueDatabaseBackingStorageInner<T> {\n         Ok(())\n     }\n \n-    /// Used to read the previous session id and the next free task ID from the database.\n+    /// Used to read the next free task ID from the database.\n     fn get_infra_u32(&self, key: u32) -> Result<Option<u32>> {\n         let tx = self.database.begin_read_transaction()?;\n         self.database\n@@ -269,16 +268,6 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             .map_or(Ok(TaskId::MIN), TaskId::try_from)?)\n     }\n \n-    fn next_session_id(&self) -> Result<SessionId> {\n-        Ok(SessionId::try_from(\n-            self.inner\n-                .get_infra_u32(META_KEY_SESSION_ID)\n-                .context(\"Unable to read session id from database\")?\n-                .unwrap_or(0)\n-                + 1,\n-        )?)\n-    }\n-\n     fn uncompleted_operations(&self) -> Result<Vec<AnyOperation>> {\n         fn get(database: &impl KeyValueDatabase) -> Result<Vec<AnyOperation>> {\n             let tx = database.begin_read_transaction()?;\n@@ -302,7 +291,6 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n \n     fn save_snapshot<I>(\n         &self,\n-        session_id: SessionId,\n         operations: Vec<Arc<AnyOperation>>,\n         task_cache_updates: Vec<ChunkedVec<(Arc<CachedTaskType>, TaskId)>>,\n         snapshots: Vec<I>,\n@@ -317,7 +305,7 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n             > + Send\n             + Sync,\n     {\n-        let _span = tracing::info_span!(\"save snapshot\", session_id = ?session_id, operations = operations.len()).entered();\n+        let _span = tracing::info_span!(\"save snapshot\", operations = operations.len()).entered();\n         let mut batch = self.inner.database.write_batch()?;\n \n         // Start organizing the updates in parallel\n@@ -401,7 +389,6 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                 save_infra::<T::SerialWriteBatch<'_>, T::ConcurrentWriteBatch<'_>>(\n                     &mut WriteBatchRef::concurrent(batch),\n                     next_task_id,\n-                    session_id,\n                     operations,\n                 )?;\n             }\n@@ -473,7 +460,6 @@ impl<T: KeyValueDatabase + Send + Sync + 'static> BackingStorageSealed\n                 save_infra::<T::SerialWriteBatch<'_>, T::ConcurrentWriteBatch<'_>>(\n                     &mut WriteBatchRef::serial(batch),\n                     next_task_id,\n-                    session_id,\n                     operations,\n                 )?;\n             }\n@@ -608,7 +594,6 @@ where\n fn save_infra<'a, S, C>(\n     batch: &mut WriteBatchRef<'_, 'a, S, C>,\n     next_task_id: u32,\n-    session_id: SessionId,\n     operations: Vec<Arc<AnyOperation>>,\n ) -> Result<(), anyhow::Error>\n where\n@@ -624,16 +609,6 @@ where\n             )\n             .with_context(|| anyhow!(\"Unable to write next free task id\"))?;\n     }\n-    {\n-        let _span = tracing::trace_span!(\"update session id\", session_id = ?session_id).entered();\n-        batch\n-            .put(\n-                KeySpace::Infra,\n-                WriteBuffer::Borrowed(IntKey::new(META_KEY_SESSION_ID).as_ref()),\n-                WriteBuffer::Borrowed(&session_id.to_le_bytes()),\n-            )\n-            .with_context(|| anyhow!(\"Unable to write next session id\"))?;\n-    }\n     {\n         let _span =\n             tracing::trace_span!(\"update operations\", operations = operations.len()).entered();"
        },
        {
            "sha": "1580e08174b9098e9a095340a6084a05daeab746",
            "filename": "turbopack/crates/turbo-tasks/src/id.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fid.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -122,7 +122,6 @@ define_id!(TaskId: u32, derive(Serialize, Deserialize), serde(transparent));\n define_id!(FunctionId: u16);\n define_id!(ValueTypeId: u16);\n define_id!(TraitTypeId: u16);\n-define_id!(SessionId: u32, derive(Debug, Serialize, Deserialize), serde(transparent));\n define_id!(\n     LocalTaskId: u32,\n     derive(Debug, Serialize, Deserialize),"
        },
        {
            "sha": "6b5276be95e8cca7cf0d4a693031bcc9801d54ca",
            "filename": "turbopack/crates/turbo-tasks/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/78a802cb1ed4730992855d7df88652a4727d5f71/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs?ref=78a802cb1ed4730992855d7df88652a4727d5f71",
            "patch": "@@ -96,9 +96,7 @@ pub use collectibles::CollectiblesSource;\n pub use completion::{Completion, Completions};\n pub use display::ValueToString;\n pub use effect::{ApplyEffectsContext, Effects, apply_effects, effect, get_effects};\n-pub use id::{\n-    ExecutionId, LocalTaskId, SessionId, TRANSIENT_TASK_BIT, TaskId, TraitTypeId, ValueTypeId,\n-};\n+pub use id::{ExecutionId, LocalTaskId, TRANSIENT_TASK_BIT, TaskId, TraitTypeId, ValueTypeId};\n pub use invalidation::{\n     InvalidationReason, InvalidationReasonKind, InvalidationReasonSet, Invalidator, get_invalidator,\n };"
        }
    ],
    "stats": {
        "total": 375,
        "additions": 115,
        "deletions": 260
    }
}