{
    "author": "sokra",
    "message": "[Turbopack] smarter merging of small chunks in production chunking (#76319)\n\n### What?\n\nInstead of merging the smallest chunks to get over the min chunk size, choose chunks with the biggest overlap in chunk groups to merge.\nThis makes it more likely to have these merged chunks to be shared between chunk groups.",
    "sha": "7633c6736fab6773caaf7a67699daf1a2b83441c",
    "files": [
        {
            "sha": "915b5b04e5c1b39d4fc3be9b5e6bc80a6147e399",
            "filename": "turbopack/crates/turbopack-core/src/chunk/chunking/production.rs",
            "status": "modified",
            "additions": 193,
            "deletions": 35,
            "changes": 228,
            "blob_url": "https://github.com/vercel/next.js/blob/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fchunk%2Fchunking%2Fproduction.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fchunk%2Fchunking%2Fproduction.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fchunk%2Fchunking%2Fproduction.rs?ref=7633c6736fab6773caaf7a67699daf1a2b83441c",
            "patch": "@@ -1,4 +1,4 @@\n-use std::{collections::BinaryHeap, hash::BuildHasherDefault};\n+use std::{borrow::Cow, collections::BinaryHeap, hash::BuildHasherDefault};\n \n use anyhow::{bail, Result};\n use rustc_hash::FxHasher;\n@@ -12,7 +12,7 @@ use crate::{\n         ChunkingConfig,\n     },\n     module::Module,\n-    module_graph::ModuleGraph,\n+    module_graph::{chunk_group_info::RoaringBitmapWrapper, ModuleGraph},\n };\n \n pub async fn make_production_chunks(\n@@ -70,53 +70,150 @@ pub async fn make_production_chunks(\n             }\n         } else {\n             let mut heap = grouped_chunk_items\n-                .into_values()\n-                .map(|chunk_items| {\n+                .into_iter()\n+                .map(|(key, chunk_items)| {\n                     let size = chunk_items\n                         .iter()\n                         .map(|chunk_item| chunk_item.size)\n                         .sum::<usize>();\n-                    ChunkCandidate { size, chunk_items }\n+                    ChunkCandidate {\n+                        size,\n+                        chunk_items,\n+                        chunk_groups: key.map(Cow::Borrowed),\n+                    }\n                 })\n                 .collect::<BinaryHeap<_>>();\n \n             span.record(\"chunks_before_limits\", heap.len());\n \n-            loop {\n-                if let Some(smallest) = heap.peek() {\n-                    let chunk_over_limit =\n-                        max_merge_chunk_size != 0 && smallest.size > max_merge_chunk_size;\n-                    if chunk_over_limit {\n-                        break;\n+            if min_chunk_size != 0 || max_chunk_count_per_group != 0 {\n+                let mut chunks_to_merge = BinaryHeap::new();\n+                let mut chunks_to_merge_size = 0;\n+\n+                // Determine chunk to merge\n+                loop {\n+                    if let Some(smallest) = heap.peek() {\n+                        let chunk_over_limit =\n+                            max_merge_chunk_size != 0 && smallest.size > max_merge_chunk_size;\n+                        if chunk_over_limit {\n+                            break;\n+                        }\n+                        let merge_threshold = if min_chunk_size != 0 {\n+                            min_chunk_size\n+                        } else {\n+                            smallest.size\n+                        };\n+                        let too_many_chunks = max_chunk_count_per_group != 0\n+                            && heap.len() + chunks_to_merge_size / merge_threshold\n+                                > max_chunk_count_per_group;\n+                        let too_small_chunk = min_chunk_size != 0 && smallest.size < min_chunk_size;\n+                        if too_many_chunks || too_small_chunk {\n+                            let ChunkCandidate {\n+                                size,\n+                                chunk_items,\n+                                chunk_groups,\n+                            } = heap.pop().unwrap();\n+                            chunks_to_merge_size += size;\n+                            chunks_to_merge.push(MergeCandidate {\n+                                size,\n+                                chunk_items,\n+                                chunk_groups,\n+                            });\n+                            continue;\n+                        }\n                     }\n-                    let too_many_chunks = max_chunk_count_per_group != 0\n-                        && heap.len() + 1 > max_chunk_count_per_group;\n-                    let too_small_chunk = min_chunk_size != 0 && smallest.size < min_chunk_size;\n-                    if too_many_chunks || too_small_chunk {\n-                        let ChunkCandidate { size, chunk_items } = heap.pop().unwrap();\n-                        // TODO find a small chunk with the biggest overlap in chunk groups\n-                        if let Some(mut item) = heap.peek_mut() {\n-                            let chunk_over_limit =\n-                                max_merge_chunk_size != 0 && item.size > max_merge_chunk_size;\n-                            let too_small_chunk = min_chunk_size != 0 && item.size < min_chunk_size;\n-                            if !chunk_over_limit && (too_many_chunks || too_small_chunk) {\n-                                // Merge them\n-                                item.size += size;\n-                                item.chunk_items.extend(chunk_items);\n-                                continue;\n+                    break;\n+                }\n+\n+                let merge_threshold = if min_chunk_size != 0 {\n+                    min_chunk_size\n+                } else if let Some(smallest) = heap.peek() {\n+                    smallest.size\n+                } else if max_chunk_count_per_group != 0 {\n+                    chunks_to_merge_size / max_chunk_count_per_group\n+                } else {\n+                    unreachable!();\n+                };\n+\n+                while chunks_to_merge.len() > 1 {\n+                    // Find best candidate\n+                    let mut selection: Vec<MergeCandidate<'_>> = Vec::new();\n+                    let mut best_combination = None;\n+                    while let Some(candidate) = chunks_to_merge.pop() {\n+                        // Exist early when no better overlaps are possible\n+                        if let Some((_, _, best_value)) = best_combination.as_ref() {\n+                            let candiate_best_possible_value = candidate.chunk_groups_len();\n+                            if *best_value >= candiate_best_possible_value {\n+                                chunks_to_merge.push(candidate);\n+                                break;\n+                            }\n+                        }\n+\n+                        // Check all combination with the new candidate\n+                        for (i, other) in selection.iter().enumerate() {\n+                            let value = overlap(&candidate.chunk_groups, &other.chunk_groups);\n+                            if let Some((best_i1, best_i2, best_value)) = best_combination.as_mut()\n+                            {\n+                                if value > *best_value {\n+                                    *best_i1 = i;\n+                                    *best_i2 = selection.len();\n+                                    *best_value = value;\n+                                }\n+                            } else {\n+                                best_combination = Some((i, selection.len(), value));\n                             }\n                         }\n-                        // Couldn't be merged, reinsert\n-                        heap.push(ChunkCandidate { size, chunk_items });\n+                        selection.push(candidate);\n+                    }\n+\n+                    if let Some((best_i1, best_i2, _)) = best_combination.as_ref() {\n+                        let other = selection.swap_remove(*best_i2);\n+                        let mut candidate = selection.swap_remove(*best_i1);\n+                        for unused in selection {\n+                            chunks_to_merge.push(unused);\n+                        }\n+                        // Merge other into candidate\n+                        let MergeCandidate {\n+                            size,\n+                            chunk_items,\n+                            chunk_groups,\n+                        } = other;\n+                        candidate.size += size;\n+                        candidate.chunk_items.extend(chunk_items);\n+                        candidate.chunk_groups =\n+                            merge_chunk_groups(&candidate.chunk_groups, &chunk_groups);\n+\n+                        // Merged chunk either goes back to the heap or\n+                        // is considered for merging again\n+                        if candidate.size > merge_threshold {\n+                            heap.push(ChunkCandidate {\n+                                size: candidate.size,\n+                                chunk_items: candidate.chunk_items,\n+                                chunk_groups: candidate.chunk_groups,\n+                            });\n+                        } else {\n+                            chunks_to_merge.push(candidate);\n+                        }\n                     }\n                 }\n-                break;\n+\n+                // Left-over chunks go back to the heap\n+                for chunk in chunks_to_merge {\n+                    heap.push(ChunkCandidate {\n+                        size: chunk.size,\n+                        chunk_items: chunk.chunk_items,\n+                        chunk_groups: chunk.chunk_groups,\n+                    });\n+                }\n             }\n \n             span.record(\"chunks\", heap.len());\n \n             let mut total_size = 0;\n-            for ChunkCandidate { chunk_items, size } in heap.into_iter() {\n+            for ChunkCandidate {\n+                chunk_items, size, ..\n+            } in heap.into_iter()\n+            {\n                 total_size += size;\n                 make_chunk(chunk_items, &mut String::new(), &mut split_context).await?;\n             }\n@@ -129,27 +226,88 @@ pub async fn make_production_chunks(\n     .await\n }\n \n-struct ChunkCandidate {\n+struct ChunkCandidate<'l> {\n     size: usize,\n     chunk_items: Vec<ChunkItemWithInfo>,\n+    chunk_groups: Option<Cow<'l, RoaringBitmapWrapper>>,\n }\n \n-impl Ord for ChunkCandidate {\n+impl Ord for ChunkCandidate<'_> {\n     fn cmp(&self, other: &Self) -> std::cmp::Ordering {\n         self.size.cmp(&other.size).reverse()\n     }\n }\n \n-impl PartialOrd for ChunkCandidate {\n+impl PartialOrd for ChunkCandidate<'_> {\n     fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {\n         Some(self.cmp(other))\n     }\n }\n \n-impl Eq for ChunkCandidate {}\n+impl Eq for ChunkCandidate<'_> {}\n \n-impl PartialEq for ChunkCandidate {\n+impl PartialEq for ChunkCandidate<'_> {\n     fn eq(&self, other: &Self) -> bool {\n         self.size == other.size\n     }\n }\n+\n+struct MergeCandidate<'l> {\n+    size: usize,\n+    chunk_items: Vec<ChunkItemWithInfo>,\n+    chunk_groups: Option<Cow<'l, RoaringBitmapWrapper>>,\n+}\n+\n+impl MergeCandidate<'_> {\n+    fn chunk_groups_len(&self) -> u64 {\n+        self.chunk_groups\n+            .as_ref()\n+            .map_or(0, |chunk_groups| chunk_groups.len())\n+    }\n+}\n+\n+impl Ord for MergeCandidate<'_> {\n+    fn cmp(&self, other: &Self) -> std::cmp::Ordering {\n+        self.chunk_groups_len()\n+            .cmp(&other.chunk_groups_len())\n+            .then_with(|| self.size.cmp(&other.size).reverse())\n+    }\n+}\n+\n+impl PartialOrd for MergeCandidate<'_> {\n+    fn partial_cmp(&self, other: &Self) -> Option<std::cmp::Ordering> {\n+        Some(self.cmp(other))\n+    }\n+}\n+\n+impl Eq for MergeCandidate<'_> {}\n+\n+impl PartialEq for MergeCandidate<'_> {\n+    fn eq(&self, other: &Self) -> bool {\n+        self.size == other.size\n+    }\n+}\n+\n+fn overlap(\n+    chunk_groups: &Option<Cow<'_, RoaringBitmapWrapper>>,\n+    chunk_groups2: &Option<Cow<'_, RoaringBitmapWrapper>>,\n+) -> u64 {\n+    if let (Some(chunk_groups), Some(chunk_groups2)) = (chunk_groups, chunk_groups2) {\n+        chunk_groups.intersection_len(chunk_groups2)\n+    } else {\n+        0\n+    }\n+}\n+\n+fn merge_chunk_groups<'l>(\n+    chunk_groups: &Option<Cow<'l, RoaringBitmapWrapper>>,\n+    chunk_groups2: &Option<Cow<'l, RoaringBitmapWrapper>>,\n+) -> Option<Cow<'l, RoaringBitmapWrapper>> {\n+    if let (Some(chunk_groups), Some(chunk_groups2)) = (chunk_groups, chunk_groups2) {\n+        let l = &**chunk_groups.as_ref();\n+        let r = &**chunk_groups2.as_ref();\n+        Some(Cow::Owned(RoaringBitmapWrapper(l & r)))\n+    } else {\n+        None\n+    }\n+}"
        },
        {
            "sha": "cca3a9039a3bdf4f5c893421c012351e229677c7",
            "filename": "turbopack/crates/turbopack-core/src/module_graph/chunk_group_info.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fchunk_group_info.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fchunk_group_info.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fchunk_group_info.rs?ref=7633c6736fab6773caaf7a67699daf1a2b83441c",
            "patch": "@@ -30,7 +30,7 @@ use crate::{\n #[derive(\n     Clone, Debug, Default, PartialEq, Serialize, Deserialize, TraceRawVcs, ValueDebugFormat,\n )]\n-pub struct RoaringBitmapWrapper(#[turbo_tasks(trace_ignore)] RoaringBitmap);\n+pub struct RoaringBitmapWrapper(#[turbo_tasks(trace_ignore)] pub RoaringBitmap);\n \n impl TaskInput for RoaringBitmapWrapper {\n     fn is_transient(&self) -> bool {"
        },
        {
            "sha": "27192b6575705d9de0c009beb885fe0ea9f31fa3",
            "filename": "turbopack/crates/turbopack-tests/tests/execution.rs",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-tests%2Ftests%2Fexecution.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/7633c6736fab6773caaf7a67699daf1a2b83441c/turbopack%2Fcrates%2Fturbopack-tests%2Ftests%2Fexecution.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-tests%2Ftests%2Fexecution.rs?ref=7633c6736fab6773caaf7a67699daf1a2b83441c",
            "patch": "@@ -29,6 +29,7 @@ use turbopack::{\n     ModuleAssetContext,\n };\n use turbopack_core::{\n+    chunk::ChunkingConfig,\n     compile_time_defines,\n     compile_time_info::CompileTimeInfo,\n     condition::ContextCondition,\n@@ -415,6 +416,10 @@ async fn run_test_operation(prepared_test: ResolvedVc<PreparedTest>) -> Result<V\n         env,\n         RuntimeType::Development,\n     )\n+    .ecmascript_chunking_config(ChunkingConfig {\n+        min_chunk_size: 20_000,\n+        ..Default::default()\n+    })\n     .build();\n \n     let jest_entry_source = FileSource::new(jest_entry_path);"
        }
    ],
    "stats": {
        "total": 235,
        "additions": 199,
        "deletions": 36
    }
}