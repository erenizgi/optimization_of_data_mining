{
    "author": "bgw",
    "message": "refactor(CI): Convert daily turbopack (areweturboyet) integration tests into reusable workflows (#76251)\n\nThis builds on top of work that @timneutkens did in the\n`wbinnssmith/try-ci-test` branch to rebuild the integration test CI on\ntop of `build_reusable.yml` and work around issues with the\n`next-integration-stat`, but takes it a few steps further:\n\n- As much of the integration test logic as possible is moved into a\nsingle re-usable workflow so that we won't need to duplicate logic\nbetween 6 workflows going forward (turbopack dev, turbopack build,\nturbopack examples, rspack dev, rspack build, rspack examples). Right\nnow this just ports turbopack dev and build.\n\n- Cleaned up a ton of legacy dead/broken code in\n`next-integration-stat`. We might want to revive the comment-on-PR\nfunctionality, so I didn't completely remove it, just the very obviously\nbroken parts (e.g. references to a >2-year-old stale branch of the\nturborepo repository).\n\n---\n\nManually triggered the workflows:\n\nDev tests: https://github.com/vercel/next.js/actions/runs/13466611352\nProd tests: https://github.com/vercel/next.js/actions/runs/13466609857\n\nTested by patching the `test/build-turbopack-*-tests-manifest.js`\nscripts like so:\n\n```diff\ndiff --git a/test/build-turbopack-dev-tests-manifest.js b/test/build-turbopack-dev-tests-manifest.js\nindex bc1928cf2d..e6546e0018 100644\n--- a/test/build-turbopack-dev-tests-manifest.js\n+++ b/test/build-turbopack-dev-tests-manifest.js\n@@ -91,7 +91,11 @@ async function fetchLatestTestArtifact() {\n   const res = JSON.parse(stdout)\n \n   for (const artifact of res.artifacts) {\n-    if (artifact.expired || artifact.workflow_run.head_branch !== 'canary') {\n+    if (\n+      artifact.expired ||\n+      artifact.workflow_run.head_branch !==\n+        'bgw/reusable-integration-test-workflow'\n+    ) {\n       continue\n     }\n```\n\nAnd then diffing the generated json manifests:\nhttps://gist.github.com/bgw/08778b5f63861811fbe88e3f466a8679\n\nNote that some differences are expected: These jobs have been broken for\nat least 2-3 weeks.",
    "sha": "13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
    "files": [
        {
            "sha": "413fc08cb9b07c48d126342aac9d0718c36776f2",
            "filename": ".gitattributes",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.gitattributes",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.gitattributes",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.gitattributes?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -1,3 +1,4 @@\n+.github/actions/*/dist/** -text linguist-vendored\n packages/next/bundles/** -text linguist-vendored\n packages/next/compiled/** -text linguist-vendored\n "
        },
        {
            "sha": "02f96df4341e475ffad92a3188ba24494d99a078",
            "filename": ".github/actions/next-integration-stat/dist/index.js",
            "status": "modified",
            "additions": 52693,
            "deletions": 9850,
            "changes": 62543,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fdist%2Findex.js",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fdist%2Findex.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Factions%2Fnext-integration-stat%2Fdist%2Findex.js?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55"
        },
        {
            "sha": "0983916b2613e8641c4ff8b58f07e86e4404929b",
            "filename": ".github/actions/next-integration-stat/src/index.ts",
            "status": "modified",
            "additions": 37,
            "deletions": 308,
            "changes": 345,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Findex.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Findex.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Findex.ts?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -2,8 +2,6 @@ import { context, getOctokit } from '@actions/github'\n import { info, getInput } from '@actions/core'\n const { default: stripAnsi } = require('strip-ansi')\n const fs = require('fs')\n-const path = require('path')\n-const semver = require('semver')\n \n /// <reference path=\"./manifest\" />\n \n@@ -18,74 +16,17 @@ const BOT_COMMENT_MARKER = `<!-- __marker__ next.js integration stats __marker__\n // Header for the test report.\n const commentTitlePre = `## Failing next.js integration test suites`\n \n-async function findNextJsVersionFromBuildLogs(\n-  octokit: Octokit,\n-  token: string,\n-  job: Job\n-): Promise<string> {\n-  console.log(\n-    'findNextJsVersionFromBuildLogs: Checking logs for the job ',\n-    job.name\n-  )\n-\n-  // downloadJobLogsForWorkflowRun returns a redirect to the actual logs\n-  const jobLogRedirectResponse =\n-    await octokit.rest.actions.downloadJobLogsForWorkflowRun({\n-      accept: 'application/vnd.github+json',\n-      ...context.repo,\n-      job_id: job.id,\n-    })\n-\n-  console.log(\n-    'findNextJsVersionFromBuildLogs: Trying to get logs from redirect url ',\n-    jobLogRedirectResponse.url\n-  )\n-\n-  // fetch the actual logs\n-  const jobLogsResponse = await fetch(jobLogRedirectResponse.url, {\n-    headers: {\n-      Accept: 'application/vnd.github.v3+json',\n-      // [NOTE] we used to attach auth token, but seems this can cause 403\n-      // redirect url is public anyway\n-      //Authorization: `token ${token}`,\n-    },\n-  })\n-\n-  if (!jobLogsResponse.ok) {\n-    throw new Error(\n-      `Failed to get logsUrl, got status ${jobLogsResponse.status}`\n-    )\n-  }\n-\n-  // this should be the check_run's raw logs including each line\n-  // prefixed with a timestamp in format 2020-03-02T18:42:30.8504261Z\n-  const logText: string = await jobLogsResponse.text()\n-  const dateTimeStripped = logText\n-    .split('\\n')\n-    .map((line) => line.substr('2020-03-02T19:39:16.8832288Z '.length))\n-\n-  const nextjsVersion = dateTimeStripped\n-    .find((x) => x.includes('RUNNING NEXTJS VERSION:') && !x.includes('$('))\n-    ?.split('RUNNING NEXTJS VERSION:')\n-    .pop()\n-    ?.trim()!\n-\n-  console.log('Found Next.js version: ', nextjsVersion)\n-\n-  return nextjsVersion\n-}\n-\n // Download logs for a job in a workflow run by reading redirect url from workflow log response.\n async function fetchJobLogsFromWorkflow(\n   octokit: Octokit,\n-  token: string,\n   job: Job\n ): Promise<{ logs: string; job: Job }> {\n   console.log(\n     `fetchJobLogsFromWorkflow ${job.name}: Checking test results for the job`\n   )\n \n   // downloadJobLogsForWorkflowRun returns a redirect to the actual logs\n+  // The returned URL is valid (without any additional auth) for 1 minute\n   const jobLogRedirectResponse =\n     await octokit.rest.actions.downloadJobLogsForWorkflowRun({\n       accept: 'application/vnd.github.v3+json',\n@@ -101,7 +42,6 @@ async function fetchJobLogsFromWorkflow(\n   const jobLogsResponse = await fetch(jobLogRedirectResponse.url, {\n     headers: {\n       Accept: 'application/vnd.github.v3+json',\n-      //Authorization: `token ${token}`,\n     },\n   })\n \n@@ -120,7 +60,7 @@ async function fetchJobLogsFromWorkflow(\n   const logText: string = await jobLogsResponse.text()\n   const dateTimeStripped = logText\n     .split('\\n')\n-    .map((line) => line.substr('2020-03-02T19:39:16.8832288Z '.length))\n+    .map((line) => line.substring('2020-03-02T19:39:16.8832288Z '.length))\n \n   const logs = dateTimeStripped.join('\\n')\n \n@@ -130,45 +70,35 @@ async function fetchJobLogsFromWorkflow(\n // Collect necessary inputs to run actions,\n async function getInputs(): Promise<{\n   token: string\n-  shouldDiffWithMain: boolean\n   octokit: Octokit\n   prNumber: number | undefined\n   sha: string\n   noBaseComparison: boolean\n   shouldExpandResultMessages: boolean\n }> {\n   const token = getInput('token')\n+  const octokit = getOctokit(token)\n+\n   const shouldExpandResultMessages =\n     getInput('expand_result_messages') === 'true'\n-  const diffBase = getInput('diff_base')\n-  const shouldDiffWithMain = diffBase === 'main'\n-  // For the daily cron workflow, we don't compare to previous but post daily summary\n-  const noBaseComparison = diffBase === 'none'\n-  if (diffBase !== 'main' && diffBase !== 'release' && diffBase !== 'none') {\n-    console.error('Invalid diff_base, must be \"main\" or \"release\" or \"none\"')\n-    process.exit(1)\n-  }\n \n   if (!shouldExpandResultMessages) {\n     console.log('Test report comment will not include result messages.')\n   }\n \n-  const octokit = getOctokit(token)\n-\n   const prNumber = context?.payload?.pull_request?.number\n   const sha = context?.sha\n \n-  let comments:\n-    | Awaited<ReturnType<typeof octokit.rest.issues.listComments>>['data']\n-    | null = null\n+  // For the daily cron workflow, we don't compare to previous but post daily summary\n+  const noBaseComparison = prNumber == null\n \n-  if (prNumber) {\n+  if (prNumber != null) {\n     console.log('Trying to collect integration stats for PR', {\n       prNumber,\n       sha: sha,\n     })\n \n-    comments = await octokit.paginate(octokit.rest.issues.listComments, {\n+    const comments = await octokit.paginate(octokit.rest.issues.listComments, {\n       ...context.repo,\n       issue_number: prNumber,\n       per_page: 200,\n@@ -198,23 +128,21 @@ async function getInputs(): Promise<{\n     info('No PR number found in context, will not try to post comment.')\n   }\n \n-  console.log('getInputs: these inputs will be used to collect test results', {\n-    token: !!token,\n-    shouldDiffWithMain,\n-    prNumber,\n-    sha,\n-    diff_base: getInput('diff_base'),\n-  })\n-\n-  return {\n+  const inputs = {\n     token,\n-    shouldDiffWithMain,\n     octokit,\n     prNumber,\n     sha,\n     noBaseComparison,\n     shouldExpandResultMessages,\n   }\n+\n+  console.log('getInputs: these inputs will be used to collect test results', {\n+    ...inputs,\n+    token: !!token, // redact this\n+  })\n+\n+  return inputs\n }\n \n // Iterate all the jobs in the current workflow run, collect & parse logs for failed jobs for the postprocessing.\n@@ -233,45 +161,9 @@ async function getJobResults(\n     }\n   )\n \n-  // Filter out next.js build setup jobs\n-  const nextjsBuildSetupJob = jobs?.find((job) =>\n-    /Build Next.js for the turbopack integration test$/.test(job.name)\n-  )\n-\n-  // Next.js build setup jobs includes the version of next.js that is being tested, try to read it.\n-  const nextjsVersion = await findNextJsVersionFromBuildLogs(\n-    octokit,\n-    token,\n-    nextjsBuildSetupJob\n-  )\n-\n-  // Find out next-swc build workflow\n-  const nextSwcBuildJob = jobs?.find((job) =>\n-    job.name.includes('Build Next.js for the turbopack integration test')\n-  )\n-  const nextSwcBuildLogs = (\n-    await fetchJobLogsFromWorkflow(octokit, token, nextSwcBuildJob)\n-  ).logs.split('\\n')\n-  const buildTimeMatch = (\n-    nextSwcBuildLogs.find((line) => line.includes('Time (abs â‰¡):')) ?? ''\n-  ).match(/  ([+-]?(?=\\.\\d|\\d)(?:\\d+)?(?:\\.?\\d*))(?:[Ee]([+-]?\\d+))? s/)\n-  const buildTime = buildTimeMatch?.length >= 2 ? buildTimeMatch[1] : undefined\n-  const nextSwcBuildSize = (\n-    nextSwcBuildLogs.find(\n-      (line) =>\n-        line.includes('NEXT_SWC_FILESIZE:') &&\n-        /NEXT_SWC_FILESIZE: (\\d+)/.test(line)\n-    ) ?? ''\n-  ).match(/NEXT_SWC_FILESIZE: (\\d+)/)[1]\n-\n-  console.log(`Found next-swc build information from build logs`, {\n-    buildTime,\n-    nextSwcBuildSize,\n-  })\n-\n   // Filter out next.js integration test jobs\n   const integrationTestJobs = jobs?.filter((job) =>\n-    /Next\\.js integration test \\([^)]*\\) \\([^)]*\\)$/.test(job.name)\n+    /Next\\.js integration test \\([^)]*\\) \\([^)]*\\)/.test(job.name)\n   )\n \n   console.log(\n@@ -281,20 +173,11 @@ async function getJobResults(\n \n   // Iterate over all of next.js integration test jobs, read logs and collect failed test results if exists.\n   const fullJobLogsFromWorkflow = await Promise.all(\n-    integrationTestJobs.map((job) =>\n-      fetchJobLogsFromWorkflow(octokit, token, job)\n-    )\n+    integrationTestJobs.map((job) => fetchJobLogsFromWorkflow(octokit, job))\n   )\n \n   console.log('Logs downloaded for all jobs')\n \n-  const testResultManifest: TestResultManifest = {\n-    nextjsVersion,\n-    buildTime,\n-    buildSize: nextSwcBuildSize,\n-    ref: sha,\n-  } as any\n-\n   const [jobResults, flakyMonitorJobResults] = fullJobLogsFromWorkflow.reduce(\n     (acc, { logs, job }) => {\n       const subset = job.name.includes('FLAKY_SUBSET')\n@@ -306,7 +189,7 @@ async function getJobResults(\n       // First item isn't test data, it's just the log header\n       splittedLogs.shift()\n       for (const logLine of splittedLogs) {\n-        let testData\n+        let testData: string | undefined\n         try {\n           testData = logLine.split('--test output end--')[0].trim()!\n \n@@ -333,8 +216,11 @@ async function getJobResults(\n \n   console.log(`Flakyness test subset results`, { flakyMonitorJobResults })\n \n-  testResultManifest.flakyMonitorJobResults = flakyMonitorJobResults\n-  testResultManifest.result = jobResults\n+  const testResultManifest: TestResultManifest = {\n+    ref: sha,\n+    flakyMonitorJobResults: flakyMonitorJobResults,\n+    result: jobResults,\n+  }\n \n   // Collect all test results into single manifest to store into file. This'll allow to upload / compare test results\n   // across different runs.\n@@ -348,158 +234,16 @@ async function getJobResults(\n \n // Get the latest base test results to diff against with current test results.\n async function getTestResultDiffBase(\n-  octokit: Octokit,\n-  shouldDiffWithMain: boolean\n+  _octokit: Octokit\n ): Promise<TestResultManifest | null> {\n-  console.log('Trying to find latest test results to compare')\n-\n-  // First, get the tree of `test-results` from `nextjs-integration-test-data` branch\n-  const branchTree = (\n-    await octokit.rest.git.getTree({\n-      ...context.repo,\n-      tree_sha: 'refs/heads/nextjs-integration-test-data',\n-    })\n-  ).data.tree.find((tree) => tree.path === 'test-results')\n-\n-  if (!branchTree || !branchTree.sha) {\n-    console.error(\"Couldn't find existing test results\")\n-    return null\n-  }\n-\n-  // Get the trees under `/test-results`\n-  const testResultsTree = (\n-    await octokit.rest.git.getTree({\n-      ...context.repo,\n-      tree_sha: branchTree.sha,\n-    })\n-  ).data.tree\n-\n-  // If base is main, get the tree under `test-results/main`\n-  // Otherwise iterate over all the trees under `test-results` then find latest next.js release\n-  let testResultJsonTree:\n-    | Awaited<\n-        ReturnType<Awaited<Octokit['rest']['git']['getTree']>>\n-      >['data']['tree']\n-    | undefined\n-\n-  if (shouldDiffWithMain) {\n-    console.log('Trying to find latest test results from main branch')\n-    const baseTree = testResultsTree.find((tree) => tree.path === 'main')\n-\n-    if (!baseTree || !baseTree.sha) {\n-      console.log('There is no base to compare test results against')\n-      return null\n-    }\n-    console.log('Found base tree', baseTree)\n-\n-    // Now tree should point the list of .json for the actual test results\n-    testResultJsonTree = (\n-      await octokit.rest.git.getTree({\n-        ...context.repo,\n-        tree_sha: baseTree.sha,\n-      })\n-    ).data.tree\n-  } else {\n-    console.log('Trying to find latest test results from next.js release')\n-    const getVersion = (v: { path?: string }) => {\n-      if (v.path) {\n-        console.log('Trying to get version from base path', v.path)\n-        const base = path.basename(v.path, '.json')\n-        const ret = base.split('-').slice(1, 3).join('-')\n-        console.log('Found version', ret)\n-        return ret\n-      }\n-\n-      return null\n-    }\n-\n-    const baseTree = testResultsTree\n-      .filter((tree) => tree.path !== 'main')\n-      .reduce((acc, value) => {\n-        if (!acc) {\n-          return value\n-        }\n-\n-        const currentVersion = semver.valid(getVersion(value))\n-        const accVersion = semver.valid(getVersion(acc))\n-\n-        if (!currentVersion || !accVersion) {\n-          return acc\n-        }\n-\n-        return semver.gt(currentVersion, accVersion) ? value : acc\n-      }, null)\n-\n-    if (!baseTree || !baseTree.sha) {\n-      console.log('There is no base to compare test results against')\n-      return null\n-    }\n-    console.log('Found base tree', baseTree)\n-\n-    // If the results is for the release, no need to traverse down the tree\n-    testResultJsonTree = [baseTree]\n-  }\n-\n-  if (!testResultJsonTree) {\n-    console.log('There is no test results stored in the base yet')\n-    return null\n-  }\n-\n-  // Find the latest test result tree, iterate results file names to find out the latest one.\n-  // Filename follow ${yyyyMMddHHmm}-${sha}.json format.\n-  const actualTestResultTree = testResultJsonTree.reduce(\n-    (acc, value) => {\n-      const dateStr = value.path?.split('-')[0].match(/(....)(..)(..)(..)(..)/)\n-\n-      if (!dateStr || dateStr.length < 5) {\n-        return acc\n-      }\n-\n-      const date = new Date(\n-        dateStr![1] as any,\n-        (dateStr![2] as any) - 1,\n-        dateStr![3] as any,\n-        dateStr![4] as any,\n-        dateStr![5] as any\n-      )\n-      if (!acc) {\n-        return {\n-          date,\n-          value,\n-        }\n-      }\n-\n-      return acc.date >= date ? acc : { date, value }\n-    },\n-    null as any as { date: Date; value: (typeof testResultJsonTree)[0] }\n-  )\n-\n-  if (!actualTestResultTree || !actualTestResultTree?.value?.sha) {\n-    console.log('There is no test results json stored in the base yet')\n-    return null\n-  }\n-\n-  console.log(\n-    'Found test results to compare against: ',\n-    actualTestResultTree.value\n-  )\n-\n-  // actualTestResultTree should point to the file that contains the test results\n-  // we can try to read now.\n-  const { data } = await octokit.rest.git.getBlob({\n-    ...context.repo,\n-    file_sha: actualTestResultTree.value.sha,\n-  })\n-\n-  const { encoding, content } = data\n-\n-  if (encoding === 'base64') {\n-    return JSON.parse(Buffer.from(content, 'base64').toString())\n-  } else if (encoding === 'utf-8') {\n-    return JSON.parse(content)\n-  } else {\n-    throw new Error('Unknown encoding: ' + encoding)\n-  }\n+  // TODO: This code was previously written for the `vercel/turborepo`\n+  // repository which used to have a `nextjs-integration-test-data` branch with\n+  // all the previous test run data.\n+  //\n+  // The last update to that branch is from Dec 2023. If we want to support\n+  // comparisions with the canary branch, we need to read this data from\n+  // somewhere else.\n+  return null\n }\n \n function withoutRetries(results: Array<JobResult>): Array<JobResult> {\n@@ -519,7 +263,6 @@ function withoutRetries(results: Array<JobResult>): Array<JobResult> {\n \n function getTestSummary(\n   sha: string,\n-  shouldDiffWithMain: boolean,\n   baseResults: TestResultManifest | null,\n   jobResults: TestResultManifest\n ) {\n@@ -559,8 +302,6 @@ function getTestSummary(\n     }\n   )\n \n-  const shortCurrentNextJsVersion = jobResults.nextjsVersion.split(' ')[1]\n-\n   console.log(\n     'Current test summary',\n     JSON.stringify(\n@@ -656,15 +397,9 @@ function getTestSummary(\n     testCaseDiff = `:arrow_up_small: ${-caseCountDiff}`\n   }\n \n-  const shortBaseNextJsVersion = baseResults.nextjsVersion.split(' ')[1]\n-\n   // Append summary test report to the comment body\n   let ret = `### Test summary\n-|   | ${\n-    shouldDiffWithMain\n-      ? `main (${baseResults.ref} / ${shortBaseNextJsVersion})`\n-      : `release (${baseResults.ref} / ${shortBaseNextJsVersion})`\n-  } | Current (${sha} / ${shortCurrentNextJsVersion}) | Diff (Failed) |\n+|   | ${`canary (${baseResults.ref}`} | Current (${sha}) | Diff (Failed) |\n |---|---|---|---|\n | Test suites | :red_circle: ${baseTestFailedSuiteCount} / :green_circle: ${baseTestPassedSuiteCount} (Total: ${baseTestTotalSuiteCount}) | :red_circle: ${currentTestFailedSuiteCount} / :green_circle: ${currentTestPassedSuiteCount} (Total: ${currentTestTotalSuiteCount}) | ${testSuiteDiff} |\n | Test cases | :red_circle: ${baseTestFailedCaseCount} / :green_circle: ${baseTestPassedCaseCount} (Total: ${baseTestTotalCaseCount}) | :red_circle: ${currentTestFailedCaseCount} / :green_circle: ${currentTestPassedCaseCount} (Total: ${currentTestTotalCaseCount}) | ${testCaseDiff} |\n@@ -740,7 +475,6 @@ async function run() {\n   const {\n     token,\n     octokit,\n-    shouldDiffWithMain,\n     prNumber,\n     sha,\n     noBaseComparison,\n@@ -753,7 +487,7 @@ async function run() {\n   // Get the base to compare against\n   const baseResults = noBaseComparison\n     ? null\n-    : await getTestResultDiffBase(octokit, shouldDiffWithMain)\n+    : await getTestResultDiffBase(octokit)\n \n   const postCommentAsync = createCommentPostAsync(octokit, prNumber)\n \n@@ -763,7 +497,7 @@ async function run() {\n   const perJobFailedLists = {}\n \n   // Consturct a comment body to post test report with summary & full details.\n-  const comments = jobResults.result.reduce((acc, value, idx) => {\n+  const comments = jobResults.result.reduce((acc, value, _idx) => {\n     const { data: testData } = value\n \n     const commentValues = []\n@@ -860,12 +594,7 @@ async function run() {\n     {\n       header: [`Commit: ${sha}`],\n       contents: [\n-        getTestSummary(\n-          sha,\n-          shouldDiffWithMain,\n-          noBaseComparison ? null : baseResults,\n-          jobResults\n-        ),\n+        getTestSummary(sha, noBaseComparison ? null : baseResults, jobResults),\n       ],\n     },\n     ...comments,"
        },
        {
            "sha": "7eacc376bd1db6b410811a04c02ccd72a8ed4b2e",
            "filename": ".github/actions/next-integration-stat/src/manifest.d.ts",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Fmanifest.d.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Fmanifest.d.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Factions%2Fnext-integration-stat%2Fsrc%2Fmanifest.d.ts?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -4,10 +4,7 @@ interface JobResult {\n }\n \n interface TestResultManifest {\n-  nextjsVersion: string\n   ref: string\n-  buildTime?: string\n-  buildSize?: string\n   result: Array<JobResult>\n   flakyMonitorJobResults: Array<JobResult>\n }"
        },
        {
            "sha": "3a21f5b1469d3e41983c57f9bfbfa7d5e2434e8d",
            "filename": ".github/workflows/build_reusable.yml",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fbuild_reusable.yml",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fbuild_reusable.yml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Fworkflows%2Fbuild_reusable.yml?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -226,7 +226,13 @@ jobs:\n \n       - run: turbo run get-test-timings -- --build ${{ github.sha }}\n \n-      - run: /bin/bash -c \"${{ inputs.afterBuild }}\"\n+      - run: ${{ inputs.afterBuild }}\n+        # defaults.run.shell sets a stronger options (`-leo pipefail`)\n+        # Set this back to github action's weaker defaults:\n+        # https://docs.github.com/en/actions/writing-workflows/workflow-syntax-for-github-actions#jobsjob_idstepsshell\n+        #\n+        # We must use a login shell: fnm installation may modify the `.profile`\n+        shell: bash -le {0}\n         timeout-minutes: ${{ inputs.timeout_minutes }}\n \n       - name: Upload artifact"
        },
        {
            "sha": "bf85668920dc2afcce06daa9cc4e2279aa7f128b",
            "filename": ".github/workflows/integration_tests_reusable.yml",
            "status": "added",
            "additions": 170,
            "deletions": 0,
            "changes": 170,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fintegration_tests_reusable.yml",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fintegration_tests_reusable.yml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Fworkflows%2Fintegration_tests_reusable.yml?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -0,0 +1,170 @@\n+name: Integration Tests Reusable\n+\n+on:\n+  workflow_call:\n+    inputs:\n+      name:\n+        description: A unique identifer used for uploaded assets\n+        type: string\n+      test_type:\n+        description: '\"development\" or \"production\"'\n+        required: true\n+        type: string\n+      run_before_test:\n+        description: >\n+          Bash code to run before executing the test (e.g. setting environment\n+          variables). Runs in the same step as the test.\n+        type: string\n+        default: ''\n+      e2e_groups:\n+        description: >\n+          Size of the matrix used for running e2e tests (controls parallelism)\n+        type: number\n+        default: 6\n+      integration_groups:\n+        description: >\n+          Size of the matrix used for running legacy integration tests (controls\n+          parallelism)\n+        type: number\n+        default: 6\n+      e2e_timeout_minutes:\n+        type: number\n+        default: 30\n+      integration_timeout_minutes:\n+        type: number\n+        default: 30\n+\n+jobs:\n+  # First, build Next.js to execute across tests.\n+  build-next:\n+    name: build-next\n+    uses: ./.github/workflows/build_reusable.yml\n+    with:\n+      skipNativeBuild: yes\n+      stepName: build-next\n+    secrets: inherit\n+\n+  build-native:\n+    name: build-native\n+    uses: ./.github/workflows/build_reusable.yml\n+    with:\n+      skipInstallBuild: yes\n+      stepName: build-native\n+    secrets: inherit\n+\n+  generate-matrices:\n+    runs-on: [self-hosted, linux, x64, metal]\n+    steps:\n+      - id: out\n+        run: |\n+          printf 'e2e=[%s]\\n' \\\n+            \"$(seq -s, 1 ${{ inputs.e2e_groups }})\" | \\\n+            tee -a \"$GITHUB_OUTPUT\"\n+          printf 'integration=[%s]\\n' \\\n+            \"$(seq -s, 1 ${{ inputs.integration_groups }})\" | \\\n+            tee -a \"$GITHUB_OUTPUT\"\n+    outputs:\n+      e2e: ${{ steps.out.outputs.e2e }}\n+      integration: ${{ steps.out.outputs.integration }}\n+\n+  # Actual test scheduling. These jobs mimic the normal test jobs.\n+  # Refer build_and_test.yml for more details.\n+  #\n+  # We run tests in two parts. Legacy integration tests are run separately:\n+  # https://github.com/vercel/next.js/blob/canary/contributing/core/testing.md#test-types-in-nextjs\n+  test-e2e:\n+    # Name must match `integrationTestJobs` in\n+    # `./.github/actions/next-integration-stat`\n+    name: >-\n+      Next.js integration test (E2E and ${{ inputs.test_type }})\n+      (${{ matrix.group }}/${{ inputs.e2e_groups }})\n+    needs: [build-next, build-native, generate-matrices]\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        group: ${{ fromJSON(needs.generate-matrices.outputs.e2e) }}\n+    uses: ./.github/workflows/build_reusable.yml\n+    with:\n+      afterBuild: |\n+        # e2e and ${{ inputs.test_type }} tests with `node run-tests.js`\n+\n+        export NEXT_TEST_CONTINUE_ON_ERROR=TRUE\n+        export NEXT_E2E_TEST_TIMEOUT=240000\n+        export NEXT_TEST_MODE=${{\n+          inputs.test_type == 'development' && 'dev' || 'start'\n+        }}\n+\n+        ${{ inputs.run_before_test }}\n+\n+        node run-tests.js \\\n+          -g ${{ matrix.group }}/${{ inputs.e2e_groups }} \\\n+          -c $TEST_CONCURRENCY \\\n+          --type ${{ inputs.test_type }}\n+      stepName: test-${{ inputs.name }}-${{ matrix.group }}\n+      timeout_minutes: ${{ inputs.e2e_timeout_minutes }}\n+    secrets: inherit\n+\n+  test-integration:\n+    # Name must match `integrationTestJobs` in\n+    # `./.github/actions/next-integration-stat`\n+    name: >-\n+      Next.js integration test (Integration)\n+      (${{ matrix.group }}/${{ inputs.e2e_groups }})\n+    needs: [build-next, build-native, generate-matrices]\n+    strategy:\n+      fail-fast: false\n+      matrix:\n+        group: ${{ fromJSON(needs.generate-matrices.outputs.integration) }}\n+    uses: ./.github/workflows/build_reusable.yml\n+    with:\n+      nodeVersion: 18.18.2\n+      afterBuild: |\n+        # legacy integration tests with `node run-tests.js`\n+\n+        export NEXT_TEST_CONTINUE_ON_ERROR=TRUE\n+        export NEXT_E2E_TEST_TIMEOUT=240000\n+\n+        # HACK: Despite the name, these environment variables are just used to\n+        # gate tests, so they're applicable to both turbopack and rspack tests\n+        export ${{\n+          inputs.test_type == 'development' &&\n+            'TURBOPACK_DEV=1' ||\n+            'TURBOPACK_BUILD=1'\n+        }}\n+\n+        ${{ inputs.run_before_test }}\n+\n+        node run-tests.js \\\n+          -g ${{ matrix.group }}/${{ inputs.integration_groups }} \\\n+          -c $TEST_CONCURRENCY \\\n+          --type integration\n+      stepName: test-${{ inputs.name }}-integration-${{ matrix.group }}\n+      timeout_minutes: ${{ inputs.integration_timeout_minutes }}\n+    secrets: inherit\n+\n+  # Collect integration test results from execute_tests,\n+  # Store it as github artifact for next step to consume.\n+  collect_nextjs_development_integration_stat:\n+    needs: [test-e2e, test-integration]\n+    name: Next.js integration test development status report\n+    runs-on: [self-hosted, linux, x64, metal]\n+    if: always()\n+    permissions:\n+      pull-requests: write\n+    steps:\n+      - name: Checkout\n+        uses: actions/checkout@v4\n+\n+      - name: Collect integration test stat\n+        uses: ./.github/actions/next-integration-stat\n+        with:\n+          token: ${{ secrets.GITHUB_TOKEN }}\n+\n+      - name: Store artifacts\n+        uses: actions/upload-artifact@v4\n+        with:\n+          name: test-results-${{ inputs.name }}\n+          path: |\n+            nextjs-test-results.json\n+            failed-test-path-list.json\n+            passed-test-path-list.json"
        },
        {
            "sha": "9409247a2d7759b12efefda4a7d9b167b05c8d38",
            "filename": ".github/workflows/turbopack-nextjs-build-integration-tests.yml",
            "status": "modified",
            "additions": 16,
            "deletions": 204,
            "changes": 220,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fturbopack-nextjs-build-integration-tests.yml",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fturbopack-nextjs-build-integration-tests.yml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Fworkflows%2Fturbopack-nextjs-build-integration-tests.yml?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -1,212 +1,24 @@\n-# Reusable workflow to execute certain version of Next.js integration tests\n-# with turbopack.\n-#\n-# Refer test.yml for how this workflow is being initialized\n-# - Workflow can specify `inputs.version` to specify which version of next.js to use, otherwise will use latest release version.\n name: Turbopack Next.js production integration tests\n \n on:\n   schedule:\n     - cron: '0 6 * * *'\n-  workflow_dispatch:\n-    inputs:\n-      # Allow to specify Next.js version to run integration test against.\n-      # If not specified, will use latest release version including canary.\n-      version:\n-        description: Next.js version, sha, branch to test\n-        type: string\n-        default: 'canary'\n-      # The base of the test results to compare against. If not specified, will try to compare with latest main branch's test results.\n-      diff_base:\n-        type: string\n-        default: 'none'\n-\n-# Workflow-common env variables\n-env:\n-  # Enabling backtrace will makes snapshot tests fail\n-  RUST_BACKTRACE: 0\n-  NEXT_TELEMETRY_DISABLED: 1\n-  TEST_CONCURRENCY: 6\n-  NEXT_JUNIT_TEST_REPORT: 'true'\n-  __INTERNAL_CUSTOM_TURBOPACK_BINDINGS: ${{ github.workspace }}/packages/next-swc/native/next-swc.linux-x64-gnu.node\n-  NEXT_TEST_SKIP_RETRY_MANIFEST: ${{ github.workspace }}/integration-test-data/test-results/main/failed-test-path-list.json\n-  NEXT_TEST_CONTINUE_ON_ERROR: TRUE\n-  NEXT_E2E_TEST_TIMEOUT: 240000\n-  NEXT_TEST_JOB: 1\n+  workflow_dispatch: {}\n \n jobs:\n-  # First, build Next.js to execute across tests.\n-  setup_nextjs:\n-    name: Setup Next.js build\n-    uses: ./.github/workflows/setup-nextjs-build.yml\n+  test-dev:\n+    name: Next.js integration tests\n+    uses: ./.github/workflows/integration_tests_reusable.yml\n     with:\n-      nodeVersion: 18.18.2\n-      version: ${{ inputs.version || 'canary' }}\n-\n-  # Actual test scheduling. These jobs mimic the same jobs in Next.js repo,\n-  # which we do allow some of duplications to make it easier to update if upstream changes.\n-  # Refer build_and_test.yml in the Next.js repo for more details.\n-  test-production:\n-    # This job name is being used in github action to collect test results. Do not change it, or should update\n-    # ./.github/actions/next-integration-stat to match the new name.\n-    name: Next.js integration test (Production)\n-    # Currently it is possible test grouping puts large number of failing tests suites in a single group,\n-    # which ends up job timeouts. Temporarily relieve the timeout until we make progresses on the failing suites.\n-    # ref: https://github.com/vercel/turbo/pull/5668\n-    # timeout-minutes: 180\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    needs: [setup_nextjs]\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        group: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n-\n-    steps:\n-      - name: Setup Node.js\n-        uses: actions/setup-node@v4\n-        with:\n-          node-version: 18.18.2\n-          check-latest: true\n-      - uses: actions/cache/restore@v3\n-        id: restore-build\n-        with:\n-          path: ./*\n-          key: ${{ inputs.version || 'canary' }}-${{ github.sha }}-${{ github.run_id }}-${{ github.run_attempt}}-${{ github.run_number }}\n-          fail-on-cache-miss: true\n-\n-      - name: Enable corepack and install yarn\n-        run: |\n-          corepack enable\n-          corepack prepare --activate yarn@1.22.19\n-\n-      - name: Setup playwright\n-        run: |\n-          pnpm playwright install\n-\n-      - name: Run test/production\n-        run: |\n-          NEXT_TEST_MODE=start TURBOPACK=1 TURBOPACK_BUILD=1 NEXT_E2E_TEST_TIMEOUT=240000 node run-tests.js -g ${{ matrix.group }}/12 -c ${TEST_CONCURRENCY} --type production\n-        # It is currently expected to fail some of next.js integration test, do not fail CI check.\n-        continue-on-error: true\n-\n-      - name: Upload test report artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-reports-start-${{ matrix.group }}\n-          if-no-files-found: 'error'\n-          path: |\n-            test/turbopack-test-junit-report\n-\n-  test-integration-production:\n-    name: Next.js integration test (Integration)\n-    needs: [setup_nextjs]\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    timeout-minutes: 180\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        group: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n-\n-    steps:\n-      - name: Setup Node.js\n-        uses: actions/setup-node@v4\n-        with:\n-          node-version: 18.18.2\n-          check-latest: true\n-      - uses: actions/cache/restore@v3\n-        id: restore-build\n-        with:\n-          path: ./*\n-          key: ${{ inputs.version || 'canary' }}-${{ github.sha }}\n-          fail-on-cache-miss: true\n-\n-      - name: Enable corepack and install yarn\n-        run: |\n-          corepack enable\n-          corepack prepare --activate yarn@1.22.19\n-\n-      - name: Setup playwright\n-        run: |\n-          pnpm playwright install\n-\n-      - name: Run test/integration\n-        run: |\n-          TURBOPACK=1 TURBOPACK_BUILD=1 NEXT_E2E_TEST_TIMEOUT=240000 node run-tests.js -g ${{ matrix.group }}/12 -c ${TEST_CONCURRENCY} --type integration\n-        continue-on-error: true\n-\n-      - name: Upload test report artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-reports-build-integration-${{ matrix.group }}\n-          if-no-files-found: 'error'\n-          path: |\n-            test/turbopack-test-junit-report\n-\n-  # Collect integration test results from execute_tests,\n-  # Store it as github artifact for next step to consume.\n-  collect_nextjs_production_integration_stat:\n-    needs: [test-production, test-integration-production]\n-    name: Next.js integration test production status report\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    if: always()\n-    permissions:\n-      pull-requests: write\n-    steps:\n-      - name: Checkout\n-        uses: actions/checkout@v4\n-\n-      - name: Collect integration test stat\n-        uses: ./.github/actions/next-integration-stat\n-        with:\n-          diff_base: ${{ inputs.diff_base || 'none' }}\n-\n-      - name: Store artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-results-turbopack-production\n-          path: |\n-            nextjs-test-results.json\n-            failed-test-path-list.json\n-            passed-test-path-list.json\n-\n-  upload_test_report:\n-    needs: [test-production, test-integration-production]\n-    name: Upload test report to datadog\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    if: ${{ !cancelled() }}\n-    steps:\n-      - name: Download test report artifacts\n-        id: download-test-reports\n-        uses: actions/download-artifact@v4\n-        with:\n-          pattern: test-reports-*\n-          path: test/reports\n-          merge-multiple: true\n-\n-      - name: Upload to datadog\n-        env:\n-          DATADOG_API_KEY: ${{ secrets.DATA_DOG_API_KEY }}\n-          DD_ENV: 'ci'\n-        run: |\n-          # We'll tag this to the \"Turbopack\" datadog service, not \"nextjs\"\n-          npx @datadog/datadog-ci@2.23.1 junit upload --tags test.type:turbopack-build.daily --service Turbopack-build ./test/reports\n+      name: turbopack-production\n+      test_type: production\n+      run_before_test: |\n+        export TURBOPACK=1 TURBOPACK_BUILD=1\n+      # Failing tests take longer (due to timeouts and retries). Since we have\n+      # many failing tests, we need smaller groups and longer timeouts, in case\n+      # a group gets stuck with a cluster of failing tests.\n+      e2e_groups: 12\n+      integration_groups: 12\n+      e2e_timeout_minutes: 60\n+      integration_timeout_minutes: 60\n+    secrets: inherit"
        },
        {
            "sha": "9e1f4a4a470e91715d5aa9dc21ae0bec4fad87f7",
            "filename": ".github/workflows/turbopack-nextjs-dev-integration-tests.yml",
            "status": "modified",
            "additions": 9,
            "deletions": 204,
            "changes": 213,
            "blob_url": "https://github.com/vercel/next.js/blob/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fturbopack-nextjs-dev-integration-tests.yml",
            "raw_url": "https://github.com/vercel/next.js/raw/13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55/.github%2Fworkflows%2Fturbopack-nextjs-dev-integration-tests.yml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/.github%2Fworkflows%2Fturbopack-nextjs-dev-integration-tests.yml?ref=13fcfabf1beb3565d2bb191bd8d8ce4ad6d97b55",
            "patch": "@@ -1,212 +1,17 @@\n-# Reusable workflow to execute certain version of Next.js integration tests\n-# with turbopack.\n-#\n-# Refer test.yml for how this workflow is being initialized\n-# - Workflow can specify `inputs.version` to specify which version of next.js to use, otherwise will use latest release version.\n name: Turbopack Next.js development integration tests\n \n on:\n   schedule:\n     - cron: '0 6 * * *'\n-  workflow_dispatch:\n-    inputs:\n-      # Allow to specify Next.js version to run integration test against.\n-      # If not specified, will use latest release version including canary.\n-      version:\n-        description: Next.js version, sha, branch to test\n-        type: string\n-        default: 'canary'\n-      # The base of the test results to compare against. If not specified, will try to compare with latest main branch's test results.\n-      diff_base:\n-        type: string\n-        default: 'none'\n-\n-# Workflow-common env variables\n-env:\n-  # Enabling backtrace will makes snapshot tests fail\n-  RUST_BACKTRACE: 0\n-  NEXT_TELEMETRY_DISABLED: 1\n-  TEST_CONCURRENCY: 6\n-  NEXT_JUNIT_TEST_REPORT: 'true'\n-  __INTERNAL_CUSTOM_TURBOPACK_BINDINGS: ${{ github.workspace }}/packages/next-swc/native/next-swc.linux-x64-gnu.node\n-  NEXT_TEST_SKIP_RETRY_MANIFEST: ${{ github.workspace }}/integration-test-data/test-results/main/failed-test-path-list.json\n-  NEXT_TEST_CONTINUE_ON_ERROR: TRUE\n-  NEXT_E2E_TEST_TIMEOUT: 240000\n-  NEXT_TEST_JOB: 1\n+  workflow_dispatch: {}\n \n jobs:\n-  # First, build next-dev and Next.js both to execute across tests.\n-  setup_nextjs:\n-    name: Setup Next.js build\n-    uses: ./.github/workflows/setup-nextjs-build.yml\n-    with:\n-      nodeVersion: 18.18.2\n-      version: ${{ inputs.version || 'canary' }}\n-\n-  # Actual test scheduling. These jobs mimic the same jobs in Next.js repo,\n-  # which we do allow some of duplications to make it easier to update if upstream changes.\n-  # Refer build_and_test.yml in the Next.js repo for more details.\n   test-dev:\n-    # This job name is being used in github action to collect test results. Do not change it, or should update\n-    # ./.github/actions/next-integration-stat to match the new name.\n-    name: Next.js integration test (Development)\n-    # Currently it is possible test grouping puts large number of failing tests suites in a single group,\n-    # which ends up job timeouts. Temporarily relieve the timeout until we make progresses on the failing suites.\n-    # ref: https://github.com/vercel/turbo/pull/5668\n-    # timeout-minutes: 180\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    needs: [setup_nextjs]\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        group: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n-\n-    steps:\n-      - name: Setup Node.js\n-        uses: actions/setup-node@v4\n-        with:\n-          node-version: 18.18.2\n-          check-latest: true\n-      - uses: actions/cache/restore@v3\n-        id: restore-build\n-        with:\n-          path: ./*\n-          key: ${{ inputs.version || 'canary' }}-${{ github.sha }}-${{ github.run_id }}-${{ github.run_attempt}}-${{ github.run_number }}\n-          fail-on-cache-miss: true\n-\n-      - name: Enable corepack and install yarn\n-        run: |\n-          corepack enable\n-          corepack prepare --activate yarn@1.22.19\n-\n-      - name: Setup playwright\n-        run: |\n-          pnpm playwright install\n-\n-      - name: Run test/development\n-        run: |\n-          NEXT_TEST_MODE=dev TURBOPACK=1 TURBOPACK_DEV=1 NEXT_E2E_TEST_TIMEOUT=240000 node run-tests.js -g ${{ matrix.group }}/12 -c ${TEST_CONCURRENCY} --type development\n-        # It is currently expected to fail some of next.js integration test, do not fail CI check.\n-        continue-on-error: true\n-\n-      - name: Upload test report artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-reports-dev-${{ matrix.group }}\n-          if-no-files-found: 'error'\n-          path: |\n-            test/turbopack-test-junit-report\n-\n-  test-integration-development:\n-    name: Next.js integration test (Integration)\n-    needs: [setup_nextjs]\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    timeout-minutes: 180\n-    strategy:\n-      fail-fast: false\n-      matrix:\n-        group: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n-\n-    steps:\n-      - name: Setup Node.js\n-        uses: actions/setup-node@v4\n-        with:\n-          node-version: 18.18.2\n-          check-latest: true\n-      - uses: actions/cache/restore@v3\n-        id: restore-build\n-        with:\n-          path: ./*\n-          key: ${{ inputs.version || 'canary' }}-${{ github.sha }}\n-          fail-on-cache-miss: true\n-\n-      - name: Enable corepack and install yarn\n-        run: |\n-          corepack enable\n-          corepack prepare --activate yarn@1.22.19\n-\n-      - name: Setup playwright\n-        run: |\n-          pnpm playwright install\n-\n-      - name: Run test/integration\n-        run: |\n-          TURBOPACK=1 TURBOPACK_DEV=1 NEXT_E2E_TEST_TIMEOUT=240000 node run-tests.js -g ${{ matrix.group }}/12 -c ${TEST_CONCURRENCY} --type integration\n-        continue-on-error: true\n-\n-      - name: Upload test report artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-reports-dev-integration-${{ matrix.group }}\n-          if-no-files-found: 'error'\n-          path: |\n-            test/turbopack-test-junit-report\n-\n-  # Collect integration test results from execute_tests,\n-  # Store it as github artifact for next step to consume.\n-  collect_nextjs_development_integration_stat:\n-    needs: [test-dev, test-integration-development]\n-    name: Next.js integration test development status report\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    if: always()\n-    permissions:\n-      pull-requests: write\n-    steps:\n-      - name: Checkout\n-        uses: actions/checkout@v4\n-\n-      - name: Collect integration test stat\n-        uses: ./.github/actions/next-integration-stat\n-        with:\n-          diff_base: ${{ inputs.diff_base || 'none' }}\n-\n-      - name: Store artifacts\n-        uses: actions/upload-artifact@v4\n-        with:\n-          name: test-results-turbopack-development\n-          path: |\n-            nextjs-test-results.json\n-            failed-test-path-list.json\n-            passed-test-path-list.json\n-\n-  upload_test_report:\n-    needs: [test-dev, test-integration-development]\n-    name: Upload test report to datadog\n-    runs-on:\n-      - 'self-hosted'\n-      - 'linux'\n-      - 'x64'\n-      - 'metal'\n-\n-    if: ${{ !cancelled() }}\n-    steps:\n-      - name: Download test report artifacts\n-        id: download-test-reports\n-        uses: actions/download-artifact@v4\n-        with:\n-          pattern: test-reports-*\n-          path: test/reports\n-          merge-multiple: true\n-\n-      - name: Upload to datadog\n-        env:\n-          DATADOG_API_KEY: ${{ secrets.DATA_DOG_API_KEY }}\n-          DD_ENV: 'ci'\n-        run: |\n-          # We'll tag this to the \"Turbopack\" datadog service, not \"nextjs\"\n-          npx @datadog/datadog-ci@2.23.1 junit upload --tags test.type:turbopack.daily --service Turbopack ./test/reports\n+    name: Next.js integration tests\n+    uses: ./.github/workflows/integration_tests_reusable.yml\n+    with:\n+      name: turbopack-development\n+      test_type: development\n+      run_before_test: |\n+        export TURBOPACK=1\n+    secrets: inherit"
        }
    ],
    "stats": {
        "total": 63503,
        "additions": 52933,
        "deletions": 10570
    }
}