{
    "author": "sokra",
    "message": "Turbopack: no need to avoid allocations anymore (#82222)\n\n### What?\n\nNo need to manually manage a free list, since mimalloc is able to handle this now",
    "sha": "b07bf2a0f7681080fd827c2cf408b2e0adff019d",
    "files": [
        {
            "sha": "a487ea2bbbdda422f6bd4427e0fb1bf87a7c4fa3",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/b07bf2a0f7681080fd827c2cf408b2e0adff019d/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b07bf2a0f7681080fd827c2cf408b2e0adff019d/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=b07bf2a0f7681080fd827c2cf408b2e0adff019d",
            "patch": "@@ -1,5 +1,4 @@\n use std::{\n-    any::{Any, TypeId},\n     borrow::Cow,\n     collections::HashSet,\n     fs::{self, File, OpenOptions, ReadDir},\n@@ -117,9 +116,6 @@ pub struct TurboPersistence {\n     read_only: bool,\n     /// The inner state of the database. Writing will update that.\n     inner: RwLock<Inner>,\n-    /// A cache for the last WriteBatch. It is used to avoid reallocation of buffers for the\n-    /// WriteBatch.\n-    idle_write_batch: Mutex<Option<(TypeId, Box<dyn Any + Send + Sync>)>>,\n     /// A flag to indicate if a write operation is currently active. Prevents multiple concurrent\n     /// write operations.\n     active_write_operation: AtomicBool,\n@@ -161,7 +157,6 @@ impl TurboPersistence {\n                 meta_files: Vec::new(),\n                 current_sequence_number: 0,\n             }),\n-            idle_write_batch: Mutex::new(None),\n             active_write_operation: AtomicBool::new(false),\n             aqmf_cache: AqmfCache::with(\n                 AQMF_CACHE_SIZE as usize / AQMF_AVG_SIZE,\n@@ -418,13 +413,6 @@ impl TurboPersistence {\n             );\n         }\n         let current = self.inner.read().current_sequence_number;\n-        if let Some((ty, any)) = self.idle_write_batch.lock().take()\n-            && ty == TypeId::of::<WriteBatch<K, FAMILIES>>()\n-        {\n-            let mut write_batch = *any.downcast::<WriteBatch<K, FAMILIES>>().unwrap();\n-            write_batch.reset(current);\n-            return Ok(write_batch);\n-        }\n         Ok(WriteBatch::new(self.path.clone(), current))\n     }\n \n@@ -466,10 +454,6 @@ impl TurboPersistence {\n             keys_written,\n         })?;\n         self.active_write_operation.store(false, Ordering::Release);\n-        self.idle_write_batch.lock().replace((\n-            TypeId::of::<WriteBatch<K, FAMILIES>>(),\n-            Box::new(write_batch),\n-        ));\n         Ok(())\n     }\n "
        },
        {
            "sha": "a52377a7e07b0cf6de0fefdf96fc9edbdb5ed90d",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 46,
            "changes": 58,
            "blob_url": "https://github.com/vercel/next.js/blob/b07bf2a0f7681080fd827c2cf408b2e0adff019d/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b07bf2a0f7681080fd827c2cf408b2e0adff019d/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=b07bf2a0f7681080fd827c2cf408b2e0adff019d",
            "patch": "@@ -82,10 +82,6 @@ pub struct WriteBatch<K: StoreKey + Send, const FAMILIES: usize> {\n     /// The list of new SST files that have been created.\n     /// Tuple of (sequence number, file).\n     new_sst_files: Mutex<Vec<(u32, File)>>,\n-    /// Collectors that are currently unused, but have memory preallocated.\n-    idle_collectors: Mutex<Vec<Collector<K>>>,\n-    /// Collectors that are currently unused, but have memory preallocated.\n-    idle_thread_local_collectors: Mutex<Vec<Collector<K, THREAD_LOCAL_SIZE_SHIFT>>>,\n }\n \n impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n@@ -102,18 +98,9 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                 .map(|_| Mutex::new(GlobalCollectorState::Unsharded(Collector::new()))),\n             meta_collectors: [(); FAMILIES].map(|_| Mutex::new(Vec::new())),\n             new_sst_files: Mutex::new(Vec::new()),\n-            idle_collectors: Mutex::new(Vec::new()),\n-            idle_thread_local_collectors: Mutex::new(Vec::new()),\n         }\n     }\n \n-    /// Resets the write batch to a new sequence number. This is called when the WriteBatch is\n-    /// reused.\n-    pub(crate) fn reset(&mut self, current: u32) {\n-        self.current_sequence_number\n-            .store(current, Ordering::SeqCst);\n-    }\n-\n     /// Returns the thread local state for the current thread.\n     #[allow(clippy::mut_from_ref)]\n     fn thread_local_state(&self) -> &mut ThreadLocalState<K, FAMILIES> {\n@@ -134,12 +121,8 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         family: u32,\n     ) -> Result<&'l mut Collector<K, THREAD_LOCAL_SIZE_SHIFT>> {\n         debug_assert!(usize_from_u32(family) < FAMILIES);\n-        let collector = state.collectors[usize_from_u32(family)].get_or_insert_with(|| {\n-            self.idle_thread_local_collectors\n-                .lock()\n-                .pop()\n-                .unwrap_or_else(|| Collector::new())\n-        });\n+        let collector =\n+            state.collectors[usize_from_u32(family)].get_or_insert_with(|| Collector::new());\n         if collector.is_full() {\n             self.flush_thread_local_collector(family, collector)?;\n         }\n@@ -172,7 +155,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                             for collector in shards.iter_mut() {\n                                 if collector.is_full() {\n                                     full_collectors\n-                                        .push(replace(&mut *collector, self.get_new_collector()));\n+                                        .push(replace(&mut *collector, Collector::new()));\n                                 }\n                             }\n                             *global_collector_state = GlobalCollectorState::Sharded(shards);\n@@ -183,8 +166,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                         let collector = &mut shards[shard];\n                         collector.add_entry(entry);\n                         if collector.is_full() {\n-                            full_collectors\n-                                .push(replace(&mut *collector, self.get_new_collector()));\n+                            full_collectors.push(replace(&mut *collector, Collector::new()));\n                         }\n                     }\n                 }\n@@ -193,28 +175,12 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         for mut global_collector in full_collectors {\n             // When the global collector is full, we create a new SST file.\n             let sst = self.create_sst_file(family, global_collector.sorted())?;\n-            global_collector.clear();\n             self.new_sst_files.lock().push(sst);\n-            self.dispose_collector(global_collector);\n+            drop(global_collector);\n         }\n         Ok(())\n     }\n \n-    fn get_new_collector(&self) -> Collector<K> {\n-        self.idle_collectors\n-            .lock()\n-            .pop()\n-            .unwrap_or_else(|| Collector::new())\n-    }\n-\n-    fn dispose_collector(&self, collector: Collector<K>) {\n-        self.idle_collectors.lock().push(collector);\n-    }\n-\n-    fn dispose_thread_local_collector(&self, collector: Collector<K, THREAD_LOCAL_SIZE_SHIFT>) {\n-        self.idle_thread_local_collectors.lock().push(collector);\n-    }\n-\n     /// Puts a key-value pair into the write batch.\n     pub fn put(&self, family: u32, key: K, value: ValueBuffer<'_>) -> Result<()> {\n         let state = self.thread_local_state();\n@@ -261,7 +227,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         collectors.into_par_iter().try_for_each(|mut collector| {\n             let _span = span.clone().entered();\n             self.flush_thread_local_collector(family, &mut collector)?;\n-            self.dispose_thread_local_collector(collector);\n+            drop(collector);\n             anyhow::Ok(())\n         })?;\n \n@@ -278,7 +244,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n             GlobalCollectorState::Sharded(_) => {\n                 let GlobalCollectorState::Sharded(shards) = replace(\n                     &mut *collector_state,\n-                    GlobalCollectorState::Unsharded(self.get_new_collector()),\n+                    GlobalCollectorState::Unsharded(Collector::new()),\n                 ) else {\n                     unreachable!();\n                 };\n@@ -288,7 +254,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                         let sst = self.create_sst_file(family, collector.sorted())?;\n                         collector.clear();\n                         self.new_sst_files.lock().push(sst);\n-                        self.dispose_collector(collector);\n+                        drop(collector);\n                     }\n                     anyhow::Ok(())\n                 })?;\n@@ -332,7 +298,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                         {\n                             *shared_error.lock() = Err(err);\n                         }\n-                        this.dispose_thread_local_collector(collector);\n+                        drop(collector);\n                     });\n                 }\n             }\n@@ -344,8 +310,8 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         let mut new_sst_files = take(self.new_sst_files.get_mut());\n         let shared_new_sst_files = Mutex::new(&mut new_sst_files);\n \n-        let new_collectors = [(); FAMILIES]\n-            .map(|_| Mutex::new(GlobalCollectorState::Unsharded(self.get_new_collector())));\n+        let new_collectors =\n+            [(); FAMILIES].map(|_| Mutex::new(GlobalCollectorState::Unsharded(Collector::new())));\n         let collectors = replace(&mut self.collectors, new_collectors);\n         let span = Span::current();\n         collectors\n@@ -370,7 +336,7 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n                 if !collector.is_empty() {\n                     let sst = self.create_sst_file(family, collector.sorted())?;\n                     collector.clear();\n-                    self.dispose_collector(collector);\n+                    drop(collector);\n                     shared_new_sst_files.lock().push(sst);\n                 }\n                 anyhow::Ok(())"
        }
    ],
    "stats": {
        "total": 74,
        "additions": 12,
        "deletions": 62
    }
}