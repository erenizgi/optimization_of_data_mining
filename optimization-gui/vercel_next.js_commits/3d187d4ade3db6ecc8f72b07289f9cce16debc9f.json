{
    "author": "sokra",
    "message": "Turbopack: initially shard SST files (#78652)\n\n### What?\n\nWhen many entries are written for a key family in a write batch, shard the entries into multiple SST files by key space.\n\nThis results in better initial distribution of keys and allows for 4 compactions to happen in parallel",
    "sha": "3d187d4ade3db6ecc8f72b07289f9cce16debc9f",
    "files": [
        {
            "sha": "bf4692097f65f8e64f8d2ab085e15e534d42548b",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 72,
            "deletions": 26,
            "changes": 98,
            "blob_url": "https://github.com/vercel/next.js/blob/3d187d4ade3db6ecc8f72b07289f9cce16debc9f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/3d187d4ade3db6ecc8f72b07289f9cce16debc9f/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=3d187d4ade3db6ecc8f72b07289f9cce16debc9f",
            "patch": "@@ -12,7 +12,7 @@ use byteorder::{WriteBytesExt, BE};\n use lzzzz::lz4::{self, ACC_LEVEL_DEFAULT};\n use parking_lot::Mutex;\n use rayon::{\n-    iter::{IndexedParallelIterator, IntoParallelIterator, ParallelIterator},\n+    iter::{Either, IndexedParallelIterator, IntoParallelIterator, ParallelIterator},\n     scope,\n };\n use smallvec::SmallVec;\n@@ -40,6 +40,10 @@ struct ThreadLocalState<K: StoreKey + Send, const FAMILIES: usize> {\n     new_blob_files: Vec<(u32, File)>,\n }\n \n+const COLLECTOR_SHARDS: usize = 4;\n+const COLLECTOR_SHARD_SHIFT: usize =\n+    u64::BITS as usize - COLLECTOR_SHARDS.trailing_zeros() as usize;\n+\n /// The result of a `WriteBatch::finish` operation.\n pub(crate) struct FinishResult {\n     pub(crate) sequence_number: u32,\n@@ -49,6 +53,14 @@ pub(crate) struct FinishResult {\n     pub(crate) new_blob_files: Vec<(u32, File)>,\n }\n \n+enum GlobalCollectorState<K: StoreKey + Send> {\n+    /// Initial state. Single collector. Once the collector is full, we switch to sharded mode.\n+    Unsharded(Collector<K>),\n+    /// Sharded mode.\n+    /// We use multiple collectors, and select one based on the first bits of the key hash.\n+    Sharded([Collector<K>; COLLECTOR_SHARDS]),\n+}\n+\n /// A write batch.\n pub struct WriteBatch<K: StoreKey + Send, const FAMILIES: usize> {\n     /// The database path\n@@ -58,7 +70,7 @@ pub struct WriteBatch<K: StoreKey + Send, const FAMILIES: usize> {\n     /// The thread local state.\n     thread_locals: ThreadLocal<UnsafeCell<ThreadLocalState<K, FAMILIES>>>,\n     /// Collectors in use. The thread local collectors flush into these when they are full.\n-    collectors: [Mutex<Collector<K>>; FAMILIES],\n+    collectors: [Mutex<GlobalCollectorState<K>>; FAMILIES],\n     /// The list of new SST files that have been created.\n     /// Tuple of (sequence number, file).\n     new_sst_files: Mutex<Vec<(u32, File)>>,\n@@ -78,7 +90,8 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n             path,\n             current_sequence_number: AtomicU32::new(current),\n             thread_locals: ThreadLocal::new(),\n-            collectors: [(); FAMILIES].map(|_| Mutex::new(Collector::new())),\n+            collectors: [(); FAMILIES]\n+                .map(|_| Mutex::new(GlobalCollectorState::Unsharded(Collector::new()))),\n             new_sst_files: Mutex::new(Vec::new()),\n             idle_collectors: Mutex::new(Vec::new()),\n             idle_thread_local_collectors: Mutex::new(Vec::new()),\n@@ -131,17 +144,39 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n     ) -> Result<()> {\n         let mut full_collectors = SmallVec::<[_; 2]>::new();\n         {\n-            let mut global_collector = self.collectors[usize_from_u32(family)].lock();\n+            let mut global_collector_state = self.collectors[usize_from_u32(family)].lock();\n             for entry in collector.drain() {\n-                global_collector.add_entry(entry);\n-                if global_collector.is_full() {\n-                    full_collectors.push(replace(\n-                        &mut *global_collector,\n-                        self.idle_collectors\n-                            .lock()\n-                            .pop()\n-                            .unwrap_or_else(|| Collector::new()),\n-                    ));\n+                match &mut *global_collector_state {\n+                    GlobalCollectorState::Unsharded(collector) => {\n+                        collector.add_entry(entry);\n+                        if collector.is_full() {\n+                            // When full, split the entries into shards.\n+                            let mut shards: [Collector<K>; 4] =\n+                                [(); COLLECTOR_SHARDS].map(|_| Collector::new());\n+                            for entry in collector.drain() {\n+                                let shard = (entry.key.hash >> COLLECTOR_SHARD_SHIFT) as usize;\n+                                shards[shard].add_entry(entry);\n+                            }\n+                            // There is a rare edge case where all entries are in the same shard,\n+                            // and the collector is full after the split.\n+                            for collector in shards.iter_mut() {\n+                                if collector.is_full() {\n+                                    full_collectors\n+                                        .push(replace(&mut *collector, self.get_new_collector()));\n+                                }\n+                            }\n+                            *global_collector_state = GlobalCollectorState::Sharded(shards);\n+                        }\n+                    }\n+                    GlobalCollectorState::Sharded(shards) => {\n+                        let shard = (entry.key.hash >> COLLECTOR_SHARD_SHIFT) as usize;\n+                        let collector = &mut shards[shard];\n+                        collector.add_entry(entry);\n+                        if collector.is_full() {\n+                            full_collectors\n+                                .push(replace(&mut *collector, self.get_new_collector()));\n+                        }\n+                    }\n                 }\n             }\n         }\n@@ -155,6 +190,13 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         Ok(())\n     }\n \n+    fn get_new_collector(&self) -> Collector<K> {\n+        self.idle_collectors\n+            .lock()\n+            .pop()\n+            .unwrap_or_else(|| Collector::new())\n+    }\n+\n     /// Puts a key-value pair into the write batch.\n     pub fn put(&self, family: u32, key: K, value: ValueBuffer<'_>) -> Result<()> {\n         let state = self.thread_local_state();\n@@ -217,23 +259,27 @@ impl<K: StoreKey + Send + Sync, const FAMILIES: usize> WriteBatch<K, FAMILIES> {\n         let mut new_sst_files = take(self.new_sst_files.get_mut());\n         let shared_new_sst_files = Mutex::new(&mut new_sst_files);\n \n-        let collectors = replace(\n-            &mut self.collectors,\n-            [(); FAMILIES].map(|_| {\n-                Mutex::new(\n-                    self.idle_collectors\n-                        .lock()\n-                        .pop()\n-                        .unwrap_or_else(|| Collector::new()),\n-                )\n-            }),\n-        );\n+        let new_collectors = [(); FAMILIES]\n+            .map(|_| Mutex::new(GlobalCollectorState::Unsharded(self.get_new_collector())));\n+        let collectors = replace(&mut self.collectors, new_collectors);\n         collectors\n             .into_par_iter()\n             .enumerate()\n-            .try_for_each(|(family, collector)| {\n+            .flat_map(|(family, state)| {\n+                let collector = state.into_inner();\n+                match collector {\n+                    GlobalCollectorState::Unsharded(collector) => {\n+                        Either::Left([(family, collector)].into_par_iter())\n+                    }\n+                    GlobalCollectorState::Sharded(shards) => Either::Right(\n+                        shards\n+                            .into_par_iter()\n+                            .map(move |collector| (family, collector)),\n+                    ),\n+                }\n+            })\n+            .try_for_each(|(family, mut collector)| {\n                 let family = family as u32;\n-                let mut collector = collector.into_inner();\n                 if !collector.is_empty() {\n                     let sst = self.create_sst_file(family, collector.sorted())?;\n                     collector.clear();"
        }
    ],
    "stats": {
        "total": 98,
        "additions": 72,
        "deletions": 26
    }
}