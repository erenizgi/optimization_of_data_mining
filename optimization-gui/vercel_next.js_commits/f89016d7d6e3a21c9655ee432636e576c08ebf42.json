{
    "author": "mischnic",
    "message": "Turbopack: improve eventual consistency (#86682)\n\nas always..",
    "sha": "f89016d7d6e3a21c9655ee432636e576c08ebf42",
    "files": [
        {
            "sha": "4d745611e3db235d95001d0341849ae03521cf62",
            "filename": "turbopack/crates/turbopack-core/src/module_graph/binding_usage_info.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/f89016d7d6e3a21c9655ee432636e576c08ebf42/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fbinding_usage_info.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f89016d7d6e3a21c9655ee432636e576c08ebf42/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fbinding_usage_info.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fbinding_usage_info.rs?ref=f89016d7d6e3a21c9655ee432636e576c08ebf42",
            "patch": "@@ -1,6 +1,6 @@\n use std::collections::hash_map::Entry;\n \n-use anyhow::{Result, bail};\n+use anyhow::{Context, Result, bail};\n use auto_hash_map::AutoSet;\n use rustc_hash::{FxHashMap, FxHashSet};\n use tracing::Instrument;\n@@ -140,7 +140,9 @@ pub async fn compute_binding_usage_info(\n                     // If the current edge is an unused import, skip it\n                     match &ref_data.binding_usage.import {\n                         ImportUsage::Exports(exports) => {\n-                            let source_used_exports = used_exports.get(&parent).unwrap();\n+                            let source_used_exports = used_exports\n+                                .get(&parent)\n+                                .context(\"parent module must have usage info\")?;\n                             if exports\n                                 .iter()\n                                 .all(|e| !source_used_exports.is_export_used(e))"
        },
        {
            "sha": "a90069b65b40661d09f42a99ab6ea7f9914e9e92",
            "filename": "turbopack/crates/turbopack-core/src/module_graph/module_batches.rs",
            "status": "modified",
            "additions": 21,
            "deletions": 13,
            "changes": 34,
            "blob_url": "https://github.com/vercel/next.js/blob/f89016d7d6e3a21c9655ee432636e576c08ebf42/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fmodule_batches.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f89016d7d6e3a21c9655ee432636e576c08ebf42/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fmodule_batches.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fmodule_graph%2Fmodule_batches.rs?ref=f89016d7d6e3a21c9655ee432636e576c08ebf42",
            "patch": "@@ -449,10 +449,13 @@ pub async fn compute_module_batches(\n                     |v| Either::Right(v.iter().copied()),\n                 )\n                 .map(|module| {\n-                    let idx = *pre_batches.entries.get(&module).unwrap();\n-                    (idx, 0)\n+                    let idx = *pre_batches\n+                        .entries\n+                        .get(&module)\n+                        .context(\"could not prebatch for module\")?;\n+                    Ok((idx, 0))\n                 })\n-                .collect::<Vec<_>>();\n+                .collect::<Result<Vec<_>>>()?;\n             stack.reverse();\n             let mut visited = FxHashSet::default();\n             while let Some((idx, mut pos)) = stack.pop() {\n@@ -501,7 +504,7 @@ pub async fn compute_module_batches(\n                     let idx = chunk_group_info\n                         .chunk_group_keys\n                         .get_index_of(&chunk_group_key)\n-                        .unwrap();\n+                        .context(\"could not find chunk group key for merged chunk group\")?;\n                     ordered_entries[idx] = Some(merged_modules);\n                 }\n             }\n@@ -536,7 +539,9 @@ pub async fn compute_module_batches(\n         let mut extracted_shared_items = 0;\n         // Extract shared modules into separate batches\n         for i in 0..parallel_module_to_pre_batch.len() {\n-            let (&module, batches) = parallel_module_to_pre_batch.get_index(i).unwrap();\n+            let (&module, batches) = parallel_module_to_pre_batch\n+                .get_index(i)\n+                .context(\"could not find parallel module to pre batch index\")?;\n             if batches.len() > 1 {\n                 // Create a new batch for the shared modules\n                 let batches_with_item_index = batches\n@@ -545,10 +550,10 @@ pub async fn compute_module_batches(\n                         let batch_items = &pre_batches.batches[idx].items;\n                         let item_idx = batch_items\n                             .get_index_of(&PreBatchItem::ParallelModule(module))\n-                            .unwrap();\n-                        (idx, item_idx)\n+                            .context(\"could not find batch item index for parallel module\")?;\n+                        Ok((idx, item_idx))\n                     })\n-                    .collect::<Vec<_>>();\n+                    .collect::<Result<Vec<_>>>()?;\n                 let mut selected_items = 1;\n                 fn get_item_at(\n                     pre_batches: &PreBatches,\n@@ -564,7 +569,10 @@ pub async fn compute_module_batches(\n                         &pre_batches,\n                         batches_with_item_index[0].0,\n                         batches_with_item_index[0].1 + selected_items,\n-                    ) && parallel_module_to_pre_batch.get(next_module).unwrap().len()\n+                    ) && parallel_module_to_pre_batch\n+                        .get(next_module)\n+                        .context(\"could not find pre batch for parallel module\")?\n+                        .len()\n                         == batches.len()\n                         && batches_with_item_index[1..]\n                             .iter()\n@@ -602,7 +610,7 @@ pub async fn compute_module_batches(\n                         if let PreBatchItem::ParallelModule(module) = item {\n                             parallel_module_to_pre_batch\n                                 .get_mut(module)\n-                                .unwrap()\n+                                .context(\"could not find pre batch for parallel module\")?\n                                 .clear();\n                         }\n                     }\n@@ -624,7 +632,7 @@ pub async fn compute_module_batches(\n                         if let PreBatchItem::ParallelModule(module) = item {\n                             parallel_module_to_pre_batch\n                                 .get_mut(module)\n-                                .unwrap()\n+                                .context(\"could not find pre batch for parallel module\")?\n                                 .clear();\n                         }\n                     }\n@@ -852,7 +860,7 @@ pub async fn compute_module_batches(\n                         let idx = pre_batches\n                             .single_module_entries\n                             .get_index_of(&module)\n-                            .unwrap();\n+                            .context(\"could not find single module entry index\")?;\n                         let idx = single_module_indices[idx];\n                         graph.add_edge(\n                             index,\n@@ -882,7 +890,7 @@ pub async fn compute_module_batches(\n                 let idx = pre_batches\n                     .single_module_entries\n                     .get_index_of(&module)\n-                    .unwrap();\n+                    .context(\"could not find single module entry index\")?;\n                 let idx = single_module_indices[idx];\n                 entries.insert(module, idx);\n             }"
        }
    ],
    "stats": {
        "total": 40,
        "additions": 25,
        "deletions": 15
    }
}