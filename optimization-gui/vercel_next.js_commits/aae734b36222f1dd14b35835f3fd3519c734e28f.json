{
    "author": "sokra",
    "message": "Turbopack: next build --analyze (#85197)\n\nThis implements a portion of the first iteration of a bundle analyzer for Turbopack in Next.js by writing data files to disk. A separate visualization and explorer tool will follow.\r\n\r\nThis data is written when builds are run with `next build --experimental-analyze`. An upcoming PR will implement a dedicated `next analyze` command that will write the data files without writing a complete build.\r\n\r\nThe data is derived from Turbopackâ€™s module and chunk graphs, and precise module sizes are reversed from the source map data of each chunk. Importantly, this requires that source maps are generated within Turbopack and the project is recomputed with them -- however, no source maps are written as part of the build artifacts if the user did not configure their Next.js config that way.\r\n\r\nThe binary format written in these files is subject to change, so the feature is experimental for the time being. Until it stabilizes, no guarantees will be provided between it and the visualizer tool.\r\n\r\nTest Plan: \r\n\r\nIn a test app:\r\n- do not configure `productionBrowserSourceMaps`\r\n- run `next build` and confirm **no files are written** to `.next/diagnostics/analyze`\r\n- run `next build --analyze` and confirm files **are** written to `.next/diagnostics/analyze`\r\n- Open the data with the yet-to-be-published visualization tool and confirm data is visible",
    "sha": "aae734b36222f1dd14b35835f3fd3519c734e28f",
    "files": [
        {
            "sha": "6c61e61dba977fa1ab1b26ab63d0a2b198e15a41",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 19,
            "deletions": 0,
            "changes": 19,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -4253,6 +4253,7 @@ name = \"next-api\"\n version = \"0.1.0\"\n dependencies = [\n  \"anyhow\",\n+ \"byteorder\",\n  \"either\",\n  \"futures\",\n  \"indexmap 2.9.0\",\n@@ -4274,6 +4275,7 @@ dependencies = [\n  \"turbo-tasks-malloc\",\n  \"turbo-unix-path\",\n  \"turbopack\",\n+ \"turbopack-analyze\",\n  \"turbopack-browser\",\n  \"turbopack-core\",\n  \"turbopack-ecmascript\",\n@@ -9469,6 +9471,23 @@ dependencies = [\n  \"turbopack-wasm\",\n ]\n \n+[[package]]\n+name = \"turbopack-analyze\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"anyhow\",\n+ \"rustc-hash 2.1.1\",\n+ \"serde\",\n+ \"serde_json\",\n+ \"tokio\",\n+ \"turbo-rcstr\",\n+ \"turbo-tasks\",\n+ \"turbo-tasks-backend\",\n+ \"turbo-tasks-fs\",\n+ \"turbo-tasks-testing\",\n+ \"turbopack-core\",\n+]\n+\n [[package]]\n name = \"turbopack-bench\"\n version = \"0.1.0\""
        },
        {
            "sha": "6b358486375dddf8389703856745d22eca2c28e5",
            "filename": "Cargo.toml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/Cargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/Cargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.toml?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -317,6 +317,7 @@ turbopack-cli-utils = { path = \"turbopack/crates/turbopack-cli-utils\" }\n turbopack-core = { path = \"turbopack/crates/turbopack-core\" }\n turbopack-create-test-app = { path = \"turbopack/crates/turbopack-create-test-app\" }\n turbopack-css = { path = \"turbopack/crates/turbopack-css\" }\n+turbopack-analyze = { path = \"turbopack/crates/turbopack-analyze\" }\n turbopack-browser = { path = \"turbopack/crates/turbopack-browser\" }\n turbopack-dev-server = { path = \"turbopack/crates/turbopack-dev-server\" }\n turbopack-ecmascript = { path = \"turbopack/crates/turbopack-ecmascript\" }\n@@ -377,6 +378,7 @@ async-compression = { version = \"0.3.13\", default-features = false, features = [\n ] }\n async-trait = \"0.1.64\"\n bitfield = \"0.18.0\"\n+byteorder = \"1.5.0\"\n bytes = \"1.1.0\"\n bytes-str = \"0.2.7\"\n chrono = \"0.4.23\""
        },
        {
            "sha": "b986a920619c1bfa4308e27a3fa4539a1dbf8452",
            "filename": "crates/napi/src/next_api/analyze.rs",
            "status": "added",
            "additions": 108,
            "deletions": 0,
            "changes": 108,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fanalyze.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fanalyze.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnapi%2Fsrc%2Fnext_api%2Fanalyze.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,108 @@\n+use std::{iter::once, sync::Arc};\n+\n+use anyhow::Result;\n+use next_api::{\n+    analyze::{AnalyzeDataOutputAsset, ModulesDataOutputAsset},\n+    project::ProjectContainer,\n+};\n+use turbo_tasks::{Effects, ReadRef, ResolvedVc, TryJoinIterExt, Vc};\n+use turbopack_core::{diagnostics::PlainDiagnostic, issue::PlainIssue, output::OutputAssets};\n+\n+use crate::next_api::utils::strongly_consistent_catch_collectables;\n+\n+#[turbo_tasks::value(serialization = \"none\")]\n+pub struct WriteAnalyzeResult {\n+    pub issues: Arc<Vec<ReadRef<PlainIssue>>>,\n+    pub diagnostics: Arc<Vec<ReadRef<PlainDiagnostic>>>,\n+    pub effects: Arc<Effects>,\n+}\n+\n+#[turbo_tasks::function(operation)]\n+pub async fn write_analyze_data_with_issues_operation(\n+    project: ResolvedVc<ProjectContainer>,\n+    app_dir_only: bool,\n+) -> Result<Vc<WriteAnalyzeResult>> {\n+    let analyze_data_op = write_analyze_data_with_issues_operation_inner(project, app_dir_only);\n+\n+    let (_analyze_data, issues, diagnostics, effects) =\n+        strongly_consistent_catch_collectables(analyze_data_op).await?;\n+\n+    Ok(WriteAnalyzeResult {\n+        issues,\n+        diagnostics,\n+        effects,\n+    }\n+    .cell())\n+}\n+\n+#[turbo_tasks::function(operation)]\n+async fn write_analyze_data_with_issues_operation_inner(\n+    project: ResolvedVc<ProjectContainer>,\n+    app_dir_only: bool,\n+) -> Result<()> {\n+    let analyze_data_op = get_analyze_data_operation(project, app_dir_only);\n+\n+    project\n+        .project()\n+        .emit_all_output_assets(analyze_data_op)\n+        .as_side_effect()\n+        .await?;\n+\n+    Ok(())\n+}\n+\n+#[turbo_tasks::function(operation)]\n+async fn get_analyze_data_operation(\n+    container: ResolvedVc<ProjectContainer>,\n+    app_dir_only: bool,\n+) -> Result<Vc<OutputAssets>> {\n+    let project = container.project();\n+    let project =\n+        project.with_next_config(project.next_config().with_production_browser_source_maps());\n+\n+    let analyze_output_root = project\n+        .node_root()\n+        .owned()\n+        .await?\n+        .join(\"diagnostics/analyze\")?;\n+    let whole_app_module_graphs = project.whole_app_module_graphs();\n+    let analyze_output_root = &analyze_output_root;\n+    let analyze_data = project\n+        .get_all_endpoint_groups(app_dir_only)\n+        .await?\n+        .iter()\n+        .map(|(key, endpoint_group)| async move {\n+            let output_assets = endpoint_group.output_assets();\n+            let analyze_data = AnalyzeDataOutputAsset::new(\n+                analyze_output_root\n+                    .join(&key.to_string())?\n+                    .join(\"analyze.data\")?,\n+                output_assets,\n+            )\n+            .to_resolved()\n+            .await?;\n+\n+            Ok(ResolvedVc::upcast(analyze_data))\n+        })\n+        .try_join()\n+        .await?;\n+\n+    whole_app_module_graphs.as_side_effect().await?;\n+\n+    let modules_data = ResolvedVc::upcast(\n+        ModulesDataOutputAsset::new(\n+            analyze_output_root.join(\"modules.data\")?,\n+            Vc::cell(vec![whole_app_module_graphs.await?.full]),\n+        )\n+        .to_resolved()\n+        .await?,\n+    );\n+\n+    Ok(Vc::cell(\n+        analyze_data\n+            .iter()\n+            .cloned()\n+            .chain(once(modules_data))\n+            .collect(),\n+    ))\n+}"
        },
        {
            "sha": "6dcf3d119c1c6e498be22332ff58c43ad0a8d392",
            "filename": "crates/napi/src/next_api/mod.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnapi%2Fsrc%2Fnext_api%2Fmod.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -1,3 +1,4 @@\n+pub mod analyze;\n pub mod endpoint;\n pub mod project;\n pub mod turbopack_ctx;"
        },
        {
            "sha": "1f785de2107d5888f5f871f1d3573ef887186f9a",
            "filename": "crates/napi/src/next_api/project.rs",
            "status": "modified",
            "additions": 87,
            "deletions": 1,
            "changes": 88,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fproject.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnapi%2Fsrc%2Fnext_api%2Fproject.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnapi%2Fsrc%2Fnext_api%2Fproject.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -64,6 +64,7 @@ use url::Url;\n \n use crate::{\n     next_api::{\n+        analyze::{WriteAnalyzeResult, write_analyze_data_with_issues_operation},\n         endpoint::ExternalEndpoint,\n         turbopack_ctx::{\n             NapiNextTurbopackCallbacks, NapiNextTurbopackCallbacksJsObject, NextTurboTasks,\n@@ -915,6 +916,13 @@ fn project_container_entrypoints_operation(\n     container.entrypoints()\n }\n \n+#[turbo_tasks::value(serialization = \"none\")]\n+struct OperationResult {\n+    issues: Arc<Vec<ReadRef<PlainIssue>>>,\n+    diagnostics: Arc<Vec<ReadRef<PlainDiagnostic>>>,\n+    effects: Arc<Effects>,\n+}\n+\n #[turbo_tasks::value(serialization = \"none\")]\n struct AllWrittenEntrypointsWithIssues {\n     entrypoints: Option<ReadRef<EntrypointsOperation>>,\n@@ -995,9 +1003,10 @@ pub async fn all_entrypoints_write_to_disk_operation(\n     project: ResolvedVc<ProjectContainer>,\n     app_dir_only: bool,\n ) -> Result<Vc<Entrypoints>> {\n+    let output_assets_operation = output_assets_operation(project, app_dir_only);\n     project\n         .project()\n-        .emit_all_output_assets(output_assets_operation(project, app_dir_only))\n+        .emit_all_output_assets(output_assets_operation)\n         .as_side_effect()\n         .await?;\n \n@@ -1037,6 +1046,49 @@ async fn output_assets_operation(\n }\n \n #[tracing::instrument(level = \"info\", name = \"get entrypoints\", skip_all)]\n+#[napi]\n+pub async fn project_entrypoints(\n+    #[napi(ts_arg_type = \"{ __napiType: \\\"Project\\\" }\")] project: External<ProjectInstance>,\n+) -> napi::Result<TurbopackResult<Option<NapiEntrypoints>>> {\n+    let container = project.container;\n+\n+    let (entrypoints, issues, diags) = project\n+        .turbopack_ctx\n+        .turbo_tasks()\n+        .run_once(async move {\n+            let entrypoints_with_issues_op = get_entrypoints_with_issues_operation(container);\n+\n+            // Read and compile the files\n+            let EntrypointsWithIssues {\n+                entrypoints,\n+                issues,\n+                diagnostics,\n+                effects: _,\n+            } = &*entrypoints_with_issues_op\n+                .read_strongly_consistent()\n+                .await?;\n+\n+            Ok((entrypoints.clone(), issues.clone(), diagnostics.clone()))\n+        })\n+        .await\n+        .map_err(|e| napi::Error::from_reason(PrettyPrintError(&e).to_string()))?;\n+\n+    let result = match entrypoints {\n+        Some(entrypoints) => Some(NapiEntrypoints::from_entrypoints_op(\n+            &entrypoints,\n+            &project.turbopack_ctx,\n+        )?),\n+        None => None,\n+    };\n+\n+    Ok(TurbopackResult {\n+        result,\n+        issues: issues.iter().map(|i| NapiIssue::from(&**i)).collect(),\n+        diagnostics: diags.iter().map(|d| NapiDiagnostic::from(d)).collect(),\n+    })\n+}\n+\n+#[tracing::instrument(level = \"info\", name = \"subscribe to entrypoints\", skip_all)]\n #[napi(ts_return_type = \"{ __napiType: \\\"RootTask\\\" }\")]\n pub fn project_entrypoints_subscribe(\n     #[napi(ts_arg_type = \"{ __napiType: \\\"Project\\\" }\")] project: External<ProjectInstance>,\n@@ -1718,3 +1770,37 @@ pub fn project_get_source_map_sync(\n         tokio::runtime::Handle::current().block_on(project_get_source_map(project, file_path))\n     })\n }\n+\n+#[napi]\n+pub async fn project_write_analyze_data(\n+    #[napi(ts_arg_type = \"{ __napiType: \\\"Project\\\" }\")] project: External<ProjectInstance>,\n+    app_dir_only: bool,\n+) -> napi::Result<TurbopackResult<()>> {\n+    let container = project.container;\n+    let (issues, diagnostics) = project\n+        .turbopack_ctx\n+        .turbo_tasks()\n+        .run_once(async move {\n+            let analyze_data_op = write_analyze_data_with_issues_operation(container, app_dir_only);\n+            let WriteAnalyzeResult {\n+                issues,\n+                diagnostics,\n+                effects,\n+            } = &*analyze_data_op.read_strongly_consistent().await?;\n+\n+            // Write the files to disk\n+            effects.apply().await?;\n+            Ok((issues.clone(), diagnostics.clone()))\n+        })\n+        .await\n+        .map_err(|e| napi::Error::from_reason(PrettyPrintError(&e).to_string()))?;\n+\n+    Ok(TurbopackResult {\n+        result: (),\n+        issues: issues.iter().map(|i| NapiIssue::from(&**i)).collect(),\n+        diagnostics: diagnostics\n+            .iter()\n+            .map(|d| NapiDiagnostic::from(d))\n+            .collect(),\n+    })\n+}"
        },
        {
            "sha": "6c6f878276c55495d33d71a5179073489030924e",
            "filename": "crates/next-api/Cargo.toml",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2FCargo.toml?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -14,6 +14,7 @@ workspace = true\n \n [dependencies]\n anyhow = { workspace = true, features = [\"backtrace\"] }\n+byteorder = { workspace = true }\n either = { workspace = true }\n futures = { workspace = true }\n indexmap = { workspace = true }\n@@ -31,6 +32,7 @@ turbo-tasks-env = { workspace = true }\n turbo-tasks-fs = { workspace = true }\n turbo-unix-path = { workspace = true }\n turbopack = { workspace = true }\n+turbopack-analyze = { workspace = true }\n turbopack-browser = { workspace = true }\n turbopack-core = { workspace = true }\n turbopack-ecmascript = { workspace = true }"
        },
        {
            "sha": "65dd992b6acb3de1b38b0b22fbea2a994dc74e16",
            "filename": "crates/next-api/src/analyze.rs",
            "status": "added",
            "additions": 610,
            "deletions": 0,
            "changes": 610,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fanalyze.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fanalyze.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fanalyze.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,610 @@\n+use std::io::Write;\n+\n+use anyhow::Result;\n+use byteorder::{BE, WriteBytesExt};\n+use rustc_hash::FxHashMap;\n+use serde::{Deserialize, Serialize};\n+use turbo_rcstr::RcStr;\n+use turbo_tasks::{\n+    FxIndexSet, NonLocalValue, ResolvedVc, TryFlatJoinIterExt, ValueToString, Vc,\n+    trace::TraceRawVcs,\n+};\n+use turbo_tasks_fs::{\n+    File, FileContent, FileSystemPath,\n+    rope::{Rope, RopeBuilder},\n+};\n+use turbopack_analyze::split_chunk::split_output_asset_into_parts;\n+use turbopack_core::{\n+    SOURCE_URL_PROTOCOL,\n+    asset::{Asset, AssetContent},\n+    chunk::ChunkingType,\n+    module::Module,\n+    output::{OutputAsset, OutputAssets},\n+    reference::all_assets_from_entries,\n+};\n+\n+use crate::route::{Endpoint, ModuleGraphs};\n+\n+#[derive(\n+    Default, Clone, Debug, Deserialize, Eq, NonLocalValue, PartialEq, Serialize, TraceRawVcs,\n+)]\n+pub struct EdgesData {\n+    pub offsets: Vec<u32>,\n+    pub data: Vec<u32>,\n+}\n+\n+impl EdgesData {\n+    fn from_iterator<'a>(iterable: impl IntoIterator<Item = &'a Vec<u32>> + Clone) -> Self {\n+        let mut current_offset = 0;\n+        let sum: usize = iterable.clone().into_iter().map(|v| v.len()).sum();\n+        let mut data = Vec::with_capacity(sum);\n+        let offsets = iterable\n+            .into_iter()\n+            .map(|edges| {\n+                current_offset += edges.len() as u32;\n+                data.extend(edges);\n+                current_offset\n+            })\n+            .collect();\n+        Self { offsets, data }\n+    }\n+\n+    fn write(&self, writer: &mut impl Write) -> Result<()> {\n+        writer.write_u32::<BE>(self.offsets.len() as u32)?;\n+        for &offset in &self.offsets {\n+            writer.write_u32::<BE>(offset)?;\n+        }\n+        for &data in &self.data {\n+            writer.write_u32::<BE>(data)?;\n+        }\n+        Ok(())\n+    }\n+}\n+\n+#[derive(Serialize)]\n+pub struct AnalyzeSource {\n+    pub parent_source_index: Option<u32>,\n+    /// Path. When there is a parent, this is concatenated to the parent's path.\n+    /// Folders end with a slash. Might have multiple path segments when folders contain only a\n+    /// single child.\n+    pub path: RcStr,\n+}\n+\n+#[derive(Serialize)]\n+pub struct AnalyzeModule {\n+    pub path: RcStr,\n+    pub depth: u32,\n+}\n+\n+#[derive(Serialize)]\n+pub struct AnalyzeChunkPart {\n+    pub source_index: u32,\n+    pub output_file_index: u32,\n+    pub size: u32,\n+}\n+\n+#[derive(Serialize)]\n+pub struct AnalyzeOutputFile {\n+    pub filename: RcStr,\n+}\n+\n+#[derive(Serialize)]\n+struct EdgesDataReference {\n+    pub offset: u32,\n+    pub length: u32,\n+}\n+\n+#[derive(Serialize)]\n+struct AnalyzeDataHeader {\n+    pub sources: Vec<AnalyzeSource>,\n+    pub chunk_parts: Vec<AnalyzeChunkPart>,\n+    pub output_files: Vec<AnalyzeOutputFile>,\n+    /// Edges from chunks to chunk parts\n+    pub output_file_chunk_parts: EdgesDataReference,\n+    /// Edges from sources to chunk parts\n+    pub source_chunk_parts: EdgesDataReference,\n+    /// Edges from sources to their children sources\n+    pub source_children: EdgesDataReference,\n+    /// Root level sources, walking their children will reach all sources\n+    pub source_roots: Vec<u32>,\n+}\n+\n+#[derive(Serialize)]\n+struct ModulesDataHeader {\n+    pub modules: Vec<AnalyzeModule>,\n+    /// Edges from modules to modules\n+    pub module_dependents: EdgesDataReference,\n+    /// Edges from modules to modules\n+    pub async_module_dependents: EdgesDataReference,\n+    /// Edges from modules to modules\n+    pub module_dependencies: EdgesDataReference,\n+    /// Edges from modules to modules\n+    pub async_module_dependencies: EdgesDataReference,\n+}\n+\n+struct AnalyzeOutputFileBuilder {\n+    output_file: AnalyzeOutputFile,\n+    chunk_part_indices: Vec<u32>,\n+}\n+\n+struct AnalyzeSourceBuilder {\n+    source: AnalyzeSource,\n+    child_source_indices: Vec<u32>,\n+    chunk_part_indices: Vec<u32>,\n+}\n+\n+struct AnalyzeModuleBuilder {\n+    module: AnalyzeModule,\n+    dependencies: FxIndexSet<u32>,\n+    async_dependencies: FxIndexSet<u32>,\n+    dependents: FxIndexSet<u32>,\n+    async_dependents: FxIndexSet<u32>,\n+}\n+\n+struct AnalyzeDataBuilder {\n+    sources: Vec<AnalyzeSourceBuilder>,\n+    source_index_map: FxHashMap<RcStr, u32>,\n+    chunk_parts: Vec<AnalyzeChunkPart>,\n+    output_files: Vec<AnalyzeOutputFileBuilder>,\n+}\n+\n+struct ModulesDataBuilder {\n+    modules: Vec<AnalyzeModuleBuilder>,\n+    module_index_map: FxHashMap<RcStr, u32>,\n+}\n+\n+struct EdgesDataSectionBuilder {\n+    data: Vec<u8>,\n+}\n+\n+impl EdgesDataSectionBuilder {\n+    fn new() -> Self {\n+        Self { data: vec![] }\n+    }\n+\n+    fn add_edges(&mut self, edges: &EdgesData) -> EdgesDataReference {\n+        let offset = self.data.len().try_into().unwrap();\n+        edges.write(&mut self.data).unwrap();\n+        let length = (self.data.len() - offset as usize).try_into().unwrap();\n+        EdgesDataReference { offset, length }\n+    }\n+}\n+\n+impl AnalyzeDataBuilder {\n+    fn new() -> Self {\n+        Self {\n+            sources: vec![],\n+            source_index_map: FxHashMap::default(),\n+            chunk_parts: vec![],\n+            output_files: vec![],\n+        }\n+    }\n+\n+    fn ensure_source(&mut self, path: &str) -> (&mut AnalyzeSourceBuilder, u32) {\n+        if let Some(&index) = self.source_index_map.get(path) {\n+            return (&mut self.sources[index as usize], index);\n+        }\n+        let index = self.sources.len() as u32;\n+        let path = RcStr::from(path);\n+        self.source_index_map.insert(path.clone(), index);\n+        self.sources.push(AnalyzeSourceBuilder {\n+            source: AnalyzeSource {\n+                parent_source_index: None,\n+                path,\n+            },\n+            child_source_indices: vec![],\n+            chunk_part_indices: vec![],\n+        });\n+        (&mut self.sources[index as usize], index)\n+    }\n+\n+    fn add_chunk_part(&mut self, chunk_part: AnalyzeChunkPart) -> u32 {\n+        let i = self.chunk_parts.len() as u32;\n+        self.chunk_parts.push(chunk_part);\n+        i\n+    }\n+\n+    fn add_output_file(&mut self, output_file: AnalyzeOutputFile) -> u32 {\n+        let i = self.output_files.len() as u32;\n+        self.output_files.push(AnalyzeOutputFileBuilder {\n+            output_file,\n+            chunk_part_indices: vec![],\n+        });\n+        i\n+    }\n+\n+    fn add_chunk_part_to_output_file(&mut self, output_file_index: u32, chunk_part_index: u32) {\n+        self.output_files[output_file_index as usize]\n+            .chunk_part_indices\n+            .push(chunk_part_index);\n+    }\n+\n+    fn add_chunk_part_to_source(&mut self, source_index: u32, chunk_part_index: u32) {\n+        self.sources[source_index as usize]\n+            .chunk_part_indices\n+            .push(chunk_part_index);\n+    }\n+\n+    fn build(self) -> Rope {\n+        let source_roots = self\n+            .sources\n+            .iter()\n+            .enumerate()\n+            .filter_map(|(i, s)| {\n+                if s.source.parent_source_index.is_none() {\n+                    Some(i as u32)\n+                } else {\n+                    None\n+                }\n+            })\n+            .collect();\n+\n+        let source_children =\n+            EdgesData::from_iterator(self.sources.iter().map(|s| &s.child_source_indices));\n+\n+        let source_chunk_parts =\n+            EdgesData::from_iterator(self.sources.iter().map(|s| &s.chunk_part_indices));\n+\n+        let output_file_chunk_parts =\n+            EdgesData::from_iterator(self.output_files.iter().map(|of| &of.chunk_part_indices));\n+\n+        let mut binary_section = EdgesDataSectionBuilder::new();\n+\n+        let header = AnalyzeDataHeader {\n+            sources: self.sources.into_iter().map(|s| s.source).collect(),\n+            chunk_parts: self.chunk_parts,\n+            output_files: self\n+                .output_files\n+                .into_iter()\n+                .map(|of| of.output_file)\n+                .collect(),\n+            output_file_chunk_parts: binary_section.add_edges(&output_file_chunk_parts),\n+            source_chunk_parts: binary_section.add_edges(&source_chunk_parts),\n+            source_children: binary_section.add_edges(&source_children),\n+            source_roots,\n+        };\n+\n+        let header_json = serde_json::to_vec(&header).unwrap();\n+\n+        let mut rope = RopeBuilder::default();\n+        rope.push_bytes(&(header_json.len() as u32).to_be_bytes());\n+        rope.reserve_bytes(header_json.len() + binary_section.data.len());\n+        rope.push_bytes(&header_json);\n+        rope.push_bytes(&binary_section.data);\n+        rope.build()\n+    }\n+}\n+\n+impl ModulesDataBuilder {\n+    fn new() -> Self {\n+        Self {\n+            modules: vec![],\n+            module_index_map: FxHashMap::default(),\n+        }\n+    }\n+\n+    fn ensure_module(&mut self, path: &str) -> (&mut AnalyzeModuleBuilder, u32) {\n+        if let Some(&index) = self.module_index_map.get(path) {\n+            return (&mut self.modules[index as usize], index);\n+        }\n+        let index = self.modules.len() as u32;\n+        let path = RcStr::from(path);\n+        self.module_index_map.insert(path.clone(), index);\n+        self.modules.push(AnalyzeModuleBuilder {\n+            module: AnalyzeModule {\n+                path,\n+                depth: u32::MAX,\n+            },\n+            dependencies: FxIndexSet::default(),\n+            async_dependencies: FxIndexSet::default(),\n+            dependents: FxIndexSet::default(),\n+            async_dependents: FxIndexSet::default(),\n+        });\n+        (&mut self.modules[index as usize], index)\n+    }\n+\n+    fn build(self) -> Rope {\n+        let module_dependencies_vecs: Vec<Vec<u32>> = self\n+            .modules\n+            .iter()\n+            .map(|s| s.dependencies.iter().copied().collect())\n+            .collect();\n+        let async_module_dependencies_vecs: Vec<Vec<u32>> = self\n+            .modules\n+            .iter()\n+            .map(|s| s.async_dependencies.iter().copied().collect())\n+            .collect();\n+        let module_dependents_vecs: Vec<Vec<u32>> = self\n+            .modules\n+            .iter()\n+            .map(|s| s.dependents.iter().copied().collect())\n+            .collect();\n+        let async_module_dependents_vecs: Vec<Vec<u32>> = self\n+            .modules\n+            .iter()\n+            .map(|s| s.async_dependents.iter().copied().collect())\n+            .collect();\n+\n+        let module_dependencies = EdgesData::from_iterator(&module_dependencies_vecs);\n+        let async_module_dependencies = EdgesData::from_iterator(&async_module_dependencies_vecs);\n+        let module_dependents = EdgesData::from_iterator(&module_dependents_vecs);\n+        let async_module_dependents = EdgesData::from_iterator(&async_module_dependents_vecs);\n+\n+        let mut binary_section = EdgesDataSectionBuilder::new();\n+\n+        let header = ModulesDataHeader {\n+            modules: self.modules.into_iter().map(|s| s.module).collect(),\n+            module_dependents: binary_section.add_edges(&module_dependents),\n+            async_module_dependents: binary_section.add_edges(&async_module_dependents),\n+            module_dependencies: binary_section.add_edges(&module_dependencies),\n+            async_module_dependencies: binary_section.add_edges(&async_module_dependencies),\n+        };\n+\n+        let header_json = serde_json::to_vec(&header).unwrap();\n+\n+        let mut rope = RopeBuilder::default();\n+        rope.push_bytes(&(header_json.len() as u32).to_be_bytes());\n+        rope.reserve_bytes(header_json.len() + binary_section.data.len());\n+        rope.push_bytes(&header_json);\n+        rope.push_bytes(&binary_section.data);\n+        rope.build()\n+    }\n+}\n+\n+#[turbo_tasks::function]\n+pub async fn analyze_output_assets(output_assets: Vc<OutputAssets>) -> Result<Vc<FileContent>> {\n+    let output_assets = all_assets_from_entries(output_assets);\n+\n+    let mut builder = AnalyzeDataBuilder::new();\n+\n+    let prefix = format!(\"{SOURCE_URL_PROTOCOL}///\");\n+\n+    // Process the output assets and extract chunk parts.\n+    // Also creates sources for the chunk parts.\n+    for &asset in output_assets.await? {\n+        let filename = asset.path().to_string().owned().await?;\n+        if filename.ends_with(\".map\") || filename.ends_with(\".nft.json\") {\n+            // Skip source maps.\n+            continue;\n+        }\n+        let output_file_index = builder.add_output_file(AnalyzeOutputFile { filename });\n+        let chunk_parts = split_output_asset_into_parts(*asset).await?;\n+        for chunk_part in chunk_parts {\n+            let source_index = builder\n+                .ensure_source(chunk_part.source.trim_start_matches(&prefix))\n+                .1;\n+            let chunk_part_index = builder.add_chunk_part(AnalyzeChunkPart {\n+                source_index,\n+                output_file_index,\n+                size: chunk_part.real_size + chunk_part.unaccounted_size,\n+            });\n+            builder.add_chunk_part_to_output_file(output_file_index, chunk_part_index);\n+            builder.add_chunk_part_to_source(source_index, chunk_part_index);\n+        }\n+    }\n+\n+    // Build a directory structure for the sources.\n+    let mut i: u32 = 0;\n+    while i < builder.sources.len().try_into().unwrap() {\n+        let source = &builder.sources[i as usize];\n+        let path = source.source.path.as_str();\n+        if !path.is_empty() {\n+            let (parent_path, path) = if let Some(pos) = path.trim_end_matches('/').rfind('/') {\n+                (&path[..pos + 1], &path[pos + 1..])\n+            } else {\n+                (\"\", path)\n+            };\n+            let parent_path = parent_path.to_string();\n+            let path = path.into();\n+            let (parent_source, parent_index) = builder.ensure_source(&parent_path);\n+            parent_source.child_source_indices.push(i);\n+            builder.sources[i as usize].source.parent_source_index = Some(parent_index);\n+            builder.sources[i as usize].source.path = path;\n+        }\n+        i += 1;\n+    }\n+\n+    let rope = builder.build();\n+    Ok(FileContent::Content(File::from(rope)).cell())\n+}\n+\n+#[turbo_tasks::function]\n+pub async fn analyze_module_graphs(module_graphs: Vc<ModuleGraphs>) -> Result<Vc<FileContent>> {\n+    let mut builder = ModulesDataBuilder::new();\n+\n+    let mut all_edges = FxIndexSet::default();\n+    let mut all_async_edges = FxIndexSet::default();\n+    for &module_graph in module_graphs.await? {\n+        let module_graph = module_graph.read_graphs().await?;\n+        module_graph.traverse_all_edges_unordered(|(parent_node, reference), node| {\n+            match reference.chunking_type {\n+                ChunkingType::Async => {\n+                    all_async_edges.insert((parent_node.module, node.module));\n+                }\n+                _ => {\n+                    all_edges.insert((parent_node.module, node.module));\n+                }\n+            }\n+            Ok(())\n+        })?;\n+    }\n+\n+    type ModulePair = (ResolvedVc<Box<dyn Module>>, ResolvedVc<Box<dyn Module>>);\n+    async fn mapper((from, to): ModulePair) -> Result<Option<(RcStr, RcStr)>> {\n+        if from == to {\n+            return Ok(None);\n+        }\n+        let from_path = from.ident().path().to_string().owned().await?;\n+        let to_path = to.ident().path().to_string().owned().await?;\n+        Ok(Some((from_path, to_path)))\n+    }\n+\n+    let all_edges = all_edges\n+        .iter()\n+        .copied()\n+        .map(mapper)\n+        .try_flat_join()\n+        .await?;\n+    let all_async_edges = all_async_edges\n+        .iter()\n+        .copied()\n+        .map(mapper)\n+        .try_flat_join()\n+        .await?;\n+    for (from_path, to_path) in all_edges {\n+        let from_index = builder.ensure_module(&from_path).1;\n+        let to_index = builder.ensure_module(&to_path).1;\n+        if from_index == to_index {\n+            continue;\n+        }\n+        builder.modules[from_index as usize]\n+            .dependencies\n+            .insert(to_index);\n+        builder.modules[to_index as usize]\n+            .dependents\n+            .insert(from_index);\n+    }\n+    for (from_path, to_path) in all_async_edges {\n+        let from_index = builder.ensure_module(&from_path).1;\n+        let to_index = builder.ensure_module(&to_path).1;\n+        if from_index == to_index {\n+            continue;\n+        }\n+        builder.modules[from_index as usize]\n+            .async_dependencies\n+            .insert(to_index);\n+        builder.modules[to_index as usize]\n+            .async_dependents\n+            .insert(from_index);\n+    }\n+\n+    // Compute depth using BFS from modules without incoming edges\n+    let mut queue = std::collections::VecDeque::new();\n+\n+    // Find modules without incoming edges and set their depth to 0\n+    for (index, module) in builder.modules.iter_mut().enumerate() {\n+        if module.dependents.is_empty() && module.async_dependents.is_empty() {\n+            module.module.depth = 0;\n+            queue.push_back(index as u32);\n+        }\n+    }\n+\n+    // Process queue and propagate depth\n+    while let Some(current_index) = queue.pop_front() {\n+        let current_depth = builder.modules[current_index as usize].module.depth;\n+\n+        // Collect dependencies to avoid borrow conflicts\n+        let dependencies: Vec<u32> = builder.modules[current_index as usize]\n+            .dependencies\n+            .iter()\n+            .copied()\n+            .collect();\n+\n+        // Update dependencies\n+        let new_depth = current_depth + 1;\n+        for &dep_index in &dependencies {\n+            let dep_module = &mut builder.modules[dep_index as usize];\n+            if new_depth < dep_module.module.depth {\n+                dep_module.module.depth = new_depth;\n+                queue.push_back(dep_index);\n+            }\n+        }\n+\n+        // Collect async dependencies to avoid borrow conflicts\n+        let async_dependencies: Vec<u32> = builder.modules[current_index as usize]\n+            .async_dependencies\n+            .iter()\n+            .copied()\n+            .collect();\n+\n+        // Update async dependencies\n+        let new_depth = current_depth + 1000;\n+        for &dep_index in &async_dependencies {\n+            let dep_module = &mut builder.modules[dep_index as usize];\n+            if new_depth < dep_module.module.depth {\n+                dep_module.module.depth = new_depth;\n+                queue.push_back(dep_index);\n+            }\n+        }\n+    }\n+\n+    let rope = builder.build();\n+    Ok(FileContent::Content(File::from(rope)).cell())\n+}\n+\n+#[turbo_tasks::function]\n+pub async fn analyze_endpoint(endpoint: Vc<Box<dyn Endpoint>>) -> Result<Vc<FileContent>> {\n+    Ok(analyze_output_assets(\n+        *endpoint.output().await?.output_assets,\n+    ))\n+}\n+\n+#[turbo_tasks::value]\n+pub struct AnalyzeDataOutputAsset {\n+    pub path: FileSystemPath,\n+    pub output_assets: ResolvedVc<OutputAssets>,\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl AnalyzeDataOutputAsset {\n+    #[turbo_tasks::function]\n+    pub async fn new(path: FileSystemPath, output_assets: Vc<OutputAssets>) -> Result<Vc<Self>> {\n+        Ok(Self {\n+            path,\n+            output_assets: output_assets.to_resolved().await?,\n+        }\n+        .cell())\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl Asset for AnalyzeDataOutputAsset {\n+    #[turbo_tasks::function]\n+    fn content(&self) -> Vc<AssetContent> {\n+        let file_content = analyze_output_assets(*self.output_assets);\n+        AssetContent::file(file_content)\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl OutputAsset for AnalyzeDataOutputAsset {\n+    #[turbo_tasks::function]\n+    fn path(&self) -> Vc<FileSystemPath> {\n+        self.path.clone().cell()\n+    }\n+}\n+\n+#[turbo_tasks::value]\n+pub struct ModulesDataOutputAsset {\n+    pub path: FileSystemPath,\n+    pub module_graphs: ResolvedVc<ModuleGraphs>,\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl ModulesDataOutputAsset {\n+    #[turbo_tasks::function]\n+    pub async fn new(path: FileSystemPath, module_graphs: Vc<ModuleGraphs>) -> Result<Vc<Self>> {\n+        Ok(Self {\n+            path,\n+            module_graphs: module_graphs.to_resolved().await?,\n+        }\n+        .cell())\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl Asset for ModulesDataOutputAsset {\n+    #[turbo_tasks::function]\n+    fn content(&self) -> Vc<AssetContent> {\n+        let file_content = analyze_module_graphs(*self.module_graphs);\n+        AssetContent::file(file_content)\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl OutputAsset for ModulesDataOutputAsset {\n+    #[turbo_tasks::function]\n+    fn path(&self) -> Vc<FileSystemPath> {\n+        self.path.clone().cell()\n+    }\n+}"
        },
        {
            "sha": "28b5fec7bbddb09b6061d363a36194d427631aa9",
            "filename": "crates/next-api/src/app.rs",
            "status": "modified",
            "additions": 22,
            "deletions": 4,
            "changes": 26,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fapp.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fapp.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fapp.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -81,8 +81,10 @@ use crate::{\n         all_paths_in_root, all_server_paths, get_asset_paths_from_root, get_js_paths_from_root,\n         get_wasm_paths_from_root, paths_to_bindings, wasm_paths_to_bindings,\n     },\n-    project::{ModuleGraphs, Project},\n-    route::{AppPageRoute, Endpoint, EndpointOutput, EndpointOutputPaths, Route, Routes},\n+    project::{BaseAndFullModuleGraph, Project},\n+    route::{\n+        AppPageRoute, Endpoint, EndpointOutput, EndpointOutputPaths, ModuleGraphs, Route, Routes,\n+    },\n     server_actions::{build_server_actions_loader, create_server_actions_manifest},\n     webpack_stats::generate_webpack_stats,\n };\n@@ -850,7 +852,7 @@ impl AppProject {\n         rsc_entry: ResolvedVc<Box<dyn Module>>,\n         client_shared_entries: Vc<EvaluatableAssets>,\n         has_layout_segments: bool,\n-    ) -> Result<Vc<ModuleGraphs>> {\n+    ) -> Result<Vc<BaseAndFullModuleGraph>> {\n         if *self.project.per_page_module_graph().await? {\n             let should_trace = self.project.next_mode().await?.is_production();\n             let client_shared_entries = client_shared_entries\n@@ -946,7 +948,7 @@ impl AppProject {\n                 graphs.push(additional_module_graph);\n \n                 let full = ModuleGraph::from_graphs(graphs);\n-                Ok(ModuleGraphs {\n+                Ok(BaseAndFullModuleGraph {\n                     base: base.to_resolved().await?,\n                     full: full.to_resolved().await?,\n                 }\n@@ -2102,6 +2104,22 @@ impl Endpoint for AppEndpoint {\n             server_actions_loader,\n         ])]))\n     }\n+\n+    #[turbo_tasks::function]\n+    async fn module_graphs(self: Vc<Self>) -> Result<Vc<ModuleGraphs>> {\n+        let this = self.await?;\n+        let app_entry = self.app_endpoint_entry().await?;\n+        let module_graphs = this\n+            .app_project\n+            .app_module_graphs(\n+                self,\n+                *app_entry.rsc_entry,\n+                this.app_project.client_runtime_entries(),\n+                matches!(this.ty, AppEndpointType::Page { .. }),\n+            )\n+            .await?;\n+        Ok(Vc::cell(vec![module_graphs.full]))\n+    }\n }\n \n #[turbo_tasks::value]"
        },
        {
            "sha": "cc220d178458e8aaa771005721a9c9bdb818e931",
            "filename": "crates/next-api/src/empty.rs",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fempty.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fempty.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fempty.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -2,7 +2,7 @@ use anyhow::{Result, bail};\n use turbo_tasks::{Completion, Vc};\n use turbopack_core::module_graph::GraphEntries;\n \n-use crate::route::{Endpoint, EndpointOutput};\n+use crate::route::{Endpoint, EndpointOutput, ModuleGraphs};\n \n #[turbo_tasks::value]\n pub struct EmptyEndpoint;\n@@ -36,4 +36,9 @@ impl Endpoint for EmptyEndpoint {\n     fn entries(self: Vc<Self>) -> Vc<GraphEntries> {\n         GraphEntries::empty()\n     }\n+\n+    #[turbo_tasks::function]\n+    fn module_graphs(self: Vc<Self>) -> Vc<ModuleGraphs> {\n+        Vc::cell(vec![])\n+    }\n }"
        },
        {
            "sha": "a283a61150ea405116ca03554f692bd5593bd54b",
            "filename": "crates/next-api/src/instrumentation.rs",
            "status": "modified",
            "additions": 19,
            "deletions": 23,
            "changes": 42,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Finstrumentation.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Finstrumentation.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Finstrumentation.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -32,7 +32,7 @@ use crate::{\n         all_server_paths, get_js_paths_from_root, get_wasm_paths_from_root, wasm_paths_to_bindings,\n     },\n     project::Project,\n-    route::{Endpoint, EndpointOutput, EndpointOutputPaths},\n+    route::{Endpoint, EndpointOutput, EndpointOutputPaths, ModuleGraphs},\n };\n \n #[turbo_tasks::value]\n@@ -69,7 +69,7 @@ impl InstrumentationEndpoint {\n     }\n \n     #[turbo_tasks::function]\n-    async fn core_modules(&self) -> Result<Vc<InstrumentationCoreModules>> {\n+    async fn entry_module(&self) -> Result<Vc<Box<dyn Module>>> {\n         let userland_module = self\n             .asset_context\n             .process(\n@@ -80,6 +80,10 @@ impl InstrumentationEndpoint {\n             .to_resolved()\n             .await?;\n \n+        if !self.is_edge {\n+            return Ok(*userland_module);\n+        }\n+\n         let edge_entry_module = wrap_edge_entry(\n             *self.asset_context,\n             self.project.project_path().owned().await?,\n@@ -89,17 +93,13 @@ impl InstrumentationEndpoint {\n         .to_resolved()\n         .await?;\n \n-        Ok(InstrumentationCoreModules {\n-            userland_module,\n-            edge_entry_module,\n-        }\n-        .cell())\n+        Ok(*edge_entry_module)\n     }\n \n     #[turbo_tasks::function]\n     async fn edge_chunk_group(self: Vc<Self>) -> Result<Vc<OutputAssetsWithReferenced>> {\n         let this = self.await?;\n-        let module = self.core_modules().await?.edge_entry_module;\n+        let module = self.entry_module().to_resolved().await?;\n \n         let module_graph = this.project.module_graph(*module);\n \n@@ -118,7 +118,7 @@ impl InstrumentationEndpoint {\n \n         let chunking_context = this.project.server_chunking_context(false);\n \n-        let userland_module = self.core_modules().await?.userland_module;\n+        let userland_module = self.entry_module().to_resolved().await?;\n         let module_graph = this.project.module_graph(*userland_module);\n \n         let Some(module) = ResolvedVc::try_downcast(userland_module) else {\n@@ -200,12 +200,6 @@ impl InstrumentationEndpoint {\n     }\n }\n \n-#[turbo_tasks::value]\n-struct InstrumentationCoreModules {\n-    pub userland_module: ResolvedVc<Box<dyn Module>>,\n-    pub edge_entry_module: ResolvedVc<Box<dyn Module>>,\n-}\n-\n #[turbo_tasks::value_impl]\n impl Endpoint for InstrumentationEndpoint {\n     #[turbo_tasks::function]\n@@ -249,13 +243,15 @@ impl Endpoint for InstrumentationEndpoint {\n \n     #[turbo_tasks::function]\n     async fn entries(self: Vc<Self>) -> Result<Vc<GraphEntries>> {\n-        let core_modules = self.core_modules().await?;\n-        Ok(Vc::cell(vec![ChunkGroupEntry::Entry(\n-            if self.await?.is_edge {\n-                vec![core_modules.edge_entry_module]\n-            } else {\n-                vec![core_modules.userland_module]\n-            },\n-        )]))\n+        let entry_module = self.entry_module().to_resolved().await?;\n+        Ok(Vc::cell(vec![ChunkGroupEntry::Entry(vec![entry_module])]))\n+    }\n+\n+    #[turbo_tasks::function]\n+    async fn module_graphs(self: Vc<Self>) -> Result<Vc<ModuleGraphs>> {\n+        let this = self.await?;\n+        let module = self.entry_module();\n+        let module_graph = this.project.module_graph(module).to_resolved().await?;\n+        Ok(Vc::cell(vec![module_graph]))\n     }\n }"
        },
        {
            "sha": "9c8d2b4dc72494f39ec273650c93f6ccba0eeac7",
            "filename": "crates/next-api/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Flib.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -3,6 +3,7 @@\n #![feature(arbitrary_self_types_pointers)]\n #![feature(impl_trait_in_assoc_type)]\n \n+pub mod analyze;\n mod app;\n mod client_references;\n mod dynamic_imports;"
        },
        {
            "sha": "f90f093b7c199f60c6d7980cec9e9ee9f70ac670",
            "filename": "crates/next-api/src/middleware.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fmiddleware.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fmiddleware.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fmiddleware.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -38,7 +38,7 @@ use crate::{\n         get_wasm_paths_from_root, paths_to_bindings, wasm_paths_to_bindings,\n     },\n     project::Project,\n-    route::{Endpoint, EndpointOutput, EndpointOutputPaths},\n+    route::{Endpoint, EndpointOutput, EndpointOutputPaths, ModuleGraphs},\n };\n \n #[turbo_tasks::value]\n@@ -386,4 +386,15 @@ impl Endpoint for MiddlewareEndpoint {\n             self.entry_module().to_resolved().await?,\n         ])]))\n     }\n+\n+    #[turbo_tasks::function]\n+    async fn module_graphs(self: Vc<Self>) -> Result<Vc<ModuleGraphs>> {\n+        let this = self.await?;\n+        let module_graph = this\n+            .project\n+            .module_graph(self.entry_module())\n+            .to_resolved()\n+            .await?;\n+        Ok(Vc::cell(vec![module_graph]))\n+    }\n }"
        },
        {
            "sha": "7307d313e37ffa9d6b38bb60dcec0625f8770a5a",
            "filename": "crates/next-api/src/pages.rs",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fpages.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fpages.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fpages.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -78,7 +78,7 @@ use crate::{\n         get_wasm_paths_from_root, paths_to_bindings, wasm_paths_to_bindings,\n     },\n     project::Project,\n-    route::{Endpoint, EndpointOutput, EndpointOutputPaths, Route, Routes},\n+    route::{Endpoint, EndpointOutput, EndpointOutputPaths, ModuleGraphs, Route, Routes},\n     webpack_stats::generate_webpack_stats,\n };\n \n@@ -1728,6 +1728,13 @@ impl Endpoint for PageEndpoint {\n \n         Ok(Vc::cell(modules))\n     }\n+\n+    #[turbo_tasks::function]\n+    async fn module_graphs(self: Vc<Self>) -> Result<Vc<ModuleGraphs>> {\n+        let client_module_graph = self.client_module_graph().to_resolved().await?;\n+        let ssr_module_graph = self.ssr_module_graph().to_resolved().await?;\n+        Ok(Vc::cell(vec![client_module_graph, ssr_module_graph]))\n+    }\n }\n \n #[turbo_tasks::value]"
        },
        {
            "sha": "e3b04f77b53532bb444dd896901cb9f4f3ab372d",
            "filename": "crates/next-api/src/project.rs",
            "status": "modified",
            "additions": 92,
            "deletions": 40,
            "changes": 132,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fproject.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Fproject.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Fproject.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -84,7 +84,7 @@ use crate::{\n     instrumentation::InstrumentationEndpoint,\n     middleware::MiddlewareEndpoint,\n     pages::PagesProject,\n-    route::{AppPageRoute, Endpoint, Endpoints, Route},\n+    route::{Endpoint, EndpointGroup, EndpointGroupKey, EndpointGroups, Endpoints, Route},\n     versioned_content_map::VersionedContentMap,\n };\n \n@@ -534,6 +534,7 @@ impl ProjectContainer {\n     }\n }\n \n+#[derive(Clone)]\n #[turbo_tasks::value]\n pub struct Project {\n     /// An absolute root path (Windows or Unix path) from which all files must be nested under.\n@@ -793,7 +794,7 @@ impl Project {\n     }\n \n     #[turbo_tasks::function]\n-    pub(super) fn next_config(&self) -> Vc<NextConfig> {\n+    pub fn next_config(&self) -> Vc<NextConfig> {\n         *self.next_config\n     }\n \n@@ -866,74 +867,114 @@ impl Project {\n     }\n \n     #[turbo_tasks::function]\n-    pub async fn get_all_endpoints(self: Vc<Self>, app_dir_only: bool) -> Result<Vc<Endpoints>> {\n-        let mut endpoints = Vec::new();\n+    pub async fn get_all_endpoint_groups(\n+        self: Vc<Self>,\n+        app_dir_only: bool,\n+    ) -> Result<Vc<EndpointGroups>> {\n+        let mut endpoint_groups = Vec::new();\n \n         let entrypoints = self.entrypoints().await?;\n-        let mut is_pages_entries_added = false;\n+        let mut add_pages_entries = false;\n \n         if let Some(middleware) = &entrypoints.middleware {\n-            endpoints.push(middleware.endpoint);\n+            endpoint_groups.push((\n+                EndpointGroupKey::Middleware,\n+                EndpointGroup::from(middleware.endpoint),\n+            ));\n         }\n \n         if let Some(instrumentation) = &entrypoints.instrumentation {\n-            endpoints.push(instrumentation.node_js);\n-            endpoints.push(instrumentation.edge);\n+            endpoint_groups.push((\n+                EndpointGroupKey::Instrumentation,\n+                EndpointGroup::from(instrumentation.node_js),\n+            ));\n+            endpoint_groups.push((\n+                EndpointGroupKey::InstrumentationEdge,\n+                EndpointGroup::from(instrumentation.edge),\n+            ));\n         }\n \n-        for (_, route) in entrypoints.routes.iter() {\n+        for (key, route) in entrypoints.routes.iter() {\n             match route {\n                 Route::Page {\n                     html_endpoint,\n                     data_endpoint,\n                 } => {\n                     if !app_dir_only {\n-                        endpoints.push(*html_endpoint);\n-                        if !is_pages_entries_added {\n-                            endpoints.push(entrypoints.pages_error_endpoint);\n-                            endpoints.push(entrypoints.pages_app_endpoint);\n-                            endpoints.push(entrypoints.pages_document_endpoint);\n-                            is_pages_entries_added = true;\n-                        }\n-                        // This only exists in development mode for HMR\n-                        if let Some(data_endpoint) = data_endpoint {\n-                            endpoints.push(*data_endpoint);\n-                        }\n+                        endpoint_groups.push((\n+                            EndpointGroupKey::Route(key.clone()),\n+                            EndpointGroup {\n+                                primary: vec![*html_endpoint],\n+                                // This only exists in development mode for HMR\n+                                additional: data_endpoint.iter().copied().collect(),\n+                            },\n+                        ));\n+                        add_pages_entries = true;\n                     }\n                 }\n                 Route::PageApi { endpoint } => {\n                     if !app_dir_only {\n-                        endpoints.push(*endpoint);\n-                        if !is_pages_entries_added {\n-                            endpoints.push(entrypoints.pages_error_endpoint);\n-                            endpoints.push(entrypoints.pages_app_endpoint);\n-                            endpoints.push(entrypoints.pages_document_endpoint);\n-                            is_pages_entries_added = true;\n-                        }\n+                        endpoint_groups.push((\n+                            EndpointGroupKey::Route(key.clone()),\n+                            EndpointGroup::from(*endpoint),\n+                        ));\n+                        add_pages_entries = true;\n                     }\n                 }\n                 Route::AppPage(page_routes) => {\n-                    for AppPageRoute {\n-                        original_name: _,\n-                        html_endpoint,\n-                        rsc_endpoint: _,\n-                    } in page_routes\n-                    {\n-                        endpoints.push(*html_endpoint);\n-                    }\n+                    endpoint_groups.push((\n+                        EndpointGroupKey::Route(key.clone()),\n+                        EndpointGroup {\n+                            primary: page_routes.iter().map(|r| r.html_endpoint).collect(),\n+                            additional: Vec::new(),\n+                        },\n+                    ));\n                 }\n                 Route::AppRoute {\n                     original_name: _,\n                     endpoint,\n                 } => {\n-                    endpoints.push(*endpoint);\n+                    endpoint_groups.push((\n+                        EndpointGroupKey::Route(key.clone()),\n+                        EndpointGroup::from(*endpoint),\n+                    ));\n                 }\n                 Route::Conflict => {\n                     tracing::info!(\"WARN: conflict\");\n                 }\n             }\n         }\n \n+        if add_pages_entries {\n+            endpoint_groups.push((\n+                EndpointGroupKey::PagesError,\n+                EndpointGroup::from(entrypoints.pages_error_endpoint),\n+            ));\n+            endpoint_groups.push((\n+                EndpointGroupKey::PagesApp,\n+                EndpointGroup::from(entrypoints.pages_app_endpoint),\n+            ));\n+            endpoint_groups.push((\n+                EndpointGroupKey::PagesDocument,\n+                EndpointGroup::from(entrypoints.pages_document_endpoint),\n+            ));\n+        }\n+\n+        Ok(Vc::cell(endpoint_groups))\n+    }\n+\n+    #[turbo_tasks::function]\n+    pub async fn get_all_endpoints(self: Vc<Self>, app_dir_only: bool) -> Result<Vc<Endpoints>> {\n+        let mut endpoints = Vec::new();\n+        for (_key, group) in self.get_all_endpoint_groups(app_dir_only).await?.iter() {\n+            for &endpoint in group.primary.iter() {\n+                endpoints.push(endpoint);\n+            }\n+            for &endpoint in group.additional.iter() {\n+                endpoints.push(endpoint);\n+            }\n+        }\n+\n         Ok(Vc::cell(endpoints))\n     }\n \n@@ -999,7 +1040,9 @@ impl Project {\n     }\n \n     #[turbo_tasks::function]\n-    pub async fn whole_app_module_graphs(self: ResolvedVc<Self>) -> Result<Vc<ModuleGraphs>> {\n+    pub async fn whole_app_module_graphs(\n+        self: ResolvedVc<Self>,\n+    ) -> Result<Vc<BaseAndFullModuleGraph>> {\n         async move {\n             let module_graphs_op = whole_app_module_graph_operation(self);\n             let module_graphs_vc = if self.next_mode().await?.is_production() {\n@@ -1843,14 +1886,23 @@ impl Project {\n             Ok(Vc::cell(None))\n         }\n     }\n+\n+    #[turbo_tasks::function]\n+    pub async fn with_next_config(&self, next_config: Vc<NextConfig>) -> Result<Vc<Self>> {\n+        Ok(Self {\n+            next_config: next_config.to_resolved().await?,\n+            ..(*self).clone()\n+        }\n+        .cell())\n+    }\n }\n \n // This is a performance optimization. This function is a root aggregation function that\n // aggregates over the whole subgraph.\n #[turbo_tasks::function(operation)]\n async fn whole_app_module_graph_operation(\n     project: ResolvedVc<Project>,\n-) -> Result<Vc<ModuleGraphs>> {\n+) -> Result<Vc<BaseAndFullModuleGraph>> {\n     mark_root();\n \n     let should_trace = project.next_mode().await?.is_production();\n@@ -1868,15 +1920,15 @@ async fn whole_app_module_graph_operation(\n     );\n \n     let full = ModuleGraph::from_graphs(vec![base_single_module_graph, additional_module_graph]);\n-    Ok(ModuleGraphs {\n+    Ok(BaseAndFullModuleGraph {\n         base: base.to_resolved().await?,\n         full: full.to_resolved().await?,\n     }\n     .cell())\n }\n \n #[turbo_tasks::value(shared)]\n-pub struct ModuleGraphs {\n+pub struct BaseAndFullModuleGraph {\n     pub base: ResolvedVc<ModuleGraph>,\n     pub full: ResolvedVc<ModuleGraph>,\n }"
        },
        {
            "sha": "2dd77f52dd19e1645b9139ec96d11240f8b77e31",
            "filename": "crates/next-api/src/route.rs",
            "status": "modified",
            "additions": 107,
            "deletions": 2,
            "changes": 109,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Froute.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-api%2Fsrc%2Froute.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2Fsrc%2Froute.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -1,9 +1,11 @@\n+use std::fmt::Display;\n+\n use anyhow::Result;\n use serde::{Deserialize, Serialize};\n use turbo_rcstr::RcStr;\n use turbo_tasks::{\n-    Completion, FxIndexMap, NonLocalValue, OperationVc, ResolvedVc, Vc, debug::ValueDebugFormat,\n-    trace::TraceRawVcs,\n+    Completion, FxIndexMap, FxIndexSet, NonLocalValue, OperationVc, ResolvedVc, TryFlatJoinIterExt,\n+    TryJoinIterExt, Vc, debug::ValueDebugFormat, trace::TraceRawVcs,\n };\n use turbopack_core::{\n     module_graph::{GraphEntries, ModuleGraph},\n@@ -47,6 +49,9 @@ pub enum Route {\n     Conflict,\n }\n \n+#[turbo_tasks::value(transparent)]\n+pub struct ModuleGraphs(Vec<ResolvedVc<ModuleGraph>>);\n+\n #[turbo_tasks::value_trait]\n pub trait Endpoint {\n     #[turbo_tasks::function]\n@@ -65,8 +70,108 @@ pub trait Endpoint {\n     fn additional_entries(self: Vc<Self>, _graph: Vc<ModuleGraph>) -> Vc<GraphEntries> {\n         GraphEntries::empty()\n     }\n+    #[turbo_tasks::function]\n+    fn module_graphs(self: Vc<Self>) -> Vc<ModuleGraphs>;\n }\n \n+#[derive(\n+    TraceRawVcs,\n+    Serialize,\n+    Deserialize,\n+    PartialEq,\n+    Eq,\n+    ValueDebugFormat,\n+    Clone,\n+    Debug,\n+    NonLocalValue,\n+)]\n+pub enum EndpointGroupKey {\n+    Instrumentation,\n+    InstrumentationEdge,\n+    Middleware,\n+    PagesError,\n+    PagesApp,\n+    PagesDocument,\n+    Route(RcStr),\n+}\n+\n+impl Display for EndpointGroupKey {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        match self {\n+            EndpointGroupKey::Instrumentation => write!(f, \"instrumentation\"),\n+            EndpointGroupKey::InstrumentationEdge => write!(f, \"instrumentation-edge\"),\n+            EndpointGroupKey::Middleware => write!(f, \"middleware\"),\n+            EndpointGroupKey::PagesError => write!(f, \"_error\"),\n+            EndpointGroupKey::PagesApp => write!(f, \"_app\"),\n+            EndpointGroupKey::PagesDocument => write!(f, \"_document\"),\n+            EndpointGroupKey::Route(route) => write!(f, \"/{}\", route),\n+        }\n+    }\n+}\n+\n+#[derive(\n+    TraceRawVcs,\n+    Serialize,\n+    Deserialize,\n+    PartialEq,\n+    Eq,\n+    ValueDebugFormat,\n+    Clone,\n+    Debug,\n+    NonLocalValue,\n+)]\n+pub struct EndpointGroup {\n+    pub primary: Vec<ResolvedVc<Box<dyn Endpoint>>>,\n+    pub additional: Vec<ResolvedVc<Box<dyn Endpoint>>>,\n+}\n+\n+impl EndpointGroup {\n+    pub fn from(endpoint: ResolvedVc<Box<dyn Endpoint>>) -> Self {\n+        Self {\n+            primary: vec![endpoint],\n+            additional: vec![],\n+        }\n+    }\n+\n+    pub fn output_assets(&self) -> Vc<OutputAssets> {\n+        output_of_endpoints(self.primary.iter().map(|endpoint| **endpoint).collect())\n+    }\n+\n+    pub fn module_graphs(&self) -> Vc<ModuleGraphs> {\n+        module_graphs_of_endpoints(self.primary.iter().map(|endpoint| **endpoint).collect())\n+    }\n+}\n+\n+#[turbo_tasks::function]\n+async fn output_of_endpoints(endpoints: Vec<Vc<Box<dyn Endpoint>>>) -> Result<Vc<OutputAssets>> {\n+    let assets = endpoints\n+        .iter()\n+        .map(async |endpoint| Ok(*endpoint.output().await?.output_assets))\n+        .try_join()\n+        .await?;\n+    Ok(OutputAssets::concat(assets))\n+}\n+\n+#[turbo_tasks::function]\n+async fn module_graphs_of_endpoints(\n+    endpoints: Vec<Vc<Box<dyn Endpoint>>>,\n+) -> Result<Vc<ModuleGraphs>> {\n+    let module_graphs = endpoints\n+        .iter()\n+        .map(async |endpoint| Ok(endpoint.module_graphs().await?.into_iter()))\n+        .try_flat_join()\n+        .await?\n+        .into_iter()\n+        .copied()\n+        .collect::<FxIndexSet<_>>()\n+        .into_iter()\n+        .collect::<Vec<_>>();\n+    Ok(Vc::cell(module_graphs))\n+}\n+\n+#[turbo_tasks::value(transparent)]\n+pub struct EndpointGroups(Vec<(EndpointGroupKey, EndpointGroup)>);\n+\n #[turbo_tasks::value(transparent)]\n pub struct Endpoints(Vec<ResolvedVc<Box<dyn Endpoint>>>);\n "
        },
        {
            "sha": "d823943592bbed6e487971d564d9ed8e1d2520f5",
            "filename": "crates/next-core/src/next_config.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-core%2Fsrc%2Fnext_config.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/crates%2Fnext-core%2Fsrc%2Fnext_config.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-core%2Fsrc%2Fnext_config.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -158,6 +158,18 @@ pub struct NextConfig {\n     webpack: Option<serde_json::Value>,\n }\n \n+#[turbo_tasks::value_impl]\n+impl NextConfig {\n+    #[turbo_tasks::function]\n+    pub fn with_production_browser_source_maps(&self) -> Vc<Self> {\n+        Self {\n+            production_browser_source_maps: true,\n+            ..self.clone()\n+        }\n+        .cell()\n+    }\n+}\n+\n #[derive(\n     Clone, Debug, PartialEq, Eq, Serialize, Deserialize, TraceRawVcs, NonLocalValue, OperationValue,\n )]"
        },
        {
            "sha": "5d13e2d1024103ce39a5799ac7701ee7ceaeed6f",
            "filename": "packages/next/src/bin/next.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbin%2Fnext.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbin%2Fnext.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbin%2Fnext.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -146,6 +146,10 @@ program\n       'If no directory is provided, the current directory will be used.'\n     )}`\n   )\n+  .option(\n+    '--experimental-analyze',\n+    'Analyze bundle output. Only compatible with Turbopack.'\n+  )\n   .option('-d, --debug', 'Enables a more verbose build output.')\n   .option(\n     '--debug-prerender',"
        },
        {
            "sha": "00b1dc958ad4c1bf584e58a85e3a0770a037174c",
            "filename": "packages/next/src/build/build-context.ts",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fbuild-context.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fbuild-context.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fbuild-context.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -95,4 +95,5 @@ export const NextBuildContext: Partial<{\n   allowedRevalidateHeaderKeys?: string[]\n   isCompileMode?: boolean\n   debugPrerender: boolean\n+  analyze: boolean\n }> = {}"
        },
        {
            "sha": "2e5efa73794a2bae3a2cd140f1dc258fda687191",
            "filename": "packages/next/src/build/index.ts",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Findex.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -904,6 +904,7 @@ async function getBuildId(\n \n export default async function build(\n   dir: string,\n+  experimentalAnalyze = false,\n   reactProductionProfiling = false,\n   debugOutput = false,\n   debugPrerender = false,\n@@ -918,6 +919,7 @@ export default async function build(\n   const isCompileMode = experimentalBuildMode === 'compile'\n   const isGenerateMode = experimentalBuildMode === 'generate'\n   NextBuildContext.isCompileMode = isCompileMode\n+  NextBuildContext.analyze = experimentalAnalyze\n   const buildStartTime = Date.now()\n \n   let loadedConfig: NextConfigComplete | undefined"
        },
        {
            "sha": "08fed01ec5009a722cf39947ec949497c5dd1b69",
            "filename": "packages/next/src/build/swc/generated-native.d.ts",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Fgenerated-native.d.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Fgenerated-native.d.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Fgenerated-native.d.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -297,6 +297,9 @@ export declare function projectWriteAllEntrypointsToDisk(\n   project: { __napiType: 'Project' },\n   appDirOnly: boolean\n ): Promise<TurbopackResult>\n+export declare function projectEntrypoints(project: {\n+  __napiType: 'Project'\n+}): Promise<TurbopackResult>\n export declare function projectEntrypointsSubscribe(\n   project: { __napiType: 'Project' },\n   func: (...args: any[]) => any\n@@ -373,6 +376,10 @@ export declare function projectGetSourceMapSync(\n   project: { __napiType: 'Project' },\n   filePath: RcStr\n ): string | null\n+export declare function projectWriteAnalyzeData(\n+  project: { __napiType: 'Project' },\n+  appDirOnly: boolean\n+): Promise<TurbopackResult>\n /**\n  * A version of [`NapiNextTurbopackCallbacks`] that can accepted as an argument to a napi function.\n  *"
        },
        {
            "sha": "eff67e1f7398126587f8692f4439845c69d6f353",
            "filename": "packages/next/src/build/swc/index.ts",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Findex.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Findex.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Findex.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -655,6 +655,16 @@ function bindingToApi(\n       )\n     }\n \n+    async writeAnalyzeData(\n+      appDirOnly: boolean\n+    ): Promise<TurbopackResult<void>> {\n+      const napiResult = (await binding.projectWriteAnalyzeData(\n+        this._nativeProject,\n+        appDirOnly\n+      )) as TurbopackResult<void>\n+      return napiResult\n+    }\n+\n     async writeAllEntrypointsToDisk(\n       appDirOnly: boolean\n     ): Promise<TurbopackResult<Partial<RawEntrypoints>>> {"
        },
        {
            "sha": "3726cc10aac8653a229585b90d3871edf5aff442",
            "filename": "packages/next/src/build/swc/types.ts",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Ftypes.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Ftypes.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fswc%2Ftypes.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -231,6 +231,8 @@ export interface UpdateInfo {\n export interface Project {\n   update(options: Partial<ProjectOptions>): Promise<void>\n \n+  writeAnalyzeData(appDirOnly: boolean): Promise<TurbopackResult<void>>\n+\n   writeAllEntrypointsToDisk(\n     appDirOnly: boolean\n   ): Promise<TurbopackResult<Partial<RawEntrypoints>>>"
        },
        {
            "sha": "d67393cc09d0c32ddac4086e790ff8282b58191b",
            "filename": "packages/next/src/build/turbopack-build/impl.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fturbopack-build%2Fimpl.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fbuild%2Fturbopack-build%2Fimpl.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fbuild%2Fturbopack-build%2Fimpl.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -193,6 +193,10 @@ export async function turbopackBuild(): Promise<{\n       entrypoints: currentEntrypoints,\n     })\n \n+    if (NextBuildContext.analyze) {\n+      await project.writeAnalyzeData(appDirOnly)\n+    }\n+\n     const shutdownPromise = project.shutdown()\n \n     const time = process.hrtime(startTime)"
        },
        {
            "sha": "61590ed233ba38a4f8b718507676d8ae5f68a18c",
            "filename": "packages/next/src/cli/next-build.ts",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fcli%2Fnext-build.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Fsrc%2Fcli%2Fnext-build.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fcli%2Fnext-build.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -10,13 +10,14 @@ import isError from '../lib/is-error'\n import { getProjectDir } from '../lib/get-project-dir'\n import { enableMemoryDebuggingMode } from '../lib/memory/startup'\n import { disableMemoryDebuggingMode } from '../lib/memory/shutdown'\n-import { parseBundlerArgs } from '../lib/bundler'\n+import { Bundler, parseBundlerArgs } from '../lib/bundler'\n import {\n   resolveBuildPaths,\n   parseBuildPathsInput,\n } from '../lib/resolve-build-paths'\n \n export type NextBuildOptions = {\n+  experimentalAnalyze?: boolean\n   debug?: boolean\n   debugPrerender?: boolean\n   profile?: boolean\n@@ -38,6 +39,7 @@ const nextBuild = async (options: NextBuildOptions, directory?: string) => {\n   process.on('SIGINT', () => process.exit(130))\n \n   const {\n+    experimentalAnalyze,\n     debug,\n     debugPrerender,\n     experimentalDebugMemoryUsage,\n@@ -54,6 +56,14 @@ const nextBuild = async (options: NextBuildOptions, directory?: string) => {\n     traceUploadUrl = experimentalUploadTrace\n   }\n \n+  const bundler = parseBundlerArgs(options)\n+\n+  if (experimentalAnalyze && bundler !== Bundler.Turbopack) {\n+    printAndExit(\n+      '--experimental-analyze is only compatible with the Turbopack bundler.'\n+    )\n+  }\n+\n   if (!mangling) {\n     warn(\n       `Mangling is disabled. ${italic('Note: This may affect performance and should only be used for debugging purposes.')}`\n@@ -85,8 +95,6 @@ const nextBuild = async (options: NextBuildOptions, directory?: string) => {\n     printAndExit(`> No such directory exists as the project root: ${dir}`)\n   }\n \n-  const bundler = parseBundlerArgs(options)\n-\n   // Resolve selective build paths\n   let resolvedAppPaths: string[] | undefined\n   let resolvedPagePaths: string[] | undefined\n@@ -110,6 +118,7 @@ const nextBuild = async (options: NextBuildOptions, directory?: string) => {\n \n   return build(\n     dir,\n+    experimentalAnalyze,\n     profile,\n     debug || Boolean(process.env.NEXT_DEBUG_BUILD),\n     debugPrerender,"
        },
        {
            "sha": "58da2783ee16b53f0abba3458c670dabfbffef12",
            "filename": "packages/next/taskfile-swc.js",
            "status": "modified",
            "additions": 5,
            "deletions": 1,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Ftaskfile-swc.js",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/packages%2Fnext%2Ftaskfile-swc.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Ftaskfile-swc.js?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -123,7 +123,11 @@ module.exports = function (task) {\n       const distFilePath = path.dirname(\n         // we must strip src from filePath as it isn't carried into\n         // the dist file path\n-        path.join(__dirname, 'dist', filePath.replace(/^src[/\\\\]/, ''))\n+        path.join(\n+          __dirname,\n+          esm ? 'dist/esm' : 'dist',\n+          filePath.replace(/^src[/\\\\]/, '')\n+        )\n       )\n \n       const options = {"
        },
        {
            "sha": "83311bdfa26499785257d6fe0bac03e61f315690",
            "filename": "test/integration/custom-server-types/next-env.d.ts",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/test%2Fintegration%2Fcustom-server-types%2Fnext-env.d.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/test%2Fintegration%2Fcustom-server-types%2Fnext-env.d.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fintegration%2Fcustom-server-types%2Fnext-env.d.ts?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -1,6 +1,6 @@\n /// <reference types=\"next\" />\n /// <reference types=\"next/image-types/global\" />\n-import \"./.next/dev/types/routes.d.ts\";\n+import './.next/dev/types/routes.d.ts'\n \n // NOTE: This file should not be edited\n // see https://nextjs.org/docs/pages/api-reference/config/typescript for more information."
        },
        {
            "sha": "a7901664f5f73eedcf52bef45980f9ff5805f31d",
            "filename": "turbopack/crates/turbo-persistence/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -15,7 +15,7 @@ print_stats = [\"stats\"]\n anyhow = { workspace = true }\n either = { workspace = true }\n pot = \"3.0.0\"\n-byteorder = \"1.5.0\"\n+byteorder = { workspace = true }\n jiff = \"0.2.10\"\n lzzzz = \"1.1.0\"\n memmap2 = \"0.9.5\""
        },
        {
            "sha": "e33ab839e9eb653900be23e9a291247de2e7e516",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -31,7 +31,7 @@ anyhow = { workspace = true }\n arc-swap = { version = \"1.7.1\" }\n auto-hash-map = { workspace = true }\n bitfield = { workspace = true }\n-byteorder = \"1.5.0\"\n+byteorder = { workspace = true }\n dashmap = { workspace = true, features = [\"raw-api\"]}\n either = { workspace = true }\n hashbrown = { workspace = true, features = [\"raw\"] }"
        },
        {
            "sha": "1765c6f8c816ca7502b6be76bf29dc926316400a",
            "filename": "turbopack/crates/turbo-tasks-fs/src/lib.rs",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Flib.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -2289,6 +2289,17 @@ pub struct FileLine {\n     pub bytes_offset: u32,\n }\n \n+impl FileLine {\n+    pub fn len(&self) -> usize {\n+        self.content.len()\n+    }\n+\n+    #[must_use]\n+    pub fn is_empty(&self) -> bool {\n+        self.len() == 0\n+    }\n+}\n+\n #[turbo_tasks::value(shared, serialization = \"none\")]\n pub enum FileLinesContent {\n     Lines(#[turbo_tasks(trace_ignore)] Vec<FileLine>),"
        },
        {
            "sha": "9d49f8e48e3d8f2362c814d11eab1049df6e68e5",
            "filename": "turbopack/crates/turbo-tasks-fs/src/rope.rs",
            "status": "modified",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fsrc%2Frope.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -164,6 +164,14 @@ impl RopeBuilder {\n         self.uncommitted.push_bytes(bytes);\n     }\n \n+    /// Reserve additional capacity for owned bytes in the Rope.\n+    ///\n+    /// This is useful to call before multiple `push_bytes` calls to avoid\n+    /// multiple allocations.\n+    pub fn reserve_bytes(&mut self, additional: usize) {\n+        self.uncommitted.reserve_bytes(additional);\n+    }\n+\n     /// Push static lifetime bytes into the Rope.\n     ///\n     /// This is more efficient than pushing owned bytes, because the internal\n@@ -305,6 +313,24 @@ impl Uncommitted {\n         }\n     }\n \n+    /// Reserves additional capacity for owned bytes, converting the current\n+    /// representation to an Owned if it's not already.\n+    fn reserve_bytes(&mut self, additional: usize) {\n+        match self {\n+            Self::None => {\n+                *self = Self::Owned(Vec::with_capacity(additional));\n+            }\n+            Self::Static(s) => {\n+                let mut v = Vec::with_capacity(s.len() + additional);\n+                v.extend_from_slice(s);\n+                *self = Self::Owned(v);\n+            }\n+            Self::Owned(v) => {\n+                v.reserve(additional);\n+            }\n+        }\n+    }\n+\n     /// Pushes static lifetime bytes, but only if the current representation is\n     /// None. Else, it coverts to an Owned.\n     fn push_static_bytes(&mut self, bytes: &'static [u8]) {"
        },
        {
            "sha": "f469b901d5d1e2c3040e8b11f54fd325b3b4db9d",
            "filename": "turbopack/crates/turbopack-analyze/Cargo.toml",
            "status": "added",
            "additions": 27,
            "deletions": 0,
            "changes": 27,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-analyze%2FCargo.toml?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,27 @@\n+[package]\n+name = \"turbopack-analyze\"\n+version = \"0.1.0\"\n+edition = \"2024\"\n+license = \"MIT\"\n+autobenches = false\n+\n+[lib]\n+bench = false\n+\n+[dependencies]\n+anyhow = { workspace = true }\n+rustc-hash = { workspace = true }\n+serde = { workspace = true, features = [\"derive\"] }\n+turbo-rcstr = { workspace = true }\n+turbo-tasks = { workspace = true }\n+turbo-tasks-fs = { workspace = true }\n+turbopack-core = { workspace = true }\n+\n+[dev-dependencies]\n+serde_json = { workspace = true }\n+tokio = { workspace = true, features = [\"full\"] }\n+turbo-tasks-testing = { workspace = true }\n+turbo-tasks-backend = { workspace = true }\n+\n+[lints]\n+workspace = true"
        },
        {
            "sha": "46648698eee704d1967ae22c7e17c51e48458b21",
            "filename": "turbopack/crates/turbopack-analyze/src/lib.rs",
            "status": "added",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Flib.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,3 @@\n+#![feature(arbitrary_self_types_pointers)]\n+\n+pub mod split_chunk;"
        },
        {
            "sha": "657b4081b2b22da4dc08c23aaed11de75669ce36",
            "filename": "turbopack/crates/turbopack-analyze/src/split_chunk.rs",
            "status": "added",
            "additions": 315,
            "deletions": 0,
            "changes": 315,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Fsplit_chunk.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Fsplit_chunk.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-analyze%2Fsrc%2Fsplit_chunk.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,315 @@\n+use std::mem::replace;\n+\n+use anyhow::Result;\n+use serde::{Deserialize, Serialize};\n+use turbo_rcstr::RcStr;\n+use turbo_tasks::{FxIndexMap, NonLocalValue, ValueToString, Vc, trace::TraceRawVcs};\n+use turbo_tasks_fs::{FileContent, FileLine, FileLinesContent, rope::Rope};\n+use turbopack_core::{\n+    asset::{Asset, AssetContent},\n+    output::OutputAsset,\n+    source_map::{GenerateSourceMap, OriginalToken, SourceMap, SyntheticToken, Token},\n+};\n+\n+#[derive(Clone, Debug, Deserialize, Eq, NonLocalValue, PartialEq, Serialize, TraceRawVcs)]\n+pub struct ChunkPartRange {\n+    pub line: u32,\n+    pub start_column: u32,\n+    pub end_column: u32,\n+}\n+\n+#[derive(Clone, Debug, Deserialize, Eq, NonLocalValue, PartialEq, Serialize, TraceRawVcs)]\n+pub struct ChunkPart {\n+    pub source: RcStr,\n+    pub real_size: u32,\n+    pub unaccounted_size: u32,\n+    pub ranges: Vec<ChunkPartRange>,\n+}\n+\n+#[turbo_tasks::value(transparent)]\n+#[derive(Debug)]\n+pub struct ChunkParts(Vec<ChunkPart>);\n+\n+#[turbo_tasks::function]\n+pub async fn split_output_asset_into_parts(\n+    asset: Vc<Box<dyn OutputAsset>>,\n+) -> Result<Vc<ChunkParts>> {\n+    let content = asset.content().await?;\n+    let AssetContent::File(file_content) = &*content else {\n+        return Ok(Vc::cell(vec![]));\n+    };\n+    let FileContent::Content(content) = &*file_content.await? else {\n+        return Ok(Vc::cell(vec![]));\n+    };\n+    let content = content.content();\n+    let Some(generate_source_map) =\n+        Vc::try_resolve_sidecast::<Box<dyn GenerateSourceMap>>(asset).await?\n+    else {\n+        return self_mapped(asset, content).await;\n+    };\n+    let Some(source_map) = &*generate_source_map.generate_source_map().await? else {\n+        return self_mapped(asset, content).await;\n+    };\n+    let Some(source_map) = SourceMap::new_from_rope(source_map)? else {\n+        return unaccounted(asset, content).await;\n+    };\n+\n+    let lines = file_content.lines().await?;\n+    let FileLinesContent::Lines(lines) = &*lines else {\n+        return unaccounted(asset, content).await;\n+    };\n+\n+    fn end_of_mapping_column(\n+        start_line: u32,\n+        end_line: u32,\n+        end_column: u32,\n+        lines: &[FileLine],\n+    ) -> u32 {\n+        let start_line = start_line.min(lines.len() as u32 - 1);\n+        let line_end = lines[start_line as usize].len() as u32;\n+        if start_line == end_line {\n+            end_column.min(line_end)\n+        } else {\n+            line_end\n+        }\n+    }\n+    fn len_between(\n+        start_line: u32,\n+        start_column: u32,\n+        end_line: u32,\n+        end_column: u32,\n+        lines: &[FileLine],\n+    ) -> u32 {\n+        let start_line = start_line.min(lines.len() as u32 - 1);\n+        let end_line = end_line.min(lines.len() as u32 - 1);\n+        if start_line == end_line {\n+            return end_column - start_column;\n+        }\n+        let mut len = lines[start_line as usize].len() as u32 - start_column + 1;\n+        for line in &lines[start_line as usize + 1..end_line as usize] {\n+            len += line.len() as u32 + 1;\n+        }\n+        len += end_column;\n+        len\n+    }\n+\n+    let mut chunk_parts = FxIndexMap::default();\n+    fn add_chunk_part_range(\n+        source: RcStr,\n+        chunk_part_range: ChunkPartRange,\n+        size: u32,\n+        chunk_parts: &mut FxIndexMap<RcStr, ChunkPart>,\n+    ) {\n+        let entry = chunk_parts\n+            .entry(source)\n+            .or_insert_with_key(|source| ChunkPart {\n+                source: source.clone(),\n+                real_size: 0,\n+                unaccounted_size: 0,\n+                ranges: vec![],\n+            });\n+        entry.real_size += size;\n+        entry.ranges.push(chunk_part_range);\n+    }\n+    fn add_unaccounted_chunk_part(\n+        source: RcStr,\n+        unaccounted: u32,\n+        chunk_parts: &mut FxIndexMap<RcStr, ChunkPart>,\n+    ) {\n+        let entry = chunk_parts\n+            .entry(source)\n+            .or_insert_with_key(|source| ChunkPart {\n+                source: source.clone(),\n+                real_size: 0,\n+                unaccounted_size: 0,\n+                ranges: vec![],\n+            });\n+        entry.unaccounted_size += unaccounted;\n+    }\n+\n+    enum State {\n+        StartOfFile,\n+        InMapping {\n+            source: RcStr,\n+            current_generated_line: u32,\n+            current_generated_column: u32,\n+        },\n+        AfterMapping {\n+            source: RcStr,\n+            current_generated_line: u32,\n+            current_generated_column: u32,\n+        },\n+    }\n+\n+    let mut state: State = State::StartOfFile;\n+\n+    fn end_current_token(\n+        lines: &[FileLine],\n+        chunk_parts: &mut FxIndexMap<RcStr, ChunkPart>,\n+        state: &mut State,\n+        token: &Token,\n+    ) {\n+        if let State::InMapping {\n+            ref source,\n+            current_generated_line,\n+            current_generated_column,\n+        } = *state\n+        {\n+            let (Token::Original(OriginalToken {\n+                generated_line,\n+                generated_column,\n+                ..\n+            })\n+            | Token::Synthetic(SyntheticToken {\n+                generated_line,\n+                generated_column,\n+                ..\n+            })) = *token;\n+            let mapping_end_column = end_of_mapping_column(\n+                current_generated_line,\n+                generated_line,\n+                generated_column,\n+                lines,\n+            );\n+            // TODO: Handle this better\n+            let len = mapping_end_column.saturating_sub(current_generated_column);\n+            add_chunk_part_range(\n+                source.clone(),\n+                ChunkPartRange {\n+                    line: current_generated_line,\n+                    start_column: current_generated_column,\n+                    end_column: mapping_end_column,\n+                },\n+                len,\n+                chunk_parts,\n+            );\n+            *state = State::AfterMapping {\n+                source: source.clone(),\n+                current_generated_line,\n+                current_generated_column: mapping_end_column,\n+            };\n+        }\n+    }\n+\n+    fn start_new_mapping(\n+        lines: &[FileLine],\n+        chunk_parts: &mut FxIndexMap<RcStr, ChunkPart>,\n+        state: &mut State,\n+        original_file: RcStr,\n+        generated_line: u32,\n+        generated_column: u32,\n+    ) {\n+        match replace(\n+            state,\n+            State::InMapping {\n+                source: original_file.clone(),\n+                current_generated_line: generated_line,\n+                current_generated_column: generated_column,\n+            },\n+        ) {\n+            State::InMapping { .. } => {\n+                unreachable!();\n+            }\n+            State::AfterMapping {\n+                source,\n+                current_generated_line,\n+                current_generated_column,\n+            } => {\n+                let len = len_between(\n+                    current_generated_line,\n+                    current_generated_column,\n+                    generated_line,\n+                    generated_column,\n+                    lines,\n+                );\n+                let half = len / 2;\n+                add_unaccounted_chunk_part(source, half, chunk_parts);\n+                add_unaccounted_chunk_part(original_file.clone(), len - half, chunk_parts);\n+            }\n+            State::StartOfFile => {\n+                let len = len_between(0, 0, generated_line, generated_column, lines);\n+                add_unaccounted_chunk_part(original_file.clone(), len, chunk_parts);\n+            }\n+        }\n+    }\n+\n+    for token in source_map.tokens() {\n+        // First end the previous mapping if we were in one\n+        end_current_token(lines, &mut chunk_parts, &mut state, &token);\n+\n+        if let Token::Original(OriginalToken {\n+            original_file,\n+            generated_line,\n+            generated_column,\n+            ..\n+        }) = token\n+        {\n+            // Start a new mapping and put the unaccounted part in between\n+            // somewhere\n+            start_new_mapping(\n+                lines,\n+                &mut chunk_parts,\n+                &mut state,\n+                original_file,\n+                generated_line,\n+                generated_column,\n+            );\n+        }\n+    }\n+    let last_line = lines.len() as u32 - 1;\n+    let last_column = lines[last_line as usize].len() as u32;\n+    end_current_token(\n+        lines,\n+        &mut chunk_parts,\n+        &mut state,\n+        &Token::Synthetic(SyntheticToken {\n+            generated_line: last_line,\n+            generated_column: last_column,\n+            guessed_original_file: None,\n+        }),\n+    );\n+    match state {\n+        State::InMapping { .. } => {\n+            unreachable!();\n+        }\n+        State::AfterMapping {\n+            source,\n+            current_generated_line,\n+            current_generated_column,\n+        } => {\n+            let len = len_between(\n+                current_generated_line,\n+                current_generated_column,\n+                last_line,\n+                last_column,\n+                lines,\n+            );\n+            add_unaccounted_chunk_part(source, len, &mut chunk_parts);\n+        }\n+        State::StartOfFile => {\n+            return unaccounted(asset, content).await;\n+        }\n+    }\n+\n+    Ok(Vc::cell(chunk_parts.into_values().collect()))\n+}\n+\n+async fn self_mapped(asset: Vc<Box<dyn OutputAsset>>, content: &Rope) -> Result<Vc<ChunkParts>> {\n+    let len = content.len().try_into().unwrap_or(u32::MAX);\n+    Ok(Vc::cell(vec![ChunkPart {\n+        source: asset.path().to_string().owned().await?,\n+        real_size: len,\n+        unaccounted_size: 0,\n+        ranges: vec![],\n+    }]))\n+}\n+\n+async fn unaccounted(asset: Vc<Box<dyn OutputAsset>>, content: &Rope) -> Result<Vc<ChunkParts>> {\n+    let len = content.len().try_into().unwrap_or(u32::MAX);\n+    Ok(Vc::cell(vec![ChunkPart {\n+        source: asset.path().to_string().owned().await?,\n+        real_size: 0,\n+        unaccounted_size: len,\n+        ranges: vec![],\n+    }]))\n+}"
        },
        {
            "sha": "a1eca4d3265df9f4bbe2db2aaed0a8c2d2c3cdda",
            "filename": "turbopack/crates/turbopack-analyze/tests/split_chunk.rs",
            "status": "added",
            "additions": 133,
            "deletions": 0,
            "changes": 133,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Fsplit_chunk.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Fsplit_chunk.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Fsplit_chunk.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,133 @@\n+#![feature(arbitrary_self_types_pointers)]\n+#![allow(clippy::needless_return)] // tokio macro-generated code doesn't respect this\n+#![cfg(test)]\n+\n+use anyhow::Result;\n+use serde_json::json;\n+use turbo_rcstr::rcstr;\n+use turbo_tasks::{ResolvedVc, Vc};\n+use turbo_tasks_fs::{File, FileSystem, FileSystemPath, VirtualFileSystem, rope::Rope};\n+use turbo_tasks_testing::{Registration, register, run_once};\n+use turbopack_analyze::split_chunk::{ChunkPart, ChunkPartRange, split_output_asset_into_parts};\n+use turbopack_core::{\n+    asset::{Asset, AssetContent},\n+    code_builder::{Code, CodeBuilder},\n+    output::OutputAsset,\n+    source_map::{GenerateSourceMap, OptionStringifiedSourceMap},\n+};\n+\n+static REGISTRATION: Registration = register!(turbo_tasks_fetch::register);\n+\n+#[tokio::test(flavor = \"multi_thread\", worker_threads = 2)]\n+async fn split_chunk() {\n+    run_once(&REGISTRATION, || async {\n+        let mut code = CodeBuilder::new(true, false);\n+        code += \"Hello world!\\n\";\n+        code += \"This is a test file.\\n\";\n+        code.push_source(\n+            &Rope::from(\"Hello world!\\n123\"),\n+            Some(Rope::from(serde_json::to_string_pretty(&json! ({\n+                \"version\": 3,\n+                \"mappings\": \"AAAA;AACA\",\n+                \"sources\": [\"source1.js\"],\n+                \"names\": [],\n+                \"sourcesContent\": [\"console.log('Hello world!');\"]\n+            }))?)),\n+        );\n+        code += \"This is the middle of the file.\\n\";\n+        code.push_source(\n+            &Rope::from(\"This is the middle of the file.\\n\"),\n+            Some(Rope::from(serde_json::to_string_pretty(&json! ({\n+                \"version\": 3,\n+                \"mappings\": \"AAAA\",\n+                \"sources\": [\"source2.js\"],\n+                \"names\": [],\n+                \"sourcesContent\": [\"console.log('Middle of file');\"]\n+            }))?)),\n+        );\n+        code += \"This is the end of the file.\\n\";\n+        let code = code.build();\n+\n+        let asset = Vc::upcast(\n+            TestAsset {\n+                code: code.resolved_cell(),\n+            }\n+            .cell(),\n+        );\n+\n+        let parts = split_output_asset_into_parts(asset).await.unwrap();\n+\n+        assert_eq!(\n+            &*parts,\n+            &vec![\n+                ChunkPart {\n+                    source: rcstr!(\"source1.js\"),\n+                    real_size: 15,\n+                    unaccounted_size: 51,\n+                    ranges: vec![\n+                        ChunkPartRange {\n+                            line: 2,\n+                            start_column: 0,\n+                            end_column: 12,\n+                        },\n+                        ChunkPartRange {\n+                            line: 3,\n+                            start_column: 0,\n+                            end_column: 3,\n+                        },\n+                    ],\n+                },\n+                ChunkPart {\n+                    source: rcstr!(\"source2.js\"),\n+                    real_size: 31,\n+                    unaccounted_size: 46,\n+                    ranges: vec![ChunkPartRange {\n+                        line: 4,\n+                        start_column: 0,\n+                        end_column: 31,\n+                    }],\n+                },\n+            ]\n+        );\n+\n+        println!(\"{:#?}\", parts);\n+        anyhow::Ok(())\n+    })\n+    .await\n+    .unwrap()\n+}\n+\n+#[turbo_tasks::value]\n+struct TestAsset {\n+    code: ResolvedVc<Code>,\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl OutputAsset for TestAsset {\n+    #[turbo_tasks::function]\n+    async fn path(&self) -> Result<Vc<FileSystemPath>> {\n+        Ok(VirtualFileSystem::new()\n+            .root()\n+            .await?\n+            .join(\"test.js\")?\n+            .cell())\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl Asset for TestAsset {\n+    #[turbo_tasks::function]\n+    async fn content(&self) -> Result<Vc<AssetContent>> {\n+        Ok(AssetContent::file(\n+            File::from(self.code.await?.source_code().clone()).into(),\n+        ))\n+    }\n+}\n+\n+#[turbo_tasks::value_impl]\n+impl GenerateSourceMap for TestAsset {\n+    #[turbo_tasks::function]\n+    pub fn generate_source_map(&self) -> Vc<OptionStringifiedSourceMap> {\n+        self.code.generate_source_map()\n+    }\n+}"
        },
        {
            "sha": "16c4cccefb9d0bed312f564c1ddf72a70f7171e7",
            "filename": "turbopack/crates/turbopack-analyze/tests/test_config.trs",
            "status": "added",
            "additions": 26,
            "deletions": 0,
            "changes": 26,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Ftest_config.trs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Ftest_config.trs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-analyze%2Ftests%2Ftest_config.trs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -0,0 +1,26 @@\n+|name, initial| {\n+  let path = std::path::PathBuf::from(\n+    format!(\"{}/.cache/{}\", env!(\"CARGO_TARGET_TMPDIR\"), name));\n+  if initial {\n+    let _ = std::fs::remove_dir_all(&path);\n+  }\n+  std::fs::create_dir_all(&path).unwrap();\n+  turbo_tasks::TurboTasks::new(\n+    turbo_tasks_backend::TurboTasksBackend::new(\n+      turbo_tasks_backend::BackendOptions {\n+        num_workers: Some(2),\n+        small_preallocation: true,\n+        ..Default::default()\n+      },\n+      turbo_tasks_backend::default_backing_storage(\n+        path.as_path(),\n+        &turbo_tasks_backend::GitVersionInfo {\n+          describe: \"test-unversioned\",\n+          dirty: false,\n+        },\n+        false,\n+        true,\n+      ).unwrap().0\n+    )\n+  )\n+}"
        },
        {
            "sha": "be83f2a99002015453398483aae668813ea5dc94",
            "filename": "turbopack/crates/turbopack-core/src/output.rs",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Foutput.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Foutput.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Foutput.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -52,6 +52,15 @@ impl OutputAssets {\n         assets.extend(other.await?.iter().copied());\n         Ok(Vc::cell(assets.into_iter().collect()))\n     }\n+\n+    #[turbo_tasks::function]\n+    pub async fn concat(other: Vec<Vc<Self>>) -> Result<Vc<Self>> {\n+        let mut assets: FxIndexSet<_> = FxIndexSet::default();\n+        for other in other {\n+            assets.extend(other.await?.iter().copied());\n+        }\n+        Ok(Vc::cell(assets.into_iter().collect()))\n+    }\n }\n \n impl OutputAssets {"
        },
        {
            "sha": "d0eec0a954b7c5872b1131af86c22953218b8dc4",
            "filename": "turbopack/crates/turbopack-core/src/source_map/mod.rs",
            "status": "modified",
            "additions": 83,
            "deletions": 3,
            "changes": 86,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fsource_map%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fsource_map%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Fsource_map%2Fmod.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -2,6 +2,7 @@ use std::{borrow::Cow, io::Write, ops::Deref, sync::Arc};\n \n use anyhow::Result;\n use bytes_str::BytesStr;\n+use either::Either;\n use once_cell::sync::Lazy;\n use ref_cast::RefCast;\n use regex::Regex;\n@@ -93,9 +94,6 @@ impl OptionSourceMap {\n         ResolvedVc::cell(None)\n     }\n }\n-#[turbo_tasks::value(transparent)]\n-#[derive(Clone, Debug)]\n-pub struct Tokens(Vec<Token>);\n \n /// A token represents a mapping in a source map.\n ///\n@@ -153,6 +151,32 @@ impl Token {\n             Self::Synthetic(t) => t.generated_column,\n         }\n     }\n+\n+    pub fn with_offset(&self, line_offset: u32, column_offset: u32) -> Self {\n+        match self {\n+            Self::Original(t) => Self::Original(OriginalToken {\n+                generated_line: t.generated_line + line_offset,\n+                generated_column: if t.generated_line == 0 {\n+                    t.generated_column + column_offset\n+                } else {\n+                    t.generated_column\n+                },\n+                original_file: t.original_file.clone(),\n+                original_line: t.original_line,\n+                original_column: t.original_column,\n+                name: t.name.clone(),\n+            }),\n+            Self::Synthetic(t) => Self::Synthetic(SyntheticToken {\n+                generated_line: t.generated_line + line_offset,\n+                generated_column: if t.generated_line == 0 {\n+                    t.generated_column + column_offset\n+                } else {\n+                    t.generated_column\n+                },\n+                guessed_original_file: t.guessed_original_file.clone(),\n+            }),\n+        }\n+    }\n }\n \n impl From<swc_sourcemap::Token<'_>> for Token {\n@@ -554,6 +578,62 @@ impl SourceMap {\n     }\n }\n \n+impl SourceMap {\n+    pub fn tokens(&self) -> impl Iterator<Item = Token> + '_ {\n+        let map = &self.map;\n+\n+        fn regular_map_to_tokens(\n+            map: &RegularMap,\n+            offset_line: u32,\n+            offset_column: u32,\n+        ) -> impl Iterator<Item = Token> + '_ {\n+            map.tokens()\n+                .map(move |t| Token::from(t).with_offset(offset_line, offset_column))\n+        }\n+\n+        fn index_map_to_tokens(\n+            map: &SourceMapIndex,\n+            offset_line: u32,\n+            offset_column: u32,\n+        ) -> impl Iterator<Item = Token> + '_ {\n+            map.sections().flat_map(move |section| {\n+                let (line, col) = section.get_offset();\n+                let offset_line = offset_line + line;\n+                let offset_column = if line == 0 { offset_column + col } else { col };\n+                if let Some(source_map) = section.get_sourcemap() {\n+                    Either::Left(Box::new(decoded_map_to_tokens(\n+                        source_map,\n+                        offset_line,\n+                        offset_column,\n+                    )) as Box<dyn Iterator<Item = Token>>)\n+                } else {\n+                    Either::Right(std::iter::empty())\n+                }\n+            })\n+        }\n+\n+        fn decoded_map_to_tokens(\n+            map: &DecodedMap,\n+            offset_line: u32,\n+            offset_column: u32,\n+        ) -> impl Iterator<Item = Token> + '_ {\n+            match map {\n+                DecodedMap::Regular(map) => {\n+                    Either::Left(regular_map_to_tokens(map, offset_line, offset_column))\n+                }\n+                DecodedMap::Index(map) => {\n+                    Either::Right(index_map_to_tokens(map, offset_line, offset_column))\n+                }\n+                DecodedMap::Hermes(_) => {\n+                    todo!(\"hermes source maps are not implemented\");\n+                }\n+            }\n+        }\n+\n+        decoded_map_to_tokens(&map.0, 0, 0)\n+    }\n+}\n+\n #[turbo_tasks::value_impl]\n impl GenerateSourceMap for SourceMap {\n     #[turbo_tasks::function]"
        },
        {
            "sha": "119cdfbe03e4aba57d9ddbbce9cc1bbd6bac60e0",
            "filename": "turbopack/crates/turbopack-core/src/traced_asset.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ftraced_asset.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/aae734b36222f1dd14b35835f3fd3519c734e28f/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ftraced_asset.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ftraced_asset.rs?ref=aae734b36222f1dd14b35835f3fd3519c734e28f",
            "patch": "@@ -50,6 +50,6 @@ impl OutputAsset for TracedAsset {\n impl Asset for TracedAsset {\n     #[turbo_tasks::function]\n     fn content(&self) -> Vc<AssetContent> {\n-        panic!(\"TracedAsset::content() should never be called\");\n+        self.module.content()\n     }\n }"
        }
    ],
    "stats": {
        "total": 1876,
        "additions": 1792,
        "deletions": 84
    }
}