{
    "author": "unstubbable",
    "message": "Ensure user-space stack frame for `'use cache'` in page/layout component (#85519)",
    "sha": "b07fb8644f224049dcb664ca06584d5861ac4208",
    "files": [
        {
            "sha": "3da2d65b2c531425ac4d36958331d97f31272007",
            "filename": "crates/next-custom-transforms/src/transforms/server_actions.rs",
            "status": "modified",
            "additions": 132,
            "deletions": 59,
            "changes": 191,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Fsrc%2Ftransforms%2Fserver_actions.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Fsrc%2Ftransforms%2Fserver_actions.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Fsrc%2Ftransforms%2Fserver_actions.rs?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -545,9 +545,6 @@ impl<C: Comments> ServerActions<C> {\n                                         ..Default::default()\n                                     }),\n                                 },\n-                                decorators: vec![],\n-                                span: DUMMY_SP,\n-                                is_generator: false,\n                                 is_async: true,\n                                 ..Default::default()\n                             }),\n@@ -752,44 +749,49 @@ impl<C: Comments> ServerActions<C> {\n             });\n         }\n \n-        // Create the action export decl from the arrow function\n-        // export var cache_ident = async function() {}\n+        let inner_fn_body = match *arrow.body.take() {\n+            BlockStmtOrExpr::BlockStmt(body) => Some(body),\n+            BlockStmtOrExpr::Expr(expr) => Some(BlockStmt {\n+                stmts: vec![Stmt::Return(ReturnStmt {\n+                    span: DUMMY_SP,\n+                    arg: Some(expr),\n+                })],\n+                ..Default::default()\n+            }),\n+        };\n+\n+        let inner_fn = Box::new(Expr::Fn(FnExpr {\n+            ident: None,\n+            function: Box::new(Function {\n+                params: new_params.clone(),\n+                body: inner_fn_body,\n+                span: arrow.span,\n+                is_generator: false,\n+                is_async: true,\n+                ..Default::default()\n+            }),\n+        }));\n+\n+        // Wrap with $$reactCache__(function foo() { return $$cache__(...) })\n+        let wrapper_fn = wrap_cache_expr(\n+            cache_kind.as_str(),\n+            reference_id.as_str(),\n+            ids_from_closure.len(),\n+            inner_fn,\n+            self.arrow_or_fn_expr_ident.clone(),\n+            arrow.span,\n+        );\n+\n+        // Create the export: export var $$RSC_SERVER_CACHE_0 = ...\n         self.hoisted_extra_items\n             .push(ModuleItem::ModuleDecl(ModuleDecl::ExportDecl(ExportDecl {\n                 span: DUMMY_SP,\n                 decl: VarDecl {\n-                    span: DUMMY_SP,\n                     kind: VarDeclKind::Var,\n                     decls: vec![VarDeclarator {\n                         span: arrow.span,\n                         name: Pat::Ident(cache_ident.clone().into()),\n-                        init: Some(wrap_cache_expr(\n-                            Box::new(Expr::Fn(FnExpr {\n-                                ident: None,\n-                                function: Box::new(Function {\n-                                    params: new_params,\n-                                    body: match *arrow.body.take() {\n-                                        BlockStmtOrExpr::BlockStmt(body) => Some(body),\n-                                        BlockStmtOrExpr::Expr(expr) => Some(BlockStmt {\n-                                            span: DUMMY_SP,\n-                                            stmts: vec![Stmt::Return(ReturnStmt {\n-                                                span: DUMMY_SP,\n-                                                arg: Some(expr),\n-                                            })],\n-                                            ..Default::default()\n-                                        }),\n-                                    },\n-                                    decorators: vec![],\n-                                    span: DUMMY_SP,\n-                                    is_generator: false,\n-                                    is_async: true,\n-                                    ..Default::default()\n-                                }),\n-                            })),\n-                            &cache_kind,\n-                            &reference_id,\n-                            ids_from_closure.len(),\n-                        )),\n+                        init: Some(wrapper_fn),\n                         definite: false,\n                     }],\n                     ..Default::default()\n@@ -866,28 +868,40 @@ impl<C: Comments> ServerActions<C> {\n             private_ctxt: self.private_ctxt,\n         });\n \n-        // export var cache_ident = async function() {}\n+        let function_body = function.body.take();\n+        let function_span = function.span;\n+\n+        let inner_fn = Box::new(Expr::Fn(FnExpr {\n+            ident: fn_name.clone(),\n+            function: Box::new(Function {\n+                params: new_params.clone(),\n+                body: function_body,\n+                span: function_span,\n+                is_async: true,\n+                ..function.take()\n+            }),\n+        }));\n+\n+        // Wrap with $$reactCache__(function foo() { return $$cache__(...) })\n+        let wrapper_fn = wrap_cache_expr(\n+            cache_kind.as_str(),\n+            reference_id.as_str(),\n+            ids_from_closure.len(),\n+            inner_fn,\n+            fn_name.clone(),\n+            function_span,\n+        );\n+\n+        // Create the export: export var $$RSC_SERVER_CACHE_0 = ...\n         self.hoisted_extra_items\n             .push(ModuleItem::ModuleDecl(ModuleDecl::ExportDecl(ExportDecl {\n                 span: DUMMY_SP,\n                 decl: VarDecl {\n-                    span: DUMMY_SP,\n                     kind: VarDeclKind::Var,\n                     decls: vec![VarDeclarator {\n-                        span: function.span,\n+                        span: function_span,\n                         name: Pat::Ident(cache_ident.clone().into()),\n-                        init: Some(wrap_cache_expr(\n-                            Box::new(Expr::Fn(FnExpr {\n-                                ident: fn_name.clone(),\n-                                function: Box::new(Function {\n-                                    params: new_params,\n-                                    ..function.take()\n-                                }),\n-                            })),\n-                            &cache_kind,\n-                            &reference_id,\n-                            ids_from_closure.len(),\n-                        )),\n+                        init: Some(wrapper_fn),\n                         definite: false,\n                     }],\n                     ..Default::default()\n@@ -901,7 +915,7 @@ impl<C: Comments> ServerActions<C> {\n                 expr: Box::new(annotate_ident_as_server_reference(\n                     cache_ident.clone(),\n                     reference_id.clone(),\n-                    function.span,\n+                    function_span,\n                 )),\n             })));\n \n@@ -2049,6 +2063,7 @@ impl<C: Comments> VisitMut for ServerActions<C> {\n         }\n \n         // import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+        // import { cache as $$reactCache__ } from \"react\";\n         if self.has_cache && self.config.is_react_server_layer {\n             new.push(ModuleItem::ModuleDecl(ModuleDecl::Import(ImportDecl {\n                 span: DUMMY_SP,\n@@ -2068,8 +2083,26 @@ impl<C: Comments> VisitMut for ServerActions<C> {\n                 phase: Default::default(),\n             })));\n \n-            // Make it the first item\n-            new.rotate_right(1);\n+            new.push(ModuleItem::ModuleDecl(ModuleDecl::Import(ImportDecl {\n+                span: DUMMY_SP,\n+                specifiers: vec![ImportSpecifier::Named(ImportNamedSpecifier {\n+                    span: DUMMY_SP,\n+                    local: quote_ident!(\"$$reactCache__\").into(),\n+                    imported: Some(quote_ident!(\"cache\").into()),\n+                    is_type_only: false,\n+                })],\n+                src: Box::new(Str {\n+                    span: DUMMY_SP,\n+                    value: atom!(\"react\"),\n+                    raw: None,\n+                }),\n+                type_only: false,\n+                with: None,\n+                phase: Default::default(),\n+            })));\n+\n+            // Make them the first items\n+            new.rotate_right(2);\n         }\n \n         if (self.has_action || self.has_cache) && self.config.is_react_server_layer {\n@@ -2379,24 +2412,64 @@ fn retain_names_from_declared_idents(\n     *child_names = retained_names;\n }\n \n-fn wrap_cache_expr(expr: Box<Expr>, name: &str, id: &str, bound_args_len: usize) -> Box<Expr> {\n-    // expr -> $$cache__(\"name\", \"id\", 0, expr)\n-    Box::new(Expr::Call(CallExpr {\n-        span: DUMMY_SP,\n+fn wrap_cache_expr(\n+    cache_kind: &str,\n+    reference_id: &str,\n+    bound_args_length: usize,\n+    inner_fn: Box<Expr>,\n+    fn_ident: Option<Ident>,\n+    original_span: Span,\n+) -> Box<Expr> {\n+    let cache_call = CallExpr {\n+        span: original_span,\n         callee: quote_ident!(\"$$cache__\").as_callee(),\n         args: vec![\n             ExprOrSpread {\n                 spread: None,\n-                expr: Box::new(name.into()),\n+                expr: Box::new(cache_kind.into()),\n+            },\n+            ExprOrSpread {\n+                spread: None,\n+                expr: Box::new(reference_id.into()),\n+            },\n+            ExprOrSpread {\n+                spread: None,\n+                expr: Box::new(Expr::Lit(Lit::Num(Number {\n+                    span: DUMMY_SP,\n+                    value: bound_args_length as f64,\n+                    raw: None,\n+                }))),\n             },\n+            inner_fn.as_arg(),\n             ExprOrSpread {\n                 spread: None,\n-                expr: Box::new(id.into()),\n+                expr: Box::new(Expr::Ident(private_ident!(DUMMY_SP, \"arguments\"))),\n             },\n-            Number::from(bound_args_len).as_arg(),\n-            expr.as_arg(),\n         ],\n         ..Default::default()\n+    };\n+\n+    // This wrapper function ensures that we have a user-space call stack frame.\n+    let wrapper_fn = Box::new(Expr::Fn(FnExpr {\n+        ident: fn_ident,\n+        function: Box::new(Function {\n+            body: Some(BlockStmt {\n+                span: DUMMY_SP,\n+                stmts: vec![Stmt::Return(ReturnStmt {\n+                    span: DUMMY_SP,\n+                    arg: Some(Box::new(Expr::Call(cache_call))),\n+                })],\n+                ..Default::default()\n+            }),\n+            span: original_span,\n+            ..Default::default()\n+        }),\n+    }));\n+\n+    Box::new(Expr::Call(CallExpr {\n+        callee: quote_ident!(\"$$reactCache__\").as_callee(),\n+        args: vec![wrapper_fn.as_arg()],\n+        ..Default::default()\n     }))\n }\n "
        },
        {
            "sha": "fbc7d67790a2fd91ee2e7c842571744f36b11fe3",
            "filename": "crates/next-custom-transforms/tests/fixture/next-font-with-directive/use-cache/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fnext-font-with-directive%2Fuse-cache%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fnext-font-with-directive%2Fuse-cache%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fnext-font-with-directive%2Fuse-cache%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,10 +1,13 @@\n /* __next_internal_action_entry_do_not_use__ {\"c0dd5bb6fef67f5ab84327f5164ac2c3111a159337\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n import React from 'react';\n import inter from '@next/font/google/target.css?{\"path\":\"app/test.tsx\",\"import\":\"Inter\",\"arguments\":[],\"variableName\":\"inter\"}';\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"c0dd5bb6fef67f5ab84327f5164ac2c3111a159337\", 0, async function Cached({ children }) {\n-    return <div className={inter.className}>{children}</div>;\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function Cached() {\n+    return $$cache__(\"default\", \"c0dd5bb6fef67f5ab84327f5164ac2c3111a159337\", 0, async function Cached({ children }) {\n+        return <div className={inter.className}>{children}</div>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"c0dd5bb6fef67f5ab84327f5164ac2c3111a159337\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "2e19662d526a849a43032f55f044083c3dca2674",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/next.d.ts",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fnext.d.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fnext.d.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fnext.d.ts?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -44,6 +44,7 @@ declare module 'private-next-rsc-cache-wrapper' {\n     kind: string,\n     id: string,\n     boundArgsLength: number,\n-    fn: TFn\n-  ): TFn\n+    fn: TFn,\n+    argsObj: IArguments\n+  ): Promise<any>\n }"
        },
        {
            "sha": "034ece8e19a615aaff3f6f1bb3def3c66c177721",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/33/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F33%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F33%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F33%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,9 +1,12 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n const v = 'world';\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fn() {\n-    return 'hello, ' + v;\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function fn() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fn() {\n+        return 'hello, ' + v;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "2769b42858ad9447d9dccd253537b7667d1fc9ad",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/34/output.js",
            "status": "modified",
            "additions": 17,
            "deletions": 8,
            "changes": 25,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F34%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F34%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F34%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"8012a8d21b6362b4cc8f5b15560525095bc48dba80\":\"$$RSC_SERVER_CACHE_3\",\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\",\"8069348c79fce073bae2f70f139565a2fda1c74c74\":\"$$RSC_SERVER_CACHE_2\",\"80951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {\n-    return 'foo';\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {\n+        return 'foo';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n@@ -11,8 +14,10 @@ Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n });\n const foo = $$RSC_SERVER_CACHE_0;\n export { bar };\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n-    return 'bar';\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function bar() {\n+    return $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n+        return 'bar';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {\n@@ -24,17 +29,21 @@ var bar = $$RSC_SERVER_CACHE_1;\n const qux = async function qux() {\n     return 'qux';\n };\n-export var $$RSC_SERVER_CACHE_2 = $$cache__(\"default\", \"8069348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function baz() {\n-    return qux() + 'baz';\n+export var $$RSC_SERVER_CACHE_2 = $$reactCache__(function baz() {\n+    return $$cache__(\"default\", \"8069348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function baz() {\n+        return qux() + 'baz';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_2, \"8069348c79fce073bae2f70f139565a2fda1c74c74\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_2, \"name\", {\n     value: \"baz\",\n     writable: false\n });\n const baz = $$RSC_SERVER_CACHE_2;\n-export var $$RSC_SERVER_CACHE_3 = $$cache__(\"default\", \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", 0, async function() {\n-    return 'quux';\n+export var $$RSC_SERVER_CACHE_3 = $$reactCache__(function quux() {\n+    return $$cache__(\"default\", \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", 0, async function() {\n+        return 'quux';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_3, \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_3, \"name\", {"
        },
        {
            "sha": "7e482e8c3793778a018e383162d4baa6f30a6827",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/35/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F35%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F35%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F35%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {\n-    return 'data';\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function my_fn() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {\n+        return 'data';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "5c30e24ef6d671709fdc51eb6e7ec96ad8978ca1",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/36/output.js",
            "status": "modified",
            "additions": 17,
            "deletions": 8,
            "changes": 25,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F36%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F36%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F36%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,35 +1,44 @@\n /* __next_internal_action_entry_do_not_use__ {\"8012a8d21b6362b4cc8f5b15560525095bc48dba80\":\"$$RSC_SERVER_CACHE_3\",\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\",\"80951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\",\"c069348c79fce073bae2f70f139565a2fda1c74c74\":\"$$RSC_SERVER_CACHE_2\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n-    return 'data A';\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n+        return 'data A';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n     value: \"foo\",\n     writable: false\n });\n export var foo = $$RSC_SERVER_CACHE_0;\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n-    return 'data B';\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function bar() {\n+    return $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n+        return 'data B';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {\n     value: \"bar\",\n     writable: false\n });\n export var bar = $$RSC_SERVER_CACHE_1;\n-export var $$RSC_SERVER_CACHE_2 = $$cache__(\"default\", \"c069348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function Cached({ children }) {\n-    return children;\n+export var $$RSC_SERVER_CACHE_2 = $$reactCache__(function Cached() {\n+    return $$cache__(\"default\", \"c069348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function Cached({ children }) {\n+        return children;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_2, \"c069348c79fce073bae2f70f139565a2fda1c74c74\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_2, \"name\", {\n     value: \"Cached\",\n     writable: false\n });\n export default $$RSC_SERVER_CACHE_2;\n-export var $$RSC_SERVER_CACHE_3 = $$cache__(\"default\", \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", 0, async function baz() {\n-    return 'data C';\n+export var $$RSC_SERVER_CACHE_3 = $$reactCache__(function baz() {\n+    return $$cache__(\"default\", \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", 0, async function baz() {\n+        return 'data C';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_3, \"8012a8d21b6362b4cc8f5b15560525095bc48dba80\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_3, \"name\", {"
        },
        {
            "sha": "6eb0199d1e85a9eb4d24344cf51efdad9ce786d1",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/37/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F37%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F37%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F37%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fn() {\n-    return 'foo';\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function fn() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fn() {\n+        return 'foo';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "4e7e15e2dc3c63e10302a9c1ee5f354f58f939de",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/38/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F38%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F38%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F38%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"x\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n-    return 'data';\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"x\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n+        return 'data';\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "9d1bf1061be0008238e4737ae0e9d9a70b257d48",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/39/input.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Finput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Finput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Finput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -10,6 +10,6 @@ async function Component({ foo }) {\n   }\n \n   const data = await fn()\n-  // @ts-expect-error: data is not a valid react child\n+  // @ts-ignore: data is not a valid react child\n   return <div>{data}</div>\n }"
        },
        {
            "sha": "b57a82ca6e4574b5252e899952b14d4582c93631",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/39/output.js",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F39%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,11 +1,14 @@\n /* __next_internal_action_entry_do_not_use__ {\"c03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function fn([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n-    console.log($$ACTION_ARG_0);\n-    return {\n-        foo: $$ACTION_ARG_1\n-    };\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function fn() {\n+    return $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function fn([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n+        console.log($$ACTION_ARG_0);\n+        return {\n+            foo: $$ACTION_ARG_1\n+        };\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"c03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n@@ -16,6 +19,6 @@ async function Component({ foo }) {\n     const a = 123;\n     var fn = $$RSC_SERVER_CACHE_0.bind(null, encryptActionBoundArgs(\"c03128060c414d59f8552e4788b846c0d2b7f74743\", a, foo));\n     const data = await fn();\n-    // @ts-expect-error: data is not a valid react child\n+    // @ts-ignore: data is not a valid react child\n     return <div>{data}</div>;\n }"
        },
        {
            "sha": "abce8c606bc8bfa1269c8fc080b063833182a5ff",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/40/output.js",
            "status": "modified",
            "additions": 11,
            "deletions": 8,
            "changes": 19,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F40%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F40%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F40%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,15 +1,18 @@\n /* __next_internal_action_entry_do_not_use__ {\"6090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"e03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n import { Form } from 'components';\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function cache([$$ACTION_ARG_0, $$ACTION_ARG_1], e) {\n-    const f = $$ACTION_ARG_0 + e;\n-    return [\n-        f,\n-        {\n-            a: $$ACTION_ARG_1\n-        }\n-    ];\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function cache() {\n+    return $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function cache([$$ACTION_ARG_0, $$ACTION_ARG_1], e) {\n+        const f = $$ACTION_ARG_0 + e;\n+        return [\n+            f,\n+            {\n+                a: $$ACTION_ARG_1\n+            }\n+        ];\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"e03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "f321824c6d8c8ae8d6eddded588cf229519a9594",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/41/output.js",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F41%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F41%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F41%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,6 +1,7 @@\n /* __next_internal_action_entry_do_not_use__ {\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\":\"$$RSC_SERVER_ACTION_0\",\"c0951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n export const $$RSC_SERVER_ACTION_0 = async function fn($$ACTION_CLOSURE_BOUND) {\n     var [$$ACTION_ARG_0, $$ACTION_ARG_1] = await decryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", $$ACTION_CLOSURE_BOUND);\n     console.log($$ACTION_ARG_0);\n@@ -9,12 +10,14 @@ export const $$RSC_SERVER_ACTION_0 = async function fn($$ACTION_CLOSURE_BOUND) {\n     };\n };\n registerServerReference($$RSC_SERVER_ACTION_0, \"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", null);\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function Component({ foo }) {\n-    const a = 123;\n-    var fn = $$RSC_SERVER_ACTION_0.bind(null, encryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", a, foo));\n-    const data = await fn();\n-    // @ts-expect-error: data is not a valid react child\n-    return <div>{data}</div>;\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function Component() {\n+    return $$cache__(\"default\", \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function Component({ foo }) {\n+        const a = 123;\n+        var fn = $$RSC_SERVER_ACTION_0.bind(null, encryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", a, foo));\n+        const data = await fn();\n+        // @ts-expect-error: data is not a valid react child\n+        return <div>{data}</div>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {"
        },
        {
            "sha": "6cd45bb82972e2fabce981aaa0a8188ce1477561",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/42/input.js",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Finput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Finput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Finput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -10,6 +10,6 @@ async function Component({ foo }) {\n   }\n \n   const data = await fn()\n-  // @ts-expect-error: data is not a valid react child\n+  // @ts-ignore: data is not a valid react child\n   return <div>{data}</div>\n }"
        },
        {
            "sha": "58b929d549c26f2c11e290e24c811b776558e8cf",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/42/output.js",
            "status": "modified",
            "additions": 9,
            "deletions": 6,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F42%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,11 +1,14 @@\n /* __next_internal_action_entry_do_not_use__ {\"c03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n-    console.log($$ACTION_ARG_0);\n-    return {\n-        foo: $$ACTION_ARG_1\n-    };\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function fn() {\n+    return $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n+        console.log($$ACTION_ARG_0);\n+        return {\n+            foo: $$ACTION_ARG_1\n+        };\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"c03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n@@ -16,6 +19,6 @@ async function Component({ foo }) {\n     const a = 123;\n     const fn = $$RSC_SERVER_CACHE_0.bind(null, encryptActionBoundArgs(\"c03128060c414d59f8552e4788b846c0d2b7f74743\", a, foo));\n     const data = await fn();\n-    // @ts-expect-error: data is not a valid react child\n+    // @ts-ignore: data is not a valid react child\n     return <div>{data}</div>;\n }"
        },
        {
            "sha": "9edbf417ade209d133a703c5025cd8cf67fbbcd8",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/43/output.js",
            "status": "modified",
            "additions": 10,
            "deletions": 7,
            "changes": 17,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F43%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F43%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F43%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,20 +1,23 @@\n /* __next_internal_action_entry_do_not_use__ {\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\":\"$$RSC_SERVER_ACTION_0\",\"e0951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n import { Button } from 'components';\n const secret = 'my password is qwerty123';\n export const $$RSC_SERVER_ACTION_0 = async function action($$ACTION_CLOSURE_BOUND) {\n     var [$$ACTION_ARG_0] = await decryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", $$ACTION_CLOSURE_BOUND);\n     console.log(secret, $$ACTION_ARG_0);\n };\n registerServerReference($$RSC_SERVER_ACTION_0, \"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", null);\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"e0951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function getCachedRandom(x, children) {\n-    return {\n-        x,\n-        y: Math.random(),\n-        z: <Button action={$$RSC_SERVER_ACTION_0.bind(null, encryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", x))}/>,\n-        r: children\n-    };\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function getCachedRandom() {\n+    return $$cache__(\"default\", \"e0951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function getCachedRandom(x, children) {\n+        return {\n+            x,\n+            y: Math.random(),\n+            z: <Button action={$$RSC_SERVER_ACTION_0.bind(null, encryptActionBoundArgs(\"406a88810ecce4a4e8b59d53b8327d7e98bbf251d7\", x))}/>,\n+            r: children\n+        };\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"e0951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {"
        },
        {
            "sha": "3490889998b9b3736a27f6e094b7b0f9a7254794",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/45/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F45%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F45%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F45%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,14 +1,17 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n // Expect no error here, this is allowed to be sync because it's not exported.\n function Foo() {\n     const v = Math.random();\n     console.log(v);\n     return v;\n }\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function bar() {\n-    return <Foo/>;\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function bar() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function bar() {\n+        return <Foo/>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "28fb3b653b59f2118086b815e9e7c47bcc573d16",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/46/output.js",
            "status": "modified",
            "additions": 28,
            "deletions": 21,
            "changes": 49,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F46%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F46%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F46%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -3,11 +3,14 @@\n /* __next_internal_action_entry_do_not_use__ {\"6090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"7c9ed0cc47abc4e1c64320cf42b74ae60b58c40f00\":\"$$RSC_SERVER_ACTION_3\",\"7ea9b2939c1f39073a6bed227fd20233064c8b7869\":\"$$RSC_SERVER_ACTION_4\",\"e03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\",\"ff471a5eb0be1c31686dd4ba938a80328b80b1615d\":\"$$RSC_SERVER_CACHE_5\",\"ff69348c79fce073bae2f70f139565a2fda1c74c74\":\"$$RSC_SERVER_CACHE_2\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function f1(a, b) {\n-    return [\n-        a,\n-        b\n-    ];\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function f1() {\n+    return $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function f1(a, b) {\n+        return [\n+            a,\n+            b\n+        ];\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"e03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n@@ -25,12 +28,14 @@ $$RSC_SERVER_ACTION_1 = async function f2(a, b) {\n registerServerReference($$RSC_SERVER_ACTION_1, \"6090b5db271335765a4b0eab01f044b381b5ebd5cd\", null);\n var f2 = $$RSC_SERVER_ACTION_1;\n export var // Should be 1 111111 1, which is \"ff\" in hex.\n-$$RSC_SERVER_CACHE_2 = $$cache__(\"default\", \"ff69348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function f3(a, b, ...rest) {\n-    return [\n-        a,\n-        b,\n-        rest\n-    ];\n+$$RSC_SERVER_CACHE_2 = $$reactCache__(function f3() {\n+    return $$cache__(\"default\", \"ff69348c79fce073bae2f70f139565a2fda1c74c74\", 0, async function f3(a, b, ...rest) {\n+        return [\n+            a,\n+            b,\n+            rest\n+        ];\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_2, \"ff69348c79fce073bae2f70f139565a2fda1c74c74\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_2, \"name\", {\n@@ -64,16 +69,18 @@ $$RSC_SERVER_ACTION_4 = async function f5(a, b, c, d, e, f) {\n registerServerReference($$RSC_SERVER_ACTION_4, \"7ea9b2939c1f39073a6bed227fd20233064c8b7869\", null);\n var f5 = $$RSC_SERVER_ACTION_4;\n export var // Should be 1 111111 1, which is \"ff\" in hex.\n-$$RSC_SERVER_CACHE_5 = $$cache__(\"default\", \"ff471a5eb0be1c31686dd4ba938a80328b80b1615d\", 0, async function f6(a, b, c, d, e, f, g) {\n-    return [\n-        a,\n-        b,\n-        c,\n-        d,\n-        e,\n-        f,\n-        g\n-    ];\n+$$RSC_SERVER_CACHE_5 = $$reactCache__(function f6() {\n+    return $$cache__(\"default\", \"ff471a5eb0be1c31686dd4ba938a80328b80b1615d\", 0, async function f6(a, b, c, d, e, f, g) {\n+        return [\n+            a,\n+            b,\n+            c,\n+            d,\n+            e,\n+            f,\n+            g\n+        ];\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_5, \"ff471a5eb0be1c31686dd4ba938a80328b80b1615d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_5, \"name\", {"
        },
        {
            "sha": "d31c9466056f42fad240fb8dcc8155a2078f660b",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/48/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F48%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F48%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F48%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,6 +1,7 @@\n /* __next_internal_action_entry_do_not_use__ {\"60079087479e4c103d815f273878c7d1b8e902cc39\":\"action3\",\"70f14702b5a021dd117f7ec7a3c838f397c2046d3b\":\"action\",\"7fc18c215a6b7cdc64bf709f3a714ffdef1bf9651d\":\"default\",\"e03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n // Should be 0 111000 0, which is \"70\" in hex.\n export async function action(a, b, c) {\n     return <div>\n@@ -24,11 +25,13 @@ export async function action3(a, b) {\n       {b}\n     </div>;\n }\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function cache(a, b) {\n-    return <div>\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function cache() {\n+    return $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function cache(a, b) {\n+        return <div>\n       {a}\n       {b}\n     </div>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"e03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "00e5933aebabedfa65448c58aeb4159913581b94",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/49/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F49%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F49%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F49%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,12 +1,15 @@\n /* __next_internal_action_entry_do_not_use__ {\"f03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"f03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function(a, b, c) {\n-    return <div>\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function() {\n+    return $$cache__(\"default\", \"f03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function(a, b, c) {\n+        return <div>\n       {a}\n       {b}\n       {c}\n     </div>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"f03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n export default $$RSC_SERVER_CACHE_0;"
        },
        {
            "sha": "4cb2c9e527ba2af77cb17ee2bd1d1539d6b4bd19",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/50/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F50%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F50%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F50%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,12 +1,15 @@\n /* __next_internal_action_entry_do_not_use__ {\"f03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"f03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function(a, b, c) {\n-    return <div>\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function() {\n+    return $$cache__(\"default\", \"f03128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function(a, b, c) {\n+        return <div>\n       {a}\n       {b}\n       {c}\n     </div>;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"f03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "590b8b263f69b1a142f4b75b542a0c9e0058ab2b",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/52/output.js",
            "status": "modified",
            "additions": 13,
            "deletions": 8,
            "changes": 21,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F52%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F52%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F52%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,19 +1,26 @@\n /* __next_internal_action_entry_do_not_use__ {\"409ed0cc47abc4e1c64320cf42b74ae60b58c40f00\":\"$$RSC_SERVER_ACTION_3\",\"601c36b06e398c97abe5d5d7ae8c672bfddf4e1b91\":\"$$RSC_SERVER_ACTION_2\",\"c0951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\",\"e03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n import { Client } from 'components';\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function([$$ACTION_ARG_0, $$ACTION_ARG_1], c) {\n-    return $$ACTION_ARG_0 + $$ACTION_ARG_1 + c;\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function // Should be 1 110000 0, which is \"e0\" in hex (counts as two params,\n+// because of the encrypted bound args param)\n+fn1() {\n+    return $$cache__(\"default\", \"e03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function([$$ACTION_ARG_0, $$ACTION_ARG_1], c) {\n+        return $$ACTION_ARG_0 + $$ACTION_ARG_1 + c;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"e03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n     value: \"fn1\",\n     writable: false\n });\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", 2, async function // Should be 1 100000 0, which is \"c0\" in hex (counts as one param,\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function // Should be 1 100000 0, which is \"c0\" in hex (counts as one param,\n // because of the encrypted bound args param)\n-fn2([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n-    return $$ACTION_ARG_0 + $$ACTION_ARG_1;\n+fn2() {\n+    return $$cache__(\"default\", \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", 2, async function fn2([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n+        return $$ACTION_ARG_0 + $$ACTION_ARG_1;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {\n@@ -36,7 +43,5 @@ fn4($$ACTION_CLOSURE_BOUND) {\n registerServerReference($$RSC_SERVER_ACTION_3, \"409ed0cc47abc4e1c64320cf42b74ae60b58c40f00\", null);\n export async function Component(a) {\n     const b = 1;\n-    return <Client // Should be 1 110000 0, which is \"e0\" in hex (counts as two params,\n-    // because of the encrypted bound args param)\n-    fn1={$$RSC_SERVER_CACHE_0.bind(null, encryptActionBoundArgs(\"e03128060c414d59f8552e4788b846c0d2b7f74743\", a, b))} fn2={$$RSC_SERVER_CACHE_1.bind(null, encryptActionBoundArgs(\"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", a, b))} fn3={$$RSC_SERVER_ACTION_2.bind(null, encryptActionBoundArgs(\"601c36b06e398c97abe5d5d7ae8c672bfddf4e1b91\", a, b))} fn4={$$RSC_SERVER_ACTION_3.bind(null, encryptActionBoundArgs(\"409ed0cc47abc4e1c64320cf42b74ae60b58c40f00\", a, b))}/>;\n+    return <Client fn1={$$RSC_SERVER_CACHE_0.bind(null, encryptActionBoundArgs(\"e03128060c414d59f8552e4788b846c0d2b7f74743\", a, b))} fn2={$$RSC_SERVER_CACHE_1.bind(null, encryptActionBoundArgs(\"c0951c375b4a6a6e89d67b743ec5808127cfde405d\", a, b))} fn3={$$RSC_SERVER_ACTION_2.bind(null, encryptActionBoundArgs(\"601c36b06e398c97abe5d5d7ae8c672bfddf4e1b91\", a, b))} fn4={$$RSC_SERVER_ACTION_3.bind(null, encryptActionBoundArgs(\"409ed0cc47abc4e1c64320cf42b74ae60b58c40f00\", a, b))}/>;\n }"
        },
        {
            "sha": "ee66e902ca24de26516b448bf16c4c9b34a4d6b5",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/53/output.js",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F53%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F53%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F53%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,7 +1,10 @@\n /* __next_internal_action_entry_do_not_use__ {\"0090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {});\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {}, arguments);\n+});\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n     value: \"foo\","
        },
        {
            "sha": "96fa538edb9baf567897cfc50284559e1b0675b4",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/54/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F54%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F54%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F54%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"4090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"c03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function foo([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n-    return $$ACTION_ARG_0 * $$ACTION_ARG_1;\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 2, async function foo([$$ACTION_ARG_0, $$ACTION_ARG_1]) {\n+        return $$ACTION_ARG_0 * $$ACTION_ARG_1;\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"c03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "ff89475d384568954eef4219af4d9ce83c8ba561",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/55/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F55%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F55%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F55%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fetch1() {\n-    return fetch('https://example.com').then((res)=>res.json());\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function fetch1() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function fetch1() {\n+        return fetch('https://example.com').then((res)=>res.json());\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "8701b04e1406868d99182a7a8e98d234f8e07ec1",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/57/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F57%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F57%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F57%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"0090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n-    return fetch('https://example.com').then((res)=>res.json());\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function foo() {\n+        return fetch('https://example.com').then((res)=>res.json());\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {"
        },
        {
            "sha": "506feeabef654d24d5c90b9c808b662a8153966e",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/58/output.js",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F58%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F58%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F58%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,8 +1,11 @@\n /* __next_internal_action_entry_do_not_use__ {\"4090b5db271335765a4b0eab01f044b381b5ebd5cd\":\"$$RSC_SERVER_ACTION_1\",\"c03128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 1, async function([$$ACTION_ARG_0]) {\n-    return $$ACTION_ARG_0();\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function() {\n+    return $$cache__(\"default\", \"c03128060c414d59f8552e4788b846c0d2b7f74743\", 1, async function([$$ACTION_ARG_0]) {\n+        return $$ACTION_ARG_0();\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_0, \"c03128060c414d59f8552e4788b846c0d2b7f74743\", null);\n function createCachedFn(start) {"
        },
        {
            "sha": "cd68086d2e41473fa111adb3db0f3f11e118f49c",
            "filename": "crates/next-custom-transforms/tests/fixture/server-actions/server-graph/60/output.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F60%2Foutput.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F60%2Foutput.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fserver-actions%2Fserver-graph%2F60%2Foutput.ts?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,6 +1,7 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n+import { cache as $$reactCache__ } from \"react\";\n // Exported TypeScript nodes should be ignored when validating that all module\n // exports are async functions.\n export type T = {\n@@ -11,7 +12,9 @@ export enum E {\n }\n export default interface D {\n }\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function Page() {});\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function Page() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function Page() {}, arguments);\n+});\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n     value: \"Page\","
        },
        {
            "sha": "86580137134d07defd4b71483b485fcebe328f87",
            "filename": "crates/next-custom-transforms/tests/fixture/source-maps/server-graph/use-cache/1/output.js",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.js",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.js",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.js?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1,15 +1,20 @@\n /* __next_internal_action_entry_do_not_use__ {\"803128060c414d59f8552e4788b846c0d2b7f74743\":\"$$RSC_SERVER_CACHE_0\",\"80951c375b4a6a6e89d67b743ec5808127cfde405d\":\"$$RSC_SERVER_CACHE_1\"} */ import { registerServerReference } from \"private-next-rsc-server-reference\";\n import { encryptActionBoundArgs, decryptActionBoundArgs } from \"private-next-rsc-action-encryption\";\n import { cache as $$cache__ } from \"private-next-rsc-cache-wrapper\";\n-export var $$RSC_SERVER_CACHE_0 = $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {});\n+import { cache as $$reactCache__ } from \"react\";\n+export var $$RSC_SERVER_CACHE_0 = $$reactCache__(function foo() {\n+    return $$cache__(\"default\", \"803128060c414d59f8552e4788b846c0d2b7f74743\", 0, async function() {}, arguments);\n+});\n registerServerReference($$RSC_SERVER_CACHE_0, \"803128060c414d59f8552e4788b846c0d2b7f74743\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_0, \"name\", {\n     value: \"foo\",\n     writable: false\n });\n const foo = $$RSC_SERVER_CACHE_0;\n-export var $$RSC_SERVER_CACHE_1 = $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n-    return foo();\n+export var $$RSC_SERVER_CACHE_1 = $$reactCache__(function bar() {\n+    return $$cache__(\"default\", \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", 0, async function bar() {\n+        return foo();\n+    }, arguments);\n });\n registerServerReference($$RSC_SERVER_CACHE_1, \"80951c375b4a6a6e89d67b743ec5808127cfde405d\", null);\n Object[\"defineProperty\"]($$RSC_SERVER_CACHE_1, \"name\", {"
        },
        {
            "sha": "d11f5cc559c35613c55705743e81d7207623f54a",
            "filename": "crates/next-custom-transforms/tests/fixture/source-maps/server-graph/use-cache/1/output.map",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.map",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.map",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-custom-transforms%2Ftests%2Ffixture%2Fsource-maps%2Fserver-graph%2Fuse-cache%2F1%2Foutput.map?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -1 +1 @@\n-{\"version\":3,\"sources\":[\"input.js\"],\"sourcesContent\":[\"'use cache'\\n\\nconst foo = async () => {\\n  'use cache'\\n}\\n\\nexport async function bar() {\\n  return foo()\\n}\\n\"],\"names\":[],\"mappings\":\";;;WAEY,+GAEZ;AAFY;;;;;AAAZ,MAAM;WAIC,6FAAA,eAAe;IACpB,OAAO;AACT;;;;;;AAFA,WAAsB\"}\n+{\"version\":3,\"sources\":[\"input.js\"],\"sourcesContent\":[\"'use cache'\\n\\nconst foo = async () => {\\n  'use cache'\\n}\\n\\nexport async function bar() {\\n  return foo()\\n}\\n\"],\"names\":[],\"mappings\":\";;;;WAEY,sCAAA,SAAN;WAAM,sEAAA,kBAEZ;;AAFY;;;;;AAAZ,MAAM;WAIC,sCAAA,SAAe;WAAf,sEAAA,eAAe;QACpB,OAAO;IACT;;AAFO;;;;;AAAP,WAAsB\"}"
        },
        {
            "sha": "5105a44945f4e506735ba7d9b8ba3fb90206f352",
            "filename": "packages/next/src/server/use-cache/use-cache-wrapper.ts",
            "status": "modified",
            "additions": 750,
            "deletions": 774,
            "changes": 1524,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -66,7 +66,6 @@ import {\n   type SearchParams,\n } from '../request/search-params'\n import type { Params } from '../request/params'\n-import React from 'react'\n import { createLazyResult, isResolvedLazyResult } from '../lib/lazy-result'\n import { dynamicAccessAsyncStorage } from '../app-render/dynamic-access-async-storage.external'\n import { isReactLargeShellError } from '../app-render/react-large-shell-error'\n@@ -138,7 +137,7 @@ function generateCacheEntry(\n   clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n   encodedArguments: FormData | string,\n   fn: (...args: unknown[]) => Promise<unknown>,\n-  sharedErrorStack: string | undefined\n+  timeoutError: UseCacheTimeoutError\n ) {\n   // We need to run this inside a clean AsyncLocalStorage snapshot so that the cache\n   // generation cannot read anything from the context we're currently executing which\n@@ -152,7 +151,7 @@ function generateCacheEntry(\n     clientReferenceManifest,\n     encodedArguments,\n     fn,\n-    sharedErrorStack\n+    timeoutError\n   )\n }\n \n@@ -162,7 +161,7 @@ function generateCacheEntryWithRestoredWorkStore(\n   clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n   encodedArguments: FormData | string,\n   fn: (...args: unknown[]) => Promise<unknown>,\n-  sharedErrorStack: string | undefined\n+  timeoutError: UseCacheTimeoutError\n ) {\n   // Since we cleared the AsyncLocalStorage we need to restore the workStore.\n   // Note: We explicitly don't restore the RequestStore nor the PrerenderStore.\n@@ -179,7 +178,7 @@ function generateCacheEntryWithRestoredWorkStore(\n     clientReferenceManifest,\n     encodedArguments,\n     fn,\n-    sharedErrorStack\n+    timeoutError\n   )\n }\n \n@@ -285,7 +284,7 @@ function generateCacheEntryWithCacheContext(\n   clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n   encodedArguments: FormData | string,\n   fn: (...args: unknown[]) => Promise<unknown>,\n-  sharedErrorStack: string | undefined\n+  timeoutError: UseCacheTimeoutError\n ) {\n   if (!workStore.cacheLifeProfiles) {\n     throw new InvariantError('cacheLifeProfiles should always be provided.')\n@@ -310,7 +309,7 @@ function generateCacheEntryWithCacheContext(\n       clientReferenceManifest,\n       encodedArguments,\n       fn,\n-      sharedErrorStack\n+      timeoutError\n     )\n   )\n }\n@@ -525,7 +524,7 @@ async function generateCacheEntryImpl(\n   clientReferenceManifest: DeepReadonly<ClientReferenceManifestForRsc>,\n   encodedArguments: FormData | string,\n   fn: (...args: unknown[]) => Promise<unknown>,\n-  sharedErrorStack: string | undefined\n+  timeoutError: UseCacheTimeoutError\n ): Promise<GenerateCacheEntryResult> {\n   const temporaryReferences = createServerTemporaryReferenceSet()\n   const outerWorkUnitStore = cacheContext.outerWorkUnitStore\n@@ -631,12 +630,8 @@ async function generateCacheEntryImpl(\n       // Otherwise we assume you stalled on hanging input and de-opt. This needs\n       // to be lower than just the general timeout of 60 seconds.\n       const timer = setTimeout(() => {\n-        const error = new UseCacheTimeoutError()\n-        if (sharedErrorStack) {\n-          error.stack = error.name + ': ' + error.message + sharedErrorStack\n-        }\n-        workStore.invalidDynamicUsageError = error\n-        timeoutAbortController.abort(error)\n+        workStore.invalidDynamicUsageError = timeoutError\n+        timeoutAbortController.abort(timeoutError)\n       }, 50000)\n \n       const dynamicAccessAbortSignal =\n@@ -689,7 +684,7 @@ async function generateCacheEntryImpl(\n         const hangingPromise = makeHangingPromise<never>(\n           outerWorkUnitStore.renderSignal,\n           workStore.route,\n-          abortSignal.reason\n+          'dynamic \"use cache\"'\n         )\n \n         if (outerWorkUnitStore.cacheSignal) {\n@@ -830,26 +825,15 @@ function createTrackedReadableStream(\n   })\n }\n \n-function wrapAsInvalidDynamicUsageError(\n-  error: Error,\n-  sharedErrorStack: string | undefined,\n-  workStore: WorkStore\n-) {\n-  if (sharedErrorStack) {\n-    error.stack = error.name + ': ' + error.message + sharedErrorStack\n-  }\n-\n-  workStore.invalidDynamicUsageError ??= error\n-\n-  return error\n-}\n-\n-export function cache(\n+export async function cache(\n   kind: string,\n   id: string,\n   boundArgsLength: number,\n-  originalFn: (...args: unknown[]) => Promise<unknown>\n+  originalFn: (...args: unknown[]) => Promise<unknown>,\n+  argsObj: IArguments\n ) {\n+  let args = Array.prototype.slice.call(argsObj)\n+\n   const isPrivate = kind === 'private'\n \n   // Private caches are currently only stored in the Resume Data Cache (RDC),\n@@ -860,635 +844,409 @@ export function cache(\n     throw new Error('Unknown cache handler: ' + kind)\n   }\n \n-  // Capture a better error stack in this scope.\n-  const sharedError = new Error()\n-  Error.captureStackTrace(sharedError, cache)\n-  const sharedErrorStack = sharedError.stack?.slice(\n-    sharedError.stack.indexOf('\\n')\n-  )\n+  const timeoutError = new UseCacheTimeoutError()\n+  Error.captureStackTrace(timeoutError, cache)\n \n-  const name = originalFn.name\n-  const cachedFn = {\n-    [name]: async function (...args: any[]) {\n-      const workStore = workAsyncStorage.getStore()\n-      if (workStore === undefined) {\n-        throw new Error(\n-          '\"use cache\" cannot be used outside of App Router. Expected a WorkStore.'\n-        )\n-      }\n+  const wrapAsInvalidDynamicUsageError = (\n+    error: Error,\n+    workStore: WorkStore\n+  ) => {\n+    Error.captureStackTrace(error, cache)\n+    workStore.invalidDynamicUsageError ??= error\n \n-      let fn = originalFn\n+    return error\n+  }\n \n-      const workUnitStore = workUnitAsyncStorage.getStore()\n+  const workStore = workAsyncStorage.getStore()\n+  if (workStore === undefined) {\n+    throw new Error(\n+      '\"use cache\" cannot be used outside of App Router. Expected a WorkStore.'\n+    )\n+  }\n \n-      let cacheContext: CacheContext\n+  const workUnitStore = workUnitAsyncStorage.getStore()\n+  const name = originalFn.name\n+  let fn = originalFn\n+  let cacheContext: CacheContext\n \n-      if (isPrivate) {\n-        const expression = '\"use cache: private\"'\n+  if (isPrivate) {\n+    const expression = '\"use cache: private\"'\n \n-        switch (workUnitStore?.type) {\n-          // \"use cache: private\" is dynamic in prerendering contexts.\n-          case 'prerender':\n-            return makeHangingPromise(\n-              workUnitStore.renderSignal,\n-              workStore.route,\n-              expression\n-            )\n-          case 'prerender-ppr':\n-            return postponeWithTracking(\n-              workStore.route,\n-              expression,\n-              workUnitStore.dynamicTracking\n-            )\n-          case 'prerender-legacy':\n-            return throwToInterruptStaticGeneration(\n-              expression,\n-              workStore,\n-              workUnitStore\n-            )\n-          case 'prerender-client':\n-            throw new InvariantError(\n-              `${expression} must not be used within a client component. Next.js should be preventing ${expression} from being allowed in client components statically, but did not in this case.`\n-            )\n-          case 'unstable-cache': {\n-            throw wrapAsInvalidDynamicUsageError(\n-              new Error(\n-                // TODO: Add a link to an error documentation page when we have one.\n-                `${expression} must not be used within \\`unstable_cache()\\`.`\n-              ),\n-              sharedErrorStack,\n-              workStore\n-            )\n-          }\n-          case 'cache': {\n-            throw wrapAsInvalidDynamicUsageError(\n-              new Error(\n-                // TODO: Add a link to an error documentation page when we have one.\n-                `${expression} must not be used within \"use cache\". It can only be nested inside of another ${expression}.`\n-              ),\n-              sharedErrorStack,\n-              workStore\n-            )\n-          }\n-          case 'request':\n-          case 'prerender-runtime':\n-          case 'private-cache':\n-            cacheContext = {\n-              kind: 'private',\n-              outerWorkUnitStore: workUnitStore,\n-            }\n-            break\n-          case undefined:\n-            throw wrapAsInvalidDynamicUsageError(\n-              new Error(\n-                // TODO: Add a link to an error documentation page when we have one.\n-                `${expression} cannot be used outside of a request context.`\n-              ),\n-              sharedErrorStack,\n-              workStore\n-            )\n-          default:\n-            workUnitStore satisfies never\n-            // This is dead code, but without throwing an error here, TypeScript\n-            // will assume that cacheContext is used before being assigned.\n-            throw new InvariantError(`Unexpected work unit store.`)\n-        }\n-      } else {\n-        switch (workUnitStore?.type) {\n-          case 'prerender-client':\n-            const expression = '\"use cache\"'\n-            throw new InvariantError(\n-              `${expression} must not be used within a client component. Next.js should be preventing ${expression} from being allowed in client components statically, but did not in this case.`\n-            )\n-          case 'prerender':\n-          case 'prerender-runtime':\n-          case 'prerender-ppr':\n-          case 'prerender-legacy':\n-          case 'request':\n-          case 'cache':\n-          case 'private-cache':\n-          // TODO: We should probably forbid nesting \"use cache\" inside\n-          // unstable_cache. (fallthrough)\n-          case 'unstable-cache':\n-          case undefined:\n-            cacheContext = {\n-              kind: 'public',\n-              outerWorkUnitStore: workUnitStore,\n-            }\n-            break\n-          default:\n-            workUnitStore satisfies never\n-            // This is dead code, but without throwing an error here, TypeScript\n-            // will assume that cacheContext is used before being assigned.\n-            throw new InvariantError(`Unexpected work unit store.`)\n-        }\n+    switch (workUnitStore?.type) {\n+      // \"use cache: private\" is dynamic in prerendering contexts.\n+      case 'prerender':\n+        return makeHangingPromise(\n+          workUnitStore.renderSignal,\n+          workStore.route,\n+          expression\n+        )\n+      case 'prerender-ppr':\n+        return postponeWithTracking(\n+          workStore.route,\n+          expression,\n+          workUnitStore.dynamicTracking\n+        )\n+      case 'prerender-legacy':\n+        return throwToInterruptStaticGeneration(\n+          expression,\n+          workStore,\n+          workUnitStore\n+        )\n+      case 'prerender-client':\n+        throw new InvariantError(\n+          `${expression} must not be used within a client component. Next.js should be preventing ${expression} from being allowed in client components statically, but did not in this case.`\n+        )\n+      case 'unstable-cache': {\n+        throw wrapAsInvalidDynamicUsageError(\n+          new Error(\n+            // TODO: Add a link to an error documentation page when we have one.\n+            `${expression} must not be used within \\`unstable_cache()\\`.`\n+          ),\n+          workStore\n+        )\n       }\n-\n-      // Get the clientReferenceManifest while we're still in the outer Context.\n-      // In case getClientReferenceManifestSingleton is implemented using AsyncLocalStorage.\n-      const clientReferenceManifest = getClientReferenceManifestForRsc()\n-\n-      // Because the Action ID is not yet unique per implementation of that Action we can't\n-      // safely reuse the results across builds yet. In the meantime we add the buildId to the\n-      // arguments as a seed to ensure they're not reused. Remove this once Action IDs hash\n-      // the implementation.\n-      const buildId = workStore.buildId\n-\n-      // In dev mode, when the HMR refresh hash is set, we include it in the\n-      // cache key. This ensures that cache entries are not reused when server\n-      // components have been edited. This is a very coarse approach. But it's\n-      // also only a temporary solution until Action IDs are unique per\n-      // implementation. Remove this once Action IDs hash the implementation.\n-      const hmrRefreshHash =\n-        workUnitStore && getHmrRefreshHash(workStore, workUnitStore)\n-\n-      const hangingInputAbortSignal = workUnitStore\n-        ? createHangingInputAbortSignal(workUnitStore)\n-        : undefined\n-\n-      if (cacheContext.kind === 'private') {\n-        const { outerWorkUnitStore } = cacheContext\n-        switch (outerWorkUnitStore.type) {\n-          case 'prerender-runtime': {\n-            // In a runtime prerender, we have to make sure that APIs that would hang during a static prerender\n-            // are resolved with a delay, in the runtime stage. Private caches are one of these.\n-            if (outerWorkUnitStore.runtimeStagePromise) {\n-              await outerWorkUnitStore.runtimeStagePromise\n-            }\n-            break\n-          }\n-          case 'request': {\n-            if (process.env.NODE_ENV === 'development') {\n-              // Similar to runtime prerenders, private caches should not resolve in the static stage\n-              // of a dev request, so we delay them.\n-              await makeDevtoolsIOAwarePromise(\n-                undefined,\n-                outerWorkUnitStore,\n-                RenderStage.Runtime\n-              )\n-            }\n-            break\n-          }\n-          case 'private-cache':\n-            break\n-          default: {\n-            outerWorkUnitStore satisfies never\n-          }\n-        }\n+      case 'cache': {\n+        throw wrapAsInvalidDynamicUsageError(\n+          new Error(\n+            // TODO: Add a link to an error documentation page when we have one.\n+            `${expression} must not be used within \"use cache\". It can only be nested inside of another ${expression}.`\n+          ),\n+          workStore\n+        )\n       }\n-\n-      let isPageOrLayoutSegmentFunction = false\n-\n-      // For page and layout segment functions (i.e. the page/layout component,\n-      // or generateMetadata/generateViewport), the cache function is\n-      // overwritten, which allows us to apply special handling for params and\n-      // searchParams. For pages and layouts we're using the outer params prop,\n-      // and not the inner one that was serialized/deserialized. While it's not\n-      // generally true for \"use cache\" args, in the case of `params` the inner\n-      // and outer object are essentially equivalent, so this is safe to do\n-      // (including fallback params that are hanging promises). It allows us to\n-      // avoid waiting for the timeout, when prerendering a fallback shell of a\n-      // cached page or layout that awaits params.\n-      if (isPageSegmentFunction(args)) {\n-        isPageOrLayoutSegmentFunction = true\n-\n-        const [\n-          { params: outerParams, searchParams: outerSearchParams },\n-          ...otherOuterArgs\n-        ] = args\n-\n-        const props: UseCachePageInnerProps = {\n-          params: outerParams,\n-          // Omit searchParams and $$isPage.\n-        }\n-\n-        if (isPrivate) {\n-          // Private caches allow accessing search params. We need to include\n-          // them in the serialized args and when generating the cache key.\n-          props.searchParams = outerSearchParams\n+      case 'request':\n+      case 'prerender-runtime':\n+      case 'private-cache':\n+        cacheContext = {\n+          kind: 'private',\n+          outerWorkUnitStore: workUnitStore,\n         }\n-\n-        args = [props, ...otherOuterArgs]\n-\n-        fn = {\n-          [name]: async (\n-            {\n-              params: _innerParams,\n-              searchParams: innerSearchParams,\n-            }: UseCachePageInnerProps,\n-            ...otherInnerArgs: unknown[]\n-          ) =>\n-            originalFn.apply(null, [\n-              {\n-                params: outerParams,\n-                searchParams:\n-                  innerSearchParams ??\n-                  // For public caches, search params are omitted from the cache\n-                  // key (and the serialized args) to avoid mismatches between\n-                  // prerendering and resuming a cached page that does not\n-                  // access search params. This is also the reason why we're not\n-                  // using a hanging promise for search params. For cached pages\n-                  // that do access them, which is an invalid dynamic usage, we\n-                  // need to ensure that an error is shown.\n-                  makeErroringSearchParamsForUseCache(workStore),\n-              },\n-              ...otherInnerArgs,\n-            ]),\n-        }[name] as (...args: unknown[]) => Promise<unknown>\n-      } else if (isLayoutSegmentFunction(args)) {\n-        isPageOrLayoutSegmentFunction = true\n-\n-        const [\n-          { params: outerParams, $$isLayout, ...outerSlots },\n-          ...otherOuterArgs\n-        ] = args\n-\n-        // Overwrite the props to omit $$isLayout. Note that slots are only\n-        // passed to the layout component (if any are defined), and not to\n-        // generateMetadata nor generateViewport. For those functions,\n-        // outerSlots/innerSlots is an empty object, which is fine because we're\n-        // just spreading it into the props.\n-        args = [{ params: outerParams, ...outerSlots }, ...otherOuterArgs]\n-\n-        fn = {\n-          [name]: async (\n-            {\n-              params: _innerParams,\n-              ...innerSlots\n-            }: Omit<UseCacheLayoutProps, '$$isLayout'>,\n-            ...otherInnerArgs: unknown[]\n-          ) =>\n-            originalFn.apply(null, [\n-              { params: outerParams, ...innerSlots },\n-              ...otherInnerArgs,\n-            ]),\n-        }[name] as (...args: unknown[]) => Promise<unknown>\n-      }\n-\n-      if (boundArgsLength > 0) {\n-        if (args.length === 0) {\n-          throw new InvariantError(\n-            `Expected the \"use cache\" function ${JSON.stringify(fn.name)} to receive its encrypted bound arguments as the first argument.`\n-          )\n+        break\n+      case undefined:\n+        throw wrapAsInvalidDynamicUsageError(\n+          new Error(\n+            // TODO: Add a link to an error documentation page when we have one.\n+            `${expression} cannot be used outside of a request context.`\n+          ),\n+          workStore\n+        )\n+      default:\n+        workUnitStore satisfies never\n+        // This is dead code, but without throwing an error here, TypeScript\n+        // will assume that cacheContext is used before being assigned.\n+        throw new InvariantError(`Unexpected work unit store.`)\n+    }\n+  } else {\n+    switch (workUnitStore?.type) {\n+      case 'prerender-client':\n+        const expression = '\"use cache\"'\n+        throw new InvariantError(\n+          `${expression} must not be used within a client component. Next.js should be preventing ${expression} from being allowed in client components statically, but did not in this case.`\n+        )\n+      case 'prerender':\n+      case 'prerender-runtime':\n+      case 'prerender-ppr':\n+      case 'prerender-legacy':\n+      case 'request':\n+      case 'cache':\n+      case 'private-cache':\n+      // TODO: We should probably forbid nesting \"use cache\" inside\n+      // unstable_cache. (fallthrough)\n+      case 'unstable-cache':\n+      case undefined:\n+        cacheContext = {\n+          kind: 'public',\n+          outerWorkUnitStore: workUnitStore,\n         }\n+        break\n+      default:\n+        workUnitStore satisfies never\n+        // This is dead code, but without throwing an error here, TypeScript\n+        // will assume that cacheContext is used before being assigned.\n+        throw new InvariantError(`Unexpected work unit store.`)\n+    }\n+  }\n \n-        const encryptedBoundArgs = args.shift()\n-        const boundArgs = await decryptActionBoundArgs(id, encryptedBoundArgs)\n+  // Get the clientReferenceManifest while we're still in the outer Context.\n+  // In case getClientReferenceManifestSingleton is implemented using AsyncLocalStorage.\n+  const clientReferenceManifest = getClientReferenceManifestForRsc()\n+\n+  // Because the Action ID is not yet unique per implementation of that Action we can't\n+  // safely reuse the results across builds yet. In the meantime we add the buildId to the\n+  // arguments as a seed to ensure they're not reused. Remove this once Action IDs hash\n+  // the implementation.\n+  const buildId = workStore.buildId\n+\n+  // In dev mode, when the HMR refresh hash is set, we include it in the\n+  // cache key. This ensures that cache entries are not reused when server\n+  // components have been edited. This is a very coarse approach. But it's\n+  // also only a temporary solution until Action IDs are unique per\n+  // implementation. Remove this once Action IDs hash the implementation.\n+  const hmrRefreshHash =\n+    workUnitStore && getHmrRefreshHash(workStore, workUnitStore)\n+\n+  const hangingInputAbortSignal = workUnitStore\n+    ? createHangingInputAbortSignal(workUnitStore)\n+    : undefined\n \n-        if (!Array.isArray(boundArgs)) {\n-          throw new InvariantError(\n-            `Expected the bound arguments of \"use cache\" function ${JSON.stringify(fn.name)} to deserialize into an array, got ${typeof boundArgs} instead.`\n-          )\n+  if (cacheContext.kind === 'private') {\n+    const { outerWorkUnitStore } = cacheContext\n+    switch (outerWorkUnitStore.type) {\n+      case 'prerender-runtime': {\n+        // In a runtime prerender, we have to make sure that APIs that would hang during a static prerender\n+        // are resolved with a delay, in the runtime stage. Private caches are one of these.\n+        if (outerWorkUnitStore.runtimeStagePromise) {\n+          await outerWorkUnitStore.runtimeStagePromise\n         }\n-\n-        if (boundArgsLength !== boundArgs.length) {\n-          throw new InvariantError(\n-            `Expected the \"use cache\" function ${JSON.stringify(fn.name)} to receive ${boundArgsLength} bound arguments, got ${boundArgs.length} instead.`\n+        break\n+      }\n+      case 'request': {\n+        if (process.env.NODE_ENV === 'development') {\n+          // Similar to runtime prerenders, private caches should not resolve in the static stage\n+          // of a dev request, so we delay them.\n+          await makeDevtoolsIOAwarePromise(\n+            undefined,\n+            outerWorkUnitStore,\n+            RenderStage.Runtime\n           )\n         }\n-\n-        args.unshift(boundArgs)\n+        break\n       }\n-\n-      const temporaryReferences = createClientTemporaryReferenceSet()\n-\n-      // For private caches, which are allowed to read cookies, we still don't\n-      // need to include the cookies in the cache key. This is because we don't\n-      // store the cache entries in a cache handler, but only in the Resume Data\n-      // Cache (RDC). Private caches are only used during dynamic requests and\n-      // runtime prefetches. For dynamic requests, the RDC is immutable, so it\n-      // does not include any private caches. For runtime prefetches, the RDC is\n-      // mutable, but only lives as long as the request, so the key does not\n-      // need to include cookies.\n-      const cacheKeyParts: CacheKeyParts = hmrRefreshHash\n-        ? [buildId, id, args, hmrRefreshHash]\n-        : [buildId, id, args]\n-\n-      const encodeCacheKeyParts = () =>\n-        encodeReply(cacheKeyParts, {\n-          temporaryReferences,\n-          signal: hangingInputAbortSignal,\n-        })\n-\n-      let encodedCacheKeyParts: FormData | string\n-\n-      switch (workUnitStore?.type) {\n-        case 'prerender-runtime':\n-        // We're currently only using `dynamicAccessAsyncStorage` for params,\n-        // which are always available in a runtime prerender, so they will never hang,\n-        // effectively making the tracking below a no-op.\n-        // However, a runtime prerender shares a lot of the semantics with a static prerender,\n-        // and might need to follow this codepath in the future\n-        // if we start using `dynamicAccessAsyncStorage` for other APIs.\n-        //\n-        // fallthrough\n-        case 'prerender':\n-          if (!isPageOrLayoutSegmentFunction) {\n-            // If the \"use cache\" function is not a page or layout segment\n-            // function, we need to track dynamic access already when encoding\n-            // the arguments. If params are passed explicitly into a \"use cache\"\n-            // function (as opposed to receiving them automatically in a page or\n-            // layout), we assume that the params are also accessed. This allows\n-            // us to abort early, and treat the function as dynamic, instead of\n-            // waiting for the timeout to be reached.\n-            const dynamicAccessAbortController = new AbortController()\n-\n-            encodedCacheKeyParts = await dynamicAccessAsyncStorage.run(\n-              { abortController: dynamicAccessAbortController },\n-              encodeCacheKeyParts\n-            )\n-\n-            if (dynamicAccessAbortController.signal.aborted) {\n-              return makeHangingPromise(\n-                workUnitStore.renderSignal,\n-                workStore.route,\n-                dynamicAccessAbortController.signal.reason.message\n-              )\n-            }\n-            break\n-          }\n-        // fallthrough\n-        case 'prerender-ppr':\n-        case 'prerender-legacy':\n-        case 'request':\n-        // TODO(restart-on-cache-miss): We need to handle params/searchParams on page components.\n-        // the promises will be tasky, so `encodeCacheKeyParts` will not resolve in the static stage.\n-        // We have not started a cache read at this point, so we might just miss the cache completely.\n-        // fallthrough\n-        case 'cache':\n-        case 'private-cache':\n-        case 'unstable-cache':\n-        case undefined:\n-          encodedCacheKeyParts = await encodeCacheKeyParts()\n-          break\n-        default:\n-          return workUnitStore satisfies never\n+      case 'private-cache':\n+        break\n+      default: {\n+        outerWorkUnitStore satisfies never\n       }\n+    }\n+  }\n \n-      const serializedCacheKey =\n-        typeof encodedCacheKeyParts === 'string'\n-          ? // Fast path for the simple case for simple inputs. We let the CacheHandler\n-            // Convert it to an ArrayBuffer if it wants to.\n-            encodedCacheKeyParts\n-          : await encodeFormData(encodedCacheKeyParts)\n-\n-      let stream: undefined | ReadableStream = undefined\n-\n-      // Get an immutable and mutable versions of the resume data cache.\n-      const prerenderResumeDataCache = workUnitStore\n-        ? getPrerenderResumeDataCache(workUnitStore)\n-        : null\n-      const renderResumeDataCache = workUnitStore\n-        ? getRenderResumeDataCache(workUnitStore)\n-        : null\n+  let isPageOrLayoutSegmentFunction = false\n+\n+  // For page and layout segment functions (i.e. the page/layout component,\n+  // or generateMetadata/generateViewport), the cache function is\n+  // overwritten, which allows us to apply special handling for params and\n+  // searchParams. For pages and layouts we're using the outer params prop,\n+  // and not the inner one that was serialized/deserialized. While it's not\n+  // generally true for \"use cache\" args, in the case of `params` the inner\n+  // and outer object are essentially equivalent, so this is safe to do\n+  // (including fallback params that are hanging promises). It allows us to\n+  // avoid waiting for the timeout, when prerendering a fallback shell of a\n+  // cached page or layout that awaits params.\n+  if (isPageSegmentFunction(args)) {\n+    isPageOrLayoutSegmentFunction = true\n+\n+    const [\n+      { params: outerParams, searchParams: outerSearchParams },\n+      ...otherOuterArgs\n+    ] = args\n+\n+    const props: UseCachePageInnerProps = {\n+      params: outerParams,\n+      // Omit searchParams and $$isPage.\n+    }\n \n-      if (renderResumeDataCache) {\n-        const cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n+    if (isPrivate) {\n+      // Private caches allow accessing search params. We need to include\n+      // them in the serialized args and when generating the cache key.\n+      props.searchParams = outerSearchParams\n+    }\n \n-        if (cacheSignal) {\n-          cacheSignal.beginRead()\n-        }\n-        const cachedEntry = renderResumeDataCache.cache.get(serializedCacheKey)\n-        if (cachedEntry !== undefined) {\n-          const existingEntry = await cachedEntry\n-          if (workUnitStore !== undefined && existingEntry !== undefined) {\n-            if (\n-              existingEntry.revalidate === 0 ||\n-              existingEntry.expire < DYNAMIC_EXPIRE\n-            ) {\n-              switch (workUnitStore.type) {\n-                case 'prerender':\n-                  // In a Dynamic I/O prerender, if the cache entry has\n-                  // revalidate: 0 or if the expire time is under 5 minutes,\n-                  // then we consider this cache entry dynamic as it's not worth\n-                  // generating static pages for such data. It's better to leave\n-                  // a dynamic hole that can be filled in during the resume with\n-                  // a potentially cached entry.\n-                  if (cacheSignal) {\n-                    cacheSignal.endRead()\n-                  }\n-                  return makeHangingPromise(\n-                    workUnitStore.renderSignal,\n-                    workStore.route,\n-                    'dynamic \"use cache\"'\n-                  )\n-                case 'prerender-runtime': {\n-                  // In the final phase of a runtime prerender, we have to make\n-                  // sure that APIs that would hang during a static prerender\n-                  // are resolved with a delay, in the runtime stage.\n-                  if (workUnitStore.runtimeStagePromise) {\n-                    await workUnitStore.runtimeStagePromise\n-                  }\n-                  break\n-                }\n-                case 'request': {\n-                  if (process.env.NODE_ENV === 'development') {\n-                    // We delay the cache here so that it doesn't resolve in the static task --\n-                    // in a regular static prerender, it'd be a hanging promise, and we need to reflect that,\n-                    // so it has to resolve later.\n-                    // TODO(restart-on-cache-miss): Optimize this to avoid unnecessary restarts.\n-                    // We don't end the cache read here, so this will always appear as a cache miss in the static stage,\n-                    // and thus will cause a restart even if all caches are filled.\n-                    await makeDevtoolsIOAwarePromise(\n-                      undefined,\n-                      workUnitStore,\n-                      RenderStage.Runtime\n-                    )\n-                  }\n-                  break\n-                }\n-                case 'prerender-ppr':\n-                case 'prerender-legacy':\n-                case 'cache':\n-                case 'private-cache':\n-                case 'unstable-cache':\n-                  break\n-                default:\n-                  workUnitStore satisfies never\n-              }\n-            }\n+    args = [props, ...otherOuterArgs]\n \n-            if (existingEntry.stale < RUNTIME_PREFETCH_DYNAMIC_STALE) {\n-              switch (workUnitStore.type) {\n-                case 'prerender-runtime':\n-                  // In a runtime prerender, if the cache entry will become\n-                  // stale in less then 30 seconds, we consider this cache entry\n-                  // dynamic as it's not worth prefetching. It's better to leave\n-                  // a dynamic hole that can be filled during the navigation.\n-                  if (cacheSignal) {\n-                    cacheSignal.endRead()\n-                  }\n-                  return makeHangingPromise(\n-                    workUnitStore.renderSignal,\n-                    workStore.route,\n-                    'dynamic \"use cache\"'\n-                  )\n-                case 'request': {\n-                  if (process.env.NODE_ENV === 'development') {\n-                    // We delay the cache here so that it doesn't resolve in the runtime phase --\n-                    // in a regular runtime prerender, it'd be a hanging promise, and we need to reflect that,\n-                    // so it has to resolve later.\n-                    // TODO(restart-on-cache-miss): Optimize this to avoid unnecessary restarts.\n-                    // We don't end the cache read here, so this will always appear as a cache miss in the runtime stage,\n-                    // and thus will cause a restart even if all caches are filled.\n-                    await makeDevtoolsIOAwarePromise(\n-                      undefined,\n-                      workUnitStore,\n-                      RenderStage.Dynamic\n-                    )\n-                  }\n-                  break\n-                }\n-                case 'prerender':\n-                case 'prerender-ppr':\n-                case 'prerender-legacy':\n-                case 'cache':\n-                case 'private-cache':\n-                case 'unstable-cache':\n-                  break\n-                default:\n-                  workUnitStore satisfies never\n-              }\n-            }\n-          }\n+    fn = {\n+      [name]: async (\n+        {\n+          params: _innerParams,\n+          searchParams: innerSearchParams,\n+        }: UseCachePageInnerProps,\n+        ...otherInnerArgs: unknown[]\n+      ) =>\n+        originalFn.apply(null, [\n+          {\n+            params: outerParams,\n+            searchParams:\n+              innerSearchParams ??\n+              // For public caches, search params are omitted from the cache\n+              // key (and the serialized args) to avoid mismatches between\n+              // prerendering and resuming a cached page that does not\n+              // access search params. This is also the reason why we're not\n+              // using a hanging promise for search params. For cached pages\n+              // that do access them, which is an invalid dynamic usage, we\n+              // need to ensure that an error is shown.\n+              makeErroringSearchParamsForUseCache(workStore),\n+          },\n+          ...otherInnerArgs,\n+        ]),\n+    }[name] as (...args: unknown[]) => Promise<unknown>\n+  } else if (isLayoutSegmentFunction(args)) {\n+    isPageOrLayoutSegmentFunction = true\n+\n+    const [\n+      { params: outerParams, $$isLayout, ...outerSlots },\n+      ...otherOuterArgs\n+    ] = args\n+\n+    // Overwrite the props to omit $$isLayout. Note that slots are only\n+    // passed to the layout component (if any are defined), and not to\n+    // generateMetadata nor generateViewport. For those functions,\n+    // outerSlots/innerSlots is an empty object, which is fine because we're\n+    // just spreading it into the props.\n+    args = [{ params: outerParams, ...outerSlots }, ...otherOuterArgs]\n+\n+    fn = {\n+      [name]: async (\n+        {\n+          params: _innerParams,\n+          ...innerSlots\n+        }: Omit<UseCacheLayoutProps, '$$isLayout'>,\n+        ...otherInnerArgs: unknown[]\n+      ) =>\n+        originalFn.apply(null, [\n+          { params: outerParams, ...innerSlots },\n+          ...otherInnerArgs,\n+        ]),\n+    }[name] as (...args: unknown[]) => Promise<unknown>\n+  }\n \n-          // We want to make sure we only propagate cache life & tags if the\n-          // entry was *not* omitted from the prerender. So we only do this\n-          // after the above early returns.\n-          propagateCacheLifeAndTags(cacheContext, existingEntry)\n+  if (boundArgsLength > 0) {\n+    if (args.length === 0) {\n+      throw new InvariantError(\n+        `Expected the \"use cache\" function ${JSON.stringify(fn.name)} to receive its encrypted bound arguments as the first argument.`\n+      )\n+    }\n \n-          const [streamA, streamB] = existingEntry.value.tee()\n-          existingEntry.value = streamB\n+    const encryptedBoundArgs = args.shift()\n+    const boundArgs = await decryptActionBoundArgs(id, encryptedBoundArgs)\n \n-          if (cacheSignal) {\n-            // When we have a cacheSignal we need to block on reading the cache\n-            // entry before ending the read.\n-            stream = createTrackedReadableStream(streamA, cacheSignal)\n-          } else {\n-            stream = streamA\n-          }\n-        } else {\n-          if (cacheSignal) {\n-            cacheSignal.endRead()\n-          }\n+    if (!Array.isArray(boundArgs)) {\n+      throw new InvariantError(\n+        `Expected the bound arguments of \"use cache\" function ${JSON.stringify(fn.name)} to deserialize into an array, got ${typeof boundArgs} instead.`\n+      )\n+    }\n \n-          if (workUnitStore) {\n-            switch (workUnitStore.type) {\n-              case 'prerender':\n-                // If `allowEmptyStaticShell` is true, and thus a prefilled\n-                // resume data cache was provided, then a cache miss means that\n-                // params were part of the cache key. In this case, we can make\n-                // this cache function a dynamic hole in the shell (or produce\n-                // an empty shell if there's no parent suspense boundary).\n-                // Currently, this also includes layouts and pages that don't\n-                // read params, which will be improved when we implement\n-                // NAR-136. Otherwise, we assume that if params are passed\n-                // explicitly into a \"use cache\" function, that the params are\n-                // also accessed. This allows us to abort early, and treat the\n-                // function as dynamic, instead of waiting for the timeout to be\n-                // reached. Compared to the instrumentation-based params bailout\n-                // we do here, this also covers the case where params are\n-                // transformed with an async function, before being passed into\n-                // the \"use cache\" function, which escapes the instrumentation.\n-                if (workUnitStore.allowEmptyStaticShell) {\n-                  return makeHangingPromise(\n-                    workUnitStore.renderSignal,\n-                    workStore.route,\n-                    'dynamic \"use cache\"'\n-                  )\n-                }\n-                break\n-              case 'prerender-runtime':\n-              case 'prerender-ppr':\n-              case 'prerender-legacy':\n-              case 'request':\n-              case 'cache':\n-              case 'private-cache':\n-              case 'unstable-cache':\n-                break\n-              default:\n-                workUnitStore satisfies never\n-            }\n-          }\n-        }\n-      }\n+    if (boundArgsLength !== boundArgs.length) {\n+      throw new InvariantError(\n+        `Expected the \"use cache\" function ${JSON.stringify(fn.name)} to receive ${boundArgsLength} bound arguments, got ${boundArgs.length} instead.`\n+      )\n+    }\n \n-      if (stream === undefined) {\n-        const cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n-        if (cacheSignal) {\n-          // Either the cache handler or the generation can be using I/O at this point.\n-          // We need to track when they start and when they complete.\n-          cacheSignal.beginRead()\n-        }\n+    args.unshift(boundArgs)\n+  }\n \n-        const lazyRefreshTags = workStore.refreshTagsByCacheKind.get(kind)\n+  const temporaryReferences = createClientTemporaryReferenceSet()\n+\n+  // For private caches, which are allowed to read cookies, we still don't\n+  // need to include the cookies in the cache key. This is because we don't\n+  // store the cache entries in a cache handler, but only in the Resume Data\n+  // Cache (RDC). Private caches are only used during dynamic requests and\n+  // runtime prefetches. For dynamic requests, the RDC is immutable, so it\n+  // does not include any private caches. For runtime prefetches, the RDC is\n+  // mutable, but only lives as long as the request, so the key does not\n+  // need to include cookies.\n+  const cacheKeyParts: CacheKeyParts = hmrRefreshHash\n+    ? [buildId, id, args, hmrRefreshHash]\n+    : [buildId, id, args]\n+\n+  const encodeCacheKeyParts = () =>\n+    encodeReply(cacheKeyParts, {\n+      temporaryReferences,\n+      signal: hangingInputAbortSignal,\n+    })\n+\n+  let encodedCacheKeyParts: FormData | string\n+\n+  switch (workUnitStore?.type) {\n+    case 'prerender-runtime':\n+    // We're currently only using `dynamicAccessAsyncStorage` for params,\n+    // which are always available in a runtime prerender, so they will never hang,\n+    // effectively making the tracking below a no-op.\n+    // However, a runtime prerender shares a lot of the semantics with a static prerender,\n+    // and might need to follow this codepath in the future\n+    // if we start using `dynamicAccessAsyncStorage` for other APIs.\n+    //\n+    // fallthrough\n+    case 'prerender':\n+      if (!isPageOrLayoutSegmentFunction) {\n+        // If the \"use cache\" function is not a page or layout segment\n+        // function, we need to track dynamic access already when encoding\n+        // the arguments. If params are passed explicitly into a \"use cache\"\n+        // function (as opposed to receiving them automatically in a page or\n+        // layout), we assume that the params are also accessed. This allows\n+        // us to abort early, and treat the function as dynamic, instead of\n+        // waiting for the timeout to be reached.\n+        const dynamicAccessAbortController = new AbortController()\n+\n+        encodedCacheKeyParts = await dynamicAccessAsyncStorage.run(\n+          { abortController: dynamicAccessAbortController },\n+          encodeCacheKeyParts\n+        )\n \n-        if (lazyRefreshTags && !isResolvedLazyResult(lazyRefreshTags)) {\n-          await lazyRefreshTags\n+        if (dynamicAccessAbortController.signal.aborted) {\n+          return makeHangingPromise(\n+            workUnitStore.renderSignal,\n+            workStore.route,\n+            'dynamic \"use cache\"'\n+          )\n         }\n+        break\n+      }\n+    // fallthrough\n+    case 'prerender-ppr':\n+    case 'prerender-legacy':\n+    case 'request':\n+    // TODO(restart-on-cache-miss): We need to handle params/searchParams on page components.\n+    // the promises will be tasky, so `encodeCacheKeyParts` will not resolve in the static stage.\n+    // We have not started a cache read at this point, so we might just miss the cache completely.\n+    // fallthrough\n+    case 'cache':\n+    case 'private-cache':\n+    case 'unstable-cache':\n+    case undefined:\n+      encodedCacheKeyParts = await encodeCacheKeyParts()\n+      break\n+    default:\n+      return workUnitStore satisfies never\n+  }\n \n-        let entry: CacheEntry | undefined\n+  const serializedCacheKey =\n+    typeof encodedCacheKeyParts === 'string'\n+      ? // Fast path for the simple case for simple inputs. We let the CacheHandler\n+        // Convert it to an ArrayBuffer if it wants to.\n+        encodedCacheKeyParts\n+      : await encodeFormData(encodedCacheKeyParts)\n \n-        // We ignore existing cache entries when force revalidating.\n-        if (cacheHandler && !shouldForceRevalidate(workStore, workUnitStore)) {\n-          entry = await cacheHandler.get(\n-            serializedCacheKey,\n-            workUnitStore?.implicitTags?.tags ?? []\n-          )\n-        }\n+  let stream: undefined | ReadableStream = undefined\n \n-        if (entry) {\n-          const implicitTags = workUnitStore?.implicitTags?.tags ?? []\n-          let implicitTagsExpiration = 0\n-\n-          if (workUnitStore?.implicitTags) {\n-            const lazyExpiration =\n-              workUnitStore.implicitTags.expirationsByCacheKind.get(kind)\n-\n-            if (lazyExpiration) {\n-              const expiration = isResolvedLazyResult(lazyExpiration)\n-                ? lazyExpiration.value\n-                : await lazyExpiration\n-\n-              // If a cache handler returns an expiration time of Infinity, it\n-              // signals to Next.js that it handles checking cache entries for\n-              // staleness based on the expiration of the implicit tags passed\n-              // into the `get` method. In this case, we keep the default of 0,\n-              // which means that the implicit tags are not considered expired.\n-              if (expiration < Infinity) {\n-                implicitTagsExpiration = expiration\n-              }\n-            }\n-          }\n+  // Get an immutable and mutable versions of the resume data cache.\n+  const prerenderResumeDataCache = workUnitStore\n+    ? getPrerenderResumeDataCache(workUnitStore)\n+    : null\n+  const renderResumeDataCache = workUnitStore\n+    ? getRenderResumeDataCache(workUnitStore)\n+    : null\n \n-          if (\n-            shouldDiscardCacheEntry(\n-              entry,\n-              workStore,\n-              workUnitStore,\n-              implicitTags,\n-              implicitTagsExpiration\n-            )\n-          ) {\n-            debug?.('discarding expired entry', serializedCacheKey)\n-            entry = undefined\n-          }\n-        }\n+  if (renderResumeDataCache) {\n+    const cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n \n-        const currentTime = performance.timeOrigin + performance.now()\n+    if (cacheSignal) {\n+      cacheSignal.beginRead()\n+    }\n+    const cachedEntry = renderResumeDataCache.cache.get(serializedCacheKey)\n+    if (cachedEntry !== undefined) {\n+      const existingEntry = await cachedEntry\n+      if (workUnitStore !== undefined && existingEntry !== undefined) {\n         if (\n-          workUnitStore !== undefined &&\n-          entry !== undefined &&\n-          (entry.revalidate === 0 || entry.expire < DYNAMIC_EXPIRE)\n+          existingEntry.revalidate === 0 ||\n+          existingEntry.expire < DYNAMIC_EXPIRE\n         ) {\n           switch (workUnitStore.type) {\n             case 'prerender':\n-              // In a Dynamic I/O prerender, if the cache entry has revalidate:\n-              // 0 or if the expire time is under 5 minutes, then we consider\n-              // this cache entry dynamic as it's not worth generating static\n-              // pages for such data. It's better to leave a dynamic hole that\n-              // can be filled in during the resume with a potentially cached\n-              // entry.\n+              // In a Dynamic I/O prerender, if the cache entry has\n+              // revalidate: 0 or if the expire time is under 5 minutes,\n+              // then we consider this cache entry dynamic as it's not worth\n+              // generating static pages for such data. It's better to leave\n+              // a dynamic hole that can be filled in during the resume with\n+              // a potentially cached entry.\n               if (cacheSignal) {\n                 cacheSignal.endRead()\n               }\n@@ -1497,6 +1255,15 @@ export function cache(\n                 workStore.route,\n                 'dynamic \"use cache\"'\n               )\n+            case 'prerender-runtime': {\n+              // In the final phase of a runtime prerender, we have to make\n+              // sure that APIs that would hang during a static prerender\n+              // are resolved with a delay, in the runtime stage.\n+              if (workUnitStore.runtimeStagePromise) {\n+                await workUnitStore.runtimeStagePromise\n+              }\n+              break\n+            }\n             case 'request': {\n               if (process.env.NODE_ENV === 'development') {\n                 // We delay the cache here so that it doesn't resolve in the static task --\n@@ -1513,7 +1280,49 @@ export function cache(\n               }\n               break\n             }\n+            case 'prerender-ppr':\n+            case 'prerender-legacy':\n+            case 'cache':\n+            case 'private-cache':\n+            case 'unstable-cache':\n+              break\n+            default:\n+              workUnitStore satisfies never\n+          }\n+        }\n+\n+        if (existingEntry.stale < RUNTIME_PREFETCH_DYNAMIC_STALE) {\n+          switch (workUnitStore.type) {\n             case 'prerender-runtime':\n+              // In a runtime prerender, if the cache entry will become\n+              // stale in less then 30 seconds, we consider this cache entry\n+              // dynamic as it's not worth prefetching. It's better to leave\n+              // a dynamic hole that can be filled during the navigation.\n+              if (cacheSignal) {\n+                cacheSignal.endRead()\n+              }\n+              return makeHangingPromise(\n+                workUnitStore.renderSignal,\n+                workStore.route,\n+                'dynamic \"use cache\"'\n+              )\n+            case 'request': {\n+              if (process.env.NODE_ENV === 'development') {\n+                // We delay the cache here so that it doesn't resolve in the runtime phase --\n+                // in a regular runtime prerender, it'd be a hanging promise, and we need to reflect that,\n+                // so it has to resolve later.\n+                // TODO(restart-on-cache-miss): Optimize this to avoid unnecessary restarts.\n+                // We don't end the cache read here, so this will always appear as a cache miss in the runtime stage,\n+                // and thus will cause a restart even if all caches are filled.\n+                await makeDevtoolsIOAwarePromise(\n+                  undefined,\n+                  workUnitStore,\n+                  RenderStage.Dynamic\n+                )\n+              }\n+              break\n+            }\n+            case 'prerender':\n             case 'prerender-ppr':\n             case 'prerender-legacy':\n             case 'cache':\n@@ -1524,192 +1333,359 @@ export function cache(\n               workUnitStore satisfies never\n           }\n         }\n+      }\n \n-        if (\n-          entry === undefined ||\n-          currentTime > entry.timestamp + entry.expire * 1000 ||\n-          (workStore.isStaticGeneration &&\n-            currentTime > entry.timestamp + entry.revalidate * 1000)\n-        ) {\n-          // Miss. Generate a new result.\n+      // We want to make sure we only propagate cache life & tags if the\n+      // entry was *not* omitted from the prerender. So we only do this\n+      // after the above early returns.\n+      propagateCacheLifeAndTags(cacheContext, existingEntry)\n \n-          // If the cache entry is stale and we're prerendering, we don't want to use the\n-          // stale entry since it would unnecessarily need to shorten the lifetime of the\n-          // prerender. We're not time constrained here so we can re-generated it now.\n+      const [streamA, streamB] = existingEntry.value.tee()\n+      existingEntry.value = streamB\n \n-          // We need to run this inside a clean AsyncLocalStorage snapshot so that the cache\n-          // generation cannot read anything from the context we're currently executing which\n-          // might include request specific things like cookies() inside a React.cache().\n-          // Note: It is important that we await at least once before this because it lets us\n-          // pop out of any stack specific contexts as well - aka \"Sync\" Local Storage.\n+      if (cacheSignal) {\n+        // When we have a cacheSignal we need to block on reading the cache\n+        // entry before ending the read.\n+        stream = createTrackedReadableStream(streamA, cacheSignal)\n+      } else {\n+        stream = streamA\n+      }\n+    } else {\n+      if (cacheSignal) {\n+        cacheSignal.endRead()\n+      }\n \n-          if (entry) {\n-            if (currentTime > entry.timestamp + entry.expire * 1000) {\n-              debug?.('entry is expired', serializedCacheKey)\n+      if (workUnitStore) {\n+        switch (workUnitStore.type) {\n+          case 'prerender':\n+            // If `allowEmptyStaticShell` is true, and thus a prefilled\n+            // resume data cache was provided, then a cache miss means that\n+            // params were part of the cache key. In this case, we can make\n+            // this cache function a dynamic hole in the shell (or produce\n+            // an empty shell if there's no parent suspense boundary).\n+            // Currently, this also includes layouts and pages that don't\n+            // read params, which will be improved when we implement\n+            // NAR-136. Otherwise, we assume that if params are passed\n+            // explicitly into a \"use cache\" function, that the params are\n+            // also accessed. This allows us to abort early, and treat the\n+            // function as dynamic, instead of waiting for the timeout to be\n+            // reached. Compared to the instrumentation-based params bailout\n+            // we do here, this also covers the case where params are\n+            // transformed with an async function, before being passed into\n+            // the \"use cache\" function, which escapes the instrumentation.\n+            if (workUnitStore.allowEmptyStaticShell) {\n+              return makeHangingPromise(\n+                workUnitStore.renderSignal,\n+                workStore.route,\n+                'dynamic \"use cache\"'\n+              )\n             }\n+            break\n+          case 'prerender-runtime':\n+          case 'prerender-ppr':\n+          case 'prerender-legacy':\n+          case 'request':\n+          case 'cache':\n+          case 'private-cache':\n+          case 'unstable-cache':\n+            break\n+          default:\n+            workUnitStore satisfies never\n+        }\n+      }\n+    }\n+  }\n \n-            if (\n-              workStore.isStaticGeneration &&\n-              currentTime > entry.timestamp + entry.revalidate * 1000\n-            ) {\n-              debug?.('static generation, entry is stale', serializedCacheKey)\n-            }\n+  if (stream === undefined) {\n+    const cacheSignal = workUnitStore ? getCacheSignal(workUnitStore) : null\n+    if (cacheSignal) {\n+      // Either the cache handler or the generation can be using I/O at this point.\n+      // We need to track when they start and when they complete.\n+      cacheSignal.beginRead()\n+    }\n+\n+    const lazyRefreshTags = workStore.refreshTagsByCacheKind.get(kind)\n+\n+    if (lazyRefreshTags && !isResolvedLazyResult(lazyRefreshTags)) {\n+      await lazyRefreshTags\n+    }\n+\n+    let entry: CacheEntry | undefined\n+\n+    // We ignore existing cache entries when force revalidating.\n+    if (cacheHandler && !shouldForceRevalidate(workStore, workUnitStore)) {\n+      entry = await cacheHandler.get(\n+        serializedCacheKey,\n+        workUnitStore?.implicitTags?.tags ?? []\n+      )\n+    }\n+\n+    if (entry) {\n+      const implicitTags = workUnitStore?.implicitTags?.tags ?? []\n+      let implicitTagsExpiration = 0\n+\n+      if (workUnitStore?.implicitTags) {\n+        const lazyExpiration =\n+          workUnitStore.implicitTags.expirationsByCacheKind.get(kind)\n+\n+        if (lazyExpiration) {\n+          const expiration = isResolvedLazyResult(lazyExpiration)\n+            ? lazyExpiration.value\n+            : await lazyExpiration\n+\n+          // If a cache handler returns an expiration time of Infinity, it\n+          // signals to Next.js that it handles checking cache entries for\n+          // staleness based on the expiration of the implicit tags passed\n+          // into the `get` method. In this case, we keep the default of 0,\n+          // which means that the implicit tags are not considered expired.\n+          if (expiration < Infinity) {\n+            implicitTagsExpiration = expiration\n           }\n+        }\n+      }\n \n-          const result = await generateCacheEntry(\n-            workStore,\n-            cacheContext,\n-            clientReferenceManifest,\n-            encodedCacheKeyParts,\n-            fn,\n-            sharedErrorStack\n-          )\n+      if (\n+        shouldDiscardCacheEntry(\n+          entry,\n+          workStore,\n+          workUnitStore,\n+          implicitTags,\n+          implicitTagsExpiration\n+        )\n+      ) {\n+        debug?.('discarding expired entry', serializedCacheKey)\n+        entry = undefined\n+      }\n+    }\n \n-          if (result.type === 'prerender-dynamic') {\n-            return result.hangingPromise\n+    const currentTime = performance.timeOrigin + performance.now()\n+    if (\n+      workUnitStore !== undefined &&\n+      entry !== undefined &&\n+      (entry.revalidate === 0 || entry.expire < DYNAMIC_EXPIRE)\n+    ) {\n+      switch (workUnitStore.type) {\n+        case 'prerender':\n+          // In a Dynamic I/O prerender, if the cache entry has revalidate:\n+          // 0 or if the expire time is under 5 minutes, then we consider\n+          // this cache entry dynamic as it's not worth generating static\n+          // pages for such data. It's better to leave a dynamic hole that\n+          // can be filled in during the resume with a potentially cached\n+          // entry.\n+          if (cacheSignal) {\n+            cacheSignal.endRead()\n+          }\n+          return makeHangingPromise(\n+            workUnitStore.renderSignal,\n+            workStore.route,\n+            'dynamic \"use cache\"'\n+          )\n+        case 'request': {\n+          if (process.env.NODE_ENV === 'development') {\n+            // We delay the cache here so that it doesn't resolve in the static task --\n+            // in a regular static prerender, it'd be a hanging promise, and we need to reflect that,\n+            // so it has to resolve later.\n+            // TODO(restart-on-cache-miss): Optimize this to avoid unnecessary restarts.\n+            // We don't end the cache read here, so this will always appear as a cache miss in the static stage,\n+            // and thus will cause a restart even if all caches are filled.\n+            await makeDevtoolsIOAwarePromise(\n+              undefined,\n+              workUnitStore,\n+              RenderStage.Runtime\n+            )\n           }\n+          break\n+        }\n+        case 'prerender-runtime':\n+        case 'prerender-ppr':\n+        case 'prerender-legacy':\n+        case 'cache':\n+        case 'private-cache':\n+        case 'unstable-cache':\n+          break\n+        default:\n+          workUnitStore satisfies never\n+      }\n+    }\n \n-          const { stream: newStream, pendingCacheEntry } = result\n+    if (\n+      entry === undefined ||\n+      currentTime > entry.timestamp + entry.expire * 1000 ||\n+      (workStore.isStaticGeneration &&\n+        currentTime > entry.timestamp + entry.revalidate * 1000)\n+    ) {\n+      // Miss. Generate a new result.\n+\n+      // If the cache entry is stale and we're prerendering, we don't want to use the\n+      // stale entry since it would unnecessarily need to shorten the lifetime of the\n+      // prerender. We're not time constrained here so we can re-generated it now.\n+\n+      // We need to run this inside a clean AsyncLocalStorage snapshot so that the cache\n+      // generation cannot read anything from the context we're currently executing which\n+      // might include request specific things like cookies() inside a React.cache().\n+      // Note: It is important that we await at least once before this because it lets us\n+      // pop out of any stack specific contexts as well - aka \"Sync\" Local Storage.\n+\n+      if (entry) {\n+        if (currentTime > entry.timestamp + entry.expire * 1000) {\n+          debug?.('entry is expired', serializedCacheKey)\n+        }\n \n-          // When draft mode is enabled, we must not save the cache entry.\n-          if (!workStore.isDraftMode) {\n-            let savedCacheEntry\n+        if (\n+          workStore.isStaticGeneration &&\n+          currentTime > entry.timestamp + entry.revalidate * 1000\n+        ) {\n+          debug?.('static generation, entry is stale', serializedCacheKey)\n+        }\n+      }\n \n-            if (prerenderResumeDataCache) {\n-              // Create a clone that goes into the cache scope memory cache.\n-              const split = clonePendingCacheEntry(pendingCacheEntry)\n-              savedCacheEntry = getNthCacheEntry(split, 0)\n-              prerenderResumeDataCache.cache.set(\n-                serializedCacheKey,\n-                getNthCacheEntry(split, 1)\n-              )\n-            } else {\n-              savedCacheEntry = pendingCacheEntry\n-            }\n+      const result = await generateCacheEntry(\n+        workStore,\n+        cacheContext,\n+        clientReferenceManifest,\n+        encodedCacheKeyParts,\n+        fn,\n+        timeoutError\n+      )\n \n-            if (cacheHandler) {\n-              const promise = cacheHandler.set(\n-                serializedCacheKey,\n-                savedCacheEntry\n-              )\n+      if (result.type === 'prerender-dynamic') {\n+        return result.hangingPromise\n+      }\n \n-              workStore.pendingRevalidateWrites ??= []\n-              workStore.pendingRevalidateWrites.push(promise)\n-            }\n-          }\n+      const { stream: newStream, pendingCacheEntry } = result\n+\n+      // When draft mode is enabled, we must not save the cache entry.\n+      if (!workStore.isDraftMode) {\n+        let savedCacheEntry\n \n-          stream = newStream\n+        if (prerenderResumeDataCache) {\n+          // Create a clone that goes into the cache scope memory cache.\n+          const split = clonePendingCacheEntry(pendingCacheEntry)\n+          savedCacheEntry = getNthCacheEntry(split, 0)\n+          prerenderResumeDataCache.cache.set(\n+            serializedCacheKey,\n+            getNthCacheEntry(split, 1)\n+          )\n         } else {\n-          // If we have an entry at this point, this can't be a private cache\n-          // entry.\n-          if (cacheContext.kind === 'private') {\n-            throw new InvariantError(\n-              `A private cache entry must not be retrieved from the cache handler.`\n-            )\n-          }\n+          savedCacheEntry = pendingCacheEntry\n+        }\n \n-          propagateCacheLifeAndTags(cacheContext, entry)\n+        if (cacheHandler) {\n+          const promise = cacheHandler.set(serializedCacheKey, savedCacheEntry)\n \n-          // We want to return this stream, even if it's stale.\n-          stream = entry.value\n+          workStore.pendingRevalidateWrites ??= []\n+          workStore.pendingRevalidateWrites.push(promise)\n+        }\n+      }\n \n-          // If we have a cache scope, we need to clone the entry and set it on\n-          // the inner cache scope.\n-          if (prerenderResumeDataCache) {\n-            const [entryLeft, entryRight] = cloneCacheEntry(entry)\n-            if (cacheSignal) {\n-              stream = createTrackedReadableStream(entryLeft.value, cacheSignal)\n-            } else {\n-              stream = entryLeft.value\n-            }\n+      stream = newStream\n+    } else {\n+      // If we have an entry at this point, this can't be a private cache\n+      // entry.\n+      if (cacheContext.kind === 'private') {\n+        throw new InvariantError(\n+          `A private cache entry must not be retrieved from the cache handler.`\n+        )\n+      }\n+\n+      propagateCacheLifeAndTags(cacheContext, entry)\n+\n+      // We want to return this stream, even if it's stale.\n+      stream = entry.value\n+\n+      // If we have a cache scope, we need to clone the entry and set it on\n+      // the inner cache scope.\n+      if (prerenderResumeDataCache) {\n+        const [entryLeft, entryRight] = cloneCacheEntry(entry)\n+        if (cacheSignal) {\n+          stream = createTrackedReadableStream(entryLeft.value, cacheSignal)\n+        } else {\n+          stream = entryLeft.value\n+        }\n+\n+        prerenderResumeDataCache.cache.set(\n+          serializedCacheKey,\n+          Promise.resolve(entryRight)\n+        )\n+      } else {\n+        // If we're not regenerating we need to signal that we've finished\n+        // putting the entry into the cache scope at this point. Otherwise we do\n+        // that inside generateCacheEntry.\n+        cacheSignal?.endRead()\n+      }\n+\n+      if (currentTime > entry.timestamp + entry.revalidate * 1000) {\n+        // If this is stale, and we're not in a prerender (i.e. this is\n+        // dynamic render), then we should warm up the cache with a fresh\n+        // revalidated entry.\n+        const result = await generateCacheEntry(\n+          workStore,\n+          // This is not running within the context of this unit.\n+          { kind: cacheContext.kind, outerWorkUnitStore: undefined },\n+          clientReferenceManifest,\n+          encodedCacheKeyParts,\n+          fn,\n+          timeoutError\n+        )\n+\n+        if (result.type === 'cached') {\n+          const { stream: ignoredStream, pendingCacheEntry } = result\n+          let savedCacheEntry: Promise<CacheEntry>\n \n+          if (prerenderResumeDataCache) {\n+            const split = clonePendingCacheEntry(pendingCacheEntry)\n+            savedCacheEntry = getNthCacheEntry(split, 0)\n             prerenderResumeDataCache.cache.set(\n               serializedCacheKey,\n-              Promise.resolve(entryRight)\n+              getNthCacheEntry(split, 1)\n             )\n           } else {\n-            // If we're not regenerating we need to signal that we've finished\n-            // putting the entry into the cache scope at this point. Otherwise we do\n-            // that inside generateCacheEntry.\n-            cacheSignal?.endRead()\n+            savedCacheEntry = pendingCacheEntry\n           }\n \n-          if (currentTime > entry.timestamp + entry.revalidate * 1000) {\n-            // If this is stale, and we're not in a prerender (i.e. this is\n-            // dynamic render), then we should warm up the cache with a fresh\n-            // revalidated entry.\n-            const result = await generateCacheEntry(\n-              workStore,\n-              // This is not running within the context of this unit.\n-              { kind: cacheContext.kind, outerWorkUnitStore: undefined },\n-              clientReferenceManifest,\n-              encodedCacheKeyParts,\n-              fn,\n-              sharedErrorStack\n+          if (cacheHandler) {\n+            const promise = cacheHandler.set(\n+              serializedCacheKey,\n+              savedCacheEntry\n             )\n \n-            if (result.type === 'cached') {\n-              const { stream: ignoredStream, pendingCacheEntry } = result\n-              let savedCacheEntry: Promise<CacheEntry>\n-\n-              if (prerenderResumeDataCache) {\n-                const split = clonePendingCacheEntry(pendingCacheEntry)\n-                savedCacheEntry = getNthCacheEntry(split, 0)\n-                prerenderResumeDataCache.cache.set(\n-                  serializedCacheKey,\n-                  getNthCacheEntry(split, 1)\n-                )\n-              } else {\n-                savedCacheEntry = pendingCacheEntry\n-              }\n-\n-              if (cacheHandler) {\n-                const promise = cacheHandler.set(\n-                  serializedCacheKey,\n-                  savedCacheEntry\n-                )\n-\n-                workStore.pendingRevalidateWrites ??= []\n-                workStore.pendingRevalidateWrites.push(promise)\n-              }\n-\n-              await ignoredStream.cancel()\n-            }\n+            workStore.pendingRevalidateWrites ??= []\n+            workStore.pendingRevalidateWrites.push(promise)\n           }\n-        }\n-      }\n \n-      // Logs are replayed even if it's a hit - to ensure we see them on the client eventually.\n-      // If we didn't then the client wouldn't see the logs if it was seeded from a prewarm that\n-      // never made it to the client. However, this also means that you see logs even when the\n-      // cached function isn't actually re-executed. We should instead ensure prewarms always\n-      // make it to the client. Another issue is that this will cause double logging in the\n-      // server terminal. Once while generating the cache entry and once when replaying it on\n-      // the server, which is required to pick it up for replaying again on the client.\n-      const replayConsoleLogs = true\n-\n-      const serverConsumerManifest = {\n-        // moduleLoading must be null because we don't want to trigger preloads of ClientReferences\n-        // to be added to the consumer. Instead, we'll wait for any ClientReference to be emitted\n-        // which themselves will handle the preloading.\n-        moduleLoading: null,\n-        moduleMap: isEdgeRuntime\n-          ? clientReferenceManifest.edgeRscModuleMapping\n-          : clientReferenceManifest.rscModuleMapping,\n-        serverModuleMap: getServerModuleMap(),\n+          await ignoredStream.cancel()\n+        }\n       }\n+    }\n+  }\n \n-      return createFromReadableStream(stream, {\n-        findSourceMapURL,\n-        serverConsumerManifest,\n-        temporaryReferences,\n-        replayConsoleLogs,\n-        environmentName: 'Cache',\n-      })\n-    },\n-  }[name]\n+  // Logs are replayed even if it's a hit - to ensure we see them on the client eventually.\n+  // If we didn't then the client wouldn't see the logs if it was seeded from a prewarm that\n+  // never made it to the client. However, this also means that you see logs even when the\n+  // cached function isn't actually re-executed. We should instead ensure prewarms always\n+  // make it to the client. Another issue is that this will cause double logging in the\n+  // server terminal. Once while generating the cache entry and once when replaying it on\n+  // the server, which is required to pick it up for replaying again on the client.\n+  const replayConsoleLogs = true\n+\n+  const serverConsumerManifest = {\n+    // moduleLoading must be null because we don't want to trigger preloads of ClientReferences\n+    // to be added to the consumer. Instead, we'll wait for any ClientReference to be emitted\n+    // which themselves will handle the preloading.\n+    moduleLoading: null,\n+    moduleMap: isEdgeRuntime\n+      ? clientReferenceManifest.edgeRscModuleMapping\n+      : clientReferenceManifest.rscModuleMapping,\n+    serverModuleMap: getServerModuleMap(),\n+  }\n \n-  return React.cache(cachedFn)\n+  return createFromReadableStream(stream, {\n+    findSourceMapURL,\n+    serverConsumerManifest,\n+    temporaryReferences,\n+    replayConsoleLogs,\n+    environmentName: 'Cache',\n+  })\n }\n \n /**"
        },
        {
            "sha": "5465b70fbeaf3cd859fde02696e2e0beff7c2769",
            "filename": "test/e2e/app-dir/cache-components-errors/cache-components-errors.test.ts",
            "status": "modified",
            "additions": 43,
            "deletions": 182,
            "changes": 225,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/test%2Fe2e%2Fapp-dir%2Fcache-components-errors%2Fcache-components-errors.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/test%2Fe2e%2Fapp-dir%2Fcache-components-errors%2Fcache-components-errors.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fcache-components-errors%2Fcache-components-errors.test.ts?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -2280,7 +2280,6 @@ describe('Cache Components Errors', () => {\n           it('should show a redbox error', async () => {\n             const browser = await next.browser('/use-cache-low-expire')\n \n-            // FIXME: Should have a codeframe\n             await expect(browser).toDisplayCollapsedRedbox(`\n              {\n                \"description\": \"Uncached data was accessed outside of <Suspense>\n@@ -2300,9 +2299,11 @@ describe('Cache Components Errors', () => {\n              Learn more: https://nextjs.org/docs/messages/blocking-route\",\n                \"environmentLabel\": \"Server\",\n                \"label\": \"Blocking Route\",\n-               \"source\": null,\n+               \"source\": \"app/use-cache-low-expire/page.tsx (3:16) @ Page\n+             > 3 | export default async function Page() {\n+                 |                ^\",\n                \"stack\": [\n-                 \"Page [Server] <anonymous>\",\n+                 \"Page app/use-cache-low-expire/page.tsx (3:16)\",\n                  \"LogSafely <anonymous>\",\n                ],\n              }\n@@ -2402,7 +2403,6 @@ describe('Cache Components Errors', () => {\n           it('should show a redbox error', async () => {\n             const browser = await next.browser('/use-cache-revalidate-0')\n \n-            // FIXME: Should have a codeframe\n             await expect(browser).toDisplayCollapsedRedbox(`\n              {\n                \"description\": \"Uncached data was accessed outside of <Suspense>\n@@ -2422,9 +2422,11 @@ describe('Cache Components Errors', () => {\n              Learn more: https://nextjs.org/docs/messages/blocking-route\",\n                \"environmentLabel\": \"Server\",\n                \"label\": \"Blocking Route\",\n-               \"source\": null,\n+               \"source\": \"app/use-cache-revalidate-0/page.tsx (3:16) @ Page\n+             > 3 | export default async function Page() {\n+                 |                ^\",\n                \"stack\": [\n-                 \"Page [Server] <anonymous>\",\n+                 \"Page app/use-cache-revalidate-0/page.tsx (3:16)\",\n                  \"LogSafely <anonymous>\",\n                ],\n              }\n@@ -2643,28 +2645,12 @@ describe('Cache Components Errors', () => {\n                  \"description\": \"\"use cache: private\" must not be used within \\`unstable_cache()\\`.\",\n                  \"environmentLabel\": null,\n                  \"label\": \"Runtime Error\",\n-                 \"source\": \"app/use-cache-private-in-unstable-cache/page.tsx (21:38) @ module evaluation\n-               > 21 | const getCachedData = unstable_cache(async () => {\n-                    |                                      ^\",\n-                 \"stack\": [\n-                   \"module evaluation app/use-cache-private-in-unstable-cache/page.tsx (21:38)\",\n-                   \"<FIXME-next-dist-dir>\",\n-                 ],\n-               }\n-              `)\n-            } else if (isRspack) {\n-              await expect(browser).toDisplayRedbox(`\n-               {\n-                 \"description\": \"\"use cache: private\" must not be used within \\`unstable_cache()\\`.\",\n-                 \"environmentLabel\": null,\n-                 \"label\": \"Runtime Error\",\n-                 \"source\": \"app/use-cache-private-in-unstable-cache/page.tsx (21:38) @ eval\n+                 \"source\": \"app/use-cache-private-in-unstable-cache/page.tsx (21:38) @ <unknown>\n                > 21 | const getCachedData = unstable_cache(async () => {\n                     |                                      ^\",\n                  \"stack\": [\n-                   \"eval app/use-cache-private-in-unstable-cache/page.tsx (21:38)\",\n-                   \"<FIXME-next-dist-dir>\",\n-                   \"<FIXME-next-dist-dir>\",\n+                   \"<unknown> app/use-cache-private-in-unstable-cache/page.tsx (21:38)\",\n+                   \"async ComponentWithCachedData app/use-cache-private-in-unstable-cache/page.tsx (16:16)\",\n                  ],\n                }\n               `)\n@@ -2679,7 +2665,7 @@ describe('Cache Components Errors', () => {\n                     |                                      ^\",\n                  \"stack\": [\n                    \"eval app/use-cache-private-in-unstable-cache/page.tsx (21:38)\",\n-                   \"<FIXME-next-dist-dir>\",\n+                   \"async ComponentWithCachedData app/use-cache-private-in-unstable-cache/page.tsx (16:16)\",\n                  ],\n                }\n               `)\n@@ -2698,12 +2684,11 @@ describe('Cache Components Errors', () => {\n               { isMinified: !isDebugPrerender }\n             )\n \n-            if (isTurbopack) {\n-              if (isDebugPrerender) {\n-                expect(output).toMatchInlineSnapshot(`\n+            if (isDebugPrerender) {\n+              expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \\`unstable_cache()\\`.\n-                     at module evaluation (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n-                     at a (<next-dist-dir>)\n+                     at <unknown> (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n+                     at async ComponentWithCachedData (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:16:16)\n                    19 | }\n                    20 |\n                  > 21 | const getCachedData = unstable_cache(async () => {\n@@ -2717,10 +2702,12 @@ describe('Cache Components Errors', () => {\n                  > Export encountered errors on following paths:\n                  \t/use-cache-private-in-unstable-cache/page: /use-cache-private-in-unstable-cache\"\n                 `)\n-              } else {\n+            } else {\n+              if (isTurbopack) {\n                 expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \\`unstable_cache()\\`.\n-                     at module evaluation (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n+                     at <unknown> (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n+                     at async h (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:16:16)\n                    19 | }\n                    20 |\n                  > 21 | const getCachedData = unstable_cache(async () => {\n@@ -2734,50 +2721,12 @@ describe('Cache Components Errors', () => {\n                  Error occurred prerendering page \"/use-cache-private-in-unstable-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n                  Export encountered an error on /use-cache-private-in-unstable-cache/page: /use-cache-private-in-unstable-cache, exiting the build.\"\n                 `)\n-              }\n-            } else {\n-              if (isDebugPrerender) {\n-                if (isRspack) {\n-                  expect(output).toMatchInlineSnapshot(`\n-                 \"Error: \"use cache: private\" must not be used within \\`unstable_cache()\\`.\n-                     at 0 (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n-                     at a (<next-dist-dir>)\n-                   19 | }\n-                   20 |\n-                 > 21 | const getCachedData = unstable_cache(async () => {\n-                      |                                      ^\n-                   22 |   'use cache: private'\n-                   23 |\n-                   24 |   return fetch('https://next-data-api-endpoint.vercel.app/api/random').then(\n-                 To get a more detailed stack trace and pinpoint the issue, start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-unstable-cache\" in your browser to investigate the error.\n-                 Error occurred prerendering page \"/use-cache-private-in-unstable-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n-\n-                 > Export encountered errors on following paths:\n-                 \t/use-cache-private-in-unstable-cache/page: /use-cache-private-in-unstable-cache\"\n-                `)\n-                } else {\n-                  expect(output).toMatchInlineSnapshot(`\n-                 \"Error: \"use cache: private\" must not be used within \\`unstable_cache()\\`.\n-                     at 0 (bundler:///app/use-cache-private-in-unstable-cache/page.tsx:21:38)\n-                   19 | }\n-                   20 |\n-                 > 21 | const getCachedData = unstable_cache(async () => {\n-                      |                                      ^\n-                   22 |   'use cache: private'\n-                   23 |\n-                   24 |   return fetch('https://next-data-api-endpoint.vercel.app/api/random').then(\n-                 To get a more detailed stack trace and pinpoint the issue, start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-unstable-cache\" in your browser to investigate the error.\n-                 Error occurred prerendering page \"/use-cache-private-in-unstable-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n-\n-                 > Export encountered errors on following paths:\n-                 \t/use-cache-private-in-unstable-cache/page: /use-cache-private-in-unstable-cache\"\n-                `)\n-                }\n               } else {\n                 expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \\`unstable_cache()\\`.\n                      at a (<next-dist-dir>)\n                      at b (<next-dist-dir>)\n+                     at c (<next-dist-dir>)\n                  To get a more detailed stack trace and pinpoint the issue, try one of the following:\n                    - Start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-unstable-cache\" in your browser to investigate the error.\n                    - Rerun the production build with \\`next build --debug-prerender\\` to generate better stack traces.\n@@ -2797,53 +2746,20 @@ describe('Cache Components Errors', () => {\n               '/use-cache-private-in-use-cache'\n             )\n \n-            if (isTurbopack) {\n-              await expect(browser).toDisplayRedbox(`\n-               {\n-                 \"description\": \"\"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\",\n-                 \"environmentLabel\": null,\n-                 \"label\": \"Runtime Error\",\n-                 \"source\": \"app/use-cache-private-in-use-cache/page.tsx (15:1) @ module evaluation\n-               > 15 | async function Private() {\n-                    | ^\",\n-                 \"stack\": [\n-                   \"module evaluation app/use-cache-private-in-use-cache/page.tsx (15:1)\",\n-                   \"<FIXME-next-dist-dir>\",\n-                 ],\n-               }\n-              `)\n-            } else if (isRspack) {\n-              await expect(browser).toDisplayRedbox(`\n-               {\n-                 \"description\": \"\"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\",\n-                 \"environmentLabel\": null,\n-                 \"label\": \"Runtime Error\",\n-                 \"source\": \"app/use-cache-private-in-use-cache/page.tsx (15:1) @ eval\n-               > 15 | async function Private() {\n-                    | ^\",\n-                 \"stack\": [\n-                   \"eval app/use-cache-private-in-use-cache/page.tsx (15:1)\",\n-                   \"<FIXME-next-dist-dir>\",\n-                   \"<FIXME-next-dist-dir>\",\n-                 ],\n-               }\n-              `)\n-            } else {\n-              await expect(browser).toDisplayRedbox(`\n+            await expect(browser).toDisplayRedbox(`\n                {\n                  \"description\": \"\"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\",\n                  \"environmentLabel\": null,\n                  \"label\": \"Runtime Error\",\n-                 \"source\": \"app/use-cache-private-in-use-cache/page.tsx (15:1) @ eval\n+                 \"source\": \"app/use-cache-private-in-use-cache/page.tsx (15:1) @ Private\n                > 15 | async function Private() {\n                     | ^\",\n                  \"stack\": [\n-                   \"eval app/use-cache-private-in-use-cache/page.tsx (15:1)\",\n-                   \"<FIXME-next-dist-dir>\",\n+                   \"Private app/use-cache-private-in-use-cache/page.tsx (15:1)\",\n+                   \"stringify <anonymous>\",\n                  ],\n                }\n               `)\n-            }\n           })\n         } else {\n           it('should error the build', async () => {\n@@ -2859,12 +2775,11 @@ describe('Cache Components Errors', () => {\n             )\n \n             // TODO: Ideally, the error should only be shown once.\n-            if (isTurbopack) {\n-              if (isDebugPrerender) {\n-                expect(output).toMatchInlineSnapshot(`\n+            if (isDebugPrerender) {\n+              expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at module evaluation (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                     at a (<next-dist-dir>)\n+                     at Private (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at stringify (<anonymous>)\n                    13 | }\n                    14 |\n                  > 15 | async function Private() {\n@@ -2873,8 +2788,8 @@ describe('Cache Components Errors', () => {\n                    17 |\n                    18 |   return <p>Private</p>\n                  Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at module evaluation (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                     at b (<next-dist-dir>)\n+                     at Private (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at stringify (<anonymous>)\n                    13 | }\n                    14 |\n                  > 15 | async function Private() {\n@@ -2888,10 +2803,12 @@ describe('Cache Components Errors', () => {\n                  > Export encountered errors on following paths:\n                  \t/use-cache-private-in-use-cache/page: /use-cache-private-in-use-cache\"\n                 `)\n-              } else {\n+            } else {\n+              if (isTurbopack) {\n                 expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at module evaluation (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at <unknown> (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at a (<anonymous>)\n                    13 | }\n                    14 |\n                  > 15 | async function Private() {\n@@ -2900,7 +2817,8 @@ describe('Cache Components Errors', () => {\n                    17 |\n                    18 |   return <p>Private</p>\n                  Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at module evaluation (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at <unknown> (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n+                     at b (<anonymous>)\n                    13 | }\n                    14 |\n                  > 15 | async function Private() {\n@@ -2914,72 +2832,14 @@ describe('Cache Components Errors', () => {\n                  Error occurred prerendering page \"/use-cache-private-in-use-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n                  Export encountered an error on /use-cache-private-in-use-cache/page: /use-cache-private-in-use-cache, exiting the build.\"\n                 `)\n-              }\n-            } else {\n-              if (isDebugPrerender) {\n-                if (isRspack) {\n-                  expect(output).toMatchInlineSnapshot(`\n-                 \"Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at 0 (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                     at a (<next-dist-dir>)\n-                   13 | }\n-                   14 |\n-                 > 15 | async function Private() {\n-                      | ^\n-                   16 |   'use cache: private'\n-                   17 |\n-                   18 |   return <p>Private</p>\n-                 Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at 1 (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                     at b (<next-dist-dir>)\n-                   13 | }\n-                   14 |\n-                 > 15 | async function Private() {\n-                      | ^\n-                   16 |   'use cache: private'\n-                   17 |\n-                   18 |   return <p>Private</p>\n-                 To get a more detailed stack trace and pinpoint the issue, start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-use-cache\" in your browser to investigate the error.\n-                 Error occurred prerendering page \"/use-cache-private-in-use-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n-\n-                 > Export encountered errors on following paths:\n-                 \t/use-cache-private-in-use-cache/page: /use-cache-private-in-use-cache\"\n-                `)\n-                } else {\n-                  expect(output).toMatchInlineSnapshot(`\n-                 \"Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at 0 (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                   13 | }\n-                   14 |\n-                 > 15 | async function Private() {\n-                      | ^\n-                   16 |   'use cache: private'\n-                   17 |\n-                   18 |   return <p>Private</p>\n-                 Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n-                     at 1 (bundler:///app/use-cache-private-in-use-cache/page.tsx:15:1)\n-                   13 | }\n-                   14 |\n-                 > 15 | async function Private() {\n-                      | ^\n-                   16 |   'use cache: private'\n-                   17 |\n-                   18 |   return <p>Private</p>\n-                 To get a more detailed stack trace and pinpoint the issue, start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-use-cache\" in your browser to investigate the error.\n-                 Error occurred prerendering page \"/use-cache-private-in-use-cache\". Read more: https://nextjs.org/docs/messages/prerender-error\n-\n-                 > Export encountered errors on following paths:\n-                 \t/use-cache-private-in-use-cache/page: /use-cache-private-in-use-cache\"\n-                `)\n-                }\n               } else {\n                 expect(output).toMatchInlineSnapshot(`\n                  \"Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n                      at a (<next-dist-dir>)\n-                     at b (<next-dist-dir>)\n+                     at b (<anonymous>)\n                  Error: \"use cache: private\" must not be used within \"use cache\". It can only be nested inside of another \"use cache: private\".\n                      at c (<next-dist-dir>)\n-                     at d (<next-dist-dir>)\n+                     at d (<anonymous>)\n                  To get a more detailed stack trace and pinpoint the issue, try one of the following:\n                    - Start the app in development mode by running \\`next dev\\`, then open \"/use-cache-private-in-use-cache\" in your browser to investigate the error.\n                    - Rerun the production build with \\`next build --debug-prerender\\` to generate better stack traces.\n@@ -3018,10 +2878,11 @@ describe('Cache Components Errors', () => {\n              Learn more: https://nextjs.org/docs/messages/blocking-route\",\n                \"environmentLabel\": \"Server\",\n                \"label\": \"Blocking Route\",\n-               \"source\": \"app/use-cache-private-without-suspense/page.tsx (10:7) @ Page\n-             > 10 |       <Private />\n-                  |       ^\",\n+               \"source\": \"app/use-cache-private-without-suspense/page.tsx (15:1) @ Private\n+             > 15 | async function Private() {\n+                  | ^\",\n                \"stack\": [\n+                 \"Private app/use-cache-private-without-suspense/page.tsx (15:1)\",\n                  \"Page app/use-cache-private-without-suspense/page.tsx (10:7)\",\n                  \"LogSafely <anonymous>\",\n                ],"
        },
        {
            "sha": "d5507929f5048be411739e177e9b9757db3e52b2",
            "filename": "test/e2e/app-dir/use-cache-hanging-inputs/use-cache-hanging-inputs.test.ts",
            "status": "modified",
            "additions": 44,
            "deletions": 94,
            "changes": 138,
            "blob_url": "https://github.com/vercel/next.js/blob/b07fb8644f224049dcb664ca06584d5861ac4208/test%2Fe2e%2Fapp-dir%2Fuse-cache-hanging-inputs%2Fuse-cache-hanging-inputs.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/b07fb8644f224049dcb664ca06584d5861ac4208/test%2Fe2e%2Fapp-dir%2Fuse-cache-hanging-inputs%2Fuse-cache-hanging-inputs.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache-hanging-inputs%2Fuse-cache-hanging-inputs.test.ts?ref=b07fb8644f224049dcb664ca06584d5861ac4208",
            "patch": "@@ -14,7 +14,7 @@ const expectedTimeoutErrorMessage =\n   'Filling a cache during prerender timed out, likely because request-specific arguments such as params, searchParams, cookies() or dynamic data were used inside \"use cache\".'\n \n describe('use-cache-hanging-inputs', () => {\n-  const { next, isNextDev, isTurbopack, skipped } = nextTestSetup({\n+  const { next, isNextDev, skipped } = nextTestSetup({\n     files: __dirname,\n     skipDeployment: true,\n     skipStart: process.env.NEXT_TEST_MODE !== 'dev',\n@@ -45,37 +45,20 @@ describe('use-cache-hanging-inputs', () => {\n \n         const cliOutput = stripAnsi(next.cliOutput.slice(outputIndex))\n \n-        if (isTurbopack) {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-           \"app/uncached-promise/page.tsx (10:13) @ module evaluation\n-\n-              8 | }\n-              9 |\n-           > 10 | const Foo = async ({ promise }) => {\n-                |             ^\n-             11 |   'use cache'\n-             12 |\n-             13 |   return (\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at module evaluation`)\n-        } else {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-           \"app/uncached-promise/page.tsx (10:13) @ eval\n-\n-              8 | }\n-              9 |\n-           > 10 | const Foo = async ({ promise }) => {\n-                |             ^\n-             11 |   'use cache'\n-             12 |\n-             13 |   return (\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at eval (app/uncached-promise/page.tsx:10:13)`)\n-        }\n+        expect(errorSource).toMatchInlineSnapshot(`\n+         \"app/uncached-promise/page.tsx (10:13) @ Foo\n+\n+            8 | }\n+            9 |\n+         > 10 | const Foo = async ({ promise }) => {\n+              |             ^\n+           11 |   'use cache'\n+           12 |\n+           13 |   return (\"\n+        `)\n+\n+        expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n+    at Foo (app/uncached-promise/page.tsx:10:13)`)\n       }, 180_000)\n     })\n \n@@ -99,37 +82,21 @@ describe('use-cache-hanging-inputs', () => {\n \n         const cliOutput = stripAnsi(next.cliOutput.slice(outputIndex))\n \n-        if (isTurbopack) {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-           \"app/uncached-promise-nested/page.tsx (16:1) @ module evaluation\n-\n-             14 | }\n-             15 |\n-           > 16 | async function indirection(promise: Promise<number>) {\n-                | ^\n-             17 |   'use cache'\n-             18 |\n-             19 |   return getCachedData(promise)\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at module evaluation`)\n-        } else {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-           \"app/uncached-promise-nested/page.tsx (16:1) @ eval\n-\n-             14 | }\n-             15 |\n-           > 16 | async function indirection(promise: Promise<number>) {\n-                | ^\n-             17 |   'use cache'\n-             18 |\n-             19 |   return getCachedData(promise)\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at eval (app/uncached-promise-nested/page.tsx:16:1)`)\n-        }\n+        expect(errorSource).toMatchInlineSnapshot(`\n+         \"app/uncached-promise-nested/page.tsx (16:1) @ indirection\n+\n+           14 | }\n+           15 |\n+         > 16 | async function indirection(promise: Promise<number>) {\n+              | ^\n+           17 |   'use cache'\n+           18 |\n+           19 |   return getCachedData(promise)\"\n+        `)\n+\n+        expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n+    at indirection (app/uncached-promise-nested/page.tsx:16:1)\n+    at Page (app/uncached-promise-nested/page.tsx:23:22)`)\n       }, 180_000)\n     })\n \n@@ -154,37 +121,20 @@ describe('use-cache-hanging-inputs', () => {\n \n         expect(errorDescription).toBe(expectedTimeoutErrorMessage)\n \n-        if (isTurbopack) {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-           \"app/bound-args/page.tsx (13:15) @ module evaluation\n-\n-             11 |   const uncachedDataPromise = fetchUncachedData()\n-             12 |\n-           > 13 |   const Foo = async () => {\n-                |               ^\n-             14 |     'use cache'\n-             15 |\n-             16 |     return (\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at module evaluation`)\n-        } else {\n-          expect(errorSource).toMatchInlineSnapshot(`\n-            \"app/bound-args/page.tsx (13:15) @ eval\n-\n-              11 |   const uncachedDataPromise = fetchUncachedData()\n-              12 |\n-            > 13 |   const Foo = async () => {\n-                 |               ^\n-              14 |     'use cache'\n-              15 |\n-              16 |     return (\"\n-          `)\n-\n-          expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n-    at eval (app/bound-args/page.tsx:13:15)`)\n-        }\n+        expect(errorSource).toMatchInlineSnapshot(`\n+         \"app/bound-args/page.tsx (13:15) @ Foo\n+\n+           11 |   const uncachedDataPromise = fetchUncachedData()\n+           12 |\n+         > 13 |   const Foo = async () => {\n+              |               ^\n+           14 |     'use cache'\n+           15 |\n+           16 |     return (\"\n+        `)\n+\n+        expect(cliOutput).toContain(`Error: ${expectedTimeoutErrorMessage}\n+    at Foo (app/bound-args/page.tsx:13:15)`)\n       }, 180_000)\n     })\n "
        }
    ],
    "stats": {
        "total": 2402,
        "additions": 1179,
        "deletions": 1223
    }
}