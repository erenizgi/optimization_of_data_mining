{
    "author": "sokra",
    "message": "Turbopack: add tool to print DB structure (#80148)\n\n### What?\r\n\r\nAdds a small CLI tool that prints the database structure like that:\r\n\r\n```\r\nMETA 00000417.meta: family = 4, \r\n  SST 00000411.sst: 000dade6cc76e41a - fffa6721f94e901f (p = 1/1)\r\n    AQMF 4695 entries = 4 KiB\r\n    180 KiB = 0 kiB key compression dict + 23 KiB value compression dict + 46 blocks (avg 3512 bytes/block)\r\nMETA 00000416.meta: family = 3, \r\n  SST 00000412.sst: 0025bba83f4b6ab9 - ffde0483d58f3b5e (p = 1/1)\r\n    AQMF 4695 entries = 4 KiB\r\n    182 KiB = 24 kiB key compression dict + 0 KiB value compression dict + 46 blocks (avg 3522 bytes/block)\r\nMETA 00000415.meta: family = 1, \r\n  SST 00000389.sst: 00005eac4b66cb4e - 3fffed60c1451cfe (p = 1/4)\r\n    AQMF 299033 entries = 292 KiB\r\n    24350 KiB = 0 kiB key compression dict + 63 KiB value compression dict + 3596 blocks (avg 6915 bytes/block)\r\n  SST 00000391.sst: 800015a5a9666318 - bfffdd05778fc576 (p = 1/4)\r\n    AQMF 299033 entries = 292 KiB\r\n    24851 KiB = 0 kiB key compression dict + 63 KiB value compression dict + 3933 blocks (avg 6453 bytes/block)\r\n  ...\r\n...\r\n```\r\n\r\nThe tool is only intended for internal usage and not exposed to the end user",
    "sha": "4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
    "files": [
        {
            "sha": "f8d028ae42786e5ee58b6b9ab84d4ef6e71c278e",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -9513,6 +9513,7 @@ version = \"0.1.0\"\n dependencies = [\n  \"anyhow\",\n  \"byteorder\",\n+ \"either\",\n  \"jiff\",\n  \"lzzzz\",\n  \"memmap2 0.9.5\",\n@@ -9531,6 +9532,14 @@ dependencies = [\n  \"zstd\",\n ]\n \n+[[package]]\n+name = \"turbo-persistence-tools\"\n+version = \"0.1.0\"\n+dependencies = [\n+ \"anyhow\",\n+ \"turbo-persistence\",\n+]\n+\n [[package]]\n name = \"turbo-prehash\"\n version = \"0.1.0\""
        },
        {
            "sha": "c1639d3a018c1e12690615c417d842e3298e4a5d",
            "filename": "turbopack/crates/turbo-persistence-tools/Cargo.toml",
            "status": "added",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence-tools%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence-tools%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence-tools%2FCargo.toml?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -0,0 +1,12 @@\n+[package]\n+name = \"turbo-persistence-tools\"\n+version = \"0.1.0\"\n+edition = \"2024\"\n+license = \"MIT\"\n+\n+[dependencies]\n+anyhow = { workspace = true }\n+turbo-persistence = { workspace = true }\n+\n+[lints]\n+workspace = true"
        },
        {
            "sha": "3c9633bd4a69458e6bff42dc888e2303963e5b74",
            "filename": "turbopack/crates/turbo-persistence-tools/src/main.rs",
            "status": "added",
            "additions": 70,
            "deletions": 0,
            "changes": 70,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -0,0 +1,70 @@\n+#![feature(iter_intersperse)]\n+\n+use std::path::PathBuf;\n+\n+use anyhow::{Context, Result, bail};\n+use turbo_persistence::{MetaFileEntryInfo, TurboPersistence};\n+\n+fn main() -> Result<()> {\n+    // Get CLI argument\n+    let path = PathBuf::from(\n+        std::env::args()\n+            .nth(1)\n+            .context(\"Please provide a path to the TurboPersistence directory\")?,\n+    );\n+    if !path.exists() {\n+        bail!(\"The provided path does not exist: {}\", path.display());\n+    }\n+\n+    let db = TurboPersistence::open_read_only(path)?;\n+    let meta_info = db\n+        .meta_info()\n+        .context(\"Failed to retrieve meta information\")?;\n+    for meta_file in meta_info {\n+        println!(\n+            \"META {:08}.meta: family = {}, \",\n+            meta_file.sequence_number, meta_file.family\n+        );\n+        for MetaFileEntryInfo {\n+            sequence_number,\n+            min_hash,\n+            max_hash,\n+            aqmf_size,\n+            aqmf_entries,\n+            sst_size,\n+            key_compression_dictionary_size,\n+            value_compression_dictionary_size,\n+            block_count,\n+        } in meta_file.entries\n+        {\n+            println!(\n+                \"  SST {sequence_number:08}.sst: {min_hash:016x} - {max_hash:016x} (p = 1/{})\",\n+                u64::MAX / (max_hash - min_hash)\n+            );\n+            println!(\"    AQMF {aqmf_entries} entries = {} KiB\", aqmf_size / 1024);\n+            println!(\n+                \"    {} KiB = {} kiB key compression dict + {} KiB value compression dict + \\\n+                 {block_count} blocks (avg {} bytes/block)\",\n+                sst_size / 1024,\n+                key_compression_dictionary_size / 1024,\n+                value_compression_dictionary_size / 1024,\n+                (sst_size\n+                    - key_compression_dictionary_size as u64\n+                    - value_compression_dictionary_size as u64)\n+                    / block_count as u64\n+            );\n+        }\n+        if !meta_file.obsolete_sst_files.is_empty() {\n+            println!(\n+                \"  OBSOLETE SSTs {}\",\n+                meta_file\n+                    .obsolete_sst_files\n+                    .iter()\n+                    .map(|seq| format!(\"{seq:08}.sst\"))\n+                    .intersperse(\", \".to_string())\n+                    .collect::<String>()\n+            );\n+        }\n+    }\n+    Ok(())\n+}"
        },
        {
            "sha": "0b4bf03885327db990d1e55f4108fd182e9e2f42",
            "filename": "turbopack/crates/turbo-persistence/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -13,6 +13,7 @@ print_stats = [\"stats\"]\n \n [dependencies]\n anyhow = { workspace = true }\n+either = { workspace = true}\n pot = \"3.0.0\"\n byteorder = \"1.5.0\"\n jiff = \"0.2.10\""
        },
        {
            "sha": "e26ee56d55a4657e6cb8ae374205afc8d0e949bd",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 116,
            "deletions": 23,
            "changes": 139,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -111,6 +111,9 @@ struct TrackedStats {\n pub struct TurboPersistence {\n     /// The path to the directory where the database is stored\n     path: PathBuf,\n+    /// If true, the database is opened in read-only mode. In this mode, no writes are allowed and\n+    /// no modification on the database is performed.\n+    read_only: bool,\n     /// The inner state of the database. Writing will update that.\n     inner: RwLock<Inner>,\n     /// A cache for the last WriteBatch. It is used to avoid reallocation of buffers for the\n@@ -149,13 +152,10 @@ pub struct CommitOptions {\n }\n \n impl TurboPersistence {\n-    /// Open a TurboPersistence database at the given path.\n-    /// This will read the directory and might performance cleanup when the database was not closed\n-    /// properly. Cleanup only requires to read a few bytes from a few files and to delete\n-    /// files, so it's fast.\n-    pub fn open(path: PathBuf) -> Result<Self> {\n-        let mut db = Self {\n+    fn new(path: PathBuf, read_only: bool) -> Self {\n+        Self {\n             path,\n+            read_only,\n             inner: RwLock::new(Inner {\n                 meta_files: Vec::new(),\n                 current_sequence_number: 0,\n@@ -185,26 +185,45 @@ impl TurboPersistence {\n             ),\n             #[cfg(feature = \"stats\")]\n             stats: TrackedStats::default(),\n-        };\n-        db.open_directory()?;\n+        }\n+    }\n+\n+    /// Open a TurboPersistence database at the given path.\n+    /// This will read the directory and might performance cleanup when the database was not closed\n+    /// properly. Cleanup only requires to read a few bytes from a few files and to delete\n+    /// files, so it's fast.\n+    pub fn open(path: PathBuf) -> Result<Self> {\n+        let mut db = Self::new(path, false);\n+        db.open_directory(false)?;\n+        Ok(db)\n+    }\n+\n+    /// Open a TurboPersistence database at the given path in read only mode.\n+    /// This will read the directory. No Cleanup is performed.\n+    pub fn open_read_only(path: PathBuf) -> Result<Self> {\n+        let mut db = Self::new(path, true);\n+        db.open_directory(false)?;\n         Ok(db)\n     }\n \n     /// Performs the initial check on the database directory.\n-    fn open_directory(&mut self) -> Result<()> {\n+    fn open_directory(&mut self, read_only: bool) -> Result<()> {\n         match fs::read_dir(&self.path) {\n             Ok(entries) => {\n                 if !self\n-                    .load_directory(entries)\n+                    .load_directory(entries, read_only)\n                     .context(\"Loading persistence directory failed\")?\n                 {\n+                    if read_only {\n+                        bail!(\"Failed to open database\");\n+                    }\n                     self.init_directory()\n                         .context(\"Initializing persistence directory failed\")?;\n                 }\n                 Ok(())\n             }\n             Err(e) => {\n-                if e.kind() == std::io::ErrorKind::NotFound {\n+                if !read_only && e.kind() == std::io::ErrorKind::NotFound {\n                     self.create_and_init_directory()\n                         .context(\"Creating and initializing persistence directory failed\")?;\n                     Ok(())\n@@ -230,12 +249,12 @@ impl TurboPersistence {\n     }\n \n     /// Loads an existing database directory and performs cleanup if necessary.\n-    fn load_directory(&mut self, entries: ReadDir) -> Result<bool> {\n+    fn load_directory(&mut self, entries: ReadDir, read_only: bool) -> Result<bool> {\n         let mut meta_files = Vec::new();\n         let mut current_file = match File::open(self.path.join(\"CURRENT\")) {\n             Ok(file) => file,\n             Err(e) => {\n-                if e.kind() == std::io::ErrorKind::NotFound {\n+                if !read_only && e.kind() == std::io::ErrorKind::NotFound {\n                     return Ok(false);\n                 } else {\n                     return Err(e).context(\"Failed to open CURRENT file\");\n@@ -260,7 +279,9 @@ impl TurboPersistence {\n                     continue;\n                 }\n                 if seq > current {\n-                    fs::remove_file(&path)?;\n+                    if !read_only {\n+                        fs::remove_file(&path)?;\n+                    }\n                 } else {\n                     match ext {\n                         \"meta\" => {\n@@ -272,17 +293,20 @@ impl TurboPersistence {\n                             while !content.is_empty() {\n                                 let seq = content.read_u32::<BE>()?;\n                                 deleted_files.insert(seq);\n-                                let sst_file = self.path.join(format!(\"{seq:08}.sst\"));\n-                                let meta_file = self.path.join(format!(\"{seq:08}.meta\"));\n-                                let blob_file = self.path.join(format!(\"{seq:08}.blob\"));\n-                                for path in [sst_file, meta_file, blob_file] {\n-                                    if fs::exists(&path)? {\n-                                        fs::remove_file(path)?;\n-                                        no_existing_files = false;\n+                                if !read_only {\n+                                    // Remove the files that are marked for deletion\n+                                    let sst_file = self.path.join(format!(\"{seq:08}.sst\"));\n+                                    let meta_file = self.path.join(format!(\"{seq:08}.meta\"));\n+                                    let blob_file = self.path.join(format!(\"{seq:08}.blob\"));\n+                                    for path in [sst_file, meta_file, blob_file] {\n+                                        if fs::exists(&path)? {\n+                                            fs::remove_file(path)?;\n+                                            no_existing_files = false;\n+                                        }\n                                     }\n                                 }\n                             }\n-                            if no_existing_files {\n+                            if !read_only && no_existing_files {\n                                 fs::remove_file(&path)?;\n                             }\n                         }\n@@ -379,6 +403,9 @@ impl TurboPersistence {\n     pub fn write_batch<K: StoreKey + Send + Sync + 'static, const FAMILIES: usize>(\n         &self,\n     ) -> Result<WriteBatch<K, FAMILIES>> {\n+        if self.read_only {\n+            bail!(\"Cannot write to a read-only database\");\n+        }\n         if self\n             .active_write_operation\n             .compare_exchange(false, true, Ordering::AcqRel, Ordering::Acquire)\n@@ -401,6 +428,9 @@ impl TurboPersistence {\n     }\n \n     fn open_log(&self) -> Result<BufWriter<File>> {\n+        if self.read_only {\n+            unreachable!(\"Only write operations can open the log file\");\n+        }\n         let log_path = self.path.join(\"LOG\");\n         let log_file = OpenOptions::new()\n             .create(true)\n@@ -415,6 +445,9 @@ impl TurboPersistence {\n         &self,\n         mut write_batch: WriteBatch<K, FAMILIES>,\n     ) -> Result<()> {\n+        if self.read_only {\n+            unreachable!(\"It's not possible to create a write batch for a read-only database\");\n+        }\n         let FinishResult {\n             sequence_number,\n             new_meta_files,\n@@ -622,6 +655,9 @@ impl TurboPersistence {\n         max_merge_sequence: usize,\n         max_merge_size: u64,\n     ) -> Result<()> {\n+        if self.read_only {\n+            bail!(\"Compaction is not allowed on a read only database\");\n+        }\n         let _span = tracing::info_span!(\"compact database\").entered();\n         if self\n             .active_write_operation\n@@ -1006,7 +1042,7 @@ impl TurboPersistence {\n                     let index_in_meta = ssts_with_ranges[index].index_in_meta;\n                     let meta_file = &meta_files[meta_index];\n                     let entry = meta_file.entry(index_in_meta);\n-                    let aqmf = entry.aqmf(meta_file.aqmf_data()).to_vec();\n+                    let aqmf = entry.raw_aqmf(meta_file.aqmf_data()).to_vec();\n                     let meta = StaticSortedFileBuilderMeta {\n                         min_hash: entry.min_hash(),\n                         max_hash: entry.max_hash(),\n@@ -1169,10 +1205,67 @@ impl TurboPersistence {\n         }\n     }\n \n+    pub fn meta_info(&self) -> Result<Vec<MetaFileInfo>> {\n+        Ok(self\n+            .inner\n+            .read()\n+            .meta_files\n+            .iter()\n+            .rev()\n+            .map(|meta_file| {\n+                let entries = meta_file\n+                    .entries()\n+                    .iter()\n+                    .map(|entry| {\n+                        let aqmf = entry.raw_aqmf(meta_file.aqmf_data());\n+                        MetaFileEntryInfo {\n+                            sequence_number: entry.sequence_number(),\n+                            min_hash: entry.min_hash(),\n+                            max_hash: entry.max_hash(),\n+                            sst_size: entry.size(),\n+                            aqmf_size: entry.aqmf_size(),\n+                            aqmf_entries: aqmf.len(),\n+                            key_compression_dictionary_size: entry\n+                                .key_compression_dictionary_length(),\n+                            value_compression_dictionary_size: entry\n+                                .value_compression_dictionary_length(),\n+                            block_count: entry.block_count(),\n+                        }\n+                    })\n+                    .collect();\n+                MetaFileInfo {\n+                    sequence_number: meta_file.sequence_number(),\n+                    family: meta_file.family(),\n+                    obsolete_sst_files: meta_file.obsolete_sst_files().to_vec(),\n+                    entries,\n+                }\n+            })\n+            .collect())\n+    }\n+\n     /// Shuts down the database. This will print statistics if the `print_stats` feature is enabled.\n     pub fn shutdown(&self) -> Result<()> {\n         #[cfg(feature = \"print_stats\")]\n         println!(\"{:#?}\", self.statistics());\n         Ok(())\n     }\n }\n+\n+pub struct MetaFileInfo {\n+    pub sequence_number: u32,\n+    pub family: u32,\n+    pub obsolete_sst_files: Vec<u32>,\n+    pub entries: Vec<MetaFileEntryInfo>,\n+}\n+\n+pub struct MetaFileEntryInfo {\n+    pub sequence_number: u32,\n+    pub min_hash: u64,\n+    pub max_hash: u64,\n+    pub aqmf_size: u32,\n+    pub aqmf_entries: usize,\n+    pub sst_size: u64,\n+    pub key_compression_dictionary_size: u16,\n+    pub value_compression_dictionary_size: u16,\n+    pub block_count: u16,\n+}"
        },
        {
            "sha": "30701f0d7a49aa87fc6b437e785bdcd77d77dbb4",
            "filename": "turbopack/crates/turbo-persistence/src/lib.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Flib.rs?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -25,7 +25,7 @@ mod tests;\n mod value_buf;\n \n pub use arc_slice::ArcSlice;\n-pub use db::TurboPersistence;\n+pub use db::{MetaFileEntryInfo, MetaFileInfo, TurboPersistence};\n pub use key::{KeyBase, QueryKey, StoreKey};\n pub use value_buf::ValueBuffer;\n pub use write_batch::WriteBatch;"
        },
        {
            "sha": "f48719b9735176a61fd3ed243986eac0165ba866",
            "filename": "turbopack/crates/turbo-persistence/src/meta_file.rs",
            "status": "modified",
            "additions": 48,
            "deletions": 36,
            "changes": 84,
            "blob_url": "https://github.com/vercel/next.js/blob/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs?ref=4c683ed2ca4e32b50d28f5d75f3fd6e2b10429d2",
            "patch": "@@ -2,12 +2,14 @@ use std::{\n     fs::File,\n     hash::BuildHasherDefault,\n     io::{BufReader, Seek},\n+    ops::Deref,\n     path::{Path, PathBuf},\n     sync::{Arc, OnceLock},\n };\n \n use anyhow::{Context, Result, bail};\n use byteorder::{BE, ReadBytesExt};\n+use either::Either;\n use memmap2::{Mmap, MmapOptions};\n use quick_cache::sync::GuardResult;\n use rustc_hash::FxHasher;\n@@ -62,12 +64,54 @@ impl MetaEntry {\n         self.size\n     }\n \n-    pub fn aqmf<'l>(&self, aqmf_data: &'l [u8]) -> &'l [u8] {\n+    pub fn aqmf_size(&self) -> u32 {\n+        self.end_of_aqmf_data_offset - self.start_of_aqmf_data_offset\n+    }\n+\n+    pub fn raw_aqmf<'l>(&self, aqmf_data: &'l [u8]) -> &'l [u8] {\n         aqmf_data\n             .get(self.start_of_aqmf_data_offset as usize..self.end_of_aqmf_data_offset as usize)\n             .expect(\"AQMF data out of bounds\")\n     }\n \n+    pub fn deserialize_aqmf(&self, meta: &MetaFile) -> Result<qfilter::Filter> {\n+        let aqmf = self.raw_aqmf(meta.aqmf_data());\n+        pot::from_slice(aqmf).with_context(|| {\n+            format!(\n+                \"Failed to deserialize AQMF from {:08}.meta for {:08}.sst\",\n+                meta.sequence_number,\n+                self.sequence_number()\n+            )\n+        })\n+    }\n+\n+    pub fn aqmf(\n+        &self,\n+        meta: &MetaFile,\n+        aqmf_cache: &AqmfCache,\n+    ) -> Result<impl Deref<Target = qfilter::Filter>> {\n+        let use_aqmf_cache = self.max_hash - self.min_hash < 1 << 60;\n+        Ok(if use_aqmf_cache {\n+            let aqmf = match aqmf_cache.get_value_or_guard(&self.sequence_number(), None) {\n+                GuardResult::Value(aqmf) => aqmf,\n+                GuardResult::Guard(guard) => {\n+                    let aqmf = self.deserialize_aqmf(meta)?;\n+                    let aqmf: Arc<qfilter::Filter> = Arc::new(aqmf);\n+                    let _ = guard.insert(aqmf.clone());\n+                    aqmf\n+                }\n+                GuardResult::Timeout => unreachable!(),\n+            };\n+            Either::Left(aqmf)\n+        } else {\n+            let aqmf = self.aqmf.get_or_try_init(|| {\n+                let aqmf = self.deserialize_aqmf(meta)?;\n+                anyhow::Ok(aqmf)\n+            })?;\n+            Either::Right(aqmf)\n+        })\n+    }\n+\n     pub fn sst(&self, meta: &MetaFile) -> Result<&StaticSortedFile> {\n         self.sst.get_or_try_init(|| {\n             StaticSortedFile::open(&meta.db_path, self.sst_data.clone()).with_context(|| {\n@@ -262,45 +306,13 @@ impl MetaFile {\n             if key_hash < entry.min_hash || key_hash > entry.max_hash {\n                 continue;\n             }\n-            let use_aqmf_cache = entry.max_hash - entry.min_hash < 1 << 60;\n-            if use_aqmf_cache {\n-                let aqmf = match aqmf_cache.get_value_or_guard(&entry.sequence_number(), None) {\n-                    GuardResult::Value(aqmf) => aqmf,\n-                    GuardResult::Guard(guard) => {\n-                        let aqmf = entry.aqmf(self.aqmf_data());\n-                        let aqmf: Arc<qfilter::Filter> =\n-                            Arc::new(pot::from_slice(aqmf).with_context(|| {\n-                                format!(\n-                                    \"Failed to deserialize AQMF from {:08}.meta for {:08}.sst\",\n-                                    self.sequence_number,\n-                                    entry.sequence_number()\n-                                )\n-                            })?);\n-                        let _ = guard.insert(aqmf.clone());\n-                        aqmf\n-                    }\n-                    GuardResult::Timeout => unreachable!(),\n-                };\n+            {\n+                let aqmf = entry.aqmf(self, aqmf_cache)?;\n                 if !aqmf.contains_fingerprint(key_hash) {\n                     miss_result = MetaLookupResult::QuickFilterMiss;\n                     continue;\n                 }\n-            } else {\n-                let aqmf = entry.aqmf.get_or_try_init(|| {\n-                    let aqmf = entry.aqmf(self.aqmf_data());\n-                    anyhow::Ok(pot::from_slice(aqmf).with_context(|| {\n-                        format!(\n-                            \"Failed to deserialize AQMF from {:08}.meta for {:08}.sst\",\n-                            self.sequence_number,\n-                            entry.sequence_number()\n-                        )\n-                    })?)\n-                })?;\n-                if !aqmf.contains_fingerprint(key_hash) {\n-                    miss_result = MetaLookupResult::QuickFilterMiss;\n-                    continue;\n-                }\n-            };\n+            }\n             let result =\n                 entry\n                     .sst(self)?"
        }
    ],
    "stats": {
        "total": 317,
        "additions": 257,
        "deletions": 60
    }
}