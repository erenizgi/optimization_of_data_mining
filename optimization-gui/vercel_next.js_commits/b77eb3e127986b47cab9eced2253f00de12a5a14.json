{
    "author": "sokra",
    "message": "Turbopack: fix hanging problem due to stale tasks (#81413)\n\n### What?\r\n\r\nWhen tasks become dirty they eventually need to be scheduled again when needed. To do that we maintain \"activeness\" of tasks. And we also maintain \"dirtyness\" of subgraphs, to allow for strongly consistency of a subgraph. But all that is a bit more involved since we don't want to touch all tasks of a subgraph (a subgraph could be millions of nodes).\r\n\r\nSo we do some \"aggregation\" of subgraphs to optimize the affected tasks. Once a task becomes dirty, we propagate that dirtyness up the aggregated tasks: Every aggregated task has a list of inner tasks which subgraph contain dirty tasks (`dirty_containers`). This way we can follow the graph directly down the dirty tasks without walking the whole graph.\r\n\r\nThis is where activeness comes into play. When a task is active we want to schedule all dirty tasks in the subgraph. This can happen under 2 cases:\r\n1. A task becomes active -> all dirty_containers are scheduled\r\n2. A dirty_container propagates to an already active task -> that task is scheduled\r\n\r\nThere is this case where a task is newly connected to an active task. This is covered by case 2, because a newly connected tasks will apply its aggregated info to the upper case, which hit case 2 then.\r\n\r\nAll root tasks are active as long as they are relevant (you can dispose them, or some are once off tasks). So when a task becomes dirty, it propagates the `dirty_container` to the root tasks, which would schedule the subgraph by walking the dirty_containers.\r\n\r\nBut it would break if another task becomes dirty below the same aggregated task. The aggregated task is already listed as `dirty_container` in the root tasks and it would not be scheduled again. To handle this all aggregated tasks, that are listed as `dirty_container` of an active task, are made temporarily active (`active_until_clean`). This also has the benefit that we don't have to do so many hops to schedule a task.\r\n\r\nSo this works in most cases, but there is a race condition in this design which this pull request fixes. We said only aggregated tasks are made temporarily active. But there is this edge case where while a task is already dirty, it is converted from a leaf task into an aggregated tasks and a inner task becomes dirty. This leads to the problem that the newly aggregated task is not temporarily active - as it was not an aggregated task when it was scheduled. So the inner task is not scheduled - since the upper task is not (temporarily) active. So the task is never executed and stays stale. But a strongly consistent read further up the graph will wait for this task to become not-dirty - since it is listed as `dirty_container`. This leads to a hanging build.\r\n\r\nTo fix that we make all tasks temporarily active, even leaf tasks.",
    "sha": "b77eb3e127986b47cab9eced2253f00de12a5a14",
    "files": [
        {
            "sha": "9706c975d31524f66abf25c204376fdf8a5fd0d6",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/aggregation_update.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 16,
            "changes": 28,
            "blob_url": "https://github.com/vercel/next.js/blob/b77eb3e127986b47cab9eced2253f00de12a5a14/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b77eb3e127986b47cab9eced2253f00de12a5a14/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs?ref=b77eb3e127986b47cab9eced2253f00de12a5a14",
            "patch": "@@ -1224,22 +1224,18 @@ impl AggregationUpdateQueue {\n                 ctx.schedule(task_id);\n             }\n         }\n-        let aggregation_number = get_aggregation_number(&task);\n-        if is_aggregating_node(aggregation_number) {\n-            // if it has `Activeness` we can skip visiting the nested nodes since\n-            // this would already be scheduled by the `Activeness`\n-            let is_active_until_clean =\n-                get!(task, Activeness).is_some_and(|a| a.active_until_clean);\n-            if !is_active_until_clean {\n-                let dirty_containers: Vec<_> = get_many!(task, AggregatedDirtyContainer { task } count if count.get(session_id) > 0 => task);\n-                if !dirty_containers.is_empty() || dirty {\n-                    let activeness_state =\n-                        get_mut_or_insert_with!(task, Activeness, || ActivenessState::new(task_id));\n-                    activeness_state.set_active_until_clean();\n-                    drop(task);\n-\n-                    self.extend_find_and_schedule_dirty(dirty_containers);\n-                }\n+        // if it has `Activeness` we can skip visiting the nested nodes since\n+        // this would already be scheduled by the `Activeness`\n+        let is_active_until_clean = get!(task, Activeness).is_some_and(|a| a.active_until_clean);\n+        if !is_active_until_clean {\n+            let dirty_containers: Vec<_> = get_many!(task, AggregatedDirtyContainer { task } count if count.get(session_id) > 0 => task);\n+            if !dirty_containers.is_empty() || dirty {\n+                let activeness_state =\n+                    get_mut_or_insert_with!(task, Activeness, || ActivenessState::new(task_id));\n+                activeness_state.set_active_until_clean();\n+                drop(task);\n+\n+                self.extend_find_and_schedule_dirty(dirty_containers);\n             }\n         }\n     }"
        }
    ],
    "stats": {
        "total": 28,
        "additions": 12,
        "deletions": 16
    }
}