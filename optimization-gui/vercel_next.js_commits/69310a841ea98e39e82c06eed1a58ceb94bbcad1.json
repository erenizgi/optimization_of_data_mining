{
    "author": "sokra",
    "message": "Turbopack: use block in place for db writes (#82380)\n\n<!-- Thanks for opening a PR! Your contribution is much appreciated.\nTo make sure your PR is handled as smoothly as possible we request that you follow the checklist sections below.\nChoose the right checklist for the change(s) that you're making:\n\n## For Contributors\n\n### Improving Documentation\n\n- Run `pnpm prettier-fix` to fix formatting issues before opening the PR.\n- Read the Docs Contribution Guide to ensure your contribution follows the docs guidelines: https://nextjs.org/docs/community/contribution-guide\n\n### Adding or Updating Examples\n\n- The \"examples guidelines\" are followed from our contributing doc https://github.com/vercel/next.js/blob/canary/contributing/examples/adding-examples.md\n- Make sure the linting passes by running `pnpm build && pnpm lint`. See https://github.com/vercel/next.js/blob/canary/contributing/repository/linting.md\n\n### Fixing a bug\n\n- Related issues linked using `fixes #number`\n- Tests added. See: https://github.com/vercel/next.js/blob/canary/contributing/core/testing.md#writing-tests-for-nextjs\n- Errors have a helpful link attached, see https://github.com/vercel/next.js/blob/canary/contributing.md\n\n### Adding a feature\n\n- Implements an existing feature request or RFC. Make sure the feature request has been accepted for implementation before opening a PR. (A discussion must be opened, see https://github.com/vercel/next.js/discussions/new?category=ideas)\n- Related issues/discussions are linked using `fixes #number`\n- e2e tests added (https://github.com/vercel/next.js/blob/canary/contributing/core/testing.md#writing-tests-for-nextjs)\n- Documentation added\n- Telemetry added. In case of a feature if it's used or not.\n- Errors have a helpful link attached, see https://github.com/vercel/next.js/blob/canary/contributing.md\n\n\n## For Maintainers\n\n- Minimal description (aim for explaining to someone not on the team to understand the PR)\n- When linking to a Slack thread, you might want to share details of the conclusion\n- Link both the Linear (Fixes NEXT-xxx) and the GitHub issues\n- Add review comments if necessary to explain to the reviewer the logic behind a change\n\n### What?\n\n### Why?\n\n### How?\n\nCloses NEXT-\nFixes #\n\n-->",
    "sha": "69310a841ea98e39e82c06eed1a58ceb94bbcad1",
    "files": [
        {
            "sha": "9d95aee336cba977407453cd85e0b2a98724b462",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 100,
            "deletions": 86,
            "changes": 186,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -508,12 +508,15 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             sst_filter.apply_filter(meta_file);\n         }\n \n-        for (_, file) in new_sst_files.iter() {\n-            file.sync_all()?;\n-        }\n-        for (_, file) in new_blob_files.iter() {\n-            file.sync_all()?;\n-        }\n+        self.parallel_scheduler.block_in_place(|| {\n+            for (_, file) in new_sst_files.iter() {\n+                file.sync_all()?;\n+            }\n+            for (_, file) in new_blob_files.iter() {\n+                file.sync_all()?;\n+            }\n+            anyhow::Ok(())\n+        })?;\n \n         let new_meta_info = new_meta_files\n             .iter()\n@@ -566,86 +569,88 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             inner.current_sequence_number = seq;\n         }\n \n-        if has_delete_file {\n-            sst_seq_numbers_to_delete.sort_unstable();\n-            meta_seq_numbers_to_delete.sort_unstable();\n-            blob_seq_numbers_to_delete.sort_unstable();\n-            // Write *.del file, marking the selected files as to delete\n-            let mut buf = Vec::with_capacity(\n-                (sst_seq_numbers_to_delete.len()\n-                    + meta_seq_numbers_to_delete.len()\n-                    + blob_seq_numbers_to_delete.len())\n-                    * size_of::<u32>(),\n-            );\n-            for seq in sst_seq_numbers_to_delete.iter() {\n-                buf.write_u32::<BE>(*seq)?;\n-            }\n-            for seq in meta_seq_numbers_to_delete.iter() {\n-                buf.write_u32::<BE>(*seq)?;\n-            }\n-            for seq in blob_seq_numbers_to_delete.iter() {\n-                buf.write_u32::<BE>(*seq)?;\n-            }\n-            let mut file = File::create(self.path.join(format!(\"{seq:08}.del\")))?;\n-            file.write_all(&buf)?;\n-            file.sync_all()?;\n-        }\n-\n-        let mut current_file = OpenOptions::new()\n-            .write(true)\n-            .truncate(false)\n-            .read(false)\n-            .open(self.path.join(\"CURRENT\"))?;\n-        current_file.write_u32::<BE>(seq)?;\n-        current_file.sync_all()?;\n-\n-        for seq in sst_seq_numbers_to_delete.iter() {\n-            fs::remove_file(self.path.join(format!(\"{seq:08}.sst\")))?;\n-        }\n-        for seq in meta_seq_numbers_to_delete.iter() {\n-            fs::remove_file(self.path.join(format!(\"{seq:08}.meta\")))?;\n-        }\n-        for seq in blob_seq_numbers_to_delete.iter() {\n-            fs::remove_file(self.path.join(format!(\"{seq:08}.blob\")))?;\n-        }\n-\n-        {\n-            let mut log = self.open_log()?;\n-            writeln!(log, \"Time {time}\")?;\n-            let span = time.until(Timestamp::now())?;\n-            writeln!(log, \"Commit {seq:08} {keys_written} keys in {span:#}\")?;\n-            for (seq, family, ssts, obsolete) in new_meta_info {\n-                writeln!(log, \"{seq:08} META family:{family}\",)?;\n-                for (seq, min, max, size) in ssts {\n-                    writeln!(\n-                        log,\n-                        \"  {seq:08} SST  {min:016x}-{max:016x} {} MiB\",\n-                        size / 1024 / 1024\n-                    )?;\n+        self.parallel_scheduler.block_in_place(|| {\n+            if has_delete_file {\n+                sst_seq_numbers_to_delete.sort_unstable();\n+                meta_seq_numbers_to_delete.sort_unstable();\n+                blob_seq_numbers_to_delete.sort_unstable();\n+                // Write *.del file, marking the selected files as to delete\n+                let mut buf = Vec::with_capacity(\n+                    (sst_seq_numbers_to_delete.len()\n+                        + meta_seq_numbers_to_delete.len()\n+                        + blob_seq_numbers_to_delete.len())\n+                        * size_of::<u32>(),\n+                );\n+                for seq in sst_seq_numbers_to_delete.iter() {\n+                    buf.write_u32::<BE>(*seq)?;\n                 }\n-                for seq in obsolete {\n-                    writeln!(log, \"  {seq:08} OBSOLETE SST\")?;\n+                for seq in meta_seq_numbers_to_delete.iter() {\n+                    buf.write_u32::<BE>(*seq)?;\n                 }\n+                for seq in blob_seq_numbers_to_delete.iter() {\n+                    buf.write_u32::<BE>(*seq)?;\n+                }\n+                let mut file = File::create(self.path.join(format!(\"{seq:08}.del\")))?;\n+                file.write_all(&buf)?;\n+                file.sync_all()?;\n             }\n-            new_sst_files.sort_unstable_by_key(|(seq, _)| *seq);\n-            for (seq, _) in new_sst_files.iter() {\n-                writeln!(log, \"{seq:08} NEW SST\")?;\n-            }\n-            new_blob_files.sort_unstable_by_key(|(seq, _)| *seq);\n-            for (seq, _) in new_blob_files.iter() {\n-                writeln!(log, \"{seq:08} NEW BLOB\")?;\n-            }\n+\n+            let mut current_file = OpenOptions::new()\n+                .write(true)\n+                .truncate(false)\n+                .read(false)\n+                .open(self.path.join(\"CURRENT\"))?;\n+            current_file.write_u32::<BE>(seq)?;\n+            current_file.sync_all()?;\n+\n             for seq in sst_seq_numbers_to_delete.iter() {\n-                writeln!(log, \"{seq:08} SST DELETED\")?;\n+                fs::remove_file(self.path.join(format!(\"{seq:08}.sst\")))?;\n             }\n             for seq in meta_seq_numbers_to_delete.iter() {\n-                writeln!(log, \"{seq:08} META DELETED\")?;\n+                fs::remove_file(self.path.join(format!(\"{seq:08}.meta\")))?;\n             }\n             for seq in blob_seq_numbers_to_delete.iter() {\n-                writeln!(log, \"{seq:08} BLOB DELETED\")?;\n+                fs::remove_file(self.path.join(format!(\"{seq:08}.blob\")))?;\n             }\n-        }\n \n+            {\n+                let mut log = self.open_log()?;\n+                writeln!(log, \"Time {time}\")?;\n+                let span = time.until(Timestamp::now())?;\n+                writeln!(log, \"Commit {seq:08} {keys_written} keys in {span:#}\")?;\n+                for (seq, family, ssts, obsolete) in new_meta_info {\n+                    writeln!(log, \"{seq:08} META family:{family}\",)?;\n+                    for (seq, min, max, size) in ssts {\n+                        writeln!(\n+                            log,\n+                            \"  {seq:08} SST  {min:016x}-{max:016x} {} MiB\",\n+                            size / 1024 / 1024\n+                        )?;\n+                    }\n+                    for seq in obsolete {\n+                        writeln!(log, \"  {seq:08} OBSOLETE SST\")?;\n+                    }\n+                }\n+                new_sst_files.sort_unstable_by_key(|(seq, _)| *seq);\n+                for (seq, _) in new_sst_files.iter() {\n+                    writeln!(log, \"{seq:08} NEW SST\")?;\n+                }\n+                new_blob_files.sort_unstable_by_key(|(seq, _)| *seq);\n+                for (seq, _) in new_blob_files.iter() {\n+                    writeln!(log, \"{seq:08} NEW BLOB\")?;\n+                }\n+                for seq in sst_seq_numbers_to_delete.iter() {\n+                    writeln!(log, \"{seq:08} SST DELETED\")?;\n+                }\n+                for seq in meta_seq_numbers_to_delete.iter() {\n+                    writeln!(log, \"{seq:08} META DELETED\")?;\n+                }\n+                for seq in blob_seq_numbers_to_delete.iter() {\n+                    writeln!(log, \"{seq:08} BLOB DELETED\")?;\n+                }\n+            }\n+            anyhow::Ok(())\n+        })?;\n         Ok(())\n     }\n \n@@ -837,7 +842,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                         });\n                     }\n \n-                    {\n+                    self.parallel_scheduler.block_in_place(|| {\n                         let metrics = compute_metrics(&ssts_with_ranges, 0..=u64::MAX);\n                         let guard = log_mutex.lock();\n                         let mut log = self.open_log()?;\n@@ -859,7 +864,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                             }\n                         }\n                         drop(guard);\n-                    }\n+                        anyhow::Ok(())\n+                    })?;\n \n                     // Later we will remove the merged files\n                     let sst_seq_numbers_to_delete = merge_jobs\n@@ -912,7 +918,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                 });\n                             }\n \n-                            fn create_sst_file(\n+                            fn create_sst_file<S: ParallelScheduler>(\n+                                parallel_scheduler: &S,\n                                 entries: &[LookupEntry],\n                                 total_key_size: usize,\n                                 total_value_size: usize,\n@@ -921,12 +928,14 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                             ) -> Result<(u32, File, StaticSortedFileBuilderMeta<'static>)>\n                             {\n                                 let _span = tracing::trace_span!(\"write merged sst file\").entered();\n-                                let (meta, file) = write_static_stored_file(\n-                                    entries,\n-                                    total_key_size,\n-                                    total_value_size,\n-                                    &path.join(format!(\"{seq:08}.sst\")),\n-                                )?;\n+                                let (meta, file) = parallel_scheduler.block_in_place(|| {\n+                                    write_static_stored_file(\n+                                        entries,\n+                                        total_key_size,\n+                                        total_value_size,\n+                                        &path.join(format!(\"{seq:08}.sst\")),\n+                                    )\n+                                })?;\n                                 Ok((seq, file, meta))\n                             }\n \n@@ -993,6 +1002,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n                                                 keys_written += entries.len() as u64;\n                                                 new_sst_files.push(create_sst_file(\n+                                                    &self.parallel_scheduler,\n                                                     &entries,\n                                                     selected_total_key_size,\n                                                     selected_total_value_size,\n@@ -1023,6 +1033,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n                                 keys_written += entries.len() as u64;\n                                 new_sst_files.push(create_sst_file(\n+                                    &self.parallel_scheduler,\n                                     &entries,\n                                     total_key_size,\n                                     total_value_size,\n@@ -1046,6 +1057,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n                                 keys_written += part1.len() as u64;\n                                 new_sst_files.push(create_sst_file(\n+                                    &self.parallel_scheduler,\n                                     part1,\n                                     // We don't know the exact sizes so we estimate them\n                                     last_entries_total_sizes.0 / 2,\n@@ -1056,6 +1068,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n                                 keys_written += part2.len() as u64;\n                                 new_sst_files.push(create_sst_file(\n+                                    &self.parallel_scheduler,\n                                     part2,\n                                     last_entries_total_sizes.0 / 2,\n                                     last_entries_total_sizes.1 / 2,\n@@ -1126,7 +1139,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                     let seq = sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n                     let meta_file = {\n                         let _span = tracing::trace_span!(\"write meta file\").entered();\n-                        meta_file_builder.write(&self.path, seq)?\n+                        self.parallel_scheduler\n+                            .block_in_place(|| meta_file_builder.write(&self.path, seq))?\n                     };\n \n                     Ok(PartialResultPerFamily {"
        },
        {
            "sha": "1ec00c98b6e9bb2417d8b49343fd3b054bc2a66f",
            "filename": "turbopack/crates/turbo-persistence/src/parallel_scheduler.rs",
            "status": "modified",
            "additions": 11,
            "deletions": 0,
            "changes": 11,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fparallel_scheduler.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fparallel_scheduler.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fparallel_scheduler.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -1,4 +1,8 @@\n pub trait ParallelScheduler: Clone + Sync + Send {\n+    fn block_in_place<R>(&self, f: impl FnOnce() -> R + Send) -> R\n+    where\n+        R: Send;\n+\n     fn parallel_for_each<T>(&self, items: &[T], f: impl Fn(&T) + Send + Sync)\n     where\n         T: Sync;\n@@ -55,6 +59,13 @@ pub trait ParallelScheduler: Clone + Sync + Send {\n pub struct SerialScheduler;\n \n impl ParallelScheduler for SerialScheduler {\n+    fn block_in_place<R>(&self, f: impl FnOnce() -> R + Send) -> R\n+    where\n+        R: Send,\n+    {\n+        f()\n+    }\n+\n     fn parallel_for_each<T>(&self, items: &[T], f: impl Fn(&T) + Send + Sync)\n     where\n         T: Sync,"
        },
        {
            "sha": "a52f7e9dd44b08a0732a0216f17d0a7f196a63ea",
            "filename": "turbopack/crates/turbo-persistence/src/tests.rs",
            "status": "modified",
            "additions": 7,
            "deletions": 0,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -14,6 +14,13 @@ use crate::{\n struct RayonParallelScheduler;\n \n impl ParallelScheduler for RayonParallelScheduler {\n+    fn block_in_place<R>(&self, f: impl FnOnce() -> R + Send) -> R\n+    where\n+        R: Send,\n+    {\n+        f()\n+    }\n+\n     fn parallel_for_each<T>(&self, items: &[T], f: impl Fn(&T) + Send + Sync)\n     where\n         T: Sync,"
        },
        {
            "sha": "f6cbd44acc6fdfd7a72d75d758bee33b9da85b1b",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 6,
            "deletions": 3,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -413,9 +413,12 @@ impl<K: StoreKey + Send + Sync, S: ParallelScheduler, const FAMILIES: usize>\n         let seq = self.current_sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n \n         let path = self.db_path.join(format!(\"{seq:08}.sst\"));\n-        let (meta, file) =\n-            write_static_stored_file(entries, total_key_size, total_value_size, &path)\n-                .with_context(|| format!(\"Unable to write SST file {seq:08}.sst\"))?;\n+        let (meta, file) = self\n+            .parallel_scheduler\n+            .block_in_place(|| {\n+                write_static_stored_file(entries, total_key_size, total_value_size, &path)\n+            })\n+            .with_context(|| format!(\"Unable to write SST file {seq:08}.sst\"))?;\n \n         #[cfg(feature = \"verify_sst_content\")]\n         {"
        },
        {
            "sha": "a8c11256115fce173cd5bff93696094b6e51aad4",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/turbo/parallel_scheduler.rs",
            "status": "modified",
            "additions": 8,
            "deletions": 1,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fparallel_scheduler.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fparallel_scheduler.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fparallel_scheduler.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -1,10 +1,17 @@\n use turbo_persistence::ParallelScheduler;\n-use turbo_tasks::parallel;\n+use turbo_tasks::{block_in_place, parallel};\n \n #[derive(Clone, Copy, Default)]\n pub struct TurboTasksParallelScheduler;\n \n impl ParallelScheduler for TurboTasksParallelScheduler {\n+    fn block_in_place<R>(&self, f: impl FnOnce() -> R + Send) -> R\n+    where\n+        R: Send,\n+    {\n+        block_in_place(f)\n+    }\n+\n     fn parallel_for_each<T>(&self, items: &[T], f: impl Fn(&T) + Send + Sync)\n     where\n         T: Sync,"
        },
        {
            "sha": "63733068534774d811894e5eb8ccf0701172153b",
            "filename": "turbopack/crates/turbo-tasks/src/effect.rs",
            "status": "modified",
            "additions": 6,
            "deletions": 25,
            "changes": 31,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Feffect.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Feffect.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Feffect.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -1,27 +1,26 @@\n use std::{\n     any::{Any, TypeId},\n-    borrow::Cow,\n     future::Future,\n     mem::replace,\n     panic,\n     pin::Pin,\n     sync::Arc,\n };\n \n-use anyhow::{Result, anyhow};\n+use anyhow::Result;\n use auto_hash_map::AutoSet;\n use futures::{StreamExt, TryStreamExt};\n use parking_lot::Mutex;\n use rustc_hash::{FxHashMap, FxHashSet};\n use tokio::task_local;\n-use tracing::{Instrument, Span};\n+use tracing::Instrument;\n \n use crate::{\n     self as turbo_tasks, CollectiblesSource, NonLocalValue, ReadRef, ResolvedVc, TryJoinIterExt,\n     debug::ValueDebugFormat,\n     emit,\n     event::{Event, EventListener},\n-    manager::turbo_tasks_future_scope,\n+    spawn,\n     trace::TraceRawVcs,\n     util::SharedError,\n };\n@@ -98,28 +97,10 @@ impl EffectInstance {\n                     listener.await;\n                 }\n                 State::NotStarted(EffectInner { future }) => {\n-                    let join_handle = tokio::spawn(ApplyEffectsContext::in_current_scope(\n-                        turbo_tasks_future_scope(turbo_tasks::turbo_tasks(), future)\n-                            .instrument(Span::current()),\n-                    ));\n+                    let join_handle = spawn(ApplyEffectsContext::in_current_scope(future));\n                     let result = match join_handle.await {\n-                        Ok(Err(err)) => Err(SharedError::new(err)),\n-                        Err(err) => {\n-                            let any = err.into_panic();\n-                            let panic = match any.downcast::<String>() {\n-                                Ok(owned) => Some(Cow::Owned(*owned)),\n-                                Err(any) => match any.downcast::<&'static str>() {\n-                                    Ok(str) => Some(Cow::Borrowed(*str)),\n-                                    Err(_) => None,\n-                                },\n-                            };\n-                            Err(SharedError::new(if let Some(panic) = panic {\n-                                anyhow!(\"Task effect panicked: {panic}\")\n-                            } else {\n-                                anyhow!(\"Task effect panicked\")\n-                            }))\n-                        }\n-                        Ok(Ok(())) => Ok(()),\n+                        Err(err) => Err(SharedError::new(err)),\n+                        Ok(()) => Ok(()),\n                     };\n                     let event = {\n                         let mut guard = self.inner.lock();"
        },
        {
            "sha": "4a994d7d556a1ce120217b6ac5879aab4ad2a7ec",
            "filename": "turbopack/crates/turbo-tasks/src/lib.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Flib.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -120,7 +120,9 @@ pub use read_ref::ReadRef;\n use rustc_hash::FxHasher;\n pub use serialization_invalidation::SerializationInvalidator;\n pub use shrink_to_fit::ShrinkToFit;\n-pub use spawn::{JoinHandle, block_for_future, spawn, spawn_blocking, spawn_thread};\n+pub use spawn::{\n+    JoinHandle, block_for_future, block_in_place, spawn, spawn_blocking, spawn_thread,\n+};\n pub use state::{State, TransientState};\n pub use task::{SharedReference, TypedSharedReference, task_input::TaskInput};\n pub use task_execution_reason::TaskExecutionReason;"
        },
        {
            "sha": "278b14fb000a489b3ff094aae2f318525beec2f9",
            "filename": "turbopack/crates/turbo-tasks/src/spawn.rs",
            "status": "modified",
            "additions": 10,
            "deletions": 1,
            "changes": 11,
            "blob_url": "https://github.com/vercel/next.js/blob/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/69310a841ea98e39e82c06eed1a58ceb94bbcad1/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs?ref=69310a841ea98e39e82c06eed1a58ceb94bbcad1",
            "patch": "@@ -8,7 +8,7 @@ use std::{\n \n use anyhow::Result;\n use futures::{FutureExt, ready};\n-use tokio::{runtime::Handle, task::block_in_place};\n+use tokio::runtime::Handle;\n use tracing::{Instrument, Span, info_span};\n use turbo_tasks_malloc::{AllocationInfo, TurboMalloc};\n \n@@ -94,6 +94,15 @@ pub fn spawn_thread(func: impl FnOnce() + Send + 'static) {\n     });\n }\n \n+/// Tells the scheduler about blocking work happening in the current thread.\n+/// It will make sure to allocate extra threads for the pool.\n+pub fn block_in_place<R>(f: impl FnOnce() -> R + Send) -> R\n+where\n+    R: Send,\n+{\n+    tokio::task::block_in_place(f)\n+}\n+\n /// Blocking waits for a future to complete. This blocks the current thread potentially staling\n /// other concurrent futures (but not other concurrent tasks). Try to avoid this method infavor of\n /// awaiting the future instead."
        }
    ],
    "stats": {
        "total": 268,
        "additions": 151,
        "deletions": 117
    }
}