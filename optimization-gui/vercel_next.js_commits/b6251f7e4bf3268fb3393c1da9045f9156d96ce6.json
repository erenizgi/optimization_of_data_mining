{
    "author": "sokra",
    "message": "add feature flag to verify aggregation graph (#78964)\n\n### What?\n\nimplement a feature flag which validates the aggregation graph and reports some missing or invalid edges.",
    "sha": "b6251f7e4bf3268fb3393c1da9045f9156d96ce6",
    "files": [
        {
            "sha": "49db8a52e791b7648e70ebdee25fc3c8b892888c",
            "filename": "turbopack/crates/turbo-tasks-backend/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/b6251f7e4bf3268fb3393c1da9045f9156d96ce6/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/b6251f7e4bf3268fb3393c1da9045f9156d96ce6/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2FCargo.toml?ref=b6251f7e4bf3268fb3393c1da9045f9156d96ce6",
            "patch": "@@ -15,6 +15,7 @@ workspace = true\n [features]\n default = []\n verify_serialization = []\n+verify_aggregation_graph = []\n trace_aggregation_update = []\n trace_find_and_schedule = []\n trace_task_completion = []"
        },
        {
            "sha": "fe70f468b5b5d6c3659cdd4f1cb6a6dc9b22cd92",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 225,
            "deletions": 6,
            "changes": 231,
            "blob_url": "https://github.com/vercel/next.js/blob/b6251f7e4bf3268fb3393c1da9045f9156d96ce6/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/b6251f7e4bf3268fb3393c1da9045f9156d96ce6/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=b6251f7e4bf3268fb3393c1da9045f9156d96ce6",
            "patch": "@@ -189,10 +189,15 @@ struct TurboTasksBackendInner<B: BackingStorage> {\n     stopping_event: Event,\n     idle_start_event: Event,\n     idle_end_event: Event,\n+    #[cfg(feature = \"verify_aggregation_graph\")]\n+    is_idle: AtomicBool,\n \n     task_statistics: TaskStatisticsApi,\n \n     backing_storage: B,\n+\n+    #[cfg(feature = \"verify_aggregation_graph\")]\n+    root_tasks: Mutex<FxHashSet<TaskId>>,\n }\n \n impl<B: BackingStorage> TurboTasksBackend<B> {\n@@ -237,8 +242,12 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n             stopping_event: Event::new(|| \"TurboTasksBackend::stopping_event\".to_string()),\n             idle_start_event: Event::new(|| \"TurboTasksBackend::idle_start_event\".to_string()),\n             idle_end_event: Event::new(|| \"TurboTasksBackend::idle_end_event\".to_string()),\n+            #[cfg(feature = \"verify_aggregation_graph\")]\n+            is_idle: AtomicBool::new(false),\n             task_statistics: TaskStatisticsApi::default(),\n             backing_storage,\n+            #[cfg(feature = \"verify_aggregation_graph\")]\n+            root_tasks: Default::default(),\n         }\n     }\n \n@@ -980,17 +989,49 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         self.stopping_event.notify(usize::MAX);\n     }\n \n-    fn stop(&self) {\n+    #[allow(unused_variables)]\n+    fn stop(&self, turbo_tasks: &dyn TurboTasksBackendApi<TurboTasksBackend<B>>) {\n+        #[cfg(feature = \"verify_aggregation_graph\")]\n+        {\n+            self.is_idle.store(false, Ordering::Release);\n+            self.verify_aggregation_graph(turbo_tasks, false);\n+        }\n         if let Err(err) = self.backing_storage.shutdown() {\n             println!(\"Shutting down failed: {err}\");\n         }\n     }\n \n-    fn idle_start(&self) {\n+    #[allow(unused_variables)]\n+    fn idle_start(self: &Arc<Self>, turbo_tasks: &dyn TurboTasksBackendApi<TurboTasksBackend<B>>) {\n         self.idle_start_event.notify(usize::MAX);\n+\n+        #[cfg(feature = \"verify_aggregation_graph\")]\n+        {\n+            use tokio::select;\n+\n+            self.is_idle.store(true, Ordering::Release);\n+            let this = self.clone();\n+            let turbo_tasks = turbo_tasks.pin();\n+            tokio::task::spawn(async move {\n+                select! {\n+                    _ = tokio::time::sleep(Duration::from_secs(5)) => {\n+                        // do nothing\n+                    }\n+                    _ = this.idle_end_event.listen() => {\n+                        return;\n+                    }\n+                }\n+                if !this.is_idle.load(Ordering::Relaxed) {\n+                    return;\n+                }\n+                this.verify_aggregation_graph(&*turbo_tasks, true);\n+            });\n+        }\n     }\n \n     fn idle_end(&self) {\n+        #[cfg(feature = \"verify_aggregation_graph\")]\n+        self.is_idle.store(false, Ordering::Release);\n         self.idle_end_event.notify(usize::MAX);\n     }\n \n@@ -2148,6 +2189,8 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                 RootType::OnceTask => \"Once Task\".to_string(),\n             }));\n         }\n+        #[cfg(feature = \"verify_aggregation_graph\")]\n+        self.root_tasks.lock().insert(task_id);\n         task_id\n     }\n \n@@ -2156,6 +2199,9 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         task_id: TaskId,\n         turbo_tasks: &dyn TurboTasksBackendApi<TurboTasksBackend<B>>,\n     ) {\n+        #[cfg(feature = \"verify_aggregation_graph\")]\n+        self.root_tasks.lock().remove(&task_id);\n+\n         let mut ctx = self.execute_context(turbo_tasks);\n         let mut task = ctx.task(task_id, TaskDataCategory::All);\n         let is_dirty = get!(task, Dirty).map_or(false, |dirty| dirty.get(self.session_id));\n@@ -2176,6 +2222,179 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         }\n     }\n \n+    #[cfg(feature = \"verify_aggregation_graph\")]\n+    fn verify_aggregation_graph(\n+        &self,\n+        turbo_tasks: &dyn TurboTasksBackendApi<TurboTasksBackend<B>>,\n+        idle: bool,\n+    ) {\n+        if env::var(\"TURBO_ENGINE_VERIFY_GRAPH\").ok().as_deref() == Some(\"0\") {\n+            return;\n+        }\n+        use std::{collections::VecDeque, env, io::stdout};\n+\n+        use crate::backend::operation::{get_uppers, is_aggregating_node};\n+\n+        let mut ctx = self.execute_context(turbo_tasks);\n+        let root_tasks = self.root_tasks.lock().clone();\n+        let len = root_tasks.len();\n+\n+        for (i, task_id) in root_tasks.into_iter().enumerate() {\n+            println!(\"Verifying graph from root {task_id} {i}/{len}...\");\n+            let mut queue = VecDeque::new();\n+            let mut visited = FxHashSet::default();\n+            let mut aggregated_nodes = FxHashSet::default();\n+            let mut collectibles = FxHashMap::default();\n+            let root_task_id = task_id;\n+            visited.insert(task_id);\n+            aggregated_nodes.insert(task_id);\n+            queue.push_back(task_id);\n+            let mut counter = 0;\n+            while let Some(task_id) = queue.pop_front() {\n+                counter += 1;\n+                if counter % 100000 == 0 {\n+                    println!(\n+                        \"queue={}, visited={}, aggregated_nodes={}\",\n+                        queue.len(),\n+                        visited.len(),\n+                        aggregated_nodes.len()\n+                    );\n+                }\n+                let task = ctx.task(task_id, TaskDataCategory::All);\n+                if idle && !self.is_idle.load(Ordering::Relaxed) {\n+                    return;\n+                }\n+\n+                let uppers = get_uppers(&task);\n+                if task_id != root_task_id\n+                    && !uppers.iter().any(|upper| aggregated_nodes.contains(upper))\n+                {\n+                    println!(\n+                        \"Task {} {} doesn't report to any root but is reachable from one (uppers: \\\n+                         {:?})\",\n+                        task_id,\n+                        ctx.get_task_description(task_id),\n+                        uppers\n+                    );\n+                }\n+\n+                let aggregated_collectibles: Vec<_> = get_many!(task, AggregatedCollectible { collectible } value if *value > 0 => {collectible});\n+                for collectible in aggregated_collectibles {\n+                    collectibles\n+                        .entry(collectible)\n+                        .or_insert_with(|| (false, Vec::new()))\n+                        .1\n+                        .push(task_id);\n+                }\n+\n+                let own_collectibles: Vec<_> = get_many!(task, Collectible { collectible } value if *value > 0 => {collectible});\n+                for collectible in own_collectibles {\n+                    if let Some((flag, _)) = collectibles.get_mut(&collectible) {\n+                        *flag = true\n+                    } else {\n+                        println!(\n+                            \"Task {} has a collectible {:?} that is not in any upper task\",\n+                            task_id, collectible\n+                        );\n+                    }\n+                }\n+\n+                let is_dirty = get!(task, Dirty).is_some_and(|dirty| dirty.get(self.session_id));\n+                let has_dirty_container = get!(task, AggregatedDirtyContainerCount)\n+                    .is_some_and(|count| count.get(self.session_id) > 0);\n+                let should_be_in_upper = is_dirty || has_dirty_container;\n+\n+                let aggregation_number = get_aggregation_number(&task);\n+                if is_aggregating_node(aggregation_number) {\n+                    aggregated_nodes.insert(task_id);\n+                }\n+                // println!(\n+                //     \"{task_id}: {} agg_num = {aggregation_number}, uppers = {:#?}\",\n+                //     ctx.get_task_description(task_id),\n+                //     uppers\n+                // );\n+\n+                for child_id in iter_many!(task, Child { task } => task) {\n+                    // println!(\"{task_id}: child -> {child_id}\");\n+                    if visited.insert(child_id) {\n+                        queue.push_back(child_id);\n+                    }\n+                }\n+                drop(task);\n+\n+                if should_be_in_upper {\n+                    for upper_id in uppers {\n+                        let task = ctx.task(task_id, TaskDataCategory::All);\n+                        let in_upper = get!(task, AggregatedDirtyContainer { task: task_id })\n+                            .is_some_and(|dirty| dirty.get(self.session_id) > 0);\n+                        if !in_upper {\n+                            println!(\n+                                \"Task {} is dirty, but is not listed in the upper task {}\",\n+                                task_id, upper_id\n+                            );\n+                        }\n+                    }\n+                }\n+            }\n+\n+            for (collectible, (flag, task_ids)) in collectibles {\n+                if !flag {\n+                    use std::io::Write;\n+                    let mut stdout = stdout().lock();\n+                    writeln!(\n+                        stdout,\n+                        \"{:?} that is not emitted in any child task but in these aggregated \\\n+                         tasks: {:#?}\",\n+                        collectible,\n+                        task_ids\n+                            .iter()\n+                            .map(|t| format!(\"{t} {}\", ctx.get_task_description(*t)))\n+                            .collect::<Vec<_>>()\n+                    );\n+\n+                    let task_id = collectible.cell.task;\n+                    let mut queue = {\n+                        let task = ctx.task(task_id, TaskDataCategory::All);\n+                        get_uppers(&task)\n+                    };\n+                    let mut visited = FxHashSet::default();\n+                    for &upper_id in queue.iter() {\n+                        visited.insert(upper_id);\n+                        writeln!(stdout, \"{task_id:?} -> {upper_id:?}\");\n+                    }\n+                    while let Some(task_id) = queue.pop() {\n+                        let desc = ctx.get_task_description(task_id);\n+                        let task = ctx.task(task_id, TaskDataCategory::All);\n+                        let aggregated_collectible =\n+                            get!(task, AggregatedCollectible { collectible })\n+                                .copied()\n+                                .unwrap_or_default();\n+                        let uppers = get_uppers(&task);\n+                        drop(task);\n+                        writeln!(\n+                            stdout,\n+                            \"upper {task_id} {desc} collectible={aggregated_collectible}\"\n+                        );\n+                        if task_ids.contains(&task_id) {\n+                            writeln!(\n+                                stdout,\n+                                \"Task has an upper connection to an aggregated task that doesn't \\\n+                                 reference it. Upper connection is invalid!\"\n+                            );\n+                        }\n+                        for upper_id in uppers {\n+                            writeln!(stdout, \"{task_id:?} -> {upper_id:?}\");\n+                            if !visited.contains(&upper_id) {\n+                                queue.push(upper_id);\n+                            }\n+                        }\n+                    }\n+                }\n+            }\n+            println!(\"visited {task_id} {} tasks\", visited.len());\n+        }\n+    }\n+\n     fn assert_not_persistent_calling_transient(\n         &self,\n         parent_id: TaskId,\n@@ -2254,12 +2473,12 @@ impl<B: BackingStorage> Backend for TurboTasksBackend<B> {\n         self.0.stopping();\n     }\n \n-    fn stop(&self, _turbo_tasks: &dyn TurboTasksBackendApi<Self>) {\n-        self.0.stop();\n+    fn stop(&self, turbo_tasks: &dyn TurboTasksBackendApi<Self>) {\n+        self.0.stop(turbo_tasks);\n     }\n \n-    fn idle_start(&self, _turbo_tasks: &dyn TurboTasksBackendApi<Self>) {\n-        self.0.idle_start();\n+    fn idle_start(&self, turbo_tasks: &dyn TurboTasksBackendApi<Self>) {\n+        self.0.idle_start(turbo_tasks);\n     }\n \n     fn idle_end(&self, _turbo_tasks: &dyn TurboTasksBackendApi<Self>) {"
        }
    ],
    "stats": {
        "total": 232,
        "additions": 226,
        "deletions": 6
    }
}