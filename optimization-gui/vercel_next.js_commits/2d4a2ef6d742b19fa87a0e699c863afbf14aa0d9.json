{
    "author": "sokra",
    "message": "Turbopack: prefetch restoring of task dependencies (#82960)\n\n### What?\n\nWhen scheduling a task, we also prefetch all dependencies of the tasks so that they are restored from the persistent cache in parallel.",
    "sha": "2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
    "files": [
        {
            "sha": "ac6f70958a3748f449a57e9b289149994c6a52ca",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 47,
            "deletions": 7,
            "changes": 54,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -3,6 +3,7 @@ mod operation;\n mod storage;\n \n use std::{\n+    any::Any,\n     borrow::Cow,\n     fmt::{self, Write},\n     future::Future,\n@@ -23,7 +24,7 @@ use parking_lot::{Condvar, Mutex};\n use rustc_hash::{FxHashMap, FxHashSet, FxHasher};\n use smallvec::{SmallVec, smallvec};\n use tokio::time::{Duration, Instant};\n-use tracing::field::Empty;\n+use tracing::{field::Empty, info_span};\n use turbo_tasks::{\n     CellId, FxDashMap, KeyValuePair, RawVc, ReadCellOptions, ReadConsistency, SessionId,\n     TRANSIENT_TASK_BIT, TaskExecutionReason, TaskId, TraitTypeId, TurboTasksBackendApi,\n@@ -38,7 +39,7 @@ use turbo_tasks::{\n     task_statistics::TaskStatisticsApi,\n     trace::TraceRawVcs,\n     turbo_tasks,\n-    util::IdFactoryWithReuse,\n+    util::{IdFactoryWithReuse, good_chunk_size, into_chunks},\n };\n \n pub use self::{operation::AnyOperation, storage::TaskDataCategory};\n@@ -71,6 +72,8 @@ use crate::{\n \n const BACKEND_JOB_INITIAL_SNAPSHOT: BackendJobId = unsafe { BackendJobId::new_unchecked(1) };\n const BACKEND_JOB_FOLLOW_UP_SNAPSHOT: BackendJobId = unsafe { BackendJobId::new_unchecked(2) };\n+const BACKEND_JOB_PREFETCH_TASK: BackendJobId = unsafe { BackendJobId::new_unchecked(3) };\n+const BACKEND_JOB_PREFETCH_CHUNK_TASK: BackendJobId = unsafe { BackendJobId::new_unchecked(4) };\n \n const SNAPSHOT_REQUESTED_BIT: usize = 1 << (usize::BITS - 1);\n \n@@ -744,7 +747,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         // It's not possible that the task is InProgress at this point. If it is InProgress {\n         // done: true } it must have Output and would early return.\n         task.add_new(item);\n-        turbo_tasks.schedule(task_id);\n+        ctx.schedule_task(task);\n \n         Ok(Err(listener))\n     }\n@@ -873,7 +876,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                 || self.get_task_desc_fn(task_id),\n             ))\n         {\n-            turbo_tasks.schedule(task_id);\n+            ctx.schedule_task(task);\n         }\n \n         Ok(Err(listener))\n@@ -1207,7 +1210,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n \n         if self.should_persist() {\n             // Schedule the snapshot job\n-            turbo_tasks.schedule_backend_background_job(BACKEND_JOB_INITIAL_SNAPSHOT);\n+            turbo_tasks.schedule_backend_background_job(BACKEND_JOB_INITIAL_SNAPSHOT, None);\n         }\n     }\n \n@@ -2133,6 +2136,7 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n     fn run_backend_job<'a>(\n         self: &'a Arc<Self>,\n         id: BackendJobId,\n+        data: Option<Box<dyn Any + Send>>,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<TurboTasksBackend<B>>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>> {\n         Box::pin(async move {\n@@ -2203,10 +2207,45 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n                             Ordering::Relaxed,\n                         );\n \n-                        turbo_tasks.schedule_backend_background_job(BACKEND_JOB_FOLLOW_UP_SNAPSHOT);\n+                        turbo_tasks\n+                            .schedule_backend_background_job(BACKEND_JOB_FOLLOW_UP_SNAPSHOT, None);\n                         return;\n                     }\n                 }\n+            } else if id == BACKEND_JOB_PREFETCH_TASK || id == BACKEND_JOB_PREFETCH_CHUNK_TASK {\n+                const DATA_EXPECTATION: &str =\n+                    \"Expected data to be a FxHashMap<TaskId, bool> for BACKEND_JOB_PREFETCH_TASK\";\n+                let data = Box::<dyn Any + Send>::downcast::<Vec<(TaskId, bool)>>(\n+                    data.expect(DATA_EXPECTATION),\n+                )\n+                .expect(DATA_EXPECTATION);\n+\n+                fn prefetch_task(ctx: &mut impl ExecuteContext<'_>, task: TaskId, with_data: bool) {\n+                    let category = if with_data {\n+                        TaskDataCategory::All\n+                    } else {\n+                        TaskDataCategory::Meta\n+                    };\n+                    // Prefetch the task\n+                    drop(ctx.task(task, category));\n+                }\n+\n+                if id == BACKEND_JOB_PREFETCH_TASK && data.len() > 128 {\n+                    let chunk_size = good_chunk_size(data.len());\n+                    for chunk in into_chunks(*data, chunk_size) {\n+                        let data: Box<Vec<(TaskId, bool)>> = Box::new(chunk.collect::<Vec<_>>());\n+                        turbo_tasks.schedule_backend_foreground_job(\n+                            BACKEND_JOB_PREFETCH_CHUNK_TASK,\n+                            Some(data),\n+                        );\n+                    }\n+                } else {\n+                    let _span = info_span!(\"prefetching\").entered();\n+                    let mut ctx = self.execute_context(turbo_tasks);\n+                    for (task, with_data) in data.into_iter() {\n+                        prefetch_task(&mut ctx, task, with_data);\n+                    }\n+                }\n             }\n         })\n     }\n@@ -2898,9 +2937,10 @@ impl<B: BackingStorage> Backend for TurboTasksBackend<B> {\n     fn run_backend_job<'a>(\n         &'a self,\n         id: BackendJobId,\n+        data: Option<Box<dyn Any + Send>>,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<Self>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>> {\n-        self.0.run_backend_job(id, turbo_tasks)\n+        self.0.run_backend_job(id, data, turbo_tasks)\n     }\n \n     fn try_read_task_output("
        },
        {
            "sha": "d45700a396136e64fc73cfa6a2d76e3564966498",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/aggregation_update.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 10,
            "changes": 22,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -1218,24 +1218,26 @@ impl AggregationUpdateQueue {\n         } else {\n             None\n         };\n-        if let Some(reason) = should_schedule {\n-            let description = || ctx.get_task_desc_fn(task_id);\n-            if task.add(CachedDataItem::new_scheduled(reason, description)) {\n-                ctx.schedule(task_id);\n-            }\n-        }\n+\n         // if it has `Activeness` we can skip visiting the nested nodes since\n         // this would already be scheduled by the `Activeness`\n         let is_active_until_clean = get!(task, Activeness).is_some_and(|a| a.active_until_clean);\n         if !is_active_until_clean {\n-            let dirty_containers: Vec<_> = get_many!(task, AggregatedDirtyContainer { task } count if count.get(session_id) > 0 => task);\n-            if !dirty_containers.is_empty() || dirty {\n+            let mut dirty_containers = iter_many!(task, AggregatedDirtyContainer { task } count if count.get(session_id) > 0 => task).peekable();\n+            let is_empty = dirty_containers.peek().is_none();\n+            if !is_empty || dirty {\n+                self.extend_find_and_schedule_dirty(dirty_containers);\n+\n                 let activeness_state =\n                     get_mut_or_insert_with!(task, Activeness, || ActivenessState::new(task_id));\n                 activeness_state.set_active_until_clean();\n+            }\n+        }\n+        if let Some(reason) = should_schedule {\n+            let description = || ctx.get_task_desc_fn(task_id);\n+            if task.add(CachedDataItem::new_scheduled(reason, description)) {\n                 drop(task);\n-\n-                self.extend_find_and_schedule_dirty(dirty_containers);\n+                ctx.schedule(task_id);\n             }\n         }\n     }"
        },
        {
            "sha": "f249b43883e9c370639e2668acc1f4b381315fd3",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/connect_child.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 16,
            "changes": 28,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_child.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -25,16 +25,14 @@ pub enum ConnectChildOperation {\n impl ConnectChildOperation {\n     pub fn run(parent_task_id: TaskId, child_task_id: TaskId, mut ctx: impl ExecuteContext) {\n         if !ctx.should_track_children() {\n-            let mut task = ctx.task(child_task_id, TaskDataCategory::All);\n-            if !task.has_key(&CachedDataItemKey::Output {}) {\n-                let should_schedule = task.add(CachedDataItem::new_scheduled(\n+            let mut child_task = ctx.task(child_task_id, TaskDataCategory::All);\n+            if !child_task.has_key(&CachedDataItemKey::Output {})\n+                && child_task.add(CachedDataItem::new_scheduled(\n                     TaskExecutionReason::Connect,\n                     || ctx.get_task_desc_fn(child_task_id),\n-                ));\n-                drop(task);\n-                if should_schedule {\n-                    ctx.schedule(child_task_id);\n-                }\n+                ))\n+            {\n+                ctx.schedule_task(child_task);\n             }\n             return;\n         }\n@@ -76,17 +74,15 @@ impl ConnectChildOperation {\n                 task: child_task_id,\n             });\n         } else {\n-            let mut task = ctx.task(child_task_id, TaskDataCategory::All);\n+            let mut child_task = ctx.task(child_task_id, TaskDataCategory::All);\n \n-            if !task.has_key(&CachedDataItemKey::Output {}) {\n-                let should_schedule = task.add(CachedDataItem::new_scheduled(\n+            if !child_task.has_key(&CachedDataItemKey::Output {})\n+                && child_task.add(CachedDataItem::new_scheduled(\n                     TaskExecutionReason::Connect,\n                     || ctx.get_task_desc_fn(child_task_id),\n-                ));\n-                drop(task);\n-                if should_schedule {\n-                    ctx.schedule(child_task_id);\n-                }\n+                ))\n+            {\n+                ctx.schedule_task(child_task);\n             }\n         }\n "
        },
        {
            "sha": "d76912c940a45ed38bd5d8662cdd98d78422cc4e",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/invalidate.rs",
            "status": "modified",
            "additions": 8,
            "deletions": 6,
            "changes": 14,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Finvalidate.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -176,10 +176,10 @@ pub fn make_task_dirty(\n         return;\n     }\n \n-    let mut task = ctx.task(task_id, TaskDataCategory::Meta);\n+    let task = ctx.task(task_id, TaskDataCategory::Meta);\n \n     make_task_dirty_internal(\n-        &mut task,\n+        task,\n         task_id,\n         true,\n         #[cfg(feature = \"trace_task_dirty\")]\n@@ -190,12 +190,12 @@ pub fn make_task_dirty(\n }\n \n pub fn make_task_dirty_internal(\n-    task: &mut impl TaskGuard,\n+    mut task: impl TaskGuard,\n     task_id: TaskId,\n     make_stale: bool,\n     #[cfg(feature = \"trace_task_dirty\")] cause: TaskDirtyCause,\n     queue: &mut AggregationUpdateQueue,\n-    ctx: &impl ExecuteContext,\n+    ctx: &mut impl ExecuteContext,\n ) {\n     // There must be no way to invalidate immutable tasks. If there would be a way the task is not\n     // immutable.\n@@ -286,7 +286,7 @@ pub fn make_task_dirty_internal(\n         });\n         if !aggregated_update.is_zero() {\n             queue.extend(AggregationUpdateJob::data_update(\n-                task,\n+                &mut task,\n                 AggregatedDataUpdate::new().dirty_container_update(task_id, aggregated_update),\n             ));\n         }\n@@ -301,7 +301,9 @@ pub fn make_task_dirty_internal(\n             TaskExecutionReason::Invalidated,\n             description,\n         )) {\n-            ctx.schedule(task_id);\n+            drop(task);\n+            let task = ctx.task(task_id, TaskDataCategory::All);\n+            ctx.schedule_task(task);\n         }\n     }\n }"
        },
        {
            "sha": "c9ca06ded5aa1a9bd0a4fef0adba34c3fd3e66e8",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/mod.rs",
            "status": "modified",
            "additions": 34,
            "deletions": 5,
            "changes": 39,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fmod.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -14,13 +14,15 @@ use std::{\n     sync::atomic::Ordering,\n };\n \n+use rustc_hash::FxHashMap;\n use serde::{Deserialize, Serialize};\n use turbo_tasks::{KeyValuePair, SessionId, TaskId, TurboTasksBackendApi};\n \n use crate::{\n     backend::{\n-        OperationGuard, TaskDataCategory, TransientTask, TurboTasksBackend, TurboTasksBackendInner,\n-        storage::{SpecificTaskDataCategory, StorageWriteGuard},\n+        BACKEND_JOB_PREFETCH_TASK, OperationGuard, TaskDataCategory, TransientTask,\n+        TurboTasksBackend, TurboTasksBackendInner,\n+        storage::{SpecificTaskDataCategory, StorageWriteGuard, iter_many},\n     },\n     backing_storage::BackingStorage,\n     data::{\n@@ -56,7 +58,8 @@ pub trait ExecuteContext<'e>: Sized {\n         task_id2: TaskId,\n         category: TaskDataCategory,\n     ) -> (impl TaskGuard + 'e, impl TaskGuard + 'e);\n-    fn schedule(&self, task_id: TaskId);\n+    fn schedule(&mut self, task_id: TaskId);\n+    fn schedule_task(&self, task: impl TaskGuard + '_);\n     fn operation_suspend_point<T>(&mut self, op: &T)\n     where\n         T: Clone + Into<AnyOperation>;\n@@ -255,8 +258,19 @@ where\n         )\n     }\n \n-    fn schedule(&self, task_id: TaskId) {\n-        self.turbo_tasks.schedule(task_id);\n+    fn schedule(&mut self, task_id: TaskId) {\n+        let task = self.task(task_id, TaskDataCategory::All);\n+        self.schedule_task(task);\n+    }\n+\n+    fn schedule_task(&self, mut task: impl TaskGuard + '_) {\n+        if let Some(tasks_to_prefetch) = task.prefetch() {\n+            self.turbo_tasks.schedule_backend_foreground_job(\n+                BACKEND_JOB_PREFETCH_TASK,\n+                Some(Box::new(tasks_to_prefetch)),\n+            );\n+        }\n+        self.turbo_tasks.schedule(task.id());\n     }\n \n     fn operation_suspend_point<T: Clone + Into<AnyOperation>>(&mut self, op: &T) {\n@@ -322,6 +336,7 @@ pub trait TaskGuard: Debug {\n     where\n         F: for<'a> FnMut(CachedDataItemKey, CachedDataItemValueRef<'a>) -> bool + 'l;\n     fn invalidate_serialization(&mut self);\n+    fn prefetch(&mut self) -> Option<Vec<(TaskId, bool)>>;\n     fn is_immutable(&self) -> bool;\n }\n \n@@ -511,6 +526,20 @@ impl<B: BackingStorage> TaskGuard for TaskGuardImpl<'_, B> {\n         }\n     }\n \n+    fn prefetch(&mut self) -> Option<Vec<(TaskId, bool)>> {\n+        if !self.task.state().prefetched() {\n+            self.task.state_mut().set_prefetched(true);\n+            let map = iter_many!(self, OutputDependency { target } => (target, false))\n+                .chain(iter_many!(self, CellDependency { target } => (target.task, true)))\n+                .chain(iter_many!(self, CollectiblesDependency { target } => (target.task, true)))\n+                .collect::<FxHashMap<_, _>>();\n+            if map.len() > 16 {\n+                return Some(map.into_iter().collect());\n+            }\n+        }\n+        None\n+    }\n+\n     fn is_immutable(&self) -> bool {\n         self.task.contains_key(&CachedDataItemKey::Immutable {})\n     }"
        },
        {
            "sha": "5b62b5f9d73f723d6c79c9d42ffedc5ee9718043",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/update_output.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_output.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_output.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fupdate_output.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -116,16 +116,15 @@ impl UpdateOutputOperation {\n             }\n \n             make_task_dirty_internal(\n-                &mut task,\n+                task,\n                 task_id,\n                 false,\n                 #[cfg(feature = \"trace_task_dirty\")]\n                 TaskDirtyCause::InitialDirty,\n                 &mut queue,\n-                &ctx,\n+                &mut ctx,\n             );\n \n-            drop(task);\n             drop(old_content);\n         }\n \n@@ -173,10 +172,10 @@ impl Operation for UpdateOutputOperation {\n                     ref mut queue,\n                 } => {\n                     if let Some(child_id) = children.pop() {\n-                        let mut child_task = ctx.task(child_id, TaskDataCategory::Meta);\n+                        let child_task = ctx.task(child_id, TaskDataCategory::Meta);\n                         if !child_task.has_key(&CachedDataItemKey::Output {}) {\n                             make_task_dirty_internal(\n-                                &mut child_task,\n+                                child_task,\n                                 child_id,\n                                 false,\n                                 #[cfg(feature = \"trace_task_dirty\")]"
        },
        {
            "sha": "6e96a34a5acbbabcbab7baac5955d1de54f8f3d5",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/storage.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fstorage.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -101,6 +101,8 @@ bitfield! {\n     /// Item was modified after snapshot mode was entered. A snapshot was taken.\n     pub meta_snapshot, set_meta_snapshot: 4;\n     pub data_snapshot, set_data_snapshot: 5;\n+    /// Prefetched dependencies\n+    pub prefetched, set_prefetched: 6;\n }\n \n impl InnerStorageState {"
        },
        {
            "sha": "d1f59fdb697200a269f58edcc5bfec66fdef5c34",
            "filename": "turbopack/crates/turbo-tasks/src/backend.rs",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -1,4 +1,5 @@\n use std::{\n+    any::Any,\n     borrow::Cow,\n     error::Error,\n     fmt::{self, Debug, Display},\n@@ -585,6 +586,7 @@ pub trait Backend: Sync + Send {\n     fn run_backend_job<'a>(\n         &'a self,\n         id: BackendJobId,\n+        data: Option<Box<dyn Any + Send>>,\n         turbo_tasks: &'a dyn TurboTasksBackendApi<Self>,\n     ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>>;\n "
        },
        {
            "sha": "dfd0d26c91b12d25592f664bc92315abf6b322b0",
            "filename": "turbopack/crates/turbo-tasks/src/manager.rs",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -250,8 +250,8 @@ pub trait TurboTasksBackendApi<B: Backend + 'static>: TurboTasksCallApi + Sync +\n     unsafe fn reuse_transient_task_id(&self, id: Unused<TaskId>);\n \n     fn schedule(&self, task: TaskId);\n-    fn schedule_backend_background_job(&self, id: BackendJobId);\n-    fn schedule_backend_foreground_job(&self, id: BackendJobId);\n+    fn schedule_backend_background_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>);\n+    fn schedule_backend_foreground_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>);\n \n     fn try_foreground_done(&self) -> Result<(), EventListener>;\n     fn wait_foreground_done_excluding_own<'a>(\n@@ -1478,16 +1478,16 @@ impl<B: Backend + 'static> TurboTasksBackendApi<B> for TurboTasks<B> {\n     }\n \n     #[track_caller]\n-    fn schedule_backend_background_job(&self, id: BackendJobId) {\n+    fn schedule_backend_background_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>) {\n         self.schedule_background_job(move |this| async move {\n-            this.backend.run_backend_job(id, &*this).await;\n+            this.backend.run_backend_job(id, data, &*this).await;\n         })\n     }\n \n     #[track_caller]\n-    fn schedule_backend_foreground_job(&self, id: BackendJobId) {\n+    fn schedule_backend_foreground_job(&self, id: BackendJobId, data: Option<Box<dyn Any + Send>>) {\n         self.schedule_foreground_job(move |this| async move {\n-            this.backend.run_backend_job(id, &*this).await;\n+            this.backend.run_backend_job(id, data, &*this).await;\n         })\n     }\n "
        },
        {
            "sha": "0883c2b27ed6165cf9a433e27c7a992b2325c5c3",
            "filename": "turbopack/crates/turbo-tasks/src/parallel.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 12,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -4,18 +4,10 @@\n //! tokio. It also avoid having multiple thread pools.\n //! see also https://pwy.io/posts/mimalloc-cigarette/\n \n-use std::{sync::LazyLock, thread::available_parallelism};\n-\n-use crate::{scope::scope_and_block, util::into_chunks};\n-\n-/// Calculates a good chunk size for parallel processing based on the number of available threads.\n-/// This is used to ensure that the workload is evenly distributed across the threads.\n-fn good_chunk_size(len: usize) -> usize {\n-    static GOOD_CHUNK_COUNT: LazyLock<usize> =\n-        LazyLock::new(|| available_parallelism().map_or(16, |c| c.get() * 4));\n-    let min_chunk_count = *GOOD_CHUNK_COUNT;\n-    len.div_ceil(min_chunk_count)\n-}\n+use crate::{\n+    scope::scope_and_block,\n+    util::{good_chunk_size, into_chunks},\n+};\n \n pub fn for_each<'l, T, F>(items: &'l [T], f: F)\n where"
        },
        {
            "sha": "b9ae1a68557fb781ff9568c3948e58fb206b95d3",
            "filename": "turbopack/crates/turbo-tasks/src/util.rs",
            "status": "modified",
            "additions": 11,
            "deletions": 1,
            "changes": 12,
            "blob_url": "https://github.com/vercel/next.js/blob/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Futil.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Futil.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Futil.rs?ref=2d4a2ef6d742b19fa87a0e699c863afbf14aa0d9",
            "patch": "@@ -7,8 +7,9 @@ use std::{\n     mem::ManuallyDrop,\n     ops::Deref,\n     pin::Pin,\n-    sync::Arc,\n+    sync::{Arc, LazyLock},\n     task::{Context, Poll},\n+    thread::available_parallelism,\n     time::Duration,\n };\n \n@@ -262,6 +263,15 @@ impl<F: Future, W: for<'a> Fn(Pin<&mut F>, &mut Context<'a>) -> Poll<F::Output>>\n     }\n }\n \n+/// Calculates a good chunk size for parallel processing based on the number of available threads.\n+/// This is used to ensure that the workload is evenly distributed across the threads.\n+pub fn good_chunk_size(len: usize) -> usize {\n+    static GOOD_CHUNK_COUNT: LazyLock<usize> =\n+        LazyLock::new(|| available_parallelism().map_or(16, |c| c.get() * 4));\n+    let min_chunk_count = *GOOD_CHUNK_COUNT;\n+    len.div_ceil(min_chunk_count)\n+}\n+\n /// Similar to slice::chunks but for owned data. Chunks are Send and Sync to allow to use it for\n /// parallelism.\n pub fn into_chunks<T>(data: Vec<T>, chunk_size: usize) -> IntoChunks<T> {"
        }
    ],
    "stats": {
        "total": 210,
        "additions": 142,
        "deletions": 68
    }
}