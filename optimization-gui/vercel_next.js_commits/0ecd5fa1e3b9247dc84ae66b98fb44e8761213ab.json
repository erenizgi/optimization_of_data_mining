{
    "author": "unstubbable",
    "message": "Use React's `prerender` function for `\"use cache\"` with Dynamic IO (#78382)\n\nDuring prerendering, we don't need to return a stream early for a `\"use\ncache\"` function. We can instead prerender the cache function fully,\nbefore returning the prelude as the stream. This simplifies the timeout\nhandling a bit, when `dynamicIO` is enabled, and more importantly, it\nprepares us for handling cookies access in `\"use cache\"` functions\nduring prerendering.\n\n- [x] depends on facebook/react#32953",
    "sha": "0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab",
    "files": [
        {
            "sha": "12a996ebd46735a45e9e19495b86336a0c375589",
            "filename": "packages/next/src/server/use-cache/use-cache-wrapper.ts",
            "status": "modified",
            "additions": 94,
            "deletions": 47,
            "changes": 141,
            "blob_url": "https://github.com/vercel/next.js/blob/0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts?ref=0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab",
            "patch": "@@ -6,12 +6,13 @@ import {\n   decodeReplyFromAsyncIterable,\n   createTemporaryReferenceSet as createServerTemporaryReferenceSet,\n } from 'react-server-dom-webpack/server.edge'\n-/* eslint-disable import/no-extraneous-dependencies */\n import {\n   createFromReadableStream,\n   encodeReply,\n   createTemporaryReferenceSet as createClientTemporaryReferenceSet,\n } from 'react-server-dom-webpack/client.edge'\n+import { unstable_prerender as prerender } from 'react-server-dom-webpack/static.edge'\n+/* eslint-enable import/no-extraneous-dependencies */\n \n import type { WorkStore } from '../app-render/work-async-storage.external'\n import { workAsyncStorage } from '../app-render/work-async-storage.external'\n@@ -224,8 +225,7 @@ async function collectResult(\n   outerWorkUnitStore: WorkUnitStore | undefined,\n   innerCacheStore: UseCacheStore,\n   startTime: number,\n-  errors: Array<unknown>, // This is a live array that gets pushed into.,\n-  timer: any\n+  errors: Array<unknown> // This is a live array that gets pushed into.\n ): Promise<CacheEntry> {\n   // We create a buffered stream that collects all chunks until the end to\n   // ensure that RSC has finished rendering and therefore we have collected\n@@ -242,8 +242,13 @@ async function collectResult(\n \n   const buffer: any[] = []\n   const reader = savedStream.getReader()\n-  for (let entry; !(entry = await reader.read()).done; ) {\n-    buffer.push(entry.value)\n+\n+  try {\n+    for (let entry; !(entry = await reader.read()).done; ) {\n+      buffer.push(entry.value)\n+    }\n+  } catch (error) {\n+    errors.push(error)\n   }\n \n   let idx = 0\n@@ -287,21 +292,19 @@ async function collectResult(\n     stale: collectedStale,\n     tags: collectedTags === null ? [] : collectedTags,\n   }\n+\n   // Propagate tags/revalidate to the parent context.\n   propagateCacheLifeAndTags(outerWorkUnitStore, entry)\n \n   const cacheSignal =\n     outerWorkUnitStore && outerWorkUnitStore.type === 'prerender'\n       ? outerWorkUnitStore.cacheSignal\n       : null\n+\n   if (cacheSignal) {\n     cacheSignal.endRead()\n   }\n \n-  if (timer !== undefined) {\n-    clearTimeout(timer)\n-  }\n-\n   return entry\n }\n \n@@ -363,53 +366,98 @@ async function generateCacheEntryImpl(\n   const resultPromise = createLazyResult(() => fn.apply(null, args))\n \n   let errors: Array<unknown> = []\n+  let timeoutErrorHandled = false\n+\n+  // In the \"Cache\" environment, we only need to make sure that the error\n+  // digests are handled correctly. Error formatting and reporting is not\n+  // necessary here; the errors are encoded in the stream, and will be reported\n+  // in the \"Server\" environment.\n+  const handleError = (error: unknown): string | undefined => {\n+    const digest = getDigestForWellKnownError(error)\n+\n+    if (digest) {\n+      return digest\n+    }\n+\n+    if (process.env.NODE_ENV !== 'development') {\n+      // TODO: For now we're also reporting the error here, because in\n+      // production, the \"Server\" environment will only get the obfuscated\n+      // error (created by the Flight Client in the cache wrapper).\n+      console.error(error)\n+    }\n+\n+    if (error === timeoutError) {\n+      timeoutErrorHandled = true\n+      // The timeout error already aborted the whole stream. We don't need\n+      // to also push this error into the `errors` array.\n+      return timeoutError.digest\n+    }\n+\n+    errors.push(error)\n+  }\n+\n+  let stream: ReadableStream<Uint8Array>\n \n-  let timer = undefined\n-  const controller = new AbortController()\n   if (outerWorkUnitStore?.type === 'prerender') {\n+    const timeoutAbortController = new AbortController()\n+\n     // If we're prerendering, we give you 50 seconds to fill a cache entry.\n     // Otherwise we assume you stalled on hanging input and de-opt. This needs\n     // to be lower than just the general timeout of 60 seconds.\n-    timer = setTimeout(() => {\n-      controller.abort(timeoutError)\n+    const timer = setTimeout(() => {\n+      timeoutAbortController.abort(timeoutError)\n     }, 50000)\n-  }\n \n-  const stream = renderToReadableStream(\n-    resultPromise,\n-    clientReferenceManifest.clientModules,\n-    {\n-      environmentName: 'Cache',\n-      signal: controller.signal,\n-      temporaryReferences,\n-      // In the \"Cache\" environment, we only need to make sure that the error\n-      // digests are handled correctly. Error formatting and reporting is not\n-      // necessary here; the errors are encoded in the stream, and will be\n-      // reported in the \"Server\" environment.\n-      onError: (error) => {\n-        const digest = getDigestForWellKnownError(error)\n-\n-        if (digest) {\n-          return digest\n-        }\n+    const { renderSignal } = outerWorkUnitStore\n \n-        if (process.env.NODE_ENV !== 'development') {\n-          // TODO: For now we're also reporting the error here, because in\n-          // production, the \"Server\" environment will only get the obfuscated\n-          // error (created by the Flight Client in the cache wrapper).\n-          console.error(error)\n-        }\n+    const abortSignal = AbortSignal.any([\n+      renderSignal,\n+      timeoutAbortController.signal,\n+    ])\n \n-        if (error === timeoutError) {\n-          // The timeout error already aborted the whole stream. We don't need\n-          // to also push this error into the `errors` array.\n-          return timeoutError.digest\n-        }\n+    const { prelude } = await prerender(\n+      resultPromise,\n+      clientReferenceManifest.clientModules,\n+      {\n+        environmentName: 'Cache',\n+        signal: abortSignal,\n+        temporaryReferences,\n+        onError(error) {\n+          if (renderSignal.aborted && renderSignal.reason === error) {\n+            return undefined\n+          }\n \n-        errors.push(error)\n-      },\n+          return handleError(error)\n+        },\n+      }\n+    )\n+\n+    clearTimeout(timer)\n+\n+    if (timeoutAbortController.signal.aborted && !timeoutErrorHandled) {\n+      // When halting is enabled, the prerender will not call `onError` when\n+      // it's aborted with the timeout abort signal, and hanging promises will\n+      // also not be rejected. In this case, we're creating an erroring stream\n+      // here, to ensure that the error is propagated to the server environment.\n+      stream = new ReadableStream({\n+        start(controller) {\n+          controller.error(timeoutError)\n+        },\n+      })\n+    } else {\n+      stream = prelude\n     }\n-  )\n+  } else {\n+    stream = renderToReadableStream(\n+      resultPromise,\n+      clientReferenceManifest.clientModules,\n+      {\n+        environmentName: 'Cache',\n+        temporaryReferences,\n+        onError: handleError,\n+      }\n+    )\n+  }\n \n   const [returnStream, savedStream] = stream.tee()\n \n@@ -419,8 +467,7 @@ async function generateCacheEntryImpl(\n     outerWorkUnitStore,\n     innerCacheStore,\n     startTime,\n-    errors,\n-    timer\n+    errors\n   )\n \n   // Return the stream as we're creating it. This means that if it ends up"
        },
        {
            "sha": "15bd1281777eda08e43fb782bf03ec8e6ba4d46e",
            "filename": "packages/next/types/$$compiled.internal.d.ts",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab/packages%2Fnext%2Ftypes%2F%24%24compiled.internal.d.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab/packages%2Fnext%2Ftypes%2F%24%24compiled.internal.d.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Ftypes%2F%24%24compiled.internal.d.ts?ref=0ecd5fa1e3b9247dc84ae66b98fb44e8761213ab",
            "patch": "@@ -217,6 +217,8 @@ declare module 'react-server-dom-webpack/server.node' {\n   ): Promise<ReactFormState | null>\n }\n declare module 'react-server-dom-webpack/static.edge' {\n+  export type TemporaryReferenceSet = WeakMap<any, string>\n+\n   export function unstable_prerender(\n     children: any,\n     webpackMap: {\n@@ -232,6 +234,7 @@ declare module 'react-server-dom-webpack/static.edge' {\n       filterStackFrame?: (url: string, functionName: string) => boolean\n       identifierPrefix?: string\n       signal?: AbortSignal\n+      temporaryReferences?: TemporaryReferenceSet\n       onError?: (error: unknown) => void\n       onPostpone?: (reason: string) => void\n     }"
        }
    ],
    "stats": {
        "total": 144,
        "additions": 97,
        "deletions": 47
    }
}