{
    "author": "sokra",
    "message": "Turbopack: avoid negative uppers and follower and use retry loop instead (#79451)\n\n### Why?\n\nMultiple graph modifications can happen concurrently. Each modification only locks one or two tasks in the graph at a single step, but a full graph modification could affect many tasks in graph. So modifications are executed step by step only affecting a maximum of two tasks on each step.\n\nBecause of this operation mode modifications bubble through the graph and multiple modifications can bubble through the graph concurrently, even at different speeds.\n\nOne important case is that an \"add\" modification could be partially applied, while a \"remove\" modification for the same item is triggered. This \"remove\" modification could be faster and would try to remove items from tasks where they have not been added yet (as the \"add\" modification is still in progress).\n\nTo account for this problem we used to allow negative counts on each item, so the \"remove\" modification would temporarily cause negative item counts until the \"add\" modification returns the count to zero.\n\nBut some decisions (e. g. if a upper or follower should be removed) are based on the values of these counts, so this approach doesn't work correctly in some rare race condition edge cases. So this change uses a different approach.\n\n### What?\n\nWe want to avoid negative counts, so when the \"remove\" modification tries to remove an non-existent item, it should wait for the \"add\" modification to catch up before continuing. There are two cases here: Either the \"add\" modification is done by a different thread, or it's done by the same thread and is in the queue. The first case is handled by a busy loop yielding. The second case is handled by re-enqueuing the job at the end of the queue.\n\nThere is a limit of 10s for retries after that we panic. This allows to detect invalid graph scenarios and points out bugs in the graph implementation. Let's hope we never see this panic. In the old implementation this problem was silently ignored: Count got negative, but that was just accepted and has let to weird side effects (like errors/collectibles not disappearing or hanging compilation).",
    "sha": "5dad2d4f2cb9a8b6bc4b6968fea326bd41219140",
    "files": [
        {
            "sha": "56619cee3d99891ee0db9613d346ec54cdf22f3b",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/aggregation_update.rs",
            "status": "modified",
            "additions": 329,
            "deletions": 193,
            "changes": 522,
            "blob_url": "https://github.com/vercel/next.js/blob/5dad2d4f2cb9a8b6bc4b6968fea326bd41219140/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/5dad2d4f2cb9a8b6bc4b6968fea326bd41219140/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Faggregation_update.rs?ref=5dad2d4f2cb9a8b6bc4b6968fea326bd41219140",
            "patch": "@@ -4,8 +4,12 @@ use std::{\n     hash::Hash,\n     mem::take,\n     num::NonZeroU32,\n+    ops::ControlFlow,\n+    thread::yield_now,\n+    time::{Duration, Instant},\n };\n \n+use anyhow::Result;\n use indexmap::map::Entry;\n use rustc_hash::{FxHashMap, FxHashSet};\n use serde::{Deserialize, Serialize, Serializer, ser::SerializeSeq};\n@@ -151,13 +155,15 @@ pub enum AggregationUpdateJob {\n     InnerOfUppersLostFollower {\n         upper_ids: TaskIdVec,\n         lost_follower_id: TaskId,\n+        retry: u16,\n     },\n     /// Notifies multiple upper tasks that one of its inner tasks has lost followers.\n     InnerOfUppersLostFollowers(Box<InnerOfUppersLostFollowersJob>),\n     /// Notifies an upper task that one of its inner tasks has lost followers.\n     InnerOfUpperLostFollowers {\n         upper_id: TaskId,\n         lost_follower_ids: TaskIdVec,\n+        retry: u16,\n     },\n     /// Notifies an upper task about changed data from an inner task.\n     AggregatedDataUpdate(Box<AggregatedDataUpdateJob>),\n@@ -831,7 +837,7 @@ impl AggregationUpdateQueue {\n                             } else {\n                                 take(upper_ids)\n                             };\n-                            self.inner_of_uppers_lost_follower(ctx, lost_follower_id, upper_ids);\n+                            self.inner_of_uppers_lost_follower(ctx, lost_follower_id, upper_ids, 0);\n                         }\n                     } else if let Some(upper_id) = upper_ids.pop() {\n                         let lost_follower_ids = if !upper_ids.is_empty() {\n@@ -843,20 +849,22 @@ impl AggregationUpdateQueue {\n                         } else {\n                             take(lost_follower_ids)\n                         };\n-                        self.inner_of_upper_lost_followers(ctx, lost_follower_ids, upper_id);\n+                        self.inner_of_upper_lost_followers(ctx, lost_follower_ids, upper_id, 0);\n                     }\n                 }\n                 AggregationUpdateJob::InnerOfUppersLostFollower {\n                     upper_ids,\n                     lost_follower_id,\n+                    retry,\n                 } => {\n-                    self.inner_of_uppers_lost_follower(ctx, lost_follower_id, upper_ids);\n+                    self.inner_of_uppers_lost_follower(ctx, lost_follower_id, upper_ids, retry);\n                 }\n                 AggregationUpdateJob::InnerOfUpperLostFollowers {\n                     upper_id,\n                     lost_follower_ids,\n+                    retry,\n                 } => {\n-                    self.inner_of_upper_lost_followers(ctx, lost_follower_ids, upper_id);\n+                    self.inner_of_upper_lost_followers(ctx, lost_follower_ids, upper_id, retry);\n                 }\n                 AggregationUpdateJob::AggregatedDataUpdate(box AggregatedDataUpdateJob {\n                     upper_ids,\n@@ -1080,6 +1088,7 @@ impl AggregationUpdateQueue {\n                         self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n                             upper_ids,\n                             lost_follower_id: task_id,\n+                            retry: 0,\n                         });\n                     }\n \n@@ -1273,119 +1282,163 @@ impl AggregationUpdateQueue {\n         ctx: &mut impl ExecuteContext,\n         lost_follower_id: TaskId,\n         mut upper_ids: TaskIdVec,\n+        mut retry: u16,\n     ) {\n         #[cfg(feature = \"trace_aggregation_update\")]\n         let _span = trace_span!(\"lost follower (n uppers)\", uppers = upper_ids.len()).entered();\n \n-        let mut follower = ctx.task(\n-            lost_follower_id,\n-            // For performance reasons this should stay `Meta` and not `All`\n-            TaskDataCategory::Meta,\n-        );\n-        let mut follower_in_upper_ids = Vec::new();\n-        let mut persistent_uppers = 0;\n-        upper_ids.retain(|&mut upper_id| {\n-            let mut keep_upper = false;\n-            update!(follower, Upper { task: upper_id }, |old| {\n-                let Some(old) = old else {\n-                    follower_in_upper_ids.push(upper_id);\n-                    return None;\n-                };\n-                if old < 0 {\n-                    follower_in_upper_ids.push(upper_id);\n-                    return Some(old);\n-                }\n-                if old == 1 {\n-                    keep_upper = true;\n-                    if !upper_id.is_transient() {\n-                        persistent_uppers += 1;\n+        // see documentation of `retry_loop` for more information why this is needed\n+        let result = retry_loop(|| {\n+            let mut follower = ctx.task(\n+                lost_follower_id,\n+                // For performance reasons this should stay `Meta` and not `All`\n+                TaskDataCategory::Meta,\n+            );\n+            let mut removed_uppers = SmallVec::new();\n+            swap_retain(&mut upper_ids, |&mut upper_id| {\n+                let mut keep_upper = false;\n+                let mut follower_in_upper = false;\n+\n+                update!(follower, Upper { task: upper_id }, |old| {\n+                    let Some(old) = old else {\n+                        follower_in_upper = true;\n+                        return None;\n+                    };\n+                    if old < 0 {\n+                        follower_in_upper = true;\n+                        return Some(old);\n                     }\n-                    return None;\n-                }\n-                Some(old - 1)\n+                    if old == 1 {\n+                        keep_upper = true;\n+                        removed_uppers.push(upper_id);\n+                        return None;\n+                    }\n+                    Some(old - 1)\n+                });\n+                follower_in_upper\n             });\n-            keep_upper\n-        });\n-        if !upper_ids.is_empty() {\n-            let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n-            let followers = get_followers(&follower);\n-            drop(follower);\n+            if !removed_uppers.is_empty() {\n+                let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n+                let followers = get_followers(&follower);\n+                drop(follower);\n \n-            if !data.is_empty() {\n-                for upper_id in upper_ids.iter() {\n-                    // remove data from upper\n-                    let mut upper = ctx.task(\n-                        *upper_id,\n-                        // For performance reasons this should stay `Meta` and not `All`\n-                        TaskDataCategory::Meta,\n-                    );\n-                    let diff = data.apply(\n-                        &mut upper,\n-                        ctx.session_id(),\n-                        ctx.should_track_activeness(),\n-                        self,\n-                    );\n-                    if !diff.is_empty() {\n-                        let upper_ids = get_uppers(&upper);\n-                        self.push(\n-                            AggregatedDataUpdateJob {\n-                                upper_ids,\n-                                update: diff,\n-                            }\n-                            .into(),\n-                        )\n+                if !data.is_empty() {\n+                    for upper_id in removed_uppers.iter() {\n+                        // remove data from upper\n+                        let mut upper = ctx.task(\n+                            *upper_id,\n+                            // For performance reasons this should stay `Meta` and not `All`\n+                            TaskDataCategory::Meta,\n+                        );\n+                        let diff = data.apply(\n+                            &mut upper,\n+                            ctx.session_id(),\n+                            ctx.should_track_activeness(),\n+                            self,\n+                        );\n+                        if !diff.is_empty() {\n+                            let upper_ids = get_uppers(&upper);\n+                            self.push(\n+                                AggregatedDataUpdateJob {\n+                                    upper_ids,\n+                                    update: diff,\n+                                }\n+                                .into(),\n+                            )\n+                        }\n                     }\n                 }\n+                if !followers.is_empty() {\n+                    self.push(\n+                        InnerOfUppersLostFollowersJob {\n+                            upper_ids: removed_uppers.clone(),\n+                            lost_follower_ids: followers,\n+                        }\n+                        .into(),\n+                    );\n+                }\n+            } else {\n+                drop(follower);\n             }\n-            if !followers.is_empty() {\n-                self.push(\n-                    InnerOfUppersLostFollowersJob {\n-                        upper_ids: upper_ids.clone(),\n-                        lost_follower_ids: followers,\n+\n+            if upper_ids.is_empty() {\n+                return ControlFlow::Break(());\n+            }\n+            swap_retain(&mut upper_ids, |&mut upper_id| {\n+                let mut upper = ctx.task(\n+                    upper_id,\n+                    // For performance reasons this should stay `Meta` and not `All`\n+                    TaskDataCategory::Meta,\n+                );\n+                let mut inner_in_upper = false;\n+                let mut removed_follower = false;\n+                update!(\n+                    upper,\n+                    Follower {\n+                        task: lost_follower_id\n+                    },\n+                    |old| {\n+                        let Some(old) = old else {\n+                            inner_in_upper = true;\n+                            return None;\n+                        };\n+                        if old < 0 {\n+                            inner_in_upper = true;\n+                            return Some(old);\n+                        }\n+                        if old == 1 {\n+                            removed_follower = true;\n+                            return None;\n+                        }\n+                        Some(old - 1)\n                     }\n-                    .into(),\n                 );\n-            }\n-        } else {\n-            drop(follower);\n-        }\n-\n-        for upper_id in follower_in_upper_ids {\n-            let mut upper = ctx.task(\n-                upper_id,\n-                // For performance reasons this should stay `Meta` and not `All`\n-                TaskDataCategory::Meta,\n-            );\n-            if update_count!(\n-                upper,\n-                Follower {\n-                    task: lost_follower_id\n-                },\n-                -1\n-            ) {\n-                // May optimize the task\n-                if count!(upper, Follower).is_power_of_two() {\n-                    self.push_optimize_task(upper_id);\n-                }\n+                if removed_follower {\n+                    // May optimize the task\n+                    if count!(upper, Follower).is_power_of_two() {\n+                        self.push_optimize_task(upper_id);\n+                    }\n \n-                let has_active_count = ctx.should_track_activeness()\n-                    && get!(upper, Activeness).is_some_and(|a| a.active_counter > 0);\n-                let upper_ids = get_uppers(&upper);\n-                drop(upper);\n-                // update active count\n-                if has_active_count {\n-                    self.push(AggregationUpdateJob::DecreaseActiveCount {\n-                        task: lost_follower_id,\n-                    });\n-                }\n-                // notify uppers about new follower\n-                if !upper_ids.is_empty() {\n-                    self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n-                        upper_ids,\n-                        lost_follower_id,\n-                    });\n+                    let has_active_count = ctx.should_track_activeness()\n+                        && get!(upper, Activeness).is_some_and(|a| a.active_counter > 0);\n+                    let upper_ids = get_uppers(&upper);\n+                    drop(upper);\n+                    // update active count\n+                    if has_active_count {\n+                        self.push(AggregationUpdateJob::DecreaseActiveCount {\n+                            task: lost_follower_id,\n+                        });\n+                    }\n+                    // notify uppers about new follower\n+                    if !upper_ids.is_empty() {\n+                        self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n+                            upper_ids,\n+                            lost_follower_id,\n+                            retry: 0,\n+                        });\n+                    }\n                 }\n+                inner_in_upper\n+            });\n+            if upper_ids.is_empty() {\n+                return ControlFlow::Break(());\n+            }\n+            ControlFlow::Continue(())\n+        });\n+        if result.is_err() {\n+            retry += 1;\n+            if retry > MAX_RETRIES {\n+                panic!(\n+                    \"inner_of_uppers_lost_follower is not able to remove follower \\\n+                     {lost_follower_id:?} from {upper_ids:?} as they don't exist as upper or \\\n+                     follower edges\"\n+                );\n             }\n+            self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n+                upper_ids,\n+                lost_follower_id,\n+                retry,\n+            });\n         }\n     }\n \n@@ -1394,6 +1447,7 @@ impl AggregationUpdateQueue {\n         ctx: &mut impl ExecuteContext,\n         mut lost_follower_ids: TaskIdVec,\n         upper_id: TaskId,\n+        mut retry: u16,\n     ) {\n         #[cfg(feature = \"trace_aggregation_update\")]\n         let _span = trace_span!(\n@@ -1402,105 +1456,150 @@ impl AggregationUpdateQueue {\n         )\n         .entered();\n \n-        lost_follower_ids.retain(|lost_follower_id| {\n-            let mut follower = ctx.task(\n-                *lost_follower_id,\n-                // For performance reasons this should stay `Meta` and not `All`\n-                TaskDataCategory::Meta,\n-            );\n-            let mut remove_upper = false;\n-            let mut follower_in_upper = false;\n-            update!(follower, Upper { task: upper_id }, |old| {\n-                let Some(old) = old else {\n-                    follower_in_upper = true;\n-                    return None;\n-                };\n-                if old < 0 {\n-                    follower_in_upper = true;\n-                    return Some(old);\n-                }\n-                if old == 1 {\n-                    remove_upper = true;\n-                    return None;\n+        // see documentation of `retry_loop` for more information why this is needed\n+        let result = retry_loop(|| {\n+            swap_retain(&mut lost_follower_ids, |&mut lost_follower_id| {\n+                let mut follower = ctx.task(\n+                    lost_follower_id,\n+                    // For performance reasons this should stay `Meta` and not `All`\n+                    TaskDataCategory::Meta,\n+                );\n+                let mut remove_upper = false;\n+                let mut follower_in_upper = false;\n+                update!(follower, Upper { task: upper_id }, |old| {\n+                    let Some(old) = old else {\n+                        follower_in_upper = true;\n+                        return None;\n+                    };\n+                    if old < 0 {\n+                        follower_in_upper = true;\n+                        return Some(old);\n+                    }\n+                    if old == 1 {\n+                        remove_upper = true;\n+                        return None;\n+                    }\n+                    Some(old - 1)\n+                });\n+                if remove_upper {\n+                    let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n+                    let followers = get_followers(&follower);\n+                    drop(follower);\n+\n+                    if !data.is_empty() {\n+                        // remove data from upper\n+                        let mut upper = ctx.task(\n+                            upper_id,\n+                            // For performance reasons this should stay `Meta` and not `All`\n+                            TaskDataCategory::Meta,\n+                        );\n+                        let diff = data.apply(\n+                            &mut upper,\n+                            ctx.session_id(),\n+                            ctx.should_track_activeness(),\n+                            self,\n+                        );\n+                        if !diff.is_empty() {\n+                            let upper_ids = get_uppers(&upper);\n+                            self.push(\n+                                AggregatedDataUpdateJob {\n+                                    upper_ids,\n+                                    update: diff,\n+                                }\n+                                .into(),\n+                            )\n+                        }\n+                    }\n+                    if !followers.is_empty() {\n+                        self.push(AggregationUpdateJob::InnerOfUpperLostFollowers {\n+                            upper_id,\n+                            lost_follower_ids: followers,\n+                            retry: 0,\n+                        });\n+                    }\n+                } else {\n+                    drop(follower);\n                 }\n-                Some(old - 1)\n+                follower_in_upper\n             });\n-            if remove_upper {\n-                let data = AggregatedDataUpdate::from_task(&mut follower).invert();\n-                let followers = get_followers(&follower);\n-                drop(follower);\n+            if lost_follower_ids.is_empty() {\n+                return ControlFlow::Break(());\n+            }\n+            swap_retain(&mut lost_follower_ids, |&mut lost_follower_id| {\n+                let mut upper = ctx.task(\n+                    upper_id,\n+                    // For performance reasons this should stay `Meta` and not `All`\n+                    TaskDataCategory::Meta,\n+                );\n+                let mut inner_in_upper = false;\n+                let mut removed_follower = false;\n+                update!(\n+                    upper,\n+                    Follower {\n+                        task: lost_follower_id\n+                    },\n+                    |old| {\n+                        let Some(old) = old else {\n+                            inner_in_upper = true;\n+                            return None;\n+                        };\n+                        if old < 0 {\n+                            inner_in_upper = true;\n+                            return Some(old);\n+                        }\n+                        if old == 1 {\n+                            removed_follower = true;\n+                            return None;\n+                        }\n+                        Some(old - 1)\n+                    }\n+                );\n+                if removed_follower {\n+                    // May optimize the task\n+                    if count!(upper, Follower).is_power_of_two() {\n+                        self.push_optimize_task(upper_id);\n+                    }\n \n-                if !data.is_empty() {\n-                    // remove data from upper\n-                    let mut upper = ctx.task(\n-                        upper_id,\n-                        // For performance reasons this should stay `Meta` and not `All`\n-                        TaskDataCategory::Meta,\n-                    );\n-                    let diff = data.apply(\n-                        &mut upper,\n-                        ctx.session_id(),\n-                        ctx.should_track_activeness(),\n-                        self,\n-                    );\n-                    if !diff.is_empty() {\n-                        let upper_ids = get_uppers(&upper);\n-                        self.push(\n-                            AggregatedDataUpdateJob {\n-                                upper_ids,\n-                                update: diff,\n-                            }\n-                            .into(),\n-                        )\n+                    let upper_ids = get_uppers(&upper);\n+                    let has_active_count =\n+                        get!(upper, Activeness).is_some_and(|a| a.active_counter > 0);\n+                    drop(upper);\n+                    // update active count\n+                    if has_active_count {\n+                        self.push(AggregationUpdateJob::DecreaseActiveCount {\n+                            task: lost_follower_id,\n+                        });\n+                    }\n+                    // notify uppers about new follower\n+                    if !upper_ids.is_empty() {\n+                        self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n+                            upper_ids,\n+                            lost_follower_id,\n+                            retry: 0,\n+                        });\n                     }\n                 }\n-                if !followers.is_empty() {\n-                    self.push(AggregationUpdateJob::InnerOfUpperLostFollowers {\n-                        upper_id,\n-                        lost_follower_ids: followers,\n-                    });\n-                }\n-            } else {\n-                drop(follower);\n+                inner_in_upper\n+            });\n+            if lost_follower_ids.is_empty() {\n+                return ControlFlow::Break(());\n             }\n-            follower_in_upper\n+            ControlFlow::Continue(())\n         });\n-        for lost_follower_id in lost_follower_ids {\n-            let mut upper = ctx.task(\n-                upper_id,\n-                // For performance reasons this should stay `Meta` and not `All`\n-                TaskDataCategory::Meta,\n-            );\n-            if update_count!(\n-                upper,\n-                Follower {\n-                    task: lost_follower_id\n-                },\n-                -1\n-            ) {\n-                // May optimize the task\n-                if count!(upper, Follower).is_power_of_two() {\n-                    self.push_optimize_task(upper_id);\n-                }\n-\n-                let upper_ids = get_uppers(&upper);\n-                let has_active_count =\n-                    get!(upper, Activeness).is_some_and(|a| a.active_counter > 0);\n-                drop(upper);\n-                // update active count\n-                if has_active_count {\n-                    self.push(AggregationUpdateJob::DecreaseActiveCount {\n-                        task: lost_follower_id,\n-                    });\n-                }\n-                // notify uppers about new follower\n-                if !upper_ids.is_empty() {\n-                    self.push(AggregationUpdateJob::InnerOfUppersLostFollower {\n-                        upper_ids,\n-                        lost_follower_id,\n-                    });\n-                }\n+        if result.is_err() {\n+            retry += 1;\n+            if retry > MAX_RETRIES {\n+                panic!(\n+                    \"inner_of_upper_lost_followers is not able to remove followers \\\n+                     {lost_follower_ids:?} from {upper_id:?} as they don't exist as upper or \\\n+                     follower edges\"\n+                )\n             }\n+            self.push(AggregationUpdateJob::InnerOfUpperLostFollowers {\n+                upper_id,\n+                lost_follower_ids,\n+                retry,\n+            });\n         }\n     }\n \n@@ -2355,3 +2454,40 @@ impl Operation for AggregationUpdateQueue {\n         }\n     }\n }\n+\n+struct RetryTimeout;\n+\n+const MAX_YIELD_DURATION: Duration = Duration::from_millis(1);\n+const MAX_RETRIES: u16 = 10000;\n+\n+/// Retry the passed function for a few milliseconds, while yielding to other threads.\n+/// Returns an error if the function was not ablue to complete and the timeout was reached.\n+///\n+/// Each graph modification will only lock one or two tasks at a time, but updates usually also\n+/// require follow-up updates to connected tasks. So an update will \"slowly\" propagate through the\n+/// graph. This can lead to the race condition when one update adds something and another update\n+/// removes the same thing. The \"add\" update might not be fully propagated through the graph yet and\n+/// the \"remove\" update can overtake the \"add\" update. When this happens the \"remove\" update is\n+/// unable to remove the things it wants to remove (because they have not been added by the \"add\"\n+/// update yet). So we will retry (with this method) removals until the thing is there. So this is\n+/// basically a busy loop that waits for the \"add\" update to complete. If the busy loop is not\n+/// sucessful, the update is added to the end of the queue again. This is important as the \"add\"\n+/// update might even be in the curreent thread and in the same queue. If that's the case yielding\n+/// won't help and the update need to be requeued.\n+fn retry_loop(mut f: impl FnMut() -> ControlFlow<()>) -> Result<(), RetryTimeout> {\n+    let mut time: Option<Instant> = None;\n+    loop {\n+        match f() {\n+            ControlFlow::Continue(()) => {}\n+            ControlFlow::Break(()) => return Ok(()),\n+        }\n+        yield_now();\n+        if let Some(t) = time {\n+            if t.elapsed() > MAX_YIELD_DURATION {\n+                return Err(RetryTimeout);\n+            }\n+        } else {\n+            time = Some(Instant::now());\n+        }\n+    }\n+}"
        },
        {
            "sha": "634226d61c4efc2eda092b9e4bf37757bac8ee6b",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/cleanup_old_edges.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/5dad2d4f2cb9a8b6bc4b6968fea326bd41219140/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/5dad2d4f2cb9a8b6bc4b6968fea326bd41219140/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fcleanup_old_edges.rs?ref=5dad2d4f2cb9a8b6bc4b6968fea326bd41219140",
            "patch": "@@ -98,6 +98,7 @@ impl Operation for CleanupOldEdgesOperation {\n                                     queue.push(AggregationUpdateJob::InnerOfUpperLostFollowers {\n                                         upper_id: task_id,\n                                         lost_follower_ids: children,\n+                                        retry: 0,\n                                     });\n                                 } else {\n                                     let upper_ids = get_uppers(&task);"
        }
    ],
    "stats": {
        "total": 523,
        "additions": 330,
        "deletions": 193
    }
}