{
    "author": "sokra",
    "message": "Turbopack: store frequently used entries separately in database (#85826)\n\n### What?\n\n* capture used key hashes and store them in the meta file\n* During compaction separate used and unused entries\n\nThis eventually leads to a state where frequently used entries are stored in separate files, which makes it faster to restore. This improves db restore performance after a few runs.",
    "sha": "27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
    "files": [
        {
            "sha": "ef8194063276bc1f7d836dfbec996b5bf50cf505",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 9,
            "deletions": 0,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -4512,6 +4512,12 @@ dependencies = [\n  \"libc\",\n ]\n \n+[[package]]\n+name = \"nohash-hasher\"\n+version = \"0.2.0\"\n+source = \"registry+https://github.com/rust-lang/crates.io-index\"\n+checksum = \"2bf50223579dc7cdcfb3bfcacf7069ff68243f8c363f62ffa99cf000a6b9c451\"\n+\n [[package]]\n name = \"nom\"\n version = \"5.1.3\"\n@@ -9129,11 +9135,14 @@ name = \"turbo-persistence\"\n version = \"0.1.0\"\n dependencies = [\n  \"anyhow\",\n+ \"bitfield\",\n  \"byteorder\",\n+ \"dashmap 6.1.0\",\n  \"either\",\n  \"jiff\",\n  \"lzzzz\",\n  \"memmap2 0.9.5\",\n+ \"nohash-hasher\",\n  \"parking_lot\",\n  \"pot\",\n  \"qfilter\","
        },
        {
            "sha": "dd8404ebc1f827c5b664853c66ace65af095e304",
            "filename": "Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/Cargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/Cargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.toml?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -422,6 +422,7 @@ napi = { version = \"2\", default-features = false, features = [\n   \"napi5\",\n   \"compat-mode\",\n ] }\n+nohash-hasher = \"0.2.0\"\n notify = \"8.1.0\"\n once_cell = \"1.17.1\"\n owo-colors = \"4.2.2\""
        },
        {
            "sha": "759242caea19ad794a0edc9f056564603d9df47a",
            "filename": "turbopack/crates/turbo-persistence-tools/src/main.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 2,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence-tools%2Fsrc%2Fmain.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -16,7 +16,7 @@ fn main() -> Result<()> {\n         bail!(\"The provided path does not exist: {}\", path.display());\n     }\n \n-    let db: TurboPersistence<SerialScheduler> = TurboPersistence::open_read_only(path)?;\n+    let db: TurboPersistence<SerialScheduler, 0> = TurboPersistence::open_read_only(path)?;\n     let meta_info = db\n         .meta_info()\n         .context(\"Failed to retrieve meta information\")?;\n@@ -34,12 +34,14 @@ fn main() -> Result<()> {\n             amqf_size,\n             amqf_entries,\n             sst_size,\n+            flags,\n             key_compression_dictionary_size,\n             block_count,\n         } in meta_file.entries\n         {\n             println!(\n-                \"  SST {sequence_number:08}.sst: {min_hash:016x} - {max_hash:016x} (p = 1/{})\",\n+                \"  SST {sequence_number:08}.sst: {flags} {min_hash:016x} - {max_hash:016x} (p = \\\n+                 1/{})\",\n                 u64::MAX / (max_hash - min_hash + 1)\n             );\n             println!(\"    AMQF {amqf_entries} entries = {} KiB\", amqf_size / 1024);"
        },
        {
            "sha": "e25a637f0ce04d8936244f2275145f5bffc182c9",
            "filename": "turbopack/crates/turbo-persistence/Cargo.toml",
            "status": "modified",
            "additions": 3,
            "deletions": 0,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FCargo.toml?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -14,12 +14,15 @@ verbose_log = []\n \n [dependencies]\n anyhow = { workspace = true }\n+bitfield = { workspace = true }\n+dashmap = { workspace = true}\n either = { workspace = true }\n pot = \"3.0.0\"\n byteorder = { workspace = true }\n jiff = \"0.2.10\"\n lzzzz = \"1.1.0\"\n memmap2 = \"0.9.5\"\n+nohash-hasher = { workspace = true }\n parking_lot = { workspace = true }\n qfilter = { version = \"0.2.4\", features = [\"serde\"] }\n quick_cache = { workspace = true }"
        },
        {
            "sha": "fc50fa2c6352d9d373bb93b2ca97117e2dd91fc1",
            "filename": "turbopack/crates/turbo-persistence/README.md",
            "status": "modified",
            "additions": 9,
            "deletions": 4,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2FREADME.md?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -49,9 +49,14 @@ A meta file can contain metadata about multiple SST files. The metadata is store\n     - 8 bytes min hash\n     - 8 bytes max hash\n     - 8 bytes SST file size\n+    - 4 bytes flags\n+      - bit 0: cold (compacted and not recently accessed)\n+      - bit 1: fresh (not yet compacted)\n     - 4 bytes end of AMQF offset relative to start of all AMQF data\n+  - 4 bytes end of AMQF offset relative to start of all AMQF data of the \"used key hashes\" AMQF\n - foreach described SST file\n   - serialized AMQF\n+- serialized \"used key hashes\" AMQF\n \n ### SST file\n \n@@ -169,7 +174,7 @@ Compaction chooses a few SST files and runs the merge step of merge sort on tham\n \n Example:\n \n-```\n+``` text\n key hash range: | 0    ...    u64::MAX |\n SST 1:             |----------------|\n SST 2:                |----------------|\n@@ -178,7 +183,7 @@ SST 3:            |-----|\n \n can be compacted into:\n \n-```\n+``` text\n key hash range: | 0    ...    u64::MAX |\n SST 1':           |-------|\n SST 2':                   |------|\n@@ -206,7 +211,7 @@ Full example:\n \n Example:\n \n-```\n+``` text\n key hash range: | 0    ...    u64::MAX | Family\n SST 1:             |-|                   1\n SST 2:             |----------------|    1\n@@ -234,7 +239,7 @@ Then we delete SST files 2, 3, 6 and 4, 5, 8 and 7, 9. The\n \n SST files 1 stays unchanged.\n \n-```\n+``` text\n key hash range: | 0    ...    u64::MAX | Family\n SST 1:             |-|                   1\n SST 10:            |-----|               1"
        },
        {
            "sha": "1e134f3b336fe25d2a7403c57fc8ef0e01a8496a",
            "filename": "turbopack/crates/turbo-persistence/src/compaction/selector.rs",
            "status": "modified",
            "additions": 28,
            "deletions": 9,
            "changes": 37,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompaction%2Fselector.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -1,5 +1,6 @@\n use std::ops::RangeInclusive;\n \n+use rustc_hash::FxHashMap;\n use smallvec::{SmallVec, smallvec};\n \n use crate::compaction::interval_map::IntervalMap;\n@@ -12,6 +13,12 @@ pub trait Compactable {\n \n     /// The size of the compactable database segment in bytes.\n     fn size(&self) -> u64;\n+\n+    /// The category of the compactable. Overlap between different categories is not considered for\n+    /// compaction.\n+    fn category(&self) -> u8 {\n+        0\n+    }\n }\n \n fn is_overlapping(a: &RangeInclusive<u64>, b: &RangeInclusive<u64>) -> bool {\n@@ -37,6 +44,7 @@ fn extend_range(a: &mut RangeInclusive<u64>, b: &RangeInclusive<u64>) -> bool {\n     extended\n }\n \n+#[cfg(test)]\n #[derive(Debug)]\n pub struct CompactableMetrics {\n     /// The total coverage of the compactables.\n@@ -53,6 +61,7 @@ pub struct CompactableMetrics {\n }\n \n /// Computes metrics about the compactables.\n+#[cfg(test)]\n pub fn compute_metrics<T: Compactable>(\n     compactables: &[T],\n     full_range: RangeInclusive<u64>,\n@@ -155,7 +164,7 @@ impl DuplicationInfo {\n     /// Get a value in the range `0..=u64` that represents the estimated amount of duplication\n     /// across the given range. The units are arbitrary, but linear.\n     fn duplication(&self, range: &RangeInclusive<u64>) -> u64 {\n-        if self.total_size == 0 {\n+        if self.max_size == self.total_size {\n             return 0;\n         }\n         // the maximum numerator value is `u64::MAX + 1`\n@@ -167,6 +176,7 @@ impl DuplicationInfo {\n     }\n \n     /// The estimated size (in bytes) of a database segment containing `range` keys.\n+    #[cfg(test)]\n     fn size(&self, range: &RangeInclusive<u64>) -> u64 {\n         if self.total_size == 0 {\n             return 0;\n@@ -190,11 +200,14 @@ impl DuplicationInfo {\n     }\n }\n \n-fn total_duplication_size(duplication: &IntervalMap<Option<DuplicationInfo>>) -> u64 {\n+fn total_duplication_size(duplication: &IntervalMap<FxHashMap<u8, DuplicationInfo>>) -> u64 {\n     duplication\n         .iter()\n-        .flat_map(|(range, info)| Some((range, info.as_ref()?)))\n-        .map(|(range, info)| info.duplication(&range))\n+        .map(|(range, info)| {\n+            info.values()\n+                .map(|info| info.duplication(&range))\n+                .sum::<u64>()\n+        })\n         .sum()\n }\n \n@@ -238,16 +251,18 @@ pub fn get_merge_segments<T: Compactable>(\n         }\n         let start_compactable_range = start_compactable.range();\n         let start_compactable_size = start_compactable.size();\n+        let start_compactable_category = start_compactable.category();\n         let mut current_range = start_compactable_range.clone();\n \n         // We might need to restart the search if we need to extend the range.\n         'search: loop {\n             let mut current_set = smallvec![start_index];\n             let mut current_size = start_compactable_size;\n-            let mut duplication = IntervalMap::<Option<DuplicationInfo>>::new();\n+            let mut duplication = IntervalMap::<FxHashMap<u8, DuplicationInfo>>::new();\n             duplication.update(start_compactable_range.clone(), |dup_info| {\n                 dup_info\n-                    .get_or_insert_default()\n+                    .entry(start_compactable_category)\n+                    .or_default()\n                     .add(start_compactable_size, &start_compactable_range);\n             });\n             let mut current_skip = 0;\n@@ -337,8 +352,9 @@ pub fn get_merge_segments<T: Compactable>(\n                 // set.\n                 current_set.push(next_index);\n                 current_size += size;\n+                let category = compactable.category();\n                 duplication.update(range.clone(), |dup_info| {\n-                    dup_info.get_or_insert_default().add(size, &range);\n+                    dup_info.entry(category).or_default().add(size, &range);\n                 });\n             }\n         }\n@@ -633,13 +649,16 @@ mod tests {\n \n                 let new_metrics = compute_metrics(&containers, 0..=KEY_RANGE);\n                 println!(\n-                    \"Compaction done: coverage: {} ({}), overlap: {} ({}), duplication: {} ({})\",\n+                    \"Compaction done: coverage: {} ({}), overlap: {} ({}), duplication: {} ({}), \\\n+                     duplicated_size: {} ({})\",\n                     new_metrics.coverage,\n                     new_metrics.coverage - metrics.coverage,\n                     new_metrics.overlap,\n                     new_metrics.overlap - metrics.overlap,\n                     new_metrics.duplication,\n-                    new_metrics.duplication - metrics.duplication\n+                    new_metrics.duplication - metrics.duplication,\n+                    new_metrics.duplicated_size,\n+                    (new_metrics.duplicated_size as f32) - metrics.duplicated_size as f32,\n                 );\n             } else {\n                 println!(\"No compaction needed\");"
        },
        {
            "sha": "adfa37017ce039ed19785a0c2205546de1af9464",
            "filename": "turbopack/crates/turbo-persistence/src/compression.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompression.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompression.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fcompression.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -3,7 +3,6 @@ use std::{mem::MaybeUninit, sync::Arc};\n use anyhow::{Context, Result};\n use lzzzz::lz4::{ACC_LEVEL_DEFAULT, decompress, decompress_with_dict};\n \n-#[tracing::instrument(level = \"trace\", skip_all, name = \"decompress database block\")]\n pub fn decompress_into_arc(\n     uncompressed_length: u32,\n     block: &[u8],"
        },
        {
            "sha": "e44941b4143393e6be958d06a1ab16e8a3cd73dc",
            "filename": "turbopack/crates/turbo-persistence/src/db.rs",
            "status": "modified",
            "additions": 226,
            "deletions": 128,
            "changes": 354,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fdb.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -3,24 +3,26 @@ use std::{\n     collections::HashSet,\n     fs::{self, File, OpenOptions, ReadDir},\n     io::{BufWriter, Write},\n-    mem::swap,\n+    mem::{swap, take},\n     ops::RangeInclusive,\n     path::{Path, PathBuf},\n     sync::atomic::{AtomicBool, AtomicU32, Ordering},\n };\n \n use anyhow::{Context, Result, bail};\n use byteorder::{BE, ReadBytesExt, WriteBytesExt};\n+use dashmap::DashSet;\n use jiff::Timestamp;\n use memmap2::Mmap;\n+use nohash_hasher::BuildNoHashHasher;\n use parking_lot::{Mutex, RwLock};\n use smallvec::SmallVec;\n \n pub use crate::compaction::selector::CompactConfig;\n use crate::{\n     QueryKey,\n     arc_slice::ArcSlice,\n-    compaction::selector::{Compactable, compute_metrics, get_merge_segments},\n+    compaction::selector::{Compactable, get_merge_segments},\n     compression::decompress_into_arc,\n     constants::{\n         AMQF_AVG_SIZE, AMQF_CACHE_SIZE, DATA_THRESHOLD_PER_COMPACTED_FILE, KEY_BLOCK_AVG_SIZE,\n@@ -30,7 +32,7 @@ use crate::{\n     key::{StoreKey, hash_key},\n     lookup_entry::{LookupEntry, LookupValue},\n     merge_iter::MergeIter,\n-    meta_file::{AmqfCache, MetaFile, MetaLookupResult, StaticSortedFileRange},\n+    meta_file::{AmqfCache, MetaEntryFlags, MetaFile, MetaLookupResult, StaticSortedFileRange},\n     meta_file_builder::MetaFileBuilder,\n     parallel_scheduler::ParallelScheduler,\n     sst_filter::SstFilter,\n@@ -105,15 +107,15 @@ struct TrackedStats {\n \n /// TurboPersistence is a persistent key-value store. It is limited to a single writer at a time\n /// using a single write batch. It allows for concurrent reads.\n-pub struct TurboPersistence<S: ParallelScheduler> {\n+pub struct TurboPersistence<S: ParallelScheduler, const FAMILIES: usize> {\n     parallel_scheduler: S,\n     /// The path to the directory where the database is stored\n     path: PathBuf,\n     /// If true, the database is opened in read-only mode. In this mode, no writes are allowed and\n     /// no modification on the database is performed.\n     read_only: bool,\n     /// The inner state of the database. Writing will update that.\n-    inner: RwLock<Inner>,\n+    inner: RwLock<Inner<FAMILIES>>,\n     /// A flag to indicate if a write operation is currently active. Prevents multiple concurrent\n     /// write operations.\n     active_write_operation: AtomicBool,\n@@ -129,11 +131,15 @@ pub struct TurboPersistence<S: ParallelScheduler> {\n }\n \n /// The inner state of the database.\n-struct Inner {\n+struct Inner<const FAMILIES: usize> {\n     /// The list of meta files in the database. This is used to derive the SST files.\n     meta_files: Vec<MetaFile>,\n     /// The current sequence number for the database.\n     current_sequence_number: u32,\n+    /// The in progress set of hashes of keys that have been accessed.\n+    /// It will be flushed onto disk (into a meta file) on next commit.\n+    /// It's a dashset to allow modification while only tracking a read lock on Inner.\n+    accessed_key_hashes: [DashSet<u64, BuildNoHashHasher<u64>>; FAMILIES],\n }\n \n pub struct CommitOptions {\n@@ -146,7 +152,7 @@ pub struct CommitOptions {\n     keys_written: u64,\n }\n \n-impl<S: ParallelScheduler + Default> TurboPersistence<S> {\n+impl<S: ParallelScheduler + Default, const FAMILIES: usize> TurboPersistence<S, FAMILIES> {\n     /// Open a TurboPersistence database at the given path.\n     /// This will read the directory and might performance cleanup when the database was not closed\n     /// properly. Cleanup only requires to read a few bytes from a few files and to delete\n@@ -162,7 +168,7 @@ impl<S: ParallelScheduler + Default> TurboPersistence<S> {\n     }\n }\n \n-impl<S: ParallelScheduler> TurboPersistence<S> {\n+impl<S: ParallelScheduler, const FAMILIES: usize> TurboPersistence<S, FAMILIES> {\n     fn new(path: PathBuf, read_only: bool, parallel_scheduler: S) -> Self {\n         Self {\n             parallel_scheduler,\n@@ -171,6 +177,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             inner: RwLock::new(Inner {\n                 meta_files: Vec::new(),\n                 current_sequence_number: 0,\n+                accessed_key_hashes: [(); FAMILIES]\n+                    .map(|_| DashSet::with_hasher(BuildNoHashHasher::default())),\n             }),\n             active_write_operation: AtomicBool::new(false),\n             amqf_cache: AmqfCache::with(\n@@ -406,7 +414,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n     /// time. The WriteBatch need to be committed with [`TurboPersistence::commit_write_batch`].\n     /// Note that the WriteBatch might start writing data to disk while it's filled up with data.\n     /// This data will only become visible after the WriteBatch is committed.\n-    pub fn write_batch<K: StoreKey + Send + Sync + 'static, const FAMILIES: usize>(\n+    pub fn write_batch<K: StoreKey + Send + Sync + 'static>(\n         &self,\n     ) -> Result<WriteBatch<K, S, FAMILIES>> {\n         if self.read_only {\n@@ -444,7 +452,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n     /// Commits a WriteBatch to the database. This will finish writing the data to disk and make it\n     /// visible to readers.\n-    pub fn commit_write_batch<K: StoreKey + Send + Sync + 'static, const FAMILIES: usize>(\n+    pub fn commit_write_batch<K: StoreKey + Send + Sync + 'static>(\n         &self,\n         mut write_batch: WriteBatch<K, S, FAMILIES>,\n     ) -> Result<()> {\n@@ -457,7 +465,27 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             new_sst_files,\n             new_blob_files,\n             keys_written,\n-        } = write_batch.finish()?;\n+        } = write_batch.finish(|family| {\n+            let inner = self.inner.read();\n+            let set = &inner.accessed_key_hashes[family as usize];\n+            // len is only a snapshot at that time and it can change while we create the filter.\n+            // So we give it 5% more space to make resizes less likely.\n+            let initial_capacity = set.len() * 20 / 19;\n+            let mut amqf =\n+                qfilter::Filter::with_fingerprint_size(initial_capacity as u64, u64::BITS as u8)\n+                    .unwrap();\n+            // This drains items from the set. But due to concurrency it might not be empty\n+            // afterwards, but that's fine. It will be part of the next commit.\n+            set.retain(|hash| {\n+                // Performance-wise it would usually be better to insert sorted fingerprints, but we\n+                // assume that hashes are equally distributed, which makes it unnecessary.\n+                // Good for cache locality is that we insert in the order of the dashset's buckets.\n+                amqf.insert_fingerprint(false, *hash)\n+                    .expect(\"Failed to insert fingerprint\");\n+                false\n+            });\n+            amqf\n+        })?;\n         self.commit(CommitOptions {\n             new_meta_files,\n             new_sst_files,\n@@ -524,7 +552,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                         let seq = entry.sequence_number();\n                         let range = entry.range();\n                         let size = entry.size();\n-                        (seq, range.min_hash, range.max_hash, size)\n+                        let flags = entry.flags();\n+                        (seq, range.min_hash, range.max_hash, size, flags)\n                     })\n                     .collect::<Vec<_>>();\n                 (\n@@ -614,14 +643,15 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                 writeln!(log, \"Time {time}\")?;\n                 let span = time.until(Timestamp::now())?;\n                 writeln!(log, \"Commit {seq:08} {keys_written} keys in {span:#}\")?;\n-                writeln!(log, \"FAM | META SEQ | SST SEQ        | RANGE\")?;\n+                writeln!(log, \"FAM | META SEQ | SST SEQ         | RANGE\")?;\n                 for (meta_seq, family, ssts, obsolete) in new_meta_info {\n-                    for (seq, min, max, size) in ssts {\n+                    for (seq, min, max, size, flags) in ssts {\n                         writeln!(\n                             log,\n-                            \"{family:3} | {meta_seq:08} | {seq:08} SST    | {} ({} MiB)\",\n+                            \"{family:3} | {meta_seq:08} | {seq:08} SST    | {} ({} MiB, {})\",\n                             range_to_str(min, max),\n-                            size / 1024 / 1024\n+                            size / 1024 / 1024,\n+                            flags\n                         )?;\n                     }\n                     for obsolete in obsolete.chunks(15) {\n@@ -673,7 +703,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                 #[cfg(feature = \"verbose_log\")]\n                 {\n                     writeln!(log, \"New database state:\")?;\n-                    writeln!(log, \"FAM | META SEQ | SST SEQ        | RANGE\")?;\n+                    writeln!(log, \"FAM | META SEQ | SST SEQ  FLAGS | RANGE\")?;\n                     let inner = self.inner.read();\n                     let families = inner.meta_files.iter().map(|meta| meta.family()).filter({\n                         let mut set = HashSet::new();\n@@ -690,7 +720,8 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                 let range = entry.range();\n                                 writeln!(\n                                     log,\n-                                    \"{family:3} | {meta_seq:08} | {seq:08}        | {}\",\n+                                    \"{family:3} | {meta_seq:08} | {seq:08} {:>6} | {}\",\n+                                    entry.flags(),\n                                     range_to_str(range.min_hash, range.max_hash)\n                                 )?;\n                             }\n@@ -802,6 +833,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             seq: u32,\n             range: StaticSortedFileRange,\n             size: u64,\n+            flags: MetaEntryFlags,\n         }\n \n         impl Compactable for SstWithRange {\n@@ -812,6 +844,12 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             fn size(&self) -> u64 {\n                 self.size\n             }\n+\n+            fn category(&self) -> u8 {\n+                // Cold and non-cold files are placed separately so we pass different category\n+                // values to ensure they are not merged together.\n+                if self.flags.cold() { 1 } else { 0 }\n+            }\n         }\n \n         let ssts_with_ranges = meta_files\n@@ -827,19 +865,12 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                         seq: entry.sequence_number(),\n                         range: entry.range(),\n                         size: entry.size(),\n+                        flags: entry.flags(),\n                     })\n             })\n             .collect::<Vec<_>>();\n \n-        let families = ssts_with_ranges\n-            .iter()\n-            .map(|s| s.range.family)\n-            .max()\n-            .unwrap() as usize\n-            + 1;\n-\n-        let mut sst_by_family = Vec::with_capacity(families);\n-        sst_by_family.resize_with(families, Vec::new);\n+        let mut sst_by_family = [(); FAMILIES].map(|_| Vec::new());\n \n         for sst in ssts_with_ranges {\n             sst_by_family[sst.range.family as usize].push(sst);\n@@ -874,6 +905,22 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n             })\n             .collect::<Vec<_>>();\n \n+        let mut used_key_hashes = [(); FAMILIES].map(|_| Vec::new());\n+\n+        {\n+            for &(family, ..) in merge_jobs.iter() {\n+                used_key_hashes[family].extend(\n+                    meta_files\n+                        .iter()\n+                        .filter(|m| m.family() == family as u32)\n+                        .filter_map(|meta_file| {\n+                            meta_file.deserialize_used_key_hashes_amqf().transpose()\n+                        })\n+                        .collect::<Result<Vec<_>>>()?,\n+                );\n+            }\n+        }\n+\n         let result = self\n             .parallel_scheduler\n             .parallel_map_collect_owned::<_, _, Result<Vec<_>>>(\n@@ -891,8 +938,6 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                         });\n                     }\n \n-                    let metrics = compute_metrics(&ssts_with_ranges, 0..=u64::MAX);\n-\n                     // Later we will remove the merged files\n                     let sst_seq_numbers_to_delete = merge_jobs\n                         .iter()\n@@ -937,6 +982,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                             .key_compression_dictionary_length(),\n                                         block_count: entry.block_count(),\n                                         size: entry.size(),\n+                                        flags: entry.flags(),\n                                         entries: 0,\n                                     };\n                                     return Ok(PartialMergeResult::Move {\n@@ -951,6 +997,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                     total_key_size: usize,\n                                     path: &Path,\n                                     seq: u32,\n+                                    flags: MetaEntryFlags,\n                                 ) -> Result<(u32, File, StaticSortedFileBuilderMeta<'static>)>\n                                 {\n                                     let _span =\n@@ -960,13 +1007,12 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                             entries,\n                                             total_key_size,\n                                             &path.join(format!(\"{seq:08}.sst\")),\n+                                            flags,\n                                         )\n                                     })?;\n                                     Ok((seq, file, meta))\n                                 }\n \n-                                let mut new_sst_files = Vec::new();\n-\n                                 // Iterate all SST files\n                                 let iters = indicies\n                                     .iter()\n@@ -988,114 +1034,166 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n \n                                 let mut keys_written = 0;\n \n-                                let mut total_key_size = 0;\n-                                let mut total_value_size = 0;\n                                 let mut current: Option<LookupEntry<'_>> = None;\n-                                let mut entries = Vec::new();\n-                                let mut last_entries = Vec::new();\n-                                let mut last_entries_total_key_size = 0;\n+\n+                                #[derive(Default)]\n+                                struct Collector<'l> {\n+                                    entries: Vec<LookupEntry<'l>>,\n+                                    total_key_size: usize,\n+                                    total_value_size: usize,\n+                                    last_entries: Vec<LookupEntry<'l>>,\n+                                    last_entries_total_key_size: usize,\n+                                    new_sst_files:\n+                                        Vec<(u32, File, StaticSortedFileBuilderMeta<'static>)>,\n+                                }\n+                                let mut used_collector = Collector::default();\n+                                let mut unused_collector = Collector::default();\n                                 for entry in iter {\n                                     let entry = entry?;\n \n                                     // Remove duplicates\n                                     if let Some(current) = current.take() {\n                                         if current.key != entry.key {\n+                                            let is_used =\n+                                                used_key_hashes[family as usize].iter().any(\n+                                                    |amqf| amqf.contains_fingerprint(current.hash),\n+                                                );\n+                                            let collector = if is_used {\n+                                                &mut used_collector\n+                                            } else {\n+                                                &mut unused_collector\n+                                            };\n                                             let key_size = current.key.len();\n                                             let value_size =\n                                                 current.value.uncompressed_size_in_sst();\n-                                            total_key_size += key_size;\n-                                            total_value_size += value_size;\n+                                            collector.total_key_size += key_size;\n+                                            collector.total_value_size += value_size;\n \n-                                            if total_key_size + total_value_size\n+                                            if collector.total_key_size + collector.total_value_size\n                                                 > DATA_THRESHOLD_PER_COMPACTED_FILE\n-                                                || entries.len() >= MAX_ENTRIES_PER_COMPACTED_FILE\n+                                                || collector.entries.len()\n+                                                    >= MAX_ENTRIES_PER_COMPACTED_FILE\n                                             {\n                                                 let selected_total_key_size =\n-                                                    last_entries_total_key_size;\n-                                                swap(&mut entries, &mut last_entries);\n-                                                last_entries_total_key_size =\n-                                                    total_key_size - key_size;\n-                                                total_key_size = key_size;\n-                                                total_value_size = value_size;\n-\n-                                                if !entries.is_empty() {\n+                                                    collector.last_entries_total_key_size;\n+                                                swap(\n+                                                    &mut collector.entries,\n+                                                    &mut collector.last_entries,\n+                                                );\n+                                                collector.last_entries_total_key_size =\n+                                                    collector.total_key_size - key_size;\n+                                                collector.total_key_size = key_size;\n+                                                collector.total_value_size = value_size;\n+\n+                                                if !collector.entries.is_empty() {\n                                                     let seq = sequence_number\n                                                         .fetch_add(1, Ordering::SeqCst)\n                                                         + 1;\n \n-                                                    keys_written += entries.len() as u64;\n-                                                    new_sst_files.push(create_sst_file(\n+                                                    keys_written += collector.entries.len() as u64;\n+\n+                                                    let mut flags = MetaEntryFlags::default();\n+                                                    flags.set_cold(!is_used);\n+                                                    collector.new_sst_files.push(create_sst_file(\n                                                         &self.parallel_scheduler,\n-                                                        &entries,\n+                                                        &collector.entries,\n                                                         selected_total_key_size,\n                                                         path,\n                                                         seq,\n+                                                        flags,\n                                                     )?);\n \n-                                                    entries.clear();\n+                                                    collector.entries.clear();\n                                                 }\n                                             }\n \n-                                            entries.push(current);\n+                                            collector.entries.push(current);\n                                         } else {\n                                             // Override value\n+                                            // TODO delete blob file\n                                         }\n                                     }\n                                     current = Some(entry);\n                                 }\n                                 if let Some(entry) = current {\n-                                    total_key_size += entry.key.len();\n+                                    let is_used = used_key_hashes[family as usize]\n+                                        .iter()\n+                                        .any(|amqf| amqf.contains_fingerprint(entry.hash));\n+                                    let collector = if is_used {\n+                                        &mut used_collector\n+                                    } else {\n+                                        &mut unused_collector\n+                                    };\n+\n+                                    collector.total_key_size += entry.key.len();\n                                     // Obsolete as we no longer need total_value_size\n                                     // total_value_size += entry.value.uncompressed_size_in_sst();\n-                                    entries.push(entry);\n+                                    collector.entries.push(entry);\n                                 }\n \n                                 // If we have one set of entries left, write them to a new SST file\n-                                if last_entries.is_empty() && !entries.is_empty() {\n-                                    let seq = sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n-\n-                                    keys_written += entries.len() as u64;\n-                                    new_sst_files.push(create_sst_file(\n-                                        &self.parallel_scheduler,\n-                                        &entries,\n-                                        total_key_size,\n-                                        path,\n-                                        seq,\n-                                    )?);\n-                                } else\n-                                // If we have two sets of entries left, merge them and\n-                                // split it into two SST files, to avoid having a\n-                                // single SST file that is very small.\n-                                if !last_entries.is_empty() {\n-                                    last_entries.append(&mut entries);\n-\n-                                    last_entries_total_key_size += total_key_size;\n-\n-                                    let (part1, part2) =\n-                                        last_entries.split_at(last_entries.len() / 2);\n-\n-                                    let seq1 = sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n-                                    let seq2 = sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n-\n-                                    keys_written += part1.len() as u64;\n-                                    new_sst_files.push(create_sst_file(\n-                                        &self.parallel_scheduler,\n-                                        part1,\n-                                        // We don't know the exact sizes so we estimate them\n-                                        last_entries_total_key_size / 2,\n-                                        path,\n-                                        seq1,\n-                                    )?);\n-\n-                                    keys_written += part2.len() as u64;\n-                                    new_sst_files.push(create_sst_file(\n-                                        &self.parallel_scheduler,\n-                                        part2,\n-                                        last_entries_total_key_size / 2,\n-                                        path,\n-                                        seq2,\n-                                    )?);\n+                                for (collector, flags) in [\n+                                    (&mut used_collector, MetaEntryFlags::WARM),\n+                                    (&mut unused_collector, MetaEntryFlags::COLD),\n+                                ] {\n+                                    if collector.last_entries.is_empty()\n+                                        && !collector.entries.is_empty()\n+                                    {\n+                                        let seq =\n+                                            sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n+\n+                                        keys_written += collector.entries.len() as u64;\n+                                        collector.new_sst_files.push(create_sst_file(\n+                                            &self.parallel_scheduler,\n+                                            &collector.entries,\n+                                            collector.total_key_size,\n+                                            path,\n+                                            seq,\n+                                            flags,\n+                                        )?);\n+                                    } else\n+                                    // If we have two sets of entries left, merge them and\n+                                    // split it into two SST files, to avoid having a\n+                                    // single SST file that is very small.\n+                                    if !collector.last_entries.is_empty() {\n+                                        collector.last_entries.append(&mut collector.entries);\n+\n+                                        collector.last_entries_total_key_size +=\n+                                            collector.total_key_size;\n+\n+                                        let (part1, part2) = collector\n+                                            .last_entries\n+                                            .split_at(collector.last_entries.len() / 2);\n+\n+                                        let seq1 =\n+                                            sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n+                                        let seq2 =\n+                                            sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n+\n+                                        keys_written += part1.len() as u64;\n+                                        collector.new_sst_files.push(create_sst_file(\n+                                            &self.parallel_scheduler,\n+                                            part1,\n+                                            // We don't know the exact sizes so we estimate them\n+                                            collector.last_entries_total_key_size / 2,\n+                                            path,\n+                                            seq1,\n+                                            flags,\n+                                        )?);\n+\n+                                        keys_written += part2.len() as u64;\n+                                        collector.new_sst_files.push(create_sst_file(\n+                                            &self.parallel_scheduler,\n+                                            part2,\n+                                            collector.last_entries_total_key_size / 2,\n+                                            path,\n+                                            seq2,\n+                                            flags,\n+                                        )?);\n+                                    }\n                                 }\n+                                let mut new_sst_files = take(&mut unused_collector.new_sst_files);\n+                                new_sst_files.append(&mut used_collector.new_sst_files);\n                                 Ok(PartialMergeResult::Merged {\n                                     new_sst_files,\n                                     blob_seq_numbers_to_delete,\n@@ -1138,15 +1236,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                     self.parallel_scheduler.block_in_place(|| {\n                         let guard = log_mutex.lock();\n                         let mut log = self.open_log()?;\n-                        writeln!(\n-                            log,\n-                            \"{family:3} | {meta_seq:08} | Compaction (coverage: {}, overlap: {}, \\\n-                             duplication: {} / {} MiB):\",\n-                            metrics.coverage,\n-                            metrics.overlap,\n-                            metrics.duplication,\n-                            metrics.duplicated_size / 1024 / 1024\n-                        )?;\n+                        writeln!(log, \"{family:3} | {meta_seq:08} | Compaction:\",)?;\n                         for result in merge_result {\n                             match result {\n                                 PartialMergeResult::Merged {\n@@ -1165,7 +1255,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                         let (min, max) = ssts_with_ranges[*i].range().into_inner();\n                                         writeln!(\n                                             log,\n-                                            \"{family:3} | {meta_seq:08} | {seq:08} INPUT  | {} \",\n+                                            \"{family:3} | {meta_seq:08} | {seq:08} INPUT  | {}\",\n                                             range_to_str(min, max)\n                                         )?;\n                                     }\n@@ -1174,8 +1264,10 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                                         let max = meta.max_hash;\n                                         writeln!(\n                                             log,\n-                                            \"{family:3} | {meta_seq:08} | {seq:08} OUTPUT | {}\",\n-                                            range_to_str(min, max)\n+                                            \"{family:3} | {meta_seq:08} | {seq:08} OUTPUT | {} \\\n+                                             ({})\",\n+                                            range_to_str(min, max),\n+                                            meta.flags\n                                         )?;\n \n                                         meta_file_builder.add(seq, meta);\n@@ -1245,6 +1337,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n     /// Get a value from the database. Returns None if the key is not found. The returned value\n     /// might hold onto a block of the database and it should not be hold long-term.\n     pub fn get<K: QueryKey>(&self, family: usize, key: &K) -> Result<Option<ArcSlice<u8>>> {\n+        debug_assert!(family < FAMILIES, \"Family index out of bounds\");\n         let hash = hash_key(key);\n         let inner = self.inner.read();\n         for meta in inner.meta_files.iter().rev() {\n@@ -1269,24 +1362,27 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                     self.stats.miss_amqf.fetch_add(1, Ordering::Relaxed);\n                 }\n                 MetaLookupResult::SstLookup(result) => match result {\n-                    SstLookupResult::Found(result) => match result {\n-                        LookupValue::Deleted => {\n-                            #[cfg(feature = \"stats\")]\n-                            self.stats.hits_deleted.fetch_add(1, Ordering::Relaxed);\n-                            return Ok(None);\n-                        }\n-                        LookupValue::Slice { value } => {\n-                            #[cfg(feature = \"stats\")]\n-                            self.stats.hits_small.fetch_add(1, Ordering::Relaxed);\n-                            return Ok(Some(value));\n-                        }\n-                        LookupValue::Blob { sequence_number } => {\n-                            #[cfg(feature = \"stats\")]\n-                            self.stats.hits_blob.fetch_add(1, Ordering::Relaxed);\n-                            let blob = self.read_blob(sequence_number)?;\n-                            return Ok(Some(blob));\n+                    SstLookupResult::Found(result) => {\n+                        inner.accessed_key_hashes[family].insert(hash);\n+                        match result {\n+                            LookupValue::Deleted => {\n+                                #[cfg(feature = \"stats\")]\n+                                self.stats.hits_deleted.fetch_add(1, Ordering::Relaxed);\n+                                return Ok(None);\n+                            }\n+                            LookupValue::Slice { value } => {\n+                                #[cfg(feature = \"stats\")]\n+                                self.stats.hits_small.fetch_add(1, Ordering::Relaxed);\n+                                return Ok(Some(value));\n+                            }\n+                            LookupValue::Blob { sequence_number } => {\n+                                #[cfg(feature = \"stats\")]\n+                                self.stats.hits_blob.fetch_add(1, Ordering::Relaxed);\n+                                let blob = self.read_blob(sequence_number)?;\n+                                return Ok(Some(blob));\n+                            }\n                         }\n-                    },\n+                    }\n                     SstLookupResult::NotFound => {\n                         #[cfg(feature = \"stats\")]\n                         self.stats.miss_key.fetch_add(1, Ordering::Relaxed);\n@@ -1338,6 +1434,7 @@ impl<S: ParallelScheduler> TurboPersistence<S> {\n                             min_hash: entry.min_hash(),\n                             max_hash: entry.max_hash(),\n                             sst_size: entry.size(),\n+                            flags: entry.flags(),\n                             amqf_size: entry.amqf_size(),\n                             amqf_entries: amqf.len(),\n                             key_compression_dictionary_size: entry\n@@ -1402,6 +1499,7 @@ pub struct MetaFileEntryInfo {\n     pub amqf_size: u32,\n     pub amqf_entries: usize,\n     pub sst_size: u64,\n+    pub flags: MetaEntryFlags,\n     pub key_compression_dictionary_size: u16,\n     pub block_count: u16,\n }"
        },
        {
            "sha": "7f279c0aec614b472d5fd4c142fdb822f0104986",
            "filename": "turbopack/crates/turbo-persistence/src/meta_file.rs",
            "status": "modified",
            "additions": 63,
            "deletions": 0,
            "changes": 63,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -1,4 +1,5 @@\n use std::{\n+    fmt::Display,\n     fs::File,\n     hash::BuildHasherDefault,\n     io::{BufReader, Seek},\n@@ -8,6 +9,7 @@ use std::{\n };\n \n use anyhow::{Context, Result, bail};\n+use bitfield::bitfield;\n use byteorder::{BE, ReadBytesExt};\n use either::Either;\n use memmap2::{Mmap, MmapOptions};\n@@ -31,6 +33,35 @@ impl quick_cache::Weighter<u32, Arc<qfilter::Filter>> for AmqfWeighter {\n pub type AmqfCache =\n     quick_cache::sync::Cache<u32, Arc<qfilter::Filter>, AmqfWeighter, BuildHasherDefault<FxHasher>>;\n \n+bitfield! {\n+    #[derive(Clone, Copy, Default)]\n+    pub struct MetaEntryFlags(u32);\n+    impl Debug;\n+    impl From<u32>;\n+    /// The SST file was compacted and none of the entries have been accessed recently.\n+    pub cold, set_cold: 0;\n+    /// The SST file was freshly written and has not been compacted yet.\n+    pub fresh, set_fresh: 1;\n+}\n+\n+impl MetaEntryFlags {\n+    pub const FRESH: MetaEntryFlags = MetaEntryFlags(0b10);\n+    pub const COLD: MetaEntryFlags = MetaEntryFlags(0b01);\n+    pub const WARM: MetaEntryFlags = MetaEntryFlags(0b00);\n+}\n+\n+impl Display for MetaEntryFlags {\n+    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n+        if self.fresh() {\n+            f.pad_integral(true, \"\", \"fresh\")\n+        } else if self.cold() {\n+            f.pad_integral(true, \"\", \"cold\")\n+        } else {\n+            f.pad_integral(true, \"\", \"warm\")\n+        }\n+    }\n+}\n+\n pub struct MetaEntry {\n     /// The metadata for the static sorted file.\n     sst_data: StaticSortedFileMetaData,\n@@ -42,6 +73,8 @@ pub struct MetaEntry {\n     max_hash: u64,\n     /// The size of the SST file in bytes.\n     size: u64,\n+    /// The status flags for this entry.\n+    flags: MetaEntryFlags,\n     /// The offset of the start of the AMQF data in the meta file relative to the end of the\n     /// header.\n     start_of_amqf_data_offset: u32,\n@@ -64,6 +97,10 @@ impl MetaEntry {\n         self.size\n     }\n \n+    pub fn flags(&self) -> MetaEntryFlags {\n+        self.flags\n+    }\n+\n     pub fn amqf_size(&self) -> u32 {\n         self.end_of_amqf_data_offset - self.start_of_amqf_data_offset\n     }\n@@ -183,6 +220,12 @@ pub struct MetaFile {\n     obsolete_entries: Vec<u32>,\n     /// The obsolete SST files.\n     obsolete_sst_files: Vec<u32>,\n+    /// The offset of the start of the \"used keys\" AMQF data in the meta file relative to the end\n+    /// of the header.\n+    start_of_used_keys_amqf_data_offset: u32,\n+    /// The offset of the end of the \"used keys\" AMQF data in the the meta file relative to the end\n+    /// of the header.\n+    end_of_used_keys_amqf_data_offset: u32,\n     /// The memory mapped file.\n     mmap: Mmap,\n }\n@@ -224,6 +267,7 @@ impl MetaFile {\n                 min_hash: file.read_u64::<BE>()?,\n                 max_hash: file.read_u64::<BE>()?,\n                 size: file.read_u64::<BE>()?,\n+                flags: MetaEntryFlags(file.read_u32::<BE>()?),\n                 start_of_amqf_data_offset,\n                 end_of_amqf_data_offset: file.read_u32::<BE>()?,\n                 amqf: OnceLock::new(),\n@@ -232,6 +276,9 @@ impl MetaFile {\n             start_of_amqf_data_offset = entry.end_of_amqf_data_offset;\n             entries.push(entry);\n         }\n+        let start_of_used_keys_amqf_data_offset = start_of_amqf_data_offset;\n+        let end_of_used_keys_amqf_data_offset = file.read_u32::<BE>()?;\n+\n         let offset = file.stream_position()?;\n         let file = file.into_inner();\n         let mut options = MmapOptions::new();\n@@ -246,6 +293,8 @@ impl MetaFile {\n             entries,\n             obsolete_entries: Vec::new(),\n             obsolete_sst_files,\n+            start_of_used_keys_amqf_data_offset,\n+            end_of_used_keys_amqf_data_offset,\n             mmap,\n         };\n         Ok(file)\n@@ -272,6 +321,20 @@ impl MetaFile {\n         &self.mmap\n     }\n \n+    pub fn deserialize_used_key_hashes_amqf(&self) -> Result<Option<qfilter::Filter>> {\n+        if self.start_of_used_keys_amqf_data_offset == self.end_of_used_keys_amqf_data_offset {\n+            return Ok(None);\n+        }\n+        let amqf = &self.amqf_data()[self.start_of_used_keys_amqf_data_offset as usize\n+            ..self.end_of_used_keys_amqf_data_offset as usize];\n+        Ok(Some(pot::from_slice(amqf).with_context(|| {\n+            format!(\n+                \"Failed to deserialize used key hashes AMQF from {:08}.meta\",\n+                self.sequence_number\n+            )\n+        })?))\n+    }\n+\n     pub fn retain_entries(&mut self, mut predicate: impl FnMut(u32) -> bool) -> bool {\n         let old_len = self.entries.len();\n         self.entries.retain(|entry| {"
        },
        {
            "sha": "ea6876958921310c89b6a2f296240e40c3431799",
            "filename": "turbopack/crates/turbo-persistence/src/meta_file_builder.rs",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fmeta_file_builder.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -6,6 +6,7 @@ use std::{\n \n use anyhow::{Context, Result};\n use byteorder::{BE, WriteBytesExt};\n+use qfilter::Filter;\n \n use crate::static_sorted_file_builder::StaticSortedFileBuilderMeta;\n \n@@ -15,6 +16,8 @@ pub struct MetaFileBuilder<'a> {\n     entries: Vec<(u32, StaticSortedFileBuilderMeta<'a>)>,\n     /// Obsolete SST files, represented by their sequence numbers\n     obsolete_sst_files: Vec<u32>,\n+    /// Optional AMQF for used key hashes\n+    used_key_hashes_amqf: Option<Filter>,\n }\n \n impl<'a> MetaFileBuilder<'a> {\n@@ -23,6 +26,7 @@ impl<'a> MetaFileBuilder<'a> {\n             family,\n             entries: Vec::new(),\n             obsolete_sst_files: Vec::new(),\n+            used_key_hashes_amqf: None,\n         }\n     }\n \n@@ -34,6 +38,10 @@ impl<'a> MetaFileBuilder<'a> {\n         self.obsolete_sst_files.push(sequence_number);\n     }\n \n+    pub fn set_used_key_hashes_amqf(&mut self, amqf: Filter) {\n+        self.used_key_hashes_amqf = Some(amqf);\n+    }\n+\n     #[tracing::instrument(level = \"trace\", skip_all)]\n     pub fn write(self, db_path: &Path, seq: u32) -> Result<File> {\n         let file = db_path.join(format!(\"{seq:08}.meta\"));\n@@ -62,13 +70,26 @@ impl<'a> MetaFileBuilder<'a> {\n             file.write_u64::<BE>(sst.min_hash)?;\n             file.write_u64::<BE>(sst.max_hash)?;\n             file.write_u64::<BE>(sst.size)?;\n+            file.write_u32::<BE>(sst.flags.0)?;\n             amqf_offset += sst.amqf.len();\n             file.write_u32::<BE>(amqf_offset as u32)?;\n         }\n+        let serialized_used_key_hashes = self\n+            .used_key_hashes_amqf\n+            .as_ref()\n+            .map(|f| pot::to_vec(f).expect(\"AMQF serialization failed\"));\n+        amqf_offset += serialized_used_key_hashes\n+            .as_ref()\n+            .map(|bytes| bytes.len())\n+            .unwrap_or(0);\n+        file.write_u32::<BE>(amqf_offset as u32)?;\n \n         for (_, sst) in &self.entries {\n             file.write_all(&sst.amqf)?;\n         }\n+        if let Some(bytes) = &serialized_used_key_hashes {\n+            file.write_all(bytes)?;\n+        }\n         Ok(file.into_inner()?)\n     }\n }"
        },
        {
            "sha": "89278ed5e323ddf6499cc7cf6aee3e99289162a2",
            "filename": "turbopack/crates/turbo-persistence/src/static_sorted_file_builder.rs",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fstatic_sorted_file_builder.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -11,6 +11,7 @@ use byteorder::{BE, ByteOrder, WriteBytesExt};\n \n use crate::{\n     compression::compress_into_buffer,\n+    meta_file::MetaEntryFlags,\n     static_sorted_file::{\n         BLOCK_TYPE_INDEX, BLOCK_TYPE_KEY, KEY_BLOCK_ENTRY_TYPE_BLOB, KEY_BLOCK_ENTRY_TYPE_DELETED,\n         KEY_BLOCK_ENTRY_TYPE_MEDIUM, KEY_BLOCK_ENTRY_TYPE_SMALL,\n@@ -88,6 +89,8 @@ pub struct StaticSortedFileBuilderMeta<'a> {\n     pub block_count: u16,\n     /// The file size of the SST file\n     pub size: u64,\n+    /// The status flags for this SST file\n+    pub flags: MetaEntryFlags,\n     /// The number of entries in the SST file\n     pub entries: u64,\n }\n@@ -96,6 +99,7 @@ pub fn write_static_stored_file<E: Entry>(\n     entries: &[E],\n     total_key_size: usize,\n     file: &Path,\n+    flags: MetaEntryFlags,\n ) -> Result<(StaticSortedFileBuilderMeta<'static>, File)> {\n     debug_assert!(entries.iter().map(|e| e.key_hash()).is_sorted());\n \n@@ -141,6 +145,7 @@ pub fn write_static_stored_file<E: Entry>(\n         key_compression_dictionary_length: key_dict.len().try_into().unwrap(),\n         block_count,\n         size: file.stream_position()?,\n+        flags,\n         entries: entries.len() as u64,\n     };\n     Ok((meta, file.into_inner()?))"
        },
        {
            "sha": "05691f27e8e77e442fa03f0f969bc8d9e5ba3e5f",
            "filename": "turbopack/crates/turbo-persistence/src/tests.rs",
            "status": "modified",
            "additions": 23,
            "deletions": 22,
            "changes": 45,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Ftests.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -109,20 +109,21 @@ fn full_cycle() -> Result<()> {\n     type TestCases = Vec<(\n         &'static str,\n         Box<dyn Fn(&mut WriteBatch<Vec<u8>, RayonParallelScheduler, 16>) -> Result<()>>,\n-        Box<dyn Fn(&TurboPersistence<RayonParallelScheduler>) -> Result<()>>,\n+        Box<dyn Fn(&TurboPersistence<RayonParallelScheduler, 16>) -> Result<()>>,\n     )>;\n \n     fn test_case(\n         test_cases: &mut TestCases,\n         name: &'static str,\n         write: impl Fn(&mut WriteBatch<Vec<u8>, RayonParallelScheduler, 16>) -> Result<()> + 'static,\n-        read: impl Fn(&TurboPersistence<RayonParallelScheduler>) -> Result<()> + 'static,\n+        read: impl Fn(&TurboPersistence<RayonParallelScheduler, 16>) -> Result<()> + 'static,\n     ) {\n         test_cases.push((\n             name,\n             Box::new(write)\n                 as Box<dyn Fn(&mut WriteBatch<Vec<u8>, RayonParallelScheduler, 16>) -> Result<()>>,\n-            Box::new(read) as Box<dyn Fn(&TurboPersistence<RayonParallelScheduler>) -> Result<()>>,\n+            Box::new(read)\n+                as Box<dyn Fn(&TurboPersistence<RayonParallelScheduler, 16>) -> Result<()>>,\n         ));\n     }\n \n@@ -506,7 +507,7 @@ fn persist_changes() -> Result<()> {\n         }\n         Ok(())\n     }\n-    fn check(db: &TurboPersistence<RayonParallelScheduler>, key: u8, value: u8) -> Result<()> {\n+    fn check(db: &TurboPersistence<RayonParallelScheduler, 1>, key: u8, value: u8) -> Result<()> {\n         for i in 0..READ_COUNT {\n             // read every 10th item\n             let i = i * 10;\n@@ -519,11 +520,11 @@ fn persist_changes() -> Result<()> {\n     }\n \n     {\n-        let db = TurboPersistence::open_with_parallel_scheduler(\n+        let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n             path.to_path_buf(),\n             RayonParallelScheduler,\n         )?;\n-        let b = db.write_batch::<_, 1>()?;\n+        let b = db.write_batch()?;\n         put(&b, 1, 11)?;\n         put(&b, 2, 21)?;\n         put(&b, 3, 31)?;\n@@ -538,11 +539,11 @@ fn persist_changes() -> Result<()> {\n \n     println!(\"---\");\n     {\n-        let db = TurboPersistence::open_with_parallel_scheduler(\n+        let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n             path.to_path_buf(),\n             RayonParallelScheduler,\n         )?;\n-        let b = db.write_batch::<_, 1>()?;\n+        let b = db.write_batch()?;\n         put(&b, 1, 12)?;\n         put(&b, 2, 22)?;\n         db.commit_write_batch(b)?;\n@@ -555,11 +556,11 @@ fn persist_changes() -> Result<()> {\n     }\n \n     {\n-        let db = TurboPersistence::open_with_parallel_scheduler(\n+        let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n             path.to_path_buf(),\n             RayonParallelScheduler,\n         )?;\n-        let b = db.write_batch::<_, 1>()?;\n+        let b = db.write_batch()?;\n         put(&b, 1, 13)?;\n         db.commit_write_batch(b)?;\n \n@@ -638,7 +639,7 @@ fn partial_compaction() -> Result<()> {\n         }\n         Ok(())\n     }\n-    fn check(db: &TurboPersistence<RayonParallelScheduler>, key: u8, value: u8) -> Result<()> {\n+    fn check(db: &TurboPersistence<RayonParallelScheduler, 1>, key: u8, value: u8) -> Result<()> {\n         for i in 0..READ_COUNT {\n             // read every 10th item\n             let i = i * 10;\n@@ -655,11 +656,11 @@ fn partial_compaction() -> Result<()> {\n         println!(\"--- Iteration {i} ---\");\n         println!(\"Add more entries\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;\n-            let b = db.write_batch::<_, 1>()?;\n+            let b = db.write_batch()?;\n             put(&b, i, i)?;\n             put(&b, i + 1, i)?;\n             put(&b, i + 2, i)?;\n@@ -677,7 +678,7 @@ fn partial_compaction() -> Result<()> {\n \n         println!(\"Compaction\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;\n@@ -701,7 +702,7 @@ fn partial_compaction() -> Result<()> {\n \n         println!(\"Restore check\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;\n@@ -742,7 +743,7 @@ fn merge_file_removal() -> Result<()> {\n         }\n         Ok(())\n     }\n-    fn check(db: &TurboPersistence<RayonParallelScheduler>, key: u8, value: u32) -> Result<()> {\n+    fn check(db: &TurboPersistence<RayonParallelScheduler, 1>, key: u8, value: u32) -> Result<()> {\n         for i in 0..READ_COUNT {\n             // read every 10th item\n             let i = i * 10;\n@@ -760,11 +761,11 @@ fn merge_file_removal() -> Result<()> {\n \n     {\n         println!(\"--- Init ---\");\n-        let db = TurboPersistence::open_with_parallel_scheduler(\n+        let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n             path.to_path_buf(),\n             RayonParallelScheduler,\n         )?;\n-        let b = db.write_batch::<_, 1>()?;\n+        let b = db.write_batch()?;\n         for j in 0..=255 {\n             put(&b, j, 0)?;\n         }\n@@ -779,11 +780,11 @@ fn merge_file_removal() -> Result<()> {\n         let i = i * 37;\n         println!(\"Add more entries\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;\n-            let b = db.write_batch::<_, 1>()?;\n+            let b = db.write_batch()?;\n             for j in iter_bits(i) {\n                 println!(\"Put {j} = {i}\");\n                 expected_values[j as usize] = i;\n@@ -800,7 +801,7 @@ fn merge_file_removal() -> Result<()> {\n \n         println!(\"Compaction\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;\n@@ -821,7 +822,7 @@ fn merge_file_removal() -> Result<()> {\n \n         println!(\"Restore check\");\n         {\n-            let db = TurboPersistence::open_with_parallel_scheduler(\n+            let db = TurboPersistence::<_, 1>::open_with_parallel_scheduler(\n                 path.to_path_buf(),\n                 RayonParallelScheduler,\n             )?;"
        },
        {
            "sha": "81ca849151b9be94d63f49073e32153f53ac94d7",
            "filename": "turbopack/crates/turbo-persistence/src/write_batch.rs",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-persistence%2Fsrc%2Fwrite_batch.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -21,6 +21,7 @@ use crate::{\n     compression::compress_into_buffer,\n     constants::{MAX_MEDIUM_VALUE_SIZE, THREAD_LOCAL_SIZE_SHIFT},\n     key::StoreKey,\n+    meta_file::MetaEntryFlags,\n     meta_file_builder::MetaFileBuilder,\n     parallel_scheduler::ParallelScheduler,\n     static_sorted_file_builder::{StaticSortedFileBuilderMeta, write_static_stored_file},\n@@ -267,8 +268,11 @@ impl<K: StoreKey + Send + Sync, S: ParallelScheduler, const FAMILIES: usize>\n \n     /// Finishes the write batch by returning the new sequence number and the new SST files. This\n     /// writes all outstanding thread local data to disk.\n-    #[tracing::instrument(level = \"trace\", skip(self))]\n-    pub(crate) fn finish(&mut self) -> Result<FinishResult> {\n+    #[tracing::instrument(level = \"trace\", skip_all)]\n+    pub(crate) fn finish(\n+        &mut self,\n+        get_accessed_key_hashes: impl Fn(u32) -> qfilter::Filter + Send + Sync,\n+    ) -> Result<FinishResult> {\n         let mut new_blob_files = Vec::new();\n \n         // First, we flush all thread local collectors to the global collectors.\n@@ -343,7 +347,7 @@ impl<K: StoreKey + Send + Sync, S: ParallelScheduler, const FAMILIES: usize>\n             },\n         )?;\n \n-        // Not we need to write the new meta files.\n+        // Now we need to write the new meta files.\n         let new_meta_collectors = [(); FAMILIES].map(|_| Mutex::new(Vec::new()));\n         let meta_collectors = replace(&mut self.meta_collectors, new_meta_collectors);\n         let keys_written = AtomicU64::new(0);\n@@ -366,6 +370,8 @@ impl<K: StoreKey + Send + Sync, S: ParallelScheduler, const FAMILIES: usize>\n                         builder.add(seq, sst);\n                     }\n                     keys_written.fetch_add(entries, Ordering::Relaxed);\n+                    let accessed_key_hashes = get_accessed_key_hashes(family);\n+                    builder.set_used_key_hashes_amqf(accessed_key_hashes);\n                     let seq = self.current_sequence_number.fetch_add(1, Ordering::SeqCst) + 1;\n                     let file = builder.write(&self.db_path, seq)?;\n                     Ok((seq, file))\n@@ -415,7 +421,9 @@ impl<K: StoreKey + Send + Sync, S: ParallelScheduler, const FAMILIES: usize>\n         let path = self.db_path.join(format!(\"{seq:08}.sst\"));\n         let (meta, file) = self\n             .parallel_scheduler\n-            .block_in_place(|| write_static_stored_file(entries, total_key_size, &path))\n+            .block_in_place(|| {\n+                write_static_stored_file(entries, total_key_size, &path, MetaEntryFlags::FRESH)\n+            })\n             .with_context(|| format!(\"Unable to write SST file {seq:08}.sst\"))?;\n \n         #[cfg(feature = \"verify_sst_content\")]"
        },
        {
            "sha": "e8501ff485219fa23d85948669a60a019981c1c4",
            "filename": "turbopack/crates/turbo-tasks-backend/src/database/turbo/mod.rs",
            "status": "modified",
            "additions": 27,
            "deletions": 18,
            "changes": 45,
            "blob_url": "https://github.com/vercel/next.js/blob/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/27c24bf79258597ebf67c5f558091d3ea4f9dcaf/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fdatabase%2Fturbo%2Fmod.rs?ref=27c24bf79258597ebf67c5f558091d3ea4f9dcaf",
            "patch": "@@ -21,6 +21,9 @@ use crate::database::{\n \n mod parallel_scheduler;\n \n+/// Number of key families, see KeySpace enum for their numbers.\n+const FAMILIES: usize = 5;\n+\n const MB: u64 = 1024 * 1024;\n const COMPACT_CONFIG: CompactConfig = CompactConfig {\n     min_merge_count: 3,\n@@ -33,10 +36,11 @@ const COMPACT_CONFIG: CompactConfig = CompactConfig {\n };\n \n pub struct TurboKeyValueDatabase {\n-    db: Arc<TurboPersistence<TurboTasksParallelScheduler>>,\n+    db: Arc<TurboPersistence<TurboTasksParallelScheduler, FAMILIES>>,\n     compact_join_handle: Mutex<Option<JoinHandle<Result<()>>>>,\n     is_ci: bool,\n     is_short_session: bool,\n+    is_fresh: bool,\n }\n \n impl TurboKeyValueDatabase {\n@@ -47,6 +51,7 @@ impl TurboKeyValueDatabase {\n             compact_join_handle: Mutex::new(None),\n             is_ci,\n             is_short_session,\n+            is_fresh: db.is_empty(),\n         })\n     }\n }\n@@ -108,28 +113,31 @@ impl KeyValueDatabase for TurboKeyValueDatabase {\n             join_handle.join()?;\n         }\n         // Compact the database on shutdown\n-        if self.is_ci {\n-            // Fully compact in CI to reduce cache size\n-            do_compact(\n-                &self.db,\n-                \"Finished filesystem cache database compaction\",\n-                usize::MAX,\n-            )?;\n-        } else {\n-            // Compact with a reasonable limit in non-CI environments\n-            do_compact(\n-                &self.db,\n-                \"Finished filesystem cache database compaction\",\n-                available_parallelism().map_or(4, |c| max(4, c.get())),\n-            )?;\n+        // (Avoid compacting a fresh database since we don't have any usage info yet)\n+        if !self.is_fresh {\n+            if self.is_ci {\n+                // Fully compact in CI to reduce cache size\n+                do_compact(\n+                    &self.db,\n+                    \"Finished filesystem cache database compaction\",\n+                    usize::MAX,\n+                )?;\n+            } else {\n+                // Compact with a reasonable limit in non-CI environments\n+                do_compact(\n+                    &self.db,\n+                    \"Finished filesystem cache database compaction\",\n+                    available_parallelism().map_or(4, |c| max(4, c.get())),\n+                )?;\n+            }\n         }\n         // Shutdown the database\n         self.db.shutdown()\n     }\n }\n \n fn do_compact(\n-    db: &TurboPersistence<TurboTasksParallelScheduler>,\n+    db: &TurboPersistence<TurboTasksParallelScheduler, FAMILIES>,\n     message: &'static str,\n     max_merge_segment_count: usize,\n ) -> Result<()> {\n@@ -151,8 +159,9 @@ fn do_compact(\n }\n \n pub struct TurboWriteBatch<'a> {\n-    batch: turbo_persistence::WriteBatch<WriteBuffer<'static>, TurboTasksParallelScheduler, 5>,\n-    db: &'a Arc<TurboPersistence<TurboTasksParallelScheduler>>,\n+    batch:\n+        turbo_persistence::WriteBatch<WriteBuffer<'static>, TurboTasksParallelScheduler, FAMILIES>,\n+    db: &'a Arc<TurboPersistence<TurboTasksParallelScheduler, FAMILIES>>,\n     compact_join_handle: Option<&'a Mutex<Option<JoinHandle<Result<()>>>>>,\n }\n "
        }
    ],
    "stats": {
        "total": 619,
        "additions": 431,
        "deletions": 188
    }
}