{
    "author": "lubieowoce",
    "message": "[Cache Components] Don't propagate tags/life for omitted caches (#82884)\n\nCaches with staleness/expiration below certain thresholds are not\nincluded in static prerenders and are treated as dynamic. However, the\nlogic for propagating life/tags did not factor this in, meaning that a\nprerender could get `cacheLife(\"seconds\")`, making it expire (both on\nthe server and in the client router cache) much earlier than necessary.\nThis PR fixes that.\n\nCloses NAR-271\n\n### Implementation notes\n\nThe solution relies on the fact that in a Cache Components prerender,\nwe'll first fill the caches in the prospective render, and then read\nthem again in the final prerender. Previously, we'd propagate cache\nlife/tags in the prospective render, when the cache was filled, but this\ndidn't factor in the fact that the final render might decide to omit the\ncache, leading to the problem described earlier. After this change,\nwe'll be relying on the fact that the entry will be read in the final\nprerender, at which point we decide if it should be included or not, and\nthen propagate cache life/tags if it is.\n\nAdditionally, we filter the omitted cache entries from the resume data\ncache (RDC). Otherwise they would be available during the resume, which\nthey should not be.\n\nTo be honest, this feels a bit brittle, and perhaps we should take a\nlook at how we're handling this and make it cleaner, but it should work\nfor now.\n\n---------\n\nCo-authored-by: Hendrik Liebau <mail@hendrik-liebau.de>",
    "sha": "678f1052d3653c0a897cb943f95c3c4d26ec6f19",
    "files": [
        {
            "sha": "d5cd96a317792c9bfe7ee413aa36d3ff82cd0550",
            "filename": "packages/next/src/export/routes/app-page.ts",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fexport%2Froutes%2Fapp-page.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fexport%2Froutes%2Fapp-page.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fexport%2Froutes%2Fapp-page.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -244,7 +244,10 @@ export async function exportAppPage(\n       cacheControl,\n       fetchMetrics,\n       renderResumeDataCache: renderResumeDataCache\n-        ? await stringifyResumeDataCache(renderResumeDataCache)\n+        ? await stringifyResumeDataCache(\n+            renderResumeDataCache,\n+            renderOpts.experimental.cacheComponents\n+          )\n         : undefined,\n     }\n   } catch (err) {"
        },
        {
            "sha": "307177ea9141862741f8a603a5c0fa80d7aacbdf",
            "filename": "packages/next/src/server/app-render/app-render.tsx",
            "status": "modified",
            "additions": 12,
            "deletions": 6,
            "changes": 18,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fapp-render.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fapp-render.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fapp-render.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -3932,12 +3932,15 @@ async function prerenderToStream(\n               ? DynamicHTMLPreludeState.Empty\n               : DynamicHTMLPreludeState.Full,\n             fallbackRouteParams,\n-            resumeDataCache\n+            resumeDataCache,\n+            experimental.cacheComponents\n           )\n         } else {\n           // Dynamic Data case\n-          metadata.postponed =\n-            await getDynamicDataPostponedState(resumeDataCache)\n+          metadata.postponed = await getDynamicDataPostponedState(\n+            resumeDataCache,\n+            experimental.cacheComponents\n+          )\n         }\n         reactServerResult.consume()\n         return {\n@@ -4155,12 +4158,14 @@ async function prerenderToStream(\n               ? DynamicHTMLPreludeState.Empty\n               : DynamicHTMLPreludeState.Full,\n             fallbackRouteParams,\n-            prerenderResumeDataCache\n+            prerenderResumeDataCache,\n+            experimental.cacheComponents\n           )\n         } else {\n           // Dynamic Data case.\n           metadata.postponed = await getDynamicDataPostponedState(\n-            prerenderResumeDataCache\n+            prerenderResumeDataCache,\n+            experimental.cacheComponents\n           )\n         }\n         // Regardless of whether this is the Dynamic HTML or Dynamic Data case we need to ensure we include\n@@ -4185,7 +4190,8 @@ async function prerenderToStream(\n       } else if (fallbackRouteParams && fallbackRouteParams.size > 0) {\n         // Rendering the fallback case.\n         metadata.postponed = await getDynamicDataPostponedState(\n-          prerenderResumeDataCache\n+          prerenderResumeDataCache,\n+          experimental.cacheComponents\n         )\n \n         return {"
        },
        {
            "sha": "775e6580c5c2cf2322eee181cd2ffcdb2b6a7658",
            "filename": "packages/next/src/server/app-render/postponed-state.test.ts",
            "status": "modified",
            "additions": 14,
            "deletions": 6,
            "changes": 20,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.test.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -21,6 +21,9 @@ export function createMockOpaqueFallbackRouteParams(\n   return new Map(Object.entries(params))\n }\n \n+const isCacheComponentsEnabled =\n+  process.env.__NEXT_EXPERIMENTAL_CACHE_COMPONENTS === 'true'\n+\n describe('getDynamicHTMLPostponedState', () => {\n   it('serializes a HTML postponed state with fallback params', async () => {\n     const key = '%%drp:slug:e9615126684e5%%'\n@@ -36,19 +39,21 @@ describe('getDynamicHTMLPostponedState', () => {\n         tags: [],\n         stale: 0,\n         timestamp: 0,\n-        expire: 0,\n-        revalidate: 0,\n+        expire: 300,\n+        revalidate: 1,\n       })\n     )\n \n     const state = await getDynamicHTMLPostponedState(\n       { [key]: key, nested: { [key]: key } },\n       DynamicHTMLPreludeState.Full,\n       fallbackRouteParams,\n-      prerenderResumeDataCache\n+      prerenderResumeDataCache,\n+      isCacheComponentsEnabled\n     )\n \n     const parsed = parsePostponedState(state, '/blog/[slug]', { slug: '123' })\n+\n     expect(parsed).toMatchInlineSnapshot(`\n      {\n        \"data\": [\n@@ -84,7 +89,8 @@ describe('getDynamicHTMLPostponedState', () => {\n       { key: 'value' },\n       DynamicHTMLPreludeState.Full,\n       null,\n-      createPrerenderResumeDataCache()\n+      createPrerenderResumeDataCache(),\n+      isCacheComponentsEnabled\n     )\n     expect(state).toMatchInlineSnapshot(`\"19:[1,{\"key\":\"value\"}]null\"`)\n   })\n@@ -98,7 +104,8 @@ describe('getDynamicHTMLPostponedState', () => {\n       { [key]: key },\n       DynamicHTMLPreludeState.Full,\n       fallbackRouteParams,\n-      createPrerenderResumeDataCache()\n+      createPrerenderResumeDataCache(),\n+      isCacheComponentsEnabled\n     )\n \n     const value = 'hello'\n@@ -118,7 +125,8 @@ describe('getDynamicHTMLPostponedState', () => {\n describe('getDynamicDataPostponedState', () => {\n   it('serializes a data postponed state with fallback params', async () => {\n     const state = await getDynamicDataPostponedState(\n-      createPrerenderResumeDataCache()\n+      createPrerenderResumeDataCache(),\n+      isCacheComponentsEnabled\n     )\n     expect(state).toMatchInlineSnapshot(`\"4:nullnull\"`)\n   })"
        },
        {
            "sha": "712a4ed8fc394882a6c6c9f4aac01845d8d55d3a",
            "filename": "packages/next/src/server/app-render/postponed-state.ts",
            "status": "modified",
            "additions": 8,
            "deletions": 5,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fapp-render%2Fpostponed-state.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -79,7 +79,8 @@ export async function getDynamicHTMLPostponedState(\n   postponed: ReactPostponed,\n   preludeState: DynamicHTMLPreludeState,\n   fallbackRouteParams: OpaqueFallbackRouteParams | null,\n-  resumeDataCache: PrerenderResumeDataCache | RenderResumeDataCache\n+  resumeDataCache: PrerenderResumeDataCache | RenderResumeDataCache,\n+  isCacheComponentsEnabled: boolean\n ): Promise<string> {\n   const data: DynamicHTMLPostponedState['data'] = [preludeState, postponed]\n   const dataString = JSON.stringify(data)\n@@ -89,7 +90,8 @@ export async function getDynamicHTMLPostponedState(\n   if (!fallbackRouteParams || fallbackRouteParams.size === 0) {\n     // Serialized as `<postponedString.length>:<postponedString><renderResumeDataCache>`\n     return `${dataString.length}:${dataString}${await stringifyResumeDataCache(\n-      createRenderResumeDataCache(resumeDataCache)\n+      createRenderResumeDataCache(resumeDataCache),\n+      isCacheComponentsEnabled\n     )}`\n   }\n \n@@ -102,13 +104,14 @@ export async function getDynamicHTMLPostponedState(\n   const postponedString = `${replacementsString.length}${replacementsString}${dataString}`\n \n   // Serialized as `<postponedString.length>:<postponedString><renderResumeDataCache>`\n-  return `${postponedString.length}:${postponedString}${await stringifyResumeDataCache(resumeDataCache)}`\n+  return `${postponedString.length}:${postponedString}${await stringifyResumeDataCache(resumeDataCache, isCacheComponentsEnabled)}`\n }\n \n export async function getDynamicDataPostponedState(\n-  resumeDataCache: PrerenderResumeDataCache | RenderResumeDataCache\n+  resumeDataCache: PrerenderResumeDataCache | RenderResumeDataCache,\n+  isCacheComponentsEnabled: boolean\n ): Promise<string> {\n-  return `4:null${await stringifyResumeDataCache(createRenderResumeDataCache(resumeDataCache))}`\n+  return `4:null${await stringifyResumeDataCache(createRenderResumeDataCache(resumeDataCache), isCacheComponentsEnabled)}`\n }\n \n export function parsePostponedState("
        },
        {
            "sha": "6f2f621896e9a5203911e1256dc0047fd12b9c04",
            "filename": "packages/next/src/server/resume-data-cache/cache-store.ts",
            "status": "modified",
            "additions": 12,
            "deletions": 1,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fcache-store.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fcache-store.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fcache-store.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -4,6 +4,7 @@ import {\n } from '../app-render/encryption-utils'\n import type { CacheEntry } from '../lib/cache-handlers/types'\n import type { CachedFetchValue } from '../response-cache/types'\n+import { DYNAMIC_EXPIRE } from '../use-cache/constants'\n \n /**\n  * A generic cache store type that provides a subset of Map functionality\n@@ -92,12 +93,22 @@ export function parseUseCacheCacheStore(\n  * @returns A promise that resolves to an array of key-value pairs with serialized values\n  */\n export async function serializeUseCacheCacheStore(\n-  entries: IterableIterator<[string, Promise<CacheEntry>]>\n+  entries: IterableIterator<[string, Promise<CacheEntry>]>,\n+  isCacheComponentsEnabled: boolean\n ): Promise<Array<[string, UseCacheCacheStoreSerialized] | null>> {\n   return Promise.all(\n     Array.from(entries).map(([key, value]) => {\n       return value\n         .then(async (entry) => {\n+          if (\n+            isCacheComponentsEnabled &&\n+            (entry.revalidate === 0 || entry.expire < DYNAMIC_EXPIRE)\n+          ) {\n+            // The entry was omitted from the prerender result, and subsequently\n+            // does not need to be included in the serialized RDC.\n+            return null\n+          }\n+\n           const [left, right] = entry.value.tee()\n           entry.value = right\n "
        },
        {
            "sha": "27f8229679b8b7832b98f938f566adb5d39b9a6d",
            "filename": "packages/next/src/server/resume-data-cache/resume-data-cache.test.ts",
            "status": "modified",
            "additions": 79,
            "deletions": 23,
            "changes": 102,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.test.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -6,25 +6,56 @@ import { createPrerenderResumeDataCache } from './resume-data-cache'\n import { streamFromString } from '../stream-utils/node-web-streams-helper'\n import { inflateSync } from 'node:zlib'\n \n-function createCacheWithSingleEntry() {\n+const isCacheComponentsEnabled =\n+  process.env.__NEXT_EXPERIMENTAL_CACHE_COMPONENTS === 'true'\n+\n+function createMockedCache() {\n   const cache = createPrerenderResumeDataCache()\n+\n+  // Should be included during serialization.\n   cache.cache.set(\n     'success',\n     Promise.resolve({\n       value: streamFromString('value'),\n       tags: [],\n       stale: 0,\n       timestamp: 0,\n-      expire: 0,\n+      expire: 300,\n+      revalidate: 1,\n+    })\n+  )\n+\n+  // Should be omitted during serialization.\n+  cache.cache.set(\n+    'dynamic-expire',\n+    Promise.resolve({\n+      value: streamFromString('value'),\n+      tags: [],\n+      stale: 0,\n+      timestamp: 0,\n+      expire: 299,\n+      revalidate: 1,\n+    })\n+  )\n+\n+  // Should be omitted during serialization.\n+  cache.cache.set(\n+    'zero-revalidate',\n+    Promise.resolve({\n+      value: streamFromString('value'),\n+      tags: [],\n+      stale: 0,\n+      timestamp: 0,\n+      expire: 300,\n       revalidate: 0,\n     })\n   )\n \n   return cache\n }\n \n-function createCacheWithSingleEntryThatFails() {\n-  const cache = createCacheWithSingleEntry()\n+function createMockedCacheWithEntryThatFails() {\n+  const cache = createMockedCache()\n   cache.cache.set('fail', Promise.reject(new Error('Failed to serialize')))\n \n   return cache\n@@ -33,12 +64,18 @@ function createCacheWithSingleEntryThatFails() {\n describe('stringifyResumeDataCache', () => {\n   it('serializes an empty cache', async () => {\n     const cache = createPrerenderResumeDataCache()\n-    expect(await stringifyResumeDataCache(cache)).toBe('null')\n+    expect(\n+      await stringifyResumeDataCache(cache, isCacheComponentsEnabled)\n+    ).toBe('null')\n   })\n \n-  it('serializes a cache with a single entry', async () => {\n-    const cache = createCacheWithSingleEntry()\n-    const compressed = await stringifyResumeDataCache(cache)\n+  it('only serializes cache entries that were not excluded from the prerender result', async () => {\n+    const cache = createMockedCache()\n+\n+    const compressed = await stringifyResumeDataCache(\n+      cache,\n+      isCacheComponentsEnabled\n+    )\n \n     // We have to decompress the output because the compressed string is not\n     // deterministic. If it fails here it's because the compressed string is\n@@ -47,14 +84,24 @@ describe('stringifyResumeDataCache', () => {\n       Buffer.from(compressed, 'base64')\n     ).toString('utf-8')\n \n-    expect(decompressed).toMatchInlineSnapshot(\n-      `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":0,\"revalidate\":0}},\"encryptedBoundArgs\":{}}}\"`\n-    )\n+    if (isCacheComponentsEnabled) {\n+      expect(decompressed).toMatchInlineSnapshot(\n+        `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":1}},\"encryptedBoundArgs\":{}}}\"`\n+      )\n+    } else {\n+      expect(decompressed).toMatchInlineSnapshot(\n+        `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":1},\"dynamic-expire\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":299,\"revalidate\":1},\"zero-revalidate\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":0}},\"encryptedBoundArgs\":{}}}\"`\n+      )\n+    }\n   })\n \n-  it('serializes a cache with a single entry that fails', async () => {\n-    const cache = createCacheWithSingleEntryThatFails()\n-    const compressed = await stringifyResumeDataCache(cache)\n+  it('serializes a cache with an entry that fails', async () => {\n+    const cache = createMockedCacheWithEntryThatFails()\n+\n+    const compressed = await stringifyResumeDataCache(\n+      cache,\n+      isCacheComponentsEnabled\n+    )\n \n     // We have to decompress the output because the compressed string is not\n     // deterministic. If it fails here it's because the compressed string is\n@@ -63,11 +110,17 @@ describe('stringifyResumeDataCache', () => {\n       Buffer.from(compressed, 'base64')\n     ).toString('utf-8')\n \n-    // We expect that the cache will still contain the successful entry but the\n-    // failed entry will be ignored and omitted from the output.\n-    expect(decompressed).toMatchInlineSnapshot(\n-      `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":0,\"revalidate\":0}},\"encryptedBoundArgs\":{}}}\"`\n-    )\n+    // We expect that the cache will still contain the successful entries\n+    // but the failed entry will be ignored and omitted from the output.\n+    if (isCacheComponentsEnabled) {\n+      expect(decompressed).toMatchInlineSnapshot(\n+        `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":1}},\"encryptedBoundArgs\":{}}}\"`\n+      )\n+    } else {\n+      expect(decompressed).toMatchInlineSnapshot(\n+        `\"{\"store\":{\"fetch\":{},\"cache\":{\"success\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":1},\"dynamic-expire\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":299,\"revalidate\":1},\"zero-revalidate\":{\"value\":\"dmFsdWU=\",\"tags\":[],\"stale\":0,\"timestamp\":0,\"expire\":300,\"revalidate\":0}},\"encryptedBoundArgs\":{}}}\"`\n+      )\n+    }\n   })\n })\n \n@@ -78,13 +131,16 @@ describe('parseResumeDataCache', () => {\n     )\n   })\n \n-  it('parses a cache with a single entry', async () => {\n-    const cache = createCacheWithSingleEntry()\n-    const serialized = await stringifyResumeDataCache(cache)\n+  it('parses a filled cache', async () => {\n+    const cache = createMockedCache()\n+    const serialized = await stringifyResumeDataCache(\n+      cache,\n+      isCacheComponentsEnabled\n+    )\n \n     const parsed = createRenderResumeDataCache(serialized)\n \n-    expect(parsed.cache.size).toBe(1)\n+    expect(parsed.cache.size).toBe(isCacheComponentsEnabled ? 1 : 3)\n     expect(parsed.fetch.size).toBe(0)\n   })\n })"
        },
        {
            "sha": "32bc2b51261a24a7042fe989e89de2a2ccd0a1e5",
            "filename": "packages/next/src/server/resume-data-cache/resume-data-cache.ts",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fresume-data-cache%2Fresume-data-cache.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -100,7 +100,8 @@ type ResumeStoreSerialized = {\n  * 'null' if empty\n  */\n export async function stringifyResumeDataCache(\n-  resumeDataCache: RenderResumeDataCache | PrerenderResumeDataCache\n+  resumeDataCache: RenderResumeDataCache | PrerenderResumeDataCache,\n+  isCacheComponentsEnabled: boolean\n ): Promise<string> {\n   if (process.env.NEXT_RUNTIME === 'edge') {\n     throw new InvariantError(\n@@ -116,7 +117,10 @@ export async function stringifyResumeDataCache(\n         fetch: Object.fromEntries(Array.from(resumeDataCache.fetch.entries())),\n         cache: Object.fromEntries(\n           (\n-            await serializeUseCacheCacheStore(resumeDataCache.cache.entries())\n+            await serializeUseCacheCacheStore(\n+              resumeDataCache.cache.entries(),\n+              isCacheComponentsEnabled\n+            )\n           ).filter(\n             (entry): entry is [string, UseCacheCacheStoreSerialized] =>\n               entry !== null"
        },
        {
            "sha": "b911020caa21c3ad882811db867cf2580e4b26f7",
            "filename": "packages/next/src/server/use-cache/use-cache-wrapper.ts",
            "status": "modified",
            "additions": 54,
            "deletions": 32,
            "changes": 86,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/packages%2Fnext%2Fsrc%2Fserver%2Fuse-cache%2Fuse-cache-wrapper.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -378,7 +378,7 @@ function propagateCacheLifeAndTags(\n }\n \n async function collectResult(\n-  savedStream: ReadableStream,\n+  savedStream: ReadableStream<Uint8Array>,\n   workStore: WorkStore,\n   cacheContext: CacheContext,\n   innerCacheStore: UseCacheStore,\n@@ -398,7 +398,7 @@ async function collectResult(\n   // that the stream might also error for other reasons anyway such as losing\n   // connection.\n \n-  const buffer: any[] = []\n+  const buffer: Uint8Array[] = []\n   const reader = savedStream.getReader()\n \n   try {\n@@ -410,7 +410,7 @@ async function collectResult(\n   }\n \n   let idx = 0\n-  const bufferStream = new ReadableStream({\n+  const bufferStream = new ReadableStream<Uint8Array>({\n     pull(controller) {\n       if (workStore.invalidDynamicUsageError) {\n         controller.error(workStore.invalidDynamicUsageError)\n@@ -451,17 +451,40 @@ async function collectResult(\n     tags: collectedTags === null ? [] : collectedTags,\n   }\n \n-  // Propagate tags/revalidate to the parent context.\n-  if (cacheContext) {\n-    propagateCacheLifeAndTags(cacheContext, entry)\n-  }\n+  if (cacheContext.outerWorkUnitStore) {\n+    const outerWorkUnitStore = cacheContext.outerWorkUnitStore\n \n-  const cacheSignal = cacheContext.outerWorkUnitStore\n-    ? getCacheSignal(cacheContext.outerWorkUnitStore)\n-    : null\n+    // Propagate cache life & tags to the parent context if appropriate.\n+    switch (outerWorkUnitStore.type) {\n+      case 'prerender':\n+      case 'prerender-runtime': {\n+        // If we've just created a cache result, and we're filling caches for a\n+        // Cache Components prerender, then we don't want to propagate cache\n+        // life & tags yet, in case the entry ends up being omitted from the\n+        // final prerender due to short expire/stale times. If it is omitted,\n+        // then it shouldn't have any effects on the prerender. We'll decide\n+        // whether or not this cache should have its life & tags propagated when\n+        // we read the entry in the final prerender from the resume data cache.\n+        break\n+      }\n+      case 'request':\n+      case 'private-cache':\n+      case 'cache':\n+      case 'unstable-cache':\n+      case 'prerender-legacy':\n+      case 'prerender-ppr': {\n+        propagateCacheLifeAndTags(cacheContext, entry)\n+        break\n+      }\n+      default: {\n+        outerWorkUnitStore satisfies never\n+      }\n+    }\n \n-  if (cacheSignal) {\n-    cacheSignal.endRead()\n+    const cacheSignal = getCacheSignal(outerWorkUnitStore)\n+    if (cacheSignal) {\n+      cacheSignal.endRead()\n+    }\n   }\n \n   return entry\n@@ -1160,8 +1183,6 @@ export function cache(\n         const cachedEntry = renderResumeDataCache.cache.get(serializedCacheKey)\n         if (cachedEntry !== undefined) {\n           const existingEntry = await cachedEntry\n-          propagateCacheLifeAndTags(cacheContext, existingEntry)\n-\n           if (workUnitStore !== undefined && existingEntry !== undefined) {\n             if (\n               existingEntry.revalidate === 0 ||\n@@ -1170,11 +1191,11 @@ export function cache(\n               switch (workUnitStore.type) {\n                 case 'prerender':\n                   // In a Dynamic I/O prerender, if the cache entry has\n-                  // revalidate: 0 or if the expire time is under 5 minutes, then\n-                  // we consider this cache entry dynamic as it's not worth\n-                  // generating static pages for such data. It's better to leave a\n-                  // PPR hole that can be filled in dynamically with a potentially\n-                  // cached entry.\n+                  // revalidate: 0 or if the expire time is under 5 minutes,\n+                  // then we consider this cache entry dynamic as it's not worth\n+                  // generating static pages for such data. It's better to leave\n+                  // a dynamic hole that can be filled in during the resume with\n+                  // a potentially cached entry.\n                   if (cacheSignal) {\n                     cacheSignal.endRead()\n                   }\n@@ -1184,7 +1205,8 @@ export function cache(\n                     'dynamic \"use cache\"'\n                   )\n                 case 'prerender-runtime': {\n-                  // In a runtime prerender, we have to make sure that APIs that would hang during a static prerender\n+                  // In the final phase of a runtime prerender, we have to make\n+                  // sure that APIs that would hang during a static prerender\n                   // are resolved with a delay, in the runtime stage.\n                   if (workUnitStore.runtimeStagePromise) {\n                     await workUnitStore.runtimeStagePromise\n@@ -1206,10 +1228,10 @@ export function cache(\n             if (existingEntry.stale < RUNTIME_PREFETCH_DYNAMIC_STALE) {\n               switch (workUnitStore.type) {\n                 case 'prerender-runtime':\n-                  // In a runtime prerender, if the cache entry will become stale in less then 30 seconds,\n-                  // we consider this cache entry dynamic as it's not worth prefetching.\n-                  // It's better to leave a PPR hole that can be filled in dynamically\n-                  // with a potentially cached entry.\n+                  // In a runtime prerender, if the cache entry will become\n+                  // stale in less then 30 seconds, we consider this cache entry\n+                  // dynamic as it's not worth prefetching. It's better to leave\n+                  // a dynamic hole that can be filled during the navigation.\n                   if (cacheSignal) {\n                     cacheSignal.endRead()\n                   }\n@@ -1232,6 +1254,11 @@ export function cache(\n             }\n           }\n \n+          // We want to make sure we only propagate cache life & tags if the\n+          // entry was *not* omitted from the prerender. So we only do this\n+          // after the above early returns.\n+          propagateCacheLifeAndTags(cacheContext, existingEntry)\n+\n           const [streamA, streamB] = existingEntry.value.tee()\n           existingEntry.value = streamB\n \n@@ -1361,8 +1388,9 @@ export function cache(\n               // In a Dynamic I/O prerender, if the cache entry has revalidate:\n               // 0 or if the expire time is under 5 minutes, then we consider\n               // this cache entry dynamic as it's not worth generating static\n-              // pages for such data. It's better to leave a PPR hole that can\n-              // be filled in dynamically with a potentially cached entry.\n+              // pages for such data. It's better to leave a dynamic hole that\n+              // can be filled in during the resume with a potentially cached\n+              // entry.\n               if (cacheSignal) {\n                 cacheSignal.endRead()\n               }\n@@ -1372,12 +1400,6 @@ export function cache(\n                 'dynamic \"use cache\"'\n               )\n             case 'prerender-runtime':\n-              // In a runtime prerender, we have to make sure that APIs that would hang during a static prerender\n-              // are resolved with a delay, in the runtime stage.\n-              if (workUnitStore.runtimeStagePromise) {\n-                await workUnitStore.runtimeStagePromise\n-              }\n-              break\n             case 'prerender-ppr':\n             case 'prerender-legacy':\n             case 'request':"
        },
        {
            "sha": "081328826f8beae99ccbfda8d72283312fb5f766",
            "filename": "test/e2e/app-dir/segment-cache/staleness/app/page.tsx",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fpage.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fpage.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fpage.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -33,6 +33,11 @@ export default function Page() {\n         <li>\n           <LinkAccordion href=\"/dynamic\">Page with dynamic data</LinkAccordion>\n         </li>\n+        <li>\n+          <LinkAccordion href=\"/seconds\">\n+            Page with cached data with <code>cacheLife(\"seconds\")</code>\n+          </LinkAccordion>\n+        </li>\n       </ul>\n     </>\n   )"
        },
        {
            "sha": "bf98ee73b3591deb5f0e01f9a4e121b406914a1e",
            "filename": "test/e2e/app-dir/segment-cache/staleness/app/seconds/page.tsx",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fseconds%2Fpage.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fseconds%2Fpage.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fapp%2Fseconds%2Fpage.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -0,0 +1,32 @@\n+import { Suspense } from 'react'\n+import { unstable_cacheLife } from 'next/cache'\n+\n+export default function Page() {\n+  return (\n+    <main>\n+      <p>\n+        Caches that use the 'seconds' profile will be omitted from static\n+        prerenders, making this essentially dynamic. If we omit it, it should\n+        not affect the cache life of the prerender.\n+      </p>\n+      <Suspense fallback=\"Loading...\">\n+        <ShortLivedContent />\n+      </Suspense>\n+      <br />\n+      <p>Longer lived caches should still affect the cache life of the page.</p>\n+      <LongerLivedContent />\n+    </main>\n+  )\n+}\n+\n+async function ShortLivedContent() {\n+  'use cache'\n+  unstable_cacheLife('seconds')\n+  return <div>Short-lived cached content</div>\n+}\n+\n+async function LongerLivedContent() {\n+  'use cache'\n+  unstable_cacheLife('minutes')\n+  return <div>Longer-lived cached content</div>\n+}"
        },
        {
            "sha": "f300aa1fcba18050184d9d7eb90cee05bb3bcf39",
            "filename": "test/e2e/app-dir/segment-cache/staleness/segment-cache-stale-time.test.ts",
            "status": "modified",
            "additions": 69,
            "deletions": 0,
            "changes": 69,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fsegment-cache-stale-time.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fsegment-cache-stale-time.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fsegment-cache%2Fstaleness%2Fsegment-cache-stale-time.test.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -220,4 +220,73 @@ describe('segment cache (staleness)', () => {\n       'Dynamic content'\n     )\n   })\n+\n+  it('caches omitted from the prerender should not affect when the prefetch is expired', async () => {\n+    let page: Playwright.Page\n+    const browser = await next.browser('/', {\n+      beforePageLoad(p: Playwright.Page) {\n+        page = p\n+      },\n+    })\n+    const act = createRouterAct(page)\n+\n+    await page.clock.install()\n+\n+    // Reveal the link to trigger a prefetch\n+    await act(\n+      async () => {\n+        await browser\n+          .elementByCss('input[data-link-accordion=\"/seconds\"]')\n+          .click()\n+        await browser.elementByCss('a[href=\"/seconds\"]')\n+      },\n+      {\n+        // cacheLife(\"seconds\") should be excluded from a static prerender\n+        includes: 'Short-lived cached content',\n+        block: 'reject',\n+      }\n+    )\n+\n+    // Hide the link\n+    await browser.elementByCss('input[data-link-accordion=\"/seconds\"]').click()\n+\n+    // Fast forward 30 seconds and 1 millisecond\n+    // (matching the staleness of the \"seconds\" profile)\n+    const timeStep = 30 * 1000 + 1\n+    await page.clock.fastForward(timeStep)\n+\n+    // Reveal the link again to trigger new prefetch tasks.\n+    // The cache with `cacheLife('seconds'`) should not affect the stale time of the prefetch,\n+    // because we omit it from the prerender, so we shouldn't refetch anything yet.\n+    await act(async () => {\n+      await browser\n+        .elementByCss('input[data-link-accordion=\"/seconds\"]')\n+        .click()\n+      await browser.elementByCss('a[href=\"/seconds\"]')\n+    }, 'no-requests')\n+\n+    // Hide the link again\n+    await browser.elementByCss('input[data-link-accordion=\"/seconds\"]').click()\n+\n+    // Fast forward to 5 minutes and 1 millisecond after the prefetch.\n+    // (matching the staleness of the \"minutes\" profile)\n+    // Note that we should exclude the timestep we've already done.\n+    await page.clock.fastForward(5 * 60 * 1000 + 1 - timeStep)\n+\n+    // Reveal the link to trigger a prefetch.\n+    // The longer-lived cache we used on the page should make the previous prefetch expire,\n+    // so we should issue a new request.\n+    await act(\n+      async () => {\n+        await browser\n+          .elementByCss('input[data-link-accordion=\"/seconds\"]')\n+          .click()\n+        await browser.elementByCss('a[href=\"/seconds\"]')\n+      },\n+      {\n+        includes: 'Short-lived cached content',\n+        block: 'reject',\n+      }\n+    )\n+  })\n })"
        },
        {
            "sha": "7e514d331b0647c1b5f82b8aaba826a5f0a8d5fc",
            "filename": "test/e2e/app-dir/use-cache-custom-handler/app/prerender/page.tsx",
            "status": "added",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fapp%2Fprerender%2Fpage.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fapp%2Fprerender%2Fpage.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fapp%2Fprerender%2Fpage.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -0,0 +1,21 @@\n+import { Suspense } from 'react'\n+import { unstable_cacheLife as cacheLife } from 'next/cache'\n+\n+// The id prop is just used to assert on the logged cache key in tests.\n+async function DynamicCache({ id }: { id: string }) {\n+  'use cache'\n+  cacheLife('seconds')\n+  return <p>{new Date().toISOString()}</p>\n+}\n+\n+export default function Page() {\n+  return (\n+    <p>\n+      This page uses a short-lived \"use cache\", which is omitted from the\n+      prerender, but should still be saved in the cache handler.\n+      <Suspense>\n+        <DynamicCache id=\"dynamic-cache\" />\n+      </Suspense>\n+    </p>\n+  )\n+}"
        },
        {
            "sha": "0dec480db0b5729e87529d7435e8948df5680a47",
            "filename": "test/e2e/app-dir/use-cache-custom-handler/use-cache-custom-handler.test.ts",
            "status": "modified",
            "additions": 9,
            "deletions": 1,
            "changes": 10,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fuse-cache-custom-handler.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fuse-cache-custom-handler.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache-custom-handler%2Fuse-cache-custom-handler.test.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -4,7 +4,7 @@ import { retry } from 'next-test-utils'\n const isoDateRegExp = /^\\d{4}-\\d{2}-\\d{2}T\\d{2}:\\d{2}:\\d{2}\\.\\d{3}Z$/\n \n describe('use-cache-custom-handler', () => {\n-  const { next, skipped } = nextTestSetup({\n+  const { next, skipped, isNextStart } = nextTestSetup({\n     files: __dirname,\n     // Skip deployment so we can test the custom cache handlers log output\n     skipDeployment: true,\n@@ -184,4 +184,12 @@ describe('use-cache-custom-handler', () => {\n       )\n     })\n   })\n+\n+  if (isNextStart) {\n+    it('should save a short-lived cache during prerendering at buildtime', async () => {\n+      expect(next.cliOutput).toMatch(\n+        /ModernCustomCacheHandler::set \\[\"[A-Za-z0-9_-]{21}\",\"([0-9a-f]{2})+\",\\[{\"id\":\"dynamic-cache\"},\"\\$undefined\"\\]\\]/\n+      )\n+    })\n+  }\n })"
        },
        {
            "sha": "afe534295bf4465d34ce787e564ba6aa0431b5a3",
            "filename": "test/e2e/app-dir/use-cache/app/(partially-static)/cache-life-with-dynamic/page.tsx",
            "status": "added",
            "additions": 36,
            "deletions": 0,
            "changes": 36,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Fcache-life-with-dynamic%2Fpage.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Fcache-life-with-dynamic%2Fpage.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Fcache-life-with-dynamic%2Fpage.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -0,0 +1,36 @@\n+import { unstable_cacheLife as cacheLife } from 'next/cache'\n+import { connection } from 'next/server'\n+import { Suspense } from 'react'\n+\n+async function getCachedRandom() {\n+  'use cache'\n+  cacheLife('frequent')\n+  return Math.random()\n+}\n+\n+async function DynamicCache() {\n+  'use cache'\n+  cacheLife({ revalidate: 99, expire: 299, stale: 18 })\n+  return <p id=\"y\">{new Date().toISOString()}</p>\n+}\n+\n+async function Dynamic() {\n+  await connection()\n+  return null\n+}\n+\n+export default async function Page() {\n+  const x = await getCachedRandom()\n+\n+  return (\n+    <>\n+      <p id=\"x\">{x}</p>\n+      <Suspense fallback={<p id=\"y\">Loading...</p>}>\n+        <DynamicCache />\n+      </Suspense>\n+      <Suspense>\n+        <Dynamic />\n+      </Suspense>\n+    </>\n+  )\n+}"
        },
        {
            "sha": "2238358ba6d87711fa57ebf8c288667a1e26c419",
            "filename": "test/e2e/app-dir/use-cache/app/(partially-static)/rdc/page.tsx",
            "status": "modified",
            "additions": 20,
            "deletions": 2,
            "changes": 22,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Frdc%2Fpage.tsx",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Frdc%2Fpage.tsx",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fapp%2F(partially-static)%2Frdc%2Fpage.tsx?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -1,3 +1,4 @@\n+import { unstable_cacheLife } from 'next/cache'\n import { connection } from 'next/server'\n import { Suspense } from 'react'\n \n@@ -16,18 +17,35 @@ async function innermost(id: string) {\n   return id\n }\n \n+async function Short({ id }: { id: string }) {\n+  'use cache'\n+  unstable_cacheLife('seconds')\n+  return id\n+}\n+\n async function Dynamic() {\n   await connection()\n   return null\n }\n \n-export default async function Page() {\n+async function CachedStuff() {\n   await outermost('outer')\n   await innermost('inner')\n \n   return (\n     <Suspense>\n-      <Dynamic />\n+      <Short id=\"short\" />\n     </Suspense>\n   )\n }\n+\n+export default function Page() {\n+  return (\n+    <div>\n+      <CachedStuff />\n+      <Suspense>\n+        <Dynamic />\n+      </Suspense>\n+    </div>\n+  )\n+}"
        },
        {
            "sha": "280770e3fe342151cf467de06c1c7dd4e516fd61",
            "filename": "test/e2e/app-dir/use-cache/use-cache.test.ts",
            "status": "modified",
            "additions": 81,
            "deletions": 13,
            "changes": 94,
            "blob_url": "https://github.com/vercel/next.js/blob/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fuse-cache.test.ts",
            "raw_url": "https://github.com/vercel/next.js/raw/678f1052d3653c0a897cb943f95c3c4d26ec6f19/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fuse-cache.test.ts",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/test%2Fe2e%2Fapp-dir%2Fuse-cache%2Fuse-cache.test.ts?ref=678f1052d3653c0a897cb943f95c3c4d26ec6f19",
            "patch": "@@ -1,5 +1,5 @@\n import { nextTestSetup } from 'e2e-utils'\n-import { retry } from 'next-test-utils'\n+import { assertNoConsoleErrors, retry } from 'next-test-utils'\n import stripAnsi from 'strip-ansi'\n import { format } from 'util'\n import { Playwright } from 'next-webdriver'\n@@ -12,6 +12,11 @@ import { PrerenderManifest } from 'next/dist/build'\n const GENERIC_RSC_ERROR =\n   'An error occurred in the Server Components render. The specific message is omitted in production builds to avoid leaking sensitive details. A digest property is included on this error instance which may provide additional details about the nature of the error.'\n \n+const withPPR = process.env.__NEXT_EXPERIMENTAL_PPR === 'true'\n+\n+const withCacheComponents =\n+  process.env.__NEXT_EXPERIMENTAL_CACHE_COMPONENTS === 'true'\n+\n describe('use-cache', () => {\n   const { next, isNextDev, isNextDeploy, isNextStart, skipped } = nextTestSetup(\n     {\n@@ -444,11 +449,6 @@ describe('use-cache', () => {\n         await next.readFile('.next/prerender-manifest.json')\n       ) as PrerenderManifest\n \n-      const withPPR = process.env.__NEXT_EXPERIMENTAL_PPR === 'true'\n-\n-      const withCacheComponents =\n-        process.env.__NEXT_EXPERIMENTAL_CACHE_COMPONENTS === 'true'\n-\n       let prerenderedRoutes = Object.entries(prerenderManifest.routes)\n \n       if (withPPR || withCacheComponents) {\n@@ -518,25 +518,59 @@ describe('use-cache', () => {\n       expect(routes['/cache-life'].initialRevalidateSeconds).toBe(100)\n       expect(routes['/cache-life'].initialExpireSeconds).toBe(300)\n \n+      if (withCacheComponents) {\n+        expect(\n+          routes['/cache-life-with-dynamic'].initialRevalidateSeconds\n+        ).toBe(100)\n+        expect(routes['/cache-life-with-dynamic'].initialExpireSeconds).toBe(\n+          300\n+        )\n+      } else if (withPPR) {\n+        // We don't exclude dynamic caches for the legacy PPR prerendering.\n+        expect(\n+          routes['/cache-life-with-dynamic'].initialRevalidateSeconds\n+        ).toBe(99)\n+        expect(routes['/cache-life-with-dynamic'].initialExpireSeconds).toBe(\n+          299\n+        )\n+      }\n+\n       // default expireTime\n       expect(routes['/cache-fetch'].initialExpireSeconds).toBe(31536000)\n \n       // The revalidate config from the fetch call should lower the revalidate\n       // config for the page.\n       expect(routes['/cache-tag'].initialRevalidateSeconds).toBe(42)\n \n-      if (process.env.__NEXT_EXPERIMENTAL_PPR === 'true') {\n+      if (withPPR) {\n         // cache life profile \"weeks\"\n         expect(dynamicRoutes['/[id]'].fallbackRevalidate).toBe(604800)\n         expect(dynamicRoutes['/[id]'].fallbackExpire).toBe(2592000)\n       }\n     })\n \n     it('should match the expected stale config in the page header', async () => {\n-      const meta = JSON.parse(\n+      const cacheLifeMeta = JSON.parse(\n         await next.readFile('.next/server/app/cache-life.meta')\n       )\n-      expect(meta.headers['x-nextjs-stale-time']).toBe('19')\n+      expect(cacheLifeMeta.headers['x-nextjs-stale-time']).toBe('19')\n+\n+      if (withCacheComponents) {\n+        const cacheLifeWithDynamicMeta = JSON.parse(\n+          await next.readFile('.next/server/app/cache-life-with-dynamic.meta')\n+        )\n+        expect(cacheLifeWithDynamicMeta.headers['x-nextjs-stale-time']).toBe(\n+          '19'\n+        )\n+      } else if (withPPR) {\n+        const cacheLifeWithDynamicMeta = JSON.parse(\n+          await next.readFile('.next/server/app/cache-life-with-dynamic.meta')\n+        )\n+        // We don't exclude dynamic caches for the legacy PPR prerendering.\n+        expect(cacheLifeWithDynamicMeta.headers['x-nextjs-stale-time']).toBe(\n+          '18'\n+        )\n+      }\n     })\n \n     it('should send an SWR cache-control header based on the revalidate and expire values', async () => {\n@@ -556,6 +590,30 @@ describe('use-cache', () => {\n       )\n     })\n \n+    if (withCacheComponents) {\n+      it('should omit dynamic caches from prerendered shells', async () => {\n+        const browser = await next.browser('/cache-life-with-dynamic', {\n+          disableJavaScript: true,\n+        })\n+\n+        expect(await browser.elementById('y').text()).toBe('Loading...')\n+      })\n+    }\n+\n+    it('should not have hydration errors when resuming a partial shell with dynamic caches', async () => {\n+      const browser = await next.browser('/cache-life-with-dynamic', {\n+        pushErrorAsConsoleLog: true,\n+      })\n+\n+      await retry(async () => {\n+        expect(await browser.elementById('y').text()).not.toBe('Loading...')\n+      })\n+\n+      // There should be no hydration errors due to a buildtime date being\n+      // replaced by a new runtime date.\n+      await assertNoConsoleErrors(browser)\n+    })\n+\n     it('should propagate unstable_cache tags correctly', async () => {\n       const meta = JSON.parse(\n         await next.readFile('.next/server/app/cache-tag.meta')\n@@ -962,8 +1020,8 @@ describe('use-cache', () => {\n     })\n   }\n \n-  if (isNextStart && process.env.__NEXT_EXPERIMENTAL_PPR === 'true') {\n-    it('should exclude inner caches from the resume data cache (RDC)', async () => {\n+  if (isNextStart && withPPR) {\n+    it('should exclude inner caches and omitted caches from the resume data cache (RDC)', async () => {\n       await next.fetch('/rdc')\n \n       const resumeDataCache = extractResumeDataCacheFromPostponedState(\n@@ -974,11 +1032,21 @@ describe('use-cache', () => {\n \n       // There should be no cache entry for the \"middle\" cache function, because\n       // it's only used inside another cache scope (\"outer\"). Whereas \"inner\" is\n-      // also used inside a prerender scope (the page). Note: We're matching on\n-      // the \"id\" args that are encoded into the respective cache keys.\n+      // also used inside a prerender scope (the page). Additionally, there\n+      // should also be no cache entry for \"short\", because it has a short\n+      // lifetime and is subsequently omitted from the prerendered shell. The\n+      // following expectation is matching on the full list. If any additional\n+      // keys are found, the test will fail and print the unexpected keys.\n       expect(cacheKeys).toMatchObject([\n+        // Note: We're matching on the args that are encoded into the respective\n+        // cache keys.\n         expect.stringContaining('[\"outer\"]'),\n         expect.stringContaining('[\"inner\"]'),\n+        ...(withCacheComponents\n+          ? []\n+          : // With legacy PPR, the \"short\" cache is included in the prerendered\n+            // shell.\n+            [expect.stringContaining('[{\"id\":\"short\"},\"$undefined\"]]')]),\n       ])\n     })\n   }"
        }
    ],
    "stats": {
        "total": 554,
        "additions": 462,
        "deletions": 92
    }
}