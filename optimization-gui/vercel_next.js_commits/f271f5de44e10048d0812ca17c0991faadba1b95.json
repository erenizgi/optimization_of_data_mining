{
    "author": "sokra",
    "message": "Turbopack: follow up changes from parallel children (#84219)\n\n### What?\n\nCode cleanup\nadd helper method for parallel chunks\nhandle cancelled tasks\nrename variable\nadd comment to explain number\nadd parallel implementation overhead benchmark",
    "sha": "f271f5de44e10048d0812ca17c0991faadba1b95",
    "files": [
        {
            "sha": "0f1eb7f7674270689f831cae92dc7a7980659b6e",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -9134,6 +9134,7 @@ dependencies = [\n  \"anyhow\",\n  \"async-trait\",\n  \"auto-hash-map\",\n+ \"codspeed-criterion-compat\",\n  \"concurrent-queue\",\n  \"dashmap 6.1.0\",\n  \"either\","
        },
        {
            "sha": "bd3e99a14c4b3acb6823f386957f09ff1b745f4f",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 15,
            "deletions": 0,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -1792,6 +1792,13 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let Some(in_progress) = get_mut!(task, InProgress) else {\n             panic!(\"Task execution completed, but task is not in progress: {task:#?}\");\n         };\n+        if matches!(in_progress, InProgressState::Canceled) {\n+            return Some(TaskExecutionCompletePrepareResult {\n+                new_children: Default::default(),\n+                removed_data: Default::default(),\n+                is_now_immutable: false,\n+            });\n+        }\n         let &mut InProgressState::InProgress(box InProgressStateInner {\n             stale,\n             ref mut done,\n@@ -2013,6 +2020,10 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let Some(in_progress) = get!(task, InProgress) else {\n             panic!(\"Task execution completed, but task is not in progress: {task:#?}\");\n         };\n+        if matches!(in_progress, InProgressState::Canceled) {\n+            // Task was canceled in the meantime, so we don't connect the children\n+            return false;\n+        }\n         let InProgressState::InProgress(box InProgressStateInner {\n             #[cfg(not(feature = \"no_fast_stale\"))]\n             stale,\n@@ -2074,6 +2085,10 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let Some(in_progress) = remove!(task, InProgress) else {\n             panic!(\"Task execution completed, but task is not in progress: {task:#?}\");\n         };\n+        if matches!(in_progress, InProgressState::Canceled) {\n+            // Task was canceled in the meantime, so we don't finish it\n+            return false;\n+        }\n         let InProgressState::InProgress(box InProgressStateInner {\n             done_event,\n             once_task: _,"
        },
        {
            "sha": "b8baadf5d861e8304511cfac6a396e4d8d775461",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/operation/connect_children.rs",
            "status": "modified",
            "additions": 13,
            "deletions": 5,
            "changes": 18,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_children.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_children.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Foperation%2Fconnect_children.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -20,7 +20,7 @@ pub fn connect_children(\n     parent_task_id: TaskId,\n     mut parent_task: impl TaskGuard,\n     new_children: FxHashSet<TaskId>,\n-    has_active_count: bool,\n+    parent_has_active_count: bool,\n     should_track_activeness: bool,\n ) {\n     debug_assert!(!new_children.is_empty());\n@@ -46,7 +46,7 @@ pub fn connect_children(\n         new_follower_ids: SmallVec<[TaskId; 4]>,\n         upper_ids: Option<SmallVec<[TaskId; 4]>>,\n         parent_task_id: TaskId,\n-        has_active_count: bool,\n+        parent_has_active_count: bool,\n         should_track_activeness: bool,\n     ) {\n         debug_assert!(!new_follower_ids.is_empty());\n@@ -62,7 +62,7 @@ pub fn connect_children(\n             // active count was temporarily increased during connect_child. We need to\n             // increase the active count when the parent has active count, because it's\n             // added as follower.\n-            let decrease_active_count = should_track_activeness && !has_active_count;\n+            let decrease_active_count = should_track_activeness && !parent_has_active_count;\n \n             // We special case the situation when we need to do both operations to avoid\n             // cloning the new follower ids unnecessarily.\n@@ -116,6 +116,14 @@ pub fn connect_children(\n         }\n     }\n \n+    // Connecting a child varies a lot, but it's in the range of 10-30µs.\n+    // Usually many tasks run in parallel and so it this operation.\n+    // But sometimes there is only one task running and everybody waits on it.\n+    // In this case we want to avoid a long single threaded operation.\n+    // Where there are more than 10k children we parallelize the operation.\n+    // This avoids long pauses of more than 30µs * 10k = 300ms.\n+    // We don't want to parallelize too eagerly as spawning tasks and the temporary allocations have\n+    // a cost as well.\n     const MIN_CHILDREN_FOR_PARALLEL: usize = 10000;\n \n     let len = new_follower_ids.len();\n@@ -134,7 +142,7 @@ pub fn connect_children(\n                         new_follower_ids,\n                         upper_ids.clone(),\n                         parent_task_id,\n-                        has_active_count,\n+                        parent_has_active_count,\n                         should_track_activeness,\n                     );\n                 });\n@@ -146,7 +154,7 @@ pub fn connect_children(\n             new_follower_ids,\n             upper_ids,\n             parent_task_id,\n-            has_active_count,\n+            parent_has_active_count,\n             should_track_activeness,\n         );\n     }"
        },
        {
            "sha": "2fed2d83292fb85a65c86c712d6234ee91e82df0",
            "filename": "turbopack/crates/turbo-tasks/Cargo.toml",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2FCargo.toml?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -56,3 +56,9 @@ turbo-tasks-malloc = { workspace = true }\n unsize = { workspace = true }\n inventory = { workspace = true }\n \n+[dev-dependencies]\n+criterion = { workspace = true, features = [\"async_tokio\"] }\n+\n+[[bench]]\n+name = \"mod\"\n+harness = false"
        },
        {
            "sha": "8b511f6c8ffa9efb76567955bdd13ad3f2923cb6",
            "filename": "turbopack/crates/turbo-tasks/benches/mod.rs",
            "status": "added",
            "additions": 13,
            "deletions": 0,
            "changes": 13,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fmod.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -0,0 +1,13 @@\n+#![feature(arbitrary_self_types)]\n+#![feature(arbitrary_self_types_pointers)]\n+\n+use criterion::{Criterion, criterion_group, criterion_main};\n+\n+pub(crate) mod scope;\n+\n+criterion_group!(\n+    name = turbo_tasks;\n+    config = Criterion::default();\n+    targets = scope::overhead\n+);\n+criterion_main!(turbo_tasks);"
        },
        {
            "sha": "f31ab4fe8e18f268cb5d4ddf9be1f2565453d557",
            "filename": "turbopack/crates/turbo-tasks/benches/scope.rs",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fscope.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fscope.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fbenches%2Fscope.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -0,0 +1,76 @@\n+use std::time::{Duration, Instant};\n+\n+use criterion::{BenchmarkId, Criterion, black_box};\n+use turbo_tasks::parallel;\n+\n+#[global_allocator]\n+static ALLOC: turbo_tasks_malloc::TurboMalloc = turbo_tasks_malloc::TurboMalloc;\n+\n+// Tunable task: busy-wait for a given duration\n+#[inline(never)]\n+fn busy_task<T>(duration: Duration, result: T) -> T {\n+    let start = Instant::now();\n+    while start.elapsed() < duration {\n+        std::hint::spin_loop();\n+    }\n+    black_box(result) // prevent optimizing away the function\n+}\n+\n+fn get_test_cases() -> Vec<(Duration, u32)> {\n+    let mut cases = Vec::new();\n+    for item_dur in [30_000] {\n+        let item_duration = Duration::from_nanos(item_dur);\n+        for item_count in [10, 30, 100, 300, 1000, 3000, 10_000, 30_000, 100_000] {\n+            let total_duration = item_duration * item_count * 20;\n+            if total_duration > Duration::from_secs(20) {\n+                // Skip very long runs\n+                continue;\n+            }\n+            cases.push((item_duration, item_count));\n+        }\n+    }\n+    cases\n+}\n+\n+pub fn overhead(c: &mut Criterion) {\n+    let mut group = c.benchmark_group(\"scope_overhead\");\n+    group.sample_size(20);\n+\n+    let rt = tokio::runtime::Builder::new_multi_thread()\n+        .disable_lifo_slot()\n+        .thread_name(\"tokio-thread\")\n+        .enable_all()\n+        .build()\n+        .unwrap();\n+\n+    for (item_duration, item_count) in get_test_cases() {\n+        group.bench_with_input(\n+            BenchmarkId::new(format!(\"parallel {item_duration:?}\"), item_count),\n+            &item_count,\n+            |b, &d| {\n+                let items = (0..d).collect::<Vec<_>>();\n+                b.to_async(&rt).iter(|| async {\n+                    let result: Vec<_> =\n+                        parallel::map_collect(&items, |&i| black_box(busy_task(item_duration, i)));\n+                    result\n+                });\n+            },\n+        );\n+    }\n+\n+    for (item_duration, item_count) in get_test_cases() {\n+        group.bench_with_input(\n+            BenchmarkId::new(format!(\"single_threaded {item_duration:?}\"), item_count),\n+            &item_count,\n+            |b, &d| {\n+                let items = (0..d).collect::<Vec<_>>();\n+                b.iter(|| {\n+                    items\n+                        .iter()\n+                        .map(|&i| black_box(busy_task(item_duration, i)))\n+                        .collect::<Vec<_>>()\n+                });\n+            },\n+        );\n+    }\n+}"
        },
        {
            "sha": "e304da76e039d0a52a2c5e66dd1b867c2ac0b278",
            "filename": "turbopack/crates/turbo-tasks/src/parallel.rs",
            "status": "modified",
            "additions": 71,
            "deletions": 39,
            "changes": 110,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fparallel.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -9,21 +9,43 @@ use crate::{\n     util::{good_chunk_size, into_chunks},\n };\n \n+struct Chunked {\n+    chunk_size: usize,\n+    chunk_count: usize,\n+}\n+\n+fn get_chunked(len: usize) -> Option<Chunked> {\n+    if len <= 1 {\n+        return None;\n+    }\n+    let chunk_size = good_chunk_size(len);\n+    let chunk_count = len.div_ceil(chunk_size);\n+    if chunk_count <= 1 {\n+        return None;\n+    }\n+    Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    })\n+}\n+\n pub fn for_each<'l, T, F>(items: &'l [T], f: F)\n where\n     T: Sync,\n     F: Fn(&'l T) + Send + Sync,\n {\n-    let len = items.len();\n-    if len <= 1 {\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n         for item in items {\n             f(item);\n         }\n         return;\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    };\n     let f = &f;\n-    let _results = scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    let _results = scope_and_block(chunk_count, |scope| {\n         for chunk in items.chunks(chunk_size) {\n             scope.spawn(move || {\n                 for item in chunk {\n@@ -38,16 +60,18 @@ pub fn for_each_owned<T>(items: Vec<T>, f: impl Fn(T) + Send + Sync)\n where\n     T: Send + Sync,\n {\n-    let len = items.len();\n-    if len <= 1 {\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n         for item in items {\n             f(item);\n         }\n         return;\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    };\n     let f = &f;\n-    let _results = scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    let _results = scope_and_block(chunk_count, |scope| {\n         for chunk in into_chunks(items, chunk_size) {\n             scope.spawn(move || {\n                 // SAFETY: Even when f() panics we drop all items in the chunk.\n@@ -67,16 +91,18 @@ where\n     T: Sync,\n     E: Send + 'static,\n {\n-    let len = items.len();\n-    if len <= 1 {\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n         for item in items {\n             f(item)?;\n         }\n         return Ok(());\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    };\n     let f = &f;\n-    scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    scope_and_block(chunk_count, |scope| {\n         for chunk in items.chunks(chunk_size) {\n             scope.spawn(move || {\n                 for item in chunk {\n@@ -97,16 +123,18 @@ where\n     T: Send + Sync,\n     E: Send + 'static,\n {\n-    let len = items.len();\n-    if len <= 1 {\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n         for item in items {\n             f(item)?;\n         }\n         return Ok(());\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    };\n     let f = &f;\n-    scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    scope_and_block(chunk_count, |scope| {\n         for chunk in items.chunks_mut(chunk_size) {\n             scope.spawn(move || {\n                 for item in chunk {\n@@ -127,16 +155,18 @@ where\n     T: Send + Sync,\n     E: Send + 'static,\n {\n-    let len = items.len();\n-    if len <= 1 {\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n         for item in items {\n             f(item)?;\n         }\n         return Ok(());\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    };\n     let f = &f;\n-    scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    scope_and_block(chunk_count, |scope| {\n         for chunk in into_chunks(items, chunk_size) {\n             scope.spawn(move || {\n                 for item in chunk {\n@@ -158,14 +188,15 @@ where\n     PerItemResult: Send + Sync + 'l,\n     Result: FromIterator<PerItemResult>,\n {\n-    let len = items.len();\n-    if len == 0 {\n-        return Result::from_iter(std::iter::empty()); // No items to process, return empty\n-        // collection\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n+        return Result::from_iter(items.iter().map(f));\n+    };\n     let f = &f;\n-    scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    scope_and_block(chunk_count, |scope| {\n         for chunk in items.chunks(chunk_size) {\n             scope.spawn(move || chunk.iter().map(f).collect::<Vec<_>>())\n         }\n@@ -183,14 +214,15 @@ where\n     PerItemResult: Send + Sync + 'l,\n     Result: FromIterator<PerItemResult>,\n {\n-    let len = items.len();\n-    if len == 0 {\n-        return Result::from_iter(std::iter::empty()); // No items to process, return empty\n-        // collection;\n-    }\n-    let chunk_size = good_chunk_size(len);\n+    let Some(Chunked {\n+        chunk_size,\n+        chunk_count,\n+    }) = get_chunked(items.len())\n+    else {\n+        return Result::from_iter(items.into_iter().map(f));\n+    };\n     let f = &f;\n-    scope_and_block(len.div_ceil(chunk_size), |scope| {\n+    scope_and_block(chunk_count, |scope| {\n         for chunk in into_chunks(items, chunk_size) {\n             scope.spawn(move || chunk.map(f).collect::<Vec<_>>())\n         }"
        },
        {
            "sha": "68b114524ba5f33ebda70dc8434cf8bac2662662",
            "filename": "turbopack/crates/turbo-tasks/src/scope.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/vercel/next.js/blob/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fscope.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f271f5de44e10048d0812ca17c0991faadba1b95/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fscope.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fscope.rs?ref=f271f5de44e10048d0812ca17c0991faadba1b95",
            "patch": "@@ -296,9 +296,11 @@ mod tests {\n                 scope.spawn(move || i);\n             }\n         });\n-        results.enumerate().for_each(|(i, result)| {\n+        let results = results.collect::<Vec<_>>();\n+        results.iter().enumerate().for_each(|(i, &result)| {\n             assert_eq!(result, i);\n         });\n+        assert_eq!(results.len(), 1000);\n     }\n \n     #[tokio::test(flavor = \"multi_thread\", worker_threads = 2)]"
        }
    ],
    "stats": {
        "total": 243,
        "additions": 198,
        "deletions": 45
    }
}