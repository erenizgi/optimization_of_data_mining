{
    "author": "lukesandberg",
    "message": "[turbopack] Drop duration and allocation tracking from CaptureFuture (#85534)\n\nThis data was mostly unused\n\n* allocation tracking was completely dead.  So this saves a bit of memory and some data copies\n* duration tracking was only used for task statistics.  This was a relatively new feature and not particularly useful.  I considered wrapping it in a `feature` but dropping is simpler and this data is very redundant with tracing output anyway.",
    "sha": "67aa5f3d281705e64940b43b43408f580ad6f3b0",
    "files": [
        {
            "sha": "225b250b600fa63f392453ec9683fcc4237477b9",
            "filename": "turbopack/crates/turbo-tasks-backend/benches/overhead.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 36,
            "changes": 37,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fbenches%2Foverhead.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -3,7 +3,7 @@ use std::time::{Duration, Instant};\n use criterion::{BenchmarkId, Criterion, black_box};\n use futures::{FutureExt, StreamExt, stream::FuturesUnordered};\n use tokio::spawn;\n-use turbo_tasks::{TurboTasks, TurboTasksApi};\n+use turbo_tasks::TurboTasks;\n use turbo_tasks_backend::{BackendOptions, TurboTasksBackend, noop_backing_storage};\n \n #[global_allocator]\n@@ -79,15 +79,6 @@ pub fn overhead(c: &mut Criterion) {\n                 run_turbo::<Uncached>(&rt, b, d, false);\n             },\n         );\n-        // Same as turbo-uncached but reports the time as measured by turbotasks itself\n-        // This allows us to understand the cost of the indirection within turbotasks\n-        group.bench_with_input(\n-            BenchmarkId::new(\"turbo-uncached-stats\", micros),\n-            &duration,\n-            |b, &d| {\n-                run_turbo_stats(&rt, b, d);\n-            },\n-        );\n \n         group.bench_with_input(\n             BenchmarkId::new(\"turbo-cached-same-keys\", micros),\n@@ -224,29 +215,3 @@ fn run_turbo<Mode: TurboMode>(\n         }\n     });\n }\n-\n-fn run_turbo_stats(rt: &tokio::runtime::Runtime, b: &mut criterion::Bencher<'_>, d: Duration) {\n-    b.to_async(rt).iter_custom(|iters| {\n-        // It is important to create the tt instance here to ensure the cache is not shared across\n-        // iterations.\n-        let tt = TurboTasks::new(TurboTasksBackend::new(\n-            BackendOptions {\n-                storage_mode: None,\n-                ..Default::default()\n-            },\n-            noop_backing_storage(),\n-        ));\n-        let stats = tt.task_statistics().enable().clone();\n-\n-        async move {\n-            tt.run_once(async move {\n-                for i in 0..iters {\n-                    black_box(busy_turbo(i, black_box(d)).await?);\n-                }\n-                Ok(stats.get(&BUSY_TURBO_FUNCTION).duration)\n-            })\n-            .await\n-            .unwrap()\n-        }\n-    });\n-}"
        },
        {
            "sha": "144bd4c6099b95d328428cf5bd57e6822940ce1f",
            "filename": "turbopack/crates/turbo-tasks-backend/src/backend/mod.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-backend%2Fsrc%2Fbackend%2Fmod.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -391,14 +391,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         self.task_statistics\n             .map(|stats| stats.increment_cache_miss(task_type.native_fn));\n     }\n-\n-    fn track_task_duration(&self, task_id: TaskId, duration: std::time::Duration) {\n-        self.task_statistics.map(|stats| {\n-            if let Some(task_type) = self.task_cache.lookup_reverse(&task_id) {\n-                stats.increment_execution_duration(task_type.native_fn, duration);\n-            }\n-        });\n-    }\n }\n \n pub(crate) struct OperationGuard<'a, B: BackingStorage> {\n@@ -1751,8 +1743,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n     fn task_execution_completed(\n         &self,\n         task_id: TaskId,\n-        duration: Duration,\n-        _memory_usage: usize,\n         result: Result<RawVc, TurboTasksExecutionError>,\n         cell_counters: &AutoMap<ValueTypeId, u32, BuildHasherDefault<FxHasher>, 8>,\n         stateful: bool,\n@@ -1776,8 +1766,6 @@ impl<B: BackingStorage> TurboTasksBackendInner<B> {\n         let span = tracing::trace_span!(\"task execution completed\", immutable = Empty).entered();\n         let mut ctx = self.execute_context(turbo_tasks);\n \n-        self.track_task_duration(task_id, duration);\n-\n         let Some(TaskExecutionCompletePrepareResult {\n             new_children,\n             mut removed_data,\n@@ -3194,8 +3182,6 @@ impl<B: BackingStorage> Backend for TurboTasksBackend<B> {\n     fn task_execution_completed(\n         &self,\n         task_id: TaskId,\n-        _duration: Duration,\n-        _memory_usage: usize,\n         result: Result<RawVc, TurboTasksExecutionError>,\n         cell_counters: &AutoMap<ValueTypeId, u32, BuildHasherDefault<FxHasher>, 8>,\n         stateful: bool,\n@@ -3204,8 +3190,6 @@ impl<B: BackingStorage> Backend for TurboTasksBackend<B> {\n     ) -> bool {\n         self.0.task_execution_completed(\n             task_id,\n-            _duration,\n-            _memory_usage,\n             result,\n             cell_counters,\n             stateful,"
        },
        {
            "sha": "e527288cb351003c45dcf41e0b8a1a8f3dfe7053",
            "filename": "turbopack/crates/turbo-tasks/src/backend.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fbackend.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -6,7 +6,6 @@ use std::{\n     hash::{BuildHasherDefault, Hash},\n     pin::Pin,\n     sync::Arc,\n-    time::Duration,\n };\n \n use anyhow::{Result, anyhow};\n@@ -541,8 +540,6 @@ pub trait Backend: Sync + Send {\n     fn task_execution_completed(\n         &self,\n         task: TaskId,\n-        duration: Duration,\n-        memory_usage: usize,\n         result: Result<RawVc, TurboTasksExecutionError>,\n         cell_counters: &AutoMap<ValueTypeId, u32, BuildHasherDefault<FxHasher>, 8>,\n         stateful: bool,"
        },
        {
            "sha": "ba86a33b10917b0e5aac3dda51775cf446b75901",
            "filename": "turbopack/crates/turbo-tasks/src/capture_future.rs",
            "status": "modified",
            "additions": 4,
            "deletions": 73,
            "changes": 77,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fcapture_future.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -1,74 +1,31 @@\n use std::{\n     borrow::Cow,\n-    cell::RefCell,\n     fmt::Display,\n     future::Future,\n     panic,\n     pin::Pin,\n     task::{Context, Poll},\n-    time::{Duration, Instant},\n };\n \n use anyhow::Result;\n use pin_project_lite::pin_project;\n use serde::{Deserialize, Serialize};\n-use turbo_tasks_malloc::{AllocationInfo, TurboMalloc};\n \n use crate::{backend::TurboTasksExecutionErrorMessage, panic_hooks::LAST_ERROR_LOCATION};\n \n-struct ThreadLocalData {\n-    duration: Duration,\n-    allocations: usize,\n-    deallocations: usize,\n-}\n-\n-thread_local! {\n-    static EXTRA: RefCell<Option<*mut ThreadLocalData>> = const { RefCell::new(None) };\n-}\n-\n pin_project! {\n     pub struct CaptureFuture<T, F: Future<Output = T>> {\n         #[pin]\n         future: F,\n-        duration: Duration,\n-        allocations: AllocationInfo,\n     }\n }\n \n impl<T, F: Future<Output = T>> CaptureFuture<T, F> {\n     pub fn new(future: F) -> Self {\n-        Self {\n-            future,\n-            duration: Duration::ZERO,\n-            allocations: AllocationInfo::ZERO,\n-        }\n+        Self { future }\n     }\n }\n \n-fn try_with_thread_local_data(f: impl FnOnce(&mut ThreadLocalData)) {\n-    EXTRA.with_borrow(|cell| {\n-        if let Some(data) = cell {\n-            // Safety: This data is thread local and only accessed in this thread\n-            unsafe {\n-                f(&mut **data);\n-            }\n-        }\n-    });\n-}\n-\n-pub fn add_duration(duration: Duration) {\n-    try_with_thread_local_data(|data| {\n-        data.duration += duration;\n-    });\n-}\n-\n-pub fn add_allocation_info(alloc_info: AllocationInfo) {\n-    try_with_thread_local_data(|data| {\n-        data.allocations += alloc_info.allocations;\n-        data.deallocations += alloc_info.deallocations;\n-    });\n-}\n-\n #[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]\n pub struct TurboTasksPanic {\n     pub message: TurboTasksExecutionErrorMessage,\n@@ -93,21 +50,10 @@ impl Display for TurboTasksPanic {\n }\n \n impl<T, F: Future<Output = T>> Future for CaptureFuture<T, F> {\n-    type Output = (Result<T, TurboTasksPanic>, Duration, AllocationInfo);\n+    type Output = Result<T, TurboTasksPanic>;\n \n     fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n         let this = self.project();\n-        let start = Instant::now();\n-        let start_allocations = TurboMalloc::allocation_counters();\n-        let guard = ThreadLocalDataDropGuard;\n-        let mut data = ThreadLocalData {\n-            duration: Duration::ZERO,\n-            allocations: 0,\n-            deallocations: 0,\n-        };\n-        EXTRA.with_borrow_mut(|cell| {\n-            *cell = Some(&mut data as *mut ThreadLocalData);\n-        });\n \n         let result =\n             panic::catch_unwind(panic::AssertUnwindSafe(|| this.future.poll(cx))).map_err(|err| {\n@@ -132,25 +78,10 @@ impl<T, F: Future<Output = T>> Future for CaptureFuture<T, F> {\n                 })\n             });\n \n-        drop(guard);\n-        let elapsed = start.elapsed();\n-        let allocations = start_allocations.until_now();\n-        *this.duration += elapsed + data.duration;\n-        *this.allocations += allocations;\n         match result {\n-            Err(err) => Poll::Ready((Err(err), *this.duration, this.allocations.clone())),\n-            Ok(Poll::Ready(r)) => Poll::Ready((Ok(r), *this.duration, this.allocations.clone())),\n+            Err(err) => Poll::Ready(Err(err)),\n+            Ok(Poll::Ready(r)) => Poll::Ready(Ok(r)),\n             Ok(Poll::Pending) => Poll::Pending,\n         }\n     }\n }\n-\n-struct ThreadLocalDataDropGuard;\n-\n-impl Drop for ThreadLocalDataDropGuard {\n-    fn drop(&mut self) {\n-        EXTRA.with_borrow_mut(|cell| {\n-            *cell = None;\n-        });\n-    }\n-}"
        },
        {
            "sha": "5e488c405ad107b060c43b175a0ebb9b0fff7f34",
            "filename": "turbopack/crates/turbo-tasks/src/manager.rs",
            "status": "modified",
            "additions": 3,
            "deletions": 5,
            "changes": 8,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fmanager.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -578,7 +578,7 @@ impl<B: Backend + 'static> TurboTasks<B> {\n             .scope(\n                 self.pin(),\n                 CURRENT_TASK_STATE.scope(current_task_state, async {\n-                    let (result, _duration, _alloc_info) = CaptureFuture::new(future).await;\n+                    let result = CaptureFuture::new(future).await;\n \n                     // wait for all spawned local tasks using `local` to finish\n                     let ltt =\n@@ -736,7 +736,7 @@ impl<B: Backend + 'static> TurboTasks<B> {\n                     };\n \n                     async {\n-                        let (result, duration, alloc_info) = CaptureFuture::new(future).await;\n+                        let result = CaptureFuture::new(future).await;\n \n                         // wait for all spawned local tasks using `local` to finish\n                         let ltt = CURRENT_TASK_STATE\n@@ -758,8 +758,6 @@ impl<B: Backend + 'static> TurboTasks<B> {\n                             .with(|ts| ts.write().unwrap().cell_counters.take().unwrap());\n                         this.backend.task_execution_completed(\n                             task_id,\n-                            duration,\n-                            alloc_info.memory_usage(),\n                             result,\n                             &cell_counters,\n                             stateful,\n@@ -835,7 +833,7 @@ impl<B: Backend + 'static> TurboTasks<B> {\n             let TaskExecutionSpec { future, span } =\n                 crate::task::local_task::get_local_task_execution_spec(&*this, &ty, persistence);\n             async move {\n-                let (result, _duration, _memory_usage) = CaptureFuture::new(future).await;\n+                let result = CaptureFuture::new(future).await;\n \n                 let result = match result {\n                     Ok(Ok(raw_vc)) => Ok(raw_vc),"
        },
        {
            "sha": "56aa1d1870cc3b0b5afaa58eef7dd5dbeafdd24a",
            "filename": "turbopack/crates/turbo-tasks/src/spawn.rs",
            "status": "modified",
            "additions": 8,
            "deletions": 19,
            "changes": 27,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Fspawn.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -3,24 +3,20 @@ use std::{\n     pin::Pin,\n     task::{Context, Poll},\n     thread,\n-    time::{Duration, Instant},\n };\n \n use anyhow::Result;\n use futures::{FutureExt, ready};\n use tokio::runtime::Handle;\n use tracing::{Instrument, Span, info_span};\n-use turbo_tasks_malloc::{AllocationInfo, TurboMalloc};\n \n use crate::{\n-    TurboTasksPanic,\n-    capture_future::{self, CaptureFuture},\n-    manager::turbo_tasks_future_scope,\n-    turbo_tasks, turbo_tasks_scope,\n+    TurboTasksPanic, capture_future::CaptureFuture, manager::turbo_tasks_future_scope, turbo_tasks,\n+    turbo_tasks_scope,\n };\n \n pub struct JoinHandle<T> {\n-    join_handle: tokio::task::JoinHandle<(Result<T, TurboTasksPanic>, Duration, AllocationInfo)>,\n+    join_handle: tokio::task::JoinHandle<Result<T, TurboTasksPanic>>,\n }\n \n impl<T: Send + 'static> JoinHandle<T> {\n@@ -35,14 +31,10 @@ impl<T> Future for JoinHandle<T> {\n     fn poll(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n         let this = self.get_mut();\n         match ready!(this.join_handle.poll_unpin(cx)) {\n-            Ok((res, duration, alloc_info)) => {\n-                capture_future::add_duration(duration);\n-                capture_future::add_allocation_info(alloc_info);\n-                match res {\n-                    Ok(res) => Poll::Ready(res),\n-                    Err(e) => resume_unwind(e.into_panic()),\n-                }\n-            }\n+            Ok(res) => match res {\n+                Ok(res) => Poll::Ready(res),\n+                Err(e) => resume_unwind(e.into_panic()),\n+            },\n             Err(e) => resume_unwind(e.into_panic()),\n         }\n     }\n@@ -71,10 +63,7 @@ pub fn spawn_blocking<T: Send + 'static>(\n     let span = Span::current();\n     let join_handle = tokio::task::spawn_blocking(|| {\n         let _guard = span.entered();\n-        let start = Instant::now();\n-        let start_allocations = TurboMalloc::allocation_counters();\n-        let r = turbo_tasks_scope(turbo_tasks, func);\n-        (Ok(r), start.elapsed(), start_allocations.until_now())\n+        Ok(turbo_tasks_scope(turbo_tasks, func))\n     });\n     JoinHandle { join_handle }\n }"
        },
        {
            "sha": "cc8656024ad168d0e0c7a2413870081ef95151e8",
            "filename": "turbopack/crates/turbo-tasks/src/task_statistics.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 15,
            "changes": 15,
            "blob_url": "https://github.com/vercel/next.js/blob/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask_statistics.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/67aa5f3d281705e64940b43b43408f580ad6f3b0/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask_statistics.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks%2Fsrc%2Ftask_statistics.rs?ref=67aa5f3d281705e64940b43b43408f580ad6f3b0",
            "patch": "@@ -46,17 +46,6 @@ impl TaskStatistics {\n         self.with_task_type_statistics(native_fn, |stats| stats.cache_miss += 1)\n     }\n \n-    pub fn increment_execution_duration(\n-        &self,\n-        native_fn: &'static NativeFunction,\n-        duration: std::time::Duration,\n-    ) {\n-        self.with_task_type_statistics(native_fn, |stats| {\n-            stats.executions += 1;\n-            stats.duration += duration\n-        })\n-    }\n-\n     fn with_task_type_statistics(\n         &self,\n         native_fn: &'static NativeFunction,\n@@ -75,10 +64,6 @@ impl TaskStatistics {\n pub struct TaskFunctionStatistics {\n     pub cache_hit: u32,\n     pub cache_miss: u32,\n-    // Generally executions == cache_miss, however they can diverge when there are invalidations.\n-    // The caller gets one cache miss but we might execute multiple times.\n-    pub executions: u32,\n-    pub duration: std::time::Duration,\n }\n \n impl Serialize for TaskStatistics {"
        }
    ],
    "stats": {
        "total": 183,
        "additions": 16,
        "deletions": 167
    }
}