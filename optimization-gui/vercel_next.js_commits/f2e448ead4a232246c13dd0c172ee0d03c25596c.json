{
    "author": "bgw",
    "message": "chore(turbo-tasks): Remove old and unused `turbo-tasks-memory` backend (#79560)\n\nI'm deleting all of @sokra's hard work in favor of @sokra's hard work.\n\nRIP memory backend, you served us well ðŸ«¡\n\nThe new `turbo-tasks-backend` supports both persistent (via LDMB or `turbo-persistence`) and in-memory databases (via the no-op storage implementation), and tends to be faster than `turbo-tasks-memory` when used with the no-op storage. Maintaining both has increasingly become a headache.",
    "sha": "f2e448ead4a232246c13dd0c172ee0d03c25596c",
    "files": [
        {
            "sha": "f0ef70e7ac5c78e4e96bcc86281d22497fb88d5d",
            "filename": "Cargo.lock",
            "status": "modified",
            "additions": 4,
            "deletions": 113,
            "changes": 117,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/Cargo.lock",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/Cargo.lock",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.lock?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -2583,19 +2583,6 @@ dependencies = [\n  \"slab\",\n ]\n \n-[[package]]\n-name = \"generator\"\n-version = \"0.8.2\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"979f00864edc7516466d6b3157706e06c032f22715700ddd878228a91d02bc56\"\n-dependencies = [\n- \"cfg-if\",\n- \"libc\",\n- \"log\",\n- \"rustversion\",\n- \"windows 0.58.0\",\n-]\n-\n [[package]]\n name = \"generic-array\"\n version = \"0.14.7\"\n@@ -3153,7 +3140,7 @@ dependencies = [\n  \"iana-time-zone-haiku\",\n  \"js-sys\",\n  \"wasm-bindgen\",\n- \"windows 0.48.0\",\n+ \"windows\",\n ]\n \n [[package]]\n@@ -4070,19 +4057,6 @@ dependencies = [\n  \"value-bag\",\n ]\n \n-[[package]]\n-name = \"loom\"\n-version = \"0.7.2\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"419e0dc8046cb947daa77eb95ae174acfbddb7673b4151f56d1eed8e93fbfaca\"\n-dependencies = [\n- \"cfg-if\",\n- \"generator\",\n- \"scoped-tls\",\n- \"tracing\",\n- \"tracing-subscriber\",\n-]\n-\n [[package]]\n name = \"loop9\"\n version = \"0.1.5\"\n@@ -4559,7 +4533,6 @@ dependencies = [\n  \"turbo-tasks-env\",\n  \"turbo-tasks-fs\",\n  \"turbo-tasks-hash\",\n- \"turbo-tasks-memory\",\n  \"turbopack\",\n  \"turbopack-browser\",\n  \"turbopack-cli-utils\",\n@@ -4752,7 +4725,6 @@ dependencies = [\n  \"turbo-tasks-build\",\n  \"turbo-tasks-fs\",\n  \"turbo-tasks-malloc\",\n- \"turbo-tasks-memory\",\n  \"turbopack\",\n  \"turbopack-core\",\n  \"turbopack-ecmascript-hmr-protocol\",\n@@ -9708,9 +9680,9 @@ dependencies = [\n  \"tokio\",\n  \"turbo-rcstr\",\n  \"turbo-tasks\",\n+ \"turbo-tasks-backend\",\n  \"turbo-tasks-build\",\n  \"turbo-tasks-fs\",\n- \"turbo-tasks-memory\",\n  \"turbo-tasks-testing\",\n  \"turbopack-core\",\n ]\n@@ -9753,7 +9725,6 @@ dependencies = [\n  \"turbo-tasks-backend\",\n  \"turbo-tasks-build\",\n  \"turbo-tasks-hash\",\n- \"turbo-tasks-memory\",\n  \"turbo-tasks-testing\",\n  \"unicode-segmentation\",\n  \"unsize\",\n@@ -9816,8 +9787,8 @@ dependencies = [\n  \"tokio\",\n  \"trybuild\",\n  \"turbo-tasks\",\n+ \"turbo-tasks-backend\",\n  \"turbo-tasks-build\",\n- \"turbo-tasks-memory\",\n  \"turbo-tasks-testing\",\n ]\n \n@@ -9828,40 +9799,6 @@ dependencies = [\n  \"mimalloc\",\n ]\n \n-[[package]]\n-name = \"turbo-tasks-memory\"\n-version = \"0.1.0\"\n-dependencies = [\n- \"anyhow\",\n- \"auto-hash-map\",\n- \"concurrent-queue\",\n- \"criterion\",\n- \"dashmap 6.1.0\",\n- \"either\",\n- \"indexmap 2.7.1\",\n- \"loom\",\n- \"num_cpus\",\n- \"once_cell\",\n- \"parking_lot\",\n- \"rand 0.9.0\",\n- \"ref-cast\",\n- \"regex\",\n- \"rstest\",\n- \"rustc-hash 2.1.1\",\n- \"serde\",\n- \"serde_json\",\n- \"smallvec\",\n- \"tokio\",\n- \"tracing\",\n- \"turbo-prehash\",\n- \"turbo-rcstr\",\n- \"turbo-tasks\",\n- \"turbo-tasks-build\",\n- \"turbo-tasks-hash\",\n- \"turbo-tasks-malloc\",\n- \"turbo-tasks-testing\",\n-]\n-\n [[package]]\n name = \"turbo-tasks-testing\"\n version = \"0.1.0\"\n@@ -9903,7 +9840,6 @@ dependencies = [\n  \"turbo-tasks-fs\",\n  \"turbo-tasks-hash\",\n  \"turbo-tasks-malloc\",\n- \"turbo-tasks-memory\",\n  \"turbopack-core\",\n  \"turbopack-css\",\n  \"turbopack-ecmascript\",\n@@ -10176,10 +10112,10 @@ dependencies = [\n  \"turbo-esregex\",\n  \"turbo-rcstr\",\n  \"turbo-tasks\",\n+ \"turbo-tasks-backend\",\n  \"turbo-tasks-build\",\n  \"turbo-tasks-fs\",\n  \"turbo-tasks-hash\",\n- \"turbo-tasks-memory\",\n  \"turbo-tasks-testing\",\n  \"turbopack-core\",\n  \"turbopack-resolve\",\n@@ -11791,51 +11727,6 @@ dependencies = [\n  \"windows-targets 0.48.1\",\n ]\n \n-[[package]]\n-name = \"windows\"\n-version = \"0.58.0\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"dd04d41d93c4992d421894c18c8b43496aa748dd4c081bac0dc93eb0489272b6\"\n-dependencies = [\n- \"windows-core\",\n- \"windows-targets 0.52.6\",\n-]\n-\n-[[package]]\n-name = \"windows-core\"\n-version = \"0.58.0\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"6ba6d44ec8c2591c134257ce647b7ea6b20335bf6379a27dac5f1641fcf59f99\"\n-dependencies = [\n- \"windows-implement\",\n- \"windows-interface\",\n- \"windows-result\",\n- \"windows-strings\",\n- \"windows-targets 0.52.6\",\n-]\n-\n-[[package]]\n-name = \"windows-implement\"\n-version = \"0.58.0\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"2bbd5b46c938e506ecbce286b6628a02171d56153ba733b6c741fc627ec9579b\"\n-dependencies = [\n- \"proc-macro2\",\n- \"quote\",\n- \"syn 2.0.100\",\n-]\n-\n-[[package]]\n-name = \"windows-interface\"\n-version = \"0.58.0\"\n-source = \"registry+https://github.com/rust-lang/crates.io-index\"\n-checksum = \"053c4c462dc91d3b1504c6fe5a726dd15e216ba718e84a0e46a88fbe5ded3515\"\n-dependencies = [\n- \"proc-macro2\",\n- \"quote\",\n- \"syn 2.0.100\",\n-]\n-\n [[package]]\n name = \"windows-link\"\n version = \"0.1.1\""
        },
        {
            "sha": "32f971e534c0627aa65a803d97663a927ff5b2cc",
            "filename": "Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/Cargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/Cargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/Cargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -266,7 +266,6 @@ turbo-tasks-hash = { path = \"turbopack/crates/turbo-tasks-hash\" }\n turbo-tasks-macros = { path = \"turbopack/crates/turbo-tasks-macros\" }\n turbo-tasks-macros-shared = { path = \"turbopack/crates/turbo-tasks-macros-shared\" }\n turbo-tasks-macros-tests = { path = \"turbopack/crates/turbo-tasks-macros-tests\" }\n-turbo-tasks-memory = { path = \"turbopack/crates/turbo-tasks-memory\" }\n turbo-tasks-testing = { path = \"turbopack/crates/turbo-tasks-testing\" }\n turbopack = { path = \"turbopack/crates/turbopack\" }\n turbopack-bench = { path = \"turbopack/crates/turbopack-bench\" }"
        },
        {
            "sha": "5f45322c3e48a6ccef2789671df9528a185de1d2",
            "filename": "crates/napi/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/crates%2Fnapi%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/crates%2Fnapi%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnapi%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -103,7 +103,6 @@ lightningcss-napi = { workspace = true }\n tokio = { workspace = true, features = [\"full\"] }\n turbo-rcstr = { workspace = true }\n turbo-tasks = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n turbo-tasks-backend = { workspace = true }\n turbo-tasks-fs = { workspace = true }\n next-api = { workspace = true }"
        },
        {
            "sha": "7eb8761bfb8eca727a70eff8ffe4878c0a809218",
            "filename": "crates/next-api/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/crates%2Fnext-api%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/crates%2Fnext-api%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-api%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -31,7 +31,6 @@ turbo-tasks = { workspace = true }\n turbo-tasks-env = { workspace = true }\n turbo-tasks-fs = { workspace = true }\n turbo-tasks-hash = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n turbopack = { workspace = true }\n turbopack-browser = { workspace = true }\n turbopack-cli-utils = { workspace = true }"
        },
        {
            "sha": "d1e0cf2fc5daa8195a31cbf60c93cd7a76fe3092",
            "filename": "crates/next-core/src/next_app/app_favicon_entry.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 97,
            "changes": 97,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/crates%2Fnext-core%2Fsrc%2Fnext_app%2Fapp_favicon_entry.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/crates%2Fnext-core%2Fsrc%2Fnext_app%2Fapp_favicon_entry.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/crates%2Fnext-core%2Fsrc%2Fnext_app%2Fapp_favicon_entry.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,97 +0,0 @@\n-use std::io::Write;\n-\n-use anyhow::{bail, Result};\n-use base64::{display::Base64Display, engine::general_purpose::STANDARD};\n-use indoc::writedoc;\n-use turbo_tasks::{ValueToString, Vc};\n-use turbo_tasks_fs::{self, DiskFileSystem, FileContent, FileSystem, FileSystemPath};\n-use turbo_tasks_memory::MemoryBackend;\n-use turbopack_core::{\n-    asset::AssetContent,\n-    diagnostics::PlainDiagnostic,\n-    error::PrettyPrintError,\n-    issue::PlainIssue,\n-    source_map::Token,\n-    version::{PartialUpdate, TotalUpdate, Update, VersionState},\n-    virtual_source::VirtualSource,\n-};\n-\n-use super::app_route_entry::get_app_route_entry;\n-use crate::{\n-    app_structure::MetadataItem,\n-    next_app::{AppEntry, AppPage, PageSegment},\n-};\n-\n-/// Computes the entry for a Next.js favicon file.\n-#[turbo_tasks::function]\n-pub async fn get_app_route_favicon_entry(\n-    nodejs_context: Vc<ModuleAssetContext>,\n-    edge_context: Vc<ModuleAssetContext>,\n-    favicon: MetadataItem,\n-    project_root: Vc<FileSystemPath>,\n-) -> Result<Vc<AppEntry>> {\n-    let path = match favicon {\n-        // TODO(alexkirsz) Is there a difference here?\n-        MetadataItem::Static { path } => path,\n-        MetadataItem::Dynamic { path: _ } => bail!(\"Dynamic metadata is not implemented yet\"),\n-    };\n-\n-    let mut code = RopeBuilder::default();\n-\n-    let content_type = mime_guess::from_ext(&path.extension().await?)\n-        .first_or_octet_stream()\n-        .to_string();\n-    let original_file_content = path.read().await?;\n-    let original_file_content_b64 = match &*original_file_content {\n-        FileContent::Content(content) => {\n-            let content = content.content().to_bytes()?;\n-            Base64Display::new(&content, &STANDARD).to_string()\n-        }\n-        FileContent::NotFound => {\n-            bail!(\"favicon file not found: {}\", &path.to_string().await?);\n-        }\n-    };\n-    // Specific to favicon\n-    let cache_control = \"public, max-age=0, must-revalidate\";\n-\n-    // TODO(alexkirsz) Generalize this to any file.\n-    writedoc! {\n-        code,\n-        r#\"\n-            import {{ NextResponse }} from 'next/server'\n-\n-            const contentType = {content_type}\n-            const cacheControl = {cache_control}\n-            const buffer = Buffer.from({original_file_content_b64}, 'base64')\n-\n-            export function GET() {{\n-                return new NextResponse(buffer, {{\n-                    headers: {{\n-                        'Content-Type': contentType,\n-                        'Cache-Control': cacheControl,\n-                    }},\n-                }})\n-            }}\n-\n-            export const dynamic = 'force-static'\n-            \"#,\n-        content_type = StringifyJs(&content_type),\n-        cache_control = StringifyJs(&cache_control),\n-        original_file_content_b64 = StringifyJs(&original_file_content_b64),\n-    }?;\n-\n-    let file = File::from(code.build());\n-    let source =\n-        // TODO(alexkirsz) Figure out how to name this virtual source.\n-        VirtualSource::new(project_root.join(\"favicon-entry.tsx\".to_string()), AssetContent::file(file.into()));\n-\n-    Ok(get_app_route_entry(\n-        nodejs_context,\n-        edge_context,\n-        Vc::upcast(source),\n-        // TODO(alexkirsz) Get this from the metadata?\n-        AppPage(vec![PageSegment::Static(\"/favicon.ico\".to_string())]),\n-        project_root,\n-        None,\n-    ))\n-}"
        },
        {
            "sha": "31e37af70674d341880aa42198b44456e6dc1e8d",
            "filename": "turbopack/crates/turbo-tasks-fetch/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fetch%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fetch%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fetch%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -37,7 +37,7 @@ turbopack-core = { workspace = true }\n httpmock = { workspace = true }\n tokio = { workspace = true, features = [\"full\"] }\n turbo-tasks-testing = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n+turbo-tasks-backend = { workspace = true }\n \n [build-dependencies]\n turbo-tasks-build = { workspace = true }"
        },
        {
            "sha": "a444a1b87dc2dbe2f1d0f66856ec549173561437",
            "filename": "turbopack/crates/turbo-tasks-fetch/tests/test_config.trs",
            "status": "modified",
            "additions": 21,
            "deletions": 2,
            "changes": 23,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fetch%2Ftests%2Ftest_config.trs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fetch%2Ftests%2Ftest_config.trs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fetch%2Ftests%2Ftest_config.trs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -1,3 +1,22 @@\n-|_name, _initial | {\n-  turbo_tasks::TurboTasks::new(turbo_tasks_memory::MemoryBackend::new(usize::MAX))\n+|name, initial| {\n+  let path = std::path::PathBuf::from(format!(concat!(\n+    env!(\"OUT_DIR\"),\n+    \"/.cache/{}\",\n+  ), name));\n+  if initial {\n+    let _ = std::fs::remove_dir_all(&path);\n+  }\n+  std::fs::create_dir_all(&path).unwrap();\n+  turbo_tasks::TurboTasks::new(\n+    turbo_tasks_backend::TurboTasksBackend::new(\n+      turbo_tasks_backend::BackendOptions::default(),\n+      turbo_tasks_backend::default_backing_storage(\n+        path.as_path(),\n+        &turbo_tasks_backend::GitVersionInfo {\n+          describe: \"test-unversioned\",\n+          dirty: false,\n+        },\n+      ).unwrap()\n+    )\n+  )\n }"
        },
        {
            "sha": "41cb7b3ce7cd785df7e766d240f9ee9dd77259f2",
            "filename": "turbopack/crates/turbo-tasks-fs/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -62,7 +62,6 @@ criterion = { workspace = true, features = [\"async_tokio\"] }\n rstest = { workspace = true }\n sha2 = \"0.10.2\"\n tempfile = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n turbo-tasks-testing = { workspace = true }\n turbo-tasks-backend = { workspace = true }\n "
        },
        {
            "sha": "850fee89286189a2f40573fadd1f11d6e335b471",
            "filename": "turbopack/crates/turbo-tasks-fs/examples/hash_directory.rs",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fexamples%2Fhash_directory.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fexamples%2Fhash_directory.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-fs%2Fexamples%2Fhash_directory.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -12,11 +12,11 @@ use anyhow::Result;\n use sha2::{Digest, Sha256};\n use turbo_rcstr::RcStr;\n use turbo_tasks::{ReadConsistency, TurboTasks, UpdateInfo, Vc, util::FormatDuration};\n+use turbo_tasks_backend::{BackendOptions, TurboTasksBackend, noop_backing_storage};\n use turbo_tasks_fs::{\n     DirectoryContent, DirectoryEntry, DiskFileSystem, FileContent, FileSystem, FileSystemPath,\n     register,\n };\n-use turbo_tasks_memory::MemoryBackend;\n \n #[tokio::main]\n async fn main() -> Result<()> {\n@@ -26,7 +26,10 @@ async fn main() -> Result<()> {\n         \"/register_example_hash_directory.rs\"\n     ));\n \n-    let tt = TurboTasks::new(MemoryBackend::default());\n+    let tt = TurboTasks::new(TurboTasksBackend::new(\n+        BackendOptions::default(),\n+        noop_backing_storage(),\n+    ));\n     let start = Instant::now();\n \n     let task = tt.spawn_root_task(|| {"
        },
        {
            "sha": "18f2bd4c968c1e3d76e49490cc6734d75c3cb9d0",
            "filename": "turbopack/crates/turbo-tasks-macros-tests/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -12,7 +12,7 @@ tokio = { workspace = true }\n trybuild = { version = \"1.0.104\" }\n turbo-tasks = { workspace = true }\n turbo-tasks-testing = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n+turbo-tasks-backend = { workspace = true }\n \n [build-dependencies]\n turbo-tasks-build = { workspace = true }"
        },
        {
            "sha": "70ca7cb18989de433d3e1f962650bed68b92802f",
            "filename": "turbopack/crates/turbo-tasks-macros-tests/tests/test_config.trs",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2Ftests%2Ftest_config.trs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2Ftests%2Ftest_config.trs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-macros-tests%2Ftests%2Ftest_config.trs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -1,3 +1,8 @@\n-|_name, _initial | {\n-  turbo_tasks::TurboTasks::new(turbo_tasks_memory::MemoryBackend::new(usize::MAX))\n+|_name, _initial| {\n+  turbo_tasks::TurboTasks::new(\n+    turbo_tasks_backend::TurboTasksBackend::new(\n+      turbo_tasks_backend::BackendOptions::default(),\n+      turbo_tasks_backend::noop_backing_storage(),\n+    )\n+  )\n }"
        },
        {
            "sha": "0874c14c8a7a881648a93c688451d382adfd84e7",
            "filename": "turbopack/crates/turbo-tasks-memory/Cargo.toml",
            "status": "removed",
            "additions": 0,
            "deletions": 56,
            "changes": 56,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2FCargo.toml?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,56 +0,0 @@\n-[package]\n-name = \"turbo-tasks-memory\"\n-version = \"0.1.0\"\n-description = \"TBD\"\n-license = \"MIT\"\n-edition = \"2024\"\n-autobenches = false\n-\n-[lib]\n-bench = false\n-\n-[lints]\n-workspace = true\n-\n-[dependencies]\n-anyhow = { workspace = true }\n-auto-hash-map = { workspace = true }\n-concurrent-queue = { workspace = true }\n-dashmap = { workspace = true }\n-either = { workspace = true }\n-indexmap = { workspace = true }\n-num_cpus = \"1.13.1\"\n-once_cell = { workspace = true }\n-parking_lot = { workspace = true }\n-ref-cast = \"1.0.20\"\n-rustc-hash = { workspace = true }\n-serde = { workspace = true }\n-smallvec = { workspace = true }\n-tokio = { workspace = true }\n-tracing = { workspace = true }\n-turbo-prehash = { workspace = true }\n-turbo-tasks = { workspace = true }\n-turbo-tasks-hash = { workspace = true }\n-turbo-tasks-malloc = { workspace = true, default-features = false }\n-\n-[dev-dependencies]\n-criterion = { workspace = true, features = [\"async_tokio\"] }\n-loom = \"0.7.2\"\n-rand = { workspace = true, features = [\"small_rng\"] }\n-regex = { workspace = true }\n-rstest = { workspace = true }\n-serde_json = { workspace = true }\n-tokio = { workspace = true, features = [\"full\"] }\n-turbo-rcstr = { workspace = true }\n-turbo-tasks-testing = { workspace = true }\n-\n-[build-dependencies]\n-turbo-tasks-build = { workspace = true }\n-\n-[features]\n-track_unfinished = []\n-default = []\n-\n-[[bench]]\n-name = \"mod\"\n-harness = false"
        },
        {
            "sha": "4c8c1a1f00b7e11824d9508863bf0c882cb4cca7",
            "filename": "turbopack/crates/turbo-tasks-memory/benches/mod.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 19,
            "changes": 19,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fmod.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,19 +0,0 @@\n-#![feature(arbitrary_self_types)]\n-#![feature(arbitrary_self_types_pointers)]\n-\n-use criterion::{Criterion, criterion_group, criterion_main};\n-\n-pub(crate) mod scope_stress;\n-pub(crate) mod stress;\n-\n-criterion_group!(\n-    name = turbo_tasks_memory_stress;\n-    config = Criterion::default();\n-    targets = stress::fibonacci, scope_stress::scope_stress\n-);\n-criterion_main!(turbo_tasks_memory_stress);\n-\n-pub fn register() {\n-    turbo_tasks::register();\n-    include!(concat!(env!(\"OUT_DIR\"), \"/register_benches.rs\"));\n-}"
        },
        {
            "sha": "8e406a25a25f16c653530123944d18a1e91d50f4",
            "filename": "turbopack/crates/turbo-tasks-memory/benches/scope_stress.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 79,
            "changes": 79,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fscope_stress.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fscope_stress.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fscope_stress.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,79 +0,0 @@\n-use anyhow::Result;\n-use criterion::{BenchmarkId, Criterion};\n-use turbo_tasks::{Completion, ReadConsistency, TryJoinIterExt, TurboTasks, Vc};\n-use turbo_tasks_memory::MemoryBackend;\n-\n-use super::register;\n-\n-pub fn scope_stress(c: &mut Criterion) {\n-    if matches!(\n-        std::env::var(\"TURBOPACK_BENCH_STRESS\").ok().as_deref(),\n-        None | Some(\"\") | Some(\"no\") | Some(\"false\")\n-    ) {\n-        return;\n-    }\n-\n-    register();\n-\n-    let mut group = c.benchmark_group(\"turbo_tasks_memory_scope_stress\");\n-    group.sample_size(20);\n-\n-    for size in [5, 10, 15, 20, 25, 30, 100, 200, 300] {\n-        group.throughput(criterion::Throughput::Elements(\n-            /* tasks for fib from 0 to size - 1 = */\n-            (size as u64) * (size as u64) +\n-            /* root tasks = */\n-            (2 * size as u64)\n-                - 1,\n-        ));\n-        group.bench_with_input(\n-            BenchmarkId::new(\"rectangle\", format_args!(\"{size} x {size}\")),\n-            &size,\n-            |b, size| {\n-                let rt = tokio::runtime::Builder::new_multi_thread()\n-                    .enable_all()\n-                    .build()\n-                    .unwrap();\n-                let size = *size;\n-\n-                b.to_async(rt).iter_with_large_drop(move || {\n-                    let tt = TurboTasks::new(MemoryBackend::default());\n-                    async move {\n-                        (0..size)\n-                            .map(|a| (a, size - 1))\n-                            .chain((0..size - 1).map(|b| (size - 1, b)))\n-                            .map(|(a, b)| {\n-                                let tt = &tt;\n-                                async move {\n-                                    let task = tt.spawn_once_task(async move {\n-                                        rectangle(a, b).strongly_consistent().await?;\n-                                        Ok::<Vc<()>, _>(Default::default())\n-                                    });\n-                                    tt.wait_task_completion(task, ReadConsistency::Eventual)\n-                                        .await\n-                                }\n-                            })\n-                            .try_join()\n-                            .await\n-                            .unwrap();\n-\n-                        tt\n-                    }\n-                })\n-            },\n-        );\n-    }\n-}\n-\n-/// This fills a rectagle from (0, 0) to (a, b) by\n-/// first filling (0, 0) to (a - 1, b) and then (0, 0) to (a, b - 1) recursively\n-#[turbo_tasks::function]\n-async fn rectangle(a: u32, b: u32) -> Result<Vc<Completion>> {\n-    if a > 0 {\n-        rectangle(a - 1, b).await?;\n-    }\n-    if b > 0 {\n-        rectangle(a, b - 1).await?;\n-    }\n-    Ok(Completion::new())\n-}"
        },
        {
            "sha": "31040560e46a957baa22c532af4649a7cb75bacb",
            "filename": "turbopack/crates/turbo-tasks-memory/benches/stress.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 80,
            "changes": 80,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fstress.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fstress.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbenches%2Fstress.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,80 +0,0 @@\n-use anyhow::Result;\n-use criterion::{BenchmarkId, Criterion};\n-use turbo_tasks::{ReadConsistency, TryJoinIterExt, TurboTasks, Vc};\n-use turbo_tasks_memory::MemoryBackend;\n-\n-use super::register;\n-\n-pub fn fibonacci(c: &mut Criterion) {\n-    if matches!(\n-        std::env::var(\"TURBOPACK_BENCH_STRESS\").ok().as_deref(),\n-        None | Some(\"\") | Some(\"no\") | Some(\"false\")\n-    ) {\n-        return;\n-    }\n-\n-    register();\n-\n-    let mut group = c.benchmark_group(\"turbo_tasks_memory_stress\");\n-    group.sample_size(20);\n-\n-    for size in [100, 200, 500, 1000, 1414] {\n-        group.throughput(criterion::Throughput::Elements(\n-            /* tasks for fib from 0 to size - 1 = */\n-            size as u64 * (size as u64 + 1) / 2 +\n-            /* root task = */\n-            1,\n-        ));\n-        group.bench_with_input(BenchmarkId::new(\"fibonacci\", size), &size, |b, size| {\n-            let rt = tokio::runtime::Builder::new_multi_thread()\n-                .enable_all()\n-                .build()\n-                .unwrap();\n-            let size = *size;\n-\n-            b.to_async(rt).iter_with_large_drop(move || {\n-                let tt = TurboTasks::new(MemoryBackend::default());\n-                async move {\n-                    let task = tt.spawn_once_task(async move {\n-                        // Number of tasks:\n-                        // 1 root task\n-                        // size >= 1 => + fib(0) = 1\n-                        // size >= 2 => + fib(1) = 2\n-                        (0..size).map(|i| fib(i, i)).try_join().await?;\n-                        Ok::<Vc<()>, _>(Default::default())\n-                    });\n-                    tt.wait_task_completion(task, ReadConsistency::Eventual)\n-                        .await\n-                        .unwrap();\n-                    tt\n-                }\n-            })\n-        });\n-    }\n-}\n-\n-#[turbo_tasks::value(transparent)]\n-struct FibResult(u64);\n-\n-// Number of tasks:\n-// fib(0) = 1 tasks\n-// fib(1) = 2 tasks\n-// fib(n) = n + 1 tasks\n-\n-/// Computes a fibonacci number in a recursive matter. Due to turbo-tasks this\n-/// will result in a lot of cached tasks, so its performance is only O(n)\n-/// (compared to non-turbo-tasks O(1.6^N)).\n-/// This function also has a `key` parameter to allow forcing it to separate\n-/// cache entries by using different keys.\n-#[turbo_tasks::function]\n-async fn fib(i: u32, key: u32) -> Result<Vc<FibResult>> {\n-    Ok(match i {\n-        0 => FibResult(1).cell(),\n-        1 => fib(0, key),\n-        _ => {\n-            let a = fib(i - 1, key);\n-            let b = fib(i - 2, key);\n-            FibResult(a.await?.wrapping_add(*b.await?)).cell()\n-        }\n-    })\n-}"
        },
        {
            "sha": "1673efed59cce6379c6a83d17829dfc0687e253f",
            "filename": "turbopack/crates/turbo-tasks-memory/build.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbuild.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbuild.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fbuild.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,5 +0,0 @@\n-use turbo_tasks_build::generate_register;\n-\n-fn main() {\n-    generate_register();\n-}"
        },
        {
            "sha": "80b5435d3f955376040a10f8f5c06a25792d6b6e",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/aggregation_data.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 84,
            "changes": 84,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Faggregation_data.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Faggregation_data.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Faggregation_data.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,84 +0,0 @@\n-use std::ops::{Deref, DerefMut};\n-\n-use super::{\n-    AggregationContext, AggregationNode, AggregationNodeGuard, increase_aggregation_number_internal,\n-};\n-use crate::aggregation::{balance_queue::BalanceQueue, increase::IncreaseReason};\n-\n-/// Gives an reference to the aggregated data for a given item. This will\n-/// convert the item to a fully aggregated node.\n-pub fn aggregation_data<'l, C>(\n-    ctx: &'l C,\n-    node_id: &C::NodeRef,\n-) -> AggregationDataGuard<C::Guard<'l>>\n-where\n-    C: AggregationContext + 'l,\n-{\n-    let guard = ctx.node(node_id);\n-    if guard.aggregation_number() == u32::MAX {\n-        AggregationDataGuard { guard }\n-    } else {\n-        let mut balance_queue = BalanceQueue::new();\n-        increase_aggregation_number_internal(\n-            ctx,\n-            &mut balance_queue,\n-            guard,\n-            node_id,\n-            u32::MAX,\n-            u32::MAX,\n-            IncreaseReason::AggregationData,\n-        );\n-        balance_queue.process(ctx);\n-        let guard = ctx.node(node_id);\n-        debug_assert!(guard.aggregation_number() == u32::MAX);\n-        AggregationDataGuard { guard }\n-    }\n-}\n-\n-/// Converted the given node to a fully aggregated node. To make the next call\n-/// to `aggregation_data` instant.\n-#[cfg(test)]\n-pub fn prepare_aggregation_data<C: AggregationContext>(ctx: &C, node_id: &C::NodeRef) {\n-    let mut balance_queue = BalanceQueue::new();\n-    increase_aggregation_number_internal(\n-        ctx,\n-        &mut balance_queue,\n-        ctx.node(node_id),\n-        node_id,\n-        u32::MAX,\n-        u32::MAX,\n-        IncreaseReason::AggregationData,\n-    );\n-    balance_queue.process(ctx);\n-}\n-\n-/// A reference to the aggregated data of a node. This holds a lock to the node.\n-pub struct AggregationDataGuard<G> {\n-    guard: G,\n-}\n-\n-impl<G> AggregationDataGuard<G> {\n-    pub fn into_inner(self) -> G {\n-        self.guard\n-    }\n-}\n-\n-impl<G: AggregationNodeGuard> Deref for AggregationDataGuard<G> {\n-    type Target = G::Data;\n-\n-    fn deref(&self) -> &Self::Target {\n-        match &*self.guard {\n-            AggregationNode::Leaf { .. } => unreachable!(),\n-            AggregationNode::Aggegating(aggregating) => &aggregating.data,\n-        }\n-    }\n-}\n-\n-impl<G: AggregationNodeGuard> DerefMut for AggregationDataGuard<G> {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        match &mut *self.guard {\n-            AggregationNode::Leaf { .. } => unreachable!(),\n-            AggregationNode::Aggegating(aggregating) => &mut aggregating.data,\n-        }\n-    }\n-}"
        },
        {
            "sha": "fa686a8b96be19092b1debdbc8c908951763a0a2",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/balance_edge.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 190,
            "changes": 190,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_edge.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_edge.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_edge.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,190 +0,0 @@\n-use std::cmp::Ordering;\n-\n-use super::{\n-    AggregationContext, AggregationNode, PreparedInternalOperation, PreparedOperation, StackVec,\n-    balance_queue::BalanceQueue,\n-    in_progress::{is_in_progress, start_in_progress_all, start_in_progress_count},\n-    increase::IncreaseReason,\n-    increase_aggregation_number_internal,\n-    notify_lost_follower::notify_lost_follower,\n-    notify_new_follower::notify_new_follower,\n-    util::{get_aggregated_add_change, get_aggregated_remove_change, get_followers_or_children},\n-};\n-\n-// Migrate followers to uppers or uppers to followers depending on the\n-// aggregation numbers of the nodes involved in the edge. Might increase targets\n-// aggregation number if they are equal.\n-pub(super) fn balance_edge<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    upper_id: &C::NodeRef,\n-    target_id: &C::NodeRef,\n-) {\n-    loop {\n-        let (mut upper, mut target) = ctx.node_pair(upper_id, target_id);\n-        let upper_aggregation_number = upper.aggregation_number();\n-        let target_aggregation_number = target.aggregation_number();\n-\n-        let root = upper_aggregation_number == u32::MAX || target_aggregation_number == u32::MAX;\n-        let order = if root {\n-            Ordering::Greater\n-        } else {\n-            upper_aggregation_number.cmp(&target_aggregation_number)\n-        };\n-        match order {\n-            Ordering::Equal => {\n-                drop(upper);\n-                // increase target aggregation number\n-                increase_aggregation_number_internal(\n-                    ctx,\n-                    balance_queue,\n-                    target,\n-                    target_id,\n-                    target_aggregation_number + 1,\n-                    target_aggregation_number + 1,\n-                    IncreaseReason::EqualAggregationNumberOnBalance,\n-                );\n-            }\n-            Ordering::Less => {\n-                if is_in_progress(ctx, upper_id) {\n-                    drop(target);\n-                    let AggregationNode::Aggegating(aggregating) = &mut *upper else {\n-                        unreachable!();\n-                    };\n-                    aggregating\n-                        .enqueued_balancing\n-                        .push((upper_id.clone(), target_id.clone()));\n-                    drop(upper);\n-                    // Somebody else will balance this edge\n-                    break;\n-                }\n-\n-                // target should be a follower of upper\n-                let count = target\n-                    .uppers_mut()\n-                    .remove_all_positive_clonable_count(upper_id);\n-                if count == 0 {\n-                    break;\n-                }\n-                let added = upper\n-                    .followers_mut()\n-                    .unwrap()\n-                    .add_clonable_count(target_id, count);\n-\n-                // target removed as upper\n-                let remove_change = get_aggregated_remove_change(ctx, &target);\n-                let followers = get_followers_or_children(ctx, &target);\n-\n-                let upper_uppers = if added {\n-                    // target added as follower\n-                    let uppers = upper.uppers().iter().cloned().collect::<StackVec<_>>();\n-                    start_in_progress_all(ctx, &uppers);\n-                    uppers\n-                } else {\n-                    Default::default()\n-                };\n-\n-                drop(target);\n-\n-                // target removed as upper\n-                let remove_prepared =\n-                    remove_change.and_then(|remove_change| upper.apply_change(ctx, remove_change));\n-                start_in_progress_count(ctx, upper_id, followers.len() as u32);\n-                let prepared = followers\n-                    .into_iter()\n-                    .map(|child_id| {\n-                        upper.notify_lost_follower(ctx, balance_queue, upper_id, &child_id)\n-                    })\n-                    .collect::<StackVec<_>>();\n-                drop(upper);\n-\n-                // target added as follower\n-                for upper_id in upper_uppers {\n-                    notify_new_follower(\n-                        ctx,\n-                        balance_queue,\n-                        ctx.node(&upper_id),\n-                        &upper_id,\n-                        target_id,\n-                        false,\n-                    );\n-                }\n-\n-                // target removed as upper\n-                remove_prepared.apply(ctx);\n-                prepared.apply(ctx, balance_queue);\n-\n-                break;\n-            }\n-            Ordering::Greater => {\n-                if is_in_progress(ctx, upper_id) {\n-                    let AggregationNode::Aggegating(aggregating) = &mut *upper else {\n-                        unreachable!();\n-                    };\n-                    aggregating\n-                        .enqueued_balancing\n-                        .push((upper_id.clone(), target_id.clone()));\n-                    drop(upper);\n-                    // Somebody else will balance this edge\n-                    break;\n-                }\n-\n-                // target should be a inner node of upper\n-                let count = upper\n-                    .followers_mut()\n-                    .unwrap()\n-                    .remove_all_positive_clonable_count(target_id);\n-                if count == 0 {\n-                    break;\n-                }\n-                let added = target.uppers_mut().add_clonable_count(upper_id, count);\n-\n-                // target removed as follower\n-                let uppers = upper.uppers().iter().cloned().collect::<StackVec<_>>();\n-                start_in_progress_all(ctx, &uppers);\n-\n-                let (add_change, followers) = if added {\n-                    // target added as upper\n-                    let add_change = get_aggregated_add_change(ctx, &target);\n-                    let followers = get_followers_or_children(ctx, &target);\n-                    start_in_progress_count(ctx, upper_id, followers.len() as u32);\n-                    (add_change, followers)\n-                } else {\n-                    (None, Default::default())\n-                };\n-\n-                drop(target);\n-\n-                // target added as upper\n-                let add_prepared =\n-                    add_change.and_then(|add_change| upper.apply_change(ctx, add_change));\n-                let prepared = followers\n-                    .into_iter()\n-                    .filter_map(|child_id| {\n-                        upper.notify_new_follower(ctx, balance_queue, upper_id, &child_id, false)\n-                    })\n-                    .collect::<StackVec<_>>();\n-\n-                drop(upper);\n-\n-                add_prepared.apply(ctx);\n-                for prepared in prepared {\n-                    prepared.apply(ctx, balance_queue);\n-                }\n-\n-                // target removed as follower\n-                for upper_id in uppers {\n-                    notify_lost_follower(\n-                        ctx,\n-                        balance_queue,\n-                        ctx.node(&upper_id),\n-                        &upper_id,\n-                        target_id,\n-                    );\n-                }\n-\n-                break;\n-            }\n-        }\n-    }\n-}"
        },
        {
            "sha": "cc0df24a00bcf0e03fcff9aeb7d8040088a348ee",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/balance_queue.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 44,
            "changes": 44,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_queue.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_queue.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fbalance_queue.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,44 +0,0 @@\n-use std::{hash::Hash, mem::take};\n-\n-use turbo_tasks::FxIndexSet;\n-\n-use super::{AggregationContext, balance_edge};\n-\n-/// Enqueued edges that need to be balanced. Deduplicates edges and keeps track\n-/// of aggregation numbers read during balancing.\n-pub struct BalanceQueue<I> {\n-    queue: FxIndexSet<(I, I)>,\n-}\n-\n-impl<I: Hash + Eq + Clone> BalanceQueue<I> {\n-    pub fn new() -> Self {\n-        Self {\n-            queue: FxIndexSet::default(),\n-        }\n-    }\n-\n-    /// Add an edge to the queue. The edge will be balanced during the next\n-    /// call.\n-    pub fn balance(&mut self, upper_id: I, target_id: I) {\n-        debug_assert!(upper_id != target_id);\n-        self.queue.insert((upper_id.clone(), target_id.clone()));\n-    }\n-\n-    /// Add multiple edges to the queue. The edges will be balanced during the\n-    /// next call.\n-    pub fn balance_all(&mut self, edges: Vec<(I, I)>) {\n-        for (upper_id, target_id) in edges {\n-            self.balance(upper_id, target_id);\n-        }\n-    }\n-\n-    /// Process the queue and balance all enqueued edges.\n-    pub fn process<C: AggregationContext<NodeRef = I>>(mut self, ctx: &C) {\n-        while !self.queue.is_empty() {\n-            let queue = take(&mut self.queue);\n-            for (upper_id, target_id) in queue {\n-                balance_edge(ctx, &mut self, &upper_id, &target_id);\n-            }\n-        }\n-    }\n-}"
        },
        {
            "sha": "fc69033cf6f7ad068e5e5fc0ee2678ae6aba8201",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/change.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 108,
            "changes": 108,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fchange.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fchange.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fchange.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,108 +0,0 @@\n-use std::hash::Hash;\n-\n-use super::{AggegatingNode, AggregationContext, AggregationNode, PreparedOperation, StackVec};\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    /// Prepares to apply a change to a node. Changes will be propagated to all\n-    /// upper nodes.\n-    #[must_use]\n-    pub fn apply_change<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        change: C::DataChange,\n-    ) -> Option<PreparedChange<C>> {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => (!uppers.is_empty()).then(|| PreparedChange {\n-                uppers: uppers.iter().cloned().collect::<StackVec<_>>(),\n-                change,\n-            }),\n-            AggregationNode::Aggegating(aggegating) => {\n-                let AggegatingNode { data, uppers, .. } = &mut **aggegating;\n-                let change = ctx.apply_change(data, &change);\n-                if uppers.is_empty() {\n-                    None\n-                } else {\n-                    change.map(|change| PreparedChange {\n-                        uppers: uppers.iter().cloned().collect::<StackVec<_>>(),\n-                        change,\n-                    })\n-                }\n-            }\n-        }\n-    }\n-\n-    /// Prepares to apply a change to a node. Changes will be propagated to all\n-    /// upper nodes.\n-    #[must_use]\n-    pub fn apply_change_ref<'l, C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        change: &'l C::DataChange,\n-    ) -> Option<PreparedChangeRef<'l, C>> {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => {\n-                (!uppers.is_empty()).then(|| PreparedChangeRef::Borrowed {\n-                    uppers: uppers.iter().cloned().collect::<StackVec<_>>(),\n-                    change,\n-                })\n-            }\n-            AggregationNode::Aggegating(aggegating) => {\n-                let AggegatingNode { data, uppers, .. } = &mut **aggegating;\n-                let change = ctx.apply_change(data, change);\n-                if uppers.is_empty() {\n-                    None\n-                } else {\n-                    change.map(|change| PreparedChangeRef::Owned {\n-                        uppers: uppers.iter().cloned().collect::<StackVec<_>>(),\n-                        change,\n-                    })\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-/// A prepared `apply_change` operation.\n-pub struct PreparedChange<C: AggregationContext> {\n-    uppers: StackVec<C::NodeRef>,\n-    change: C::DataChange,\n-}\n-\n-impl<C: AggregationContext> PreparedOperation<C> for PreparedChange<C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) {\n-        let prepared = self\n-            .uppers\n-            .into_iter()\n-            .filter_map(|upper_id| ctx.node(&upper_id).apply_change_ref(ctx, &self.change))\n-            .collect::<StackVec<_>>();\n-        prepared.apply(ctx);\n-    }\n-}\n-\n-/// A prepared `apply_change_ref` operation.\n-pub enum PreparedChangeRef<'l, C: AggregationContext> {\n-    Borrowed {\n-        uppers: StackVec<C::NodeRef>,\n-        change: &'l C::DataChange,\n-    },\n-    Owned {\n-        uppers: StackVec<C::NodeRef>,\n-        change: C::DataChange,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedOperation<C> for PreparedChangeRef<'_, C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) {\n-        let (uppers, change) = match self {\n-            PreparedChangeRef::Borrowed { uppers, change } => (uppers, change),\n-            PreparedChangeRef::Owned { uppers, ref change } => (uppers, change),\n-        };\n-        let prepared = uppers\n-            .into_iter()\n-            .filter_map(|upper_id| ctx.node(&upper_id).apply_change_ref(ctx, change))\n-            .collect::<StackVec<_>>();\n-        prepared.apply(ctx);\n-    }\n-}"
        },
        {
            "sha": "9546f8245b26af35bcf78b31372107b3145a642c",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/followers.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 88,
            "changes": 88,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ffollowers.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ffollowers.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ffollowers.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,88 +0,0 @@\n-use super::{\n-    AggregationContext, AggregationNode, StackVec,\n-    balance_queue::BalanceQueue,\n-    in_progress::start_in_progress_all,\n-    notify_new_follower,\n-    optimize::{MAX_FOLLOWERS, optimize_aggregation_number_for_followers},\n-};\n-\n-/// Add a follower to a node. Followers will be propagated to the uppers of the\n-/// node.\n-pub fn add_follower<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut node: C::Guard<'_>,\n-    node_id: &C::NodeRef,\n-    follower_id: &C::NodeRef,\n-    already_optimizing_for_node: bool,\n-) -> usize {\n-    let AggregationNode::Aggegating(aggregating) = &mut *node else {\n-        unreachable!();\n-    };\n-    if aggregating.followers.add_clonable(follower_id) {\n-        on_added(\n-            ctx,\n-            balance_queue,\n-            node,\n-            node_id,\n-            follower_id,\n-            already_optimizing_for_node,\n-        )\n-    } else {\n-        0\n-    }\n-}\n-\n-/// Handle the addition of a follower to a node. This function is called after\n-/// the follower has been added to the node.\n-pub fn on_added<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut node: C::Guard<'_>,\n-    node_id: &C::NodeRef,\n-    follower_id: &C::NodeRef,\n-    already_optimizing_for_node: bool,\n-) -> usize {\n-    let AggregationNode::Aggegating(aggregating) = &mut *node else {\n-        unreachable!();\n-    };\n-    let followers_len = aggregating.followers.len();\n-    let optimize = (!already_optimizing_for_node\n-        && followers_len >= MAX_FOLLOWERS\n-        && followers_len.is_power_of_two())\n-    .then(|| {\n-        aggregating\n-            .followers\n-            .iter()\n-            .cloned()\n-            .collect::<StackVec<_>>()\n-    });\n-    let uppers = aggregating.uppers.iter().cloned().collect::<StackVec<_>>();\n-    start_in_progress_all(ctx, &uppers);\n-    drop(node);\n-\n-    let mut optimizing = false;\n-\n-    if let Some(followers) = optimize {\n-        optimizing = optimize_aggregation_number_for_followers(\n-            ctx,\n-            balance_queue,\n-            node_id,\n-            followers,\n-            false,\n-        );\n-    }\n-\n-    let mut affected_nodes = uppers.len();\n-    for upper_id in uppers {\n-        affected_nodes += notify_new_follower(\n-            ctx,\n-            balance_queue,\n-            ctx.node(&upper_id),\n-            &upper_id,\n-            follower_id,\n-            optimizing,\n-        );\n-    }\n-    affected_nodes\n-}"
        },
        {
            "sha": "c7088a31bbaa0172757a5d51a9db244b8f1861be",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/in_progress.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 75,
            "changes": 75,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fin_progress.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fin_progress.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fin_progress.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,75 +0,0 @@\n-use std::{hash::Hash, mem::take};\n-\n-use super::{AggregationContext, AggregationNode, StackVec, balance_queue::BalanceQueue};\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    /// Finishes an in progress operation. This might enqueue balancing\n-    /// operations when they weren't possible due to the in progress operation.\n-    pub(super) fn finish_in_progress<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        balance_queue: &mut BalanceQueue<I>,\n-        node_id: &I,\n-    ) {\n-        let value = ctx\n-            .atomic_in_progress_counter(node_id)\n-            .fetch_sub(1, std::sync::atomic::Ordering::AcqRel);\n-        debug_assert!(value > 0);\n-        if value == 1 {\n-            if let AggregationNode::Aggegating(aggegating) = &mut *self {\n-                balance_queue.balance_all(take(&mut aggegating.enqueued_balancing))\n-            }\n-        }\n-    }\n-}\n-\n-/// Finishes an in progress operation. This might enqueue balancing\n-/// operations when they weren't possible due to the in progress operation.\n-/// This version doesn't require a node guard.\n-pub fn finish_in_progress_without_node<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    node_id: &C::NodeRef,\n-) {\n-    let value = ctx\n-        .atomic_in_progress_counter(node_id)\n-        .fetch_sub(1, std::sync::atomic::Ordering::AcqRel);\n-    debug_assert!(value > 0);\n-    if value == 1 {\n-        let mut node = ctx.node(node_id);\n-        if let AggregationNode::Aggegating(aggegating) = &mut *node {\n-            balance_queue.balance_all(take(&mut aggegating.enqueued_balancing))\n-        }\n-    }\n-}\n-\n-/// Starts an in progress operation for all nodes in the list.\n-pub fn start_in_progress_all<C: AggregationContext>(ctx: &C, node_ids: &StackVec<C::NodeRef>) {\n-    for node_id in node_ids {\n-        start_in_progress(ctx, node_id);\n-    }\n-}\n-\n-/// Starts an in progress operation for a node.\n-pub fn start_in_progress<C: AggregationContext>(ctx: &C, node_id: &C::NodeRef) {\n-    start_in_progress_count(ctx, node_id, 1);\n-}\n-\n-/// Starts multiple in progress operations for a node.\n-pub fn start_in_progress_count<C: AggregationContext>(ctx: &C, node_id: &C::NodeRef, count: u32) {\n-    if count == 0 {\n-        return;\n-    }\n-    ctx.atomic_in_progress_counter(node_id)\n-        .fetch_add(count, std::sync::atomic::Ordering::Release);\n-}\n-\n-/// Checks if there is an in progress operation for a node.\n-/// It doesn't require a lock, but should run under a lock of the node or a\n-/// follower/inner node.\n-pub fn is_in_progress<C: AggregationContext>(ctx: &C, node_id: &C::NodeRef) -> bool {\n-    let counter = ctx\n-        .atomic_in_progress_counter(node_id)\n-        .load(std::sync::atomic::Ordering::Acquire);\n-    counter > 0\n-}"
        },
        {
            "sha": "1a74d201c1d6ee683e62c2dc6971c4e2d0d46e1d",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/increase.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 333,
            "changes": 333,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fincrease.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fincrease.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fincrease.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,333 +0,0 @@\n-use std::{hash::Hash, mem::take};\n-\n-use super::{\n-    AggegatingNode, AggregationContext, AggregationNode, AggregationNodeGuard,\n-    PreparedInternalOperation, PreparedOperation, StackVec, balance_queue::BalanceQueue,\n-};\n-pub(super) const LEAF_NUMBER: u32 = 16;\n-\n-#[derive(Debug)]\n-pub enum IncreaseReason {\n-    Upgraded,\n-    AggregationData,\n-    EqualAggregationNumberOnBalance,\n-    EqualAggregationNumberOnNewFollower,\n-    OptimizeForUppers,\n-    OptimizeForFollowers,\n-    LeafEdge,\n-    LeafEdgeAfterIncrease,\n-    #[cfg(test)]\n-    Test,\n-}\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    /// Increase the aggregation number of a node. This might temporarily\n-    /// violate the graph invariants between uppers and followers of that node.\n-    /// Therefore a balancing operation is enqueued to restore the invariants.\n-    /// The actual change to the aggregation number is applied in the prepared\n-    /// operation after checking all upper nodes aggregation numbers.\n-    #[must_use]\n-    pub(super) fn increase_aggregation_number_internal<\n-        C: AggregationContext<NodeRef = I, Data = D>,\n-    >(\n-        &mut self,\n-        _ctx: &C,\n-        node_id: &C::NodeRef,\n-        min_aggregation_number: u32,\n-        target_aggregation_number: u32,\n-        reason: IncreaseReason,\n-    ) -> Option<PreparedInternalIncreaseAggregationNumber<C>> {\n-        if self.aggregation_number() >= min_aggregation_number {\n-            return None;\n-        }\n-        Some(PreparedInternalIncreaseAggregationNumber::Lazy {\n-            node_id: node_id.clone(),\n-            uppers: self.uppers_mut().iter().cloned().collect(),\n-            min_aggregation_number,\n-            target_aggregation_number,\n-            reason,\n-        })\n-    }\n-\n-    /// Increase the aggregation number of a node. This is only for testing\n-    /// proposes.\n-    #[cfg(test)]\n-    pub fn increase_aggregation_number<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        _ctx: &C,\n-        node_id: &C::NodeRef,\n-        new_aggregation_number: u32,\n-    ) -> Option<PreparedIncreaseAggregationNumber<C>> {\n-        self.increase_aggregation_number_internal(\n-            _ctx,\n-            node_id,\n-            new_aggregation_number,\n-            new_aggregation_number,\n-            IncreaseReason::Test,\n-        )\n-        .map(PreparedIncreaseAggregationNumber)\n-    }\n-}\n-\n-/// Increase the aggregation number of a node directly. This might temporarily\n-/// violate the graph invariants between uppers and followers of that node.\n-/// Therefore a balancing operation is enqueued to restore the invariants.\n-/// The actual change to the aggregation number is applied directly without\n-/// checking the upper nodes.\n-#[must_use]\n-pub(super) fn increase_aggregation_number_immediately<C: AggregationContext>(\n-    _ctx: &C,\n-    node: &mut C::Guard<'_>,\n-    node_id: C::NodeRef,\n-    min_aggregation_number: u32,\n-    target_aggregation_number: u32,\n-    reason: IncreaseReason,\n-) -> Option<PreparedInternalIncreaseAggregationNumber<C>> {\n-    if node.aggregation_number() >= min_aggregation_number {\n-        return None;\n-    }\n-\n-    let _span = tracing::trace_span!(\n-        \"increase_aggregation_number_immediately\",\n-        reason = debug(&reason)\n-    )\n-    .entered();\n-    let children = matches!(**node, AggregationNode::Leaf { .. })\n-        .then(|| node.children().collect::<StackVec<_>>());\n-    match &mut **node {\n-        AggregationNode::Leaf {\n-            aggregation_number,\n-            uppers,\n-        } => {\n-            let children = children.unwrap();\n-            if target_aggregation_number < LEAF_NUMBER {\n-                *aggregation_number = target_aggregation_number as u8;\n-                Some(PreparedInternalIncreaseAggregationNumber::Leaf {\n-                    target_aggregation_number,\n-                    children,\n-                })\n-            } else {\n-                let uppers_copy = uppers.iter().cloned().collect::<StackVec<_>>();\n-                // Convert to Aggregating\n-                **node = AggregationNode::Aggegating(Box::new(AggegatingNode {\n-                    aggregation_number: target_aggregation_number,\n-                    uppers: take(uppers),\n-                    followers: children.iter().cloned().collect(),\n-                    data: node.get_initial_data(),\n-                    enqueued_balancing: Vec::new(),\n-                }));\n-                let followers = children;\n-                Some(PreparedInternalIncreaseAggregationNumber::Aggregating {\n-                    node_id,\n-                    uppers: uppers_copy,\n-                    followers,\n-                })\n-            }\n-        }\n-        AggregationNode::Aggegating(aggegating) => {\n-            let AggegatingNode {\n-                followers,\n-                uppers,\n-                aggregation_number,\n-                ..\n-            } = &mut **aggegating;\n-            let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-            let followers = followers.iter().cloned().collect();\n-            *aggregation_number = target_aggregation_number;\n-            Some(PreparedInternalIncreaseAggregationNumber::Aggregating {\n-                node_id,\n-                uppers,\n-                followers,\n-            })\n-        }\n-    }\n-}\n-\n-/// A prepared `increase_aggregation_number` operation.\n-pub enum PreparedInternalIncreaseAggregationNumber<C: AggregationContext> {\n-    Lazy {\n-        node_id: C::NodeRef,\n-        uppers: StackVec<C::NodeRef>,\n-        min_aggregation_number: u32,\n-        target_aggregation_number: u32,\n-        reason: IncreaseReason,\n-    },\n-    Leaf {\n-        children: StackVec<C::NodeRef>,\n-        target_aggregation_number: u32,\n-    },\n-    Aggregating {\n-        node_id: C::NodeRef,\n-        uppers: StackVec<C::NodeRef>,\n-        followers: StackVec<C::NodeRef>,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedInternalOperation<C>\n-    for PreparedInternalIncreaseAggregationNumber<C>\n-{\n-    type Result = ();\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) {\n-        match self {\n-            PreparedInternalIncreaseAggregationNumber::Lazy {\n-                min_aggregation_number,\n-                mut target_aggregation_number,\n-                node_id,\n-                uppers,\n-                reason,\n-            } => {\n-                if target_aggregation_number >= LEAF_NUMBER {\n-                    let mut need_to_run = true;\n-                    while need_to_run {\n-                        need_to_run = false;\n-                        let mut max = 0;\n-                        for upper_id in &uppers {\n-                            let upper = ctx.node(upper_id);\n-                            let aggregation_number = upper.aggregation_number();\n-                            if aggregation_number != u32::MAX {\n-                                if aggregation_number > max {\n-                                    max = aggregation_number;\n-                                }\n-                                if aggregation_number == target_aggregation_number {\n-                                    target_aggregation_number += 1;\n-                                    if max >= target_aggregation_number {\n-                                        need_to_run = true;\n-                                    }\n-                                }\n-                            }\n-                        }\n-                    }\n-                }\n-                drop(uppers);\n-                let mut node = ctx.node(&node_id);\n-                if node.aggregation_number() >= min_aggregation_number {\n-                    return;\n-                }\n-                let _span =\n-                    tracing::trace_span!(\"increase_aggregation_number\", reason = debug(&reason))\n-                        .entered();\n-                let children = matches!(*node, AggregationNode::Leaf { .. })\n-                    .then(|| node.children().collect::<StackVec<_>>());\n-                let (uppers, followers) = match &mut *node {\n-                    AggregationNode::Leaf {\n-                        aggregation_number,\n-                        uppers,\n-                    } => {\n-                        let children = children.unwrap();\n-                        if target_aggregation_number < LEAF_NUMBER {\n-                            *aggregation_number = target_aggregation_number as u8;\n-                            drop(node);\n-                            for child_id in children {\n-                                increase_aggregation_number_internal(\n-                                    ctx,\n-                                    balance_queue,\n-                                    ctx.node(&child_id),\n-                                    &child_id,\n-                                    target_aggregation_number + 1,\n-                                    target_aggregation_number + 1,\n-                                    IncreaseReason::LeafEdgeAfterIncrease,\n-                                );\n-                            }\n-                            return;\n-                        } else {\n-                            let uppers_copy = uppers.iter().cloned().collect::<StackVec<_>>();\n-                            // Convert to Aggregating\n-                            *node = AggregationNode::Aggegating(Box::new(AggegatingNode {\n-                                aggregation_number: target_aggregation_number,\n-                                uppers: take(uppers),\n-                                followers: children.iter().cloned().collect(),\n-                                data: node.get_initial_data(),\n-                                enqueued_balancing: Vec::new(),\n-                            }));\n-                            let followers = children;\n-                            drop(node);\n-                            (uppers_copy, followers)\n-                        }\n-                    }\n-                    AggregationNode::Aggegating(aggegating) => {\n-                        let AggegatingNode {\n-                            followers,\n-                            uppers,\n-                            aggregation_number,\n-                            ..\n-                        } = &mut **aggegating;\n-                        let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-                        let followers = followers.iter().cloned().collect();\n-                        *aggregation_number = target_aggregation_number;\n-                        drop(node);\n-                        (uppers, followers)\n-                    }\n-                };\n-                for follower_id in followers {\n-                    balance_queue.balance(node_id.clone(), follower_id);\n-                }\n-                for upper_id in uppers {\n-                    balance_queue.balance(upper_id, node_id.clone());\n-                }\n-            }\n-            PreparedInternalIncreaseAggregationNumber::Leaf {\n-                children,\n-                target_aggregation_number,\n-            } => {\n-                for child_id in children {\n-                    increase_aggregation_number_internal(\n-                        ctx,\n-                        balance_queue,\n-                        ctx.node(&child_id),\n-                        &child_id,\n-                        target_aggregation_number + 1,\n-                        target_aggregation_number + 1,\n-                        IncreaseReason::LeafEdgeAfterIncrease,\n-                    );\n-                }\n-            }\n-            PreparedInternalIncreaseAggregationNumber::Aggregating {\n-                node_id,\n-                uppers,\n-                followers,\n-            } => {\n-                for follower_id in followers {\n-                    balance_queue.balance(node_id.clone(), follower_id);\n-                }\n-                for upper_id in uppers {\n-                    balance_queue.balance(upper_id, node_id.clone());\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-pub fn increase_aggregation_number_internal<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut node: C::Guard<'_>,\n-    node_id: &C::NodeRef,\n-    min_aggregation_number: u32,\n-    target_aggregation_number: u32,\n-    reason: IncreaseReason,\n-) {\n-    let prepared = node.increase_aggregation_number_internal(\n-        ctx,\n-        node_id,\n-        min_aggregation_number,\n-        target_aggregation_number,\n-        reason,\n-    );\n-    drop(node);\n-    prepared.apply(ctx, balance_queue);\n-}\n-\n-#[allow(dead_code)]\n-/// A prepared `increase_aggregation_number` operation.\n-pub struct PreparedIncreaseAggregationNumber<C: AggregationContext>(\n-    PreparedInternalIncreaseAggregationNumber<C>,\n-);\n-\n-impl<C: AggregationContext> PreparedOperation<C> for PreparedIncreaseAggregationNumber<C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) {\n-        let mut balance_queue = BalanceQueue::new();\n-        self.0.apply(ctx, &mut balance_queue);\n-        balance_queue.process(ctx);\n-    }\n-}"
        },
        {
            "sha": "369d7d477889124dce894e52c6003dd8f82cd053",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/loom_tests.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 298,
            "changes": 298,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Floom_tests.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Floom_tests.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Floom_tests.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,298 +0,0 @@\n-use std::{\n-    fmt::Debug,\n-    hash::Hash,\n-    ops::{Deref, DerefMut},\n-    sync::{Arc, atomic::AtomicU32},\n-};\n-\n-use loom::{\n-    sync::{Mutex, MutexGuard},\n-    thread,\n-};\n-use rand::{Rng, SeedableRng, rngs::SmallRng};\n-use ref_cast::RefCast;\n-use rstest::*;\n-\n-use super::{\n-    AggregationContext, AggregationNode, AggregationNodeGuard, PreparedOperation, aggregation_data,\n-    handle_new_edge,\n-};\n-\n-struct Node {\n-    atomic: AtomicU32,\n-    inner: Mutex<NodeInner>,\n-}\n-\n-impl Node {\n-    fn new(value: u32) -> Arc<Self> {\n-        Arc::new(Node {\n-            atomic: AtomicU32::new(0),\n-            inner: Mutex::new(NodeInner {\n-                children: Vec::new(),\n-                aggregation_node: AggregationNode::new(),\n-                value,\n-            }),\n-        })\n-    }\n-\n-    fn add_child(self: &Arc<Node>, aggregation_context: &NodeAggregationContext, child: Arc<Node>) {\n-        let mut guard = self.inner.lock().unwrap();\n-        guard.children.push(child.clone());\n-        let number_of_children = guard.children.len();\n-        let mut guard = unsafe { NodeGuard::new(guard, self.clone()) };\n-        let prepared = handle_new_edge(\n-            aggregation_context,\n-            &mut guard,\n-            &NodeRef(self.clone()),\n-            &NodeRef(child),\n-            number_of_children,\n-        );\n-        drop(guard);\n-        prepared.apply(aggregation_context);\n-    }\n-}\n-\n-#[derive(Copy, Clone)]\n-struct Change {}\n-\n-struct NodeInner {\n-    children: Vec<Arc<Node>>,\n-    aggregation_node: AggregationNode<NodeRef, Aggregated>,\n-    value: u32,\n-}\n-\n-struct NodeAggregationContext {}\n-\n-#[derive(Clone, RefCast)]\n-#[repr(transparent)]\n-struct NodeRef(Arc<Node>);\n-\n-impl Debug for NodeRef {\n-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n-        write!(f, \"NodeRef({})\", self.0.inner.lock().unwrap().value)\n-    }\n-}\n-\n-impl Hash for NodeRef {\n-    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n-        Arc::as_ptr(&self.0).hash(state);\n-    }\n-}\n-\n-impl PartialEq for NodeRef {\n-    fn eq(&self, other: &Self) -> bool {\n-        Arc::ptr_eq(&self.0, &other.0)\n-    }\n-}\n-\n-impl Eq for NodeRef {}\n-\n-struct NodeGuard {\n-    guard: MutexGuard<'static, NodeInner>,\n-    // This field is important to keep the node alive\n-    #[allow(dead_code)]\n-    node: Arc<Node>,\n-}\n-\n-impl NodeGuard {\n-    unsafe fn new(guard: MutexGuard<'_, NodeInner>, node: Arc<Node>) -> Self {\n-        NodeGuard {\n-            // #[allow(clippy::missing_transmute_annotations, reason = \"this is a test\")]\n-            guard: unsafe {\n-                std::mem::transmute::<MutexGuard<'_, NodeInner>, MutexGuard<'_, NodeInner>>(guard)\n-            },\n-            node,\n-        }\n-    }\n-}\n-\n-impl Deref for NodeGuard {\n-    type Target = AggregationNode<NodeRef, Aggregated>;\n-\n-    fn deref(&self) -> &Self::Target {\n-        &self.guard.aggregation_node\n-    }\n-}\n-\n-impl DerefMut for NodeGuard {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        &mut self.guard.aggregation_node\n-    }\n-}\n-\n-impl AggregationNodeGuard for NodeGuard {\n-    type Data = Aggregated;\n-    type NodeRef = NodeRef;\n-    type DataChange = Change;\n-    type ChildrenIter<'a> = impl Iterator<Item = NodeRef> + 'a;\n-\n-    fn children(&self) -> Self::ChildrenIter<'_> {\n-        self.guard\n-            .children\n-            .iter()\n-            .map(|child| NodeRef(child.clone()))\n-    }\n-\n-    fn get_remove_change(&self) -> Option<Change> {\n-        None\n-    }\n-\n-    fn get_add_change(&self) -> Option<Change> {\n-        None\n-    }\n-\n-    fn get_initial_data(&self) -> Self::Data {\n-        Aggregated {}\n-    }\n-}\n-\n-impl AggregationContext for NodeAggregationContext {\n-    type Guard<'l>\n-        = NodeGuard\n-    where\n-        Self: 'l;\n-    type Data = Aggregated;\n-    type NodeRef = NodeRef;\n-    type DataChange = Change;\n-\n-    fn node<'b>(&'b self, reference: &Self::NodeRef) -> Self::Guard<'b> {\n-        let r = reference.0.clone();\n-        let guard = reference.0.inner.lock().unwrap();\n-        unsafe { NodeGuard::new(guard, r) }\n-    }\n-\n-    fn node_pair<'b>(\n-        &'b self,\n-        id1: &Self::NodeRef,\n-        id2: &Self::NodeRef,\n-    ) -> (Self::Guard<'b>, Self::Guard<'b>) {\n-        let r1 = id1.0.clone();\n-        let r2 = id2.0.clone();\n-        loop {\n-            {\n-                let guard1 = id1.0.inner.lock().unwrap();\n-                if let Ok(guard2) = id2.0.inner.try_lock() {\n-                    return (unsafe { NodeGuard::new(guard1, r1) }, unsafe {\n-                        NodeGuard::new(guard2, r2)\n-                    });\n-                }\n-            }\n-            {\n-                let guard2 = id2.0.inner.lock().unwrap();\n-                if let Ok(guard1) = id1.0.inner.try_lock() {\n-                    return (unsafe { NodeGuard::new(guard1, r1) }, unsafe {\n-                        NodeGuard::new(guard2, r2)\n-                    });\n-                }\n-            }\n-        }\n-    }\n-\n-    fn atomic_in_progress_counter<'l>(&self, id: &'l NodeRef) -> &'l AtomicU32\n-    where\n-        Self: 'l,\n-    {\n-        &id.0.atomic\n-    }\n-\n-    fn apply_change(&self, _data: &mut Aggregated, _change: &Change) -> Option<Change> {\n-        None\n-    }\n-\n-    fn data_to_add_change(&self, _data: &Self::Data) -> Option<Self::DataChange> {\n-        None\n-    }\n-\n-    fn data_to_remove_change(&self, _data: &Self::Data) -> Option<Self::DataChange> {\n-        None\n-    }\n-}\n-\n-#[derive(Default)]\n-struct Aggregated {}\n-\n-// #[test]\n-#[allow(dead_code)]\n-fn fuzzy_loom_new() {\n-    for size in [10, 20] {\n-        for _ in 0..1000 {\n-            let seed = rand::random();\n-            println!(\"Seed {seed} Size {size}\");\n-            fuzzy_loom(seed, size);\n-        }\n-    }\n-}\n-\n-#[rstest]\n-#[case::a(3302552607, 10)]\n-// #[case::b(3629477471, 50)]\n-// #[case::c(1006976052, 20)]\n-// #[case::d(2174645157, 10)]\n-fn fuzzy_loom(#[case] seed: u32, #[case] count: u32) {\n-    let mut builder = loom::model::Builder::new();\n-    builder.max_branches = 100000;\n-    builder.check(move || {\n-        loom::stop_exploring();\n-        thread::Builder::new()\n-            .stack_size(80000)\n-            .spawn(move || {\n-                let ctx = NodeAggregationContext {};\n-\n-                let mut seed_buffer = [0; 32];\n-                seed_buffer[0..4].copy_from_slice(&seed.to_be_bytes());\n-                let mut r = SmallRng::from_seed(seed_buffer);\n-                let mut nodes = Vec::new();\n-                for i in 0..count {\n-                    nodes.push(Node::new(i));\n-                }\n-                aggregation_data(&ctx, &NodeRef(nodes[0].clone()));\n-                aggregation_data(&ctx, &NodeRef(nodes[1].clone()));\n-\n-                // setup graph\n-                for _ in 0..20 {\n-                    let parent = r.random_range(0..nodes.len() - 1);\n-                    let child = r.random_range(parent + 1..nodes.len());\n-                    let parent_node = nodes[parent].clone();\n-                    let child_node = nodes[child].clone();\n-                    parent_node.add_child(&ctx, child_node);\n-                }\n-\n-                let mut edges = Vec::new();\n-                for _ in 0..2 {\n-                    let parent = r.random_range(0..nodes.len() - 1);\n-                    let child = r.random_range(parent + 1..nodes.len());\n-                    let parent_node = nodes[parent].clone();\n-                    let child_node = nodes[child].clone();\n-                    edges.push((parent_node, child_node));\n-                }\n-\n-                let ctx = Arc::new(ctx);\n-\n-                loom::explore();\n-\n-                let mut threads = Vec::new();\n-\n-                // Fancy testing\n-                for (parent_node, child_node) in edges.iter() {\n-                    let parent_node = parent_node.clone();\n-                    let child_node = child_node.clone();\n-                    let ctx = ctx.clone();\n-                    threads.push(\n-                        thread::Builder::new()\n-                            .stack_size(80000)\n-                            .spawn(move || {\n-                                parent_node.add_child(&ctx, child_node);\n-                            })\n-                            .unwrap(),\n-                    );\n-                }\n-\n-                for thread in threads {\n-                    thread.join().unwrap();\n-                }\n-            })\n-            .unwrap()\n-            .join()\n-            .unwrap();\n-    });\n-}"
        },
        {
            "sha": "979fe30f7c58bf0e54de72dec8635b589d85f152",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/lost_edge.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 115,
            "changes": 115,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Flost_edge.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Flost_edge.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Flost_edge.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,115 +0,0 @@\n-use std::hash::Hash;\n-\n-use super::{\n-    AggregationContext, AggregationNode, PreparedInternalOperation, PreparedOperation, StackVec,\n-    balance_queue::BalanceQueue, in_progress::start_in_progress_count,\n-    notify_lost_follower::PreparedNotifyLostFollower,\n-};\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    /// Handles the loss of edges to a node. This will notify all upper nodes\n-    /// about the new follower or add the new node as inner node.\n-    #[must_use]\n-    pub fn handle_lost_edges<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        origin_id: &C::NodeRef,\n-        target_ids: impl IntoIterator<Item = C::NodeRef>,\n-    ) -> Option<PreparedLostEdges<C>> {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => {\n-                let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-                let target_ids: StackVec<_> = target_ids.into_iter().collect();\n-                for upper_id in &uppers {\n-                    start_in_progress_count(ctx, upper_id, target_ids.len() as u32);\n-                }\n-                Some(PreparedLostEdgesInner::Leaf { uppers, target_ids }.into())\n-            }\n-            AggregationNode::Aggegating(_) => {\n-                let notify = target_ids\n-                    .into_iter()\n-                    .filter_map(|target_id| {\n-                        self.notify_lost_follower_not_in_progress(ctx, origin_id, &target_id)\n-                    })\n-                    .collect::<StackVec<_>>();\n-                (!notify.is_empty()).then(|| notify.into())\n-            }\n-        }\n-    }\n-}\n-\n-/// A prepared `handle_lost_edges` operation.\n-pub struct PreparedLostEdges<C: AggregationContext> {\n-    inner: PreparedLostEdgesInner<C>,\n-}\n-\n-impl<C: AggregationContext> From<PreparedLostEdgesInner<C>> for PreparedLostEdges<C> {\n-    fn from(inner: PreparedLostEdgesInner<C>) -> Self {\n-        Self { inner }\n-    }\n-}\n-\n-impl<C: AggregationContext> From<StackVec<PreparedNotifyLostFollower<C>>> for PreparedLostEdges<C> {\n-    fn from(notify: StackVec<PreparedNotifyLostFollower<C>>) -> Self {\n-        Self {\n-            inner: PreparedLostEdgesInner::Aggregating { notify },\n-        }\n-    }\n-}\n-\n-#[allow(clippy::large_enum_variant)]\n-enum PreparedLostEdgesInner<C: AggregationContext> {\n-    Leaf {\n-        uppers: StackVec<C::NodeRef>,\n-        target_ids: StackVec<C::NodeRef>,\n-    },\n-    Aggregating {\n-        notify: StackVec<PreparedNotifyLostFollower<C>>,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedOperation<C> for PreparedLostEdges<C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) {\n-        let mut balance_queue = BalanceQueue::new();\n-        match self.inner {\n-            PreparedLostEdgesInner::Leaf { uppers, target_ids } => {\n-                // TODO This could be more efficient\n-                for upper_id in uppers {\n-                    let mut upper = ctx.node(&upper_id);\n-                    let prepared = target_ids\n-                        .iter()\n-                        .filter_map(|target_id| {\n-                            upper.notify_lost_follower(\n-                                ctx,\n-                                &mut balance_queue,\n-                                &upper_id,\n-                                target_id,\n-                            )\n-                        })\n-                        .collect::<StackVec<_>>();\n-                    drop(upper);\n-                    prepared.apply(ctx, &mut balance_queue);\n-                }\n-            }\n-            PreparedLostEdgesInner::Aggregating { notify } => {\n-                notify.apply(ctx, &mut balance_queue);\n-            }\n-        }\n-        balance_queue.process(ctx);\n-    }\n-}\n-\n-/// Handles the loss of edges to a node. This will notify all upper nodes\n-/// about the new follower or add the new node as inner node.\n-#[cfg(test)]\n-pub fn handle_lost_edges<C: AggregationContext>(\n-    ctx: &C,\n-    mut origin: C::Guard<'_>,\n-    origin_id: &C::NodeRef,\n-    target_ids: impl IntoIterator<Item = C::NodeRef>,\n-) {\n-    let p = origin.handle_lost_edges(ctx, origin_id, target_ids);\n-    drop(origin);\n-    p.apply(ctx);\n-}"
        },
        {
            "sha": "962f64d42a681be4dd8d6277614038113d462308",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/mod.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 260,
            "changes": 260,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fmod.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fmod.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fmod.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,260 +0,0 @@\n-use std::{fmt::Debug, hash::Hash, ops::DerefMut, sync::atomic::AtomicU32};\n-\n-use smallvec::SmallVec;\n-\n-use crate::count_hash_set::CountHashSet;\n-\n-mod aggregation_data;\n-mod balance_edge;\n-mod balance_queue;\n-mod change;\n-mod followers;\n-mod in_progress;\n-mod increase;\n-#[cfg(test)]\n-mod loom_tests;\n-mod lost_edge;\n-mod new_edge;\n-mod notify_lost_follower;\n-mod notify_new_follower;\n-mod optimize;\n-mod root_query;\n-#[cfg(test)]\n-mod tests;\n-mod uppers;\n-mod util;\n-\n-pub use aggregation_data::{AggregationDataGuard, aggregation_data};\n-use balance_edge::balance_edge;\n-use increase::increase_aggregation_number_internal;\n-pub use new_edge::handle_new_edge;\n-use notify_new_follower::notify_new_follower;\n-pub use root_query::{RootQuery, query_root_info};\n-\n-use self::balance_queue::BalanceQueue;\n-\n-type StackVec<I> = SmallVec<[I; 16]>;\n-\n-/// The aggregation node structure. This stores the aggregation number, the\n-/// aggregation edges to uppers and followers and the aggregated data.\n-pub enum AggregationNode<I, D> {\n-    Leaf {\n-        aggregation_number: u8,\n-        uppers: CountHashSet<I>,\n-    },\n-    Aggegating(Box<AggegatingNode<I, D>>),\n-}\n-\n-/// The aggregation node structure for aggregating nodes.\n-pub struct AggegatingNode<I, D> {\n-    aggregation_number: u32,\n-    uppers: CountHashSet<I>,\n-    followers: CountHashSet<I>,\n-    data: D,\n-    enqueued_balancing: Vec<(I, I)>,\n-}\n-\n-impl<I, A> AggregationNode<I, A> {\n-    pub fn new() -> Self {\n-        Self::Leaf {\n-            aggregation_number: 0,\n-            uppers: CountHashSet::new(),\n-        }\n-    }\n-\n-    pub fn shrink_to_fit(&mut self)\n-    where\n-        I: Hash + Eq,\n-    {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => uppers.shrink_to_fit(),\n-            AggregationNode::Aggegating(aggregating) => {\n-                aggregating.uppers.shrink_to_fit();\n-                aggregating.followers.shrink_to_fit();\n-            }\n-        }\n-    }\n-\n-    /// Returns the aggregation number of the node.\n-    pub fn aggregation_number(&self) -> u32 {\n-        match self {\n-            AggregationNode::Leaf {\n-                aggregation_number, ..\n-            } => *aggregation_number as u32,\n-            AggregationNode::Aggegating(aggregating) => aggregating.aggregation_number,\n-        }\n-    }\n-\n-    fn is_leaf(&self) -> bool {\n-        matches!(self, AggregationNode::Leaf { .. })\n-    }\n-\n-    fn uppers(&self) -> &CountHashSet<I> {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => uppers,\n-            AggregationNode::Aggegating(aggregating) => &aggregating.uppers,\n-        }\n-    }\n-\n-    fn uppers_mut(&mut self) -> &mut CountHashSet<I> {\n-        match self {\n-            AggregationNode::Leaf { uppers, .. } => uppers,\n-            AggregationNode::Aggegating(aggregating) => &mut aggregating.uppers,\n-        }\n-    }\n-\n-    fn followers(&self) -> Option<&CountHashSet<I>> {\n-        match self {\n-            AggregationNode::Leaf { .. } => None,\n-            AggregationNode::Aggegating(aggregating) => Some(&aggregating.followers),\n-        }\n-    }\n-\n-    fn followers_mut(&mut self) -> Option<&mut CountHashSet<I>> {\n-        match self {\n-            AggregationNode::Leaf { .. } => None,\n-            AggregationNode::Aggegating(aggregating) => Some(&mut aggregating.followers),\n-        }\n-    }\n-}\n-\n-/// A prepared operation. Must be applied outside of node locks.\n-#[must_use]\n-pub trait PreparedOperation<C: AggregationContext> {\n-    type Result;\n-    fn apply(self, ctx: &C) -> Self::Result;\n-}\n-\n-impl<C: AggregationContext, T: PreparedOperation<C>> PreparedOperation<C> for Option<T> {\n-    type Result = Option<T::Result>;\n-    fn apply(self, ctx: &C) -> Self::Result {\n-        self.map(|prepared| prepared.apply(ctx))\n-    }\n-}\n-\n-impl<C: AggregationContext, T: PreparedOperation<C>> PreparedOperation<C> for Vec<T> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) -> Self::Result {\n-        for prepared in self {\n-            prepared.apply(ctx);\n-        }\n-    }\n-}\n-\n-impl<C: AggregationContext, T: PreparedOperation<C>, const N: usize> PreparedOperation<C>\n-    for SmallVec<[T; N]>\n-{\n-    type Result = ();\n-    fn apply(self, ctx: &C) -> Self::Result {\n-        for prepared in self {\n-            prepared.apply(ctx);\n-        }\n-    }\n-}\n-\n-/// A prepared internal operation. Must be applied inside of node locks and with\n-/// a balance queue.\n-#[must_use]\n-trait PreparedInternalOperation<C: AggregationContext> {\n-    type Result;\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) -> Self::Result;\n-}\n-\n-impl<C: AggregationContext, T: PreparedInternalOperation<C>> PreparedInternalOperation<C>\n-    for Option<T>\n-{\n-    type Result = Option<T::Result>;\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) -> Self::Result {\n-        self.map(|prepared| prepared.apply(ctx, balance_queue))\n-    }\n-}\n-\n-impl<C: AggregationContext, T: PreparedInternalOperation<C>> PreparedInternalOperation<C>\n-    for Vec<T>\n-{\n-    type Result = ();\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) -> Self::Result {\n-        for prepared in self {\n-            prepared.apply(ctx, balance_queue);\n-        }\n-    }\n-}\n-\n-impl<C: AggregationContext, T: PreparedInternalOperation<C>, const N: usize>\n-    PreparedInternalOperation<C> for SmallVec<[T; N]>\n-{\n-    type Result = ();\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) -> Self::Result {\n-        for prepared in self {\n-            prepared.apply(ctx, balance_queue);\n-        }\n-    }\n-}\n-\n-/// Context for aggregation operations.\n-pub trait AggregationContext {\n-    type NodeRef: Clone + Eq + Hash + Debug + 'static;\n-    type Guard<'l>: AggregationNodeGuard<\n-            NodeRef = Self::NodeRef,\n-            Data = Self::Data,\n-            DataChange = Self::DataChange,\n-        >\n-    where\n-        Self: 'l;\n-    type Data: 'static;\n-    type DataChange: 'static;\n-\n-    /// Gets mutable access to an item.\n-    fn node<'l>(&'l self, id: &Self::NodeRef) -> Self::Guard<'l>;\n-\n-    /// Gets mutable access to two items.\n-    fn node_pair<'l>(\n-        &'l self,\n-        id1: &Self::NodeRef,\n-        id2: &Self::NodeRef,\n-    ) -> (Self::Guard<'l>, Self::Guard<'l>);\n-\n-    /// Get the atomic in progress counter for a node.\n-    fn atomic_in_progress_counter<'l>(&self, id: &'l Self::NodeRef) -> &'l AtomicU32\n-    where\n-        Self: 'l;\n-\n-    /// Apply a changeset to an aggregated data object. Returns a new changeset\n-    /// that should be applied to the next aggregation level. Might return None,\n-    /// if no change should be applied to the next level.\n-    fn apply_change(\n-        &self,\n-        data: &mut Self::Data,\n-        change: &Self::DataChange,\n-    ) -> Option<Self::DataChange>;\n-\n-    /// Creates a changeset from an aggregated data object, that represents\n-    /// adding the aggregated node to an aggregated node of the next level.\n-    fn data_to_add_change(&self, data: &Self::Data) -> Option<Self::DataChange>;\n-    /// Creates a changeset from an aggregated data object, that represents\n-    /// removing the aggregated node from an aggregated node of the next level.\n-    fn data_to_remove_change(&self, data: &Self::Data) -> Option<Self::DataChange>;\n-}\n-\n-/// A guard for a node that allows to access the aggregation node, children and\n-/// data.\n-pub trait AggregationNodeGuard:\n-    DerefMut<Target = AggregationNode<Self::NodeRef, Self::Data>>\n-{\n-    type NodeRef: Clone + Eq + Hash;\n-    type Data;\n-    type DataChange;\n-\n-    type ChildrenIter<'a>: Iterator<Item = Self::NodeRef> + 'a\n-    where\n-        Self: 'a;\n-\n-    /// Returns an iterator over the children.\n-    fn children(&self) -> Self::ChildrenIter<'_>;\n-    /// Returns a changeset that represents the addition of the node.\n-    fn get_add_change(&self) -> Option<Self::DataChange>;\n-    /// Returns a changeset that represents the removal of the node.\n-    fn get_remove_change(&self) -> Option<Self::DataChange>;\n-    /// Returns the aggregated data which contains only that node\n-    fn get_initial_data(&self) -> Self::Data;\n-}"
        },
        {
            "sha": "1b13c848ff476953a7355f2263ba7b9a6c2770e7",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/new_edge.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 173,
            "changes": 173,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnew_edge.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnew_edge.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnew_edge.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,173 +0,0 @@\n-use super::{\n-    AggregationContext, AggregationNode, PreparedInternalOperation, PreparedOperation, StackVec,\n-    balance_queue::BalanceQueue,\n-    in_progress::start_in_progress_all,\n-    increase::{\n-        IncreaseReason, LEAF_NUMBER, PreparedInternalIncreaseAggregationNumber,\n-        increase_aggregation_number_immediately,\n-    },\n-    increase_aggregation_number_internal, notify_new_follower,\n-    notify_new_follower::PreparedNotifyNewFollower,\n-    optimize::optimize_aggregation_number_for_uppers,\n-};\n-\n-const BUFFER_SPACE: u32 = 2;\n-\n-const MAX_UPPERS_TIMES_CHILDREN: usize = 32;\n-\n-const MAX_AFFECTED_NODES: usize = 4096;\n-\n-/// Handle the addition of a new edge to a node. The edge is propagated to\n-/// the uppers of that node or added a inner node.\n-pub fn handle_new_edge<C: AggregationContext>(\n-    ctx: &C,\n-    origin: &mut C::Guard<'_>,\n-    origin_id: &C::NodeRef,\n-    target_id: &C::NodeRef,\n-    number_of_children: usize,\n-) -> impl PreparedOperation<C> + use<C> {\n-    match **origin {\n-        AggregationNode::Leaf {\n-            ref mut aggregation_number,\n-            ref uppers,\n-        } => {\n-            if number_of_children.is_power_of_two()\n-                && (uppers.len() + 1) * number_of_children >= MAX_UPPERS_TIMES_CHILDREN\n-            {\n-                let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-                start_in_progress_all(ctx, &uppers);\n-                let increase = increase_aggregation_number_immediately(\n-                    ctx,\n-                    origin,\n-                    origin_id.clone(),\n-                    LEAF_NUMBER,\n-                    LEAF_NUMBER,\n-                    IncreaseReason::Upgraded,\n-                )\n-                .unwrap();\n-                Some(PreparedNewEdge::Upgraded {\n-                    uppers,\n-                    target_id: target_id.clone(),\n-                    increase,\n-                })\n-            } else {\n-                let min_aggregation_number = *aggregation_number as u32 + 1;\n-                let target_aggregation_number = *aggregation_number as u32 + 1 + BUFFER_SPACE;\n-                let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-                start_in_progress_all(ctx, &uppers);\n-                Some(PreparedNewEdge::Leaf {\n-                    min_aggregation_number,\n-                    target_aggregation_number,\n-                    uppers,\n-                    target_id: target_id.clone(),\n-                })\n-            }\n-        }\n-        AggregationNode::Aggegating(_) => origin\n-            .notify_new_follower_not_in_progress(ctx, origin_id, target_id)\n-            .map(|notify| PreparedNewEdge::Aggegating {\n-                target_id: target_id.clone(),\n-                notify,\n-            }),\n-    }\n-}\n-\n-/// A prepared `handle_new_edge` operation.\n-enum PreparedNewEdge<C: AggregationContext> {\n-    Leaf {\n-        min_aggregation_number: u32,\n-        target_aggregation_number: u32,\n-        uppers: StackVec<C::NodeRef>,\n-        target_id: C::NodeRef,\n-    },\n-    Upgraded {\n-        uppers: StackVec<C::NodeRef>,\n-        target_id: C::NodeRef,\n-        increase: PreparedInternalIncreaseAggregationNumber<C>,\n-    },\n-    Aggegating {\n-        notify: PreparedNotifyNewFollower<C>,\n-        target_id: C::NodeRef,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedOperation<C> for PreparedNewEdge<C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C) {\n-        let mut balance_queue = BalanceQueue::new();\n-        match self {\n-            PreparedNewEdge::Leaf {\n-                min_aggregation_number,\n-                target_aggregation_number,\n-                uppers,\n-                target_id,\n-            } => {\n-                increase_aggregation_number_internal(\n-                    ctx,\n-                    &mut balance_queue,\n-                    ctx.node(&target_id),\n-                    &target_id,\n-                    min_aggregation_number,\n-                    target_aggregation_number,\n-                    IncreaseReason::LeafEdge,\n-                );\n-                let mut affected_nodes = 0;\n-                for upper_id in uppers {\n-                    affected_nodes += notify_new_follower(\n-                        ctx,\n-                        &mut balance_queue,\n-                        ctx.node(&upper_id),\n-                        &upper_id,\n-                        &target_id,\n-                        false,\n-                    );\n-                    if affected_nodes > MAX_AFFECTED_NODES {\n-                        handle_expensive_node(ctx, &mut balance_queue, &target_id);\n-                    }\n-                }\n-            }\n-            PreparedNewEdge::Upgraded {\n-                uppers,\n-                target_id,\n-                increase,\n-            } => {\n-                // Since it was added to a leaf node, we would add it to the uppers\n-                for upper_id in uppers {\n-                    notify_new_follower(\n-                        ctx,\n-                        &mut balance_queue,\n-                        ctx.node(&upper_id),\n-                        &upper_id,\n-                        &target_id,\n-                        true,\n-                    );\n-                }\n-                // The balancing will attach it to the aggregated node later\n-                increase.apply(ctx, &mut balance_queue);\n-            }\n-            PreparedNewEdge::Aggegating { target_id, notify } => {\n-                let affected_nodes = notify.apply(ctx, &mut balance_queue);\n-                if affected_nodes > MAX_AFFECTED_NODES {\n-                    handle_expensive_node(ctx, &mut balance_queue, &target_id);\n-                }\n-            }\n-        }\n-        balance_queue.process(ctx);\n-    }\n-}\n-\n-/// Called in the case when we detect that adding this node was expensive. It\n-/// optimizes the aggregation number of the node so it can be cheaper on the\n-/// next call.\n-fn handle_expensive_node<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    node_id: &C::NodeRef,\n-) {\n-    let _span = tracing::trace_span!(\"handle_expensive_node\").entered();\n-    let node = ctx.node(node_id);\n-    let uppers = node.uppers().iter().cloned().collect::<StackVec<_>>();\n-    let leaf = matches!(*node, AggregationNode::Leaf { .. });\n-    drop(node);\n-    optimize_aggregation_number_for_uppers(ctx, balance_queue, node_id, leaf, uppers);\n-}"
        },
        {
            "sha": "7130080567450d30dba20b2398f31c78df05634c",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/notify_lost_follower.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 211,
            "changes": 211,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_lost_follower.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_lost_follower.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_lost_follower.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,211 +0,0 @@\n-use std::{hash::Hash, thread::yield_now};\n-\n-use super::{\n-    AggegatingNode, AggregationContext, AggregationNode, AggregationNodeGuard,\n-    PreparedInternalOperation, PreparedOperation, StackVec,\n-    balance_queue::BalanceQueue,\n-    in_progress::{finish_in_progress_without_node, start_in_progress, start_in_progress_all},\n-    util::get_aggregated_remove_change,\n-};\n-use crate::count_hash_set::RemoveIfEntryResult;\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    /// Called when a inner node of the upper node has lost a follower\n-    /// It's expected that the upper node is flagged as \"in progress\".\n-    pub(super) fn notify_lost_follower<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        balance_queue: &mut BalanceQueue<I>,\n-        upper_id: &C::NodeRef,\n-        follower_id: &C::NodeRef,\n-    ) -> Option<PreparedNotifyLostFollower<C>> {\n-        let AggregationNode::Aggegating(aggregating) = self else {\n-            unreachable!();\n-        };\n-        match aggregating.followers.remove_if_entry(follower_id) {\n-            RemoveIfEntryResult::PartiallyRemoved => {\n-                self.finish_in_progress(ctx, balance_queue, upper_id);\n-                None\n-            }\n-            RemoveIfEntryResult::Removed => {\n-                aggregating.followers.shrink_amortized();\n-                let uppers = aggregating.uppers.iter().cloned().collect::<StackVec<_>>();\n-                start_in_progress_all(ctx, &uppers);\n-                self.finish_in_progress(ctx, balance_queue, upper_id);\n-                Some(PreparedNotifyLostFollower::RemovedFollower {\n-                    uppers,\n-                    follower_id: follower_id.clone(),\n-                })\n-            }\n-            RemoveIfEntryResult::NotPresent => Some(PreparedNotifyLostFollower::NotFollower {\n-                upper_id: upper_id.clone(),\n-                follower_id: follower_id.clone(),\n-            }),\n-        }\n-    }\n-\n-    /// Called when a inner node of the upper node has lost a follower.\n-    /// It's expected that the upper node is NOT flagged as \"in progress\".\n-    pub(super) fn notify_lost_follower_not_in_progress<\n-        C: AggregationContext<NodeRef = I, Data = D>,\n-    >(\n-        &mut self,\n-        ctx: &C,\n-        upper_id: &C::NodeRef,\n-        follower_id: &C::NodeRef,\n-    ) -> Option<PreparedNotifyLostFollower<C>> {\n-        let AggregationNode::Aggegating(aggregating) = self else {\n-            unreachable!();\n-        };\n-        match aggregating.followers.remove_if_entry(follower_id) {\n-            RemoveIfEntryResult::PartiallyRemoved => None,\n-            RemoveIfEntryResult::Removed => {\n-                aggregating.followers.shrink_amortized();\n-                let uppers = aggregating.uppers.iter().cloned().collect::<StackVec<_>>();\n-                start_in_progress_all(ctx, &uppers);\n-                Some(PreparedNotifyLostFollower::RemovedFollower {\n-                    uppers,\n-                    follower_id: follower_id.clone(),\n-                })\n-            }\n-            RemoveIfEntryResult::NotPresent => {\n-                start_in_progress(ctx, upper_id);\n-                Some(PreparedNotifyLostFollower::NotFollower {\n-                    upper_id: upper_id.clone(),\n-                    follower_id: follower_id.clone(),\n-                })\n-            }\n-        }\n-    }\n-}\n-\n-/// A prepared `notify_lost_follower` operation.\n-pub(super) enum PreparedNotifyLostFollower<C: AggregationContext> {\n-    RemovedFollower {\n-        uppers: StackVec<C::NodeRef>,\n-        follower_id: C::NodeRef,\n-    },\n-    NotFollower {\n-        upper_id: C::NodeRef,\n-        follower_id: C::NodeRef,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedInternalOperation<C> for PreparedNotifyLostFollower<C> {\n-    type Result = ();\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) {\n-        match self {\n-            PreparedNotifyLostFollower::RemovedFollower {\n-                uppers,\n-                follower_id,\n-            } => {\n-                for upper_id in uppers {\n-                    notify_lost_follower(\n-                        ctx,\n-                        balance_queue,\n-                        ctx.node(&upper_id),\n-                        &upper_id,\n-                        &follower_id,\n-                    );\n-                }\n-            }\n-            PreparedNotifyLostFollower::NotFollower {\n-                upper_id,\n-                follower_id,\n-            } => {\n-                loop {\n-                    let mut follower = ctx.node(&follower_id);\n-                    match follower.uppers_mut().remove_if_entry(&upper_id) {\n-                        RemoveIfEntryResult::PartiallyRemoved => {\n-                            finish_in_progress_without_node(ctx, balance_queue, &upper_id);\n-                            drop(follower);\n-                            return;\n-                        }\n-                        RemoveIfEntryResult::Removed => {\n-                            let remove_change = get_aggregated_remove_change(ctx, &follower);\n-                            let followers = match &*follower {\n-                                AggregationNode::Leaf { .. } => {\n-                                    follower.children().collect::<StackVec<_>>()\n-                                }\n-                                AggregationNode::Aggegating(aggregating) => {\n-                                    let AggegatingNode { ref followers, .. } = **aggregating;\n-                                    followers.iter().cloned().collect::<StackVec<_>>()\n-                                }\n-                            };\n-                            drop(follower);\n-\n-                            let mut upper = ctx.node(&upper_id);\n-                            let remove_change = remove_change\n-                                .map(|remove_change| upper.apply_change(ctx, remove_change));\n-                            let prepared = followers\n-                                .into_iter()\n-                                .filter_map(|follower_id| {\n-                                    upper.notify_lost_follower_not_in_progress(\n-                                        ctx,\n-                                        &upper_id,\n-                                        &follower_id,\n-                                    )\n-                                })\n-                                .collect::<StackVec<_>>();\n-                            upper.finish_in_progress(ctx, balance_queue, &upper_id);\n-                            drop(upper);\n-                            prepared.apply(ctx, balance_queue);\n-                            remove_change.apply(ctx);\n-                            return;\n-                        }\n-                        RemoveIfEntryResult::NotPresent => {\n-                            drop(follower);\n-                            let mut upper = ctx.node(&upper_id);\n-                            let AggregationNode::Aggegating(aggregating) = &mut *upper else {\n-                                unreachable!();\n-                            };\n-                            match aggregating.followers.remove_if_entry(&follower_id) {\n-                                RemoveIfEntryResult::PartiallyRemoved => {\n-                                    upper.finish_in_progress(ctx, balance_queue, &upper_id);\n-                                    return;\n-                                }\n-                                RemoveIfEntryResult::Removed => {\n-                                    aggregating.followers.shrink_amortized();\n-                                    let uppers =\n-                                        aggregating.uppers.iter().cloned().collect::<StackVec<_>>();\n-                                    start_in_progress_all(ctx, &uppers);\n-                                    upper.finish_in_progress(ctx, balance_queue, &upper_id);\n-                                    drop(upper);\n-                                    for upper_id in uppers {\n-                                        notify_lost_follower(\n-                                            ctx,\n-                                            balance_queue,\n-                                            ctx.node(&upper_id),\n-                                            &upper_id,\n-                                            &follower_id,\n-                                        );\n-                                    }\n-                                    return;\n-                                }\n-                                RemoveIfEntryResult::NotPresent => {\n-                                    drop(upper);\n-                                    yield_now()\n-                                    // Retry, concurrency\n-                                }\n-                            }\n-                        }\n-                    }\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-/// Notifies the upper node that a follower has been lost.\n-/// It's expected that the upper node is flagged as \"in progress\".\n-pub fn notify_lost_follower<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut upper: C::Guard<'_>,\n-    upper_id: &C::NodeRef,\n-    follower_id: &C::NodeRef,\n-) {\n-    let p = upper.notify_lost_follower(ctx, balance_queue, upper_id, follower_id);\n-    drop(upper);\n-    p.apply(ctx, balance_queue);\n-}"
        },
        {
            "sha": "4b41cbf6e813346ef744b46422131c1c4da9a4da",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/notify_new_follower.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 252,
            "changes": 252,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_new_follower.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_new_follower.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fnotify_new_follower.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,252 +0,0 @@\n-use std::{cmp::Ordering, hash::Hash};\n-\n-use super::{\n-    AggregationContext, AggregationNode, PreparedInternalOperation, StackVec,\n-    balance_queue::BalanceQueue,\n-    followers::add_follower,\n-    in_progress::{finish_in_progress_without_node, start_in_progress},\n-    increase::IncreaseReason,\n-    increase_aggregation_number_internal,\n-    optimize::optimize_aggregation_number_for_uppers,\n-    uppers::add_upper,\n-};\n-\n-const MAX_AFFECTED_NODES: usize = 4096;\n-\n-impl<I: Clone + Eq + Hash, D> AggregationNode<I, D> {\n-    // Called when a inner node of the upper node has a new follower.\n-    // It's expected that the upper node is flagged as \"in progress\".\n-    pub(super) fn notify_new_follower<C: AggregationContext<NodeRef = I, Data = D>>(\n-        &mut self,\n-        ctx: &C,\n-        balance_queue: &mut BalanceQueue<I>,\n-        upper_id: &C::NodeRef,\n-        follower_id: &C::NodeRef,\n-        already_optimizing_for_upper: bool,\n-    ) -> Option<PreparedNotifyNewFollower<C>> {\n-        let AggregationNode::Aggegating(aggregating) = self else {\n-            unreachable!();\n-        };\n-        if aggregating.followers.add_if_entry(follower_id) {\n-            self.finish_in_progress(ctx, balance_queue, upper_id);\n-            None\n-        } else {\n-            let upper_aggregation_number = aggregating.aggregation_number;\n-            if upper_aggregation_number == u32::MAX {\n-                Some(PreparedNotifyNewFollower::Inner {\n-                    upper_id: upper_id.clone(),\n-                    follower_id: follower_id.clone(),\n-                    already_optimizing_for_upper,\n-                })\n-            } else {\n-                Some(PreparedNotifyNewFollower::FollowerOrInner {\n-                    upper_aggregation_number,\n-                    upper_id: upper_id.clone(),\n-                    follower_id: follower_id.clone(),\n-                    already_optimizing_for_upper,\n-                })\n-            }\n-        }\n-    }\n-\n-    // Called when a inner node of the upper node has a new follower.\n-    // It's expected that the upper node is NOT flagged as \"in progress\".\n-    pub(super) fn notify_new_follower_not_in_progress<\n-        C: AggregationContext<NodeRef = I, Data = D>,\n-    >(\n-        &mut self,\n-        ctx: &C,\n-        upper_id: &C::NodeRef,\n-        follower_id: &C::NodeRef,\n-    ) -> Option<PreparedNotifyNewFollower<C>> {\n-        let AggregationNode::Aggegating(aggregating) = self else {\n-            unreachable!();\n-        };\n-        if aggregating.followers.add_if_entry(follower_id) {\n-            None\n-        } else {\n-            start_in_progress(ctx, upper_id);\n-            let upper_aggregation_number = aggregating.aggregation_number;\n-            if upper_aggregation_number == u32::MAX {\n-                Some(PreparedNotifyNewFollower::Inner {\n-                    upper_id: upper_id.clone(),\n-                    follower_id: follower_id.clone(),\n-                    already_optimizing_for_upper: false,\n-                })\n-            } else {\n-                Some(PreparedNotifyNewFollower::FollowerOrInner {\n-                    upper_aggregation_number,\n-                    upper_id: upper_id.clone(),\n-                    follower_id: follower_id.clone(),\n-                    already_optimizing_for_upper: false,\n-                })\n-            }\n-        }\n-    }\n-}\n-\n-/// A prepared `notify_new_follower` operation.\n-pub(super) enum PreparedNotifyNewFollower<C: AggregationContext> {\n-    Inner {\n-        upper_id: C::NodeRef,\n-        follower_id: C::NodeRef,\n-        already_optimizing_for_upper: bool,\n-    },\n-    FollowerOrInner {\n-        upper_aggregation_number: u32,\n-        upper_id: C::NodeRef,\n-        follower_id: C::NodeRef,\n-        already_optimizing_for_upper: bool,\n-    },\n-}\n-\n-impl<C: AggregationContext> PreparedInternalOperation<C> for PreparedNotifyNewFollower<C> {\n-    type Result = usize;\n-    fn apply(self, ctx: &C, balance_queue: &mut BalanceQueue<C::NodeRef>) -> Self::Result {\n-        match self {\n-            PreparedNotifyNewFollower::Inner {\n-                upper_id,\n-                follower_id,\n-                already_optimizing_for_upper,\n-            } => {\n-                let follower = ctx.node(&follower_id);\n-                let affected_nodes = add_upper(\n-                    ctx,\n-                    balance_queue,\n-                    follower,\n-                    &follower_id,\n-                    &upper_id,\n-                    already_optimizing_for_upper,\n-                );\n-                finish_in_progress_without_node(ctx, balance_queue, &upper_id);\n-                if !already_optimizing_for_upper && affected_nodes > MAX_AFFECTED_NODES {\n-                    let follower = ctx.node(&follower_id);\n-                    let uppers = follower.uppers().iter().cloned().collect::<StackVec<_>>();\n-                    let leaf: bool = follower.is_leaf();\n-                    drop(follower);\n-                    if optimize_aggregation_number_for_uppers(\n-                        ctx,\n-                        balance_queue,\n-                        &follower_id,\n-                        leaf,\n-                        uppers,\n-                    ) {\n-                        return 1;\n-                    }\n-                }\n-                affected_nodes\n-            }\n-            PreparedNotifyNewFollower::FollowerOrInner {\n-                mut upper_aggregation_number,\n-                upper_id,\n-                follower_id,\n-                already_optimizing_for_upper,\n-            } => loop {\n-                let follower = ctx.node(&follower_id);\n-                let follower_aggregation_number = follower.aggregation_number();\n-                if follower_aggregation_number < upper_aggregation_number {\n-                    let affected_nodes = add_upper(\n-                        ctx,\n-                        balance_queue,\n-                        follower,\n-                        &follower_id,\n-                        &upper_id,\n-                        already_optimizing_for_upper,\n-                    );\n-                    finish_in_progress_without_node(ctx, balance_queue, &upper_id);\n-                    if !already_optimizing_for_upper && affected_nodes > MAX_AFFECTED_NODES {\n-                        let follower = ctx.node(&follower_id);\n-                        let uppers = follower.uppers().iter().cloned().collect::<StackVec<_>>();\n-                        let leaf = follower.is_leaf();\n-                        drop(follower);\n-                        if optimize_aggregation_number_for_uppers(\n-                            ctx,\n-                            balance_queue,\n-                            &follower_id,\n-                            leaf,\n-                            uppers,\n-                        ) {\n-                            return 1;\n-                        }\n-                    }\n-                    return affected_nodes;\n-                } else {\n-                    drop(follower);\n-                    let mut upper = ctx.node(&upper_id);\n-                    let AggregationNode::Aggegating(aggregating) = &mut *upper else {\n-                        unreachable!();\n-                    };\n-                    upper_aggregation_number = aggregating.aggregation_number;\n-                    if upper_aggregation_number == u32::MAX {\n-                        // retry, concurrency\n-                    } else {\n-                        match follower_aggregation_number.cmp(&upper_aggregation_number) {\n-                            Ordering::Less => {\n-                                // retry, concurrency\n-                            }\n-                            Ordering::Equal => {\n-                                drop(upper);\n-                                let follower = ctx.node(&follower_id);\n-                                let follower_aggregation_number = follower.aggregation_number();\n-                                if follower_aggregation_number == upper_aggregation_number {\n-                                    if upper_id == follower_id {\n-                                        panic!(\n-                                            \"Cycle in call graph (A function calls itself \\\n-                                             recursively with the same arguments. This will never \\\n-                                             finish and would hang indefinitely.)\"\n-                                        );\n-                                    }\n-                                    increase_aggregation_number_internal(\n-                                        ctx,\n-                                        balance_queue,\n-                                        follower,\n-                                        &follower_id,\n-                                        upper_aggregation_number + 1,\n-                                        upper_aggregation_number + 1,\n-                                        IncreaseReason::EqualAggregationNumberOnNewFollower,\n-                                    );\n-                                    // retry\n-                                } else {\n-                                    // retry, concurrency\n-                                }\n-                            }\n-                            Ordering::Greater => {\n-                                upper.finish_in_progress(ctx, balance_queue, &upper_id);\n-                                return add_follower(\n-                                    ctx,\n-                                    balance_queue,\n-                                    upper,\n-                                    &upper_id,\n-                                    &follower_id,\n-                                    already_optimizing_for_upper,\n-                                );\n-                            }\n-                        }\n-                    }\n-                }\n-            },\n-        }\n-    }\n-}\n-\n-/// Notifies the upper node that it has a new follower.\n-/// Returns the number of affected nodes.\n-/// The upper node is expected to be flagged as \"in progress\".\n-pub fn notify_new_follower<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut upper: C::Guard<'_>,\n-    upper_id: &C::NodeRef,\n-    follower_id: &C::NodeRef,\n-    already_optimizing_for_upper: bool,\n-) -> usize {\n-    let p = upper.notify_new_follower(\n-        ctx,\n-        balance_queue,\n-        upper_id,\n-        follower_id,\n-        already_optimizing_for_upper,\n-    );\n-    drop(upper);\n-    p.apply(ctx, balance_queue).unwrap_or_default()\n-}"
        },
        {
            "sha": "47c0356d47d8d017aabb567594acd084cba7f933",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/optimize.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 146,
            "changes": 146,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Foptimize.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Foptimize.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Foptimize.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,146 +0,0 @@\n-use tracing::Level;\n-\n-use super::{\n-    AggregationContext, StackVec,\n-    balance_queue::BalanceQueue,\n-    increase::{IncreaseReason, LEAF_NUMBER, increase_aggregation_number_internal},\n-};\n-\n-pub const MAX_UPPERS: usize = 512;\n-\n-pub const MAX_FOLLOWERS: usize = 128;\n-\n-/// Optimize the aggregation number for a node based on a list of upper nodes.\n-/// The goal is to reduce the number of upper nodes, so we try to find a\n-/// aggregation number that is higher than some of the upper nodes.\n-/// Returns true if the aggregation number was increased.\n-#[tracing::instrument(level = Level::TRACE, skip(ctx, balance_queue, node_id, uppers))]\n-pub fn optimize_aggregation_number_for_uppers<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    node_id: &C::NodeRef,\n-    leaf: bool,\n-    uppers: StackVec<C::NodeRef>,\n-) -> bool {\n-    let count = uppers.len();\n-    let mut root_count = 0;\n-    let mut min = u32::MAX;\n-    let mut max = 0;\n-    let mut uppers_uppers = 0;\n-    for upper_id in uppers.into_iter() {\n-        let upper = ctx.node(&upper_id);\n-        let aggregation_number = upper.aggregation_number();\n-        if aggregation_number == u32::MAX {\n-            root_count += 1;\n-        } else {\n-            let upper_uppers = upper.uppers().len();\n-            uppers_uppers += upper_uppers;\n-            if aggregation_number < min {\n-                min = aggregation_number;\n-            }\n-            if aggregation_number > max {\n-                max = aggregation_number;\n-            }\n-        }\n-    }\n-    if min == u32::MAX {\n-        min = LEAF_NUMBER - 1;\n-    }\n-    if max < LEAF_NUMBER {\n-        max = LEAF_NUMBER - 1;\n-    }\n-    let aggregation_number = (min + max) / 2 + 1;\n-    if leaf {\n-        increase_aggregation_number_internal(\n-            ctx,\n-            balance_queue,\n-            ctx.node(node_id),\n-            node_id,\n-            aggregation_number,\n-            aggregation_number,\n-            IncreaseReason::OptimizeForUppers,\n-        );\n-        return true;\n-    } else {\n-        let normal_count = count - root_count;\n-        if normal_count > 0 {\n-            let avg_uppers_uppers = uppers_uppers / normal_count;\n-            if count > avg_uppers_uppers && root_count * 2 < count {\n-                increase_aggregation_number_internal(\n-                    ctx,\n-                    balance_queue,\n-                    ctx.node(node_id),\n-                    node_id,\n-                    aggregation_number,\n-                    aggregation_number,\n-                    IncreaseReason::OptimizeForUppers,\n-                );\n-                return true;\n-            }\n-        }\n-    }\n-    false\n-}\n-\n-/// Optimize the aggregation number for a node based on a list of followers.\n-/// The goal is to reduce the number of followers, so we try to find a\n-/// aggregation number that is higher than some of the followers.\n-/// Returns true if the aggregation number was increased.\n-#[tracing::instrument(level = Level::TRACE, skip(ctx, balance_queue, node_id, followers))]\n-pub fn optimize_aggregation_number_for_followers<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    node_id: &C::NodeRef,\n-    followers: StackVec<C::NodeRef>,\n-    force: bool,\n-) -> bool {\n-    let count = followers.len();\n-    let mut root_count = 0;\n-    let mut min = u32::MAX;\n-    let mut max = 0;\n-    let mut followers_followers = 0;\n-    for follower_id in followers.into_iter() {\n-        let follower = ctx.node(&follower_id);\n-        let aggregation_number = follower.aggregation_number();\n-        if aggregation_number == u32::MAX {\n-            root_count += 1;\n-        } else {\n-            let follower_followers = follower.followers().map_or(0, |f| f.len());\n-            followers_followers += follower_followers;\n-            if aggregation_number < min {\n-                min = aggregation_number;\n-            }\n-            if aggregation_number > max {\n-                max = aggregation_number;\n-            }\n-        }\n-    }\n-    if min == u32::MAX {\n-        min = LEAF_NUMBER - 1;\n-    }\n-    if min < LEAF_NUMBER {\n-        min = LEAF_NUMBER - 1;\n-    }\n-    if max < min {\n-        max = min;\n-    }\n-    let normal_count = count - root_count;\n-    if normal_count > 0 {\n-        let avg_followers_followers = followers_followers / normal_count;\n-        let makes_sense = count > avg_followers_followers || force;\n-        if makes_sense && root_count * 2 < count {\n-            let aggregation_number = (min + max) / 2 + 1;\n-            increase_aggregation_number_internal(\n-                ctx,\n-                balance_queue,\n-                ctx.node(node_id),\n-                node_id,\n-                aggregation_number,\n-                aggregation_number,\n-                IncreaseReason::OptimizeForFollowers,\n-            );\n-            return true;\n-        }\n-    }\n-    false\n-}"
        },
        {
            "sha": "74cacffb6961a39e254b8f034f99da042b0cf6be",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/root_query.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 51,
            "changes": 51,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Froot_query.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Froot_query.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Froot_query.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,51 +0,0 @@\n-use std::ops::ControlFlow;\n-\n-use auto_hash_map::AutoSet;\n-\n-use super::{AggregationContext, AggregationNode, StackVec};\n-\n-/// A query about aggregation data in a root node.\n-pub trait RootQuery {\n-    type Data;\n-    type Result;\n-\n-    /// Processes the aggregated data of a root node. Can decide to stop the\n-    /// query.\n-    fn query(&mut self, data: &Self::Data) -> ControlFlow<()>;\n-    /// Returns the result of the query.\n-    fn result(self) -> Self::Result;\n-}\n-\n-/// Queries the root node of an aggregation tree.\n-pub fn query_root_info<C: AggregationContext, Q: RootQuery<Data = C::Data>>(\n-    ctx: &C,\n-    mut query: Q,\n-    node_id: C::NodeRef,\n-) -> Q::Result {\n-    let mut queue = StackVec::new();\n-    queue.push(node_id);\n-    let mut visited = AutoSet::new();\n-    while let Some(node_id) = queue.pop() {\n-        let node = ctx.node(&node_id);\n-        match &*node {\n-            AggregationNode::Leaf { uppers, .. } => {\n-                for upper_id in uppers.iter() {\n-                    if visited.insert(upper_id.clone()) {\n-                        queue.push(upper_id.clone());\n-                    }\n-                }\n-            }\n-            AggregationNode::Aggegating(aggegrating) => {\n-                if let ControlFlow::Break(_) = query.query(&aggegrating.data) {\n-                    return query.result();\n-                }\n-                for upper_id in aggegrating.uppers.iter() {\n-                    if visited.insert(upper_id.clone()) {\n-                        queue.push(upper_id.clone());\n-                    }\n-                }\n-            }\n-        }\n-    }\n-    query.result()\n-}"
        },
        {
            "sha": "7cf70e45d3fca3a0e7e1d8a9b9ba7d6c819738df",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/tests.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1088,
            "changes": 1088,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ftests.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ftests.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Ftests.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,1088 +0,0 @@\n-use std::{\n-    fmt::Debug,\n-    hash::Hash,\n-    iter::once,\n-    ops::{ControlFlow, Deref, DerefMut},\n-    sync::{\n-        Arc,\n-        atomic::{AtomicU32, Ordering},\n-    },\n-    time::Instant,\n-};\n-\n-use parking_lot::{Mutex, MutexGuard};\n-use rand::{Rng, SeedableRng, rngs::SmallRng};\n-use ref_cast::RefCast;\n-use rstest::*;\n-use rustc_hash::FxHashSet;\n-use turbo_tasks::FxIndexSet;\n-\n-use self::aggregation_data::prepare_aggregation_data;\n-use super::{\n-    AggregationContext, AggregationNode, AggregationNodeGuard, RootQuery, aggregation_data,\n-    handle_new_edge, lost_edge::handle_lost_edges,\n-};\n-use crate::aggregation::{PreparedOperation, StackVec, query_root_info};\n-\n-fn find_root(mut node: NodeRef) -> NodeRef {\n-    loop {\n-        let lock = node.0.inner.lock();\n-        let uppers = lock.aggregation_node.uppers();\n-        if uppers.is_empty() {\n-            drop(lock);\n-            return node;\n-        }\n-        let upper = uppers.iter().next().unwrap().clone();\n-        drop(lock);\n-        node = upper;\n-    }\n-}\n-\n-fn check_invariants(ctx: &NodeAggregationContext<'_>, node_ids: impl IntoIterator<Item = NodeRef>) {\n-    let mut queue = node_ids.into_iter().collect::<Vec<_>>();\n-    // print(ctx, &queue[0], true);\n-    #[allow(clippy::mutable_key_type, reason = \"this is a test\")]\n-    let mut visited = FxHashSet::default();\n-    while let Some(node_id) = queue.pop() {\n-        assert_eq!(node_id.0.atomic.load(Ordering::SeqCst), 0);\n-        let node = ctx.node(&node_id);\n-        for child_id in node.children() {\n-            if visited.insert(child_id.clone()) {\n-                queue.push(child_id.clone());\n-            }\n-        }\n-\n-        let aggregation_number = node.aggregation_number();\n-        let node_value = node.guard.value;\n-        let uppers = match &*node {\n-            AggregationNode::Leaf { uppers, .. } => {\n-                let uppers = uppers.iter().cloned().collect::<StackVec<_>>();\n-                drop(node);\n-                uppers\n-            }\n-            AggregationNode::Aggegating(aggegrating) => {\n-                let uppers = aggegrating.uppers.iter().cloned().collect::<StackVec<_>>();\n-                let followers = aggegrating\n-                    .followers\n-                    .iter()\n-                    .cloned()\n-                    .collect::<StackVec<_>>();\n-                drop(node);\n-                for follower_id in followers {\n-                    let follower_aggregation_number;\n-                    let follower_uppers;\n-                    let follower_value;\n-                    {\n-                        let follower = ctx.node(&follower_id);\n-\n-                        follower_aggregation_number = follower.aggregation_number();\n-                        follower_uppers =\n-                            follower.uppers().iter().cloned().collect::<StackVec<_>>();\n-                        follower_value = follower.guard.value;\n-                    }\n-\n-                    // A follower should have a bigger aggregation number\n-                    let condition = follower_aggregation_number > aggregation_number\n-                        || aggregation_number == u32::MAX;\n-                    if !condition {\n-                        let msg = format!(\n-                            \"follower #{node_value} {aggregation_number} -> #{follower_value} \\\n-                             {follower_aggregation_number}\"\n-                        );\n-                        print(ctx, &find_root(node_id.clone()), true);\n-                        panic!(\"{msg}\");\n-                    }\n-\n-                    // All followers should also be connected to all uppers\n-                    let missing_uppers = uppers.iter().filter(|&upper_id| {\n-                        if follower_uppers\n-                            .iter()\n-                            .any(|follower_upper_id| follower_upper_id == upper_id)\n-                        {\n-                            return false;\n-                        }\n-                        let upper = ctx.node(upper_id);\n-                        if let Some(followers) = upper.followers() {\n-                            !followers\n-                                .iter()\n-                                .any(|follower_upper_id| follower_upper_id == &follower_id)\n-                        } else {\n-                            false\n-                        }\n-                    });\n-                    #[allow(clippy::never_loop)]\n-                    for missing_upper in missing_uppers {\n-                        let upper_value = {\n-                            let upper = ctx.node(missing_upper);\n-                            upper.guard.value\n-                        };\n-                        let msg = format!(\n-                            \"follower #{node_value} -> #{follower_value} is not connected to \\\n-                             upper #{upper_value}\",\n-                        );\n-                        print(ctx, &find_root(node_id.clone()), true);\n-                        panic!(\"{msg}\");\n-                    }\n-\n-                    // And visit them too\n-                    if visited.insert(follower_id.clone()) {\n-                        queue.push(follower_id);\n-                    }\n-                }\n-                uppers\n-            }\n-        };\n-        for upper_id in uppers {\n-            {\n-                let upper = ctx.node(&upper_id);\n-                let upper_aggregation_number = upper.aggregation_number();\n-                let condition =\n-                    upper_aggregation_number > aggregation_number || aggregation_number == u32::MAX;\n-                if !condition {\n-                    let msg = format!(\n-                        \"upper #{} {} -> #{} {}\",\n-                        node_value, aggregation_number, upper.guard.value, upper_aggregation_number\n-                    );\n-                    drop(upper);\n-                    print(ctx, &find_root(upper_id.clone()), true);\n-                    panic!(\"{msg}\");\n-                }\n-            }\n-            if visited.insert(upper_id.clone()) {\n-                queue.push(upper_id);\n-            }\n-        }\n-    }\n-}\n-\n-fn print_graph<C: AggregationContext>(\n-    ctx: &C,\n-    entries: impl IntoIterator<Item = C::NodeRef>,\n-    show_internal: bool,\n-    name_fn: impl Fn(&C::NodeRef) -> String,\n-) {\n-    let mut queue = entries.into_iter().collect::<Vec<_>>();\n-    let mut visited = queue.iter().cloned().collect::<FxHashSet<_>>();\n-    while let Some(node_id) = queue.pop() {\n-        let name = name_fn(&node_id);\n-        let node = ctx.node(&node_id);\n-        let n = node.aggregation_number();\n-        let n = if n == u32::MAX {\n-            \"â™¾\".to_string()\n-        } else {\n-            n.to_string()\n-        };\n-        let color = if matches!(*node, AggregationNode::Leaf { .. }) {\n-            \"gray\"\n-        } else {\n-            \"#99ff99\"\n-        };\n-        let children = node.children().collect::<StackVec<_>>();\n-        let uppers = node.uppers().iter().cloned().collect::<StackVec<_>>();\n-        let followers = match &*node {\n-            AggregationNode::Aggegating(aggegrating) => aggegrating\n-                .followers\n-                .iter()\n-                .cloned()\n-                .collect::<StackVec<_>>(),\n-            AggregationNode::Leaf { .. } => StackVec::new(),\n-        };\n-        drop(node);\n-\n-        if show_internal {\n-            println!(\"\\\"{name}\\\" [label=\\\"{name}\\\\n{n}\\\", style=filled, fillcolor=\\\"{color}\\\"];\");\n-        } else {\n-            println!(\n-                \"\\\"{}\\\" [label=\\\"{}\\\\n{}\\\\n{}U {}F\\\", style=filled, fillcolor=\\\"{}\\\"];\",\n-                name,\n-                name,\n-                n,\n-                uppers.len(),\n-                followers.len(),\n-                color,\n-            );\n-        }\n-\n-        for child_id in children {\n-            let child_name = name_fn(&child_id);\n-            println!(\"\\\"{name}\\\" -> \\\"{child_name}\\\";\");\n-            if visited.insert(child_id.clone()) {\n-                queue.push(child_id);\n-            }\n-        }\n-        if show_internal {\n-            for upper_id in uppers {\n-                let upper_name = name_fn(&upper_id);\n-                println!(\"\\\"{name}\\\" -> \\\"{upper_name}\\\" [style=dashed, color=green];\");\n-                if visited.insert(upper_id.clone()) {\n-                    queue.push(upper_id);\n-                }\n-            }\n-            for follower_id in followers {\n-                let follower_name = name_fn(&follower_id);\n-                println!(\"\\\"{name}\\\" -> \\\"{follower_name}\\\" [style=dashed, color=red];\");\n-                if visited.insert(follower_id.clone()) {\n-                    queue.push(follower_id);\n-                }\n-            }\n-        }\n-    }\n-}\n-\n-struct Node {\n-    atomic: AtomicU32,\n-    inner: Mutex<NodeInner>,\n-}\n-\n-impl Node {\n-    fn new(value: u32) -> Arc<Self> {\n-        Arc::new(Node {\n-            atomic: AtomicU32::new(0),\n-            inner: Mutex::new(NodeInner {\n-                children: Vec::new(),\n-                aggregation_node: AggregationNode::new(),\n-                value,\n-            }),\n-        })\n-    }\n-\n-    fn new_with_children(\n-        aggregation_context: &NodeAggregationContext,\n-        value: u32,\n-        children: Vec<Arc<Node>>,\n-    ) -> Arc<Self> {\n-        let node = Self::new(value);\n-        for child in children {\n-            node.add_child(aggregation_context, child);\n-        }\n-        node\n-    }\n-\n-    fn add_child(self: &Arc<Node>, aggregation_context: &NodeAggregationContext, child: Arc<Node>) {\n-        self.add_child_unchecked(aggregation_context, child);\n-        check_invariants(aggregation_context, once(find_root(NodeRef(self.clone()))));\n-    }\n-\n-    fn add_child_unchecked(\n-        self: &Arc<Node>,\n-        aggregation_context: &NodeAggregationContext,\n-        child: Arc<Node>,\n-    ) {\n-        let mut guard = self.inner.lock();\n-        guard.children.push(child.clone());\n-        let number_of_children = guard.children.len();\n-        let mut guard = unsafe { NodeGuard::new(guard, self.clone()) };\n-        let prepared = handle_new_edge(\n-            aggregation_context,\n-            &mut guard,\n-            &NodeRef(self.clone()),\n-            &NodeRef(child),\n-            number_of_children,\n-        );\n-        drop(guard);\n-        prepared.apply(aggregation_context);\n-    }\n-\n-    fn prepare_add_child<'c>(\n-        self: &Arc<Node>,\n-        aggregation_context: &'c NodeAggregationContext<'c>,\n-        child: Arc<Node>,\n-    ) -> impl PreparedOperation<NodeAggregationContext<'c>> {\n-        let mut guard = self.inner.lock();\n-        guard.children.push(child.clone());\n-        let number_of_children = guard.children.len();\n-        let mut guard = unsafe { NodeGuard::new(guard, self.clone()) };\n-        handle_new_edge(\n-            aggregation_context,\n-            &mut guard,\n-            &NodeRef(self.clone()),\n-            &NodeRef(child),\n-            number_of_children,\n-        )\n-    }\n-\n-    fn prepare_aggregation_number<'c>(\n-        self: &Arc<Node>,\n-        aggregation_context: &'c NodeAggregationContext<'c>,\n-        aggregation_number: u32,\n-    ) -> impl PreparedOperation<NodeAggregationContext<'c>> {\n-        let mut guard = self.inner.lock();\n-        guard.aggregation_node.increase_aggregation_number(\n-            aggregation_context,\n-            &NodeRef(self.clone()),\n-            aggregation_number,\n-        )\n-    }\n-\n-    fn remove_child(\n-        self: &Arc<Node>,\n-        aggregation_context: &NodeAggregationContext,\n-        child: &Arc<Node>,\n-    ) {\n-        self.remove_child_unchecked(aggregation_context, child);\n-        check_invariants(aggregation_context, once(NodeRef(self.clone())));\n-    }\n-\n-    fn remove_child_unchecked(\n-        self: &Arc<Node>,\n-        aggregation_context: &NodeAggregationContext,\n-        child: &Arc<Node>,\n-    ) {\n-        let mut guard = self.inner.lock();\n-        if let Some(idx) = guard\n-            .children\n-            .iter()\n-            .position(|item| Arc::ptr_eq(item, child))\n-        {\n-            guard.children.swap_remove(idx);\n-            handle_lost_edges(\n-                aggregation_context,\n-                unsafe { NodeGuard::new(guard, self.clone()) },\n-                &NodeRef(self.clone()),\n-                [NodeRef(child.clone())],\n-            );\n-        }\n-    }\n-\n-    fn incr(self: &Arc<Node>, aggregation_context: &NodeAggregationContext) {\n-        let mut guard = self.inner.lock();\n-        guard.value += 10000;\n-        let prepared = guard\n-            .aggregation_node\n-            .apply_change(aggregation_context, Change { value: 10000 });\n-        drop(guard);\n-        prepared.apply(aggregation_context);\n-        check_invariants(aggregation_context, once(NodeRef(self.clone())));\n-    }\n-}\n-\n-#[derive(Copy, Clone)]\n-struct Change {\n-    value: i32,\n-}\n-\n-impl Change {\n-    fn is_empty(&self) -> bool {\n-        self.value == 0\n-    }\n-}\n-\n-struct NodeInner {\n-    children: Vec<Arc<Node>>,\n-    aggregation_node: AggregationNode<NodeRef, Aggregated>,\n-    value: u32,\n-}\n-\n-struct NodeAggregationContext<'a> {\n-    additions: AtomicU32,\n-    #[allow(dead_code)]\n-    something_with_lifetime: &'a u32,\n-    add_value: bool,\n-}\n-\n-#[derive(Clone, RefCast)]\n-#[repr(transparent)]\n-struct NodeRef(Arc<Node>);\n-\n-impl Debug for NodeRef {\n-    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n-        write!(f, \"NodeRef({})\", self.0.inner.lock().value)\n-    }\n-}\n-\n-impl Hash for NodeRef {\n-    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n-        Arc::as_ptr(&self.0).hash(state);\n-    }\n-}\n-\n-impl PartialEq for NodeRef {\n-    fn eq(&self, other: &Self) -> bool {\n-        Arc::ptr_eq(&self.0, &other.0)\n-    }\n-}\n-\n-impl Eq for NodeRef {}\n-\n-struct NodeGuard {\n-    guard: MutexGuard<'static, NodeInner>,\n-    // This field is important to keep the node alive\n-    #[allow(dead_code)]\n-    node: Arc<Node>,\n-}\n-\n-impl NodeGuard {\n-    unsafe fn new(guard: MutexGuard<'_, NodeInner>, node: Arc<Node>) -> Self {\n-        NodeGuard {\n-            guard: unsafe {\n-                std::mem::transmute::<MutexGuard<'_, NodeInner>, MutexGuard<'_, NodeInner>>(guard)\n-            },\n-            node,\n-        }\n-    }\n-}\n-\n-impl Deref for NodeGuard {\n-    type Target = AggregationNode<NodeRef, Aggregated>;\n-\n-    fn deref(&self) -> &Self::Target {\n-        &self.guard.aggregation_node\n-    }\n-}\n-\n-impl DerefMut for NodeGuard {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        &mut self.guard.aggregation_node\n-    }\n-}\n-\n-impl AggregationNodeGuard for NodeGuard {\n-    type Data = Aggregated;\n-    type NodeRef = NodeRef;\n-    type DataChange = Change;\n-    type ChildrenIter<'a> = impl Iterator<Item = NodeRef> + 'a;\n-\n-    fn children(&self) -> Self::ChildrenIter<'_> {\n-        self.guard\n-            .children\n-            .iter()\n-            .map(|child| NodeRef(child.clone()))\n-    }\n-\n-    fn get_remove_change(&self) -> Option<Change> {\n-        let change = Change {\n-            value: -(self.guard.value as i32),\n-        };\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-\n-    fn get_add_change(&self) -> Option<Change> {\n-        let change = Change {\n-            value: self.guard.value as i32,\n-        };\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-\n-    fn get_initial_data(&self) -> Self::Data {\n-        Aggregated {\n-            value: self.guard.value as i32,\n-            active: false,\n-        }\n-    }\n-}\n-\n-impl AggregationContext for NodeAggregationContext<'_> {\n-    type Guard<'l>\n-        = NodeGuard\n-    where\n-        Self: 'l;\n-    type Data = Aggregated;\n-    type NodeRef = NodeRef;\n-    type DataChange = Change;\n-\n-    fn node<'b>(&'b self, reference: &Self::NodeRef) -> Self::Guard<'b> {\n-        let r = reference.0.clone();\n-        let guard = reference.0.inner.lock();\n-        unsafe { NodeGuard::new(guard, r) }\n-    }\n-\n-    fn node_pair<'b>(\n-        &'b self,\n-        id1: &Self::NodeRef,\n-        id2: &Self::NodeRef,\n-    ) -> (Self::Guard<'b>, Self::Guard<'b>) {\n-        let r1 = id1.0.clone();\n-        let r2 = id2.0.clone();\n-        loop {\n-            {\n-                let guard1 = id1.0.inner.lock();\n-                if let Some(guard2) = id2.0.inner.try_lock() {\n-                    return (unsafe { NodeGuard::new(guard1, r1) }, unsafe {\n-                        NodeGuard::new(guard2, r2)\n-                    });\n-                }\n-            }\n-            {\n-                let guard2 = id2.0.inner.lock();\n-                if let Some(guard1) = id1.0.inner.try_lock() {\n-                    return (unsafe { NodeGuard::new(guard1, r1) }, unsafe {\n-                        NodeGuard::new(guard2, r2)\n-                    });\n-                }\n-            }\n-        }\n-    }\n-\n-    fn atomic_in_progress_counter<'l>(&self, id: &'l Self::NodeRef) -> &'l AtomicU32\n-    where\n-        Self: 'l,\n-    {\n-        &id.0.atomic\n-    }\n-\n-    fn apply_change(&self, data: &mut Aggregated, change: &Change) -> Option<Change> {\n-        if data.value != 0 {\n-            self.additions.fetch_add(1, Ordering::SeqCst);\n-        }\n-        if self.add_value {\n-            data.value += change.value;\n-            Some(*change)\n-        } else {\n-            None\n-        }\n-    }\n-\n-    fn data_to_add_change(&self, data: &Self::Data) -> Option<Self::DataChange> {\n-        let change = Change { value: data.value };\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-\n-    fn data_to_remove_change(&self, data: &Self::Data) -> Option<Self::DataChange> {\n-        let change = Change { value: -data.value };\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-}\n-\n-#[derive(Default)]\n-struct ActiveQuery {\n-    active: bool,\n-}\n-\n-impl RootQuery for ActiveQuery {\n-    type Data = Aggregated;\n-    type Result = bool;\n-\n-    fn query(&mut self, data: &Self::Data) -> ControlFlow<()> {\n-        if data.active {\n-            self.active = true;\n-            ControlFlow::Break(())\n-        } else {\n-            ControlFlow::Continue(())\n-        }\n-    }\n-\n-    fn result(self) -> Self::Result {\n-        self.active\n-    }\n-}\n-\n-#[derive(Default)]\n-struct Aggregated {\n-    value: i32,\n-    active: bool,\n-}\n-\n-#[test]\n-fn chain() {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: true,\n-    };\n-    let root = Node::new(1);\n-    let mut current = root.clone();\n-    for i in 2..=100 {\n-        let node = Node::new(i);\n-        current.add_child(&ctx, node.clone());\n-        current = node;\n-    }\n-    let leaf = Node::new(10000);\n-    current.add_child(&ctx, leaf.clone());\n-    let current = NodeRef(root);\n-\n-    {\n-        let root_info = query_root_info(&ctx, ActiveQuery::default(), NodeRef(leaf.clone()));\n-        assert!(!root_info);\n-    }\n-\n-    {\n-        let aggregated = aggregation_data(&ctx, &current);\n-        assert_eq!(aggregated.value, 15050);\n-    }\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 182);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-    check_invariants(&ctx, once(current.clone()));\n-\n-    {\n-        let root_info = query_root_info(&ctx, ActiveQuery::default(), NodeRef(leaf.clone()));\n-        assert!(!root_info);\n-    }\n-    check_invariants(&ctx, once(current.clone()));\n-\n-    leaf.incr(&ctx);\n-    // The change need to propagate through 4 aggregated nodes\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 4);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-\n-    {\n-        let mut aggregated = aggregation_data(&ctx, &current);\n-        assert_eq!(aggregated.value, 25050);\n-        aggregated.active = true;\n-    }\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 0);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-\n-    {\n-        let root_info = query_root_info(&ctx, ActiveQuery::default(), NodeRef(leaf.clone()));\n-        assert!(root_info);\n-    }\n-\n-    let i = 101;\n-    let current = Node::new_with_children(&ctx, i, vec![current.0]);\n-    let current = NodeRef(current);\n-\n-    {\n-        let aggregated = aggregation_data(&ctx, &current);\n-        assert_eq!(aggregated.value, 25151);\n-    }\n-    // This should be way less the 100 to prove that we are reusing trees\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 1);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-\n-    leaf.incr(&ctx);\n-    // This should be less the 20 to prove that we are reusing trees\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 5);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-\n-    {\n-        let root_info = query_root_info(&ctx, ActiveQuery::default(), NodeRef(leaf.clone()));\n-        assert!(root_info);\n-    }\n-\n-    print(&ctx, &current, true);\n-    check_invariants(&ctx, once(current.clone()));\n-}\n-\n-#[test]\n-fn chain_double_connected() {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: true,\n-    };\n-    let root = Node::new(1);\n-    let mut nodes = vec![root.clone()];\n-    let mut current = root.clone();\n-    let mut current2 = Node::new(2);\n-    current.add_child(&ctx, current2.clone());\n-    nodes.push(current2.clone());\n-    for i in 3..=100 {\n-        let node = Node::new(i);\n-        nodes.push(node.clone());\n-        current.add_child(&ctx, node.clone());\n-        current2.add_child(&ctx, node.clone());\n-        current = current2;\n-        current2 = node;\n-    }\n-    let current = NodeRef(root);\n-\n-    {\n-        let aggregated = aggregation_data(&ctx, &current);\n-        assert_eq!(aggregated.value, 20017);\n-    }\n-    check_invariants(&ctx, once(current.clone()));\n-    assert_eq!(ctx.additions.load(Ordering::SeqCst), 643);\n-    ctx.additions.store(0, Ordering::SeqCst);\n-\n-    print(&ctx, &current, true);\n-\n-    for i in 2..nodes.len() {\n-        nodes[i - 2].remove_child(&ctx, &nodes[i]);\n-        nodes[i - 1].remove_child(&ctx, &nodes[i]);\n-    }\n-    nodes[0].remove_child(&ctx, &nodes[1]);\n-\n-    {\n-        let aggregated = aggregation_data(&ctx, &current);\n-        assert_eq!(aggregated.value, 1);\n-    }\n-}\n-\n-const RECT_SIZE: usize = 30;\n-const RECT_MULT: usize = 100;\n-\n-#[test]\n-fn rectangle_tree() {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: false,\n-    };\n-    let mut nodes: Vec<Vec<Arc<Node>>> = Vec::new();\n-    let mut extra_nodes = Vec::new();\n-    for y in 0..RECT_SIZE {\n-        let mut line: Vec<Arc<Node>> = Vec::new();\n-        for x in 0..RECT_SIZE {\n-            let mut parents = Vec::new();\n-            if x > 0 {\n-                parents.push(line[x - 1].clone());\n-            }\n-            if y > 0 {\n-                parents.push(nodes[y - 1][x].clone());\n-            }\n-            let value = (x + y * RECT_MULT) as u32;\n-            let node = Node::new(value);\n-            if x == 0 || y == 0 {\n-                let extra_node = Node::new(value + 100000);\n-                prepare_aggregation_data(&ctx, &NodeRef(extra_node.clone()));\n-                extra_node.add_child(&ctx, node.clone());\n-                extra_nodes.push(extra_node);\n-                prepare_aggregation_data(&ctx, &NodeRef(node.clone()));\n-            }\n-            for parent in parents {\n-                parent.add_child_unchecked(&ctx, node.clone());\n-            }\n-            if x == 0 || y == 0 {\n-                prepare_aggregation_data(&ctx, &NodeRef(node.clone()));\n-            }\n-            line.push(node);\n-        }\n-        nodes.push(line);\n-    }\n-\n-    check_invariants(&ctx, extra_nodes.iter().cloned().map(NodeRef));\n-\n-    let root = NodeRef(extra_nodes[0].clone());\n-    print(&ctx, &root, false);\n-}\n-\n-#[rstest]\n-#[case::many_roots_initial(100000, 0, 2, 1)]\n-#[case::many_roots_later(1, 100000, 2, 1)]\n-#[case::many_roots_later2(0, 100000, 2, 1)]\n-#[case::many_roots(50000, 50000, 2, 1)]\n-#[case::many_children(2, 0, 100000, 1)]\n-#[case::many_roots_and_children(5000, 5000, 10000, 1)]\n-#[case::many_roots_and_subgraph(5000, 5000, 100, 2)]\n-#[case::large_subgraph_a(9, 1, 10, 5)]\n-#[case::large_subgraph_b(5, 5, 10, 5)]\n-#[case::large_subgraph_c(1, 9, 10, 5)]\n-#[case::large_subgraph_d(6, 0, 10, 5)]\n-#[case::large_subgraph_e(0, 10, 10, 5)]\n-#[case::many_roots_large_subgraph(5000, 5000, 10, 5)]\n-fn performance(\n-    #[case] initial_root_count: u32,\n-    #[case] additional_root_count: u32,\n-    #[case] children_count: u32,\n-    #[case] children_layers_count: u32,\n-) {\n-    fn print_aggregation_numbers(node: Arc<Node>) {\n-        print!(\"Aggregation numbers \");\n-        let mut current = node.clone();\n-        loop {\n-            let guard = current.inner.lock();\n-            let n = guard.aggregation_node.aggregation_number();\n-            let f = guard.aggregation_node.followers().map_or(0, |f| f.len());\n-            let u = guard.aggregation_node.uppers().len();\n-            print!(\" -> {n} [{u}U {f}F]\");\n-            if guard.children.is_empty() {\n-                break;\n-            }\n-            let child = guard.children[guard.children.len() / 2].clone();\n-            drop(guard);\n-            current = child;\n-        }\n-        println!();\n-    }\n-\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: false,\n-    };\n-    let mut roots: Vec<Arc<Node>> = Vec::new();\n-    let inner_node = Node::new(0);\n-    // Setup\n-    for i in 0..initial_root_count {\n-        let node = Node::new(2 + i);\n-        roots.push(node.clone());\n-        aggregation_data(&ctx, &NodeRef(node.clone())).active = true;\n-        node.add_child_unchecked(&ctx, inner_node.clone());\n-    }\n-    let start = Instant::now();\n-    let mut children = vec![inner_node.clone()];\n-    for j in 0..children_layers_count {\n-        let mut new_children = Vec::new();\n-        for child in children {\n-            for i in 0..children_count {\n-                let node = Node::new(1000000 * (j + 1) + i);\n-                new_children.push(node.clone());\n-                child.add_child_unchecked(&ctx, node.clone());\n-            }\n-        }\n-        children = new_children;\n-    }\n-    println!(\"Setup children: {:?}\", start.elapsed());\n-\n-    print_aggregation_numbers(inner_node.clone());\n-\n-    let start = Instant::now();\n-    for i in 0..additional_root_count {\n-        let node = Node::new(2 + i);\n-        roots.push(node.clone());\n-        aggregation_data(&ctx, &NodeRef(node.clone())).active = true;\n-        node.add_child_unchecked(&ctx, inner_node.clone());\n-    }\n-    println!(\"Setup additional roots: {:?}\", start.elapsed());\n-\n-    print_aggregation_numbers(inner_node.clone());\n-\n-    // Add another root\n-    let start = Instant::now();\n-    {\n-        let node = Node::new(1);\n-        roots.push(node.clone());\n-        aggregation_data(&ctx, &NodeRef(node.clone())).active = true;\n-        node.add_child_unchecked(&ctx, inner_node.clone());\n-    }\n-    let root_duration = start.elapsed();\n-    println!(\"Root: {root_duration:?}\");\n-\n-    // Add another child\n-    let start = Instant::now();\n-    {\n-        let node = Node::new(999999);\n-        inner_node.add_child_unchecked(&ctx, node.clone());\n-    }\n-    let child_duration = start.elapsed();\n-    println!(\"Child: {child_duration:?}\");\n-\n-    print_aggregation_numbers(inner_node.clone());\n-\n-    assert!(root_duration.as_micros() < 10000);\n-    assert!(child_duration.as_micros() < 10000);\n-\n-    // check_invariants(&ctx, roots.iter().cloned().map(NodeRef));\n-}\n-\n-#[test]\n-fn many_children() {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: false,\n-    };\n-    let mut roots: Vec<Arc<Node>> = Vec::new();\n-    let mut children: Vec<Arc<Node>> = Vec::new();\n-    const CHILDREN: u32 = 100000;\n-    const ROOTS: u32 = 3;\n-    let inner_node = Node::new(0);\n-    let start = Instant::now();\n-    for i in 0..ROOTS {\n-        let node = Node::new(10000 + i);\n-        roots.push(node.clone());\n-        aggregation_data(&ctx, &NodeRef(node.clone())).active = true;\n-        node.add_child_unchecked(&ctx, inner_node.clone());\n-    }\n-    println!(\"Roots: {:?}\", start.elapsed());\n-    let start = Instant::now();\n-    for i in 0..CHILDREN {\n-        let node = Node::new(20000 + i);\n-        children.push(node.clone());\n-        inner_node.add_child_unchecked(&ctx, node.clone());\n-    }\n-    println!(\"Children: {:?}\", start.elapsed());\n-    let start = Instant::now();\n-    for i in 0..CHILDREN {\n-        let node = Node::new(40000 + i);\n-        children.push(node.clone());\n-        inner_node.add_child_unchecked(&ctx, node.clone());\n-    }\n-    let children_duration = start.elapsed();\n-    println!(\"Children: {children_duration:?}\");\n-    for j in 0.. {\n-        let start = Instant::now();\n-        for i in 0..CHILDREN {\n-            let node = Node::new(50000 + j * 10000 + i);\n-            children.push(node.clone());\n-            inner_node.add_child_unchecked(&ctx, node.clone());\n-        }\n-        let dur = start.elapsed();\n-        println!(\"Children: {dur:?}\");\n-        let is_slow = dur > children_duration * 2;\n-        if j > 10 && !is_slow {\n-            break;\n-        }\n-        if j > 20 {\n-            panic!(\"Adding children has become slower over time\");\n-        }\n-    }\n-\n-    let start = Instant::now();\n-    for i in 0..ROOTS {\n-        let node = Node::new(30000 + i);\n-        roots.push(node.clone());\n-        aggregation_data(&ctx, &NodeRef(node.clone())).active = true;\n-        node.add_child_unchecked(&ctx, inner_node.clone());\n-    }\n-    println!(\"Roots: {:?}\", start.elapsed());\n-\n-    check_invariants(&ctx, roots.iter().cloned().map(NodeRef));\n-\n-    // let root = NodeRef(roots[0].clone());\n-    // print(&ctx, &root, false);\n-}\n-\n-#[test]\n-fn concurrent_modification() {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: true,\n-    };\n-    let root1 = Node::new(1);\n-    let root2 = Node::new(2);\n-    let helper = Node::new(3);\n-    let inner_node = Node::new(10);\n-    let outer_node1 = Node::new(11);\n-    let outer_node2 = Node::new(12);\n-    let outer_node3 = Node::new(13);\n-    let outer_node4 = Node::new(14);\n-    inner_node.add_child(&ctx, outer_node1.clone());\n-    inner_node.add_child(&ctx, outer_node2.clone());\n-    root2.add_child(&ctx, helper.clone());\n-    outer_node1.prepare_aggregation_number(&ctx, 7).apply(&ctx);\n-    outer_node3.prepare_aggregation_number(&ctx, 7).apply(&ctx);\n-    root1.prepare_aggregation_number(&ctx, 8).apply(&ctx);\n-    root2.prepare_aggregation_number(&ctx, 4).apply(&ctx);\n-    helper.prepare_aggregation_number(&ctx, 3).apply(&ctx);\n-\n-    let add_job1 = root1.prepare_add_child(&ctx, inner_node.clone());\n-    let add_job2 = inner_node.prepare_add_child(&ctx, outer_node3.clone());\n-    let add_job3 = inner_node.prepare_add_child(&ctx, outer_node4.clone());\n-    let add_job4 = helper.prepare_add_child(&ctx, inner_node.clone());\n-\n-    add_job4.apply(&ctx);\n-    print_all(&ctx, [root1.clone(), root2.clone()].map(NodeRef), true);\n-    add_job3.apply(&ctx);\n-    print_all(&ctx, [root1.clone(), root2.clone()].map(NodeRef), true);\n-    add_job2.apply(&ctx);\n-    print_all(&ctx, [root1.clone(), root2.clone()].map(NodeRef), true);\n-    add_job1.apply(&ctx);\n-\n-    print_all(&ctx, [root1.clone(), root2.clone()].map(NodeRef), true);\n-\n-    check_invariants(&ctx, [root1, root2].map(NodeRef));\n-}\n-\n-#[test]\n-fn fuzzy_new() {\n-    for size in [10, 50, 100, 200, 1000] {\n-        for _ in 0..100 {\n-            let seed = rand::random();\n-            println!(\"Seed {seed} Size {size}\");\n-            fuzzy(seed, size);\n-        }\n-    }\n-}\n-\n-#[rstest]\n-#[case::a(4059591975, 10)]\n-#[case::b(603692396, 100)]\n-#[case::c(3317876847, 10)]\n-#[case::d(4012518846, 50)]\n-fn fuzzy(#[case] seed: u32, #[case] count: u32) {\n-    let something_with_lifetime = 0;\n-    let ctx = NodeAggregationContext {\n-        additions: AtomicU32::new(0),\n-        something_with_lifetime: &something_with_lifetime,\n-        add_value: true,\n-    };\n-\n-    let mut seed_buffer = [0; 32];\n-    seed_buffer[0..4].copy_from_slice(&seed.to_be_bytes());\n-    let mut r = SmallRng::from_seed(seed_buffer);\n-    let mut nodes = Vec::new();\n-    for i in 0..count {\n-        nodes.push(Node::new(i));\n-    }\n-    prepare_aggregation_data(&ctx, &NodeRef(nodes[0].clone()));\n-\n-    let mut edges = FxIndexSet::default();\n-\n-    for _ in 0..1000 {\n-        match r.random_range(0..=2) {\n-            0 | 1 => {\n-                // if x == 47 {\n-                //     print_all(&ctx, nodes.iter().cloned().map(NodeRef), true);\n-                // }\n-                // add edge\n-                let parent = r.random_range(0..nodes.len() - 1);\n-                let child = r.random_range(parent + 1..nodes.len());\n-                // println!(\"add edge {} -> {}\", parent, child);\n-                if edges.insert((parent, child)) {\n-                    nodes[parent].add_child(&ctx, nodes[child].clone());\n-                }\n-            }\n-            2 => {\n-                // remove edge\n-                if edges.is_empty() {\n-                    continue;\n-                }\n-                let i = r.random_range(0..edges.len());\n-                let (parent, child) = edges.swap_remove_index(i).unwrap();\n-                // println!(\"remove edge {} -> {}\", parent, child);\n-                nodes[parent].remove_child(&ctx, &nodes[child]);\n-            }\n-            _ => unreachable!(),\n-        }\n-    }\n-\n-    for (parent, child) in edges {\n-        nodes[parent].remove_child(&ctx, &nodes[child]);\n-    }\n-\n-    assert_eq!(aggregation_data(&ctx, &NodeRef(nodes[0].clone())).value, 0);\n-\n-    check_invariants(&ctx, nodes.iter().cloned().map(NodeRef));\n-\n-    for node in nodes {\n-        let lock = node.inner.lock();\n-        if let AggregationNode::Aggegating(a) = &lock.aggregation_node {\n-            assert_eq!(a.data.value, lock.value as i32);\n-        }\n-    }\n-}\n-\n-fn print(aggregation_context: &NodeAggregationContext<'_>, root: &NodeRef, show_internal: bool) {\n-    print_all(aggregation_context, once(root.clone()), show_internal);\n-}\n-\n-fn print_all(\n-    aggregation_context: &NodeAggregationContext<'_>,\n-    nodes: impl IntoIterator<Item = NodeRef>,\n-    show_internal: bool,\n-) {\n-    println!(\"digraph {{\");\n-    print_graph(aggregation_context, nodes, show_internal, |item| {\n-        let lock = item.0.inner.lock();\n-        if let AggregationNode::Aggegating(a) = &lock.aggregation_node {\n-            format!(\"#{} [{}]\", lock.value, a.data.value)\n-        } else {\n-            format!(\"#{}\", lock.value)\n-        }\n-    });\n-    println!(\"\\n}}\");\n-}"
        },
        {
            "sha": "49c8063794f920f32be641d458d8e6f0686f773b",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/uppers.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 104,
            "changes": 104,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fuppers.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fuppers.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Fuppers.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,104 +0,0 @@\n-use super::{\n-    AggegatingNode, AggregationContext, AggregationNode, AggregationNodeGuard,\n-    PreparedInternalOperation, PreparedOperation, StackVec,\n-    balance_queue::BalanceQueue,\n-    in_progress::start_in_progress_count,\n-    optimize::{MAX_UPPERS, optimize_aggregation_number_for_uppers},\n-};\n-\n-/// Adds an upper node to a node. Returns the number of affected nodes by this\n-/// operation. This will also propagate the followers to the new upper node.\n-pub fn add_upper<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut node: C::Guard<'_>,\n-    node_id: &C::NodeRef,\n-    upper_id: &C::NodeRef,\n-    already_optimizing_for_upper: bool,\n-) -> usize {\n-    let added = match &mut *node {\n-        AggregationNode::Leaf { uppers, .. } => uppers.add_clonable(upper_id),\n-        AggregationNode::Aggegating(aggegating) => {\n-            let AggegatingNode { ref mut uppers, .. } = **aggegating;\n-            uppers.add_clonable(upper_id)\n-        }\n-    };\n-    let mut affected_nodes = 0;\n-    if added {\n-        affected_nodes = on_added(\n-            ctx,\n-            balance_queue,\n-            node,\n-            node_id,\n-            upper_id,\n-            already_optimizing_for_upper,\n-        );\n-    } else {\n-        drop(node);\n-    }\n-    affected_nodes\n-}\n-\n-/// Called when an upper node was added to a node. This will propagate the\n-/// followers to the new upper node.\n-pub fn on_added<C: AggregationContext>(\n-    ctx: &C,\n-    balance_queue: &mut BalanceQueue<C::NodeRef>,\n-    mut node: C::Guard<'_>,\n-    node_id: &C::NodeRef,\n-    upper_id: &C::NodeRef,\n-    already_optimizing_for_upper: bool,\n-) -> usize {\n-    let uppers = node.uppers();\n-    let uppers_len = uppers.len();\n-    let optimize =\n-        (!already_optimizing_for_upper && uppers_len >= MAX_UPPERS && uppers_len.is_power_of_two())\n-            .then(|| (true, uppers.iter().cloned().collect::<StackVec<_>>()));\n-    let (add_change, followers) = match &mut *node {\n-        AggregationNode::Leaf { .. } => {\n-            let add_change = node.get_add_change();\n-            let children = node.children().collect::<StackVec<_>>();\n-            start_in_progress_count(ctx, upper_id, children.len() as u32);\n-            drop(node);\n-            (add_change, children)\n-        }\n-        AggregationNode::Aggegating(aggegating) => {\n-            let AggegatingNode { ref followers, .. } = **aggegating;\n-            let add_change = ctx.data_to_add_change(&aggegating.data);\n-            let followers = followers.iter().cloned().collect::<StackVec<_>>();\n-            start_in_progress_count(ctx, upper_id, followers.len() as u32);\n-            drop(node);\n-\n-            (add_change, followers)\n-        }\n-    };\n-\n-    let mut optimizing = false;\n-\n-    // This heuristic ensures that we donâ€™t have too many upper edges, which would\n-    // degrade update performance\n-    if let Some((leaf, uppers)) = optimize {\n-        optimizing =\n-            optimize_aggregation_number_for_uppers(ctx, balance_queue, node_id, leaf, uppers);\n-    }\n-\n-    let mut affected_nodes = 0;\n-\n-    // Make sure to propagate the change to the upper node\n-    let mut upper = ctx.node(upper_id);\n-    let add_prepared = add_change.and_then(|add_change| upper.apply_change(ctx, add_change));\n-    affected_nodes += followers.len();\n-    let prepared = followers\n-        .into_iter()\n-        .filter_map(|child_id| {\n-            upper.notify_new_follower(ctx, balance_queue, upper_id, &child_id, optimizing)\n-        })\n-        .collect::<StackVec<_>>();\n-    drop(upper);\n-    add_prepared.apply(ctx);\n-    for prepared in prepared {\n-        affected_nodes += prepared.apply(ctx, balance_queue);\n-    }\n-\n-    affected_nodes\n-}"
        },
        {
            "sha": "44a82a59dd3805302fa273d67093acfbb40f1627",
            "filename": "turbopack/crates/turbo-tasks-memory/src/aggregation/util.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 31,
            "changes": 31,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Futil.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Futil.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Faggregation%2Futil.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,31 +0,0 @@\n-use super::{AggregationContext, AggregationNode, AggregationNodeGuard, StackVec};\n-\n-pub fn get_aggregated_remove_change<C: AggregationContext>(\n-    ctx: &C,\n-    guard: &C::Guard<'_>,\n-) -> Option<C::DataChange> {\n-    match &**guard {\n-        AggregationNode::Leaf { .. } => guard.get_remove_change(),\n-        AggregationNode::Aggegating(aggegating) => ctx.data_to_remove_change(&aggegating.data),\n-    }\n-}\n-\n-pub fn get_aggregated_add_change<C: AggregationContext>(\n-    ctx: &C,\n-    guard: &C::Guard<'_>,\n-) -> Option<C::DataChange> {\n-    match &**guard {\n-        AggregationNode::Leaf { .. } => guard.get_add_change(),\n-        AggregationNode::Aggegating(aggegating) => ctx.data_to_add_change(&aggegating.data),\n-    }\n-}\n-\n-pub fn get_followers_or_children<C: AggregationContext>(\n-    _ctx: &C,\n-    guard: &C::Guard<'_>,\n-) -> StackVec<C::NodeRef> {\n-    match &**guard {\n-        AggregationNode::Leaf { .. } => guard.children().collect(),\n-        AggregationNode::Aggegating(aggegating) => aggegating.followers.iter().cloned().collect(),\n-    }\n-}"
        },
        {
            "sha": "2124f937a4e40cbe5a9b86b4ddb2567cb4438662",
            "filename": "turbopack/crates/turbo-tasks-memory/src/cell.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 272,
            "changes": 272,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcell.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcell.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcell.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,272 +0,0 @@\n-use std::{fmt::Debug, mem::replace};\n-\n-use turbo_tasks::{\n-    TaskId, TaskIdSet, TurboTasksBackendApi,\n-    backend::CellContent,\n-    event::{Event, EventListener},\n-};\n-\n-use crate::MemoryBackend;\n-\n-#[derive(Default, Debug)]\n-pub(crate) struct Cell {\n-    dependent_tasks: TaskIdSet,\n-    state: CellState,\n-}\n-\n-#[derive(Default, Debug)]\n-pub(crate) enum CellState {\n-    /// No content has been set yet, or\n-    /// it was removed for memory pressure reasons, or\n-    /// cell is no longer used (It was assigned once and then no longer used\n-    /// after recomputation).\n-    ///\n-    /// Assigning a value will transition to the Value state.\n-    /// Reading this cell will,\n-    /// - transition to the Computing state if the task is progress\n-    /// - return an error if the task is already done.\n-    #[default]\n-    Empty,\n-    /// The content has been removed for memory pressure reasons, but the\n-    /// tracking is still active. Any update will invalidate dependent tasks.\n-    /// Assigning a value will transition to the Value state.\n-    /// Reading this cell will transition to the Computing state.\n-    TrackedValueless,\n-    /// Someone wanted to read the content and it was not available. The content\n-    /// is now being computed.\n-    /// Assigning a value will transition to the Value state.\n-    /// When the task ends this transitions to the Empty state if not assigned.\n-    Computing {\n-        /// The event that will be triggered when transitioning to another\n-        /// state.\n-        event: Event,\n-    },\n-    /// The content was set only once and is tracked.\n-    /// GC operation will transition to the TrackedValueless state.\n-    Value { content: CellContent },\n-}\n-\n-pub enum ReadContentError {\n-    Computing {\n-        listener: EventListener,\n-        schedule: bool,\n-    },\n-    Unused,\n-}\n-\n-impl Cell {\n-    /// Removes a task from the list of dependent tasks.\n-    pub fn remove_dependent_task(&mut self, task: TaskId) {\n-        self.dependent_tasks.remove(&task);\n-    }\n-\n-    /// Switch the cell to recomputing state.\n-    fn compute(\n-        &mut self,\n-        description: impl Fn() -> String + Sync + Send + 'static,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-    ) -> EventListener {\n-        let event = Event::new(move || (description)() + \" -> CellState::Computing::event\");\n-        let listener = event.listen_with_note(note);\n-        self.state = CellState::Computing { event };\n-        listener\n-    }\n-\n-    /// Read the content of the cell when avaiable. Registers the reader as\n-    /// dependent task. Will trigger recomputation is no content is\n-    /// available.\n-    pub fn read_content(\n-        &mut self,\n-        reader: TaskId,\n-        task_done: bool,\n-        description: impl Fn() -> String + Sync + Send + 'static,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-    ) -> Result<CellContent, ReadContentError> {\n-        match &self.state {\n-            CellState::Value { content } => {\n-                self.dependent_tasks.insert(reader);\n-                Ok(content.clone())\n-            }\n-            CellState::Empty if task_done => {\n-                self.dependent_tasks.insert(reader);\n-                Err(ReadContentError::Unused)\n-            }\n-            _ => {\n-                // Same behavior for all other states, so we reuse the same code.\n-                self.read_content_untracked(task_done, description, note)\n-            }\n-        }\n-    }\n-\n-    /// Read the content of the cell when avaiable. Does not register the reader\n-    /// as dependent task. Will trigger recomputation is no content is\n-    /// available.\n-    ///\n-    /// INVALIDATION: Be careful with this, it will not\n-    /// track dependencies, so using it could break cache invalidation.\n-    pub fn read_content_untracked(\n-        &mut self,\n-        task_done: bool,\n-        description: impl Fn() -> String + Sync + Send + 'static,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-    ) -> Result<CellContent, ReadContentError> {\n-        match &self.state {\n-            CellState::Value { content } => Ok(content.clone()),\n-            CellState::Empty => {\n-                if task_done {\n-                    Err(ReadContentError::Unused)\n-                } else {\n-                    let listener = self.compute(description, note);\n-                    Err(ReadContentError::Computing {\n-                        listener,\n-                        schedule: true,\n-                    })\n-                }\n-            }\n-            CellState::Computing { event } => {\n-                let listener = event.listen_with_note(note);\n-                Err(ReadContentError::Computing {\n-                    listener,\n-                    schedule: false,\n-                })\n-            }\n-            CellState::TrackedValueless => {\n-                let listener = self.compute(description, note);\n-                Err(ReadContentError::Computing {\n-                    listener,\n-                    schedule: true,\n-                })\n-            }\n-        }\n-    }\n-\n-    /// Read the content of the cell when avaiable. Does not register the reader\n-    /// as dependent task. Will not start recomputing when content is not\n-    /// available.\n-    ///\n-    /// INVALIDATION: Be careful with this, it will not track\n-    /// dependencies, so using it could break cache invalidation.\n-    pub fn read_own_content_untracked(&self) -> CellContent {\n-        match &self.state {\n-            CellState::Empty | CellState::Computing { .. } | CellState::TrackedValueless => {\n-                CellContent(None)\n-            }\n-            CellState::Value { content } => content.to_owned(),\n-        }\n-    }\n-\n-    /// Assigns a new content to the cell. Will notify dependent tasks if the\n-    /// content has changed.\n-    /// If clean = true, the task inputs weren't changes since the last\n-    /// execution and can be assumed to produce the same content again.\n-    ///\n-    /// Safety: This funtion does not check if the type of the content is the\n-    /// same as the type of the cell. It is the caller's responsibility to\n-    /// ensure that the content is of the correct type.\n-    pub fn assign(\n-        &mut self,\n-        content: CellContent,\n-        clean: bool,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        match &self.state {\n-            CellState::Empty => {}\n-            CellState::Computing { event } => {\n-                event.notify(usize::MAX);\n-                if clean {\n-                    // We can assume that the task is deterministic and produces the same content\n-                    // again. No need to notify dependent tasks.\n-                    self.state = CellState::Value { content };\n-                    return;\n-                }\n-            }\n-            CellState::TrackedValueless => {\n-                if clean {\n-                    // We can assume that the task is deterministic and produces the same content\n-                    // again. No need to notify dependent tasks.\n-                    self.state = CellState::Value { content };\n-                    return;\n-                }\n-            }\n-            CellState::Value {\n-                content: cell_content,\n-            } => {\n-                if content == *cell_content {\n-                    return;\n-                }\n-            }\n-        }\n-        self.state = CellState::Value { content };\n-        // Assigning to a cell will invalidate all dependent tasks as the content might\n-        // have changed.\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&self.dependent_tasks);\n-            self.dependent_tasks.clear();\n-        }\n-    }\n-\n-    pub fn empty(\n-        &mut self,\n-        clean: bool,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<CellContent> {\n-        let content = match replace(&mut self.state, CellState::Empty) {\n-            CellState::TrackedValueless | CellState::Empty => None,\n-            CellState::Computing { event } => {\n-                event.notify(usize::MAX);\n-                if clean {\n-                    // We can assume that the task is deterministic and produces the same content\n-                    // again. No need to notify dependent tasks.\n-                    return None;\n-                }\n-                None\n-            }\n-            CellState::Value { content } => Some(content),\n-        };\n-        // Assigning to a cell will invalidate all dependent tasks as the content might\n-        // have changed.\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&self.dependent_tasks);\n-            self.dependent_tasks.clear();\n-        }\n-        content\n-    }\n-\n-    /// Reduces memory needs to the minimum.\n-    pub fn shrink_to_fit(&mut self) {\n-        self.dependent_tasks.shrink_to_fit();\n-    }\n-\n-    /// Returns true if the cell is current not used and could be dropped from\n-    /// the array.\n-    pub fn is_unused(&self) -> bool {\n-        self.dependent_tasks.is_empty() && matches!(self.state, CellState::Empty)\n-    }\n-\n-    /// Takes the content out of the cell. Make sure to drop the content outside\n-    /// of the task state lock.\n-    #[must_use]\n-    pub fn gc_content(&mut self) -> Option<CellContent> {\n-        match self.state {\n-            CellState::Empty | CellState::Computing { .. } | CellState::TrackedValueless => None,\n-            CellState::Value { .. } => {\n-                let CellState::Value { content, .. } =\n-                    replace(&mut self.state, CellState::TrackedValueless)\n-                else {\n-                    unreachable!()\n-                };\n-                Some(content)\n-            }\n-        }\n-    }\n-\n-    /// Drops the cell after GC. Will notify all dependent tasks and events.\n-    pub fn gc_drop(self, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&self.dependent_tasks);\n-        }\n-        if let CellState::Computing { event } = self.state {\n-            event.notify(usize::MAX);\n-        }\n-    }\n-}"
        },
        {
            "sha": "1c24879675e47495010428c2eee80318f5c061ce",
            "filename": "turbopack/crates/turbo-tasks-memory/src/count_hash_set.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 452,
            "changes": 452,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcount_hash_set.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcount_hash_set.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fcount_hash_set.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,452 +0,0 @@\n-use std::{\n-    borrow::Borrow,\n-    fmt::{Debug, Formatter},\n-    hash::{BuildHasher, BuildHasherDefault, Hash},\n-    iter::FilterMap,\n-};\n-\n-use auto_hash_map::{\n-    AutoMap,\n-    map::{Entry, Iter, RawEntry},\n-};\n-use rustc_hash::FxHasher;\n-\n-#[derive(Clone)]\n-pub struct CountHashSet<T, H = BuildHasherDefault<FxHasher>> {\n-    inner: AutoMap<T, isize, H>,\n-    negative_entries: usize,\n-}\n-\n-impl<T: Debug, H> Debug for CountHashSet<T, H> {\n-    fn fmt(&self, f: &mut Formatter<'_>) -> std::fmt::Result {\n-        f.debug_struct(\"CountHashSet\")\n-            .field(\"inner\", &self.inner)\n-            .field(\"negative_entries\", &self.negative_entries)\n-            .finish()\n-    }\n-}\n-\n-impl<T: Eq + Hash, H: BuildHasher + Default, const N: usize> From<[T; N]> for CountHashSet<T, H> {\n-    fn from(list: [T; N]) -> Self {\n-        let mut set = CountHashSet::default();\n-        for item in list {\n-            set.add(item);\n-        }\n-        set\n-    }\n-}\n-\n-impl<T, H: Default> Default for CountHashSet<T, H> {\n-    fn default() -> Self {\n-        Self {\n-            inner: Default::default(),\n-            negative_entries: 0,\n-        }\n-    }\n-}\n-\n-impl<T: Eq + Hash, H: BuildHasher + Default> FromIterator<T> for CountHashSet<T, H> {\n-    fn from_iter<I: IntoIterator<Item = T>>(iter: I) -> Self {\n-        let mut set = CountHashSet::default();\n-        for item in iter {\n-            set.add(item);\n-        }\n-        set\n-    }\n-}\n-\n-impl<T, H: Default> CountHashSet<T, H> {\n-    pub fn new() -> Self {\n-        Self::default()\n-    }\n-}\n-\n-impl<T, H> CountHashSet<T, H> {\n-    /// Get the number of positive entries\n-    pub fn len(&self) -> usize {\n-        self.inner.len() - self.negative_entries\n-    }\n-\n-    /// Checks if the set looks empty from outside. It might still have negative\n-    /// entries, but they should be treated as not existing.\n-    pub fn is_empty(&self) -> bool {\n-        self.len() == 0\n-    }\n-}\n-\n-#[derive(Debug, PartialEq, Eq)]\n-pub enum RemoveIfEntryResult {\n-    PartiallyRemoved,\n-    Removed,\n-    NotPresent,\n-}\n-\n-impl<T: Eq + Hash, H: BuildHasher + Default> CountHashSet<T, H> {\n-    /// Returns true, when the value has become visible from outside\n-    pub fn add_count(&mut self, item: T, count: usize) -> bool {\n-        if count == 0 {\n-            return false;\n-        }\n-        match self.inner.entry(item) {\n-            Entry::Occupied(mut e) => {\n-                let value = e.get_mut();\n-                let old = *value;\n-                *value += count as isize;\n-                if old > 0 {\n-                    // it was positive before\n-                    false\n-                } else if *value > 0 {\n-                    // it was negative and has become positive\n-                    self.negative_entries -= 1;\n-                    true\n-                } else if *value == 0 {\n-                    // it was negative and has become zero\n-                    self.negative_entries -= 1;\n-                    e.remove();\n-                    false\n-                } else {\n-                    // it was and still is negative\n-                    false\n-                }\n-            }\n-            Entry::Vacant(e) => {\n-                // it was zero and is now positive\n-                e.insert(count as isize);\n-                true\n-            }\n-        }\n-    }\n-\n-    /// Returns true when the value has become visible from outside\n-    pub fn add(&mut self, item: T) -> bool {\n-        self.add_count(item, 1)\n-    }\n-\n-    /// Returns true, when the value has been added. Returns false, when the\n-    /// value was not part of the set before (positive or negative). The\n-    /// visibility from outside will never change due to this method.\n-    pub fn add_if_entry<Q>(&mut self, item: &Q) -> bool\n-    where\n-        T: Borrow<Q>,\n-        Q: Hash + Eq + ?Sized,\n-    {\n-        match self.inner.raw_entry_mut(item) {\n-            RawEntry::Occupied(mut e) => {\n-                let value = e.get_mut();\n-                *value += 1;\n-                if *value == 0 {\n-                    // it was negative and has become zero\n-                    self.negative_entries -= 1;\n-                    e.remove();\n-                }\n-                true\n-            }\n-            RawEntry::Vacant(_) => false,\n-        }\n-    }\n-\n-    /// Removes an item if it is present.\n-    pub fn remove_if_entry(&mut self, item: &T) -> RemoveIfEntryResult {\n-        match self.inner.raw_entry_mut(item) {\n-            RawEntry::Occupied(mut e) => {\n-                let value = e.get_mut();\n-                if *value < 0 {\n-                    return RemoveIfEntryResult::NotPresent;\n-                }\n-                *value -= 1;\n-                if *value == 0 {\n-                    // It was positive and has become zero\n-                    e.remove();\n-                    RemoveIfEntryResult::Removed\n-                } else {\n-                    RemoveIfEntryResult::PartiallyRemoved\n-                }\n-            }\n-            RawEntry::Vacant(_) => RemoveIfEntryResult::NotPresent,\n-        }\n-    }\n-\n-    pub fn iter(&self) -> CountHashSetIter<'_, T> {\n-        CountHashSetIter {\n-            inner: self.inner.iter().filter_map(filter),\n-            count: self.inner.len() - self.negative_entries,\n-        }\n-    }\n-\n-    /// Frees unused memory\n-    pub fn shrink_to_fit(&mut self) {\n-        self.inner.shrink_to_fit();\n-    }\n-\n-    /// Frees unused memory in an amortized way\n-    pub fn shrink_amortized(&mut self) {\n-        self.inner.shrink_amortized()\n-    }\n-}\n-\n-impl<T: Eq + Hash + Clone, H: BuildHasher + Default> CountHashSet<T, H> {\n-    /// Returns true, when the value has become visible from outside\n-    pub fn add_clonable_count(&mut self, item: &T, count: usize) -> bool {\n-        if count == 0 {\n-            return false;\n-        }\n-        match self.inner.raw_entry_mut(item) {\n-            RawEntry::Occupied(mut e) => {\n-                let value = e.get_mut();\n-                let old = *value;\n-                *value += count as isize;\n-                if old > 0 {\n-                    // it was positive before\n-                    false\n-                } else if *value > 0 {\n-                    // it was negative and has become positive\n-                    self.negative_entries -= 1;\n-                    true\n-                } else if *value == 0 {\n-                    // it was negative and has become zero\n-                    self.negative_entries -= 1;\n-                    e.remove();\n-                    false\n-                } else {\n-                    // it was and still is negative\n-                    false\n-                }\n-            }\n-            RawEntry::Vacant(e) => {\n-                // it was zero and is now positive\n-                e.insert(item.clone(), count as isize);\n-                true\n-            }\n-        }\n-    }\n-\n-    /// Returns true when the value has become visible from outside\n-    pub fn add_clonable(&mut self, item: &T) -> bool {\n-        self.add_clonable_count(item, 1)\n-    }\n-\n-    #[allow(dead_code)]\n-    /// Returns true when the value is no longer visible from outside\n-    pub fn remove_clonable_count(&mut self, item: &T, count: usize) -> bool {\n-        if count == 0 {\n-            return false;\n-        }\n-        match self.inner.raw_entry_mut(item) {\n-            RawEntry::Occupied(mut e) => {\n-                let value = e.get_mut();\n-                let old = *value;\n-                *value -= count as isize;\n-                if *value > 0 {\n-                    // It was and still is positive\n-                    false\n-                } else if *value == 0 {\n-                    // It was positive and has become zero\n-                    e.remove();\n-                    true\n-                } else if old > 0 {\n-                    // It was positive and is negative now\n-                    self.negative_entries += 1;\n-                    true\n-                } else {\n-                    // It was and still is negative\n-                    false\n-                }\n-            }\n-            RawEntry::Vacant(e) => {\n-                // It was zero and is negative now\n-                e.insert(item.clone(), -(count as isize));\n-                self.negative_entries += 1;\n-                false\n-            }\n-        }\n-    }\n-\n-    pub fn remove_all_positive_clonable_count(&mut self, item: &T) -> usize {\n-        match self.inner.raw_entry_mut(item) {\n-            RawEntry::Occupied(mut e) => {\n-                if *e.get_mut() > 0 {\n-                    let value = e.remove();\n-                    value as usize\n-                } else {\n-                    0\n-                }\n-            }\n-            RawEntry::Vacant(_) => 0,\n-        }\n-    }\n-}\n-\n-fn filter<'a, T>((k, v): (&'a T, &'a isize)) -> Option<&'a T> {\n-    if *v > 0 { Some(k) } else { None }\n-}\n-\n-type InnerIter<'a, T> =\n-    FilterMap<Iter<'a, T, isize>, for<'b> fn((&'b T, &'b isize)) -> Option<&'b T>>;\n-\n-pub struct CountHashSetIter<'a, T> {\n-    inner: InnerIter<'a, T>,\n-    count: usize,\n-}\n-\n-impl<'a, T> Iterator for CountHashSetIter<'a, T> {\n-    type Item = &'a T;\n-\n-    fn next(&mut self) -> Option<Self::Item> {\n-        self.count = self.count.saturating_sub(1);\n-        self.inner.next()\n-    }\n-\n-    fn size_hint(&self) -> (usize, Option<usize>) {\n-        (self.count, Some(self.count))\n-    }\n-}\n-\n-#[cfg(test)]\n-mod tests {\n-    use super::*;\n-\n-    #[test]\n-    fn test_add_remove() {\n-        let mut set: CountHashSet<i32> = CountHashSet::new();\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(set.add(1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.add(1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.add(2));\n-        assert_eq!(set.len(), 2);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.remove_clonable_count(&2, 2));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&2, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.remove_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.add_count(2, 2));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert_eq!(\n-            format!(\"{set:?}\"),\n-            \"CountHashSet { inner: {}, negative_entries: 0 }\"\n-        );\n-    }\n-\n-    #[test]\n-    fn test_add_remove_cloneable() {\n-        let mut set: CountHashSet<i32> = CountHashSet::new();\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(set.add_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.add_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.add_clonable_count(&2, 1));\n-        assert_eq!(set.len(), 2);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.remove_clonable_count(&2, 2));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&2, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert!(set.remove_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.add_clonable_count(&2, 2));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert_eq!(\n-            format!(\"{set:?}\"),\n-            \"CountHashSet { inner: {}, negative_entries: 0 }\"\n-        );\n-    }\n-\n-    #[test]\n-    fn test_add_remove_if_entry() {\n-        let mut set: CountHashSet<i32> = CountHashSet::new();\n-\n-        assert!(!set.add_if_entry(&1));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(set.add(1));\n-\n-        assert!(set.add_if_entry(&1));\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert_eq!(\n-            set.remove_if_entry(&1),\n-            RemoveIfEntryResult::PartiallyRemoved\n-        );\n-        assert_eq!(set.len(), 1);\n-        assert!(!set.is_empty());\n-\n-        assert_eq!(set.remove_if_entry(&1), RemoveIfEntryResult::Removed);\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert_eq!(set.remove_if_entry(&1), RemoveIfEntryResult::NotPresent);\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-    }\n-\n-    #[test]\n-    fn test_zero() {\n-        let mut set: CountHashSet<i32> = CountHashSet::new();\n-\n-        assert!(!set.add_count(1, 0));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&1, 0));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.add_clonable_count(&1, 0));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&1, 0));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert!(!set.remove_clonable_count(&1, 1));\n-        assert_eq!(set.len(), 0);\n-        assert!(set.is_empty());\n-\n-        assert_eq!(set.remove_if_entry(&1), RemoveIfEntryResult::NotPresent);\n-    }\n-}"
        },
        {
            "sha": "87b4367212aae0a9edc85bba374a931dc49eca1e",
            "filename": "turbopack/crates/turbo-tasks-memory/src/edges_set.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 585,
            "changes": 585,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fedges_set.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fedges_set.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fedges_set.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,585 +0,0 @@\n-use std::{hash::BuildHasherDefault, mem::replace};\n-\n-use auto_hash_map::{AutoMap, AutoSet, map::Entry};\n-use either::Either;\n-use rustc_hash::FxHasher;\n-use smallvec::SmallVec;\n-use turbo_tasks::{CellId, TaskId, TraitTypeId, ValueTypeId};\n-\n-#[derive(Hash, Copy, Clone, PartialEq, Eq)]\n-pub enum TaskEdge {\n-    Output(TaskId),\n-    Cell(TaskId, CellId),\n-    Collectibles(TaskId, TraitTypeId),\n-    Child(TaskId),\n-}\n-\n-impl TaskEdge {\n-    fn task_and_edge_entry(self) -> (TaskId, EdgeEntry) {\n-        match self {\n-            TaskEdge::Output(task) => (task, EdgeEntry::Output),\n-            TaskEdge::Cell(task, cell_id) => (task, EdgeEntry::Cell(cell_id)),\n-            TaskEdge::Collectibles(task, trait_type_id) => {\n-                (task, EdgeEntry::Collectibles(trait_type_id))\n-            }\n-            TaskEdge::Child(task) => (task, EdgeEntry::Child),\n-        }\n-    }\n-}\n-\n-#[derive(Hash, Copy, Clone, PartialEq, Eq, Debug)]\n-enum EdgeEntry {\n-    Output,\n-    Child,\n-    Cell(CellId),\n-    Collectibles(TraitTypeId),\n-}\n-\n-impl EdgeEntry {\n-    fn into_dependency(self, task: TaskId) -> TaskEdge {\n-        match self {\n-            EdgeEntry::Output => TaskEdge::Output(task),\n-            EdgeEntry::Cell(cell_id) => TaskEdge::Cell(task, cell_id),\n-            EdgeEntry::Collectibles(trait_type_id) => TaskEdge::Collectibles(task, trait_type_id),\n-            EdgeEntry::Child => TaskEdge::Child(task),\n-        }\n-    }\n-}\n-\n-type ComplexSet = AutoSet<EdgeEntry, BuildHasherDefault<FxHasher>, 9>;\n-\n-/// Represents a set of [`EdgeEntry`]s for an individual task, where common\n-/// cases are stored using compact representations.\n-#[derive(Debug)]\n-enum EdgesDataEntry {\n-    Empty,\n-    Output,\n-    Child,\n-    ChildAndOutput,\n-    Cell0(ValueTypeId),\n-    ChildAndCell0(ValueTypeId),\n-    OutputAndCell0(ValueTypeId),\n-    ChildOutputAndCell0(ValueTypeId),\n-    Complex(Box<ComplexSet>),\n-}\n-\n-impl EdgesDataEntry {\n-    fn from(entry: EdgeEntry) -> Self {\n-        match entry {\n-            EdgeEntry::Output => EdgesDataEntry::Output,\n-            EdgeEntry::Child => EdgesDataEntry::Child,\n-            EdgeEntry::Cell(CellId { type_id, index }) => {\n-                if index == 0 {\n-                    EdgesDataEntry::Cell0(type_id)\n-                } else {\n-                    let mut set = AutoSet::default();\n-                    set.insert(EdgeEntry::Cell(CellId { type_id, index }));\n-                    EdgesDataEntry::Complex(Box::new(set))\n-                }\n-            }\n-            EdgeEntry::Collectibles(trait_type_id) => {\n-                let mut set = AutoSet::default();\n-                set.insert(EdgeEntry::Collectibles(trait_type_id));\n-                EdgesDataEntry::Complex(Box::new(set))\n-            }\n-        }\n-    }\n-\n-    fn into_iter(self) -> impl Iterator<Item = EdgeEntry> {\n-        match self {\n-            EdgesDataEntry::Empty => unreachable!(),\n-            EdgesDataEntry::Output => Either::Left(Either::Left([EdgeEntry::Output].into_iter())),\n-            EdgesDataEntry::Child => Either::Left(Either::Left([EdgeEntry::Child].into_iter())),\n-            EdgesDataEntry::Cell0(type_id) => Either::Left(Either::Left(\n-                [EdgeEntry::Cell(CellId { type_id, index: 0 })].into_iter(),\n-            )),\n-            EdgesDataEntry::ChildAndOutput => Either::Left(Either::Right(\n-                [EdgeEntry::Child, EdgeEntry::Output].into_iter(),\n-            )),\n-            EdgesDataEntry::ChildAndCell0(type_id) => Either::Left(Either::Right(\n-                [\n-                    EdgeEntry::Child,\n-                    EdgeEntry::Cell(CellId { type_id, index: 0 }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::OutputAndCell0(type_id) => Either::Left(Either::Right(\n-                [\n-                    EdgeEntry::Output,\n-                    EdgeEntry::Cell(CellId { type_id, index: 0 }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::ChildOutputAndCell0(type_id) => Either::Right(Either::Left(\n-                [\n-                    EdgeEntry::Child,\n-                    EdgeEntry::Output,\n-                    EdgeEntry::Cell(CellId { type_id, index: 0 }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::Complex(set) => Either::Right(Either::Right(set.into_iter())),\n-        }\n-    }\n-\n-    fn iter(&self) -> impl Iterator<Item = EdgeEntry> + '_ {\n-        match self {\n-            EdgesDataEntry::Empty => unreachable!(),\n-            EdgesDataEntry::Output => Either::Left(Either::Left([EdgeEntry::Output].into_iter())),\n-            EdgesDataEntry::Child => Either::Left(Either::Left([EdgeEntry::Child].into_iter())),\n-            EdgesDataEntry::Cell0(type_id) => Either::Left(Either::Left(\n-                [EdgeEntry::Cell(CellId {\n-                    type_id: *type_id,\n-                    index: 0,\n-                })]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::ChildAndOutput => Either::Left(Either::Right(\n-                [EdgeEntry::Child, EdgeEntry::Output].into_iter(),\n-            )),\n-            EdgesDataEntry::ChildAndCell0(type_id) => Either::Left(Either::Right(\n-                [\n-                    EdgeEntry::Child,\n-                    EdgeEntry::Cell(CellId {\n-                        type_id: *type_id,\n-                        index: 0,\n-                    }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::OutputAndCell0(type_id) => Either::Left(Either::Right(\n-                [\n-                    EdgeEntry::Output,\n-                    EdgeEntry::Cell(CellId {\n-                        type_id: *type_id,\n-                        index: 0,\n-                    }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::ChildOutputAndCell0(type_id) => Either::Right(Either::Left(\n-                [\n-                    EdgeEntry::Child,\n-                    EdgeEntry::Output,\n-                    EdgeEntry::Cell(CellId {\n-                        type_id: *type_id,\n-                        index: 0,\n-                    }),\n-                ]\n-                .into_iter(),\n-            )),\n-            EdgesDataEntry::Complex(set) => Either::Right(Either::Right(set.iter().copied())),\n-        }\n-    }\n-\n-    fn has(&self, entry: EdgeEntry) -> bool {\n-        match (entry, self) {\n-            (\n-                EdgeEntry::Output,\n-                EdgesDataEntry::Output\n-                | EdgesDataEntry::OutputAndCell0(_)\n-                | EdgesDataEntry::ChildAndOutput\n-                | EdgesDataEntry::ChildOutputAndCell0(_),\n-            ) => true,\n-            (\n-                EdgeEntry::Child,\n-                EdgesDataEntry::Child\n-                | EdgesDataEntry::ChildAndOutput\n-                | EdgesDataEntry::ChildAndCell0(_)\n-                | EdgesDataEntry::ChildOutputAndCell0(_),\n-            ) => true,\n-            (\n-                EdgeEntry::Cell(cell_id),\n-                EdgesDataEntry::Cell0(type_id)\n-                | EdgesDataEntry::OutputAndCell0(type_id)\n-                | EdgesDataEntry::ChildAndCell0(type_id)\n-                | EdgesDataEntry::ChildOutputAndCell0(type_id),\n-            ) => cell_id.index == 0 && *type_id == cell_id.type_id,\n-            (entry, EdgesDataEntry::Complex(set)) => set.contains(&entry),\n-            _ => false,\n-        }\n-    }\n-\n-    fn as_complex(&mut self) -> &mut ComplexSet {\n-        match self {\n-            EdgesDataEntry::Complex(set) => set,\n-            _ => {\n-                let items = replace(self, EdgesDataEntry::Output).into_iter().collect();\n-                *self = EdgesDataEntry::Complex(Box::new(items));\n-                let EdgesDataEntry::Complex(set) = self else {\n-                    unreachable!();\n-                };\n-                set\n-            }\n-        }\n-    }\n-\n-    fn try_insert_without_complex(&mut self, entry: EdgeEntry) -> Result<bool, ()> {\n-        if self.has(entry) {\n-            return Ok(false);\n-        }\n-        match entry {\n-            EdgeEntry::Output => match self {\n-                EdgesDataEntry::Child => {\n-                    *self = EdgesDataEntry::ChildAndOutput;\n-                    return Ok(true);\n-                }\n-                EdgesDataEntry::Cell0(type_id) => {\n-                    *self = EdgesDataEntry::OutputAndCell0(*type_id);\n-                    return Ok(true);\n-                }\n-                EdgesDataEntry::ChildAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::ChildOutputAndCell0(*type_id);\n-                    return Ok(true);\n-                }\n-                _ => {}\n-            },\n-            EdgeEntry::Child => match self {\n-                EdgesDataEntry::Output => {\n-                    *self = EdgesDataEntry::ChildAndOutput;\n-                    return Ok(true);\n-                }\n-                EdgesDataEntry::Cell0(type_id) => {\n-                    *self = EdgesDataEntry::ChildAndCell0(*type_id);\n-                    return Ok(true);\n-                }\n-                EdgesDataEntry::OutputAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::ChildOutputAndCell0(*type_id);\n-                    return Ok(true);\n-                }\n-                _ => {}\n-            },\n-            EdgeEntry::Cell(type_id) => {\n-                let CellId { type_id, index } = type_id;\n-                if index == 0 {\n-                    match self {\n-                        EdgesDataEntry::Output => {\n-                            *self = EdgesDataEntry::OutputAndCell0(type_id);\n-                            return Ok(true);\n-                        }\n-                        EdgesDataEntry::Child => {\n-                            *self = EdgesDataEntry::ChildAndCell0(type_id);\n-                            return Ok(true);\n-                        }\n-                        EdgesDataEntry::ChildAndOutput => {\n-                            *self = EdgesDataEntry::ChildOutputAndCell0(type_id);\n-                            return Ok(true);\n-                        }\n-                        _ => {}\n-                    }\n-                }\n-            }\n-            EdgeEntry::Collectibles(_) => {}\n-        }\n-        Err(())\n-    }\n-\n-    fn insert(&mut self, entry: EdgeEntry) -> bool {\n-        match self.try_insert_without_complex(entry) {\n-            Ok(true) => true,\n-            Ok(false) => false,\n-            Err(()) => self.as_complex().insert(entry),\n-        }\n-    }\n-\n-    /// Removes the entry from the set, returning `true` if the entry was\n-    /// present. When the entry was removed, `self` might become `Empty` and\n-    /// must be removed.\n-    fn remove(&mut self, entry: EdgeEntry) -> bool {\n-        if !self.has(entry) {\n-            return false;\n-        }\n-        // We verified that the entry is present, so any non-complex case is easier to\n-        // handle\n-        match entry {\n-            EdgeEntry::Output => match self {\n-                EdgesDataEntry::Output => {\n-                    *self = EdgesDataEntry::Empty;\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildAndOutput => {\n-                    *self = EdgesDataEntry::Child;\n-                    return true;\n-                }\n-                EdgesDataEntry::OutputAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::Cell0(*type_id);\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildOutputAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::ChildAndCell0(*type_id);\n-                    return true;\n-                }\n-                _ => {}\n-            },\n-            EdgeEntry::Child => match self {\n-                EdgesDataEntry::Child => {\n-                    *self = EdgesDataEntry::Empty;\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildAndOutput => {\n-                    *self = EdgesDataEntry::Output;\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::Cell0(*type_id);\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildOutputAndCell0(type_id) => {\n-                    *self = EdgesDataEntry::OutputAndCell0(*type_id);\n-                    return true;\n-                }\n-                _ => {}\n-            },\n-            EdgeEntry::Cell(cell_id) if cell_id.index == 0 => match self {\n-                EdgesDataEntry::Cell0(value_ty) if cell_id.type_id == *value_ty => {\n-                    *self = EdgesDataEntry::Empty;\n-                    return true;\n-                }\n-                EdgesDataEntry::OutputAndCell0(value_ty) if cell_id.type_id == *value_ty => {\n-                    *self = EdgesDataEntry::Output;\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildAndCell0(value_ty) if cell_id.type_id == *value_ty => {\n-                    *self = EdgesDataEntry::Child;\n-                    return true;\n-                }\n-                EdgesDataEntry::ChildOutputAndCell0(value_ty) if cell_id.type_id == *value_ty => {\n-                    *self = EdgesDataEntry::ChildAndOutput;\n-                    return true;\n-                }\n-                _ => {}\n-            },\n-            EdgeEntry::Cell(_) | EdgeEntry::Collectibles(_) => {}\n-        }\n-        if let EdgesDataEntry::Complex(set) = self {\n-            if set.remove(&entry) {\n-                self.simplify();\n-                return true;\n-            }\n-        }\n-        false\n-    }\n-\n-    fn shrink_to_fit(&mut self) {\n-        if let EdgesDataEntry::Complex(set) = self {\n-            set.shrink_to_fit();\n-        }\n-    }\n-\n-    /// Simplifies the set by converting it to a more compact representation.\n-    /// When `self` becomes `Empty`, it must be removed.\n-    fn simplify(&mut self) {\n-        if let EdgesDataEntry::Complex(set) = self {\n-            match set.len() {\n-                0 => {\n-                    *self = EdgesDataEntry::Empty;\n-                }\n-                1..=3 => {\n-                    let mut iter = set.iter();\n-                    let first = iter.next().unwrap();\n-                    if matches!(\n-                        first,\n-                        EdgeEntry::Output\n-                            | EdgeEntry::Child\n-                            | EdgeEntry::Cell(CellId { index: 0, .. })\n-                    ) {\n-                        let mut new = EdgesDataEntry::from(*first);\n-                        for entry in iter {\n-                            if new.try_insert_without_complex(*entry).is_err() {\n-                                return;\n-                            }\n-                        }\n-                        *self = new;\n-                    }\n-                }\n-                _ => (),\n-            }\n-        }\n-    }\n-}\n-\n-#[derive(Default, Debug)]\n-pub struct TaskEdgesSet {\n-    edges: AutoMap<TaskId, EdgesDataEntry, BuildHasherDefault<FxHasher>>,\n-}\n-\n-impl TaskEdgesSet {\n-    pub fn new() -> Self {\n-        Self {\n-            edges: Default::default(),\n-        }\n-    }\n-\n-    pub fn insert(&mut self, edge: TaskEdge) -> bool {\n-        let (task, edge) = edge.task_and_edge_entry();\n-        match self.edges.entry(task) {\n-            Entry::Occupied(mut entry) => {\n-                let entry = entry.get_mut();\n-                entry.insert(edge)\n-            }\n-            Entry::Vacant(entry) => {\n-                entry.insert(EdgesDataEntry::from(edge));\n-                true\n-            }\n-        }\n-    }\n-\n-    pub fn shrink_to_fit(&mut self) {\n-        for entry in self.edges.values_mut() {\n-            entry.shrink_to_fit();\n-        }\n-        self.edges.shrink_to_fit();\n-    }\n-\n-    pub fn is_empty(&self) -> bool {\n-        self.edges.is_empty()\n-    }\n-\n-    pub fn into_list(self) -> TaskEdgesList {\n-        let mut edges = Vec::with_capacity(self.edges.len());\n-        self.edges.into_iter().for_each(|edge| edges.push(edge));\n-        TaskEdgesList {\n-            edges: edges.into_boxed_slice(),\n-        }\n-    }\n-\n-    pub(crate) fn drain_children(&mut self) -> SmallVec<[TaskId; 6]> {\n-        let mut children = SmallVec::new();\n-        self.edges.retain(|&task, entry| match entry {\n-            EdgesDataEntry::Child => {\n-                children.push(task);\n-                false\n-            }\n-            EdgesDataEntry::ChildAndOutput => {\n-                children.push(task);\n-                *entry = EdgesDataEntry::Output;\n-                true\n-            }\n-            EdgesDataEntry::ChildAndCell0(type_id) => {\n-                children.push(task);\n-                *entry = EdgesDataEntry::Cell0(*type_id);\n-                true\n-            }\n-            EdgesDataEntry::ChildOutputAndCell0(type_id) => {\n-                children.push(task);\n-                *entry = EdgesDataEntry::OutputAndCell0(*type_id);\n-                true\n-            }\n-            EdgesDataEntry::Complex(set) => {\n-                if set.remove(&EdgeEntry::Child) {\n-                    children.push(task);\n-                    entry.simplify();\n-                    !matches!(entry, EdgesDataEntry::Empty)\n-                } else {\n-                    true\n-                }\n-            }\n-            _ => true,\n-        });\n-        children\n-    }\n-\n-    /// Removes all dependencies from the passed `dependencies` argument\n-    pub(crate) fn remove_all(&mut self, dependencies: &TaskEdgesSet) {\n-        self.edges.retain(|task, entry| {\n-            if let Some(other) = dependencies.edges.get(task) {\n-                for item in other.iter() {\n-                    entry.remove(item);\n-                }\n-                !matches!(entry, EdgesDataEntry::Empty)\n-            } else {\n-                true\n-            }\n-        });\n-    }\n-\n-    pub(crate) fn remove(&mut self, child_id: TaskEdge) -> bool {\n-        let (task, edge) = child_id.task_and_edge_entry();\n-        let Entry::Occupied(mut entry) = self.edges.entry(task) else {\n-            return false;\n-        };\n-        let edge_entry = entry.get_mut();\n-        if edge_entry.remove(edge) {\n-            if matches!(edge_entry, EdgesDataEntry::Empty) {\n-                entry.remove();\n-            }\n-            true\n-        } else {\n-            false\n-        }\n-    }\n-\n-    pub fn children(&self) -> impl Iterator<Item = TaskId> + '_ {\n-        self.edges.iter().filter_map(|(task, entry)| match entry {\n-            EdgesDataEntry::Child => Some(*task),\n-            EdgesDataEntry::ChildAndOutput => Some(*task),\n-            EdgesDataEntry::ChildAndCell0(_) => Some(*task),\n-            EdgesDataEntry::ChildOutputAndCell0(_) => Some(*task),\n-            EdgesDataEntry::Complex(set) => {\n-                if set.contains(&EdgeEntry::Child) {\n-                    Some(*task)\n-                } else {\n-                    None\n-                }\n-            }\n-            _ => None,\n-        })\n-    }\n-}\n-\n-impl IntoIterator for TaskEdgesSet {\n-    type Item = TaskEdge;\n-    type IntoIter = impl Iterator<Item = TaskEdge>;\n-\n-    fn into_iter(self) -> Self::IntoIter {\n-        self.edges\n-            .into_iter()\n-            .flat_map(|(task, entry)| entry.into_iter().map(move |e| e.into_dependency(task)))\n-    }\n-}\n-\n-#[derive(Default)]\n-pub struct TaskEdgesList {\n-    edges: Box<[(TaskId, EdgesDataEntry)]>,\n-}\n-\n-impl TaskEdgesList {\n-    pub fn into_set(self) -> TaskEdgesSet {\n-        TaskEdgesSet {\n-            edges: self.edges.into_vec().into_iter().collect(),\n-        }\n-    }\n-\n-    pub fn is_empty(&self) -> bool {\n-        self.edges.is_empty()\n-    }\n-\n-    pub fn children(&self) -> impl Iterator<Item = TaskId> + '_ {\n-        self.edges.iter().filter_map(|(task, entry)| match entry {\n-            EdgesDataEntry::Child => Some(*task),\n-            EdgesDataEntry::ChildAndOutput => Some(*task),\n-            EdgesDataEntry::ChildAndCell0(_) => Some(*task),\n-            EdgesDataEntry::ChildOutputAndCell0(_) => Some(*task),\n-            EdgesDataEntry::Complex(set) => {\n-                if set.contains(&EdgeEntry::Child) {\n-                    Some(*task)\n-                } else {\n-                    None\n-                }\n-            }\n-            _ => None,\n-        })\n-    }\n-}\n-\n-impl IntoIterator for TaskEdgesList {\n-    type Item = TaskEdge;\n-    type IntoIter = impl Iterator<Item = TaskEdge>;\n-\n-    fn into_iter(self) -> Self::IntoIter {\n-        self.edges\n-            .into_vec()\n-            .into_iter()\n-            .flat_map(|(task, entry)| entry.into_iter().map(move |e| e.into_dependency(task)))\n-    }\n-}"
        },
        {
            "sha": "dc339d840d8d1e9cb942ef47d1aeb6904b7648cf",
            "filename": "turbopack/crates/turbo-tasks-memory/src/gc.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 395,
            "changes": 395,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fgc.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fgc.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fgc.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,395 +0,0 @@\n-use std::{\n-    cmp::{Reverse, max},\n-    collections::VecDeque,\n-    fmt::Debug,\n-    mem::take,\n-    num::NonZeroU32,\n-    sync::atomic::{AtomicU32, AtomicUsize, Ordering},\n-    time::Duration,\n-};\n-\n-use concurrent_queue::ConcurrentQueue;\n-use dashmap::DashSet;\n-use parking_lot::Mutex;\n-use tracing::field::{Empty, debug};\n-use turbo_tasks::{TaskId, TurboTasksBackendApi};\n-\n-use crate::{MemoryBackend, task::GcResult};\n-\n-/// The priority of a task for garbage collection.\n-/// Any action will shrink the internal memory structures of the task in a\n-/// transparent way.\n-#[derive(Debug, Default, PartialEq, Eq, PartialOrd, Ord, Copy, Clone)]\n-pub struct GcPriority {\n-    // Memory usage divided by compute duration. Specifies how efficient garbage collection would\n-    // be with this task. Higher memory usage and lower compute duration makes it more likely to be\n-    // garbage collected.\n-    memory_per_time: u16,\n-}\n-\n-/// State about garbage collection for a task.\n-#[derive(Clone, Copy, Debug, Default)]\n-pub struct GcTaskState {\n-    pub priority: GcPriority,\n-    /// The generation where the task was last accessed.\n-    pub generation: Option<NonZeroU32>,\n-}\n-\n-impl GcTaskState {\n-    pub(crate) fn execution_completed(\n-        &mut self,\n-        duration: Duration,\n-        memory_usage: usize,\n-        generation: NonZeroU32,\n-    ) {\n-        self.generation = Some(generation);\n-        self.priority = GcPriority {\n-            memory_per_time: ((memory_usage + TASK_BASE_MEMORY_USAGE) as u64\n-                / (duration.as_micros() as u64 + TASK_BASE_COMPUTE_DURATION_IN_MICROS))\n-                .try_into()\n-                .unwrap_or(u16::MAX),\n-        };\n-    }\n-\n-    pub(crate) fn on_read(&mut self, generation: NonZeroU32) -> bool {\n-        if let Some(old_generation) = self.generation {\n-            if old_generation < generation {\n-                self.generation = Some(generation);\n-                true\n-            } else {\n-                false\n-            }\n-        } else {\n-            self.generation = Some(generation);\n-            true\n-        }\n-    }\n-}\n-\n-const MAX_DEACTIVATIONS: usize = 100_000;\n-const TASKS_PER_NEW_GENERATION: usize = 100_000;\n-const MAX_TASKS_PER_OLD_GENERATION: usize = 200_000;\n-const PERCENTAGE_TO_COLLECT: usize = 30;\n-const TASK_BASE_MEMORY_USAGE: usize = 1_000;\n-const TASK_BASE_COMPUTE_DURATION_IN_MICROS: u64 = 1_000;\n-pub const PERCENTAGE_MIN_TARGET_MEMORY: usize = 70;\n-pub const PERCENTAGE_MAX_TARGET_MEMORY: usize = 75;\n-pub const PERCENTAGE_MIN_IDLE_TARGET_MEMORY: usize = 55;\n-pub const PERCENTAGE_MAX_IDLE_TARGET_MEMORY: usize = 60;\n-pub const MAX_GC_STEPS: usize = 100;\n-\n-struct OldGeneration {\n-    tasks: Vec<TaskId>,\n-    generation: NonZeroU32,\n-}\n-\n-#[derive(Default)]\n-struct ProcessGenerationResult {\n-    old_generations: usize,\n-    priority: Option<GcPriority>,\n-    content_dropped_count: usize,\n-    unloaded_count: usize,\n-    already_unloaded_count: usize,\n-}\n-\n-struct ProcessDeactivationsResult {\n-    count: usize,\n-}\n-\n-/// The queue of actions that garbage collection should perform.\n-pub struct GcQueue {\n-    /// The current generation number.\n-    generation: AtomicU32,\n-    /// Fresh or read tasks that should added to the queue.\n-    incoming_tasks: ConcurrentQueue<TaskId>,\n-    /// Number of tasks in `incoming_tasks`.\n-    incoming_tasks_count: AtomicUsize,\n-    /// Tasks from old generations. The oldest generation will be garbage\n-    /// collected next.\n-    generations: Mutex<VecDeque<OldGeneration>>,\n-    /// Tasks that have become inactive. Processing them should ensure them for\n-    /// GC, if they are not already ensured and put all child tasks into the\n-    /// activation_queue\n-    deactivation_queue: ConcurrentQueue<TaskId>,\n-    /// Tasks that are active and not enqueued in the deactivation queue.\n-    // TODO Could be a bit field with locks, an array of atomics or an AMQF.\n-    active_tasks: DashSet<TaskId>,\n-}\n-\n-impl GcQueue {\n-    pub fn new() -> Self {\n-        Self {\n-            // SAFETY: Starting at 1 to produce NonZeroU32s\n-            generation: AtomicU32::new(1),\n-            incoming_tasks: ConcurrentQueue::unbounded(),\n-            incoming_tasks_count: AtomicUsize::new(0),\n-            generations: Mutex::new(VecDeque::with_capacity(128)),\n-            deactivation_queue: ConcurrentQueue::unbounded(),\n-            active_tasks: DashSet::new(),\n-        }\n-    }\n-\n-    /// Get the current generation number.\n-    pub fn generation(&self) -> NonZeroU32 {\n-        // SAFETY: We are sure that the generation is not 0, since we start at 1.\n-        unsafe { NonZeroU32::new_unchecked(self.generation.load(Ordering::Relaxed)) }\n-    }\n-\n-    /// Notify the GC queue that a task has been executed.\n-    #[must_use]\n-    pub fn task_executed(&self, task: TaskId) -> NonZeroU32 {\n-        self.add_task(task)\n-    }\n-\n-    /// Notify the GC queue that a task has been accessed.\n-    #[must_use]\n-    pub fn task_accessed(&self, task: TaskId) -> NonZeroU32 {\n-        self.add_task(task)\n-    }\n-\n-    /// Notify the GC queue that a task should be enqueue for GC because it is\n-    /// inactive.\n-    #[must_use]\n-    pub fn task_inactive(&self, task: TaskId) -> NonZeroU32 {\n-        self.add_task(task)\n-    }\n-\n-    /// Notify the GC queue that a task was active during GC\n-    pub fn task_gc_active(&self, task: TaskId) {\n-        self.active_tasks.insert(task);\n-    }\n-\n-    /// Notify the GC queue that a task might be inactive now.\n-    pub fn task_potentially_no_longer_active(&self, task: TaskId) {\n-        if self.active_tasks.remove(&task).is_some() {\n-            let _ = self.deactivation_queue.push(task);\n-        }\n-    }\n-\n-    fn add_task(&self, task: TaskId) -> NonZeroU32 {\n-        let _ = self.incoming_tasks.push(task);\n-        if self.incoming_tasks_count.fetch_add(1, Ordering::Acquire) % TASKS_PER_NEW_GENERATION\n-            == TASKS_PER_NEW_GENERATION - 1\n-        {\n-            self.incoming_tasks_count\n-                .fetch_sub(TASKS_PER_NEW_GENERATION, Ordering::Release);\n-            // We are selected to move TASKS_PER_NEW_GENERATION tasks into a generation\n-            let generation = unsafe {\n-                // SAFETY: We are sure that the generation is not 0, since we start at 1.\n-                NonZeroU32::new_unchecked(self.generation.fetch_add(1, Ordering::Relaxed))\n-            };\n-            let mut tasks = Vec::with_capacity(TASKS_PER_NEW_GENERATION);\n-            for _ in 0..TASKS_PER_NEW_GENERATION {\n-                match self.incoming_tasks.pop() {\n-                    Ok(task) => {\n-                        tasks.push(task);\n-                    }\n-                    Err(_) => {\n-                        // That will not happen, since we only pop the same amount as we have\n-                        // pushed.\n-                        unreachable!();\n-                    }\n-                }\n-            }\n-            self.generations\n-                .lock()\n-                .push_front(OldGeneration { tasks, generation });\n-            generation\n-        } else {\n-            self.generation()\n-        }\n-    }\n-\n-    fn process_deactivations(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> ProcessDeactivationsResult {\n-        let mut i = 0;\n-        loop {\n-            let Ok(id) = self.deactivation_queue.pop() else {\n-                break;\n-            };\n-            backend.with_task(id, |task| {\n-                if !task.potentially_become_inactive(self, backend, turbo_tasks) {\n-                    self.active_tasks.insert(id);\n-                }\n-            });\n-            i += 1;\n-            if i > MAX_DEACTIVATIONS {\n-                break;\n-            }\n-        }\n-        ProcessDeactivationsResult { count: i }\n-    }\n-\n-    fn process_old_generation(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<ProcessGenerationResult> {\n-        let old_generation_info = {\n-            let guard = &mut self.generations.lock();\n-            let len = guard.len();\n-            guard.pop_back().map(|g| (g, len))\n-        };\n-        let Some((\n-            OldGeneration {\n-                mut tasks,\n-                generation,\n-            },\n-            old_generations,\n-        )) = old_generation_info\n-        else {\n-            // No old generation to process\n-            return None;\n-        };\n-        // Check all tasks for the correct generation\n-        let mut indices = Vec::with_capacity(tasks.len());\n-        assert!(tasks.len() <= MAX_TASKS_PER_OLD_GENERATION);\n-        for (i, task) in tasks.iter().enumerate() {\n-            backend.with_task(*task, |task| {\n-                if let Some(state) = task.gc_state() {\n-                    if let Some(task_generation) = state.generation {\n-                        if task_generation <= generation {\n-                            indices.push((Reverse(state.priority), i as u32));\n-                        }\n-                    }\n-                }\n-            });\n-        }\n-\n-        if indices.is_empty() {\n-            // No valid tasks in old generation to process\n-            return Some(ProcessGenerationResult {\n-                old_generations,\n-                ..ProcessGenerationResult::default()\n-            });\n-        }\n-\n-        // Sorting based on sort_by_cached_key from std lib\n-        indices.sort_unstable();\n-        for i in 0..indices.len() {\n-            let mut index = indices[i].1;\n-            while (index as usize) < i {\n-                index = indices[index as usize].1;\n-            }\n-            indices[i].1 = index;\n-            tasks.swap(i, index as usize);\n-        }\n-        tasks.truncate(indices.len());\n-\n-        let tasks_to_collect = max(1, tasks.len() * PERCENTAGE_TO_COLLECT / 100);\n-        let (Reverse(max_priority), _) = indices[0];\n-        drop(indices);\n-\n-        // Put back remaining tasks into the queue\n-        let remaining_tasks = &tasks[tasks_to_collect..];\n-        {\n-            let mut guard = self.generations.lock();\n-            if !remaining_tasks.is_empty() {\n-                if let Some(first) = guard.front_mut() {\n-                    first.tasks.extend(remaining_tasks);\n-                    if first.tasks.len() > MAX_TASKS_PER_OLD_GENERATION {\n-                        // Need to split the tasks into two generations\n-                        let mut gen_b = Vec::with_capacity(first.tasks.len() / 2);\n-                        let mut gen_a = Vec::with_capacity(first.tasks.len() - gen_b.capacity());\n-                        for (i, task) in take(&mut first.tasks).into_iter().enumerate() {\n-                            if i % 2 == 0 {\n-                                gen_a.push(task);\n-                            } else {\n-                                gen_b.push(task);\n-                            }\n-                        }\n-                        let generation = first.generation;\n-                        first.tasks = gen_a;\n-                        guard.push_front(OldGeneration {\n-                            tasks: gen_b,\n-                            generation,\n-                        });\n-                    }\n-                } else {\n-                    guard.push_front(OldGeneration {\n-                        tasks: remaining_tasks.to_vec(),\n-                        generation,\n-                    });\n-                }\n-            }\n-        }\n-\n-        // GC the tasks\n-        let mut content_dropped_count = 0;\n-        let mut unloaded_count = 0;\n-        let mut already_unloaded_count = 0;\n-        for task in tasks[..tasks_to_collect].iter() {\n-            backend.with_task(*task, |task| {\n-                match task.run_gc(generation, self, backend, turbo_tasks) {\n-                    GcResult::NotPossible => {}\n-                    GcResult::Stale => {}\n-                    GcResult::ContentDropped => {\n-                        content_dropped_count += 1;\n-                    }\n-                    GcResult::Unloaded => {\n-                        unloaded_count += 1;\n-                    }\n-                    GcResult::AlreadyUnloaded => {\n-                        already_unloaded_count += 1;\n-                    }\n-                }\n-            });\n-        }\n-\n-        Some(ProcessGenerationResult {\n-            old_generations,\n-            priority: Some(max_priority),\n-            content_dropped_count,\n-            unloaded_count,\n-            already_unloaded_count,\n-        })\n-    }\n-\n-    /// Run garbage collection on the queue. Returns true, if some progress has\n-    /// been made. Returns the number of old generations.\n-    pub fn run_gc(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<usize> {\n-        let span = tracing::trace_span!(\n-            \"garbage collection step\",\n-            priority = Empty,\n-            deactivations_count = Empty,\n-            content_dropped_count = Empty,\n-            unloaded_count = Empty,\n-            already_unloaded_count = Empty\n-        )\n-        .entered();\n-\n-        let ProcessDeactivationsResult {\n-            count: deactivations_count,\n-        } = self.process_deactivations(backend, turbo_tasks);\n-\n-        if let Some(ProcessGenerationResult {\n-            old_generations,\n-            priority,\n-            content_dropped_count,\n-            unloaded_count,\n-            already_unloaded_count,\n-        }) = self.process_old_generation(backend, turbo_tasks)\n-        {\n-            span.record(\"deactivations_count\", deactivations_count);\n-            span.record(\"content_dropped_count\", content_dropped_count);\n-            span.record(\"unloaded_count\", unloaded_count);\n-            span.record(\"already_unloaded_count\", already_unloaded_count);\n-            if let Some(priority) = &priority {\n-                span.record(\"priority\", debug(priority));\n-            } else {\n-                span.record(\"priority\", \"\");\n-            }\n-\n-            Some(old_generations)\n-        } else {\n-            (deactivations_count > 0).then_some(0)\n-        }\n-    }\n-}"
        },
        {
            "sha": "bd2a5476b5b402ff1c8290feab73fa29f948b3f5",
            "filename": "turbopack/crates/turbo-tasks-memory/src/lib.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 17,
            "changes": 17,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Flib.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Flib.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Flib.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,17 +0,0 @@\n-#![feature(type_alias_impl_trait)]\n-#![feature(box_patterns)]\n-#![feature(int_roundings)]\n-#![feature(impl_trait_in_assoc_type)]\n-#![deny(unsafe_op_in_unsafe_fn)]\n-\n-mod aggregation;\n-mod cell;\n-mod count_hash_set;\n-mod edges_set;\n-mod gc;\n-mod map_guard;\n-mod memory_backend;\n-mod output;\n-mod task;\n-\n-pub use memory_backend::MemoryBackend;"
        },
        {
            "sha": "c0d324d2d8546bf14a8e5f1614662405603b9098",
            "filename": "turbopack/crates/turbo-tasks-memory/src/map_guard.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 68,
            "changes": 68,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmap_guard.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmap_guard.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmap_guard.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,68 +0,0 @@\n-use std::ops::{Deref, DerefMut};\n-\n-use parking_lot::{RwLockReadGuard, RwLockWriteGuard};\n-\n-pub struct ReadGuard<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>> {\n-    inner: RwLockReadGuard<'a, T>,\n-    map: M,\n-}\n-\n-impl<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>> ReadGuard<'a, T, U, M> {\n-    pub fn new(guard: RwLockReadGuard<'a, T>, map: M) -> Self {\n-        Self { inner: guard, map }\n-    }\n-}\n-\n-impl<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>> Deref for ReadGuard<'a, T, U, M> {\n-    type Target = U;\n-\n-    fn deref(&self) -> &Self::Target {\n-        (self.map)(&self.inner).unwrap()\n-    }\n-}\n-\n-pub struct WriteGuard<\n-    'a,\n-    T: 'a,\n-    U: 'a,\n-    M: 'a + Fn(&T) -> Option<&U>,\n-    MM: 'a + Fn(&mut T) -> Option<&mut U>,\n-> {\n-    inner: RwLockWriteGuard<'a, T>,\n-    map: M,\n-    map_mut: MM,\n-}\n-\n-impl<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>, MM: 'a + Fn(&mut T) -> Option<&mut U>>\n-    WriteGuard<'a, T, U, M, MM>\n-{\n-    pub fn new(guard: RwLockWriteGuard<'a, T>, map: M, map_mut: MM) -> Self {\n-        Self {\n-            inner: guard,\n-            map,\n-            map_mut,\n-        }\n-    }\n-\n-    pub fn into_inner(self) -> RwLockWriteGuard<'a, T> {\n-        self.inner\n-    }\n-}\n-\n-impl<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>, MM: 'a + Fn(&mut T) -> Option<&mut U>> Deref\n-    for WriteGuard<'a, T, U, M, MM>\n-{\n-    type Target = U;\n-\n-    fn deref(&self) -> &Self::Target {\n-        (self.map)(&self.inner).unwrap()\n-    }\n-}\n-\n-impl<'a, T: 'a, U: 'a, M: 'a + Fn(&T) -> Option<&U>, MM: 'a + Fn(&mut T) -> Option<&mut U>> DerefMut\n-    for WriteGuard<'a, T, U, M, MM>\n-{\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        (self.map_mut)(&mut self.inner).unwrap()\n-    }\n-}"
        },
        {
            "sha": "4fcd2d6ce47b51093f71c55e023fb746f20bdd3c",
            "filename": "turbopack/crates/turbo-tasks-memory/src/memory_backend.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 818,
            "changes": 818,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmemory_backend.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmemory_backend.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Fmemory_backend.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,818 +0,0 @@\n-use std::{\n-    borrow::Borrow,\n-    future::Future,\n-    hash::{BuildHasher, BuildHasherDefault, Hash},\n-    num::NonZeroU32,\n-    pin::Pin,\n-    sync::{\n-        Arc,\n-        atomic::{AtomicBool, AtomicUsize, Ordering},\n-    },\n-    time::Duration,\n-};\n-\n-use anyhow::{Result, anyhow, bail};\n-use auto_hash_map::AutoMap;\n-use dashmap::{DashMap, mapref::entry::Entry};\n-use rustc_hash::FxHasher;\n-use tracing::trace_span;\n-use turbo_prehash::{BuildHasherExt, PassThroughHash, PreHashed};\n-use turbo_tasks::{\n-    CellId, FunctionId, RawVc, ReadCellOptions, ReadConsistency, TRANSIENT_TASK_BIT, TaskId,\n-    TaskIdSet, TraitTypeId, TurboTasksBackendApi, Unused, ValueTypeId,\n-    backend::{\n-        Backend, BackendJobId, CachedTaskType, CellContent, TaskCollectiblesMap, TaskExecutionSpec,\n-        TransientTaskType, TurboTasksExecutionError, TypedCellContent,\n-    },\n-    event::EventListener,\n-    task_statistics::TaskStatisticsApi,\n-    util::{IdFactoryWithReuse, NoMoveVec},\n-};\n-\n-use crate::{\n-    edges_set::{TaskEdge, TaskEdgesSet},\n-    gc::{\n-        GcQueue, MAX_GC_STEPS, PERCENTAGE_MAX_IDLE_TARGET_MEMORY, PERCENTAGE_MAX_TARGET_MEMORY,\n-        PERCENTAGE_MIN_IDLE_TARGET_MEMORY, PERCENTAGE_MIN_TARGET_MEMORY,\n-    },\n-    output::Output,\n-    task::{ReadCellError, Task, TaskType},\n-};\n-\n-fn prehash_task_type(task_type: CachedTaskType) -> PreHashed<CachedTaskType> {\n-    BuildHasherDefault::<FxHasher>::prehash(&Default::default(), task_type)\n-}\n-\n-pub struct TaskState {\n-    /// Cells/Outputs/Collectibles that are read during task execution. These will be stored as\n-    /// dependencies when the execution has finished.\n-    pub dependencies_to_track: TaskEdgesSet,\n-}\n-\n-pub struct MemoryBackend {\n-    persistent_tasks: NoMoveVec<Task, 13>,\n-    transient_tasks: NoMoveVec<Task, 10>,\n-    backend_jobs: NoMoveVec<Job>,\n-    backend_job_id_factory: IdFactoryWithReuse<BackendJobId>,\n-    task_cache:\n-        DashMap<Arc<PreHashed<CachedTaskType>>, TaskId, BuildHasherDefault<PassThroughHash>>,\n-    transient_task_cache:\n-        DashMap<Arc<PreHashed<CachedTaskType>>, TaskId, BuildHasherDefault<PassThroughHash>>,\n-    memory_limit: AtomicUsize,\n-    gc_queue: Option<GcQueue>,\n-    idle_gc_active: AtomicBool,\n-    task_statistics: TaskStatisticsApi,\n-    pub(crate) print_task_invalidation: bool,\n-}\n-\n-impl Default for MemoryBackend {\n-    fn default() -> Self {\n-        Self::new(usize::MAX)\n-    }\n-}\n-\n-impl MemoryBackend {\n-    pub fn new(memory_limit_bytes: usize) -> Self {\n-        let shard_amount =\n-            (std::thread::available_parallelism().map_or(1, usize::from) * 32).next_power_of_two();\n-        Self {\n-            persistent_tasks: NoMoveVec::new(),\n-            transient_tasks: NoMoveVec::new(),\n-            backend_jobs: NoMoveVec::new(),\n-            backend_job_id_factory: IdFactoryWithReuse::new(BackendJobId::MIN, BackendJobId::MAX),\n-            task_cache: DashMap::with_hasher_and_shard_amount(Default::default(), shard_amount),\n-            transient_task_cache: DashMap::with_hasher_and_shard_amount(\n-                Default::default(),\n-                shard_amount,\n-            ),\n-            memory_limit: AtomicUsize::new(memory_limit_bytes),\n-            gc_queue: (memory_limit_bytes != usize::MAX).then(GcQueue::new),\n-            idle_gc_active: AtomicBool::new(false),\n-            task_statistics: TaskStatisticsApi::default(),\n-            print_task_invalidation: false,\n-        }\n-    }\n-\n-    /// A debug feature that prints detailed task invalidation information to stdout if enabled.\n-    ///\n-    /// To enable this in next.js, use the `NEXT_TURBOPACK_PRINT_TASK_INVALIDATION` environment\n-    /// variable.\n-    pub fn print_task_invalidation(&mut self, value: bool) {\n-        self.print_task_invalidation = value;\n-    }\n-\n-    fn connect_task_child(\n-        &self,\n-        parent: TaskId,\n-        child: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(parent, |parent| {\n-            parent.connect_child(child, self, turbo_tasks)\n-        });\n-    }\n-\n-    pub(crate) fn create_backend_job(&self, job: Job) -> BackendJobId {\n-        job.before_schedule(self);\n-        let id = self.backend_job_id_factory.get();\n-        // SAFETY: This is a fresh id\n-        unsafe {\n-            self.backend_jobs.insert(*id as usize, job);\n-        }\n-        id\n-    }\n-\n-    pub(crate) fn has_gc(&self) -> bool {\n-        self.gc_queue.is_some()\n-    }\n-\n-    fn try_get_output<T, F: FnOnce(&mut Output) -> Result<T>>(\n-        &self,\n-        id: TaskId,\n-        consistency: ReadConsistency,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-        func: F,\n-    ) -> Result<Result<T, EventListener>> {\n-        self.with_task(id, |task| {\n-            task.get_or_wait_output(consistency, func, note, self, turbo_tasks)\n-        })\n-    }\n-\n-    pub fn with_all_cached_tasks(&self, mut func: impl FnMut(TaskId)) {\n-        for id in self.task_cache.clone().into_read_only().values() {\n-            func(*id);\n-        }\n-        for id in self.transient_task_cache.clone().into_read_only().values() {\n-            func(*id);\n-        }\n-    }\n-\n-    #[inline(always)]\n-    pub fn with_task<T>(&self, id: TaskId, func: impl FnOnce(&Task) -> T) -> T {\n-        let value = *id;\n-        let index = (value & !TRANSIENT_TASK_BIT) as usize;\n-        let item = if value & TRANSIENT_TASK_BIT == 0 {\n-            self.persistent_tasks.get(index)\n-        } else {\n-            self.transient_tasks.get(index)\n-        };\n-        func(item.unwrap())\n-    }\n-\n-    #[inline(always)]\n-    pub fn task(&self, id: TaskId) -> &Task {\n-        let value = *id;\n-        let index = (value & !TRANSIENT_TASK_BIT) as usize;\n-        let item = if value & TRANSIENT_TASK_BIT == 0 {\n-            self.persistent_tasks.get(index)\n-        } else {\n-            self.transient_tasks.get(index)\n-        };\n-        item.unwrap()\n-    }\n-\n-    /// Runs the garbage collection until reaching the target memory. An `idle`\n-    /// garbage collection has a lower target memory. Returns true, when\n-    /// memory was collected.\n-    pub fn run_gc(\n-        &self,\n-        idle: bool,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> bool {\n-        if let Some(gc_queue) = &self.gc_queue {\n-            let mut did_something = false;\n-            let mut remaining_generations = 0;\n-            let mut mem_limit = self.memory_limit.load(Ordering::Relaxed);\n-            let mut span = None;\n-            'outer: loop {\n-                let mut collected_generations = 0;\n-                let (min, max) = if idle {\n-                    (\n-                        mem_limit * PERCENTAGE_MIN_IDLE_TARGET_MEMORY / 100,\n-                        mem_limit * PERCENTAGE_MAX_IDLE_TARGET_MEMORY / 100,\n-                    )\n-                } else {\n-                    (\n-                        mem_limit * PERCENTAGE_MIN_TARGET_MEMORY / 100,\n-                        mem_limit * PERCENTAGE_MAX_TARGET_MEMORY / 100,\n-                    )\n-                };\n-                let mut target = max;\n-                let mut counter = 0;\n-                loop {\n-                    let usage = turbo_tasks_malloc::TurboMalloc::memory_usage();\n-                    if usage < target {\n-                        return did_something;\n-                    }\n-                    target = min;\n-                    if span.is_none() {\n-                        span =\n-                            Some(tracing::trace_span!(parent: None, \"garbage collection\", usage));\n-                    }\n-\n-                    let progress = gc_queue.run_gc(self, turbo_tasks);\n-\n-                    if progress.is_some() {\n-                        did_something = true;\n-                    }\n-\n-                    if let Some(g) = progress {\n-                        remaining_generations = g;\n-                        if g > 0 {\n-                            collected_generations += 1;\n-                        }\n-                    }\n-\n-                    counter += 1;\n-                    if counter > MAX_GC_STEPS\n-                        || collected_generations > remaining_generations\n-                        || progress.is_none()\n-                    {\n-                        let new_mem_limit = mem_limit * 4 / 3;\n-                        if self\n-                            .memory_limit\n-                            .compare_exchange(\n-                                mem_limit,\n-                                new_mem_limit,\n-                                Ordering::Relaxed,\n-                                Ordering::Relaxed,\n-                            )\n-                            .is_ok()\n-                        {\n-                            println!(\n-                                \"Ineffective GC, increasing memory limit {} MB -> {} MB\",\n-                                mem_limit / 1024 / 1024,\n-                                new_mem_limit / 1024 / 1024\n-                            );\n-                            mem_limit = new_mem_limit;\n-                        } else {\n-                            mem_limit = self.memory_limit.load(Ordering::Relaxed);\n-                        }\n-                        continue 'outer;\n-                    }\n-\n-                    did_something = true;\n-                }\n-            }\n-        }\n-        false\n-    }\n-\n-    fn insert_and_connect_fresh_task<K: Eq + Hash, H: BuildHasher + Clone, const N: u32>(\n-        &self,\n-        parent_task: TaskId,\n-        task_cache: &DashMap<K, TaskId, H>,\n-        task_storage: &NoMoveVec<Task, N>,\n-        task_storage_offset: u32,\n-        key: K,\n-        new_id: Unused<TaskId>,\n-        task: Task,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> TaskId {\n-        let new_id = new_id.into();\n-        let index = (*new_id - task_storage_offset) as usize;\n-        // Safety: We have a fresh task id that nobody knows about yet\n-        unsafe { task_storage.insert(index, task) };\n-        let result_task = match task_cache.entry(key) {\n-            Entry::Vacant(entry) => {\n-                // This is the most likely case\n-                entry.insert(new_id);\n-                new_id\n-            }\n-            Entry::Occupied(entry) => {\n-                // Safety: We have a fresh task id that nobody knows about yet\n-                let task_id = *entry.get();\n-                drop(entry);\n-                unsafe {\n-                    task_storage.remove(index);\n-                    if new_id.is_transient() {\n-                        let new_id = Unused::new_unchecked(new_id);\n-                        turbo_tasks.reuse_transient_task_id(new_id);\n-                    } else {\n-                        let new_id = Unused::new_unchecked(new_id);\n-                        turbo_tasks.reuse_persistent_task_id(new_id);\n-                    }\n-                }\n-                task_id\n-            }\n-        };\n-        self.connect_task_child(parent_task, result_task, turbo_tasks);\n-        result_task\n-    }\n-\n-    fn lookup_and_connect_task<K, Q, H: BuildHasher + Clone>(\n-        &self,\n-        parent_task: TaskId,\n-        task_cache: &DashMap<K, TaskId, H>,\n-        key: &Q,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<TaskId>\n-    where\n-        K: Borrow<Q> + Hash + Eq,\n-        Q: Hash + Eq + ?Sized,\n-    {\n-        task_cache\n-            .get(key)\n-            // Avoid holding the lock for too long\n-            .map(|task_ref| *task_ref)\n-            .inspect(|&task_id| {\n-                self.connect_task_child(parent_task, task_id, turbo_tasks);\n-            })\n-    }\n-\n-    pub(crate) fn schedule_when_dirty_from_aggregation(\n-        &self,\n-        set: TaskIdSet,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        for task in set {\n-            self.with_task(task, |task| {\n-                task.schedule_when_dirty_from_aggregation(self, turbo_tasks)\n-            });\n-        }\n-    }\n-\n-    fn track_cache_hit(&self, task_type: &CachedTaskType) {\n-        self.task_statistics()\n-            .map(|stats| stats.increment_cache_hit(task_type.fn_type));\n-    }\n-\n-    fn track_cache_miss(&self, task_type: &CachedTaskType) {\n-        self.task_statistics()\n-            .map(|stats| stats.increment_cache_miss(task_type.fn_type));\n-    }\n-}\n-\n-impl Backend for MemoryBackend {\n-    fn idle_start(&self, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        if self\n-            .idle_gc_active\n-            .compare_exchange(false, true, Ordering::AcqRel, Ordering::Acquire)\n-            .is_ok()\n-        {\n-            let job = self.create_backend_job(Job::GarbageCollection);\n-            turbo_tasks.schedule_backend_background_job(job);\n-        }\n-    }\n-\n-    fn invalidate_task(&self, task: TaskId, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        self.with_task(task, |task| task.invalidate(self, turbo_tasks));\n-    }\n-\n-    fn invalidate_tasks(\n-        &self,\n-        tasks: &[TaskId],\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        for &task in tasks {\n-            self.with_task(task, |task| {\n-                task.invalidate(self, turbo_tasks);\n-            });\n-        }\n-    }\n-\n-    fn invalidate_tasks_set(\n-        &self,\n-        tasks: &TaskIdSet,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        for &task in tasks {\n-            self.with_task(task, |task| {\n-                task.invalidate(self, turbo_tasks);\n-            });\n-        }\n-    }\n-\n-    fn get_task_description(&self, task: TaskId) -> String {\n-        self.with_task(task, |task| task.get_description())\n-    }\n-\n-    type TaskState = TaskState;\n-    fn new_task_state(&self, _task: TaskId) -> Self::TaskState {\n-        TaskState {\n-            dependencies_to_track: TaskEdgesSet::new(),\n-        }\n-    }\n-\n-    fn task_execution_canceled(\n-        &self,\n-        _task: TaskId,\n-        _turbo_tasks: &dyn TurboTasksBackendApi<Self>,\n-    ) {\n-        todo!()\n-    }\n-\n-    fn try_start_task_execution<'a>(\n-        &'a self,\n-        task: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<TaskExecutionSpec<'a>> {\n-        let task = self.task(task);\n-        task.execute(self, turbo_tasks)\n-    }\n-\n-    fn task_execution_result(\n-        &self,\n-        task_id: TaskId,\n-        result: Result<RawVc, Arc<TurboTasksExecutionError>>,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(task_id, |task| {\n-            #[cfg(debug_assertions)]\n-            if let Ok(RawVc::TaskOutput(result)) = result.as_ref() {\n-                if *result == task_id {\n-                    panic!(\"Task {} returned itself as output\", task.get_description());\n-                }\n-            }\n-            task.execution_result(result, self, turbo_tasks);\n-        })\n-    }\n-\n-    fn task_execution_completed(\n-        &self,\n-        task_id: TaskId,\n-        duration: Duration,\n-        memory_usage: usize,\n-        cell_counters: &AutoMap<ValueTypeId, u32, BuildHasherDefault<FxHasher>, 8>,\n-        stateful: bool,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> bool {\n-        let generation = if let Some(gc_queue) = &self.gc_queue {\n-            gc_queue.generation()\n-        } else {\n-            // SAFETY: 1 is not zero\n-            unsafe { NonZeroU32::new_unchecked(1) }\n-        };\n-        let (reexecute, once_task) = self.with_task(task_id, |task| {\n-            (\n-                task.execution_completed(\n-                    duration,\n-                    memory_usage,\n-                    generation,\n-                    cell_counters,\n-                    stateful,\n-                    self,\n-                    turbo_tasks,\n-                ),\n-                task.is_once(),\n-            )\n-        });\n-        if !reexecute {\n-            if let Some(gc_queue) = &self.gc_queue {\n-                let _ = gc_queue.task_executed(task_id);\n-                if once_task {\n-                    gc_queue.task_potentially_no_longer_active(task_id);\n-                }\n-                self.run_gc(false, turbo_tasks);\n-            }\n-        }\n-        reexecute\n-    }\n-\n-    fn try_read_task_output(\n-        &self,\n-        task: TaskId,\n-        reader: TaskId,\n-        consistency: ReadConsistency,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<Result<RawVc, EventListener>> {\n-        if task == reader {\n-            bail!(\"reading it's own output is not possible\");\n-        }\n-        self.try_get_output(\n-            task,\n-            consistency,\n-            move || format!(\"reading task output from {reader}\"),\n-            turbo_tasks,\n-            |output| {\n-                Task::add_dependency_to_current(TaskEdge::Output(task), turbo_tasks);\n-                output.read(reader)\n-            },\n-        )\n-    }\n-\n-    fn try_read_task_output_untracked(\n-        &self,\n-        task: TaskId,\n-        consistency: ReadConsistency,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<Result<RawVc, EventListener>> {\n-        self.try_get_output(\n-            task,\n-            consistency,\n-            || \"reading task output untracked\".to_string(),\n-            turbo_tasks,\n-            |output| output.read_untracked(),\n-        )\n-    }\n-\n-    fn try_read_task_cell(\n-        &self,\n-        task_id: TaskId,\n-        index: CellId,\n-        reader: TaskId,\n-        _options: ReadCellOptions,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<Result<TypedCellContent, EventListener>> {\n-        if task_id == reader {\n-            Ok(Ok(self\n-                .with_task(task_id, |task| {\n-                    task.with_cell(index, |cell| cell.read_own_content_untracked())\n-                })\n-                .into_typed(index.type_id)))\n-        } else {\n-            Task::add_dependency_to_current(TaskEdge::Cell(task_id, index), turbo_tasks);\n-            self.with_task(task_id, |task| {\n-                match task.read_cell(\n-                    index,\n-                    self.gc_queue.as_ref(),\n-                    move || format!(\"reading {task_id} {index} from {reader}\"),\n-                    Some(reader),\n-                    self,\n-                    turbo_tasks,\n-                ) {\n-                    Ok(content) => Ok(Ok(content.into_typed(index.type_id))),\n-                    Err(ReadCellError::Recomputing(listener)) => Ok(Err(listener)),\n-                    Err(ReadCellError::CellRemoved) => Err(anyhow!(\"Cell doesn't exist\")),\n-                }\n-            })\n-        }\n-    }\n-\n-    fn try_read_own_task_cell_untracked(\n-        &self,\n-        current_task: TaskId,\n-        index: CellId,\n-        _options: ReadCellOptions,\n-        _turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<TypedCellContent> {\n-        Ok(self.with_task(current_task, |task| {\n-            task.with_cell(index, |cell| cell.read_own_content_untracked())\n-                .into_typed(index.type_id)\n-        }))\n-    }\n-\n-    fn try_read_task_cell_untracked(\n-        &self,\n-        task_id: TaskId,\n-        index: CellId,\n-        _options: ReadCellOptions,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<Result<TypedCellContent, EventListener>> {\n-        self.with_task(task_id, |task| {\n-            match task.read_cell(\n-                index,\n-                self.gc_queue.as_ref(),\n-                move || format!(\"reading {task_id} {index} untracked\"),\n-                None,\n-                self,\n-                turbo_tasks,\n-            ) {\n-                Ok(content) => Ok(Ok(content.into_typed(index.type_id))),\n-                Err(ReadCellError::Recomputing(listener)) => Ok(Err(listener)),\n-                Err(ReadCellError::CellRemoved) => Err(anyhow!(\"Cell doesn't exist\")),\n-            }\n-        })\n-    }\n-\n-    fn read_task_collectibles(\n-        &self,\n-        id: TaskId,\n-        trait_id: TraitTypeId,\n-        reader: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> TaskCollectiblesMap {\n-        Task::add_dependency_to_current(TaskEdge::Collectibles(id, trait_id), turbo_tasks);\n-        Task::read_collectibles(id, trait_id, reader, self, turbo_tasks)\n-    }\n-\n-    fn emit_collectible(\n-        &self,\n-        trait_type: TraitTypeId,\n-        collectible: RawVc,\n-        id: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(id, |task| {\n-            task.emit_collectible(trait_type, collectible, self, turbo_tasks)\n-        });\n-    }\n-\n-    fn unemit_collectible(\n-        &self,\n-        trait_type: TraitTypeId,\n-        collectible: RawVc,\n-        count: u32,\n-        id: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(id, |task| {\n-            task.unemit_collectible(trait_type, collectible, count, self, turbo_tasks);\n-        });\n-    }\n-\n-    /// SAFETY: This function does not validate that the data in `content` is of\n-    /// the same type as in `index`. It is the caller's responsibility to ensure\n-    /// that the content is of the correct type.\n-    fn update_task_cell(\n-        &self,\n-        task: TaskId,\n-        index: CellId,\n-        content: CellContent,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(task, |task| {\n-            task.access_cell_for_write(index, |cell, clean| {\n-                cell.assign(content, clean, turbo_tasks)\n-            })\n-        })\n-    }\n-\n-    /// SAFETY: Must only called once with the same id\n-    fn run_backend_job<'a>(\n-        &'a self,\n-        id: BackendJobId,\n-        turbo_tasks: &'a dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Pin<Box<dyn Future<Output = ()> + Send + 'a>> {\n-        // SAFETY: id will not be reused until with job is done\n-        if let Some(job) = unsafe { self.backend_jobs.take(*id as usize) } {\n-            Box::pin(async move {\n-                job.run(self, turbo_tasks).await;\n-                // SAFETY: This id will no longer be used\n-                unsafe {\n-                    self.backend_job_id_factory.reuse(id);\n-                }\n-            })\n-        } else {\n-            Box::pin(async {})\n-        }\n-    }\n-\n-    fn get_or_create_persistent_task(\n-        &self,\n-        task_type: CachedTaskType,\n-        parent_task: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> TaskId {\n-        let task_type = prehash_task_type(task_type);\n-        if let Some(task) =\n-            self.lookup_and_connect_task(parent_task, &self.task_cache, &task_type, turbo_tasks)\n-        {\n-            // fast pass without creating a new task\n-            self.track_cache_hit(&task_type);\n-            task\n-        } else {\n-            self.track_cache_miss(&task_type);\n-            // It's important to avoid overallocating memory as this will go into the task\n-            // cache and stay there forever. We can to be as small as possible.\n-            let (task_type_hash, task_type) = PreHashed::into_parts(task_type);\n-            let task_type = Arc::new(PreHashed::new(task_type_hash, task_type));\n-            // slow pass with key lock\n-            let id = turbo_tasks.get_fresh_persistent_task_id();\n-            let task = Task::new_persistent(\n-                // Safety: That task will hold the value, but we are still in\n-                // control of the task\n-                *unsafe { id.get_unchecked() },\n-                task_type.clone(),\n-            );\n-            self.insert_and_connect_fresh_task(\n-                parent_task,\n-                &self.task_cache,\n-                &self.persistent_tasks,\n-                0,\n-                task_type,\n-                id,\n-                task,\n-                turbo_tasks,\n-            )\n-        }\n-    }\n-\n-    fn get_or_create_transient_task(\n-        &self,\n-        task_type: CachedTaskType,\n-        parent_task: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<Self>,\n-    ) -> TaskId {\n-        let task_type = prehash_task_type(task_type);\n-        if let Some(task) = self.lookup_and_connect_task(\n-            parent_task,\n-            &self.transient_task_cache,\n-            &task_type,\n-            turbo_tasks,\n-        ) {\n-            // fast pass without creating a new task\n-            self.track_cache_hit(&task_type);\n-            task\n-        } else {\n-            self.track_cache_miss(&task_type);\n-            // It's important to avoid overallocating memory as this will go into the task\n-            // cache and stay there forever. We can to be as small as possible.\n-            let (task_type_hash, task_type) = PreHashed::into_parts(task_type);\n-            let task_type = Arc::new(PreHashed::new(task_type_hash, task_type));\n-            // slow pass with key lock\n-            let id = turbo_tasks.get_fresh_transient_task_id();\n-            let task = Task::new_transient(\n-                // Safety: That task will hold the value, but we are still in\n-                // control of the task\n-                *unsafe { id.get_unchecked() },\n-                task_type.clone(),\n-            );\n-            self.insert_and_connect_fresh_task(\n-                parent_task,\n-                &self.transient_task_cache,\n-                &self.transient_tasks,\n-                TRANSIENT_TASK_BIT,\n-                task_type,\n-                id,\n-                task,\n-                turbo_tasks,\n-            )\n-        }\n-    }\n-\n-    fn try_get_function_id(&self, task_id: TaskId) -> Option<FunctionId> {\n-        self.with_task(task_id, |task| match &task.ty {\n-            TaskType::Persistent { ty } => Some(ty.fn_type),\n-            _ => None,\n-        })\n-    }\n-\n-    fn connect_task(\n-        &self,\n-        task: TaskId,\n-        parent_task: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.connect_task_child(parent_task, task, turbo_tasks);\n-    }\n-\n-    fn mark_own_task_as_finished(\n-        &self,\n-        task: TaskId,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.with_task(task, |task| task.mark_as_finished(self, turbo_tasks))\n-    }\n-\n-    fn create_transient_task(\n-        &self,\n-        task_type: TransientTaskType,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> TaskId {\n-        let id = turbo_tasks.get_fresh_transient_task_id();\n-        let id = id.into();\n-        let index = (*id - TRANSIENT_TASK_BIT) as usize;\n-        match task_type {\n-            TransientTaskType::Root(f) => {\n-                let task = Task::new_root(id, move || f() as _);\n-                // SAFETY: We have a fresh task id where nobody knows about yet\n-                unsafe { self.transient_tasks.insert(index, task) };\n-                Task::set_root(id, self, turbo_tasks);\n-            }\n-            TransientTaskType::Once(f) => {\n-                let task = Task::new_once(id, f);\n-                // SAFETY: We have a fresh task id where nobody knows about yet\n-                unsafe { self.transient_tasks.insert(index, task) };\n-                Task::set_once(id, self, turbo_tasks);\n-            }\n-        };\n-        id\n-    }\n-\n-    fn dispose_root_task(&self, task: TaskId, turbo_tasks: &dyn TurboTasksBackendApi<Self>) {\n-        Task::unset_root(task, self, turbo_tasks);\n-    }\n-\n-    fn task_statistics(&self) -> &TaskStatisticsApi {\n-        &self.task_statistics\n-    }\n-}\n-\n-pub(crate) enum Job {\n-    GarbageCollection,\n-}\n-\n-impl Job {\n-    // TODO remove this method\n-    fn before_schedule(&self, _backend: &MemoryBackend) {}\n-\n-    async fn run(\n-        self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        match self {\n-            Job::GarbageCollection => {\n-                let _guard = trace_span!(\"Job::GarbageCollection\").entered();\n-                if backend.run_gc(true, turbo_tasks) {\n-                    let job = backend.create_backend_job(Job::GarbageCollection);\n-                    turbo_tasks.schedule_backend_background_job(job);\n-                } else {\n-                    backend.idle_gc_active.store(false, Ordering::Release);\n-                }\n-            }\n-        }\n-    }\n-}"
        },
        {
            "sha": "94d2fa14ea8ffa271ead2b91686520cdecc200a3",
            "filename": "turbopack/crates/turbo-tasks-memory/src/output.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 69,
            "changes": 69,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Foutput.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Foutput.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Foutput.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,69 +0,0 @@\n-use std::{fmt::Debug, mem::take};\n-\n-use anyhow::{Error, Result, anyhow};\n-use turbo_tasks::{\n-    OutputContent, RawVc, TaskId, TaskIdSet, TurboTasksBackendApi, util::SharedError,\n-};\n-\n-use crate::MemoryBackend;\n-\n-#[derive(Default, Debug)]\n-pub struct Output {\n-    pub(crate) content: Option<OutputContent>,\n-    pub(crate) dependent_tasks: TaskIdSet,\n-}\n-\n-impl Output {\n-    pub fn read(&mut self, reader: TaskId) -> Result<RawVc> {\n-        self.dependent_tasks.insert(reader);\n-        self.read_untracked()\n-    }\n-\n-    /// INVALIDATION: Be careful with this, it will not track dependencies, so\n-    /// using it could break cache invalidation.\n-    pub fn read_untracked(&self) -> Result<RawVc> {\n-        match &self.content {\n-            None => Err(anyhow!(\"Output is empty\")),\n-            Some(content) => content.as_read_result(),\n-        }\n-    }\n-\n-    pub fn link(&mut self, target: RawVc, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        debug_assert!(*self != target);\n-        if let Some(OutputContent::Link(old_target)) = &self.content {\n-            if *old_target == target {\n-                // unchanged\n-                return;\n-            }\n-        }\n-        self.content = Some(OutputContent::Link(target));\n-        // notify\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&take(&mut self.dependent_tasks));\n-        }\n-    }\n-\n-    pub fn error(&mut self, error: Error, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        self.content = Some(OutputContent::Error(SharedError::new(error)));\n-        // notify\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&take(&mut self.dependent_tasks));\n-        }\n-    }\n-\n-    pub fn gc_drop(self, turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>) {\n-        // notify\n-        if !self.dependent_tasks.is_empty() {\n-            turbo_tasks.schedule_notify_tasks_set(&self.dependent_tasks);\n-        }\n-    }\n-}\n-\n-impl PartialEq<RawVc> for Output {\n-    fn eq(&self, rhs: &RawVc) -> bool {\n-        match &self.content {\n-            Some(OutputContent::Link(old_target)) => old_target == rhs,\n-            Some(OutputContent::Error(_) | OutputContent::Panic(_)) | None => false,\n-        }\n-    }\n-}"
        },
        {
            "sha": "8a861c3d5ce8f718601bac64a988e8e89f810f96",
            "filename": "turbopack/crates/turbo-tasks-memory/src/task.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1934,
            "changes": 1934,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,1934 +0,0 @@\n-use std::{\n-    fmt::{self, Debug, Display, Formatter},\n-    future::Future,\n-    hash::{BuildHasherDefault, Hash},\n-    mem::{replace, take},\n-    num::NonZeroU32,\n-    pin::Pin,\n-    sync::{Arc, atomic::AtomicU32},\n-    time::Duration,\n-};\n-\n-use anyhow::Result;\n-use auto_hash_map::AutoMap;\n-use either::Either;\n-use parking_lot::{Mutex, RwLock};\n-use rustc_hash::FxHasher;\n-use smallvec::SmallVec;\n-use tracing::Span;\n-use turbo_prehash::PreHashed;\n-use turbo_tasks::{\n-    CellId, Invalidator, RawVc, ReadConsistency, TaskId, TaskIdSet, TraitTypeId,\n-    TurboTasksBackendApi, TurboTasksBackendApiExt, ValueTypeId,\n-    backend::{\n-        CachedTaskType, CellContent, TaskCollectiblesMap, TaskExecutionSpec,\n-        TurboTasksExecutionError,\n-    },\n-    event::{Event, EventListener},\n-    get_invalidator, registry,\n-};\n-\n-use crate::{\n-    MemoryBackend,\n-    aggregation::{\n-        AggregationDataGuard, PreparedOperation, aggregation_data, handle_new_edge, query_root_info,\n-    },\n-    cell::{Cell, ReadContentError},\n-    edges_set::{TaskEdge, TaskEdgesList, TaskEdgesSet},\n-    gc::{GcQueue, GcTaskState},\n-    output::Output,\n-    task::aggregation::{TaskAggregationContext, TaskChange},\n-};\n-\n-pub type NativeTaskFuture = Pin<Box<dyn Future<Output = Result<RawVc>> + Send>>;\n-pub type NativeTaskFn = Box<dyn Fn() -> NativeTaskFuture + Send + Sync>;\n-\n-mod aggregation;\n-mod meta_state;\n-\n-type OnceTaskFn = Mutex<Option<Pin<Box<dyn Future<Output = Result<RawVc>> + Send + 'static>>>>;\n-\n-/// Different Task types\n-pub enum TaskType {\n-    // Note: double boxed to reduce TaskType size\n-    /// A root task that will track dependencies and re-execute when\n-    /// dependencies change. Task will eventually settle to the correct\n-    /// execution.\n-    Root(Box<NativeTaskFn>),\n-\n-    // Note: double boxed to reduce TaskType size\n-    /// A single root task execution. It won't track dependencies.\n-    /// Task will definitely include all invalidations that happened before the\n-    /// start of the task. It may or may not include invalidations that\n-    /// happened after that. It may see these invalidations partially\n-    /// applied.\n-    Once(Box<OnceTaskFn>),\n-\n-    /// A normal persistent task\n-    Persistent { ty: Arc<PreHashed<CachedTaskType>> },\n-\n-    /// A cached transient task\n-    Transient { ty: Arc<PreHashed<CachedTaskType>> },\n-}\n-\n-#[derive(Clone)]\n-enum TaskTypeForDescription {\n-    Root,\n-    Once,\n-    Persistent(Arc<PreHashed<CachedTaskType>>),\n-}\n-\n-impl TaskTypeForDescription {\n-    fn from(task_type: &TaskType) -> Self {\n-        match task_type {\n-            TaskType::Root(..) => Self::Root,\n-            TaskType::Once(..) => Self::Once,\n-            TaskType::Persistent { ty, .. } => Self::Persistent(ty.clone()),\n-            TaskType::Transient { ty, .. } => Self::Persistent(ty.clone()),\n-        }\n-    }\n-}\n-\n-impl Debug for TaskType {\n-    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n-        match self {\n-            Self::Root(..) => f.debug_tuple(\"Root\").finish(),\n-            Self::Once(..) => f.debug_tuple(\"Once\").finish(),\n-            Self::Persistent { ty, .. } => Debug::fmt(ty, f),\n-            Self::Transient { ty } => Debug::fmt(ty, f),\n-        }\n-    }\n-}\n-\n-impl Display for TaskType {\n-    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n-        match self {\n-            Self::Root(..) => f.debug_tuple(\"Root\").finish(),\n-            Self::Once(..) => f.debug_tuple(\"Once\").finish(),\n-            Self::Persistent { ty, .. } => Display::fmt(ty, f),\n-            Self::Transient { ty } => Display::fmt(ty, f),\n-        }\n-    }\n-}\n-\n-/// A Task is an instantiation of an Function with some arguments.\n-/// The same combinations of Function and arguments usually results in the same\n-/// Task instance.\n-pub struct Task {\n-    id: TaskId,\n-    /// The type of the task\n-    pub(crate) ty: TaskType,\n-    /// The mutable state of the task\n-    /// Unset state is equal to a Dirty task that has not been executed yet\n-    state: RwLock<TaskMetaState>,\n-    /// Atomic in progress counter for graph modification\n-    graph_modification_in_progress_counter: AtomicU32,\n-}\n-\n-impl Debug for Task {\n-    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n-        let mut result = f.debug_struct(\"Task\");\n-        result.field(\"id\", &self.id);\n-        result.field(\"ty\", &self.ty);\n-        if let Some(state) = self.try_state() {\n-            match state {\n-                TaskMetaStateReadGuard::Full(state) => {\n-                    result.field(\"state\", &Task::state_string(&state));\n-                }\n-                TaskMetaStateReadGuard::Partial(_) => {\n-                    result.field(\"state\", &\"partial\");\n-                }\n-                TaskMetaStateReadGuard::Unloaded => {\n-                    result.field(\"state\", &\"unloaded\");\n-                }\n-            }\n-        }\n-        result.finish()\n-    }\n-}\n-\n-/// The full state of a [Task], it includes all information.\n-struct TaskState {\n-    aggregation_node: TaskAggregationNode,\n-\n-    // TODO using a Atomic might be possible here\n-    /// More flags of task state, where not all combinations are possible.\n-    /// dirty, scheduled, in progress\n-    state_type: TaskStateType,\n-\n-    /// Collectibles are only modified from execution\n-    collectibles: MaybeCollectibles,\n-    output: Output,\n-    cells: AutoMap<ValueTypeId, SmallVec<[Cell; 1]>, BuildHasherDefault<FxHasher>>,\n-\n-    // GC state:\n-    gc: GcTaskState,\n-}\n-\n-impl TaskState {\n-    fn new() -> Self {\n-        Self {\n-            aggregation_node: TaskAggregationNode::new(),\n-            state_type: Dirty {\n-                outdated_edges: Default::default(),\n-            },\n-            collectibles: Default::default(),\n-            output: Default::default(),\n-            cells: Default::default(),\n-            gc: Default::default(),\n-        }\n-    }\n-\n-    fn new_scheduled(description: impl Fn() -> String + Send + Sync + Clone + 'static) -> Self {\n-        let description2 = description.clone();\n-        Self {\n-            aggregation_node: TaskAggregationNode::new(),\n-            state_type: Scheduled(Box::new(ScheduledState {\n-                start_event: Event::new(move || {\n-                    format!(\"TaskState({})::start_event\", description())\n-                }),\n-                done_event: Event::new(move || {\n-                    format!(\"TaskState({})::done_event\", description2())\n-                }),\n-                outdated_edges: Default::default(),\n-                clean: true,\n-            })),\n-            collectibles: Default::default(),\n-            output: Default::default(),\n-            cells: Default::default(),\n-            gc: Default::default(),\n-        }\n-    }\n-}\n-\n-/// The partial task state. It's equal to a full TaskState with state = Dirty\n-/// and all other fields empty. It looks like a dirty task that has not been\n-/// executed yet. The task might still referenced by some parents tasks.\n-/// A Task can get into this state when it is unloaded by garbage collection,\n-/// but is still attached to parents and aggregated.\n-struct PartialTaskState {\n-    aggregation_node: TaskAggregationNode,\n-}\n-\n-impl PartialTaskState {\n-    fn into_full(self) -> TaskState {\n-        TaskState {\n-            aggregation_node: self.aggregation_node,\n-            state_type: Dirty {\n-                outdated_edges: Default::default(),\n-            },\n-            collectibles: Default::default(),\n-            output: Default::default(),\n-            cells: Default::default(),\n-            gc: Default::default(),\n-        }\n-    }\n-}\n-\n-/// A fully unloaded task state. It's equal to a partial task state without\n-/// being referenced by any parent. This state is stored inlined instead of in a\n-/// [Box] to reduce the memory consumption. Make sure to not add more fields\n-/// than the size of a [Box].\n-struct UnloadedTaskState {}\n-\n-#[cfg(test)]\n-#[test]\n-fn test_unloaded_task_state_size() {\n-    assert!(std::mem::size_of::<UnloadedTaskState>() <= std::mem::size_of::<Box<()>>());\n-}\n-\n-impl UnloadedTaskState {\n-    fn into_full(self) -> TaskState {\n-        TaskState {\n-            aggregation_node: TaskAggregationNode::new(),\n-            state_type: Dirty {\n-                outdated_edges: Default::default(),\n-            },\n-            collectibles: Default::default(),\n-            output: Default::default(),\n-            cells: Default::default(),\n-            gc: Default::default(),\n-        }\n-    }\n-\n-    fn into_partial(self) -> PartialTaskState {\n-        PartialTaskState {\n-            aggregation_node: TaskAggregationNode::new(),\n-        }\n-    }\n-}\n-\n-/// The collectibles of a task.\n-type Collectibles = AutoMap<(TraitTypeId, RawVc), i32>;\n-\n-/// Keeps track of emitted and unemitted collectibles and the\n-/// read_collectibles tasks. Defaults to None to avoid allocating memory when no\n-/// collectibles are emitted or read.\n-#[derive(Default)]\n-struct MaybeCollectibles {\n-    inner: Option<Box<Collectibles>>,\n-}\n-\n-impl MaybeCollectibles {\n-    /// Consumes the collectibles (if any) and return them.\n-    fn take_collectibles(&mut self) -> Collectibles {\n-        self.inner\n-            .as_mut()\n-            .map(|boxed| take(&mut **boxed))\n-            .unwrap_or_default()\n-    }\n-\n-    /// Consumes the collectibles (if any) and return them.\n-    fn into_inner(self) -> Option<Box<Collectibles>> {\n-        self.inner\n-    }\n-\n-    /// Returns a reference to the collectibles (if any).\n-    fn as_ref(&self) -> Option<&Collectibles> {\n-        if let Some(inner) = &self.inner {\n-            Some(&**inner)\n-        } else {\n-            None\n-        }\n-    }\n-\n-    /// Emits a collectible.\n-    fn emit(&mut self, trait_type: TraitTypeId, value: RawVc) {\n-        let value = self\n-            .inner\n-            .get_or_insert_default()\n-            .entry((trait_type, value))\n-            .or_default();\n-        *value += 1;\n-    }\n-\n-    /// Unemits a collectible.\n-    fn unemit(&mut self, trait_type: TraitTypeId, value: RawVc, count: u32) {\n-        let value = self\n-            .inner\n-            .get_or_insert_default()\n-            .entry((trait_type, value))\n-            .or_default();\n-        *value -= count as i32;\n-    }\n-\n-    /// Removes an collectible if the count is positive.\n-    fn remove_emit(&mut self, trait_type: TraitTypeId, value: RawVc) -> bool {\n-        let Some(inner) = self.inner.as_mut() else {\n-            return false;\n-        };\n-\n-        let auto_hash_map::map::Entry::Occupied(mut e) = inner.entry((trait_type, value)) else {\n-            return false;\n-        };\n-        let value = e.get_mut();\n-        *value -= 1;\n-        if *value == 0 {\n-            e.remove();\n-        }\n-        true\n-    }\n-}\n-\n-struct InProgressState {\n-    /// Event is fired when the task is Done.\n-    done_event: Event,\n-    /// true, when the task was marked as finished.\n-    count_as_finished: bool,\n-    /// true, when the task wasn't changed since the last execution\n-    clean: bool,\n-    /// true, when the task was invalidated while executing. It will be\n-    /// scheduled again.\n-    stale: bool,\n-    /// Dependencies and children that need to be disconnected once entering\n-    /// Done.\n-    outdated_edges: TaskEdgesSet,\n-    /// Children that are connected during execution. These children are already\n-    /// removed from `outdated_edges`.\n-    new_children: TaskIdSet,\n-    /// Collectibles that need to be removed once leaving this state.\n-    outdated_collectibles: MaybeCollectibles,\n-}\n-\n-struct ScheduledState {\n-    /// Event is fired when the task is IsProgress.\n-    start_event: Event,\n-    /// Event is fired when the task is Done.\n-    done_event: Event,\n-    /// Dependencies and children that need to be disconnected once entering\n-    /// Done.\n-    outdated_edges: Box<TaskEdgesSet>,\n-    /// true, when the task wasn't changed since the last execution\n-    clean: bool,\n-}\n-\n-enum TaskStateType {\n-    /// Ready\n-    ///\n-    /// on invalidation this will move to Dirty or Scheduled depending on active\n-    /// flag\n-    Done {\n-        /// true, when the task has state and that can't be dropped\n-        stateful: bool,\n-\n-        /// Cells/Outputs/Collectibles that the task has read during execution.\n-        /// And children that are connected to this task.\n-        /// The Task will keep these tasks alive as invalidations that happen\n-        /// there might affect this task.\n-        ///\n-        /// This back-edge is [Cell] `dependent_tasks`, which is a weak edge.\n-        edges: TaskEdgesList,\n-    },\n-\n-    /// Execution is invalid, but not yet scheduled\n-    ///\n-    /// on activation this will move to Scheduled\n-    Dirty { outdated_edges: Box<TaskEdgesSet> },\n-\n-    /// Execution is invalid and scheduled\n-    ///\n-    /// on start this will move to InProgress or Dirty depending on active flag\n-    Scheduled(Box<ScheduledState>),\n-\n-    /// Execution is happening\n-    ///\n-    /// on finish this will move to Done (!stale) or Scheduled (stale)\n-    ///\n-    /// on invalidation this will set it's stale flag\n-    InProgress(Box<InProgressState>),\n-}\n-\n-impl TaskStateType {\n-    fn children(&self) -> impl Iterator<Item = TaskId> + '_ {\n-        match self {\n-            TaskStateType::Done { edges, .. } => Either::Left(edges.children()),\n-            TaskStateType::InProgress(box InProgressState {\n-                outdated_edges,\n-                new_children,\n-                ..\n-            }) => Either::Right(Either::Left(\n-                outdated_edges\n-                    .children()\n-                    .chain(new_children.iter().copied()),\n-            )),\n-            TaskStateType::Dirty { outdated_edges, .. } => {\n-                Either::Right(Either::Right(outdated_edges.children()))\n-            }\n-            TaskStateType::Scheduled(box ScheduledState { outdated_edges, .. }) => {\n-                Either::Right(Either::Right(outdated_edges.children()))\n-            }\n-        }\n-    }\n-\n-    fn into_dependencies_and_children(self) -> (TaskEdgesSet, SmallVec<[TaskId; 6]>) {\n-        match self {\n-            TaskStateType::Done { edges, .. } => {\n-                let mut edges = edges.into_set();\n-                let children = edges.drain_children();\n-                (edges, children)\n-            }\n-            TaskStateType::InProgress(box InProgressState {\n-                outdated_edges,\n-                new_children,\n-                ..\n-            }) => {\n-                let mut edges = outdated_edges;\n-                let mut children = edges.drain_children();\n-                children.extend(new_children.iter().copied());\n-                (edges, children)\n-            }\n-            TaskStateType::Dirty { outdated_edges, .. }\n-            | TaskStateType::Scheduled(box ScheduledState { outdated_edges, .. }) => {\n-                let mut edges = *outdated_edges;\n-                let children = edges.drain_children();\n-                (edges, children)\n-            }\n-        }\n-    }\n-}\n-\n-use TaskStateType::*;\n-\n-use self::{\n-    aggregation::{ActiveQuery, RootType, TaskAggregationNode, TaskGuard},\n-    meta_state::{\n-        FullTaskWriteGuard, TaskMetaState, TaskMetaStateReadGuard, TaskMetaStateWriteGuard,\n-    },\n-};\n-\n-pub enum GcResult {\n-    /// The task is not allowed to GC, e. g. due to it being non-pure or having\n-    /// state.\n-    NotPossible,\n-    /// The task was rescheduled for GC and must not be GC'ed now but at a later\n-    /// time.\n-    Stale,\n-    /// Dropped the content of task cells to save memory.\n-    ContentDropped,\n-    /// Unloaded the task completely to save memory. This disconnects the task\n-    /// from the graph and only makes sense when the task isn't currently\n-    /// active.\n-    Unloaded,\n-    AlreadyUnloaded,\n-}\n-\n-pub enum ReadCellError {\n-    CellRemoved,\n-    Recomputing(EventListener),\n-}\n-\n-impl Task {\n-    pub(crate) fn new_persistent(id: TaskId, task_type: Arc<PreHashed<CachedTaskType>>) -> Self {\n-        let ty = TaskType::Persistent { ty: task_type };\n-        Self {\n-            id,\n-            ty,\n-            state: RwLock::new(TaskMetaState::Full(Box::new(TaskState::new()))),\n-            graph_modification_in_progress_counter: AtomicU32::new(0),\n-        }\n-    }\n-\n-    pub(crate) fn new_transient(id: TaskId, task_type: Arc<PreHashed<CachedTaskType>>) -> Self {\n-        let ty = TaskType::Transient { ty: task_type };\n-        Self {\n-            id,\n-            ty,\n-            state: RwLock::new(TaskMetaState::Full(Box::new(TaskState::new()))),\n-            graph_modification_in_progress_counter: AtomicU32::new(0),\n-        }\n-    }\n-\n-    pub(crate) fn new_root(\n-        id: TaskId,\n-        functor: impl Fn() -> NativeTaskFuture + Sync + Send + 'static,\n-    ) -> Self {\n-        let ty = TaskType::Root(Box::new(Box::new(functor)));\n-        let description = Self::get_event_description_static(id, &ty);\n-        Self {\n-            id,\n-            ty,\n-            state: RwLock::new(TaskMetaState::Full(Box::new(TaskState::new_scheduled(\n-                description,\n-            )))),\n-            graph_modification_in_progress_counter: AtomicU32::new(0),\n-        }\n-    }\n-\n-    pub(crate) fn new_once(\n-        id: TaskId,\n-        functor: impl Future<Output = Result<RawVc>> + Send + 'static,\n-    ) -> Self {\n-        let ty = TaskType::Once(Box::new(Mutex::new(Some(Box::pin(functor)))));\n-        let description = Self::get_event_description_static(id, &ty);\n-        Self {\n-            id,\n-            ty,\n-            state: RwLock::new(TaskMetaState::Full(Box::new(TaskState::new_scheduled(\n-                description,\n-            )))),\n-            graph_modification_in_progress_counter: AtomicU32::new(0),\n-        }\n-    }\n-\n-    pub(crate) fn is_pure(&self) -> bool {\n-        match &self.ty {\n-            TaskType::Persistent { .. } => true,\n-            TaskType::Transient { .. } => true,\n-            TaskType::Root(_) => false,\n-            TaskType::Once(_) => false,\n-        }\n-    }\n-\n-    pub(crate) fn is_once(&self) -> bool {\n-        match &self.ty {\n-            TaskType::Persistent { .. } => false,\n-            TaskType::Transient { .. } => false,\n-            TaskType::Root(_) => false,\n-            TaskType::Once(_) => true,\n-        }\n-    }\n-\n-    pub(crate) fn set_root(\n-        id: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        {\n-            Self::set_root_type(\n-                &aggregation_context,\n-                &mut aggregation_context.aggregation_data(id),\n-                RootType::Root,\n-            );\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn set_once(\n-        id: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        {\n-            let mut aggregation_guard = aggregation_context.aggregation_data(id);\n-            Self::set_root_type(&aggregation_context, &mut aggregation_guard, RootType::Once);\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    fn set_root_type(\n-        aggregation_context: &TaskAggregationContext,\n-        aggregation: &mut AggregationDataGuard<TaskGuard<'_>>,\n-        root_type: RootType,\n-    ) {\n-        aggregation.root_type = Some(root_type);\n-        let dirty_tasks = aggregation\n-            .dirty_tasks\n-            .iter()\n-            .filter_map(|(&id, &count)| (count > 0).then_some(id));\n-        let mut tasks_to_schedule = aggregation_context.dirty_tasks_to_schedule.lock();\n-        tasks_to_schedule\n-            .get_or_insert_default()\n-            .extend(dirty_tasks);\n-    }\n-\n-    pub(crate) fn unset_root(\n-        id: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        {\n-            aggregation_context.aggregation_data(id).root_type = None;\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn get_function_name(&self) -> Option<&'static str> {\n-        if let TaskType::Persistent { ty, .. } | TaskType::Transient { ty, .. } = &self.ty {\n-            Some(ty.get_name())\n-        } else {\n-            None\n-        }\n-    }\n-\n-    pub(crate) fn get_description(&self) -> String {\n-        Self::format_description(&TaskTypeForDescription::from(&self.ty), self.id)\n-    }\n-\n-    fn format_description(ty: &TaskTypeForDescription, id: TaskId) -> String {\n-        match ty {\n-            TaskTypeForDescription::Root => format!(\"[{id}] root\"),\n-            TaskTypeForDescription::Once => format!(\"[{id}] once\"),\n-            TaskTypeForDescription::Persistent(ty) => format!(\"[{id}] {ty}\"),\n-        }\n-    }\n-\n-    fn get_event_description_static(\n-        id: TaskId,\n-        ty: &TaskType,\n-    ) -> impl Fn() -> String + Send + Sync + Clone + 'static {\n-        let ty = TaskTypeForDescription::from(ty);\n-        move || Self::format_description(&ty, id)\n-    }\n-\n-    fn get_event_description(&self) -> impl Fn() -> String + Send + Sync + Clone + 'static {\n-        Self::get_event_description_static(self.id, &self.ty)\n-    }\n-\n-    pub(crate) fn remove_dependency(\n-        dep: TaskEdge,\n-        reader: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        match dep {\n-            TaskEdge::Output(task) => {\n-                backend.with_task(task, |task| {\n-                    task.access_output_for_removing_dependents(|output| {\n-                        output.dependent_tasks.remove(&reader);\n-                    });\n-                });\n-            }\n-            TaskEdge::Cell(task, index) => {\n-                backend.with_task(task, |task| {\n-                    task.access_cell_for_removing_dependents(index, |cell| {\n-                        cell.remove_dependent_task(reader);\n-                    });\n-                });\n-            }\n-            TaskEdge::Collectibles(task, trait_type) => {\n-                let aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-                let mut aggregation = aggregation_context.aggregation_data(task);\n-                aggregation.remove_collectible_dependent_task(trait_type, reader);\n-            }\n-            TaskEdge::Child(_) => {\n-                panic!(\"Children should not be removed via remove_dependency\")\n-            }\n-        }\n-    }\n-\n-    fn clear_dependencies(\n-        &self,\n-        dependencies: TaskEdgesSet,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        for dep in dependencies.into_iter() {\n-            Task::remove_dependency(dep, self.id, backend, turbo_tasks);\n-        }\n-    }\n-\n-    fn state(&self) -> TaskMetaStateReadGuard<'_> {\n-        self.state.read().into()\n-    }\n-\n-    fn try_state(&self) -> Option<TaskMetaStateReadGuard<'_>> {\n-        self.state.try_read().map(|guard| guard.into())\n-    }\n-\n-    fn state_mut(&self) -> TaskMetaStateWriteGuard<'_> {\n-        self.state.write().into()\n-    }\n-\n-    fn try_state_mut(&self) -> Option<TaskMetaStateWriteGuard<'_>> {\n-        self.state.try_write().map(|guard| guard.into())\n-    }\n-\n-    fn full_state_mut(&self) -> FullTaskWriteGuard<'_> {\n-        TaskMetaStateWriteGuard::full_from(self.state.write())\n-    }\n-\n-    #[allow(dead_code, reason = \"We need this in future\")]\n-    fn partial_state_mut(&self) -> TaskMetaStateWriteGuard<'_> {\n-        TaskMetaStateWriteGuard::partial_from(self.state.write())\n-    }\n-\n-    pub(crate) fn execute<'a>(\n-        self: &'a Task,\n-        backend: &'a MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Option<TaskExecutionSpec<'a>> {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let (future, span) = {\n-            let mut state = self.full_state_mut();\n-            match state.state_type {\n-                Done { .. } | InProgress { .. } => {\n-                    // should not start in this state\n-                    return None;\n-                }\n-                Scheduled(box ScheduledState {\n-                    ref mut done_event,\n-                    ref mut start_event,\n-                    ref mut outdated_edges,\n-                    clean,\n-                }) => {\n-                    start_event.notify(usize::MAX);\n-                    let done_event = done_event.take();\n-                    let outdated_edges = *take(outdated_edges);\n-                    let outdated_collectibles = take(&mut state.collectibles);\n-                    state.state_type = InProgress(Box::new(InProgressState {\n-                        done_event,\n-                        count_as_finished: false,\n-                        clean,\n-                        stale: false,\n-                        outdated_edges,\n-                        outdated_collectibles,\n-                        new_children: Default::default(),\n-                    }));\n-                }\n-                Dirty { .. } => {\n-                    let state_type = Task::state_string(&state);\n-                    panic!(\"{self:?} execution started in unexpected state {state_type}\")\n-                }\n-            };\n-            self.make_execution_future()\n-        };\n-        aggregation_context.apply_queued_updates();\n-        Some(TaskExecutionSpec { future, span })\n-    }\n-\n-    /// Prepares task execution and returns a future that will execute the task.\n-    fn make_execution_future<'a>(\n-        self: &'a Task,\n-    ) -> (\n-        Pin<Box<dyn Future<Output = Result<RawVc>> + Send + 'a>>,\n-        Span,\n-    ) {\n-        match &self.ty {\n-            TaskType::Root(bound_fn) => {\n-                (bound_fn(), tracing::trace_span!(\"turbo_tasks::root_task\"))\n-            }\n-            TaskType::Once(mutex) => (\n-                mutex.lock().take().expect(\"Task can only be executed once\"),\n-                tracing::trace_span!(\"turbo_tasks::once_task\"),\n-            ),\n-            TaskType::Persistent { ty, .. } | TaskType::Transient { ty, .. } => {\n-                let CachedTaskType {\n-                    fn_type: native_fn_id,\n-                    this,\n-                    arg,\n-                } = &***ty;\n-                let func = registry::get_function(*native_fn_id);\n-                let span = func.span(self.id.persistence());\n-                let entered = span.enter();\n-                let future = func.execute(*this, &**arg);\n-                drop(entered);\n-                (future, span)\n-            }\n-        }\n-    }\n-\n-    pub(crate) fn mark_as_finished(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let TaskMetaStateWriteGuard::Full(mut state) = self.state_mut() else {\n-            return;\n-        };\n-        let TaskStateType::InProgress(box InProgressState {\n-            ref mut count_as_finished,\n-            ref mut stale,\n-            ref mut outdated_collectibles,\n-            ref mut outdated_edges,\n-            ..\n-        }) = state.state_type\n-        else {\n-            return;\n-        };\n-        if *count_as_finished || *stale {\n-            return;\n-        }\n-        *count_as_finished = true;\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        {\n-            let outdated_children = outdated_edges.drain_children();\n-            let outdated_collectibles = outdated_collectibles.take_collectibles();\n-\n-            let remove_job = if outdated_children.is_empty() {\n-                None\n-            } else {\n-                state.aggregation_node.handle_lost_edges(\n-                    &aggregation_context,\n-                    &self.id,\n-                    outdated_children,\n-                )\n-            };\n-\n-            let mut change = TaskChange {\n-                unfinished: -1,\n-                #[cfg(feature = \"track_unfinished\")]\n-                unfinished_tasks_update: vec![(self.id, -1)],\n-                ..Default::default()\n-            };\n-            for ((trait_type, value), count) in outdated_collectibles.into_iter() {\n-                change.collectibles.push((trait_type, value, -count));\n-            }\n-            let change_job = state\n-                .aggregation_node\n-                .apply_change(&aggregation_context, change);\n-\n-            drop(state);\n-            remove_job.apply(&aggregation_context);\n-            change_job.apply(&aggregation_context);\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn execution_result(\n-        &self,\n-        result: Result<RawVc, Arc<TurboTasksExecutionError>>,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut state = self.full_state_mut();\n-        match state.state_type {\n-            InProgress(ref state) if state.stale => {\n-                // We don't want to assign the output cell here\n-                // as we want to avoid unnecessary updates\n-                // TODO maybe this should be controlled by a heuristic\n-            }\n-            InProgress(..) => match result {\n-                Ok(result) => {\n-                    if state.output != result {\n-                        if backend.print_task_invalidation && state.output.content.is_some() {\n-                            println!(\n-                                \"Task {{ id: {}, name: {} }} invalidates:\",\n-                                *self.id, self.ty\n-                            );\n-                            for dep in state.output.dependent_tasks.iter() {\n-                                backend.with_task(*dep, |task| {\n-                                    println!(\"\\tTask {{ id: {}, name: {} }}\", *task.id, task.ty);\n-                                });\n-                            }\n-                        }\n-                        state.output.link(result, turbo_tasks)\n-                    }\n-                }\n-                Err(err) => {\n-                    let err = anyhow::Error::new(err).context(\n-                        if let Some(name) = self.get_function_name() {\n-                            format!(\"Execution of {name} failed\")\n-                        } else {\n-                            \"Execution failed\".to_string()\n-                        },\n-                    );\n-\n-                    state.output.error(err, turbo_tasks)\n-                }\n-            },\n-\n-            Dirty { .. } | Scheduled { .. } | Done { .. } => {\n-                panic!(\n-                    \"Task execution completed in unexpected state {}\",\n-                    Task::state_string(&state)\n-                )\n-            }\n-        };\n-    }\n-\n-    #[must_use]\n-    pub(crate) fn execution_completed(\n-        &self,\n-        duration: Duration,\n-        memory_usage: usize,\n-        generation: NonZeroU32,\n-        cell_counters: &AutoMap<ValueTypeId, u32, BuildHasherDefault<FxHasher>, 8>,\n-        stateful: bool,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> bool {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut schedule_task = false;\n-        {\n-            let mut change_job = None;\n-            let mut remove_job = None;\n-            let mut drained_cells = SmallVec::<[Cell; 8]>::new();\n-            let dependencies = turbo_tasks\n-                .write_task_state(|deps| std::mem::take(&mut deps.dependencies_to_track));\n-            {\n-                let mut state = self.full_state_mut();\n-\n-                state\n-                    .gc\n-                    .execution_completed(duration, memory_usage, generation);\n-\n-                let TaskState {\n-                    ref mut cells,\n-                    ref mut state_type,\n-                    ..\n-                } = *state;\n-\n-                let InProgress(box InProgressState {\n-                    ref mut done_event,\n-                    count_as_finished,\n-                    ref mut outdated_edges,\n-                    ref mut outdated_collectibles,\n-                    ref mut new_children,\n-                    clean,\n-                    stale,\n-                }) = *state_type\n-                else {\n-                    panic!(\n-                        \"Task execution completed in unexpected state {}\",\n-                        Task::state_string(&state)\n-                    )\n-                };\n-                for (value_type, cells) in cells.iter_mut() {\n-                    let counter =\n-                        cell_counters.get(value_type).copied().unwrap_or_default() as usize;\n-                    let mut is_unused = true;\n-                    while counter < cells.len() {\n-                        let last = cells.last_mut().unwrap();\n-                        last.empty(clean, turbo_tasks);\n-                        if is_unused {\n-                            if last.is_unused() {\n-                                drained_cells.push(cells.pop().unwrap());\n-                            } else {\n-                                is_unused = false;\n-                            }\n-                        }\n-                    }\n-                }\n-                let done_event = done_event.take();\n-                let outdated_collectibles = outdated_collectibles.take_collectibles();\n-                let mut outdated_edges = take(outdated_edges);\n-                let mut new_edges = dependencies;\n-                let new_children = take(new_children);\n-                if stale {\n-                    for dep in new_edges.into_iter() {\n-                        // TODO Could be more efficent\n-                        outdated_edges.insert(dep);\n-                    }\n-                    for child in new_children {\n-                        outdated_edges.insert(TaskEdge::Child(child));\n-                    }\n-                    if !outdated_collectibles.is_empty() {\n-                        let mut change = TaskChange::default();\n-                        for ((trait_type, value), count) in outdated_collectibles.into_iter() {\n-                            change.collectibles.push((trait_type, value, -count));\n-                        }\n-                        change_job = state\n-                            .aggregation_node\n-                            .apply_change(&aggregation_context, change);\n-                    }\n-                    let description = self.get_event_description();\n-                    let start_event =\n-                        Event::new(move || format!(\"TaskState({})::start_event\", description()));\n-                    state.state_type = Scheduled(Box::new(ScheduledState {\n-                        start_event,\n-                        done_event,\n-                        outdated_edges: Box::new(outdated_edges),\n-                        clean: false,\n-                    }));\n-                    drop(state);\n-                    schedule_task = true;\n-                } else {\n-                    outdated_edges.remove_all(&new_edges);\n-                    for child in new_children {\n-                        new_edges.insert(TaskEdge::Child(child));\n-                    }\n-                    if !backend.has_gc() {\n-                        // This will stay here for longer, so make sure to not consume too\n-                        // much memory\n-                        for cells in state.cells.values_mut() {\n-                            cells.shrink_to_fit();\n-                        }\n-                        state.cells.shrink_to_fit();\n-                    }\n-                    state.state_type = Done {\n-                        stateful,\n-                        edges: new_edges.into_list(),\n-                    };\n-                    let outdated_children = outdated_edges.drain_children();\n-                    if !outdated_children.is_empty() {\n-                        remove_job = state.aggregation_node.handle_lost_edges(\n-                            &aggregation_context,\n-                            &self.id,\n-                            outdated_children,\n-                        );\n-                    }\n-                    if !count_as_finished {\n-                        let mut change = TaskChange {\n-                            unfinished: -1,\n-                            #[cfg(feature = \"track_unfinished\")]\n-                            unfinished_tasks_update: vec![(self.id, -1)],\n-                            ..Default::default()\n-                        };\n-                        for ((trait_type, value), count) in outdated_collectibles.into_iter() {\n-                            change.collectibles.push((trait_type, value, -count));\n-                        }\n-                        change_job = state\n-                            .aggregation_node\n-                            .apply_change(&aggregation_context, change);\n-                    } else if !outdated_collectibles.is_empty() {\n-                        let mut change = TaskChange::default();\n-                        for ((trait_type, value), count) in outdated_collectibles.into_iter() {\n-                            change.collectibles.push((trait_type, value, -count));\n-                        }\n-                        change_job = state\n-                            .aggregation_node\n-                            .apply_change(&aggregation_context, change);\n-                    }\n-\n-                    done_event.notify(usize::MAX);\n-                    drop(state);\n-                    self.clear_dependencies(outdated_edges, backend, turbo_tasks);\n-                }\n-            }\n-            for cell in drained_cells {\n-                cell.gc_drop(turbo_tasks);\n-            }\n-            remove_job.apply(&aggregation_context);\n-            change_job.apply(&aggregation_context);\n-        }\n-        if let TaskType::Once(_) = self.ty {\n-            // unset the root type, so tasks below are no longer active\n-            aggregation_context.aggregation_data(self.id).root_type = None;\n-        }\n-        aggregation_context.apply_queued_updates();\n-\n-        schedule_task\n-    }\n-\n-    fn make_dirty(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        if let TaskType::Once(_) = self.ty {\n-            // once task won't become dirty\n-            return;\n-        }\n-\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let should_schedule =\n-            query_root_info(&aggregation_context, ActiveQuery::default(), self.id);\n-\n-        if let TaskMetaStateWriteGuard::Full(mut state) = self.state_mut() {\n-            match state.state_type {\n-                Scheduled(box ScheduledState { ref mut clean, .. }) => {\n-                    *clean = false;\n-\n-                    // already scheduled\n-                    drop(state);\n-                }\n-                Dirty { .. } => {\n-                    // already dirty\n-                    drop(state);\n-                }\n-                Done { ref mut edges, .. } => {\n-                    let outdated_edges = take(edges).into_set();\n-                    // add to dirty lists and potentially schedule\n-                    if should_schedule {\n-                        let change_job = state.aggregation_node.apply_change(\n-                            &aggregation_context,\n-                            TaskChange {\n-                                unfinished: 1,\n-                                #[cfg(feature = \"track_unfinished\")]\n-                                unfinished_tasks_update: vec![(self.id, 1)],\n-                                ..Default::default()\n-                            },\n-                        );\n-                        let description = self.get_event_description();\n-                        let description2 = description.clone();\n-                        state.state_type = Scheduled(Box::new(ScheduledState {\n-                            done_event: Event::new(move || {\n-                                format!(\"TaskState({})::done_event\", description())\n-                            }),\n-                            start_event: Event::new(move || {\n-                                format!(\"TaskState({})::start_event\", description2())\n-                            }),\n-                            outdated_edges: Box::new(outdated_edges),\n-                            clean: false,\n-                        }));\n-                        drop(state);\n-                        change_job.apply(&aggregation_context);\n-\n-                        if backend.print_task_invalidation {\n-                            println!(\"invalidated Task {{ id: {}, name: {} }}\", *self.id, self.ty);\n-                        }\n-                        turbo_tasks.schedule(self.id);\n-                    } else {\n-                        let change_job = state.aggregation_node.apply_change(\n-                            &aggregation_context,\n-                            TaskChange {\n-                                unfinished: 1,\n-                                #[cfg(feature = \"track_unfinished\")]\n-                                unfinished_tasks_update: vec![(self.id, 1)],\n-                                dirty_tasks_update: vec![(self.id, 1)],\n-                                ..Default::default()\n-                            },\n-                        );\n-                        state.state_type = Dirty {\n-                            outdated_edges: Box::new(outdated_edges),\n-                        };\n-                        drop(state);\n-                        change_job.apply(&aggregation_context);\n-                    }\n-                }\n-                InProgress(box InProgressState {\n-                    ref mut count_as_finished,\n-                    ref mut clean,\n-                    ref mut stale,\n-                    ..\n-                }) => {\n-                    if !*stale {\n-                        *clean = false;\n-                        *stale = true;\n-                        let change_job = if *count_as_finished {\n-                            *count_as_finished = false;\n-                            let change = TaskChange {\n-                                unfinished: 1,\n-                                #[cfg(feature = \"track_unfinished\")]\n-                                unfinished_tasks_update: vec![(self.id, 1)],\n-                                ..Default::default()\n-                            };\n-                            Some(\n-                                state\n-                                    .aggregation_node\n-                                    .apply_change(&aggregation_context, change),\n-                            )\n-                        } else {\n-                            None\n-                        };\n-                        drop(state);\n-                        change_job.apply(&aggregation_context);\n-                    }\n-                }\n-            }\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    /// Called when the task need to be recomputed because a gc'ed cell was\n-    /// read.\n-    pub(crate) fn recompute(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let _span = tracing::trace_span!(\"turbo_tasks::recompute\", id = *self.id).entered();\n-\n-        // Events that lead to recomputation of non-pure task must not happen\n-        assert!(self.is_pure());\n-\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut state = self.full_state_mut();\n-        match state.state_type {\n-            Scheduled { .. } => {\n-                // already scheduled\n-                drop(state);\n-            }\n-            InProgress(..) => {\n-                // already in progress\n-                drop(state);\n-            }\n-            Dirty {\n-                ref mut outdated_edges,\n-            } => {\n-                let description = self.get_event_description();\n-                let description2 = description.clone();\n-                state.state_type = Scheduled(Box::new(ScheduledState {\n-                    start_event: Event::new(move || {\n-                        format!(\"TaskState({})::start_event\", description())\n-                    }),\n-                    done_event: Event::new(move || {\n-                        format!(\"TaskState({})::done_event\", description2())\n-                    }),\n-                    outdated_edges: take(outdated_edges),\n-                    clean: false,\n-                }));\n-                let change_job = state.aggregation_node.apply_change(\n-                    &aggregation_context,\n-                    TaskChange {\n-                        dirty_tasks_update: vec![(self.id, -1)],\n-                        ..Default::default()\n-                    },\n-                );\n-                drop(state);\n-                change_job.apply(&aggregation_context);\n-                turbo_tasks.schedule(self.id);\n-            }\n-            Done { ref mut edges, .. } => {\n-                let outdated_edges = take(edges).into_set();\n-                // add to dirty lists and potentially schedule\n-                let change_job = state.aggregation_node.apply_change(\n-                    &aggregation_context,\n-                    TaskChange {\n-                        unfinished: 1,\n-                        #[cfg(feature = \"track_unfinished\")]\n-                        unfinished_tasks_update: vec![(self.id, 1)],\n-                        ..Default::default()\n-                    },\n-                );\n-                let description = self.get_event_description();\n-                let description2 = description.clone();\n-                state.state_type = Scheduled(Box::new(ScheduledState {\n-                    start_event: Event::new(move || {\n-                        format!(\"TaskState({})::start_event\", description())\n-                    }),\n-                    done_event: Event::new(move || {\n-                        format!(\"TaskState({})::done_event\", description2())\n-                    }),\n-                    outdated_edges: Box::new(outdated_edges),\n-                    clean: true,\n-                }));\n-                drop(state);\n-                change_job.apply(&aggregation_context);\n-\n-                turbo_tasks.schedule(self.id);\n-            }\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn schedule_when_dirty_from_aggregation(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut state = self.full_state_mut();\n-        if let TaskStateType::Dirty {\n-            ref mut outdated_edges,\n-        } = state.state_type\n-        {\n-            let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-            let description = self.get_event_description();\n-            let description2 = description.clone();\n-            state.state_type = Scheduled(Box::new(ScheduledState {\n-                start_event: Event::new(move || {\n-                    format!(\"TaskState({})::start_event\", description())\n-                }),\n-                done_event: Event::new(move || {\n-                    format!(\"TaskState({})::done_event\", description2())\n-                }),\n-                outdated_edges: take(outdated_edges),\n-                clean: false,\n-            }));\n-            let job = state.aggregation_node.apply_change(\n-                &aggregation_context,\n-                TaskChange {\n-                    dirty_tasks_update: vec![(self.id, -1)],\n-                    ..Default::default()\n-                },\n-            );\n-            drop(state);\n-            turbo_tasks.schedule(self.id);\n-            job.apply(&aggregation_context);\n-            aggregation_context.apply_queued_updates();\n-        }\n-    }\n-\n-    pub(crate) fn add_dependency_to_current(\n-        dep: TaskEdge,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        turbo_tasks.write_task_state(|ts| {\n-            ts.dependencies_to_track.insert(dep);\n-        });\n-    }\n-\n-    /// Get an [Invalidator] that can be used to invalidate the current [Task]\n-    /// based on external events.\n-    pub fn get_invalidator() -> Invalidator {\n-        get_invalidator()\n-    }\n-\n-    /// Called by the [Invalidator]. Invalidate the [Task]. When the task is\n-    /// active it will be scheduled for execution.\n-    pub(crate) fn invalidate(\n-        &self,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        self.make_dirty(backend, turbo_tasks)\n-    }\n-\n-    /// Access to the output cell.\n-    pub(crate) fn access_output_for_removing_dependents<T>(\n-        &self,\n-        func: impl FnOnce(&mut Output) -> T,\n-    ) -> Option<T> {\n-        if let TaskMetaStateWriteGuard::Full(mut state) = self.state_mut() {\n-            Some(func(&mut state.output))\n-        } else {\n-            None\n-        }\n-    }\n-\n-    /// Read a cell.\n-    pub(crate) fn read_cell(\n-        &self,\n-        index: CellId,\n-        gc_queue: Option<&GcQueue>,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-        reader: Option<TaskId>,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<CellContent, ReadCellError> {\n-        let task_id = self.id;\n-        let mut state = self.full_state_mut();\n-        if let Some(gc_queue) = gc_queue {\n-            let generation = gc_queue.generation();\n-            if state.gc.on_read(generation) {\n-                let _ = gc_queue.task_accessed(self.id);\n-            }\n-        }\n-        match state.state_type {\n-            Done { .. } | InProgress(..) => {\n-                let is_done = matches!(state.state_type, Done { .. });\n-                let list = state.cells.entry(index.type_id).or_default();\n-                let i = index.index as usize;\n-                if list.len() <= i {\n-                    list.resize_with(i + 1, Default::default);\n-                }\n-                let cell = &mut list[i];\n-                let description = move || format!(\"{task_id} {index}\");\n-                let read_result = if let Some(reader) = reader {\n-                    cell.read_content(reader, is_done, description, note)\n-                } else {\n-                    cell.read_content_untracked(is_done, description, note)\n-                };\n-                drop(state);\n-                match read_result {\n-                    Ok(content) => Ok(content),\n-                    Err(ReadContentError::Computing { listener, schedule }) => {\n-                        if schedule {\n-                            self.recompute(backend, turbo_tasks);\n-                        }\n-                        Err(ReadCellError::Recomputing(listener))\n-                    }\n-                    Err(ReadContentError::Unused) => Err(ReadCellError::CellRemoved),\n-                }\n-            }\n-            Dirty {\n-                ref mut outdated_edges,\n-            } => {\n-                let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-                let description = self.get_event_description();\n-                let description2 = description.clone();\n-                let start_event =\n-                    Event::new(move || format!(\"TaskState({})::start_event\", description()));\n-                let listener = start_event.listen_with_note(note);\n-                state.state_type = Scheduled(Box::new(ScheduledState {\n-                    start_event,\n-                    done_event: Event::new(move || {\n-                        format!(\"TaskState({})::done_event\", description2())\n-                    }),\n-                    outdated_edges: take(outdated_edges),\n-                    clean: false,\n-                }));\n-                let change_job = state.aggregation_node.apply_change(\n-                    &aggregation_context,\n-                    TaskChange {\n-                        dirty_tasks_update: vec![(self.id, -1)],\n-                        ..Default::default()\n-                    },\n-                );\n-                drop(state);\n-                turbo_tasks.schedule(self.id);\n-                change_job.apply(&aggregation_context);\n-                aggregation_context.apply_queued_updates();\n-                Err(ReadCellError::Recomputing(listener))\n-            }\n-            Scheduled(box ScheduledState {\n-                ref start_event, ..\n-            }) => Err(ReadCellError::Recomputing(\n-                start_event.listen_with_note(note),\n-            )),\n-        }\n-    }\n-\n-    /// Access to a cell.\n-    pub(crate) fn access_cell_for_write<T>(\n-        &self,\n-        index: CellId,\n-        func: impl FnOnce(&mut Cell, bool) -> T,\n-    ) -> T {\n-        let mut state = self.full_state_mut();\n-        let clean = match state.state_type {\n-            InProgress(box InProgressState { clean, .. }) => clean,\n-            _ => false,\n-        };\n-        let list = state.cells.entry(index.type_id).or_default();\n-        let i = index.index as usize;\n-        if list.len() <= i {\n-            list.resize_with(i + 1, Default::default);\n-        }\n-        func(&mut list[i], clean)\n-    }\n-\n-    /// Access to a cell.\n-    pub(crate) fn access_cell_for_removing_dependents<T>(\n-        &self,\n-        index: CellId,\n-        func: impl FnOnce(&mut Cell) -> T,\n-    ) -> Option<T> {\n-        self.state_mut()\n-            .as_full_mut()\n-            .and_then(|state| state.cells.get_mut(&index.type_id))\n-            .and_then(|list| list.get_mut(index.index as usize).map(func))\n-    }\n-\n-    /// Access to a cell.\n-    pub(crate) fn with_cell<T>(&self, index: CellId, func: impl FnOnce(&Cell) -> T) -> T {\n-        if let Some(cell) = self\n-            .state()\n-            .as_full()\n-            .and_then(|state| state.cells.get(&index.type_id))\n-            .and_then(|list| list.get(index.index as usize))\n-        {\n-            func(cell)\n-        } else {\n-            func(&Default::default())\n-        }\n-    }\n-\n-    /// Checks if the task is inactive. Returns false if it's still active.\n-    pub(crate) fn potentially_become_inactive(\n-        &self,\n-        gc_queue: &GcQueue,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> bool {\n-        let aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let active = query_root_info(&aggregation_context, ActiveQuery::default(), self.id);\n-        if active {\n-            return false;\n-        }\n-        if let TaskMetaStateWriteGuard::Full(mut state) = self.state_mut() {\n-            if state.gc.generation.is_none() {\n-                let generation = gc_queue.task_inactive(self.id);\n-                state.gc.generation = Some(generation);\n-            }\n-            for child in state.state_type.children() {\n-                gc_queue.task_potentially_no_longer_active(child);\n-            }\n-        }\n-        true\n-    }\n-\n-    pub fn is_pending(&self) -> bool {\n-        if let TaskMetaStateReadGuard::Full(state) = self.state() {\n-            !matches!(state.state_type, TaskStateType::Done { .. })\n-        } else {\n-            true\n-        }\n-    }\n-\n-    pub fn is_dirty(&self) -> bool {\n-        if let TaskMetaStateReadGuard::Full(state) = self.state() {\n-            matches!(state.state_type, TaskStateType::Dirty { .. })\n-        } else {\n-            false\n-        }\n-    }\n-\n-    fn state_string(state: &TaskState) -> &'static str {\n-        match state.state_type {\n-            Scheduled { .. } => \"scheduled\",\n-            InProgress(box InProgressState { stale: true, .. }) => \"in progress (stale)\",\n-            InProgress(box InProgressState { clean: true, .. }) => \"in progress (clean)\",\n-            InProgress(box InProgressState {\n-                count_as_finished: true,\n-                ..\n-            }) => \"in progress (marked as finished)\",\n-            InProgress(box InProgressState { .. }) => \"in progress\",\n-            Done { .. } => \"done\",\n-            Dirty { .. } => \"dirty\",\n-        }\n-    }\n-\n-    pub(crate) fn connect_child(\n-        &self,\n-        child_id: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        {\n-            let mut add_job = None;\n-            {\n-                let mut state = self.full_state_mut();\n-                match &mut state.state_type {\n-                    TaskStateType::InProgress(box InProgressState {\n-                        outdated_edges,\n-                        new_children,\n-                        ..\n-                    }) => {\n-                        if new_children.insert(child_id) {\n-                            if outdated_edges.remove(TaskEdge::Child(child_id)) {\n-                                drop(state);\n-                                aggregation_context.apply_queued_updates();\n-                                return;\n-                            }\n-                            let number_of_children = new_children.len();\n-                            let mut guard = TaskGuard::from_full(self.id, state);\n-                            add_job = Some(handle_new_edge(\n-                                &aggregation_context,\n-                                &mut guard,\n-                                &self.id,\n-                                &child_id,\n-                                number_of_children,\n-                            ));\n-                        }\n-                    }\n-                    _ => panic!(\"Unexpected task state when adding a child task\"),\n-                }\n-            }\n-            if let Some(job) = add_job {\n-                // To avoid bubbling up the dirty tasks into the new parent tree, we make a\n-                // quick check for activeness of the parent when the child is dirty. This is\n-                // purely an optimization and not required for correctness.\n-                // So it's fine to ignore the race condition existing here.\n-                backend.with_task(child_id, |child| {\n-                    if child.is_dirty() {\n-                        let active =\n-                            query_root_info(&aggregation_context, ActiveQuery::default(), self.id);\n-                        if active {\n-                            child.schedule_when_dirty_from_aggregation(backend, turbo_tasks);\n-                        }\n-                    }\n-                });\n-                job.apply(&aggregation_context);\n-            }\n-        }\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn get_or_wait_output<T, F: FnOnce(&mut Output) -> Result<T>>(\n-        &self,\n-        consistency: ReadConsistency,\n-        func: F,\n-        note: impl Fn() -> String + Sync + Send + 'static,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> Result<Result<T, EventListener>> {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut state = if consistency == ReadConsistency::Strong {\n-            let mut aggregation = aggregation_data(&aggregation_context, &self.id);\n-            if aggregation.unfinished > 0 {\n-                if aggregation.root_type.is_none() {\n-                    Self::set_root_type(\n-                        &aggregation_context,\n-                        &mut aggregation,\n-                        RootType::ReadingStronglyConsistent,\n-                    );\n-                }\n-                let listener = aggregation.unfinished_event.listen_with_note(note);\n-                drop(aggregation);\n-                aggregation_context.apply_queued_updates();\n-\n-                return Ok(Err(listener));\n-            } else if matches!(\n-                aggregation.root_type,\n-                Some(RootType::ReadingStronglyConsistent)\n-            ) {\n-                aggregation.root_type = None;\n-            }\n-            let state = aggregation.into_inner().into_inner().into_inner();\n-            TaskMetaStateWriteGuard::full_from(state)\n-        } else {\n-            self.full_state_mut()\n-        };\n-        let result = match state.state_type {\n-            Done { .. } => {\n-                let result = func(&mut state.output)?;\n-                drop(state);\n-\n-                Ok(Ok(result))\n-            }\n-            Dirty {\n-                ref mut outdated_edges,\n-            } => {\n-                turbo_tasks.schedule(self.id);\n-                let description = self.get_event_description();\n-                let description2 = description.clone();\n-                let done_event =\n-                    Event::new(move || format!(\"TaskState({})::done_event\", description()));\n-                let listener = done_event.listen_with_note(note);\n-                state.state_type = Scheduled(Box::new(ScheduledState {\n-                    start_event: Event::new(move || {\n-                        format!(\"TaskState({})::start_event\", description2())\n-                    }),\n-                    done_event,\n-                    outdated_edges: take(outdated_edges),\n-                    clean: false,\n-                }));\n-                let change_job = state.aggregation_node.apply_change(\n-                    &aggregation_context,\n-                    TaskChange {\n-                        dirty_tasks_update: vec![(self.id, -1)],\n-                        ..Default::default()\n-                    },\n-                );\n-                drop(state);\n-                change_job.apply(&aggregation_context);\n-                Ok(Err(listener))\n-            }\n-            Scheduled(box ScheduledState { ref done_event, .. })\n-            | InProgress(box InProgressState { ref done_event, .. }) => {\n-                let listener = done_event.listen_with_note(note);\n-                drop(state);\n-                Ok(Err(listener))\n-            }\n-        };\n-        aggregation_context.apply_queued_updates();\n-        result\n-    }\n-\n-    pub(crate) fn read_collectibles(\n-        id: TaskId,\n-        trait_type: TraitTypeId,\n-        reader: TaskId,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> TaskCollectiblesMap {\n-        let aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut aggregation_data = aggregation_context.aggregation_data(id);\n-        aggregation_data.read_collectibles(trait_type, reader)\n-    }\n-\n-    pub(crate) fn emit_collectible(\n-        &self,\n-        trait_type: TraitTypeId,\n-        collectible: RawVc,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut state = self.full_state_mut();\n-        state.collectibles.emit(trait_type, collectible);\n-        if let TaskStateType::InProgress(box InProgressState {\n-            outdated_collectibles,\n-            ..\n-        }) = &mut state.state_type\n-        {\n-            if outdated_collectibles.remove_emit(trait_type, collectible) {\n-                return;\n-            }\n-        }\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let change_job = state.aggregation_node.apply_change(\n-            &aggregation_context,\n-            TaskChange {\n-                collectibles: vec![(trait_type, collectible, 1)],\n-                ..Default::default()\n-            },\n-        );\n-        drop(state);\n-        change_job.apply(&aggregation_context);\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn unemit_collectible(\n-        &self,\n-        trait_type: TraitTypeId,\n-        collectible: RawVc,\n-        count: u32,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut state = self.full_state_mut();\n-        state.collectibles.unemit(trait_type, collectible, count);\n-        let change_job = state.aggregation_node.apply_change(\n-            &aggregation_context,\n-            TaskChange {\n-                collectibles: vec![(trait_type, collectible, -(count as i32))],\n-                ..Default::default()\n-            },\n-        );\n-        drop(state);\n-        change_job.apply(&aggregation_context);\n-        aggregation_context.apply_queued_updates();\n-    }\n-\n-    pub(crate) fn run_gc(\n-        &self,\n-        generation: NonZeroU32,\n-        gc_queue: &GcQueue,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> GcResult {\n-        if !self.is_pure() {\n-            return GcResult::NotPossible;\n-        }\n-\n-        let aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let active = query_root_info(&aggregation_context, ActiveQuery::default(), self.id);\n-\n-        match self.state_mut() {\n-            TaskMetaStateWriteGuard::Full(mut state) => {\n-                if let Some(old_gen) = state.gc.generation {\n-                    if old_gen > generation {\n-                        return GcResult::Stale;\n-                    }\n-                } else {\n-                    return GcResult::Stale;\n-                }\n-                state.gc.generation = None;\n-\n-                match &mut state.state_type {\n-                    TaskStateType::Done { stateful, edges: _ } => {\n-                        if *stateful {\n-                            return GcResult::NotPossible;\n-                        }\n-                    }\n-                    TaskStateType::Dirty { .. } => {}\n-                    _ => {\n-                        // GC can't run in this state. We will reschedule it when the execution\n-                        // completes.\n-                        return GcResult::NotPossible;\n-                    }\n-                }\n-\n-                if active {\n-                    let mut cells_to_drop = Vec::new();\n-\n-                    // shrinking memory and dropping cells\n-                    state.aggregation_node.shrink_to_fit();\n-                    state.output.dependent_tasks.shrink_to_fit();\n-                    state.cells.shrink_to_fit();\n-                    for cells in state.cells.values_mut() {\n-                        cells.shrink_to_fit();\n-                        for cell in cells.iter_mut() {\n-                            cells_to_drop.extend(cell.gc_content());\n-                            cell.shrink_to_fit();\n-                        }\n-                    }\n-\n-                    drop(state);\n-\n-                    gc_queue.task_gc_active(self.id);\n-\n-                    // Dropping cells outside of the lock\n-                    drop(cells_to_drop);\n-\n-                    GcResult::ContentDropped\n-                } else {\n-                    // Task is inactive, unload task\n-                    self.unload(state, backend, turbo_tasks);\n-                    GcResult::Unloaded\n-                }\n-            }\n-            TaskMetaStateWriteGuard::Partial(mut state) => {\n-                state.aggregation_node.shrink_to_fit();\n-                GcResult::AlreadyUnloaded\n-            }\n-            TaskMetaStateWriteGuard::Unloaded(_) => GcResult::AlreadyUnloaded,\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-\n-    pub(crate) fn gc_state(&self) -> Option<GcTaskState> {\n-        if let TaskMetaStateReadGuard::Full(state) = self.state() {\n-            Some(state.gc)\n-        } else {\n-            None\n-        }\n-    }\n-\n-    fn unload(\n-        &self,\n-        mut full_state: FullTaskWriteGuard<'_>,\n-        backend: &MemoryBackend,\n-        turbo_tasks: &dyn TurboTasksBackendApi<MemoryBackend>,\n-    ) -> bool {\n-        let mut aggregation_context = TaskAggregationContext::new(turbo_tasks, backend);\n-        let mut change_job = None;\n-        let TaskState {\n-            ref mut aggregation_node,\n-            ref mut state_type,\n-            ..\n-        } = *full_state;\n-        match state_type {\n-            Done { edges: _, stateful } => {\n-                if *stateful {\n-                    return false;\n-                }\n-                change_job = aggregation_node.apply_change(\n-                    &aggregation_context,\n-                    TaskChange {\n-                        unfinished: 1,\n-                        dirty_tasks_update: vec![(self.id, 1)],\n-                        ..Default::default()\n-                    },\n-                );\n-            }\n-            Dirty { outdated_edges: _ } => {}\n-            _ => {\n-                // Any other state is not unloadable.\n-                return false;\n-            }\n-        }\n-        // Task is now dirty, so we can safely unload it\n-\n-        let mut state = full_state.into_inner();\n-        let old_state = replace(\n-            &mut *state,\n-            // placeholder\n-            TaskMetaState::Unloaded(UnloadedTaskState {}),\n-        );\n-        let TaskState {\n-            cells,\n-            output,\n-            collectibles,\n-            mut aggregation_node,\n-            // can be dropped as always Dirty, event has been notified above\n-            state_type,\n-            // can be dropped as only gc meta info\n-            gc: _,\n-        } = old_state.into_full().unwrap();\n-\n-        let (dependencies, children) = state_type.into_dependencies_and_children();\n-\n-        // Remove all children, as they will be added again when this task is executed\n-        // again\n-        let remove_job = (!children.is_empty())\n-            .then(|| aggregation_node.handle_lost_edges(&aggregation_context, &self.id, children));\n-\n-        // Remove all collectibles, as they will be added again when this task is\n-        // executed again.\n-        let collectibles_job = if let Some(collectibles) = collectibles.into_inner() {\n-            aggregation_node.apply_change(\n-                &aggregation_context,\n-                TaskChange {\n-                    collectibles: collectibles\n-                        .into_iter()\n-                        .map(|((t, r), c)| (t, r, -c))\n-                        .collect(),\n-                    ..Default::default()\n-                },\n-            )\n-        } else {\n-            None\n-        };\n-\n-        aggregation_node.shrink_to_fit();\n-\n-        // TODO aggregation_node\n-        let unset = false;\n-\n-        if unset {\n-            *state = TaskMetaState::Unloaded(UnloadedTaskState {});\n-        } else {\n-            *state = TaskMetaState::Partial(Box::new(PartialTaskState { aggregation_node }));\n-        }\n-        drop(state);\n-\n-        change_job.apply(&aggregation_context);\n-        remove_job.apply(&aggregation_context);\n-        collectibles_job.apply(&aggregation_context);\n-\n-        // Notify everyone that is listening on our output or cells.\n-        // This will mark everyone as dirty and will trigger a new execution when they\n-        // become active again.\n-        for cells in cells.into_values() {\n-            for cell in cells {\n-                cell.gc_drop(turbo_tasks);\n-            }\n-        }\n-        output.gc_drop(turbo_tasks);\n-\n-        // TODO This is a race condition, the task might be executed again while\n-        // removing dependencies.\n-        // We can clear the dependencies as we are already marked as dirty\n-        self.clear_dependencies(dependencies, backend, turbo_tasks);\n-\n-        aggregation_context.apply_queued_updates();\n-\n-        true\n-    }\n-}\n-\n-impl Display for Task {\n-    fn fmt(&self, f: &mut Formatter<'_>) -> fmt::Result {\n-        if let TaskMetaStateReadGuard::Full(state) = self.state() {\n-            write!(\n-                f,\n-                \"Task({}, {})\",\n-                self.get_description(),\n-                Task::state_string(&state)\n-            )\n-        } else {\n-            write!(f, \"Task({}, unloaded)\", self.get_description())\n-        }\n-    }\n-}\n-\n-impl Hash for Task {\n-    fn hash<H: std::hash::Hasher>(&self, state: &mut H) {\n-        Hash::hash(&(self as *const Task), state)\n-    }\n-}\n-\n-impl PartialEq for Task {\n-    fn eq(&self, other: &Self) -> bool {\n-        std::ptr::eq(self, other)\n-    }\n-}\n-\n-impl Eq for Task {}"
        },
        {
            "sha": "eb2d88b7ba5723637cd1b1cc59e6f9b3e12399ce",
            "filename": "turbopack/crates/turbo-tasks-memory/src/task/aggregation.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 692,
            "changes": 692,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Faggregation.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Faggregation.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Faggregation.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,692 +0,0 @@\n-use std::{\n-    cmp::Ordering,\n-    hash::{BuildHasher, BuildHasherDefault, Hash},\n-    mem::take,\n-    ops::{ControlFlow, Deref, DerefMut},\n-    sync::atomic::AtomicU32,\n-};\n-\n-use auto_hash_map::{AutoMap, map::Entry};\n-use either::Either;\n-use parking_lot::Mutex;\n-use rustc_hash::FxHasher;\n-use turbo_tasks::{\n-    RawVc, TaskId, TaskIdSet, TraitTypeId, TurboTasksBackendApi, backend::TaskCollectiblesMap,\n-    event::Event,\n-};\n-\n-use super::{\n-    InProgressState, TaskStateType,\n-    meta_state::{FullTaskWriteGuard, TaskMetaStateWriteGuard},\n-};\n-use crate::{\n-    MemoryBackend,\n-    aggregation::{\n-        AggregationContext, AggregationDataGuard, AggregationNode, AggregationNodeGuard, RootQuery,\n-        aggregation_data,\n-    },\n-};\n-\n-pub enum RootType {\n-    Once,\n-    Root,\n-    ReadingStronglyConsistent,\n-}\n-\n-#[derive(Debug, Default)]\n-pub struct CollectiblesInfo {\n-    collectibles: TaskCollectiblesMap,\n-    dependent_tasks: TaskIdSet,\n-}\n-\n-impl CollectiblesInfo {\n-    fn is_unset(&self) -> bool {\n-        self.collectibles.is_empty() && self.dependent_tasks.is_empty()\n-    }\n-}\n-\n-pub struct Aggregated {\n-    /// The number of unfinished items in the lower aggregation level.\n-    /// Unfinished means not \"Done\".\n-    // TODO determine if this can go negative in concurrent situations.\n-    pub unfinished: i32,\n-    /// Event that will be notified when all unfinished tasks are done.\n-    pub unfinished_event: Event,\n-    /// A list of all tasks that are unfinished. Only for debugging.\n-    #[cfg(feature = \"track_unfinished\")]\n-    pub unfinished_tasks: AutoMap<TaskId, i32, BuildHasherDefault<FxHasher>>,\n-    /// A list of all tasks that are dirty.\n-    /// When the it becomes active, these need to be scheduled.\n-    // TODO evaluate a more efficient data structure for this since we are copying the list on\n-    // every level.\n-    pub dirty_tasks: AutoMap<TaskId, i32, BuildHasherDefault<FxHasher>>,\n-    /// Emitted collectibles with count and dependent_tasks by trait type\n-    pub collectibles: AutoMap<TraitTypeId, CollectiblesInfo, BuildHasherDefault<FxHasher>>,\n-\n-    /// Only used for the aggregation root. Which kind of root is this?\n-    /// [RootType::Once] for OnceTasks or [RootType::Root] for Root Tasks.\n-    /// [RootType::ReadingStronglyConsistent] while currently reading a task\n-    /// strongly consistent. It's set to None for other tasks, when the once\n-    /// task is done or when the root task is disposed.\n-    pub root_type: Option<RootType>,\n-}\n-\n-impl Default for Aggregated {\n-    fn default() -> Self {\n-        Self {\n-            unfinished: 0,\n-            unfinished_event: Event::new(|| \"Aggregated::unfinished_event\".to_string()),\n-            #[cfg(feature = \"track_unfinished\")]\n-            unfinished_tasks: AutoMap::with_hasher(),\n-            dirty_tasks: AutoMap::with_hasher(),\n-            collectibles: AutoMap::with_hasher(),\n-            root_type: None,\n-        }\n-    }\n-}\n-\n-impl Aggregated {\n-    pub(crate) fn remove_collectible_dependent_task(\n-        &mut self,\n-        trait_type: TraitTypeId,\n-        reader: TaskId,\n-    ) {\n-        if let Entry::Occupied(mut entry) = self.collectibles.entry(trait_type) {\n-            let info = entry.get_mut();\n-            let removed = info.dependent_tasks.remove(&reader);\n-            if removed && info.is_unset() {\n-                entry.remove();\n-            }\n-        }\n-    }\n-\n-    pub(crate) fn read_collectibles(\n-        &mut self,\n-        trait_type: TraitTypeId,\n-        reader: TaskId,\n-    ) -> TaskCollectiblesMap {\n-        match self.collectibles.entry(trait_type) {\n-            Entry::Occupied(mut e) => {\n-                let info = e.get_mut();\n-                info.dependent_tasks.insert(reader);\n-                info.collectibles.clone()\n-            }\n-            Entry::Vacant(e) => {\n-                e.insert(CollectiblesInfo::default())\n-                    .dependent_tasks\n-                    .insert(reader);\n-                AutoMap::default()\n-            }\n-        }\n-    }\n-}\n-\n-#[derive(Default, Debug)]\n-pub struct TaskChange {\n-    pub unfinished: i32,\n-    #[cfg(feature = \"track_unfinished\")]\n-    pub unfinished_tasks_update: Vec<(TaskId, i32)>,\n-    pub dirty_tasks_update: Vec<(TaskId, i32)>,\n-    pub collectibles: Vec<(TraitTypeId, RawVc, i32)>,\n-}\n-\n-impl TaskChange {\n-    pub fn is_empty(&self) -> bool {\n-        #[allow(unused_mut, reason = \"feature flag\")]\n-        let mut empty = self.unfinished == 0\n-            && self.dirty_tasks_update.is_empty()\n-            && self.collectibles.is_empty();\n-        #[cfg(feature = \"track_unfinished\")]\n-        if !self.unfinished_tasks_update.is_empty() {\n-            empty = false;\n-        }\n-        empty\n-    }\n-}\n-\n-pub struct TaskAggregationContext<'a> {\n-    pub turbo_tasks: &'a dyn TurboTasksBackendApi<MemoryBackend>,\n-    pub backend: &'a MemoryBackend,\n-    pub dirty_tasks_to_schedule: Mutex<Option<TaskIdSet>>,\n-    pub tasks_to_notify: Mutex<Option<TaskIdSet>>,\n-}\n-\n-impl<'a> TaskAggregationContext<'a> {\n-    pub fn new(\n-        turbo_tasks: &'a dyn TurboTasksBackendApi<MemoryBackend>,\n-        backend: &'a MemoryBackend,\n-    ) -> Self {\n-        Self {\n-            turbo_tasks,\n-            backend,\n-            dirty_tasks_to_schedule: Mutex::new(None),\n-            tasks_to_notify: Mutex::new(None),\n-        }\n-    }\n-\n-    pub fn apply_queued_updates(&mut self) {\n-        {\n-            let mut _span = None;\n-            let tasks = self.dirty_tasks_to_schedule.get_mut();\n-            if let Some(tasks) = tasks.as_mut() {\n-                let tasks = take(tasks);\n-                if !tasks.is_empty() {\n-                    _span.get_or_insert_with(|| {\n-                        tracing::trace_span!(\"task aggregation apply_queued_updates\").entered()\n-                    });\n-                    self.backend\n-                        .schedule_when_dirty_from_aggregation(tasks, self.turbo_tasks);\n-                }\n-            }\n-        }\n-        let tasks = self.tasks_to_notify.get_mut();\n-        if let Some(tasks) = tasks.as_mut() {\n-            let tasks = take(tasks);\n-            if !tasks.is_empty() {\n-                self.turbo_tasks.schedule_notify_tasks_set(&tasks);\n-            }\n-        }\n-    }\n-\n-    pub fn aggregation_data(&self, id: TaskId) -> AggregationDataGuard<TaskGuard<'_>> {\n-        aggregation_data(self, &id)\n-    }\n-}\n-\n-#[cfg(debug_assertions)]\n-impl Drop for TaskAggregationContext<'_> {\n-    fn drop(&mut self) {\n-        let tasks_to_schedule = self.dirty_tasks_to_schedule.get_mut();\n-        if let Some(tasks_to_schedule) = tasks_to_schedule.as_ref() {\n-            if !tasks_to_schedule.is_empty() {\n-                panic!(\"TaskAggregationContext dropped without scheduling all tasks\");\n-            }\n-        }\n-        let tasks_to_notify = self.tasks_to_notify.get_mut();\n-        if let Some(tasks_to_notify) = tasks_to_notify.as_ref() {\n-            if !tasks_to_notify.is_empty() {\n-                panic!(\"TaskAggregationContext dropped without notifying all tasks\");\n-            }\n-        }\n-    }\n-}\n-\n-impl AggregationContext for TaskAggregationContext<'_> {\n-    type Guard<'l>\n-        = TaskGuard<'l>\n-    where\n-        Self: 'l;\n-    type Data = Aggregated;\n-    type DataChange = TaskChange;\n-    type NodeRef = TaskId;\n-\n-    fn node<'b>(&'b self, reference: &TaskId) -> Self::Guard<'b> {\n-        let task = self.backend.task(*reference);\n-        TaskGuard::new(*reference, task.state_mut())\n-    }\n-\n-    fn node_pair<'l>(\n-        &'l self,\n-        id1: &Self::NodeRef,\n-        id2: &Self::NodeRef,\n-    ) -> (Self::Guard<'l>, Self::Guard<'l>) {\n-        let task1 = self.backend.task(*id1);\n-        let task2 = self.backend.task(*id2);\n-        loop {\n-            {\n-                let state1 = task1.state_mut();\n-                if let Some(state2) = task2.try_state_mut() {\n-                    return (TaskGuard::new(*id1, state1), TaskGuard::new(*id2, state2));\n-                }\n-            }\n-            {\n-                let state2 = task2.state_mut();\n-                if let Some(state1) = task1.try_state_mut() {\n-                    return (TaskGuard::new(*id1, state1), TaskGuard::new(*id2, state2));\n-                }\n-            }\n-        }\n-    }\n-\n-    fn atomic_in_progress_counter<'l>(&self, id: &'l TaskId) -> &'l AtomicU32\n-    where\n-        Self: 'l,\n-    {\n-        &self\n-            .backend\n-            .task(*id)\n-            .graph_modification_in_progress_counter\n-    }\n-\n-    fn apply_change(\n-        &self,\n-        info: &mut Aggregated,\n-        change: &Self::DataChange,\n-    ) -> Option<Self::DataChange> {\n-        let mut unfinished = 0;\n-        if info.unfinished > 0 {\n-            info.unfinished += change.unfinished;\n-            if info.unfinished <= 0 {\n-                info.unfinished_event.notify(usize::MAX);\n-                unfinished = -1;\n-            }\n-        } else {\n-            info.unfinished += change.unfinished;\n-            if info.unfinished > 0 {\n-                unfinished = 1;\n-            }\n-        }\n-        #[cfg(feature = \"track_unfinished\")]\n-        let mut unfinished_tasks_update = Vec::new();\n-        #[cfg(feature = \"track_unfinished\")]\n-        for &(task, count) in change.unfinished_tasks_update.iter() {\n-            match update_count_entry(info.unfinished_tasks.entry(task), count) {\n-                (_, UpdateCountEntryChange::Removed) => unfinished_tasks_update.push((task, -1)),\n-                (_, UpdateCountEntryChange::Inserted) => unfinished_tasks_update.push((task, 1)),\n-                _ => {}\n-            }\n-        }\n-        let mut dirty_tasks_update = Vec::new();\n-        let is_root = info.root_type.is_some();\n-        for &(task, count) in change.dirty_tasks_update.iter() {\n-            match update_count_entry(info.dirty_tasks.entry(task), count) {\n-                (_, UpdateCountEntryChange::Removed) => dirty_tasks_update.push((task, -1)),\n-                (_, UpdateCountEntryChange::Inserted) => {\n-                    if is_root {\n-                        let mut tasks_to_schedule = self.dirty_tasks_to_schedule.lock();\n-                        tasks_to_schedule.get_or_insert_default().insert(task);\n-                    }\n-                    dirty_tasks_update.push((task, 1))\n-                }\n-                _ => {}\n-            }\n-        }\n-        for &(trait_type_id, collectible, count) in change.collectibles.iter() {\n-            let collectibles_info_entry = info.collectibles.entry(trait_type_id);\n-            match collectibles_info_entry {\n-                Entry::Occupied(mut e) => {\n-                    let collectibles_info = e.get_mut();\n-                    let (value, _) = update_count_entry(\n-                        collectibles_info.collectibles.entry(collectible),\n-                        count,\n-                    );\n-                    if !collectibles_info.dependent_tasks.is_empty() {\n-                        self.tasks_to_notify\n-                            .lock()\n-                            .get_or_insert_default()\n-                            .extend(take(&mut collectibles_info.dependent_tasks).into_iter());\n-                    }\n-                    if value == 0 && collectibles_info.is_unset() {\n-                        e.remove();\n-                    }\n-                }\n-                Entry::Vacant(e) => {\n-                    let mut collectibles_info = CollectiblesInfo::default();\n-                    collectibles_info.collectibles.insert(collectible, count);\n-                    e.insert(collectibles_info);\n-                }\n-            }\n-        }\n-        #[cfg(feature = \"track_unfinished\")]\n-        if info.unfinished > 0 && info.unfinished_tasks.is_empty()\n-            || info.unfinished == 0 && !info.unfinished_tasks.is_empty()\n-        {\n-            panic!(\n-                \"inconsistent state: unfinished {}, unfinished_tasks {:?}, change {:?}\",\n-                info.unfinished, info.unfinished_tasks, change\n-            );\n-        }\n-        let new_change = TaskChange {\n-            unfinished,\n-            #[cfg(feature = \"track_unfinished\")]\n-            unfinished_tasks_update,\n-            dirty_tasks_update,\n-            collectibles: change.collectibles.clone(),\n-        };\n-        if new_change.is_empty() {\n-            None\n-        } else {\n-            Some(new_change)\n-        }\n-    }\n-\n-    fn data_to_add_change(&self, data: &Aggregated) -> Option<Self::DataChange> {\n-        let mut change = TaskChange::default();\n-        if data.unfinished > 0 {\n-            change.unfinished = 1;\n-        }\n-        #[cfg(feature = \"track_unfinished\")]\n-        for (&task, &count) in data.unfinished_tasks.iter() {\n-            if count > 0 {\n-                change.unfinished_tasks_update.push((task, 1));\n-            }\n-        }\n-        for (&task, &count) in data.dirty_tasks.iter() {\n-            if count > 0 {\n-                change.dirty_tasks_update.push((task, 1));\n-            }\n-        }\n-        for (trait_type_id, collectibles_info) in data.collectibles.iter() {\n-            for (collectible, count) in collectibles_info.collectibles.iter() {\n-                change\n-                    .collectibles\n-                    .push((*trait_type_id, *collectible, *count));\n-            }\n-        }\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-\n-    fn data_to_remove_change(&self, data: &Aggregated) -> Option<Self::DataChange> {\n-        let mut change = TaskChange::default();\n-        if data.unfinished > 0 {\n-            change.unfinished = -1;\n-        }\n-        #[cfg(feature = \"track_unfinished\")]\n-        for (&task, &count) in data.unfinished_tasks.iter() {\n-            change.unfinished_tasks_update.push((task, -count));\n-        }\n-        for (&task, &count) in data.dirty_tasks.iter() {\n-            if count > 0 {\n-                change.dirty_tasks_update.push((task, -1));\n-            }\n-        }\n-        for (trait_type_id, collectibles_info) in data.collectibles.iter() {\n-            for (collectible, count) in collectibles_info.collectibles.iter() {\n-                change\n-                    .collectibles\n-                    .push((*trait_type_id, *collectible, -*count));\n-            }\n-        }\n-        if change.is_empty() {\n-            None\n-        } else {\n-            Some(change)\n-        }\n-    }\n-}\n-\n-#[derive(Default)]\n-pub struct ActiveQuery {\n-    active: bool,\n-}\n-\n-impl RootQuery for ActiveQuery {\n-    type Data = Aggregated;\n-    type Result = bool;\n-\n-    fn query(&mut self, data: &Self::Data) -> ControlFlow<()> {\n-        if data.root_type.is_some() {\n-            self.active = true;\n-            ControlFlow::Break(())\n-        } else {\n-            ControlFlow::Continue(())\n-        }\n-    }\n-\n-    fn result(self) -> Self::Result {\n-        self.active\n-    }\n-}\n-\n-pub struct TaskGuard<'l> {\n-    id: TaskId,\n-    guard: TaskMetaStateWriteGuard<'l>,\n-}\n-\n-impl<'l> TaskGuard<'l> {\n-    pub fn new(id: TaskId, mut guard: TaskMetaStateWriteGuard<'l>) -> Self {\n-        guard.ensure_at_least_partial();\n-        Self { id, guard }\n-    }\n-\n-    pub fn from_full(id: TaskId, guard: FullTaskWriteGuard<'l>) -> Self {\n-        Self {\n-            id,\n-            guard: TaskMetaStateWriteGuard::Full(guard),\n-        }\n-    }\n-\n-    pub fn into_inner(self) -> TaskMetaStateWriteGuard<'l> {\n-        self.guard\n-    }\n-}\n-\n-impl Deref for TaskGuard<'_> {\n-    type Target = AggregationNode<\n-        <Self as AggregationNodeGuard>::NodeRef,\n-        <Self as AggregationNodeGuard>::Data,\n-    >;\n-\n-    fn deref(&self) -> &Self::Target {\n-        match self.guard {\n-            TaskMetaStateWriteGuard::Full(ref guard) => &guard.aggregation_node,\n-            TaskMetaStateWriteGuard::Partial(ref guard) => &guard.aggregation_node,\n-            TaskMetaStateWriteGuard::Unloaded(_) => unreachable!(),\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-}\n-\n-impl DerefMut for TaskGuard<'_> {\n-    fn deref_mut(&mut self) -> &mut Self::Target {\n-        match self.guard {\n-            TaskMetaStateWriteGuard::Full(ref mut guard) => &mut guard.aggregation_node,\n-            TaskMetaStateWriteGuard::Partial(ref mut guard) => &mut guard.aggregation_node,\n-            TaskMetaStateWriteGuard::Unloaded(_) => unreachable!(),\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-}\n-\n-impl AggregationNodeGuard for TaskGuard<'_> {\n-    type Data = Aggregated;\n-    type NodeRef = TaskId;\n-    type DataChange = TaskChange;\n-    type ChildrenIter<'a>\n-        = impl Iterator<Item = TaskId> + 'a\n-    where\n-        Self: 'a;\n-\n-    fn children(&self) -> Self::ChildrenIter<'_> {\n-        match self.guard {\n-            TaskMetaStateWriteGuard::Full(ref guard) => Either::Left(guard.state_type.children()),\n-            TaskMetaStateWriteGuard::Partial(_) | TaskMetaStateWriteGuard::Unloaded(_) => {\n-                Either::Right(std::iter::empty())\n-            }\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-\n-    fn get_add_change(&self) -> Option<Self::DataChange> {\n-        match self.guard {\n-            TaskMetaStateWriteGuard::Full(ref guard) => {\n-                let mut change = TaskChange::default();\n-                if !matches!(\n-                    guard.state_type,\n-                    TaskStateType::Done { .. }\n-                        | TaskStateType::InProgress (box InProgressState{\n-                            count_as_finished: true,\n-                            ..\n-                        })\n-                ) {\n-                    change.unfinished = 1;\n-                    #[cfg(feature = \"track_unfinished\")]\n-                    change.unfinished_tasks_update.push((self.id, 1));\n-                }\n-                if matches!(guard.state_type, TaskStateType::Dirty { .. }) {\n-                    change.dirty_tasks_update.push((self.id, 1));\n-                }\n-                if let Some(collectibles) = guard.collectibles.as_ref() {\n-                    for (&(trait_type_id, collectible), count) in collectibles.iter() {\n-                        change\n-                            .collectibles\n-                            .push((trait_type_id, collectible, *count));\n-                    }\n-                }\n-                if let TaskStateType::InProgress(box InProgressState {\n-                    outdated_collectibles,\n-                    ..\n-                }) = &guard.state_type\n-                {\n-                    if let Some(collectibles) = outdated_collectibles.as_ref() {\n-                        for (&(trait_type_id, collectible), count) in collectibles.iter() {\n-                            change\n-                                .collectibles\n-                                .push((trait_type_id, collectible, *count));\n-                        }\n-                    }\n-                }\n-                if change.is_empty() {\n-                    None\n-                } else {\n-                    Some(change)\n-                }\n-            }\n-            TaskMetaStateWriteGuard::Partial(_) | TaskMetaStateWriteGuard::Unloaded(_) => {\n-                Some(TaskChange {\n-                    unfinished: 1,\n-                    dirty_tasks_update: vec![(self.id, 1)],\n-                    collectibles: vec![],\n-                })\n-            }\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-\n-    fn get_remove_change(&self) -> Option<Self::DataChange> {\n-        match self.guard {\n-            TaskMetaStateWriteGuard::Full(ref guard) => {\n-                let mut change = TaskChange::default();\n-                if !matches!(\n-                    guard.state_type,\n-                    TaskStateType::Done { .. }\n-                        | TaskStateType::InProgress (box InProgressState{\n-                            count_as_finished: true,\n-                            ..\n-                        })\n-                ) {\n-                    change.unfinished = -1;\n-                    #[cfg(feature = \"track_unfinished\")]\n-                    change.unfinished_tasks_update.push((self.id, -1));\n-                }\n-                if matches!(guard.state_type, TaskStateType::Dirty { .. }) {\n-                    change.dirty_tasks_update.push((self.id, -1));\n-                }\n-                if let Some(collectibles) = guard.collectibles.as_ref() {\n-                    for (&(trait_type_id, collectible), count) in collectibles.iter() {\n-                        change\n-                            .collectibles\n-                            .push((trait_type_id, collectible, -*count));\n-                    }\n-                }\n-                if let TaskStateType::InProgress(box InProgressState {\n-                    outdated_collectibles,\n-                    ..\n-                }) = &guard.state_type\n-                {\n-                    if let Some(collectibles) = outdated_collectibles.as_ref() {\n-                        for (&(trait_type_id, collectible), count) in collectibles.iter() {\n-                            change\n-                                .collectibles\n-                                .push((trait_type_id, collectible, -*count));\n-                        }\n-                    }\n-                }\n-                if change.is_empty() {\n-                    None\n-                } else {\n-                    Some(change)\n-                }\n-            }\n-            TaskMetaStateWriteGuard::Partial(_) | TaskMetaStateWriteGuard::Unloaded(_) => {\n-                Some(TaskChange {\n-                    unfinished: -1,\n-                    dirty_tasks_update: vec![(self.id, -1)],\n-                    collectibles: vec![],\n-                })\n-            }\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-\n-    fn get_initial_data(&self) -> Self::Data {\n-        let mut data = Aggregated::default();\n-        if let Some(TaskChange {\n-            unfinished,\n-            #[cfg(feature = \"track_unfinished\")]\n-            unfinished_tasks_update,\n-            dirty_tasks_update,\n-            collectibles,\n-        }) = self.get_add_change()\n-        {\n-            data.unfinished = unfinished;\n-            #[cfg(feature = \"track_unfinished\")]\n-            {\n-                data.unfinished_tasks = unfinished_tasks_update.into_iter().collect();\n-            }\n-            for (t, n) in dirty_tasks_update.into_iter() {\n-                data.dirty_tasks.insert(t, n);\n-            }\n-            for (trait_type_id, collectible, count) in collectibles.into_iter() {\n-                let info = data.collectibles.entry(trait_type_id).or_default();\n-                update_count_entry(info.collectibles.entry(collectible), count);\n-            }\n-        }\n-        data\n-    }\n-}\n-\n-pub type TaskAggregationNode = AggregationNode<TaskId, Aggregated>;\n-\n-enum UpdateCountEntryChange {\n-    Removed,\n-    Inserted,\n-    Updated,\n-}\n-\n-fn update_count_entry<K: Eq + Hash, H: BuildHasher + Default, const I: usize>(\n-    entry: Entry<'_, K, i32, H, I>,\n-    update: i32,\n-) -> (i32, UpdateCountEntryChange) {\n-    match entry {\n-        Entry::Occupied(mut e) => {\n-            let value = e.get_mut();\n-            if *value < 0 {\n-                *value += update;\n-                match (*value).cmp(&0) {\n-                    Ordering::Less => (*value, UpdateCountEntryChange::Updated),\n-                    Ordering::Equal => {\n-                        e.remove();\n-                        (0, UpdateCountEntryChange::Updated)\n-                    }\n-                    Ordering::Greater => (*value, UpdateCountEntryChange::Inserted),\n-                }\n-            } else {\n-                *value += update;\n-                match (*value).cmp(&0) {\n-                    Ordering::Less => (*value, UpdateCountEntryChange::Removed),\n-                    Ordering::Equal => {\n-                        e.remove();\n-                        (0, UpdateCountEntryChange::Removed)\n-                    }\n-                    Ordering::Greater => (*value, UpdateCountEntryChange::Updated),\n-                }\n-            }\n-        }\n-        Entry::Vacant(e) => match update.cmp(&0) {\n-            Ordering::Less => {\n-                e.insert(update);\n-                (update, UpdateCountEntryChange::Updated)\n-            }\n-            Ordering::Equal => (0, UpdateCountEntryChange::Updated),\n-            Ordering::Greater => {\n-                e.insert(update);\n-                (update, UpdateCountEntryChange::Inserted)\n-            }\n-        },\n-    }\n-}"
        },
        {
            "sha": "1f0eac8f10fce771074af8681a8479a5e76ba309",
            "filename": "turbopack/crates/turbo-tasks-memory/src/task/meta_state.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 267,
            "changes": 267,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Fmeta_state.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Fmeta_state.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Fsrc%2Ftask%2Fmeta_state.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,267 +0,0 @@\n-use std::mem::replace;\n-\n-use parking_lot::{RwLockReadGuard, RwLockWriteGuard};\n-\n-use super::{PartialTaskState, TaskState, UnloadedTaskState};\n-use crate::{\n-    aggregation::AggregationNode,\n-    map_guard::{ReadGuard, WriteGuard},\n-};\n-\n-pub(super) enum TaskMetaState {\n-    Full(Box<TaskState>),\n-    Partial(Box<PartialTaskState>),\n-    Unloaded(UnloadedTaskState),\n-}\n-\n-impl TaskMetaState {\n-    pub(super) fn into_full(self) -> Option<TaskState> {\n-        match self {\n-            Self::Full(state) => Some(*state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn into_partial(self) -> Option<PartialTaskState> {\n-        match self {\n-            Self::Partial(state) => Some(*state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn into_unloaded(self) -> Option<UnloadedTaskState> {\n-        match self {\n-            Self::Unloaded(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_full(&self) -> Option<&TaskState> {\n-        match self {\n-            Self::Full(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_partial(&self) -> Option<&PartialTaskState> {\n-        match self {\n-            Self::Partial(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_unloaded(&self) -> Option<&UnloadedTaskState> {\n-        match self {\n-            Self::Unloaded(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_full_mut(&mut self) -> Option<&mut TaskState> {\n-        match self {\n-            Self::Full(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_partial_mut(&mut self) -> Option<&mut PartialTaskState> {\n-        match self {\n-            Self::Partial(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn as_unloaded_mut(&mut self) -> Option<&mut UnloadedTaskState> {\n-        match self {\n-            Self::Unloaded(state) => Some(state),\n-            _ => None,\n-        }\n-    }\n-}\n-\n-pub(super) type TaskMetaStateAsFull = for<'a> fn(&'a TaskMetaState) -> Option<&'a TaskState>;\n-pub(super) type TaskMetaStateAsPartial =\n-    for<'a> fn(&'a TaskMetaState) -> Option<&'a PartialTaskState>;\n-pub(super) type TaskMetaStateAsUnloaded =\n-    for<'a> fn(&'a TaskMetaState) -> Option<&'a UnloadedTaskState>;\n-pub(super) type TaskMetaStateAsFullMut =\n-    for<'a> fn(&'a mut TaskMetaState) -> Option<&'a mut TaskState>;\n-pub(super) type TaskMetaStateAsPartialMut =\n-    for<'a> fn(&'a mut TaskMetaState) -> Option<&'a mut PartialTaskState>;\n-pub(super) type TaskMetaStateAsUnloadedMut =\n-    for<'a> fn(&'a mut TaskMetaState) -> Option<&'a mut UnloadedTaskState>;\n-\n-#[allow(dead_code, reason = \"test\")]\n-pub(super) enum TaskMetaStateReadGuard<'a> {\n-    Full(ReadGuard<'a, TaskMetaState, TaskState, TaskMetaStateAsFull>),\n-    Partial(ReadGuard<'a, TaskMetaState, PartialTaskState, TaskMetaStateAsPartial>),\n-    Unloaded,\n-}\n-\n-pub(super) type FullTaskWriteGuard<'a> =\n-    WriteGuard<'a, TaskMetaState, TaskState, TaskMetaStateAsFull, TaskMetaStateAsFullMut>;\n-\n-pub(super) enum TaskMetaStateWriteGuard<'a> {\n-    Full(FullTaskWriteGuard<'a>),\n-    Partial(\n-        WriteGuard<\n-            'a,\n-            TaskMetaState,\n-            PartialTaskState,\n-            TaskMetaStateAsPartial,\n-            TaskMetaStateAsPartialMut,\n-        >,\n-    ),\n-    Unloaded(\n-        WriteGuard<\n-            'a,\n-            TaskMetaState,\n-            UnloadedTaskState,\n-            TaskMetaStateAsUnloaded,\n-            TaskMetaStateAsUnloadedMut,\n-        >,\n-    ),\n-    TemporaryFiller,\n-}\n-\n-impl<'a> From<RwLockReadGuard<'a, TaskMetaState>> for TaskMetaStateReadGuard<'a> {\n-    fn from(guard: RwLockReadGuard<'a, TaskMetaState>) -> Self {\n-        match &*guard {\n-            TaskMetaState::Full(_) => {\n-                TaskMetaStateReadGuard::Full(ReadGuard::new(guard, TaskMetaState::as_full))\n-            }\n-            TaskMetaState::Partial(_) => {\n-                TaskMetaStateReadGuard::Partial(ReadGuard::new(guard, TaskMetaState::as_partial))\n-            }\n-            TaskMetaState::Unloaded(_) => TaskMetaStateReadGuard::Unloaded,\n-        }\n-    }\n-}\n-\n-impl<'a> From<RwLockWriteGuard<'a, TaskMetaState>> for TaskMetaStateWriteGuard<'a> {\n-    fn from(guard: RwLockWriteGuard<'a, TaskMetaState>) -> Self {\n-        match &*guard {\n-            TaskMetaState::Full(_) => TaskMetaStateWriteGuard::Full(WriteGuard::new(\n-                guard,\n-                TaskMetaState::as_full,\n-                TaskMetaState::as_full_mut,\n-            )),\n-            TaskMetaState::Partial(_) => TaskMetaStateWriteGuard::Partial(WriteGuard::new(\n-                guard,\n-                TaskMetaState::as_partial,\n-                TaskMetaState::as_partial_mut,\n-            )),\n-            TaskMetaState::Unloaded(_) => TaskMetaStateWriteGuard::Unloaded(WriteGuard::new(\n-                guard,\n-                TaskMetaState::as_unloaded,\n-                TaskMetaState::as_unloaded_mut,\n-            )),\n-        }\n-    }\n-}\n-\n-impl TaskMetaStateReadGuard<'_> {\n-    pub(super) fn as_full(&mut self) -> Option<&TaskState> {\n-        match self {\n-            TaskMetaStateReadGuard::Full(state) => Some(&**state),\n-            _ => None,\n-        }\n-    }\n-}\n-\n-impl<'a> TaskMetaStateWriteGuard<'a> {\n-    pub(super) fn full_from(\n-        mut guard: RwLockWriteGuard<'a, TaskMetaState>,\n-    ) -> FullTaskWriteGuard<'a> {\n-        match &*guard {\n-            TaskMetaState::Full(_) => {}\n-            TaskMetaState::Partial(_) => {\n-                let partial = replace(\n-                    &mut *guard,\n-                    // placeholder\n-                    TaskMetaState::Unloaded(UnloadedTaskState {}),\n-                )\n-                .into_partial()\n-                .unwrap();\n-                *guard = TaskMetaState::Full(Box::new(partial.into_full()));\n-            }\n-            TaskMetaState::Unloaded(_) => {\n-                let unloaded = replace(\n-                    &mut *guard,\n-                    // placeholder\n-                    TaskMetaState::Unloaded(UnloadedTaskState {}),\n-                )\n-                .into_unloaded()\n-                .unwrap();\n-                *guard = TaskMetaState::Full(Box::new(unloaded.into_full()));\n-            }\n-        }\n-        WriteGuard::new(guard, TaskMetaState::as_full, TaskMetaState::as_full_mut)\n-    }\n-\n-    #[allow(dead_code, reason = \"We need this in future\")]\n-    pub(super) fn partial_from(mut guard: RwLockWriteGuard<'a, TaskMetaState>) -> Self {\n-        match &*guard {\n-            TaskMetaState::Full(_) => TaskMetaStateWriteGuard::Full(WriteGuard::new(\n-                guard,\n-                TaskMetaState::as_full,\n-                TaskMetaState::as_full_mut,\n-            )),\n-            TaskMetaState::Partial(_) => TaskMetaStateWriteGuard::Partial(WriteGuard::new(\n-                guard,\n-                TaskMetaState::as_partial,\n-                TaskMetaState::as_partial_mut,\n-            )),\n-            TaskMetaState::Unloaded(_) => {\n-                let unloaded = replace(\n-                    &mut *guard,\n-                    // placeholder\n-                    TaskMetaState::Unloaded(UnloadedTaskState {}),\n-                )\n-                .into_unloaded()\n-                .unwrap();\n-                *guard = TaskMetaState::Partial(Box::new(unloaded.into_partial()));\n-                TaskMetaStateWriteGuard::Partial(WriteGuard::new(\n-                    guard,\n-                    TaskMetaState::as_partial,\n-                    TaskMetaState::as_partial_mut,\n-                ))\n-            }\n-        }\n-    }\n-\n-    pub(super) fn as_full_mut(&mut self) -> Option<&mut TaskState> {\n-        match self {\n-            TaskMetaStateWriteGuard::Full(state) => Some(&mut **state),\n-            _ => None,\n-        }\n-    }\n-\n-    pub(super) fn into_inner(self) -> RwLockWriteGuard<'a, TaskMetaState> {\n-        match self {\n-            TaskMetaStateWriteGuard::Full(state) => state.into_inner(),\n-            TaskMetaStateWriteGuard::Partial(state) => state.into_inner(),\n-            TaskMetaStateWriteGuard::Unloaded(state) => state.into_inner(),\n-            TaskMetaStateWriteGuard::TemporaryFiller => unreachable!(),\n-        }\n-    }\n-\n-    pub(super) fn ensure_at_least_partial(&mut self) {\n-        if matches!(self, TaskMetaStateWriteGuard::Unloaded(..)) {\n-            let TaskMetaStateWriteGuard::Unloaded(state) =\n-                replace(self, TaskMetaStateWriteGuard::TemporaryFiller)\n-            else {\n-                unreachable!();\n-            };\n-            let mut state = state.into_inner();\n-            *state = TaskMetaState::Partial(Box::new(PartialTaskState {\n-                aggregation_node: AggregationNode::new(),\n-            }));\n-            *self = TaskMetaStateWriteGuard::Partial(WriteGuard::new(\n-                state,\n-                TaskMetaState::as_partial,\n-                TaskMetaState::as_partial_mut,\n-            ));\n-        }\n-    }\n-}"
        },
        {
            "sha": "391ab595a93e26ff2684f12233a790887f30d690",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/all_in_one.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fall_in_one.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fall_in_one.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fall_in_one.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/all_in_one.rs\n\\ No newline at end of file"
        },
        {
            "sha": "d2c98272f0102e92f62e2c3a406297cae5d0e0a8",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/basic.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fbasic.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fbasic.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fbasic.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/basic.rs\n\\ No newline at end of file"
        },
        {
            "sha": "b20501cd53c797d0ed3f67cf3ced0f4ff95f31f3",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/call_types.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcall_types.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcall_types.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcall_types.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/call_types.rs\n\\ No newline at end of file"
        },
        {
            "sha": "7de5bc7d80499a5edb81bcdef0c45032fe35ae5f",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/collectibles.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcollectibles.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcollectibles.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fcollectibles.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/collectibles.rs\n\\ No newline at end of file"
        },
        {
            "sha": "ee7aea7eab52f2b2bf60a72a03eac9034d5194fb",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/debug.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdebug.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdebug.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdebug.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/debug.rs\n\\ No newline at end of file"
        },
        {
            "sha": "e726e54a7881e648ea8fc968a051d22b9f9e6256",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/detached.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdetached.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdetached.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdetached.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/detached.rs\n\\ No newline at end of file"
        },
        {
            "sha": "0a45daf6b8443d06fff4376a92a9b9973cd87a7e",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/dirty_in_progress.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdirty_in_progress.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdirty_in_progress.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fdirty_in_progress.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/dirty_in_progress.rs\n\\ No newline at end of file"
        },
        {
            "sha": "9070c4d0b4dcc91aecd199ce9f146a714a7fc3a2",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/emptied_cells.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Femptied_cells.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Femptied_cells.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Femptied_cells.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/emptied_cells.rs\n\\ No newline at end of file"
        },
        {
            "sha": "1230ad8c6d7c250547da65a365dee36778705507",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/filter_unused_args.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ffilter_unused_args.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ffilter_unused_args.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ffilter_unused_args.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/filter_unused_args.rs\n\\ No newline at end of file"
        },
        {
            "sha": "29d9f86f4556624de6731c988410fbcfdea877fb",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/local_tasks.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Flocal_tasks.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Flocal_tasks.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Flocal_tasks.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/local_tasks.rs\n\\ No newline at end of file"
        },
        {
            "sha": "0fe3b98a6abc652de414c6eb8c97ae5f8e5a5cf7",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/operation_vc.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Foperation_vc.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Foperation_vc.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Foperation_vc.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/operation_vc.rs\n\\ No newline at end of file"
        },
        {
            "sha": "23ff275bf1de5385ac2933d6c1ac3ec0094fc613",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/performance.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fperformance.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fperformance.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fperformance.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/performance.rs\n\\ No newline at end of file"
        },
        {
            "sha": "4e1719dfefec28fc10983f51be6c4f1f2158786a",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/read_ref_cell.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fread_ref_cell.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fread_ref_cell.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fread_ref_cell.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/read_ref_cell.rs\n\\ No newline at end of file"
        },
        {
            "sha": "5c35fb81af4e34e7de242b4b1599768d36affa03",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/recompute.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/recompute.rs\n\\ No newline at end of file"
        },
        {
            "sha": "664d8d48d14087af32a89785b4a0ee3221ef9ad0",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/recompute_collectibles.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute_collectibles.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute_collectibles.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Frecompute_collectibles.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/recompute_collectibles.rs\n\\ No newline at end of file"
        },
        {
            "sha": "601c7f0fc000894a40a5eb2890280905fe53d6ee",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/resolved_vc.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fresolved_vc.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fresolved_vc.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fresolved_vc.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/resolved_vc.rs\n\\ No newline at end of file"
        },
        {
            "sha": "0ca21b0967629db70abaa7d438cbb2c2da5ec6ec",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/scope_stress.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fscope_stress.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fscope_stress.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fscope_stress.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/scope_stress.rs\n\\ No newline at end of file"
        },
        {
            "sha": "bd2c655c31c6b588567d8c5795a3193e663cad70",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/shrink_to_fit.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fshrink_to_fit.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fshrink_to_fit.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Fshrink_to_fit.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/shrink_to_fit.rs\n\\ No newline at end of file"
        },
        {
            "sha": "bc0c0bbb90f5ada666b578042350e6caed89633c",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/task_statistics.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftask_statistics.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftask_statistics.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftask_statistics.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/task_statistics.rs\n\\ No newline at end of file"
        },
        {
            "sha": "037d1ff9fe8cb3d9d3e533611c0165aca5070602",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/test_config.trs",
            "status": "removed",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftest_config.trs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftest_config.trs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftest_config.trs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1,3 +0,0 @@\n-|_name, _initial | {\n-  turbo_tasks::TurboTasks::new(turbo_tasks_memory::MemoryBackend::new(usize::MAX))\n-}"
        },
        {
            "sha": "026eed7f3b50f2f95f9c8e4c28057db36f568b70",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/trait_ref_cell.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftrait_ref_cell.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftrait_ref_cell.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftrait_ref_cell.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/trait_ref_cell.rs\n\\ No newline at end of file"
        },
        {
            "sha": "a12b998ce9f5b2d88691103ff08931147e21e787",
            "filename": "turbopack/crates/turbo-tasks-memory/tests/transient_vc.rs",
            "status": "removed",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftransient_vc.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/04b2f069178d25e703181555f8244eae0cf4097e/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftransient_vc.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbo-tasks-memory%2Ftests%2Ftransient_vc.rs?ref=04b2f069178d25e703181555f8244eae0cf4097e",
            "patch": "@@ -1 +0,0 @@\n-../../turbo-tasks-testing/tests/transient_vc.rs\n\\ No newline at end of file"
        },
        {
            "sha": "b3d00971f7018fdcc21913f19717e6ed0eb650f3",
            "filename": "turbopack/crates/turbopack-core/src/error.rs",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ferror.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ferror.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-core%2Fsrc%2Ferror.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -16,7 +16,7 @@ impl Display for PrettyPrintError<'_> {\n             .collect::<Vec<_>>();\n \n         for description in &descriptions {\n-            // see turbo-tasks-memory/src/task.rs for the error message\n+            // see turbo-tasks-backend/src/backend/operation/update_output.rs for the error message\n             let hidden = description.starts_with(\"Execution of \");\n             if !hidden {\n                 let header ="
        },
        {
            "sha": "32f9271e8ea0cbc7b4fb03531fbac21d8df46c34",
            "filename": "turbopack/crates/turbopack-ecmascript/Cargo.toml",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-ecmascript%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-ecmascript%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-ecmascript%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -76,8 +76,7 @@ par-core = { workspace = true, features = [\"rayon\"] }\n \n [dev-dependencies]\n criterion = { workspace = true, features = [\"async_tokio\"] }\n-#rstest = { workspace = true }\n-turbo-tasks-memory = { workspace = true }\n+turbo-tasks-backend = { workspace = true }\n turbo-tasks-testing = { workspace = true }\n \n [build-dependencies]"
        },
        {
            "sha": "8b11051d09440c8ee3df667456e65cb06ce40784",
            "filename": "turbopack/crates/turbopack-trace-utils/src/tracing_presets.rs",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-trace-utils%2Fsrc%2Ftracing_presets.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack-trace-utils%2Fsrc%2Ftracing_presets.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack-trace-utils%2Fsrc%2Ftracing_presets.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -69,7 +69,6 @@ pub static TRACING_TURBO_TASKS_TARGETS: Lazy<Vec<&str>> = Lazy::new(|| {\n             \"turbo_tasks_fetch=trace\",\n             \"turbo_tasks_fs=trace\",\n             \"turbo_tasks_hash=trace\",\n-            \"turbo_tasks_memory=trace\",\n             \"turbo_tasks_backend=trace\",\n             \"turbo_persistence=trace\",\n         ],"
        },
        {
            "sha": "e7df9afd109e4b83fe1229bef75c8f814ae0ce9a",
            "filename": "turbopack/crates/turbopack/Cargo.toml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2FCargo.toml",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2FCargo.toml",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack%2FCargo.toml?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -53,7 +53,6 @@ rstest = { workspace = true }\n rstest_reuse = \"0.5.0\"\n tokio = { workspace = true }\n turbo-tasks-malloc = { workspace = true, default-features = false }\n-turbo-tasks-memory = { workspace = true }\n turbo-tasks-backend = { workspace = true }\n \n [build-dependencies]"
        },
        {
            "sha": "62799efa6fb70e38fa7a4a0272ebea0e917d9e08",
            "filename": "turbopack/crates/turbopack/benches/node_file_trace.rs",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Fbenches%2Fnode_file_trace.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Fbenches%2Fnode_file_trace.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack%2Fbenches%2Fnode_file_trace.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -4,8 +4,8 @@ use criterion::{Bencher, BenchmarkId, Criterion};\n use regex::Regex;\n use turbo_rcstr::RcStr;\n use turbo_tasks::{ReadConsistency, ResolvedVc, TurboTasks, Value, Vc, apply_effects};\n+use turbo_tasks_backend::{BackendOptions, TurboTasksBackend, noop_backing_storage};\n use turbo_tasks_fs::{DiskFileSystem, FileSystem, NullFileSystem};\n-use turbo_tasks_memory::MemoryBackend;\n use turbopack::{\n     ModuleAssetContext, emit_with_completion_operation,\n     module_options::{EcmascriptOptionsContext, ModuleOptionsContext},\n@@ -70,7 +70,10 @@ fn bench_emit(b: &mut Bencher, bench_input: &BenchInput) {\n         .unwrap();\n \n     b.to_async(rt).iter(move || {\n-        let tt = TurboTasks::new(MemoryBackend::default());\n+        let tt = TurboTasks::new(TurboTasksBackend::new(\n+            BackendOptions::default(),\n+            noop_backing_storage(),\n+        ));\n         let tests_root: RcStr = bench_input.tests_root.clone().into();\n         let input: RcStr = bench_input.input.clone().into();\n         async move {"
        },
        {
            "sha": "9b075efde00862b7866fa3ccefeba29aa9c260ef",
            "filename": "turbopack/crates/turbopack/examples/turbopack.rs",
            "status": "modified",
            "additions": 5,
            "deletions": 2,
            "changes": 7,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Fexamples%2Fturbopack.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Fexamples%2Fturbopack.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack%2Fexamples%2Fturbopack.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -10,8 +10,8 @@ use anyhow::Result;\n use tokio::{spawn, time::sleep};\n use turbo_rcstr::RcStr;\n use turbo_tasks::{ReadConsistency, TurboTasks, UpdateInfo, Value, Vc, util::FormatDuration};\n+use turbo_tasks_backend::{BackendOptions, TurboTasksBackend, noop_backing_storage};\n use turbo_tasks_fs::{DiskFileSystem, FileSystem};\n-use turbo_tasks_memory::MemoryBackend;\n use turbopack::{emit_with_completion, register};\n use turbopack_core::{\n     PROJECT_FILESYSTEM_NAME,\n@@ -27,7 +27,10 @@ use turbopack_resolve::resolve_options_context::ResolveOptionsContext;\n async fn main() -> Result<()> {\n     register();\n \n-    let tt = TurboTasks::new(MemoryBackend::default());\n+    let tt = TurboTasks::new(TurboTasksBackend::new(\n+        BackendOptions::default(),\n+        noop_backing_storage(),\n+    ));\n     let start = Instant::now();\n \n     let task = tt.spawn_root_task(|| {"
        },
        {
            "sha": "ae5c541ab1b4e5d1f024f9296c05c40e4d6ab987",
            "filename": "turbopack/crates/turbopack/tests/node-file-trace.rs",
            "status": "modified",
            "additions": 161,
            "deletions": 193,
            "changes": 354,
            "blob_url": "https://github.com/vercel/next.js/blob/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Ftests%2Fnode-file-trace.rs",
            "raw_url": "https://github.com/vercel/next.js/raw/f2e448ead4a232246c13dd0c172ee0d03c25596c/turbopack%2Fcrates%2Fturbopack%2Ftests%2Fnode-file-trace.rs",
            "contents_url": "https://api.github.com/repos/vercel/next.js/contents/turbopack%2Fcrates%2Fturbopack%2Ftests%2Fnode-file-trace.rs?ref=f2e448ead4a232246c13dd0c172ee0d03c25596c",
            "patch": "@@ -3,8 +3,6 @@\n #![feature(arbitrary_self_types_pointers)]\n \n mod helpers;\n-#[cfg(feature = \"bench_against_node_nft\")]\n-use std::time::Instant;\n use std::{\n     collections::HashSet,\n     env::temp_dir,\n@@ -15,7 +13,7 @@ use std::{\n     io::{ErrorKind, Write as _},\n     path::{Path, PathBuf},\n     sync::{Arc, Mutex},\n-    time::Duration,\n+    time::{Duration, Instant},\n };\n \n use anyhow::{Context, Result, anyhow};\n@@ -31,10 +29,11 @@ use serde::{Deserialize, Serialize};\n use tokio::{process::Command, time::timeout};\n use turbo_rcstr::RcStr;\n use turbo_tasks::{\n-    ReadRef, ResolvedVc, TurboTasks, Value, ValueToString, Vc, apply_effects, backend::Backend,\n+    ResolvedVc, TurboTasks, Value, ValueToString, Vc, apply_effects, backend::Backend,\n+    trace::TraceRawVcs,\n };\n-use turbo_tasks_fs::{DiskFileSystem, FileSystem, FileSystemPath};\n-use turbo_tasks_memory::MemoryBackend;\n+use turbo_tasks_backend::TurboTasksBackend;\n+use turbo_tasks_fs::{DiskFileSystem, FileSystem};\n use turbopack::{\n     ModuleAssetContext, emit_with_completion_operation,\n     module_options::{CssOptionsContext, EcmascriptOptionsContext, ModuleOptionsContext},\n@@ -265,46 +264,30 @@ static ALLOC: turbo_tasks_malloc::TurboMalloc = turbo_tasks_malloc::TurboMalloc;\n fn test_cases() {}\n \n #[apply(test_cases)]\n-fn node_file_trace_memory(#[case] input: CaseInput) {\n-    node_file_trace(\n-        input,\n-        \"memory\",\n-        false,\n-        1,\n-        120,\n-        |_| TurboTasks::new(MemoryBackend::default()),\n-        |tt| {\n-            let b = tt.backend();\n-            b.with_all_cached_tasks(|task| {\n-                b.with_task(task, |task| {\n-                    if task.is_pending() {\n-                        println!(\"PENDING: {task}\");\n-                    }\n-                })\n-            });\n-        },\n-    );\n+fn node_file_trace_noop_backing_storage(#[case] input: CaseInput) {\n+    node_file_trace(input, \"noop_backing_storage\", false, 1, 120, |_| {\n+        TurboTasks::new(TurboTasksBackend::new(\n+            turbo_tasks_backend::BackendOptions::default(),\n+            turbo_tasks_backend::noop_backing_storage(),\n+        ))\n+    });\n }\n \n-#[cfg(feature = \"test_persistent_cache\")]\n #[apply(test_cases)]\n-fn node_file_trace_rocksdb(#[case] input: CaseInput) {\n-    use turbo_tasks_memory::MemoryBackendWithPersistedGraph;\n-    use turbo_tasks_rocksdb::RocksDbPersistedGraph;\n-\n-    node_file_trace(\n-        input,\n-        \"rockdb\",\n-        false,\n-        2,\n-        240,\n-        |directory_path| {\n-            TurboTasks::new(MemoryBackendWithPersistedGraph::new(\n-                RocksDbPersistedGraph::new(directory_path.join(\".db\")).unwrap(),\n-            ))\n-        },\n-        |_| {},\n-    );\n+fn node_file_trace_persistent(#[case] input: CaseInput) {\n+    node_file_trace(input, \"persistent_cache\", false, 2, 240, |directory_path| {\n+        TurboTasks::new(TurboTasksBackend::new(\n+            turbo_tasks_backend::BackendOptions::default(),\n+            turbo_tasks_backend::default_backing_storage(\n+                &directory_path.join(\".cache\"),\n+                &turbo_tasks_backend::GitVersionInfo {\n+                    describe: \"test-unversioned\",\n+                    dirty: false,\n+                },\n+            )\n+            .unwrap(),\n+        ))\n+    });\n }\n \n #[cfg(feature = \"bench_against_node_nft\")]\n@@ -323,24 +306,81 @@ fn bench_against_node_nft_mt(#[case] input: CaseInput) {\n fn bench_against_node_nft_inner(input: CaseInput, multi_threaded: bool) {\n     node_file_trace(\n         input,\n-        \"memory\",\n+        \"noop_backing_storage\",\n         multi_threaded,\n         1,\n         120,\n-        |_| TurboTasks::new(MemoryBackend::default()),\n-        |tt| {\n-            let b = tt.backend();\n-            b.with_all_cached_tasks(|task| {\n-                b.with_task(task, |task| {\n-                    if task.is_pending() {\n-                        println!(\"PENDING: {task}\");\n-                    }\n-                })\n-            });\n+        |_| {\n+            TurboTasks::new(TurboTasksBackend::new(\n+                turbo_tasks_backend::BackendOptions::default(),\n+                turbo_tasks_backend::noop_backing_storage(),\n+            ))\n         },\n     );\n }\n \n+#[turbo_tasks::function(operation)]\n+async fn node_file_trace_operation(\n+    package_root: RcStr,\n+    input: RcStr,\n+    directory: RcStr,\n+) -> Result<Vc<RebasedAsset>> {\n+    let workspace_fs: Vc<Box<dyn FileSystem>> = Vc::upcast(DiskFileSystem::new(\n+        \"workspace\".into(),\n+        package_root.clone(),\n+        vec![],\n+    ));\n+    let input_dir = workspace_fs.root().to_resolved().await?;\n+    let input = input_dir.join(format!(\"tests/{input}\").into());\n+\n+    let output_fs = DiskFileSystem::new(\"output\".into(), directory.clone(), vec![]);\n+    let output_dir = output_fs.root().to_resolved().await?;\n+\n+    let source = FileSource::new(input);\n+    let module_asset_context = ModuleAssetContext::new(\n+        Default::default(),\n+        // TODO It's easy to make a mistake here as this should match the config in the\n+        // binary. TODO These test cases should move into the\n+        // `node-file-trace` crate and use the same config.\n+        CompileTimeInfo::new(Environment::new(Value::new(\n+            ExecutionEnvironment::NodeJsLambda(NodeJsEnvironment::default().resolved_cell()),\n+        ))),\n+        ModuleOptionsContext {\n+            ecmascript: EcmascriptOptionsContext {\n+                enable_types: true,\n+                ..Default::default()\n+            },\n+            css: CssOptionsContext {\n+                enable_raw_css: true,\n+                ..Default::default()\n+            },\n+            ..Default::default()\n+        }\n+        .cell(),\n+        ResolveOptionsContext {\n+            enable_node_native_modules: true,\n+            enable_node_modules: Some(input_dir),\n+            custom_conditions: vec![\"node\".into()],\n+            ..Default::default()\n+        }\n+        .cell(),\n+        Vc::cell(\"test\".into()),\n+    );\n+    let module = module_asset_context\n+        .process(Vc::upcast(source), Value::new(ReferenceType::Undefined))\n+        .module();\n+\n+    let rebased = RebasedAsset::new(Vc::upcast(module), *input_dir, *output_dir)\n+        .to_resolved()\n+        .await?;\n+\n+    let emit_op = emit_with_completion_operation(ResolvedVc::upcast(rebased), output_dir);\n+    emit_op.read_strongly_consistent().await?;\n+    apply_effects(emit_op).await?;\n+\n+    Ok(*rebased)\n+}\n+\n fn node_file_trace<B: Backend + 'static>(\n     CaseInput {\n         path: input_path,\n@@ -352,7 +392,6 @@ fn node_file_trace<B: Backend + 'static>(\n     run_count: i32,\n     timeout_len: u64,\n     create_turbo_tasks: impl Fn(&Path) -> Arc<TurboTasks<B>>,\n-    handle_timeout_error: impl Fn(&Arc<TurboTasks<B>>),\n ) {\n     lazy_static! {\n         static ref BENCH_SUITES: Arc<Mutex<Vec<BenchSuite>>> = Arc::new(Mutex::new(Vec::new()));\n@@ -398,108 +437,46 @@ fn node_file_trace<B: Backend + 'static>(\n \n         for _ in 0..run_count {\n             let bench_suites = bench_suites.clone();\n+            let expected_stderr = expected_stderr.clone();\n             let package_root = package_root.clone();\n-            let input_string = input.clone();\n+            let input = input.clone();\n             let directory = directory.clone();\n-            #[cfg(not(feature = \"bench_against_node_nft\"))]\n-            let expected_stderr = expected_stderr.clone();\n             let task = async move {\n                 #[allow(unused)]\n                 let bench_suites = bench_suites.clone();\n-                #[cfg(feature = \"bench_against_node_nft\")]\n                 let before_start = Instant::now();\n-                let workspace_fs: Vc<Box<dyn FileSystem>> = Vc::upcast(DiskFileSystem::new(\n-                    \"workspace\".into(),\n+\n+                let rebased = node_file_trace_operation(\n                     package_root.clone(),\n-                    vec![],\n-                ));\n-                let input_dir = workspace_fs.root().to_resolved().await?;\n-                let input = input_dir.join(format!(\"tests/{input_string}\").into());\n-\n-                #[cfg(not(feature = \"bench_against_node_nft\"))]\n-                let original_output = exec_node(package_root, input);\n-\n-                let output_fs = DiskFileSystem::new(\"output\".into(), directory.clone(), vec![]);\n-                let output_dir = output_fs.root().to_resolved().await?;\n-\n-                let source = FileSource::new(input);\n-                let module_asset_context = ModuleAssetContext::new(\n-                    Default::default(),\n-                    // TODO It's easy to make a mistake here as this should match the config in the\n-                    // binary. TODO These test cases should move into the\n-                    // `node-file-trace` crate and use the same config.\n-                    CompileTimeInfo::new(Environment::new(Value::new(\n-                        ExecutionEnvironment::NodeJsLambda(\n-                            NodeJsEnvironment::default().resolved_cell(),\n-                        ),\n-                    ))),\n-                    ModuleOptionsContext {\n-                        ecmascript: EcmascriptOptionsContext {\n-                            enable_types: true,\n-                            ..Default::default()\n-                        },\n-                        css: CssOptionsContext {\n-                            enable_raw_css: true,\n-                            ..Default::default()\n-                        },\n-                        ..Default::default()\n-                    }\n-                    .cell(),\n-                    ResolveOptionsContext {\n-                        enable_node_native_modules: true,\n-                        enable_node_modules: Some(input_dir),\n-                        custom_conditions: vec![\"node\".into()],\n-                        ..Default::default()\n-                    }\n-                    .cell(),\n-                    Vc::cell(\"test\".into()),\n-                );\n-                let module = module_asset_context\n-                    .process(Vc::upcast(source), Value::new(ReferenceType::Undefined))\n-                    .module();\n-                let rebased = RebasedAsset::new(Vc::upcast(module), *input_dir, *output_dir)\n-                    .to_resolved()\n-                    .await?;\n-\n-                #[cfg(not(feature = \"bench_against_node_nft\"))]\n-                let output_path = rebased.path();\n+                    input.clone(),\n+                    directory.clone(),\n+                )\n+                .resolve_strongly_consistent()\n+                .await?;\n \n                 print_graph(ResolvedVc::upcast(rebased)).await?;\n \n-                let emit_op =\n-                    emit_with_completion_operation(ResolvedVc::upcast(rebased), output_dir);\n-                emit_op.read_strongly_consistent().await?;\n-                apply_effects(emit_op).await?;\n-\n-                #[cfg(not(feature = \"bench_against_node_nft\"))]\n-                {\n-                    let output = exec_node(directory.clone(), output_path);\n-                    let output =\n-                        assert_output(original_output, output, expected_stderr.map(From::from));\n-                    output.await\n-                }\n-                #[cfg(feature = \"bench_against_node_nft\")]\n-                {\n+                if cfg!(feature = \"bench_against_node_nft\") {\n                     let duration = before_start.elapsed();\n                     let node_start = Instant::now();\n-                    exec_node(package_root, input.clone()).await?;\n+                    exec_node(&package_root, &input).await?;\n                     let node_duration = node_start.elapsed();\n                     let is_faster = node_duration > duration;\n                     {\n                         let mut bench_suites_lock = bench_suites.lock().unwrap();\n                         let rust_speedup =\n                             node_duration.as_millis() as f32 / duration.as_millis() as f32 - 1.0;\n-                        let rust_duration = format!(\"{:?}\", duration);\n-                        let node_duration = format!(\"{:?}\", node_duration);\n+                        let rust_duration = format!(\"{duration:?}\");\n+                        let node_duration = format!(\"{node_duration:?}\");\n                         let rust_speedup = if rust_speedup > 1.0 {\n-                            format!(\"+{:.2}x\", rust_speedup)\n+                            format!(\"+{rust_speedup:.2}x\")\n                         } else if rust_speedup > 0.0 {\n                             format!(\"+{:.0}%\", rust_speedup * 100.0)\n                         } else {\n                             format!(\"-{:.0}%\", -rust_speedup * 100.0)\n                         };\n                         bench_suites_lock.push(BenchSuite {\n-                            suite: input_string\n+                            suite: input\n                                 .trim_start_matches(\"node-file-trace/integration/\")\n                                 .to_string()\n                                 + (if multi_threaded {\n@@ -513,28 +490,35 @@ fn node_file_trace<B: Backend + 'static>(\n                             rust_speedup,\n                         });\n                     }\n-                    CommandOutput::cell(CommandOutput {\n+                    Ok(CommandOutput {\n                         stdout: String::new(),\n                         stderr: String::new(),\n                     })\n-                    .await\n+                } else {\n+                    let output_path = &rebased.path().await?.path;\n+                    let original_output =\n+                        exec_node(&package_root, &format!(\"{package_root}/tests/{input}\")).await?;\n+                    let output = exec_node(&directory, output_path).await?;\n+                    assert_output(original_output, output, expected_stderr.map(From::from))\n                 }\n             };\n-            let handle_result = |result: Result<ReadRef<CommandOutput>>| match result {\n-                #[allow(unused)]\n-                Ok(output) => {\n-                    #[cfg(not(feature = \"bench_against_node_nft\"))]\n-                    {\n-                        assert!(\n-                            output.is_empty(),\n-                            \"emitted files behave differently when executed via node.js\\n{output}\"\n-                        );\n+\n+            fn handle_result(result: Result<CommandOutput>) {\n+                match result {\n+                    Ok(output) => {\n+                        if !cfg!(feature = \"bench_against_node_nft\") {\n+                            assert!(\n+                                output.is_empty(),\n+                                \"emitted files behave differently when executed via \\\n+                                 node.js\\n{output}\"\n+                            );\n+                        }\n+                    }\n+                    Err(err) => {\n+                        panic!(\"Execution failed: {err:?}\");\n                     }\n                 }\n-                Err(err) => {\n-                    panic!(\"Execution failed: {err:?}\");\n-                }\n-            };\n+            }\n \n             let tt = create_turbo_tasks(directory_path.as_path());\n             let output = timeout(Duration::from_secs(timeout_len), tt.run_once(task)).await;\n@@ -543,7 +527,6 @@ fn node_file_trace<B: Backend + 'static>(\n             match (output, stop) {\n                 (Ok(result), Ok(_)) => handle_result(result),\n                 (Err(err), _) => {\n-                    handle_timeout_error(&tt);\n                     panic!(\"Execution is hanging (for > {timeout_len}s): {err}\");\n                 }\n                 (_, Err(err)) => {\n@@ -569,13 +552,12 @@ fn node_file_trace<B: Backend + 'static>(\n     })\n }\n \n-#[turbo_tasks::value]\n+#[derive(TraceRawVcs)]\n struct CommandOutput {\n     stdout: String,\n     stderr: String,\n }\n \n-#[cfg(not(feature = \"bench_against_node_nft\"))]\n impl CommandOutput {\n     fn is_empty(&self) -> bool {\n         self.stderr.is_empty() && self.stdout.is_empty()\n@@ -592,36 +574,23 @@ impl Display for CommandOutput {\n     }\n }\n \n-#[turbo_tasks::function]\n-async fn exec_node(directory: RcStr, path: Vc<FileSystemPath>) -> Result<Vc<CommandOutput>> {\n+async fn exec_node(directory: &str, path: &str) -> Result<CommandOutput> {\n     let mut cmd = Command::new(\"node\");\n \n-    let p = path.await?;\n-    let f = Path::new(&directory).join(&p.path);\n+    let f = Path::new(&directory).join(path);\n     let dir = f.parent().unwrap();\n     println!(\"[CWD]: {}\", dir.display());\n-    let label = path.to_string().await?;\n \n-    if p.path.contains(\"mdx\") {\n+    if path.contains(\"mdx\") {\n         cmd.arg(\"--experimental-loader=@mdx-js/node-loader\")\n             .arg(\"--no-warnings\");\n     }\n \n-    #[cfg(not(feature = \"bench_against_node_nft\"))]\n-    if p.path.ends_with(\".ts\") {\n-        let mut ts_node = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n-        ts_node.push(\"tests\");\n-        ts_node.push(\"node-file-trace\");\n-        ts_node.push(\"node_modules\");\n-        ts_node.push(\"ts-node\");\n-        ts_node.push(\"dist\");\n-        ts_node.push(\"bin.js\");\n-        cmd.arg(&ts_node);\n-    }\n+    if cfg!(feature = \"bench_against_node_nft\") {\n+        let current_dir = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n+        cmd.current_dir(&current_dir);\n \n-    #[cfg(feature = \"bench_against_node_nft\")]\n-    {\n-        let mut node_nft = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n+        let mut node_nft = current_dir;\n         node_nft.push(\"tests\");\n         node_nft.push(\"node-file-trace\");\n         node_nft.push(\"node_modules\");\n@@ -630,25 +599,28 @@ async fn exec_node(directory: RcStr, path: Vc<FileSystemPath>) -> Result<Vc<Comm\n         node_nft.push(\"out\");\n         node_nft.push(\"cli.js\");\n         cmd.arg(&node_nft).arg(\"build\");\n-    }\n-    #[cfg(not(feature = \"bench_against_node_nft\"))]\n-    {\n-        cmd.arg(&f);\n+        cmd.arg(path);\n+    } else {\n         cmd.current_dir(dir);\n-    }\n-    #[cfg(feature = \"bench_against_node_nft\")]\n-    {\n-        let current_dir = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n-        cmd.arg(&p.path);\n-        cmd.current_dir(current_dir);\n+        if path.ends_with(\".ts\") {\n+            let mut ts_node = PathBuf::from(env!(\"CARGO_MANIFEST_DIR\"));\n+            ts_node.push(\"tests\");\n+            ts_node.push(\"node-file-trace\");\n+            ts_node.push(\"node_modules\");\n+            ts_node.push(\"ts-node\");\n+            ts_node.push(\"dist\");\n+            ts_node.push(\"bin.js\");\n+            cmd.arg(&ts_node);\n+        }\n+        cmd.arg(&f);\n     }\n \n     println!(\"[CMD]: {cmd:#?}\");\n \n     let output = timeout(Duration::from_secs(100), cmd.output())\n         .await\n-        .with_context(|| anyhow!(\"node execution of {label} is hanging\"))?\n-        .with_context(|| anyhow!(\"failed to spawn node process of {label}\"))?;\n+        .with_context(|| anyhow!(\"node execution of {path} is hanging\"))?\n+        .with_context(|| anyhow!(\"failed to spawn node process of {path}\"))?;\n \n     let output = CommandOutput {\n         stdout: String::from_utf8_lossy(&output.stdout).to_string(),\n@@ -657,7 +629,7 @@ async fn exec_node(directory: RcStr, path: Vc<FileSystemPath>) -> Result<Vc<Comm\n \n     println!(\"File: {}\\n{}\", f.display(), output,);\n \n-    Ok(CommandOutput::cell(output))\n+    Ok(output)\n }\n \n fn clean_stderr(str: &str) -> String {\n@@ -689,16 +661,12 @@ fn diff(expected: &str, actual: &str) -> String {\n     print_changeset(&Changeset::new(expected.trim(), actual.trim(), \"\\n\"))\n }\n \n-#[allow(unused)]\n-#[turbo_tasks::function]\n-async fn assert_output(\n-    expected: Vc<CommandOutput>,\n-    actual: Vc<CommandOutput>,\n+fn assert_output(\n+    expected: CommandOutput,\n+    actual: CommandOutput,\n     expected_stderr: Option<RcStr>,\n-) -> Result<Vc<CommandOutput>> {\n-    let expected = expected.await?;\n-    let actual = actual.await?;\n-    Ok(CommandOutput::cell(CommandOutput {\n+) -> Result<CommandOutput> {\n+    Ok(CommandOutput {\n         stdout: diff(&expected.stdout, &actual.stdout),\n         stderr: if let Some(expected_stderr) = expected_stderr {\n             if actual.stderr.contains(&*expected_stderr)\n@@ -712,7 +680,7 @@ async fn assert_output(\n         } else {\n             diff(&expected.stderr, &actual.stderr)\n         },\n-    }))\n+    })\n }\n \n #[derive(Debug, Serialize, Deserialize)]"
        }
    ],
    "stats": {
        "total": 10119,
        "additions": 212,
        "deletions": 9907
    }
}