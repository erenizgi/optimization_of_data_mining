{
    "author": "moT01",
    "message": "feat(curriculum): add audio/video lecture transcripts (#57635)\n\nCo-authored-by: Dario-DC <105294544+Dario-DC@users.noreply.github.com>",
    "sha": "fec4f62553b2264760d61a32b948ca42c0f4b33a",
    "files": [
        {
            "sha": "3e5fd2b7bfbf5832329325fae1884cd43151cc37",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733ab12b60bd7f6b2b0b0c0.md",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733ab12b60bd7f6b2b0b0c0.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733ab12b60bd7f6b2b0b0c0.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733ab12b60bd7f6b2b0b0c0.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,26 @@\n ---\n id: 6733ab12b60bd7f6b2b0b0c0\n title: How Does the Audio Constructor Work, and What Are Some Common Methods?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: how-does-the-audio-constructor-work-and-what-are-some-common-methods\n ---\n \n # --description--\n \n-Watch the video lecture and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+Let's learn about the Audio constructor and its common methods.\n+\n+The `Audio` constructor, like other constructors, is a special function called with the `new` keyword. It returns an HTMLAudioElement, which you can then use to play audio for the user, or append to the DOM for the user to control themselves.\n+\n+When you call the constructor, you can optionally pass a URL as the (only) argument. This URL should point to the source of the audio file you want to play. Or, if you need to change the source dynamically, you can assign the URL to the `src` property of the returned audio element.\n+\n+The returned audio element offers various methods for controlling the audio. You'll most likely use the `play()` method, which begins audio playback. There is also the `pause()` method, which pauses the audio playback but preserves the current location in the track allowing `play()` to resume playback from that point.\n+\n+You might expect there to be a `stop()` method, to pause audio playback and reset the track to the beginning. But instead, you should call `pause()` and set the `currentTime` property directly.\n+\n+Finally, the `canPlayType()` method can be used to determine if a browser is likely to be able to play your specific audio format. You will learn about audio and video formats in the next lecture.\n \n # --questions--\n "
        },
        {
            "sha": "9dd440c85be6989fe6dc2895ca6e9914ee21668c",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733d8203da84a08a0f5eab4.md",
            "status": "modified",
            "additions": 23,
            "deletions": 3,
            "changes": 26,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8203da84a08a0f5eab4.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8203da84a08a0f5eab4.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8203da84a08a0f5eab4.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,34 @@\n ---\n id: 6733d8203da84a08a0f5eab4\n title: What Are the Different Types of Video and Audio Formats?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: what-are-the-different-types-of-video-and-audio-formats\n ---\n \n # --description--\n \n-Watch the lecture video and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+Let's learn about the different types of audio and video formats.\n+\n+You have probably heard of, or even used, a few common ones. If the terms MP3, MP4, MOV, or WebM are familiar to you, those are all different formats for video and audio. And there are quite a few more that are available.\n+\n+Before we dive in to file formats, we need to talk about MIME types. A MIME type, standing for Multipurpose Internet Mail Extensions, is a standardized way to programmatically indicate a file type.\n+\n+Nearly every file format has a MIME type. HTML, for example, has the type `text/html`. A JSON object has the type `application/json`. Even a Windows `.exe` installer has a MIME type: `application/vnd.microsoft.portable-executable`.\n+\n+The MIME type can tell an application, such as your browser, how to handle a specific file. In the case of audio and video, the MIME type indicates it is a multimedia format that can be embedded in the web page.\n+\n+An MP3 file has the MIME type `audio/mp3`. An MP4, however, can have the MIME type `audio/mp4` OR `video/mp4`, depending on whether it's a video file or audio-only. This distinction tells the browser how to handle the file.\n+\n+There are plenty of other file formats, such as the waveform format WAV, the multipurpose OGG, WMV for the Windows media player, the open source MKV, and many more.\n+\n+Knowing the differences between these file formats can help you ensure your users get the best experience, but sometimes you can't know what format a user's computer will support (or not support). Thankfully, `video` and `audio` elements both support the `source` element.\n+\n+With the `source` element, you can specify a file type and `source` and can include multiple different types by using multiple `source` elements. When you do this, the browser will determine the best format to use for the user's current environment.\n+\n+This takes away the guess work and allows you to focus on building engaging applications.\n \n # --questions--\n "
        },
        {
            "sha": "f532d6710ebca70ed8158da3d864259ccd5200d8",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733d829d983c008d2db41a1.md",
            "status": "modified",
            "additions": 17,
            "deletions": 3,
            "changes": 20,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d829d983c008d2db41a1.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d829d983c008d2db41a1.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d829d983c008d2db41a1.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,28 @@\n ---\n id: 6733d829d983c008d2db41a1\n title: What Is Codecs and How Does It Work?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: what-is-codecs-and-how-does-it-work\n ---\n \n # --description--\n \n-Watch the lecture video and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+Let's learn about codecs and how they work.\n+\n+If you have worked with videos or audio before, you may have heard about codecs. A codec, short for “encoder/decoder\", is an algorithm or software that can convert audio and video between analogue and digital formats.\n+\n+Codecs can be specified as part of the MIME type. The basic syntax to define a codec is to add a semi-colon after the media type, then `codecs=` and the codec.\n+\n+For example, an OGG audio file which uses the Vorbis codec might have a MIME type of `audio/ogg; codecs=vorbis`. Or, if a file supports multiple codecs, you can specify them as comma separated, but must surround them with quotes: `video/webm; codecs=\"vp8, vorbis\"`.\n+\n+But some file types have a much more complicated syntax for codecs. For example, an MP4 might have a codec of `codecs=\"avc1.4d002a\"`, indicating it was encoded with H.264.\n+\n+But when might you actually use these? Well, you can include them in the `type` attribute for a `source` element. This allows you to specify different codecs for the same format, giving the browser more granular options when determining which format to use for that user's environment.\n+\n+But you can also use them as part of the MIME type you pass to the global `MediaSource.isTypeSupported()` method. This method accepts a MIME-type, and returns `true` if the environment is likely to support it. Or rather, it returns `false` if it fails to instantiate a buffer for that file type. This approach allows you to programmatically select a source yourself, rather than relying on whatever the browser determines is “best\".\n \n # --questions--\n "
        },
        {
            "sha": "f2b698adf76559438726fb2410441c0f8fe23b18",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733d83630e76f08ff49e6dc.md",
            "status": "modified",
            "additions": 21,
            "deletions": 3,
            "changes": 24,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d83630e76f08ff49e6dc.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d83630e76f08ff49e6dc.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d83630e76f08ff49e6dc.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,32 @@\n ---\n id: 6733d83630e76f08ff49e6dc\n title: What Is the HTMLMediaElement API and How Does It Work?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: what-is-the-htmlmediaelement-api-and-how-does-it-work\n ---\n \n # --description--\n \n-Watch the lecture video and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+The HTMLMediaElement API is a powerful tool to control the behavior of audio and video elements on your page. It extends the base HTMLElement interface, so you have access to the base properties as well as these helpful methods.\n+\n+You've already explored some of the methods in a previous lecture about the Audio element, such as `play()` and `pause()`. These same methods are available on video elements as well.\n+\n+There are some other helpful methods, such as the `addTextTrack()` method. This method allows you to specify a text track to associate with the media element which is especially helpful for adding subtitles to a video.\n+\n+Or the `fastSeek()` method, which allows you to move the playback position to a specific time within the media.\n+\n+The HTMLMediaElement API also provides access to some new events that a standard element does not have.\n+\n+The `play` and `pause` events are fired when the media starts and stops playing. The `ended` event fires when the end of the media has been reached.\n+\n+The `waiting` event fires when playback is automatically paused due to data buffering.\n+\n+And the `canplay` and `canplaythrough` events fire when the media can be partially played, or played in totality.\n+\n+The HTMLMediaElement offers a great deal of control over your interactive media, and we've only scratched the surface. I encourage you to explore and experiment with the API to find the best ways to integrate it with your applications.\n \n # --questions--\n "
        },
        {
            "sha": "05d05cf9b8d5e41f7a90e5bb19ed2776834665c1",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733d852175df50937f06061.md",
            "status": "modified",
            "additions": 47,
            "deletions": 3,
            "changes": 50,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d852175df50937f06061.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d852175df50937f06061.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d852175df50937f06061.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,58 @@\n ---\n id: 6733d852175df50937f06061\n title: How Can You Work with the Media Streams to Capture Video and Audio from a Local Device?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: how-can-you-work-with-the-media-streams-getusermedia-to-capture-video-and-audio-from-a-local-device\n ---\n \n # --description--\n \n-Watch the lecture video and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+Instead of playing audio and video, you may sometimes want to capture audio or video. The Media Capture and Streams API, or the MediaStream API, allows you to do this.\n+\n+In order to use the API, however, you need to create the `MediaStream` object. You could do this with the constructor, but it would not be tied to the user's hardware. Instead, the `mediaDevices` property of the global `navigator` object has a `getUserMedia()` method for you to use.\n+\n+This method accepts a single `constraints` object which defines the type of media you want to receive. This object has an `audio` and `video` property, reflecting audio and video streams. These properties can be `false`, if you do not want to receive that type of stream, `true` if you do, or objects defining additional constraints.\n+\n+For example, you can require a specific resolution of video output:\n+\n+```js\n+window.navigator.mediaDevices.getUserMedia({\n+  audio: true,\n+  video: {\n+    width: {\n+      min: 1280,\n+      ideal: 1920,\n+      max: 3840\n+    },\n+    height: {\n+      min: 720,\n+      ideal: 1080,\n+      max: 2160\n+    }\n+  }\n+});\n+```\n+\n+This constraint object specifies minimum and maximum resolutions for the video feed. The `ideal` property specifies the resolution you'd most like to have – and the stream will provide the resolution closest to your ideal.\n+\n+Once you've created your MediaStream (assuming the user approves the automated request to access their hardware), you can use the stream data however you need.\n+\n+Note that `getUserMedia()` returns a Promise, which means you will either need a callback function to consume the stream, or use async/await syntax. You will learn more about Promises and asynchronous programming in future lectures. \n+\n+Here's a basic example which renders the user's webcam feed to the page.\n+\n+```js\n+const video = document.querySelector(\"video\");\n+const stream =\n+  await window.navigator.mediaDevices.getUserMedia({ video: true });\n+video.srcObject = stream;\n+await video.play();\n+```\n+\n+It is worth noting that this API does not offer access to screen capture. You'll learn about that API in the next lecture.\n \n # --questions--\n "
        },
        {
            "sha": "7f67086d4c6b907584b0130bb1dbcbadfc2cf674",
            "filename": "curriculum/challenges/english/25-front-end-development/lecture-working-with-audio-and-video/6733d8606fb893099e3d0df3.md",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/freeCodeCamp/freeCodeCamp/blob/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8606fb893099e3d0df3.md",
            "raw_url": "https://github.com/freeCodeCamp/freeCodeCamp/raw/fec4f62553b2264760d61a32b948ca42c0f4b33a/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8606fb893099e3d0df3.md",
            "contents_url": "https://api.github.com/repos/freeCodeCamp/freeCodeCamp/contents/curriculum%2Fchallenges%2Fenglish%2F25-front-end-development%2Flecture-working-with-audio-and-video%2F6733d8606fb893099e3d0df3.md?ref=fec4f62553b2264760d61a32b948ca42c0f4b33a",
            "patch": "@@ -1,14 +1,26 @@\n ---\n id: 6733d8606fb893099e3d0df3\n title: What Are Some Other Examples of Video and Audio APIs?\n-challengeType: 11\n-videoId: nVAaxZ34khk\n+challengeType: 19\n+# videoId: nVAaxZ34khk\n dashedName: what-are-some-other-examples-of-video-and-audio-apis\n ---\n \n # --description--\n \n-Watch the lecture video and answer the questions below.\n+The video for this lecture isn't available yet, one will be available soon. Here is a transcript of the lecture for now:\n+\n+You've learned about the HTMLMediaElement and MediaStreams APIs, but there are a few more APIs that can be quite helpful in working with video and audio.\n+\n+The first is the Screen Capture API. As the name might suggest, this API allows you to record a user's screen. This API is exposed by calling the `getDisplayMedia()` method of the `mediaDevices` object and consuming the returned media stream.\n+\n+Then there is the MediaStream Recording API. This API works in tandem with the MediaStreams APIs, allowing you to record a MediaStream (or even an HTMLMediaElement directly). It then fires `dataavailable` events with Blob payloads you can write to the local file storage.\n+\n+Underlying all of this technology is the Media Source Extensions API. The Media Source Extensions API is what allows you to directly pass a user's webcam feed to a video element with the `srcObject` property, for example. \n+\n+And finally, the Web Audio API which powers everything audible on the web. This API includes important objects like an `AudioBuffer` (representing a Buffer specifically containing audio data) or the `AudioContext`. \n+\n+And that wraps up our lectures on audio and video!\n \n # --questions--\n "
        }
    ],
    "stats": {
        "total": 156,
        "additions": 138,
        "deletions": 18
    }
}