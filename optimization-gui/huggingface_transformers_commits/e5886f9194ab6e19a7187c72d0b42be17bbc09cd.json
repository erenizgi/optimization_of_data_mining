{
    "author": "yonigozlan",
    "message": "[SAM 2] Change checkpoints in docs and tests (#40213)\n\n* change checkpoints in docs and tests\n\n* add notebook",
    "sha": "e5886f9194ab6e19a7187c72d0b42be17bbc09cd",
    "files": [
        {
            "sha": "6cf8e21587cda2e32ec7ab0c2e16201d85a3c4d6",
            "filename": "docs/source/en/model_doc/sam2.md",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2.md?ref=e5886f9194ab6e19a7187c72d0b42be17bbc09cd",
            "patch": "@@ -52,7 +52,7 @@ SAM2 can be used for automatic mask generation to segment all objects in an imag\n ```python\n >>> from transformers import pipeline\n \n->>> generator = pipeline(\"mask-generation\", model=\"yonigozlan/sam2.1_hiera_large_hf\", device=0)\n+>>> generator = pipeline(\"mask-generation\", model=\"facebook/sam2.1-hiera-large\", device=0)\n >>> image_url = \"https://huggingface.co/datasets/hf-internal-testing/sam2-fixtures/resolve/main/truck.jpg\"\n >>> outputs = generator(image_url, points_per_batch=64)\n \n@@ -74,8 +74,8 @@ You can segment objects by providing a single point click on the object you want\n \n >>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n->>> model = Sam2Model.from_pretrained(\"yonigozlan/sam2.1_hiera_large_hf\").to(device)\n->>> processor = Sam2Processor.from_pretrained(\"yonigozlan/sam2.1_hiera_large_hf\")\n+>>> model = Sam2Model.from_pretrained(\"facebook/sam2.1-hiera-large\").to(device)\n+>>> processor = Sam2Processor.from_pretrained(\"facebook/sam2.1-hiera-large\")\n \n >>> image_url = \"https://huggingface.co/datasets/hf-internal-testing/sam2-fixtures/resolve/main/truck.jpg\"\n >>> raw_image = Image.open(requests.get(image_url, stream=True).raw).convert(\"RGB\")\n@@ -162,8 +162,8 @@ Process multiple images simultaneously for improved efficiency:\n \n >>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n \n->>> model = Sam2Model.from_pretrained(\"yonigozlan/sam2.1_hiera_large_hf\").to(device)\n->>> processor = Sam2Processor.from_pretrained(\"yonigozlan/sam2.1_hiera_large_hf\")\n+>>> model = Sam2Model.from_pretrained(\"facebook/sam2.1-hiera-large\").to(device)\n+>>> processor = Sam2Processor.from_pretrained(\"facebook/sam2.1-hiera-large\")\n \n >>> # Load multiple images\n >>> image_urls = ["
        },
        {
            "sha": "aa3db3ba5581665aaf0d8682c9fbd13f9beada17",
            "filename": "docs/source/en/model_doc/sam2_video.md",
            "status": "modified",
            "additions": 6,
            "deletions": 5,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fsam2_video.md?ref=e5886f9194ab6e19a7187c72d0b42be17bbc09cd",
            "patch": "@@ -56,8 +56,8 @@ SAM2's key strength is its ability to track objects across video frames. Here's\n >>> import torch\n \n >>> device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n->>> model = Sam2VideoModel.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\").to(device, dtype=torch.bfloat16)\n->>> processor = Sam2VideoProcessor.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\")\n+>>> model = Sam2VideoModel.from_pretrained(\"facebook/sam2.1-hiera-tiny\").to(device, dtype=torch.bfloat16)\n+>>> processor = Sam2VideoProcessor.from_pretrained(\"facebook/sam2.1-hiera-tiny\")\n \n >>> # Load video frames (example assumes you have a list of PIL Images)\n >>> # video_frames = [Image.open(f\"frame_{i:05d}.jpg\") for i in range(num_frames)]\n@@ -274,10 +274,11 @@ Tracked 2 objects through 180 frames\n ```\n \n <!-- TODO replace with sam2 resources -->\n-<!-- ## Resources -->\n-<!-- A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with SAM.\n+## Resources\n \n-- [Demo notebook](https://github.com/huggingface/notebooks/blob/main/examples/segment_anything_2.ipynb) for using the model. -->\n+A list of official Hugging Face and community (indicated by ðŸŒŽ) resources to help you get started with SAM.\n+\n+- [Demo notebook ðŸŒŽ](https://colab.research.google.com/drive/1Z0NGLE7p8qnc9UpuI8KBETHd2xBbOEhv?usp=sharing) for using the model, contributed by [Sangbum Choi](https://github.com/SangbumChoi).\n \n ## Sam2VideoConfig\n "
        },
        {
            "sha": "e97da57d9fc77a5618bda32732e2f26da7fc2d40",
            "filename": "tests/models/sam2/test_modeling_sam2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 5,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/tests%2Fmodels%2Fsam2%2Ftest_modeling_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/tests%2Fmodels%2Fsam2%2Ftest_modeling_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam2%2Ftest_modeling_sam2.py?ref=e5886f9194ab6e19a7187c72d0b42be17bbc09cd",
            "patch": "@@ -712,7 +712,7 @@ def test_hidden_states_output(self):\n \n     @slow\n     def test_model_from_pretrained(self):\n-        model_name = \"yonigozlan/sam2.1_hiera_tiny_hf\"\n+        model_name = \"facebook/sam2.1-hiera-tiny\"\n         model = Sam2Model.from_pretrained(model_name)\n         self.assertIsNotNone(model)\n \n@@ -749,9 +749,8 @@ def prepare_video():\n class Sam2ModelIntegrationTest(unittest.TestCase):\n     def setUp(self):\n         super().setUp()\n-        # fill_hole area is set to 0 to avoid running the `get_connected_components` cuda kernel\n-        self.model = Sam2Model.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\", fill_hole_area=0).to(torch.float32)\n-        self.processor = Sam2Processor.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\")\n+        self.model = Sam2Model.from_pretrained(\"facebook/sam2.1-hiera-tiny\").to(torch.float32)\n+        self.processor = Sam2Processor.from_pretrained(\"facebook/sam2.1-hiera-tiny\")\n         self.model.to(torch_device)\n         self.model.eval()\n \n@@ -1007,7 +1006,7 @@ def test_inference_mask_generation_from_existing_points_and_mask(self):\n         )\n \n     def test_dummy_pipeline_generation(self):\n-        generator = pipeline(\"mask-generation\", model=\"yonigozlan/sam2.1_hiera_tiny_hf\", device=torch_device)\n+        generator = pipeline(\"mask-generation\", model=\"facebook/sam2.1-hiera-tiny\", device=torch_device)\n         raw_image = prepare_image()\n \n         _ = generator(raw_image, points_per_batch=64)"
        },
        {
            "sha": "0c23e22b89df0b3f467acd08d4c4b4e6983dea98",
            "filename": "tests/models/sam2_video/test_modeling_sam2_video.py",
            "status": "modified",
            "additions": 2,
            "deletions": 5,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/tests%2Fmodels%2Fsam2_video%2Ftest_modeling_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e5886f9194ab6e19a7187c72d0b42be17bbc09cd/tests%2Fmodels%2Fsam2_video%2Ftest_modeling_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fsam2_video%2Ftest_modeling_sam2_video.py?ref=e5886f9194ab6e19a7187c72d0b42be17bbc09cd",
            "patch": "@@ -66,11 +66,8 @@ def prepare_video():\n class Sam2VideoModelIntegrationTest(unittest.TestCase):\n     def setUp(self):\n         super().setUp()\n-        # fill_hole area is set to 0 to avoid running the `get_connected_components` cuda kernel\n-        self.video_model = Sam2VideoModel.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\", fill_hole_area=0).to(\n-            torch.float32\n-        )\n-        self.processor = Sam2VideoProcessor.from_pretrained(\"yonigozlan/sam2.1_hiera_tiny_hf\")\n+        self.video_model = Sam2VideoModel.from_pretrained(\"facebook/sam2.1-hiera-tiny\").to(torch.float32)\n+        self.processor = Sam2VideoProcessor.from_pretrained(\"facebook/sam2.1-hiera-tiny\")\n         self.video_model.to(torch_device)\n         self.video_model.eval()\n "
        }
    ],
    "stats": {
        "total": 37,
        "additions": 17,
        "deletions": 20
    }
}