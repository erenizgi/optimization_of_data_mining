{
    "author": "gante",
    "message": "[repo utils] Update `models_to_deprecate.py` (#41231)\n\n* update models_to_deprecate\n\n* exclude this file\n\n* handle typos and aliases\n\n* don't commit files\n\n* PR suggestions; make fixup",
    "sha": "1d1ac078933dc7eb902a4d49b9eb347e5242d1e6",
    "files": [
        {
            "sha": "c3c4eaf8e4d8ad52de9d7edb240b744563babf4f",
            "filename": "utils/models_to_deprecate.py",
            "status": "modified",
            "additions": 159,
            "deletions": 21,
            "changes": 180,
            "blob_url": "https://github.com/huggingface/transformers/blob/1d1ac078933dc7eb902a4d49b9eb347e5242d1e6/utils%2Fmodels_to_deprecate.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1d1ac078933dc7eb902a4d49b9eb347e5242d1e6/utils%2Fmodels_to_deprecate.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fmodels_to_deprecate.py?ref=1d1ac078933dc7eb902a4d49b9eb347e5242d1e6",
            "patch": "@@ -12,7 +12,8 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \"\"\"\n-Script to find a candidate list of models to deprecate based on the number of downloads and the date of the last commit.\n+Script to find a candidate list of models to deprecate based on the number of downloads and the date of the last\n+commit.\n \"\"\"\n \n import argparse\n@@ -25,6 +26,9 @@\n \n from git import Repo\n from huggingface_hub import HfApi\n+from tqdm import tqdm\n+\n+from transformers.models.auto.configuration_auto import DEPRECATED_MODELS, MODEL_NAMES_MAPPING\n \n \n api = HfApi()\n@@ -33,14 +37,105 @@\n repo = Repo(PATH_TO_REPO)\n \n \n+# Used when the folder name on the hub does not match the folder name in `transformers/models`\n+# format = {folder name in `transformers/models`: expected tag on the hub}\n+MODEL_FOLDER_NAME_TO_TAG_MAPPING = {\n+    \"audio_spectrogram_transformer\": \"audio-spectrogram-transformer\",\n+    \"bert_generation\": \"bert-generation\",\n+    \"blenderbot_small\": \"blenderbot-small\",\n+    \"blip_2\": \"blip-2\",\n+    \"dab_detr\": \"dab-detr\",\n+    \"data2vec\": \"data2vec-audio\",  # actually, the base model is never used as a tag, but the sub models are\n+    \"deberta_v2\": \"deberta-v2\",\n+    \"donut\": \"donut-swin\",\n+    \"encoder_decoder\": \"encoder-decoder\",\n+    \"grounding_dino\": \"grounding-dino\",\n+    \"kosmos2\": \"kosmos-2\",\n+    \"kosmos2_5\": \"kosmos-2.5\",\n+    \"megatron_bert\": \"megatron-bert\",\n+    \"mgp_str\": \"mgp-str\",\n+    \"mm_grounding_dino\": \"mm-grounding-dino\",\n+    \"modernbert_decoder\": \"modernbert-decoder\",\n+    \"nllb_moe\": \"nllb-moe\",\n+    \"omdet_turbo\": \"omdet-turbo\",\n+    \"openai\": \"openai-gpt\",\n+    \"roberta_prelayernorm\": \"roberta-prelayernorm\",\n+    \"sew_d\": \"sew-d\",\n+    \"speech_encoder_decoder\": \"speech-encoder-decoder\",\n+    \"table_transformer\": \"table-transformer\",\n+    \"unispeech_sat\": \"unispeech-sat\",\n+    \"vision_encoder_decoder\": \"vision-encoder-decoder\",\n+    \"vision_text_dual_encoder\": \"vision-text-dual-encoder\",\n+    \"wav2vec2_bert\": \"wav2vec2-bert\",\n+    \"wav2vec2_conformer\": \"wav2vec2-conformer\",\n+    \"x_clip\": \"xclip\",\n+    \"xlm_roberta\": \"xlm-roberta\",\n+    \"xlm_roberta_xl\": \"xlm-roberta-xl\",\n+}\n+\n+# Used on model architectures with multiple tags on the hub (e.g. on VLMs, we often support a text-only model).\n+# Applied after the model folder name mapping. format = {base model tag: [extra tags]}\n+EXTRA_TAGS_MAPPING = {\n+    \"aimv2\": [\"aimv2_vision_model\"],\n+    \"aria\": [\"aria_text\"],\n+    \"bart\": [\"barthez\", \"bartpho\"],\n+    \"bert\": [\"bert-japanese\", \"bertweet\", \"herbert\", \"phobert\"],\n+    \"beit\": [\"dit\"],\n+    \"blip-2\": [\"blip_2_qformer\"],\n+    \"chinese_clip\": [\"chinese_clip_vision_model\"],\n+    \"clip\": [\"clip_text_model\", \"clip_vision_model\"],\n+    \"data2vec-audio\": [\"data2vec-text\", \"data2vec-vision\"],\n+    \"depth_anything\": [\"depth_anything_v2\"],\n+    \"donut-swin\": [\"nougat\"],\n+    \"edgetam\": [\"edgetam_vision_model\"],\n+    \"fastspeech2_conformer\": [\"fastspeech2_conformer_with_hifigan\"],\n+    \"gemma3\": [\"gemma3_text\"],\n+    \"gemma3n\": [\"gemma3n_audio\", \"gemma3n_text\", \"gemma3n_vision\"],\n+    \"gpt2\": [\"cpm\", \"dialogpt\", \"gpt-sw3\", \"megatron_gpt2\"],\n+    \"glm4v_moe\": [\"glm4v_moe_text\"],\n+    \"glm4v\": [\"glm4v_text\"],\n+    \"idefics3\": [\"idefics3_vision\"],\n+    \"internvl\": [\"internvl_vision\"],\n+    \"layoutlmv2\": [\"layoutxlm\"],\n+    \"llama\": [\"code_llama\", \"falcon3\", \"llama2\", \"llama3\"],\n+    \"llama4\": [\"llama4_text\"],\n+    \"llava_next\": [\"granitevision\"],\n+    \"luke\": [\"mluke\"],\n+    \"m2m_100\": [\"nllb\"],\n+    \"maskformer\": [\"maskformer-swin\"],\n+    \"mbart\": [\"mbart50\"],\n+    \"parakeet\": [\"parakeet_ctc\", \"parakeet_encoder\"],\n+    \"perception_lm\": [\"perception_encoder\"],\n+    \"pix2struct\": [\"deplot\", \"matcha\"],\n+    \"qwen2_5_vl\": [\"qwen2_5_vl_text\"],\n+    \"qwen2_audio\": [\"qwen2_audio_encoder\"],\n+    \"qwen2_vl\": [\"qwen2_vl_text\"],\n+    \"qwen3_vl_moe\": [\"qwen3_vl_moe_text\"],\n+    \"qwen3_vl\": [\"qwen3_vl_text\"],\n+    \"rt_detr\": [\"rt_detr_resnet\"],\n+    \"sam2\": [\"sam2_hiera_det_model\", \"sam2_vision_model\"],\n+    \"sam\": [\"sam_hq_vision_model\", \"sam_vision_model\"],\n+    \"siglip2\": [\"siglip2_vision_model\"],\n+    \"siglip\": [\"siglip_vision_model\"],\n+    \"smolvlm\": [\"smolvlm_vision\"],\n+    \"t5\": [\"byt5\", \"flan-t5\", \"flan-ul2\", \"madlad-400\", \"myt5\", \"t5v1.1\", \"ul2\"],\n+    \"voxtral\": [\"voxtral_encoder\"],\n+    \"wav2vec2\": [\"mms\", \"wav2vec2_phoneme\", \"xls_r\", \"xlsr_wav2vec2\"],\n+    \"xlm-roberta\": [\"xlm-v\"],\n+}\n+\n+# Similar to `DEPRECATED_MODELS`, but containing the tags when the model tag does not match the model folder name :'(\n+DEPRECATED_MODELS_TAGS = {\"gptsan-japanese\", \"open-llama\", \"transfo-xl\", \"xlm-prophetnet\"}\n+\n+\n class HubModelLister:\n     \"\"\"\n     Utility for getting models from the hub based on tags. Handles errors without crashing the script.\n     \"\"\"\n \n     def __init__(self, tags):\n         self.tags = tags\n-        self.model_list = api.list_models(tags=tags)\n+        self.model_list = api.list_models(filter=tags)\n \n     def __iter__(self):\n         try:\n@@ -97,9 +192,11 @@ def get_list_of_models_to_deprecate(\n             info[\"first_commit_datetime\"] = datetime.fromisoformat(info[\"first_commit_datetime\"])\n \n     else:\n-        # Build a dictionary of model info: first commit datetime, commit hash, model path\n+        print(\"Building a dictionary of basic model info...\")\n         models_info = defaultdict(dict)\n-        for model_path in model_paths:\n+        for i, model_path in enumerate(tqdm(sorted(model_paths))):\n+            if max_num_models != -1 and i > max_num_models:\n+                break\n             model = model_path.split(\"/\")[-2]\n             if model in models_info:\n                 continue\n@@ -111,32 +208,63 @@ def get_list_of_models_to_deprecate(\n             models_info[model][\"first_commit_datetime\"] = committed_datetime\n             models_info[model][\"model_path\"] = model_path\n             models_info[model][\"downloads\"] = 0\n+            models_info[model][\"tags\"] = [model]\n+\n+        # The keys in the dictionary above are the model folder names. In some cases, the model tag on the hub does not\n+        # match the model folder name. We replace the key and append the expected tag.\n+        for folder_name, expected_tag in MODEL_FOLDER_NAME_TO_TAG_MAPPING.items():\n+            if folder_name in models_info:\n+                models_info[expected_tag] = models_info[folder_name]\n+                models_info[expected_tag][\"tags\"] = [expected_tag]\n+                del models_info[folder_name]\n \n-            # Some tags on the hub are formatted differently than in the library\n-            tags = [model]\n-            if \"_\" in model:\n-                tags.append(model.replace(\"_\", \"-\"))\n-            models_info[model][\"tags\"] = tags\n+        # Some models have multiple tags on the hub. We add the expected tag to the list of tags.\n+        for model_name, extra_tags in EXTRA_TAGS_MAPPING.items():\n+            if model_name in models_info:\n+                models_info[model_name][\"tags\"].extend(extra_tags)\n+\n+        # Sanity check for the case with all models: the model tags must match the keys in the MODEL_NAMES_MAPPING\n+        # (= actual model tags on the hub)\n+        if max_num_models == -1:\n+            all_model_tags = set()\n+            for model_name in models_info:\n+                all_model_tags.update(models_info[model_name][\"tags\"])\n+\n+            non_deprecated_model_tags = (\n+                set(MODEL_NAMES_MAPPING.keys()) - set(DEPRECATED_MODELS_TAGS) - set(DEPRECATED_MODELS)\n+            )\n+            if all_model_tags != non_deprecated_model_tags:\n+                raise ValueError(\n+                    \"The tags of the `models_info` dictionary must match the keys in the `MODEL_NAMES_MAPPING`!\"\n+                    \"\\nMissing tags in `model_info`: \"\n+                    + str(sorted(non_deprecated_model_tags - all_model_tags))\n+                    + \"\\nExtra tags in `model_info`: \"\n+                    + str(sorted(all_model_tags - non_deprecated_model_tags))\n+                    + \"\\n\\nYou need to update one or more of the following: `MODEL_NAMES_MAPPING`, \"\n+                    \"`EXTRA_TAGS_MAPPING` or `DEPRECATED_MODELS_TAGS`.\"\n+                )\n \n         # Filter out models which were added less than a year ago\n         models_info = {\n             model: info for model, info in models_info.items() if info[\"first_commit_datetime\"] < thresh_date\n         }\n \n         # We make successive calls to the hub, filtering based on the model tags\n-        n_seen = 0\n-        for model, model_info in models_info.items():\n+        print(\"Making calls to the hub to find models below the threshold number of downloads...\")\n+        num_models = len(models_info)\n+        for i, (model, model_info) in enumerate(models_info.items()):\n+            print(f\"{i + 1}/{num_models}: getting hub downloads for model='{model}' (tags={model_info['tags']})\")\n             for model_tag in model_info[\"tags\"]:\n+                if model_info[\"downloads\"] > thresh_num_downloads:\n+                    break\n                 model_list = HubModelLister(tags=model_tag)\n-                for i, hub_model in enumerate(model_list):\n-                    n_seen += 1\n-                    if i % 100 == 0:\n-                        print(f\"Processing model {i} for tag {model_tag}\")\n-                    if max_num_models != -1 and i > n_seen:\n-                        break\n+                for hub_model in model_list:\n                     if hub_model.private:\n                         continue\n                     model_info[\"downloads\"] += hub_model.downloads\n+                    # No need to make further hub calls, it's above the set threshold\n+                    if model_info[\"downloads\"] > thresh_num_downloads:\n+                        break\n \n     if save_model_info and not (use_cache and os.path.exists(\"models_info.json\")):\n         # Make datetimes serializable\n@@ -156,7 +284,11 @@ def get_list_of_models_to_deprecate(\n             print(f\"\\nModel: {model}\")\n             print(f\"Downloads: {n_downloads}\")\n             print(f\"Date: {info['first_commit_datetime']}\")\n-    print(\"\\nModels to deprecate: \", \"\\n\" + \"\\n\".join(models_to_deprecate.keys()))\n+\n+    # sort models to deprecate by downloads (lowest downloads first)\n+    models_to_deprecate = sorted(models_to_deprecate.items(), key=lambda x: x[1][\"downloads\"])\n+\n+    print(\"\\nModels to deprecate: \", \"\\n\" + \"\\n\".join([model[0] for model in models_to_deprecate]))\n     print(f\"\\nNumber of models to deprecate: {n_models_to_deprecate}\")\n     print(\"Before deprecating make sure to verify the models, including if they're used as a module in other models.\")\n \n@@ -171,19 +303,25 @@ def get_list_of_models_to_deprecate(\n         \"--thresh_num_downloads\",\n         type=int,\n         default=5_000,\n-        help=\"Threshold number of downloads below which a model should be deprecated. Default is 5,000.\",\n+        help=(\n+            \"Threshold number of downloads below which a model should be deprecated. Default is 5,000. If you are \"\n+            \"considering a sweep and using a cache, set this to the highest number of the sweep.\"\n+        ),\n     )\n     parser.add_argument(\n         \"--thresh_date\",\n         type=str,\n         default=None,\n-        help=\"Date to consider the first commit from. Format: YYYY-MM-DD. If unset, defaults to one year ago from today.\",\n+        help=(\n+            \"Date to consider the first commit from. Format: YYYY-MM-DD. If unset, defaults to one year ago from \"\n+            \"today.\"\n+        ),\n     )\n     parser.add_argument(\n         \"--max_num_models\",\n         type=int,\n         default=-1,\n-        help=\"Maximum number of models to consider from the hub. -1 means all models. Useful for testing.\",\n+        help=\"Maximum number of models architectures to consider. -1 means all models. Useful for testing.\",\n     )\n     args = parser.parse_args()\n "
        }
    ],
    "stats": {
        "total": 180,
        "additions": 159,
        "deletions": 21
    }
}