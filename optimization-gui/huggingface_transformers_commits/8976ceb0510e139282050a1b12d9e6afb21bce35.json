{
    "author": "yonigozlan",
    "message": "Refactor check_auto_docstring using AST (#41432)\n\n* refactor check_auto_docstring with AST\n\n* use dataclass for ASTIndexes\n\n* simplify and improve readability\n\n* fix missing imports\n\n* fix modular\n\n* fix modular issues",
    "sha": "8976ceb0510e139282050a1b12d9e6afb21bce35",
    "files": [
        {
            "sha": "689b7e0b5e230a2712e2bd74ca4989843593574d",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=8976ceb0510e139282050a1b12d9e6afb21bce35",
            "patch": "@@ -1418,14 +1418,11 @@ def forward(\n         pixel_values_videos: Optional[torch.FloatTensor] = None,\n         image_grid_thw: Optional[torch.LongTensor] = None,\n         video_grid_thw: Optional[torch.LongTensor] = None,\n-        rope_deltas: Optional[torch.LongTensor] = None,\n         cache_position: Optional[torch.LongTensor] = None,\n         logits_to_keep: Union[int, torch.Tensor] = 0,\n         **kwargs: Unpack[TransformersKwargs],\n     ) -> Union[tuple, Glm4vCausalLMOutputWithPast]:\n         r\"\"\"\n-        rope_deltas (`torch.LongTensor` of shape `(batch_size, )`, *optional*):\n-            The rope index difference between sequence length and multimodal rope.\n         labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n             Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n             config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored"
        },
        {
            "sha": "a6e303d8e7bbe008307e24b0073564aab507b1fd",
            "filename": "src/transformers/models/glm4v/modular_glm4v.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py?ref=8976ceb0510e139282050a1b12d9e6afb21bce35",
            "patch": "@@ -1341,14 +1341,11 @@ def forward(\n         pixel_values_videos: Optional[torch.FloatTensor] = None,\n         image_grid_thw: Optional[torch.LongTensor] = None,\n         video_grid_thw: Optional[torch.LongTensor] = None,\n-        rope_deltas: Optional[torch.LongTensor] = None,\n         cache_position: Optional[torch.LongTensor] = None,\n         logits_to_keep: Union[int, torch.Tensor] = 0,\n         **kwargs: Unpack[TransformersKwargs],\n     ) -> Union[tuple, Glm4vCausalLMOutputWithPast]:\n         r\"\"\"\n-        rope_deltas (`torch.LongTensor` of shape `(batch_size, )`, *optional*):\n-            The rope index difference between sequence length and multimodal rope.\n         labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n             Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n             config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored"
        },
        {
            "sha": "6cff89f8a37bfa14eeebe2c73eef9e69c8531591",
            "filename": "src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8976ceb0510e139282050a1b12d9e6afb21bce35/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py?ref=8976ceb0510e139282050a1b12d9e6afb21bce35",
            "patch": "@@ -1638,8 +1638,6 @@ def forward(\n         **kwargs: Unpack[TransformersKwargs],\n     ) -> Union[tuple, Glm4vMoeCausalLMOutputWithPast]:\n         r\"\"\"\n-        rope_deltas (`torch.LongTensor` of shape `(batch_size, )`, *optional*):\n-            The rope index difference between sequence length and multimodal rope.\n         labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n             Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\n             config.vocab_size]` or -100 (see `input_ids` docstring). Tokens with indices set to `-100` are ignored"
        },
        {
            "sha": "79c150de0260bc53e4f7abc86446f15bc5d3d833",
            "filename": "utils/check_docstrings.py",
            "status": "modified",
            "additions": 243,
            "deletions": 206,
            "changes": 449,
            "blob_url": "https://github.com/huggingface/transformers/blob/8976ceb0510e139282050a1b12d9e6afb21bce35/utils%2Fcheck_docstrings.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/8976ceb0510e139282050a1b12d9e6afb21bce35/utils%2Fcheck_docstrings.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_docstrings.py?ref=8976ceb0510e139282050a1b12d9e6afb21bce35",
            "patch": "@@ -42,8 +42,9 @@\n import os\n import re\n from collections import OrderedDict\n+from dataclasses import dataclass\n from pathlib import Path\n-from typing import Any\n+from typing import Any, Optional, Union\n \n from check_repo import ignore_undocumented\n from git import Repo\n@@ -59,6 +60,25 @@\n )\n \n \n+@dataclass\n+class DecoratedItem:\n+    \"\"\"Information about a single @auto_docstring decorated function or class.\"\"\"\n+\n+    decorator_line: int  # 1-based line number of the decorator\n+    def_line: int  # 1-based line number of the def/class statement\n+    kind: str  # 'function' or 'class'\n+    body_start_line: (\n+        int  # 1-based line number where body starts (for functions) or __init__ body start (for classes with __init__)\n+    )\n+    args: list[str]  # List of argument names (excluding self, *args, **kwargs) - for classes, these are __init__ args\n+    custom_args_text: Optional[str] = None  # custom_args string if provided in decorator\n+\n+    # Class-specific fields (only populated when kind == 'class')\n+    has_init: bool = False  # Whether the class has an __init__ method\n+    init_def_line: Optional[int] = None  # 1-based line number of __init__ def (if has_init)\n+    is_model_output: bool = False  # Whether the class inherits from ModelOutput\n+\n+\n PATH_TO_REPO = Path(__file__).parent.parent.resolve()\n PATH_TO_TRANSFORMERS = Path(\"src\").resolve() / \"transformers\"\n \n@@ -874,34 +894,35 @@ def fix_docstring(obj: Any, old_doc_args: str, new_doc_args: str):\n         f.write(\"\\n\".join(lines))\n \n \n-def _find_sig_line(lines, line_end):\n-    parenthesis_count = 0\n-    sig_line_end = line_end\n-    found_sig = False\n-    while not found_sig:\n-        for char in lines[sig_line_end]:\n-            if char == \"(\":\n-                parenthesis_count += 1\n-            elif char == \")\":\n-                parenthesis_count -= 1\n-                if parenthesis_count == 0:\n-                    found_sig = True\n-                    break\n-        sig_line_end += 1\n-    return sig_line_end\n-\n-\n def _find_docstring_end_line(lines, docstring_start_line):\n-    if '\"\"\"' not in lines[docstring_start_line]:\n+    \"\"\"Find the line number where a docstring ends. Only handles triple double quotes.\"\"\"\n+    if docstring_start_line is None or docstring_start_line < 0 or docstring_start_line >= len(lines):\n         return None\n-    docstring_end = docstring_start_line\n-    if docstring_start_line is not None:\n-        docstring_end = docstring_start_line\n-        if not lines[docstring_start_line].count('\"\"\"') >= 2:\n-            docstring_end += 1\n-            while '\"\"\"' not in lines[docstring_end]:\n-                docstring_end += 1\n-    return docstring_end\n+    start_line = lines[docstring_start_line]\n+    if '\"\"\"' not in start_line:\n+        return None\n+    # Check if docstring starts and ends on the same line\n+    if start_line.count('\"\"\"') >= 2:\n+        return docstring_start_line\n+    # Find the closing triple quotes on subsequent lines\n+    for idx in range(docstring_start_line + 1, len(lines)):\n+        if '\"\"\"' in lines[idx]:\n+            return idx\n+    return len(lines) - 1\n+\n+\n+def _is_auto_docstring_decorator(dec):\n+    \"\"\"Return True if the decorator expression corresponds to `@auto_docstring`.\"\"\"\n+    # Handle @auto_docstring(...) - unwrap the Call to get the function\n+    target = dec.func if isinstance(dec, ast.Call) else dec\n+    # Check if it's named \"auto_docstring\"\n+    return isinstance(target, ast.Name) and target.id == \"auto_docstring\"\n+\n+\n+def _extract_function_args(func_node: Union[ast.FunctionDef, ast.AsyncFunctionDef]) -> list[str]:\n+    \"\"\"Extract argument names from a function node, excluding 'self', *args, **kwargs.\"\"\"\n+    all_args = (func_node.args.posonlyargs or []) + func_node.args.args + func_node.args.kwonlyargs\n+    return [a.arg for a in all_args if a.arg != \"self\"]\n \n \n def find_matching_model_files(check_all: bool = False):\n@@ -947,64 +968,20 @@ def find_matching_model_files(check_all: bool = False):\n def find_files_with_auto_docstring(matching_files, decorator=\"@auto_docstring\"):\n     \"\"\"\n     From a list of files, return those that contain the @auto_docstring decorator.\n+    Fast path: simple substring presence check.\n     \"\"\"\n     auto_docstrings_files = []\n     for file_path in matching_files:\n-        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n-            content_base_file = f.read()\n-            if decorator in content_base_file:\n-                lines = content_base_file.split(\"\\n\")\n-                line_numbers = [i for i, line in enumerate(lines) if decorator in line]\n-                for line_number in line_numbers:\n-                    line_end = line_number\n-                    end_patterns = [\"class \", \"    def\"]\n-                    stop_condition = False\n-                    while line_end < len(lines) and not stop_condition:\n-                        line_end += 1\n-                        stop_condition = any(lines[line_end].startswith(end_pattern) for end_pattern in end_patterns)\n-                    candidate_patterns = [\"class \", \"    def\"]\n-                    candidate = any(\n-                        lines[line_end].startswith(candidate_pattern) for candidate_pattern in candidate_patterns\n-                    )\n-                    if stop_condition and candidate:\n-                        auto_docstrings_files.append(file_path)\n-                        break\n+        try:\n+            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n+                source = f.read()\n+        except OSError:\n+            continue\n+        if decorator in source:\n+            auto_docstrings_files.append(file_path)\n     return auto_docstrings_files\n \n \n-def get_auto_docstring_candidate_lines(lines):\n-    \"\"\"\n-    For a file's lines, find the start and end line indices of all @auto_docstring candidates.\n-    Returns two lists: starts and ends.\n-    \"\"\"\n-    line_numbers = [i for i, line in enumerate(lines) if \"@auto_docstring\" in line]\n-    line_starts_candidates = []\n-    line_ends_candidates = []\n-    for line_number in line_numbers:\n-        line_end = line_number\n-        end_patterns = [\"class \", \"    def\"]\n-        stop_condition = False\n-        while line_end < len(lines) and not stop_condition:\n-            line_end += 1\n-            stop_condition = any(lines[line_end].startswith(end_pattern) for end_pattern in end_patterns)\n-        candidate_patterns = [\"class \", \"    def\"]\n-        candidate = any(lines[line_end].startswith(candidate_pattern) for candidate_pattern in candidate_patterns)\n-        if stop_condition and candidate:\n-            line_ends_candidates.append(line_end)\n-            line_starts_candidates.append(line_number)\n-    return line_starts_candidates, line_ends_candidates\n-\n-\n-def get_args_in_signature(lines, signature_content):\n-    signature_content = [line.split(\"#\")[0] for line in signature_content]\n-    signature_content = \"\".join(signature_content)\n-    signature_content = \"\".join(signature_content.split(\")\")[:-1])\n-    args_in_signature = re.findall(r\"[,(]\\s*(\\w+)\\s*(?=:|=|,|\\))\", signature_content)\n-    if \"self\" in args_in_signature:\n-        args_in_signature.remove(\"self\")\n-    return args_in_signature\n-\n-\n def get_args_in_dataclass(lines, dataclass_content):\n     dataclass_content = [line.split(\"#\")[0] for line in dataclass_content]\n     dataclass_content = \"\\n\".join(dataclass_content)\n@@ -1051,6 +1028,9 @@ def generate_new_docstring_for_signature(\n     else:\n         docstring_end_line = None\n \n+    # Remove pre-existing entries for *args and untyped **kwargs from the docstring\n+    # (No longer needed since *args are excluded from args_in_signature)\n+\n     # Remove args that are the same as the ones in the source args doc\n     for arg in args_docstring_dict:\n         if arg in get_args_doc_from_source(source_args_doc) and arg not in ALWAYS_OVERRIDE:\n@@ -1132,13 +1112,16 @@ def generate_new_docstring_for_signature(\n     )\n \n \n-def generate_new_docstring_for_function(lines, current_line_end, custom_args_dict):\n+def generate_new_docstring_for_function(\n+    lines,\n+    item: DecoratedItem,\n+    custom_args_dict,\n+):\n     \"\"\"\n     Wrapper for function docstring generation using the generalized helper.\n     \"\"\"\n-    sig_end_line = _find_sig_line(lines, current_line_end)\n-    signature_content = lines[current_line_end:sig_end_line]\n-    args_in_signature = get_args_in_signature(lines, signature_content)\n+    sig_end_line = item.body_start_line - 1  # Convert to 0-based\n+    args_in_signature = item.args\n     docstring_start_line = sig_end_line if '\"\"\"' in lines[sig_end_line] else None\n     return generate_new_docstring_for_signature(\n         lines,\n@@ -1150,34 +1133,27 @@ def generate_new_docstring_for_function(lines, current_line_end, custom_args_dic\n     )\n \n \n-def generate_new_docstring_for_class(lines, current_line_end, custom_args_dict):\n+def generate_new_docstring_for_class(\n+    lines,\n+    item: DecoratedItem,\n+    custom_args_dict,\n+    source: str,\n+):\n     \"\"\"\n     Wrapper for class docstring generation (via __init__) using the generalized helper.\n     Returns the new docstring and relevant signature/docstring indices.\n     \"\"\"\n-    sig_start_line = current_line_end\n-    found_init_method = False\n-    found_model_output = False\n-    while sig_start_line < len(lines) - 1 and not found_init_method:\n-        sig_start_line += 1\n-        if \"    def __init__\" in lines[sig_start_line]:\n-            found_init_method = True\n-        elif lines[sig_start_line].startswith(\"class \") or lines[sig_start_line].startswith(\"def \"):\n-            break\n-    if not found_init_method:\n-        if \"ModelOutput\" in lines[current_line_end]:\n-            found_model_output = True\n-            sig_start_line = current_line_end\n-        else:\n-            return \"\", None, None, [], [], []\n-\n-    if found_init_method:\n-        sig_end_line = _find_sig_line(lines, sig_start_line)\n-        signature_content = lines[sig_start_line:sig_end_line]\n-        args_in_signature = get_args_in_signature(lines, signature_content)\n-    else:\n-        # we have a ModelOutput class, the class attributes are the args\n-        sig_end_line = sig_start_line + 1\n+    # Use pre-extracted information from DecoratedItem (no need to search or re-parse!)\n+    if item.has_init:\n+        # Class has an __init__ method - use its args and body start\n+        sig_end_line = item.body_start_line - 1  # Convert from body start to sig end (0-based)\n+        args_in_signature = item.args\n+        output_docstring_indent = 8\n+        source_args_doc = [ModelArgs, ImageProcessorArgs]\n+    elif item.is_model_output:\n+        # ModelOutput class - extract args from dataclass attributes\n+        current_line_end = item.def_line - 1  # Convert to 0-based\n+        sig_end_line = current_line_end + 1\n         docstring_end = _find_docstring_end_line(lines, sig_end_line)\n         model_output_class_start = docstring_end + 1 if docstring_end is not None else sig_end_line - 1\n         model_output_class_end = model_output_class_start\n@@ -1187,6 +1163,11 @@ def generate_new_docstring_for_class(lines, current_line_end, custom_args_dict):\n             model_output_class_end += 1\n         dataclass_content = lines[model_output_class_start : model_output_class_end - 1]\n         args_in_signature = get_args_in_dataclass(lines, dataclass_content)\n+        output_docstring_indent = 4\n+        source_args_doc = [ModelOutputArgs]\n+    else:\n+        # Class has no __init__ and is not a ModelOutput - nothing to document\n+        return \"\", None, None, [], [], []\n \n     docstring_start_line = sig_end_line if '\"\"\"' in lines[sig_end_line] else None\n \n@@ -1197,127 +1178,177 @@ def generate_new_docstring_for_class(lines, current_line_end, custom_args_dict):\n         docstring_start_line,\n         arg_indent=\"\",\n         custom_args_dict=custom_args_dict,\n-        output_docstring_indent=4 if found_model_output else 8,\n-        source_args_doc=[ModelArgs, ImageProcessorArgs] if not found_model_output else [ModelOutputArgs],\n+        output_docstring_indent=output_docstring_indent,\n+        source_args_doc=source_args_doc,\n     )\n \n \n-def find_custom_args_with_details(file_content: str, custom_args_var_name: str) -> list[dict]:\n-    \"\"\"\n-    Find the given custom args variable in the file content and return its content.\n+def _build_ast_indexes(source: str) -> list[DecoratedItem]:\n+    \"\"\"Parse source once and return list of all @auto_docstring decorated items.\n \n-    Args:\n-        file_content: The string content of the Python file.\n-        custom_args_var_name: The name of the custom args variable.\n+    Returns:\n+        List of DecoratedItem objects, one for each @auto_docstring decorated function or class.\n     \"\"\"\n-    # Escape the variable_name to handle any special regex characters it might contain\n-    escaped_variable_name = re.escape(custom_args_var_name)\n-\n-    # Construct the regex pattern dynamically with the specific variable name\n-    # This regex looks for:\n-    # ^\\s* : Start of a line with optional leading whitespace.\n-    # ({escaped_variable_name}) : Capture the exact variable name.\n-    # \\s*=\\s* : An equals sign, surrounded by optional whitespace.\n-    # (r?\\\"\\\"\\\")               : Capture the opening triple quotes (raw or normal string).\n-    # (.*?)                    : Capture the content (non-greedy).\n-    # (\\\"\\\"\\\")                  : Match the closing triple quotes.\n-    regex_pattern = rf\"^\\s*({escaped_variable_name})\\s*=\\s*(r?\\\"\\\"\\\")(.*?)(\\\"\\\"\\\")\"\n-\n-    flags = re.MULTILINE | re.DOTALL\n+    tree = ast.parse(source)\n+    # First pass: collect top-level string variables (for resolving custom_args variable references)\n+    var_to_string: dict[str, str] = {}\n+    for node in tree.body:\n+        # Handle: ARGS = \"some string\"\n+        if isinstance(node, ast.Assign) and isinstance(node.value, ast.Constant):\n+            if isinstance(node.value.value, str):\n+                for target in node.targets:\n+                    if isinstance(target, ast.Name):\n+                        var_to_string[target.id] = node.value.value\n+        # Handle: ARGS: str = \"some string\"\n+        elif isinstance(node, ast.AnnAssign) and isinstance(node.value, ast.Constant):\n+            if isinstance(node.value.value, str) and isinstance(node.target, ast.Name):\n+                var_to_string[node.target.id] = node.value.value\n+    # Second pass: find all @auto_docstring decorated functions/classes\n+    decorated_items: list[DecoratedItem] = []\n+    for node in ast.walk(tree):\n+        if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n+            continue\n+        # Find @auto_docstring decorator and extract custom_args if present\n+        decorator_line = None\n+        custom_args_text = None\n+        for dec in node.decorator_list:\n+            if not _is_auto_docstring_decorator(dec):\n+                continue\n+            decorator_line = dec.lineno\n+            # Extract custom_args from @auto_docstring(custom_args=...)\n+            if isinstance(dec, ast.Call):\n+                for kw in dec.keywords:\n+                    if kw.arg == \"custom_args\":\n+                        if isinstance(kw.value, ast.Constant) and isinstance(kw.value.value, str):\n+                            custom_args_text = kw.value.value.strip()\n+                        elif isinstance(kw.value, ast.Name):\n+                            custom_args_text = var_to_string.get(kw.value.id, \"\").strip()\n+            break\n+        if decorator_line is None:  # No @auto_docstring decorator found\n+            continue\n+        # Extract info for this decorated item\n+        kind = \"class\" if isinstance(node, ast.ClassDef) else \"function\"\n+        body_start_line = node.body[0].lineno if node.body else node.lineno + 1\n+        # Extract function arguments (skip self, *args, **kwargs)\n+        arg_names = []\n+        has_init = False\n+        init_def_line = None\n+        is_model_output = False\n+        if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n+            # For functions, extract args directly\n+            arg_names = _extract_function_args(node)\n+        elif isinstance(node, ast.ClassDef):\n+            # For classes, look for __init__ method and check if it's a ModelOutput\n+            # Check if class inherits from ModelOutput\n+            for base in node.bases:\n+                if isinstance(base, ast.Name) and \"ModelOutput\" in base.id:\n+                    is_model_output = True\n+                    break\n+            # Look for __init__ method in the class body\n+            for class_item in node.body:\n+                if isinstance(class_item, ast.FunctionDef) and class_item.name == \"__init__\":\n+                    has_init = True\n+                    init_def_line = class_item.lineno\n+                    arg_names = _extract_function_args(class_item)\n+                    # Update body_start_line to be the __init__ body start\n+                    body_start_line = class_item.body[0].lineno if class_item.body else class_item.lineno + 1\n+                    break\n \n-    # Use re.search to find the first match\n-    match = re.search(regex_pattern, file_content, flags)\n+        decorated_items.append(\n+            DecoratedItem(\n+                decorator_line=decorator_line,\n+                def_line=node.lineno,\n+                kind=kind,\n+                body_start_line=body_start_line,\n+                args=arg_names,\n+                custom_args_text=custom_args_text,\n+                has_init=has_init,\n+                init_def_line=init_def_line,\n+                is_model_output=is_model_output,\n+            )\n+        )\n \n-    if match:\n-        # match.group(1) will be the variable_name itself\n-        # match.group(3) will be the content inside the triple quotes\n-        content = match.group(3).strip()\n-        return content\n-    return None\n+    return sorted(decorated_items, key=lambda x: x.decorator_line)\n \n \n def update_file_with_new_docstrings(\n-    candidate_file, lines, line_starts_candidates, line_ends_candidates, overwrite=False\n+    candidate_file,\n+    lines,\n+    decorated_items: list[DecoratedItem],\n+    source: str,\n+    overwrite=False,\n ):\n     \"\"\"\n     For a given file, update the docstrings for all @auto_docstring candidates and write the new content.\n     \"\"\"\n-    content_base_file_new_lines = lines[: line_ends_candidates[0]]\n-    current_line_start = line_starts_candidates[0]\n-    current_line_end = line_ends_candidates[0]\n-    index = 1\n+    if not decorated_items:\n+        return [], [], []\n+\n     missing_docstring_args_warnings = []\n     fill_docstring_args_warnings = []\n     docstring_args_ro_remove_warnings = []\n \n-    while index <= len(line_starts_candidates):\n+    # Build new file content by processing decorated items and unchanged sections\n+    content_base_file_new_lines = []\n+    last_line_added = 0  # Track the last line we've already added to output (0-based)\n+\n+    for index, item in enumerate(decorated_items):\n+        def_line_0 = item.def_line - 1  # Convert to 0-based\n+\n+        # Parse custom_args if present\n         custom_args_dict = {}\n-        auto_docstring_signature_content = \"\".join(lines[current_line_start:current_line_end])\n-        match = re.findall(r\"custom_args=(\\w+)\", auto_docstring_signature_content)\n-        if match:\n-            custom_args_var_name = match[0]\n-            custom_args_var_content = find_custom_args_with_details(\"\\n\".join(lines), custom_args_var_name)\n-            if custom_args_var_content:\n-                custom_args_dict, _ = parse_docstring(custom_args_var_content)\n-        new_docstring = \"\"\n-        modify_class_docstring = False\n-        # Function\n-        if \"    def\" in lines[current_line_end]:\n+        if item.custom_args_text:\n+            custom_args_dict, _ = parse_docstring(item.custom_args_text)\n+\n+        # Generate new docstring based on kind\n+        if item.kind == \"function\":\n             (\n                 new_docstring,\n                 sig_line_end,\n                 docstring_end,\n                 missing_docstring_args,\n                 fill_docstring_args,\n                 docstring_args_ro_remove,\n-            ) = generate_new_docstring_for_function(lines, current_line_end, custom_args_dict)\n-        # Class\n-        elif \"class \" in lines[current_line_end]:\n+            ) = generate_new_docstring_for_function(lines, item, custom_args_dict)\n+        else:  # class\n             (\n                 new_docstring,\n-                class_sig_line_end,\n-                class_docstring_end_line,\n+                sig_line_end,\n+                docstring_end,\n                 missing_docstring_args,\n                 fill_docstring_args,\n                 docstring_args_ro_remove,\n-            ) = generate_new_docstring_for_class(lines, current_line_end, custom_args_dict)\n-            modify_class_docstring = class_sig_line_end is not None\n-        # Add warnings if needed\n-        if missing_docstring_args:\n-            for arg in missing_docstring_args:\n-                missing_docstring_args_warnings.append(f\"    - {arg} line {current_line_end}\")\n-        if fill_docstring_args:\n-            for arg in fill_docstring_args:\n-                fill_docstring_args_warnings.append(f\"    - {arg} line {current_line_end}\")\n-        if docstring_args_ro_remove:\n-            for arg in docstring_args_ro_remove:\n-                docstring_args_ro_remove_warnings.append(f\"    - {arg} line {current_line_end}\")\n-        # Write new lines\n-        if index >= len(line_ends_candidates) or line_ends_candidates[index] > current_line_end:\n-            if \"    def\" in lines[current_line_end]:\n-                content_base_file_new_lines += lines[current_line_end:sig_line_end]\n-                if new_docstring != \"\":\n-                    content_base_file_new_lines += new_docstring.split(\"\\n\")\n-                if index < len(line_ends_candidates):\n-                    content_base_file_new_lines += lines[docstring_end + 1 : line_ends_candidates[index]]\n-                else:\n-                    content_base_file_new_lines += lines[docstring_end + 1 :]\n-            elif modify_class_docstring:\n-                content_base_file_new_lines += lines[current_line_end:class_sig_line_end]\n-                if new_docstring != \"\":\n-                    content_base_file_new_lines += new_docstring.split(\"\\n\")\n-                if index < len(line_ends_candidates):\n-                    content_base_file_new_lines += lines[class_docstring_end_line + 1 : line_ends_candidates[index]]\n-                else:\n-                    content_base_file_new_lines += lines[class_docstring_end_line + 1 :]\n-            elif index < len(line_ends_candidates):\n-                content_base_file_new_lines += lines[current_line_end : line_ends_candidates[index]]\n-            else:\n-                content_base_file_new_lines += lines[current_line_end:]\n-            if index < len(line_ends_candidates):\n-                current_line_end = line_ends_candidates[index]\n-                current_line_start = line_starts_candidates[index]\n-        index += 1\n+            ) = generate_new_docstring_for_class(lines, item, custom_args_dict, source)\n+\n+        # If sig_line_end is None, this item couldn't be processed (e.g., class with no __init__)\n+        # In this case, we don't modify anything and just continue to the next item\n+        if sig_line_end is None:\n+            continue\n+\n+        # Add all lines from last processed line up to current def line\n+        content_base_file_new_lines += lines[last_line_added:def_line_0]\n+\n+        # Collect warnings\n+        for arg in missing_docstring_args:\n+            missing_docstring_args_warnings.append(f\"    - {arg} line {def_line_0}\")\n+        for arg in fill_docstring_args:\n+            fill_docstring_args_warnings.append(f\"    - {arg} line {def_line_0}\")\n+        for arg in docstring_args_ro_remove:\n+            docstring_args_ro_remove_warnings.append(f\"    - {arg} line {def_line_0}\")\n+\n+        # Add lines from current def through signature\n+        content_base_file_new_lines += lines[def_line_0:sig_line_end]\n+\n+        # Add new docstring if generated\n+        if new_docstring:\n+            content_base_file_new_lines += new_docstring.split(\"\\n\")\n+\n+        # Update last_line_added to skip the old docstring\n+        last_line_added = (docstring_end + 1) if docstring_end is not None else sig_line_end\n+\n+    # Add any remaining lines after the last decorated item\n+    content_base_file_new_lines += lines[last_line_added:]\n+\n     content_base_file_new = \"\\n\".join(content_base_file_new_lines)\n     if overwrite:\n         with open(candidate_file, \"w\", encoding=\"utf-8\") as f:\n@@ -1330,12 +1361,6 @@ def update_file_with_new_docstrings(\n     )\n \n \n-# TODO (Yoni): The functions in check_auto_docstrings rely on direct code parsing, which is prone to\n-# failure on edge cases and not robust to code changes. While this approach is significantly faster\n-# than using inspect (like in check_docstrings) and allows parsing any object including non-public\n-# ones, it may need to be refactored in the future to use a more robust parsing method. Note that\n-# we still need auto_docstring for some non-public objects since their docstrings are included in the\n-# docs of public objects (e.g. ModelOutput classes).\n def check_auto_docstrings(overwrite: bool = False, check_all: bool = False):\n     \"\"\"\n     Check docstrings of all public objects that are decorated with `@auto_docstrings`.\n@@ -1351,11 +1376,23 @@ def check_auto_docstrings(overwrite: bool = False, check_all: bool = False):\n     # 3. For each file, update docstrings for all candidates\n     for candidate_file in auto_docstrings_files:\n         with open(candidate_file, \"r\", encoding=\"utf-8\") as f:\n-            lines = f.read().split(\"\\n\")\n-        line_starts_candidates, line_ends_candidates = get_auto_docstring_candidate_lines(lines)\n+            content = f.read()\n+        lines = content.split(\"\\n\")\n+\n+        # Parse file once to find all @auto_docstring decorated items\n+        decorated_items = _build_ast_indexes(content)\n+\n+        if not decorated_items:\n+            continue\n+\n+        # Update docstrings for all decorated items\n         missing_docstring_args_warnings, fill_docstring_args_warnings, docstring_args_ro_remove_warnings = (\n             update_file_with_new_docstrings(\n-                candidate_file, lines, line_starts_candidates, line_ends_candidates, overwrite=overwrite\n+                candidate_file,\n+                lines,\n+                decorated_items,\n+                content,\n+                overwrite=overwrite,\n             )\n         )\n         if missing_docstring_args_warnings:"
        }
    ],
    "stats": {
        "total": 457,
        "additions": 243,
        "deletions": 214
    }
}