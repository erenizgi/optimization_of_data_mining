{
    "author": "sywangyi",
    "message": "fix FastSpeech2ConformerTokenizer crash in tokenize (#42888)\n\nSigned-off-by: Wang, Yi <yi.a.wang@intel.com>",
    "sha": "24b311eead0ee199ed6e77f8b562f01b7afa924d",
    "files": [
        {
            "sha": "c36d6ff2fbcb1921946b844cc988c2cabe26fda2",
            "filename": "src/transformers/models/fastspeech2_conformer/tokenization_fastspeech2_conformer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/24b311eead0ee199ed6e77f8b562f01b7afa924d/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Ftokenization_fastspeech2_conformer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/24b311eead0ee199ed6e77f8b562f01b7afa924d/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Ftokenization_fastspeech2_conformer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffastspeech2_conformer%2Ftokenization_fastspeech2_conformer.py?ref=24b311eead0ee199ed6e77f8b562f01b7afa924d",
            "patch": "@@ -79,6 +79,7 @@ def __init__(\n             unk_token=unk_token,\n             pad_token=pad_token,\n             should_strip_spaces=should_strip_spaces,\n+            special_tokens_pattern=\"none\",\n             **kwargs,\n         )\n "
        }
    ],
    "stats": {
        "total": 1,
        "additions": 1,
        "deletions": 0
    }
}