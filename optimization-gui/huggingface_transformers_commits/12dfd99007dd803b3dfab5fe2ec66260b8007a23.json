{
    "author": "MekkCyber",
    "message": "Fix : Nemotron Processor in GGUF conversion (#35708)\n\n* fixing nemotron processor\r\n\r\n* make style",
    "sha": "12dfd99007dd803b3dfab5fe2ec66260b8007a23",
    "files": [
        {
            "sha": "0da06a1f582ade0fd3d1918febc57f2e415839ee",
            "filename": "src/transformers/modeling_gguf_pytorch_utils.py",
            "status": "modified",
            "additions": 12,
            "deletions": 0,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/12dfd99007dd803b3dfab5fe2ec66260b8007a23/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/12dfd99007dd803b3dfab5fe2ec66260b8007a23/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_gguf_pytorch_utils.py?ref=12dfd99007dd803b3dfab5fe2ec66260b8007a23",
            "patch": "@@ -221,6 +221,17 @@ def process(self, weights, name, **kwargs):\n         return GGUFTensor(weights, name, {})\n \n \n+class NemotronTensorProcessor(TensorProcessor):\n+    def __init__(self, config=None):\n+        super().__init__(config=config)\n+\n+    # ref : https://github.com/ggerganov/llama.cpp/blob/master/convert_hf_to_gguf.py#L4666\n+    def process(self, weights, name, **kwargs):\n+        if \"norm.weight\" in name:\n+            weights = weights - 1\n+        return GGUFTensor(weights, name, {})\n+\n+\n class Gemma2TensorProcessor(TensorProcessor):\n     def __init__(self, config=None):\n         super().__init__(config=config)\n@@ -241,6 +252,7 @@ def process(self, weights, name, **kwargs):\n     \"t5encoder\": T5TensorProcessor,\n     \"gpt2\": GPT2TensorProcessor,\n     \"mamba\": MambaTensorProcessor,\n+    \"nemotron\": NemotronTensorProcessor,\n     \"gemma2\": Gemma2TensorProcessor,\n }\n "
        }
    ],
    "stats": {
        "total": 12,
        "additions": 12,
        "deletions": 0
    }
}