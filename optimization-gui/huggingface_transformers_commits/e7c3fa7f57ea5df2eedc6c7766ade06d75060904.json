{
    "author": "yonigozlan",
    "message": "Fix continue_final_message for image-text-to-text chat templates (#34236)\n\n* fix continue_final_message for vlms\r\n\r\n* Add one test for vlms continue_final_message chat template",
    "sha": "e7c3fa7f57ea5df2eedc6c7766ade06d75060904",
    "files": [
        {
            "sha": "16c05a14028eeeabdca134e4068b445070e9d2bf",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7c3fa7f57ea5df2eedc6c7766ade06d75060904/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7c3fa7f57ea5df2eedc6c7766ade06d75060904/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=e7c3fa7f57ea5df2eedc6c7766ade06d75060904",
            "patch": "@@ -1874,7 +1874,10 @@ def apply_chat_template(\n                     **template_kwargs,\n                 )\n             if continue_final_message:\n-                final_message = chat[-1][\"content\"].strip()\n+                final_message = chat[-1][\"content\"]\n+                if isinstance(final_message, (list, tuple)):\n+                    final_message = final_message[-1][\"text\"]\n+                final_message = final_message.strip()\n                 rendered_chat = rendered_chat[: rendered_chat.rindex(final_message) + len(final_message)].rstrip()\n             rendered.append(rendered_chat)\n "
        },
        {
            "sha": "d3a66a16df9a64d775aebfeb0d11d6f91a62e15e",
            "filename": "tests/models/llava/test_processor_llava.py",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/e7c3fa7f57ea5df2eedc6c7766ade06d75060904/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/e7c3fa7f57ea5df2eedc6c7766ade06d75060904/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava%2Ftest_processor_llava.py?ref=e7c3fa7f57ea5df2eedc6c7766ade06d75060904",
            "patch": "@@ -93,3 +93,24 @@ def test_chat_template(self):\n \n         formatted_prompt = processor.apply_chat_template(messages, add_generation_prompt=True)\n         self.assertEqual(expected_prompt, formatted_prompt)\n+\n+    def test_chat_template_with_continue_final_message(self):\n+        processor = LlavaProcessor.from_pretrained(\"llava-hf/llava-1.5-7b-hf\")\n+        expected_prompt = \"USER: <image>\\nDescribe this image. ASSISTANT: There is a dog and\"\n+        messages = [\n+            {\n+                \"role\": \"user\",\n+                \"content\": [\n+                    {\"type\": \"image\"},\n+                    {\"type\": \"text\", \"text\": \"Describe this image.\"},\n+                ],\n+            },\n+            {\n+                \"role\": \"assistant\",\n+                \"content\": [\n+                    {\"type\": \"text\", \"text\": \"There is a dog and\"},\n+                ],\n+            },\n+        ]\n+        prompt = processor.apply_chat_template(messages, continue_final_message=True)\n+        self.assertEqual(expected_prompt, prompt)"
        }
    ],
    "stats": {
        "total": 26,
        "additions": 25,
        "deletions": 1
    }
}