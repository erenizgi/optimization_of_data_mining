{
    "author": "Yacklin",
    "message": "Correct syntax error in trainer.md (#42001)\n\nA comma is missing between two parameters in the signature of compute_loss function.",
    "sha": "6ff4fabd9d1d02b8de1a0019e0dc48af09da5de4",
    "files": [
        {
            "sha": "1d700d398b5cfaeafbb98122513685fdd37eedba",
            "filename": "docs/source/en/trainer.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/6ff4fabd9d1d02b8de1a0019e0dc48af09da5de4/docs%2Fsource%2Fen%2Ftrainer.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/6ff4fabd9d1d02b8de1a0019e0dc48af09da5de4/docs%2Fsource%2Fen%2Ftrainer.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftrainer.md?ref=6ff4fabd9d1d02b8de1a0019e0dc48af09da5de4",
            "patch": "@@ -187,7 +187,7 @@ from torch import nn\n from transformers import Trainer\n \n class CustomTrainer(Trainer):\n-    def compute_loss(self, model: nn.Module, inputs: dict[str, Union[torch.Tensor, Any]], return_outputs: bool = False num_items_in_batch: Optional[torch.Tensor] = None):\n+    def compute_loss(self, model: nn.Module, inputs: dict[str, Union[torch.Tensor, Any]], return_outputs: bool = False, num_items_in_batch: Optional[torch.Tensor] = None):\n         labels = inputs.pop(\"labels\")\n         # forward pass\n         outputs = model(**inputs)"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}