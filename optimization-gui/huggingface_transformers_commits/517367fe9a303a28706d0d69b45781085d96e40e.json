{
    "author": "Rocketknight1",
    "message": "Revert change that breaks on Torch 2.1 (#37531)\n\n* Revert change that breaks on Torch 2.1\n\n* Add TODO\n\n* Trigger tests\n\n* Trigger tests",
    "sha": "517367fe9a303a28706d0d69b45781085d96e40e",
    "files": [
        {
            "sha": "d5c9213cc909cc7015178c143e140f2cc75ab690",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 4,
            "deletions": 1,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/517367fe9a303a28706d0d69b45781085d96e40e/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/517367fe9a303a28706d0d69b45781085d96e40e/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=517367fe9a303a28706d0d69b45781085d96e40e",
            "patch": "@@ -3704,7 +3704,10 @@ def autocast_smart_context_manager(self, cache_enabled: Optional[bool] = True):\n         arguments, depending on the situation.\n         \"\"\"\n         if self.use_cpu_amp:\n-            ctx_manager = torch.amp.autocast(\"cpu\", cache_enabled=cache_enabled, dtype=self.amp_dtype)\n+            # TODO Matt: This syntax is deprecated and the preferred version is\n+            #      torch.amp.autocast(\"cpu\", cache_enabled=cache_enabled, dtype=self.amp_dtype)\n+            #      but this is unavailable on Torch 2.1 or earlier. We can change this when we stop supporting 2.1.\n+            ctx_manager = torch.cpu.amp.autocast(cache_enabled=cache_enabled, dtype=self.amp_dtype)\n         else:\n             ctx_manager = contextlib.nullcontext()\n "
        }
    ],
    "stats": {
        "total": 5,
        "additions": 4,
        "deletions": 1
    }
}