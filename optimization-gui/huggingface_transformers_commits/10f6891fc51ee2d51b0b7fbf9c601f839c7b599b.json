{
    "author": "LysandreJik",
    "message": "Remove data from examples (#41168)\n\nRemove telemetry",
    "sha": "10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
    "files": [
        {
            "sha": "bd190e801520c8a5f3efd02ae8c853b77fd8d838",
            "filename": "examples/pytorch/audio-classification/run_audio_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Faudio-classification%2Frun_audio_classification.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -48,7 +48,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -218,10 +218,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_audio_classification\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "461062f6849bc8d865594caa9dde4043379ce995",
            "filename": "examples/pytorch/contrastive-image-text/run_clip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fcontrastive-image-text%2Frun_clip.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -247,10 +247,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_clip\", model_args, data_args)\n-\n     # 2. Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "8b498b545c45f8789f13ec87a9e3e589cf62af89",
            "filename": "examples/pytorch/image-classification/run_image_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -59,7 +59,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -201,10 +201,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_image_classification\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "cc88143053898889d8a37e66dada3f22e59a0cc8",
            "filename": "examples/pytorch/image-classification/run_image_classification_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n \n import transformers\n from transformers import AutoConfig, AutoImageProcessor, AutoModelForImageClassification, SchedulerType, get_scheduler\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -234,10 +234,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_image_classification_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "2d92d8ab434d8f78fa5ba3067a6a33ef4b0a39d4",
            "filename": "examples/pytorch/image-pretraining/run_mae.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mae.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -42,7 +42,7 @@\n     ViTMAEForPreTraining,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -193,10 +193,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_mae\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "5a636bbad58b473f4db87e37800b36ccd3efb018",
            "filename": "examples/pytorch/image-pretraining/run_mim.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -45,7 +45,7 @@\n     TrainingArguments,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -257,10 +257,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_mim\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "1c56360886328a17e8d16644ba2b79037611e673",
            "filename": "examples/pytorch/image-pretraining/run_mim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -49,7 +49,7 @@\n     SchedulerType,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -384,10 +384,6 @@ def collate_fn(examples):\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_mim_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "ddfd05e0f661be2b787bff1041194a87e765f9e6",
            "filename": "examples/pytorch/instance-segmentation/run_instance_segmentation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -50,7 +50,7 @@\n from transformers.image_processing_utils import BatchFeature\n from transformers.trainer import EvalPrediction\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -367,10 +367,6 @@ def main():\n     training_args.batch_eval_metrics = True\n     training_args.remove_unused_columns = False\n \n-    # # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_instance_segmentation\", args)\n-\n     # Setup logging and log on each process the small summary:\n     setup_logging(training_args)\n     logger.warning("
        },
        {
            "sha": "bff3abb32715159e7348f26b78a02183494b64a1",
            "filename": "examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n     get_scheduler,\n )\n from transformers.image_processing_utils import BatchFeature\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -413,10 +413,6 @@ def handle_repository_creation(accelerator: Accelerator, args: argparse.Namespac\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_instance_segmentation_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "8c677b404630bf8c91932959fc866ac8e0e6eb6f",
            "filename": "examples/pytorch/language-modeling/run_clm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -64,7 +64,7 @@\n )\n from transformers.testing_utils import CaptureLogger\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -292,10 +292,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_clm\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "c750d9274a36f01f361524afe853cb8be8053c88",
            "filename": "examples/pytorch/language-modeling/run_clm_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -66,7 +66,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -268,10 +268,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_clm_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "134d741f6b6c8014706d4e503ed74aaee93b696c",
            "filename": "examples/pytorch/language-modeling/run_fim.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -67,7 +67,7 @@\n from transformers.integrations import is_deepspeed_zero3_enabled\n from transformers.testing_utils import CaptureLogger\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -319,10 +319,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_fim\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "693f4d44b781c0cd5197ac4f968c2d3e48d329fa",
            "filename": "examples/pytorch/language-modeling/run_fim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -69,7 +69,7 @@\n     is_torch_xla_available,\n )\n from transformers.integrations import is_deepspeed_zero3_enabled\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -328,10 +328,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_fim_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "9c0bf50ede281bb2f74d7446b76fb3e237148060",
            "filename": "examples/pytorch/language-modeling/run_mlm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -63,7 +63,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -264,10 +264,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_mlm\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "59ee11926c4062f41a44bdd1a1ee7ca4b11986a2",
            "filename": "examples/pytorch/language-modeling/run_mlm_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -66,7 +66,7 @@\n     SchedulerType,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -275,10 +275,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_mlm_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "86bc31beedf891aab08ef959871bc281b32da72d",
            "filename": "examples/pytorch/language-modeling/run_plm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_plm.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -244,10 +244,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_plm\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "a8679f2b739c91a139004cd74485467a5da41777",
            "filename": "examples/pytorch/multiple-choice/run_swag.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -53,7 +53,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n \n \n # Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n@@ -188,10 +188,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_swag\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "c77a10e990d0a2788668dab1fde41eacea95df8c",
            "filename": "examples/pytorch/multiple-choice/run_swag_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -61,7 +61,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n \n \n # Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n@@ -238,10 +238,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_swag_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "ee0bd66cae99c5882bfd845f5ac960b673673b5d",
            "filename": "examples/pytorch/object-detection/run_object_detection.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -52,7 +52,7 @@\n from transformers.image_transforms import center_to_corners_format\n from transformers.trainer import EvalPrediction\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -349,10 +349,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_object_detection\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "543f3d1087421a6916fc761bdd904fdb49c8966e",
            "filename": "examples/pytorch/object-detection/run_object_detection_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -58,7 +58,7 @@\n )\n from transformers.image_processing_utils import BatchFeature\n from transformers.image_transforms import center_to_corners_format\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -411,10 +411,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_object_detection_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "be93a526b803a838686ed3c09abce3195c143a39",
            "filename": "examples/pytorch/question-answering/run_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -44,7 +44,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -237,10 +237,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_qa\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "4bcf4f9af8c8b558a2a2c40c45755af61f1e45ae",
            "filename": "examples/pytorch/question-answering/run_qa_beam_search.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -42,7 +42,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -235,10 +235,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_qa_beam_search\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "c95a5b46030ce02f748735a4f30524ed9750e179",
            "filename": "examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -49,7 +49,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -299,10 +299,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_qa_beam_search_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "a39047560c523c95988fff2055e2cd0d4de5fcc4",
            "filename": "examples/pytorch/question-answering/run_qa_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -51,7 +51,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -338,10 +338,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_qa_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "ac3c8ef4ec6299df3be5f59513a1d29b056a4e3d",
            "filename": "examples/pytorch/question-answering/run_seq2seq_qa.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_seq2seq_qa.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -40,7 +40,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import EvalLoopOutput, EvalPrediction, get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -282,10 +282,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_seq2seq_qa\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "cc45239f75c01120c6826fc1faa1b62653a98c71",
            "filename": "examples/pytorch/semantic-segmentation/run_semantic_segmentation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -53,7 +53,7 @@\n     default_data_collator,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -197,10 +197,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_semantic_segmentation\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "66b0af0ef6355e3360cfc6f2e40040d5f70ff6ca",
            "filename": "examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -57,7 +57,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -253,10 +253,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_semantic_segmentation_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "1840d7e4ed7a1eddc15eea8bc5a255bc6e7c2e55",
            "filename": "examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py",
            "status": "modified",
            "additions": 0,
            "deletions": 5,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-pretraining%2Frun_wav2vec2_pretraining_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-pretraining%2Frun_wav2vec2_pretraining_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-pretraining%2Frun_wav2vec2_pretraining_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -53,7 +53,6 @@\n     set_seed,\n )\n from transformers.models.wav2vec2.modeling_wav2vec2 import _compute_mask_indices, _sample_negative_indices\n-from transformers.utils import send_example_telemetry\n \n \n logger = get_logger(__name__)\n@@ -410,10 +409,6 @@ def main():\n     # We now keep distinct sets of args, for a cleaner separation of concerns.\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_wav2vec2_pretraining_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     accelerator = Accelerator()\n     logger.info(accelerator.state, main_process_only=False)"
        },
        {
            "sha": "86efea29fc10794223d4fa9aba6db49ed1635af6",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint, is_main_process\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -416,10 +416,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_speech_recognition_ctc\", model_args, data_args)\n-\n     # Detecting last checkpoint.\n     last_checkpoint = None\n     if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:"
        },
        {
            "sha": "56ca644a8c5a0de54aa0fce70fc30df43a9bd777",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -59,7 +59,7 @@\n )\n from transformers.models.wav2vec2.modeling_wav2vec2 import WAV2VEC2_ADAPTER_SAFE_FILE\n from transformers.trainer_utils import get_last_checkpoint, is_main_process\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -396,10 +396,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_speech_recognition_ctc_adapter\", model_args, data_args)\n-\n     # Detecting last checkpoint.\n     last_checkpoint = None\n     if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:"
        },
        {
            "sha": "c05f7104a92fbc4da9207108f1eb9ccb95a8bbdd",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_seq2seq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_seq2seq.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -55,7 +55,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint, is_main_process\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -300,10 +300,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_speech_recognition_seq2seq\", model_args, data_args)\n-\n     # 2. Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "dd7dd083b49a067f12cc105fc0e35d67057ef611",
            "filename": "examples/pytorch/summarization/run_summarization.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -62,7 +62,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, is_offline_mode, send_example_telemetry\n+from transformers.utils import check_min_version, is_offline_mode\n from transformers.utils.versions import require_version\n \n \n@@ -337,10 +337,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_summarization\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "b24bbc773bc028474572329aa7d9251d8ac69ed8",
            "filename": "examples/pytorch/summarization/run_summarization_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -66,7 +66,7 @@\n     SchedulerType,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, is_offline_mode, send_example_telemetry\n+from transformers.utils import check_min_version, is_offline_mode\n from transformers.utils.versions import require_version\n \n \n@@ -338,9 +338,6 @@ def parse_args():\n \n def main():\n     args = parse_args()\n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_summarization_no_trainer\", args)\n \n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers"
        },
        {
            "sha": "35413cd7875b73373626a5f006a1e70ea31f3377",
            "filename": "examples/pytorch/text-classification/run_classification.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -296,10 +296,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_classification\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "afa09d74604176ae5eef2b202a2ed8900e5d84f5",
            "filename": "examples/pytorch/text-classification/run_glue.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -58,7 +58,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -241,10 +241,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_glue\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "05c51eb8ae3a667863fd1627f1e23ddd5b044880",
            "filename": "examples/pytorch/text-classification/run_glue_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -58,7 +58,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -234,9 +234,6 @@ def parse_args():\n \n def main():\n     args = parse_args()\n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_glue_no_trainer\", args)\n \n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers"
        },
        {
            "sha": "3027da5feae6d9a9338b3c1f70a245a5c97cc13e",
            "filename": "examples/pytorch/text-classification/run_xnli.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_xnli.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -57,7 +57,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -199,10 +199,6 @@ def main():\n     parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n     model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_xnli\", model_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "7620d697c1264dd30590c50ca04dc99a8f18dde7",
            "filename": "examples/pytorch/token-classification/run_ner.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftoken-classification%2Frun_ner.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -55,7 +55,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -238,10 +238,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_ner\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "0d31cf46ab8a8e537b822acad5b91e0178f9b90a",
            "filename": "examples/pytorch/token-classification/run_ner_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -62,7 +62,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -284,10 +284,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_ner_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "8e005e0d7323fa386fbedf1cd53ff74f600a5f66",
            "filename": "examples/pytorch/translation/run_translation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftranslation%2Frun_translation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftranslation%2Frun_translation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -61,7 +61,7 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -285,10 +285,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_translation\", model_args, data_args)\n-\n     # Setup logging\n     logging.basicConfig(\n         format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\","
        },
        {
            "sha": "9dae2ec653f0711f491a0ebf4c30348523b82a88",
            "filename": "examples/pytorch/translation/run_translation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -66,7 +66,7 @@\n     default_data_collator,\n     get_scheduler,\n )\n-from transformers.utils import check_min_version, send_example_telemetry\n+from transformers.utils import check_min_version\n from transformers.utils.versions import require_version\n \n \n@@ -330,10 +330,6 @@ def main():\n     # Parse the arguments\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_translation_no_trainer\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     # If we're using tracking, we also need to initialize it here and it will by default pick up all supported trackers\n     # in the environment"
        },
        {
            "sha": "0f968f7e252d02544242e4f6d82bbab4e795541a",
            "filename": "src/transformers/utils/__init__.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/src%2Ftransformers%2Futils%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/src%2Ftransformers%2Futils%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2F__init__.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -101,7 +101,6 @@\n     is_offline_mode,\n     is_remote_url,\n     list_repo_templates,\n-    send_example_telemetry,\n     try_to_load_from_cache,\n )\n from .import_utils import ("
        },
        {
            "sha": "dab357941b818534814c9a7e56d94620e2c3339f",
            "filename": "src/transformers/utils/hub.py",
            "status": "modified",
            "additions": 0,
            "deletions": 36,
            "changes": 36,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/src%2Ftransformers%2Futils%2Fhub.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/src%2Ftransformers%2Futils%2Fhub.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fhub.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -56,7 +56,6 @@\n     build_hf_headers,\n     get_session,\n     hf_raise_for_status,\n-    send_telemetry,\n )\n \n from . import __version__, logging\n@@ -985,41 +984,6 @@ def push_to_hub(\n             )\n \n \n-def send_example_telemetry(example_name, *example_args, framework=\"pytorch\"):\n-    \"\"\"\n-    Sends telemetry that helps tracking the examples use.\n-\n-    Args:\n-        example_name (`str`): The name of the example.\n-        *example_args (dataclasses or `argparse.ArgumentParser`): The arguments to the script. This function will only\n-            try to extract the model and dataset name from those. Nothing else is tracked.\n-        framework (`str`, *optional*, defaults to `\"pytorch\"`): The framework for the example.\n-    \"\"\"\n-    if is_offline_mode():\n-        return\n-\n-    data = {\"example\": example_name, \"framework\": framework}\n-    for args in example_args:\n-        args_as_dict = {k: v for k, v in args.__dict__.items() if not k.startswith(\"_\") and v is not None}\n-        if \"model_name_or_path\" in args_as_dict:\n-            model_name = args_as_dict[\"model_name_or_path\"]\n-            # Filter out local paths\n-            if not os.path.isdir(model_name):\n-                data[\"model_name\"] = args_as_dict[\"model_name_or_path\"]\n-        if \"dataset_name\" in args_as_dict:\n-            data[\"dataset_name\"] = args_as_dict[\"dataset_name\"]\n-        elif \"task_name\" in args_as_dict:\n-            # Extract script name from the example_name\n-            script_name = example_name.replace(\"run_\", \"\")\n-            script_name = script_name.replace(\"_no_trainer\", \"\")\n-            data[\"dataset_name\"] = f\"{script_name}-{args_as_dict['task_name']}\"\n-\n-    # Send telemetry in the background\n-    send_telemetry(\n-        topic=\"examples\", library_name=\"transformers\", library_version=__version__, user_agent=http_user_agent(data)\n-    )\n-\n-\n def convert_file_size_to_int(size: Union[int, str]):\n     \"\"\"\n     Converts a size expressed as a string with digits an unit (like `\"5MB\"`) to an integer (in bytes)."
        },
        {
            "sha": "8ada67913b037b37fa05c0ed00cac927f138db44",
            "filename": "templates/adding_a_new_example_script/{{cookiecutter.directory_name}}/run_{{cookiecutter.example_shortcut}}.py",
            "status": "modified",
            "additions": 0,
            "deletions": 10,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/10f6891fc51ee2d51b0b7fbf9c601f839c7b599b/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/templates%2Fadding_a_new_example_script%2F%7B%7Bcookiecutter.directory_name%7D%7D%2Frun_%7B%7Bcookiecutter.example_shortcut%7D%7D.py?ref=10f6891fc51ee2d51b0b7fbf9c601f839c7b599b",
            "patch": "@@ -46,7 +46,6 @@\n     set_seed,\n )\n from transformers.trainer_utils import get_last_checkpoint\n-from transformers.utils import send_example_telemetry\n \n \n logger = logging.getLogger(__name__)\n@@ -220,10 +219,6 @@ def main():\n     else:\n         model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_{{cookiecutter.example_shortcut}}\", model_args, data_args)\n-\n     # Detecting last checkpoint.\n     last_checkpoint = None\n     if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n@@ -545,7 +540,6 @@ def _mp_fn(index):\n     get_scheduler,\n     set_seed,\n )\n-from transformers.utils import send_example_telemetry\n \n \n logger = logging.getLogger(__name__)\n@@ -698,10 +692,6 @@ def parse_args():\n def main():\n     args = parse_args()\n \n-    # Sending telemetry. Tracking the example usage helps us better allocate resources to maintain them. The\n-    # information sent is the one passed as arguments along with your Python/PyTorch versions.\n-    send_example_telemetry(\"run_{{cookiecutter.example_shortcut}\", args)\n-\n     # Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n     accelerator = Accelerator()\n     # Make one log on every process with the configuration for debugging."
        }
    ],
    "stats": {
        "total": 290,
        "additions": 40,
        "deletions": 250
    }
}