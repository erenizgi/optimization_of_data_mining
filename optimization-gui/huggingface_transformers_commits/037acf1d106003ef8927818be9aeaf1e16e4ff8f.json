{
    "author": "remi-or",
    "message": "[janus] Fix failing tests on mi3XX (#38426)\n\n* Fix multiple devices error on Janus\n\n* Fix AttributeError on Janus BOI token\n\n* Initialize lm first in Janus to get correct device map\n\n* Added expectations for Janus test_model_generate_images\n\n* Fixed JanusVisionEncoderLayer being split across devices\n\n* Code formatting\n\n* Adding modeling file\n\n* Reverted changes out of scope for this PR",
    "sha": "037acf1d106003ef8927818be9aeaf1e16e4ff8f",
    "files": [
        {
            "sha": "a526ce5d7af16385d9465ba1b38b6bcce0d83c92",
            "filename": "src/transformers/models/janus/modeling_janus.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/037acf1d106003ef8927818be9aeaf1e16e4ff8f/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/037acf1d106003ef8927818be9aeaf1e16e4ff8f/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py?ref=037acf1d106003ef8927818be9aeaf1e16e4ff8f",
            "patch": "@@ -58,7 +58,7 @@ class JanusPreTrainedModel(PreTrainedModel):\n     config_class = JanusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"LlamaDecoderLayer\"]\n+    _no_split_modules = [\"LlamaDecoderLayer\", \"JanusVisionEncoderLayer\"]\n     _skip_keys_device_placement = [\"past_key_values\", \"causal_mask\"]\n     _supports_flash_attn_2 = True\n     _supports_sdpa = True\n@@ -1133,6 +1133,7 @@ def forward(\n             image_features = image_embeds.reshape(-1, embed_dim)\n             image_attention_mask = image_attention_mask.unsqueeze(-1).expand(-1, -1, embed_dim)\n \n+            image_attention_mask = image_attention_mask.to(inputs_embeds.device)\n             image_features = image_features.to(inputs_embeds.device, inputs_embeds.dtype)\n             inputs_embeds = inputs_embeds.masked_scatter(image_attention_mask, image_features)\n "
        },
        {
            "sha": "0d484ffb0c0598abab8195437fe18b069783ca35",
            "filename": "src/transformers/models/janus/modular_janus.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/037acf1d106003ef8927818be9aeaf1e16e4ff8f/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/037acf1d106003ef8927818be9aeaf1e16e4ff8f/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py?ref=037acf1d106003ef8927818be9aeaf1e16e4ff8f",
            "patch": "@@ -379,7 +379,7 @@ class JanusPreTrainedModel(PreTrainedModel):\n     config_class = JanusConfig\n     base_model_prefix = \"model\"\n     supports_gradient_checkpointing = True\n-    _no_split_modules = [\"LlamaDecoderLayer\"]\n+    _no_split_modules = [\"LlamaDecoderLayer\", \"JanusVisionEncoderLayer\"]\n     _skip_keys_device_placement = [\"past_key_values\", \"causal_mask\"]\n     _supports_flash_attn_2 = True\n     _supports_sdpa = True\n@@ -971,6 +971,7 @@ def forward(\n             image_features = image_embeds.reshape(-1, embed_dim)\n             image_attention_mask = image_attention_mask.unsqueeze(-1).expand(-1, -1, embed_dim)\n \n+            image_attention_mask = image_attention_mask.to(inputs_embeds.device)\n             image_features = image_features.to(inputs_embeds.device, inputs_embeds.dtype)\n             inputs_embeds = inputs_embeds.masked_scatter(image_attention_mask, image_features)\n "
        },
        {
            "sha": "2729c0718c3abf88766ab922df0a64d4dc0501ca",
            "filename": "tests/models/janus/test_modeling_janus.py",
            "status": "modified",
            "additions": 16,
            "deletions": 6,
            "changes": 22,
            "blob_url": "https://github.com/huggingface/transformers/blob/037acf1d106003ef8927818be9aeaf1e16e4ff8f/tests%2Fmodels%2Fjanus%2Ftest_modeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/037acf1d106003ef8927818be9aeaf1e16e4ff8f/tests%2Fmodels%2Fjanus%2Ftest_modeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fjanus%2Ftest_modeling_janus.py?ref=037acf1d106003ef8927818be9aeaf1e16e4ff8f",
            "patch": "@@ -35,6 +35,7 @@\n from transformers.models.auto import get_values\n from transformers.models.auto.modeling_auto import MODEL_FOR_BACKBONE_MAPPING_NAMES, MODEL_MAPPING_NAMES\n from transformers.testing_utils import (\n+    Expectations,\n     require_torch,\n     slow,\n     torch_device,\n@@ -538,12 +539,21 @@ def test_model_generate_images(self):\n         self.assertTrue(out.shape[1] == 576)\n \n         # fmt: off\n-        expected_tokens = torch.tensor([4484,  4015, 15750,   506,  3758, 11651,  8597,  5739,  4861,   971,\n-         14985, 14834, 15438,  7548,  1820,  1465, 13529, 12761, 10503, 12761,\n-         14303,  6155,  4015, 11766,   705, 15736, 14146, 10417,  1951,  7713,\n-         14305, 15617,  6169,  2706,  8006, 14893,  3855, 10188, 15652,  6297,\n-          1097, 12108, 15038,   311, 14998, 15165,   897,  4044,  1762,  4676,\n-        ]).to(model.device)\n+        expected_tokens =  Expectations(\n+            {\n+                (\"rocm\", None): [10367, 1380, 4841, 15155, 1224, 16361, 15834, 13722, 15258, 8321, 10496, 14532, 8770,\n+                                 12353, 5481, 11484, 2585, 8587, 3201, 14292, 3356, 2037, 3077, 6107, 3758, 2572, 9376,\n+                                 13219, 6007, 14292, 12696, 10666, 10046, 13483, 8282, 9101, 5208, 4260, 13886, 13335,\n+                                 6135, 2316, 15423,  311, 5460, 12218, 14172, 8583, 14577, 3648\n+                                 ],\n+                (\"cuda\", None): [4484, 4015, 15750, 506, 3758, 11651, 8597, 5739, 4861, 971, 14985, 14834, 15438, 7548,\n+                                 1820, 1465, 13529, 12761, 10503, 12761, 14303, 6155, 4015, 11766, 705, 15736, 14146,\n+                                 10417, 1951, 7713, 14305, 15617, 6169, 2706, 8006, 14893, 3855, 10188, 15652, 6297,\n+                                 1097, 12108, 15038, 311, 14998, 15165, 897, 4044, 1762, 4676\n+                                 ],\n+            }\n+        )\n+        expected_tokens = torch.tensor(expected_tokens.get_expectation()).to(model.device)\n         # fmt: on\n \n         # Compare the first 50 generated tokens."
        }
    ],
    "stats": {
        "total": 28,
        "additions": 20,
        "deletions": 8
    }
}