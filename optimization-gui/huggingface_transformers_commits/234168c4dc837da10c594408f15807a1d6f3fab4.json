{
    "author": "rwightman",
    "message": "Fixes, improvements to `timm` import behaviour (#35800)\n\n* Fix timm dummy import logic\r\n\r\n* Add requires to TimmWrapperConfig.from_dict so users see a helpful import error message if timm not installed",
    "sha": "234168c4dc837da10c594408f15807a1d6f3fab4",
    "files": [
        {
            "sha": "a5aede6c714821120c3cbf7809be3e086b820f70",
            "filename": "src/transformers/__init__.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/234168c4dc837da10c594408f15807a1d6f3fab4/src%2Ftransformers%2F__init__.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/234168c4dc837da10c594408f15807a1d6f3fab4/src%2Ftransformers%2F__init__.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2F__init__.py?ref=234168c4dc837da10c594408f15807a1d6f3fab4",
            "patch": "@@ -1302,7 +1302,7 @@\n     _import_structure[\"models.vit\"].append(\"ViTImageProcessorFast\")\n \n try:\n-    if not is_torchvision_available() and not is_timm_available():\n+    if not (is_torchvision_available() and is_timm_available()):\n         raise OptionalDependencyNotAvailable()\n except OptionalDependencyNotAvailable:\n     from .utils import dummy_timm_and_torchvision_objects\n@@ -6399,7 +6399,7 @@\n         from .models.vit import ViTImageProcessorFast\n \n     try:\n-        if not is_torchvision_available() and not is_timm_available():\n+        if not (is_torchvision_available() and is_timm_available()):\n             raise OptionalDependencyNotAvailable()\n     except OptionalDependencyNotAvailable:\n         from .utils.dummy_timm_and_torchvision_objects import *"
        },
        {
            "sha": "4313ad854add5955150268d43d4f3a6b97e73ed1",
            "filename": "src/transformers/models/timm_wrapper/configuration_timm_wrapper.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/234168c4dc837da10c594408f15807a1d6f3fab4/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/234168c4dc837da10c594408f15807a1d6f3fab4/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py?ref=234168c4dc837da10c594408f15807a1d6f3fab4",
            "patch": "@@ -18,7 +18,7 @@\n from typing import Any, Dict\n \n from ...configuration_utils import PretrainedConfig\n-from ...utils import is_timm_available, logging\n+from ...utils import is_timm_available, logging, requires_backends\n \n \n if is_timm_available():\n@@ -72,6 +72,7 @@ def from_dict(cls, config_dict: Dict[str, Any], **kwargs):\n \n         # if no labels added to config, use imagenet labeller in timm\n         if label_names is None and not is_custom_model:\n+            requires_backends(cls, [\"timm\"])\n             imagenet_subset = infer_imagenet_subset(config_dict)\n             if imagenet_subset:\n                 dataset_info = ImageNetInfo(imagenet_subset)"
        }
    ],
    "stats": {
        "total": 7,
        "additions": 4,
        "deletions": 3
    }
}