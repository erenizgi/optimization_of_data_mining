{
    "author": "AhmedAlmaghz",
    "message": "[i18n-ar] Translated file : `docs/source/ar/community.md` into Arabic (#33027)\n\n* Add docs/source/ar/community.md to Add_docs_source_ar_community.md\r\n\r\n* Update community.md\r\n\r\n* Update community.md\r\n\r\n* Update community.md\r\n\r\n* Update _toctree.yml - add community.md\r\n\r\n* Update docs/source/ar/community.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Create how_to_hack_models.md\r\n\r\n* Create modular_transformers.md\r\n\r\n* Create tiktoken.md\r\n\r\n* Update _toctree.yml\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/how_to_hack_models.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/modular_transformers.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/tiktoken.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n* Update docs/source/ar/tiktoken.md\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Abdullah Mohammed <554032+abodacs@users.noreply.github.com>",
    "sha": "425af6cdc20d20e93fb814e6932c1b194b3f2915",
    "files": [
        {
            "sha": "138d3a1bd8aa084f2a0f9eb3ce88caa07a4153b4",
            "filename": "docs/source/ar/_toctree.yml",
            "status": "modified",
            "additions": 8,
            "deletions": 2,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2F_toctree.yml?ref=425af6cdc20d20e93fb814e6932c1b194b3f2915",
            "patch": "@@ -133,12 +133,18 @@\n     title: ุงููุนุงููุฑ\n   - local: notebooks\n     title: ุฏูุงุชุฑ ุงูููุงุญุธุงุช ูุน ุงูุฃูุซูุฉ\n-#   - local: community\n-#     title: ููุงุฑุฏ ุงููุฌุชูุน\n+  - local: community\n+    title: ููุงุฑุฏ ุงููุฌุชูุน\n   - local: troubleshooting\n     title: ุงุณุชูุดุงู ุงูุฃุฎุทุงุก ูุฅุตูุงุญูุง\n   - local: gguf\n     title: ุงูุชูุงูู ูุน ูููุงุช GGUF\n+  - local: tiktoken\n+    title: ุงูุชูุงูู ูุน ูููุงุช TikToken\n+  - local: modular_transformers\n+    title: ุงููุญุฏุงุช ุงูููุทูุฉ ูู `transformers`\n+  - local: how_to_hack_models\n+    title: ุงุฎุชุฑุงู ุงููููุฐุฌ (ุงููุชุงุจุฉ ููู ูุฆุฉ ูุงุณุชุฎุฏุงูู)\n   title: ุฃุฏูุฉ ุงููุทูุฑูู\n # - sections:\n #   - local: quantization/overview"
        },
        {
            "sha": "5a1c31de0aaa3f7e8c2399a016a59be982d17960",
            "filename": "docs/source/ar/community.md",
            "status": "added",
            "additions": 66,
            "deletions": 0,
            "changes": 66,
            "blob_url": "https://github.com/huggingface/transformers/blob/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fcommunity.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fcommunity.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fcommunity.md?ref=425af6cdc20d20e93fb814e6932c1b194b3f2915",
            "patch": "@@ -0,0 +1,66 @@\n+# ูุฌุชูุน ุงููุทูุฑูู\n+\n+ูุฐู ุงูุตูุญุฉ ุชุฌูุน ุงูููุงุฑุฏ ุญูู ๐ค Transformers ุงูุชู ุทูุฑูุง ุงููุฌุชูุน.\n+\n+## ููุงุฑุฏ ุงููุฌุชูุน:\n+\n+| ุงููุตุฏุฑ     |      ุงููุตู      |      ุงููุคูู      |\n+|:----------|:-------------|------:|\n+| [Hugging Face Transformers Glossary Flashcards](https://www.darigovresearch.com/huggingface-transformers-glossary-flashcards) | ูุฌููุนุฉ ูู ุงูุจุทุงูุงุช ุงูุชุนููููุฉ ุงููุงุฆูุฉ ุนูู [Transformers Docs Glossary](glossary) ูุงูุชู ุชู ูุถุนูุง ูู ุดูู ูููู ุชุนููู/ูุฑุงุฌุนุชู ุจุณูููุฉ ุจุงุณุชุฎุฏุงู [Anki](https://apps.ankiweb.net/) ููู ุชุทุจูู ููุชูุญ ุงููุตุฏุฑ ูุชุนุฏุฏ ุงูููุตุงุช ูุตูู ุฎุตูุตูุง ููุงุญุชูุงุธ ุจุงููุนุฑูุฉ ุนูู ุงููุฏู ุงูุทููู. ุดุงูุฏ ูุฐุง [ููุฏูู ุชูููุฏู ุญูู ููููุฉ ุงุณุชุฎุฏุงู ุงูุจุทุงูุงุช ุงูุชุนููููุฉ](https://www.youtube.com/watch?v=Dji_7PILrw). | [Darigov Research](https://www.darigovresearch.com/) |\n+\n+## ุฏูุงุชุฑ ููุงุญุธุงุช ุงููุฌุชูุน:\n+\n+| ุงูุฏูุชุฑ     |      ุงููุตู      |      ุงููุคูู      |      |\n+|:----------|:-------------|:-------------|------:|\n+| [Fine-tune a pre-trained Transformer to generate lyrics](https://github.com/AlekseyKorshuk/huggingartists) | ููููุฉ ุชูููุฏ ูููุงุช ุงูุฃุบุงูู ุนูู ุบุฑุงุฑ ููุงูู ุงูููุถู ูู ุฎูุงู ุถุจุท ูููุฐุฌ GPT-2 |  [Aleksey Korshuk](https://github.com/AlekseyKorshuk) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AlekseyKorshuk/huggingartists/blob/master/huggingartists-demo.ipynb) |\n+| [Train T5 in Tensorflow 2](https://github.com/snapthat/TF-T5-text-to-text) | ููููุฉ ุชุฏุฑูุจ T5 ูุฃู ูููุฉ ุจุงุณุชุฎุฏุงู Tensorflow 2. ููุถุญ ูุฐุง ุงูุฏูุชุฑ ูููุฉ ุงูุณุคุงู ูุงูุฌูุงุจ ุงููููุฐุฉ ูู Tensorflow 2 ุจุงุณุชุฎุฏุงู SQUAD | [Muhammad Harris](https://github.com/HarrisDePerceptron) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb) |\n+| [Train T5 on TPU](https://github.com/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb)  | ููููุฉ ุชุฏุฑูุจ T5 ุนูู SQUAD ูุน Transformers ู Nlp | [Suraj Patil](https://github.com/patil-suraj) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/T5_on_TPU.ipynb#scrollTo=QLGiFCDqvuil) |\n+| [Fine-tune T5 for Classification and Multiple Choice](https://github.com/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb)  | ููููุฉ ุถุจุท ูููุฐุฌ T5 ููุชุตููู ูุงูููุงู ูุชุนุฏุฏุฉ ุงูุฎูุงุฑุงุช ุจุงุณุชุฎุฏุงู ุชูุณูู ุงููุต ุฅูู ูุต ูุน PyTorch Lightning |  [Suraj Patil](https://github.com/patil-suraj) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patil-suraj/exploring-T5/blob/master/t5_fine_tuning.ipynb) |\n+| [Fine-tune DialoGPT on New Datasets and Languages](https://github.com/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb)  | ููููุฉ ุถุจุท ูููุฐุฌ DialoGPT ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุฌุฏูุฏุฉ ูุฑูุจูุชุงุช ุงูุฏุฑุฏุดุฉ ุงููุญุงุฏุซูุฉ ุงูููุชูุญุฉ |  [Nathan Cooper](https://github.com/ncoop57) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ncoop57/i-am-a-nerd/blob/master/_notebooks/2020-05-12-chatbot-part-1.ipynb) |\n+| [Long Sequence Modeling with Reformer](https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb)  | ููููุฉ ุงูุชุฏุฑูุจ ุนูู ุชุณูุณูุงุช ุทูููุฉ ุชุตู ุฅูู 500,000 ุฑูุฒ ุจุงุณุชุฎุฏุงู Reformer |  [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb)  |\n+| [Fine-tune BART for Summarization](https://github.com/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ BART ููุชูุฎูุต ุจุงุณุชุฎุฏุงู fastai ุจุงุณุชุฎุฏุงู blurr | [Wayde Gilliam](https://ohmeow.com/) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ohmeow/ohmeow_website/blob/master/posts/2021-05-25-mbart-sequence-classification-with-blurr.ipynb) |\n+| [Fine-tune a pre-trained Transformer on anyone's tweets](https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb) | ููููุฉ ุชูููุฏ ุชุบุฑูุฏุงุช ุนูู ุบุฑุงุฑ ุญุณุงุจ Twitter ุงูููุถู ูุฏูู ูู ุฎูุงู ุถุจุท ูููุฐุฌ GPT-2 |  [Boris Dayma](https://github.com/borisdayma) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/borisdayma/huggingtweets/blob/master/huggingtweets-demo.ipynb) |\n+| [Optimize ๐ค Hugging Face models with Weights & Biases](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb) | ุฏููู ูุงูู ูุนุฑุถ ุชูุงูู W&B ูุน Hugging Face | [Boris Dayma](https://github.com/borisdayma) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/huggingface/Optimize_Hugging_Face_models_with_Weights_%26_Biases.ipynb) |\n+| [Pretrain Longformer](https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb)  | ููููุฉ ุจูุงุก ูุณุฎุฉ \"ุทูููุฉ\" ูู ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ุงูููุฌูุฏุฉ |  [Iz Beltagy](https://beltagy.net) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb) |\n+| [Fine-tune Longformer for QA](https://github.com/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ Longformer ููููุฉ QA | [Suraj Patil](https://github.com/patil-suraj) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb) |\n+| [Evaluate Model with ๐คnlp](https://github.com/patrickvonplaten/notebooks/blob/master/How_to_evaluate_Longformer_on_TriviaQA_using_NLP.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ Longformer ุนูู TriviaQA ูุน `nlp` | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1m7eTGlPmLRgoPkkA7rkhQdZ9ydpmsdLE?usp=sharing) |\n+| [Fine-tune T5 for Sentiment Span Extraction](https://github.com/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb)  | ููููุฉ ุถุจุท ูููุฐุฌ T5 ูุงุณุชุฎุฑุงุฌ ุงููุดุงุนุฑ ุจุงุณุชุฎุฏุงู ุชูุณูู ุงููุต ุฅูู ูุต ูุน PyTorch Lightning |  [Lorenzo Ampil](https://github.com/enzoampil) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/enzoampil/t5-intro/blob/master/t5_qa_training_pytorch_span_extraction.ipynb) |\n+| [Fine-tune DistilBert for Multiclass Classification](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ DistilBert ููุชุตููู ูุชุนุฏุฏ ุงููุฆุงุช ุจุงุณุชุฎุฏุงู PyTorch | [Abhishek Kumar Mishra](https://github.com/abhimishra91) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb)|\n+|[Fine-tune BERT for Multi-label Classification](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb)|ููููุฉ ุถุจุท ูููุฐุฌ BERT ููุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช ุจุงุณุชุฎุฏุงู PyTorch|[Abhishek Kumar Mishra](https://github.com/abhimishra91) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb)|\n+|[Fine-tune T5 for Summarization](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb)|ููููุฉ ุถุจุท ูููุฐุฌ T5 ููุชูุฎูุต ูู PyTorch ูุชุชุจุน ุงูุชุฌุงุฑุจ ุจุงุณุชุฎุฏุงู WandB|[Abhishek Kumar Mishra](https://github.com/abhimishra91) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb)|\n+|[Speed up Fine-Tuning in Transformers with Dynamic Padding / Bucketing](https://github.com/ELS-RD/transformers-notebook/blob/master/Divide_Hugging_Face_Transformers_training_time_by_2_or_more.ipynb)|ููููุฉ ุชุณุฑูุน ุงูุถุจุท ุงูุฏููู ุจุนุงูู 2 ุจุงุณุชุฎุฏุงู ุงูุถุจุท ุงูุฏููุงูููู/ุงูุชูุณูู|[Michael Benesty](https://github.com/pommedeterresautee) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CBfRU1zbfu7-ijiOqAAQUA-RJaxfcJoO?usp=sharing)|\n+|[Pretrain Reformer for Masked Language Modeling](https://github.com/patrickvonplaten/notebooks/blob/master/Reformer_For_Masked_LM.ipynb)| ููููุฉ ุชุฏุฑูุจ ูููุฐุฌ Reformer ูุน ุทุจูุงุช ุงูุงูุชุจุงู ุซูุงุฆูุฉ ุงูุงุชุฌุงู | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1tzzh0i8PgDQGV3SMFUGxM7_gGae3K-uW?usp=sharing)|\n+|[Expand and Fine Tune Sci-BERT](https://github.com/lordtt13/word-embeddings/blob/master/COVID-19%20Research%20Data/COVID-SciBERT.ipynb)| ููููุฉ ุฒูุงุฏุฉ ููุฑุฏุงุช ูููุฐุฌ SciBERT ุงููุณุจู ุงูุชุฏุฑูุจ ูู AllenAI ุนูู ูุฌููุนุฉ ุจูุงูุงุช CORD ูุฅูุดุงุก ุฎุท ุฃูุงุจูุจ ููุง. | [Tanmay Thakur](https://github.com/lordtt13) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1rqAR40goxbAfez1xvF3hBJphSCsvXmh8)|\n+|[Fine Tune BlenderBotSmall for Summarization using the Trainer API](https://github.com/lordtt13/transformers-experiments/blob/master/Custom%20Tasks/fine-tune-blenderbot_small-for-summarization.ipynb)| ููููุฉ ุถุจุท ูููุฐุฌ BlenderBotSmall ููุชูุฎูุต ุนูู ูุฌููุนุฉ ุจูุงูุงุช ูุฎุตุตุฉุ ุจุงุณุชุฎุฏุงู ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช Trainer. | [Tanmay Thakur](https://github.com/lordtt13) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/19Wmupuls7mykSGyRN_Qo6lPQhgp56ymq?usp=sharing)|\n+|[Fine-tune Electra and interpret with Integrated Gradients](https://github.com/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ Electra ููุชุญููู ุงูุนุงุทูู ูุชูุณูุฑ ุงูุชูุจุคุงุช ุจุงุณุชุฎุฏุงู Captum Integrated Gradients | [Eliza Szczechla](https://elsanns.github.io) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/electra_fine_tune_interpret_captum_ig.ipynb)|\n+|[fine-tune a non-English GPT-2 Model with Trainer class](https://github.com/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ GPT-2 ุบูุฑ ุงูุฅูุฌููุฒู ุจุงุณุชุฎุฏุงู ูุฆุฉ Trainer | [Philipp Schmid](https://www.philschmid.de) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/philschmid/fine-tune-GPT-2/blob/master/Fine_tune_a_non_English_GPT_2_Model_with_Huggingface.ipynb)|\n+|[Fine-tune a DistilBERT Model for Multi Label Classification task](https://github.com/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ DistilBERT ููููุฉ ุงูุชุตููู ูุชุนุฏุฏ ุงูุชุตูููุงุช | [Dhaval Taunk](https://github.com/DhavalTaunk08) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DhavalTaunk08/Transformers_scripts/blob/master/Transformers_multilabel_distilbert.ipynb)|\n+|[Fine-tune ALBERT for sentence-pair classification](https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ ALBERT ุฃู ุฃู ูููุฐุฌ ุขุฎุฑ ูุงุฆู ุนูู BERT ููููุฉ ุงูุชุตููู ุงููุฒุฏูุฌ ููุฌูู | [Nadir El Manouzi](https://github.com/NadirEM) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb)|\n+|[Fine-tune Roberta for sentiment analysis](https://github.com/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ Roberta ููุชุญููู ุงูุนุงุทูู | [Dhaval Taunk](https://github.com/DhavalTaunk08) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb)|\n+|[Evaluating Question Generation Models](https://github.com/flexudy-pipe/qugeev) | ูุง ูุฏู ุฏูุฉ ุงูุฅุฌุงุจุงุช ุนูู ุงูุฃุณุฆูุฉ ุงูุชู ูููุฏูุง ูููุฐุฌู ุงูุชุญูููู seq2seqุ | [Pascal Zoleko](https://github.com/zolekode) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1bpsSqCQU-iw_5nNoRm_crPq6FRuJthq_?usp=sharing)|\n+|[Classify text with DistilBERT and Tensorflow](https://github.com/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ DistilBERT ููุชุตููู ุงููุตู ูู TensorFlow | [Peter Bayerle](https://github.com/peterbayerle) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb)|\n+|[Leverage BERT for Encoder-Decoder Summarization on CNN/Dailymail](https://github.com/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb) | ููููุฉ ุงูุจุฏุก ุงูุณุฑูุน ููููุฐุฌ *EncoderDecoderModel* ูุน ููุทุฉ ุชูุชูุด *google-bert/bert-base-uncased* ููุชูุฎูุต ุนูู CNN/Dailymail | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/BERT2BERT_for_CNN_Dailymail.ipynb)|\n+|[Leverage RoBERTa for Encoder-Decoder Summarization on BBC XSum](https://github.com/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb) | ููููุฉ ุงูุจุฏุก ุงูุณุฑูุน ููููุฐุฌ *EncoderDecoderModel* ุงููุดุชุฑู ูุน ููุทุฉ ุชูุชูุด *FacebookAI/roberta-base* ููุชูุฎูุต ุนูู BBC/XSum | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb)|\n+|[Fine-tune TAPAS on Sequential Question Answering (SQA)](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ *TapasForQuestionAnswering* ูุน ููุทุฉ ุชูุชูุด *tapas-base* ุนูู ูุฌููุนุฉ ุจูุงูุงุช Sequential Question Answering (SQA) | [Niels Rogge](https://github.com/nielsrogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Fine_tuning_TapasForQuestionAnswering_on_SQA.ipynb)|\n+|[Evaluate TAPAS on Table Fact Checking (TabFact)](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ *TapasForSequenceClassification* ุงููุถุจูุท ูุณุจููุง ูุน ููุทุฉ ุชูุชูุด *tapas-base-finetuned-tabfact* ุจุงุณุชุฎุฏุงู ูุฒูุฌ ูู ููุชุจุชู ๐ค datasets ู ๐ค transformers | [Niels Rogge](https://github.com/nielsrogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/TAPAS/Evaluating_TAPAS_on_the_Tabfact_test_set.ipynb)|\n+|[Fine-tuning mBART for translation](https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ mBART ุจุงุณุชุฎุฏุงู Seq2SeqTrainer ููุชุฑุฌูุฉ ูู ุงูููุฏูุฉ ุฅูู ุงูุฅูุฌููุฒูุฉ | [Vasudev Gupta](https://github.com/vasudevgupta7) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb)|\n+|[Fine-tune LayoutLM on FUNSD (a form understanding dataset)](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ *LayoutLMForTokenClassification* ุนูู ูุฌููุนุฉ ุจูุงูุงุช FUNSD ูุงุณุชุฎุฑุงุฌ ุงููุนูููุงุช ูู ุงููุณุชูุฏุงุช ุงูููุณูุญุฉ ุถูุฆููุง | [Niels Rogge](https://github.com/nielsrogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForTokenClassification_on_FUNSD.ipynb)|\n+|[Fine-Tune DistilGPT2 and Generate Text](https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ DistilGPT2 ูุชูููุฏ ุงููุต | [Aakash Tripathi](https://github.com/tripathiaakash) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tripathiaakash/DistilGPT2-Tutorial/blob/main/distilgpt2_fine_tuning.ipynb)|\n+|[Fine-Tune LED on up to 8K tokens](https://github.com/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ LED ุนูู pubmed ููุชูุฎูุต ุทููู ุงููุฏู | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_tune_Longformer_Encoder_Decoder_(LED)_for_Summarization_on_pubmed.ipynb)|\n+|[Evaluate LED on Arxiv](https://github.com/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ LED ููุชูุฎูุต ุทููู ุงููุฏู ุจุดูู ูุนุงู | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/LED_on_Arxiv.ipynb)|\n+|[Fine-tune LayoutLM on RVL-CDIP (a document image classification dataset)](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ *LayoutLMForSequenceClassification* ุนูู ูุฌููุนุฉ ุจูุงูุงุช RVL-CDIP ูุชุตููู ุงููุณุชูุฏุงุช ุงูููุณูุญุฉ ุถูุฆููุง | [Niels Rogge](https://github.com/nielsrogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/LayoutLM/Fine_tuning_LayoutLMForSequenceClassification_on_RVL_CDIP.ipynb)|\n+|[Wav2Vec2 CTC decoding with GPT2 adjustment](https://github.com/voidful/huggingface_notebook/blob/main/xlsr_gpt.ipynb) | ููููุฉ ูู ุชุดููุฑ ุชุณูุณู CTC ูุน ุชุนุฏูู ูููุฐุฌ ุงููุบุฉ | [Eric Lam](https://github.com/voidful) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1e_zQHYbO2YKEaUgzb1ww1WwiAyydAj?usp=sharing)|\n+|[Fine-tune BART for summarization in two languages with Trainer class](https://github.com/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ BART ููุชูุฎูุต ุจูุบุชูู ุจุงุณุชุฎุฏุงู ูุฆุฉ Trainer | [Eliza Szczechla](https://github.com/elsanns) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/elsanns/xai-nlp-notebooks/blob/master/fine_tune_bart_summarization_two_langs.ipynb)|\n+|[Evaluate Big Bird on Trivia QA](https://github.com/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ BigBird ููุฃุณุฆูุฉ ูุงูุฃุฌูุจุฉ ุนูู ูุซุงุฆู ุทูููุฉ ุนูู Trivia QA | [Patrick von Platen](https://github.com/patrickvonplaten) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb)|\n+| [Create video captions using Wav2Vec2](https://github.com/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb) | ููููุฉ ุฅูุดุงุก ุชุนูููุงุช ุชูุถูุญูุฉ ุนูู YouTube ูู ุฃู ููุฏูู ูู ุฎูุงู ุชูุฑูุบ ุงูุตูุช ุจุงุณุชุฎุฏุงู Wav2Vec | [Niklas Muennighoff](https://github.com/Muennighoff) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Muennighoff/ytclipcc/blob/main/wav2vec_youtube_captions.ipynb) |\n+| [Fine-tune the Vision Transformer on CIFAR-10 using PyTorch Lightning](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ Vision Transformer (ViT) ุนูู CIFAR-10 ุจุงุณุชุฎุฏุงู ููุชุจุงุช HuggingFace Transformers ู Datasets ู PyTorch Lightning | [Niels Rogge](https://github.com/nielsrogge) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_PyTorch_Lightning.ipynb) |\n+| [Fine-tune the Vision Transformer on CIFAR-10 using the ๐ค Trainer](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ Vision Transformer (ViT) ุนูู CIFAR-10 ุจุงุณุชุฎุฏุงู ููุชุจุงุช HuggingFace Transformers ู Datasets ู ๐ค Trainer | [Niels Rogge](https://github.com/nielsrogge) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/VisionTransformer/Fine_tuning_the_Vision_Transformer_on_CIFAR_10_with_the_%F0%9F%A4%97_Trainer.ipynb) |\n+| [Evaluate LUKE on Open Entity, an entity typing dataset](https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ *LukeForEntityClassification* ุนูู ูุฌููุนุฉ ุจูุงูุงุช Open Entity | [Ikuya Yamada](https://github.com/ikuyamada) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_open_entity.ipynb) |\n+| [Evaluate LUKE on TACRED, a relation extraction dataset](https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ *LukeForEntityPairClassification* ุนูู ูุฌููุนุฉ ุจูุงูุงุช TACRED | [Ikuya Yamada](https://github.com/ikuyamada) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_tacred.ipynb) |\n+| [Evaluate LUKE on CoNLL-2003, an important NER benchmark](https://github.com/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ *LukeForEntitySpanClassification* ุนูู ูุฌููุนุฉ ุจูุงูุงุช CoNLL-2003 | [Ikuya Yamada](https://github.com/ikuyamada) |[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/studio-ousia/luke/blob/master/notebooks/huggingface_conll_2003.ipynb) |\n+| [Evaluate BigBird-Pegasus on PubMed dataset](https://github.com/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb) | ููููุฉ ุชูููู ูููุฐุฌ *BigBirdPegasusForConditionalGeneration* ุนูู ูุฌููุนุฉ ุจูุงูุงุช PubMed | [Vasudev Gupta](https://github.com/vasudevgupta7) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vasudevgupta7/bigbird/blob/main/notebooks/bigbird_pegasus_evaluation.ipynb) |\n+| [Speech Emotion Classification with Wav2Vec2](https://github.com/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb) | ููููุฉ ุงุณุชุฎุฏุงู ูููุฐุฌ Wav2Vec2 ุงููุณุจู ุงูุชุฏุฑูุจ ูุชุตููู ุงููุดุงุนุฑ ุนูู ูุฌููุนุฉ ุจูุงูุงุช MEGA | [Mehrdad Farahani](https://github.com/m3hrdadfi) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/m3hrdadfi/soxan/blob/main/notebooks/Emotion_recognition_in_Greek_speech_using_Wav2Vec2.ipynb) |\n+| [Detect objects in an image with DETR](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb) | ููููุฉ ุงุณุชุฎุฏุงู ูููุฐุฌ *DetrForObjectDetection* ุงููุฏุฑุจ ูููุดู ุนู ุงูุฃุฌุณุงู ูู ุตูุฑุฉ ูุชุตููุฑ ุงูุงูุชุจุงู | [Niels Rogge](https://github.com/NielsRogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/DETR_minimal_example_(with_DetrFeatureExtractor).ipynb) |\n+| [Fine-tune DETR on a custom object detection dataset](https://github.com/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ *DetrForObjectDetection* ุนูู ูุฌููุนุฉ ุจูุงูุงุช ุงููุดู ุนู ุงูุฃุฌุณุงู ุงููุฎุตุตุฉ | [Niels Rogge](https://github.com/NielsRogge) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/DETR/Fine_tuning_DetrForObjectDetection_on_custom_dataset_(balloon).ipynb) |\n+| [Finetune T5 for Named Entity Recognition](https://github.com/ToluClassics/Notebooks/blob/main/T5_Ner_Finetuning.ipynb) | ููููุฉ ุถุจุท ูููุฐุฌ *T5* ุนูู ูููุฉ ุงูุชุนุฑู ุนูู ุงูููุงูุงุช ุงููุณูุงุฉ | [Ogundepo Odunayo](https://github.com/ToluClassics) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1obr78FY_cBmWY5ODViCmzdY6O1KB65Vc?usp=sharing) |\n+| [Fine-Tuning Open-Source LLM using QLoRA with MLflow and PEFT](https://github.com/mlflow/mlflow/blob/master/docs/source/llms/transformers/tutorials/fine-tuning/transformers-peft.ipynb) | ููููุฉ ุงุณุชุฎุฏุงู [QLoRA](https://github.com/artidoro/qlora) ู [PEFT](https://huggingface.co/docs/peft/en/index) ูุถุจุท ูููุฐุฌ LLM ุจุทุฑููุฉ ูุนุงูุฉ ูู ุญูุซ ุงูุฐุงูุฑุฉุ ูุน ุงุณุชุฎุฏุงู [MLflow](https://mlflow.org/docs/latest/llms/transformers/index.html) ูุฅุฏุงุฑุฉ ุชุชุจุน ุงูุชุฌุงุฑุจ | [Yuki Watanabe](https://github.com/B-Step62) | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mlflow/mlflow/blob/master/docs/source/llms/transformers/tutorials/fine-tuning/transformers-peft.ipynb) |"
        },
        {
            "sha": "8ce3589732f06aee0de0bde51843af967f0e26a7",
            "filename": "docs/source/ar/how_to_hack_models.md",
            "status": "added",
            "additions": 163,
            "deletions": 0,
            "changes": 163,
            "blob_url": "https://github.com/huggingface/transformers/blob/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fhow_to_hack_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fhow_to_hack_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fhow_to_hack_models.md?ref=425af6cdc20d20e93fb814e6932c1b194b3f2915",
            "patch": "@@ -0,0 +1,163 @@\n+# ููููุฉ ุชุนุฏูู ุฃู ูููุฐุฌ ูู ููุงุฐุฌ Transformers\n+\n+ุชููุฑ ููุชุจุฉ [๐ค Transformers](https://github.com/huggingface/transformers) ูุฌููุนุฉ ูู ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ูุงูุฃุฏูุงุช ููุนุงูุฌุฉ ุงููุบุงุช ุงูุทุจูุนูุฉุ ูุงูุฑุคูุฉุ ููุง ุฅูู ุฐูู. ุนูู ุงูุฑุบู ูู ุฃู ูุฐู ุงูููุงุฐุฌ ุชุบุทู ูุฌููุนุฉ ูุงุณุนุฉ ูู ุงูุชุทุจููุงุชุ ููุฏ ุชูุงุฌู ุญุงูุงุช ุงุณุชุฎุฏุงู ูุง ุชุฏุนููุง ุงูููุชุจุฉ ุจุดูู ุงูุชุฑุงุถู. ููููู ููุชุฎุตูุต ุฃู ููุชุญ ุฅููุงููุงุช ุฌุฏูุฏุฉุ ูุซู ุฅุถุงูุฉ ุทุจูุงุช ุฌุฏูุฏุฉุ ุฃู ุชุนุฏูู ุงูุจููุฉ ุงููุนูุงุฑูุฉุ ุฃู ุชุญุณูู ุขููุงุช ุงูุงูุชุจุงู. ุณูููุถุญ ูู ูุฐุง ุงูุฏููู ููููุฉ ุชุนุฏูู ููุงุฐุฌ Transformers ุงูููุฌูุฏุฉ ูุชูุจูุฉ ุงุญุชูุงุฌุงุชู ุงููุญุฏุฏุฉ. ุงูุดูุก ุงูุฑุงุฆุน ูู ุฃูู ูุณุช ุจุญุงุฌุฉ ุฅูู ุงูุฎุฑูุฌ ูู ุฅุทุงุฑ ุนูู Transformers ูุฅุฌุฑุงุก ูุฐู ุงูุชุบููุฑุงุช. ู ููููู ุชุนุฏูู ุงูููุงุฐุฌ ูุจุงุดุฑุฉู ูู Transformers ูุงูุงุณุชูุงุฏุฉ ูู ุงูููุฒุงุช ูุซู [ูุงุฌูุฉ ุจุฑูุฌุฉ ุงูุชุทุจููุงุช Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer)ุ ู [PreTrainedModel](https://huggingface.co/docs/transformers/main/en/main_classes/model#transformers.PreTrainedModel)ุ ูุงูุถุจุท ุงูุฏููู ุงููุนุงู ุจุงุณุชุฎุฏุงู ุฃุฏูุงุช ูุซู [PEFT](https://huggingface.co/docs/peft/index).\n+\n+ุณูุฑุดุฏู ูู ูุฐุง ุงูุฏููู  ูููููุฉ ุชุฎุตูุต ููุงุฐุฌ Transformers ุงูููุฌูุฏุฉ ูุชูุจูุฉ ูุชุทูุจุงุชูุ ุฏูู ููุฏุงู ูุฒุงูุง ุงูุฅุทุงุฑ. ุณุชุชุนูู ููููุฉ:\n+\n+- ุชุนุฏูู ุจููุฉ ูููุฐุฌ ูุง ูู ุฎูุงู ุชุบููุฑ ุขููุฉ ุงูุงูุชุจุงู ุงูุฎุงุตุฉ ุจู.\n+- ุชุทุจูู ุชูููุงุช ูุซู Low-Rank Adaptation (LoRA) ุนูู ููููุงุช ูููุฐุฌ ูุญุฏุฏุฉ.\n+\n+ูุญู ูุดุฌุนู ุนูู ุงููุณุงููุฉ ุจุงุฎุชุฑุงูุงุชู ุงูุฎุงุตุฉ ููุดุงุฑูุชูุง ููุง ูุน ุงููุฌุชูุน1\n+\n+## ูุซุงู: ุชุนุฏูู ุขููุฉ ุงูุงูุชุจุงู ูู ูููุฐุฌ Segment Anything (SAM)\n+\n+ูููุฐุฌ **Segment Anything (SAM)** ูู ูููุฐุฌ ุฑุงุฆุฏ ูู ูุฌุงู ุชุฌุฒุฆุฉ ุงูุตูุฑ. ูู ุชูููุฐู ุงูุงูุชุฑุงุถูุ ูุณุชุฎุฏู SAM ุฅุณูุงุทูุง ูุฌูุนูุง ููุงุณุชุนูุงู ูุงูููุชุงุญ ูุงููููุฉ (`qkv`) ูู ุขููุฉ ุงูุงูุชุจุงู ุงูุฎุงุตุฉ ุจู. ููุน ุฐููุ ูุฏ ุชุฑุบุจ ูู ุถุจุท ููููุงุช ูุญุฏุฏุฉ ููุท ูู ุขููุฉ ุงูุงูุชุจุงูุ ูุซู ุฅุณูุงุทุงุช ุงูุงุณุชุนูุงู (`q`) ูุงููููุฉ (`v`)ุ ูุชูููู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ ูุงูููุงุฑุฏ ุงูุญุณุงุจูุฉ ุงููุทููุจุฉ.\n+\n+### ุงูุฏุงูุน\n+\n+ูู ุฎูุงู ุชูุณูู ุงูุฅุณูุงุท ุงููุฌูุน `qkv` ุฅูู ุฅุณูุงุทุงุช ูููุตูุฉ `q` ู `k` ู `v`ุ ููููู ุชุทุจูู ุชูููุงุช ูุซู **LoRA** (Low-Rank Adaptation) ุนูู ุฅุณูุงุทู `q` ู `v` ููุท. ูุณูุญ ูู ูุฐุง ุจูุง ููู:\n+\n+- ุถุจุท ุนุฏุฏ ุฃูู ูู ุงููุนููุงุชุ ููุง ูููู ูู ุงูุนุจุก ุงูุญุณุงุจู.\n+- ุชุญููู ุฃุฏุงุก ุฃูุถู ูู ุฎูุงู ุงูุชุฑููุฒ ุนูู ููููุงุช ูุญุฏุฏุฉ.\n+- ุชุฌุฑุจุฉ ุงุณุชุฑุงุชูุฌูุงุช ุชุนุฏูู ูุฎุชููุฉ ูู ุขููุฉ ุงูุงูุชุจุงู.\n+\n+### ุงูุชูููุฐ\n+\n+#### **ุงูุฎุทูุฉ 1: ุฅูุดุงุก ูุฆุฉ ุงูุชูุงู ูุฎุตุตุฉ**\n+\n+ุจุนุฏ ุฐููุ ูู ุจุฅูุดุงุก ูุฆุฉ ูุฑุนูุฉ ูู ูุฆุฉ `SamVisionAttention` ุงูุฃุตููุฉ ูุนุฏููุง ูุชุถู ุฅุณูุงุทุงุช `q` ู `k` ู `v` ูููุตูุฉ.\n+\n+```python\n+import torch\n+import torch.nn as nn\n+from transformers.models.sam.modeling_sam import SamVisionAttention\n+\n+class SamVisionAttentionSplit(SamVisionAttention, nn.Module):\n+    def __init__(self, config, window_size):\n+        super().__init__(config, window_size)\n+        del self.qkv\n+        # ุฅุณูุงุทุงุช ูููุตูุฉ q ู k ู v\n+        self.q = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self.k = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self.v = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self._register_load_state_dict_pre_hook(self.split_q_k_v_load_hook)\n+\n+    def split_q_k_v_load_hook(self, state_dict, prefix, *args):\n+        keys_to_delete = []\n+        for key in list(state_dict.keys()):\n+            if \"qkv.\" in key:\n+                # ุชูุณูู q ู k ู v ูู ุงูุฅุณูุงุท ุงููุฌูุน\n+                q, k, v = state_dict[key].chunk(3, dim=0)\n+                # ุงุณุชุจุฏุงู ุงูุฅุณูุงุทุงุช ุงููุฑุฏูุฉ q ู k ู v\n+                state_dict[key.replace(\"qkv.\", \"q.\")] = q\n+                state_dict[key.replace(\"qkv.\", \"k.\")] = k\n+                state_dict[key.replace(\"qkv.\", \"v.\")] = v\n+                # ูุถุน ุนูุงูุฉ ุนูู ููุชุงุญ qkv ุงููุฏูู ููุญุฐู\n+                keys_to_delete.append(key)\n+        \n+        # ุญุฐู ููุงุชูุญ qkv ุงููุฏููุฉ\n+        for key in keys_to_delete:\n+            del state_dict[key]\n+\n+    def forward(self, hidden_states: torch.Tensor, output_attentions=False) -> torch.Tensor:\n+        batch_size, height, width, _ = hidden_states.shape\n+        qkv_shapes = (batch_size *  self.num_attention_heads,  height * width, -1)\n+        query = self.q(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+        key = self.k(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+        value = self.v(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+\n+        attn_weights = (query * self.scale) @ key.transpose(-2, -1)\n+\n+        if self.use_rel_pos:\n+            attn_weights = self.add_decomposed_rel_pos(\n+                attn_weights, query, self.rel_pos_h, self.rel_pos_w, (height, width), (height, width)\n+            )\n+\n+        attn_weights = torch.nn.functional.softmax(attn_weights, dtype=torch.float32, dim=-1).to(query.dtype)\n+        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n+        attn_output = (attn_probs @ value).reshape(batch_size, self.num_attention_heads, height, width, -1)\n+        attn_output = attn_output.permute(0, 2, 3, 1, 4).reshape(batch_size, height, width, -1)\n+        attn_output = self.proj(attn_output)\n+\n+        if output_attentions:\n+            outputs = (attn_output, attn_weights)\n+        else:\n+            outputs = (attn_output, None)\n+        return outputs\n+```\n+\n+**ุงูุดุฑุญ:**\n+\n+- **ุงูุฅุณูุงุทุงุช ุงููููุตูุฉ:** ูุชู ุฅุฒุงูุฉ ุงูุฅุณูุงุท ุงูููุฌูุน `qkv`ุ ูุฅูุดุงุก ุฅุณูุงุทุงุช ุฎุทูุฉ ูููุตูุฉ `q` ู `k` ู `v`.\n+- **ุฏุงูุฉ ุงุณุชุฏุนุงุก  ุชุญููู ุงูุฃูุฒุงู:** ุชููู ุทุฑููุฉ `_split_qkv_load_hook` ุจุชูุณูู ุฃูุฒุงู `qkv` ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ุฅูู ุฃูุฒุงู `q` ู `k` ู `v` ูููุตูุฉ ุนูุฏ ุชุญููู ุงููููุฐุฌ. ูุถูู ูุฐุง ุงูุชูุงูู ูุน ุฃู ูููุฐุฌ ูุณุจู ุงูุชุฏุฑูุจ.\n+- **ุงูุชูููุฐ ุงูุฃูุงูู:** ูุชู ุญุณุงุจ ุงูุงุณุชุนูุงูุงุช ูุงูููุงุชูุญ ูุงูููู ุจุดูู ูููุตูุ ูุชุณุชูุฑ ุขููุฉ ุงูุงูุชุจุงู ูุงููุนุชุงุฏ.\n+\n+#### **ุงูุฎุทูุฉ 2: ุงุณุชุจุฏุงู ูุฆุฉ ุงูุงูุชุจุงู ุงูุฃุตููุฉ**\n+\n+ุงุณุชุจุฏู ูุฆุฉ `SamVisionAttention` ุงูุฃุตููุฉ ุจูุฆุชู ุงููุฎุตุตุฉ ุจุญูุซ ูุณุชุฎุฏู ุงููููุฐุฌ ุขููุฉ ุงูุงูุชุจุงู ุงููุนุฏูุฉ.\n+\n+```python\n+from transformers import SamModel\n+from transformers.models.sam import modeling_sam\n+\n+# ุงุณุชุจุฏุงู ูุฆุฉ ุงูุงูุชูุงู ูู ูุญุฏุฉ ููุทูุฉ modeling_sam\n+modeling_sam.SamVisionAttention = SamVisionAttentionSplit\n+\n+# ุชุญููู ูููุฐุฌ SAM ุงููุณุจู ุงูุชุฏุฑูุจ\n+model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n+```\n+\n+**ุงูุดุฑุญ:**\n+\n+- **ุงุณุชุจุฏุงู ุงููุฆุฉ:** ูู ุฎูุงู ุชุนููู ูุฆุชู ุงููุฎุตุตุฉ ุฅูู `modeling_sam.SamVisionAttention`ุ ูุฅู ุฃู ุญุงูุงุช ูู ูุฆุฉ `SamVisionAttention` ูู ุงููููุฐุฌ ุณุชุณุชุฎุฏู ุงููุณุฎุฉ ุงููุนุฏูุฉ. ูุจุงูุชุงููุ ุนูุฏ ุงุณุชุฏุนุงุก `SamModel`ุ ุณูุชู ุงุณุชุฎุฏุงู `SamVisionAttentionSplit` ุงููุญุฏุฏุฉ ุญุฏูุซูุง.\n+- **ุชุญููู ุงููููุฐุฌ:** ูุชู ุชุญููู ุงููููุฐุฌ ุจุงุณุชุฎุฏุงู `from_pretrained`ุ ููุชู ุฏูุฌ ุขููุฉ ุงูุงูุชุจุงู ุงููุฎุตุตุฉ.\n+\n+#### **ุงูุฎุทูุฉ 3: ุชุทุจูู LoRA ุนูู ุฅุณูุงุทุงุช ูุญุฏุฏุฉ**\n+\n+ูุน ูุฌูุฏ ุฅุณูุงุทุงุช `q` ู `k` ู `v` ูููุตูุฉุ ููููู ุงูุขู ุชุทุจูู LoRA ุนูู ููููุงุช ูุญุฏุฏุฉุ ูุซู ุฅุณูุงุทุงุช `q` ู `v`.\n+\n+```python\n+from peft import LoraConfig, get_peft_model\n+\n+config = LoraConfig(\n+    r=16,\n+    lora_alpha=32,\n+    target_modules=[\"q\", \"v\"],  # ุชุทุจูู LoRA ุนูู ุฅุณูุงุทุงุช q ู v\n+    lora_dropout=0.1,\n+    task_type=\"mask-generation\"\n+)\n+\n+# ุชุทุจูู LoRA ุนูู ุงููููุฐุฌ\n+model = get_peft_model(model, config)\n+```\n+\n+**ุงูุดุฑุญ:**\n+\n+- **ุชูููู LoRA:** ุชุญุฏุฏ `LoraConfig` ุงููุฑุชุจุฉ `r`ุ ูุนุงูู ุงูููุงุณ `lora_alpha`ุ ูุงููุญุฏุงุช ุงููุณุชูุฏูุฉ (`\"q\"` ู `\"v\"`)ุ ููุนุฏู ุงูุชุฎููุ ูููุน ุงููููุฉ.\n+- **ุชุทุจูู LoRA:** ุชููู ุฏุงูุฉ `get_peft_model` ุจุชุทุจูู LoRA ุนูู ุงููุญุฏุงุช ุงููุญุฏุฏุฉ ูู ุงููููุฐุฌ.\n+- **ุชูููู ุงููุนููุงุช:** ูู ุฎูุงู ุงูุชุฑููุฒ ุนูู `q` ู `v`ุ ูุฅูู ุชููู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจุ ููุง ูุคุฏู ุฅูู ุชุณุฑูุน ุงูุชุฏุฑูุจ ูุชูููู ุงุณุชุฎุฏุงู ุงูุฐุงูุฑุฉ.\n+\n+#### **ุงูุฎุทูุฉ 4: ุงูุชุญูู ูู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ**\n+\n+ูู ุงูุณูู ุงูุชุญูู ูู ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ ููุนุฑูุฉ ุชุฃุซูุฑ ุชุนุฏููู.\n+\n+```python\n+model.print_trainable_parameters()\n+```\n+\n+**ุงููุงุชุฌ ุงููุชููุน:**\n+\n+```\n+ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ: 608,256 || ุฌููุน ุงููุนููุงุช: 94,343,728 || ูุณุจุฉ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ: 0.6447\n+ุนุฏุฏ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ: 912,384 || ุฌููุน ุงููุนููุงุช: 94,647,856 || ูุณุจุฉ ุงููุนููุงุช ุงููุงุจูุฉ ููุชุฏุฑูุจ: 0.9640 # ูุน k\n+```\n+\n+## ุงููุณุงููุฉ ุจุงุจุฏุงุนุงุชู ุงูุฎุงุตุฉ\n+\n+ูููู ูุชุนุฏูู ุงูููุงุฐุฌ ุงููุณุจูุฉ ุงูุชุฏุฑูุจ ุฃู ููุชุญ ุขูุงููุง ุฌุฏูุฏุฉ ููุจุญุซ ูุงูุชุทุจูู. ูู ุฎูุงู ููู ูุชุนุฏูู ุงูุขููุงุช ุงูุฏุงุฎููุฉ ููููุงุฐุฌ ูุซู SAMุ ููููู ุชุฎุตูุตูุง ูุชูุจูุฉ ุงุญุชูุงุฌุงุชู ุงููุญุฏุฏุฉุ ูุชุญุณูู ุงูุฃุฏุงุกุ ูุชุฌุฑุจุฉ ุฃููุงุฑ ุฌุฏูุฏุฉ.\n+\n+ุฅุฐุง ููุช ุจุชุทููุฑ ุชุนุฏู๏ปปุชู ุงูุฎุงุตุฉ ูููุงุฐุฌ Transformers ูุชุฑุบุจ ูู ูุดุงุฑูุชูุงุ ูููุฑ ูู ุงููุณุงููุฉ ูู ูุฐู ุงููุซููุฉ.\n+\n+- **ุฅูุดุงุก ุทูุจ ุณุญุจ (Pull Request):** ุดุงุฑู ุชุบููุฑุงุชู ูุชุญุณููุงุชู ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูุจุงุดุฑุฉ ูู ุงููุณุชูุฏุน.\n+- **ูุชุงุจุฉ ุงูุชูุซูู:** ูุฏู ุชูุณูุฑุงุช ูุฃูุซูุฉ ูุงุถุญุฉ ูุชุนุฏููุงุชู.\n+- **ุงูุชูุงุนู ูุน ุงููุฌุชูุน:** ูุงูุด ุฃููุงุฑู ูุงุญุตู ุนูู ุชุนูููุงุช ูู ุงููุทูุฑูู ูุงูุจุงุญุซูู ุงูุขุฎุฑูู ูู ุฎูุงู ูุชุญ ูุดููุฉ."
        },
        {
            "sha": "b500fec1c92d25efc0de93890c69cd9cafeefd67",
            "filename": "docs/source/ar/modular_transformers.md",
            "status": "added",
            "additions": 184,
            "deletions": 0,
            "changes": 184,
            "blob_url": "https://github.com/huggingface/transformers/blob/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fmodular_transformers.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Fmodular_transformers.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fmodular_transformers.md?ref=425af6cdc20d20e93fb814e6932c1b194b3f2915",
            "patch": "@@ -0,0 +1,184 @@\n+# ุงููุญููุงุช ุงูููุทูุฉ\n+\n+ููุชุจุฉ `transformers` ูู ุฅุทุงุฑ ุนูู ุฐู ููุณูุฉ ูุญุฏุฏุ ูุชู ุชุนุฑูู ููุณูุชูุง ูู [ุงูุฏููู ุงูููุงูููู](./philosophy).\n+\n+ุฌููุฑ ูุฐู ุงูููุณูุฉ ูุชูุซู ูู ูุจุฏุฃ [ูููุฐุฌ ูุงุญุฏุ ููู ูุงุญุฏ](https://huggingface.co/blog/transformers-design-philosophy)\n+ูู ุงูููุชุจุฉ. ุงูุฌุงูุจ ุงูุณูุจู ููุฐุง ุงููููู ูู ุชูููุฏู ููุฑุงุซุฉ ูุงุณุชูุฑุงุฏ ููููุงุช ุงููููุงุช.\n+\n+ูุชูุฌุฉ ูุฐููุ ุชุชูุฑุฑ ููููุงุช ุงููููุฐุฌ ุนุจุฑ ุงูุนุฏูุฏ ูู ุงููููุงุช. ูุญุชูู `transformers` ุนูู ุนุฏุฏ ูุจูุฑ ูู ุทุจูุงุช ุงูุงูุชุจุงูุ ููุงุฑุจ ุนุฏุฏ ุงูููุงุฐุฌุ ูุงููุซูุฑ ูููุง ูุชุทุงุจู.  ูุชุณุจุจ ูุฐุง ูู ุชุจุงุนุฏ ุนูููุงุช ุงูุชูููุฐ ุงููุณุชููุฉ ูุน ุชุทุจูู ุงูุฅุตูุงุญุงุช ูุงูุชุบููุฑุงุช.\n+ุนูู ุฃุฌุฒุงุก ูุญุฏุฏุฉ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ.\n+\n+ูููุนุงูุฌุฉ ุฐููุ ุงุนุชูุฏูุง ููููู \"ุงููุณุฎ\" ูู ุงูููุชุจุฉ.  ูุจุฅุถุงูุฉ ุชุนููู ููุดูุฑ ุฅูู ุฃู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉ ูู ูุณุฎุฉ ูู ุฃุฎุฑูุ ูุถูู ูู ุฎูุงู ุฃูุธูุฉ  CI ูุงูุฃูุงูุฑ ุงููุญููุฉ ุนุฏู ุชุจุงุนุฏ ุงููุณุฎ.  ููู ูุฐู ุงูุนูููุฉุ ุฑุบู ุจุณุงุทุชูุงุ ุชูุณุจุจ ุฅุฑูุงูุงู.  ููุง ุฃููุง ุชุฒูุฏ ุงูุนุจุก ุนูู ุงููุณุงููููุ ููู ูุง ููุฏู ุฅูู ุชุฌุงูุฒู.\n+\n+ุบุงูุจุงู ูุง ุชุชุทูุจ ูุณุงููุงุช ุงูููุงุฐุฌ ุฅุถุงูุฉ ุชุนูููุงุช ุจุฑูุฌูุฉ (ุญูุงูู 1000 ุณุทุฑ)ุ ููุนุงูุฌ (ุญูุงูู 500 ุณุทุฑ)ุ ูุงุฎุชุจุงุฑุงุชุ ููุซุงุฆูุ ุฅูุฎ. ููุงุฏุฑุงู ูุง ุชูู ูุณุงููุงุช ุงูููุงุฐุฌ ุนู 3000-5000 ุณุทุฑ ูู ุงูุชุนูููุงุช ุงูุจุฑูุฌูุฉุ  ูุนุธููุง ุฃููุงุฏ ููุทูุฉ.  ูุฐุง ูุฑูุน ูุณุชูู  ุงููุณุงููุงุชุ\n+\n+ูููุฏู ูุน ุงููุญููุงุช ุงูููุทูุฉ ุฅูู ุฎูุถ ูุฐุง ุงููุณุชูู ุฅูู ุญุฏู ููุจูู.\n+\n+## ูุง ููุ\n+\n+ุชูุฏู ุงููุญููุงุช ุงูููุทูุฉ ููููู ููู \"ููุทู\" ููุฌูุฏ ูููุฐุฌ. ููุจู ูุฐุง ุงูููู ุงูููุทู ุชุนูููุงุช ุจุฑูุฌูุฉ\n+ุบูุฑ ููุจููุฉ ุนุงุฏุฉ ูู ูููุงุช ุงูููุฐุฌุฉ/ุงููุนุงูุฌุฉุ ุญูุซ ูุณูุญ ุจุงูุงุณุชูุฑุงุฏ ูู ููุงุฐุฌ ูุฌุงูุฑุฉ ููุฐูู\n+ุงููุฑุงุซุฉ ูู ุงููุฆุงุช ุฅูู ูุฆุงุช ุฃุฎุฑู.\n+\n+ูุนุฑูู ูุฐุง ุงูููู ุงูููุทู ุงูููุงุฐุฌ ูุงููุนุงูุฌุงุช ููุฆุฉ ุงูุชูููู ุงูุชู ุณูุชู ุชุนุฑูููุง ูู ูุญุฏุงุชูู\n+ุงููุชุนููุฉ.\n+\n+ูุฃุฎูุฑูุงุ ููุฏู ูุฐุง ุงูููุฒุฉ ุฃุฏุงุฉ `linter` ุฌุฏูุฏุฉ ูุงูุชู ุณุชุนูู ุนูู \"ุชูููู\" ุงูููู ุงูููุทู ุฅูู ุจููุฉ \"ูููุฐุฌ ูุงุญุฏุ ููู ูุงุญุฏ\"\n+ูููู ุงูุฏููู. ุณูุชู ุฅูุดุงุก ูุฐู ุงููููุงุช ุชููุงุฆููุง ูู ูู ูุฑุฉ ูุชู ูููุง ุชุดุบูู ุงูุจุฑูุงูุฌ ุงููุตูุ ููุง ูููู ูู ุงููุณุงููุงุช ุงููุทููุจุฉ\n+ุฅูู ุงูููู ุงูููุทูุ ูุจุงูุชุงูู ููุท ุฅูู ุงูุชุบููุฑุงุช ุจูู ุงููููุฐุฌ ุงููุณุงูู ูุงูููุงุฐุฌ ุงูุฃุฎุฑู.\n+\n+ุณูููู ูุณุชุฎุฏูู ุงููููุฐุฌ ูู ุงูููุงูุฉ ุจุงุณุชูุฑุงุฏ ูุงุณุชุฎุฏุงู ูุงุฌูุฉ ุงูููู ุงููุงุญุฏุ ูุฐุง ูุง ูุชููุน ุญุฏูุซ ุฃู ุชุบููุฑ ููุง. ูู ุฎูุงู ุงูููุงู ุจุฐููุ\n+ูุฃูู ูู ุงูุฌูุน ุจูู ุฃูุถู ูุง ูู ุงูุนุงูููู: ุชูููู ุงููุณุงููุงุช ุงูุจุณูุทุฉ ูุน ุงูุงูุชุฒุงู ุจููุณูุชูุง.\n+\n+ูุฐููุ ูุฐุง ุจุฏูู ูุนูุงูุงุช `# Copied from`ุ ููููู ุชููุน ุงูุชูุงู ุงูููุงุฐุฌ ุงููุณุงููุฉ ุณุงุจููุง ุฅูู\n+ุชูุณูู ุงููุญููุงุช ุงูููุทูุฉ ุงูุฌุฏูุฏ ูู ุงูุฃุดูุฑ ุงูููุจูุฉ.\n+\n+### ุงูุชูุงุตูู\n+\n+ุชูุจุณุท ุฃุฏุงุฉ \"linter\" ุงููุฑุงุซุฉุ ูููุดุฆุฉู ุฌููุน ุงููููุงุช ุงูููุฑุฏุฉ ูู ุงูููู ุงูููุทูุ ูุน ุงูุญูุงุธ ุนูู ุดูุงููุชูุง ุฃูุงู ูุณุชุฎุฏูู Python. ุญุงูููุงุ ุชูุจุณุท ุงูุฃุฏุงุฉ ูุณุชููู ูุงุญุฏูุง ูู ุงููุฑุงุซุฉ\n+\n+ุนูู ุณุจูู ุงููุซุงู:\n+- ุฅุฐุง ูุฑุซุช ูุฆุฉ ุงูุชูููู ูู ูุฆุฉ ุฃุฎุฑู ูุฃุถุงูุช/ุญุฐูุช ูุนุงููุ ูุณูุชู ุฅูุง ุงูุฅุดุงุฑุฉ ุฅูู ุงูููู ุงููููุฏ ูุจุงุดุฑุฉู\n+  (ูู ุญุงูุฉ ุงูุฅุถุงูุฉ) ุฃู ุฅุฒุงูุชู ุชูุงููุง (ูู ุญุงูุฉ ุงูุญุฐู).\n+- ุฅุฐุง ูุฑุซุช ูุฆุฉ ูู ูุฆุฉ ุฃุฎุฑูุ ุนูู ุณุจูู ุงููุซุงู: `class GemmaModel(LlamaModel):`ุ ุชูุณุชูุชุฌ ุงูุชุจุนูุงุช ุชููุงุฆููุง\n+  ุณูุชู ุงุณุชูุชุงุฌ ุฌููุน ุงููุญุฏุงุช ุงููุฑุนูุฉ ุชููุงุฆููุง ูู ุงููุฆุฉ ุงูุฃุตููุฉ.\n+- ุฅุฐุง ููุช ุจุชุนุฑูู ูุธุงุฆู ุฌุฏูุฏุฉ ูู ุงูููู `modular` ูุงุณุชุฎุฏูุชูุง ุฏุงุฎู ุงููุฆุงุชุ ูุณุชุณุชูุชุฌ ุฃุฏุงุฉ linter ุฐูู ุชููุงุฆููุง\n+\n+ูุฌุจ ุฃู ุชููู ูุงุฏุฑูุง ุนูู ูุชุงุจุฉ ูู ุดูุก (ุงููุฌุฒูุก ุงููุบููุ ูููุนุงููุฌ ุงูุตูุฑุ ูุงููููุฐุฌุ ูุงูุชูููู) ูู ุงูููู `modular`ุ ูุณูุชู ุฅูุดุงุก ุงููููุงุช ุงููููุงุจูุฉ ุชููุงุฆููุง.\n+\n+### ุงูุชุทุจูู\n+\n+[TODO] ููุฏู ุงุฎุชุจุงุฑูุง ุฌุฏูุฏูุงุ ููุชุฃูุฏ ูู ุฃู ุงููุญุชูู ุงููููุฏ ูุชุทุงุจู ูุน ูุง ูู ููุฌูุฏ ูู `modular_xxxx.py`\n+\n+### ุงูุฃูุซูุฉ\n+\n+ููุง ูุซุงู ุณุฑูุน ุจุงุณุชุฎุฏุงู BERT ู RoBERTa. ุงููููุฐุฌุงู ูุฑุชุจุทุงู ุงุฑุชุจุงุทูุง ูุซูููุง: ูุฎุชูู ุชูููุฐููุง ุงููููุฐุฌู ูู ุทุจูุฉ ุชุถููู.\n+\n+ุจุฏูุงู ูู ุฅุนุงุฏุฉ ุชุนุฑูู ุงููููุฐุฌ ุจุงููุงููุ ุฅููู ููู ูุจุฏู ููู `modular_roberta.py` ููุฆุงุช ุงูููุฐุฌุฉ ูุงูุชูููู (ูุฃุบุฑุงุถ ุงููุซุงูุ ูุชู ุชุฌุงูู ุงููุฌุฒูุก ุงููุบูู ูู ูุฐุง ุงูููุช ุญูุซ ุฃูู ูุฎุชูู ุฌุฏูุง).\n+\n+```python\n+from torch import nn\n+from ..bert.configuration_bert import BertConfig\n+from ..bert.modeling_bert import (\n+    BertModel,\n+    BertEmbeddings,\n+    BertForMaskedLM\n+)\n+\n+# ุชูููู RoBERTa ูุทุงุจู ูุชูููู BERT\n+class RobertaConfig(BertConfig):\n+  model_type = 'roberta'\n+\n+# ูุนูุฏ ุชุนุฑูู ุงูุฅุถุงูุงุช ููุง ูุชุณููุท ุงูุถูุก ุนูู ุงุฎุชูุงู ูุนุฑู ุงูุญุดูุ ููุนูุฏ ุชุนุฑูู ุงูุฅุถุงูุงุช ุงูููุถุนูุฉ\n+class RobertaEmbeddings(BertEmbeddings):\n+    def __init__(self, config):\n+        super().__init__(config())\n+\n+        self.padding_idx = config.pad_token_id\n+        self.position_embeddings = nn.Embedding(\n+            config.max_position_embeddings, config.hidden_size, padding_idx=self.padding_idx\n+        )\n+\n+# ูููุฐุฌ RoBERTa ูุทุงุจู ููููุฐุฌ BERTุ ุจุงุณุชุซูุงุก ุทุจูุฉ ุงูุฅุถุงูุงุช.\n+# ูุนูุฏ ุชุนุฑูู ุงูุฅุถุงูุงุช ุฃุนูุงูุ ูุฐุง ููุง ูุง ุชูุฌุฏ ุญุงุฌุฉ ูุนูู ุฅุถุงูู\n+class RobertaModel(BertModel):\n+  def __init__(self, config):\n+    super().__init__(config)\n+    self.embeddings = RobertaEmbeddings(config)\n+\n+      \n+# ุงูุฑุคูุณ ุงูุขู ุชุญุชุงุฌ ููุท ุฅูู ุฅุนุงุฏุฉ ุชุนุฑูู ุงููููุฐุฌ ุฏุงุฎู `RobertaModel` ุงูุตุญูุญ\n+class RobertaForMaskedLM(BertForMaskedLM):\n+  def __init__(self, config):\n+    super().__init__(config)\n+    self.model = RobertaModel(config)\n+```\n+\n+ูุงุญุธ ุฃูู ุฅุฐุง ูู ุชุณุชุฎุฏู ุงูุงุนุชูุงุฏ ุงูุฐู ุญุฏุฏุชูุ ูุณุชุญุตู ุนูู ุงูุฎุทุฃ ุงูุชุงูู:\n+\n+```bash\n+ValueError: You defined `RobertaEmbeddings` in the modular_roberta.py, it should be used\n+                                    when you define `BertModel`, as it is one of it's direct dependencies. Make sure\n+                                    you use it in the `__init__` function.\n+```\n+\n+ุจุงูุฅุถุงูุฉ ุฅูู ุฐููุ ูุฏ ุชุฌุฏ ูุงุฆูุฉ ุจุงูุฃูุซูุฉ ููุง:\n+\n+## ูุง ูู ููุณ ูุฐูู\n+\n+ููุณ ุจุฏููุงู ูุชุนูููุงุช ุจุฑูุฌุฉ ุงูููุฐุฌุฉ (ุจุนุฏุ)ุ ูุฅุฐุง ูู ููู ูููุฐุฌู ูุนุชูุฏ ุนูู ุฃู ุดูุก ุขุฎุฑ ููุฌูุฏ ูู ูุจูุ ูููููู ุฅุถุงูุฉ ููู `ููุฐุฌุฉ` ูุงูุนุงุฏุฉ.\n+\n+\n+## ุงูุงุณุชุฎุฏุงู ุงููุชูุฏู\n+\n+### ุฅุฒุงูุฉ ุงูุณูุงุช ูุงููุธุงุฆู\n+ูุฅุฒุงูุฉ ุงูุณูุงุช ุงูุชู ูุง ุชุณุชุฎุฏู ูู ูููุฐุฌู ุงูููุทูุ ูุงูุชู ูุง ุชุฑูุฏ ุฑุคูุชูุง ูู ุงูููุฐุฌุฉ ุงูููููุฉ:\n+\n+```python\n+class GemmaModel(LlamaModel):                 |           class GemmaModel(PreTrainedModel):\n+    def __init__(self, config):               |              def __init__(self, config):\n+        super().__init__(self, eos_token)     |                 super().__init__(config)\n+        del self.embed_tokens                 |                 self.padding_idx = config.pad_token_id\n+                                              |                 self.vocab_size = config.vocab_size\n+                                              |\n+                                              |                 self.layers = nn.ModuleList(\n+                                              |                     [LlamaDecoderLayer(config, layer_idx) for layer_idx in range(config.num_hidden_layers)]\n+                                              |                 )\n+                                              |                 self.norm = LlamaRMSNorm(config.hidden_size, eps=config.rms_norm_eps)\n+                                              |                 self.rotary_emb = LlamaRotaryEmbedding(config=config)\n+                                              |                 self.gradient_checkpointing = False\n+                                              |                 \n+                                              |                 # Initialize weights and apply final processing\n+                                              |                 self.post_init()\n+```\n+ุฅุฐุง ููุช ุจุงูุชุญูู ูู `LlamaModel` ุงูุฃุตููุ ูุณุชุฌุฏ `embed_tokens` ุงูุฐู ุชูุช ุฅุฒุงูุชู ููุง (ููุง ูู ูุชููุน!)\n+\n+ุฅุฒุงูุฉ ูุธููุฉ ูุดุงุจูุฉุ ุชุญุชุงุฌ ููุท ุฅูู ูุชุงุจุชูุง ูุน `raise ValueError(\"\")` ููุญุงูุงุฉ ุงูุณููู ุงูุฐู ุชุฑูุฏู ูุนูููุง ุนูุฏ ุฅุฒุงูุฉ ูุธููุฉ ุฃุตููุฉ ูู ุจุงูุซูู.\n+\n+```python\n+class GemmaTokenizer(LlamaTokenizer):\n+    ...\n+\n+    def get_spm_processor(self):\n+        raise AttributeError(\"Not needed for Gemma\")\n+\n+    def unk_token_length(self):\n+        raise AttributeError(\"Not needed for Gemma\")\n+```\n+\n+### ุชุนุฑูู ูุธุงุฆู ุฌุฏูุฏุฉ\n+\n+ุฅุฐุง ููุช ุจุชุนุฑูู ูุธููุฉ ุฌุฏูุฏุฉ ูู ุงูููู `modular` ูุงุณุชุฎุฏุงููุง ุฏุงุฎู ูุฆุฉุ ุนูู ุณุจูู ุงููุซุงู\n+\n+```python\n+def my_new_function(*args, **kwargs):\n+  # Do something here\n+  pass\n+\n+class GemmaModel(LlamaModel):\n+    def forward(*args, **kwargs):\n+      # Call the function\n+      example = my_new_function(*args, **kwargs)\n+      # continue here\n+```\n+\n+ุณูุชู ูุณุฎ ูุธููุฉ `my_new_function` (ูุจุดูู ูุชูุฑุฑุ ุฃู ูุธุงุฆู ุฃุฎุฑู ุฌุฏูุฏุฉ ูุชู ุงุณุชุฏุนุงุคูุง ูู ุฌุณููุง) ุชููุงุฆููุง\n+ูู ุงูููู ุงูุฐู ูุชู ุงุณุชุฎุฏุงูู.\n+\n+### ุงุณุชุฏุนุงุก `super()`\n+ูููุง ูุคุฎุฑูุง ุจุดุญู ุจุนุถ ุงูููุฒุงุช ุงูุชู ุชุณูุญ ูู ุจุงูุงูุชูุงู ูู:\n+```python\n+class GemmaTokenizer(LlamaTokenizer, PretrainedTokenizerFast):         |           class GemmaModel(nn.Module):\n+    def __init__(self, eos_token=\"</s>\"):                              |             def __init__(self):\n+        eos_token = AddedToken(eos_token)                              |                eos_token = AddedToken(eos_token)\n+        PretrainedTokenizerFast.__init__(self, eos_token)              |                super().__init__(eos_token)\n+```\n+ูุฐุง ูููุฏ ุนูุฏูุง ูุง ุชุฑูุฏ ุชูููู ุงุณุชุฏุนุงุก `super()`ุ ูุชุฑูุฏ ุงูุชูููุฒ ุจูู ุฃู ุงุณุชุฏุนุงุก super init ุชููู ุจู!\n+\n+### ุงูุชุณููุฉ ุงูุฎุงุตุฉ\n+ูุฏุนู ุงูุขู ุฃูุถูุง ุญุงูุงุช ุฎุงุตุฉ ูุซู\n+```python\n+class GemmaVisionModel(CLIPModel):                                 \n+    pass\n+```\n+ุญูุซ ุงุณู ูุฆุฉ `GemmaVision` ุงูุฎุงุตุฉ ุจู ููุณ ูู ููุณู `Gemma` ุงูููุทู. ูุฐุง ูููุฏ ููุบุงูุฉ ููููุงุฐุฌ ุงููุฑูุจุฉ."
        },
        {
            "sha": "6f3755d8670cdc75885662477f018ab8bfd4b0a4",
            "filename": "docs/source/ar/tiktoken.md",
            "status": "added",
            "additions": 41,
            "deletions": 0,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Ftiktoken.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/425af6cdc20d20e93fb814e6932c1b194b3f2915/docs%2Fsource%2Far%2Ftiktoken.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftiktoken.md?ref=425af6cdc20d20e93fb814e6932c1b194b3f2915",
            "patch": "@@ -0,0 +1,41 @@\n+# Tiktoken ูุงูุชูุงุนู ูุน Transformers\n+\n+ูุชู ุฏูุฌ ุฏุนู ูููุงุช ูููุฐุฌ tiktoken ุจุณูุงุณุฉ ูู ๐ค transformers ุนูุฏ ุชุญููู ุงูููุงุฐุฌ\n+`from_pretrained` ูุน ููู `tokenizer.model` tiktoken ุนูู Hubุ ูุงูุฐู ูุชู ุชุญูููู ุชููุงุฆููุง ุฅูู [ุงููุญูู ุงููุบูู ุงูุณุฑูุน](https://huggingface.co/docs/transformers/main/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast).\n+\n+### ุงูููุงุฐุฌ ุงููุนุฑููุฉ ุงูุชู ุชู ุฅุตุฏุงุฑูุง ูุน `tiktoken.model`:\n+\t- gpt2\n+\t- llama3\n+\n+## ูุซุงู ุนูู ุงูุงุณุชุฎุฏุงู\n+\n+ูู ุฃุฌู ุชุญููู ูููุงุช `tiktoken` ูู `transformers`ุ ุชุฃูุฏ ูู ุฃู ููู `tokenizer.model` ูู ููู tiktoken ูุณูุชู ุชุญูููู ุชููุงุฆููุง ุนูุฏ ุงูุชุญููู `from_pretrained`. ุฅููู ููููุฉ ุชุญููู ูุฌุฒูุก ูุบูู ููููุฐุฌุ ูุงูุฐู\n+ูููู ุชุญูููู ูู ููุณ ุงูููู ุจุงูุถุจุท:\n+\n+```py\n+from transformers import AutoTokenizer\n+\n+model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n+tokenizer = AutoTokenizer.from_pretrained(model_id, subfolder=\"original\")\n+```\n+## ุฅูุดุงุก ูุฌุฒูุก ูุบูู tiktoken\n+\n+ูุง ูุญุชูู ููู `tokenizer.model` ุนูู ุฃู ูุนูููุงุช ุญูู ุงูุฑููุฒ ุฃู ุงูุฃููุงุท ุงูุฅุถุงููุฉ. ุฅุฐุง ูุงูุช ูุฐู ุงูุฃููุฑ ูููุฉุ ูู ุจุชุญููู ุงููุญูู ุงููุบูู ุฅูู `tokenizer.json`ุ ููู ุงูุชูุณูู ุงูููุงุณุจ ูู [`PreTrainedTokenizerFast`].\n+\n+ูู ุจุชูููุฏ ููู `tokenizer.model` ุจุงุณุชุฎุฏุงู [tiktoken.get_encoding](https://github.com/openai/tiktoken/blob/63527649963def8c759b0f91f2eb69a40934e468/tiktoken/registry.py#L63) ุซู ูู ุจุชุญูููู ุฅูู `tokenizer.json` ุจุงุณุชุฎุฏุงู [`convert_tiktoken_to_fast`].\n+\n+```py\n+\n+from transformers.integrations.tiktoken import convert_tiktoken_to_fast\n+from tiktoken import get_encoding\n+\n+# ููููู ุชุญููู ุชุฑููุฒู ุงููุฎุตุต ุฃู ุงูุชุฑููุฒ ุงูุฐู ุชููุฑู OpenAI\n+encoding = get_encoding(\"gpt2\")\n+convert_tiktoken_to_fast(encoding, \"config/save/dir\")\n+```\n+\n+ูุชู ุญูุธ ููู `tokenizer.json` ุงููุงุชุฌ ูู ุงูุฏููู ุงููุญุฏุฏ ููููู ุชุญูููู ุจุงุณุชุฎุฏุงู [`PreTrainedTokenizerFast`].\n+\n+```py\n+tokenizer = PreTrainedTokenizerFast.from_pretrained(\"config/save/dir\")\n+```"
        }
    ],
    "stats": {
        "total": 464,
        "additions": 462,
        "deletions": 2
    }
}