{
    "author": "ahnjj",
    "message": "ğŸŒ [i18n-KO] Translated `gpt_neox_japanese.md` to Korean (#33894)\n\n* docs: ko: gpt_neox_japanese.md\r\n\r\n* Update _toctree.yml\r\n\r\n* fix: manual edits\r\n\r\n* Update docs/source/ko/model_doc/gpt_neox_japanese.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n* Update docs/source/ko/model_doc/gpt_neox_japanese.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n* Update docs/source/ko/model_doc/gpt_neox_japanese.md\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Sungmin Oh <fabxoe.kor@gmail.com>",
    "sha": "1ed98773e563ebe7322d1f5b501c6fe0bde1427c",
    "files": [
        {
            "sha": "2565b7b8dcdef6f3e494a648475f24f4cfc106db",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1ed98773e563ebe7322d1f5b501c6fe0bde1427c/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/1ed98773e563ebe7322d1f5b501c6fe0bde1427c/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=1ed98773e563ebe7322d1f5b501c6fe0bde1427c",
            "patch": "@@ -400,8 +400,8 @@\n         title: (ë²ˆì—­ì¤‘) GPT Neo\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) GPT NeoX\n-      - local: in_translation\n-        title: (ë²ˆì—­ì¤‘) GPT NeoX Japanese\n+      - local: model_doc/gpt_neox_japanese\n+        title: GPT NeoX Japanese\n       - local: in_translation\n         title: (ë²ˆì—­ì¤‘) GPT-J\n       - local: in_translation"
        },
        {
            "sha": "13fb656dd50e9463740e1ea273bfcb9073ecd1e1",
            "filename": "docs/source/ko/model_doc/gpt_neox_japanese.md",
            "status": "added",
            "additions": 76,
            "deletions": 0,
            "changes": 76,
            "blob_url": "https://github.com/huggingface/transformers/blob/1ed98773e563ebe7322d1f5b501c6fe0bde1427c/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt_neox_japanese.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/1ed98773e563ebe7322d1f5b501c6fe0bde1427c/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt_neox_japanese.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt_neox_japanese.md?ref=1ed98773e563ebe7322d1f5b501c6fe0bde1427c",
            "patch": "@@ -0,0 +1,76 @@\n+<!--Copyright 2022 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+specific language governing permissions and limitations under the License.\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# GPT-NeoX-Japanese [[gpt-neox-japanese]]\n+\n+## ê°œìš” [[overview]]\n+\n+\n+ì¼ë³¸ì–´ë¥¼ ìœ„í•œ ìë™íšŒê·€ ì–¸ì–´ ëª¨ë¸ì¸ GPT-NeoX-Japaneseë¥¼ ì†Œê°œí•©ë‹ˆë‹¤. ì´ ëª¨ë¸ì€ [https://github.com/EleutherAI/gpt-neox](https://github.com/EleutherAI/gpt-neox)ì—ì„œ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤. ì¼ë³¸ì–´ëŠ” ë§ì€ ì–´íœ˜ì™€ íˆë¼ê°€ë‚˜, ê°€íƒ€ì¹´ë‚˜, í•œìì˜ ì¡°í•©ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ë…íŠ¹í•œ ì–¸ì–´ì…ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¼ë³¸ì–´ì˜ ë…íŠ¹í•œ êµ¬ì¡°ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ [íŠ¹ìˆ˜ ì„œë¸Œì›Œë“œ í† í¬ë‚˜ì´ì €](https://github.com/tanreinama/Japanese-BPEEncoder_V2)ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤. ì´ ìœ ìš©í•œ í† í¬ë‚˜ì´ì €ë¥¼ ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì œê³µí•´ ì¤€ *tanreinama*ì—ê²Œ ë§¤ìš° ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.\n+\n+ì´ ëª¨ë¸ì€ Googleì˜ [PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html) ì—°êµ¬ ê¶Œì¥ ì‚¬í•­ì„ ë”°ë¥´ë©°, íŠ¸ëœìŠ¤í¬ë¨¸ ë¸”ë¡ì—ì„œ í¸í–¥ íŒŒë¼ë¯¸í„°ë¥¼ ì œê±°í•˜ì—¬ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œì¼°ìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [ì´ ê¸°ì‚¬](https://medium.com/ml-abeja/training-a-better-gpt-2-93b157662ae4)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n+\n+ëª¨ë¸ ê°œë°œì€ [ABEJA, Inc.](https://www.abejainc.com/)ì˜ [ì‹ ì•¼ ì˜¤íƒ€ë‹ˆ](https://github.com/SO0529), [íƒ€ì¹´ìš”ì‹œ ë§ˆì¹´ë² ](https://github.com/spider-man-tm), [ì•ˆì£¼ ì•„ë¡œë¼](https://github.com/Anuj040), [ì¿„ í•˜í† ë¦¬](https://github.com/go5paopao)ì— ì˜í•´ ì£¼ë„ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ ê°œë°œ í™œë™ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://tech-blog.abeja.asia/entry/abeja-gpt-project-202207)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.\n+\n+\n+\n+### ì‚¬ìš© ì˜ˆì‹œ [[usage-example]]\n+\n+`generate()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ë©´ GPT NeoX Japanese ëª¨ë¸ì„ í†µí•´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+```python\n+>>> from transformers import GPTNeoXJapaneseForCausalLM, GPTNeoXJapaneseTokenizer\n+\n+>>> model = GPTNeoXJapaneseForCausalLM.from_pretrained(\"abeja/gpt-neox-japanese-2.7b\")\n+>>> tokenizer = GPTNeoXJapaneseTokenizer.from_pretrained(\"abeja/gpt-neox-japanese-2.7b\")\n+\n+>>> prompt = \"äººã¨AIãŒå”èª¿ã™ã‚‹ãŸã‚ã«ã¯ã€\"\n+\n+>>> input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n+\n+>>> gen_tokens = model.generate(\n+...     input_ids,\n+...     do_sample=True,\n+...     temperature=0.9,\n+...     max_length=100,\n+... )\n+>>> gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)[0]\n+\n+>>> print(gen_text)\n+äººã¨AIãŒå”èª¿ã™ã‚‹ãŸã‚ã«ã¯ã€AIã¨äººãŒå…±å­˜ã—ã€AIã‚’æ­£ã—ãç†è§£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n+```\n+\n+## ìë£Œ [[resources]]\n+\n+- [ì¼ìƒ ì–¸ì–´ ëª¨ë¸ë§ ì‘ì—… ê°€ì´ë“œ ](../tasks/language_modeling)\n+\n+## GPTNeoXJapanese ì„¤ì • (GPTNeoXJapaneseConfig) [[transformers.GPTNeoXJapaneseConfig]]\n+\n+[[autodoc]] GPTNeoXJapaneseConfig\n+\n+## GPTNeoXJapaneseí† í°í™” (GPTNeoXJapaneseTokenizer) [[transformers.GPTNeoXJapaneseTokenizer]]\n+\n+[[autodoc]] GPTNeoXJapaneseTokenizer\n+\n+## GPTNeoXJapaneseModel [[transformers.GPTNeoXJapaneseModel]]\n+\n+[[autodoc]] GPTNeoXJapaneseModel\n+    - forward\n+\n+## ì¼ìƒ LLM ì„ ìœ„í•œ GPTNeoXJapanese(GPTNeoXJapaneseForCausalLM) [[transformers.GPTNeoXJapaneseForCausalLM]]\n+\n+[[autodoc]] GPTNeoXJapaneseForCausalLM\n+    - forward"
        }
    ],
    "stats": {
        "total": 80,
        "additions": 78,
        "deletions": 2
    }
}