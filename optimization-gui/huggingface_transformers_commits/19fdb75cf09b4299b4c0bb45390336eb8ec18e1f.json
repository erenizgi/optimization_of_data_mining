{
    "author": "zucchini-nlp",
    "message": "[video utils] group and reorder by number of frames (#38374)\n\nfix",
    "sha": "19fdb75cf09b4299b4c0bb45390336eb8ec18e1f",
    "files": [
        {
            "sha": "af9d80bab76b2b5e2bbe96aeaa9bd403f4a02ed1",
            "filename": "src/transformers/video_utils.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/19fdb75cf09b4299b4c0bb45390336eb8ec18e1f/src%2Ftransformers%2Fvideo_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19fdb75cf09b4299b4c0bb45390336eb8ec18e1f/src%2Ftransformers%2Fvideo_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_utils.py?ref=19fdb75cf09b4299b4c0bb45390336eb8ec18e1f",
            "patch": "@@ -696,11 +696,13 @@ def group_videos_by_shape(\n     grouped_videos_index = {}\n     for i, video in enumerate(videos):\n         shape = video.shape[-2::]\n+        num_frames = video.shape[-4]  # video format BTCHW\n+        shape = (num_frames, *shape)\n         if shape not in grouped_videos:\n             grouped_videos[shape] = []\n         grouped_videos[shape].append(video)\n         grouped_videos_index[i] = (shape, len(grouped_videos[shape]) - 1)\n-    # stack videos with the same shape\n+    # stack videos with the same size and number of frames\n     grouped_videos = {shape: torch.stack(videos, dim=0) for shape, videos in grouped_videos.items()}\n     return grouped_videos, grouped_videos_index\n "
        },
        {
            "sha": "21a5b44ff8e13ed7847a5ca3740a7de6a75bc2b0",
            "filename": "tests/utils/test_video_utils.py",
            "status": "modified",
            "additions": 50,
            "deletions": 3,
            "changes": 53,
            "blob_url": "https://github.com/huggingface/transformers/blob/19fdb75cf09b4299b4c0bb45390336eb8ec18e1f/tests%2Futils%2Ftest_video_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/19fdb75cf09b4299b4c0bb45390336eb8ec18e1f/tests%2Futils%2Ftest_video_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_video_utils.py?ref=19fdb75cf09b4299b4c0bb45390336eb8ec18e1f",
            "patch": "@@ -30,7 +30,7 @@\n     require_torchvision,\n     require_vision,\n )\n-from transformers.video_utils import make_batched_videos\n+from transformers.video_utils import group_videos_by_shape, make_batched_videos, reorder_videos\n \n \n if is_torch_available():\n@@ -43,9 +43,9 @@\n     from transformers.video_utils import VideoMetadata, load_video\n \n \n-def get_random_video(height, width, return_torch=False):\n+def get_random_video(height, width, num_frames=8, return_torch=False):\n     random_frame = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)\n-    video = np.array(([random_frame] * 8))\n+    video = np.array(([random_frame] * num_frames))\n     if return_torch:\n         # move channel first\n         return torch.from_numpy(video).permute(0, 3, 1, 2)\n@@ -189,6 +189,53 @@ def test_convert_to_rgb(self):\n         rgb_video = video_processor.convert_to_rgb(torch.cat([video, video[:, :1]], dim=1))\n         self.assertEqual(rgb_video.shape, (8, 3, 20, 20))\n \n+    def test_group_and_reorder_videos(self):\n+        \"\"\"Tests that videos can be grouped by frame size and number of frames\"\"\"\n+        video_1 = get_random_video(20, 20, num_frames=3, return_torch=True)\n+        video_2 = get_random_video(20, 20, num_frames=5, return_torch=True)\n+\n+        # Group two videos of same size but different number of frames\n+        grouped_videos, grouped_videos_index = group_videos_by_shape([video_1, video_2])\n+        self.assertEqual(len(grouped_videos), 2)\n+\n+        regrouped_videos = reorder_videos(grouped_videos, grouped_videos_index)\n+        self.assertTrue(len(regrouped_videos), 2)\n+        self.assertEqual(video_1.shape, regrouped_videos[0].shape)\n+\n+        # Group two videos of different size but same number of frames\n+        video_3 = get_random_video(15, 20, num_frames=3, return_torch=True)\n+        grouped_videos, grouped_videos_index = group_videos_by_shape([video_1, video_3])\n+        self.assertEqual(len(grouped_videos), 2)\n+\n+        regrouped_videos = reorder_videos(grouped_videos, grouped_videos_index)\n+        self.assertTrue(len(regrouped_videos), 2)\n+        self.assertEqual(video_1.shape, regrouped_videos[0].shape)\n+\n+        # Group all three videos where some have same size or same frame count\n+        # But since none have frames and sizes identical, we'll have 3 groups\n+        grouped_videos, grouped_videos_index = group_videos_by_shape([video_1, video_2, video_3])\n+        self.assertEqual(len(grouped_videos), 3)\n+\n+        regrouped_videos = reorder_videos(grouped_videos, grouped_videos_index)\n+        self.assertTrue(len(regrouped_videos), 3)\n+        self.assertEqual(video_1.shape, regrouped_videos[0].shape)\n+\n+        # Group if we had some videos with identical shapes\n+        grouped_videos, grouped_videos_index = group_videos_by_shape([video_1, video_1, video_3])\n+        self.assertEqual(len(grouped_videos), 2)\n+\n+        regrouped_videos = reorder_videos(grouped_videos, grouped_videos_index)\n+        self.assertTrue(len(regrouped_videos), 2)\n+        self.assertEqual(video_1.shape, regrouped_videos[0].shape)\n+\n+        # Group if we had all videos with identical shapes\n+        grouped_videos, grouped_videos_index = group_videos_by_shape([video_1, video_1, video_1])\n+        self.assertEqual(len(grouped_videos), 1)\n+\n+        regrouped_videos = reorder_videos(grouped_videos, grouped_videos_index)\n+        self.assertTrue(len(regrouped_videos), 1)\n+        self.assertEqual(video_1.shape, regrouped_videos[0].shape)\n+\n \n @require_vision\n @require_av"
        }
    ],
    "stats": {
        "total": 57,
        "additions": 53,
        "deletions": 4
    }
}