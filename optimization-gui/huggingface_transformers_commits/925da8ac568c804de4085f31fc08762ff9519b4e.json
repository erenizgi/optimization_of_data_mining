{
    "author": "yaswanth19",
    "message": "Fix redundant code in Janus (#38826)\n\n* minor mistake\n\n* modify return statements",
    "sha": "925da8ac568c804de4085f31fc08762ff9519b4e",
    "files": [
        {
            "sha": "7084382988f6bbcfe5584e03acbf5caa7acdef10",
            "filename": "src/transformers/models/janus/modeling_janus.py",
            "status": "modified",
            "additions": 3,
            "deletions": 7,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/925da8ac568c804de4085f31fc08762ff9519b4e/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/925da8ac568c804de4085f31fc08762ff9519b4e/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodeling_janus.py?ref=925da8ac568c804de4085f31fc08762ff9519b4e",
            "patch": "@@ -1007,9 +1007,8 @@ def forward(\n         batch_size = pixel_values.shape[0]\n         quant, embedding_loss, indices = self.encode(pixel_values)\n         decoded_pixel_values = self.decode(indices.view(batch_size, -1))\n-        output = JanusVQVAEOutput(decoded_pixel_values, embedding_loss)\n \n-        return output\n+        return JanusVQVAEOutput(decoded_pixel_values, embedding_loss)\n \n \n class JanusVQVAEAlignerMLP(nn.Module):\n@@ -1151,16 +1150,14 @@ def forward(\n             **kwargs,\n         )\n \n-        output = JanusBaseModelOutputWithPast(\n+        return JanusBaseModelOutputWithPast(\n             last_hidden_state=lm_output.last_hidden_state,\n             past_key_values=lm_output.past_key_values,\n             hidden_states=lm_output.hidden_states,\n             attentions=lm_output.attentions,\n             image_hidden_states=image_embeds if pixel_values is not None else None,\n         )\n \n-        return output\n-\n \n class JanusForConditionalGeneration(JanusPreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"model.language_model.embed_tokens.weight\", \"lm_head.weight\"]\n@@ -1249,15 +1246,14 @@ def forward(\n         if labels is not None:\n             loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.text_config.vocab_size)\n \n-        output = JanusCausalLMOutputWithPast(\n+        return JanusCausalLMOutputWithPast(\n             loss=loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n             image_hidden_states=outputs.image_hidden_states,\n         )\n-        return output\n \n     def prepare_inputs_for_generation(\n         self,"
        },
        {
            "sha": "17b6565ddcb655f626897fdc174da01766b837a0",
            "filename": "src/transformers/models/janus/modular_janus.py",
            "status": "modified",
            "additions": 5,
            "deletions": 10,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/925da8ac568c804de4085f31fc08762ff9519b4e/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/925da8ac568c804de4085f31fc08762ff9519b4e/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fmodular_janus.py?ref=925da8ac568c804de4085f31fc08762ff9519b4e",
            "patch": "@@ -49,7 +49,6 @@\n from ..chameleon.configuration_chameleon import ChameleonVQVAEConfig\n from ..chameleon.modeling_chameleon import (\n     ChameleonVQVAE,\n-    ChameleonVQVAEEncoder,\n     ChameleonVQVAEEncoderAttnBlock,\n     ChameleonVQVAEEncoderConvDownsample,\n     ChameleonVQVAEEncoderResnetBlock,\n@@ -656,9 +655,9 @@ def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n         return hidden_states\n \n \n-class JanusVQVAEEncoder(ChameleonVQVAEEncoder, nn.Module):\n+class JanusVQVAEEncoder(nn.Module):\n     def __init__(self, config):\n-        nn.Module.__init__()\n+        super().__init__()\n \n         self.num_resolutions = len(config.channel_multiplier)\n         self.num_res_blocks = config.num_res_blocks\n@@ -845,9 +844,8 @@ def forward(\n         batch_size = pixel_values.shape[0]\n         quant, embedding_loss, indices = self.encode(pixel_values)\n         decoded_pixel_values = self.decode(indices.view(batch_size, -1))\n-        output = JanusVQVAEOutput(decoded_pixel_values, embedding_loss)\n \n-        return output\n+        return JanusVQVAEOutput(decoded_pixel_values, embedding_loss)\n \n \n class JanusVQVAEAlignerMLP(nn.Module):\n@@ -989,16 +987,14 @@ def forward(\n             **kwargs,\n         )\n \n-        output = JanusBaseModelOutputWithPast(\n+        return JanusBaseModelOutputWithPast(\n             last_hidden_state=lm_output.last_hidden_state,\n             past_key_values=lm_output.past_key_values,\n             hidden_states=lm_output.hidden_states,\n             attentions=lm_output.attentions,\n             image_hidden_states=image_embeds if pixel_values is not None else None,\n         )\n \n-        return output\n-\n \n class JanusForConditionalGeneration(JanusPreTrainedModel, GenerationMixin):\n     _tied_weights_keys = [\"model.language_model.embed_tokens.weight\", \"lm_head.weight\"]\n@@ -1087,15 +1083,14 @@ def forward(\n         if labels is not None:\n             loss = self.loss_function(logits=logits, labels=labels, vocab_size=self.config.text_config.vocab_size)\n \n-        output = JanusCausalLMOutputWithPast(\n+        return JanusCausalLMOutputWithPast(\n             loss=loss,\n             logits=logits,\n             past_key_values=outputs.past_key_values,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n             image_hidden_states=outputs.image_hidden_states,\n         )\n-        return output\n \n     def prepare_inputs_for_generation(\n         self,"
        }
    ],
    "stats": {
        "total": 25,
        "additions": 8,
        "deletions": 17
    }
}