{
    "author": "MekkCyber",
    "message": "Erroring when KernelConfig is passed without use_kernels = True (#41657)\n\n* update\n\n* update",
    "sha": "fe11cbb808b4301399240e40c5cb6cca9bb00d4d",
    "files": [
        {
            "sha": "8611a4a02e953ee1816711191402345a4f9cce84",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/fe11cbb808b4301399240e40c5cb6cca9bb00d4d/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fe11cbb808b4301399240e40c5cb6cca9bb00d4d/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=fe11cbb808b4301399240e40c5cb6cca9bb00d4d",
            "patch": "@@ -4430,6 +4430,12 @@ def from_pretrained(\n                     \"loaded from GGUF files.\"\n                 )\n \n+        if kernel_config is not None and not use_kernels:\n+            logger.warning_once(\n+                \"A kernel_config was provided but use_kernels is False; setting use_kernels=True automatically. To suppress this warning, explicitly set use_kernels to True.\"\n+            )\n+            use_kernels = True\n+\n         checkpoint_files, sharded_metadata = _get_resolved_checkpoint_files(\n             pretrained_model_name_or_path=pretrained_model_name_or_path,\n             variant=variant,"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 6,
        "deletions": 0
    }
}