{
    "author": "SunMarc",
    "message": "fix dict like init for ModelOutput (#41002)\n\n* fix dict like init\n\n* style",
    "sha": "2a538b2ed4a849b99cd790731f51f1d221a318f4",
    "files": [
        {
            "sha": "1606443ccece6d65bd874c5ea169acfef32ae813",
            "filename": "src/transformers/utils/generic.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/2a538b2ed4a849b99cd790731f51f1d221a318f4/src%2Ftransformers%2Futils%2Fgeneric.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2a538b2ed4a849b99cd790731f51f1d221a318f4/src%2Ftransformers%2Futils%2Fgeneric.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fgeneric.py?ref=2a538b2ed4a849b99cd790731f51f1d221a318f4",
            "patch": "@@ -318,6 +318,8 @@ def __post_init__(self):\n             # if we provided an iterator as first field and the iterator is a (key, value) iterator\n             # set the associated fields\n             if first_field_iterator:\n+                # reset first field to None\n+                setattr(self, class_fields[0].name, None)\n                 for idx, element in enumerate(iterator):\n                     if not isinstance(element, (list, tuple)) or len(element) != 2 or not isinstance(element[0], str):\n                         if idx == 0:"
        },
        {
            "sha": "f09d8653adf4fef50d849fe4addcd4fc42c5df4d",
            "filename": "tests/utils/test_generic.py",
            "status": "modified",
            "additions": 14,
            "deletions": 1,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/2a538b2ed4a849b99cd790731f51f1d221a318f4/tests%2Futils%2Ftest_generic.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2a538b2ed4a849b99cd790731f51f1d221a318f4/tests%2Futils%2Ftest_generic.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_generic.py?ref=2a538b2ed4a849b99cd790731f51f1d221a318f4",
            "patch": "@@ -19,7 +19,7 @@\n import pytest\n \n from transformers.configuration_utils import PretrainedConfig\n-from transformers.modeling_outputs import BaseModelOutput\n+from transformers.modeling_outputs import BaseModelOutput, CausalLMOutputWithPast\n from transformers.testing_utils import require_torch\n from transformers.utils import (\n     can_return_tuple,\n@@ -139,6 +139,19 @@ def test_to_py_obj_torch(self):\n \n         self.assertTrue(to_py_obj([t1, t2]) == [x1, x2])\n \n+    def test_model_output_subclass(self):\n+        # testing with “dict-like init” case\n+        out = CausalLMOutputWithPast({\"logits\": torch.ones(2, 3, 4)})\n+        self.assertTrue(out[\"logits\"] is not None)\n+        self.assertTrue(out.loss is None)\n+        self.assertTrue(len(out.to_tuple()) == 1)\n+\n+        # testing with dataclass init case\n+        out = CausalLMOutputWithPast(logits=torch.ones(2, 3, 4))\n+        self.assertTrue(out[\"logits\"] is not None)\n+        self.assertTrue(out.loss is None)\n+        self.assertTrue(len(out.to_tuple()) == 1)\n+\n \n class ValidationDecoratorTester(unittest.TestCase):\n     def test_cases_no_warning(self):"
        }
    ],
    "stats": {
        "total": 17,
        "additions": 16,
        "deletions": 1
    }
}