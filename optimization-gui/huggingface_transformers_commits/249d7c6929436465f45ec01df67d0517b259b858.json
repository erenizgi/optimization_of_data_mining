{
    "author": "tyleryzhu",
    "message": "Update image_processing_perception_lm_fast.py to allow for proper override of vision_input_type (#40252)\n\n* Update image_processing_perception_lm_fast.py\n\nAllow for a proper override of vision_input_type in hf fast image processor, otherwise we need to resort to manually setting the attribute.\n\n* Update processing_perception_lm.py to match kwargs vision input type\n\n* Update image_processing_perception_lm_fast.py kwargs to signature args",
    "sha": "249d7c6929436465f45ec01df67d0517b259b858",
    "files": [
        {
            "sha": "c8b7c52d9a2322e3274331cf8cb02170a7b7d41e",
            "filename": "src/transformers/models/perception_lm/image_processing_perception_lm_fast.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/249d7c6929436465f45ec01df67d0517b259b858/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/249d7c6929436465f45ec01df67d0517b259b858/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fimage_processing_perception_lm_fast.py?ref=249d7c6929436465f45ec01df67d0517b259b858",
            "patch": "@@ -272,6 +272,7 @@ def _preprocess(\n         do_normalize: Optional[bool],\n         image_mean: Optional[Union[float, list[float]]],\n         image_std: Optional[Union[float, list[float]]],\n+        vision_input_type: str,\n         tile_size: int,\n         max_num_tiles: int,\n         return_tensors: Optional[Union[str, TensorType]],\n@@ -283,7 +284,7 @@ def _preprocess(\n         resized_images_grouped = {}\n         for shape, stacked_images in grouped_images.items():\n             if do_resize:\n-                if self.vision_input_type == \"thumb+tile\":\n+                if vision_input_type == \"thumb+tile\":\n                     thumbnails, _ = self.resize(stacked_images, tile_size, max_num_tiles=1)\n                     images_for_tiling, (tiles_w, tiles_h) = self.resize(\n                         stacked_images, tile_size, max_num_tiles=max_num_tiles"
        },
        {
            "sha": "7fa01932ac799473e4b8e71bf060ac53d1a79843",
            "filename": "src/transformers/models/perception_lm/processing_perception_lm.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/249d7c6929436465f45ec01df67d0517b259b858/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/249d7c6929436465f45ec01df67d0517b259b858/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fperception_lm%2Fprocessing_perception_lm.py?ref=249d7c6929436465f45ec01df67d0517b259b858",
            "patch": "@@ -213,11 +213,12 @@ def _get_num_multimodal_tokens(self, image_sizes=None, **kwargs):\n             images_kwargs = PerceptionLMProcessorKwargs._defaults.get(\"images_kwargs\", {})\n             images_kwargs.update(kwargs)\n             tile_size = images_kwargs.get(\"tile_size\", None) or self.image_processor.tile_size\n+            vision_input_type = images_kwargs.get(\"vision_input_type\", None) or self.image_processor.vision_input_type\n \n             num_image_tokens = []\n             num_image_patches = []\n             for height, width in image_sizes:\n-                if self.image_processor.vision_input_type == \"thumb+tile\":\n+                if vision_input_type == \"thumb+tile\":\n                     aspect_ratio = self.image_processor._fit_image_to_canvas(\n                         img_width=width, img_height=height, tile_size=tile_size\n                     )"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 4,
        "deletions": 2
    }
}