{
    "author": "raimbekovm",
    "message": "Add expected outputs to DetrForSegmentation docstring example (#43035)\n\n* Remove duplicate TODO comment in audio_utils.py\n\nThe same TODO comment appeared twice in the file (lines 51 and 169).\nRemoved the duplicate from the load_audio_as function as the comment\nat the import statement (line 51) is more contextually appropriate.\n\n* Add expected outputs to DetrForSegmentation docstring example",
    "sha": "1802c84ffe4a767a9cabf549189b509520e0b03a",
    "files": [
        {
            "sha": "e2804f90d750a4196efbda1a669b300be9925ce3",
            "filename": "src/transformers/audio_utils.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/1802c84ffe4a767a9cabf549189b509520e0b03a/src%2Ftransformers%2Faudio_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1802c84ffe4a767a9cabf549189b509520e0b03a/src%2Ftransformers%2Faudio_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Faudio_utils.py?ref=1802c84ffe4a767a9cabf549189b509520e0b03a",
            "patch": "@@ -166,7 +166,6 @@ def load_audio_as(\n             - `dict`: Dictionary with 'data' (base64 encoded audio data) and 'format' keys (if return_format=\"dict\")\n             - `io.BytesIO`: BytesIO object containing audio data (if return_format=\"buffer\")\n     \"\"\"\n-    # TODO: @eustlb, we actually don't need librosa but soxr is installed with librosa\n     requires_backends(load_audio_as, [\"librosa\"])\n \n     if return_format not in [\"base64\", \"dict\", \"buffer\"]:"
        },
        {
            "sha": "c135d428dd6fb5e1e5eae82882ab418a4e4ed258",
            "filename": "src/transformers/models/detr/modeling_detr.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1802c84ffe4a767a9cabf549189b509520e0b03a/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/1802c84ffe4a767a9cabf549189b509520e0b03a/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdetr%2Fmodeling_detr.py?ref=1802c84ffe4a767a9cabf549189b509520e0b03a",
            "patch": "@@ -1460,8 +1460,12 @@ def forward(\n \n         >>> # A tensor of shape (height, width) where each value denotes a segment id, filled with -1 if no segment is found\n         >>> panoptic_seg = result[0][\"segmentation\"]\n+        >>> panoptic_seg.shape\n+        torch.Size([300, 500])\n         >>> # Get prediction score and segment_id to class_id mapping of each segment\n         >>> panoptic_segments_info = result[0][\"segments_info\"]\n+        >>> len(panoptic_segments_info)\n+        5\n         ```\"\"\"\n \n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict"
        }
    ],
    "stats": {
        "total": 5,
        "additions": 4,
        "deletions": 1
    }
}