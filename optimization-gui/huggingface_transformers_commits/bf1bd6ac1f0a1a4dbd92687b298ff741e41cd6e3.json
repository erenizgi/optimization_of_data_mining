{
    "author": "yuanwu2017",
    "message": "Fix int4 quantized model cannot work with cpu (#39724)\n\n* Fix int4 quantized model cannot work with cpu\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* Update the comments\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* update\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n* update\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\n\n---------\n\nSigned-off-by: yuanwu <yuan.wu@intel.com>\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3",
    "files": [
        {
            "sha": "86cff70018273aee25976ff31447f1a89e2f1128",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3",
            "patch": "@@ -954,7 +954,7 @@ def load_shard_file(args):\n             or isinstance(hf_quantizer.quantization_config.quant_type, Int4WeightOnlyConfig)\n         )\n     ):\n-        map_location = torch.device([d for d in device_map.values() if d not in [\"cpu\", \"disk\"]][0])\n+        map_location = torch.device([d for d in device_map.values() if d not in [\"disk\"]][0])\n \n     # If shard_file is \"\", we use the existing state_dict instead of loading it\n     if shard_file != \"\":"
        },
        {
            "sha": "f283c48469cbfbb96f22dbab98d9cac3d280f5c9",
            "filename": "src/transformers/quantizers/quantizer_torchao.py",
            "status": "modified",
            "additions": 5,
            "deletions": 6,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3/src%2Ftransformers%2Fquantizers%2Fquantizer_torchao.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3/src%2Ftransformers%2Fquantizers%2Fquantizer_torchao.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fquantizers%2Fquantizer_torchao.py?ref=bf1bd6ac1f0a1a4dbd92687b298ff741e41cd6e3",
            "patch": "@@ -100,14 +100,13 @@ def validate_environment(self, *args, **kwargs):\n         self.offload = False\n         device_map = kwargs.get(\"device_map\")\n         if isinstance(device_map, dict):\n-            if \"cpu\" in device_map.values() or \"disk\" in device_map.values():\n-                if self.pre_quantized:\n+            if (\"disk\" in device_map.values() or \"cpu\" in device_map.values()) and len(device_map) > 1:\n+                self.offload = True\n+                if self.pre_quantized and \"disk\" in device_map.values():\n                     raise ValueError(\n-                        \"You are attempting to perform cpu/disk offload with a pre-quantized torchao model \"\n-                        \"This is not supported yet . Please remove the CPU or disk device from the device_map.\"\n+                        \"You are attempting to perform disk offload with a pre-quantized torchao model \"\n+                        \"This is not supported yet . Please remove the disk device from the device_map.\"\n                     )\n-                else:\n-                    self.offload = True\n         if self.pre_quantized:\n             weights_only = kwargs.get(\"weights_only\")\n             if weights_only:"
        }
    ],
    "stats": {
        "total": 13,
        "additions": 6,
        "deletions": 7
    }
}