{
    "author": "faaany",
    "message": "[docs] fix example code bug (#35054)\n\nfix code bug",
    "sha": "3deaa8179d78d3f719f9f527fcfb13799a407aa0",
    "files": [
        {
            "sha": "28bd98457ee01658c1f237c0551dc36c0a68bff2",
            "filename": "docs/source/en/tasks/image_text_to_text.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3deaa8179d78d3f719f9f527fcfb13799a407aa0/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/3deaa8179d78d3f719f9f527fcfb13799a407aa0/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fimage_text_to_text.md?ref=3deaa8179d78d3f719f9f527fcfb13799a407aa0",
            "patch": "@@ -229,7 +229,7 @@ Now let's call the `model_inference` function we created and stream the values.\n ```python\n generator = model_inference(\n     user_prompt=\"And what is in this image?\",\n-    chat_history=messages,\n+    chat_history=messages[:2],\n     max_new_tokens=100,\n     images=images\n )"
        }
    ],
    "stats": {
        "total": 2,
        "additions": 1,
        "deletions": 1
    }
}