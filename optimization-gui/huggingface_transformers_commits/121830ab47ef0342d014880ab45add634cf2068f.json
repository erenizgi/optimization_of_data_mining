{
    "author": "ydshieh",
    "message": "update examples after ruff being updated (#36972)\n\n* update\n\n* update\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "121830ab47ef0342d014880ab45add634cf2068f",
    "files": [
        {
            "sha": "19428b7bb9c28e77d1b307f0e3c9a667a2447f72",
            "filename": ".circleci/config.yml",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/.circleci%2Fconfig.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/.circleci%2Fconfig.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.circleci%2Fconfig.yml?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -154,7 +154,7 @@ jobs:\n                   path: ~/transformers/installed.txt\n             - run: python -c \"from transformers import *\" || (echo 'ðŸš¨ import failed, this means you introduced unprotected imports! ðŸš¨'; exit 1)\n             - run: ruff check examples tests src utils\n-            - run: ruff format tests src utils --check\n+            - run: ruff format examples tests src utils --check\n             - run: python utils/custom_init_isort.py --check_only\n             - run: python utils/sort_auto_mappings.py --check_only\n             - run: python utils/check_doc_toc.py"
        },
        {
            "sha": "2faea6b5c56e6a102dd2bf2bbefb279f93de880c",
            "filename": "examples/flax/language-modeling/run_bert_flax.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fflax%2Flanguage-modeling%2Frun_bert_flax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fflax%2Flanguage-modeling%2Frun_bert_flax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fflax%2Flanguage-modeling%2Frun_bert_flax.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -53,4 +53,4 @@ def func():\n     func()\n end = time.time()\n print(end - start)\n-print(f\"Throughput: {((nbenchmark * BS)/(end-start)):.3f} examples/sec\")\n+print(f\"Throughput: {((nbenchmark * BS) / (end - start)):.3f} examples/sec\")"
        },
        {
            "sha": "e9daf9fc506df77c2e4a1709f124b4e5ccef519c",
            "filename": "examples/legacy/seq2seq/finetune_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Ffinetune_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Ffinetune_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Flegacy%2Fseq2seq%2Ffinetune_trainer.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -231,9 +231,9 @@ def main():\n \n     # set decoder_start_token_id for MBart\n     if model.config.decoder_start_token_id is None and isinstance(tokenizer, (MBartTokenizer, MBartTokenizerFast)):\n-        assert (\n-            data_args.tgt_lang is not None and data_args.src_lang is not None\n-        ), \"mBart requires --tgt_lang and --src_lang\"\n+        assert data_args.tgt_lang is not None and data_args.src_lang is not None, (\n+            \"mBart requires --tgt_lang and --src_lang\"\n+        )\n         if isinstance(tokenizer, MBartTokenizer):\n             model.config.decoder_start_token_id = tokenizer.lang_code_to_id[data_args.tgt_lang]\n         else:"
        },
        {
            "sha": "e6048a4ec440532e278b68d3662b8ccab31fd5d1",
            "filename": "examples/legacy/seq2seq/run_eval_search.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Frun_eval_search.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Frun_eval_search.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Flegacy%2Fseq2seq%2Frun_eval_search.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -128,7 +128,7 @@ def run_search():\n \n     results_sorted = sorted(results, key=operator.itemgetter(*task_score_names[task]), reverse=True)\n     print(\" | \".join([f\"{col:{col_widths[col]}}\" for col in col_names]))\n-    print(\" | \".join([f\"{'-'*col_widths[col]}\" for col in col_names]))\n+    print(\" | \".join([f\"{'-' * col_widths[col]}\" for col in col_names]))\n     for row in results_sorted:\n         print(\" | \".join([f\"{row[col]:{col_widths[col]}}\" for col in col_names]))\n "
        },
        {
            "sha": "955c9e996105a9e36bfaa377422e8acf14c3b18d",
            "filename": "examples/legacy/seq2seq/utils.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Fseq2seq%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Flegacy%2Fseq2seq%2Futils.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -282,9 +282,9 @@ def __init__(self, tokenizer, data_args, decoder_start_token_id, tpu_num_cores=N\n         self.tokenizer = tokenizer\n         self.pad_token_id = tokenizer.pad_token_id\n         self.decoder_start_token_id = decoder_start_token_id\n-        assert (\n-            self.pad_token_id is not None\n-        ), f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"\n+        assert self.pad_token_id is not None, (\n+            f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"\n+        )\n         self.data_args = data_args\n         self.tpu_num_cores = tpu_num_cores\n         self.dataset_kwargs = {\"add_prefix_space\": True} if isinstance(tokenizer, BartTokenizer) else {}\n@@ -593,7 +593,7 @@ def assert_all_frozen(model):\n     model_grads: List[bool] = list(grad_status(model))\n     n_require_grad = sum(lmap(int, model_grads))\n     npars = len(model_grads)\n-    assert not any(model_grads), f\"{n_require_grad/npars:.1%} of {npars} weights require grad\"\n+    assert not any(model_grads), f\"{n_require_grad / npars:.1%} of {npars} weights require grad\"\n \n \n def assert_not_all_frozen(model):"
        },
        {
            "sha": "43de0a7f04ad83d342fad9f764f9d6002207f653",
            "filename": "examples/legacy/token-classification/tasks.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Ftoken-classification%2Ftasks.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Flegacy%2Ftoken-classification%2Ftasks.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Flegacy%2Ftoken-classification%2Ftasks.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -131,7 +131,7 @@ def write_predictions_to_file(self, writer: TextIO, test_input_reader: TextIO, p\n             s_p = preds_list[example_id]\n             out = \"\"\n             for token in sentence:\n-                out += f'{token[\"form\"]} ({token[\"upos\"]}|{s_p.pop(0)}) '\n+                out += f\"{token['form']} ({token['upos']}|{s_p.pop(0)}) \"\n             out += \"\\n\"\n             writer.write(out)\n             example_id += 1"
        },
        {
            "sha": "ba2e9a4d6f277466fa28a66c80085a17d419851e",
            "filename": "examples/modular-transformers/modeling_multimodal2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fmodular-transformers%2Fmodeling_multimodal2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fmodular-transformers%2Fmodeling_multimodal2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fmodular-transformers%2Fmodeling_multimodal2.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -534,7 +534,7 @@ def forward(self, pixel_values: torch.FloatTensor, interpolate_pos_encoding=Fals\n         batch_size, _, height, width = pixel_values.shape\n         if not interpolate_pos_encoding and (height != self.image_size or width != self.image_size):\n             raise ValueError(\n-                f\"Input image size ({height}*{width}) doesn't match model\" f\" ({self.image_size}*{self.image_size}).\"\n+                f\"Input image size ({height}*{width}) doesn't match model ({self.image_size}*{self.image_size}).\"\n             )\n         target_dtype = self.patch_embedding.weight.dtype\n         patch_embeds = self.patch_embedding(pixel_values.to(dtype=target_dtype))  # shape = [*, width, grid, grid]"
        },
        {
            "sha": "308e3a99626c71846a5cc8ea629b22d8d5bd85a7",
            "filename": "examples/pytorch/language-modeling/run_clm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -438,7 +438,7 @@ def main():\n     else:\n         model = AutoModelForCausalLM.from_config(config, trust_remote_code=model_args.trust_remote_code)\n         n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n-        logger.info(f\"Training new model from scratch - Total size={n_params/2**20:.2f}M params\")\n+        logger.info(f\"Training new model from scratch - Total size={n_params / 2**20:.2f}M params\")\n \n     # We resize the embeddings only when necessary to avoid index errors. If you are creating a model from scratch\n     # on a small vocab and want a smaller embedding size, remove this test."
        },
        {
            "sha": "f981c97a8e8d736fa4497280e16c0c30af02f1c3",
            "filename": "examples/pytorch/language-modeling/run_fim.py",
            "status": "modified",
            "additions": 2,
            "deletions": 3,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -265,8 +265,7 @@ class DataTrainingArguments:\n         default=\"<fim_pad>\",\n         metadata={\n             \"help\": (\n-                \"Fill-in-Middle Pad token. Used only when 'truncate_or_pad' is set to True. \"\n-                \"Defaults to '<fim_pad>'.\"\n+                \"Fill-in-Middle Pad token. Used only when 'truncate_or_pad' is set to True. Defaults to '<fim_pad>'.\"\n             )\n         },\n     )\n@@ -514,7 +513,7 @@ def main():\n             attn_implementation=model_args.attn_implementation,\n         )\n         n_params = sum({p.data_ptr(): p.numel() for p in model.parameters()}.values())\n-        logger.info(f\"Training new model from scratch - Total size={n_params/2**20:.2f}M params\")\n+        logger.info(f\"Training new model from scratch - Total size={n_params / 2**20:.2f}M params\")\n \n     # Add the new FIM tokens to the tokenizer and resize model's vocab embeddings\n     special_tokens = [data_args.fim_prefix_token, data_args.fim_middle_token, data_args.fim_suffix_token]"
        },
        {
            "sha": "b2cd5ddd1294d2997782caa4fe1ea348160c2150",
            "filename": "examples/pytorch/language-modeling/run_fim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -234,9 +234,7 @@ def parse_args():\n         \"--fim_pad_token\",\n         type=str,\n         default=\"<fim_pad>\",\n-        help=(\n-            \"Fill-in-Middle Pad token. Used only when 'truncate_or_pad' is set to True.\" \" Defaults to '<fim_pad>'.\"\n-        ),\n+        help=(\"Fill-in-Middle Pad token. Used only when 'truncate_or_pad' is set to True. Defaults to '<fim_pad>'.\"),\n     )\n     parser.add_argument(\n         \"--preprocessing_num_workers\","
        },
        {
            "sha": "7d943203b45087dc68750ab84cadaf460a695d7b",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -491,7 +491,7 @@ def main():\n     # E.g. characters, such as `,` and `.` do not really have an acoustic characteristic\n     # that could be easily picked up by the model\n     chars_to_ignore_regex = (\n-        f'[{\"\".join(data_args.chars_to_ignore)}]' if data_args.chars_to_ignore is not None else None\n+        f\"[{''.join(data_args.chars_to_ignore)}]\" if data_args.chars_to_ignore is not None else None\n     )\n     text_column_name = data_args.text_column_name\n "
        },
        {
            "sha": "c2091c2af91fefd3eb3f33924e5e39648990457e",
            "filename": "examples/pytorch/speech-recognition/run_speech_recognition_ctc_adapter.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fspeech-recognition%2Frun_speech_recognition_ctc_adapter.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -471,7 +471,7 @@ def main():\n     # E.g. characters, such as `,` and `.` do not really have an acoustic characteristic\n     # that could be easily picked up by the model\n     chars_to_ignore_regex = (\n-        f'[{\"\".join(data_args.chars_to_ignore)}]' if data_args.chars_to_ignore is not None else None\n+        f\"[{''.join(data_args.chars_to_ignore)}]\" if data_args.chars_to_ignore is not None else None\n     )\n     text_column_name = data_args.text_column_name\n "
        },
        {
            "sha": "49ad6687840e917995b2b74e375691f648b57e90",
            "filename": "examples/pytorch/summarization/run_summarization.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2Frun_summarization.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -505,9 +505,9 @@ def main():\n         return\n \n     if isinstance(tokenizer, tuple(MULTILINGUAL_TOKENIZERS)):\n-        assert (\n-            data_args.lang is not None\n-        ), f\"{tokenizer.__class__.__name__} is a multilingual tokenizer which requires --lang argument\"\n+        assert data_args.lang is not None, (\n+            f\"{tokenizer.__class__.__name__} is a multilingual tokenizer which requires --lang argument\"\n+        )\n \n         tokenizer.src_lang = data_args.lang\n         tokenizer.tgt_lang = data_args.lang"
        },
        {
            "sha": "28bd9a7025d2bc215283c09d44cf6ca7874cb55f",
            "filename": "examples/pytorch/text-classification/run_classification.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_classification.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -199,9 +199,9 @@ def __post_init__(self):\n             train_extension = self.train_file.split(\".\")[-1]\n             assert train_extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n             validation_extension = self.validation_file.split(\".\")[-1]\n-            assert (\n-                validation_extension == train_extension\n-            ), \"`validation_file` should have the same extension (csv or json) as `train_file`.\"\n+            assert validation_extension == train_extension, (\n+                \"`validation_file` should have the same extension (csv or json) as `train_file`.\"\n+            )\n \n \n @dataclass\n@@ -357,9 +357,9 @@ def main():\n             if data_args.test_file is not None:\n                 train_extension = data_args.train_file.split(\".\")[-1]\n                 test_extension = data_args.test_file.split(\".\")[-1]\n-                assert (\n-                    test_extension == train_extension\n-                ), \"`test_file` should have the same extension (csv or json) as `train_file`.\"\n+                assert test_extension == train_extension, (\n+                    \"`test_file` should have the same extension (csv or json) as `train_file`.\"\n+                )\n                 data_files[\"test\"] = data_args.test_file\n             else:\n                 raise ValueError(\"Need either a dataset name or a test file for `do_predict`.\")"
        },
        {
            "sha": "db3101abdaf6baf3018f9d6b4b5d89d073332d93",
            "filename": "examples/pytorch/text-classification/run_glue.py",
            "status": "modified",
            "additions": 6,
            "deletions": 6,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -156,9 +156,9 @@ def __post_init__(self):\n             train_extension = self.train_file.split(\".\")[-1]\n             assert train_extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n             validation_extension = self.validation_file.split(\".\")[-1]\n-            assert (\n-                validation_extension == train_extension\n-            ), \"`validation_file` should have the same extension (csv or json) as `train_file`.\"\n+            assert validation_extension == train_extension, (\n+                \"`validation_file` should have the same extension (csv or json) as `train_file`.\"\n+            )\n \n \n @dataclass\n@@ -313,9 +313,9 @@ def main():\n             if data_args.test_file is not None:\n                 train_extension = data_args.train_file.split(\".\")[-1]\n                 test_extension = data_args.test_file.split(\".\")[-1]\n-                assert (\n-                    test_extension == train_extension\n-                ), \"`test_file` should have the same extension (csv or json) as `train_file`.\"\n+                assert test_extension == train_extension, (\n+                    \"`test_file` should have the same extension (csv or json) as `train_file`.\"\n+                )\n                 data_files[\"test\"] = data_args.test_file\n             else:\n                 raise ValueError(\"Need either a GLUE task or a test file for `do_predict`.\")"
        },
        {
            "sha": "570eb92645f3f3f5eb9f069ee6a1b6254e752ac4",
            "filename": "examples/pytorch/text-generation/run_generation.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-generation%2Frun_generation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-generation%2Frun_generation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-generation%2Frun_generation.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -322,7 +322,7 @@ def main():\n     parser.add_argument(\n         \"--use_cpu\",\n         action=\"store_true\",\n-        help=\"Whether or not to use cpu. If set to False, \" \"we will use gpu/npu or mps device if available\",\n+        help=\"Whether or not to use cpu. If set to False, we will use gpu/npu or mps device if available\",\n     )\n     parser.add_argument(\"--num_return_sequences\", type=int, default=1, help=\"The number of samples to generate.\")\n     parser.add_argument("
        },
        {
            "sha": "a36323e4ed7e8f8ac75313661719752518279d2a",
            "filename": "examples/pytorch/text-generation/run_generation_contrastive_search.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-generation%2Frun_generation_contrastive_search.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftext-generation%2Frun_generation_contrastive_search.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-generation%2Frun_generation_contrastive_search.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -68,7 +68,7 @@ def main():\n     parser.add_argument(\n         \"--use_cpu\",\n         action=\"store_true\",\n-        help=\"Whether or not to use cpu. If set to False, \" \"we will use gpu/npu or mps device if available\",\n+        help=\"Whether or not to use cpu. If set to False, we will use gpu/npu or mps device if available\",\n     )\n     parser.add_argument(\n         \"--fp16\","
        },
        {
            "sha": "973548c2ce0cd159eb7ee6efecf6ff7c2c76530e",
            "filename": "examples/pytorch/translation/run_translation_no_trainer.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -436,9 +436,9 @@ def main():\n \n     # Set decoder_start_token_id\n     if model.config.decoder_start_token_id is None and isinstance(tokenizer, (MBartTokenizer, MBartTokenizerFast)):\n-        assert (\n-            args.target_lang is not None and args.source_lang is not None\n-        ), \"mBart requires --target_lang and --source_lang\"\n+        assert args.target_lang is not None and args.source_lang is not None, (\n+            \"mBart requires --target_lang and --source_lang\"\n+        )\n         if isinstance(tokenizer, MBartTokenizer):\n             model.config.decoder_start_token_id = tokenizer.lang_code_to_id[args.target_lang]\n         else:"
        },
        {
            "sha": "dff9d268484b381eb23a8e1f4b672f2b1eae95ce",
            "filename": "examples/run_on_remote.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Frun_on_remote.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Frun_on_remote.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Frun_on_remote.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -56,7 +56,7 @@\n     cluster.run([\"pip install torch --upgrade --extra-index-url https://download.pytorch.org/whl/cu117\"])\n \n     # Run example. You can bypass the CLI wrapper and paste your own code here.\n-    cluster.run([f'python transformers/examples/{args.example} {\" \".join(shlex.quote(arg) for arg in unknown)}'])\n+    cluster.run([f\"python transformers/examples/{args.example} {' '.join(shlex.quote(arg) for arg in unknown)}\"])\n \n     # Alternatively, we can just import and run a training function (especially if there's no wrapper CLI):\n     # from my_script... import train"
        },
        {
            "sha": "3b9a9a9c1cd5acdc205804c1199314df3cd47e8d",
            "filename": "examples/tensorflow/translation/run_translation.py",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/121830ab47ef0342d014880ab45add634cf2068f/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/121830ab47ef0342d014880ab45add634cf2068f/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Ftensorflow%2Ftranslation%2Frun_translation.py?ref=121830ab47ef0342d014880ab45add634cf2068f",
            "patch": "@@ -501,9 +501,9 @@ def preprocess_function(examples):\n \n         # region Set decoder_start_token_id\n         if model.config.decoder_start_token_id is None and isinstance(tokenizer, (MBartTokenizer, MBartTokenizerFast)):\n-            assert (\n-                data_args.target_lang is not None and data_args.source_lang is not None\n-            ), \"mBart requires --target_lang and --source_lang\"\n+            assert data_args.target_lang is not None and data_args.source_lang is not None, (\n+                \"mBart requires --target_lang and --source_lang\"\n+            )\n             if isinstance(tokenizer, MBartTokenizer):\n                 model.config.decoder_start_token_id = tokenizer.lang_code_to_id[data_args.target_lang]\n             else:"
        }
    ],
    "stats": {
        "total": 87,
        "additions": 42,
        "deletions": 45
    }
}