{
    "author": "ylacombe",
    "message": "Fix DAC slow tests (#34088)\n\n* Fix DAC slow tests and fix decode\r\n\r\n* [run-slow] dac",
    "sha": "9dca0c91169b298ddf3a748d313e86ebb62cd4b8",
    "files": [
        {
            "sha": "f465ee77faa74568225337146402a98ae0acded8",
            "filename": "src/transformers/models/dac/modeling_dac.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/9dca0c91169b298ddf3a748d313e86ebb62cd4b8/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9dca0c91169b298ddf3a748d313e86ebb62cd4b8/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdac%2Fmodeling_dac.py?ref=9dca0c91169b298ddf3a748d313e86ebb62cd4b8",
            "patch": "@@ -641,14 +641,14 @@ def encode(\n     @replace_return_docstrings(output_type=DacDecoderOutput, config_class=_CONFIG_FOR_DOC)\n     def decode(\n         self,\n-        quantized_representation: Optional[torch.Tensor],\n+        quantized_representation: Optional[torch.Tensor] = None,\n         audio_codes: Optional[torch.Tensor] = None,\n         return_dict: Optional[bool] = None,\n     ):\n         \"\"\"Decode given latent codes and return audio data\n \n         Args:\n-            quantized_representation (torch.Tensor of shape `(batch_size, dimension, time_steps)`):\n+            quantized_representation (torch.Tensor of shape `(batch_size, dimension, time_steps)`, *optional*):\n                 Quantized continuous representation of input.\n             audio_codes (`torch.Tensor` of shape `(batch_size, num_codebooks, time_steps)`, *optional*):\n                 The codebook indices for each codebook, representing the quantized discrete"
        },
        {
            "sha": "55a17ab1e009d93cc8ebd6126e356194862ad2d2",
            "filename": "tests/models/dac/test_modeling_dac.py",
            "status": "modified",
            "additions": 7,
            "deletions": 2,
            "changes": 9,
            "blob_url": "https://github.com/huggingface/transformers/blob/9dca0c91169b298ddf3a748d313e86ebb62cd4b8/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9dca0c91169b298ddf3a748d313e86ebb62cd4b8/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fdac%2Ftest_modeling_dac.py?ref=9dca0c91169b298ddf3a748d313e86ebb62cd4b8",
            "patch": "@@ -458,9 +458,9 @@ def test_integration_24khz(self):\n         expected_rmse = 0.0039\n \n         expected_encoder_output_dict = {\n-            \"quantized_representation\": torch.tensor([0.9807, 2.8212, 5.2514, 2.7241, 1.0426]),\n+            \"quantized_representation\": torch.tensor([0.6257, 3.1245, 5.2514, 2.3160, 1.5774]),\n             \"audio_codes\": torch.tensor([919, 919, 234, 777, 234]),\n-            \"projected_latents\": torch.tensor([-4.7822, -5.0046, -4.5574, -5.0363, -5.4271]),\n+            \"projected_latents\": torch.tensor([-4.7841, -5.0063, -4.5595, -5.0372, -5.4280]),\n         }\n         librispeech_dummy = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n \n@@ -507,6 +507,11 @@ def test_integration_24khz(self):\n             input_values_dec = model.decode(quantized_representation)[0]\n             input_values_enc_dec = model(inputs[\"input_values\"])[1]\n \n+            input_values_from_codes = model.decode(audio_codes=encoder_outputs.audio_codes)[0]\n+\n+            # make sure decode from audio codes and quantized values give more or less the same results\n+            self.assertTrue(torch.allclose(input_values_from_codes, input_values_dec, atol=1e-5))\n+\n             # make sure forward and decode gives same result\n             self.assertTrue(torch.allclose(input_values_dec, input_values_enc_dec, atol=1e-3))\n "
        }
    ],
    "stats": {
        "total": 13,
        "additions": 9,
        "deletions": 4
    }
}