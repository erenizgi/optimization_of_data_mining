{
    "author": "sywangyi",
    "message": "fix crash when using chat to send 2+ request to gptoss (#40536)\n\nSigned-off-by: Wang, Yi <yi.a.wang@intel.com>",
    "sha": "577fa6f1672ec3e8e4e6f27f47301b285560eded",
    "files": [
        {
            "sha": "c8e446942553a1672b753ded9496fd6c0328f039",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/577fa6f1672ec3e8e4e6f27f47301b285560eded/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/577fa6f1672ec3e8e4e6f27f47301b285560eded/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=577fa6f1672ec3e8e4e6f27f47301b285560eded",
            "patch": "@@ -1026,7 +1026,9 @@ def generate_chat_completion(self, req: dict) -> Generator[str, None, None]:\n \n         last_kv_cache = None\n         if self.is_continuation(req) and not must_discard_cache:\n-            last_kv_cache = self.last_kv_cache\n+            seq_len = self.last_kv_cache.get_seq_length()\n+            if inputs[\"input_ids\"].shape[-1] > seq_len:\n+                last_kv_cache = self.last_kv_cache\n \n         generation_kwargs = {\n             **inputs,\n@@ -1213,7 +1215,9 @@ def generate_response(self, req: dict) -> Generator[str, None, None]:\n \n         last_kv_cache = None\n         if self.is_continuation(req) and not must_discard_cache:\n-            last_kv_cache = self.last_kv_cache\n+            seq_len = self.last_kv_cache.get_seq_length()\n+            if inputs[\"input_ids\"].shape[-1] > seq_len:\n+                last_kv_cache = self.last_kv_cache\n \n         generation_kwargs = {\n             \"inputs\": inputs,"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 6,
        "deletions": 2
    }
}