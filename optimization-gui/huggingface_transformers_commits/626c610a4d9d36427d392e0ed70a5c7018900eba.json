{
    "author": "Framartin",
    "message": "Fix perplexity computation in perplexity.md (#34387)\n\nfix average NLL in perplexity.md",
    "sha": "626c610a4d9d36427d392e0ed70a5c7018900eba",
    "files": [
        {
            "sha": "ac7ef8504e72b6e7a53c0626c11516d22b2130b6",
            "filename": "docs/source/en/perplexity.md",
            "status": "modified",
            "additions": 11,
            "deletions": 4,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/626c610a4d9d36427d392e0ed70a5c7018900eba/docs%2Fsource%2Fen%2Fperplexity.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/626c610a4d9d36427d392e0ed70a5c7018900eba/docs%2Fsource%2Fen%2Fperplexity.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fperplexity.md?ref=626c610a4d9d36427d392e0ed70a5c7018900eba",
            "patch": "@@ -107,7 +107,8 @@ max_length = model.config.n_positions\n stride = 512\n seq_len = encodings.input_ids.size(1)\n \n-nlls = []\n+nll_sum = 0.0\n+n_tokens = 0\n prev_end_loc = 0\n for begin_loc in tqdm(range(0, seq_len, stride)):\n     end_loc = min(begin_loc + max_length, seq_len)\n@@ -124,13 +125,19 @@ for begin_loc in tqdm(range(0, seq_len, stride)):\n         # to the left by 1.\n         neg_log_likelihood = outputs.loss\n \n-    nlls.append(neg_log_likelihood)\n+    # Accumulate the total negative log-likelihood and the total number of tokens\n+    num_valid_tokens = (target_ids != -100).sum().item()  # number of valid tokens in target_ids\n+    batch_size = target_ids.size(0)\n+    num_loss_tokens = num_valid_tokens - batch_size  # subtract batch_size due to internal label shift\n+    nll_sum += neg_log_likelihood * num_loss_tokens\n+    n_tokens += num_loss_tokens\n \n     prev_end_loc = end_loc\n     if end_loc == seq_len:\n         break\n \n-ppl = torch.exp(torch.stack(nlls).mean())\n+avg_nll = nll_sum / n_tokens  # average negative log-likelihood per token\n+ppl = torch.exp(avg_nll)\n ```\n \n Running this with the stride length equal to the max input length is equivalent to the suboptimal, non-sliding-window\n@@ -139,5 +146,5 @@ and the better the reported perplexity will typically be.\n \n When we run the above with `stride = 1024`, i.e. no overlap, the resulting PPL is `19.44`, which is about the same\n as the `19.93` reported in the GPT-2 paper. By using `stride = 512` and thereby employing our striding window\n-strategy, this jumps down to `16.45`. This is not only a more favorable score, but is calculated in a way that is\n+strategy, this jumps down to `16.44`. This is not only a more favorable score, but is calculated in a way that is\n closer to the true autoregressive decomposition of a sequence likelihood."
        }
    ],
    "stats": {
        "total": 15,
        "additions": 11,
        "deletions": 4
    }
}