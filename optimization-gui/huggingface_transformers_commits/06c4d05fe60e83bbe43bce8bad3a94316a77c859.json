{
    "author": "alex-jw-brooks",
    "message": "Enable granite speech 3.3 tests (#37560)\n\n* Enable granite speech 3.3 tests\n\n* skip sdpa test for granite speech\n\n* Explicitly move model to device\n\n* Use granite speech 2b in tests\n\n---------\n\nCo-authored-by: Yih-Dar <2521628+ydshieh@users.noreply.github.com>",
    "sha": "06c4d05fe60e83bbe43bce8bad3a94316a77c859",
    "files": [
        {
            "sha": "cde0779a503f4e41db417842af9f1eac052250d2",
            "filename": "tests/models/granite_speech/test_modeling_granite_speech.py",
            "status": "modified",
            "additions": 13,
            "deletions": 6,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/06c4d05fe60e83bbe43bce8bad3a94316a77c859/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/06c4d05fe60e83bbe43bce8bad3a94316a77c859/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranite_speech%2Ftest_modeling_granite_speech.py?ref=06c4d05fe60e83bbe43bce8bad3a94316a77c859",
            "patch": "@@ -33,6 +33,7 @@\n )\n from transformers.utils import (\n     is_datasets_available,\n+    is_peft_available,\n     is_torch_available,\n )\n \n@@ -306,11 +307,17 @@ def test_sdpa_can_dispatch_composite_models(self):\n                     if \"SdpaAttention\" in class_name or \"SdpaSelfAttention\" in class_name:\n                         raise ValueError(\"The eager model should not have SDPA attention layers\")\n \n+    @pytest.mark.generate\n+    @require_torch_sdpa\n+    @slow\n+    @unittest.skip(reason=\"Granite Speech doesn't support SDPA for all backbones\")\n+    def test_eager_matches_sdpa_generate(self):\n+        pass\n+\n \n class GraniteSpeechForConditionalGenerationIntegrationTest(unittest.TestCase):\n     def setUp(self):\n-        # TODO - use the actual model path on HF hub after release.\n-        self.model_path = \"ibm-granite/granite-speech\"\n+        self.model_path = \"ibm-granite/granite-speech-3.3-2b\"\n         self.processor = AutoProcessor.from_pretrained(self.model_path)\n         self.prompt = self._get_prompt(self.processor.tokenizer)\n \n@@ -338,7 +345,7 @@ def _load_datasamples(self, num_samples):\n         return [x[\"array\"] for x in speech_samples]\n \n     @slow\n-    @pytest.mark.skip(\"Public models not yet available\")\n+    @pytest.mark.skipif(not is_peft_available(), reason=\"Outputs diverge without lora\")\n     def test_small_model_integration_test_single(self):\n         model = GraniteSpeechForConditionalGeneration.from_pretrained(self.model_path).to(torch_device)\n         input_speech = self._load_datasamples(1)\n@@ -364,9 +371,9 @@ def test_small_model_integration_test_single(self):\n         )\n \n     @slow\n-    @pytest.mark.skip(\"Public models not yet available\")\n+    @pytest.mark.skipif(not is_peft_available(), reason=\"Outputs diverge without lora\")\n     def test_small_model_integration_test_batch(self):\n-        model = GraniteSpeechForConditionalGeneration.from_pretrained(self.model_path)\n+        model = GraniteSpeechForConditionalGeneration.from_pretrained(self.model_path).to(torch_device)\n         input_speech = self._load_datasamples(2)\n         prompts = [self.prompt, self.prompt]\n \n@@ -384,7 +391,7 @@ def test_small_model_integration_test_batch(self):\n \n         EXPECTED_DECODED_TEXT = [\n             \"systemKnowledge Cutoff Date: April 2024.\\nToday's Date: December 19, 2024.\\nYou are Granite, developed by IBM. You are a helpful AI assistant\\nusercan you transcribe the speech into a written format?\\nassistantmister quilter is the apostle of the middle classes and we are glad to welcome his gospel\",\n-            \"systemKnowledge Cutoff Date: April 2024.\\nToday's Date: December 19, 2024.\\nYou are Granite, developed by IBM. You are a helpful AI assistant\\nusercan you transcribe the speech into a written format?\\nassistantnor is mister quilter's manner less interesting than his matter\"\n+            \"systemKnowledge Cutoff Date: April 2024.\\nToday's Date: December 19, 2024.\\nYou are Granite, developed by IBM. You are a helpful AI assistant\\nusercan you transcribe the speech into a written format?\\nassistantnor is mister quilp's manner less interesting than his matter\"\n         ]  # fmt: skip\n \n         self.assertEqual("
        },
        {
            "sha": "2f8825ce6e4629f3f616bc8103b1f6dcffc524ee",
            "filename": "tests/models/granite_speech/test_processor_granite_speech.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/06c4d05fe60e83bbe43bce8bad3a94316a77c859/tests%2Fmodels%2Fgranite_speech%2Ftest_processor_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/06c4d05fe60e83bbe43bce8bad3a94316a77c859/tests%2Fmodels%2Fgranite_speech%2Ftest_processor_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgranite_speech%2Ftest_processor_granite_speech.py?ref=06c4d05fe60e83bbe43bce8bad3a94316a77c859",
            "patch": "@@ -33,14 +33,12 @@\n     from transformers import GraniteSpeechFeatureExtractor, GraniteSpeechProcessor\n \n \n-@pytest.skip(\"Public models not yet available\", allow_module_level=True)\n @require_torch\n @require_torchaudio\n class GraniteSpeechProcessorTest(unittest.TestCase):\n     def setUp(self):\n         self.tmpdirname = tempfile.mkdtemp()\n-        # TODO - use the actual model path on HF hub after release.\n-        self.checkpoint = \"ibm-granite/granite-speech\"\n+        self.checkpoint = \"ibm-granite/granite-speech-3.3-8b\"\n         processor = GraniteSpeechProcessor.from_pretrained(self.checkpoint)\n         processor.save_pretrained(self.tmpdirname)\n "
        }
    ],
    "stats": {
        "total": 23,
        "additions": 14,
        "deletions": 9
    }
}