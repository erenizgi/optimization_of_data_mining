{
    "author": "andimarafioti",
    "message": "smol improvements to support more flexible usage (#34857)\n\n* smol improvements to support more flexible usage\r\n\r\n* ruff",
    "sha": "861758e2358bae903861d54fbc25b87d3281ea78",
    "files": [
        {
            "sha": "f9161416656cd7dfa5d5c5f2dad6d0dcf8cace76",
            "filename": "src/transformers/models/idefics3/image_processing_idefics3.py",
            "status": "modified",
            "additions": 16,
            "deletions": 24,
            "changes": 40,
            "blob_url": "https://github.com/huggingface/transformers/blob/861758e2358bae903861d54fbc25b87d3281ea78/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/861758e2358bae903861d54fbc25b87d3281ea78/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fimage_processing_idefics3.py?ref=861758e2358bae903861d54fbc25b87d3281ea78",
            "patch": "@@ -38,6 +38,7 @@\n \n \n logger = logging.get_logger(__name__)\n+MAX_IMAGE_SIZE = 4096  # 4k resolution as absolute maximum\n \n \n if is_vision_available():\n@@ -116,7 +117,6 @@ def _resize_output_size_scale_below_upper_bound(\n def get_resize_output_image_size(\n     image,\n     resolution_max_side: int,\n-    max_image_size: int = 1820,\n     input_data_format: Optional[Union[str, ChannelDimension]] = None,\n ) -> Tuple[int, int]:\n     \"\"\"\n@@ -126,24 +126,18 @@ def get_resize_output_image_size(\n             Image to resize.\n         resolution_max_side (`int`):\n             The longest edge of the image will be resized to this value. The shortest edge will be resized to keep the\n-            input aspect ratio, with a lower bound of `min_image_size`.\n-        max_image_size (`int`, *optional*, defaults to 1820):\n-            Maximum image resolution. If the image is larger than this size, the longest edge will be resized to this\n-            value, with the shortest edge resized to keep the input aspect ratio, with a lower bound of `min_image_size`.\n+            input aspect ratio.\n         input_data_format (`ChannelDimension` or `str`):\n             The channel dimension format of the input image.\n     Returns:\n         The output size of the image after resizing.\n     \"\"\"\n-    if resolution_max_side > max_image_size:\n-        raise ValueError(\"`resolution_max_side` cannot be larger than `max_image_size`\")\n-\n     height, width = get_image_size(image, channel_dim=input_data_format)\n \n     # Find the output size, when rescaling the longest edge to max_len and preserving the aspect ratio\n     height, width = _resize_output_size_rescale_to_max_len(height, width, max_len=resolution_max_side)\n-    # Find the output size when scaling the image to be below the max_image_size\n-    height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=max_image_size)\n+    # Find the output size when scaling the image to be below the MAX_IMAGE_SIZE\n+    height, width = _resize_output_size_scale_below_upper_bound(height, width, max_len=MAX_IMAGE_SIZE)\n     return height, width\n \n \n@@ -251,7 +245,7 @@ def convert_to_rgb(\n     data_format = input_data_format if data_format is None else data_format\n \n     mode = \"P\" if palette is not None else None\n-    image = to_pil_image(image, image_mode=mode)\n+    image = to_pil_image(image, image_mode=mode, input_data_format=input_data_format)\n     if image.mode == \"P\" and palette is not None:\n         image.putpalette(palette)\n \n@@ -404,7 +398,7 @@ def resize(\n         image_mode = None\n         if image.ndim == 2 or image.shape[-1] == 1:\n             image_mode = \"P\"\n-        image = to_pil_image(image, image_mode=image_mode)\n+        image = to_pil_image(image, image_mode=image_mode, input_data_format=input_data_format)\n \n         resized_image = image.resize((size[1], size[0]), resample=resample)\n         resized_image = np.array(resized_image)\n@@ -754,6 +748,16 @@ def preprocess(\n         # All transformations expect numpy arrays.\n         images_list = [[to_numpy_array(image) for image in images] for images in images_list]\n \n+        # Extra channel dimension for grayscale images\n+        if input_data_format in [ChannelDimension.LAST, None]:\n+            images_list = [\n+                [np.expand_dims(img, axis=-1) if img.ndim == 2 else img for img in images] for images in images_list\n+            ]\n+        elif input_data_format == ChannelDimension.FIRST:\n+            images_list = [\n+                [np.expand_dims(img, axis=0) if img.ndim == 2 else img for img in images] for images in images_list\n+            ]\n+\n         if is_scaled_image(images_list[0][0]) and do_rescale:\n             logger.warning_once(\n                 \"It looks like you are trying to rescale already rescaled images. If the input\"\n@@ -764,18 +768,6 @@ def preprocess(\n         if input_data_format is None:\n             input_data_format = infer_channel_dimension_format(images_list[0][0], num_channels=(1, 3, 4))\n \n-        # Extra channel dimension for grayscale images\n-        if input_data_format == ChannelDimension.LAST:\n-            images_list = [\n-                [np.expand_dims(img, axis=-1) if img.ndim == 2 else img for img in images] for images in images_list\n-            ]\n-        elif input_data_format == ChannelDimension.FIRST:\n-            images_list = [\n-                [np.expand_dims(img, axis=0) if img.ndim == 2 else img for img in images] for images in images_list\n-            ]\n-        else:\n-            raise ValueError(f\"Invalid channel dimension format {input_data_format}.\")\n-\n         if do_resize:\n             images_list = [\n                 ["
        }
    ],
    "stats": {
        "total": 40,
        "additions": 16,
        "deletions": 24
    }
}