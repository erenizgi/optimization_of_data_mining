{
    "author": "qianyue76",
    "message": "fix(qwen2vl): make Qwen2VLImageProcessor respect config['size'], align with fast version (#43095)\n\n* fix(qwen2vl): make Qwen2VLImageProcessor respect config['size'], align with Fast version\\n\\n修复：https://github.com/huggingface/transformers/issues/42910\\nQwen2VLImageProcessor 不再覆盖 config[\"size\"]，一致性对齐 Fast 处理，确保 Qwen3VL 正常。\n\n* fix(imageprocessor): make PaddleOCRVL, Video-LLaMA3 ImageProcessor respect config['size']\\n\\n和Qwen2VL处理方式保持一致，避免覆盖用户model config设定，提高一致性。参考 #42910",
    "sha": "b19834d8352ccd6bb34e280f94d376e2bfd3bf40",
    "files": [
        {
            "sha": "859e6cf185d7da0ffb84a0e8671c9200325edee8",
            "filename": "src/transformers/models/paddleocr_vl/image_processing_paddleocr_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fpaddleocr_vl%2Fimage_processing_paddleocr_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fpaddleocr_vl%2Fimage_processing_paddleocr_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaddleocr_vl%2Fimage_processing_paddleocr_vl.py?ref=b19834d8352ccd6bb34e280f94d376e2bfd3bf40",
            "patch": "@@ -165,8 +165,9 @@ def __init__(\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n-        if size is not None and (\"shortest_edge\" not in size or \"longest_edge\" not in size):\n-            raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n+        if size is not None:\n+            if \"shortest_edge\" not in size or \"longest_edge\" not in size:\n+                raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n         else:\n             size = {\"shortest_edge\": 56 * 56, \"longest_edge\": 28 * 28 * 1280}\n         # backward compatibility: override size with min_pixels and max_pixels if they are provided"
        },
        {
            "sha": "310fbf05b023dc8cacd8c3a5e1e72cea9b98fc8c",
            "filename": "src/transformers/models/qwen2_vl/image_processing_qwen2_vl.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fimage_processing_qwen2_vl.py?ref=b19834d8352ccd6bb34e280f94d376e2bfd3bf40",
            "patch": "@@ -159,8 +159,9 @@ def __init__(\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n-        if size is not None and (\"shortest_edge\" not in size or \"longest_edge\" not in size):\n-            raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n+        if size is not None:\n+            if \"shortest_edge\" not in size or \"longest_edge\" not in size:\n+                raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n         else:\n             size = {\"shortest_edge\": 56 * 56, \"longest_edge\": 28 * 28 * 1280}\n         # backward compatibility: override size with min_pixels and max_pixels if they are provided"
        },
        {
            "sha": "e84163cb36a7cdf71111d6b57db1f901b8d30ad3",
            "filename": "src/transformers/models/video_llama_3/image_processing_video_llama_3.py",
            "status": "modified",
            "additions": 3,
            "deletions": 2,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fvideo_llama_3%2Fimage_processing_video_llama_3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/b19834d8352ccd6bb34e280f94d376e2bfd3bf40/src%2Ftransformers%2Fmodels%2Fvideo_llama_3%2Fimage_processing_video_llama_3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llama_3%2Fimage_processing_video_llama_3.py?ref=b19834d8352ccd6bb34e280f94d376e2bfd3bf40",
            "patch": "@@ -154,8 +154,9 @@ def __init__(\n         **kwargs,\n     ) -> None:\n         super().__init__(**kwargs)\n-        if size is not None and (\"shortest_edge\" not in size or \"longest_edge\" not in size):\n-            raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n+        if size is not None:\n+            if \"shortest_edge\" not in size or \"longest_edge\" not in size:\n+                raise ValueError(\"size must contain 'shortest_edge' and 'longest_edge' keys.\")\n         else:\n             size = {\"shortest_edge\": 56 * 56, \"longest_edge\": 28 * 28 * 1280}\n         # backward compatibility: override size with min_pixels and max_pixels if they are provided"
        }
    ],
    "stats": {
        "total": 15,
        "additions": 9,
        "deletions": 6
    }
}