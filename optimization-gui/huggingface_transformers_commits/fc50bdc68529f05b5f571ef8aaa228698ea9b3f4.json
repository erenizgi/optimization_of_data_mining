{
    "author": "yonigozlan",
    "message": "Remove null values from fast image processors dict (#42780)\n\n* remove null values from saved preporcessor file for fast image processor\n\n* preserve explicit None values != class default\n\n* Fix flava test\n\n* extend to video processor",
    "sha": "fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
    "files": [
        {
            "sha": "3f6f6c82b3fce37f04429c041443b0bd17307227",
            "filename": "src/transformers/image_processing_utils_fast.py",
            "status": "modified",
            "additions": 15,
            "deletions": 3,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/src%2Ftransformers%2Fimage_processing_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fimage_processing_utils_fast.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -936,6 +936,18 @@ def _preprocess(\n \n     def to_dict(self):\n         encoder_dict = super().to_dict()\n-        encoder_dict.pop(\"_valid_processor_keys\", None)\n-        encoder_dict.pop(\"_valid_kwargs_names\", None)\n-        return encoder_dict\n+\n+        # Filter out None values that are class defaults, but preserve explicitly set None values\n+        filtered_dict = {}\n+        for key, value in encoder_dict.items():\n+            if value is None:\n+                class_default = getattr(type(self), key, \"NOT_FOUND\")\n+                # Keep None if user explicitly set it (class default is non-None)\n+                if class_default != \"NOT_FOUND\" and class_default is not None:\n+                    filtered_dict[key] = value\n+            else:\n+                filtered_dict[key] = value\n+\n+        filtered_dict.pop(\"_valid_processor_keys\", None)\n+        filtered_dict.pop(\"_valid_kwargs_names\", None)\n+        return filtered_dict"
        },
        {
            "sha": "07ef315062393def27711321466c96c1767b9d6b",
            "filename": "src/transformers/video_processing_utils.py",
            "status": "modified",
            "additions": 14,
            "deletions": 4,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/src%2Ftransformers%2Fvideo_processing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/src%2Ftransformers%2Fvideo_processing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fvideo_processing_utils.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -770,11 +770,21 @@ def to_dict(self) -> dict[str, Any]:\n             `dict[str, Any]`: Dictionary of all the attributes that make up this video processor instance.\n         \"\"\"\n         output = deepcopy(self.__dict__)\n-        output.pop(\"model_valid_processing_keys\", None)\n-        output.pop(\"_valid_kwargs_names\", None)\n-        output[\"video_processor_type\"] = self.__class__.__name__\n+        filtered_dict = {}\n+        for key, value in output.items():\n+            if value is None:\n+                class_default = getattr(type(self), key, \"NOT_FOUND\")\n+                # Keep None if user explicitly set it (class default is non-None)\n+                if class_default != \"NOT_FOUND\" and class_default is not None:\n+                    filtered_dict[key] = value\n+            else:\n+                filtered_dict[key] = value\n+\n+        filtered_dict.pop(\"model_valid_processing_keys\", None)\n+        filtered_dict.pop(\"_valid_kwargs_names\", None)\n+        filtered_dict[\"video_processor_type\"] = self.__class__.__name__\n \n-        return output\n+        return filtered_dict\n \n     def to_json_string(self) -> str:\n         \"\"\""
        },
        {
            "sha": "fb04e3f65d7ab10c8f015b38a880c98a0c18b35f",
            "filename": "tests/models/flava/test_image_processing_flava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Fmodels%2Fflava%2Ftest_image_processing_flava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Fmodels%2Fflava%2Ftest_image_processing_flava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fflava%2Ftest_image_processing_flava.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -66,7 +66,6 @@ def __init__(\n         image_std=FLAVA_IMAGE_STD,\n         input_size_patches=14,\n         total_mask_patches=75,\n-        mask_group_max_patches=None,\n         mask_group_min_patches=16,\n         mask_group_min_aspect_ratio=0.3,\n         mask_group_max_aspect_ratio=None,\n@@ -103,7 +102,6 @@ def __init__(\n \n         self.input_size_patches = input_size_patches\n         self.total_mask_patches = total_mask_patches\n-        self.mask_group_max_patches = mask_group_max_patches\n         self.mask_group_min_patches = mask_group_min_patches\n         self.mask_group_min_aspect_ratio = mask_group_min_aspect_ratio\n         self.mask_group_max_aspect_ratio = mask_group_max_aspect_ratio\n@@ -133,7 +131,6 @@ def prepare_image_processor_dict(self):\n             \"crop_size\": self.crop_size,\n             \"input_size_patches\": self.input_size_patches,\n             \"total_mask_patches\": self.total_mask_patches,\n-            \"mask_group_max_patches\": self.mask_group_max_patches,\n             \"mask_group_min_patches\": self.mask_group_min_patches,\n             \"mask_group_min_aspect_ratio\": self.mask_group_min_aspect_ratio,\n             \"mask_group_max_aspect_ratio\": self.mask_group_min_aspect_ratio,"
        },
        {
            "sha": "320020ff90ea9850a2ea8300b3ef4fac9263afbf",
            "filename": "tests/models/mask2former/test_image_processing_mask2former.py",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Fmodels%2Fmask2former%2Ftest_image_processing_mask2former.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Fmodels%2Fmask2former%2Ftest_image_processing_mask2former.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmask2former%2Ftest_image_processing_mask2former.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -57,7 +57,6 @@ def __init__(\n         num_labels=10,\n         do_reduce_labels=True,\n         ignore_index=255,\n-        pad_size=None,\n     ):\n         self.parent = parent\n         self.batch_size = batch_size\n@@ -70,7 +69,6 @@ def __init__(\n         self.image_mean = image_mean\n         self.image_std = image_std\n         self.size_divisor = 0\n-        self.pad_size = pad_size\n         # for the post_process_functions\n         self.batch_size = 2\n         self.num_queries = 3\n@@ -92,7 +90,6 @@ def prepare_image_processor_dict(self):\n             \"num_labels\": self.num_labels,\n             \"do_reduce_labels\": self.do_reduce_labels,\n             \"ignore_index\": self.ignore_index,\n-            \"pad_size\": self.pad_size,\n         }\n \n     def get_expected_values(self, image_inputs, batched=False):"
        },
        {
            "sha": "9a7f0996bf01566e340cdaeefffdbb9efa2c321a",
            "filename": "tests/test_image_processing_common.py",
            "status": "modified",
            "additions": 37,
            "deletions": 4,
            "changes": 41,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Ftest_image_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Ftest_image_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_image_processing_common.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -341,9 +341,10 @@ def test_save_load_fast_slow(self):\n         }\n         dict_fast_0 = {key: dict_fast_0[key] for key in set(dict_fast_0) & set(dict_fast_1)}\n         dict_fast_1 = {key: dict_fast_1[key] for key in set(dict_fast_0) & set(dict_fast_1)}\n-        # check that all additional keys are None, except for `default_to_square` and `data_format` which are only set in fast processors\n+        # Fast processors filter None values from to_dict(), so differences should only be special keys\n         self.assertTrue(\n-            all(value is None for key, value in difference.items() if key not in [\"default_to_square\", \"data_format\"])\n+            all(key in [\"default_to_square\", \"data_format\"] for key in difference.keys()),\n+            f\"Fast processors should only differ in special keys, found: {list(difference.keys())}\",\n         )\n         # check that the remaining keys are the same\n         self.assertEqual(dict_fast_0, dict_fast_1)\n@@ -391,9 +392,10 @@ def test_save_load_fast_slow_auto(self):\n         }\n         dict_fast_0 = {key: dict_fast_0[key] for key in set(dict_fast_0) & set(dict_fast_1)}\n         dict_fast_1 = {key: dict_fast_1[key] for key in set(dict_fast_0) & set(dict_fast_1)}\n-        # check that all additional keys are None, except for `default_to_square` and `data_format` which are only set in fast processors\n+        # Fast processors filter None values from to_dict(), so differences should only be special keys\n         self.assertTrue(\n-            all(value is None for key, value in difference.items() if key not in [\"default_to_square\", \"data_format\"])\n+            all(key in [\"default_to_square\", \"data_format\"] for key in difference.keys()),\n+            f\"Fast processors should only differ in special keys, found: {list(difference.keys())}\",\n         )\n         # check that the remaining keys are the same\n         self.assertEqual(dict_fast_0, dict_fast_1)\n@@ -693,6 +695,37 @@ def _is_old_model_by_commit_date(model_type, date_cutoff=(2025, 9, 1)):\n             f\"a fast image processor implementation. Please implement the corresponding fast processor.\",\n         )\n \n+    def test_fast_image_processor_explicit_none_preserved(self):\n+        \"\"\"Test that explicitly setting an attribute to None is preserved through save/load.\"\"\"\n+        if self.fast_image_processing_class is None:\n+            self.skipTest(\"Skipping test as fast image processor is not defined\")\n+\n+        # Find an attribute with a non-None class default to test explicit None override\n+        test_attr = None\n+        for attr in [\"do_resize\", \"do_rescale\", \"do_normalize\"]:\n+            if getattr(self.fast_image_processing_class, attr, None) is not None:\n+                test_attr = attr\n+                break\n+\n+        if test_attr is None:\n+            self.skipTest(\"Could not find a suitable attribute to test\")\n+\n+        # Create processor with explicit None (override the attribute)\n+        kwargs = self.image_processor_dict.copy()\n+        kwargs[test_attr] = None\n+        image_processor = self.fast_image_processing_class(**kwargs)\n+\n+        # Verify it's in to_dict() as None (not filtered out)\n+        self.assertIn(test_attr, image_processor.to_dict())\n+        self.assertIsNone(image_processor.to_dict()[test_attr])\n+\n+        # Verify explicit None survives save/load cycle\n+        with tempfile.TemporaryDirectory() as tmpdirname:\n+            image_processor.save_pretrained(tmpdirname)\n+            reloaded = self.fast_image_processing_class.from_pretrained(tmpdirname)\n+\n+        self.assertIsNone(getattr(reloaded, test_attr), f\"Explicit None for {test_attr} was lost after reload\")\n+\n \n class AnnotationFormatTestMixin:\n     # this mixin adds a test to assert that usages of the"
        },
        {
            "sha": "b2faa846204ad94eb5015d92ebb39a03f3120998",
            "filename": "tests/test_video_processing_common.py",
            "status": "modified",
            "additions": 29,
            "deletions": 0,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Ftest_video_processing_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fc50bdc68529f05b5f571ef8aaa228698ea9b3f4/tests%2Ftest_video_processing_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_video_processing_common.py?ref=fc50bdc68529f05b5f571ef8aaa228698ea9b3f4",
            "patch": "@@ -167,6 +167,35 @@ def test_init_without_params(self):\n             video_processor = video_processing_class()\n             self.assertIsNotNone(video_processor)\n \n+    def test_video_processor_explicit_none_preserved(self):\n+        \"\"\"Test that explicitly setting an attribute to None is preserved through save/load.\"\"\"\n+\n+        # Find an attribute with a non-None class default to test explicit None override\n+        test_attr = None\n+        for attr in [\"do_resize\", \"do_rescale\", \"do_normalize\"]:\n+            if getattr(self.fast_video_processing_class, attr, None) is not None:\n+                test_attr = attr\n+                break\n+\n+        if test_attr is None:\n+            self.skipTest(\"Could not find a suitable attribute to test\")\n+\n+        # Create processor with explicit None (override the attribute)\n+        kwargs = self.video_processor_dict.copy()\n+        kwargs[test_attr] = None\n+        video_processor = self.fast_video_processing_class(**kwargs)\n+\n+        # Verify it's in to_dict() as None (not filtered out)\n+        self.assertIn(test_attr, video_processor.to_dict())\n+        self.assertIsNone(video_processor.to_dict()[test_attr])\n+\n+        # Verify explicit None survives save/load cycle\n+        with tempfile.TemporaryDirectory() as tmpdirname:\n+            video_processor.save_pretrained(tmpdirname)\n+            reloaded = self.fast_video_processing_class.from_pretrained(tmpdirname)\n+\n+        self.assertIsNone(getattr(reloaded, test_attr), f\"Explicit None for {test_attr} was lost after reload\")\n+\n     @slow\n     @require_torch_accelerator\n     @require_vision"
        }
    ],
    "stats": {
        "total": 112,
        "additions": 95,
        "deletions": 17
    }
}