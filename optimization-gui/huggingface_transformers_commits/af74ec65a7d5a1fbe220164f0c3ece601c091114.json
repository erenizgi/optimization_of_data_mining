{
    "author": "eromomon",
    "message": "Update Readme to Run Multiple Choice Script from Example Directory (#39323)\n\n* Update Readme to run in current place\n\n* Update Readme files to execute PyTorch examples from their respective folders",
    "sha": "af74ec65a7d5a1fbe220164f0c3ece601c091114",
    "files": [
        {
            "sha": "9022fdb5702693bdd1e8eb4eeb0e86f7a917aec4",
            "filename": "examples/pytorch/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2FREADME.md?ref=af74ec65a7d5a1fbe220164f0c3ece601c091114",
            "patch": "@@ -65,7 +65,7 @@ examples/pytorch/token-classification/run_ner.py \\\n \n Most example scripts should have the first two command line arguments and some have the third one. You can quickly check if a given example supports any of these by passing a `-h` option, e.g.:\n ```bash\n-examples/pytorch/token-classification/run_ner.py -h\n+token-classification/run_ner.py -h\n ```\n \n ## Resuming training\n@@ -110,7 +110,7 @@ classification MNLI task using the `run_glue` script, with 8 GPUs:\n \n ```bash\n torchrun \\\n-    --nproc_per_node 8 pytorch/text-classification/run_glue.py \\\n+    --nproc_per_node 8 text-classification/run_glue.py \\\n     --model_name_or_path google-bert/bert-large-uncased-whole-word-masking \\\n     --task_name mnli \\\n     --do_train \\"
        },
        {
            "sha": "864a31b60372b020ae01194704e193b8a195e0c4",
            "filename": "examples/pytorch/contrastive-image-text/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fcontrastive-image-text%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fcontrastive-image-text%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fcontrastive-image-text%2FREADME.md?ref=af74ec65a7d5a1fbe220164f0c3ece601c091114",
            "patch": "@@ -84,7 +84,7 @@ loaded using the pre-trained weights.\n Finally, we can run the example script to train the model:\n \n ```bash\n-python examples/pytorch/contrastive-image-text/run_clip.py \\\n+python run_clip.py \\\n     --output_dir ./clip-roberta-finetuned \\\n     --model_name_or_path ./clip-roberta \\\n     --data_dir $PWD/data \\"
        },
        {
            "sha": "71462eecb5685f97d559bd7a07ba95e90b337d63",
            "filename": "examples/pytorch/multiple-choice/README.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fmultiple-choice%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fmultiple-choice%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2FREADME.md?ref=af74ec65a7d5a1fbe220164f0c3ece601c091114",
            "patch": "@@ -21,7 +21,7 @@ limitations under the License.\n `run_swag` allows you to fine-tune any model from our [hub](https://huggingface.co/models) (as long as its architecture as a `ForMultipleChoice` version in the library) on the SWAG dataset or your own csv/jsonlines files as long as they are structured the same way. To make it works on another dataset, you will need to tweak the `preprocess_function` inside the script.\n \n ```bash\n-python examples/pytorch/multiple-choice/run_swag.py \\\n+python run_swag.py \\\n --model_name_or_path FacebookAI/roberta-base \\\n --do_train \\\n --do_eval \\"
        },
        {
            "sha": "26561df242497f2f53c6dafaed0dfb2d9b241ffd",
            "filename": "examples/pytorch/summarization/README.md",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fsummarization%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Fsummarization%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2FREADME.md?ref=af74ec65a7d5a1fbe220164f0c3ece601c091114",
            "patch": "@@ -40,7 +40,7 @@ and you also will find examples of these below.\n \n Here is an example on a summarization task:\n ```bash\n-python examples/pytorch/summarization/run_summarization.py \\\n+python run_summarization.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\\n@@ -64,7 +64,7 @@ And here is how you would use it on your own files, after adjusting the values f\n `--train_file`, `--validation_file`, `--text_column` and `--summary_column` to match your setup:\n \n ```bash\n-python examples/pytorch/summarization/run_summarization.py \\\n+python run_summarization.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\"
        },
        {
            "sha": "4659843c66a134e97cba1dacc9d075f57f0630f5",
            "filename": "examples/pytorch/translation/README.md",
            "status": "modified",
            "additions": 5,
            "deletions": 5,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Ftranslation%2FREADME.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/af74ec65a7d5a1fbe220164f0c3ece601c091114/examples%2Fpytorch%2Ftranslation%2FREADME.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2FREADME.md?ref=af74ec65a7d5a1fbe220164f0c3ece601c091114",
            "patch": "@@ -42,7 +42,7 @@ and you also will find examples of these below.\n Here is an example of a translation fine-tuning with a MarianMT model:\n \n ```bash\n-python examples/pytorch/translation/run_translation.py \\\n+python run_translation.py \\\n     --model_name_or_path Helsinki-NLP/opus-mt-en-ro \\\n     --do_train \\\n     --do_eval \\\n@@ -62,7 +62,7 @@ MBart and some T5 models require special handling.\n T5 models `google-t5/t5-small`, `google-t5/t5-base`, `google-t5/t5-large`, `google-t5/t5-3b` and `google-t5/t5-11b` must use an additional argument: `--source_prefix \"translate {source_lang} to {target_lang}\"`. For example:\n \n ```bash\n-python examples/pytorch/translation/run_translation.py \\\n+python run_translation.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\\n@@ -85,7 +85,7 @@ For the aforementioned group of T5 models it's important to remember that if you\n MBart models require a different format for `--source_lang` and `--target_lang` values, e.g. instead of `en` it expects `en_XX`, for `ro` it expects `ro_RO`. The full MBart specification for language codes can be found [here](https://huggingface.co/facebook/mbart-large-cc25). For example:\n \n ```bash\n-python examples/pytorch/translation/run_translation.py \\\n+python run_translation.py \\\n     --model_name_or_path facebook/mbart-large-en-ro  \\\n     --do_train \\\n     --do_eval \\\n@@ -104,7 +104,7 @@ And here is how you would use the translation finetuning on your own files, afte\n values for the arguments `--train_file`, `--validation_file` to match your setup:\n \n ```bash\n-python examples/pytorch/translation/run_translation.py \\\n+python run_translation.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\\n@@ -133,7 +133,7 @@ Here the languages are Romanian (`ro`) and English (`en`).\n If you want to use a pre-processed dataset that leads to high BLEU scores, but for the `en-de` language pair, you can use `--dataset_name stas/wmt14-en-de-pre-processed`, as following:\n \n ```bash\n-python examples/pytorch/translation/run_translation.py \\\n+python run_translation.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 11,
        "deletions": 11
    }
}