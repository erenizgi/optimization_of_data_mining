{
    "author": "vasqu",
    "message": "[`Tests`] Fix inputs placement (#42963)\n\n* fix\n\n* more careful about the items\n\n* oops\n\n* ...",
    "sha": "007274db0fdd3a723aeb616ca9cfc51684c76cc4",
    "files": [
        {
            "sha": "3d1de0182f9b139bbc29efd59dda9e25f2634501",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 12,
            "deletions": 3,
            "changes": 15,
            "blob_url": "https://github.com/huggingface/transformers/blob/007274db0fdd3a723aeb616ca9cfc51684c76cc4/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/007274db0fdd3a723aeb616ca9cfc51684c76cc4/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=007274db0fdd3a723aeb616ca9cfc51684c76cc4",
            "patch": "@@ -1202,21 +1202,30 @@ def test_all_tensors_are_parameter_or_buffer(self):\n         config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n \n         for model_class in self.all_model_classes:\n-            # apparently this model cannot correctly create its inputs and has to use another function....\n+            # Apparently this model cannot correctly create its inputs and has to use another function....\n             if \"modeling_perceiver.py\" in inspect.getfile(model_class):\n                 _, inputs_dict = self.model_tester.prepare_config_and_inputs_for_model_class(model_class)\n \n             # Initialize the model fully on meta device, then move everything to cpu and run `init_weights`\n             with torch.device(\"meta\"):\n                 model = model_class(copy.deepcopy(config)).eval()\n-            # move everything randomly to cpu\n+            # Move everything randomly to cpu\n             model.to_empty(device=\"cpu\")\n             # Now, run all the inits\n             model.init_weights()\n \n+            # Prepare inputs to correct device\n+            inputs = self._prepare_for_class(inputs_dict, model_class)\n+            final_inputs = {}\n+            for k, v in inputs.items():\n+                if isinstance(v, torch.Tensor):\n+                    final_inputs[k] = v.to(device=\"cpu\")\n+                else:\n+                    final_inputs[k] = v\n+\n             # Try running a forward, to see if a tensor stayed on meta somewhere\n             try:\n-                _ = model(**self._prepare_for_class(inputs_dict, model_class))\n+                _ = model(**final_inputs)\n             except (RuntimeError, NotImplementedError) as e:\n                 # Re-raise a more friendly exception (unfortunately, we cannot know which tensor it was...)\n                 if \"Cannot copy out of meta tensor; no data!\" in str("
        }
    ],
    "stats": {
        "total": 15,
        "additions": 12,
        "deletions": 3
    }
}