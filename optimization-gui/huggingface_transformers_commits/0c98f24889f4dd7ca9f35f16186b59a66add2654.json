{
    "author": "kallewoof",
    "message": "fix: add __bool__ operator to tokenizer to avoid bloated asserts (#38899)\n\n* fix: add __bool__ operator to tokenizer to avoid bloated asserts\n\nWhen a user does 'assert tokenizer' to ensure that the tokenizer is not None, they inadvertently set off a rather expensive process in the '__len__()' operator. This fix adds a trivial '__bool__()' that returns True, so that a None tokenizer asserts and an actual tokenizer returns True when asserted, without calling length op.\n\n* typo",
    "sha": "0c98f24889f4dd7ca9f35f16186b59a66add2654",
    "files": [
        {
            "sha": "3fecfa0e1dd3ed56d07224dddbb5be5390b16891",
            "filename": "src/transformers/tokenization_utils_fast.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/0c98f24889f4dd7ca9f35f16186b59a66add2654/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0c98f24889f4dd7ca9f35f16186b59a66add2654/src%2Ftransformers%2Ftokenization_utils_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_fast.py?ref=0c98f24889f4dd7ca9f35f16186b59a66add2654",
            "patch": "@@ -278,6 +278,12 @@ def get_added_vocab(self) -> dict[str, int]:\n         \"\"\"\n         return {k.content: v for v, k in sorted(self.added_tokens_decoder.items(), key=lambda item: item[0])}\n \n+    def __bool__(self) -> bool:\n+        \"\"\"\n+        Returns True, to avoid expensive `assert tokenizer` gotchas.\n+        \"\"\"\n+        return True\n+\n     def __len__(self) -> int:\n         \"\"\"\n         Size of the full vocabulary with the added tokens."
        }
    ],
    "stats": {
        "total": 6,
        "additions": 6,
        "deletions": 0
    }
}