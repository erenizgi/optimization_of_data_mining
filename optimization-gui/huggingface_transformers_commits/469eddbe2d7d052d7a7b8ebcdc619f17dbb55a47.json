{
    "author": "ydshieh",
    "message": "Fix `check_training_gradient_checkpointing` (#34806)\n\nfix\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "469eddbe2d7d052d7a7b8ebcdc619f17dbb55a47",
    "files": [
        {
            "sha": "4cfc91aade282530f389548e3a4881012daf30ba",
            "filename": "tests/test_modeling_common.py",
            "status": "modified",
            "additions": 3,
            "deletions": 1,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/469eddbe2d7d052d7a7b8ebcdc619f17dbb55a47/tests%2Ftest_modeling_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/469eddbe2d7d052d7a7b8ebcdc619f17dbb55a47/tests%2Ftest_modeling_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_modeling_common.py?ref=469eddbe2d7d052d7a7b8ebcdc619f17dbb55a47",
            "patch": "@@ -847,7 +847,9 @@ def check_training_gradient_checkpointing(self, gradient_checkpointing_kwargs=No\n                     ]\n                     or not model_class.supports_gradient_checkpointing\n                 ):\n-                    self.skipTest(reason=f\"`supports_gradient_checkpointing` is False for {model_class.__name__}.\")\n+                    # TODO (ydshieh): use `skipTest` once pytest-dev/pytest-subtests/pull/169 is merged\n+                    # self.skipTest(reason=f\"`supports_gradient_checkpointing` is False for {model_class.__name__}.\")\n+                    continue\n \n                 config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()\n                 config.use_cache = False"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 3,
        "deletions": 1
    }
}