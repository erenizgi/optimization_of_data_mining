{
    "author": "jackzhxng",
    "message": "Standardize audio embedding function name for audio multimodal models (#40919)\n\n* Standardize audio embedding function name for audio multimodal models\n\n* PR review",
    "sha": "3bb1b4867cbb047517abb1be68fb55493b346f08",
    "files": [
        {
            "sha": "15ef9e541c0b9f17e395fe964d367b3a6fc538ec",
            "filename": "src/transformers/models/voxtral/modeling_voxtral.py",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/3bb1b4867cbb047517abb1be68fb55493b346f08/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3bb1b4867cbb047517abb1be68fb55493b346f08/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodeling_voxtral.py?ref=3bb1b4867cbb047517abb1be68fb55493b346f08",
            "patch": "@@ -20,6 +20,7 @@\n # limitations under the License.\n \n import math\n+import warnings\n from typing import Callable, Optional, Union\n \n import torch\n@@ -431,7 +432,7 @@ def set_decoder(self, decoder):\n     def get_decoder(self):\n         return self.language_model.get_decoder()\n \n-    def get_audio_embeds(self, input_features: torch.FloatTensor):\n+    def get_audio_features(self, input_features: torch.FloatTensor):\n         \"\"\"\n         This method is used to get the audio embeddings from input features (a log mel spectrogram), meaning inferring the audio encoder and the multi-modal projector.\n         Args:\n@@ -452,6 +453,12 @@ def get_audio_embeds(self, input_features: torch.FloatTensor):\n         audio_embeds = self.multi_modal_projector(audio_hidden_states)\n         return audio_embeds\n \n+    def get_audio_embeds(self, input_features: torch.FloatTensor):\n+        warnings.warn(\n+            \"The method `get_audio_embeds` is deprecated. Please use `get_audio_features` instead.\", FutureWarning\n+        )\n+        return self.get_audio_features(input_features)\n+\n     @can_return_tuple\n     @auto_docstring\n     def forward(\n@@ -505,7 +512,7 @@ def forward(\n             inputs_embeds = self.get_input_embeddings()(input_ids)\n \n         if input_features is not None and input_ids is not None:\n-            audio_embeds = self.get_audio_embeds(input_features)\n+            audio_embeds = self.get_audio_features(input_features)\n \n             # replace text-audio token placeholders with audio embeddings\n             audio_token_mask = (input_ids == self.config.audio_token_id).unsqueeze(-1)"
        },
        {
            "sha": "c02e8ec5886488aa48553513016ee7404565174e",
            "filename": "src/transformers/models/voxtral/modular_voxtral.py",
            "status": "modified",
            "additions": 9,
            "deletions": 2,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/3bb1b4867cbb047517abb1be68fb55493b346f08/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3bb1b4867cbb047517abb1be68fb55493b346f08/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvoxtral%2Fmodular_voxtral.py?ref=3bb1b4867cbb047517abb1be68fb55493b346f08",
            "patch": "@@ -13,6 +13,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n \n+import warnings\n from typing import Optional, Union\n \n import torch\n@@ -166,7 +167,7 @@ def set_decoder(self, decoder):\n     def get_decoder(self):\n         return self.language_model.get_decoder()\n \n-    def get_audio_embeds(self, input_features: torch.FloatTensor):\n+    def get_audio_features(self, input_features: torch.FloatTensor):\n         \"\"\"\n         This method is used to get the audio embeddings from input features (a log mel spectrogram), meaning inferring the audio encoder and the multi-modal projector.\n         Args:\n@@ -187,6 +188,12 @@ def get_audio_embeds(self, input_features: torch.FloatTensor):\n         audio_embeds = self.multi_modal_projector(audio_hidden_states)\n         return audio_embeds\n \n+    def get_audio_embeds(self, input_features: torch.FloatTensor):\n+        warnings.warn(\n+            \"The method `get_audio_embeds` is deprecated. Please use `get_audio_features` instead.\", FutureWarning\n+        )\n+        return self.get_audio_features(input_features)\n+\n     @can_return_tuple\n     @auto_docstring\n     def forward(\n@@ -240,7 +247,7 @@ def forward(\n             inputs_embeds = self.get_input_embeddings()(input_ids)\n \n         if input_features is not None and input_ids is not None:\n-            audio_embeds = self.get_audio_embeds(input_features)\n+            audio_embeds = self.get_audio_features(input_features)\n \n             # replace text-audio token placeholders with audio embeddings\n             audio_token_mask = (input_ids == self.config.audio_token_id).unsqueeze(-1)"
        }
    ],
    "stats": {
        "total": 22,
        "additions": 18,
        "deletions": 4
    }
}