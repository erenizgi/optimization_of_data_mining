{
    "author": "ivarflakstad",
    "message": "Expectations test utils (#36569)\n\n* Add expectation classes + tests\n\n* Use typing Union instead of |\n\n* Use bits to track score in properties cmp method\n\n* Add exceptions and tests + comments\n\n* Remove compute cap minor as it is not needed currently\n\n* Simplify. Remove Properties class\n\n* Add example Exceptions usage\n\n* Expectations as dict subclass\n\n* Update example Exceptions usage\n\n* Refactor. Improve type name. Document score fn.\n\n* Rename to DeviceProperties.",
    "sha": "706703bba6c920b10aa7e7ee8163b06a8a03c450",
    "files": [
        {
            "sha": "e2811ae9f108634514d5c7e849fef24dd2796110",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 78,
            "deletions": 3,
            "changes": 81,
            "blob_url": "https://github.com/huggingface/transformers/blob/706703bba6c920b10aa7e7ee8163b06a8a03c450/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/706703bba6c920b10aa7e7ee8163b06a8a03c450/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=706703bba6c920b10aa7e7ee8163b06a8a03c450",
            "patch": "@@ -32,13 +32,13 @@\n import threading\n import time\n import unittest\n-from collections import defaultdict\n+from collections import UserDict, defaultdict\n from collections.abc import Mapping\n from dataclasses import MISSING, fields\n-from functools import wraps\n+from functools import cache, wraps\n from io import StringIO\n from pathlib import Path\n-from typing import Callable, Dict, Generator, Iterable, Iterator, List, Optional, Union\n+from typing import Any, Callable, Dict, Generator, Iterable, Iterator, List, Optional, Union\n from unittest import mock\n from unittest.mock import patch\n \n@@ -3042,3 +3042,78 @@ def cleanup(device: str, gc_collect=False):\n     if gc_collect:\n         gc.collect()\n     backend_empty_cache(device)\n+\n+\n+# Type definition of key used in `Expectations` class.\n+DeviceProperties = tuple[Union[str, None], Union[int, None]]\n+\n+\n+@cache\n+def get_device_properties(self) -> DeviceProperties:\n+    \"\"\"\n+    Get environment device properties.\n+    \"\"\"\n+    if IS_CUDA_SYSTEM or IS_ROCM_SYSTEM:\n+        import torch\n+\n+        major, _ = torch.cuda.get_device_capability()\n+        if IS_ROCM_SYSTEM:\n+            return (\"rocm\", major)\n+        else:\n+            return (\"cuda\", major)\n+    else:\n+        return (torch_device, None)\n+\n+\n+class Expectations(UserDict[DeviceProperties, Any]):\n+    def get_expectation(self) -> Any:\n+        \"\"\"\n+        Find best matching expectation based on environment device properties.\n+        \"\"\"\n+        return self.find_expectation(get_device_properties())\n+\n+    @staticmethod\n+    def is_default(key: DeviceProperties) -> bool:\n+        return all(p is None for p in key)\n+\n+    @staticmethod\n+    def score(key: DeviceProperties, other: DeviceProperties) -> int:\n+        \"\"\"\n+        Returns score indicating how similar two instances of the `Properties` tuple are.\n+        Points are calculated using bits, but documented as int.\n+        Rules are as follows:\n+            * Matching `type` gives 8 points.\n+            * Semi-matching `type`, for example cuda and rocm, gives 4 points.\n+            * Matching `major` (compute capability major version) gives 2 points.\n+            * Default expectation (if present) gives 1 points.\n+        \"\"\"\n+        (device_type, major) = key\n+        (other_device_type, other_major) = other\n+\n+        score = 0b0\n+        if device_type == other_device_type:\n+            score |= 0b1000\n+        elif device_type in [\"cuda\", \"rocm\"] and other_device_type in [\"cuda\", \"rocm\"]:\n+            score |= 0b100\n+\n+        if major == other_major and other_major is not None:\n+            score |= 0b10\n+\n+        if Expectations.is_default(other):\n+            score |= 0b1\n+\n+        return int(score)\n+\n+    def find_expectation(self, key: DeviceProperties = (None, None)) -> Any:\n+        \"\"\"\n+        Find best matching expectation based on provided device properties.\n+        \"\"\"\n+        (result_key, result) = max(self.data.items(), key=lambda x: Expectations.score(key, x[0]))\n+\n+        if Expectations.score(key, result_key) == 0:\n+            raise ValueError(f\"No matching expectation found for {key}\")\n+\n+        return result\n+\n+    def __repr__(self):\n+        return f\"{self.data}\""
        },
        {
            "sha": "ca0f4c95ff5cb4df24b434837d94489425825eb1",
            "filename": "tests/models/bamba/test_modeling_bamba.py",
            "status": "modified",
            "additions": 15,
            "deletions": 16,
            "changes": 31,
            "blob_url": "https://github.com/huggingface/transformers/blob/706703bba6c920b10aa7e7ee8163b06a8a03c450/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/706703bba6c920b10aa7e7ee8163b06a8a03c450/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbamba%2Ftest_modeling_bamba.py?ref=706703bba6c920b10aa7e7ee8163b06a8a03c450",
            "patch": "@@ -20,12 +20,7 @@\n import pytest\n \n from transformers import AutoTokenizer, BambaConfig, is_torch_available\n-from transformers.testing_utils import (\n-    require_torch,\n-    require_torch_gpu,\n-    slow,\n-    torch_device,\n-)\n+from transformers.testing_utils import Expectations, require_torch, require_torch_gpu, slow, torch_device\n \n from ...generation.test_utils import GenerationTesterMixin\n from ...test_configuration_common import ConfigTester\n@@ -503,15 +498,18 @@ def setUpClass(cls):\n             cls.cuda_compute_capability_major_version = torch.cuda.get_device_capability()[0]\n \n     def test_simple_generate(self):\n-        # Key 9 for MI300, Key 8 for A100/A10, and Key 7 for T4.\n-        #\n-        # Note: Key 9 is currently set for MI300, but may need potential future adjustments for H100s,\n-        # considering differences in hardware processing and potential deviations in generated text.\n-        EXPECTED_TEXTS = {\n-            # 7: \"\",\n-            8: \"<|begin_of_text|>Hey how are you doing on this lovely evening? I hope you are all having a good time.\",\n-            9: \"<|begin_of_text|>Hey how are you doing on this lovely evening? I hope you are doing well. I am here\",\n-        }\n+        expectations = Expectations(\n+            {\n+                (\n+                    \"cuda\",\n+                    8,\n+                ): \"<|begin_of_text|>Hey how are you doing on this lovely evening? I hope you are all having a good time.\",\n+                (\n+                    \"rocm\",\n+                    9,\n+                ): \"<|begin_of_text|>Hey how are you doing on this lovely evening? I hope you are doing well. I am here\",\n+            }\n+        )\n \n         self.model.to(torch_device)\n \n@@ -520,7 +518,8 @@ def test_simple_generate(self):\n         ].to(torch_device)\n         out = self.model.generate(input_ids, do_sample=False, max_new_tokens=10)\n         output_sentence = self.tokenizer.decode(out[0, :])\n-        self.assertEqual(output_sentence, EXPECTED_TEXTS[self.cuda_compute_capability_major_version])\n+        expected = expectations.get_expectation()\n+        self.assertEqual(output_sentence, expected)\n \n         # TODO: there are significant differences in the logits across major cuda versions, which shouldn't exist\n         if self.cuda_compute_capability_major_version == 8:"
        },
        {
            "sha": "b4372d262ed6c41ede8e2f1d258b1eb65fd22ba3",
            "filename": "tests/utils/test_expectations.py",
            "status": "added",
            "additions": 32,
            "deletions": 0,
            "changes": 32,
            "blob_url": "https://github.com/huggingface/transformers/blob/706703bba6c920b10aa7e7ee8163b06a8a03c450/tests%2Futils%2Ftest_expectations.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/706703bba6c920b10aa7e7ee8163b06a8a03c450/tests%2Futils%2Ftest_expectations.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Futils%2Ftest_expectations.py?ref=706703bba6c920b10aa7e7ee8163b06a8a03c450",
            "patch": "@@ -0,0 +1,32 @@\n+import unittest\n+\n+from transformers.testing_utils import Expectations\n+\n+\n+class ExpectationsTest(unittest.TestCase):\n+    def test_expectations(self):\n+        expectations = Expectations(\n+            {\n+                (None, None): 1,\n+                (\"cuda\", 8): 2,\n+                (\"cuda\", 7): 3,\n+                (\"rocm\", 8): 4,\n+                (\"rocm\", None): 5,\n+                (\"cpu\", None): 6,\n+            }\n+        )\n+\n+        def check(value, key):\n+            assert expectations.find_expectation(key) == value\n+\n+        # xpu has no matches so should find default expectation\n+        check(1, (\"xpu\", None))\n+        check(2, (\"cuda\", 8))\n+        check(3, (\"cuda\", 7))\n+        check(4, (\"rocm\", 9))\n+        check(4, (\"rocm\", None))\n+        check(2, (\"cuda\", 2))\n+\n+        expectations = Expectations({(\"cuda\", 8): 1})\n+        with self.assertRaises(ValueError):\n+            expectations.find_expectation((\"xpu\", None))"
        }
    ],
    "stats": {
        "total": 144,
        "additions": 125,
        "deletions": 19
    }
}