{
    "author": "efazal",
    "message": "feat(trainer): Just-in-time (JIT) asynchronous checkpointing using SIGTERM signals (#41723)\n\n* Just-in-time (JIT) asynchronous checkpointing using SIGTERM signals and cuda streams.\n\n* Fix failing ci tests\n\n* Update JIT checkpoint code to remove CUDA streams and async checkpointing. Introduce sentinal file to identify incomplete checkpoints. Update trainer arg doc and tests.\n\n* Fix sentinel file save path to checkpoint folder, update checkpoint related envs with HF_ prefix.\n\n* Refactor JIT checkpoint logic: rename methods and variables for clarity, improve SIGTERM handling, and update related tests.\n\n* Remove support for environment variable overrides in `TrainingArguments` and update related documentation.\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "fda2d7350d717a6feb820065dad91e4302066070",
    "files": [
        {
            "sha": "3ae0c2dc669465cf8e5c9fefa81bf0271222cef0",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 10,
            "deletions": 0,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=fda2d7350d717a6feb820065dad91e4302066070",
            "patch": "@@ -642,6 +642,16 @@ def __init__(\n                 \"You should subclass `Trainer` and override the `create_optimizer_and_scheduler` method.\"\n             )\n         default_callbacks = DEFAULT_CALLBACKS + get_reporting_integration_callbacks(self.args.report_to)\n+\n+        # Add JIT checkpoint callback if enabled\n+        if self.args.enable_jit_checkpoint:\n+            from .trainer_jit_checkpoint import JITCheckpointCallback\n+\n+            jit_callback = JITCheckpointCallback()\n+            default_callbacks = default_callbacks + [jit_callback]\n+            # Set trainer reference for JIT callback after initialization\n+            jit_callback.set_trainer(self)\n+\n         callbacks = default_callbacks if callbacks is None else default_callbacks + callbacks\n         self.callback_handler = CallbackHandler(\n             callbacks, self.model, self.processing_class, self.optimizer, self.lr_scheduler"
        },
        {
            "sha": "5a5c948fc2a332d14d3033e284b9b3fd6aa74b0d",
            "filename": "src/transformers/trainer_jit_checkpoint.py",
            "status": "added",
            "additions": 126,
            "deletions": 0,
            "changes": 126,
            "blob_url": "https://github.com/huggingface/transformers/blob/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftrainer_jit_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftrainer_jit_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_jit_checkpoint.py?ref=fda2d7350d717a6feb820065dad91e4302066070",
            "patch": "@@ -0,0 +1,126 @@\n+import os\n+import signal\n+import threading\n+from typing import Optional\n+\n+from .trainer_callback import TrainerCallback\n+from .trainer_utils import PREFIX_CHECKPOINT_DIR\n+from .utils import logging\n+\n+\n+logger = logging.get_logger(__name__)\n+\n+\n+class CheckpointManager:\n+    def __init__(self, trainer, kill_wait: int = 3):\n+        \"\"\"\n+        Initialize the CheckpointManager for Just-In-Time checkpoint handling.\n+\n+        Args:\n+            trainer: The Trainer instance that will be used to save checkpoints when SIGTERM is received.\n+            kill_wait (`int`, *optional*, defaults to 3): Grace period to distinguish between SIGTERM and SIGKILL.\n+        \"\"\"\n+        self.trainer = trainer\n+        self.is_checkpoint_requested = False\n+        self._original_sigterm_handler = None\n+        self.kill_wait = kill_wait\n+\n+    def setup_signal_handler(self):\n+        self._original_sigterm_handler = signal.signal(signal.SIGTERM, self._sigterm_handler)\n+        logger.info(\"JIT checkpoint signal handler registered for SIGTERM\")\n+\n+    def _sigterm_handler(self, signum, frame):\n+        if self.is_checkpoint_requested:\n+            return\n+\n+        logger.info(f\"SIGTERM received, will request JIT checkpoint after {self.kill_wait}s\")\n+        threading.Timer(self.kill_wait, self._enable_checkpoint).start()\n+\n+    def _enable_checkpoint(self):\n+        logger.info(\"Kill wait period elapsed, requesting checkpoint\")\n+        self.is_checkpoint_requested = True\n+\n+    def execute_jit_checkpoint(self):\n+        try:\n+            # Set checkpoint flag to False to avoid multiple checkpoints getting triggered by other callbacks\n+            self.is_checkpoint_requested = False\n+\n+            logger.info(\"Starting JIT checkpointing...\")\n+            current_step = self.trainer.state.global_step\n+            logger.info(f\"Saving JIT checkpoint at step {current_step}\")\n+\n+            output_dir = self.trainer._get_output_dir(trial=None)\n+            checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-{current_step}\"\n+            checkpoint_path = os.path.join(output_dir, checkpoint_folder)\n+\n+            # Create checkpoint directory\n+            os.makedirs(checkpoint_path, exist_ok=True)\n+\n+            # Create a sentinel file to indicate checkpointing is in progress\n+            sentinel_file = os.path.join(output_dir, checkpoint_folder, \"checkpoint-is-incomplete.txt\")\n+            with open(sentinel_file, \"w\") as f:\n+                f.write(f\"Checkpoint started at step {current_step} and in progress...\")\n+            logger.info(f\"Created checkpoint progress sentinel marker file: {sentinel_file}\")\n+\n+            # Invoke the trainer's checkpoint method directly\n+            self.trainer._save_checkpoint(self.trainer.model, trial=None)\n+\n+            # Remove sentinel file upon successful checkpointing\n+            if os.path.exists(sentinel_file):\n+                os.remove(sentinel_file)\n+                logger.info(\"Sentinel marker file removed\")\n+\n+            logger.info(\"Immediate JIT checkpoint completed successfully\")\n+\n+        except Exception as e:\n+            logger.error(f\"Failed to save JIT checkpoint: {e}\")\n+            raise\n+\n+\n+class JITCheckpointCallback(TrainerCallback):\n+    \"\"\"\n+    Callback for Just-In-Time checkpointing on SIGTERM signals.\n+\n+    When SIGTERM is received, the checkpoint manager sets `is_checkpoint_requested=True`.\n+    The callbacks detect this flag and set `control.should_training_stop=True`, which signals\n+    the Trainer's training loop to exit gracefully after saving the checkpoint.\n+    \"\"\"\n+\n+    def __init__(self):\n+        self.trainer = None\n+        self.jit_manager: Optional[CheckpointManager] = None\n+\n+    def set_trainer(self, trainer):\n+        self.trainer = trainer\n+        if trainer.args.enable_jit_checkpoint:\n+            self.jit_manager = CheckpointManager(trainer=trainer)\n+            self.jit_manager.setup_signal_handler()\n+            logger.info(\"JIT checkpointing enabled\")\n+\n+    def on_pre_optimizer_step(self, args, state, control, **kwargs):\n+        if self.jit_manager and self.jit_manager.is_checkpoint_requested:\n+            control.should_training_stop = True\n+            self.jit_manager.execute_jit_checkpoint()\n+\n+    def on_step_begin(self, args, state, control, **kwargs):\n+        if self.jit_manager and self.jit_manager.is_checkpoint_requested:\n+            control.should_training_stop = True\n+            self.jit_manager.execute_jit_checkpoint()\n+\n+    def on_step_end(self, args, state, control, **kwargs):\n+        if self.jit_manager and self.jit_manager.is_checkpoint_requested:\n+            control.should_save = False\n+            control.should_training_stop = True\n+            self.jit_manager.execute_jit_checkpoint()\n+\n+    def on_epoch_end(self, args, state, control, **kwargs):\n+        if self.jit_manager and self.jit_manager.is_checkpoint_requested:\n+            control.should_save = False\n+            control.should_training_stop = True\n+            self.jit_manager.execute_jit_checkpoint()\n+\n+    def on_train_end(self, args, state, control, **kwargs):\n+        #  Restore original SIGTERM handler\n+        if self.jit_manager and self.jit_manager._original_sigterm_handler is not None:\n+            signal.signal(signal.SIGTERM, self.jit_manager._original_sigterm_handler)\n+            logger.info(\"Restored original SIGTERM handler after training completion\")"
        },
        {
            "sha": "963bed209ac554888bc65b2e420ac45812c5ab7f",
            "filename": "src/transformers/training_args.py",
            "status": "modified",
            "additions": 28,
            "deletions": 1,
            "changes": 29,
            "blob_url": "https://github.com/huggingface/transformers/blob/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftraining_args.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fda2d7350d717a6feb820065dad91e4302066070/src%2Ftransformers%2Ftraining_args.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftraining_args.py?ref=fda2d7350d717a6feb820065dad91e4302066070",
            "patch": "@@ -340,6 +340,17 @@ class TrainingArguments:\n             `save_total_limit=5` and `load_best_model_at_end`, the four last checkpoints will always be retained\n             alongside the best model. When `save_total_limit=1` and `load_best_model_at_end`, it is possible that two\n             checkpoints are saved: the last one and the best one (if they are different).\n+        enable_jit_checkpoint (`bool`, *optional*, defaults to `False`):\n+            Whether to enable Just-In-Time (JIT) checkpointing on SIGTERM signal. When enabled, training will\n+            checkpoint upon receiving SIGTERM, allowing for graceful termination without losing\n+            progress. This is particularly useful for shared clusters with preemptible workloads (e.g., Kueue).\n+            **Important**: You must configure your orchestrator's graceful shutdown period to allow sufficient time\n+            for checkpoint completion. For Kubernetes, set `terminationGracePeriodSeconds` in your job definition\n+            (method varies by cloud-native trainer: Kubeflow, Ray, etc.). Note: the default is only 30 seconds,\n+            which is typically insufficient. For Slurm, use `--signal=USR1@<seconds>` in your sbatch script to send\n+            SIGTERM with adequate time before the job time limit. Calculate the required grace period as: longest\n+            possible iteration time + checkpoint saving time. For example, if an iteration takes 2 minutes and\n+            checkpoint saving takes 2 minutes, set at least 4 minutes (240 seconds) of grace time.\n         save_safetensors (`bool`, *optional*, defaults to `True`):\n             Use [safetensors](https://huggingface.co/docs/safetensors) saving and loading for state dicts instead of\n             default `torch.load` and `torch.save`.\n@@ -929,7 +940,23 @@ class TrainingArguments:\n                 \" for `save_total_limit=5` and `load_best_model_at_end=True`, the four last checkpoints will always be\"\n                 \" retained alongside the best model. When `save_total_limit=1` and `load_best_model_at_end=True`,\"\n                 \" it is possible that two checkpoints are saved: the last one and the best one (if they are different).\"\n-                \" Default is unlimited checkpoints\"\n+                \" Default is unlimited checkpoints.\"\n+            )\n+        },\n+    )\n+    enable_jit_checkpoint: bool = field(\n+        default=False,\n+        metadata={\n+            \"help\": (\n+                \"Whether to enable Just-In-Time (JIT) checkpointing on SIGTERM signal. \"\n+                \"When enabled, training will checkpoint upon receiving SIGTERM, \"\n+                \"allowing for graceful termination without losing progress. \"\n+                \"This is particularly useful for shared clusters with preemptible workloads (Kueue). \"\n+                \"IMPORTANT: You must configure your orchestrator's graceful shutdown period. \"\n+                \"Kubernetes: set terminationGracePeriodSeconds (default 30s is insufficient!) in your job definition. \"\n+                \"Slurm: use --signal=USR1@<seconds> in sbatch to send SIGTERM before time limit. \"\n+                \"Calculate required grace period as: iteration time + checkpoint saving time. \"\n+                \"Example: 2min iteration + 2min checkpoint = 240 seconds minimum.\"\n             )\n         },\n     )"
        },
        {
            "sha": "4024951ff4dd59ab6b7a9661ba91a9b16f3be00e",
            "filename": "tests/trainer/test_trainer_jit_checkpoint.py",
            "status": "added",
            "additions": 406,
            "deletions": 0,
            "changes": 406,
            "blob_url": "https://github.com/huggingface/transformers/blob/fda2d7350d717a6feb820065dad91e4302066070/tests%2Ftrainer%2Ftest_trainer_jit_checkpoint.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/fda2d7350d717a6feb820065dad91e4302066070/tests%2Ftrainer%2Ftest_trainer_jit_checkpoint.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer_jit_checkpoint.py?ref=fda2d7350d717a6feb820065dad91e4302066070",
            "patch": "@@ -0,0 +1,406 @@\n+# Copyright 2020 The HuggingFace Team. All rights reserved.\n+#\n+# Licensed under the Apache License, Version 2.0 (the \"License\");\n+# you may not use this file except in compliance with the License.\n+# You may obtain a copy of the License at\n+#\n+#     http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+import os\n+import signal\n+import tempfile\n+import unittest\n+from unittest.mock import Mock, patch\n+\n+from transformers import TrainingArguments, is_torch_available\n+from transformers.testing_utils import require_torch\n+\n+\n+if is_torch_available():\n+    from transformers.trainer_jit_checkpoint import CheckpointManager, JITCheckpointCallback\n+\n+    from .test_trainer import RegressionDataset, RegressionModelConfig, RegressionPreTrainedModel\n+\n+\n+@require_torch\n+class JITCheckpointTest(unittest.TestCase):\n+    def setUp(self):\n+        self.test_dir = tempfile.mkdtemp()\n+\n+    def tearDown(self):\n+        import shutil\n+\n+        shutil.rmtree(self.test_dir, ignore_errors=True)\n+\n+    def get_trainer(self, enable_jit=True):\n+        \"\"\"Helper method to create a trainer with JIT checkpointing enabled.\"\"\"\n+        from transformers import Trainer\n+\n+        model_config = RegressionModelConfig(a=1.5, b=2.5)\n+        model = RegressionPreTrainedModel(model_config)\n+\n+        args = TrainingArguments(\n+            output_dir=self.test_dir,\n+            enable_jit_checkpoint=enable_jit,\n+            per_device_train_batch_size=16,\n+            learning_rate=0.1,\n+            logging_steps=1,\n+            num_train_epochs=1,\n+            max_steps=10,\n+            save_steps=10,\n+        )\n+\n+        train_dataset = RegressionDataset(length=64)\n+\n+        return Trainer(model=model, args=args, train_dataset=train_dataset)\n+\n+    def test_checkpoint_manager_initialization(self):\n+        \"\"\"Test CheckpointManager initialization with different configurations.\"\"\"\n+        trainer = self.get_trainer()\n+\n+        # Test with default parameters\n+        manager = CheckpointManager(trainer)\n+        self.assertEqual(manager.trainer, trainer)\n+        self.assertEqual(manager.kill_wait, 3)\n+        self.assertFalse(manager.is_checkpoint_requested)\n+\n+        # Test with custom parameters\n+        manager_custom = CheckpointManager(trainer, kill_wait=5)\n+        self.assertEqual(manager_custom.kill_wait, 5)\n+\n+    def test_signal_handler_setup(self):\n+        \"\"\"Test signal handler setup and restoration.\"\"\"\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer)\n+\n+        # Store original handler\n+        original_handler = signal.signal(signal.SIGTERM, signal.SIG_DFL)\n+\n+        try:\n+            # Setup JIT signal handler\n+            manager.setup_signal_handler()\n+\n+            # Verify handler is set\n+            current_handler = signal.signal(signal.SIGTERM, signal.SIG_DFL)\n+            self.assertNotEqual(current_handler, signal.SIG_DFL)\n+\n+            # Verify original handler is stored\n+            self.assertIsNotNone(manager._original_sigterm_handler)\n+\n+        finally:\n+            # Restore original handler\n+            signal.signal(signal.SIGTERM, original_handler)\n+\n+    @patch(\"threading.Timer\")\n+    def test_sigterm_handler_flow(self, mock_timer):\n+        \"\"\"Test SIGTERM handler execution flow.\"\"\"\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer, kill_wait=2)\n+\n+        # Mock timer to prevent actual threading\n+        mock_timer_instance = Mock()\n+        mock_timer.return_value = mock_timer_instance\n+\n+        # Test first SIGTERM call\n+        self.assertFalse(manager.is_checkpoint_requested)\n+        manager._sigterm_handler(signal.SIGTERM, None)\n+\n+        # Verify checkpoint was NOT immediately requested (timer is used)\n+        self.assertFalse(manager.is_checkpoint_requested)\n+\n+        # Verify timer was created with kill_wait period and correct callback\n+        mock_timer.assert_called_once_with(2, manager._enable_checkpoint)\n+        mock_timer_instance.start.assert_called_once()\n+\n+        # Manually trigger the timer callback to test flag setting\n+        manager._enable_checkpoint()\n+\n+        # Verify checkpoint is now requested\n+        self.assertTrue(manager.is_checkpoint_requested)\n+\n+        # Test second SIGTERM call (should be ignored)\n+        mock_timer.reset_mock()\n+        manager._sigterm_handler(signal.SIGTERM, None)\n+\n+        # Verify no additional timer was created\n+        mock_timer.assert_not_called()\n+\n+    def test_toggle_checkpoint_flag(self):\n+        \"\"\"Test the toggle checkpoint flag method.\"\"\"\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer)\n+\n+        # Initially should not be requested\n+        self.assertFalse(manager.is_checkpoint_requested)\n+\n+        # Toggle flag\n+        manager._enable_checkpoint()\n+\n+        # Should now be requested\n+        self.assertTrue(manager.is_checkpoint_requested)\n+\n+    def test_execute_jit_checkpoint(self):\n+        \"\"\"Test the checkpoint execution logic with sentinel file.\"\"\"\n+        from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n+\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer)\n+\n+        # Mock trainer's save checkpoint method\n+        trainer._save_checkpoint = Mock()\n+        trainer.state.global_step = 42\n+\n+        # Set checkpoint requested flag\n+        manager.is_checkpoint_requested = True\n+\n+        # Execute checkpoint\n+        manager.execute_jit_checkpoint()\n+\n+        # Verify checkpoint was called\n+        trainer._save_checkpoint.assert_called_once_with(trainer.model, trial=None)\n+\n+        # Verify checkpoint flag was reset\n+        self.assertFalse(manager.is_checkpoint_requested)\n+\n+        # Verify sentinel file was removed (should be in checkpoint-42 folder)\n+        checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-42\"\n+        sentinel_file = os.path.join(self.test_dir, checkpoint_folder, \"checkpoint-is-incomplete.txt\")\n+        self.assertFalse(os.path.exists(sentinel_file))\n+\n+    def test_execute_jit_checkpoint_sentinel_file_cleanup(self):\n+        \"\"\"Test that sentinel file is cleaned up after successful checkpoint.\"\"\"\n+        from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n+\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer)\n+\n+        # Mock trainer's save checkpoint method\n+        trainer._save_checkpoint = Mock()\n+        trainer.state.global_step = 42\n+\n+        checkpoint_folder = f\"{PREFIX_CHECKPOINT_DIR}-42\"\n+        sentinel_file = os.path.join(self.test_dir, checkpoint_folder, \"checkpoint-is-incomplete.txt\")\n+\n+        # Execute checkpoint\n+        manager.execute_jit_checkpoint()\n+\n+        # Verify sentinel file doesn't exist after successful checkpoint\n+        self.assertFalse(os.path.exists(sentinel_file))\n+\n+    def test_execute_jit_checkpoint_with_exception(self):\n+        \"\"\"Test checkpoint execution with exception handling.\"\"\"\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer)\n+\n+        # Mock trainer's save checkpoint method to raise exception\n+        trainer._save_checkpoint = Mock(side_effect=Exception(\"Checkpoint failed\"))\n+        trainer.state.global_step = 42\n+\n+        # Test that exception is re-raised\n+        with self.assertRaises(Exception) as context:\n+            manager.execute_jit_checkpoint()\n+\n+        self.assertEqual(str(context.exception), \"Checkpoint failed\")\n+\n+        # Verify checkpoint flag was still reset to avoid multiple attempts\n+        self.assertFalse(manager.is_checkpoint_requested)\n+\n+    def test_jit_checkpoint_callback_initialization(self):\n+        \"\"\"Test JITCheckpointCallback initialization.\"\"\"\n+        callback = JITCheckpointCallback()\n+\n+        self.assertIsNone(callback.trainer)\n+        self.assertIsNone(callback.jit_manager)\n+\n+    def test_jit_checkpoint_callback_set_trainer_enabled(self):\n+        \"\"\"Test setting trainer with JIT checkpointing enabled.\"\"\"\n+        trainer = self.get_trainer(enable_jit=True)\n+        callback = JITCheckpointCallback()\n+\n+        with patch.object(CheckpointManager, \"setup_signal_handler\") as mock_setup:\n+            callback.set_trainer(trainer)\n+\n+            self.assertEqual(callback.trainer, trainer)\n+            self.assertIsNotNone(callback.jit_manager)\n+            self.assertIsInstance(callback.jit_manager, CheckpointManager)\n+            mock_setup.assert_called_once()\n+\n+    def test_jit_checkpoint_callback_set_trainer_disabled(self):\n+        \"\"\"Test setting trainer with JIT checkpointing disabled.\"\"\"\n+        trainer = self.get_trainer(enable_jit=False)\n+        callback = JITCheckpointCallback()\n+\n+        callback.set_trainer(trainer)\n+\n+        self.assertEqual(callback.trainer, trainer)\n+        self.assertIsNone(callback.jit_manager)\n+\n+    def test_jit_checkpoint_callback_on_pre_optimizer_step(self):\n+        \"\"\"Test callback behavior during pre-optimizer step.\"\"\"\n+        trainer = self.get_trainer()\n+        callback = JITCheckpointCallback()\n+        callback.set_trainer(trainer)\n+\n+        # Mock control object\n+        control = Mock()\n+        control.should_training_stop = False\n+\n+        # Mock execute method\n+        with patch.object(callback.jit_manager, \"execute_jit_checkpoint\") as mock_execute:\n+            # Test when checkpoint not requested\n+            callback.jit_manager.is_checkpoint_requested = False\n+            callback.on_pre_optimizer_step(trainer.args, trainer.state, control)\n+            self.assertFalse(control.should_training_stop)\n+            mock_execute.assert_not_called()\n+\n+            # Test when checkpoint requested\n+            callback.jit_manager.is_checkpoint_requested = True\n+            callback.on_pre_optimizer_step(trainer.args, trainer.state, control)\n+            self.assertTrue(control.should_training_stop)\n+            mock_execute.assert_called_once()\n+\n+    def test_jit_checkpoint_callback_on_step_begin(self):\n+        \"\"\"Test callback behavior at step begin.\"\"\"\n+        trainer = self.get_trainer()\n+        callback = JITCheckpointCallback()\n+        callback.set_trainer(trainer)\n+\n+        # Mock control object\n+        control = Mock()\n+        control.should_training_stop = False\n+\n+        # Mock execute method\n+        with patch.object(callback.jit_manager, \"execute_jit_checkpoint\") as mock_execute:\n+            # Test when checkpoint not requested\n+            callback.jit_manager.is_checkpoint_requested = False\n+            callback.on_step_begin(trainer.args, trainer.state, control)\n+            self.assertFalse(control.should_training_stop)\n+            mock_execute.assert_not_called()\n+\n+            # Test when checkpoint requested\n+            callback.jit_manager.is_checkpoint_requested = True\n+            callback.on_step_begin(trainer.args, trainer.state, control)\n+            self.assertTrue(control.should_training_stop)\n+            mock_execute.assert_called_once()\n+\n+    def test_jit_checkpoint_callback_on_step_end(self):\n+        \"\"\"Test callback behavior at step end.\"\"\"\n+        trainer = self.get_trainer()\n+        callback = JITCheckpointCallback()\n+        callback.set_trainer(trainer)\n+\n+        # Mock control object\n+        control = Mock()\n+        control.should_training_stop = False\n+        control.should_save = True\n+\n+        # Mock execute method\n+        with patch.object(callback.jit_manager, \"execute_jit_checkpoint\") as mock_execute:\n+            # Test when checkpoint not requested\n+            callback.jit_manager.is_checkpoint_requested = False\n+            callback.on_step_end(trainer.args, trainer.state, control)\n+            self.assertFalse(control.should_training_stop)\n+            mock_execute.assert_not_called()\n+\n+            # Reset control\n+            control.should_save = True\n+\n+            # Test when checkpoint requested\n+            callback.jit_manager.is_checkpoint_requested = True\n+            callback.on_step_end(trainer.args, trainer.state, control)\n+            self.assertTrue(control.should_training_stop)\n+            self.assertFalse(control.should_save)\n+            mock_execute.assert_called_once()\n+\n+    def test_jit_checkpoint_callback_on_epoch_end(self):\n+        \"\"\"Test callback behavior at epoch end.\"\"\"\n+        trainer = self.get_trainer()\n+        callback = JITCheckpointCallback()\n+        callback.set_trainer(trainer)\n+\n+        # Mock control object\n+        control = Mock()\n+        control.should_save = True\n+        control.should_training_stop = False\n+\n+        # Mock execute method\n+        with patch.object(callback.jit_manager, \"execute_jit_checkpoint\") as mock_execute:\n+            # Test when checkpoint not requested\n+            callback.jit_manager.is_checkpoint_requested = False\n+            callback.on_epoch_end(trainer.args, trainer.state, control)\n+            # should_save should remain unchanged when checkpoint not requested\n+            self.assertTrue(control.should_save)\n+            self.assertFalse(control.should_training_stop)\n+            mock_execute.assert_not_called()\n+\n+            # Reset control\n+            control.should_save = True\n+            control.should_training_stop = False\n+\n+            # Test when checkpoint requested\n+            callback.jit_manager.is_checkpoint_requested = True\n+            callback.on_epoch_end(trainer.args, trainer.state, control)\n+            self.assertFalse(control.should_save)\n+            self.assertTrue(control.should_training_stop)\n+            mock_execute.assert_called_once()\n+\n+    def test_jit_checkpoint_callback_on_train_end(self):\n+        \"\"\"Test signal handler restoration on training end.\"\"\"\n+        trainer = self.get_trainer()\n+        callback = JITCheckpointCallback()\n+\n+        # Store original SIGTERM handler\n+        original_handler = signal.signal(signal.SIGTERM, signal.SIG_DFL)\n+\n+        try:\n+            callback.set_trainer(trainer)\n+\n+            # Verify signal handler was set up\n+            self.assertIsNotNone(callback.jit_manager._original_sigterm_handler)\n+\n+            # Mock control object\n+            control = Mock()\n+\n+            # Call on_train_end\n+            callback.on_train_end(trainer.args, trainer.state, control)\n+\n+            # Verify signal handler was restored\n+            current_handler = signal.signal(signal.SIGTERM, signal.SIG_DFL)\n+            self.assertEqual(current_handler, callback.jit_manager._original_sigterm_handler)\n+\n+        finally:\n+            # Restore original handler for cleanup\n+            signal.signal(signal.SIGTERM, original_handler)\n+\n+    @patch(\"threading.Timer\")\n+    def test_kill_wait_period(self, mock_timer):\n+        \"\"\"Test the kill wait period functionality.\"\"\"\n+        trainer = self.get_trainer()\n+        manager = CheckpointManager(trainer, kill_wait=5)\n+\n+        mock_timer_instance = Mock()\n+        mock_timer.return_value = mock_timer_instance\n+\n+        manager._sigterm_handler(signal.SIGTERM, None)\n+\n+        # Verify Timer was created with the correct kill_wait period and callback\n+        mock_timer.assert_called_once_with(5, manager._enable_checkpoint)\n+        mock_timer_instance.start.assert_called_once()\n+\n+    def test_integration_with_trainer(self):\n+        \"\"\"Test integration of JIT checkpointing with Trainer.\"\"\"\n+        trainer = self.get_trainer(enable_jit=True)\n+\n+        # Check that JIT callback was added\n+        jit_callbacks = [cb for cb in trainer.callback_handler.callbacks if isinstance(cb, JITCheckpointCallback)]\n+        self.assertEqual(len(jit_callbacks), 1)\n+\n+        jit_callback = jit_callbacks[0]\n+        self.assertIsNotNone(jit_callback.jit_manager)\n+        self.assertEqual(jit_callback.trainer, trainer)"
        }
    ],
    "stats": {
        "total": 571,
        "additions": 570,
        "deletions": 1
    }
}