{
    "author": "gante",
    "message": "[Tests] flaky `test_constrained_beam_search_generate_dict_output`  (#37276)",
    "sha": "acbcb5d07d3b771113d115b95e509d77289267ce",
    "files": [
        {
            "sha": "a922f88d7cf8078c3dbbd029820a071fa658b7b1",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/acbcb5d07d3b771113d115b95e509d77289267ce/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/acbcb5d07d3b771113d115b95e509d77289267ce/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=acbcb5d07d3b771113d115b95e509d77289267ce",
            "patch": "@@ -889,8 +889,7 @@ def test_group_beam_search_generate_dict_output(self):\n                 num_beams=beam_kwargs[\"num_beams\"],\n             )\n \n-    # TODO: @gante check why it is flaky\n-    @is_flaky()\n+    @is_flaky()  # Some models have position-specific tokens, this test may try to force them in an invalid position\n     @pytest.mark.generate\n     def test_constrained_beam_search_generate(self):\n         for model_class in self.all_generative_model_classes:\n@@ -947,6 +946,7 @@ def test_constrained_beam_search_generate(self):\n             for generation_output in output_generate:\n                 self._check_sequence_inside_sequence(force_tokens, generation_output)\n \n+    @is_flaky()  # Some models have position-specific tokens, this test may try to force them in an invalid position\n     @pytest.mark.generate\n     def test_constrained_beam_search_generate_dict_output(self):\n         for model_class in self.all_generative_model_classes:"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}