{
    "author": "larin92",
    "message": "Update `trainer._get_eval_sampler()` to support `group_by_length` arg (#33514)\n\nUpdate 'trainer._get_eval_sampler()' to support 'group_by_length' argument\r\n\r\nTrainer didn't support grouping by length for evaluation, which made evaluation slow with 'eval_batch_size'>1.\r\n\r\nUpdated 'trainer._get_eval_sampler()' method was based off of 'trainer._get_train_sampler()'.",
    "sha": "6d2b2033393df0594a5d43ba2aaa9ec9bc46f4e0",
    "files": [
        {
            "sha": "7e4d1e5d267bb8dee13416e0099cb2e471f97040",
            "filename": "src/transformers/trainer.py",
            "status": "modified",
            "additions": 21,
            "deletions": 0,
            "changes": 21,
            "blob_url": "https://github.com/huggingface/transformers/blob/6d2b2033393df0594a5d43ba2aaa9ec9bc46f4e0/src%2Ftransformers%2Ftrainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/6d2b2033393df0594a5d43ba2aaa9ec9bc46f4e0/src%2Ftransformers%2Ftrainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer.py?ref=6d2b2033393df0594a5d43ba2aaa9ec9bc46f4e0",
            "patch": "@@ -959,6 +959,10 @@ def get_train_dataloader(self) -> DataLoader:\n         return self.accelerator.prepare(DataLoader(train_dataset, **dataloader_params))\n \n     def _get_eval_sampler(self, eval_dataset: Dataset) -> Optional[torch.utils.data.Sampler]:\n+        if self.eval_dataset is None or not has_length(self.eval_dataset):\n+            return None\n+        # Build the sampler.\n+\n         # Deprecated code\n         if self.args.use_legacy_prediction_loop:\n             if is_torch_xla_available():\n@@ -975,6 +979,23 @@ def _get_eval_sampler(self, eval_dataset: Dataset) -> Optional[torch.utils.data.\n             else:\n                 return SequentialSampler(eval_dataset)\n \n+        if self.args.group_by_length:\n+            if is_datasets_available() and isinstance(self.eval_dataset, datasets.Dataset):\n+                lengths = (\n+                    self.eval_dataset[self.args.length_column_name]\n+                    if self.args.length_column_name in self.eval_dataset.column_names\n+                    else None\n+                )\n+            else:\n+                lengths = None\n+            model_input_name = self.tokenizer.model_input_names[0] if self.tokenizer is not None else None\n+            return LengthGroupedSampler(\n+                self.args.eval_batch_size,\n+                dataset=self.eval_dataset,\n+                lengths=lengths,\n+                model_input_name=model_input_name,\n+            )\n+\n         if self.args.world_size <= 1:\n             return SequentialSampler(eval_dataset)\n         else:"
        }
    ],
    "stats": {
        "total": 21,
        "additions": 21,
        "deletions": 0
    }
}