{
    "author": "zyfedward",
    "message": "Add GptOssForSequenceClassification for GPT-OSS models (#40043)\n\n* Add GptOssForSequenceClassification\n\n* Tiny fix\n\n* make fixup\n\n* trigger CI rerun\n\n* Check config type instead\n\n---------\n\nCo-authored-by: Yuefeng Zhan <yuefzh@microsoft.com>",
    "sha": "2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
    "files": [
        {
            "sha": "5fa916e64ec3dfa84c983bd2c6d4a97108ca052c",
            "filename": "docs/source/en/model_doc/gpt_oss.md",
            "status": "modified",
            "additions": 5,
            "deletions": 0,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fgpt_oss.md?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -56,3 +56,8 @@ The original code can be found [here](<INSERT LINK TO GITHUB REPO HERE>).\n \n [[autodoc]] GptOssForCausalLM\n     - forward\n+\n+## GptOssForSequenceClassification\n+\n+[[autodoc]] GptOssForSequenceClassification\n+    - forward"
        },
        {
            "sha": "6659b2060c6162d9ce5d11762882071e20f7a0e4",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -891,8 +891,8 @@ def _load_state_dict_into_meta_model(\n                     param_name = hf_quantizer.update_param_name(param_name)\n                     module, param_type = get_module_from_name(model, param_name)\n                     value = getattr(module, param_type)\n-                    # special case for GptOssForCausalLM, we wait for the param to be leave the meta device before casting it to cpu\n-                    if model.__class__.__name__ == \"GptOssForCausalLM\" and value.device.type == \"meta\":\n+                    # special case for gpt_oss model, we wait for the param to be leave the meta device before casting it to cpu\n+                    if model.config.model_type == \"gpt_oss\" and value.device.type == \"meta\":\n                         continue\n                     param_to = \"cpu\"\n                     if is_fsdp_enabled() and not is_local_dist_rank_0():"
        },
        {
            "sha": "ffc0d1deebdd7435f38d0e71caa8c476ad0413a3",
            "filename": "src/transformers/models/auto/modeling_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fmodeling_auto.py?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -1193,6 +1193,7 @@ class _BaseModelWithGenerate(PreTrainedModel, GenerationMixin):\n         (\"gpt_bigcode\", \"GPTBigCodeForSequenceClassification\"),\n         (\"gpt_neo\", \"GPTNeoForSequenceClassification\"),\n         (\"gpt_neox\", \"GPTNeoXForSequenceClassification\"),\n+        (\"gpt_oss\", \"GptOssForSequenceClassification\"),\n         (\"gptj\", \"GPTJForSequenceClassification\"),\n         (\"helium\", \"HeliumForSequenceClassification\"),\n         (\"ibert\", \"IBertForSequenceClassification\"),"
        },
        {
            "sha": "108d62e395907199fe2a92bd9d952de7fab58e1f",
            "filename": "src/transformers/models/gpt_oss/modeling_gpt_oss.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodeling_gpt_oss.py?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -28,7 +28,7 @@\n from ...generation import GenerationMixin\n from ...integrations.hub_kernels import use_kernel_forward_from_hub\n from ...masking_utils import create_causal_mask, create_sliding_window_causal_mask\n-from ...modeling_layers import GradientCheckpointingLayer\n+from ...modeling_layers import GenericForSequenceClassification, GradientCheckpointingLayer\n from ...modeling_outputs import MoeCausalLMOutputWithPast, MoeModelOutputWithPast\n from ...modeling_rope_utils import ROPE_INIT_FUNCTIONS, dynamic_rope_update\n from ...modeling_utils import ALL_ATTENTION_FUNCTIONS, PreTrainedModel\n@@ -703,4 +703,8 @@ def forward(\n         )\n \n \n-__all__ = [\"GptOssForCausalLM\", \"GptOssModel\", \"GptOssPreTrainedModel\"]\n+class GptOssForSequenceClassification(GenericForSequenceClassification, GptOssPreTrainedModel):\n+    pass\n+\n+\n+__all__ = [\"GptOssForCausalLM\", \"GptOssForSequenceClassification\", \"GptOssModel\", \"GptOssPreTrainedModel\"]"
        },
        {
            "sha": "1b74d73219ccb63703948e2d45d381b80c6d4c25",
            "filename": "src/transformers/models/gpt_oss/modular_gpt_oss.py",
            "status": "modified",
            "additions": 6,
            "deletions": 1,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgpt_oss%2Fmodular_gpt_oss.py?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -41,7 +41,7 @@\n     LlamaRotaryEmbedding,\n     repeat_kv,\n )\n-from ..mixtral.modeling_mixtral import MixtralForCausalLM, MixtralModel\n+from ..mixtral.modeling_mixtral import MixtralForCausalLM, MixtralForSequenceClassification, MixtralModel\n from ..qwen2.modeling_qwen2 import Qwen2Attention\n from .configuration_gpt_oss import GptOssConfig\n \n@@ -443,8 +443,13 @@ class GptOssForCausalLM(MixtralForCausalLM):\n     pass\n \n \n+class GptOssForSequenceClassification(MixtralForSequenceClassification):\n+    pass\n+\n+\n __all__ = [\n     \"GptOssForCausalLM\",\n+    \"GptOssForSequenceClassification\",\n     \"GptOssModel\",\n     \"GptOssPreTrainedModel\",\n ]"
        },
        {
            "sha": "29fed37de3ff1ccedf36f0199ca72d15c4e42f57",
            "filename": "tests/models/gpt_oss/test_modeling_gpt_oss.py",
            "status": "modified",
            "additions": 7,
            "deletions": 1,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fgpt_oss%2Ftest_modeling_gpt_oss.py?ref=2b6cbedeb2595baa3ee25a951cb323ff3b25b6ca",
            "patch": "@@ -48,6 +48,7 @@\n \n     from transformers import (\n         GptOssForCausalLM,\n+        GptOssForSequenceClassification,\n         GptOssModel,\n     )\n \n@@ -59,10 +60,12 @@ class GptOssModelTester(CausalLMModelTester):\n         config_class = GptOssConfig\n         base_model_class = GptOssModel\n         causal_lm_class = GptOssForCausalLM\n+        sequence_class = GptOssForSequenceClassification\n \n     pipeline_model_mapping = (\n         {\n             \"feature-extraction\": GptOssModel,\n+            \"text-classification\": GptOssForSequenceClassification,\n             \"text-generation\": GptOssForCausalLM,\n         }\n         if is_torch_available()\n@@ -72,10 +75,13 @@ class GptOssModelTester(CausalLMModelTester):\n \n @require_torch\n class GptOssModelTest(CausalLMModelTest, unittest.TestCase):\n-    all_model_classes = (GptOssModel, GptOssForCausalLM) if is_torch_available() else ()\n+    all_model_classes = (\n+        (GptOssModel, GptOssForCausalLM, GptOssForSequenceClassification) if is_torch_available() else ()\n+    )\n     pipeline_model_mapping = (\n         {\n             \"feature-extraction\": GptOssModel,\n+            \"text-classification\": GptOssForSequenceClassification,\n             \"text-generation\": GptOssForCausalLM,\n         }\n         if is_torch_available()"
        }
    ],
    "stats": {
        "total": 33,
        "additions": 27,
        "deletions": 6
    }
}