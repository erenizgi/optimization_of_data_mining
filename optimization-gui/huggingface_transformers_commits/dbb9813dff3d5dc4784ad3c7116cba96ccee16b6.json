{
    "author": "gante",
    "message": "[generation] Less verbose warnings by default (#38179)\n\n* tmp commit (imports broken)\n\n* working version; update tests\n\n* remove line break\n\n* shorter msg\n\n* dola checks need num_beams=1; other minor PR comments\n\n* update early trainer failing on bad gen config\n\n* make fixup\n\n* test msg",
    "sha": "dbb9813dff3d5dc4784ad3c7116cba96ccee16b6",
    "files": [
        {
            "sha": "4e0d658f9816e692c47b490d912ea8e16c0e8d53",
            "filename": "src/transformers/generation/configuration_utils.py",
            "status": "modified",
            "additions": 118,
            "deletions": 133,
            "changes": 251,
            "blob_url": "https://github.com/huggingface/transformers/blob/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fconfiguration_utils.py?ref=dbb9813dff3d5dc4784ad3c7116cba96ccee16b6",
            "patch": "@@ -35,6 +35,7 @@\n     is_torch_available,\n     logging,\n )\n+from ..utils.deprecation import deprecate_kwarg\n \n \n if TYPE_CHECKING:\n@@ -514,7 +515,7 @@ def __init__(self, **kwargs):\n                     raise err\n \n         # Validate the values of the attributes\n-        self.validate(is_init=True)\n+        self.validate()\n \n     def __hash__(self):\n         return hash(self.to_json_string(ignore_metadata=True))\n@@ -592,132 +593,142 @@ def get_generation_mode(self, assistant_model: Optional[\"PreTrainedModel\"] = Non\n                 )\n         return generation_mode\n \n-    def validate(self, is_init=False):\n+    @deprecate_kwarg(\"is_init\", version=\"4.54.0\")\n+    def validate(self, strict=False):\n         \"\"\"\n         Validates the values of the attributes of the [`GenerationConfig`] instance. Raises exceptions in the presence\n         of parameterization that can be detected as incorrect from the configuration instance alone.\n \n         Note that some parameters not validated here are best validated at generate runtime, as they may depend on\n         other inputs and/or the model, such as parameters related to the generation length.\n \n-        Arg:\n-            is_init (`bool`, *optional*, defaults to `False`):\n-                Whether the validation is performed during the initialization of the instance.\n+        Args:\n+            strict (bool): If True, raise an exception for any issues found. If False, only log issues.\n         \"\"\"\n+        minor_issues = {}  # format: {attribute_name: issue_description}\n \n-        # Validation of individual attributes\n+        # 1. Validation of individual attributes\n+        # 1.1. Decoding attributes\n         if self.early_stopping not in {True, False, \"never\"}:\n             raise ValueError(f\"`early_stopping` must be a boolean or 'never', but is {self.early_stopping}.\")\n         if self.max_new_tokens is not None and self.max_new_tokens <= 0:\n             raise ValueError(f\"`max_new_tokens` must be greater than 0, but is {self.max_new_tokens}.\")\n         if self.pad_token_id is not None and self.pad_token_id < 0:\n-            warnings.warn(\n+            minor_issues[\"pad_token_id\"] = (\n                 f\"`pad_token_id` should be positive but got {self.pad_token_id}. This will cause errors when batch \"\n                 \"generating, if there is padding. Please set `pad_token_id` explicitly as \"\n                 \"`model.generation_config.pad_token_id=PAD_TOKEN_ID` to avoid errors in generation\"\n             )\n-\n-        # Validation of attribute relations:\n-        fix_location = \"\"\n-        if is_init:\n-            fix_location = (\n-                \" This was detected when initializing the generation config instance, which means the corresponding \"\n-                \"file may hold incorrect parameterization and should be fixed.\"\n+        # 1.2. Cache attributes\n+        if self.cache_implementation is not None and self.cache_implementation not in ALL_CACHE_IMPLEMENTATIONS:\n+            raise ValueError(\n+                f\"Invalid `cache_implementation` ({self.cache_implementation}). Choose one of: \"\n+                f\"{ALL_CACHE_IMPLEMENTATIONS}\"\n             )\n+        if self.cache_config is not None:\n+            cache_class = CACHE_CONFIG_MAPPING.get(self.cache_implementation)\n+            if cache_class is None:\n+                raise ValueError(\n+                    \"You provided a `cache_config` but the cache implementation you are using \"\n+                    f\"({self.cache_implementation}) does not require any config. Make sure to use the \"\n+                    \"correct cache implementation matching your cache config.\"\n+                )\n+            if not isinstance(self.cache_config, cache_class):\n+                self.cache_config = cache_class.from_dict(self.cache_config)\n+            self.cache_config.validate()\n+        # 1.3. Performance attributes\n+        if self.compile_config is not None and not isinstance(self.compile_config, CompileConfig):\n+            raise ValueError(\n+                f\"You provided `compile_config` as an instance of {type(self.compile_config)}, but it must be an \"\n+                \"instance of `CompileConfig`.\"\n+            )\n+        # 1.4. Watermarking attributes\n+        if self.watermarking_config is not None:\n+            if not (\n+                isinstance(self.watermarking_config, WatermarkingConfig)\n+                or isinstance(self.watermarking_config, SynthIDTextWatermarkingConfig)\n+            ):\n+                minor_issues[\"watermarking_config\"] = (\n+                    \"`watermarking_config` as a dict is deprecated and will be removed in v4.54.0. Please construct \"\n+                    \"`watermarking_config` object with `WatermarkingConfig` or `SynthIDTextWatermarkingConfig` class.\"\n+                )\n+                self.watermarking_config = WatermarkingConfig.from_dict(self.watermarking_config)\n+            self.watermarking_config.validate()\n \n-        # 1. detect sampling-only parameterization when not in sampling mode\n+        # 2. Validation of attribute combinations\n+        # 2.1. detect sampling-only parameterization when not in sampling mode\n         if self.do_sample is False:\n             greedy_wrong_parameter_msg = (\n                 \"`do_sample` is set to `False`. However, `{flag_name}` is set to `{flag_value}` -- this flag is only \"\n                 \"used in sample-based generation modes. You should set `do_sample=True` or unset `{flag_name}`.\"\n-                + fix_location\n             )\n             if self.temperature is not None and self.temperature != 1.0:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"temperature\", flag_value=self.temperature),\n-                    UserWarning,\n+                minor_issues[\"temperature\"] = greedy_wrong_parameter_msg.format(\n+                    flag_name=\"temperature\", flag_value=self.temperature\n                 )\n             if self.top_p is not None and self.top_p != 1.0:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"top_p\", flag_value=self.top_p),\n-                    UserWarning,\n-                )\n+                minor_issues[\"top_p\"] = greedy_wrong_parameter_msg.format(flag_name=\"top_p\", flag_value=self.top_p)\n             if self.min_p is not None:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"min_p\", flag_value=self.min_p),\n-                    UserWarning,\n-                )\n+                minor_issues[\"min_p\"] = greedy_wrong_parameter_msg.format(flag_name=\"min_p\", flag_value=self.min_p)\n             if self.typical_p is not None and self.typical_p != 1.0:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"typical_p\", flag_value=self.typical_p),\n-                    UserWarning,\n+                minor_issues[\"typical_p\"] = greedy_wrong_parameter_msg.format(\n+                    flag_name=\"typical_p\", flag_value=self.typical_p\n                 )\n             if (\n                 self.top_k is not None and self.top_k != 50 and self.penalty_alpha is None\n             ):  # contrastive search uses top_k\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"top_k\", flag_value=self.top_k),\n-                    UserWarning,\n-                )\n+                minor_issues[\"top_k\"] = greedy_wrong_parameter_msg.format(flag_name=\"top_k\", flag_value=self.top_k)\n             if self.epsilon_cutoff is not None and self.epsilon_cutoff != 0.0:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"epsilon_cutoff\", flag_value=self.epsilon_cutoff),\n-                    UserWarning,\n+                minor_issues[\"epsilon_cutoff\"] = greedy_wrong_parameter_msg.format(\n+                    flag_name=\"epsilon_cutoff\", flag_value=self.epsilon_cutoff\n                 )\n             if self.eta_cutoff is not None and self.eta_cutoff != 0.0:\n-                warnings.warn(\n-                    greedy_wrong_parameter_msg.format(flag_name=\"eta_cutoff\", flag_value=self.eta_cutoff),\n-                    UserWarning,\n+                minor_issues[\"eta_cutoff\"] = greedy_wrong_parameter_msg.format(\n+                    flag_name=\"eta_cutoff\", flag_value=self.eta_cutoff\n                 )\n \n-        # 2. detect beam-only parameterization when not in beam mode\n-        if self.num_beams is None:\n-            warnings.warn(\"`num_beams` is set to None - defaulting to 1.\", UserWarning)\n-            self.num_beams = 1\n-\n+        # 2.2. detect beam-only parameterization when not in beam mode\n         if self.num_beams == 1:\n             single_beam_wrong_parameter_msg = (\n                 \"`num_beams` is set to 1. However, `{flag_name}` is set to `{flag_value}` -- this flag is only used \"\n-                \"in beam-based generation modes. You should set `num_beams>1` or unset `{flag_name}`.\" + fix_location\n+                \"in beam-based generation modes. You should set `num_beams>1` or unset `{flag_name}`.\"\n             )\n             if self.early_stopping is not False:\n-                warnings.warn(\n-                    single_beam_wrong_parameter_msg.format(flag_name=\"early_stopping\", flag_value=self.early_stopping),\n-                    UserWarning,\n+                minor_issues[\"early_stopping\"] = single_beam_wrong_parameter_msg.format(\n+                    flag_name=\"early_stopping\", flag_value=self.early_stopping\n                 )\n             if self.num_beam_groups is not None and self.num_beam_groups != 1:\n-                warnings.warn(\n-                    single_beam_wrong_parameter_msg.format(\n-                        flag_name=\"num_beam_groups\", flag_value=self.num_beam_groups\n-                    ),\n-                    UserWarning,\n+                minor_issues[\"num_beam_groups\"] = single_beam_wrong_parameter_msg.format(\n+                    flag_name=\"num_beam_groups\", flag_value=self.num_beam_groups\n                 )\n             if self.diversity_penalty is not None and self.diversity_penalty != 0.0:\n-                warnings.warn(\n-                    single_beam_wrong_parameter_msg.format(\n-                        flag_name=\"diversity_penalty\", flag_value=self.diversity_penalty\n-                    ),\n-                    UserWarning,\n+                minor_issues[\"diversity_penalty\"] = single_beam_wrong_parameter_msg.format(\n+                    flag_name=\"diversity_penalty\", flag_value=self.diversity_penalty\n                 )\n             if self.length_penalty is not None and self.length_penalty != 1.0:\n-                warnings.warn(\n-                    single_beam_wrong_parameter_msg.format(flag_name=\"length_penalty\", flag_value=self.length_penalty),\n-                    UserWarning,\n+                minor_issues[\"length_penalty\"] = single_beam_wrong_parameter_msg.format(\n+                    flag_name=\"length_penalty\", flag_value=self.length_penalty\n                 )\n             if self.constraints is not None:\n-                warnings.warn(\n-                    single_beam_wrong_parameter_msg.format(flag_name=\"constraints\", flag_value=self.constraints),\n-                    UserWarning,\n+                minor_issues[\"constraints\"] = single_beam_wrong_parameter_msg.format(\n+                    flag_name=\"constraints\", flag_value=self.constraints\n+                )\n+            # DoLa generation needs num_beams == 1\n+            if self.dola_layers is not None and (self.repetition_penalty is None or self.repetition_penalty < 1.2):\n+                minor_issues[\"repetition_penalty\"] = (\n+                    \"`dola_layers` is set to trigger DoLa decoding, but `repetition_penalty` is set to a value of \"\n+                    f\"{self.repetition_penalty}, which could induce unwanted repetition. The recommended value for \"\n+                    \"DoLa decoding is `repetition_penalty>=1.2`.\",\n                 )\n \n-        # 3. detect incorrect parameterization specific to advanced beam modes\n+        # 2.3. detect incorrect parameterization specific to advanced beam modes\n         else:\n             # constrained beam search\n             if self.constraints is not None or self.force_words_ids is not None:\n                 constrained_wrong_parameter_msg = (\n-                    \"one of `constraints`, `force_words_ids` is not `None`, triggering constrained beam search. However, \"\n-                    \"`{flag_name}` is set to `{flag_value}`, which is incompatible with this generation mode. Set \"\n-                    \"`constraints` and `force_words_ids` to `None` or unset `{flag_name}` to continue.\" + fix_location\n+                    \"one of `constraints`, `force_words_ids` is not `None`, triggering constrained beam search. \"\n+                    \"However, `{flag_name}` is set to `{flag_value}`, which is incompatible with this generation \"\n+                    \"mode. Set `constraints` and `force_words_ids` to `None` or unset `{flag_name}` to continue.\"\n                 )\n                 if self.do_sample is True:\n                     raise ValueError(\n@@ -730,7 +741,7 @@ def validate(self, is_init=False):\n                         )\n                     )\n             # group beam search\n-            if self.diversity_penalty != 0.0 or self.num_beam_groups != 1:\n+            elif self.diversity_penalty != 0.0 or self.num_beam_groups != 1:\n                 group_error_prefix = (\n                     \"`diversity_penalty` is not 0.0 or `num_beam_groups` is not 1, triggering group beam search. In \"\n                     \"this generation mode, \"\n@@ -744,16 +755,8 @@ def validate(self, is_init=False):\n                         group_error_prefix\n                         + \"`diversity_penalty` should be greater than `0.0`, otherwise your groups will be identical.\"\n                     )\n-            # DoLa generation\n-            if self.dola_layers is not None and (self.repetition_penalty is None or self.repetition_penalty < 1.2):\n-                warnings.warn(\n-                    \"`dola_layers` is set to trigger DoLa decoding, but `repetition_penalty` is set to a value of \"\n-                    f\"{self.repetition_penalty}, which could induce unwanted repetition. The recommended value for \"\n-                    \"DoLa decoding is `repetition_penalty>=1.2`.\",\n-                    UserWarning,\n-                )\n \n-        # 4. check `num_return_sequences`\n+        # 2.4. check `num_return_sequences`\n         if self.num_return_sequences != 1:\n             if self.num_beams == 1:\n                 if self.do_sample is False:\n@@ -767,23 +770,7 @@ def validate(self, is_init=False):\n                     f\"({self.num_beams}).\"\n                 )\n \n-        # 5. check cache-related arguments\n-        if self.cache_implementation is not None and self.cache_implementation not in ALL_CACHE_IMPLEMENTATIONS:\n-            raise ValueError(\n-                f\"Invalid `cache_implementation` ({self.cache_implementation}). Choose one of: \"\n-                f\"{ALL_CACHE_IMPLEMENTATIONS}\"\n-            )\n-        if self.cache_config is not None:\n-            cache_class = CACHE_CONFIG_MAPPING.get(self.cache_implementation)\n-            if cache_class is None:\n-                raise ValueError(\n-                    \"You provided a `cache_config` but the cache implementation you are using \"\n-                    f\"({self.cache_implementation}) does not require any config. Make sure to use the \"\n-                    \"correct cache implementation matching your cache config.\"\n-                )\n-            if not isinstance(self.cache_config, cache_class):\n-                self.cache_config = cache_class.from_dict(self.cache_config)\n-            self.cache_config.validate()\n+        # 2.5. check cache-related arguments\n         if self.use_cache is False:\n             # In this case, all cache-related arguments should be unset. However, since `use_cache=False` is often used\n             # passed to `generate` directly to hot-fix cache issues, let's raise a warning instead of an error\n@@ -794,42 +781,20 @@ def validate(self, is_init=False):\n             )\n             for arg_name in (\"cache_implementation\", \"cache_config\", \"return_legacy_cache\"):\n                 if getattr(self, arg_name) is not None:\n-                    logger.warning_once(\n-                        no_cache_warning.format(cache_arg=arg_name, cache_arg_value=getattr(self, arg_name))\n+                    minor_issues[arg_name] = no_cache_warning.format(\n+                        cache_arg=arg_name, cache_arg_value=getattr(self, arg_name)\n                     )\n \n-        # 6.  check watermarking arguments\n-        if self.watermarking_config is not None:\n-            if not (\n-                isinstance(self.watermarking_config, WatermarkingConfig)\n-                or isinstance(self.watermarking_config, SynthIDTextWatermarkingConfig)\n-            ):\n-                warnings.warn(\n-                    \"`watermarking_config` as a dict is deprecated. Please construct `watermarking_config` object with \"\n-                    \"`WatermarkingConfig` or `SynthIDTextWatermarkingConfig` class.\",\n-                    FutureWarning,\n-                )\n-                self.watermarking_config = WatermarkingConfig.from_dict(self.watermarking_config)\n-            self.watermarking_config.validate()\n-\n-        # 7. performances arguments\n-        if self.compile_config is not None and not isinstance(self.compile_config, CompileConfig):\n-            raise ValueError(\n-                f\"You provided `compile_config` as an instance of {type(self.compile_config)}, but it must be an \"\n-                \"instance of `CompileConfig`.\"\n-            )\n-\n-        # 8. other incorrect combinations\n+        # 2.6. other incorrect combinations\n         if self.return_dict_in_generate is not True:\n             for extra_output_flag in self.extra_output_flags:\n                 if getattr(self, extra_output_flag) is True:\n-                    warnings.warn(\n+                    minor_issues[extra_output_flag] = (\n                         f\"`return_dict_in_generate` is NOT set to `True`, but `{extra_output_flag}` is. When \"\n-                        f\"`return_dict_in_generate` is not `True`, `{extra_output_flag}` is ignored.\",\n-                        UserWarning,\n+                        f\"`return_dict_in_generate` is not `True`, `{extra_output_flag}` is ignored.\"\n                     )\n \n-        # 8. check common issue: passing `generate` arguments inside the generation config\n+        # 3. Check common issue: passing `generate` arguments inside the generation config\n         generate_arguments = (\n             \"logits_processor\",\n             \"stopping_criteria\",\n@@ -839,6 +804,7 @@ def validate(self, is_init=False):\n             \"streamer\",\n             \"negative_prompt_ids\",\n             \"negative_prompt_attention_mask\",\n+            \"use_model_defaults\",\n         )\n         for arg in generate_arguments:\n             if hasattr(self, arg):\n@@ -847,6 +813,30 @@ def validate(self, is_init=False):\n                     \"`generate()` (or a pipeline) directly.\"\n                 )\n \n+        # Finally, handle caught minor issues. With default parameterization, we will throw a minimal warning.\n+        if len(minor_issues) > 0:\n+            # Full list of issues with potential fixes\n+            info_message = []\n+            for attribute_name, issue_description in minor_issues.items():\n+                info_message.append(f\"- `{attribute_name}`: {issue_description}\")\n+            info_message = \"\\n\".join(info_message)\n+            info_message += (\n+                \"\\nIf you're using a pretrained model, note that some of these attributes may be set through the \"\n+                \"model's `generation_config.json` file.\"\n+            )\n+\n+            if strict:\n+                raise ValueError(\"GenerationConfig is invalid: \\n\" + info_message)\n+            else:\n+                attributes_with_issues = list(minor_issues.keys())\n+                warning_message = (\n+                    f\"The following generation flags are not valid and may be ignored: {attributes_with_issues}.\"\n+                )\n+                if logger.getEffectiveLevel() >= logging.WARNING:\n+                    warning_message += \" Set `TRANSFORMERS_VERBOSITY=info` for more details.\"\n+                logger.warning(warning_message)\n+                logger.info(info_message)\n+\n     def save_pretrained(\n         self,\n         save_directory: Union[str, os.PathLike],\n@@ -871,18 +861,13 @@ def save_pretrained(\n                 Additional key word arguments passed along to the [`~utils.PushToHubMixin.push_to_hub`] method.\n         \"\"\"\n \n-        # At save time, validate the instance -- if any warning/exception is thrown, we refuse to save the instance.\n+        # At save time, validate the instance enforcing strictness -- if any warning/exception would be thrown, we\n+        # refuse to save the instance.\n         # This strictness is enforced to prevent bad configurations from being saved and re-used.\n         try:\n-            with warnings.catch_warnings(record=True) as caught_warnings:\n-                self.validate()\n-            if len(caught_warnings) > 0:\n-                raise ValueError(str([w.message for w in caught_warnings]))\n+            self.validate(strict=True)\n         except ValueError as exc:\n-            raise ValueError(\n-                \"The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. \"\n-                \"Fix these issues to save the configuration.\\n\\nThrown during validation:\\n\" + str(exc)\n-            )\n+            raise ValueError(str(exc) + \"\\n\\nFix these issues to save the configuration.\")\n \n         use_auth_token = kwargs.pop(\"use_auth_token\", None)\n "
        },
        {
            "sha": "e3ae588cd04f2094c831c1cd5d1d6634181c7555",
            "filename": "src/transformers/trainer_seq2seq.py",
            "status": "modified",
            "additions": 3,
            "deletions": 9,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/src%2Ftransformers%2Ftrainer_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/src%2Ftransformers%2Ftrainer_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftrainer_seq2seq.py?ref=dbb9813dff3d5dc4784ad3c7116cba96ccee16b6",
            "patch": "@@ -13,7 +13,6 @@\n # limitations under the License.\n \n import contextlib\n-import warnings\n from copy import deepcopy\n from pathlib import Path\n from typing import TYPE_CHECKING, Any, Callable, Optional, Union\n@@ -129,15 +128,10 @@ def load_generation_config(gen_config_arg: Union[str, GenerationConfig]) -> Gene\n         # Strict validation to fail early. `GenerationConfig.save_pretrained()`, run at the end of training, throws\n         # an exception if there are warnings at validation time.\n         try:\n-            with warnings.catch_warnings(record=True) as caught_warnings:\n-                gen_config.validate()\n-            if len(caught_warnings) > 0:\n-                raise ValueError(str([w.message for w in caught_warnings]))\n+            gen_config.validate(strict=True)\n         except ValueError as exc:\n-            raise ValueError(\n-                \"The loaded generation config instance is invalid -- `GenerationConfig.validate()` throws warnings \"\n-                \"and/or exceptions. Fix these issues to train your model.\\n\\nThrown during validation:\\n\" + str(exc)\n-            )\n+            raise ValueError(str(exc) + \"\\n\\nFix these issues to train your model.\")\n+\n         return gen_config\n \n     def evaluate("
        },
        {
            "sha": "8a280b9e312e82b58c5bb754c8b61bfd7089fc9d",
            "filename": "tests/generation/test_configuration_utils.py",
            "status": "modified",
            "additions": 66,
            "deletions": 41,
            "changes": 107,
            "blob_url": "https://github.com/huggingface/transformers/blob/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/tests%2Fgeneration%2Ftest_configuration_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/tests%2Fgeneration%2Ftest_configuration_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_configuration_utils.py?ref=dbb9813dff3d5dc4784ad3c7116cba96ccee16b6",
            "patch": "@@ -13,6 +13,7 @@\n # limitations under the License.\n \n import copy\n+import logging\n import os\n import tempfile\n import unittest\n@@ -22,6 +23,7 @@\n from parameterized import parameterized\n \n from transformers import AutoConfig, GenerationConfig, WatermarkingConfig, is_torch_available\n+from transformers import logging as transformers_logging\n \n \n if is_torch_available():\n@@ -55,7 +57,14 @@\n     UnbatchedClassifierFreeGuidanceLogitsProcessor,\n     WatermarkLogitsProcessor,\n )\n-from transformers.testing_utils import TOKEN, TemporaryHubRepo, is_staging_test, torch_device\n+from transformers.testing_utils import (\n+    TOKEN,\n+    CaptureLogger,\n+    LoggingLevel,\n+    TemporaryHubRepo,\n+    is_staging_test,\n+    torch_device,\n+)\n \n \n class GenerationConfigTest(unittest.TestCase):\n@@ -112,24 +121,6 @@ def test_update(self):\n         # `.update()` returns a dictionary of unused kwargs\n         self.assertEqual(unused_kwargs, {\"foo\": \"bar\"})\n \n-    # TODO: @Arthur and/or @Joao\n-    # FAILED tests/generation/test_configuration_utils.py::GenerationConfigTest::test_initialize_new_kwargs - AttributeError: 'GenerationConfig' object has no attribute 'get_text_config'\n-    # See: https://app.circleci.com/pipelines/github/huggingface/transformers/104831/workflows/e5e61514-51b7-4c8c-bba7-3c4d2986956e/jobs/1394252\n-    @unittest.skip(\"failed with `'GenerationConfig' object has no attribute 'get_text_config'`\")\n-    def test_initialize_new_kwargs(self):\n-        generation_config = GenerationConfig()\n-        generation_config.foo = \"bar\"\n-\n-        with tempfile.TemporaryDirectory(\"test-generation-config\") as tmp_dir:\n-            generation_config.save_pretrained(tmp_dir)\n-\n-            new_config = GenerationConfig.from_pretrained(tmp_dir)\n-        # update_kwargs was used to update the config on valid attributes\n-        self.assertEqual(new_config.foo, \"bar\")\n-\n-        generation_config = GenerationConfig.from_model_config(new_config)\n-        assert not hasattr(generation_config, \"foo\")  # no new kwargs should be initialized if from config\n-\n     def test_kwarg_init(self):\n         \"\"\"Tests that we can overwrite attributes at `from_pretrained` time.\"\"\"\n         default_config = GenerationConfig()\n@@ -159,38 +150,39 @@ def test_validate(self):\n         \"\"\"\n         Tests that the `validate` method is working as expected. Note that `validate` is called at initialization time\n         \"\"\"\n+        logger = transformers_logging.get_logger(\"transformers.generation.configuration_utils\")\n+\n         # A correct configuration will not throw any warning\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        with CaptureLogger(logger) as captured_logs:\n             GenerationConfig()\n-        self.assertEqual(len(captured_warnings), 0)\n+        self.assertEqual(len(captured_logs.out), 0)\n \n         # Inconsequent but technically wrong configuration will throw a warning (e.g. setting sampling\n         # parameters with `do_sample=False`). May be escalated to an error in the future.\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n-            GenerationConfig(do_sample=False, temperature=0.5)\n-        self.assertEqual(len(captured_warnings), 1)\n-\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        with CaptureLogger(logger) as captured_logs:\n             GenerationConfig(return_dict_in_generate=False, output_scores=True)\n-        self.assertEqual(len(captured_warnings), 1)\n+        self.assertNotEqual(len(captured_logs.out), 0)\n+\n+        with CaptureLogger(logger) as captured_logs:\n+            generation_config_bad_temperature = GenerationConfig(do_sample=False, temperature=0.5)  # store for later\n+        self.assertNotEqual(len(captured_logs.out), 0)\n \n         # Expanding on the case above, we can update a bad configuration to get rid of the warning. Ideally,\n         # that is done by unsetting the parameter (i.e. setting it to None)\n-        generation_config_bad_temperature = GenerationConfig(do_sample=False, temperature=0.5)\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        with CaptureLogger(logger) as captured_logs:\n             # BAD - 0.9 means it is still set, we should warn\n             generation_config_bad_temperature.update(temperature=0.9)\n-        self.assertEqual(len(captured_warnings), 1)\n-        generation_config_bad_temperature = GenerationConfig(do_sample=False, temperature=0.5)\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        self.assertNotEqual(len(captured_logs.out), 0)\n+\n+        with CaptureLogger(logger) as captured_logs:\n             # CORNER CASE - 1.0 is the default, we can't detect whether it is set by the user or not, we shouldn't warn\n             generation_config_bad_temperature.update(temperature=1.0)\n-        self.assertEqual(len(captured_warnings), 0)\n-        generation_config_bad_temperature = GenerationConfig(do_sample=False, temperature=0.5)\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        self.assertEqual(len(captured_logs.out), 0)\n+\n+        with CaptureLogger(logger) as captured_logs:\n             # OK - None means it is unset, nothing to warn about\n             generation_config_bad_temperature.update(temperature=None)\n-        self.assertEqual(len(captured_warnings), 0)\n+        self.assertEqual(len(captured_logs.out), 0)\n \n         # Impossible sets of constraints/parameters will raise an exception\n         with self.assertRaises(ValueError):\n@@ -206,9 +198,32 @@ def test_validate(self):\n             GenerationConfig(logits_processor=\"foo\")\n \n         # Model-specific parameters will NOT raise an exception or a warning\n-        with warnings.catch_warnings(record=True) as captured_warnings:\n+        with CaptureLogger(logger) as captured_logs:\n             GenerationConfig(foo=\"bar\")\n-        self.assertEqual(len(captured_warnings), 0)\n+        self.assertEqual(len(captured_logs.out), 0)\n+\n+        # By default we throw a short warning. However, we log with INFO level the details.\n+        # Default: we don't log the incorrect input values, only a short summary. We explain how to get more details.\n+        with CaptureLogger(logger) as captured_logs:\n+            GenerationConfig(do_sample=False, temperature=0.5)\n+        self.assertNotIn(\"0.5\", captured_logs.out)\n+        self.assertTrue(len(captured_logs.out) < 150)  # short log\n+        self.assertIn(\"Set `TRANSFORMERS_VERBOSITY=info` for more details\", captured_logs.out)\n+\n+        # INFO level: we share the full deets\n+        with LoggingLevel(logging.INFO):\n+            with CaptureLogger(logger) as captured_logs:\n+                GenerationConfig(do_sample=False, temperature=0.5)\n+        self.assertIn(\"0.5\", captured_logs.out)\n+        self.assertTrue(len(captured_logs.out) > 400)  # long log\n+        self.assertNotIn(\"Set `TRANSFORMERS_VERBOSITY=info` for more details\", captured_logs.out)\n+\n+        # Finally, we can set `strict=True` to raise an exception on what would otherwise be a warning.\n+        generation_config = GenerationConfig()\n+        generation_config.temperature = 0.5\n+        generation_config.do_sample = False\n+        with self.assertRaises(ValueError):\n+            generation_config.validate(strict=True)\n \n     def test_refuse_to_save(self):\n         \"\"\"Tests that we refuse to save a generation config that fails validation.\"\"\"\n@@ -221,6 +236,7 @@ def test_refuse_to_save(self):\n             with self.assertRaises(ValueError) as exc:\n                 config.save_pretrained(tmp_dir)\n             self.assertTrue(\"Fix these issues to save the configuration.\" in str(exc.exception))\n+            self.assertTrue(\"`temperature` is set to `0.5`\" in str(exc.exception))\n             self.assertTrue(len(os.listdir(tmp_dir)) == 0)\n \n         # greedy decoding throws an exception if we try to return multiple sequences -> throws an exception that is\n@@ -231,15 +247,24 @@ def test_refuse_to_save(self):\n             with self.assertRaises(ValueError) as exc:\n                 config.save_pretrained(tmp_dir)\n             self.assertTrue(\"Fix these issues to save the configuration.\" in str(exc.exception))\n+            self.assertTrue(\n+                \"Greedy methods without beam search do not support `num_return_sequences` different than 1\"\n+                in str(exc.exception)\n+            )\n             self.assertTrue(len(os.listdir(tmp_dir)) == 0)\n \n-        # final check: no warnings/exceptions thrown if it is correct, and file is saved\n+        # Final check: no logs at warning level/warnings/exceptions thrown if it is correct, and file is saved.\n         config = GenerationConfig()\n         with tempfile.TemporaryDirectory() as tmp_dir:\n+            # Catch warnings\n             with warnings.catch_warnings(record=True) as captured_warnings:\n-                config.save_pretrained(tmp_dir)\n+                # Catch logs (up to WARNING level, the default level)\n+                logger = transformers_logging.get_logger(\"transformers.generation.configuration_utils\")\n+                with CaptureLogger(logger) as captured_logs:\n+                    config.save_pretrained(tmp_dir)\n             self.assertEqual(len(captured_warnings), 0)\n-            self.assertTrue(len(os.listdir(tmp_dir)) == 1)\n+            self.assertEqual(len(captured_logs.out), 0)\n+            self.assertEqual(len(os.listdir(tmp_dir)), 1)\n \n     def test_generation_mode(self):\n         \"\"\"Tests that the `get_generation_mode` method is working as expected.\"\"\""
        },
        {
            "sha": "0c4716a2bceb3838a9bd0e075cdc21af8892648a",
            "filename": "tests/trainer/test_trainer_seq2seq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/tests%2Ftrainer%2Ftest_trainer_seq2seq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dbb9813dff3d5dc4784ad3c7116cba96ccee16b6/tests%2Ftrainer%2Ftest_trainer_seq2seq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftrainer%2Ftest_trainer_seq2seq.py?ref=dbb9813dff3d5dc4784ad3c7116cba96ccee16b6",
            "patch": "@@ -202,4 +202,4 @@ def test_bad_generation_config_fail_early(self):\n                 data_collator=data_collator,\n                 compute_metrics=lambda x: {\"samples\": x[0].shape[0]},\n             )\n-        self.assertIn(\"The loaded generation config instance is invalid\", str(exc.exception))\n+        self.assertIn(\"Fix these issues to train your model\", str(exc.exception))"
        }
    ],
    "stats": {
        "total": 372,
        "additions": 188,
        "deletions": 184
    }
}