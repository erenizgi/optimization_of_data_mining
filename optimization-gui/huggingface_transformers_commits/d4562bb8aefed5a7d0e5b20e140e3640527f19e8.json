{
    "author": "SrijanUpadhyay",
    "message": "Fix Qwen3Next dtype API usage (#41735)\n\nReplace torch.get_current_dtype() with torch.get_default_dtype() to fix FLA compatibility",
    "sha": "d4562bb8aefed5a7d0e5b20e140e3640527f19e8",
    "files": [
        {
            "sha": "82939410bc7684ad5e7fc38922fff92adb523919",
            "filename": "src/transformers/models/qwen3_next/modeling_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d4562bb8aefed5a7d0e5b20e140e3640527f19e8/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d4562bb8aefed5a7d0e5b20e140e3640527f19e8/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py?ref=d4562bb8aefed5a7d0e5b20e140e3640527f19e8",
            "patch": "@@ -638,7 +638,7 @@ def __init__(self, config: Qwen3NextConfig, layer_idx: int):\n                 eps=self.layer_norm_epsilon,\n                 activation=self.activation,\n                 device=torch.cuda.current_device(),\n-                dtype=config.dtype if config.dtype is not None else torch.get_current_dtype(),\n+                dtype=config.dtype if config.dtype is not None else torch.get_default_dtype(),\n             )\n         )\n "
        },
        {
            "sha": "e624a653150b0a022c689bf17cb971f293c148ce",
            "filename": "src/transformers/models/qwen3_next/modular_qwen3_next.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d4562bb8aefed5a7d0e5b20e140e3640527f19e8/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d4562bb8aefed5a7d0e5b20e140e3640527f19e8/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodular_qwen3_next.py?ref=d4562bb8aefed5a7d0e5b20e140e3640527f19e8",
            "patch": "@@ -473,7 +473,7 @@ def __init__(self, config: Qwen3NextConfig, layer_idx: int):\n                 eps=self.layer_norm_epsilon,\n                 activation=self.activation,\n                 device=torch.cuda.current_device(),\n-                dtype=config.dtype if config.dtype is not None else torch.get_current_dtype(),\n+                dtype=config.dtype if config.dtype is not None else torch.get_default_dtype(),\n             )\n         )\n "
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}