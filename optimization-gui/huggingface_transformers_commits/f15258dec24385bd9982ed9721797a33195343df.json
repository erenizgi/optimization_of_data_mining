{
    "author": "cyyever",
    "message": "Remove <frameworkcontent> and <pt> tags from documentation (#41055)\n\n* Remove <frameworkcontent> and <pt> tags\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n* Revert changes\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n* Update docs/source/en/model_doc/madlad-400.md\n\n---------\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\nCo-authored-by: Joao Gante <joaofranciscocardosogante@gmail.com>",
    "sha": "f15258dec24385bd9982ed9721797a33195343df",
    "files": [
        {
            "sha": "9c7709e2d1724c6df9dde6b5fbdcafe92aafbd65",
            "filename": "docs/source/ar/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -115,8 +115,6 @@\n \n ## Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (AutoModel)\n \n-<frameworkcontent>\n-<pt>\n ØªØ³Ù…Ø­ Ù„Ùƒ ÙØ¦Ø§Øª `AutoModelFor` Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù„Ù…Ù‡Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](model_doc/auto) Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© ÙƒØ§Ù…Ù„Ø© Ø¨Ø§Ù„Ù…Ù‡Ø§Ù… Ø§Ù„Ù…ØªØ§Ø­Ø©). Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoModelForSequenceClassification.from_pretrained`]:\n \n ```py\n@@ -143,6 +141,4 @@\n \n \n Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ù†ÙˆØµÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙØ¦Ø© `AutoTokenizer` ÙˆÙØ¦Ø© `AutoModelFor` Ù„ØªØ­Ù…ÙŠÙ„ Ù…Ø«ÙŠÙ„Ø§Øª Ù…ÙØ¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬. Ø³ÙŠØ³Ø§Ø¹Ø¯Ùƒ Ù‡Ø°Ø§ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØµØ­ÙŠØ­Ø© ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©. ÙÙŠ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„ØªØ§Ù„ÙŠØŒ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ù„ØºÙˆÙŠ ÙˆÙ…Ø¹Ø§Ù„Ø¬ Ø§Ù„ØµÙˆØ± ÙˆÙ…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø°ÙŠ ØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ø­Ø¯ÙŠØ«Ù‹Ø§ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¶Ø¨Ø· Ø§Ù„Ø¯Ù‚ÙŠÙ‚.\n-</pt>\n \n-</frameworkcontent>"
        },
        {
            "sha": "a2b49696f04ba7f43f07e08012e4296c8bafec40",
            "filename": "docs/source/ar/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -81,8 +81,6 @@ DistilBertConfig {\n \n Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ© Ù‡ÙŠ Ø¥Ù†Ø´Ø§Ø¡ [Ù†Ù…ÙˆØ°Ø¬](main_classes/models). Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ - ÙˆÙŠÙØ´Ø§Ø± Ø¥Ù„ÙŠÙ‡ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ø¨Ø§Ø³Ù… Ø§Ù„Ø¨Ù†ÙŠØ© - ÙŠÙØ­Ø¯Ø¯ ÙˆØ¸ÙŠÙØ© ÙƒÙ„ Ø·Ø¨Ù‚Ø© ÙˆØ§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ÙŠØ© Ø§Ù„Ù…ÙÙ†ÙØ°Ø©. ØªÙØ³ØªØ®Ø¯Ù… Ø®ØµØ§Ø¦Øµ Ù…Ø«Ù„ `num_hidden_layers` Ù…Ù† Ø§Ù„ØªÙƒÙˆÙŠÙ† Ù„ØªØ­Ø¯ÙŠØ¯ Ù‡Ø°Ù‡ Ø§Ù„Ø¨Ù†ÙŠØ©. ØªØ´ØªØ±Ùƒ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ ÙÙŠ  ÙØ¦Ø© Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ§Ø­Ø¯Ø© Ù‡ÙŠ [`PreTrainedModel`] ÙˆØ¨Ø¹Ø¶ Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…ÙØ´ØªØ±ÙƒØ© Ù…Ø«Ù„ ØºÙŠÙŠØ± Ø­Ø¬Ù… Ù…ÙØ¯Ø®Ù„Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØªÙ‚Ù„ÙŠØµ Ø±Ø¤ÙˆØ³ Ø¢Ù„ÙŠØ© Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø§Ù„Ø°Ø§ØªÙŠ. Ø¨Ø§Ù„Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ Ø°Ù„ÙƒØŒ ÙØ¥Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù‡ÙŠ  ÙØ¦Ø§Øª ÙØ±Ø¹ÙŠØ© Ø¥Ù…Ø§ Ù…Ù† [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)ØŒ [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) Ø£Ùˆ [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html) . Ù‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ ÙƒÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡Ø§.\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… Ø¨ØªØ­Ù…ÙŠÙ„ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù…Ø®ØµØµØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:\n \n ```py\n@@ -105,15 +103,11 @@ DistilBertConfig {\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\"ØŒ config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Ø±Ø¤ÙˆØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n \n ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø©ØŒ Ù„Ø¯ÙŠÙƒ Ù†Ù…ÙˆØ°Ø¬ DistilBERT Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ®Ø±Ø¬ *Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù†Ø©*. ØªÙÙ…Ø±Ù‘ÙØ± Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù†Ø© ÙƒÙ…Ø¯Ø®Ù„Ø§Øª Ù„Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø¥Ù†ØªØ§Ø¬  Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©. ØªÙˆÙØ± Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø±Ø£Ø³ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø®ØªÙ„Ù Ù„ÙƒÙ„ Ù…Ù‡Ù…Ø© Ø·Ø§Ù„Ù…Ø§ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¯Ø¹Ù… Ø§Ù„Ù…Ù‡Ù…Ø© (Ø£ÙŠ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ®Ø¯Ø§Ù… DistilBERT Ù„Ù…Ù‡Ù…Ø© ØªØ³Ù„Ø³Ù„ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„ Ù…Ø«Ù„ Ø§Ù„ØªØ±Ø¬Ù…Ø©).\n \n-<frameworkcontent>\n-<pt>\n Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ [`DistilBertForSequenceClassification`] Ù‡Ùˆ Ù†Ù…ÙˆØ°Ø¬ DistilBERT Ø§Ù„Ø£Ø³Ø§Ø³  Ù…Ø²ÙˆØ¯Ù‹Ø§ Ø¨Ø±Ø£Ø³ ØªØµÙ†ÙŠÙ ØªØ³Ù„Ø³Ù„ÙŠ.  ÙŠÙØ´ÙƒÙ‘Ù„ Ø±Ø£Ø³ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ØªØ³Ù„Ø³Ù„ÙŠ Ø·Ø¨Ù‚Ø© Ø®Ø·ÙŠØ© ÙÙˆÙ‚ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©.\n \n ```py\n@@ -129,8 +123,6 @@ DistilBertConfig {\n \n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ù…Ø¬Ø²Ø¦ Ø§Ù„Ù†ØµÙˆØµ\n "
        },
        {
            "sha": "b81173b15a2906dfc73c461c465864c99d5c3549",
            "filename": "docs/source/ar/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -65,21 +65,15 @@ pip install huggingface_hub\n \n ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¢Ø®Ø± Ø£Ù…Ø± Ø³Ù‡Ù„. ØªØ£ÙƒØ¯ Ù…Ù† ØªØ«Ø¨ÙŠØª PyTorch Ùˆ TensorFlow (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](installation) Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„ØªØ«Ø¨ÙŠØª)ØŒ Ø«Ù… Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ù„Ø§Ø¦Ù… Ù„Ù…Ù‡Ù…ØªÙƒ ÙÙŠ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø¢Ø®Ø±.\n \n-<frameworkcontent>\n-<pt>\n Ø­Ø¯Ø¯ `from_tf=True` Ù„ØªØ­ÙˆÙŠÙ„ Ù†Ù‚Ø·Ø© ØªØ­Ù‚Ù‚ Ù…Ù† TensorFlow Ø¥Ù„Ù‰ PyTorch:\n \n ```py\n >>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n >>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø¯ÙØ¹ Ù†Ù…ÙˆØ°Ø¬ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n Ù…Ø´Ø§Ø±ÙƒØ© Ù†Ù…ÙˆØ°Ø¬Ùƒ Ø¹Ù„Ù‰ Hub Ù…Ø± Ø¨Ø³ÙŠØ· Ù„Ù„ØºØ§ÙŠØ© ÙƒÙ„ Ù…Ø§ Ø¹Ù„ÙŠÙƒ Ù‡Ùˆ Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„Ù…Ø© Ø£Ùˆ Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø±Ø¯ Ø¥Ø¶Ø§ÙÙŠ. ÙƒÙ…Ø§ ØªØ°ÙƒØ± Ù…Ù† Ø¯Ø±Ø³ [Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¯Ù‚ÙŠÙ‚](training)ØŒ ÙØ¥Ù† ÙØ¦Ø© [`TrainingArguments`] Ù‡ÙŠ Ø§Ù„Ù…ÙƒØ§Ù† Ø§Ù„Ø°ÙŠ ØªØ­Ø¯Ø¯ ÙÙŠÙ‡ Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„ÙØ§Ø¦Ù‚Ø© ÙˆØ®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©. ØªØ´Ù…Ù„ Ø¥Ø­Ø¯Ù‰ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù‡Ø°Ù‡ Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†ØµØ© Hub. Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† `push_to_hub=True` ÙÙŠ [`TrainingArguments`]:\n@@ -105,8 +99,6 @@ pip install huggingface_hub\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¯Ø§Ù„Ø© `push_to_hub`\n "
        },
        {
            "sha": "1418c69fd7a363c8575b3ada662914983b99d7dc",
            "filename": "docs/source/ar/preprocessing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fpreprocessing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -152,8 +152,6 @@ pip install datasets\n \n Ù‚Ù… Ø¨ØªØ¹ÙŠÙŠÙ† Ù…Ø¹Ù„Ù…Ø© `return_tensors` Ø¥Ù„Ù‰ Ø¥Ù…Ø§ `pt` Ù„Ù€ PyTorchØŒ Ø£Ùˆ `tf` Ù„Ù€ TensorFlow:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> batch_sentences = [\n@@ -173,8 +171,6 @@ pip install datasets\n                            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "55466e0a15635085838f0b8615afd640b61cd806",
            "filename": "docs/source/ar/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -12,14 +12,10 @@\n \n Ø³ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ØªØ«Ø¨ÙŠØª Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ Ø§Ù„Ù…ÙØ¶Ù„ Ù„Ø¯ÙŠÙƒ:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø®Ø· Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨\n \n@@ -116,8 +112,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Ø§Ø³ØªØ®Ø¯Ù… [`AutoModelForSequenceClassification`] Ùˆ [`AutoTokenizer`] Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙØ¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡ Ø§Ù„Ù…Ø±ØªØ¨Ø· Ø¨Ù‡ (Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ `AutoClass` ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ØªØ§Ù„ÙŠ):\n \n ```py\n@@ -126,8 +120,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n Ø­Ø¯Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙÙŠ [`pipeline`]. Ø§Ù„Ø¢Ù† ÙŠÙ…ÙƒÙ†Ùƒ ØªØ·Ø¨ÙŠÙ‚ `classifier` Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ÙØ±Ù†Ø³ÙŠ:\n \n@@ -176,8 +168,6 @@ label: NEGATIVE, with score: 0.5309\n \n ÙŠÙ…ÙƒÙ† Ø§Ù„Ù…Ø¬Ø²Ø¦ Ø£ÙŠØ¶Ù‹Ø§ Ù‚Ø¨ÙˆÙ„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§ØªØŒ ÙˆÙŠÙ‚ÙˆÙ… Ø¨Ù€ \"Ø­Ø´Ùˆ\" Ùˆ\"ØªÙ‚ØµÙŠØ±\" Ø§Ù„Ù†Øµ Ù„Ø¥Ø±Ø¬Ø§Ø¹ ÙƒØ¯ÙØ¹Ø© Ø¨Ø·ÙˆÙ„ Ù…ÙˆØ­Ø¯:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -188,8 +178,6 @@ label: NEGATIVE, with score: 0.5309\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -199,8 +187,6 @@ label: NEGATIVE, with score: 0.5309\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ØªÙ‚Ø¯Ù… Ù…ÙƒØªØ¨Ø© ğŸ¤— Transformers Ø·Ø±ÙŠÙ‚Ø© Ø¨Ø³ÙŠØ·Ø© ÙˆÙ…ÙˆØ­Ø¯Ø© Ù„ØªØ­Ù…ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§. ÙˆÙ‡Ø°Ø§ ÙŠØ¹Ù†ÙŠ Ø£Ù†Ù‡ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ù…ÙŠÙ„ [`AutoModel`] ÙƒÙ…Ø§ Ù„Ùˆ ÙƒÙ†Øª ØªÙ‚ÙˆÙ… Ø¨ØªØ­Ù…ÙŠÙ„ [`AutoTokenizer`]. Ø§Ù„ÙØ±Ù‚ Ø§Ù„ÙˆØ­ÙŠØ¯ Ù‡Ùˆ Ø§Ø®ØªÙŠØ§Ø± ÙØ¦Ø© [`AutoModel`] Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ù…Ù‡Ù…Ø©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ (Ø£Ùˆ Ø§Ù„ØªØ³Ù„Ø³Ù„)ØŒ ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ ØªØ­Ù…ÙŠÙ„ [`AutoModelForSequenceClassification`]:\n \n ```py\n@@ -236,8 +222,6 @@ label: NEGATIVE, with score: 0.5309\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -247,8 +231,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n \n ### Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬\n \n-<frameworkcontent>\n-<pt>\n Ø¨Ù…Ø¬Ø±Ø¯ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ÙƒØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø­ÙØ¸Ù‡ Ù…Ø¹ Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ±Ù…ÙŠØ² Ø§Ù„Ø®Ø§Øµ Ø¨Ù‡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`PreTrainedModel.save_pretrained`]:\n \n ```py\n@@ -262,22 +244,16 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n Ù…Ù† Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø§Ø¦Ø¹Ø© ÙÙŠ ğŸ¤— Transformers Ø§Ù„Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ Ø­ÙØ¸ Ù†Ù…ÙˆØ°Ø¬ ÙˆØ¥Ø¹Ø§Ø¯Ø© ØªØ­Ù…ÙŠÙ„Ù‡ ÙƒÙ†Ù…ÙˆØ°Ø¬ PyTorch Ø£Ùˆ TensorFlow. ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠØ­ÙˆÙ„ Ù…Ø¹Ø§Ù…Ù„ `from_pt` Ø£Ùˆ `from_tf` Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¥Ø·Ø§Ø± Ø¹Ù…Ù„ Ø¥Ù„Ù‰ Ø¢Ø®Ø±:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>\n \n \n ## Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ Ù…Ø®ØµØµØ©\n@@ -292,17 +268,13 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† ØªÙƒÙˆÙŠÙ†Ùƒ Ø§Ù„Ù…Ø®ØµØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`AutoModel.from_config`]:\n \n ```py\n >>> from transformers import AutoModel\n \n >>> my_model = AutoModel.from_config(my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n Ø§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø¯Ù„ÙŠÙ„ [Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ù†ÙŠØ© Ù…Ø®ØµØµØ©](./create_a_model) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­ÙˆÙ„ Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªÙƒÙˆÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø®ØµØµØ©.\n "
        },
        {
            "sha": "238844dc055ee29a6e847afc73ec8300958afc0e",
            "filename": "docs/source/ar/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -76,8 +76,6 @@ pip install -r requirements.txt\n \n ## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ\n \n-<frameworkcontent>\n-<pt>\n     \n - ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ Ø¨ØªÙ†Ø²ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§ Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ù…Ù† Ù…ÙƒØªØ¨Ø© ğŸ¤— [Datasets](https://huggingface.co/docs/datasets).\n - Ø«Ù… ÙŠÙ‚ÙˆÙ… Ø§Ù„Ù†Øµ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) Ø¹Ù„Ù‰ Ø¨Ù†ÙŠØ© ØªØ¯Ø¹Ù… Ø§Ù„Ù…Ù„Ø®Øµ. \n@@ -98,8 +96,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ÙˆØ²Ø¹ ÙˆØ§Ù„Ø¯Ù‚Ø© Ø§Ù„Ù…Ø®ØªÙ„Ø·Ø©\n \n@@ -129,8 +125,6 @@ torchrun \\\n \n ## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ Ø¹Ù„Ù‰ ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU)\n \n-<frameworkcontent>\n-<pt>\n     \n ØªÙØ¹Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs) Ù…ØµÙ…Ù…Ø© Ø®ØµÙŠØµÙ‹Ø§ Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ø£Ø¯Ø§Ø¡. ÙŠØ¯Ø¹Ù… PyTorch ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPUs) Ù…Ø¹ [XLA](https://www.tensorflow.org/xla) Ù…Ø¬Ù…Ø¹ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚ (Ø±Ø§Ø¬Ø¹ [Ù‡Ù†Ø§](https://github.com/pytorch/xla/blob/master/README.md) Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„ØªÙØ§ØµÙŠÙ„). Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙˆØ­Ø¯Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU)ØŒ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ Ù†Øµ `xla_spawn.py` Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ ÙˆØ§Ø³ØªØ®Ø¯Ù… Ù…Ø¹Ø§Ù…Ù„ `num_cores` Ù„ØªØ¹ÙŠÙŠÙ† Ø¹Ø¯Ø¯ ÙˆØ­Ø¯Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ÙØ§Ø¦Ù‚Ø© (TPU) Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§.\n \n@@ -149,8 +143,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## ØªØ´ØºÙŠÙ„ Ù†Øµ Ø¨Ø±Ù…Ø¬ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ğŸ¤— Accelerate\n "
        },
        {
            "sha": "4b6bb31692a7430b9f8b139e4d10da3d36d3ca67",
            "filename": "docs/source/ar/tasks/language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Flanguage_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Flanguage_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Flanguage_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -182,8 +182,6 @@ pip install transformers datasets evaluate\n \n Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorForLanguageModeling`]. Ù…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ù€ *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ø·ÙˆÙ„ ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ ÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰.\n \n-<frameworkcontent>\n-<pt>\n Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…Ø² Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ³Ù„Ø³Ù„ ÙƒØ±Ù…Ø² Ù„Ù„Ø­Ø´ÙˆØŒ ÙˆØ­Ø¯Ø¯ `mlm_probability` Ù„Ø­Ø¬Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² Ø¨Ø´ÙƒÙ„ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ø¹Ù†Ø¯ ÙƒÙ„ ØªÙƒØ±Ø§Ø± Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n \n ```py\n@@ -193,13 +191,9 @@ pip install transformers datasets evaluate\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -257,8 +251,6 @@ Perplexity: 49.61\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -288,8 +280,6 @@ Perplexity: 49.61\n [{'generated_text': \"Somatic hypermutation allows the immune system to be able to effectively reverse the damage caused by an infection.\\n\\n\\nThe damage caused by an infection is caused by the immune system's ability to perform its own self-correcting tasks.\"}]\n ```\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ø³Ù… Ø§Ù„Ù†Øµ ÙˆØ¥Ø±Ø¬Ø¹ `input_ids` ÙƒØªÙ†Ø³ÙˆØ±Ø§Øª PyTorch:\n \n ```py\n@@ -315,5 +305,3 @@ Perplexity: 49.61\n >>> tokenizer.batch_decode(outputs, skip_special_tokens=True)\n [\"Somatic hypermutation allows the immune system to react to drugs with the ability to adapt to a different environmental situation. In other words, a system of 'hypermutation' can help the immune system to adapt to a different environmental situation or in some cases even a single life. In contrast, researchers at the University of Massachusetts-Boston have found that 'hypermutation' is much stronger in mice than in humans but can be found in humans, and that it's not completely unknown to the immune system. A study on how the immune system\"]\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "846614b4b1772617b6a665e748925866aa2fec2a",
            "filename": "docs/source/ar/tasks/masked_language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fmasked_language_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fmasked_language_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Fmasked_language_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -176,8 +176,6 @@ pip install transformers datasets evaluate\n \n Ø§Ù„Ø¢Ù†ØŒ Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorForLanguageModeling`]. Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ø£Ù† ØªÙ‚ÙˆÙ… Ø¨Ù€ *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„ÙŠØµÙ„ Ø·ÙˆÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ø£Ø·ÙˆÙ„ Ø¬Ù…Ù„Ø© ÙÙŠ Ø§Ù„Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰.\n \n-<frameworkcontent>\n-<pt>\n \n Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…Ø² Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ³Ù„Ø³Ù„ ÙƒØ±Ù…Ø² Ø§Ù„Ø­Ø´Ùˆ ÙˆØ­Ø¯Ø¯ `mlm_probability` Ù„Ø­Ø¬Ø¨ Ø§Ù„Ø±Ù…ÙˆØ² Ø¹Ø´ÙˆØ§Ø¦ÙŠØ§Ù‹ ÙƒÙ„ Ù…Ø±Ø© ØªÙƒØ±Ø± ÙÙŠÙ‡Ø§ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n \n@@ -187,13 +185,9 @@ pip install transformers datasets evaluate\n >>> tokenizer.pad_token = tokenizer.eos_token\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -253,8 +247,6 @@ Perplexity: 8.76\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -295,8 +287,6 @@ Perplexity: 8.76\n   'sequence': 'The Milky Way is a small galaxy.'}]\n ```\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… Ø¨ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ù†Øµ ÙˆØ¥Ø±Ø¬Ø§Ø¹ `input_ids` ÙƒÙ…ØªØ¬Ù‡Ø§Øª PyTorch. Ø³ØªØ­ØªØ§Ø¬ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ù…ÙˆØ¶Ø¹ Ø±Ù…Ø² `<mask>`:\n \n ```py\n@@ -328,5 +318,3 @@ The Milky Way is a spiral galaxy.\n The Milky Way is a massive galaxy.\n The Milky Way is a small galaxy.\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "cdfe0b8caf6c66b5e4f05371289d88d62f25542b",
            "filename": "docs/source/ar/tasks/multiple_choice.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fmultiple_choice.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fmultiple_choice.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Fmultiple_choice.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -116,8 +116,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n \n ÙŠÙ‚ÙˆÙ… `DataCollatorForMultipleChoice` Ø¨ØªØ¬Ù…ÙŠØ¹ Ø¬Ù…ÙŠØ¹ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ØŒ ÙˆÙŠØ·Ø¨Ù‚ Ø§Ù„Ø­Ø´ÙˆØŒ Ø«Ù… ÙŠØ¹ÙŠØ¯ ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø´ÙƒÙ„Ù‡Ø§ Ø§Ù„Ø£ØµÙ„ÙŠ:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from dataclasses import dataclass\n@@ -158,8 +156,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n ...         batch[\"labels\"] = torch.tensor(labels, dtype=torch.int64)\n ...         return batch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (Evaluate)\n \n@@ -186,8 +182,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -241,8 +235,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -263,8 +255,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> candidate2 = \"The law applies to baguettes.\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ø·Ø§Ù„Ø¨Ø© ÙˆØ²ÙˆØ¬ Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø±Ø´Ø­ ÙˆØ£Ø¹Ø¯ ØªÙ†Ø³ÙˆØ±Ø§Øª PyTorch. ÙŠØ¬Ø¨ Ø¹Ù„ÙŠÙƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¥Ù†Ø´Ø§Ø¡ Ø¨Ø¹Ø¶ `Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª`:\n \n ```py\n@@ -292,5 +282,3 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> predicted_class\n 0\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "b0f00c9316b3e87c3e17cff1fc94c11504240914",
            "filename": "docs/source/ar/tasks/question_answering.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fquestion_answering.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fquestion_answering.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Fquestion_answering.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -167,21 +167,15 @@ pip install transformers datasets evaluate\n \n Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DefaultDataCollator`]. Ø¨Ø®Ù„Ø§Ù Ù…Ø¬Ù…Ù‘Ø¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ ÙÙŠ ğŸ¤— TransformersØŒ Ù„Ø§ ÙŠØ·Ø¨Ù‚ [`DefaultDataCollator`] Ø£ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø³Ø¨Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø­Ø´Ùˆ.\n \n-<frameworkcontent>\n-<pt>\n  \n ```py\n >>> from transformers import DefaultDataCollator\n \n >>> data_collator = DefaultDataCollator()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -232,8 +226,6 @@ pip install transformers datasets evaluate\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n <Tip>\n@@ -275,8 +267,6 @@ pip install transformers datasets evaluate\n \n ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n \n-<frameworkcontent>\n-<pt>\n  \n  Ù‚Ø³Ù‘Ù… Ø§Ù„Ù†Øµ ÙˆØ£Ø±Ø¬Ø¹ ØªÙ†Ø³ÙˆØ±Ø§Øª PyTorch:\n \n@@ -312,5 +302,3 @@ pip install transformers datasets evaluate\n >>> tokenizer.decode(predict_answer_tokens)\n '176 billion parameters and can generate text in 46 languages natural languages and 13'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "d8e6cb29bad51b902396734f3899074c410a42be",
            "filename": "docs/source/ar/tasks/sequence_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fsequence_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fsequence_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Fsequence_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -92,16 +92,12 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n \n Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorWithPadding`].  Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© Ù‡Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ Ù„Ø¬Ø¹Ù„ Ø§Ù„Ø¬Ù…Ù„ Ù…ØªØ³Ø§ÙˆÙŠØ© ÙÙŠ Ø§Ù„Ø·ÙˆÙ„ Ø¯Ø§Ø®Ù„ ÙƒÙ„ Ø¯ÙØ¹Ø©ØŒ Ø¨Ø¯Ù„Ù‹Ø§ Ù…Ù† Ø­Ø´Ùˆ ÙƒØ§Ù…Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„.\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorWithPadding\n \n >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªÙ‚ÙŠÙŠÙ…(Evaluate)\n \n@@ -135,8 +131,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n >>> label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n ```\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø¹Ù„Ù‰ Ø¯Ø±Ø§ÙŠØ© Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ Ø¯Ù‚ÙŠÙ‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`Trainer`], ÙØ§Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ [Ù‡Ù†Ø§](../training#train-with-pytorch-trainer)!\n@@ -197,8 +191,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -230,8 +222,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n \n ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… ÙŠØªØ¬Ø²Ø¦Ø© Ø§Ù„Ù†Øµ ÙˆØ¥Ø±Ø¬Ø§Ø¹ ØªÙ†Ø³ÙˆØ±Ø§Øª PyTorch:\n \n ```py\n@@ -258,5 +248,3 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n >>> model.config.id2label[predicted_class_id]\n 'POSITIVE'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "760b6d370d1716cc6b4432508b93e1a910270ba0",
            "filename": "docs/source/ar/tasks/summarization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fsummarization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Fsummarization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Fsummarization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -118,16 +118,12 @@ pip install transformers datasets evaluate rouge_score\n \n Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorForSeq2Seq`].  Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ Ø£Ø·ÙˆÙ„ Ø·ÙˆÙ„ ÙÙŠ Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„.\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (Evaluate)\n \n@@ -162,8 +158,6 @@ pip install transformers datasets evaluate rouge_score\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -218,8 +212,6 @@ pip install transformers datasets evaluate rouge_score\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -250,8 +242,6 @@ pip install transformers datasets evaluate rouge_score\n \n ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ø³Ù… Ø§Ù„Ù†Øµ ÙˆØ¥Ø±Ø¬Ø¹ `input_ids` ÙƒØªÙ†Ø³ÙˆØ±Ø§Øª PyTorch:\n \n ```py\n@@ -276,5 +266,3 @@ pip install transformers datasets evaluate rouge_score\n >>> tokenizer.decode(outputs[0], skip_special_tokens=True)\n 'the inflation reduction act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in american history. it will ask the ultra-wealthy and corporations to pay their fair share.'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "b3d35352796291ecfd97831e82713b24ff71ed4a",
            "filename": "docs/source/ar/tasks/token_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Ftoken_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Ftoken_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Ftoken_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -151,15 +151,11 @@ pip install transformers datasets evaluate seqeval\n \n Ø§Ù„Ø¢Ù† Ù‚Ù… Ø¨Ø¥Ù†Ø´Ø§Ø¡ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorWithPadding`].Ù…Ù† Ø§Ù„Ø£ÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ Ø£Ø·ÙˆÙ„ Ø·ÙˆÙ„ ÙÙŠ Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForTokenClassification\n \n >>> data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªÙ‚ÙŠÙŠÙ…(Evaluate)\n \n@@ -239,8 +235,6 @@ pip install transformers datasets evaluate seqeval\n ... }\n ```\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ø¹Ù„Ù‰ Ø¯Ø±Ø§ÙŠØ© Ø¨ØªØ¹Ø¯ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`Trainer`], Ø£Ù„Ù‚ Ù†Ø¸Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ [Ù‡Ù†Ø§](../training#train-with-pytorch-trainer)!\n@@ -295,8 +289,6 @@ pip install transformers datasets evaluate seqeval\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -357,8 +349,6 @@ pip install transformers datasets evaluate seqeval\n \n ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ø³Ù‘Ù… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù…ÙˆØ² ÙˆØ£Ø±Ø¬Ø¹ Ø§Ù„Ù…ÙÙˆØªÙ‘Ø±Ø§Øª Ø¨Ù„ØºØ© PyTorch:\n \n ```py\n@@ -402,5 +392,3 @@ pip install transformers datasets evaluate seqeval\n  'O',\n  'O']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "e2beb45acb59c3fcdaf5ce43ea77e76db8f48702",
            "filename": "docs/source/ar/tasks/translation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Ftranslation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftasks%2Ftranslation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftasks%2Ftranslation.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -113,16 +113,12 @@ pip install transformers datasets evaluate sacrebleu\n \n Ø§Ù„Ø¢Ù† Ø£Ù†Ø´Ø¦ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… [`DataCollatorForSeq2Seq`]. Ù…Ù† Ø§Ù„Ø£ÙƒØ«Ø± ÙƒÙØ§Ø¡Ø© *Ø§Ù„Ø­Ø´Ùˆ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠ* Ù„Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ Ø£Ø·ÙˆÙ„ Ø·ÙˆÙ„ ÙÙŠ Ø¯ÙØ¹Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¬Ù…ÙŠØ¹ØŒ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø­Ø´Ùˆ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø£ÙƒÙ…Ù„Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·ÙˆÙ„.\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ø§Ù„ØªÙ‚ÙŠÙŠÙ… (Evaluate)\n \n@@ -169,8 +165,6 @@ pip install transformers datasets evaluate sacrebleu\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Train)\n \n-<frameworkcontent>\n-<pt>\n \n <Tip>\n \n@@ -225,8 +219,6 @@ pip install transformers datasets evaluate sacrebleu\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -260,8 +252,6 @@ pip install transformers datasets evaluate sacrebleu\n \n ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ ØªÙƒØ±Ø§Ø± Ù†ØªØ§Ø¦Ø¬ `pipeline` ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ø£Ø±Ø¯Øª:\n \n-<frameworkcontent>\n-<pt>\n Ù‚Ù… Ø¨ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø±Ù…ÙˆØ² ÙˆØ¥Ø±Ø¬Ø§Ø¹ `input_ids` ÙƒÙ…ÙˆØªØ±Ø§Øª PyTorch:\n \n ```py\n@@ -286,5 +276,3 @@ pip install transformers datasets evaluate sacrebleu\n >>> tokenizer.decode(outputs[0], skip_special_tokens=True)\n 'Les lignÃ©es partagent des ressources avec des bactÃ©ries enfixant l'azote.'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "c509b27a331762094db6782f76664085766eb53e",
            "filename": "docs/source/ar/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Far%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Far%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -58,8 +58,6 @@\n ÙÙŠ Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ†Ù‚Ù„ Ø§Ù„Ø£ÙŠÙ…Ù† Ù„Ù„Ù‚ÙØ² Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ø·Ø§Ø± Ø§Ù„Ø°ÙŠ ØªØ±ÙŠØ¯Ù‡ - ÙˆØ¥Ø°Ø§ ÙƒÙ†Øª ØªØ±ÙŠØ¯ Ø¥Ø®ÙØ§Ø¡ ÙƒÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù„Ø¥Ø·Ø§Ø± Ù…Ø¹ÙŠÙ†ØŒ\n ÙØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø²Ø± ÙÙŠ Ø§Ù„Ø±ÙƒÙ† Ø§Ù„Ø¹Ù„ÙˆÙŠ Ø§Ù„Ø£ÙŠÙ…Ù† Ù…Ù† ÙƒØªÙ„Ø© Ø§Ù„Ø¥Ø·Ø§Ø±!\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ## Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyTorch Trainer\n@@ -139,14 +137,10 @@\n ```py\n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n ## ØªØ¯Ø±ÙŠØ¨ ÙÙŠ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠ\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`] ÙŠÙ‡ØªÙ… Ø¨Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆÙŠØ³Ù…Ø­ Ù„Ùƒ Ø¨Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø³Ø·Ø± ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©. Ø¨Ø§Ù„Ù†Ø³Ø¨Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠÙØ¶Ù„ÙˆÙ† ÙƒØªØ§Ø¨Ø© Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ù…ØŒ ÙŠÙ…ÙƒÙ†Ùƒ Ø£ÙŠØ¶Ù‹Ø§ Ø¶Ø¨Ø· Ù†Ù…ÙˆØ°Ø¬ ğŸ¤— Transformers ÙÙŠ PyTorch Ø§Ù„Ø£ØµÙ„ÙŠ.\n@@ -287,8 +281,6 @@ torch.cuda.empty_cache()\n \n >>> metric.compute()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        },
        {
            "sha": "94fabccb25fd59bb5b8183bec97808ed39a0fe75",
            "filename": "docs/source/de/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -81,8 +81,6 @@ Laden Sie einen Prozessor mit [`AutoProcessor.from_pretrained`]:\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n Mit den `AutoModelFor`-Klassen kÃ¶nnen Sie schlieÃŸlich ein vortrainiertes Modell fÃ¼r eine bestimmte Aufgabe laden (siehe [hier](model_doc/auto) fÃ¼r eine vollstÃ¤ndige Liste der verfÃ¼gbaren Aufgaben). Laden Sie zum Beispiel ein Modell fÃ¼r die Sequenzklassifikation mit [`AutoModelForSequenceClassification.from_pretrained`]:\n \n ```py\n@@ -108,5 +106,3 @@ TensorFlow- und Flax-Checkpoints sind nicht betroffen und kÃ¶nnen in PyTorch-Arc\n </Tip>\n \n Im Allgemeinen empfehlen wir die Verwendung der Klasse \"AutoTokenizer\" und der Klasse \"AutoModelFor\", um trainierte Instanzen von Modellen zu laden. Dadurch wird sichergestellt, dass Sie jedes Mal die richtige Architektur laden. Im nÃ¤chsten [Tutorial] (Vorverarbeitung) erfahren Sie, wie Sie Ihren neu geladenen Tokenizer, Feature Extractor und Prozessor verwenden, um einen Datensatz fÃ¼r die Feinabstimmung vorzuverarbeiten.\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "6bfc444ae50bc2ecba1e4943cb3f87351c754bd4",
            "filename": "docs/source/de/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -79,21 +79,15 @@ Um sicherzustellen, dass Ihr Modell von jemandem verwendet werden kann, der mit\n \n Die Konvertierung eines Checkpoints fÃ¼r ein anderes Framework ist einfach. Stellen Sie sicher, dass Sie PyTorch und TensorFlow installiert haben (siehe [hier](installation) fÃ¼r Installationsanweisungen), und finden Sie dann das spezifische Modell fÃ¼r Ihre Aufgabe in dem anderen Framework. \n \n-<frameworkcontent>\n-<pt>\n Geben Sie `from_tf=True` an, um einen PrÃ¼fpunkt von TensorFlow nach PyTorch zu konvertieren:\n \n ```py\n >>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n >>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ein Modell wÃ¤hrend des Trainings hochladen\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n Die Weitergabe eines Modells an den Hub ist so einfach wie das HinzufÃ¼gen eines zusÃ¤tzlichen Parameters oder RÃ¼ckrufs. Erinnern Sie sich an das [Feinabstimmungs-Tutorial](training), in der Klasse [`TrainingArguments`] geben Sie Hyperparameter und zusÃ¤tzliche Trainingsoptionen an. Eine dieser Trainingsoptionen beinhaltet die MÃ¶glichkeit, ein Modell direkt an den Hub zu pushen. Setzen Sie `push_to_hub=True` in Ihrer [`TrainingArguments`]:\n@@ -119,8 +113,6 @@ Nach der Feinabstimmung Ihres Modells rufen Sie [`~transformers.Trainer.push_to_\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Verwenden Sie die Funktion `push_to_hub`.\n "
        },
        {
            "sha": "baae623d6988c390b8a7e2705fe12622527c93c9",
            "filename": "docs/source/de/preprocessing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fpreprocessing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -153,8 +153,6 @@ SchlieÃŸlich mÃ¶chten Sie, dass der Tokenizer die tatsÃ¤chlichen Tensoren zurÃ¼c\n \n Setzen Sie den Parameter `return_tensors` entweder auf `pt` fÃ¼r PyTorch, oder `tf` fÃ¼r TensorFlow:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> batch_sentences = [\n@@ -174,8 +172,6 @@ Setzen Sie den Parameter `return_tensors` entweder auf `pt` fÃ¼r PyTorch, oder `\n                            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Audio\n "
        },
        {
            "sha": "024c9fe8b3c64ea2c7e5c4538f99618f6a07e6f8",
            "filename": "docs/source/de/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,14 +66,10 @@ Im folgenden Beispiel werden Sie die [`pipeline`] fÃ¼r die Stimmungsanalyse verw\n \n Installieren Sie die folgenden AbhÃ¤ngigkeiten, falls Sie dies nicht bereits getan haben:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n Importieren sie die [`pipeline`] und spezifizieren sie die Aufgabe, welche sie lÃ¶sen mÃ¶chten:\n \n@@ -148,8 +144,6 @@ Die [`pipeline`] kann jedes Modell aus dem [Model Hub](https://huggingface.co/mo\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Use the [`AutoModelForSequenceClassification`] and [`AutoTokenizer`] to load the pretrained model and its associated tokenizer (more on an `AutoClass` below):\n \n ```py\n@@ -158,8 +152,6 @@ Use the [`AutoModelForSequenceClassification`] and [`AutoTokenizer`] to load the\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n Dann kÃ¶nnen Sie das Modell und den Tokenizer in der [`pipeline`] angeben und den `Klassifikator` auf Ihren Zieltext anwenden:\n \n@@ -210,8 +202,6 @@ Der Tokenizer gibt ein WÃ¶rterbuch zurÃ¼ck, das Folgendes enthÃ¤lt:\n \n Genau wie die [`pipeline`] akzeptiert der Tokenizer eine Liste von Eingaben. DarÃ¼ber hinaus kann der Tokenizer den Text auch auffÃ¼llen und kÃ¼rzen, um einen Stapel mit einheitlicher LÃ¤nge zurÃ¼ckzugeben:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -222,15 +212,11 @@ Genau wie die [`pipeline`] akzeptiert der Tokenizer eine Liste von Eingaben. Dar\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n Lesen Sie das Tutorial [preprocessing](./preprocessing) fÃ¼r weitere Details zur Tokenisierung.\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers bietet eine einfache und einheitliche MÃ¶glichkeit, vortrainierte Instanzen zu laden. Das bedeutet, dass Sie ein [`AutoModel`] laden kÃ¶nnen, wie Sie einen [`AutoTokenizer`] laden wÃ¼rden. Der einzige Unterschied ist die Auswahl des richtigen [`AutoModel`] fÃ¼r die Aufgabe. Da Sie eine Text- oder Sequenzklassifizierung vornehmen, laden Sie [`AutoModelForSequenceClassification`]:\n \n ```py\n@@ -262,8 +248,6 @@ Das Modell gibt die endgÃ¼ltigen Aktivierungen in dem Attribut \"logits\" aus. Wen\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -283,8 +267,6 @@ Die ModellausgÃ¤nge verhalten sich auch wie ein Tupel oder ein WÃ¶rterbuch (z.B.\n \n ### Modell speichern\n \n-<frameworkcontent>\n-<pt>\n Sobald Ihr Modell feinabgestimmt ist, kÃ¶nnen Sie es mit seinem Tokenizer speichern, indem Sie [`PreTrainedModel.save_pretrained`] verwenden:\n \n ```py\n@@ -298,22 +280,16 @@ Wenn Sie bereit sind, das Modell erneut zu verwenden, laden Sie es mit [`PreTrai\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n Ein besonders cooles ğŸ¤— Transformers-Feature ist die MÃ¶glichkeit, ein Modell zu speichern und es entweder als PyTorch- oder TensorFlow-Modell wieder zu laden. Der Parameter \"from_pt\" oder \"from_tf\" kann das Modell von einem Framework in das andere konvertieren:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Custom model builds\n \n@@ -327,17 +303,13 @@ Beginnen Sie mit dem Import von [`AutoConfig`] und laden Sie dann das trainierte\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n Create a model from your custom configuration with [`AutoModel.from_config`]:\n \n ```py\n >>> from transformers import AutoModel\n \n >>> my_model = AutoModel.from_config(my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n Weitere Informationen zur Erstellung von benutzerdefinierten Konfigurationen finden Sie in der Anleitung [Erstellen einer benutzerdefinierten Architektur](./create_a_model).\n "
        },
        {
            "sha": "004f67291979424d2f51c503a33fe62feaa50087",
            "filename": "docs/source/de/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ pip install -r requirements.txt\n \n ## Ein Skript ausfÃ¼hren\n \n-<frameworkcontent>\n-<pt>\n Das Beispielskript lÃ¤dt einen Datensatz aus der ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) Bibliothek herunter und verarbeitet ihn vor. Dann nimmt das Skript eine Feinabstimmung eines Datensatzes mit dem [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) auf einer Architektur vor, die eine Zusammenfassung unterstÃ¼tzt. Das folgende Beispiel zeigt, wie die Feinabstimmung von [T5-small](https://huggingface.co/google-t5/t5-small) auf dem Datensatz [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) durchgefÃ¼hrt wird. Das T5-Modell benÃ¶tigt aufgrund der Art und Weise, wie es trainiert wurde, ein zusÃ¤tzliches Argument `source_prefix`. Mit dieser Eingabeaufforderung weiÃŸ T5, dass es sich um eine Zusammenfassungsaufgabe handelt.\n \n ```bash\n@@ -103,8 +101,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Verteiltes Training und gemischte PrÃ¤zision\n \n@@ -134,8 +130,6 @@ TensorFlow-Skripte verwenden eine [`MirroredStrategy`](https://www.tensorflow.or\n \n ## Ein Skript auf einer TPU ausfÃ¼hren\n \n-<frameworkcontent>\n-<pt>\n Tensor Processing Units (TPUs) sind speziell fÃ¼r die Beschleunigung der Leistung konzipiert. PyTorch unterstÃ¼tzt TPUs mit dem [XLA](https://www.tensorflow.org/xla) Deep Learning Compiler (siehe [hier](https://github.com/pytorch/xla/blob/master/README.md) fÃ¼r weitere Details). Um eine TPU zu verwenden, starten Sie das Skript `xla_spawn.py` und verwenden das Argument `num_cores`, um die Anzahl der TPU-Kerne festzulegen, die Sie verwenden mÃ¶chten.\n \n ```bash\n@@ -153,8 +147,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## FÃ¼hren Sie ein Skript mit ğŸ¤— Accelerate aus.\n "
        },
        {
            "sha": "92051d5d1a584334bd3b60930d904b3faa9b101f",
            "filename": "docs/source/de/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fde%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fde%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -73,8 +73,6 @@ An dieser Stelle sollten Sie dem Abschnitt folgen, der dem Rahmen entspricht, de\n in der rechten Seitenleiste kÃ¶nnen Sie zu dem gewÃ¼nschten Abschnitt springen - und wenn Sie den gesamten Inhalt eines bestimmten Frameworks ausblenden mÃ¶chten,\n klicken Sie einfach auf die SchaltflÃ¤che oben rechts im Block des jeweiligen Frameworks!\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ## Trainieren mit PyTorch Trainer\n@@ -155,15 +153,11 @@ AnschlieÃŸend kÃ¶nnen Sie Ihr Modell durch den Aufruf von [`~transformers.Traine\n ```py\n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n \n ## Trainieren in nativem PyTorch\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`] kÃ¼mmert sich um die Trainingsschleife und ermÃ¶glicht die Feinabstimmung eines Modells in einer einzigen Codezeile. FÃ¼r Benutzer, die es vorziehen, ihre eigene Trainingsschleife zu schreiben, kÃ¶nnen Sie auch eine Feinabstimmung eines ğŸ¤— Transformers-Modells in nativem PyTorch vornehmen.\n@@ -305,8 +299,6 @@ Genauso wie Sie eine Bewertungsfunktion zu [`Trainer`] hinzugefÃ¼gt haben, mÃ¼ss\n \n >>> metric.compute()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        },
        {
            "sha": "2cdec895efc073473e69e35643e44a1305365df9",
            "filename": "docs/source/en/model_doc/efficientloftr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fefficientloftr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fefficientloftr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fefficientloftr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -156,8 +156,6 @@ processed_outputs = processor.post_process_keypoint_matching(outputs, image_size\n - post_process_keypoint_matching\n - visualize_keypoint_matching\n \n-<frameworkcontent>\n-<pt>\n ## EfficientLoFTRModel\n \n [[autodoc]] EfficientLoFTRModel\n@@ -170,5 +168,3 @@ processed_outputs = processor.post_process_keypoint_matching(outputs, image_size\n \n - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "847fabdaac20a2bef77466cc17f89684df9ebc37",
            "filename": "docs/source/en/model_doc/lightglue.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Flightglue.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Flightglue.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Flightglue.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -148,13 +148,9 @@ processed_outputs = processor.post_process_keypoint_matching(outputs, image_size\n - post_process_keypoint_matching\n - visualize_keypoint_matching\n \n-<frameworkcontent>\n-<pt>\n ## LightGlueForKeypointMatching\n \n [[autodoc]] LightGlueForKeypointMatching\n \n - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "050cae276467b675de65e07bcb31e166f9b7938f",
            "filename": "docs/source/en/model_doc/modernbert-decoder.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert-decoder.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert-decoder.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert-decoder.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -167,8 +167,6 @@ echo \"The future of artificial intelligence is\" | transformers run --task text-g\n \n [[autodoc]] ModernBertDecoderConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## ModernBertDecoderModel\n \n@@ -185,5 +183,3 @@ echo \"The future of artificial intelligence is\" | transformers run --task text-g\n [[autodoc]] ModernBertDecoderForSequenceClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "872da561fbf81d1eff3282a1d789c4139bcb69fe",
            "filename": "docs/source/en/model_doc/modernbert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fmodernbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -93,8 +93,6 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n \n [[autodoc]] ModernBertConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## ModernBertModel\n \n@@ -131,5 +129,3 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n The ModernBert model can be fine-tuned using the HuggingFace Transformers library with its [official script](https://github.com/huggingface/transformers/blob/main/examples/pytorch/question-answering/run_qa.py) for question-answering tasks.\n \n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "020b26431939f7b65aeaabcb70745d71a977895d",
            "filename": "docs/source/en/model_doc/phi3.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi3.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi3.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fphi3.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -72,8 +72,6 @@ Phi-3 has been integrated in the development version (4.40.0.dev) of `transforme\n \n [[autodoc]] Phi3Config\n \n-<frameworkcontent>\n-<pt>\n \n ## Phi3Model\n \n@@ -96,5 +94,3 @@ Phi-3 has been integrated in the development version (4.40.0.dev) of `transforme\n [[autodoc]] Phi3ForTokenClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "a564eb6145af62277e77e7218c038581eb374a83",
            "filename": "docs/source/en/model_doc/phimoe.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fphimoe.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fphimoe.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fphimoe.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -101,8 +101,6 @@ print(output[0]['generated_text'])\n \n [[autodoc]] PhimoeConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## PhimoeModel\n \n@@ -120,5 +118,3 @@ print(output[0]['generated_text'])\n [[autodoc]] PhimoeForSequenceClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "81bb91861de292430b6588a6cf1e7ac2249f3d7b",
            "filename": "docs/source/en/model_doc/superglue.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fsuperglue.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fsuperglue.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fsuperglue.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -148,13 +148,9 @@ processed_outputs = processor.post_process_keypoint_matching(outputs, image_size\n - post_process_keypoint_matching\n - visualize_keypoint_matching\n \n-<frameworkcontent>\n-<pt>\n ## SuperGlueForKeypointMatching\n \n [[autodoc]] SuperGlueForKeypointMatching\n \n - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "9a9170d29b7e3d785caf8e42e1c5ff9da736fe94",
            "filename": "docs/source/en/model_doc/xglm.md",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fxglm.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Fmodel_doc%2Fxglm.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Fmodel_doc%2Fxglm.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -67,8 +67,6 @@ This model was contributed by [Suraj](https://huggingface.co/valhalla). The orig\n \n [[autodoc]] XGLMTokenizerFast\n \n-<frameworkcontent>\n-<pt>\n \n ## XGLMModel\n "
        },
        {
            "sha": "33dc3fc518e639ef21b0def7c34432aceb09b6bc",
            "filename": "docs/source/en/tasks/asr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Ftasks%2Fasr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Ftasks%2Fasr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fasr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -228,8 +228,6 @@ Your `compute_metrics` function is ready to go now, and you'll return to it when\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n If you aren't familiar with finetuning a model with the [`Trainer`], take a look at the basic tutorial [here](../training#train-with-pytorch-trainer)!\n@@ -294,8 +292,6 @@ Once training is completed, share your model to the Hub with the [`~transformers\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -336,8 +332,6 @@ The transcription is decent, but it could be better! Try finetuning your model o\n \n You can also manually replicate the results of the `pipeline` if you'd like:\n \n-<frameworkcontent>\n-<pt>\n Load a processor to preprocess the audio file and transcription and return the `input` as PyTorch tensors:\n \n ```py\n@@ -367,5 +361,3 @@ Get the predicted `input_ids` with the highest probability, and use the processo\n >>> transcription\n ['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "52e2f965ee252c55c907525877c69ef01d96e9a1",
            "filename": "docs/source/en/tasks/audio_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fen%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Faudio_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -187,8 +187,6 @@ Your `compute_metrics` function is ready to go now, and you'll return to it when\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n If you aren't familiar with finetuning a model with the [`Trainer`], take a look at the basic tutorial [here](../training#train-with-pytorch-trainer)!\n@@ -247,8 +245,6 @@ Once training is completed, share your model to the Hub with the [`~transformers\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -289,8 +285,6 @@ The simplest way to try out your fine-tuned model for inference is to use it in\n \n You can also manually replicate the results of the `pipeline` if you'd like:\n \n-<frameworkcontent>\n-<pt>\n Load a feature extractor to preprocess the audio file and return the `input` as PyTorch tensors:\n \n ```py\n@@ -320,5 +314,3 @@ Get the class with the highest probability, and use the model's `id2label` mappi\n >>> predicted_label\n 'cash_deposit'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "67c0911dde9e9e85eba50f5aae2f38e3f71cab96",
            "filename": "docs/source/es/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -81,8 +81,6 @@ Carga un procesador con [`AutoProcessor.from_pretrained`]:\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n Finalmente, las clases `AutoModelFor` te permiten cargar un modelo preentrenado para una tarea dada (revisa [aquÃ­](model_doc/auto) para conocer la lista completa de tareas disponibles). Por ejemplo, cargue un modelo para clasificaciÃ³n de secuencias con [`AutoModelForSequenceClassification.from_pretrained`]:\n \n ```py\n@@ -100,5 +98,3 @@ Reutiliza fÃ¡cilmente el mismo checkpoint para cargar una aquitectura para algun\n ```\n \n Generalmente recomendamos utilizar las clases `AutoTokenizer` y `AutoModelFor` para cargar instancias pre-entrenadas de modelos. Ã‰sto asegurarÃ¡ que cargues la arquitectura correcta en cada ocasiÃ³n. En el siguiente [tutorial](preprocessing), aprende a usar tu tokenizador reciÃ©n cargado, el extractor de caracterÃ­sticas y el procesador para preprocesar un dataset para fine-tuning.\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "4463952f4846bc4feedf40ba37f5945bf88adad4",
            "filename": "docs/source/es/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -111,8 +111,6 @@ TambiÃ©n puedes guardar los archivos de configuraciÃ³n como un diccionario; o in\n \n El siguiente paso serÃ¡ crear un [modelo](main_classes/models). El modelo, al que a veces tambiÃ©n nos referimos como arquitectura, es el encargado de definir cada capa y quÃ© operaciones se realizan. Los atributos como `num_hidden_layers` de la configuraciÃ³n se usan para definir la arquitectura. Todos los modelos comparten una clase base, [`PreTrainedModel`], y algunos mÃ©todos comunes que se pueden usar para redimensionar los _embeddings_ o para recortar cabezas de auto-atenciÃ³n (tambiÃ©n llamadas _self-attention heads_). AdemÃ¡s, todos los modelos son subclases de [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) o [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html), lo que significa que son compatibles con su respectivo framework. \n \n-<frameworkcontent>\n-<pt>\n \n Carga los atributos de tu configuraciÃ³n personalizada en el modelo de la siguiente forma:\n \n@@ -136,16 +134,12 @@ Cuando cargues tus pesos del preentrenamiento, el modelo por defecto se carga au\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Cabezas de modelo \n \n En este punto del tutorial, tenemos un modelo DistilBERT base que devuelve los *hidden states* o estados ocultos. Los *hidden states* se pasan como parÃ¡metros de entrada a la cabeza del modelo para producir la salida. ğŸ¤— Transformers ofrece una cabeza de modelo diferente para cada tarea, siempre y cuando el modelo sea compatible para la tarea (por ejemplo, no puedes usar DistilBERT para una tarea secuencia a secuencia como la traducciÃ³n).\n \n \n-<frameworkcontent>\n-<pt>\n \n Por ejemplo,  [`DistilBertForSequenceClassification`] es un modelo DistilBERT base con una cabeza de clasificaciÃ³n de secuencias. La cabeza de clasificaciÃ³n de secuencias es una capa superior que precede a la recolecciÃ³n de las salidas.\n \n@@ -163,8 +157,6 @@ Puedes reutilizar este punto de guardado o *checkpoint* para otra tarea fÃ¡cilme\n \n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Tokenizer\n "
        },
        {
            "sha": "3599df38950a765045180a7f56e6821dac6e7eef",
            "filename": "docs/source/es/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,14 +66,10 @@ En el siguiente ejemplo, usarÃ¡s el [`pipeline`] para anÃ¡lisis de sentimiento.\n \n Instala las siguientes dependencias si aÃºn no lo has hecho:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n Importa [`pipeline`] y especifica la tarea que deseas completar:\n \n@@ -142,8 +138,6 @@ El [`pipeline`] puede acomodarse a cualquier modelo del [Model Hub](https://hugg\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Usa [`AutoModelForSequenceClassification`] y ['AutoTokenizer'] para cargar un modelo preentrenado y un tokenizador asociado (mÃ¡s en un `AutoClass` debajo):\n \n ```py\n@@ -153,9 +147,7 @@ Usa [`AutoModelForSequenceClassification`] y ['AutoTokenizer'] para cargar un mo\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n \n-</pt>\n \n-</frameworkcontent>\n \n DespuÃ©s puedes especificar el modelo y el tokenizador en el [`pipeline`], y aplicar el `classifier` en tu texto objetivo:\n \n@@ -207,8 +199,6 @@ El tokenizador devolverÃ¡ un diccionario conteniendo:\n \n Como con el [`pipeline`], el tokenizador aceptarÃ¡ una lista de inputs. AdemÃ¡s, el tokenizador tambiÃ©n puede rellenar (pad, en inglÃ©s) y truncar el texto para devolver un lote (batch, en inglÃ©s) de longitud uniforme:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -219,15 +209,11 @@ Como con el [`pipeline`], el tokenizador aceptarÃ¡ una lista de inputs. AdemÃ¡s,\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n Lee el tutorial de [preprocessing](./preprocessing) para mÃ¡s detalles acerca de la tokenizaciÃ³n.\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers provee una forma simple y unificada de cargar tus instancias preentrenadas. Esto significa que puedes cargar un [`AutoModel`] como cargarÃ­as un [`AutoTokenizer`]. La Ãºnica diferencia es seleccionar el [`AutoModel`] correcto para la tarea. Ya que estÃ¡s clasificando texto, o secuencias, carga [`AutoModelForSequenceClassification`]:\n \n ```py\n@@ -259,8 +245,6 @@ El modelo producirÃ¡ las activaciones finales en el atributo `logits`. Aplica la\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -280,8 +264,6 @@ Los outputs del modelo tambiÃ©n se comportan como tuplas o diccionarios (e.g., p\n \n ### Guarda un modelo\n \n-<frameworkcontent>\n-<pt>\n Una vez que se haya hecho fine-tuning a tu modelo puedes guardarlo con tu tokenizador usando [`PreTrainedModel.save_pretrained`]:\n \n ```py\n@@ -296,20 +278,14 @@ Cuando quieras usar el modelo otra vez cÃ¡rgalo con [`PreTrainedModel.from_pretr\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n \n-</pt>\n \n-</frameworkcontent>\n \n Una caracterÃ­stica particularmente interesante de ğŸ¤— Transformers es la habilidad de guardar el modelo y cargarlo como un modelo de PyTorch o TensorFlow. El parÃ¡metro `from_pt` o `from_tf` puede convertir el modelo de un framework al otro:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "462eb5bc303405f64648707e7d9443490452321f",
            "filename": "docs/source/es/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ pip install -r requirements.txt\n \n ## Ejecutar un script\n \n-<frameworkcontent>\n-<pt>\n El script de ejemplo descarga y preprocesa un conjunto de datos de la biblioteca ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/). Luego, el script ajusta un conjunto de datos con [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) en una arquitectura que soporta la tarea de resumen. El siguiente ejemplo muestra cÃ³mo ajustar un [T5-small](https://huggingface.co/google-t5/t5-small) en el conjunto de datos [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail). El modelo T5 requiere un argumento adicional `source_prefix` debido a cÃ³mo fue entrenado. Este aviso le permite a T5 saber que se trata de una tarea de resumir.\n \n ```bash\n@@ -103,8 +101,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Entrenamiento distribuido y de precisiÃ³n mixta\n \n@@ -134,8 +130,6 @@ Los scripts de TensorFlow utilizan [`MirroredStrategy`](https://www.tensorflow.o\n \n ## Ejecutar un script en una TPU\n \n-<frameworkcontent>\n-<pt>\n Las Unidades de Procesamiento de Tensor (TPUs) estÃ¡n diseÃ±adas especÃ­ficamente para acelerar el rendimiento. PyTorch admite TPU con el compilador de aprendizaje profundo [XLA](https://www.tensorflow.org/xla) (consulta [aquÃ­](https://github.com/pytorch/xla/blob/master/README.md) para obtener mÃ¡s detalles). Para usar una TPU, inicia el script `xla_spawn.py` y usa el argumento `num_cores` para establecer la cantidad de nÃºcleos de TPU que deseas usar.\n \n ```bash\n@@ -153,8 +147,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Ejecutar un script con ğŸ¤— Accelerate\n "
        },
        {
            "sha": "9c29ed6f0406a096256058dfc5fedba49fd1f0b6",
            "filename": "docs/source/es/serialization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fserialization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Fserialization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Fserialization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -195,8 +195,6 @@ Para exportar un modelo que estÃ¡ almacenado localmente, deberÃ¡s tener los peso\n y tokenizadores del modelo almacenados en un directorio. Por ejemplo, podemos cargar \n y guardar un checkpoint de la siguiente manera:\n \n-<frameworkcontent>\n-<pt>\n ```python\n >>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n \n@@ -214,8 +212,6 @@ del paquete `transformers.onnx` al directorio deseado:\n ```bash\n python -m transformers.onnx --model=local-pt-checkpoint onnx/\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Seleccionar caracterÃ­sticas para diferentes topologÃ­as de un modelo\n "
        },
        {
            "sha": "30c880d1f1890f6b31cdfaf06e2d4358a6453476",
            "filename": "docs/source/es/tasks/asr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fasr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fasr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Fasr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -224,8 +224,6 @@ Ahora tu funciÃ³n `compute_metrics` (computar mÃ©tricas) estÃ¡ lista y podrÃ¡s u\n \n ## Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n Si no tienes experiencia haciÃ©ndole fine-tuning a un modelo con el [`Trainer`], Â¡Ã©chale un vistazo al tutorial bÃ¡sico [aquÃ­](../training#train-with-pytorch-trainer)!\n@@ -289,8 +287,6 @@ Una vez que el entrenamiento haya sido completado, comparte tu modelo en el Hub\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -331,8 +327,6 @@ La transcripciÃ³n es decente, pero podrÃ­a ser mejor. Â¡Intenta hacerle fine-tun\n \n TambiÃ©n puedes replicar de forma manual los resultados del `pipeline` si lo deseas:\n \n-<frameworkcontent>\n-<pt>\n Carga un procesador para preprocesar el archivo de audio y la transcripciÃ³n y devuelve el `input` como un tensor de PyTorch:\n \n ```py\n@@ -362,5 +356,3 @@ ObtÃ©n los identificadores de los tokens con mayor probabilidad en las prediccio\n >>> transcription\n ['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "3b044614326255e298174a4d9f045bded9293110",
            "filename": "docs/source/es/tasks/audio_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Faudio_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -187,8 +187,6 @@ Ahora tu funciÃ³n `compute_metrics` (computar mÃ©tricas) estÃ¡ lista y podrÃ¡s u\n \n ## Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n Â¡Si no tienes experiencia haciÃ©ndo *fine-tuning* a un modelo con el [`Trainer`], Ã©chale un vistazo al tutorial bÃ¡sico [aquÃ­](../training#train-with-pytorch-trainer)!\n@@ -246,8 +244,6 @@ Una vez que el entrenamiento haya sido completado, comparte tu modelo en el Hub\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -288,8 +284,6 @@ La manera mÃ¡s simple de probar tu modelo para hacer inferencia es usarlo en un\n \n TambiÃ©n puedes replicar de forma manual los resultados del `pipeline` si lo deseas:\n \n-<frameworkcontent>\n-<pt>\n Carga el feature extractor para preprocesar el archivo de audio y devuelve el `input` como un tensor de PyTorch:\n \n ```py\n@@ -319,5 +313,3 @@ ObtÃ©n los identificadores de los clases con mayor probabilidad y usa el *mappin\n >>> predicted_label\n 'cash_deposit'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "b5937cdb13cfc6d1038e8cd97592bc368d738102",
            "filename": "docs/source/es/tasks/language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Flanguage_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Flanguage_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Flanguage_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -160,8 +160,6 @@ Aplica la funciÃ³n `group_texts` sobre todo el dataset:\n \n Para modelados de lenguaje causales, usa [`DataCollatorForLanguageModeling`] para crear un lote de ejemplos. Esto tambiÃ©n *rellenarÃ¡ dinÃ¡micamente* tu texto a la dimensiÃ³n del elemento mÃ¡s largo del lote para que de esta manera tengan largo uniforme. Si bien es posible rellenar tu texto en la funciÃ³n `tokenizer` mediante el argumento `padding=True`, el rellenado dinÃ¡mico es mÃ¡s eficiente. \n \n-<frameworkcontent>\n-<pt>\n Puedes usar el token de final de secuencia como el token de relleno y asignar `mlm=False`. Esto usarÃ¡ los inputs como etiquetas movidas un elemento hacia la derecha:\n \n ```py\n@@ -179,17 +177,13 @@ Para modelados de lenguaje por enmascaramiento usa el mismo [`DataCollatorForLan\n >>> tokenizer.pad_token = tokenizer.eos_token\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Modelado de lenguaje causal\n \n El modelado de lenguaje causal es frecuentemente utilizado para generaciÃ³n de texto. Esta secciÃ³n te muestra cÃ³mo realizar fine-tuning a [DistilGPT2](https://huggingface.co/distilbert/distilgpt2) para generar nuevo texto.\n \n ### Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n Carga DistilGPT2 con [`AutoModelForCausalLM`]:\n \n ```py\n@@ -228,17 +222,13 @@ A este punto, solo faltan tres pasos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Modelado de lenguaje por enmascaramiento\n \n El modelado de lenguaje por enmascaramiento es tambiÃ©n conocido como una tarea de rellenar la mÃ¡scara, pues predice un token enmascarado dada una secuencia. Los modelos de lenguaje por enmascaramiento requieren una buena comprensiÃ³n del contexto de una secuencia entera, en lugar de solo el contexto a la izquierda. Esta secciÃ³n te enseÃ±a como realizar el fine-tuning de [DistilRoBERTa](https://huggingface.co/distilbert/distilroberta-base) para predecir una palabra enmascarada.\n \n ### Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n Carga DistilRoBERTa con [`AutoModelForMaskedlM`]:\n \n ```py\n@@ -278,8 +268,6 @@ A este punto, solo faltan tres pasos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "d73688e36a8e431f4ef3146a088dce76264b08f0",
            "filename": "docs/source/es/tasks/multiple_choice.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fmultiple_choice.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fmultiple_choice.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Fmultiple_choice.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -102,8 +102,6 @@ El [`DataCollatorForMultipleChoice`] aplanarÃ¡ todas las entradas del modelo, le\n \n ## Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n Carga el modelo BERT con [`AutoModelForMultipleChoice`]:\n \n ```py\n@@ -146,5 +144,3 @@ En este punto, solo quedan tres pasos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "085f381aa0f5f270520df8b5cb7f631112baa0e9",
            "filename": "docs/source/es/tasks/question_answering.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fquestion_answering.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fquestion_answering.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Fquestion_answering.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -138,20 +138,14 @@ Quita las columnas que no necesites:\n \n Usa el [`DefaultDataCollator`] para crear un lote de ejemplos. A diferencia de los otros collators de datos en ğŸ¤— Transformers, el `DefaultDataCollator` no aplica ningÃºn procesamiento adicional (como el rellenado).\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DefaultDataCollator\n \n >>> data_collator = DefaultDataCollator()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n Carga el modelo DistilBERT con [`AutoModelForQuestionAnswering`]:\n \n ```py\n@@ -194,8 +188,6 @@ En este punto, solo quedan tres pasos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "7525ccaa41f6e1182c7a150a3c7aa6bbbe6c799e",
            "filename": "docs/source/es/tasks/summarization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fsummarization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fes%2Ftasks%2Fsummarization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fes%2Ftasks%2Fsummarization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -96,20 +96,14 @@ Usa la funciÃ³n [`~datasets.Dataset.map`] de ğŸ¤— Datasets para aplicar la funci\n \n Usa [`DataCollatorForSeq2Seq`] para crear un lote de ejemplos. Esto tambiÃ©n *rellenarÃ¡ dinÃ¡micamente* tu texto y etiquetas a la dimensiÃ³n del elemento mÃ¡s largo del lote para que tengan un largo uniforme. Si bien es posible rellenar tu texto en la funciÃ³n `tokenizer` mediante el argumento `padding=True`, el rellenado dinÃ¡mico es mÃ¡s eficiente.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Entrenamiento\n \n-<frameworkcontent>\n-<pt>\n Carga T5 con [`AutoModelForSeq2SeqLM`]:\n \n ```py\n@@ -154,8 +148,6 @@ En este punto, solo faltan tres pasos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "3eaa2946d7459cb9541f503d687efa0e36c66425",
            "filename": "docs/source/fr/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Ffr%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -136,8 +136,6 @@ Chargez un processeur avec [`AutoProcessor.from_pretrained`]:\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n Enfin, les classes `AutoModelFor` vous permettent de charger un modÃ¨le prÃ©-entraÃ®nÃ© pour une tÃ¢che donnÃ©e (voir [ici](model_doc/auto) pour une liste complÃ¨te des tÃ¢ches disponibles). Par exemple, chargez un modÃ¨le pour la classification de sÃ©quence avec [`AutoModelForSequenceClassification.from_pretrained`]:\n \n ```py\n@@ -163,5 +161,3 @@ Les points de contrÃ´le TensorFlow et Flax ne sont pas concernÃ©s, et peuvent Ãª\n </Tip>\n \n En gÃ©nÃ©ral, nous recommandons d'utiliser les classes `AutoTokenizer` et `AutoModelFor` pour charger des instances prÃ©-entraÃ®nÃ©es de tokenizers et modÃ¨les respectivement. Cela vous permettra de charger la bonne architecture Ã  chaque fois. Dans le prochain [tutoriel](preprocessing), vous apprenez Ã  utiliser un tokenizer, processeur d'image, extracteur de caractÃ©ristiques et processeur pour prÃ©-traiter un jeu de donnÃ©es pour le fine-tuning.\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "a0cf66e76dd366bb7784c47705f0b25629829a95",
            "filename": "docs/source/fr/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Ffr%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -28,14 +28,10 @@ Avant de commencer, assurez-vous que vous avez installÃ© toutes les bibliothÃ¨qu\n \n Vous aurez aussi besoin d'installer votre bibliothÃ¨que d'apprentissage profond favorite :\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Pipeline\n \n@@ -126,8 +122,6 @@ Le [`pipeline`] peut Ãªtre utilisÃ© avec n'importe quel modÃ¨le du [Hub](https:/\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Utilisez [`AutoModelForSequenceClassification`] et [`AutoTokenizer`] pour charger le modÃ¨le prÃ©-entraÃ®nÃ© et le tokenizer adaptÃ© (plus de dÃ©tails sur une `AutoClass` dans la section suivante) :\n \n ```py\n@@ -136,8 +130,6 @@ Utilisez [`AutoModelForSequenceClassification`] et [`AutoTokenizer`] pour charge\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n SpÃ©cifiez le modÃ¨le et le tokenizer dans le [`pipeline`], et utilisez le `classifier` sur le texte en franÃ§ais :\n \n@@ -187,8 +179,6 @@ Le tokenizer retourne un dictionnaire contenant :\n \n Un tokenizer peut Ã©galement accepter une liste de textes, et remplir et tronquer le texte pour retourner un Ã©chantillon de longueur uniforme :\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -199,8 +189,6 @@ Un tokenizer peut Ã©galement accepter une liste de textes, et remplir et tronque\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -210,8 +198,6 @@ Consultez le tutoriel [prÃ©traitement](./preprocessing) pour plus de dÃ©tails su\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers fournit un moyen simple et unifiÃ© de charger des instances prÃ©-entraÃ®nÃ©es. Cela signifie que vous pouvez charger un [`AutoModel`] comme vous chargeriez un [`AutoTokenizer`]. La seule diffÃ©rence est de sÃ©lectionner l'[`AutoModel`] appropriÃ© pour la tÃ¢che. Pour une classification de texte (ou de sÃ©quence de textes), vous devez charger [`AutoModelForSequenceClassification`] :\n \n ```py\n@@ -243,8 +229,6 @@ Le modÃ¨le produit les activations finales dans l'attribut `logits`. Appliquez l\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -254,8 +238,6 @@ Tous les modÃ¨les ğŸ¤— Transformers (PyTorch ou TensorFlow) produisent les tenso\n \n ### Sauvegarder un modÃ¨le\n \n-<frameworkcontent>\n-<pt>\n Une fois que votre modÃ¨le est finetunÃ©, vous pouvez le sauvegarder avec son tokenizer en utilisant [`PreTrainedModel.save_pretrained`] :\n \n ```py\n@@ -269,22 +251,16 @@ Lorsque vous voulez rÃ©utiliser le modÃ¨le, rechargez-le avec [`PreTrainedModel.\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n Une fonctionnalitÃ© particuliÃ¨rement cool ğŸ¤— Transformers est la possibilitÃ© d'enregistrer un modÃ¨le et de le recharger en tant que modÃ¨le PyTorch ou TensorFlow. Le paramÃ¨tre `from_pt` ou `from_tf` permet de convertir le modÃ¨le d'un framework Ã  l'autre :\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Constructions de modÃ¨les personnalisÃ©s\n \n@@ -298,17 +274,13 @@ Commencez par importer [`AutoConfig`], puis chargez le modÃ¨le prÃ©-entraÃ®nÃ© q\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n CrÃ©ez un modÃ¨le personnalisÃ© Ã  partir de votre configuration avec [`AutoModel.from_config`] :\n \n ```py\n >>> from transformers import AutoModel\n \n >>> my_model = AutoModel.from_config(my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n Consultez le guide [CrÃ©er une architecture personnalisÃ©e](./create_a_model) pour plus d'informations sur la crÃ©ation de configurations personnalisÃ©es.\n "
        },
        {
            "sha": "1acf683253daa2a74893c8e474dd262d775ccc84",
            "filename": "docs/source/fr/run_scripts_fr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Frun_scripts_fr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Ffr%2Frun_scripts_fr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Ffr%2Frun_scripts_fr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -86,8 +86,6 @@ pip install -r requirements.txt\n \n ## ExÃ©cuter un script\n \n-<frameworkcontent>\n-<pt>\n \n Le script d'exemple tÃ©lÃ©charge et prÃ©traite un jeu de donnÃ©es Ã  partir de la bibliothÃ¨que ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/). Ensuite, le script affine un ensemble de donnÃ©es Ã  l'aide de [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) sur une architecture qui prend en charge la tÃ¢che de rÃ©sumÃ©. L'exemple suivant montre comment ajuster le modÃ¨le [T5-small](https://huggingface.co/google-t5/t5-small) sur les donnÃ©es [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail). Le modÃ¨le T5 nÃ©cessite un argument supplÃ©mentaire `source_prefix` en raison de la faÃ§on dont il a Ã©tÃ© entraÃ®nÃ©. Cette invite permet Ã  T5 de savoir qu'il s'agit d'une tÃ¢che de rÃ©sumÃ©.\n \n@@ -105,8 +103,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## EntraÃ®nement distribuÃ© et prÃ©cision mixte\n \n@@ -136,8 +132,6 @@ Les scripts TensorFlow utilisent une Strategie en Miroir [`MirroredStrategy`](ht\n \n ## ExÃ©cuter un script sur un TPU \n \n-<frameworkcontent>\n-<pt>\n \n Les unitÃ©s de traitement de tenseurs (UTT) (TPU) sont spÃ©cialement conÃ§ues pour accÃ©lÃ©rer les performances. PyTorch prend en charge les TPU avec le compilateur de deep learning [XLA](https://www.tensorflow.org/xla). Pour utiliser un TPU, lancez le script xla_spawn.py et utilisez l'argument num_cores pour dÃ©finir le nombre de cÅ“urs TPU que vous souhaitez utilise\n \n@@ -156,8 +150,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## ExÃ©cuter un script avec ğŸ¤— Accelerate \n "
        },
        {
            "sha": "74587ef53c19c6dcf61e87074396cd1f4c67133a",
            "filename": "docs/source/it/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -80,8 +80,6 @@ Carica un processore con [`AutoProcessor.from_pretrained`]:\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n Infine, le classi `AutoModelFor` ti permettono di caricare un modello pre-allenato per un determinato compito (guarda [qui](model_doc/auto) per una lista completa di compiti presenti). Per esempio, carica un modello per la classificazione di sequenze con [`AutoModelForSequenceClassification.from_pretrained`]:\n \n ```py\n@@ -100,5 +98,3 @@ Semplicemente utilizza lo stesso checkpoint per caricare un'architettura per un\n \n Generalmente, raccomandiamo di utilizzare la classe `AutoTokenizer` e la classe `AutoModelFor` per caricare istanze pre-allenate dei modelli. Questo ti assicurerÃ  di aver caricato la corretta architettura ogni volta. Nel prossimo [tutorial](preprocessing), imparerai come utilizzare il tokenizer, il feature extractor e il processore per elaborare un dataset per il fine-tuning.\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "174083e73e671b44c06c9ba218118604984f8706",
            "filename": "docs/source/it/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -111,8 +111,6 @@ Puoi anche salvare il file di configurazione come dizionario oppure come la diff\n \n Il prossimo passo e di creare [modello](main_classes/models). Il modello - vagamente riferito anche come architettura - definisce cosa ogni strato deve fare e quali operazioni stanno succedendo. Attributi come `num_hidden_layers` provenienti dalla configurazione sono usati per definire l'architettura. Ogni modello condivide la classe base [`PreTrainedModel`] e alcuni metodi comuni come il ridimensionamento degli input embeddings e la soppressione delle self-attention heads . Inoltre, tutti i modelli sono la sottoclasse di [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) o [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html). Cio significa che i modelli sono compatibili con l'uso di ciascun di framework.\n \n-<frameworkcontent>\n-<pt>\n Carica gli attributi della tua configurazione personalizzata nel modello:\n \n ```py\n@@ -135,15 +133,11 @@ Quando carichi pesi pre-allenati, la configurazione del modello predefinito Ã¨ a\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Model head\n \n A questo punto, hai un modello DistilBERT base i cui output sono gli *hidden states* (in italiano stati nascosti). Gli stati nascosti sono passati come input a un model head per produrre l'output finale. ğŸ¤— Transformers fornisce un model head diverso per ogni attivitÃ  fintanto che il modello supporta l'attivitÃ   (i.e., non puoi usare DistilBERT per un attivitÃ  sequence-to-sequence come la traduzione).\n \n-<frameworkcontent>\n-<pt>\n Per esempio, [`DistilBertForSequenceClassification`] Ã¨ un modello DistilBERT base con una testa di classificazione per sequenze. La sequenza di classificazione head Ã¨ uno strato lineare sopra gli output ragruppati.\n \n ```py\n@@ -159,8 +153,6 @@ Riutilizza facilmente questo checkpoint per un'altra attivitÃ  passando ad un mo\n \n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Tokenizer\n "
        },
        {
            "sha": "ce06ade1fe2c685f58e6747d27971fe2488dcd9c",
            "filename": "docs/source/it/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -79,8 +79,6 @@ Per assicurarti che il tuo modello possa essere utilizzato da persone che lavora\n \n Convertire un checkpoint per un altro framework Ã¨ semplice. Assicurati di avere PyTorch e TensorFlow installati (vedi [qui](installation) per le istruzioni d'installazione), e poi trova il modello specifico per il tuo compito nell'altro framework.\n \n-<frameworkcontent>\n-<pt>\n Specifica `from_tf=True` per convertire un checkpoint da TensorFlow a PyTorch:\n \n ```py\n@@ -89,13 +87,9 @@ Specifica `from_tf=True` per convertire un checkpoint da TensorFlow a PyTorch:\n ... )\n >>> pt_model.save_pretrained(\"path/verso/il-nome-magnifico-che-hai-scelto\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Condividi un modello durante il training\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n Condividere un modello nell'Hub Ã¨ tanto semplice quanto aggiungere un parametro extra o un callback. Ricorda dal [tutorial sul fine-tuning](training), la classe [`TrainingArguments`] Ã¨ dove specifichi gli iperparametri e le opzioni addizionali per l'allenamento. Una di queste opzioni di training include l'abilitÃ  di condividere direttamente un modello nell'Hub. Imposta `push_to_hub=True` in [`TrainingArguments`]:\n@@ -121,8 +115,6 @@ Dopo aver effettuato il fine-tuning del tuo modello, chiama [`~transformers.Trai\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Utilizzare la funzione `push_to_hub`\n "
        },
        {
            "sha": "06295d10275de5c1c5626aa2bf3819924641d0b9",
            "filename": "docs/source/it/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,14 +66,10 @@ Nel seguente esempio, utilizzerai la [`pipeline`] per l'analisi del sentimento.\n \n Installa le seguenti dipendenze se non lo hai giÃ  fatto:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n Importa [`pipeline`] e specifica il compito che vuoi completare:\n \n@@ -152,8 +148,6 @@ La [`pipeline`] puÃ² ospitare qualsiasi modello del [Model Hub](https://huggingf\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Usa [`AutoModelForSequenceClassification`] e [`AutoTokenizer`] per caricare il modello pre-allenato e il suo tokenizer associato (maggiori informazioni su una `AutoClass` in seguito):\n \n ```py\n@@ -162,8 +156,6 @@ Usa [`AutoModelForSequenceClassification`] e [`AutoTokenizer`] per caricare il m\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n Poi puoi specificare il modello e il tokenizer nella [`pipeline`], e applicare il `classifier` sul tuo testo obiettivo:\n \n@@ -215,8 +207,6 @@ Il tokenizer restituirÃ  un dizionario contenente:\n \n Come con la [`pipeline`], il tokenizer accetterÃ  una lista di input. In piÃ¹, il tokenizer puÃ² anche completare (pad, in inglese) e troncare il testo in modo da restituire un lotto (batch, in inglese) di lunghezza uniforme:\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> pt_batch = tokenizer(\n ...     [\"Siamo molto felici di mostrarti la libreria ğŸ¤— Transformers.\", \"Speriamo te non la odierai.\"],\n@@ -226,15 +216,11 @@ Come con la [`pipeline`], il tokenizer accetterÃ  una lista di input. In piÃ¹, i\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n Leggi il tutorial sul [preprocessing](./preprocessing) per maggiori dettagli sulla tokenizzazione.\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers fornisce un metodo semplice e unificato per caricare istanze pre-allenate. Questo significa che puoi caricare un [`AutoModel`] come caricheresti un [`AutoTokenizer`]. L'unica differenza Ã¨ selezionare l'[`AutoModel`] corretto per il compito di interesse. Dato che stai facendo classificazione di testi, o sequenze, carica [`AutoModelForSequenceClassification`]:\n \n ```py\n@@ -266,8 +252,6 @@ Il modello produrrÃ  le attivazioni finali nell'attributo `logits`. Applica la f\n tensor([[0.0041, 0.0037, 0.0203, 0.2005, 0.7713],\n         [0.3766, 0.3292, 0.1832, 0.0558, 0.0552]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -287,8 +271,6 @@ Gli output del modello si comportano anche come una tupla o un dizionario (ad es\n \n ### Salva un modello\n \n-<frameworkcontent>\n-<pt>\n Una volta completato il fine-tuning del tuo modello, puoi salvarlo con il suo tokenizer utilizzando [`PreTrainedModel.save_pretrained`]:\n \n ```py\n@@ -302,19 +284,13 @@ Quando desideri utilizzare il tuo modello nuovamente, puoi ri-caricarlo con [`Pr\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n Una caratteristica particolarmente interessante di ğŸ¤— Transformers Ã¨ la sua abilitÃ  di salvare un modello e ri-caricarlo sia come modello di PyTorch che di TensorFlow. I parametri `from_pt` o `from_tf` possono convertire un modello da un framework all'altro:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "ad7df423cb9622e69678db55b4ae46c635a0ce3b",
            "filename": "docs/source/it/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -84,8 +84,6 @@ pip install -r requirements.txt\n \n ## Esegui uno script\n \n-<frameworkcontent>\n-<pt>\n \n Lo script di esempio scarica e pre-processa un dataset dalla libreria ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/). Successivamente, lo script esegue il fine-tuning su un dataset usando il [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) su un'architettura che supporta la summarization. Il seguente esempio mostra come eseguire il fine-tuning di [T5-small](https://huggingface.co/google-t5/t5-small) sul dataset [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail). Il modello T5 richiede un parametro addizionale `source_prefix` a causa del modo in cui Ã¨ stato addestrato. Questo prefisso permette a T5 di sapere che si tratta di un task di summarization.\n \n@@ -103,8 +101,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Addestramento distribuito e precisione mista\n \n@@ -134,8 +130,6 @@ Gli script TensorFlow utilizzano una [`MirroredStrategy`](https://www.tensorflow\n \n ## Esegui uno script su TPU\n \n-<frameworkcontent>\n-<pt>\n Le Tensor Processing Units (TPU) sono state progettate per migliorare le prestazioni. PyTorch supporta le TPU con il compilatore per deep learning [XLA](https://www.tensorflow.org/xla) (guarda [questo link](https://github.com/pytorch/xla/blob/master/README.md) per maggiori dettagli). Per usare una TPU, avvia lo script `xla_spawn.py` e usa l'argomento `num_cores` per impostare il numero di core TPU che intendi usare.\n \n ```bash\n@@ -153,8 +147,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Esegui uno script con ğŸ¤— Accelerate\n "
        },
        {
            "sha": "53e16d927eb97833a1e4c8975dd8e4501afea1d4",
            "filename": "docs/source/it/serialization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fserialization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Fserialization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Fserialization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -181,8 +181,6 @@ Per esportare un modello memorizzato localmente, devi disporre dei pesi del mode\n e file tokenizer memorizzati in una directory. Ad esempio, possiamo caricare e salvare un\n checkpoint come segue:\n \n-<frameworkcontent>\n-<pt>\n ```python\n >>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n \n@@ -200,8 +198,6 @@ del pacchetto `transformers.onnx` nella directory desiderata:\n ```bash\n python -m transformers.onnx --model=local-pt-checkpoint onnx/\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Selezione delle caratteristiche per diverse topologie di modello\n "
        },
        {
            "sha": "76cd41afc56db01da30d968cda9d2799b5d4cb2f",
            "filename": "docs/source/it/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fit%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fit%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -69,8 +69,6 @@ Se vuoi, puoi creare un sottoinsieme piÃ¹ piccolo del dataset per il fine-tuning\n \n ## Addestramento\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ğŸ¤— Transformers mette a disposizione la classe [`Trainer`] ottimizzata per addestrare modelli ğŸ¤— Transformers, rendendo semplice iniziare l'addestramento senza scrivere manualmente il tuo ciclo di addestramento. L'API [`Trainer`] supporta un'ampia gamma di opzioni e funzionalitÃ  di addestramento come logging, gradient accumulation e mixed precision.\n@@ -148,15 +146,11 @@ Poi metti a punto il modello richiamando [`~transformers.Trainer.train`]:\n ```py\n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n \n ## Addestramento in PyTorch nativo\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`] si occupa del ciclo di addestramento e ti consente di mettere a punto un modello con una sola riga di codice. Per chi preferisse scrivere un proprio ciclo di addestramento personale, puoi anche fare il fine-tuning di un modello ğŸ¤— Transformers in PyTorch nativo.\n@@ -296,8 +290,6 @@ Proprio come Ã¨ necessario aggiungere una funzione di valutazione del [`Trainer`\n \n >>> metric.compute()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        },
        {
            "sha": "6b5c552cd7b6d77e05a3dbd4e5e5fbfeb25575df",
            "filename": "docs/source/ja/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -102,8 +102,6 @@ http://www.apache.org/licenses/LICENSE-2.0\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n æœ€å¾Œã«ã€`AutoModelFor`ã‚¯ãƒ©ã‚¹ã¯ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«å¯¾ã—ã¦äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼ˆä½¿ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯ã®å®Œå…¨ãªä¸€è¦§ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](model_doc/auto)ã‚’å‚ç…§ï¼‰ã€‚\n ãŸã¨ãˆã°ã€[`AutoModelForSequenceClassification.from_pretrained`]ã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†é¡ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ï¼š\n \n@@ -135,5 +133,3 @@ TensorFlowãŠã‚ˆã³Flaxã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã«ã¯å½±éŸ¿ãŒãªãã€`from_\n ä¸€èˆ¬çš„ã«ã€äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«`AutoTokenizer`ã‚¯ãƒ©ã‚¹ã¨`AutoModelFor`ã‚¯ãƒ©ã‚¹ã®ä½¿ç”¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚\n ã“ã‚Œã«ã‚ˆã‚Šã€å¸¸ã«æ­£ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚\n æ¬¡ã®[tutorial](preprocessing)ã§ã¯ã€æ–°ã—ããƒ­ãƒ¼ãƒ‰ã—ãŸãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã€ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã€ç‰¹å¾´é‡æŠ½å‡ºå™¨ã€ãŠã‚ˆã³ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ä½¿ç”¨ã—ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’å‰å‡¦ç†ã™ã‚‹æ–¹æ³•ã‚’å­¦ã³ã¾ã™ã€‚\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "d708070c3dafbf08f85bbfd900fab17ac3957887",
            "filename": "docs/source/ja/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -116,8 +116,6 @@ Once you are satisfied with your model configuration, you can save it with [`Pre\n ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¯ [`PreTrainedModel`] ã‚’ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹ã¨ã—ã€å…¥åŠ›åŸ‹ã‚è¾¼ã¿ã®ãƒªã‚µã‚¤ã‚ºã‚„ã‚»ãƒ«ãƒ•ã‚¢ãƒ†ãƒ³ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ‰ã®ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°ãªã©ã€å…±é€šã®ãƒ¡ã‚½ãƒƒãƒ‰ãŒã„ãã¤ã‹ã‚ã‚Šã¾ã™ã€‚\n ã•ã‚‰ã«ã€ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã¯ [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)ã€[`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)ã€ã¾ãŸã¯ [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html) ã®ã„ãšã‚Œã‹ã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§ã‚‚ã‚ã‚Šã¾ã™ã€‚ã¤ã¾ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã¯ãã‚Œãã‚Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ä½¿ç”¨æ³•ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n ãƒ¢ãƒ‡ãƒ«ã«ã‚«ã‚¹ã‚¿ãƒ æ§‹æˆå±æ€§ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼š\n \n ```py\n@@ -144,16 +142,12 @@ Once you are satisfied with your model configuration, you can save it with [`Pre\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n \n ### Model heads\n \n ã“ã®æ™‚ç‚¹ã§ã€ãƒ™ãƒ¼ã‚¹ã®DistilBERTãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã€ã“ã‚Œã¯éš ã‚ŒãŸçŠ¶æ…‹ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚éš ã‚ŒãŸçŠ¶æ…‹ã¯ãƒ¢ãƒ‡ãƒ«ã®ãƒ˜ãƒƒãƒ‰ã¸ã®å…¥åŠ›ã¨ã—ã¦æ¸¡ã•ã‚Œã€æœ€çµ‚çš„ãªå‡ºåŠ›ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ğŸ¤— Transformersã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒãã®ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹é™ã‚Šã€å„ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã™ã‚‹ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ˜ãƒƒãƒ‰ã‚’æä¾›ã—ã¾ã™ï¼ˆã¤ã¾ã‚Šã€DistilBERTã‚’ç¿»è¨³ã®ã‚ˆã†ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹å¯¾ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚¿ã‚¹ã‚¯ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã§ãã¾ã›ã‚“ï¼‰ã€‚\n \n-<frameworkcontent>\n-<pt>\n ãŸã¨ãˆã°ã€[`DistilBertForSequenceClassification`]ã¯ã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†é¡ãƒ˜ãƒƒãƒ‰ã‚’æŒã¤ãƒ™ãƒ¼ã‚¹ã®DistilBERTãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åˆ†é¡ãƒ˜ãƒƒãƒ‰ã¯ã€ãƒ—ãƒ¼ãƒ«ã•ã‚ŒãŸå‡ºåŠ›ã®ä¸Šã«ã‚ã‚‹ç·šå½¢å±¤ã§ã™ã€‚\n \n ```py\n@@ -172,8 +166,6 @@ Once you are satisfied with your model configuration, you can save it with [`Pre\n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## Tokenizer\n "
        },
        {
            "sha": "e2fccbd8bfc55b5c7ce584d39f0ce5292ff070f0",
            "filename": "docs/source/ja/model_doc/albert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 3,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Falbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -73,8 +73,6 @@ ALBERTãƒ¢ãƒ‡ãƒ«ã¯ã€ã€Œ[ALBERT: A Lite BERT for Self-supervised Learning of Lan\n \n [[autodoc]] models.albert.modeling_albert.AlbertForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## AlbertModel\n \n@@ -110,4 +108,3 @@ ALBERTãƒ¢ãƒ‡ãƒ«ã¯ã€ã€Œ[ALBERT: A Lite BERT for Self-supervised Learning of Lan\n [[autodoc]] AlbertForQuestionAnswering\n     - forward\n \n-</pt>"
        },
        {
            "sha": "0ccd41cf13d8d734307050cbdbeb4d8a3f8f1e03",
            "filename": "docs/source/ja/model_doc/bert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -138,22 +138,16 @@ BERT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£\n     - create_token_type_ids_from_sequences\n     - save_vocabulary\n \n-<frameworkcontent>\n-<pt>\n \n ## BertTokenizerFast\n \n [[autodoc]] BertTokenizerFast\n \n-</pt>\n-</frameworkcontent>\n \n ## Bert specific outputs\n \n [[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## BertModel\n \n@@ -200,5 +194,3 @@ BERT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£\n [[autodoc]] BertForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "85248036af79f5e53dc152c84ea3c431c467646d",
            "filename": "docs/source/ja/model_doc/big_bird.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbig_bird.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ BigBird ã¯ã€è³ªå•å¿œç­”ã‚„è¦ç´„ãªã©ã®ã•ã¾ã–ã¾ãª NLP ã‚¿ã‚¹ã‚¯ã®ãƒ‘\n \n [[autodoc]] models.big_bird.modeling_big_bird.BigBirdForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## BigBirdModel\n \n@@ -128,6 +126,4 @@ BigBird ã¯ã€è³ªå•å¿œç­”ã‚„è¦ç´„ãªã©ã®ã•ã¾ã–ã¾ãª NLP ã‚¿ã‚¹ã‚¯ã®ãƒ‘\n [[autodoc]] BigBirdForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n "
        },
        {
            "sha": "bda95695923f3b5765bd3e3f389d13b2cdb09396",
            "filename": "docs/source/ja/model_doc/blip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fblip.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,8 +66,6 @@ BLIP ã¯ã€æ¬¡ã®ã‚ˆã†ãªã•ã¾ã–ã¾ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« ã‚¿ã‚¹ã‚¯ã‚’å®Ÿ\n [[autodoc]] BlipImageProcessorFast\n     - preprocess\n \n-<frameworkcontent>\n-<pt>\n \n ## BlipModel\n \n@@ -101,5 +99,3 @@ BLIP ã¯ã€æ¬¡ã®ã‚ˆã†ãªã•ã¾ã–ã¾ãªãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ« ã‚¿ã‚¹ã‚¯ã‚’å®Ÿ\n [[autodoc]] BlipForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "26d60ae7e5bb5c691aae544d98bf51d64986951b",
            "filename": "docs/source/ja/model_doc/bloom.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fbloom.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -62,8 +62,6 @@ BLOOM ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹\n     - all\n \n \n-<frameworkcontent>\n-<pt>\n \n ## BloomModel\n \n@@ -90,5 +88,3 @@ BLOOM ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹\n [[autodoc]] BloomForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "ee33721102e160e8734bf82ea9e467bab7fb17fb",
            "filename": "docs/source/ja/model_doc/camembert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fcamembert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -69,8 +69,6 @@ Bi-direction Encoders for Transformers (BERT) ã®ãƒ•ãƒ©ãƒ³ã‚¹èªç‰ˆã§ã‚ã‚‹ Cam\n \n [[autodoc]] CamembertTokenizerFast\n \n-<frameworkcontent>\n-<pt>\n \n ## CamembertModel\n \n@@ -100,5 +98,3 @@ Bi-direction Encoders for Transformers (BERT) ã®ãƒ•ãƒ©ãƒ³ã‚¹èªç‰ˆã§ã‚ã‚‹ Cam\n \n [[autodoc]] CamembertForQuestionAnswering\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "ac6cb606a52c7c93c9ebbcc8b3bf783cb64d341c",
            "filename": "docs/source/ja/model_doc/clip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fclip.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -146,8 +146,6 @@ CLIP ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹\n \n [[autodoc]] CLIPProcessor\n \n-<frameworkcontent>\n-<pt>\n \n ## CLIPModel\n \n@@ -176,5 +174,3 @@ CLIP ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹\n [[autodoc]] CLIPVisionModel\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "f904592aba245e143597b39f7bcf6d09df0a3159",
            "filename": "docs/source/ja/model_doc/convbert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -75,8 +75,6 @@ ConvBERT ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆã¯ BERT ã®ãƒ’ãƒ³ãƒˆã¨ä¼¼ã¦ã„ã¾ã™\n \n [[autodoc]] ConvBertTokenizerFast\n \n-<frameworkcontent>\n-<pt>\n \n ## ConvBertModel\n \n@@ -108,5 +106,3 @@ ConvBERT ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã®ãƒ’ãƒ³ãƒˆã¯ BERT ã®ãƒ’ãƒ³ãƒˆã¨ä¼¼ã¦ã„ã¾ã™\n [[autodoc]] ConvBertForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "46672f38cbf91ad04cf7482179162e7753e431e8",
            "filename": "docs/source/ja/model_doc/convnext.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fconvnext.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -69,8 +69,6 @@ ConvNeXT ã®ä½¿ç”¨ã‚’é–‹å§‹ã™ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³\n [[autodoc]] ConvNextImageProcessorFast\n     - preprocess\n \n-<frameworkcontent>\n-<pt>\n \n ## ConvNextModel\n \n@@ -82,5 +80,3 @@ ConvNeXT ã®ä½¿ç”¨ã‚’é–‹å§‹ã™ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³\n [[autodoc]] ConvNextForImageClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "44b6892cdc0244dba8261cbac63fba2f87e8a405",
            "filename": "docs/source/ja/model_doc/ctrl.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fctrl.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -73,8 +73,6 @@ CTRL ãƒ¢ãƒ‡ãƒ«ã¯ã€Nitish Shirish Keskar*ã€Bryan McCann*ã€Lav R. Varshneyã€C\n [[autodoc]] CTRLTokenizer\n     - save_vocabulary\n \n-<frameworkcontent>\n-<pt>\n \n ## CTRLModel\n \n@@ -91,5 +89,3 @@ CTRL ãƒ¢ãƒ‡ãƒ«ã¯ã€Nitish Shirish Keskar*ã€Bryan McCann*ã€Lav R. Varshneyã€C\n [[autodoc]] CTRLForSequenceClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "51616de75b269357044e0e3c58142293d6212d8a",
            "filename": "docs/source/ja/model_doc/cvt.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fcvt.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -57,8 +57,6 @@ CvT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ (\n \n [[autodoc]] CvtConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## CvtModel\n \n@@ -70,6 +68,4 @@ CvT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ (\n [[autodoc]] CvtForImageClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>\n "
        },
        {
            "sha": "b01e43b4a6f585d5dc9d42603e843d713751fb56",
            "filename": "docs/source/ja/model_doc/data2vec.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdata2vec.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -87,8 +87,6 @@ Data2Vec ã®ä½¿ç”¨ã‚’é–‹å§‹ã™ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³\n \n [[autodoc]] Data2VecVisionConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## Data2VecAudioModel\n \n@@ -165,5 +163,3 @@ Data2Vec ã®ä½¿ç”¨ã‚’é–‹å§‹ã™ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³\n [[autodoc]] Data2VecVisionForSemanticSegmentation\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "26202c8bb52293be1eea0bdb9f69f40a80b442aa",
            "filename": "docs/source/ja/model_doc/deberta-v2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta-v2.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ v2 ã®æ–°æ©Ÿèƒ½:\n     - build_inputs_with_special_tokens\n     - create_token_type_ids_from_sequences\n \n-<frameworkcontent>\n-<pt>\n \n ## DebertaV2Model\n \n@@ -123,7 +121,5 @@ v2 ã®æ–°æ©Ÿèƒ½:\n [[autodoc]] DebertaV2ForMultipleChoice\n     - forward\n \n-</pt>\n-</frameworkcontent>\n \n "
        },
        {
            "sha": "39ce6d854292a4a2b78879797970b5a4393bbf7b",
            "filename": "docs/source/ja/model_doc/deberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeberta.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -94,8 +94,6 @@ DeBERTa ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥\n     - build_inputs_with_special_tokens\n     - create_token_type_ids_from_sequences\n \n-<frameworkcontent>\n-<pt>\n \n ## DebertaModel\n \n@@ -126,6 +124,4 @@ DeBERTa ã‚’ä½¿ã„å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥\n [[autodoc]] DebertaForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n "
        },
        {
            "sha": "7be69bd9972fdd302c887adcd655d7d90fb4db99",
            "filename": "docs/source/ja/model_doc/deit.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_doc%2Fdeit.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -103,8 +103,6 @@ DeiT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£\n [[autodoc]] DeiTImageProcessorFast\n     - preprocess\n \n-<frameworkcontent>\n-<pt>\n \n ## DeiTModel\n \n@@ -126,5 +124,3 @@ DeiT ã‚’å§‹ã‚ã‚‹ã®ã«å½¹ç«‹ã¤å…¬å¼ Hugging Face ãŠã‚ˆã³ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£\n [[autodoc]] DeiTForImageClassificationWithTeacher\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "4a282ee6134ead0257dfbd9171a53d9c1a776c8c",
            "filename": "docs/source/ja/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,21 +85,15 @@ PyTorchãŠã‚ˆã³TensorFlowã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›ã—ã¦\n PyTorchã¨TensorFlowãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ï¼ˆã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](installation)ã‚’å‚ç…§ï¼‰ã—ã€\n ãã®å¾Œã€ä»–ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å‘ã‘ã«ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n TensorFlowã‹ã‚‰PyTorchã«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’å¤‰æ›ã™ã‚‹ã«ã¯ã€`from_tf=True`ã‚’æŒ‡å®šã—ã¾ã™ï¼š\n \n ```python\n >>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n >>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Push a model during traning\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n ãƒ¢ãƒ‡ãƒ«ã‚’Hubã«ãƒ—ãƒƒã‚·ãƒ¥ã™ã‚‹ã“ã¨ã¯ã€è¿½åŠ ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã¾ãŸã¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’è¿½åŠ ã™ã‚‹ã ã‘ã§ç°¡å˜ã§ã™ã€‚\n@@ -140,8 +134,6 @@ Pass your training arguments as usual to [`Trainer`]:\n >>> trainer.push_to_hub()\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## `push_to_hub` é–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹\n "
        },
        {
            "sha": "cb1129a8355e66f3ecae8d2505234b7318c17597",
            "filename": "docs/source/ja/preprocessing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fpreprocessing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -174,8 +174,6 @@ pip install datasets\n \n `return_tensors`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’`pt`ï¼ˆPyTorchç”¨ï¼‰ã¾ãŸã¯`tf`ï¼ˆTensorFlowç”¨ï¼‰ã«è¨­å®šã—ã¾ã™ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> batch_sentences = [\n@@ -195,8 +193,6 @@ pip install datasets\n                            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Audio\n "
        },
        {
            "sha": "44a154a614c56d51a3905ca9ede6d6a3b7b4c170",
            "filename": "docs/source/ja/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -31,14 +31,10 @@ specific language governing permissions and limitations under the License.\n \n ã‚ãªãŸã¯ã¾ãŸã€å¥½ããªæ©Ÿæ¢°å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Pipeline\n \n@@ -137,8 +133,6 @@ label: NEGATIVE, ã‚¹ã‚³ã‚¢: 0.5309\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n [`AutoModelForSequenceClassification`]ã¨[`AutoTokenizer`]ã‚’ä½¿ç”¨ã—ã¦äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ãã‚Œã«é–¢é€£ã™ã‚‹ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ï¼ˆæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§`AutoClass`ã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¾ã™ï¼‰ï¼š\n \n ```python\n@@ -148,8 +142,6 @@ label: NEGATIVE, ã‚¹ã‚³ã‚¢: 0.5309\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n æŒ‡å®šã—ãŸãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’[`pipeline`]ã«è¨­å®šã—ã€ä»Šåº¦ã¯ãƒ•ãƒ©ãƒ³ã‚¹èªã®ãƒ†ã‚­ã‚¹ãƒˆã«`classifier`ã‚’é©ç”¨ã§ãã¾ã™ï¼š\n \n@@ -206,8 +198,6 @@ Pass your text to the tokenizer:\n \n ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¯ã¾ãŸã€å…¥åŠ›ã®ãƒªã‚¹ãƒˆã‚’å—ã‘å…¥ã‚Œã€ä¸€æ§˜ãªé•·ã•ã®ãƒãƒƒãƒã‚’è¿”ã™ãŸã‚ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ãŠã‚ˆã³åˆ‡ã‚Šè©°ã‚ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -218,8 +208,6 @@ Pass your text to the tokenizer:\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -229,8 +217,6 @@ Pass your text to the tokenizer:\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformersã¯äº‹å‰å­¦ç¿’æ¸ˆã¿ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç°¡å˜ã«çµ±ä¸€çš„ã«ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•ã‚’æä¾›ã—ã¾ã™ã€‚\n ã“ã‚Œã¯ã€[`AutoTokenizer`]ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã®ã¨åŒã˜ã‚ˆã†ã«[`AutoModel`]ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã“ã¨ã‚’æ„å‘³ã—ã¾ã™ã€‚\n ã‚¿ã‚¹ã‚¯ã«é©ã—ãŸ[`AutoModel`]ã‚’é¸æŠã™ã‚‹ä»¥å¤–ã®é•ã„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚\n@@ -266,8 +252,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -280,8 +264,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n \n ### Save a Model\n \n-<frameworkcontent>\n-<pt>\n ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ãŸã‚‰ã€[`PreTrainedModel.save_pretrained`]ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã¨å…±ã«ä¿å­˜ã§ãã¾ã™ï¼š\n \n ```py\n@@ -296,13 +278,9 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ğŸ¤— Transformersã®ç‰¹ã«ç´ æ™´ã‚‰ã—ã„æ©Ÿèƒ½ã®ä¸€ã¤ã¯ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã€ãã‚Œã‚’PyTorchãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯TensorFlowãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦å†ãƒ­ãƒ¼ãƒ‰ã§ãã‚‹ã“ã¨ã§ã™ã€‚ `from_pt`ã¾ãŸã¯`from_tf`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ã§å¤‰æ›ã§ãã¾ã™ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n@@ -311,8 +289,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## Custom model builds\n \n@@ -326,8 +302,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n [`AutoModel.from_config`]ã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼š\n \n ```python\n@@ -336,8 +310,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> my_model = AutoModel.from_config(my_config)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n [ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’ä½œæˆ](./create_a_model)ã‚¬ã‚¤ãƒ‰ã‚’å‚ç…§ã—ã¦ã€ã‚«ã‚¹ã‚¿ãƒ æ§‹æˆã®è©³ç´°æƒ…å ±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n "
        },
        {
            "sha": "ee738e3e43139e37299184481955e6905e4f8a2d",
            "filename": "docs/source/ja/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -90,8 +90,6 @@ pip install -r requirements.txt\n \n ## Run a script\n \n-<frameworkcontent>\n-<pt>\n ã“ã®ä¾‹ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€å‰å‡¦ç†ã‚’è¡Œã„ã¾ã™ã€‚æ¬¡ã«ã€[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) ã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ä¸Šã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™ã€‚ä»¥ä¸‹ã®ä¾‹ã§ã¯ã€[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¸Šã§ [T5-small](https://huggingface.co/google-t5/t5-small) ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚T5 ãƒ¢ãƒ‡ãƒ«ã¯ã€ãã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ–¹æ³•ã«èµ·å› ã—ã¦è¿½åŠ ã® `source_prefix` å¼•æ•°ãŒå¿…è¦ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚Šã€T5 ã¯ã“ã‚ŒãŒè¦ç´„ã‚¿ã‚¹ã‚¯ã§ã‚ã‚‹ã“ã¨ã‚’çŸ¥ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n \n \n@@ -110,8 +108,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --predict_with_generate\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## Distributed training and mixed precision\n \n@@ -144,8 +140,6 @@ TensorFlowã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ã€åˆ†æ•£ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«[`MirroredStrategy`](h\n \n ## Run a script on a TPU\n \n-<frameworkcontent>\n-<pt>\n Tensor Processing Units (TPUs)ã¯ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åŠ é€Ÿã•ã›ã‚‹ãŸã‚ã«ç‰¹åˆ¥ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚PyTorchã¯ã€[XLA](https://www.tensorflow.org/xla)ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©ã‚’ä½¿ç”¨ã—ã¦TPUsã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ãŠã‚Šã€è©³ç´°ã«ã¤ã„ã¦ã¯[ã“ã¡ã‚‰](https://github.com/pytorch/xla/blob/master/README.md)ã‚’ã”è¦§ãã ã•ã„ã€‚TPUã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€`xla_spawn.py`ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èµ·å‹•ã—ã€`num_cores`å¼•æ•°ã‚’ä½¿ç”¨ã—ã¦ä½¿ç”¨ã™ã‚‹TPUã‚³ã‚¢ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚\n ```bash\n python xla_spawn.py --num_cores 8 \\\n@@ -162,8 +156,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Run a script with ğŸ¤— Accelerate\n "
        },
        {
            "sha": "4ccb31667423ae5790493fa9aa48c701bb4d96a7",
            "filename": "docs/source/ja/tasks/asr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fasr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fasr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fasr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -228,8 +228,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8000kHz ã§ã™ (\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -295,8 +293,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8000kHz ã§ã™ (\n >>> trainer.push_to_hub()\n ```\n \n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -337,8 +333,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8000kHz ã§ã™ (\n \n å¿…è¦ã«å¿œã˜ã¦ã€ã€Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã€ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã¨æ–‡å­—èµ·ã“ã—ã‚’å‰å‡¦ç†ã—ã€`input`ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚\n \n@@ -371,5 +365,3 @@ Pass your inputs to the model and return the logits:\n ['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n ```\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "d37485cbe226739c3c9c69a5b79ff968c3906abf",
            "filename": "docs/source/ja/tasks/audio_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Faudio_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -186,8 +186,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8khz ã§ã™ (ã“\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã¡ã‚‰](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -245,8 +243,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8khz ã§ã™ (ã“\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -287,8 +283,6 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8khz ã§ã™ (ã“\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline` ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ç‰¹å¾´æŠ½å‡ºå™¨ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ã‚ªãƒ¼ãƒ‡ã‚£ã‚ª ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰å‡¦ç†ã—ã€`input`ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚\n \n@@ -319,5 +313,3 @@ MInDS-14 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ãƒ¬ãƒ¼ãƒˆã¯ 8khz ã§ã™ (ã“\n >>> predicted_label\n 'cash_deposit'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "32c30dcff7c8645f406d87da996bdadef04ba926",
            "filename": "docs/source/ja/tasks/image_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fimage_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -111,8 +111,6 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n ```\n \n \n-<frameworkcontent>\n-<pt>\n \n ã„ãã¤ã‹ã®ç”»åƒå¤‰æ›ã‚’ç”»åƒã«é©ç”¨ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã®éå­¦ç¿’ã«å¯¾ã™ã‚‹å …ç‰¢æ€§ã‚’é«˜ã‚ã¾ã™ã€‚ã“ã“ã§ã¯ torchvision ã® [`transforms`](https://pytorch.org/vision/stable/transforms.html) ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ãŒã€ä»»æ„ã®ç”»åƒãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n@@ -153,8 +151,6 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n \n >>> data_collator = DefaultDataCollator()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Evaluate\n \n@@ -184,8 +180,6 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã¡ã‚‰](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -247,8 +241,6 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -287,8 +279,6 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ç”»åƒãƒ—ãƒ­ã‚»ãƒƒã‚µã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”»åƒã‚’å‰å‡¦ç†ã—ã€`input`ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚\n \n@@ -317,5 +307,3 @@ Datasetsã€ğŸ¤— ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‹ã‚‰ Food-101 ãƒ‡ãƒ¼ã‚¿ã‚»\n >>> model.config.id2label[predicted_label]\n 'beignets'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "d72ebb6a1046bd886bbe4a2c4e3f740980ddc813",
            "filename": "docs/source/ja/tasks/language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Flanguage_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Flanguage_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Flanguage_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -185,8 +185,6 @@ Apply the `group_texts` function over the entire dataset:\n æ¬¡ã«ã€[`DataCollatâ€‹â€‹orForLanguageModeling`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ *å‹•çš„ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°*ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„ã§ã™ã€‚\n ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æœ€å¤§é•·ã¾ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ç…§åˆä¸­ã«ãƒãƒƒãƒå†…ã®æ–‡ã‚’æœ€é•·ã®é•·ã•ã«ã—ã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ã‚·ãƒ¼ã‚±ãƒ³ã‚¹çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦ä½¿ç”¨ã—ã€`mlm=False` ã‚’è¨­å®šã—ã¾ã™ã€‚ã“ã‚Œã¯ã€å…¥åŠ›ã‚’ 1 è¦ç´ åˆ†å³ã«ã‚·ãƒ•ãƒˆã—ãŸãƒ©ãƒ™ãƒ«ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ã€‚\n \n@@ -197,14 +195,10 @@ Apply the `group_texts` function over the entire dataset:\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[åŸºæœ¬ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](../training#train-with-pytorch-trainer) ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n@@ -261,8 +255,6 @@ Perplexity: 49.61\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -293,8 +285,6 @@ Perplexity: 49.61\n [{'generated_text': \"Somatic hypermutation allows the immune system to be able to effectively reverse the damage caused by an infection.\\n\\n\\nThe damage caused by an infection is caused by the immune system's ability to perform its own self-correcting tasks.\"}]\n ```\n \n-<frameworkcontent>\n-<pt>\n \n \n ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€ã€Œinput_idsã€ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚\n@@ -323,5 +313,3 @@ Perplexity: 49.61\n [\"Somatic hypermutation allows the immune system to react to drugs with the ability to adapt to a different environmental situation. In other words, a system of 'hypermutation' can help the immune system to adapt to a different environmental situation or in some cases even a single life. In contrast, researchers at the University of Massachusetts-Boston have found that 'hypermutation' is much stronger in mice than in humans but can be found in humans, and that it's not completely unknown to the immune system. A study on how the immune system\"]\n ```\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "ff4107edb8087e705225773ee34a79d64dfd11a7",
            "filename": "docs/source/ja/tasks/masked_language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fmasked_language_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fmasked_language_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fmasked_language_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -173,8 +173,6 @@ pip install transformers datasets evaluate\n \n æ¬¡ã«ã€[`DataCollatâ€‹â€‹orForLanguageModeling`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æœ€å¤§é•·ã¾ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ç…§åˆä¸­ã«ãƒãƒƒãƒå†…ã®æœ€é•·ã®é•·ã•ã¾ã§æ–‡ã‚’ *å‹•çš„ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°* ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„ã§ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ã‚·ãƒ¼ã‚±ãƒ³ã‚¹çµ‚äº†ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° ãƒˆãƒ¼ã‚¯ãƒ³ã¨ã—ã¦ä½¿ç”¨ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’åå¾©ã™ã‚‹ãŸã³ã«ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ãƒã‚¹ã‚¯ã™ã‚‹ãŸã‚ã« `mlm_probability` ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n \n@@ -184,13 +182,9 @@ pip install transformers datasets evaluate\n >>> tokenizer.pad_token = tokenizer.eos_token\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -249,8 +243,6 @@ Perplexity: 8.76\n >>> trainer.push_to_hub()\n ```\n \n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -291,8 +283,6 @@ Perplexity: 8.76\n   'sequence': 'The Milky Way is a small galaxy.'}]\n ```\n \n-<frameworkcontent>\n-<pt>\n \n ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€`input_ids`ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚ `<mask>` ãƒˆãƒ¼ã‚¯ãƒ³ã®ä½ç½®ã‚‚æŒ‡å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n \n@@ -326,5 +316,3 @@ The Milky Way is a massive galaxy.\n The Milky Way is a small galaxy.\n ```\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "d92ff913d606a076bc77f0ad43cca6543b4db8d5",
            "filename": "docs/source/ja/tasks/multiple_choice.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fmultiple_choice.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fmultiple_choice.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fmultiple_choice.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -145,8 +145,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -199,8 +197,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n <Tip>\n@@ -224,8 +220,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> candidate2 = \"The law applies to baguettes.\"\n ```\n \n-<frameworkcontent>\n-<pt>\n \n å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å›ç­”å€™è£œã®ãƒšã‚¢ã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚ã„ãã¤ã‹ã®`lables`ã‚‚ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n \n@@ -254,5 +248,3 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> predicted_class\n '0'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "a12205b5cd39791ea2faf42552cec9270154ba52",
            "filename": "docs/source/ja/tasks/question_answering.md",
            "status": "modified",
            "additions": 0,
            "deletions": 6,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fquestion_answering.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fquestion_answering.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fquestion_answering.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -43,8 +43,6 @@\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -86,8 +84,6 @@\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¦ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n \n@@ -124,5 +120,3 @@\n >>> tokenizer.decode(predict_answer_tokens)\n '176 billion parameters and can generate text in 46 languages natural languages and 13'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "4a1a141ba4ef84de88b1610ab1bacfd4719bfd55",
            "filename": "docs/source/ja/tasks/semantic_segmentation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fsemantic_segmentation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fsemantic_segmentation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fsemantic_segmentation.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -105,8 +105,6 @@ pip install -q datasets transformers evaluate\n >>> image_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=True)\n ```\n \n-<frameworkcontent>\n-<pt>\n \n ãƒ¢ãƒ‡ãƒ«ã‚’éå­¦ç¿’ã«å¯¾ã—ã¦ã‚ˆã‚Šå …ç‰¢ã«ã™ã‚‹ãŸã‚ã«ã€ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã‚’é©ç”¨ã™ã‚‹ã®ãŒä¸€èˆ¬çš„ã§ã™ã€‚ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€[torchvision](https://pytorch.org/vision/stable/index.html) ã® [`ColorJitter`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ColorJitter.html) é–¢æ•°ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ ) ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã®è‰²ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«å¤‰æ›´ã—ã¾ã™ãŒã€ä»»æ„ã®ç”»åƒãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n@@ -140,8 +138,6 @@ pip install -q datasets transformers evaluate\n >>> test_ds.set_transform(val_transforms)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## Evaluate\n \n@@ -156,8 +152,6 @@ pip install -q datasets transformers evaluate\n æ¬¡ã«ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ [`~evaluate.EvaluationModule.compute`] ã™ã‚‹é–¢æ•°ã‚’ä½œæˆã—ã¾ã™ã€‚äºˆæ¸¬ã‚’æ¬¡ã®ã‚ˆã†ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™\n æœ€åˆã«ãƒ­ã‚¸ãƒƒãƒˆã‚’ä½œæˆã—ã€æ¬¡ã« [`~evaluate.EvaluationModule.compute`] ã‚’å‘¼ã³å‡ºã™å‰ã«ãƒ©ãƒ™ãƒ«ã®ã‚µã‚¤ã‚ºã«ä¸€è‡´ã™ã‚‹ã‚ˆã†ã«å†å½¢æˆã—ã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> import numpy as np\n@@ -189,15 +183,11 @@ pip install -q datasets transformers evaluate\n ...         return metrics\n ```\n \n-</pt>\n-</frameworkcontent>\n \n \n ã“ã‚Œã§`compute_metrics`é–¢æ•°ã®æº–å‚™ãŒæ•´ã„ã¾ã—ãŸã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚‹ã¨ãã«ã“ã®é–¢æ•°ã«æˆ»ã‚Šã¾ã™ã€‚\n \n ## Train\n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#finetune-with-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -252,8 +242,6 @@ pip install -q datasets transformers evaluate\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Inference\n \n@@ -270,8 +258,6 @@ pip install -q datasets transformers evaluate\n     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-image.png\" alt=\"Image of bedroom\"/>\n </div>\n \n-<frameworkcontent>\n-<pt>\n \n æ¨è«–ç”¨ã«å¾®èª¿æ•´ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã¯ã€ãã‚Œã‚’ [`pipeline`] ã§ä½¿ç”¨ã™ã‚‹ã“ã¨ã§ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ç”»åƒã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ã® `pipeline`ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–ã—ã€ãã‚Œã«ç”»åƒã‚’æ¸¡ã—ã¾ã™ã€‚\n \n@@ -338,8 +324,6 @@ pip install -q datasets transformers evaluate\n >>> pred_seg = upsampled_logits.argmax(dim=1)[0]\n ```\n \n-</pt>\n-</frameworkcontent>\n \n çµæœã‚’è¦–è¦šåŒ–ã™ã‚‹ã«ã¯ã€[ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ã‚«ãƒ©ãƒ¼ ãƒ‘ãƒ¬ãƒƒãƒˆ](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51) ã‚’ã€ãã‚Œãã‚Œã‚’ãƒãƒƒãƒ—ã™ã‚‹ `ade_palette()` ã¨ã—ã¦ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ã‚¯ãƒ©ã‚¹ã‚’ RGB å€¤ã«å¤‰æ›ã—ã¾ã™ã€‚æ¬¡ã«ã€ç”»åƒã¨äºˆæ¸¬ã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ ãƒãƒƒãƒ—ã‚’çµ„ã¿åˆã‚ã›ã¦ãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã™ã€‚\n "
        },
        {
            "sha": "c62583fdb281f5e72e3b19f04da361dd20a789a0",
            "filename": "docs/source/ja/tasks/summarization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fsummarization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Fsummarization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Fsummarization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -119,16 +119,12 @@ pip install transformers datasets evaluate rouge_score\n \n æ¬¡ã«ã€[`DataCollatâ€‹â€‹orForSeq2Seq`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æœ€å¤§é•·ã¾ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ç…§åˆä¸­ã«ãƒãƒƒãƒå†…ã®æœ€é•·ã®é•·ã•ã¾ã§æ–‡ã‚’ *å‹•çš„ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°* ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„ã§ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Evaluate\n \n@@ -164,8 +160,6 @@ pip install transformers datasets evaluate rouge_score\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n \n@@ -221,8 +215,6 @@ pip install transformers datasets evaluate rouge_score\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -254,8 +246,6 @@ pip install transformers datasets evaluate rouge_score\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã€ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n Tokenize the text and return the `input_ids` as PyTorch tensors:\n \n ```py\n@@ -280,5 +270,3 @@ Tokenize the text and return the `input_ids` as PyTorch tensors:\n >>> tokenizer.decode(outputs[0], skip_special_tokens=True)\n 'the inflation reduction act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in american history. it will ask the ultra-wealthy and corporations to pay their fair share.'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "f8dbd97401760e65ba5467bb5a5ce56848647a28",
            "filename": "docs/source/ja/tasks/token_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Ftoken_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Ftoken_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Ftoken_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -155,16 +155,12 @@ pip install transformers datasets evaluate seqeval\n \n æ¬¡ã«ã€[`DataCollatâ€‹â€‹orWithPadding`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æœ€å¤§é•·ã¾ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ç…§åˆä¸­ã«ãƒãƒƒãƒå†…ã®æœ€é•·ã®é•·ã•ã¾ã§æ–‡ã‚’ *å‹•çš„ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°* ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„ã§ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorForTokenClassification\n \n >>> data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Evaluate\n \n@@ -244,8 +240,6 @@ pip install transformers datasets evaluate seqeval\n ... }\n ```\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -300,8 +294,6 @@ pip install transformers datasets evaluate seqeval\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -363,8 +355,6 @@ pip install transformers datasets evaluate seqeval\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã¦ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n \n ```py\n@@ -409,5 +399,3 @@ pip install transformers datasets evaluate seqeval\n  'O']\n ```\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "e7ce04d47c1a4d6fb7622a11f9596861187ae7e9",
            "filename": "docs/source/ja/tasks/translation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Ftranslation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftasks%2Ftranslation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftasks%2Ftranslation.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -113,16 +113,12 @@ pip install transformers datasets evaluate sacrebleu\n \n æ¬¡ã«ã€[`DataCollatâ€‹â€‹orForSeq2Seq`] ã‚’ä½¿ç”¨ã—ã¦ã‚µãƒ³ãƒ—ãƒ«ã®ãƒãƒƒãƒã‚’ä½œæˆã—ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå…¨ä½“ã‚’æœ€å¤§é•·ã¾ã§ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã™ã‚‹ã®ã§ã¯ãªãã€ç…§åˆä¸­ã«ãƒãƒƒãƒå†…ã®æœ€é•·ã®é•·ã•ã¾ã§æ–‡ã‚’ *å‹•çš„ã«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°* ã™ã‚‹æ–¹ãŒåŠ¹ç‡çš„ã§ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Evaluate\n \n@@ -169,8 +165,6 @@ pip install transformers datasets evaluate sacrebleu\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`] ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«ã®å¾®èª¿æ•´ã«æ…£ã‚Œã¦ã„ãªã„å ´åˆã¯ã€[ã“ã“](../training#train-with-pytorch-trainer) ã®åŸºæœ¬çš„ãªãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚\n@@ -225,8 +219,6 @@ pip install transformers datasets evaluate sacrebleu\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -262,8 +254,6 @@ pip install transformers datasets evaluate sacrebleu\n \n å¿…è¦ã«å¿œã˜ã¦ã€`pipeline`ã®çµæœã‚’æ‰‹å‹•ã§è¤‡è£½ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã—ã€`input_ids` ã‚’ PyTorch ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¿”ã—ã¾ã™ã€‚\n \n@@ -292,5 +282,3 @@ pip install transformers datasets evaluate sacrebleu\n 'Les lignÃ©es partagent des ressources avec des bactÃ©ries enfixant l'azote.'\n ```\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "b90f2a1f53ed53cf22737180c21987148fd88e51",
            "filename": "docs/source/ja/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fja%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fja%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -77,8 +77,6 @@ rendered properly in your Markdown viewer.\n ã“ã®æ™‚ç‚¹ã§ã€ä½¿ç”¨ã—ãŸã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«å¯¾å¿œã™ã‚‹ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å¾“ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚å³å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒªãƒ³ã‚¯ã‚’ä½¿ç”¨ã—ã¦ã€ã‚¸ãƒ£ãƒ³ãƒ—ã—ãŸã„ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«ç§»å‹•ã§ãã¾ã™ã€‚\n ãã—ã¦ã€ç‰¹å®šã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã™ã¹ã¦ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’éè¡¨ç¤ºã«ã—ãŸã„å ´åˆã¯ã€ãã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ãƒ–ãƒ­ãƒƒã‚¯å³ä¸Šã«ã‚ã‚‹ãƒœã‚¿ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ï¼\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ## Train with Pytorch Trainer\n@@ -163,15 +161,11 @@ BERTãƒ¢ãƒ‡ãƒ«ã®äº‹å‰å­¦ç¿’æ¸ˆã¿ã®ãƒ˜ãƒƒãƒ‰ã¯ç ´æ£„ã•ã‚Œã€ãƒ©ãƒ³ãƒ€ãƒ ã«\n >>> trainer.train()\n ```\n \n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n \n ## Train in native Pytorch\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`]ã¯ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ«ãƒ¼ãƒ—ã‚’å‡¦ç†ã—ã€1è¡Œã®ã‚³ãƒ¼ãƒ‰ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n@@ -314,8 +308,6 @@ PyTorchã‹ã‚‰[`AdamW`](https://pytorch.org/docs/stable/generated/torch.optim.Ada\n >>> metric.compute()\n ```\n \n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        },
        {
            "sha": "d6c4b57fdbaea61b601bc91f0d15841d2a2d557d",
            "filename": "docs/source/ko/model_doc/albert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Falbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -163,8 +163,6 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n \n [[autodoc]] models.albert.modeling_albert.AlbertForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## AlbertModel[[albertmodel]]\n \n@@ -194,5 +192,3 @@ echo -e \"Plants create [MASK] through a process known as photosynthesis.\" | tran\n \n [[autodoc]] AlbertForQuestionAnswering - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "fdcc3db43877ddefdae49d88ef357cec825c6cdd",
            "filename": "docs/source/ko/model_doc/bart.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fbart.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -129,8 +129,6 @@ BARTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n     - all\n \n \n-<frameworkcontent>\n-<pt>\n \n ## BartModel[[transformers.BartModel]]\n \n@@ -157,8 +155,6 @@ BARTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n [[autodoc]] BartForCausalLM\n     - forward\n \n-</pt>\n-</frameworkcontent>\n \n \n "
        },
        {
            "sha": "f19aac769193598a66d8a50ae1cd1d5c400df055",
            "filename": "docs/source/ko/model_doc/bert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -164,22 +164,16 @@ BERTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n     - create_token_type_ids_from_sequences\n     - save_vocabulary\n \n-<frameworkcontent>\n-<pt>\n \n ## BertTokenizerFast\n \n [[autodoc]] BertTokenizerFast\n \n-</pt>\n-</frameworkcontent>\n \n ## Bert specific outputs\n \n [[autodoc]] models.bert.modeling_bert.BertForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## BertModel\n \n@@ -226,7 +220,5 @@ BERTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n [[autodoc]] BertForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n \n "
        },
        {
            "sha": "4aa81c0b9cd3e235dc430960c439df61c4f972db",
            "filename": "docs/source/ko/model_doc/blip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fblip.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -61,8 +61,6 @@ BLIPì€ ì—¬ëŸ¬ ë©€í‹°ëª¨ë‹¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤:\n [[autodoc]] BlipImageProcessor\n     - preprocess\n \n-<frameworkcontent>\n-<pt>\n \n ## BlipModel[[transformers.BlipModel]]\n \n@@ -98,5 +96,3 @@ BLIPì€ ì—¬ëŸ¬ ë©€í‹°ëª¨ë‹¬ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì…ë‹ˆë‹¤:\n [[autodoc]] BlipForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "b62629fa07711bf7178eaf6c6bb464bc83608125",
            "filename": "docs/source/ko/model_doc/clip.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fclip.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -234,8 +234,6 @@ CLIPì„ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n \n [[autodoc]] CLIPProcessor\n \n-<frameworkcontent>\n-<pt>\n \n ## CLIPModel[[transformers.CLIPModel]]\n \n@@ -269,5 +267,3 @@ CLIPì„ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ ëª©\n [[autodoc]] CLIPForImageClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "93fb06a5f166b5aa953ef81c9c1a92b70e94259b",
            "filename": "docs/source/ko/model_doc/convbert.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fconvbert.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -65,8 +65,6 @@ ConvBERT í›ˆë ¨ íŒì€ BERTì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì‚¬ìš© íŒì€ [BERT ë¬¸ì„œ](bert\n \n [[autodoc]] ConvBertTokenizerFast\n \n-<frameworkcontent>\n-<pt>\n \n ## ConvBertModel [[transformers.ConvBertModel]]\n \n@@ -98,5 +96,3 @@ ConvBERT í›ˆë ¨ íŒì€ BERTì™€ ìœ ì‚¬í•©ë‹ˆë‹¤. ì‚¬ìš© íŒì€ [BERT ë¬¸ì„œ](bert\n [[autodoc]] ConvBertForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "29bde98c1c4ac72230bfe21d0613d86ab6ce6387",
            "filename": "docs/source/ko/model_doc/deberta-v2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta-v2.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -67,8 +67,6 @@ v2ì˜ ìƒˆë¡œìš´ ì :\n     - build_inputs_with_special_tokens\n     - create_token_type_ids_from_sequences\n \n-<frameworkcontent>\n-<pt>\n \n ## DebertaV2Model\n \n@@ -105,5 +103,3 @@ v2ì˜ ìƒˆë¡œìš´ ì :\n [[autodoc]] DebertaV2ForMultipleChoice\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "11d75b6a00c0916c20f176069dbc1406baa963d3",
            "filename": "docs/source/ko/model_doc/deberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fdeberta.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -82,8 +82,6 @@ DeBERTaë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ \n     - build_inputs_with_special_tokens\n     - create_token_type_ids_from_sequences\n \n-<frameworkcontent>\n-<pt>\n \n ## DebertaModel[[transformers.DebertaModel]]\n \n@@ -114,6 +112,4 @@ DeBERTaë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” Hugging Faceì™€ community ìë£Œ \n [[autodoc]] DebertaForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>\n "
        },
        {
            "sha": "169ce388770aca60ce3f399084668707da275e6b",
            "filename": "docs/source/ko/model_doc/electra.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Felectra.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,8 +66,6 @@ Generators](https://openreview.net/pdf?id=r1xMH1BtvB) ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì—ˆ\n \n [[autodoc]] models.electra.modeling_electra.ElectraForPreTrainingOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## ElectraModel\n \n@@ -109,5 +107,3 @@ Generators](https://openreview.net/pdf?id=r1xMH1BtvB) ë…¼ë¬¸ì—ì„œ ì œì•ˆë˜ì—ˆ\n [[autodoc]] ElectraForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "0fed34179ffc4ae617767f937ce85c934eda89f0",
            "filename": "docs/source/ko/model_doc/encoder-decoder.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fencoder-decoder.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -136,14 +136,10 @@ nearly 800 thousand customers were affected by the shutoffs. the aim is to reduc\n \n [[autodoc]] EncoderDecoderConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## EncoderDecoderModel\n \n [[autodoc]] EncoderDecoderModel\n     - forward\n     - from_encoder_decoder_pretrained\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "4fde962d2d94c2c755d5b5851a57b3e160cd6d23",
            "filename": "docs/source/ko/model_doc/esm.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fesm.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -60,8 +60,6 @@ ESMFoldëŠ” [Matt](https://huggingface.co/Rocketknight1)ì™€ [Sylvain](https://hug\n     - create_token_type_ids_from_sequences\n     - save_vocabulary\n \n-<frameworkcontent>\n-<pt>\n \n ## EsmModel [[transformers.EsmModel]]\n \n@@ -88,5 +86,3 @@ ESMFoldëŠ” [Matt](https://huggingface.co/Rocketknight1)ì™€ [Sylvain](https://hug\n [[autodoc]] EsmForProteinFolding\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "316b3c4343234803c0dacefbbab771ecc62dd010",
            "filename": "docs/source/ko/model_doc/gpt2.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fgpt2.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -136,8 +136,6 @@ print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n \n [[autodoc]] models.gpt2.modeling_gpt2.GPT2DoubleHeadsModelOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## GPT2Model\n \n@@ -169,5 +167,3 @@ print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n [[autodoc]] GPT2ForTokenClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "a0701b6cfcaa004dd99eadc9026bf8efd4d3a2b5",
            "filename": "docs/source/ko/model_doc/marian.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fmarian.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -169,8 +169,6 @@ GROUP_MEMBERS = {\n [[autodoc]] MarianTokenizer\n     - build_inputs_with_special_tokens\n \n-<frameworkcontent>\n-<pt>\n \n ## MarianModel\n \n@@ -187,5 +185,3 @@ GROUP_MEMBERS = {\n [[autodoc]] MarianForCausalLM\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "9452561ca60f6ac83c3aaa46295414125970a25d",
            "filename": "docs/source/ko/model_doc/openai-gpt.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fopenai-gpt.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -97,8 +97,6 @@ OpenAI GPTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê³µì‹ Hugging Face ë° ì»¤ë®¤\n \n [[autodoc]] models.openai.modeling_openai.OpenAIGPTDoubleHeadsModelOutput\n \n-<frameworkcontent>\n-<pt>\n \n ## OpenAIGPTModel [[transformers.OpenAIGPTModel]]\n \n@@ -120,5 +118,3 @@ OpenAI GPTë¥¼ ì‹œì‘í•˜ëŠ” ë° ë„ì›€ì´ ë˜ëŠ” ê³µì‹ Hugging Face ë° ì»¤ë®¤\n [[autodoc]] OpenAIGPTForSequenceClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "7d84e1e250f15aa5f8f263e0a8795eb7afe44fc5",
            "filename": "docs/source/ko/model_doc/rag.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Frag.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -56,8 +56,6 @@ rendered properly in your Markdown viewer.\n \n [[autodoc]] RagRetriever\n \n-<frameworkcontent>\n-<pt>\n \n ## RagModel [[transformers.RagModel]]\n \n@@ -76,5 +74,3 @@ rendered properly in your Markdown viewer.\n     - forward\n     - generate\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "f7774bbbabe71c554be7053dd880e3aef17fac20",
            "filename": "docs/source/ko/model_doc/roberta.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Froberta.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -112,8 +112,6 @@ RoBERTaë¥¼ ì²˜ìŒ ë‹¤ë£° ë•Œ ë„ì›€ì´ ë˜ëŠ” Hugging Face ê³µì‹ ìë£Œì™€ ì»¤\n [[autodoc]] RobertaTokenizerFast\n     - build_inputs_with_special_tokens\n \n-<frameworkcontent>\n-<pt>\n \n ## RobertaModel\n \n@@ -150,5 +148,3 @@ RoBERTaë¥¼ ì²˜ìŒ ë‹¤ë£° ë•Œ ë„ì›€ì´ ë˜ëŠ” Hugging Face ê³µì‹ ìë£Œì™€ ì»¤\n [[autodoc]] RobertaForQuestionAnswering\n     - forward\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "6d90dc8226aecbb22c6f397d7d6412af5ede522c",
            "filename": "docs/source/ko/model_doc/swin.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fswin.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -55,8 +55,6 @@ Swin Transformerì˜ ì‚¬ìš©ì„ ë„ìš¸ ìˆ˜ ìˆëŠ” Hugging Face ë° ì»¤ë®¤ë‹ˆí‹°(\n \n [[autodoc]] SwinConfig\n \n-<frameworkcontent>\n-<pt>\n \n ## SwinModel [[transformers.SwinModel]]\n \n@@ -73,5 +71,3 @@ Swin Transformerì˜ ì‚¬ìš©ì„ ë„ìš¸ ìˆ˜ ìˆëŠ” Hugging Face ë° ì»¤ë®¤ë‹ˆí‹°(\n [[autodoc]] transformers.SwinForImageClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "7cdb6fbd6c41880a0e502c30c4861a51bd98eb1a",
            "filename": "docs/source/ko/model_doc/vit.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_doc%2Fvit.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -124,8 +124,6 @@ ViTì˜ ì¶”ë¡  ë° ì»¤ìŠ¤í…€ ë°ì´í„°ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì •ê³¼ ê´€ë ¨ëœ ë°\n [[autodoc]] ViTImageProcessorFast\n     - preprocess\n \n-<frameworkcontent>\n-<pt>\n \n ## ViTModel [[transformers.ViTModel]]\n \n@@ -142,5 +140,3 @@ ViTì˜ ì¶”ë¡  ë° ì»¤ìŠ¤í…€ ë°ì´í„°ì— ëŒ€í•œ ë¯¸ì„¸ ì¡°ì •ê³¼ ê´€ë ¨ëœ ë°\n [[autodoc]] ViTForImageClassification\n     - forward\n \n-</pt>\n-</frameworkcontent>\n\\ No newline at end of file"
        },
        {
            "sha": "223fb6571c1c71085d5fce921da52da078c3c9a6",
            "filename": "docs/source/ko/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -79,21 +79,15 @@ pip install huggingface_hub\n \n ì²´í¬í¬ì¸íŠ¸ë¥¼ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì€ ì‰½ìŠµë‹ˆë‹¤. PyTorch ë° TensorFlowê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•œ ë‹¤ìŒ(ì„¤ì¹˜ ì§€ì¹¨ì€ [ì—¬ê¸°](installation) ì°¸ì¡°) ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ì—ì„œ ì‘ì—…ì— ëŒ€í•œ íŠ¹ì • ëª¨ë¸ì„ ì°¾ìŠµë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n ì²´í¬í¬ì¸íŠ¸ë¥¼ TensorFlowì—ì„œ PyTorchë¡œ ë³€í™˜í•˜ë ¤ë©´ `from_tf=True`ë¥¼ ì§€ì •í•˜ì„¸ìš”:\n \n ```py\n >>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n >>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í›ˆë ¨ ì¤‘ ëª¨ë¸ í‘¸ì‹œí•˜ê¸°[[push-a-model-during-training]]\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n ëª¨ë¸ì„ í—ˆë¸Œì— ê³µìœ í•˜ëŠ” ê²ƒì€ ì¶”ê°€ ë§¤ê°œë³€ìˆ˜ë‚˜ ì½œë°±ì„ ì¶”ê°€í•˜ëŠ” ê²ƒë§Œí¼ ê°„ë‹¨í•©ë‹ˆë‹¤. [ë¯¸ì„¸ ì¡°ì • íŠœí† ë¦¬ì–¼](training)ì—ì„œ [`TrainingArguments`] í´ë˜ìŠ¤ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ì¶”ê°€ í›ˆë ¨ ì˜µì…˜ì„ ì§€ì •í•˜ëŠ” ê³³ì´ë¼ëŠ” ê²ƒì„ ê¸°ì–µí•˜ì„¸ìš”. ì´ëŸ¬í•œ í›ˆë ¨ ì˜µì…˜ ì¤‘ í•˜ë‚˜ëŠ” ëª¨ë¸ì„ í—ˆë¸Œë¡œ ì§ì ‘ í‘¸ì‹œí•˜ëŠ” ê¸°ëŠ¥ì„ í¬í•¨í•©ë‹ˆë‹¤. [`TrainingArguments`]ì—ì„œ `push_to_hub=True`ë¥¼ ì„¤ì •í•˜ì„¸ìš”:\n@@ -119,8 +113,6 @@ pip install huggingface_hub\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## `push_to_hub` í•¨ìˆ˜ ì‚¬ìš©í•˜ê¸°[[use-the-pushtohub-function]]\n "
        },
        {
            "sha": "de882503c9d84969f57e8f706674cfce17c1c1cf",
            "filename": "docs/source/ko/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -28,14 +28,10 @@ rendered properly in your Markdown viewer.\n \n ë˜í•œ ì„ í˜¸í•˜ëŠ” ë¨¸ì‹  ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¥¼ ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## íŒŒì´í”„ë¼ì¸ [[pipeline]]\n \n@@ -133,8 +129,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n [`AutoModelForSequenceClassification`]ê³¼ [`AutoTokenizer`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ ê´€ë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•˜ì„¸ìš” (ë‹¤ìŒ ì„¹ì…˜ì—ì„œ [`AutoClass`]ì— ëŒ€í•´ ë” ìì„¸íˆ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤):\n \n ```py\n@@ -143,8 +137,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n [`pipeline`]ì—ì„œ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ì§€ì •í•˜ë©´, ì´ì œ `classifier`ë¥¼ í”„ë‘ìŠ¤ì–´ í…ìŠ¤íŠ¸ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n \n@@ -194,8 +186,6 @@ label: NEGATIVE, with score: 0.5309\n \n í† í¬ë‚˜ì´ì €ëŠ” ì…ë ¥ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œë„ ë°›ì„ ìˆ˜ ìˆìœ¼ë©°, í…ìŠ¤íŠ¸ë¥¼ íŒ¨ë”©í•˜ê³  ì˜ë¼ë‚´ì–´ ì¼ì •í•œ ê¸¸ì´ì˜ ë¬¶ìŒì„ ë°˜í™˜í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -206,8 +196,6 @@ label: NEGATIVE, with score: 0.5309\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -217,8 +205,6 @@ label: NEGATIVE, with score: 0.5309\n \n ### AutoModel [[automodel]]\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— TransformersëŠ” ì‚¬ì „ í›ˆë ¨ëœ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê°„ë‹¨í•˜ê³  í†µí•©ëœ ë°©ë²•ìœ¼ë¡œ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¦‰, [`AutoTokenizer`]ì²˜ëŸ¼ [`AutoModel`]ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìœ ì¼í•œ ì°¨ì´ì ì€ ê³¼ì—…ì— ì•Œë§ì€ [`AutoModel`]ì„ ì„ íƒí•´ì•¼ í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤. í…ìŠ¤íŠ¸ (ë˜ëŠ” ì‹œí€€ìŠ¤) ë¶„ë¥˜ì˜ ê²½ìš° [`AutoModelForSequenceClassification`]ì„ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤:\n \n ```py\n@@ -250,8 +236,6 @@ label: NEGATIVE, with score: 0.5309\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -261,8 +245,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n \n ### ëª¨ë¸ ì €ì¥í•˜ê¸° [[save-a-model]]\n \n-<frameworkcontent>\n-<pt>\n ë¯¸ì„¸ì¡°ì •ëœ ëª¨ë¸ì„ í† í¬ë‚˜ì´ì €ì™€ í•¨ê»˜ ì €ì¥í•˜ë ¤ë©´ [`PreTrainedModel.save_pretrained`]ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:\n \n ```py\n@@ -276,22 +258,16 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ğŸ¤— Transformersì˜ ë©‹ì§„ ê¸°ëŠ¥ ì¤‘ í•˜ë‚˜ëŠ” ëª¨ë¸ì„ PyTorch ë˜ëŠ” TensorFlow ëª¨ë¸ë¡œ ì €ì¥í•´ë’€ë‹¤ê°€ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ë¡œ ë‹¤ì‹œ ë¡œë“œí•  ìˆ˜ ìˆëŠ” ì ì…ë‹ˆë‹¤. `from_pt` ë˜ëŠ” `from_tf` ë§¤ê°œë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•œ í”„ë ˆì„ì›Œí¬ì—ì„œ ë‹¤ë¥¸ í”„ë ˆì„ì›Œí¬ë¡œ ë³€í™˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## ì»¤ìŠ¤í…€ ëª¨ë¸ êµ¬ì¶•í•˜ê¸° [[custom-model-builds]]\n \n@@ -305,17 +281,13 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n [`AutoModel.from_config`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°”ê¾¼ êµ¬ì„±ëŒ€ë¡œ ëª¨ë¸ì„ ìƒì„±í•˜ì„¸ìš”:\n \n ```py\n >>> from transformers import AutoModel\n \n >>> my_model = AutoModel.from_config(my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ì»¤ìŠ¤í…€ êµ¬ì„±ì— ëŒ€í•œ ìì„¸í•œ ë‚´ìš©ì€ [ì»¤ìŠ¤í…€ ì•„í‚¤í…ì²˜ ë§Œë“¤ê¸°](./create_a_model) ê°€ì´ë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.\n "
        },
        {
            "sha": "874834a1f32ab8bfd268b3ce58ef64a7c83391bc",
            "filename": "docs/source/ko/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -90,8 +90,6 @@ pip install -r requirements.txt\n \n ## ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°[[run-a-script]]\n \n-<frameworkcontent>\n-<pt>\n ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ëŠ” ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/) ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤.\n ê·¸ëŸ° ë‹¤ìŒ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìš”ì•½ ê¸°ëŠ¥ì„ ì§€ì›í•˜ëŠ” ì•„í‚¤í…ì²˜ì—ì„œ [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\n ë‹¤ìŒ ì˜ˆëŠ” [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail) ë°ì´í„° ì„¸íŠ¸ì—ì„œ [T5-small](https://huggingface.co/google-t5/t5-small)ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\n@@ -111,8 +109,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í˜¼í•© ì •ë°€ë„(mixed precision)ë¡œ ë¶„ì‚° í›ˆë ¨í•˜ê¸°[[distributed-training-and-mixed-precision]]\n \n@@ -144,8 +140,6 @@ TensorFlow ìŠ¤í¬ë¦½íŠ¸ëŠ” ë¶„ì‚° í›ˆë ¨ì„ ìœ„í•´ [`MirroredStrategy`](https://\n \n ## TPU ìœ„ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°[[run-a-script-on-a-tpu]]\n \n-<frameworkcontent>\n-<pt>\n Tensor Processing Units (TPUs)ëŠ” ì„±ëŠ¥ì„ ê°€ì†í™”í•˜ê¸° ìœ„í•´ íŠ¹ë³„íˆ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n PyTorchëŠ” [XLA](https://www.tensorflow.org/xla) ë”¥ëŸ¬ë‹ ì»´íŒŒì¼ëŸ¬ì™€ í•¨ê»˜ TPUë¥¼ ì§€ì›í•©ë‹ˆë‹¤(ìì„¸í•œ ë‚´ìš©ì€ [ì—¬ê¸°](https://github.com/pytorch/xla/blob/master/README.md) ì°¸ì¡°). \n TPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ `xla_spawn.py` ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  `num_cores` ì¸ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©í•˜ë ¤ëŠ” TPU ì½”ì–´ ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.\n@@ -165,8 +159,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## ğŸ¤— Accelerateë¡œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰í•˜ê¸°[[run-a-script-with-accelerate]]\n "
        },
        {
            "sha": "f28dd9fbec0492234fde0ff9df77febe385e6998",
            "filename": "docs/source/ko/tasks/asr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fasr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fasr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fasr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -232,8 +232,6 @@ MInDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 8000kHzì´ë¯€ë¡œ([ë°ì´í„°\n \n ## í›ˆë ¨í•˜ê¸°[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì´ ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•´ë³´ì„¸ìš”!\n@@ -298,8 +296,6 @@ MInDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 8000kHzì´ë¯€ë¡œ([ë°ì´í„°\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -340,8 +336,6 @@ MInDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 8000kHzì´ë¯€ë¡œ([ë°ì´í„°\n \n `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¬í˜„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n ì˜¤ë””ì˜¤ íŒŒì¼ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì „ì²˜ë¦¬í•˜ê³  PyTorch í…ì„œë¡œ `input`ì„ ë°˜í™˜í•  í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ì„¸ìš”:\n \n ```py\n@@ -371,5 +365,3 @@ MInDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ë ˆì´íŠ¸ëŠ” 8000kHzì´ë¯€ë¡œ([ë°ì´í„°\n >>> transcription\n ['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "789d7ee883738e8b7781222ae524c0b3ff41c585",
            "filename": "docs/source/ko/tasks/audio_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Faudio_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -187,8 +187,6 @@ MinDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ì†ë„ëŠ” 8khzì´ë¯€ë¡œ(ì´ ì •ë³´ëŠ” [\n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë° ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì„ ì‚´í´ë³´ì„¸ìš”!\n@@ -247,8 +245,6 @@ MinDS-14 ë°ì´í„° ì„¸íŠ¸ì˜ ìƒ˜í”Œë§ ì†ë„ëŠ” 8khzì´ë¯€ë¡œ(ì´ ì •ë³´ëŠ” [\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -289,8 +285,6 @@ For a more in-depth example of how to finetune a model for audio classification,\n \n ì›í•˜ëŠ” ê²½ìš° `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n íŠ¹ì§• ì¶”ì¶œê¸°ë¥¼ ê°€ì ¸ì™€ì„œ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì „ì²˜ë¦¬í•˜ê³  `ì…ë ¥`ì„ PyTorch í…ì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤:\n \n ```py\n@@ -320,5 +314,3 @@ For a more in-depth example of how to finetune a model for audio classification,\n >>> predicted_label\n 'cash_deposit'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "54490a6f939a0869ffba7feaffbc08d3c93c96aa",
            "filename": "docs/source/ko/tasks/image_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fimage_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -108,8 +108,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n >>> image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n ```\n \n-<frameworkcontent>\n-<pt>\n ì´ë¯¸ì§€ì— ëª‡ ê°€ì§€ ì´ë¯¸ì§€ ë³€í™˜ì„ ì ìš©í•˜ì—¬ ê³¼ì í•©ì— ëŒ€í•´ ëª¨ë¸ì„ ë” ê²¬ê³ í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ì—¬ê¸°ì„œ Torchvisionì˜ [`transforms`](https://pytorch.org/vision/stable/transforms.html) ëª¨ë“ˆì„ ì‚¬ìš©í•˜ì§€ë§Œ, ì›í•˜ëŠ” ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n \n ì´ë¯¸ì§€ì˜ ì„ì˜ ë¶€ë¶„ì„ í¬ë¡­í•˜ê³  í¬ê¸°ë¥¼ ì¡°ì •í•œ ë‹¤ìŒ, ì´ë¯¸ì§€ í‰ê· ê³¼ í‘œì¤€ í¸ì°¨ë¡œ ì •ê·œí™”í•˜ì„¸ìš”:\n@@ -148,8 +146,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n >>> data_collator = DefaultDataCollator()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n ## í‰ê°€[[evaluate]]\n@@ -180,8 +176,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš°, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•˜ì„¸ìš”!\n@@ -243,8 +237,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n <Tip>\n@@ -284,8 +276,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n ì›í•œë‹¤ë©´, `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œë¥¼ ê°€ì ¸ì˜¤ê³  `input`ì„ PyTorch í…ì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤:\n \n ```py\n@@ -313,5 +303,3 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n >>> model.config.id2label[predicted_label]\n 'beignets'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "dcb665a0025a6e726847d1cd85e1cdd47ed35521",
            "filename": "docs/source/ko/tasks/language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Flanguage_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Flanguage_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Flanguage_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -175,8 +175,6 @@ pip install transformers datasets evaluate\n \n ê·¸ëŸ° ë‹¤ìŒ [`DataCollatorForLanguageModeling`]ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œì˜ ë°°ì¹˜ë¥¼ ë§Œë“­ë‹ˆë‹¤. ë°ì´í„° ì„¸íŠ¸ ì „ì²´ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ëŠ” ê²ƒë³´ë‹¤, ì·¨í•© ë‹¨ê³„ì—ì„œ ê° ë°°ì¹˜ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ *ë™ì ìœ¼ë¡œ íŒ¨ë”©*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n íŒ¨ë”© í† í°ìœ¼ë¡œ ì¢…ê²° í† í°ì„ ì‚¬ìš©í•˜ê³  `mlm=False`ë¡œ ì„¤ì •í•˜ì„¸ìš”. ì´ë ‡ê²Œ í•˜ë©´ ì…ë ¥ì„ ì˜¤ë¥¸ìª½ìœ¼ë¡œ í•œ ì¹¸ì”© ì‹œí”„íŠ¸í•œ ê°’ì„ ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤:\n \n ```py\n@@ -186,14 +184,10 @@ pip install transformers datasets evaluate\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë°©ë²•ì„ ì˜ ëª¨ë¥´ì‹ ë‹¤ë©´ [ê¸°ë³¸ íŠœí† ë¦¬ì–¼](../training#train-with-pytorch-trainer)ì„ í™•ì¸í•´ë³´ì„¸ìš”!\n@@ -249,8 +243,6 @@ Perplexity: 49.61\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -278,8 +270,6 @@ Perplexity: 49.61\n [{'generated_text': \"Somatic hypermutation allows the immune system to be able to effectively reverse the damage caused by an infection.\\n\\n\\nThe damage caused by an infection is caused by the immune system's ability to perform its own self-correcting tasks.\"}]\n ```\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œë¡œ ë°˜í™˜í•˜ì„¸ìš”:\n \n ```py\n@@ -304,5 +294,3 @@ Perplexity: 49.61\n >>> tokenizer.batch_decode(outputs, skip_special_tokens=True)\n [\"Somatic hypermutation allows the immune system to react to drugs with the ability to adapt to a different environmental situation. In other words, a system of 'hypermutation' can help the immune system to adapt to a different environmental situation or in some cases even a single life. In contrast, researchers at the University of Massachusetts-Boston have found that 'hypermutation' is much stronger in mice than in humans but can be found in humans, and that it's not completely unknown to the immune system. A study on how the immune system\"]\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "65da783f9ae8720fec5842e2d484b47580a91d93",
            "filename": "docs/source/ko/tasks/masked_language_modeling.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fmasked_language_modeling.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fmasked_language_modeling.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fmasked_language_modeling.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -179,8 +179,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì™€\n ì´ì œ [`DataCollatorForLanguageModeling`]ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„° ì˜ˆì œì˜ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. \n ë°ì´í„° ì„¸íŠ¸ ì „ì²´ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ëŠ” ê²ƒë³´ë‹¤ collation ë‹¨ê³„ì—ì„œ ë§¤ ë°°ì¹˜ì•ˆì—ì„œì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ *ë™ì ìœ¼ë¡œ íŒ¨ë”©*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n \n ì‹œí€€ìŠ¤ ë í† í°ì„ íŒ¨ë”© í† í°ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  ë°ì´í„°ë¥¼ ë°˜ë³µí•  ë•Œë§ˆë‹¤ í† í°ì„ ë¬´ì‘ìœ„ë¡œ ë§ˆìŠ¤í‚¹í•˜ë„ë¡ `mlm_-probability`ë¥¼ ì§€ì •í•©ë‹ˆë‹¤:\n \n@@ -190,13 +188,9 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì™€\n >>> tokenizer.pad_token = tokenizer.eos_token\n >>> data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë° ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ [ì—¬ê¸°](../training#train-with-pytorch-trainer)ë¥¼ ì‚´í´ë³´ì„¸ìš”!\n@@ -252,8 +246,6 @@ Perplexity: 8.76\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -295,8 +287,6 @@ Perplexity: 8.76\n   'sequence': 'The Milky Way is a small galaxy.'}]\n ```\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.\n ë˜í•œ, `<mask>` í† í°ì˜ ìœ„ì¹˜ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤:\n ```py\n@@ -327,5 +317,3 @@ The Milky Way is a spiral galaxy.\n The Milky Way is a massive galaxy.\n The Milky Way is a small galaxy.\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "c8d99bc02ca1944c36a1afc5cf66a157ef67335c",
            "filename": "docs/source/ko/tasks/multiple_choice.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fmultiple_choice.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fmultiple_choice.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fmultiple_choice.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -144,8 +144,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n \n ## í›ˆë ¨ í•˜ê¸°[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ë° ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ [ì—¬ê¸°](../training#train-with-pytorch-trainer)ë¥¼ ì‚´í´ë³´ì„¸ìš”!\n@@ -198,8 +196,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n <Tip>\n@@ -222,8 +218,6 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> candidate2 = \"The law applies to baguettes.\"\n ```\n \n-<frameworkcontent>\n-<pt>\n ê° í”„ë¡¬í”„íŠ¸ì™€ í›„ë³´ ë‹µë³€ ìŒì„ í† í°í™”í•˜ì—¬ PyTorch í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. ë˜í•œ `labels`ì„ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤:\n \n ```py\n@@ -251,5 +245,3 @@ tokenized_swag = swag.map(preprocess_function, batched=True)\n >>> predicted_class\n '0'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "6e067dc389349c2cf511632bb656bfc2874248ce",
            "filename": "docs/source/ko/tasks/question_answering.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fquestion_answering.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fquestion_answering.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fquestion_answering.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -165,20 +165,14 @@ pip install transformers datasets evaluate\n \n ì´ì œ [`DefaultDataCollator`]ë¥¼ ì´ìš©í•´ ì˜ˆì‹œ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ğŸ¤— Transformersì˜ ë‹¤ë¥¸ ë°ì´í„° ì½œë ˆì´í„°(data collator)ì™€ ë‹¬ë¦¬, [`DefaultDataCollator`]ëŠ” íŒ¨ë”©ê³¼ ê°™ì€ ì¶”ê°€ ì „ì²˜ë¦¬ë¥¼ ì ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DefaultDataCollator\n \n >>> data_collator = DefaultDataCollator()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¥¼ ì´ìš©í•´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ì´ˆ íŠœí† ë¦¬ì–¼ì„ ì‚´í´ë³´ì„¸ìš”!\n@@ -228,8 +222,6 @@ pip install transformers datasets evaluate\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -269,8 +261,6 @@ pip install transformers datasets evaluate\n \n ì›í•œë‹¤ë©´ `pipeline`ì˜ ê²°ê³¼ë¥¼ ì§ì ‘ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•´ì„œ PyTorch í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:\n \n ```py\n@@ -304,5 +294,3 @@ pip install transformers datasets evaluate\n >>> tokenizer.decode(predict_answer_tokens)\n '176 billion parameters and can generate text in 46 languages natural languages and 13'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "68acd8cda9ea1596e3c27e150aeac0f1a98e3139",
            "filename": "docs/source/ko/tasks/semantic_segmentation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsemantic_segmentation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsemantic_segmentation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fsemantic_segmentation.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -104,8 +104,6 @@ pip install -q datasets transformers evaluate\n >>> image_processor = AutoImageProcessor.from_pretrained(checkpoint, do_reduce_labels=True)\n ```\n \n-<frameworkcontent>\n-<pt>\n \n ì´ë¯¸ì§€ ë°ì´í„° ì„¸íŠ¸ì— ë°ì´í„° ì¦ê°•ì„ ì ìš©í•˜ì—¬ ê³¼ì í•©ì— ëŒ€í•´ ëª¨ë¸ì„ ë³´ë‹¤ ê°•ê±´í•˜ê²Œ ë§Œë“œëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œëŠ” [torchvision](https://pytorch.org/vision/stable/index.html)ì˜ [`ColorJitter`](https://pytorch.org/vision/stable/generated/torchvision.transforms.ColorJitter.html)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ìƒ‰ìƒ ì†ì„±ì„ ì„ì˜ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ, ìì‹ ì´ ì›í•˜ëŠ” ì´ë¯¸ì§€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n \n@@ -139,8 +137,6 @@ pip install -q datasets transformers evaluate\n >>> test_ds.set_transform(val_transforms)\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ## í‰ê°€í•˜ê¸°[[evaluate]]\n \n@@ -154,8 +150,6 @@ pip install -q datasets transformers evaluate\n \n ê·¸ëŸ° ë‹¤ìŒ ë©”íŠ¸ë¦­ì„ [`~evaluate.EvaluationModule.compute`]í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì˜ˆì¸¡ì„ ë¨¼ì € ë¡œì§“ìœ¼ë¡œ ë³€í™˜í•œ ë‹¤ìŒ, ë ˆì´ë¸”ì˜ í¬ê¸°ì— ë§ê²Œ ëª¨ì–‘ì„ ë‹¤ì‹œ ì§€ì •í•´ì•¼ [`~evaluate.EvaluationModule.compute`]ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> import numpy as np\n@@ -187,15 +181,11 @@ pip install -q datasets transformers evaluate\n ...         return metrics\n ```\n \n-</pt>\n-</frameworkcontent>\n \n \n ì´ì œ `compute_metrics` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. íŠ¸ë ˆì´ë‹ì„ ì„¤ì •í•  ë•Œ ì´ í•¨ìˆ˜ë¡œ ëŒì•„ê°€ê²Œ ë©ë‹ˆë‹¤.\n \n ## í•™ìŠµí•˜ê¸°[[train]]\n-<frameworkcontent>\n-<pt>\n <Tip>\n \n ë§Œì•½ [`Trainer`]ë¥¼ ì‚¬ìš©í•´ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ëŠ” ê²ƒì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì—¬ê¸°](../training#finetune-with-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ ì‚´í´ë³´ì„¸ìš”!\n@@ -249,8 +239,6 @@ pip install -q datasets transformers evaluate\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n \n ## ì¶”ë¡ í•˜ê¸°[[inference]]\n@@ -268,8 +256,6 @@ pip install -q datasets transformers evaluate\n     <img src=\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/semantic-seg-image.png\" alt=\"Image of bedroom\"/>\n </div>\n \n-<frameworkcontent>\n-<pt>\n \n ì¶”ë¡ ì„ ìœ„í•´ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì„ ì‹œí—˜í•´ ë³´ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ [`pipeline`]ì—ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ë¶„í• ì„ ìœ„í•œ `pipeline`ì„ ì¸ìŠ¤í„´ìŠ¤í™”í•˜ê³  ì´ë¯¸ì§€ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤:\n \n@@ -333,8 +319,6 @@ pip install -q datasets transformers evaluate\n >>> pred_seg = upsampled_logits.argmax(dim=1)[0]\n ```\n \n-</pt>\n-</frameworkcontent>\n \n ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ë ¤ë©´ [dataset color palette](https://github.com/tensorflow/models/blob/3f1ca33afe3c1631b733ea7e40c294273b9e406d/research/deeplab/utils/get_dataset_colormap.py#L51)ë¥¼ ê° í´ë˜ìŠ¤ë¥¼ RGB ê°’ì— ë§¤í•‘í•˜ëŠ” `ade_palette()`ë¡œ ë¡œë“œí•©ë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ ì´ë¯¸ì§€ì™€ ì˜ˆì¸¡ëœ ë¶„í•  ì§€ë„(segmentation map)ì„ ê²°í•©í•˜ì—¬ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n "
        },
        {
            "sha": "9ffad8ff0b24806a022144553bb64e50d766c449",
            "filename": "docs/source/ko/tasks/sequence_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsequence_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsequence_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fsequence_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -97,15 +97,11 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n \n ì´ì œ [`DataCollatorWithPadding`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤. ë°ì´í„°ì…‹ ì „ì²´ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ëŠ” ëŒ€ì‹ , *ë™ì  íŒ¨ë”©*ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ì—ì„œ ê°€ì¥ ê¸´ ê¸¸ì´ì— ë§ê²Œ ë¬¸ì¥ì„ íŒ¨ë”©í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorWithPadding\n \n >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í‰ê°€í•˜ê¸°[[evaluate]]\n \n@@ -140,8 +136,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n >>> label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n ```\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš°, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì˜ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•˜ì„¸ìš”!\n@@ -202,8 +196,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -233,8 +225,6 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n \n ì›í•œë‹¤ë©´, `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  PyTorch í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\n \n ```py\n@@ -261,5 +251,3 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n >>> model.config.id2label[predicted_class_id]\n 'POSITIVE'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "848a6cb00d0072ce18a25e324fef3605a0e558f4",
            "filename": "docs/source/ko/tasks/summarization.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsummarization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Fsummarization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Fsummarization.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -124,15 +124,11 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ì´ì œ [`DataCollatorForSeq2Seq`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ë§Œë“œì„¸ìš”.\n ì „ì²´ ë°ì´í„°ì…‹ì„ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ëŠ” ê²ƒë³´ë‹¤ ë°°ì¹˜ë§ˆë‹¤ ê°€ì¥ ê¸´ ë¬¸ì¥ ê¸¸ì´ì— ë§ì¶° *ë™ì  íŒ¨ë”©*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í‰ê°€[[evaluate]]\n \n@@ -171,8 +167,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n ## í•™ìŠµ[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n ëª¨ë¸ì„ [`Trainer`]ë¡œ íŒŒì¸íŠœë‹ í•˜ëŠ” ê²ƒì´ ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•´ë³´ì„¸ìš”!\n@@ -229,8 +223,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -263,8 +255,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ì›í•œë‹¤ë©´ ìˆ˜ë™ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•˜ì—¬ [`pipeline`]ì˜ ê²°ê³¼ì™€ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n \n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í¬ë‚˜ì´ì¦ˆí•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œë¡œ ë°˜í™˜í•©ë‹ˆë‹¤:\n \n ```py\n@@ -290,5 +280,3 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ë©´ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n >>> tokenizer.decode(outputs[0], skip_special_tokens=True)\n 'the inflation reduction act lowers prescription drug costs, health care costs, and energy costs. it's the most aggressive action on tackling the climate crisis in american history. it will ask the ultra-wealthy and corporations to pay their fair share.'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "e4975405c3deb9e25c7d17830d55b97f1dabe2b9",
            "filename": "docs/source/ko/tasks/token_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Ftoken_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Ftoken_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Ftoken_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -155,15 +155,11 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n ì´ì œ [`DataCollatorWithPadding`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤. ë°ì´í„° ì„¸íŠ¸ ì „ì²´ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ íŒ¨ë”©í•˜ëŠ” ëŒ€ì‹ , *ë™ì  íŒ¨ë”©*ì„ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ì—ì„œ ê°€ì¥ ê¸´ ê¸¸ì´ì— ë§ê²Œ ë¬¸ì¥ì„ íŒ¨ë”©í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForTokenClassification\n \n >>> data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í‰ê°€[[evaluation]]\n \n@@ -244,8 +240,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ... }\n ```\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ íŒŒì¸ íŠœë‹í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šì€ ê²½ìš°, [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ í™•ì¸í•˜ì„¸ìš”!\n@@ -300,8 +294,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -362,8 +354,6 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n \n ì›í•œë‹¤ë©´, `pipeline`ì˜ ê²°ê³¼ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  PyTorch í…ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:\n \n ```py\n@@ -407,5 +397,3 @@ Hugging Face ê³„ì •ì— ë¡œê·¸ì¸í•˜ì—¬ ëª¨ë¸ì„ ì—…ë¡œë“œí•˜ê³  ì»¤ë®¤ë‹ˆí‹°ì—\n  'O',\n  'O']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "4ecda3de384b75e8dd0c7c9e23e2357fc1866c33",
            "filename": "docs/source/ko/tasks/translation.md",
            "status": "modified",
            "additions": 0,
            "deletions": 12,
            "changes": 12,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Ftranslation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftasks%2Ftranslation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftasks%2Ftranslation.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -114,15 +114,11 @@ pip install transformers datasets evaluate sacrebleu\n \n ì´ì œ [`DataCollatorForSeq2Seq`]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì œ ë°°ì¹˜ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë°ì´í„°ì„¸íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ì „ë¶€ë¥¼ paddingí•˜ëŠ” ëŒ€ì‹ , ë°ì´í„° ì •ë ¬ ì¤‘ ê° ë°°ì¹˜ì˜ ìµœëŒ€ ê¸¸ì´ë¡œ ë¬¸ì¥ì„ *ë™ì ìœ¼ë¡œ padding*í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForSeq2Seq\n \n >>> data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## í‰ê°€[[evalulate]]\n \n@@ -171,8 +167,6 @@ pip install transformers datasets evaluate sacrebleu\n \n ## í›ˆë ¨[[train]]\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n [`Trainer`]ë¡œ ëª¨ë¸ì„ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì— ìµìˆ™í•˜ì§€ ì•Šë‹¤ë©´ [ì—¬ê¸°](../training#train-with-pytorch-trainer)ì—ì„œ ê¸°ë³¸ íŠœí† ë¦¬ì–¼ì„ ì‚´í´ë³´ì‹œê¸° ë°”ëë‹ˆë‹¤!\n@@ -226,8 +220,6 @@ pip install transformers datasets evaluate sacrebleu\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -260,8 +252,6 @@ pip install transformers datasets evaluate sacrebleu\n \n ì›í•œë‹¤ë©´ `pipeline`ì˜ ê²°ê³¼ë¥¼ ì§ì ‘ ë³µì œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤:\n \n-<frameworkcontent>\n-<pt>\n í…ìŠ¤íŠ¸ë¥¼ í† í°í™”í•˜ê³  `input_ids`ë¥¼ PyTorch í…ì„œë¡œ ë°˜í™˜í•˜ì„¸ìš”:\n \n ```py\n@@ -286,5 +276,3 @@ pip install transformers datasets evaluate sacrebleu\n >>> tokenizer.decode(outputs[0], skip_special_tokens=True)\n 'Les lignÃ©es partagent des ressources avec des bactÃ©ries enfixant l'azote.'\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "95a7fe285d3c8c312ace0d6aa9fb3e9566cc9027",
            "filename": "docs/source/ko/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fko%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -71,8 +71,6 @@ rendered properly in your Markdown viewer.\n \n ì—¬ê¸°ì„œë¶€í„°ëŠ” ì‚¬ìš©í•˜ë ¤ëŠ” í”„ë ˆì„ì›Œí¬ì— í•´ë‹¹í•˜ëŠ” ì„¹ì…˜ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤. ì˜¤ë¥¸ìª½ ì‚¬ì´ë“œë°”ì˜ ë§í¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” í”„ë ˆì„ì›Œí¬ë¡œ ì´ë™í•  ìˆ˜ ìˆìœ¼ë©°, íŠ¹ì • í”„ë ˆì„ì›Œí¬ì˜ ëª¨ë“  ì½˜í…ì¸ ë¥¼ ìˆ¨ê¸°ë ¤ë©´ í•´ë‹¹ í”„ë ˆì„ì›Œí¬ ë¸”ë¡ì˜ ì˜¤ë¥¸ìª½ ìƒë‹¨ì— ìˆëŠ” ë²„íŠ¼ì„ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤!\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ## íŒŒì´í† ì¹˜ Trainerë¡œ í›ˆë ¨í•˜ê¸°[[train-with-pytorch-trainer]]\n@@ -156,15 +154,11 @@ rendered properly in your Markdown viewer.\n ```py\n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n \n ## ê¸°ë³¸ íŒŒì´í† ì¹˜ë¡œ í›ˆë ¨í•˜ê¸°[[train-in-native-pytorch]]\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`]ëŠ” í›ˆë ¨ ë£¨í”„ë¥¼ ì²˜ë¦¬í•˜ë©° í•œ ì¤„ì˜ ì½”ë“œë¡œ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§ì ‘ í›ˆë ¨ ë£¨í”„ë¥¼ ì‘ì„±í•˜ëŠ” ê²ƒì„ ì„ í˜¸í•˜ëŠ” ì‚¬ìš©ìì˜ ê²½ìš°, ê¸°ë³¸ PyTorchì—ì„œ ğŸ¤— Transformers ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n@@ -305,8 +299,6 @@ torch.cuda.empty_cache()\n \n >>> metric.compute()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        },
        {
            "sha": "3eec2233540d676bcb0cce8a3ee51c62f99af219",
            "filename": "docs/source/pt/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -111,8 +111,6 @@ VocÃª pode tambÃ©m salvar seu arquivo de configuraÃ§Ãµes como um dicionÃ¡rio ou\n \n O prÃ³ximo passo Ã© criar um [model](main_classes/models). O modelo - tambÃ©m vagamente referido como arquitetura - define o que cada camada estÃ¡ fazendo e quais operaÃ§Ãµes estÃ£o acontecendo. Atributos como `num_hidden_layers` das configuraÃ§Ãµes sÃ£o utilizados para definir a arquitetura. Todo modelo compartilha a classe base [`PreTrainedModel`] e alguns mÃ©todos em comum como redimensionar o tamanho dos embeddings de entrada e podar as 'self-attention heads'. AlÃ©m disso, todos os modelos tambÃ©m sÃ£o subclasses de [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) ou [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html). Isso significa que os modelos sÃ£o compatÃ­veis com cada respectivo uso de framework.\n \n-<frameworkcontent>\n-<pt>\n Carregar seus atributos de configuraÃ§Ã£o customizados em um modelo:\n \n ```py\n@@ -135,15 +133,11 @@ Quando vocÃª carregar os pesos prÃ©-treinados, a configuraÃ§Ã£o padrÃ£o do model\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ### Heads do modelo\n \n Neste ponto, vocÃª tem um modelo bÃ¡sico do DistilBERT que gera os *estados ocultos*. Os estados ocultos sÃ£o passados como entrada para a head do moelo para produzir a saÃ­da final. ğŸ¤— Transformers fornece uma head de modelo diferente para cada tarefa desde que o modelo suporte essa tarefa (por exemplo, vocÃª nÃ£o consegue utilizar o modelo DistilBERT para uma tarefa de 'sequence-to-sequence' como traduÃ§Ã£o).\n \n-<frameworkcontent>\n-<pt>\n Por exemplo, [`DistilBertForSequenceClassification`] Ã© um modelo DistilBERT base com uma head de classificaÃ§Ã£o de sequÃªncia. A head de calssificaÃ§Ã£o de sequÃªncia Ã© uma camada linear no topo das saÃ­das agrupadas.\n \n ```py\n@@ -159,8 +153,6 @@ Reutilize facilmente esse ponto de parada para outra tarefe mudando para uma hea\n \n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Tokenizer\n "
        },
        {
            "sha": "541d723fd8099c0e85a4325624c408ca46a05e1f",
            "filename": "docs/source/pt/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 24,
            "changes": 24,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -66,13 +66,9 @@ No exemplo a seguir, vocÃª usarÃ¡ [`pipeline`] para anÃ¡lise sentimental.\n Instale as seguintes dependÃªncias se vocÃª ainda nÃ£o o fez:\n \n \n-<frameworkcontent>\n-<pt>\n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n Importe [`pipeline`] e especifique a tarefa que deseja completar:\n \n@@ -147,8 +143,6 @@ A [`pipeline`] pode acomodar qualquer modelo do [Model Hub](https://huggingface.\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n Use o [`AutoModelForSequenceClassification`] e [`AutoTokenizer`] para carregar o modelo prÃ©-treinado e seu tokenizer associado (mais em `AutoClass` abaixo):\n \n ```py\n@@ -157,8 +151,6 @@ Use o [`AutoModelForSequenceClassification`] e [`AutoTokenizer`] para carregar o\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n EntÃ£o vocÃª pode especificar o modelo e o tokenizador na [`pipeline`] e aplicar o `classifier` no seu texto alvo:\n \n@@ -210,8 +202,6 @@ O tokenizer retornarÃ¡ um dicionÃ¡rio contendo:\n \n Assim como o [`pipeline`], o tokenizer aceitarÃ¡ uma lista de entradas. AlÃ©m disso, o tokenizer tambÃ©m pode preencher e truncar o texto para retornar um lote com comprimento uniforme:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -222,15 +212,11 @@ Assim como o [`pipeline`], o tokenizer aceitarÃ¡ uma lista de entradas. AlÃ©m di\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n Leia o tutorial de [prÃ©-processamento](./prÃ©-processamento) para obter mais detalhes sobre tokenizaÃ§Ã£o.\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers fornecem uma maneira simples e unificada de carregar instÃ¢ncias prÃ©-treinadas. Isso significa que vocÃª pode carregar um [`AutoModel`] como carregaria um [`AutoTokenizer`]. A Ãºnica diferenÃ§a Ã© selecionar o [`AutoModel`] correto para a tarefa. Como vocÃª estÃ¡ fazendo classificaÃ§Ã£o de texto ou sequÃªncia, carregue [`AutoModelForSequenceClassification`]:\n \n ```py\n@@ -262,8 +248,6 @@ O modelo gera as ativaÃ§Ãµes finais no atributo `logits`. Aplique a funÃ§Ã£o sof\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -283,8 +267,6 @@ As saÃ­das do modelo tambÃ©m se comportam como uma tupla ou um dicionÃ¡rio (por\n \n ### Salvar um modelo\n \n-<frameworkcontent>\n-<pt>\n Uma vez que seu modelo estiver afinado, vocÃª pode salvÃ¡-lo com seu Tokenizer usando [`PreTrainedModel.save_pretrained`]:\n \n ```py\n@@ -298,19 +280,13 @@ Quando vocÃª estiver pronto para usÃ¡-lo novamente, recarregue com [`PreTrainedM\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n Um recurso particularmente interessante dos ğŸ¤— Transformers Ã© a capacidade de salvar um modelo e recarregÃ¡-lo como um modelo PyTorch ou TensorFlow. Use `from_pt` ou `from_tf` para converter o modelo de um framework para outro:\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "4b4baf18988fee195be7f20166ccb5cc9b79b1f2",
            "filename": "docs/source/pt/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ pip install -r requirements.txt\n \n ## Executando um script\n \n-<frameworkcontent>\n-<pt>\n \n O script de exemplo baixa e prÃ©-processa um conjunto de dados da biblioteca ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/). Em seguida, o script ajusta um conjunto de dados com o [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) em uma arquitetura que oferece suporte Ã  sumarizaÃ§Ã£o. O exemplo a seguir mostra como ajustar [T5-small](https://huggingface.co/google-t5/t5-small) no conjunto de dados [CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail). O modelo T5 requer um argumento `source_prefix` adicional devido Ã  forma como foi treinado. Este prompt informa ao T5 que esta Ã© uma tarefa de sumarizaÃ§Ã£o.\n \n@@ -104,8 +102,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Treinamento distribuÃ­do e precisÃ£o mista\n \n@@ -135,8 +131,6 @@ Os scripts do TensorFlow utilizam um [`MirroredStrategy`](https://www.tensorflow\n \n ## Executando um script em uma TPU\n \n-<frameworkcontent>\n-<pt>\n As Unidades de Processamento de Tensor (TPUs) sÃ£o projetadas especificamente para acelerar o desempenho. O PyTorch oferece suporte a TPUs com o compilador de aprendizado profundo [XLA](https://www.tensorflow.org/xla) (consulte [aqui](https://github.com/pytorch/xla/blob/master/README.md) para mais detalhes). Para usar uma TPU, inicie o script `xla_spawn.py` e use o argumento `num_cores` para definir o nÃºmero de nÃºcleos de TPU que vocÃª deseja usar.\n \n ```bash\n@@ -154,8 +148,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Execute um script com ğŸ¤— Accelerate\n "
        },
        {
            "sha": "70db6310e50a3be998934d9ccb9bd9d5a5212b1d",
            "filename": "docs/source/pt/tasks/sequence_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Ftasks%2Fsequence_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Ftasks%2Fsequence_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Ftasks%2Fsequence_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -78,20 +78,14 @@ tokenized_imdb = imdb.map(preprocess_function, batched=True)\n \n Use o [`DataCollatorWithPadding`] para criar um batch de exemplos. Ele tambÃ©m *preencherÃ¡ dinamicamente* seu texto atÃ© o comprimento do elemento mais longo em seu batch, para que os exemplos do batch tenham um comprimento uniforme. Embora seja possÃ­vel preencher seu texto com a funÃ§Ã£o `tokenizer` definindo `padding=True`, o preenchimento dinÃ¢mico utilizando um data collator Ã© mais eficiente.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorWithPadding\n \n >>> data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Train\n \n-<frameworkcontent>\n-<pt>\n Carregue o DistilBERT com [`AutoModelForSequenceClassification`] junto com o nÃºmero de rÃ³tulos esperados:\n \n ```py\n@@ -139,8 +133,6 @@ Nesse ponto, restam apenas trÃªs passos:\n O [`Trainer`] aplicarÃ¡ o preenchimento dinÃ¢mico por padrÃ£o quando vocÃª definir o argumento `tokenizer` dele. Nesse caso, vocÃª nÃ£o precisa especificar um data collator explicitamente.\n \n </Tip>\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "3c0ac5671589f09bf0877984c77bef0902a8dfdf",
            "filename": "docs/source/pt/tasks/token_classification.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Ftasks%2Ftoken_classification.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fpt%2Ftasks%2Ftoken_classification.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fpt%2Ftasks%2Ftoken_classification.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -136,20 +136,14 @@ Use a funÃ§Ã£o [`map`](https://huggingface.co/docs/datasets/process#map) do ğŸ¤—\n \n Use o [`DataCollatorForTokenClassification`] para criar um batch de exemplos. Ele tambÃ©m *preencherÃ¡ dinamicamente* seu texto e rÃ³tulos para o comprimento do elemento mais longo em seu batch, para que tenham um comprimento uniforme. Embora seja possÃ­vel preencher seu texto na funÃ§Ã£o `tokenizer` configurando `padding=True`, o preenchimento dinÃ¢mico Ã© mais eficiente.\n \n-<frameworkcontent>\n-<pt>\n ```py\n >>> from transformers import DataCollatorForTokenClassification\n \n >>> data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Treinamento\n \n-<frameworkcontent>\n-<pt>\n Carregue o DistilBERT com o [`AutoModelForTokenClassification`] junto com o nÃºmero de rÃ³tulos esperados:\n \n ```py\n@@ -192,8 +186,6 @@ Nesse ponto, restam apenas trÃªs passos:\n \n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n "
        },
        {
            "sha": "a65409b2d1c5b87f3cf589beccaf8fdeb44f804d",
            "filename": "docs/source/zh/autoclass_tutorial.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fautoclass_tutorial.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fautoclass_tutorial.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fautoclass_tutorial.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -96,8 +96,6 @@ rendered properly in your Markdown viewer.\n \n ## AutoModel\n \n-<frameworkcontent>\n-<pt>\n \n æœ€åï¼Œ`AutoModelFor`ç±»è®©ä½ å¯ä»¥åŠ è½½ç»™å®šä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå‚è§[è¿™é‡Œ](model_doc/auto)è·å–å¯ç”¨ä»»åŠ¡çš„å®Œæ•´åˆ—è¡¨ï¼‰ã€‚ä¾‹å¦‚ï¼Œä½¿ç”¨[`AutoModelForSequenceClassification.from_pretrained`]åŠ è½½ç”¨äºåºåˆ—åˆ†ç±»çš„æ¨¡å‹ï¼š\n \n@@ -126,5 +124,3 @@ TensorFlowå’ŒFlaxçš„checkpointsä¸å—å½±å“ï¼Œå¹¶ä¸”å¯ä»¥åœ¨PyTorchæ¶æ„ä¸­ä½¿\n \n ä¸€èˆ¬æ¥è¯´ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨`AutoTokenizer`ç±»å’Œ`AutoModelFor`ç±»æ¥åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹å®ä¾‹ã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æ¯æ¬¡åŠ è½½æ­£ç¡®çš„æ¶æ„ã€‚åœ¨ä¸‹ä¸€ä¸ª[æ•™ç¨‹](preprocessing)ä¸­ï¼Œå­¦ä¹ å¦‚ä½•ä½¿ç”¨æ–°åŠ è½½çš„`tokenizer`, `image processor`, `feature extractor`å’Œ`processor`å¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç†ä»¥è¿›è¡Œå¾®è°ƒã€‚\n \n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "c36eaef540a1aca86ec771434dc3de936633f2fa",
            "filename": "docs/source/zh/create_a_model.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fcreate_a_model.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fcreate_a_model.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fcreate_a_model.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -112,8 +112,6 @@ DistilBertConfig {\n \n æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ª[æ¨¡å‹](main_classes/models)ã€‚æ¨¡å‹ï¼Œä¹Ÿå¯æ³›æŒ‡æ¶æ„ï¼Œå®šä¹‰äº†æ¯ä¸€å±‚ç½‘ç»œçš„è¡Œä¸ºä»¥åŠè¿›è¡Œçš„æ“ä½œã€‚é…ç½®ä¸­çš„ `num_hidden_layers` ç­‰å±æ€§ç”¨äºå®šä¹‰æ¶æ„ã€‚æ¯ä¸ªæ¨¡å‹éƒ½å…±äº«åŸºç±» [`PreTrainedModel`] å’Œä¸€äº›å¸¸ç”¨æ–¹æ³•ï¼Œä¾‹å¦‚è°ƒæ•´è¾“å…¥åµŒå…¥çš„å¤§å°å’Œä¿®å‰ªè‡ªæ³¨æ„åŠ›å¤´ã€‚æ­¤å¤–ï¼Œæ‰€æœ‰æ¨¡å‹éƒ½æ˜¯ [`torch.nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)ã€[`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model) æˆ– [`flax.linen.Module`](https://flax.readthedocs.io/en/latest/api_reference/flax.linen/module.html) çš„å­ç±»ã€‚è¿™æ„å‘³ç€æ¨¡å‹ä¸å„è‡ªæ¡†æ¶çš„ç”¨æ³•å…¼å®¹ã€‚\n \n-<frameworkcontent>\n-<pt>\n å°†è‡ªå®šä¹‰é…ç½®å±æ€§åŠ è½½åˆ°æ¨¡å‹ä¸­ï¼š\n \n ```py\n@@ -136,15 +134,11 @@ DistilBertConfig {\n ```py\n >>> model = DistilBertModel.from_pretrained(\"distilbert/distilbert-base-uncased\", config=my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n ### æ¨¡å‹å¤´ï¼ˆModel headsï¼‰\n \n æ­¤æ—¶ï¼Œä½ å·²ç»æœ‰äº†ä¸€ä¸ªè¾“å‡º*éšè—çŠ¶æ€*çš„åŸºç¡€ DistilBERT æ¨¡å‹ã€‚éšè—çŠ¶æ€ä½œä¸ºè¾“å…¥ä¼ é€’åˆ°æ¨¡å‹å¤´ä»¥ç”Ÿæˆæœ€ç»ˆè¾“å‡ºã€‚ğŸ¤— Transformers ä¸ºæ¯ä¸ªä»»åŠ¡æä¾›ä¸åŒçš„æ¨¡å‹å¤´ï¼Œåªè¦æ¨¡å‹æ”¯æŒè¯¥ä»»åŠ¡ï¼ˆå³ï¼Œæ‚¨ä¸èƒ½ä½¿ç”¨ DistilBERT æ¥æ‰§è¡Œåƒç¿»è¯‘è¿™æ ·çš„åºåˆ—åˆ°åºåˆ—ä»»åŠ¡ï¼‰ã€‚\n \n-<frameworkcontent>\n-<pt>\n ä¾‹å¦‚ï¼Œ[`DistilBertForSequenceClassification`] æ˜¯ä¸€ä¸ªå¸¦æœ‰åºåˆ—åˆ†ç±»å¤´ï¼ˆsequence classification headï¼‰çš„åŸºç¡€ DistilBERT æ¨¡å‹ã€‚åºåˆ—åˆ†ç±»å¤´æ˜¯æ± åŒ–è¾“å‡ºä¹‹ä¸Šçš„çº¿æ€§å±‚ã€‚\n \n ```py\n@@ -160,8 +154,6 @@ DistilBertConfig {\n \n >>> model = DistilBertForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## åˆ†è¯å™¨\n "
        },
        {
            "sha": "07d99c93c9207a251789b0a2a2b525193c00b901",
            "filename": "docs/source/zh/model_sharing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fmodel_sharing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fmodel_sharing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fmodel_sharing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -79,22 +79,16 @@ pip install huggingface_hub\n \n ä¸ºå¦ä¸€ä¸ªæ¡†æ¶è½¬æ¢`checkpoints`å¾ˆå®¹æ˜“ã€‚ç¡®ä¿æ‚¨å·²å®‰è£…PyTorchå’ŒTensorFlowï¼ˆè¯·å‚é˜…[æ­¤å¤„](installation)çš„å®‰è£…è¯´æ˜ï¼‰ï¼Œç„¶ååœ¨å…¶ä»–æ¡†æ¶ä¸­æ‰¾åˆ°é€‚åˆæ‚¨ä»»åŠ¡çš„ç‰¹å®šæ¨¡å‹ã€‚\n \n-<frameworkcontent>\n-<pt>\n \n æŒ‡å®š`from_tf=True`å°†checkpointä»TensorFlowè½¬æ¢ä¸ºPyTorchã€‚\n \n ```py\n >>> pt_model = DistilBertForSequenceClassification.from_pretrained(\"path/to/awesome-name-you-picked\", from_tf=True)\n >>> pt_model.save_pretrained(\"path/to/awesome-name-you-picked\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ## åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¨é€æ¨¡å‹\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Z1-XMy-GNLQ\"/>\n \n å°†æ¨¡å‹åˆ†äº«åˆ°Hubå°±åƒæ·»åŠ ä¸€ä¸ªé¢å¤–çš„å‚æ•°æˆ–å›è°ƒå‡½æ•°ä¸€æ ·ç®€å•ã€‚è¯·è®°ä½ï¼Œåœ¨[å¾®è°ƒæ•™ç¨‹](training)ä¸­ï¼Œ`TrainingArguments`ç±»æ˜¯æ‚¨æŒ‡å®šè¶…å‚æ•°å’Œé™„åŠ è®­ç»ƒé€‰é¡¹çš„åœ°æ–¹ã€‚å…¶ä¸­ä¸€é¡¹è®­ç»ƒé€‰é¡¹åŒ…æ‹¬ç›´æ¥å°†æ¨¡å‹æ¨é€åˆ°Hubçš„èƒ½åŠ›ã€‚åœ¨æ‚¨çš„`TrainingArguments`ä¸­è®¾ç½®`push_to_hub=True`ï¼š\n@@ -121,8 +115,6 @@ pip install huggingface_hub\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n ## ä½¿ç”¨`push_to_hub`åŠŸèƒ½\n "
        },
        {
            "sha": "252f41f214ea5645d5ec86b49419c76d7e924d0c",
            "filename": "docs/source/zh/preprocessing.md",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fpreprocessing.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fpreprocessing.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fpreprocessing.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -173,8 +173,6 @@ pip install datasets\n \n å°† `return_tensors` å‚æ•°è®¾ç½®ä¸º `pt`ï¼ˆå¯¹äºPyTorchï¼‰æˆ– `tf`ï¼ˆå¯¹äºTensorFlowï¼‰ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n \n ```py\n@@ -195,8 +193,6 @@ pip install datasets\n                            [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n                            [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n ```\n-</pt>\n-</frameworkcontent>\n \n ## éŸ³é¢‘\n "
        },
        {
            "sha": "c4aa032df8d158ed42ffefd36f9083c9d85d2339",
            "filename": "docs/source/zh/quicktour.md",
            "status": "modified",
            "additions": 0,
            "deletions": 28,
            "changes": 28,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fquicktour.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Fquicktour.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Fquicktour.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -28,14 +28,10 @@ rendered properly in your Markdown viewer.\n \n ä½ è¿˜éœ€è¦å®‰è£…å–œæ¬¢çš„æœºå™¨å­¦ä¹ æ¡†æ¶ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n ```bash\n pip install torch\n ```\n-</pt>\n-</frameworkcontent>\n \n ## Pipeline\n \n@@ -126,8 +122,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n ```\n \n-<frameworkcontent>\n-<pt>\n ä½¿ç”¨ [`AutoModelForSequenceClassification`] å’Œ [`AutoTokenizer`] æ¥åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œå®ƒå…³è”çš„åˆ†è¯å™¨ï¼ˆæ›´å¤šä¿¡æ¯å¯ä»¥å‚è€ƒä¸‹ä¸€èŠ‚çš„ `AutoClass`ï¼‰ï¼š\n \n ```py\n@@ -136,8 +130,6 @@ label: NEGATIVE, with score: 0.5309\n >>> model = AutoModelForSequenceClassification.from_pretrained(model_name)\n >>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n ```\n-</pt>\n-</frameworkcontent>\n \n åœ¨ [`pipeline`] ä¸­æŒ‡å®šæ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œç°åœ¨ä½ å°±å¯ä»¥åœ¨æ³•è¯­æ–‡æœ¬ä¸Šä½¿ç”¨ `classifier` äº†ï¼š\n \n@@ -187,8 +179,6 @@ label: NEGATIVE, with score: 0.5309\n \n åˆ†è¯å™¨ä¹Ÿå¯ä»¥æ¥å—åˆ—è¡¨ä½œä¸ºè¾“å…¥ï¼Œå¹¶å¡«å……å’Œæˆªæ–­æ–‡æœ¬ï¼Œè¿”å›å…·æœ‰ç»Ÿä¸€é•¿åº¦çš„æ‰¹æ¬¡ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> pt_batch = tokenizer(\n@@ -199,8 +189,6 @@ label: NEGATIVE, with score: 0.5309\n ...     return_tensors=\"pt\",\n ... )\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -210,8 +198,6 @@ label: NEGATIVE, with score: 0.5309\n \n ### AutoModel\n \n-<frameworkcontent>\n-<pt>\n ğŸ¤— Transformers æä¾›äº†ä¸€ç§ç®€å•ç»Ÿä¸€çš„æ–¹å¼æ¥åŠ è½½é¢„è®­ç»ƒçš„å®ä¾‹. è¿™è¡¨ç¤ºä½ å¯ä»¥åƒåŠ è½½ [`AutoTokenizer`] ä¸€æ ·åŠ è½½ [`AutoModel`]ã€‚å”¯ä¸€ä¸åŒçš„åœ°æ–¹æ˜¯ä¸ºä½ çš„ä»»åŠ¡é€‰æ‹©æ­£ç¡®çš„[`AutoModel`]ã€‚å¯¹äºæ–‡æœ¬ï¼ˆæˆ–åºåˆ—ï¼‰åˆ†ç±»ï¼Œä½ åº”è¯¥åŠ è½½[`AutoModelForSequenceClassification`]ï¼š\n \n ```py\n@@ -243,8 +229,6 @@ label: NEGATIVE, with score: 0.5309\n tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -255,8 +239,6 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n \n ### ä¿å­˜æ¨¡å‹\n \n-<frameworkcontent>\n-<pt>\n å½“ä½ çš„æ¨¡å‹å¾®è°ƒå®Œæˆï¼Œä½ å°±å¯ä»¥ä½¿ç”¨ [`PreTrainedModel.save_pretrained`] æŠŠå®ƒå’Œå®ƒçš„åˆ†è¯å™¨ä¿å­˜ä¸‹æ¥ï¼š\n \n ```py\n@@ -270,22 +252,16 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n ```py\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(\"./pt_save_pretrained\")\n ```\n-</pt>\n-</frameworkcontent>\n \n ğŸ¤— Transformers æœ‰ä¸€ä¸ªç‰¹åˆ«é…·çš„åŠŸèƒ½ï¼Œå®ƒèƒ½å¤Ÿä¿å­˜ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶ä¸”å°†å®ƒåŠ è½½ä¸º PyTorch æˆ– TensorFlow æ¨¡å‹ã€‚`from_pt` æˆ– `from_tf` å‚æ•°å¯ä»¥å°†æ¨¡å‹ä»ä¸€ä¸ªæ¡†æ¶è½¬æ¢ä¸ºå¦ä¸€ä¸ªæ¡†æ¶ï¼š\n \n-<frameworkcontent>\n-<pt>\n \n ```py\n >>> from transformers import AutoModel\n \n >>> tokenizer = AutoTokenizer.from_pretrained(pt_save_directory)\n >>> pt_model = AutoModelForSequenceClassification.from_pretrained(pt_save_directory, from_pt=True)\n ```\n-</pt>\n-</frameworkcontent>\n \n ## è‡ªå®šä¹‰æ¨¡å‹æ„å»º\n \n@@ -299,17 +275,13 @@ tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n >>> my_config = AutoConfig.from_pretrained(\"distilbert/distilbert-base-uncased\", n_heads=12)\n ```\n \n-<frameworkcontent>\n-<pt>\n ä½¿ç”¨ [`AutoModel.from_config`] æ ¹æ®ä½ çš„è‡ªå®šä¹‰é…ç½®åˆ›å»ºä¸€ä¸ªæ¨¡å‹ï¼š\n \n ```py\n >>> from transformers import AutoModel\n \n >>> my_model = AutoModel.from_config(my_config)\n ```\n-</pt>\n-</frameworkcontent>\n \n æŸ¥é˜… [åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰ç»“æ„](./create_a_model) æŒ‡å—è·å–æ›´å¤šå…³äºæ„å»ºè‡ªå®šä¹‰é…ç½®çš„ä¿¡æ¯ã€‚\n "
        },
        {
            "sha": "78b1629657f31ebaa2f481bb6ef1a43fbc90e564",
            "filename": "docs/source/zh/run_scripts.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Frun_scripts.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -85,8 +85,6 @@ pip install -r requirements.txt\n \n ## è¿è¡Œè„šæœ¬\n \n-<frameworkcontent>\n-<pt>\n \n ç¤ºä¾‹è„šæœ¬ä»ğŸ¤— [Datasets](https://huggingface.co/docs/datasets/)åº“ä¸‹è½½å¹¶é¢„å¤„ç†æ•°æ®é›†ã€‚ç„¶åï¼Œè„šæœ¬é€šè¿‡[Trainer](https://huggingface.co/docs/transformers/main_classes/trainer)ä½¿ç”¨æ”¯æŒæ‘˜è¦ä»»åŠ¡çš„æ¶æ„å¯¹æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚ä»¥ä¸‹ç¤ºä¾‹å±•ç¤ºäº†å¦‚ä½•åœ¨[CNN/DailyMail](https://huggingface.co/datasets/cnn_dailymail)æ•°æ®é›†ä¸Šå¾®è°ƒ[T5-small](https://huggingface.co/google-t5/t5-small)ã€‚ç”±äºT5æ¨¡å‹çš„è®­ç»ƒæ–¹å¼ï¼Œå®ƒéœ€è¦ä¸€ä¸ªé¢å¤–çš„`source_prefix`å‚æ•°ã€‚è¿™ä¸ªæç¤ºè®©T5çŸ¥é“è¿™æ˜¯ä¸€ä¸ªæ‘˜è¦ä»»åŠ¡ã€‚\n \n@@ -104,8 +102,6 @@ python examples/pytorch/summarization/run_summarization.py \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## åˆ†å¸ƒå¼è®­ç»ƒå’Œæ··åˆç²¾åº¦\n \n@@ -136,8 +132,6 @@ TensorFlowè„šæœ¬ä½¿ç”¨[`MirroredStrategy`](https://www.tensorflow.org/guide/dist\n \n ## åœ¨TPUä¸Šè¿è¡Œè„šæœ¬\n \n-<frameworkcontent>\n-<pt>\n \n å¼ é‡å¤„ç†å•å…ƒï¼ˆTPUsï¼‰æ˜¯ä¸“é—¨è®¾è®¡ç”¨äºåŠ é€Ÿæ€§èƒ½çš„ã€‚PyTorchä½¿ç”¨[XLA](https://www.tensorflow.org/xla)æ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨æ”¯æŒTPUï¼ˆæ›´å¤šç»†èŠ‚è¯·å‚è§[è¿™é‡Œ](https://github.com/pytorch/xla/blob/master/README.md)ï¼‰ã€‚è¦ä½¿ç”¨TPUï¼Œè¯·å¯åŠ¨`xla_spawn.py`è„šæœ¬å¹¶ä½¿ç”¨`num_cores`å‚æ•°è®¾ç½®è¦ä½¿ç”¨çš„TPUæ ¸å¿ƒæ•°é‡ã€‚\n \n@@ -156,8 +150,6 @@ python xla_spawn.py --num_cores 8 \\\n     --overwrite_output_dir \\\n     --predict_with_generate\n ```\n-</pt>\n-</frameworkcontent>\n \n ## åŸºäºğŸ¤— Accelerateè¿è¡Œè„šæœ¬\n "
        },
        {
            "sha": "3798640026d5a069f81d8fac6663d12d0e0d289a",
            "filename": "docs/source/zh/tasks/asr.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Ftasks%2Fasr.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Ftasks%2Fasr.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Ftasks%2Fasr.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -242,8 +242,6 @@ Wav2Vec2 åˆ†è¯å™¨ä»…è®­ç»ƒäº†å¤§å†™å­—ç¬¦ï¼Œå› æ­¤æ‚¨éœ€è¦ç¡®ä¿æ–‡æœ¬ä¸åˆ†\n \n ## è®­ç»ƒ\n \n-<frameworkcontent>\n-<pt>\n <Tip>\n \n å¦‚æœæ‚¨ä¸ç†Ÿæ‚‰ä½¿ç”¨[`Trainer`]å¾®è°ƒæ¨¡å‹ï¼Œè¯·æŸ¥çœ‹è¿™é‡Œçš„åŸºæœ¬æ•™ç¨‹[here](../training#train-with-pytorch-trainer)ï¼\n@@ -311,8 +309,6 @@ Wav2Vec2 åˆ†è¯å™¨ä»…è®­ç»ƒäº†å¤§å†™å­—ç¬¦ï¼Œå› æ­¤æ‚¨éœ€è¦ç¡®ä¿æ–‡æœ¬ä¸åˆ†\n ```py\n >>> trainer.push_to_hub()\n ```\n-</pt>\n-</frameworkcontent>\n \n <Tip>\n \n@@ -356,8 +352,6 @@ Wav2Vec2 åˆ†è¯å™¨ä»…è®­ç»ƒäº†å¤§å†™å­—ç¬¦ï¼Œå› æ­¤æ‚¨éœ€è¦ç¡®ä¿æ–‡æœ¬ä¸åˆ†\n \n å¦‚æœæ‚¨æ„¿æ„ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¤åˆ¶ `pipeline` çš„ç»“æœï¼š\n \n-<frameworkcontent>\n-<pt>\n \n åŠ è½½ä¸€ä¸ªå¤„ç†å™¨æ¥é¢„å¤„ç†éŸ³é¢‘æ–‡ä»¶å’Œè½¬å½•ï¼Œå¹¶å°† `input` è¿”å›ä¸º PyTorch å¼ é‡ï¼š\n \n@@ -388,5 +382,3 @@ Wav2Vec2 åˆ†è¯å™¨ä»…è®­ç»ƒäº†å¤§å†™å­—ç¬¦ï¼Œå› æ­¤æ‚¨éœ€è¦ç¡®ä¿æ–‡æœ¬ä¸åˆ†\n >>> transcription\n ['I WOUL LIKE O SET UP JOINT ACOUNT WTH Y PARTNER']\n ```\n-</pt>\n-</frameworkcontent>"
        },
        {
            "sha": "43243ab4cfbffae326d7e06fe128b1cb0f99a7b6",
            "filename": "docs/source/zh/training.md",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Ftraining.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/f15258dec24385bd9982ed9721797a33195343df/docs%2Fsource%2Fzh%2Ftraining.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fzh%2Ftraining.md?ref=f15258dec24385bd9982ed9721797a33195343df",
            "patch": "@@ -71,8 +71,6 @@ rendered properly in your Markdown viewer.\n æ­¤æ—¶ï¼Œæ‚¨åº”è¯¥æ ¹æ®æ‚¨è®­ç»ƒæ‰€ç”¨çš„æ¡†æ¶æ¥é€‰æ‹©å¯¹åº”çš„æ•™ç¨‹ç« èŠ‚ã€‚æ‚¨å¯ä»¥ä½¿ç”¨å³ä¾§çš„é“¾æ¥è·³è½¬åˆ°æ‚¨æƒ³è¦çš„ç« èŠ‚ - å¦‚æœæ‚¨æƒ³éšè—æŸä¸ªæ¡†æ¶å¯¹åº”çš„æ‰€æœ‰æ•™ç¨‹å†…å®¹ï¼Œåªéœ€ä½¿ç”¨å³ä¸Šè§’çš„æŒ‰é’®ï¼\n \n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"nvBXf7s7vTI\"/>\n \n ## ä½¿ç”¨ PyTorch Trainer è¿›è¡Œè®­ç»ƒ\n@@ -152,15 +150,11 @@ rendered properly in your Markdown viewer.\n ```py\n >>> trainer.train()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='pytorch_native'></a>\n \n ## åœ¨åŸç”Ÿ PyTorch ä¸­è®­ç»ƒ\n \n-<frameworkcontent>\n-<pt>\n <Youtube id=\"Dh9CL8fyG80\"/>\n \n [`Trainer`] è´Ÿè´£è®­ç»ƒå¾ªç¯ï¼Œå…è®¸æ‚¨åœ¨ä¸€è¡Œä»£ç ä¸­å¾®è°ƒæ¨¡å‹ã€‚å¯¹äºå–œæ¬¢ç¼–å†™è‡ªå·±è®­ç»ƒå¾ªç¯çš„ç”¨æˆ·ï¼Œæ‚¨ä¹Ÿå¯ä»¥åœ¨åŸç”Ÿ PyTorch ä¸­å¾®è°ƒ ğŸ¤— Transformers æ¨¡å‹ã€‚\n@@ -303,8 +297,6 @@ torch.cuda.empty_cache()\n \n >>> metric.compute()\n ```\n-</pt>\n-</frameworkcontent>\n \n <a id='additional-resources'></a>\n "
        }
    ],
    "stats": {
        "total": 1115,
        "additions": 0,
        "deletions": 1115
    }
}