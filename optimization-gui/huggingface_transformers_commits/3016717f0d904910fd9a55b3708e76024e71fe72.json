{
    "author": "cyyever",
    "message": "Use removeprefix and removesuffix (#41240)\n\n* Use removeprefix and removesuffix\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n* More fixes\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>\n\n---------\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "3016717f0d904910fd9a55b3708e76024e71fe72",
    "files": [
        {
            "sha": "bc421f7d84d30ea1450ba5a62f8f8182462d0168",
            "filename": "src/transformers/commands/chat.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fcommands%2Fchat.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fcommands%2Fchat.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fchat.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -443,8 +443,7 @@ def parse_generate_flags(self, generate_flags: list[str]) -> dict:\n         # 2. b. strings should be quoted\n         def is_number(s: str) -> bool:\n             # handle negative numbers\n-            if s.startswith(\"-\"):\n-                s = s[1:]\n+            s = s.removeprefix(\"-\")\n             return s.replace(\".\", \"\", 1).isdigit()\n \n         generate_flags_as_dict = {k: f'\"{v}\"' if not is_number(v) else v for k, v in generate_flags_as_dict.items()}"
        },
        {
            "sha": "970d59c96e74a60ec478dde26501b2fa8bb3cb35",
            "filename": "src/transformers/commands/serving.py",
            "status": "modified",
            "additions": 2,
            "deletions": 4,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fcommands%2Fserving.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fcommands%2Fserving.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fcommands%2Fserving.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -1066,8 +1066,7 @@ def generate_with_cache(**kwargs):\n                 for result in streamer:\n                     # Temporary hack for GPTOS 3: don't emit the final \"<|return|>\"\n                     if \"gptoss\" in model.config.architectures[0].lower():\n-                        if result.endswith(\"<|return|>\"):\n-                            result = result[: -len(\"<|return|>\")]\n+                        result = result.removesuffix(\"<|return|>\")\n                     results += result\n \n                     # (related to temporary hack 2)\n@@ -1325,8 +1324,7 @@ def generate_with_cache(**kwargs):\n                 for result in streamer:\n                     # Temporary hack for GPTOS 3: don't emit the final \"<|return|>\"\n                     if \"gptoss\" in model.config.architectures[0].lower():\n-                        if result.endswith(\"<|return|>\"):\n-                            result = result[: -len(\"<|return|>\")]\n+                        result = result.removesuffix(\"<|return|>\")\n                     results += result\n \n                     # (related to temporary hack 2)"
        },
        {
            "sha": "6e31557c39a5ded46a0b294299aa5bd4f1cc8a20",
            "filename": "src/transformers/dynamic_module_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fdynamic_module_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fdynamic_module_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdynamic_module_utils.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -285,8 +285,7 @@ def get_class_in_module(\n         `typing.Type`: The class looked for.\n     \"\"\"\n     name = os.path.normpath(module_path)\n-    if name.endswith(\".py\"):\n-        name = name[:-3]\n+    name = name.removesuffix(\".py\")\n     name = name.replace(os.path.sep, \".\")\n     module_file: Path = Path(HF_MODULES_CACHE) / module_path\n     with _HF_REMOTE_CODE_LOCK:"
        },
        {
            "sha": "cbd148153ca53fe9a4044b4257736f00f526a336",
            "filename": "src/transformers/modelcard.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodelcard.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodelcard.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodelcard.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -667,8 +667,7 @@ def parse_log_history(log_history):\n     if idx > 0:\n         eval_results = {}\n         for key, value in log_history[idx].items():\n-            if key.startswith(\"eval_\"):\n-                key = key[5:]\n+            key = key.removeprefix(\"eval_\")\n             if key not in [\"runtime\", \"samples_per_second\", \"steps_per_second\", \"epoch\", \"step\"]:\n                 camel_cased_key = \" \".join([part.capitalize() for part in key.split(\"_\")])\n                 eval_results[camel_cased_key] = value"
        },
        {
            "sha": "4175b349ea0a4baf5a8a6ac45e3df594c0598f37",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -5397,7 +5397,7 @@ def retrieve_modules_from_names(self, names, add_prefix=False, remove_prefix=Fal\n         for name, module in self.named_modules():\n             if remove_prefix:\n                 _prefix = f\"{self.base_model_prefix}.\"\n-                name = name[len(_prefix) :] if name.startswith(_prefix) else name\n+                name = name.removeprefix(_prefix)\n             elif add_prefix:\n                 name = \".\".join([self.base_model_prefix, name]) if len(name) > 0 else self.base_model_prefix\n \n@@ -5717,7 +5717,7 @@ def _adjust_missing_and_unexpected_keys(\n         # in the warnings. For missing keys, we should show the prefix in the warning as it's part of the final model\n         if loading_task_model_from_base_state_dict:\n             _prefix = f\"{self.base_model_prefix}.\"\n-            unexpected_keys = [k[len(_prefix) :] if k.startswith(_prefix) else k for k in unexpected_keys]\n+            unexpected_keys = [k.removeprefix(_prefix) for k in unexpected_keys]\n \n         return missing_keys, unexpected_keys\n "
        },
        {
            "sha": "4b71712dfc7bbb8c3e98fe87464151a4a579f695",
            "filename": "src/transformers/models/auto/image_processing_auto.py",
            "status": "modified",
            "additions": 1,
            "deletions": 3,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fauto%2Fimage_processing_auto.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -566,9 +566,7 @@ def from_pretrained(cls, pretrained_model_name_or_path, *inputs, **kwargs):\n                     )\n                 image_processor_class = get_image_processor_class_from_name(image_processor_type)\n             else:\n-                image_processor_type_slow = (\n-                    image_processor_type[:-4] if image_processor_type.endswith(\"Fast\") else image_processor_type\n-                )\n+                image_processor_type_slow = image_processor_type.removesuffix(\"Fast\")\n                 image_processor_class = get_image_processor_class_from_name(image_processor_type_slow)\n                 if image_processor_class is None and image_processor_type.endswith(\"Fast\"):\n                     raise ValueError("
        },
        {
            "sha": "2ec838a7da6309773fafb7c0783f666b2a9fc21b",
            "filename": "src/transformers/models/chinese_clip/convert_chinese_clip_original_pytorch_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchinese_clip%2Fconvert_chinese_clip_original_pytorch_to_hf.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -105,7 +105,7 @@ def convert_chinese_clip_checkpoint(checkpoint_path, pytorch_dump_folder_path, c\n     hf_model = ChineseCLIPModel(config).eval()\n \n     pt_weights = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"state_dict\"]\n-    pt_weights = {(name[7:] if name.startswith(\"module.\") else name): value for name, value in pt_weights.items()}\n+    pt_weights = {(name.removeprefix(\"module.\")): value for name, value in pt_weights.items()}\n \n     copy_text_model_and_projection(hf_model, pt_weights)\n     copy_vision_model_and_projection(hf_model, pt_weights)"
        },
        {
            "sha": "bfde37f2c868547cb7829685dd933fa8534c75c2",
            "filename": "src/transformers/models/longt5/modeling_longt5.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flongt5%2Fmodeling_longt5.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -1243,8 +1243,7 @@ def dummy_inputs(self):\n \n     def _try_load_missing_tied_module(self, key):\n         module = self\n-        if key.endswith(\".weight\"):\n-            key = key[: -len(\".weight\")]\n+        key = key.removesuffix(\".weight\")\n         for sub_key in key.split(\".\"):\n             if not hasattr(module, sub_key):\n                 return"
        },
        {
            "sha": "49c782e5b3fa50cb8c6887e69c221b3298931322",
            "filename": "src/transformers/models/rag/retrieval_rag.py",
            "status": "modified",
            "additions": 1,
            "deletions": 4,
            "changes": 5,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Frag%2Fretrieval_rag.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -509,10 +509,7 @@ def postprocess_docs(self, docs, input_strings, prefix, n_docs, return_tensors=N\n         def cat_input_and_doc(doc_title, doc_text, input_string, prefix):\n             # TODO(Patrick): if we train more RAG models, I want to put the input first to take advantage of effortless truncation\n             # TODO(piktus): better handling of truncation\n-            if doc_title.startswith('\"'):\n-                doc_title = doc_title[1:]\n-            if doc_title.endswith('\"'):\n-                doc_title = doc_title[:-1]\n+            doc_title = doc_title.removeprefix('\"').removesuffix('\"')\n             if prefix is None:\n                 prefix = \"\"\n             out = (prefix + doc_title + self.config.title_sep + doc_text + self.config.doc_sep + input_string).replace("
        },
        {
            "sha": "15882c6b63ccbce1a971810c6680e4dcf9c03b0c",
            "filename": "src/transformers/utils/auto_docstring.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fauto_docstring.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -1185,8 +1185,7 @@ def get_checkpoint_from_config_class(config_class):\n     # For example, `('google-bert/bert-base-uncased', 'https://huggingface.co/google-bert/bert-base-uncased')`\n     for ckpt_name, ckpt_link in checkpoints:\n         # allow the link to end with `/`\n-        if ckpt_link.endswith(\"/\"):\n-            ckpt_link = ckpt_link[:-1]\n+        ckpt_link = ckpt_link.removesuffix(\"/\")\n \n         # verify the checkpoint name corresponds to the checkpoint link\n         ckpt_link_from_name = f\"https://huggingface.co/{ckpt_name}\""
        },
        {
            "sha": "d344bf426014e534555682b4699be72b5c5fac3f",
            "filename": "utils/check_config_docstrings.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/utils%2Fcheck_config_docstrings.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/utils%2Fcheck_config_docstrings.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_config_docstrings.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -64,8 +64,7 @@ def get_checkpoint_from_config_class(config_class):\n     # For example, `('google-bert/bert-base-uncased', 'https://huggingface.co/google-bert/bert-base-uncased')`\n     for ckpt_name, ckpt_link in checkpoints:\n         # allow the link to end with `/`\n-        if ckpt_link.endswith(\"/\"):\n-            ckpt_link = ckpt_link[:-1]\n+        ckpt_link = ckpt_link.removesuffix(\"/\")\n \n         # verify the checkpoint name corresponds to the checkpoint link\n         ckpt_link_from_name = f\"https://huggingface.co/{ckpt_name}\""
        },
        {
            "sha": "28b743beab5fd0102129d689f5d3eea681bb8088",
            "filename": "utils/check_copies.py",
            "status": "modified",
            "additions": 1,
            "deletions": 2,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/3016717f0d904910fd9a55b3708e76024e71fe72/utils%2Fcheck_copies.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/3016717f0d904910fd9a55b3708e76024e71fe72/utils%2Fcheck_copies.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/utils%2Fcheck_copies.py?ref=3016717f0d904910fd9a55b3708e76024e71fe72",
            "patch": "@@ -797,8 +797,7 @@ def is_copy_consistent(\n         orig_idx = -1\n         observed_code = \"\"\n         for name, code in observed_code_blocks.items():\n-            if code.endswith(\"\\n\"):\n-                code = code[:-1]\n+            code = code.removesuffix(\"\\n\")\n             for code_line in code.split(\"\\n\"):\n                 orig_idx += 1\n                 if code_line.strip() and not name.startswith((\"_ignored_existing_block_\", \"_ignored_new_block_\")):"
        }
    ],
    "stats": {
        "total": 42,
        "additions": 14,
        "deletions": 28
    }
}