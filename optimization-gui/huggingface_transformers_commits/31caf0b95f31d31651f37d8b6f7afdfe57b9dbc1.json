{
    "author": "ydshieh",
    "message": "Fix missing test in `torch_job` (#33593)\n\nfix missing tests\r\n\r\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "31caf0b95f31d31651f37d8b6f7afdfe57b9dbc1",
    "files": [
        {
            "sha": "e5a83beac868c42cbfedc41b4ba91d2788026f81",
            "filename": "tests/generation/test_utils.py",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/31caf0b95f31d31651f37d8b6f7afdfe57b9dbc1/tests%2Fgeneration%2Ftest_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/31caf0b95f31d31651f37d8b6f7afdfe57b9dbc1/tests%2Fgeneration%2Ftest_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fgeneration%2Ftest_utils.py?ref=31caf0b95f31d31651f37d8b6f7afdfe57b9dbc1",
            "patch": "@@ -89,7 +89,6 @@\n     from transformers.generation.utils import _speculative_sampling\n \n \n-@pytest.mark.generate\n class GenerationTesterMixin:\n     model_tester = None\n     all_generative_model_classes = ()\n@@ -2035,6 +2034,7 @@ def test_generate_compile_fullgraph(self):\n                 output_compiled = compiled_generate(model_inputs, generation_config=generation_config)\n                 self.assertListEqual(output_dynamic.tolist(), output_compiled.tolist())\n \n+    @pytest.mark.generate\n     def test_generate_methods_with_num_logits_to_keep(self):\n         for model_class in self.all_generative_model_classes:\n             if \"num_logits_to_keep\" not in set(inspect.signature(model_class.forward).parameters.keys()):\n@@ -2063,6 +2063,7 @@ def test_generate_methods_with_num_logits_to_keep(self):\n             )\n             self.assertEqual(with_all_logits.tolist(), without_all_logits.tolist())\n \n+    @pytest.mark.generate\n     @is_flaky()  # assisted generation tests are flaky (minor fp ops differences)\n     def test_assisted_decoding_with_num_logits_to_keep(self):\n         for model_class in self.all_generative_model_classes:"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}