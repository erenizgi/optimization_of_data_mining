{
    "author": "gante",
    "message": "[generate] beam search -- fix output cropping (#37080)\n\n* handle jagged beams\n\n* better comment\n\n* bart -- beam search tests print special tokens\n\n* more bart test updates\n\n* more tests!\n\n* better comment",
    "sha": "9fd9476005f3d11e3447666b52da416a7eea740a",
    "files": [
        {
            "sha": "1f3fe797f48912cf7a179733949ca785b7a120b7",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 8,
            "deletions": 3,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd9476005f3d11e3447666b52da416a7eea740a/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd9476005f3d11e3447666b52da416a7eea740a/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=9fd9476005f3d11e3447666b52da416a7eea740a",
            "patch": "@@ -3931,9 +3931,14 @@ def _beam_search(\n         beam_scores = self._flatten_beam_dim(beam_scores[:, :num_return_sequences])\n         beam_indices = self._flatten_beam_dim(beam_indices[:, :num_return_sequences, :])\n \n-        # Crop the static-shaped tensors to the actual size\n-        sequences = sequences[:, :cur_len]\n-        beam_indices = beam_indices[:, : cur_len - decoder_prompt_len]\n+        # Crop the static-shaped tensors to the actual size.\n+        # `beam_indices` is initialized with -1s, and is updated with the beam index of the generated token at each\n+        # step. We can use it to detect the generated length, which may be != `cur_len`  (e.g. selected beam is from a\n+        # previous decoding iteration)\n+        max_generated_length = ((beam_indices + 1).bool()).sum(dim=1).max()\n+        output_length = decoder_prompt_len + max_generated_length\n+        sequences = sequences[:, :output_length]\n+        beam_indices = beam_indices[:, :max_generated_length]\n \n         if return_dict_in_generate:\n             if not output_scores:"
        },
        {
            "sha": "475baaa5ffc7a91d47537b314a59ff6ad51bd0f6",
            "filename": "tests/models/bart/test_modeling_bart.py",
            "status": "modified",
            "additions": 28,
            "deletions": 19,
            "changes": 47,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbart%2Ftest_modeling_bart.py?ref=9fd9476005f3d11e3447666b52da416a7eea740a",
            "patch": "@@ -599,13 +599,15 @@ def test_xsum_1_1_generation(self):\n             \" 2002 to prosecute genocide, crimes against humanity and war crimes.\"\n         )\n         EXPECTED = (\n+            \"</s>\"\n             \" The International Criminal Court (ICC) has announced that it has been announced by the International\"\n             \" Criminal court.\"\n+            \"</s>\"\n         )\n \n         dct = tok(ARTICLE, return_tensors=\"pt\")\n         generated_ids = hf.generate(**dct, num_beams=4)\n-        result = tok.batch_decode(generated_ids, skip_special_tokens=True)[0]\n+        result = tok.batch_decode(generated_ids)[0]\n         assert EXPECTED == result\n \n     def test_xsum_1_1_batch_generation(self):\n@@ -729,16 +731,18 @@ def test_xsum_1_1_batch_generation(self):\n             truncation=True,\n         )\n         generated_ids = self.xsum_1_1_model.generate(**batch, num_beams=4)\n-        result = self.tok.batch_decode(generated_ids, skip_special_tokens=True)\n-        assert (\n-            result[0]\n-            == \" The International Criminal Court (ICC) has announced that it has been announced by the International\"\n+        result = self.tok.batch_decode(generated_ids)\n+        assert result[0] == (\n+            \"</s>\"\n+            \" The International Criminal Court (ICC) has announced that it has been announced by the International\"\n             \" Criminal court.\"\n+            \"</s><pad><pad><pad><pad><pad>\"\n         )\n-        assert (\n-            result[1]\n-            == \" An investigation into the crash that killed at least 10 people in the French capital has been\"\n+        assert result[1] == (\n+            \"</s>\"\n+            \" An investigation into the crash that killed at least 10 people in the French capital has been\"\n             \" released by the French police investigating the crash.\"\n+            \"</s>\"\n         )\n \n     def test_encoder_equiv(self):\n@@ -939,8 +943,10 @@ def test_xsum_summarization_same_as_fairseq(self):\n         PGE_ARTICLE = \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n \n         EXPECTED_SUMMARY = (\n+            \"</s>\"\n             \"California's largest power company has begun shutting off electricity to thousands of customers in the\"\n             \" state.\"\n+            \"</s>\"\n         )\n         dct = tok.batch_encode_plus(\n             [PGE_ARTICLE],\n@@ -962,10 +968,7 @@ def test_xsum_summarization_same_as_fairseq(self):\n             decoder_start_token_id=model.config.eos_token_id,\n         )\n \n-        decoded = tok.batch_decode(\n-            hypotheses_batch,\n-            skip_special_tokens=True,\n-        )\n+        decoded = tok.batch_decode(hypotheses_batch)\n         self.assertEqual(EXPECTED_SUMMARY, decoded[0])\n \n     def test_xsum_config_generation_params(self):\n@@ -1189,26 +1192,32 @@ def test_cnn_summarization_same_as_fairseq(self):\n         assert hypotheses_batch[:, 1].eq(0).all().item()\n \n         EXPECTED = [\n+            \"</s><s>\"\n             \"A French prosecutor says he is not aware of any video footage from on board the plane. Two German \"\n             \"magazines claim to have found a cell phone video showing the crash. The publications say they watched \"\n             \"the video, which was found by a source close to the investigation. All 150 on board Germanwings Flight \"\n-            \"9525 were killed.\",\n+            \"9525 were killed.\"\n+            \"</s>\",\n+            \"</s><s>\"\n             \"Palestinian Authority becomes 123rd member of the International Criminal Court. The move gives the court \"\n             \"jurisdiction over alleged crimes in Palestinian territories. Israel and the United States opposed the \"\n             \"Palestinians' efforts to join the body. But Palestinian Foreign Minister Riad al-Malki said it was a \"\n-            \"move toward greater justice.\",\n+            \"move toward greater justice.\"\n+            \"</s><pad><pad><pad><pad>\",\n+            \"</s><s>\"\n             \"U.S. and its negotiating partners reached a strong framework agreement with Iran. Peter Bergen: The \"\n             \"debate that has already begun will likely result in more heat than light. He says critics have made \"\n             \"dubious assumptions and doubtful assertions. Bergen says the goal was to block Iran from building a \"\n-            \"nuclear weapon.\",\n+            \"nuclear weapon.\"\n+            \"</s><pad><pad><pad>\",\n+            \"</s><s>\"\n             \"Liana Barrientos, 39, has been married 10 times, sometimes within two weeks of each other. Prosecutors \"\n             \"say the marriages were part of an immigration scam. She pleaded not guilty at State Supreme Court in the \"\n-            \"Bronx on Friday. If convicted, she faces up to four years in prison.\",\n+            \"Bronx on Friday. If convicted, she faces up to four years in prison.\"\n+            \"</s><pad><pad><pad><pad><pad>\",\n         ]\n \n-        generated_summaries = tok.batch_decode(\n-            hypotheses_batch.tolist(), clean_up_tokenization_spaces=True, skip_special_tokens=True\n-        )\n+        generated_summaries = tok.batch_decode(hypotheses_batch.tolist())\n         assert generated_summaries == EXPECTED\n \n     @slow"
        },
        {
            "sha": "42e0a4788a2c82a5fe6f99312bcab508b54ba7d4",
            "filename": "tests/models/biogpt/test_modeling_biogpt.py",
            "status": "modified",
            "additions": 5,
            "deletions": 3,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fbiogpt%2Ftest_modeling_biogpt.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fbiogpt%2Ftest_modeling_biogpt.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fbiogpt%2Ftest_modeling_biogpt.py?ref=9fd9476005f3d11e3447666b52da416a7eea740a",
            "patch": "@@ -434,7 +434,7 @@ def test_inference_lm_head_model(self):\n         torch.testing.assert_close(output[:, :3, :3], expected_slice, rtol=1e-4, atol=1e-4)\n \n     @slow\n-    def test_biogpt_generation(self):\n+    def test_biogpt_generation_beam_search(self):\n         tokenizer = BioGptTokenizer.from_pretrained(\"microsoft/biogpt\")\n         model = BioGptForCausalLM.from_pretrained(\"microsoft/biogpt\")\n         model.to(torch_device)\n@@ -448,13 +448,15 @@ def test_biogpt_generation(self):\n             num_beams=5,\n             early_stopping=True,\n         )\n-        output_str = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n+        output_str = tokenizer.decode(output_ids[0])\n \n         EXPECTED_OUTPUT_STR = (\n+            \"</s>\"\n             \"COVID-19 is a global pandemic caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), the\"\n             \" causative agent of coronavirus disease 2019 (COVID-19), which has spread to more than 200 countries and\"\n             \" territories, including the United States (US), Canada, Australia, New Zealand, the United Kingdom (UK),\"\n             \" and the United States of America (USA), as of March 11, 2020, with more than 800,000 confirmed cases and\"\n-            \" more than 800,000 deaths.\"\n+            \" more than 800,000 deaths. \"\n+            \"</s>\"\n         )\n         self.assertEqual(output_str, EXPECTED_OUTPUT_STR)"
        },
        {
            "sha": "f70cde61330c8cdab83301772fb10225ccf94fb9",
            "filename": "tests/models/m2m_100/test_modeling_m2m_100.py",
            "status": "modified",
            "additions": 10,
            "deletions": 6,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fm2m_100%2Ftest_modeling_m2m_100.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Fm2m_100%2Ftest_modeling_m2m_100.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fm2m_100%2Ftest_modeling_m2m_100.py?ref=9fd9476005f3d11e3447666b52da416a7eea740a",
            "patch": "@@ -415,16 +415,20 @@ def test_seq_to_seq_generation(self):\n         )\n \n         expected_en = [\n-            \"The NSA case highlights the total absence of intelligence debate\",\n-            \"I think there are two levels of response from the French government.\",\n+            \"</s> __en__ \"\n+            \"The NSA case highlights the total absence of intelligence debate\"\n+            \"</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n+            \"</s> __en__ \"\n+            \"I think there are two levels of response from the French government.\"\n+            \"</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\",\n+            \"</s> __en__ \"\n             \"When François Hollande calls Barack Obama or when Foreign Minister Laurent Fabius calls the U.S.\"\n             \" Ambassador, they respond to a real discovery, which is that of the scale of U.S. surveillance on all\"\n-            \" communications in France.\",\n+            \" communications in France.\"\n+            \"</s>\",\n         ]\n \n-        generated = tokenizer.batch_decode(\n-            hypotheses_batch.tolist(), clean_up_tokenization_spaces=True, skip_special_tokens=True\n-        )\n+        generated = tokenizer.batch_decode(hypotheses_batch)\n         assert generated == expected_en\n \n     @require_flash_attn"
        },
        {
            "sha": "6c6d47e8caf01f5aac36ab401ffc88d5aeba2753",
            "filename": "tests/models/t5/test_modeling_t5.py",
            "status": "modified",
            "additions": 23,
            "deletions": 14,
            "changes": 37,
            "blob_url": "https://github.com/huggingface/transformers/blob/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/9fd9476005f3d11e3447666b52da416a7eea740a/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ft5%2Ftest_modeling_t5.py?ref=9fd9476005f3d11e3447666b52da416a7eea740a",
            "patch": "@@ -1475,19 +1475,27 @@ def test_summarization(self):\n         )\n \n         expected_summaries = [\n+            \"<pad> \"\n             'prosecutor: \"so far no videos were used in the crash investigation\" two magazines claim to have found a'\n             \" cell phone video of the final seconds . \\\"one can hear cries of 'My God' in several languages,\\\" one\"\n-            \" magazine says .\",\n+            \" magazine says .\"\n+            \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\",\n+            \"<pad> \"\n             \"the formal accession was marked by a ceremony at The Hague, in the Netherlands . the ICC opened a\"\n             \" preliminary examination into the situation in the occupied Palestinian territory . as members of the\"\n-            \" court, Palestinians may be subject to counter-charges as well .\",\n+            \" court, Palestinians may be subject to counter-charges as well .\"\n+            \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\",\n+            \"<pad> \"\n             \"the u.s. and its negotiating partners reached a very strong framework agreement with Iran . aaron miller:\"\n             \" the debate that has already begun since the announcement of the new framework will likely result in more\"\n             \" heat than light . the deal would reduce Iran's low-enriched uranium stockpile, cut centrifuges and\"\n-            \" implement a rigorous inspection regime .\",\n+            \" implement a rigorous inspection regime .\"\n+            \"</s>\",\n+            \"<pad> \"\n             \"prosecutors say the marriages were part of an immigration scam . if convicted, barrientos faces two\"\n             ' criminal counts of \"offering a false instrument for filing in the first degree\" she has been married 10'\n-            \" times, with nine of her marriages occurring between 1999 and 2002 .\",\n+            \" times, with nine of her marriages occurring between 1999 and 2002 .\"\n+            \"</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>\",\n         ]\n \n         use_task_specific_params(model, \"summarization\")\n@@ -1512,11 +1520,8 @@ def test_summarization(self):\n             early_stopping=True,\n         )\n \n-        decoded = tok.batch_decode(hypotheses_batch, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n-        self.assertListEqual(\n-            expected_summaries,\n-            decoded,\n-        )\n+        decoded = tok.batch_decode(hypotheses_batch)\n+        self.assertListEqual(expected_summaries, decoded)\n \n     @slow\n     def test_translation_en_to_de(self):\n@@ -1526,13 +1531,13 @@ def test_translation_en_to_de(self):\n \n         en_text = '\"Luigi often said to me that he never wanted the brothers to end up in court\", she wrote.'\n         expected_translation = (\n-            '\"Luigi sagte mir oft, dass er nie wollte, dass die Brüder am Gericht sitzen\", schrieb sie.'\n+            '<pad> \"Luigi sagte mir oft, dass er nie wollte, dass die Brüder am Gericht sitzen\", schrieb sie.</s>'\n         )\n \n         input_ids = tok.encode(model.config.prefix + en_text, return_tensors=\"pt\")\n         input_ids = input_ids.to(torch_device)\n         output = model.generate(input_ids)\n-        translation = tok.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n+        translation = tok.decode(output[0])\n         self.assertEqual(translation, expected_translation)\n \n     @slow\n@@ -1558,13 +1563,15 @@ def test_translation_en_to_fr(self):\n             do_sample=False,\n             early_stopping=True,\n         )\n-        translation = tok.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n+        translation = tok.decode(output[0])\n         new_truncated_translation = (\n+            \"<pad> \"\n             \"Cette section d'images provenant de l'enregistrement infrarouge effectué par le télescope Spitzer montre \"\n             \"un \"\n             \"« portrait familial » de générations innombrables d’étoiles : les plus anciennes sont observées \"\n             \"sous forme \"\n             \"de points bleus.\"\n+            \"</s>\"\n         )\n \n         self.assertEqual(translation, new_truncated_translation)\n@@ -1575,11 +1582,13 @@ def test_translation_en_to_ro(self):\n         tok = self.tokenizer\n         use_task_specific_params(model, \"translation_en_to_ro\")\n         en_text = \"Taco Bell said it plans to add 2,000 locations in the US by 2022.\"\n-        expected_translation = \"Taco Bell a declarat că intenţionează să adauge 2 000 de locaţii în SUA până în 2022.\"\n+        expected_translation = (\n+            \"<pad> Taco Bell a declarat că intenţionează să adauge 2 000 de locaţii în SUA până în 2022.</s>\"\n+        )\n \n         inputs = tok(model.config.prefix + en_text, return_tensors=\"pt\").to(torch_device)\n         output = model.generate(**inputs)\n-        translation = tok.decode(output[0], skip_special_tokens=True, clean_up_tokenization_spaces=False)\n+        translation = tok.decode(output[0])\n         self.assertEqual(translation, expected_translation)\n \n     @slow"
        }
    ],
    "stats": {
        "total": 119,
        "additions": 74,
        "deletions": 45
    }
}