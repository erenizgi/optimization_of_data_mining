{
    "author": "guangy10",
    "message": "Albert is ExecuTorch compatible (#34476)\n\nCo-authored-by: Guang Yang <guangyang@fb.com>",
    "sha": "f339042b0b8bdc0b57a70d37f67cafbea960a2ab",
    "files": [
        {
            "sha": "970f1dd8555e47def1315835f60055c5711447e0",
            "filename": "tests/models/albert/test_modeling_albert.py",
            "status": "modified",
            "additions": 45,
            "deletions": 1,
            "changes": 46,
            "blob_url": "https://github.com/huggingface/transformers/blob/f339042b0b8bdc0b57a70d37f67cafbea960a2ab/tests%2Fmodels%2Falbert%2Ftest_modeling_albert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/f339042b0b8bdc0b57a70d37f67cafbea960a2ab/tests%2Fmodels%2Falbert%2Ftest_modeling_albert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Falbert%2Ftest_modeling_albert.py?ref=f339042b0b8bdc0b57a70d37f67cafbea960a2ab",
            "patch": "@@ -16,7 +16,9 @@\n \n import unittest\n \n-from transformers import AlbertConfig, is_torch_available\n+from packaging import version\n+\n+from transformers import AlbertConfig, AutoTokenizer, is_torch_available\n from transformers.models.auto import get_values\n from transformers.testing_utils import require_torch, slow, torch_device\n \n@@ -342,3 +344,45 @@ def test_inference_no_head_absolute_embedding(self):\n         )\n \n         self.assertTrue(torch.allclose(output[:, 1:4, 1:4], expected_slice, atol=1e-4))\n+\n+    @slow\n+    def test_export(self):\n+        if version.parse(torch.__version__) < version.parse(\"2.4.0\"):\n+            self.skipTest(reason=\"This test requires torch >= 2.4 to run.\")\n+\n+        distilbert_model = \"albert/albert-base-v2\"\n+        device = \"cpu\"\n+        attn_implementation = \"sdpa\"\n+        max_length = 64\n+\n+        tokenizer = AutoTokenizer.from_pretrained(distilbert_model)\n+        inputs = tokenizer(\n+            f\"Paris is the {tokenizer.mask_token} of France.\",\n+            return_tensors=\"pt\",\n+            padding=\"max_length\",\n+            max_length=max_length,\n+        )\n+\n+        model = AlbertForMaskedLM.from_pretrained(\n+            distilbert_model,\n+            device_map=device,\n+            attn_implementation=attn_implementation,\n+        )\n+\n+        logits = model(**inputs).logits\n+        eg_predicted_mask = tokenizer.decode(logits[0, 4].topk(5).indices)\n+        self.assertEqual(\n+            eg_predicted_mask.split(),\n+            [\"capital\", \"capitol\", \"comune\", \"arrondissement\", \"bastille\"],\n+        )\n+\n+        exported_program = torch.export.export(\n+            model,\n+            args=(inputs[\"input_ids\"],),\n+            kwargs={\"attention_mask\": inputs[\"attention_mask\"]},\n+            strict=True,\n+        )\n+\n+        result = exported_program.module().forward(inputs[\"input_ids\"], inputs[\"attention_mask\"])\n+        ep_predicted_mask = tokenizer.decode(result.logits[0, 4].topk(5).indices)\n+        self.assertEqual(eg_predicted_mask, ep_predicted_mask)"
        }
    ],
    "stats": {
        "total": 46,
        "additions": 45,
        "deletions": 1
    }
}