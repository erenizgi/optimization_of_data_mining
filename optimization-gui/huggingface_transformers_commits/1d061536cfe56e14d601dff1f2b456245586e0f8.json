{
    "author": "skwh54",
    "message": "ğŸŒ [i18n-KO] Translated `how_to_hack_models.md` to Korean (#39536)\n\n* docs: ko: how_to_hack_models.md\n\n* feat: nmt draft\n\n* fix: manual edits",
    "sha": "1d061536cfe56e14d601dff1f2b456245586e0f8",
    "files": [
        {
            "sha": "fb9615ffafb5c552dd3999de2b46347cd32f0e84",
            "filename": "docs/source/ko/_toctree.yml",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/1d061536cfe56e14d601dff1f2b456245586e0f8/docs%2Fsource%2Fko%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/1d061536cfe56e14d601dff1f2b456245586e0f8/docs%2Fsource%2Fko%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2F_toctree.yml?ref=1d061536cfe56e14d601dff1f2b456245586e0f8",
            "patch": "@@ -13,8 +13,8 @@\n       title: (ë²ˆì—­ì¤‘) Loading models\n     - local: custom_models\n       title: ì‚¬ìš©ì ì •ì˜ ëª¨ë¸ ê³µìœ í•˜ê¸°\n-    - local: in_translation\n-      title: (ë²ˆì—­ì¤‘) Customizing model components\n+    - local: how_to_hack_models\n+      title: ëª¨ë¸ êµ¬ì„± ìš”ì†Œ ë§ì¶¤ ì„¤ì •í•˜ê¸°\n     - local: model_sharing\n       title: ë§Œë“  ëª¨ë¸ ê³µìœ í•˜ê¸°\n     - local: modular_transformers"
        },
        {
            "sha": "9ef4839335f32bfd6519e464061eb017128ce0eb",
            "filename": "docs/source/ko/how_to_hack_models.md",
            "status": "added",
            "additions": 152,
            "deletions": 0,
            "changes": 152,
            "blob_url": "https://github.com/huggingface/transformers/blob/1d061536cfe56e14d601dff1f2b456245586e0f8/docs%2Fsource%2Fko%2Fhow_to_hack_models.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/1d061536cfe56e14d601dff1f2b456245586e0f8/docs%2Fsource%2Fko%2Fhow_to_hack_models.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fko%2Fhow_to_hack_models.md?ref=1d061536cfe56e14d601dff1f2b456245586e0f8",
            "patch": "@@ -0,0 +1,152 @@\n+<!--Copyright 2024 The HuggingFace Team. All rights reserved.\n+\n+Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+the License. You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+\n+âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be\n+rendered properly in your Markdown viewer.\n+\n+-->\n+\n+# ëª¨ë¸ êµ¬ì„± ìš”ì†Œ ë§ì¶¤ ì„¤ì •í•˜ê¸°[[customizing-model-components]]\n+\n+ëª¨ë¸ì„ ì™„ì „íˆ ìƒˆë¡œ ì‘ì„±í•˜ëŠ” ëŒ€ì‹  êµ¬ì„± ìš”ì†Œë¥¼ ìˆ˜ì •í•˜ì—¬ ëª¨ë¸ì„ ë§ì¶¤ ì„¤ì •í•˜ëŠ” ë°©ë²•ì´ ìˆìŠµë‹ˆë‹¤. ì´ ë°©ë²•ìœ¼ë¡œ ëª¨ë¸ì„ íŠ¹ì • ì‚¬ìš© ì‚¬ë¡€ì— ë§ê²Œ ëª¨ë¸ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìƒˆë¡œìš´ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì•„í‚¤í…ì²˜ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ìµœì í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë§ì¶¤ ì„¤ì •ì€ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì— ì§ì ‘ ì ìš©ë˜ë¯€ë¡œ, [`Trainer`], [`PreTrainedModel`] ë° [PEFT](https://huggingface.co/docs/peft/en/index) ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ê°™ì€ ê¸°ëŠ¥ì„ ê³„ì† ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n+\n+ì´ ê°€ì´ë“œì—ì„œëŠ” ëª¨ë¸ì˜ ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ ë§ì¶¤ ì„¤ì •í•˜ì—¬ [Low-Rank Adaptation (LoRA)](https://huggingface.co/docs/peft/conceptual_guides/adapter#low-rank-adaptation-lora)ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.\n+\n+> [!TIP]\n+> ëª¨ë¸ ì½”ë“œë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜ì •í•˜ê³  ê°œë°œí•  ë•Œ [clear_import_cache](https://github.com/huggingface/transformers/blob/9985d06add07a4cc691dc54a7e34f54205c04d40/src/transformers/utils/import_utils.py#L2286) ìœ í‹¸ë¦¬í‹°ê°€ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì€ ìºì‹œëœ ëª¨ë“  íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë“ˆì„ ì œê±°í•˜ì—¬ Pythonì´ í™˜ê²½ì„ ì¬ì‹œì‘í•˜ì§€ ì•Šê³ ë„ ìˆ˜ì •ëœ ì½”ë“œë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.\n+>\n+> ```py\n+> from transformers import AutoModel\n+> from transformers.utils.import_utils import clear_import_cache\n+>\n+> model = AutoModel.from_pretrained(\"bert-base-uncased\")\n+> # ëª¨ë¸ ì½”ë“œ ìˆ˜ì •\n+> # ìºì‹œë¥¼ ì§€ì›Œ ìˆ˜ì •ëœ ì½”ë“œë¥¼ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°\n+> clear_import_cache()\n+> # ì—…ë°ì´íŠ¸ëœ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ë‹¤ì‹œ ê°€ì ¸ì˜¤ê¸°\n+> model = AutoModel.from_pretrained(\"bert-base-uncased\")\n+> ```\n+\n+## ì–´í…ì…˜ í´ë˜ìŠ¤[[attention-class]]\n+\n+[Segment Anything](./model_doc/sam)ì€ ì´ë¯¸ì§€ ë¶„í•  ëª¨ë¸ë¡œ, ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì—ì„œ query-key-value(`qkv`) í”„ë¡œì ì…˜ì„ ê²°í•©í•©ë‹ˆë‹¤. í•™ìŠµ ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„° ìˆ˜ì™€ ì—°ì‚° ë¶€ë‹´ì„ ì¤„ì´ê¸° ìœ„í•´ `qkv` í”„ë¡œì ì…˜ì— LoRAë¥¼ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œëŠ” `qkv` í”„ë¡œì ì…˜ì„ ë¶„ë¦¬í•˜ì—¬ `q`ì™€ `v`ì— LoRAë¥¼ ê°œë³„ì ìœ¼ë¡œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n+\n+1. ì›ë˜ì˜ `SamVisionAttention` í´ë˜ìŠ¤ë¥¼ ìƒì†í•˜ì—¬ `SamVisionAttentionSplit`ì´ë¼ëŠ” ì‚¬ìš©ì ì •ì˜ ì–´í…ì…˜ í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤. `__init__`ì—ì„œ ê²°í•©ëœ `qkv`ë¥¼ ì‚­ì œí•˜ê³ , `q`, `k`, `v`ë¥¼ ìœ„í•œ ê°œë³„ ì„ í˜• ë ˆì´ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n+\n+```py\n+import torch\n+import torch.nn as nn\n+from transformers.models.sam.modeling_sam import SamVisionAttention\n+\n+class SamVisionAttentionSplit(SamVisionAttention, nn.Module):\n+    def __init__(self, config, window_size):\n+        super().__init__(config, window_size)\n+        # ê²°í•©ëœ qkv ì œê±°\n+        del self.qkv\n+        # q, k, v ê°œë³„ í”„ë¡œì ì…˜ ìƒì„±\n+        self.q = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self.k = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self.v = nn.Linear(config.hidden_size, config.hidden_size, bias=config.qkv_bias)\n+        self._register_load_state_dict_pre_hook(self.split_q_k_v_load_hook)\n+```\n+\n+2. `_split_qkv_load_hook` í•¨ìˆ˜ëŠ” ëª¨ë¸ì„ ê°€ì ¸ì˜¬ ë•Œ, ì‚¬ì „ í›ˆë ¨ëœ `qkv` ê°€ì¤‘ì¹˜ë¥¼ `q`, `k`, `v`ë¡œ ë¶„ë¦¬í•˜ì—¬ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ê³¼ì˜ í˜¸í™˜ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.\n+\n+```py\n+    def split_q_k_v_load_hook(self, state_dict, prefix, *args):\n+        keys_to_delete = []\n+        for key in list(state_dict.keys()):\n+            if \"qkv.\" in key:\n+                # ê²°í•©ëœ í”„ë¡œì ì…˜ì—ì„œ q, k, v ë¶„ë¦¬\n+                q, k, v = state_dict[key].chunk(3, dim=0)\n+                # ê°œë³„ q, k, v í”„ë¡œì ì…˜ìœ¼ë¡œ ëŒ€ì²´\n+                state_dict[key.replace(\"qkv.\", \"q.\")] = q\n+                state_dict[key.replace(\"qkv.\", \"k.\")] = k\n+                state_dict[key.replace(\"qkv.\", \"v.\")] = v\n+                # ê¸°ì¡´ qkv í‚¤ë¥¼ ì‚­ì œ ëŒ€ìƒìœ¼ë¡œ í‘œì‹œ\n+                keys_to_delete.append(key)\n+        \n+        # ê¸°ì¡´ qkv í‚¤ ì œê±°\n+        for key in keys_to_delete:\n+            del state_dict[key]\n+```\n+\n+3. `forward` ë‹¨ê³„ì—ì„œ `q`, `k`, `v`ëŠ” ê°œë³„ì ìœ¼ë¡œ ê³„ì‚°ë˜ë©°, ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì˜ ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ ë™ì¼í•˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤.\n+\n+```py\n+    def forward(self, hidden_states: torch.Tensor, output_attentions=False) -> torch.Tensor:\n+        batch_size, height, width, _ = hidden_states.shape\n+        qkv_shapes = (batch_size *  self.num_attention_heads,  height * width, -1)\n+        query = self.q(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+        key = self.k(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+        value = self.v(hidden_states).reshape((batch_size,  height * width,self.num_attention_heads, -1)).permute(0,2,1,3).reshape(qkv_shapes)\n+\n+        attn_weights = (query * self.scale) @ key.transpose(-2, -1)\n+\n+        attn_weights = torch.nn.functional.softmax(attn_weights, dtype=torch.float32, dim=-1).to(query.dtype)\n+        attn_probs = nn.functional.dropout(attn_weights, p=self.dropout, training=self.training)\n+        attn_output = (attn_probs @ value).reshape(batch_size, self.num_attention_heads, height, width, -1)\n+        attn_output = attn_output.permute(0, 2, 3, 1, 4).reshape(batch_size, height, width, -1)\n+        attn_output = self.proj(attn_output)\n+\n+        if output_attentions:\n+            outputs = (attn_output, attn_weights)\n+        else:\n+            outputs = (attn_output, None)\n+        return outputs\n+```\n+\n+ì‚¬ìš©ì ì •ì˜ `SamVisionAttentionSplit` í´ë˜ìŠ¤ë¥¼ ì›ë³¸ ëª¨ë¸ì˜ `SamVisionAttention` ëª¨ë“ˆì— í• ë‹¹í•˜ì—¬ êµì²´í•©ë‹ˆë‹¤. ëª¨ë¸ ë‚´ ëª¨ë“  `SamVisionAttention` ì¸ìŠ¤í„´ìŠ¤ëŠ” ë¶„ë¦¬ëœ ì–´í…ì…˜ ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.\n+\n+[`~PreTrainedModel.from_pretrained`]ë¡œ ëª¨ë¸ì„ ê°€ì ¸ì˜¤ì„¸ìš”.\n+\n+```py\n+from transformers import SamModel\n+\n+# ì‚¬ì „ í›ˆë ¨ëœ SAM ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°\n+model = SamModel.from_pretrained(\"facebook/sam-vit-base\")\n+\n+# ë¹„ì „-ì¸ì½”ë” ëª¨ë“ˆì—ì„œ ì–´í…ì…˜ í´ë˜ìŠ¤ êµì²´\n+for layer in model.vision_encoder.layers:\n+    if hasattr(layer, \"attn\"):\n+        layer.attn = SamVisionAttentionSplit(model.config.vision_config, model.config.vision_config.window_size)\n+```\n+\n+## LoRA[[lora]]\n+\n+ë¶„ë¦¬ëœ `q`, `k`, `v` í”„ë¡œì ì…˜ì„ ì‚¬ìš©í•  ë•Œ , `q`ì™€ `v`ì— LoRAë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n+\n+[LoraConfig](https://huggingface.co/docs/peft/package_reference/config#peft.PeftConfig)ë¥¼ ìƒì„±í•˜ê³ , ë­í¬ `r`, `lora_alpha`, `lora_dropout`, `task_type`, ê·¸ë¦¬ê³  ê°€ì¥ ì¤‘ìš”í•œ ì ìš©ë  ëª¨ë“ˆì„ ì§€ì •í•©ë‹ˆë‹¤.\n+\n+```py\n+from peft import LoraConfig, get_peft_model\n+\n+config = LoraConfig(\n+    r=16,\n+    lora_alpha=32,\n+    # qì™€ vì— LoRA ì ìš©\n+    target_modules=[\"q\", \"v\"],\n+    lora_dropout=0.1,\n+    task_type=\"FEATURE_EXTRACTION\"\n+)\n+```\n+\n+ëª¨ë¸ê³¼ [LoraConfig](https://huggingface.co/docs/peft/package_reference/config#peft.PeftConfig)ë¥¼ [get\\_peft\\_model](https://huggingface.co/docs/peft/package_reference/peft_model#peft.get_peft_model)ì— ì „ë‹¬í•˜ì—¬ ëª¨ë¸ì— LoRAë¥¼ ì ìš©í•©ë‹ˆë‹¤.\n+\n+```py\n+model = get_peft_model(model, config)\n+```\n+\n+[print_trainable_parameters](https://huggingface.co/docs/peft/package_reference/peft_model#peft.PeftMixedModel.print_trainable_parameters)ë¥¼ í˜¸ì¶œí•˜ì—¬ ì „ì²´ íŒŒë¼ë¯¸í„° ìˆ˜ ëŒ€ë¹„ í›ˆë ¨ë˜ëŠ” íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n+\n+```py\n+model.print_trainable_parameters()\n+\"trainable params: 589,824 || all params: 94,274,096 || trainable%: 0.6256\"\n+```"
        }
    ],
    "stats": {
        "total": 156,
        "additions": 154,
        "deletions": 2
    }
}