{
    "author": "Cyrilvallez",
    "message": "Fix quantized cache with only cache_implementation in generate (#40144)\n\n* fix args\n\n* comment",
    "sha": "12e49cda32a5301fe94df0d1a96d6756472ff81d",
    "files": [
        {
            "sha": "d0f5a546386b19c64ae9848e6de7e3e60e155fa5",
            "filename": "src/transformers/generation/utils.py",
            "status": "modified",
            "additions": 10,
            "deletions": 9,
            "changes": 19,
            "blob_url": "https://github.com/huggingface/transformers/blob/12e49cda32a5301fe94df0d1a96d6756472ff81d/src%2Ftransformers%2Fgeneration%2Futils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/12e49cda32a5301fe94df0d1a96d6756472ff81d/src%2Ftransformers%2Fgeneration%2Futils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Futils.py?ref=12e49cda32a5301fe94df0d1a96d6756472ff81d",
            "patch": "@@ -1990,19 +1990,20 @@ def _prepare_cache_for_generation(\n                         \"cache, please open an issue and tag @zucchini-nlp.\"\n                     )\n \n-                cache_config = (\n-                    generation_config.cache_config\n-                    if generation_config.cache_config is not None\n-                    else {\"backend\": \"quanto\"}\n-                )\n-                cache_class = QUANT_BACKEND_CLASSES_MAPPING[cache_config[\"backend\"]]\n-\n-                if cache_config[\"backend\"] == \"quanto\" and not is_optimum_quanto_available():\n+                cache_config = generation_config.cache_config if generation_config.cache_config is not None else {}\n+                # Add the config if it was not provided, as it's a required argument\n+                if \"config\" not in cache_config:\n+                    cache_config[\"config\"] = self.config.get_text_config()\n+                # Pop the backend from the config (defaults to quanto if not defined)\n+                backend = cache_config.pop(\"backend\", \"quanto\")\n+                cache_class = QUANT_BACKEND_CLASSES_MAPPING[backend]\n+\n+                if backend == \"quanto\" and not is_optimum_quanto_available():\n                     raise ImportError(\n                         \"You need to install optimum-quanto in order to use KV cache quantization with optimum-quanto backend. \"\n                         \"Please install it via  with `pip install optimum-quanto`\"\n                     )\n-                elif cache_config[\"backend\"] == \"HQQ\" and not is_hqq_available():\n+                elif backend == \"HQQ\" and not is_hqq_available():\n                     raise ImportError(\n                         \"You need to install `HQQ` in order to use KV cache quantization with HQQ backend. \"\n                         \"Please install it via  with `pip install hqq`\""
        }
    ],
    "stats": {
        "total": 19,
        "additions": 10,
        "deletions": 9
    }
}