{
    "author": "Rocketknight1",
    "message": "Correctly list the chat template file in the Tokenizer saved files list (#34974)\n\n* Correctly list the chat template file in the saved files list\r\n\r\n* Update src/transformers/tokenization_utils_base.py\r\n\r\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>\r\n\r\n* Add save file checking to test\r\n\r\n* make fixup\r\n\r\n* better filename handling\r\n\r\n* make fixup\r\n\r\n---------\r\n\r\nCo-authored-by: Arthur <48595927+ArthurZucker@users.noreply.github.com>",
    "sha": "a7d1441d657bdb2abf04c3931017ef8c9c3580cd",
    "files": [
        {
            "sha": "86e07a382f8812f0b6b790139a003e9ce3bb1532",
            "filename": "src/transformers/tokenization_utils_base.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/a7d1441d657bdb2abf04c3931017ef8c9c3580cd/src%2Ftransformers%2Ftokenization_utils_base.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a7d1441d657bdb2abf04c3931017ef8c9c3580cd/src%2Ftransformers%2Ftokenization_utils_base.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftokenization_utils_base.py?ref=a7d1441d657bdb2abf04c3931017ef8c9c3580cd",
            "patch": "@@ -2429,6 +2429,7 @@ def save_pretrained(\n             tokenizer_config[\"extra_special_tokens\"] = self.extra_special_tokens\n             tokenizer_config.update(self.extra_special_tokens)\n \n+        saved_raw_chat_template = False\n         if self.chat_template is not None:\n             if isinstance(self.chat_template, dict):\n                 # Chat template dicts are saved to the config as lists of dicts with fixed key names.\n@@ -2439,6 +2440,7 @@ def save_pretrained(\n             elif kwargs.get(\"save_raw_chat_template\", False):\n                 with open(chat_template_file, \"w\", encoding=\"utf-8\") as f:\n                     f.write(self.chat_template)\n+                saved_raw_chat_template = True\n                 logger.info(f\"chat template saved in {chat_template_file}\")\n                 if \"chat_template\" in tokenizer_config:\n                     tokenizer_config.pop(\"chat_template\")  # To ensure it doesn't somehow end up in the config too\n@@ -2498,6 +2500,8 @@ def save_pretrained(\n         logger.info(f\"Special tokens file saved in {special_tokens_map_file}\")\n \n         file_names = (tokenizer_config_file, special_tokens_map_file)\n+        if saved_raw_chat_template:\n+            file_names += (chat_template_file,)\n \n         save_files = self._save_pretrained(\n             save_directory=save_directory,"
        },
        {
            "sha": "d6957757dc55d898c4a7cd7fe71016b0b715e478",
            "filename": "tests/test_tokenization_common.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a7d1441d657bdb2abf04c3931017ef8c9c3580cd/tests%2Ftest_tokenization_common.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/a7d1441d657bdb2abf04c3931017ef8c9c3580cd/tests%2Ftest_tokenization_common.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Ftest_tokenization_common.py?ref=a7d1441d657bdb2abf04c3931017ef8c9c3580cd",
            "patch": "@@ -1107,7 +1107,9 @@ def test_chat_template(self):\n                 tokenizer.apply_chat_template(dummy_conversation, tokenize=True, return_dict=False)\n \n                 with tempfile.TemporaryDirectory() as tmp_dir_name:\n-                    tokenizer.save_pretrained(tmp_dir_name)\n+                    save_files = tokenizer.save_pretrained(tmp_dir_name)\n+                    # Check we aren't saving a chat_template.jinja file\n+                    self.assertFalse(any(file.endswith(\"chat_template.jinja\") for file in save_files))\n                     new_tokenizer = tokenizer.from_pretrained(tmp_dir_name)\n \n                 self.assertEqual(new_tokenizer.chat_template, dummy_template)  # Test template has persisted\n@@ -1117,7 +1119,9 @@ def test_chat_template(self):\n                 new_tokenizer.apply_chat_template(dummy_conversation, tokenize=True, return_dict=False)\n \n                 with tempfile.TemporaryDirectory() as tmp_dir_name:\n-                    tokenizer.save_pretrained(tmp_dir_name, save_raw_chat_template=True)\n+                    save_files = tokenizer.save_pretrained(tmp_dir_name, save_raw_chat_template=True)\n+                    # Check we are saving a chat_template.jinja file\n+                    self.assertTrue(any(file.endswith(\"chat_template.jinja\") for file in save_files))\n                     chat_template_file = Path(tmp_dir_name) / \"chat_template.jinja\"\n                     self.assertTrue(chat_template_file.is_file())\n                     self.assertEqual(chat_template_file.read_text(), dummy_template)"
        }
    ],
    "stats": {
        "total": 12,
        "additions": 10,
        "deletions": 2
    }
}