{
    "author": "cyyever",
    "message": "Use checkpoint in auto_class_docstring (#40844)\n\nSigned-off-by: Yuanyuan Chen <cyyever@outlook.com>",
    "sha": "d42e96a2a731c4a772e396baa0d915524c873ff0",
    "files": [
        {
            "sha": "a9d9a8cba78806b00d4d754451a77a0ab345552b",
            "filename": "src/transformers/utils/auto_docstring.py",
            "status": "modified",
            "additions": 7,
            "deletions": 3,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/d42e96a2a731c4a772e396baa0d915524c873ff0/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d42e96a2a731c4a772e396baa0d915524c873ff0/src%2Ftransformers%2Futils%2Fauto_docstring.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Futils%2Fauto_docstring.py?ref=d42e96a2a731c4a772e396baa0d915524c873ff0",
            "patch": "@@ -1098,7 +1098,7 @@ def contains_type(type_hint, target_type) -> tuple[bool, Optional[object]]:\n     if args == ():\n         try:\n             return issubclass(type_hint, target_type), type_hint\n-        except Exception as _:\n+        except Exception:\n             return issubclass(type(type_hint), target_type), type_hint\n     found_type_tuple = [contains_type(arg, target_type)[0] for arg in args]\n     found_type = any(found_type_tuple)\n@@ -1112,6 +1112,8 @@ def get_model_name(obj):\n     Get the model name from the file path of the object.\n     \"\"\"\n     path = inspect.getsourcefile(obj)\n+    if path is None:\n+        return None\n     if path.split(os.path.sep)[-3] != \"models\":\n         return None\n     file_name = path.split(os.path.sep)[-1]\n@@ -1783,9 +1785,10 @@ def auto_class_docstring(cls, custom_intro=None, custom_args=None, checkpoint=No\n \n     is_dataclass = False\n     docstring_init = \"\"\n+    docstring_args = \"\"\n     if \"PreTrainedModel\" in (x.__name__ for x in cls.__mro__):\n         docstring_init = auto_method_docstring(\n-            cls.__init__, parent_class=cls, custom_args=custom_args\n+            cls.__init__, parent_class=cls, custom_args=custom_args, checkpoint=checkpoint\n         ).__doc__.replace(\"Args:\", \"Parameters:\")\n     elif \"ModelOutput\" in (x.__name__ for x in cls.__mro__):\n         # We have a data class\n@@ -1797,6 +1800,7 @@ def auto_class_docstring(cls, custom_intro=None, custom_args=None, checkpoint=No\n             cls.__init__,\n             parent_class=cls,\n             custom_args=custom_args,\n+            checkpoint=checkpoint,\n             source_args_dict=get_args_doc_from_source(ModelOutputArgs),\n         ).__doc__\n     indent_level = get_indent_level(cls)\n@@ -1836,7 +1840,7 @@ def auto_class_docstring(cls, custom_intro=None, custom_args=None, checkpoint=No\n             docstring += docstring_args if docstring_args else \"\\nArgs:\\n\"\n             source_args_dict = get_args_doc_from_source(ModelOutputArgs)\n             doc_class = cls.__doc__ if cls.__doc__ else \"\"\n-            documented_kwargs, _ = parse_docstring(doc_class)\n+            documented_kwargs = parse_docstring(doc_class)[0]\n             for param_name, param_type_annotation in cls.__annotations__.items():\n                 param_type = str(param_type_annotation)\n                 optional = False"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 7,
        "deletions": 3
    }
}