{
    "author": "zucchini-nlp",
    "message": "Mllama: raise better error (#35934)\n\n* fix mllama\n\n* update test\n\n* fix test",
    "sha": "97d2f9d8aeea89d81ebf883640aa0d7dc561a46a",
    "files": [
        {
            "sha": "d26d93bc3ce18aa553b1c3ae39474276cf5201dc",
            "filename": "src/transformers/models/mllama/processing_mllama.py",
            "status": "modified",
            "additions": 6,
            "deletions": 2,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/97d2f9d8aeea89d81ebf883640aa0d7dc561a46a/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/97d2f9d8aeea89d81ebf883640aa0d7dc561a46a/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py?ref=97d2f9d8aeea89d81ebf883640aa0d7dc561a46a",
            "patch": "@@ -301,12 +301,16 @@ def __call__(\n                 raise ValueError(\n                     \"If a batch of text is provided, there should be either no images or at least one image per sample\"\n                 )\n-            if sum(n_images_in_images) != sum(n_images_in_text):\n+            if sum(n_images_in_text) > 0 and n_images_in_images != n_images_in_text:\n                 if images is None:\n                     raise ValueError(\"No image were provided, but there are image tokens in the prompt\")\n                 else:\n+                    add_message = \"\"\n+                    if sum(n_images_in_images) == sum(n_images_in_text):\n+                        add_message = \"Make sure to pass your images as a nested list, where each sub-list holds images per batch\"\n                     raise ValueError(\n-                        f\"The number of image token ({sum(n_images_in_text)}) should be the same as in the number of provided images ({sum(n_images_in_images)})\"\n+                        f\"The number of image tokens in each text ({n_images_in_text}) should be the same as the \"\n+                        f\"number of provided images per batch ({n_images_in_images}). {add_message}\"\n                     )\n \n         if images is not None:"
        },
        {
            "sha": "bbc1d3dfc86e220f43447c740abe9e6b7dd4db1e",
            "filename": "tests/models/mllama/test_processor_mllama.py",
            "status": "modified",
            "additions": 34,
            "deletions": 0,
            "changes": 34,
            "blob_url": "https://github.com/huggingface/transformers/blob/97d2f9d8aeea89d81ebf883640aa0d7dc561a46a/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/97d2f9d8aeea89d81ebf883640aa0d7dc561a46a/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmllama%2Ftest_processor_mllama.py?ref=97d2f9d8aeea89d81ebf883640aa0d7dc561a46a",
            "patch": "@@ -327,6 +327,11 @@ def test_process_interleaved_images_prompts_image_error(self):\n         with self.assertRaises(ValueError):\n             processor(text=text, images=None, padding=True)\n \n+        # see https://github.com/huggingface/transformers/pull/35934\n+        images = [self.image1, self.image2]\n+        with self.assertRaises(ValueError):\n+            processor(text=text, images=None, padding=True)\n+\n     # Override as MllamaProcessor needs image tokens in prompts\n     def prepare_text_inputs(self, batch_size: Optional[int] = None):\n         if batch_size is None:\n@@ -340,3 +345,32 @@ def prepare_text_inputs(self, batch_size: Optional[int] = None):\n         return [\"lower newer <|image|>\", \"<|image|> upper older longer string\"] + [\"<|image|> lower newer\"] * (\n             batch_size - 2\n         )\n+\n+    def test_unstructured_kwargs_batched(self):\n+        # Overriden because Mllama expects images in nested format. For 2 images it can't infer\n+        # the correct nesting, so we better throw an error\n+        if \"image_processor\" not in self.processor_class.attributes:\n+            self.skipTest(f\"image_processor attribute not present in {self.processor_class}\")\n+        processor_components = self.prepare_components()\n+        processor_kwargs = self.prepare_processor_dict()\n+        processor = self.processor_class(**processor_components, **processor_kwargs)\n+        self.skip_processor_without_typed_kwargs(processor)\n+\n+        input_str = self.prepare_text_inputs(batch_size=2)\n+        image_input = self.prepare_image_inputs(batch_size=2)\n+        image_input = [[image_input[0]], [image_input[1]]]\n+        inputs = processor(\n+            text=input_str,\n+            images=image_input,\n+            return_tensors=\"pt\",\n+            do_rescale=True,\n+            rescale_factor=-1,\n+            padding=\"longest\",\n+            max_length=76,\n+        )\n+\n+        self.assertLessEqual(inputs[self.images_input_name][0][0].mean(), 0)\n+        self.assertTrue(\n+            len(inputs[self.text_input_name][0]) == len(inputs[self.text_input_name][1])\n+            and len(inputs[self.text_input_name][1]) < 76\n+        )"
        }
    ],
    "stats": {
        "total": 42,
        "additions": 40,
        "deletions": 2
    }
}