{
    "author": "McPatate",
    "message": "feat(cb): use context manager in `generate_batch` (#42190)\n\n* feat(cb): use context manager in `generate_batch`\n\n* refactor(cb): group `with` stmts\n\n* refactor(cb): move log line before `stop` call\n\nCo-authored-by: Rémi Ouazan <83456801+remi-or@users.noreply.github.com>\n\n* fix: lint\n\n---------\n\nCo-authored-by: Rémi Ouazan <83456801+remi-or@users.noreply.github.com>",
    "sha": "eb399a95f0368b8d23f085859f8214ce57c1f2de",
    "files": [
        {
            "sha": "8a845df7891db5981c4451aeabf2a54fa88a2043",
            "filename": "src/transformers/generation/continuous_batching/continuous_api.py",
            "status": "modified",
            "additions": 60,
            "deletions": 41,
            "changes": 101,
            "blob_url": "https://github.com/huggingface/transformers/blob/eb399a95f0368b8d23f085859f8214ce57c1f2de/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/eb399a95f0368b8d23f085859f8214ce57c1f2de/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fgeneration%2Fcontinuous_batching%2Fcontinuous_api.py?ref=eb399a95f0368b8d23f085859f8214ce57c1f2de",
            "patch": "@@ -26,6 +26,7 @@\n import torch\n from torch import nn\n from tqdm import tqdm\n+from tqdm.contrib.logging import logging_redirect_tqdm\n \n from ...configuration_utils import PretrainedConfig\n from ...generation.configuration_utils import GenerationConfig\n@@ -809,6 +810,7 @@ def is_running(self) -> bool:\n         \"\"\"Check if the background generation thread is running.\"\"\"\n         return self._generation_thread is not None and self._generation_thread.is_alive()\n \n+    # NOTE: don't forget to update `continuous_batching_context_manager` when changing this method's definition\n     def stop(self, block: bool = True, timeout: float | None = None) -> None:\n         \"\"\"Signal the background thread to stop.\n \n@@ -1063,14 +1065,35 @@ class ContinuousMixin:\n     \"\"\"Mixin class for models to add continuous batching capabilities.\"\"\"\n \n     @contextmanager\n-    def continuous_batching_context_manager(self, **kwargs) -> Generator[ContinuousBatchingManager]:\n-        manager = self.init_continuous_batching(**kwargs)\n+    def continuous_batching_context_manager(\n+        self,\n+        generation_config: GenerationConfig | None = None,\n+        manual_eviction: bool = False,\n+        max_queue_size: int = 0,\n+        num_q_cuda_graphs: int = 0,\n+        num_kv_cuda_graphs: int = 0,\n+        allow_prefix_sharing: bool = True,\n+        block: bool = True,\n+        timeout: float | None = None,\n+    ) -> Generator[ContinuousBatchingManager]:\n+        manager = self.init_continuous_batching(\n+            generation_config,\n+            manual_eviction,\n+            max_queue_size,\n+            num_q_cuda_graphs,\n+            num_kv_cuda_graphs,\n+            allow_prefix_sharing,\n+        )\n         manager.start()\n         try:\n             yield manager\n         finally:\n-            manager.stop(block=True)\n+            logger.debug(\n+                \"Continuous batching loop finished\"\n+            )  # a dummy log needed for the logs of stop to show. Won't show\n+            manager.stop(block=block, timeout=timeout)\n \n+    # NOTE: don't forget to update `continuous_batching_context_manager` when changing this method's definition\n     def init_continuous_batching(\n         self,\n         generation_config: GenerationConfig | None = None,\n@@ -1149,45 +1172,41 @@ def generate_batch(\n             progress_bar = False\n \n         # Initialize manager with the batch inputs\n-        manager = self.init_continuous_batching(\n-            generation_config=generation_config,\n-            num_q_cuda_graphs=num_q_cuda_graphs,\n-            num_kv_cuda_graphs=num_kv_cuda_graphs,\n-            allow_prefix_sharing=allow_prefix_sharing,\n-        )\n-        manager.start()\n         results = {}\n         num_requests = len(inputs)\n-        try:\n-            from tqdm.contrib.logging import logging_redirect_tqdm\n-\n-            with logging_redirect_tqdm([logger]):\n-                with tqdm(\n-                    total=num_requests,\n-                    disable=(not progress_bar),\n-                    desc=f\"Solving {num_requests} requests\",\n-                    unit=\"request\",\n-                ) as pbar:\n-                    manager.add_requests(\n-                        inputs=inputs, max_new_tokens=kwargs.get(\"max_new_tokens\"), record_timestamps=record_timestamps\n-                    )\n-                    finished_count = 0\n-                    while finished_count < num_requests:\n-                        result = manager.get_result(timeout=1)\n-                        if result:\n-                            req_id = result.request_id\n-                            if result.is_finished():\n-                                results[req_id] = result\n-                                finished_count += 1\n-                                pbar.update(1)\n-                        else:\n-                            if not manager.is_running():\n-                                logger.error(\"Generation thread terminated unexpectedly.\")\n-                                break\n+        with (\n+            self.continuous_batching_context_manager(\n+                generation_config=generation_config,\n+                num_q_cuda_graphs=num_q_cuda_graphs,\n+                num_kv_cuda_graphs=num_kv_cuda_graphs,\n+                allow_prefix_sharing=allow_prefix_sharing,\n+                block=True,\n+                timeout=5,\n+            ) as manager,\n+            logging_redirect_tqdm([logger]),\n+            tqdm(\n+                total=num_requests,\n+                disable=(not progress_bar),\n+                desc=f\"Solving {num_requests} requests\",\n+                unit=\"request\",\n+            ) as pbar,\n+        ):\n+            try:\n+                manager.add_requests(inputs=inputs, max_new_tokens=kwargs.get(\"max_new_tokens\"))\n+                finished_count = 0\n+                while finished_count < num_requests:\n+                    result = manager.get_result(timeout=1)\n+                    if result:\n+                        req_id = result.request_id\n+                        if result.is_finished():\n+                            results[req_id] = result\n+                            finished_count += 1\n+                            pbar.update(1)\n+                    else:\n+                        if not manager.is_running():\n+                            logger.error(\"Generation thread terminated unexpectedly.\")\n+                            break\n \n-        except Exception as e:\n-            logger.error(f\"Error during batch generation: {e}\", exc_info=True)\n-        finally:\n-            logger.debug(\"Generate batch is finished.\")  # a dummy log needed for the logs of stop to show. Won't show.\n-            manager.stop(block=True, timeout=5.0)\n+            except Exception as e:\n+                logger.error(f\"Error during batch generation: {e}\", exc_info=True)\n         return results"
        }
    ],
    "stats": {
        "total": 101,
        "additions": 60,
        "deletions": 41
    }
}