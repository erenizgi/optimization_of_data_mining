{
    "author": "Vaibhavs10",
    "message": "purge HF_HUB_ENABLE_HF_TRANSFER; promote Xet (#41656)",
    "sha": "4a43e3d57cde839b7226750879b30d34a5de4598",
    "files": [
        {
            "sha": "1511b4392e6321e3b31adebc64ca41bd1097ffae",
            "filename": "benchmark/benches/llama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4a43e3d57cde839b7226750879b30d34a5de4598/benchmark%2Fbenches%2Fllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4a43e3d57cde839b7226750879b30d34a5de4598/benchmark%2Fbenches%2Fllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/benchmark%2Fbenches%2Fllama.py?ref=4a43e3d57cde839b7226750879b30d34a5de4598",
            "patch": "@@ -42,7 +42,7 @@\n     GenerationConfig = None\n     StaticCache = None\n \n-os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n+os.environ[\"HF_XET_HIGH_PERFORMANCE\"] = \"1\"\n os.environ[\"TOKENIZERS_PARALLELISM\"] = \"1\"\n \n # Only set torch precision if torch is available"
        },
        {
            "sha": "f270d41609239a36d4fa17be624ba978f1cc5184",
            "filename": "benchmark/requirements.txt",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/4a43e3d57cde839b7226750879b30d34a5de4598/benchmark%2Frequirements.txt",
            "raw_url": "https://github.com/huggingface/transformers/raw/4a43e3d57cde839b7226750879b30d34a5de4598/benchmark%2Frequirements.txt",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/benchmark%2Frequirements.txt?ref=4a43e3d57cde839b7226750879b30d34a5de4598",
            "patch": "@@ -2,5 +2,5 @@ gpustat==1.1.1\n psutil==6.0.0\n psycopg2==2.9.9\n torch>=2.4.0\n-hf_transfer\n+hf_xet\n pandas>=1.5.0\n\\ No newline at end of file"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}