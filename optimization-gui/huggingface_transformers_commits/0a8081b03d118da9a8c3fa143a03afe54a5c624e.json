{
    "author": "kylesayrs",
    "message": "[Modeling] Fix encoder CPU offloading for whisper (#38994)\n\n* fix cpu offloading for whisper\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n* unskip offloading tests\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n* revert small change\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n* remove tests\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>\n\n---------\n\nSigned-off-by: Kyle Sayers <kylesayrs@gmail.com>",
    "sha": "0a8081b03d118da9a8c3fa143a03afe54a5c624e",
    "files": [
        {
            "sha": "d3e9c8e03a2b049e4e5fce93e70ec6e03a52e6a2",
            "filename": "src/transformers/models/whisper/modeling_whisper.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a8081b03d118da9a8c3fa143a03afe54a5c624e/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a8081b03d118da9a8c3fa143a03afe54a5c624e/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fwhisper%2Fmodeling_whisper.py?ref=0a8081b03d118da9a8c3fa143a03afe54a5c624e",
            "patch": "@@ -687,9 +687,9 @@ def forward(\n         inputs_embeds = nn.functional.gelu(self.conv2(inputs_embeds))\n \n         inputs_embeds = inputs_embeds.permute(0, 2, 1)\n-        embed_pos = self.embed_positions.weight\n+        all_positions = torch.arange(self.embed_positions.num_embeddings, device=inputs_embeds.device)\n \n-        hidden_states = inputs_embeds + embed_pos\n+        hidden_states = inputs_embeds + self.embed_positions(all_positions)\n         hidden_states = nn.functional.dropout(hidden_states, p=self.dropout, training=self.training)\n \n         encoder_states = () if output_hidden_states else None"
        },
        {
            "sha": "1b4641f5d49bb815ed97eac18e495d83342431f2",
            "filename": "tests/models/whisper/test_modeling_whisper.py",
            "status": "modified",
            "additions": 0,
            "deletions": 16,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/0a8081b03d118da9a8c3fa143a03afe54a5c624e/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/0a8081b03d118da9a8c3fa143a03afe54a5c624e/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fwhisper%2Ftest_modeling_whisper.py?ref=0a8081b03d118da9a8c3fa143a03afe54a5c624e",
            "patch": "@@ -3356,22 +3356,6 @@ def test_forward_pass_weighted_layer_sum(self):\n         config_and_inputs = self.model_tester.prepare_config_and_inputs()\n         self.model_tester.create_and_check_model_forward(*config_and_inputs, use_weighted_layer_sum=True)\n \n-    @unittest.skip(reason=\"Some undefined behavior encountered with tiny versions of this model. Skip for now.\")\n-    def test_cpu_offload(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Some undefined behavior encountered with tiny versions of this model. Skip for now.\")\n-    def test_disk_offload_bin(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Some undefined behavior encountered with tiny versions of this model. Skip for now.\")\n-    def test_disk_offload_safetensors(self):\n-        pass\n-\n-    @unittest.skip(reason=\"Some undefined behavior encountered with tiny versions of this model. Skip for now.\")\n-    def test_model_parallelism(self):\n-        pass\n-\n     @unittest.skip(reason=\"Not applicable for an encoder-only acoustic model\")\n     def test_inputs_embeds(self):\n         # input embeds is meaningless for an encoder-only acoustic model"
        }
    ],
    "stats": {
        "total": 20,
        "additions": 2,
        "deletions": 18
    }
}