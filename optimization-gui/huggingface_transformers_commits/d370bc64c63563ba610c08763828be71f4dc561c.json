{
    "author": "kaln27",
    "message": "Fix errors when use verl to train GLM4.1v model (#39199)\n\n* Fix errors when use verl to train GLM4.1v model\n\n* Support glm4v load from AutoModelForVision2Seq\n* Set glm4v model _checkpoint_conversion_mapping attr from None to {}\n\n* Update modeling_auto.py",
    "sha": "d370bc64c63563ba610c08763828be71f4dc561c",
    "files": [
        {
            "sha": "3bbfb57c82885e4924e8f7efcc11078afc411075",
            "filename": "src/transformers/models/glm4v/modeling_glm4v.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d370bc64c63563ba610c08763828be71f4dc561c/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d370bc64c63563ba610c08763828be71f4dc561c/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodeling_glm4v.py?ref=d370bc64c63563ba610c08763828be71f4dc561c",
            "patch": "@@ -949,7 +949,7 @@ def forward(\n @auto_docstring\n class Glm4vModel(Glm4vPreTrainedModel):\n     base_model_prefix = \"\"\n-    _checkpoint_conversion_mapping = None\n+    _checkpoint_conversion_mapping = {}\n     config_class = Glm4vConfig\n     _no_split_modules = [\"Glm4vTextDecoderLayer\", \"Glm4vVisionBlock\"]\n \n@@ -1382,7 +1382,7 @@ class Glm4vCausalLMOutputWithPast(ModelOutput):\n \n \n class Glm4vForConditionalGeneration(Glm4vPreTrainedModel, GenerationMixin):\n-    _checkpoint_conversion_mapping = None\n+    _checkpoint_conversion_mapping = {}\n     _tied_weights_keys = [\"lm_head.weight\"]\n \n     def __init__(self, config):"
        },
        {
            "sha": "4b8ef1754b1bab937ab7067c4833ca045d600362",
            "filename": "src/transformers/models/glm4v/modular_glm4v.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/d370bc64c63563ba610c08763828be71f4dc561c/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d370bc64c63563ba610c08763828be71f4dc561c/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v%2Fmodular_glm4v.py?ref=d370bc64c63563ba610c08763828be71f4dc561c",
            "patch": "@@ -1001,7 +1001,7 @@ def forward(\n \n \n class Glm4vModel(Qwen2_5_VLModel):\n-    _checkpoint_conversion_mapping = None\n+    _checkpoint_conversion_mapping = {}\n     _no_split_modules = [\"Glm4vTextDecoderLayer\", \"Glm4vVisionBlock\"]\n \n     def __init__(self, config):\n@@ -1356,7 +1356,7 @@ class Glm4vCausalLMOutputWithPast(Qwen2_5_VLCausalLMOutputWithPast):\n \n \n class Glm4vForConditionalGeneration(Qwen2_5_VLForConditionalGeneration):\n-    _checkpoint_conversion_mapping = None\n+    _checkpoint_conversion_mapping = {}\n \n     def forward(\n         self,"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}