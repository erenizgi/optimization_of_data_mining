{
    "author": "faaany",
    "message": "[docs] refine the doc for `train with a script` (#33423)\n\n* add xpu note\r\n\r\n* add one more case\r\n\r\n* add more\r\n\r\n* Update docs/source/en/run_scripts.md\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Steven Liu <59462357+stevhliu@users.noreply.github.com>",
    "sha": "a05ce550bf1cda8ae3bffcc62607597770460a42",
    "files": [
        {
            "sha": "b7a895591970c37474540548df3fb9c9c697703b",
            "filename": "docs/source/en/run_scripts.md",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Frun_scripts.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Frun_scripts.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Frun_scripts.md?ref=a05ce550bf1cda8ae3bffcc62607597770460a42",
            "patch": "@@ -126,7 +126,7 @@ python examples/tensorflow/summarization/run_summarization.py  \\\n \n The [Trainer](https://huggingface.co/docs/transformers/main_classes/trainer) supports distributed training and mixed precision, which means you can also use it in a script. To enable both of these features:\n \n-- Add the `fp16` argument to enable mixed precision.\n+- Add the `fp16` or `bf16` argument to enable mixed precision. XPU devices only supports `bf16` for mixed precision training.\n - Set the number of GPUs to use with the `nproc_per_node` argument.\n \n ```bash\n@@ -287,7 +287,7 @@ Another helpful option to enable is resuming training from a previous checkpoint\n The first method uses the `output_dir previous_output_dir` argument to resume training from the latest checkpoint stored in `output_dir`. In this case, you should remove `overwrite_output_dir`:\n \n ```bash\n-python examples/pytorch/summarization/run_summarization.py\n+python examples/pytorch/summarization/run_summarization.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\\n@@ -304,7 +304,7 @@ python examples/pytorch/summarization/run_summarization.py\n The second method uses the `resume_from_checkpoint path_to_specific_checkpoint` argument to resume training from a specific checkpoint folder.\n \n ```bash\n-python examples/pytorch/summarization/run_summarization.py\n+python examples/pytorch/summarization/run_summarization.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\\n@@ -334,7 +334,7 @@ To give your repository a specific name, use the `push_to_hub_model_id` argument\n The following example shows how to upload a model with a specific repository name:\n \n ```bash\n-python examples/pytorch/summarization/run_summarization.py\n+python examples/pytorch/summarization/run_summarization.py \\\n     --model_name_or_path google-t5/t5-small \\\n     --do_train \\\n     --do_eval \\"
        },
        {
            "sha": "b79415996ca72e0c37f7a7dbfc50fac04dc23bd9",
            "filename": "docs/source/en/tasks/summarization.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Ftasks%2Fsummarization.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Ftasks%2Fsummarization.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Fsummarization.md?ref=a05ce550bf1cda8ae3bffcc62607597770460a42",
            "patch": "@@ -205,7 +205,7 @@ At this point, only three steps remain:\n ...     save_total_limit=3,\n ...     num_train_epochs=4,\n ...     predict_with_generate=True,\n-...     fp16=True,\n+...     fp16=True, #change to bf16=True for XPU\n ...     push_to_hub=True,\n ... )\n "
        },
        {
            "sha": "a4b544fe68a3205efd4bcabbafedad4068a82a1e",
            "filename": "docs/source/en/tasks/translation.md",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Ftasks%2Ftranslation.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/a05ce550bf1cda8ae3bffcc62607597770460a42/docs%2Fsource%2Fen%2Ftasks%2Ftranslation.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Ftasks%2Ftranslation.md?ref=a05ce550bf1cda8ae3bffcc62607597770460a42",
            "patch": "@@ -212,7 +212,7 @@ At this point, only three steps remain:\n ...     save_total_limit=3,\n ...     num_train_epochs=2,\n ...     predict_with_generate=True,\n-...     fp16=True,\n+...     fp16=True, #change to bf16=True for XPU\n ...     push_to_hub=True,\n ... )\n "
        }
    ],
    "stats": {
        "total": 12,
        "additions": 6,
        "deletions": 6
    }
}