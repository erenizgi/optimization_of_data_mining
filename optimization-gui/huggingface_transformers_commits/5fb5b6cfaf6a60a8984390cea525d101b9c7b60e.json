{
    "author": "SunMarc",
    "message": "Fix quant docker for fp-quant  (#39641)\n\n* fix quant docker\n\n* Apply style fixes\n\n---------\n\nCo-authored-by: Mohamed Mekkouri <93391238+MekkCyber@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>",
    "sha": "5fb5b6cfaf6a60a8984390cea525d101b9c7b60e",
    "files": [
        {
            "sha": "deb6761db8e09598dc1d08045418f26dd2abc7bf",
            "filename": "docker/transformers-quantization-latest-gpu/Dockerfile",
            "status": "modified",
            "additions": 2,
            "deletions": 1,
            "changes": 3,
            "blob_url": "https://github.com/huggingface/transformers/blob/5fb5b6cfaf6a60a8984390cea525d101b9c7b60e/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "raw_url": "https://github.com/huggingface/transformers/raw/5fb5b6cfaf6a60a8984390cea525d101b9c7b60e/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docker%2Ftransformers-quantization-latest-gpu%2FDockerfile?ref=5fb5b6cfaf6a60a8984390cea525d101b9c7b60e",
            "patch": "@@ -79,7 +79,8 @@ RUN git clone https://github.com/NetEase-FuXi/EETQ.git && cd EETQ/ && git submod\n # RUN python3 -m pip install --no-cache-dir git+https://github.com/Dao-AILab/fast-hadamard-transform.git\n \n # Add fp-quant for quantization testing\n-RUN python3 -m pip install --no-cache-dir \"fp-quant>=0.1.6\"\n+# Requires py3.11 but our CI runs on 3.9\n+# RUN python3 -m pip install --no-cache-dir \"fp-quant>=0.1.6\"\n \n # Add compressed-tensors for quantization testing\n RUN python3 -m pip install --no-cache-dir compressed-tensors"
        }
    ],
    "stats": {
        "total": 3,
        "additions": 2,
        "deletions": 1
    }
}