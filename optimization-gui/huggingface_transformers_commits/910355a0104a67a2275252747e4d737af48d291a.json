{
    "author": "leopardracer",
    "message": "Fix Typos in Comments: \"quantitation\" → \"quantization\", \"averege\" → \"average\" (#38766)\n\n* Update convert_llama4_weights_to_hf.py\n\n* Update modeling_visual_bert.py",
    "sha": "910355a0104a67a2275252747e4d737af48d291a",
    "files": [
        {
            "sha": "5e68e6ade65ecb21073d90de558be1f0cb0c7873",
            "filename": "src/transformers/models/llama4/convert_llama4_weights_to_hf.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/910355a0104a67a2275252747e4d737af48d291a/src%2Ftransformers%2Fmodels%2Fllama4%2Fconvert_llama4_weights_to_hf.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/910355a0104a67a2275252747e4d737af48d291a/src%2Ftransformers%2Fmodels%2Fllama4%2Fconvert_llama4_weights_to_hf.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fconvert_llama4_weights_to_hf.py?ref=910355a0104a67a2275252747e4d737af48d291a",
            "patch": "@@ -421,7 +421,7 @@ def write_model(\n                 tqdm.write(f\"Processing: {key.ljust(50)}  ->\\t {v}, {values.shape}\")\n                 state_dict[v] = values\n             elif _OFFLINE_QUANT_COMPATIBLE and \"feed_forward.experts.\" in new_key:\n-                # for experts, we need to split expert for offline quantiation purpose and don't need to fuse\n+                # for experts, we need to split expert for offline quantization purpose and don't need to fuse\n                 expert_lists = []\n                 for k in current_parameter:\n                     expert_lists.append("
        },
        {
            "sha": "da46d412e62a0097cf192e207e20f9de1fa638de",
            "filename": "src/transformers/models/visual_bert/modeling_visual_bert.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/910355a0104a67a2275252747e4d737af48d291a/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fmodeling_visual_bert.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/910355a0104a67a2275252747e4d737af48d291a/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fmodeling_visual_bert.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvisual_bert%2Fmodeling_visual_bert.py?ref=910355a0104a67a2275252747e4d737af48d291a",
            "patch": "@@ -131,7 +131,7 @@ def forward(\n                 visual_position_embeddings *= image_text_alignment_mask.to(dtype=dtype).unsqueeze(-1)\n                 visual_position_embeddings = visual_position_embeddings.sum(2)\n \n-                # We want to averge along the alignment_number dimension.\n+                # We want to average along the alignment_number dimension.\n                 image_text_alignment_mask = image_text_alignment_mask.to(dtype=dtype).sum(2)\n \n                 if (image_text_alignment_mask == 0).sum() != 0:"
        }
    ],
    "stats": {
        "total": 4,
        "additions": 2,
        "deletions": 2
    }
}