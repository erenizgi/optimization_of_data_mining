{
    "author": "Cyrilvallez",
    "message": "[tests] Really use small models in all fast tests (#40945)\n\n* start\n\n* xcodec\n\n* chameleon\n\n* start\n\n* layoutlm2\n\n* layoutlm\n\n* remove skip\n\n* oups\n\n* timm_wrapper\n\n* add default\n\n* doc\n\n* consistency",
    "sha": "dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
    "files": [
        {
            "sha": "b0f7c590650f43c1b5ef8dd0bff0d217a29d66a6",
            "filename": "src/transformers/models/gemma3n/configuration_gemma3n.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fconfiguration_gemma3n.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fconfiguration_gemma3n.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3n%2Fconfiguration_gemma3n.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -502,10 +502,10 @@ def __init__(\n         **kwargs,\n     ):\n         super().__init__(**kwargs)\n+        self.architecture = architecture\n         self.initializer_range = initializer_range\n         self.do_pooling = do_pooling\n         self.model_args = model_args  # named \"model_args\" for BC with timm\n-        self.architecture = architecture\n         self.hidden_size = hidden_size\n         self.vocab_size = vocab_size\n         self.vocab_offset = vocab_offset"
        },
        {
            "sha": "24142232241f9a7a20b8fa081f63bae70b0abcd2",
            "filename": "src/transformers/models/timm_wrapper/configuration_timm_wrapper.py",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ftimm_wrapper%2Fconfiguration_timm_wrapper.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -41,6 +41,8 @@ class TimmWrapperConfig(PretrainedConfig):\n     imagenet models is set to `None` due to occlusions in the label descriptions.\n \n     Args:\n+        architecture (`str`, *optional*, defaults to `\"resnet50\"`):\n+            The timm architecture to load.\n         initializer_range (`float`, *optional*, defaults to 0.02):\n             The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n         do_pooling (`bool`, *optional*, defaults to `True`):\n@@ -65,11 +67,13 @@ class TimmWrapperConfig(PretrainedConfig):\n \n     def __init__(\n         self,\n+        architecture: str = \"resnet50\",\n         initializer_range: float = 0.02,\n         do_pooling: bool = True,\n         model_args: Optional[dict[str, Any]] = None,\n         **kwargs,\n     ):\n+        self.architecture = architecture\n         self.initializer_range = initializer_range\n         self.do_pooling = do_pooling\n         self.model_args = model_args  # named \"model_args\" for BC with timm"
        },
        {
            "sha": "ecf873182234d2c08183b38a93b01d53c12dd138",
            "filename": "tests/models/chameleon/test_modeling_chameleon.py",
            "status": "modified",
            "additions": 1,
            "deletions": 9,
            "changes": 10,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fchameleon%2Ftest_modeling_chameleon.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -76,7 +76,7 @@ def __init__(\n         pad_token_id=0,\n         vq_num_embeds=5,\n         vq_embed_dim=5,\n-        vq_channel_multiplier=[1, 4],\n+        vq_channel_multiplier=[1, 2],\n         vq_img_token_start_id=10,  # has to be less than vocab size when added with vq_num_embeds\n         scope=None,\n     ):\n@@ -255,10 +255,6 @@ def test_model_rope_scaling(self, scaling_type):\n     def test_batching_equivalence(self):\n         pass\n \n-    @unittest.skip(\"Chameleon VQ model cannot be squishes more due to hardcoded layer params in model code\")\n-    def test_model_is_small(self):\n-        pass\n-\n \n class ChameleonVision2SeqModelTester(ChameleonModelTester):\n     def __init__(self, parent, image_size=10, **kwargs):\n@@ -321,10 +317,6 @@ def test_disk_offload_bin(self):\n     def test_disk_offload_safetensors(self):\n         pass\n \n-    @unittest.skip(\"Chameleon VQ model cannot be squishes more due to hardcoded layer params in model code\")\n-    def test_model_is_small(self):\n-        pass\n-\n     @unittest.skip(\"Chameleon applies key/query norm which doesn't work with packing\")\n     def test_flash_attention_2_padding_matches_padding_free_with_position_ids(self):\n         pass"
        },
        {
            "sha": "1bef4585414df3b6af86c56a3201f3d59c6d040e",
            "filename": "tests/models/emu3/test_modeling_emu3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Femu3%2Ftest_modeling_emu3.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -359,10 +359,6 @@ def test_initialization(self):\n     def test_generate_with_static_cache(self):\n         pass\n \n-    # @unittest.skip(\"Emu3 can't be smaller than currently if we want to downsample images\")\n-    # def test_model_is_small(self):\n-    #     pass\n-\n \n @require_torch\n class Emu3IntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "2c1b157e3a90d160a5880a3890cbc7ff4e0aa410",
            "filename": "tests/models/layoutlmv2/test_modeling_layoutlmv2.py",
            "status": "modified",
            "additions": 10,
            "deletions": 10,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flayoutlmv2%2Ftest_modeling_layoutlmv2.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -70,7 +70,7 @@ def __init__(\n         type_vocab_size=16,\n         type_sequence_label_size=2,\n         initializer_range=0.02,\n-        image_feature_pool_shape=[7, 7, 256],\n+        image_feature_pool_shape=[7, 7, 32],\n         coordinate_size=6,\n         shape_size=6,\n         num_labels=3,\n@@ -106,6 +106,14 @@ def __init__(\n         self.num_choices = num_choices\n         self.scope = scope\n         self.range_bbox = range_bbox\n+        detectron2_config = LayoutLMv2Config.get_default_detectron2_config()\n+        # We need to make the model smaller\n+        detectron2_config[\"MODEL.RESNETS.DEPTH\"] = 50\n+        detectron2_config[\"MODEL.RESNETS.RES2_OUT_CHANNELS\"] = 4\n+        detectron2_config[\"MODEL.RESNETS.STEM_OUT_CHANNELS\"] = 4\n+        detectron2_config[\"MODEL.FPN.OUT_CHANNELS\"] = 32\n+        detectron2_config[\"MODEL.RESNETS.NUM_GROUPS\"] = 1\n+        self.detectron2_config = detectron2_config\n \n     def prepare_config_and_inputs(self):\n         input_ids = ids_tensor([self.batch_size, self.seq_length], self.vocab_size)\n@@ -158,13 +166,9 @@ def prepare_config_and_inputs(self):\n             image_feature_pool_shape=self.image_feature_pool_shape,\n             coordinate_size=self.coordinate_size,\n             shape_size=self.shape_size,\n+            detectron2_config_args=self.detectron2_config,\n         )\n \n-        # use smaller resnet backbone to make tests faster\n-        config.detectron2_config_args[\"MODEL.RESNETS.DEPTH\"] = 18\n-        config.detectron2_config_args[\"MODEL.RESNETS.RES2_OUT_CHANNELS\"] = 64\n-        config.detectron2_config_args[\"MODEL.RESNETS.NUM_GROUPS\"] = 1\n-\n         return config, input_ids, bbox, image, token_type_ids, input_mask, sequence_labels, token_labels\n \n     def create_and_check_model(\n@@ -422,10 +426,6 @@ def check_hidden_states_output(inputs_dict, config, model_class):\n \n             check_hidden_states_output(inputs_dict, config, model_class)\n \n-    @unittest.skip(reason=\"We cannot configure detectron2 to output a smaller backbone\")\n-    def test_model_is_small(self):\n-        pass\n-\n     @slow\n     def test_model_from_pretrained(self):\n         model_name = \"microsoft/layoutlmv2-base-uncased\""
        },
        {
            "sha": "650f8b05d3b1179381724f2d303b977a8b04587d",
            "filename": "tests/models/qwen2_5_vl/test_modeling_qwen2_5_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_5_vl%2Ftest_modeling_qwen2_5_vl.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -441,10 +441,6 @@ def test_sdpa_can_dispatch_on_flash(self):\n     def test_multi_gpu_data_parallel_forward(self):\n         pass\n \n-    @unittest.skip(reason=\"We cannot configure to output a smaller model.\")\n-    def test_model_is_small(self):\n-        pass\n-\n \n @require_torch\n class Qwen2_5_VLIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "ef109fb7cca78224d92ab61d66666633ea03091b",
            "filename": "tests/models/qwen2_vl/test_modeling_qwen2_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_vl%2Ftest_modeling_qwen2_vl.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -394,10 +394,6 @@ def test_sdpa_can_dispatch_on_flash(self):\n     def test_multi_gpu_data_parallel_forward(self):\n         pass\n \n-    @unittest.skip(reason=\"We cannot configure to output a smaller model.\")\n-    def test_model_is_small(self):\n-        pass\n-\n \n @require_torch\n class Qwen2VLIntegrationTest(unittest.TestCase):"
        },
        {
            "sha": "8715aaaae7d00e6afa18ceeb8fb6e1aec467f122",
            "filename": "tests/models/timm_wrapper/test_modeling_timm_wrapper.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Ftimm_wrapper%2Ftest_modeling_timm_wrapper.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -53,14 +53,15 @@ class TimmWrapperModelTester:\n     def __init__(\n         self,\n         parent,\n-        model_name=\"timm/resnet18.a1_in1k\",\n         batch_size=3,\n         image_size=32,\n         num_channels=3,\n         is_training=True,\n     ):\n         self.parent = parent\n-        self.model_name = model_name\n+        self.architecture = \"resnet26\"\n+        # We need this to make the model smaller\n+        self.model_args = {\"channels\": (16, 16, 16, 16)}\n         self.batch_size = batch_size\n         self.image_size = image_size\n         self.num_channels = num_channels\n@@ -73,7 +74,7 @@ def prepare_config_and_inputs(self):\n         return config, pixel_values\n \n     def get_config(self):\n-        return TimmWrapperConfig.from_pretrained(self.model_name)\n+        return TimmWrapperConfig(architecture=self.architecture, model_args=self.model_args)\n \n     def prepare_config_and_inputs_for_common(self):\n         config_and_inputs = self.prepare_config_and_inputs()\n@@ -166,10 +167,6 @@ def test_initialization(self):\n     def test_mismatched_shapes_have_properly_initialized_weights(self):\n         pass\n \n-    @unittest.skip(reason=\"Need to use a timm model and there is no tiny model available.\")\n-    def test_model_is_small(self):\n-        pass\n-\n     def test_gradient_checkpointing(self):\n         config, _ = self.model_tester.prepare_config_and_inputs_for_common()\n         model = TimmWrapperModel._from_config(config)"
        },
        {
            "sha": "79a9fdd6e484eabfe091d5db5656516f0b43bde5",
            "filename": "tests/models/xcodec/test_modeling_xcodec.py",
            "status": "modified",
            "additions": 14,
            "deletions": 6,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/dd7ac4cd59563d455c9f700cc9119b2f79f8a865/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fxcodec%2Ftest_modeling_xcodec.py?ref=dd7ac4cd59563d455c9f700cc9119b2f79f8a865",
            "patch": "@@ -39,7 +39,7 @@\n if is_torch_available():\n     import torch\n \n-    from transformers import XcodecModel\n+    from transformers import DacConfig, HubertConfig, XcodecModel\n \n \n @require_torch\n@@ -51,7 +51,7 @@ def __init__(\n         num_channels=1,\n         sample_rate=16000,\n         codebook_size=1024,\n-        num_samples=400,\n+        num_samples=256,\n         is_training=False,\n     ):\n         self.parent = parent\n@@ -61,6 +61,16 @@ def __init__(\n         self.codebook_size = codebook_size\n         self.is_training = is_training\n         self.num_samples = num_samples\n+        self.acoustic_model_config = DacConfig(\n+            decoder_hidden_size=8, encoder_hidden_size=8, codebook_size=16, downsampling_ratios=[16, 16]\n+        )\n+        self.semantic_model_config = HubertConfig(\n+            hidden_size=32,\n+            num_hidden_layers=2,\n+            num_attention_heads=2,\n+            intermediate_size=12,\n+            conv_dim=(4, 4, 4, 4, 4, 4, 4),\n+        )\n \n     def prepare_config_and_inputs(self):\n         config = self.get_config()\n@@ -86,6 +96,8 @@ def get_config(self):\n             sample_rate=self.sample_rate,\n             audio_channels=self.num_channels,\n             codebook_size=self.codebook_size,\n+            acoustic_model_config=self.acoustic_model_config,\n+            semantic_model_config=self.semantic_model_config,\n         )\n \n     def create_and_check_model_forward(self, config, inputs_dict):\n@@ -151,10 +163,6 @@ def test_gradient_checkpointing_backward_compatibility(self):\n             model = model_class(config)\n             self.assertTrue(model.is_gradient_checkpointing)\n \n-    @unittest.skip(reason=\"We cannot configure to output a smaller model.\")\n-    def test_model_is_small(self):\n-        pass\n-\n     @unittest.skip(reason=\"The XcodecModel does not have `inputs_embeds` logics\")\n     def test_inputs_embeds(self):\n         pass"
        }
    ],
    "stats": {
        "total": 79,
        "additions": 34,
        "deletions": 45
    }
}