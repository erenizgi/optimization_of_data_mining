{
    "author": "i3hz",
    "message": "Correct numerical regression in vision embeddings (#41374)\n\ncreated modeling file",
    "sha": "4763b8c5b87a3e62cab599cafc7f553f8375290a",
    "files": [
        {
            "sha": "1017afb4567e68f16b37d094013fb32cf2f619fa",
            "filename": "src/transformers/models/idefics2/modeling_idefics2.py",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fmodeling_idefics2.py?ref=4763b8c5b87a3e62cab599cafc7f553f8375290a",
            "patch": "@@ -151,11 +151,19 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=pixel_values.dtype)\n+            step_h = 1.0 / nb_patches_h\n+            step_w = 1.0 / nb_patches_w\n \n-            fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n-            fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=torch.float32)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=torch.float32)\n+            fractional_coords_h = h_indices * step_h\n+            fractional_coords_w = w_indices * step_w\n+\n+            fractional_coords_h = torch.clamp(fractional_coords_h, max=(1.0 - 1e-6))\n+            fractional_coords_w = torch.clamp(fractional_coords_w, max=(1.0 - 1e-6))\n+\n+            fractional_coords_h = fractional_coords_h.to(pixel_values.dtype)\n+            fractional_coords_w = fractional_coords_w.to(pixel_values.dtype)\n \n             bucket_coords_h = torch.bucketize(fractional_coords_h, boundaries, right=True)\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)"
        },
        {
            "sha": "0829de53385fae60a7f96e0bc0cf392da9844370",
            "filename": "src/transformers/models/idefics3/modeling_idefics3.py",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fmodeling_idefics3.py?ref=4763b8c5b87a3e62cab599cafc7f553f8375290a",
            "patch": "@@ -149,11 +149,19 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=pixel_values.dtype)\n+            step_h = 1.0 / nb_patches_h\n+            step_w = 1.0 / nb_patches_w\n \n-            fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n-            fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=torch.float32)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=torch.float32)\n+            fractional_coords_h = h_indices * step_h\n+            fractional_coords_w = w_indices * step_w\n+\n+            fractional_coords_h = torch.clamp(fractional_coords_h, max=(1.0 - 1e-6))\n+            fractional_coords_w = torch.clamp(fractional_coords_w, max=(1.0 - 1e-6))\n+\n+            fractional_coords_h = fractional_coords_h.to(pixel_values.dtype)\n+            fractional_coords_w = fractional_coords_w.to(pixel_values.dtype)\n \n             bucket_coords_h = torch.bucketize(fractional_coords_h, boundaries, right=True)\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)"
        },
        {
            "sha": "8ae07bb3d8b1d17a1c56fbe418c5a7241bd0350f",
            "filename": "src/transformers/models/smolvlm/modeling_smolvlm.py",
            "status": "modified",
            "additions": 12,
            "deletions": 4,
            "changes": 16,
            "blob_url": "https://github.com/huggingface/transformers/blob/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/4763b8c5b87a3e62cab599cafc7f553f8375290a/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fmodeling_smolvlm.py?ref=4763b8c5b87a3e62cab599cafc7f553f8375290a",
            "patch": "@@ -147,11 +147,19 @@ def forward(self, pixel_values: torch.FloatTensor, patch_attention_mask: torch.B\n             nb_patches_h = p_attn_mask[:, 0].sum()\n             nb_patches_w = p_attn_mask[0].sum()\n \n-            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=pixel_values.dtype)\n-            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=pixel_values.dtype)\n+            step_h = 1.0 / nb_patches_h\n+            step_w = 1.0 / nb_patches_w\n \n-            fractional_coords_h = h_indices / nb_patches_h * (1 - 1e-6)\n-            fractional_coords_w = w_indices / nb_patches_w * (1 - 1e-6)\n+            h_indices = torch.arange(nb_patches_h, device=position_ids.device, dtype=torch.float32)\n+            w_indices = torch.arange(nb_patches_w, device=position_ids.device, dtype=torch.float32)\n+            fractional_coords_h = h_indices * step_h\n+            fractional_coords_w = w_indices * step_w\n+\n+            fractional_coords_h = torch.clamp(fractional_coords_h, max=(1.0 - 1e-6))\n+            fractional_coords_w = torch.clamp(fractional_coords_w, max=(1.0 - 1e-6))\n+\n+            fractional_coords_h = fractional_coords_h.to(pixel_values.dtype)\n+            fractional_coords_w = fractional_coords_w.to(pixel_values.dtype)\n \n             bucket_coords_h = torch.bucketize(fractional_coords_h, boundaries, right=True)\n             bucket_coords_w = torch.bucketize(fractional_coords_w, boundaries, right=True)"
        }
    ],
    "stats": {
        "total": 48,
        "additions": 36,
        "deletions": 12
    }
}