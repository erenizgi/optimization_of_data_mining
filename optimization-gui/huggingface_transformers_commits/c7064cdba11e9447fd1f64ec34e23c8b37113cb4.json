{
    "author": "yao-matrix",
    "message": "enhance require_deterministic_for_xpu (#37437)\n\n* enhance require_deterministic_for_xpu\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n* fix style\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>\n\n---------\n\nSigned-off-by: YAO Matrix <matrix.yao@intel.com>",
    "sha": "c7064cdba11e9447fd1f64ec34e23c8b37113cb4",
    "files": [
        {
            "sha": "48d4cd30ed67a37e9f5d2f8cf0101b985ef89df6",
            "filename": "src/transformers/testing_utils.py",
            "status": "modified",
            "additions": 13,
            "deletions": 7,
            "changes": 20,
            "blob_url": "https://github.com/huggingface/transformers/blob/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/src%2Ftransformers%2Ftesting_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/src%2Ftransformers%2Ftesting_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Ftesting_utils.py?ref=c7064cdba11e9447fd1f64ec34e23c8b37113cb4",
            "patch": "@@ -139,7 +139,6 @@\n     is_torch_available,\n     is_torch_bf16_available_on_device,\n     is_torch_bf16_gpu_available,\n-    is_torch_deterministic,\n     is_torch_fp16_available_on_device,\n     is_torch_greater_or_equal,\n     is_torch_hpu_available,\n@@ -1073,12 +1072,19 @@ def require_torch_bf16_gpu(test_case):\n \n \n def require_deterministic_for_xpu(test_case):\n-    if is_torch_xpu_available():\n-        return unittest.skipUnless(is_torch_deterministic(), \"test requires torch to use deterministic algorithms\")(\n-            test_case\n-        )\n-    else:\n-        return test_case\n+    @wraps(test_case)\n+    def wrapper(*args, **kwargs):\n+        if is_torch_xpu_available():\n+            original_state = torch.are_deterministic_algorithms_enabled()\n+            try:\n+                torch.use_deterministic_algorithms(True)\n+                return test_case(*args, **kwargs)\n+            finally:\n+                torch.use_deterministic_algorithms(original_state)\n+        else:\n+            return test_case(*args, **kwargs)\n+\n+    return wrapper\n \n \n def require_torch_tf32(test_case):"
        },
        {
            "sha": "a5f7afb16fcc8921dcdf5a5002ac3708e4ed4654",
            "filename": "tests/models/encoder_decoder/test_modeling_encoder_decoder.py",
            "status": "modified",
            "additions": 2,
            "deletions": 0,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/tests%2Fmodels%2Fencoder_decoder%2Ftest_modeling_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/tests%2Fmodels%2Fencoder_decoder%2Ftest_modeling_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fencoder_decoder%2Ftest_modeling_encoder_decoder.py?ref=c7064cdba11e9447fd1f64ec34e23c8b37113cb4",
            "patch": "@@ -936,6 +936,7 @@ def prepare_config_and_inputs(self):\n         }\n \n     @slow\n+    @require_deterministic_for_xpu\n     def test_roberta2roberta_summarization(self):\n         model = EncoderDecoderModel.from_pretrained(\"google/roberta2roberta_L-24_bbc\")\n         model.to(torch_device)\n@@ -1080,6 +1081,7 @@ def test_encoder_decoder_model_shared_weights(self):\n         pass\n \n     @slow\n+    @require_deterministic_for_xpu\n     def test_bert2gpt2_summarization(self):\n         model = EncoderDecoderModel.from_pretrained(\"patrickvonplaten/bert2gpt2-cnn_dailymail-fp16\")\n "
        },
        {
            "sha": "7ac8d5631d2041f62b0e5716c0755ae77e3c6de7",
            "filename": "tests/models/speech_encoder_decoder/test_modeling_speech_encoder_decoder.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/tests%2Fmodels%2Fspeech_encoder_decoder%2Ftest_modeling_speech_encoder_decoder.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/c7064cdba11e9447fd1f64ec34e23c8b37113cb4/tests%2Fmodels%2Fspeech_encoder_decoder%2Ftest_modeling_speech_encoder_decoder.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fspeech_encoder_decoder%2Ftest_modeling_speech_encoder_decoder.py?ref=c7064cdba11e9447fd1f64ec34e23c8b37113cb4",
            "patch": "@@ -634,6 +634,7 @@ def prepare_config_and_inputs(self):\n     def test_encoder_decoder_model_from_pretrained_configs(self):\n         pass\n \n+    @require_deterministic_for_xpu\n     @unittest.skip(reason=\"Cannot save full model as Speech2TextModel != Speech2TextEncoder\")\n     def test_save_and_load_from_pretrained(self):\n         pass"
        }
    ],
    "stats": {
        "total": 23,
        "additions": 16,
        "deletions": 7
    }
}