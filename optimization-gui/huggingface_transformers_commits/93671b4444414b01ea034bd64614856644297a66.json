{
    "author": "ankke",
    "message": "Swap columns and rows of the grid layout in LFM2-VL (#41755)\n\n* swap columns and rows of the grid layout\n\n* update integration tests\n\n* fix the test case\n\n* revert batched test change",
    "sha": "93671b4444414b01ea034bd64614856644297a66",
    "files": [
        {
            "sha": "c5623bc6b3e1608502ed3ffd61233ac7e65c4754",
            "filename": "src/transformers/models/lfm2_vl/image_processing_lfm2_vl_fast.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93671b4444414b01ea034bd64614856644297a66/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fimage_processing_lfm2_vl_fast.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93671b4444414b01ea034bd64614856644297a66/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fimage_processing_lfm2_vl_fast.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2_vl%2Fimage_processing_lfm2_vl_fast.py?ref=93671b4444414b01ea034bd64614856644297a66",
            "patch": "@@ -391,7 +391,7 @@ def resize_and_split(\n \n         # Big image will be cropped into patches and small images are just resized\n         if is_image_large and do_image_splitting:\n-            images, num_rows, num_cols = self.crop_image_to_patches(\n+            images, num_cols, num_rows = self.crop_image_to_patches(\n                 images,\n                 min_tiles=min_tiles,\n                 max_tiles=max_tiles,"
        },
        {
            "sha": "d43f87c5c8724b8cee6021c80381b22429afbe0d",
            "filename": "tests/models/lfm2_vl/test_modeling_lfm2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93671b4444414b01ea034bd64614856644297a66/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93671b4444414b01ea034bd64614856644297a66/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flfm2_vl%2Ftest_modeling_lfm2_vl.py?ref=93671b4444414b01ea034bd64614856644297a66",
            "patch": "@@ -300,7 +300,7 @@ def test_integration_test_batched(self):\n         )\n \n         # Create inputs\n-        text = [\"<image>In this image, we see\", \"<image>In this image, there is a cat on\"]\n+        text = [\"<image>In this image, we see\", \"<image>In this image, we see\"]\n         images = [[self.image2], [self.image]]\n         inputs = self.processor(text=text, images=images, return_tensors=\"pt\", padding=True)\n         inputs.to(device=torch_device, dtype=torch.bfloat16)"
        },
        {
            "sha": "e087519c8f4cf3812d25ec24a38e8c7e774a0209",
            "filename": "tests/models/lfm2_vl/test_processing_lfm2_vl.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/93671b4444414b01ea034bd64614856644297a66/tests%2Fmodels%2Flfm2_vl%2Ftest_processing_lfm2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/93671b4444414b01ea034bd64614856644297a66/tests%2Fmodels%2Flfm2_vl%2Ftest_processing_lfm2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Flfm2_vl%2Ftest_processing_lfm2_vl.py?ref=93671b4444414b01ea034bd64614856644297a66",
            "patch": "@@ -291,7 +291,7 @@ def test_add_special_tokens_processor_image_splitting_large_image(self):\n         # fmt: off\n         inputs = processor(text=text, images=self.large_image, add_special_tokens=False, max_pixels_tolerance=2.0, do_image_splitting=True)\n         tokenized_sentence = processor.tokenizer(text_str, add_special_tokens=False)\n-        large_image_tokens = self.get_split_image_expected_tokens(processor, 2, 4, True, 8)\n+        large_image_tokens = self.get_split_image_expected_tokens(processor, 4, 2, True, 8)\n         expected_input_ids = [tokenized_sentence[\"input_ids\"] + large_image_tokens]\n         self.assertEqual(inputs[\"input_ids\"], expected_input_ids)\n         # fmt: on"
        }
    ],
    "stats": {
        "total": 6,
        "additions": 3,
        "deletions": 3
    }
}