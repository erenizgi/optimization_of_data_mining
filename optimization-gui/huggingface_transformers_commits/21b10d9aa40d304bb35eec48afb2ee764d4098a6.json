{
    "author": "yonigozlan",
    "message": "Fix `from_args_and_dict` ProcessorMixin (#38296)\n\n* fix-from-args-and-dict-processormixin\n\n* change used_kwargs to valid_kwargs\n\n* remove manual valid_kwargs\n\n* fix copies\n\n* fix modular aria",
    "sha": "21b10d9aa40d304bb35eec48afb2ee764d4098a6",
    "files": [
        {
            "sha": "561f94e4e731d917266ab5ef0a5d96dda7153b63",
            "filename": "src/transformers/models/aria/modular_aria.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fmodular_aria.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -936,7 +936,6 @@ class AriaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\", \"size_conversion\"]\n     image_processor_class = \"AriaImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "7ecf3af670c8e4854cceed60f0ff414250c25c58",
            "filename": "src/transformers/models/aria/processing_aria.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faria%2Fprocessing_aria.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faria%2Fprocessing_aria.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faria%2Fprocessing_aria.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -60,7 +60,6 @@ class AriaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\", \"size_conversion\"]\n     image_processor_class = \"AriaImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "be3f04a181951c24983fad34e60d8cc986ad476b",
            "filename": "src/transformers/models/aya_vision/processing_aya_vision.py",
            "status": "modified",
            "additions": 2,
            "deletions": 24,
            "changes": 26,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faya_vision%2Fprocessing_aya_vision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Faya_vision%2Fprocessing_aya_vision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Faya_vision%2Fprocessing_aya_vision.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -18,17 +18,8 @@\n import numpy as np\n \n from ...image_processing_utils import BatchFeature\n-from ...image_utils import (\n-    ImageInput,\n-    make_flat_list_of_images,\n-)\n-from ...processing_utils import (\n-    ImagesKwargs,\n-    MultiModalData,\n-    ProcessingKwargs,\n-    ProcessorMixin,\n-    Unpack,\n-)\n+from ...image_utils import ImageInput, make_flat_list_of_images\n+from ...processing_utils import ImagesKwargs, MultiModalData, ProcessingKwargs, ProcessorMixin, Unpack\n from ...tokenization_utils_base import PreTokenizedInput, TextInput\n \n \n@@ -87,19 +78,6 @@ class AyaVisionProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"image_token\",\n-        \"patch_size\",\n-        \"img_size\",\n-        \"downsample_factor\",\n-        \"start_of_img_token\",\n-        \"end_of_img_token\",\n-        \"img_patch_token\",\n-        \"img_line_break_token\",\n-        \"tile_token\",\n-        \"tile_global_token\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "5970e5edbb142019205cd6b52a9293212342904f",
            "filename": "src/transformers/models/blip/processing_blip.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip%2Fprocessing_blip.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -55,7 +55,6 @@ class BlipProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = []\n     image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = (\"BertTokenizer\", \"BertTokenizerFast\")\n "
        },
        {
            "sha": "d94525f6b6f56c9e534cfe77a6b0bda0b171b9cf",
            "filename": "src/transformers/models/blip_2/processing_blip_2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fblip_2%2Fprocessing_blip_2.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -21,12 +21,7 @@\n from ...image_processing_utils import BatchFeature\n from ...image_utils import ImageInput\n from ...processing_utils import ProcessingKwargs, ProcessorMixin, Unpack\n-from ...tokenization_utils_base import (\n-    AddedToken,\n-    BatchEncoding,\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import AddedToken, BatchEncoding, PreTokenizedInput, TextInput\n from ...utils import logging\n \n \n@@ -67,7 +62,6 @@ class Blip2Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"num_query_tokens\"]\n     image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "5a364cdc34da71236f32cd798b0ac3a8f43429da",
            "filename": "src/transformers/models/chameleon/processing_chameleon.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fchameleon%2Fprocessing_chameleon.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -72,7 +72,6 @@ class ChameleonProcessor(ProcessorMixin):\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n     tokenizer_class = (\"LlamaTokenizer\", \"LlamaTokenizerFast\")\n-    valid_kwargs = [\"image_seq_length\", \"image_token\"]\n     image_processor_class = \"ChameleonImageProcessor\"\n \n     def __init__(self, image_processor, tokenizer, image_seq_length: int = 1024, image_token: str = \"<image>\"):"
        },
        {
            "sha": "f34681c1d4fa466007312720b5b764300a149d46",
            "filename": "src/transformers/models/colpali/processing_colpali.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcolpali%2Fprocessing_colpali.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -90,7 +90,6 @@ class ColPaliProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     image_processor_class = (\"SiglipImageProcessor\", \"SiglipImageProcessorFast\")\n     tokenizer_class = (\"GemmaTokenizer\", \"GemmaTokenizerFast\")\n "
        },
        {
            "sha": "955f73cb363ba0cc3fafef11c7407e2fd4fdc1c0",
            "filename": "src/transformers/models/csm/processing_csm.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fcsm%2Fprocessing_csm.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -31,10 +31,7 @@\n from ...audio_utils import AudioInput, make_list_of_audio\n from ...feature_extraction_utils import BatchFeature\n from ...processing_utils import AudioKwargs, ProcessingKwargs, ProcessorMixin, Unpack\n-from ...tokenization_utils_base import (\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import PreTokenizedInput, TextInput\n \n \n class CsmAudioKwargs(AudioKwargs, total=False):\n@@ -99,7 +96,6 @@ class CsmProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"feature_extractor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     feature_extractor_class = \"EncodecFeatureExtractor\"\n     tokenizer_class = \"PreTrainedTokenizerFast\"\n "
        },
        {
            "sha": "61b402177238d778d03d9f718de839ddd6c86201",
            "filename": "src/transformers/models/emu3/processing_emu3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Femu3%2Fprocessing_emu3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Femu3%2Fprocessing_emu3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Femu3%2Fprocessing_emu3.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -71,7 +71,6 @@ class Emu3Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     tokenizer_class = (\"GPT2Tokenizer\", \"GPT2TokenizerFast\")\n     image_processor_class = \"Emu3ImageProcessor\"\n "
        },
        {
            "sha": "4852f3aaf9ed721c021786eb9eddcb08f5141b71",
            "filename": "src/transformers/models/fuyu/processing_fuyu.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Ffuyu%2Fprocessing_fuyu.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -350,7 +350,6 @@ class FuyuProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = []\n     image_processor_class = \"FuyuImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "ab6f03290a7f0602b6b5e4680d6165933766092e",
            "filename": "src/transformers/models/gemma3/processing_gemma3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgemma3%2Fprocessing_gemma3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgemma3%2Fprocessing_gemma3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgemma3%2Fprocessing_gemma3.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -51,7 +51,6 @@ class Gemma3ProcessorKwargs(ProcessingKwargs, total=False):\n \n class Gemma3Processor(ProcessorMixin):\n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\", \"image_seq_length\"]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "b712245a64c65f336dc1b18510e558b3b16e30b0",
            "filename": "src/transformers/models/got_ocr2/processing_got_ocr2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fprocessing_got_ocr2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fprocessing_got_ocr2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgot_ocr2%2Fprocessing_got_ocr2.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -95,7 +95,6 @@ class GotOcr2Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"PreTrainedTokenizerFast\"\n "
        },
        {
            "sha": "9032601a6b22c6c57660f7763a71c8d230fe16f2",
            "filename": "src/transformers/models/granite_speech/processing_granite_speech.py",
            "status": "modified",
            "additions": 0,
            "deletions": 2,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fprocessing_granite_speech.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fprocessing_granite_speech.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fgranite_speech%2Fprocessing_granite_speech.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -31,8 +31,6 @@\n \n class GraniteSpeechProcessor(ProcessorMixin):\n     attributes = [\"audio_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"audio_token\"]\n-\n     audio_processor_class = \"GraniteSpeechFeatureExtractor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "e226e15da196552856b36feebff22d5a3e2b9362",
            "filename": "src/transformers/models/idefics/processing_idefics.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics%2Fprocessing_idefics.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -211,7 +211,6 @@ class IdeficsProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"image_size\", \"add_end_of_utterance_token\"]\n     image_processor_class = \"IdeficsImageProcessor\"\n     tokenizer_class = \"LlamaTokenizerFast\"\n "
        },
        {
            "sha": "5be15d8cd8bf49c6dc8e41e5f29c3004b3f853d0",
            "filename": "src/transformers/models/idefics2/processing_idefics2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics2%2Fprocessing_idefics2.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -85,7 +85,6 @@ class Idefics2Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"image_seq_len\", \"chat_template\"]\n     image_processor_class = \"Idefics2ImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "5f4450df8b41a6830c3757d477890a52cd749433",
            "filename": "src/transformers/models/idefics3/processing_idefics3.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fidefics3%2Fprocessing_idefics3.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -133,7 +133,6 @@ class Idefics3Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"image_seq_len\", \"chat_template\"]\n     image_processor_class = \"Idefics3ImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "d3df6f4ef90e264756ed907839caacbe5e28a65e",
            "filename": "src/transformers/models/instructblip/processing_instructblip.py",
            "status": "modified",
            "additions": 1,
            "deletions": 7,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblip%2Fprocessing_instructblip.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -22,12 +22,7 @@\n from ...image_processing_utils import BatchFeature\n from ...image_utils import ImageInput\n from ...processing_utils import ProcessingKwargs, ProcessorMixin, Unpack\n-from ...tokenization_utils_base import (\n-    AddedToken,\n-    BatchEncoding,\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import AddedToken, BatchEncoding, PreTokenizedInput, TextInput\n from ...utils import logging\n from ..auto import AutoTokenizer\n \n@@ -72,7 +67,6 @@ class InstructBlipProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"qformer_tokenizer\"]\n-    valid_kwargs = [\"num_query_tokens\"]\n     image_processor_class = (\"BlipImageProcessor\", \"BlipImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n     qformer_tokenizer_class = \"AutoTokenizer\""
        },
        {
            "sha": "fad69b72e2fba788b57bb12c01adb62aad4b92fd",
            "filename": "src/transformers/models/instructblipvideo/processing_instructblipvideo.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fprocessing_instructblipvideo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fprocessing_instructblipvideo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finstructblipvideo%2Fprocessing_instructblipvideo.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -57,7 +57,6 @@ class InstructBlipVideoProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"video_processor\", \"tokenizer\", \"qformer_tokenizer\"]\n-    valid_kwargs = [\"num_query_tokens\"]\n     video_processor_class = \"AutoVideoProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n     qformer_tokenizer_class = \"AutoTokenizer\""
        },
        {
            "sha": "c9a8c2028d50f9ff0882dfe07b50b25047f8bd47",
            "filename": "src/transformers/models/internvl/processing_internvl.py",
            "status": "modified",
            "additions": 2,
            "deletions": 16,
            "changes": 18,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finternvl%2Fprocessing_internvl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Finternvl%2Fprocessing_internvl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Finternvl%2Fprocessing_internvl.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -18,18 +18,8 @@\n import numpy as np\n \n from ...image_processing_utils import BatchFeature\n-from ...image_utils import (\n-    ImageInput,\n-    concatenate_list,\n-    make_flat_list_of_images,\n-)\n-from ...processing_utils import (\n-    ImagesKwargs,\n-    MultiModalData,\n-    ProcessingKwargs,\n-    ProcessorMixin,\n-    Unpack,\n-)\n+from ...image_utils import ImageInput, concatenate_list, make_flat_list_of_images\n+from ...processing_utils import ImagesKwargs, MultiModalData, ProcessingKwargs, ProcessorMixin, Unpack\n from ...tokenization_utils_base import PreTokenizedInput, TextInput\n from ...video_utils import VideoInput, VideoMetadata, load_video, make_batched_videos\n \n@@ -74,10 +64,6 @@ class InternVLProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"video_processor\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"image_seq_length\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     video_processor_class = \"AutoVideoProcessor\"\n     tokenizer_class = \"AutoTokenizer\""
        },
        {
            "sha": "d5f626a24c709fae3c3cc2a32d07e9d0747afdb3",
            "filename": "src/transformers/models/janus/processing_janus.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fjanus%2Fprocessing_janus.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fjanus%2Fprocessing_janus.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjanus%2Fprocessing_janus.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -21,10 +21,7 @@\n from ...feature_extraction_utils import BatchFeature\n from ...image_utils import ImageInput\n from ...processing_utils import ProcessingKwargs, ProcessorMixin, TextKwargs, Unpack\n-from ...tokenization_utils_base import (\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import PreTokenizedInput, TextInput\n from ...utils import logging\n \n \n@@ -68,7 +65,6 @@ class JanusProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\", \"use_default_system_prompt\"]\n     image_processor_class = \"JanusImageProcessor\"\n     tokenizer_class = \"LlamaTokenizerFast\"\n "
        },
        {
            "sha": "3a1c9253824c6f844d1f98073ec389f06d922a57",
            "filename": "src/transformers/models/kosmos2/processing_kosmos2.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fkosmos2%2Fprocessing_kosmos2.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -84,7 +84,6 @@ class Kosmos2Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"num_patch_index_tokens\"]\n     image_processor_class = (\"CLIPImageProcessor\", \"CLIPImageProcessorFast\")\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "a020826aadeac9ffe8a314179d0e072d6b399550",
            "filename": "src/transformers/models/llama4/processing_llama4.py",
            "status": "modified",
            "additions": 2,
            "deletions": 23,
            "changes": 25,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllama4%2Fprocessing_llama4.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllama4%2Fprocessing_llama4.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllama4%2Fprocessing_llama4.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -16,19 +16,11 @@\n \n from typing import List, Optional, Union\n \n-from transformers.processing_utils import (\n-    ImagesKwargs,\n-    ProcessingKwargs,\n-    ProcessorMixin,\n-    Unpack,\n-)\n+from transformers.processing_utils import ImagesKwargs, ProcessingKwargs, ProcessorMixin, Unpack\n from transformers.tokenization_utils_base import PreTokenizedInput, TextInput\n \n from ...image_processing_utils import BatchFeature\n-from ...image_utils import (\n-    ImageInput,\n-    make_flat_list_of_images,\n-)\n+from ...image_utils import ImageInput, make_flat_list_of_images\n \n \n class Llama4ImagesKwargs(ImagesKwargs, total=False):\n@@ -83,19 +75,6 @@ class Llama4Processor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"image_token\",\n-        \"patch_size\",\n-        \"img_size\",\n-        \"downsample_factor\",\n-        \"start_of_img_token\",\n-        \"end_of_img_token\",\n-        \"img_patch_token\",\n-        \"img_line_break_token\",\n-        \"tile_token\",\n-        \"tile_global_token\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "b345df4d23b4a44986e8cff9d194ea0fb180804e",
            "filename": "src/transformers/models/llava/processing_llava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava%2Fprocessing_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava%2Fprocessing_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava%2Fprocessing_llava.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -70,13 +70,6 @@ class LlavaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"patch_size\",\n-        \"vision_feature_select_strategy\",\n-        \"image_token\",\n-        \"num_additional_image_tokens\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "5a25f4072c2171cee89c231289a4e142c85d3af3",
            "filename": "src/transformers/models/llava_next/processing_llava_next.py",
            "status": "modified",
            "additions": 0,
            "deletions": 7,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_next%2Fprocessing_llava_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_next%2Fprocessing_llava_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next%2Fprocessing_llava_next.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -76,13 +76,6 @@ class LlavaNextProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"patch_size\",\n-        \"vision_feature_select_strategy\",\n-        \"image_token\",\n-        \"num_additional_image_tokens\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "b4cd7f7c221eaf5caa5951cf70cfffa8b108e5f3",
            "filename": "src/transformers/models/llava_next_video/processing_llava_next_video.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_next_video%2Fprocessing_llava_next_video.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -78,14 +78,6 @@ class LlavaNextVideoProcessor(ProcessorMixin):\n     # video and image processor share same args, but have different processing logic\n     # only image processor config is saved in the hub\n     attributes = [\"video_processor\", \"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"patch_size\",\n-        \"vision_feature_select_strategy\",\n-        \"image_token\",\n-        \"video_token\",\n-        \"num_additional_image_tokens\",\n-    ]\n     image_processor_class = (\"LlavaNextImageProcessor\", \"LlavaNextImageProcessorFast\")\n     video_processor_class = \"AutoVideoProcessor\"\n     tokenizer_class = (\"LlamaTokenizer\", \"LlamaTokenizerFast\")"
        },
        {
            "sha": "00cf4b579eb4f805f42bb7281f95ca78d22e6491",
            "filename": "src/transformers/models/llava_onevision/processing_llava_onevision.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fllava_onevision%2Fprocessing_llava_onevision.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -75,14 +75,6 @@ class LlavaOnevisionProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"video_processor\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"num_image_tokens\",\n-        \"vision_feature_select_strategy\",\n-        \"image_token\",\n-        \"video_token\",\n-        \"vision_aspect_ratio\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n     video_processor_class = \"AutoVideoProcessor\""
        },
        {
            "sha": "ffe76709482bb919d3f31913a036e58edb57798f",
            "filename": "src/transformers/models/mllama/processing_mllama.py",
            "status": "modified",
            "additions": 1,
            "deletions": 5,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmllama%2Fprocessing_mllama.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -22,10 +22,7 @@\n from ...feature_extraction_utils import BatchFeature\n from ...image_utils import ImageInput, make_nested_list_of_images\n from ...processing_utils import ImagesKwargs, ProcessingKwargs, ProcessorMixin, Unpack\n-from ...tokenization_utils_base import (\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import PreTokenizedInput, TextInput\n \n \n class MllamaImagesKwargs(ImagesKwargs, total=False):\n@@ -208,7 +205,6 @@ class MllamaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     image_processor_class = \"MllamaImageProcessor\"\n     tokenizer_class = \"PreTrainedTokenizerFast\"\n "
        },
        {
            "sha": "1440ea7b66fb9f37432c8539677baa6884b97b2e",
            "filename": "src/transformers/models/paligemma/processing_paligemma.py",
            "status": "modified",
            "additions": 1,
            "deletions": 6,
            "changes": 7,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpaligemma%2Fprocessing_paligemma.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -31,11 +31,7 @@\n     Unpack,\n     _validate_images_text_input_order,\n )\n-from ...tokenization_utils_base import (\n-    AddedToken,\n-    PreTokenizedInput,\n-    TextInput,\n-)\n+from ...tokenization_utils_base import AddedToken, PreTokenizedInput, TextInput\n from ...utils import logging\n \n \n@@ -120,7 +116,6 @@ class PaliGemmaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\"]\n     image_processor_class = (\"SiglipImageProcessor\", \"SiglipImageProcessorFast\")\n     tokenizer_class = (\"GemmaTokenizer\", \"GemmaTokenizerFast\")\n "
        },
        {
            "sha": "ebccdc0460883ccce97d57c324f1f63bde98e0aa",
            "filename": "src/transformers/models/phi4_multimodal/processing_phi4_multimodal.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fprocessing_phi4_multimodal.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fprocessing_phi4_multimodal.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphi4_multimodal%2Fprocessing_phi4_multimodal.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -62,7 +62,6 @@ class Phi4MultimodalProcessor(ProcessorMixin):\n     tokenizer_class = \"GPT2TokenizerFast\"\n     image_processor_class = \"Phi4MultimodalImageProcessorFast\"\n     audio_processor_class = \"Phi4MultimodalFeatureExtractor\"\n-    valid_kwargs = [\"chat_template\"]\n \n     def __init__(\n         self,"
        },
        {
            "sha": "8a15fa8e1e5fc21b540a2d69d8784952592e3a3e",
            "filename": "src/transformers/models/pixtral/processing_pixtral.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fpixtral%2Fprocessing_pixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fpixtral%2Fprocessing_pixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fpixtral%2Fprocessing_pixtral.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -90,14 +90,6 @@ class PixtralProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"patch_size\",\n-        \"spatial_merge_size\",\n-        \"image_token\",\n-        \"image_break_token\",\n-        \"image_end_token\",\n-    ]\n     image_processor_class = \"AutoImageProcessor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "ea4491847050bca3f940aa40eb2cd6c51e84637a",
            "filename": "src/transformers/models/qwen2_5_omni/processing_qwen2_5_omni.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_omni%2Fprocessing_qwen2_5_omni.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -97,7 +97,6 @@ class Qwen2_5OmniProcessor(ProcessorMixin):\n     video_processor_class = \"Qwen2VLVideoProcessor\"\n     feature_extractor_class = \"WhisperFeatureExtractor\"\n     tokenizer_class = (\"Qwen2Tokenizer\", \"Qwen2TokenizerFast\")\n-    valid_kwargs = [\"chat_template\"]\n \n     def __init__(\n         self, image_processor=None, video_processor=None, feature_extractor=None, tokenizer=None, chat_template=None"
        },
        {
            "sha": "f835390a079617485c63c7eae2ec8a2107726684",
            "filename": "src/transformers/models/qwen2_5_vl/processing_qwen2_5_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_5_vl%2Fprocessing_qwen2_5_vl.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -75,7 +75,6 @@ class Qwen2_5_VLProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"video_processor\"]\n-    valid_kwargs = [\"chat_template\"]\n \n     image_processor_class = \"AutoImageProcessor\"\n     video_processor_class = \"AutoVideoProcessor\""
        },
        {
            "sha": "1eac9e8b7c3b9b10a67e51740f213e76ac8e1daa",
            "filename": "src/transformers/models/qwen2_audio/processing_qwen2_audio.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_audio%2Fprocessing_qwen2_audio.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -60,7 +60,6 @@ class Qwen2AudioProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"feature_extractor\", \"tokenizer\"]\n-    valid_kwargs = [\"chat_template\", \"audio_token\", \"audio_bos_token\", \"audio_eos_token\"]\n     feature_extractor_class = \"WhisperFeatureExtractor\"\n     tokenizer_class = \"AutoTokenizer\"\n "
        },
        {
            "sha": "6cd056aa1d5293d36ea724b1c4e75d48bf218135",
            "filename": "src/transformers/models/qwen2_vl/processing_qwen2_vl.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_vl%2Fprocessing_qwen2_vl.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -71,7 +71,6 @@ class Qwen2VLProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"video_processor\"]\n-    valid_kwargs = [\"chat_template\"]\n     image_processor_class = \"AutoImageProcessor\"\n     video_processor_class = \"AutoVideoProcessor\"\n     tokenizer_class = (\"Qwen2Tokenizer\", \"Qwen2TokenizerFast\")"
        },
        {
            "sha": "a440a0f29b1aa57d74c43b9ddd85edd5af7ad247",
            "filename": "src/transformers/models/smolvlm/processing_smolvlm.py",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsmolvlm%2Fprocessing_smolvlm.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -139,7 +139,6 @@ class SmolVLMProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"tokenizer\", \"video_processor\"]\n-    valid_kwargs = [\"image_seq_len\", \"chat_template\"]\n     image_processor_class = \"SmolVLMImageProcessor\"\n     video_processor_class = (\n         \"SmolVLMImageProcessor\"  # TODO: raushan should be VideoProcessor when LANCZOS resizing is settled"
        },
        {
            "sha": "7a6edb8cff28b07bc9eac2d6b1c6c24ca3144e98",
            "filename": "src/transformers/models/video_llava/processing_video_llava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 8,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fvideo_llava%2Fprocessing_video_llava.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -61,14 +61,6 @@ class VideoLlavaProcessor(ProcessorMixin):\n     \"\"\"\n \n     attributes = [\"image_processor\", \"video_processor\", \"tokenizer\"]\n-    valid_kwargs = [\n-        \"chat_template\",\n-        \"patch_size\",\n-        \"vision_feature_select_strategy\",\n-        \"image_token\",\n-        \"video_token\",\n-        \"num_additional_image_tokens\",\n-    ]\n     image_processor_class = \"VideoLlavaImageProcessor\"\n     video_processor_class = \"AutoVideoProcessor\"\n     tokenizer_class = \"AutoTokenizer\""
        },
        {
            "sha": "8ee7ce5adbb634b63a98232381bfc20d694c4435",
            "filename": "src/transformers/processing_utils.py",
            "status": "modified",
            "additions": 27,
            "deletions": 15,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fprocessing_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/21b10d9aa40d304bb35eec48afb2ee764d4098a6/src%2Ftransformers%2Fprocessing_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fprocessing_utils.py?ref=21b10d9aa40d304bb35eec48afb2ee764d4098a6",
            "patch": "@@ -497,7 +497,6 @@ class ProcessorMixin(PushToHubMixin):\n     feature_extractor_class = None\n     tokenizer_class = None\n     _auto_class = None\n-    valid_kwargs: list[str] = []\n \n     # args have to match the attributes class attribute\n     def __init__(self, *args, **kwargs):\n@@ -996,18 +995,27 @@ def from_args_and_dict(cls, args, processor_dict: dict[str, Any], **kwargs):\n         if \"auto_map\" in processor_dict:\n             del processor_dict[\"auto_map\"]\n \n-        unused_kwargs = cls.validate_init_kwargs(processor_config=processor_dict, valid_kwargs=cls.valid_kwargs)\n-        processor = cls(*args, **processor_dict)\n+        # override processor_dict with given kwargs\n+        processor_dict.update(kwargs)\n \n-        # Update processor with kwargs if needed\n-        for key in set(kwargs.keys()):\n-            if hasattr(processor, key):\n-                setattr(processor, key, kwargs.pop(key))\n+        # check if there is an overlap between args and processor_dict\n+        accepted_args_and_kwargs = cls.__init__.__code__.co_varnames[: cls.__init__.__code__.co_argcount][1:]\n+\n+        # validate both processor_dict and given kwargs\n+        unused_kwargs, valid_kwargs = cls.validate_init_kwargs(\n+            processor_config=processor_dict, valid_kwargs=accepted_args_and_kwargs\n+        )\n+\n+        # remove args that are in processor_dict to avoid duplicate arguments\n+        args_to_remove = [i for i, arg in enumerate(accepted_args_and_kwargs) if arg in processor_dict]\n+        args = [arg for i, arg in enumerate(args) if i not in args_to_remove]\n+\n+        # instantiate processor with used (and valid) kwargs only\n+        processor = cls(*args, **valid_kwargs)\n \n-        kwargs.update(unused_kwargs)\n         logger.info(f\"Processor {processor}\")\n         if return_unused_kwargs:\n-            return processor, kwargs\n+            return processor, unused_kwargs\n         else:\n             return processor\n \n@@ -1294,12 +1302,16 @@ def model_input_names(self):\n \n     @staticmethod\n     def validate_init_kwargs(processor_config, valid_kwargs):\n-        kwargs_from_config = processor_config.keys()\n-        unused_kwargs = {}\n-        unused_keys = set(kwargs_from_config) - set(valid_kwargs)\n-        if unused_keys:\n-            unused_kwargs = {k: processor_config[k] for k in unused_keys}\n-        return unused_kwargs\n+        kwargs_from_config = set(processor_config.keys())\n+        valid_kwargs_set = set(valid_kwargs)\n+\n+        unused_keys = kwargs_from_config - valid_kwargs_set\n+        valid_keys = kwargs_from_config & valid_kwargs_set\n+\n+        unused_kwargs = {k: processor_config[k] for k in unused_keys} if unused_keys else {}\n+        valid_kwargs = {k: processor_config[k] for k in valid_keys} if valid_keys else {}\n+\n+        return unused_kwargs, valid_kwargs\n \n     def prepare_and_validate_optional_call_args(self, *args):\n         \"\"\""
        }
    ],
    "stats": {
        "total": 220,
        "additions": 39,
        "deletions": 181
    }
}