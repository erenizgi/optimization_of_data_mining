{
    "author": "zucchini-nlp",
    "message": "[llava] fix integration tests with Siglip (#38732)\n\nfix llava siglip test",
    "sha": "380e6ea4065afc4f639d7b1bed990e18020b7270",
    "files": [
        {
            "sha": "de6b720fdee21ffb1698fc630650efad71f2d33a",
            "filename": "tests/models/llava/test_modeling_llava.py",
            "status": "modified",
            "additions": 0,
            "deletions": 4,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/380e6ea4065afc4f639d7b1bed990e18020b7270/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/380e6ea4065afc4f639d7b1bed990e18020b7270/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fllava%2Ftest_modeling_llava.py?ref=380e6ea4065afc4f639d7b1bed990e18020b7270",
            "patch": "@@ -557,10 +557,6 @@ def test_generation_siglip_backbone(self):\n         model = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=\"float16\", device_map=torch_device)\n         processor = AutoProcessor.from_pretrained(model_id)\n \n-        # check processing with expansion of inputs (w/o expansion should work with any backbone)\n-        processor.vision_feature_select_strategy = \"default\"\n-        processor.patch_size = 14\n-\n         image_file = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n         raw_image = Image.open(requests.get(image_file, stream=True).raw)\n         inputs = processor("
        }
    ],
    "stats": {
        "total": 4,
        "additions": 0,
        "deletions": 4
    }
}