{
    "author": "eminorhan",
    "message": "fix redundant checkpointing in example training scripts (#33131)\n\n* fix redundant checkpointing in example scripts\r\n\r\n* Update examples/pytorch/image-classification/run_image_classification_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/translation/run_translation_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/token-classification/run_ner_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/text-classification/run_glue_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/summarization/run_summarization_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/language-modeling/run_mlm_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/language-modeling/run_fim_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/language-modeling/run_clm_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/image-pretraining/run_mim_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/multiple-choice/run_swag_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/question-answering/run_qa_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/object-detection/run_object_detection_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n* Update examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>\r\n\r\n---------\r\n\r\nCo-authored-by: Marc Sun <57196510+SunMarc@users.noreply.github.com>",
    "sha": "d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
    "files": [
        {
            "sha": "0c8068d4d45d5cb2e5b07e0fa6d9c240266b40d2",
            "filename": "examples/pytorch/image-classification/run_image_classification_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-classification%2Frun_image_classification_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -544,7 +544,7 @@ def collate_fn(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "e533ddfa8b01a5109faaf8ac2aa7dc8f265fd873",
            "filename": "examples/pytorch/image-pretraining/run_mim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fimage-pretraining%2Frun_mim_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -723,7 +723,7 @@ def preprocess_images(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "1605f607acb0f3566bcadcef6f00402fb84b7370",
            "filename": "examples/pytorch/instance-segmentation/run_instance_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Finstance-segmentation%2Frun_instance_segmentation_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -639,7 +639,7 @@ def main():\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "43ecba5f4d8ff4c3ff455103f9e200605a6f656a",
            "filename": "examples/pytorch/language-modeling/run_clm_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_clm_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -638,7 +638,7 @@ def group_texts(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "2c954a1b65355e1c1add44d7c21fdc69b958b918",
            "filename": "examples/pytorch/language-modeling/run_fim_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_fim_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -838,7 +838,7 @@ def apply_fim(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "c98687efadf53fb821c8bdb096165888d53db384",
            "filename": "examples/pytorch/language-modeling/run_mlm_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Flanguage-modeling%2Frun_mlm_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -675,7 +675,7 @@ def group_texts(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "8f7693ae5b0d1a968dc52e98b9423414b9851b93",
            "filename": "examples/pytorch/multiple-choice/run_swag_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fmultiple-choice%2Frun_swag_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -619,7 +619,7 @@ def preprocess_function(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "6de61be630920ea80114598c488e63bdcc07ea22",
            "filename": "examples/pytorch/object-detection/run_object_detection_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fobject-detection%2Frun_object_detection_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -677,7 +677,7 @@ def main():\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "ee791c0c8ddf2e1561cbc8b49a4691fe5e3bbf63",
            "filename": "examples/pytorch/question-answering/run_qa_beam_search_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_beam_search_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -879,7 +879,7 @@ def create_and_fill_np_array(start_or_end_logits, dataset, max_len):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     accelerator.save_state(f\"step_{completed_steps}\")\n \n             if completed_steps >= args.max_train_steps:"
        },
        {
            "sha": "7ae0d488bc40926c836688e2c5fbbf767458bdae",
            "filename": "examples/pytorch/question-answering/run_qa_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fquestion-answering%2Frun_qa_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -894,7 +894,7 @@ def create_and_fill_np_array(start_or_end_logits, dataset, max_len):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "35c3744ab5f3b3387f9af5235adf897d2e417c95",
            "filename": "examples/pytorch/semantic-segmentation/run_semantic_segmentation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsemantic-segmentation%2Frun_semantic_segmentation_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -516,7 +516,7 @@ def preprocess_batch(example_batch, transforms: A.Compose):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "36cd590ea5c949b1ae87ff2110fffa9f1c61b928",
            "filename": "examples/pytorch/summarization/run_summarization_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Fsummarization%2Frun_summarization_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -688,7 +688,7 @@ def postprocess_text(preds, labels):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "ac62edbe5e9f72ec308c11626faffce2132789bd",
            "filename": "examples/pytorch/text-classification/run_glue_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftext-classification%2Frun_glue_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -564,7 +564,7 @@ def preprocess_function(examples):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "2afb38bb44b45f2f8d3ece1bb4e2b421e844efe8",
            "filename": "examples/pytorch/token-classification/run_ner_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftoken-classification%2Frun_ner_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -722,7 +722,7 @@ def compute_metrics():\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        },
        {
            "sha": "97da3f9541d9e7093f7dc26fa3e83d4f21fdba78",
            "filename": "examples/pytorch/translation/run_translation_no_trainer.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/d47a9e8ce556be790ac98c0a9024dd41c6328fb0/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/examples%2Fpytorch%2Ftranslation%2Frun_translation_no_trainer.py?ref=d47a9e8ce556be790ac98c0a9024dd41c6328fb0",
            "patch": "@@ -664,7 +664,7 @@ def postprocess_text(preds, labels):\n                 completed_steps += 1\n \n             if isinstance(checkpointing_steps, int):\n-                if completed_steps % checkpointing_steps == 0:\n+                if completed_steps % checkpointing_steps == 0 and accelerator.sync_gradients:\n                     output_dir = f\"step_{completed_steps}\"\n                     if args.output_dir is not None:\n                         output_dir = os.path.join(args.output_dir, output_dir)"
        }
    ],
    "stats": {
        "total": 30,
        "additions": 15,
        "deletions": 15
    }
}