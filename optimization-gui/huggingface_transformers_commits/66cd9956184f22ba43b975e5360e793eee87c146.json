{
    "author": "zucchini-nlp",
    "message": "[shieldgemma] fix checkpoint loading (#39348)\n\n* fix\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "66cd9956184f22ba43b975e5360e793eee87c146",
    "files": [
        {
            "sha": "7153257a106c1acb03d8d3789a56f7f15734f9cc",
            "filename": "src/transformers/modeling_utils.py",
            "status": "modified",
            "additions": 1,
            "deletions": 0,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/66cd9956184f22ba43b975e5360e793eee87c146/src%2Ftransformers%2Fmodeling_utils.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/66cd9956184f22ba43b975e5360e793eee87c146/src%2Ftransformers%2Fmodeling_utils.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodeling_utils.py?ref=66cd9956184f22ba43b975e5360e793eee87c146",
            "patch": "@@ -240,6 +240,7 @@ def is_local_dist_rank_0():\n     \"mistral3\",\n     \"mllama\",\n     \"paligemma\",\n+    \"shieldgemma2\",\n     \"qwen2vl\",\n     \"qwen2_5_vl\",\n     \"videollava\","
        },
        {
            "sha": "a77ea28a22427f07b6300326a345c2b764002e88",
            "filename": "src/transformers/models/shieldgemma2/modeling_shieldgemma2.py",
            "status": "modified",
            "additions": 6,
            "deletions": 0,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/66cd9956184f22ba43b975e5360e793eee87c146/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/66cd9956184f22ba43b975e5360e793eee87c146/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py?ref=66cd9956184f22ba43b975e5360e793eee87c146",
            "patch": "@@ -45,6 +45,12 @@ class ShieldGemma2ImageClassifierOutputWithNoAttention(ImageClassifierOutputWith\n @auto_docstring\n class ShieldGemma2ForImageClassification(PreTrainedModel):\n     config_class = ShieldGemma2Config\n+    _checkpoint_conversion_mapping = {\n+        \"model.language_model.model\": \"model.model.language_model\",\n+        \"model.vision_tower\": \"model.model.vision_tower\",\n+        \"model.multi_modal_projector\": \"model.model.multi_modal_projector\",\n+        \"model.language_model.lm_head\": \"model.lm_head\",\n+    }\n \n     def __init__(self, config: ShieldGemma2Config):\n         super().__init__(config=config)"
        },
        {
            "sha": "4683c76bc6c5b230adfb7db009bc4f9f606703be",
            "filename": "tests/models/shieldgemma2/test_modeling_shieldgemma2.py",
            "status": "modified",
            "additions": 4,
            "deletions": 7,
            "changes": 11,
            "blob_url": "https://github.com/huggingface/transformers/blob/66cd9956184f22ba43b975e5360e793eee87c146/tests%2Fmodels%2Fshieldgemma2%2Ftest_modeling_shieldgemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/66cd9956184f22ba43b975e5360e793eee87c146/tests%2Fmodels%2Fshieldgemma2%2Ftest_modeling_shieldgemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fshieldgemma2%2Ftest_modeling_shieldgemma2.py?ref=66cd9956184f22ba43b975e5360e793eee87c146",
            "patch": "@@ -22,21 +22,20 @@\n from transformers import is_torch_available\n from transformers.testing_utils import (\n     cleanup,\n+    require_read_token,\n     require_torch_accelerator,\n     slow,\n     torch_device,\n )\n \n \n if is_torch_available():\n-    import torch\n-\n     from transformers import ShieldGemma2ForImageClassification, ShieldGemma2Processor\n \n \n @slow\n @require_torch_accelerator\n-# @require_read_token\n+@require_read_token\n class ShieldGemma2IntegrationTest(unittest.TestCase):\n     def tearDown(self):\n         cleanup(torch_device, gc_collect=True)\n@@ -49,11 +48,9 @@ def test_model(self):\n         response = requests.get(url)\n         image = Image.open(BytesIO(response.content))\n \n-        model = ShieldGemma2ForImageClassification.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(\n-            torch_device\n-        )\n+        model = ShieldGemma2ForImageClassification.from_pretrained(model_id, load_in_4bit=True)\n \n-        inputs = processor(images=[image]).to(torch_device)\n+        inputs = processor(images=[image], return_tensors=\"pt\").to(torch_device)\n         output = model(**inputs)\n         self.assertEqual(len(output.probabilities), 3)\n         for element in output.probabilities:"
        }
    ],
    "stats": {
        "total": 18,
        "additions": 11,
        "deletions": 7
    }
}