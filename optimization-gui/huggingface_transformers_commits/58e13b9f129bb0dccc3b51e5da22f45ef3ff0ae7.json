{
    "author": "ydshieh",
    "message": "Update expected values for some `test_speculative_generation` (#40949)\n\n* fix\n\n* fix\n\n---------\n\nCo-authored-by: ydshieh <ydshieh@users.noreply.github.com>",
    "sha": "58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7",
    "files": [
        {
            "sha": "1723d55afc8a1c456b4f9d8fb7b694a4244fd81d",
            "filename": "tests/models/mistral/test_modeling_mistral.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fmistral%2Ftest_modeling_mistral.py?ref=58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7",
            "patch": "@@ -254,7 +254,7 @@ def test_model_7b_long_prompt_sdpa(self):\n \n     @slow\n     def test_speculative_generation(self):\n-        EXPECTED_TEXT_COMPLETION = \"My favourite condiment is 100% Sriracha. I love it on everything. I have it on my\"\n+        EXPECTED_TEXT_COMPLETION = \"My favourite condiment is 100% ketchup. Iâ€™m not a fan of mustard, relish\"\n         prompt = \"My favourite condiment is \"\n         tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", use_fast=False)\n         model = MistralForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", dtype=torch.float16)"
        },
        {
            "sha": "d4cf34fbbca21a29e5d4eb1412c27cb61664b0ed",
            "filename": "tests/models/qwen2/test_modeling_qwen2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2%2Ftest_modeling_qwen2.py?ref=58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7",
            "patch": "@@ -207,7 +207,7 @@ def test_model_450m_long_prompt_sdpa(self):\n     @slow\n     def test_speculative_generation(self):\n         EXPECTED_TEXT_COMPLETION = (\n-            \"My favourite condiment is 100% natural honey, and I always like to use it in my recipes. I love\"\n+            \"My favourite condiment is 100% natural and organic, and I love to use it to make my own sauces.\"\n         )\n         prompt = \"My favourite condiment is \"\n         tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-7B\", use_fast=False)"
        },
        {
            "sha": "db3be5ac7e205144feda5658c1b35be680ec3f7e",
            "filename": "tests/models/qwen2_moe/test_modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen2_moe%2Ftest_modeling_qwen2_moe.py?ref=58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7",
            "patch": "@@ -252,7 +252,7 @@ def test_model_a2_7b_long_prompt_sdpa(self):\n     @slow\n     def test_speculative_generation(self):\n         EXPECTED_TEXT_COMPLETION = (\n-            \"To be or not to be, that is the question. Whether 'tis nobler in the mind to suffer the sl\"\n+            \"To be or not to be, that is the question: Whether 'tis nobler in the mind to suffer The sl\"\n         )\n         prompt = \"To be or not to\"\n         tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-MoE-A2.7B\", use_fast=False)"
        },
        {
            "sha": "ba937656d3a64ecfd61c09fc250111de29b01951",
            "filename": "tests/models/qwen3/test_modeling_qwen3.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/tests%2Fmodels%2Fqwen3%2Ftest_modeling_qwen3.py?ref=58e13b9f129bb0dccc3b51e5da22f45ef3ff0ae7",
            "patch": "@@ -199,7 +199,7 @@ def test_speculative_generation(self):\n             {\n                 (\"xpu\", 3): \"My favourite condiment is 100% peanut butter. I love it so much that I can't help but use it\",\n                 (\"cuda\", 7): \"My favourite condiment is 100% natural. It's a little spicy and a little sweet, but it's the\",\n-                (\"cuda\", 8): \"My favourite condiment is 100% peanut butter. I love it so much that I can't help but use it\",\n+                (\"cuda\", 8): \"My favourite condiment is 100% beef, 100% beef, 100% beef.\",\n             }\n         )  # fmt: skip\n         EXPECTED_TEXT_COMPLETION = EXPECTED_TEXT_COMPLETIONS.get_expectation()"
        }
    ],
    "stats": {
        "total": 8,
        "additions": 4,
        "deletions": 4
    }
}