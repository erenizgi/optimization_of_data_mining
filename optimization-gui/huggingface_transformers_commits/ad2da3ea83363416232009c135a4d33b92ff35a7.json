{
    "author": "yonigozlan",
    "message": "Fix self.dropout_p is not defined for SamAttention/Sam2Attention (#40667)\n\nFix dropout_p is not defined for SamAttention/Sam2Attention",
    "sha": "ad2da3ea83363416232009c135a4d33b92ff35a7",
    "files": [
        {
            "sha": "273322cd74cee03c1069f59b40f6200a1879a340",
            "filename": "src/transformers/models/sam/modeling_sam.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam%2Fmodeling_sam.py?ref=ad2da3ea83363416232009c135a4d33b92ff35a7",
            "patch": "@@ -262,7 +262,7 @@ def forward(\n             key,\n             value,\n             attention_mask=attention_similarity,\n-            dropout=0.0 if not self.training else self.dropout_p,\n+            dropout=0.0,\n             scaling=self.scaling,\n             is_causal=self.is_causal,\n             **kwargs,"
        },
        {
            "sha": "4d27c1c323cdfc9ce4bd20c59e76a2a195116e36",
            "filename": "src/transformers/models/sam2/modeling_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodeling_sam2.py?ref=ad2da3ea83363416232009c135a4d33b92ff35a7",
            "patch": "@@ -893,7 +893,7 @@ def forward(\n             key,\n             value,\n             attention_mask=attention_similarity,\n-            dropout=0.0 if not self.training else self.dropout_p,\n+            dropout=0.0,\n             scaling=self.scaling,\n             is_causal=self.is_causal,\n             **kwargs,"
        },
        {
            "sha": "f16ed2fb1718672597181afd5689a8715fd719c7",
            "filename": "src/transformers/models/sam2/modular_sam2.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2%2Fmodular_sam2.py?ref=ad2da3ea83363416232009c135a4d33b92ff35a7",
            "patch": "@@ -940,7 +940,7 @@ def forward(\n             key,\n             value,\n             attention_mask=attention_similarity,\n-            dropout=0.0 if not self.training else self.dropout_p,\n+            dropout=0.0,\n             scaling=self.scaling,\n             is_causal=self.is_causal,\n             **kwargs,"
        },
        {
            "sha": "4325018cf477aa04c1a4c50469e1a3452f8f7b37",
            "filename": "src/transformers/models/sam2_video/modeling_sam2_video.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam2_video%2Fmodeling_sam2_video.py?ref=ad2da3ea83363416232009c135a4d33b92ff35a7",
            "patch": "@@ -478,7 +478,7 @@ def forward(\n             key,\n             value,\n             attention_mask=attention_similarity,\n-            dropout=0.0 if not self.training else self.dropout_p,\n+            dropout=0.0,\n             scaling=self.scaling,\n             is_causal=self.is_causal,\n             **kwargs,"
        },
        {
            "sha": "ab0c9aace21aa78e9761a0bcba32d62eda5bc3c0",
            "filename": "src/transformers/models/sam_hq/modeling_sam_hq.py",
            "status": "modified",
            "additions": 1,
            "deletions": 1,
            "changes": 2,
            "blob_url": "https://github.com/huggingface/transformers/blob/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/ad2da3ea83363416232009c135a4d33b92ff35a7/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fsam_hq%2Fmodeling_sam_hq.py?ref=ad2da3ea83363416232009c135a4d33b92ff35a7",
            "patch": "@@ -674,7 +674,7 @@ def forward(\n             key,\n             value,\n             attention_mask=attention_similarity,\n-            dropout=0.0 if not self.training else self.dropout_p,\n+            dropout=0.0,\n             scaling=self.scaling,\n             is_causal=self.is_causal,\n             **kwargs,"
        }
    ],
    "stats": {
        "total": 10,
        "additions": 5,
        "deletions": 5
    }
}