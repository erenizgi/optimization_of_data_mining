{
    "author": "gante",
    "message": "[CI] doc builder without custom image (#36862)\n\n* no image\n\n* test\n\n* revert jax version updates\n\n* make fixup\n\n* update autodoc path for model_addition_debugger\n\n* shieldgemma2\n\n* add missing pages to toctree",
    "sha": "949cca4061149050d603e87861b2937e2d9da2c4",
    "files": [
        {
            "sha": "cbf7caa84e87a145fb8c415c2236663665a88e0b",
            "filename": ".github/workflows/build_pr_documentation.yml",
            "status": "modified",
            "additions": 0,
            "deletions": 1,
            "changes": 1,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/.github%2Fworkflows%2Fbuild_pr_documentation.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/.github%2Fworkflows%2Fbuild_pr_documentation.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/.github%2Fworkflows%2Fbuild_pr_documentation.yml?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -15,4 +15,3 @@ jobs:\n       pr_number: ${{ github.event.number }}\n       package: transformers\n       languages: ar de en es fr hi it ko pt tr zh ja te\n-      custom_container: huggingface/transformers-doc-builder"
        },
        {
            "sha": "00d898e4d180f3e225851da1f89f9813e27ddefd",
            "filename": "docs/source/en/_toctree.yml",
            "status": "modified",
            "additions": 4,
            "deletions": 0,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/docs%2Fsource%2Fen%2F_toctree.yml",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/docs%2Fsource%2Fen%2F_toctree.yml",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2F_toctree.yml?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -985,6 +985,8 @@\n         title: Qwen2VL\n       - local: model_doc/sam\n         title: Segment Anything\n+      - local: model_doc/shieldgemma2\n+        title: ShieldGemma2\n       - local: model_doc/siglip\n         title: SigLIP\n       - local: model_doc/siglip2\n@@ -1044,6 +1046,8 @@\n   - sections:\n     - local: internal/modeling_utils\n       title: Custom Layers and Utilities\n+    - local: internal/model_debugging_utils\n+      title: Utilities for Model Debugging\n     - local: internal/pipelines_utils\n       title: Utilities for pipelines\n     - local: internal/tokenization_utils"
        },
        {
            "sha": "ab11a45b34479d8f915af56a574284a53503e960",
            "filename": "docs/source/en/internal/model_debugging_utils.md",
            "status": "modified",
            "additions": 3,
            "deletions": 3,
            "changes": 6,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/docs%2Fsource%2Fen%2Finternal%2Fmodel_debugging_utils.md",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/docs%2Fsource%2Fen%2Finternal%2Fmodel_debugging_utils.md",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/docs%2Fsource%2Fen%2Finternal%2Fmodel_debugging_utils.md?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -26,7 +26,7 @@ Most of those are only useful if you are adding new models in the library.\n \n ### Model addition debugger - context manager for model adders\n \n-This context manager is a power user tool intended for model adders. \n+This context manager is a power user tool intended for model adders.\n It tracks all forward calls within a model forward and logs a slice of each input and output on a nested Json.\n To note, this context manager enforces `torch.inference_mode()`.\n \n@@ -66,6 +66,6 @@ with model_addition_debugger_context(model, \"optional_path_to_your_output_file.j\n ```\n \n \n-[[autodoc]] utils.model_addition_debugger\n+[[autodoc]] model_addition_debugger\n \n-[[autodoc]] utils.model_addition_debugger_context\n+[[autodoc]] model_addition_debugger_context"
        },
        {
            "sha": "9a538a9a3b835c5402a94f3b029067ab09eabd77",
            "filename": "setup.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/setup.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/setup.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/setup.py?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -121,8 +121,8 @@\n     \"importlib_metadata\",\n     \"ipadic>=1.0.0,<2.0\",\n     \"isort>=5.5.4\",\n-    \"jax>=0.4.27,<=0.4.38\",\n-    \"jaxlib>=0.4.27,<=0.4.38\",\n+    \"jax>=0.4.1,<=0.4.13\",\n+    \"jaxlib>=0.4.1,<=0.4.13\",\n     \"jieba\",\n     \"jinja2>=3.1.0\",\n     \"kenlm\","
        },
        {
            "sha": "c87bd3a27f230739fd630f520ed8f9b500d0d75b",
            "filename": "src/transformers/dependency_versions_table.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/src%2Ftransformers%2Fdependency_versions_table.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/src%2Ftransformers%2Fdependency_versions_table.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fdependency_versions_table.py?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -28,8 +28,8 @@\n     \"importlib_metadata\": \"importlib_metadata\",\n     \"ipadic\": \"ipadic>=1.0.0,<2.0\",\n     \"isort\": \"isort>=5.5.4\",\n-    \"jax\": \"jax>=0.4.27,<=0.4.38\",\n-    \"jaxlib\": \"jaxlib>=0.4.27,<=0.4.38\",\n+    \"jax\": \"jax>=0.4.1,<=0.4.13\",\n+    \"jaxlib\": \"jaxlib>=0.4.1,<=0.4.13\",\n     \"jieba\": \"jieba\",\n     \"jinja2\": \"jinja2>=3.1.0\",\n     \"kenlm\": \"kenlm\","
        },
        {
            "sha": "1826e64ff08be95e005cf06a331768d8d2ba7282",
            "filename": "src/transformers/models/shieldgemma2/modeling_shieldgemma2.py",
            "status": "modified",
            "additions": 18,
            "deletions": 24,
            "changes": 42,
            "blob_url": "https://github.com/huggingface/transformers/blob/949cca4061149050d603e87861b2937e2d9da2c4/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/949cca4061149050d603e87861b2937e2d9da2c4/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fshieldgemma2%2Fmodeling_shieldgemma2.py?ref=949cca4061149050d603e87861b2937e2d9da2c4",
            "patch": "@@ -25,7 +25,6 @@\n from ...utils import (\n     add_start_docstrings_to_model_forward,\n     logging,\n-    replace_return_docstrings,\n )\n from ...utils.deprecation import deprecate_kwarg\n from ..auto import AutoModelForImageTextToText\n@@ -109,25 +108,6 @@\n             Indices depicting the position of the input sequence tokens in the sequence. Contrarily to `position_ids`,\n             this tensor is not affected by padding. It is used to update the cache in the correct position and to infer\n             the complete sequence length.\n-\n-    Returns:\n-        A `ShieldGemma2ImageClassifierOutputWithNoAttention` instance continaing the logits and probabilities\n-        associated with the model predicting the `Yes` or `No` token as the response to that prompt, captured in the\n-        following properties.\n-\n-            *   `logits` (`torch.Tensor` of shape `(batch_size, 2)`):\n-                The first position along dim=1 is the logits for the `Yes` token and the second position along dim=1 is\n-                the logits for the `No` token.\n-            *   `probabilities` (`torch.Tensor` of shape `(batch_size, 2)`):\n-                The first position along dim=1 is the probability of predicting the `Yes` token and the second position\n-                along dim=1 is the probability of predicting the `No` token.\n-\n-        ShieldGemma prompts are constructed such that predicting the `Yes` token means the content *does violate* the\n-        policy as described. If you are only interested in the violative condition, use\n-        `violated = outputs.probabilities[:, 1]` to extract that slice from the output tensors.\n-\n-        When used with the `ShieldGemma2Processor`, the `batch_size` will be equal to `len(images) * len(policies)`,\n-        and the order within the batch will be img1_policy1, ... img1_policyN, ... imgM_policyN.\n \"\"\"\n \n \n@@ -172,9 +152,6 @@ def tie_weights(self):\n \n     @deprecate_kwarg(\"num_logits_to_keep\", version=\"4.50\", new_name=\"logits_to_keep\")\n     @add_start_docstrings_to_model_forward(SHIELDGEMMA2_INPUTS_DOCSTRING)\n-    @replace_return_docstrings(\n-        output_type=ShieldGemma2ImageClassifierOutputWithNoAttention, config_class=_CONFIG_FOR_DOC\n-    )\n     def forward(\n         self,\n         input_ids: torch.LongTensor = None,\n@@ -193,9 +170,26 @@ def forward(\n         logits_to_keep: Union[int, torch.Tensor] = 0,\n         **lm_kwargs,\n     ) -> ShieldGemma2ImageClassifierOutputWithNoAttention:\n-        \"\"\"Predicts the binary probability that the image violates the speicfied policy.\n+        \"\"\"Predicts the binary probability that the image violates the specified policy.\n \n         Returns:\n+            A `ShieldGemma2ImageClassifierOutputWithNoAttention` instance containing the logits and probabilities\n+            associated with the model predicting the `Yes` or `No` token as the response to that prompt, captured in the\n+            following properties.\n+\n+                *   `logits` (`torch.Tensor` of shape `(batch_size, 2)`):\n+                    The first position along dim=1 is the logits for the `Yes` token and the second position along dim=1 is\n+                    the logits for the `No` token.\n+                *   `probabilities` (`torch.Tensor` of shape `(batch_size, 2)`):\n+                    The first position along dim=1 is the probability of predicting the `Yes` token and the second position\n+                    along dim=1 is the probability of predicting the `No` token.\n+\n+            ShieldGemma prompts are constructed such that predicting the `Yes` token means the content *does violate* the\n+            policy as described. If you are only interested in the violative condition, use\n+            `violated = outputs.probabilities[:, 1]` to extract that slice from the output tensors.\n+\n+            When used with the `ShieldGemma2Processor`, the `batch_size` will be equal to `len(images) * len(policies)`,\n+            and the order within the batch will be img1_policy1, ... img1_policyN, ... imgM_policyN.\n         \"\"\"\n         outputs = self.model(\n             input_ids=input_ids,"
        }
    ],
    "stats": {
        "total": 61,
        "additions": 29,
        "deletions": 32
    }
}