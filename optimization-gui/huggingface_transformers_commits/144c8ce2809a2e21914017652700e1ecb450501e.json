{
    "author": "diegoakel",
    "message": "Fix modular docstring for Mixtral (#42041)\n\n* Fix modular docstring for Mixtral\n\n* fixes all docstrings",
    "sha": "144c8ce2809a2e21914017652700e1ecb450501e",
    "files": [
        {
            "sha": "a3f4eb0d334086b831cf8ba864208b3dafc9d785",
            "filename": "src/transformers/models/deepseek_v2/modeling_deepseek_v2.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v2%2Fmodeling_deepseek_v2.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -59,8 +59,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "51e720a2eedf34c421598c18e87dde9e34f52c21",
            "filename": "src/transformers/models/deepseek_v3/modeling_deepseek_v3.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdeepseek_v3%2Fmodeling_deepseek_v3.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -166,8 +166,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "d4a8188e24c65ecc34edf02029a7685b0bc03a53",
            "filename": "src/transformers/models/dots1/modeling_dots1.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fdots1%2Fmodeling_dots1.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -322,8 +322,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "01d10317cf09de38f095c6c0467813e7bd81817e",
            "filename": "src/transformers/models/flex_olmo/modeling_flex_olmo.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fflex_olmo%2Fmodeling_flex_olmo.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -310,8 +310,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "f7bc01465160427922047cbdb21424dfb8290c86",
            "filename": "src/transformers/models/glm4_moe/modeling_glm4_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4_moe%2Fmodeling_glm4_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -347,8 +347,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "7afb2e0b1463a4d912218f6a5e6ac2a1d24aa031",
            "filename": "src/transformers/models/glm4v_moe/modeling_glm4v_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fglm4v_moe%2Fmodeling_glm4v_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -368,8 +368,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "732bafbd336d3f2fa6ffdc9af1c0fe98155337c9",
            "filename": "src/transformers/models/hunyuan_v1_moe/modeling_hunyuan_v1_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fhunyuan_v1_moe%2Fmodeling_hunyuan_v1_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -261,8 +261,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "94d8cdc3f7be43148e78584cf2325edd0306a1be",
            "filename": "src/transformers/models/jamba/modeling_jamba.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fjamba%2Fmodeling_jamba.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -575,8 +575,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "ebc8d892bf314af475c93a8b5436f1412e9a4b36",
            "filename": "src/transformers/models/lfm2_moe/modeling_lfm2_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Flfm2_moe%2Fmodeling_lfm2_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -161,8 +161,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "7e8a499ed56eabc66c2f23762640077aa9c172e7",
            "filename": "src/transformers/models/minimax/modeling_minimax.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fminimax%2Fmodeling_minimax.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -488,8 +488,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "d6b1b1100ba061fe44621d11c28d472bdca42586",
            "filename": "src/transformers/models/mixtral/modeling_mixtral.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodeling_mixtral.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -89,8 +89,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "65ea9b2e6b36d0cbad0d76dd7bb975e786486486",
            "filename": "src/transformers/models/mixtral/modular_mixtral.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodular_mixtral.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodular_mixtral.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fmixtral%2Fmodular_mixtral.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -167,8 +167,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "f6034bd9fc6f8f7ab37fd1d69126a5dbd3328ef9",
            "filename": "src/transformers/models/olmoe/modeling_olmoe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Folmoe%2Fmodeling_olmoe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -313,8 +313,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "58733405678d64def703a8b4f68452b300b10ae0",
            "filename": "src/transformers/models/phimoe/modeling_phimoe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fphimoe%2Fmodeling_phimoe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -360,8 +360,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "d1e309f612c672e9fb45e82c00d3ebae7c84859b",
            "filename": "src/transformers/models/qwen2_moe/modeling_qwen2_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen2_moe%2Fmodeling_qwen2_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -306,8 +306,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "ff0855c223ee8c37d856820e5d43eec8a687a12a",
            "filename": "src/transformers/models/qwen3_moe/modeling_qwen3_moe.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_moe%2Fmodeling_qwen3_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -226,8 +226,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "3847c43117a36c5ef08504030ddb2a8d9e11cf04",
            "filename": "src/transformers/models/qwen3_next/modeling_qwen3_next.py",
            "status": "modified",
            "additions": 2,
            "deletions": 2,
            "changes": 4,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_next%2Fmodeling_qwen3_next.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -836,8 +836,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        },
        {
            "sha": "aabd906dc3b25324ffa4b87a7dd2d6c804a7e5f0",
            "filename": "src/transformers/models/qwen3_omni_moe/modeling_qwen3_omni_moe.py",
            "status": "modified",
            "additions": 4,
            "deletions": 4,
            "changes": 8,
            "blob_url": "https://github.com/huggingface/transformers/blob/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "raw_url": "https://github.com/huggingface/transformers/raw/144c8ce2809a2e21914017652700e1ecb450501e/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py",
            "contents_url": "https://api.github.com/repos/huggingface/transformers/contents/src%2Ftransformers%2Fmodels%2Fqwen3_omni_moe%2Fmodeling_qwen3_omni_moe.py?ref=144c8ce2809a2e21914017652700e1ecb450501e",
            "patch": "@@ -1340,8 +1340,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\"\n@@ -2724,8 +2724,8 @@ def forward(\n         \"\"\"\n         Args:\n             hidden_states: (batch_size * sequence_length, hidden_dim)\n-            selected_experts: (batch_size * sequence_length, top_k)\n-            routing_weights: (batch_size * sequence_length, top_k)\n+            top_k_index: (batch_size * sequence_length, top_k)\n+            top_k_weights: (batch_size * sequence_length, top_k)\n         Returns:\n             (batch_size * sequence_length, hidden_dim)\n         \"\"\""
        }
    ],
    "stats": {
        "total": 76,
        "additions": 38,
        "deletions": 38
    }
}